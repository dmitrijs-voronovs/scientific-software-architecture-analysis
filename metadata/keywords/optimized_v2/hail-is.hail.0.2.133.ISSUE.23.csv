quality_attribute,sentence,source,author,repo,version,id,keyword,matched_word,match_idx,wiki,url,total_similar,target_keywords,target_matched_words
Testability,Could you run benchmarks?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10867#issuecomment-920949276:14,benchmark,benchmarks,14,https://hail.is,https://github.com/hail-is/hail/pull/10867#issuecomment-920949276,1,['benchmark'],['benchmarks']
Testability,"Couples changes:; - Explicitly convert numpy types to hail types and don't only accept numpy floats. Apparently `np.array_equal` is very relaxed and will coerce between ints and booleans so the test that should have caught this now checks the types too.; - There was a subtle bug when extracting the numpy ndarray values into python. The values were always being extracted in row-major order, regardless of their previous layout in numpy. Changed it so now `row_major` can be `None`, in which case for numpy ndarrays it will use the existing ordering and will default to row major if just entering a python list. Note: row and column major (or in numpy terms, C contiguous and F contiguous) aren't the only options. It can be strided in a bunch of different permutations, but in these cases we read it out of numpy as row major.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6330:194,test,test,194,https://hail.is,https://github.com/hail-is/hail/pull/6330,1,['test'],['test']
Testability,CppCodegen; Running test: Test method testReadWrite(is.hail.annotations.AnnotationsSuite). Gradle suite > Gradle test > is.hail.annotations.AnnotationsSuite.testReadWrite FAILED; org.apache.spark.SparkException at AnnotationsSuite.scala:76; Caused by: java.lang.AssertionError; Running test: Test method testEmptyKeys(is.hail.io.IndexSuite). Gradle suite > Gradle test > is.hail.io.IndexSuite.testEmptyKeys FAILED; java.lang.AssertionError at IndexSuite.scala:42; Running test: Test method testIntervalIterator(is.hail.io.IndexSuite). Gradle suite > Gradle test > is.hail.io.IndexSuite.testIntervalIterator FAILED; java.lang.AssertionError at IndexSuite.scala:42; Running test: Test method testIntervalIteratorWorksWithGeneralEndpoints(is.hail.io.IndexSuite). Gradle suite > Gradle test > is.hail.io.IndexSuite.testIntervalIteratorWorksWithGeneralEndpoints FAILED; java.lang.AssertionError at IndexSuite.scala:42; Running test: Test method testIterateFromUntil(is.hail.io.IndexSuite). Gradle suite > Gradle test > is.hail.io.IndexSuite.testIterateFromUntil FAILED; java.lang.AssertionError at IndexSuite.scala:42; Running test: Test method testLowerBound(is.hail.io.IndexSuite). Gradle suite > Gradle test > is.hail.io.IndexSuite.testLowerBound FAILED; java.lang.AssertionError at IndexSuite.scala:42; Running test: Test method testQueryByKey(is.hail.io.IndexSuite). Gradle suite > Gradle test > is.hail.io.IndexSuite.testQueryByKey FAILED; java.lang.AssertionError at IndexSuite.scala:42; Running test: Test method testRangeIterator(is.hail.io.IndexSuite). Gradle suite > Gradle test > is.hail.io.IndexSuite.testRangeIterator FAILED; java.lang.AssertionError at IndexSuite.scala:42; Running test: Test method testUpperBound(is.hail.io.IndexSuite). Gradle suite > Gradle test > is.hail.io.IndexSuite.testUpperBound FAILED; java.lang.AssertionError at IndexSuite.scala:42; Running test: Test method writeReadGivesSameAsInput[0]([Ljava.lang.String;@49613eb0)(is.hail.io.IndexSuite). Gradle suite > Gradl,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4718:1540,test,test,1540,https://hail.is,https://github.com/hail-is/hail/issues/4718,1,['test'],['test']
Testability,Create fatal and parser exceptions so these can be caught in testing,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/176:61,test,testing,61,https://hail.is,https://github.com/hail-is/hail/issues/176,1,['test'],['testing']
Testability,Create framework for testing tsv output files,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/46:21,test,testing,21,https://hail.is,https://github.com/hail-is/hail/issues/46,1,['test'],['testing']
Testability,Create set of benchmarking / production environment testing standards,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/156:14,benchmark,benchmarking,14,https://hail.is,https://github.com/hail-is/hail/issues/156,2,"['benchmark', 'test']","['benchmarking', 'testing']"
Testability,"Created a Relational IR for `mt.group_by_rows(...).aggregate(...)`. I've never done this before so I just copied and massaged `MatrixMapRows`. It seems a lot longer than I anticipated. Two of the `GroupBySuite` tests exercise this path. The other two use non-IR features. When more things are put into the expr IR, they'll start exercising this path too.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3546:211,test,tests,211,https://hail.is,https://github.com/hail-is/hail/pull/3546,1,['test'],['tests']
Testability,"Created db.py in the experimental folder. In addition, also created a test_experimental.py to test the function as well.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6563:94,test,test,94,https://hail.is,https://github.com/hail-is/hail/pull/6563,1,['test'],['test']
Testability,"Created https://github.com/hail-is/hail/issues/4533 to track testing for account liveliness. There's no good solution to bullet two, I just email GitHub support and ask them to unblock. I guess this page is now the documentation for that.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4517#issuecomment-429135514:61,test,testing,61,https://hail.is,https://github.com/hail-is/hail/issues/4517#issuecomment-429135514,1,['test'],['testing']
Testability,"Creates a responsive table whose dimensions are defined on the parent (allowing child elements to be set as a percentage of that table), by setting width of the parent based on viewport. If the table exceeds that width, it will scroll, such that the elements above the table are still fixed to the flex-end position. See https://github.com/hail-is/hail/pull/7777. Narrow view (very slightly wider, because 75% of 653 is > 75% of 600, and table is in fact 653px at minimum, even when you set 600px min width):; <img width=""774"" alt=""Screenshot 2019-12-27 15 38 52"" src=""https://user-images.githubusercontent.com/5543229/71533028-73d10280-28c4-11ea-99be-bea06bc67a10.png"">. Wide view:; <img width=""1920"" alt=""Screenshot 2019-12-27 15 38 58"" src=""https://user-images.githubusercontent.com/5543229/71533029-73d10280-28c4-11ea-98ef-7b8e3afe3ca3.png"">. Table that is too wide is scrollable (wider than 1024px):; <img width=""804"" alt=""Screenshot 2019-12-27 16 09 18"" src=""https://user-images.githubusercontent.com/5543229/71532988-4be19f00-28c4-11ea-915a-1e038f179d1f.png"">; after scrolling right:; <img width=""1453"" alt=""Screenshot 2019-12-27 16 09 12"" src=""https://user-images.githubusercontent.com/5543229/71532989-4be19f00-28c4-11ea-9fbd-0270c881d085.png"">. Tested manually in browser in Firefox and Chrome.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7786:1255,Test,Tested,1255,https://hail.is,https://github.com/hail-is/hail/pull/7786,1,['Test'],['Tested']
Testability,"Creating network namespaces can often take hundreds of milliseconds (and sometimes seconds with `iptables` contention), so Batch takes this off the job hot path by pre-allocating namespaces. All job namespaces are configured identically and there is a fixed number of ""slots"" on any batch worker (`CORES * 4`), so pre-allocation and asynchronous recycling of namespaces is fairly straight-forward so long as we never attempt to run more containers on a worker than the number of slots (which the scheduling system should prohibit). However, since we started running long-lived JVM containers (#11397), the number of containers running on a given worker can easily be *greater* than `N_SLOTS`. On a 16-core machine, we create 30 JVMs that sit idle waiting for JVMJobs all the while occupying a precious network namespace. I thought for the longest time that #13402 was a race condition so was trying to trigger it through a barrage of quick jobs. Turns out all it took was running >34 long-running jobs on a single 16-core worker. In a dev deploy of `main`, running a batch with 35 quarter-core `sleep 150` jobs fails with a single job timing out waiting for a network. On this branch, I am able to run the same 35 job batch as well as a batch with 64 quarter-core jobs. Unfortunately, we don't have a great way to test ""run all these jobs at once on the same worker"". Resolves #13402",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13678:1314,test,test,1314,https://hail.is,https://github.com/hail-is/hail/pull/13678,1,['test'],['test']
Testability,"Curious if this makes our builds faster. Gradle is per-test-suite parallel, but not per-method-parallel.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2277:55,test,test-suite,55,https://hail.is,https://github.com/hail-is/hail/pull/2277,1,['test'],['test-suite']
Testability,"Curious, did you benchmark this change, in particular the local/field business?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9089#issuecomment-666769626:17,benchmark,benchmark,17,https://hail.is,https://github.com/hail-is/hail/pull/9089#issuecomment-666769626,1,['benchmark'],['benchmark']
Testability,"Current State; ---. When a commit is merged into a deployable target branch, the [CI deploys that commit](https://github.com/hail-is/hail/blob/master/ci/ci/prs.py#L166-L242). If the deploy job fails, we just [log the failure and change nothing](https://github.com/hail-is/hail/blob/master/ci/ci/prs.py#L295-L313). Since `PRS.latest_deployed` for the given target ref is not changed, the CI will attempt to deploy the latest SHA at the next heal point. We heal periodically, when master changes, when review statuses change, and probably elsewhere. Anywhere we call `PRS.heal_target`. Desired State; ---. Instead, we should track the last successful deploy as well as all the failing deploys since then. This enables us to a) not redeploy a failing deploy and b) find the most recent successful deploy and re-deploy that one. If the most recent successful deploy fails again, we should probably error very loudly. Note that when the CI first comes up there will be no most recent successful deploy. The possible situations are:. - most recent deploy succeeded. - no deploy has ever succeeded. - a deploy has succeeded, but some number of SHAs since then have all failed . Motivation; ---. We want to ensure there is a deployed artifact. For some projects a deploy failure does not leave the universe in a bad state. For example, hail itself updates the latest-hash file after all artifact uploads have succeed. For some projects, a half-way passing deployment will interrupt our users.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4435:209,log,log,209,https://hail.is,https://github.com/hail-is/hail/issues/4435,1,['log'],['log']
Testability,"Current State; ---. When a new PR is created or the source SHA for a PR changes, a build is unconditionally started for that SHA merged with the latest target SHA. When the target SHA changes, all PR builds for that target SHA are killed. When a target SHA changes, the CI heals that target. When healing a target, the CI attempts to avoid n^2 unnecessary builds. It achieves this by serializing the build+merge of approved PRs for a given target. When there are no approved PRs, the CI will build every remaining PR with pending/`Buildable` status. If a PR is unapproved and there are a number of approved PRs, it is likely the PR will spend a significant amount of time as ""pending"" as it waits for the approved PRs to be merged. Desired State; ---. The CI should track if a source SHA has ever been tested (success or failure). If the target SHA changes, a build should only be killed if the source SHA has been successfully tested before. If the source SHA changes, a PR build should be killed regardless of whether the old source SHA has been successfully built before.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4438:802,test,tested,802,https://hail.is,https://github.com/hail-is/hail/issues/4438,2,['test'],['tested']
Testability,"Current `getNestedElementPTypesOfSameType` method calls the canonical constructor of each PType it matches on. 2 options: 1) keep the implementation mostly as is, but call `ptype.copy` which calls the appropriate concrete constructor without requiring reflection; 2) use the CastRename (pType.deepRename) pattern. GIven that we've chosen in the case of CastRename not to follow the `getNestedElementPTypesOfSameType` pattern, I think #2 is the more constant option w.r.t our codebase: . default implementation:. ```scala; def unify(ptypes: Seq[PType]) =; ptypes.head.setRequired(ptypes.forall(_.required)); ```. On PCanonicalArray; ```scala; override def unify(ptypes: Seq[PType]) = {; val et = unify(ptypes.map(_.asInstanceOf[PArray].elementType); PCanonicalArray(et, ptypes.forall(_.required)); }; ```. Called from InferPType:. ```scala; def getNestedElementPTypes(ptypes: Seq[PType]): PType = {; assert(ptypes.forall(_.virtualType.isOfType(ptypes.head.virtualType))); ptypes.head.unify(ptypes: Seq[PType]); }; ```. This is necessary for non-canonical physical types to work within the InferPTypes pass. cc @tpoterba",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7921:899,assert,assert,899,https://hail.is,https://github.com/hail-is/hail/issues/7921,1,['assert'],['assert']
Testability,Current behavior is it's testing both D_== and abs(d1 -d2) <= tolerance. Now `absolute=True` specifies use `abs(d1-d2)`. Behavior used to be D_== for everything until I changed it for the BGEN test. So `absolute=True` should only be in the BGEN tests.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3364:25,test,testing,25,https://hail.is,https://github.com/hail-is/hail/pull/3364,3,['test'],"['test', 'testing', 'tests']"
Testability,Currently I'm PRing so that it goes through the batch test suite.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6329:54,test,test,54,https://hail.is,https://github.com/hail-is/hail/pull/6329,1,['test'],['test']
Testability,"Currently `docker/python-dill` images are untested and deployed manually, but used in tests and by our users. #11122 aims to both test and automatically publish those images on every release, but to move forward testing in Azure for now this pushes those images as part of the bootstrapping process. Also removed the `export HAIL` line because operators should be able to define where their hail home is.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11128:86,test,tests,86,https://hail.is,https://github.com/hail-is/hail/pull/11128,3,['test'],"['test', 'testing', 'tests']"
Testability,"Currently a change to `create_database.py` will only be tested once the change is in production, as opposed to in the PR where it was changed. This should fix that.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13008:56,test,tested,56,https://hail.is,https://github.com/hail-is/hail/pull/13008,1,['test'],['tested']
Testability,"Currently hail-vdc uses the GSA for the test user as the GSA for the test-dev user. We should be using different identities. This is done correctly in the other terraform so the following steps only apply to `hail-vdc`. After this change is applied and a new identity for test-dev is created, I will:. - Create a key for the new service account and update `test-dev-gsa-key` with that key; - Update the auth database to set the `hail_identity` for test-dev to the new identity",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13197:40,test,test,40,https://hail.is,https://github.com/hail-is/hail/pull/13197,5,['test'],"['test', 'test-dev', 'test-dev-gsa-key']"
Testability,"Currently if I visit `ci.hail.is` it shows the status of the build that CI ran in GCP. Now that we enforce all CI's pass, we can end up with situations on `ci.hail.is` where the PR is approved and the build was successful but it's not merging because the tests failed over on azure. This shows all the github statuses in addition to the cloud-local build information.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11223:255,test,tests,255,https://hail.is,https://github.com/hail-is/hail/pull/11223,1,['test'],['tests']
Testability,"Currently not used anywhere, but I wrote a test for it.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3376:43,test,test,43,https://hail.is,https://github.com/hail-is/hail/pull/3376,1,['test'],['test']
Testability,"Currently pruning dependencies, forking NextJS to remove poly fills for older browsers, and focusing on bundle size. Investigated using Inferno.js as a lighter alternative to React. Saves ~20-30KB bundle size, and is somewhat faster. However, main Inferno dev moved to React core team, and React is focusing on the optimizations present in Inferno for 2019 (DOM: move to native events where possible), as well as introducing optimizations not found in Inferno (compile time targets: initially inlining, future maybe web assembly binaries; move rendering work to separate thread / concurrent rendering). Furthermore, React ecosystem is orders of magnitude larger, so we can save a huge amount of dev time by avoiding Inferno (N modules * time to develop bespoke module avg), and have greater likelihood of LTS. Notably, I realized that most of my bundle size was coming from inefficient bundling of Material UI and due to Apollo's insanely large graphQL bundle. Removing these now. Lastly, React is actually very efficient. jQuery is ~31.1KB minified. React is 3KB, while React DOM is 33.8KB. In 2019 React DOM will shrink. In any case, given that React is both faster than jQuery, dramatically simplifies development, and introduces development structure, 4KB cost is imo worth it. Related issues:; https://github.com/zeit/next.js/issues/5923. Bundle (with header, authentication logic including jks-rsa verification of token, styles). Index.js is 336 B, _app is 2.89, and that is all that is needed for first page render. _app amortized over all other pages. Scorecard template w/fetch logic is 1.67KB. <img width=""341"" alt=""screen shot 2018-12-19 at 3 43 23 pm"" src=""https://user-images.githubusercontent.com/5543229/50247084-f3202200-03a4-11e9-8232-f1cd2a35958c.png"">",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4931#issuecomment-448652812:1380,log,logic,1380,https://hail.is,https://github.com/hail-is/hail/pull/4931#issuecomment-448652812,4,['log'],['logic']
Testability,Currently tested with TableLiteral on the Spark backend.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9591:10,test,tested,10,https://hail.is,https://github.com/hail-is/hail/pull/9591,1,['test'],['tested']
Testability,"Currently the Ops Agent does not do any parsing of the log message, so the log entry in Google Logging looks like:. ```; jsonPayload: {; message: ""{""severity"":""INFO"",""levelname"":""INFO"",""asctime"":""2024-01-22 16:10:45,748"",""filename"":""worker.py"",""funcNameAndLine"":""<module>:3461"",""message"":""closed"",""hail_log"":1}""; }; ```. The `parse_json` processor extracts the json fields from the message into fields on the `jsonPayload` so it looks like this. ```; jsonPayload: {; asctime: ""2024-01-22 16:14:06,098""; filename: ""worker.py""; funcNameAndLine: ""<module>:180""; hail_log: 1; levelname: ""INFO""; message: ""CLOUD gcp""; }; ```. and only the new `message` field is displayed in the Google Logging row instead of the whole json. This also adds a `severity` field on the log entry so filters such as `SEVERITY!=INFO` work as expected.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14187:55,log,log,55,https://hail.is,https://github.com/hail-is/hail/pull/14187,5,"['Log', 'log']","['Logging', 'log']"
Testability,"Currently the binding structure is redundantly specified in two places: Binds.scala, and the parser. We need the binding structure in the parser to propagate the environment, so we can annotate `Ref` nodes (and a few other things) with their types. But we can't use Binds.scala because we don't yet have an IR. This PR removes environment maintenance from the parser by deferring type annotation to a separate pass (which is simple, because it can use the Binds.scala infrastructure). One consequence is that we can't assign types to nodes like `Ref` during parsing, which means we can't ask for the type of any node during parsing, and by extension we can't ask for types of children in IR node constructors. Instead, all typechecking logic is moved to the `TypeCheck` pass. Some benefits of this change:; * The parser is simpler, as it doesn't have to maintain a typing environment.; * Binds.scala is now the single source of truth on the binding structure of the IR.; * Instead of typechecking being split in an ad-hoc way between IR constructors and the `TypeCheck` pass, all typechecking and type error reporting logic is in one place.; * The parser parses a context-free grammar, no more and no less. If the input is gramatically correct, the parser succeeds.; * We can round trip IR with type errors through the text representation. For instance, if we log an IR that fails TypeCheck, we can copy the IR from the log, parse it, then debug. This change was motivated by my work in progress to convert the parser to use the SSA grammar, which this should greatly simplify. I chose to make the type annotation pass after parsing mutate the IR in place (with the unfortunate exception of `Apply`, which can change into an `ApplyIR` or `ApplySpecial`. Do these really need to be separate nodes?). The type of a `Ref` node was already mutable to allow this sort of deferred annotation, and I've had to make a few other things mutable as well. Alternatively we could rebuild the entire IR to include t",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13990:736,log,logic,736,https://hail.is,https://github.com/hail-is/hail/pull/13990,1,['log'],['logic']
Testability,"Currently there are some tests failures, but they are stemming from me running more tests than I expect to it would seem (i.e. trying to run the NDArray write tests in JVM byte code world). General review of the byt ecode generation stuff would still be appreciated, I'll debug the testing stuff when I get a chance.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6874#issuecomment-521662062:25,test,tests,25,https://hail.is,https://github.com/hail-is/hail/pull/6874#issuecomment-521662062,4,['test'],"['testing', 'tests']"
Testability,"Currently, `hailctl curl` uses `external_url` instead of `url`. As a result,; if `hailctl curl` is used inside a GCE VM or on a k8s pod, the url will always; be `....hail.is` to which GCE VMs and k8s pods likely lack credentials. This was a mistake when I first wrote curl. At that time, I was only using it for; local testing. It will still work for local testing because our deploy configs are; all `external`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8584:319,test,testing,319,https://hail.is,https://github.com/hail-is/hail/pull/8584,2,['test'],['testing']
Testability,"Currently, all cleanup jobs depend on `sink`, which depends on all the deploy/test jobs finishing. This creates a problem -- short-running tests with high resource requirements end up reserving those resources for the full duration of the *longest* job. For instance, the scheduler test takes 14 seconds, but ends up reserving 3 non-preemptible cores for up to 30 minutes!. This can be solved by making the cleanup jobs depend on all descendants of the deploy jobs they are intending to clean up.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6673:78,test,test,78,https://hail.is,https://github.com/hail-is/hail/issues/6673,3,['test'],"['test', 'tests']"
Testability,"Currently, an instance that is `inactive` in batch and `Terminated` per the cloud will enter the second branch and we will call `deactivate`, which since the instance is already inactive will be a no-op. We really want the third branch to be executed in which we call delete on the instance, so that the inactive instances don't hang around forever. Vedant and I paired on this and did some case analysis to restructure the conditions here a little bit. The order of the conditions now doesn't matter and is hopefully more explicit. We also decided that an unspoken case (deleted but not terminated) should be an error scenario, let me know if you think that is an appropriate exception to log here.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11392:690,log,log,690,https://hail.is,https://github.com/hail-is/hail/pull/11392,1,['log'],['log']
Testability,"Currently, attempting to start a Dataproc cluster without either a region argument or a configured `dataproc/region` results in a long error message `subprocess.CalledProcessError: Command '['gcloud', 'dataproc', 'clusters', 'create', ... ]' returned non-zero exit status 1` with the actual cause obscured above the traceback. That cause is:; ```; Failed to find attribute [region]. The attribute can be set in the following ways:; - provide the argument [--region] on the command line; - set the property [dataproc/region]; ```. There is some logic to show a nicer error message if no region is provided. However, that is only shown if `gcloud config get-value dataproc/region` fails. When `dataproc/region` is not set, that command succeeds and outputs an empty string. This change handles that case and shows the nicer error message.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8791:544,log,logic,544,https://hail.is,https://github.com/hail-is/hail/pull/8791,1,['log'],['logic']
Testability,"Currently, dev deploy always eventually returns a timeout in the terminal because it tries to wait for the entire batch deploy / tests to run before returning. Now it will just create the batch and return the batch number instead of waiting.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6670:129,test,tests,129,https://hail.is,https://github.com/hail-is/hail/pull/6670,1,['test'],['tests']
Testability,"Currently, garbage pods will sit around in the batch-pods and test namespaces forever. In anticipation of adding expensive resources (storage), batch needs to learn to clean up after itself. Batch creates garbage whenever it is killed without warning. This happens in two circumstances:; - when batch is killed by a deploy; - CI job is running a test batch instance and is killed because master or the feature branch changed. To mitigate this issue we delete all PVCs (storage, ergo monetarily expensive resources) from the batch-pods namespace before we deploy batch. These PVCs are no longer needed because the batch instance that owns them is about to be re-deployed. Since the test namespace (where CI jobs will spin up batch instances to test) might also contain PVCs, we delete the whole namespace. We can do this because the deploy job (the one running `make deploy` is in the `batch-pods` namespace, not the `test` namespace). Since we delete the whole namespace, we need to recreate anything that's expected to exist there. ---. This is a short term fix. The long term fix mitigates these two situations differently:; - persistence of batch jobs ensures that after a deploy, the new batch instance finds the orphaned resources and adopts them; - each test job will get a fresh namespace in which it creates whatever it needs to test, batch then ensures this namespace is destroyed when the job is finished (which, of course, requires persistence of batch jobs)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5488:62,test,test,62,https://hail.is,https://github.com/hail-is/hail/pull/5488,7,['test'],['test']
Testability,"Currently, jobs in hail batch can only be run on n1 machines but with the rise of deep learning in bioinformatics, the ability to run jobs on g2 machines, as well as other GPU supported machines, is an important and exciting addition to hail batch. This PR highlights the steps needed to add new machine types into hail batch and could be used as a template for further development support. . The changes in this PR can broadly be divided into additions to the job crun container and insertion of g2 resources (CPU, RAM, L4 Accelerator) into the resources table for billing. This PR uses the NVIDIA Container Toolkit, which allows the creation of GPU accelerated containers. This toolkit is integrated with docker via the parameters —runtime=nvidia and the specification of GPUs is made through —gpus all. The toolkit is installed in the batch worker VM startup script and the corresponding docker parameters are configured if the machine type is g2, so there is no change to the docker configuration for n1 machines. For the toolkit to work there is a nvidia hook that needs to be injected into the crun config. These modifications are also done based on machine type. On the billing side, the existing pricing setup was expanded to include g2 machines. The g2 instance cores and RAM are inserted into the database, and the SKUs are hard coded. For future machine type incorporation or updates, [https://cloud.google.com/skus/?currency=USD&filter=](https://cloud.google.com/skus/?currency=USD&filter=) may serve as a useful resource to identify relevant SKU ids. A new resource type was also added for the accelerator, including preemptible and non-preemtible. Finally, g2 machines mount the worker data disk under the name nvme0n2 so the code is updated to reflect this. Future work may want to investigate a way to automatically detect what the proper disk name is or make the disk naming logic more robust.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13430:1892,log,logic,1892,https://hail.is,https://github.com/hail-is/hail/pull/13430,1,['log'],['logic']
Testability,"Currently, tasks to schedule new instances are put on the event loop inside the `Pool` and `JobPrivateInstanceManager` constructors. `Pool.create` and `JobPrivateInstanceManager.create` first instantiate an object of their respective type and then load existing instances from the database into the in-memory instance collection. This could potentially cause the create instances loop to trigger while we're drawing ""existing"" instances, which causes the assertion error in https://github.com/hail-is/hail-tasks/issues/24 when the create instances loop and load instances query race to add the instance to the in-memory data structure. This change moves the task creation from the constructor to the `create` method, so we don't start creating instances until all existing instances are accounted for. I think I would have liked to simply pass the constructor a list of instances, but we can't create an `Instance` without an `InstanceCollection`. Resolves hail-is/hail-tasks#24. I also threw in a bit of cleanup, i.e. removing some variable assignments that didn't seem very helpful and resolving a lint issue where we used `items` where we could just use `values`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11766:455,assert,assertion,455,https://hail.is,https://github.com/hail-is/hail/pull/11766,1,['assert'],['assertion']
Testability,"Currently, the Grafana service deployed with the Hail environment is behind two layers of authentication, since the Grafana NGINX configuration proxies requests to it through the `/auth` route, and the login screen built into Grafana also displays. This change removes the second login screen. Demo at https://internal.hail.is/irademac/grafana.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12192:202,log,login,202,https://hail.is,https://github.com/hail-is/hail/pull/12192,2,['log'],['login']
Testability,"Currently, the MJS and MJC requests from the worker to the driver for a given job can race, as they are run as independent asyncio tasks. This results in unnecessary database load and deadlocks between the MJS and MJC SQL procedures. Rather than address the procedures directly, we enforce that we will never run MJS and MJC concurrently. The system is resilient to never receiving an MJS (as MJC will add any attempt data if not present), so we can make the following changes to the worker:; - Serialize the submission of MJS and MJC requests by having the MJC task wait on the MJS future; - Give up retrying MJS once the job has completed because we will instead just send an MJC. This could potentially reduce the database load for very short jobs. I ran a load test of 10k `true` jobs and `sleep 5` jobs a few times against my namespace and saw 0 deadlocks 🎉",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11824:765,test,test,765,https://hail.is,https://github.com/hail-is/hail/pull/11824,1,['test'],['test']
Testability,"Currently, the `_csrf` cookie is made available to all subdomains of `.hail.is`. This means that if I first visit `batch.hail.is` I get a `_csrf` cookie set for `.hail.is`. That cookie is then reused if I visit `ci.hail.is`. Even more awkward, the same value of the cookie will get reused if I then visit `batch.azure.hail.is`. This isn't that big of a deal, these can all be considered part of the same application that the hail team delivers and secures, but it is very little work to set stricter bounds on where this cookie is sent. By removing the `domain` attribute and using `samesite='strict'`, the cookie's domain will be set by the browser to the domain of the request whose response included the `Set-Cookie` header, e.g. `batch.hail.is` or `internal.hail.is`. `Strict` mode then ensures that the cookie will only be sent to that exact domain, meaning that each application is guaranteed to receive the `_csrf` token that it itself delivered, and a `_csrf` token from CI cannot be used to take actions against Batch. This should not have an adverse impact on existing users' browser sessions. In `render_template` we preserve the value of an existing `_csrf` cookie so this change should do the following:; - Logged in user visits a page with an existing widely scoped (`.hail.is`) `_csrf` cookie; - The server returns a `Set-Cookie` header with a new `_csrf` cookie for strictly the `batch.hail.is` domain but with the same token value as the original `_csrf` cookie; - The user now has two cookies and the browser could send either one on a given request, but it does not matter because they have the same value; - If the user logs out and back in, their old widely scoped cookie will be cleared and they only get the strict cookie from now on.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14180:1220,Log,Logged,1220,https://hail.is,https://github.com/hail-is/hail/pull/14180,2,"['Log', 'log']","['Logged', 'logs']"
Testability,"Currently, the k8s namespace field is used both for routing internal requests inside kubernetes but also external requests over the internet. It also has special logic based on whether the namespace indicates a production or dev environment. For example, if `namespace == 'default'`, then we route external `batch` requests to `batch.<domain>/path`, but if `namespace == foo_dev`, we route external `batch` requests to `internal.<domain>/foo_dev/path`. This PR decouples the namespace field from routing. Aside from being overall more straightforward in my opinion, this is necessary for batch on azure terra where batch is served out of a subpath it does not control and is unrelated to whatever namespace it might reside in. The guiding principle for routing is then as follows: If the config has no subpath, use a subdomain, otherwise put everything under domain + subpath. For example:; - `{'domain': 'hail.is', 'subpath': null}` => `batch.hail.is`; - `{'domain': 'internal.hail.is', 'subpath': '/foo_dev'}` => `internal.hail.is/foo_dev/batch`. Since the CI pipeline runs on current production instances, there is a minor need to stay compatible with old deploy configs (or else hack up the CI build.yaml). It's quite a simple translation though, because if there is no subpath provided we can infer one based on the `default_namespace`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14056:162,log,logic,162,https://hail.is,https://github.com/hail-is/hail/pull/14056,1,['log'],['logic']
Testability,"Currently, the notebook scale tests are broken by this. Aiohttp [has a bug in 3.5](https://github.com/aio-libs/aiohttp/issues/3700) that incorrectly handles cookies in 302 redirects. The master commit was cherry-picked into 3.6.0.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7078:30,test,tests,30,https://hail.is,https://github.com/hail-is/hail/pull/7078,1,['test'],['tests']
Testability,"Currently, the router-resolver returns 500 if the session id is invalid. Instead,; it should return 401. This collapses two states: not authorized due to not being; a developer and not authorized due to not being logged in. This is unfortunate, but; we should avoid leaking information as to *why* this endpoint is unauthorized to; an attacker. Developers, presumably, are knowledgable enough to figure out why; they cannot log in on their own.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8583:213,log,logged,213,https://hail.is,https://github.com/hail-is/hail/pull/8583,2,['log'],"['log', 'logged']"
Testability,"Currently, the test_batch fails for local users. These changes enable test_batch to work for local users with minimal configuration. The only necessary step is for a user to execute:; ```; hailctl config set batch/billing_project hail; ```; All other steps are handled by the test suite, including uploading test data if it does not already exist. I believe this obsoletes `hail-services` bucket. Is that correct?. The main change necessary to support this was a Hail configuration system. There is now a file stored in an [XDG acceptable](https://standards.freedesktop.org/basedir-spec/basedir-spec-latest.html) location to which we can read and write sectioned key-value pairs. The `ServiceBackend` looks in this configuration file if the billing_project is unspecified. The file format is defined by the INI-like configuration file library, [`configparser`](https://docs.python.org/3/library/configparser.html#). `configparser` is included in Python. cc: @cseed your thoughts on `hailctl config` appreciated. I think we'll use this for the query service as well.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8559:276,test,test,276,https://hail.is,https://github.com/hail-is/hail/pull/8559,2,['test'],['test']
Testability,"Currently, this is done in parallel with the existing memory management; tracking (in ptypes), and we assert that the two produce the same; result. This can give us confidence that removing InferPType will not; change semantics.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9999:102,assert,assert,102,https://hail.is,https://github.com/hail-is/hail/pull/9999,1,['assert'],['assert']
Testability,D.map(RDD.scala:286); at org.broadinstitute.hail.methods.MendelErrors.writeMendel(MendelErrors.scala:143); at org.broadinstitute.hail.methods.MendelErrorsSuite.test(MendelErrorsSuite.scala:50); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:696); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:882); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1189); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:767); at org.testng.TestRunner.run(TestRunner.java:617); at org.testng.SuiteRunner.runTest(SuiteRunner.java:348); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:343); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:305); at org.testng.SuiteRunner.run(SuiteRunner.java:254); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1224); at org.testng.TestNG.runSuitesLocally(TestNG.java:1149); at org.testng.TestNG.run(TestNG.java:1057); at org.testng.IDEARemoteTestNG.run(IDEARemoteTestNG.java:72); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:122); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at com.i,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/68#issuecomment-155304880:1782,test,testng,1782,https://hail.is,https://github.com/hail-is/hail/pull/68#issuecomment-155304880,1,['test'],['testng']
Testability,DD$extension1(RichPairRDD.scala:44); 	at is.hail.variant.MatrixTable.typedRDD(MatrixTable.scala:475); 	at is.hail.methods.CalculateConcordance$.apply(CalculateConcordance.scala:108); 	at is.hail.methods.CalculateConcordance.apply(CalculateConcordance.scala); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:280); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:214); 	at java.lang.Thread.run(Thread.java:748)java.lang.AssertionError: assertion failed; 	at scala.Predef$.assert(Predef.scala:156); 	at is.hail.annotations.Region.loadInt(Region.scala:36); 	at is.hail.expr.types.TBinary$.loadLength(TBinary.scala:62); 	at is.hail.annotations.UnsafeRow$.readBinary(UnsafeRow.scala:128); 	at is.hail.annotations.UnsafeRow$.readString(UnsafeRow.scala:139); 	at is.hail.annotations.UnsafeRow$.readAltAllele(UnsafeRow.scala:152); 	at is.hail.annotations.UnsafeRow$.readArrayAltAllele(UnsafeRow.scala:164); 	at is.hail.annotations.UnsafeRow$.read(UnsafeRow.scala:210); 	at is.hail.annotations.UnsafeRow.get(UnsafeRow.scala:257); 	at is.hail.expr.FilterVariants$$anonfun$10.apply(Relational.scala:503); 	at is.hail.expr.FilterVariants$$anonfun$10.apply(Relational.scala:500); 	at scala.collection.Iterator$$anon$13.hasNext(Iterator.scala:463); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.hasNext(OrderedRVD.scala:658); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:408); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$9$$anon$5.has,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2743:7717,Assert,AssertionError,7717,https://hail.is,https://github.com/hail-is/hail/issues/2743,2,"['Assert', 'assert']","['AssertionError', 'assertion']"
Testability,"D_ENABLE_DIRECT_PATH_XDS=true</code>, then run your program.</li>; <li>When configuring your <code>StorageOptions</code> mimic the following:; <pre><code> StorageOptions.grpc(); </code></pre>; </li>; </ol>; </li>; </ol>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/googleapis/java-storage/commit/bfd48a1b5542ff28ffa337eba883c4ca6c3b0aad""><code>bfd48a1</code></a> chore(main): release 2.15.1 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1765"">#1765</a>)</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/3b8d137a113376d7dac9010b9207d435df2622f7""><code>3b8d137</code></a> docs: annotate all Option factory methods with their Nullability bounds (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1775"">#1775</a>)</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/ba49f9d903d1c68f2a67ea56489fc64907d7d31d""><code>ba49f9d</code></a> test(deps): update kms.version to v0.100.0 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1774"">#1774</a>)</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/8c59c64ccf0dd7753467b4c0f0bcf5f4b49c5bf0""><code>8c59c64</code></a> fix: update GrpcStorageImpl#get(BlobId) to return null on 404 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1772"">#1772</a>)</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/2770a38409e89f4f291ebf9ef23db0def0458b02""><code>2770a38</code></a> test(deps): update dependency org.mockito:mockito-core to v4.9.0 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1773"">#1773</a>)</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/45b2b38c3850da1795a7fbd33e0560b949cb7810""><code>45b2b38</code></a> chore: use gcp-docuploader 0.6.3 (<a href=""https://github-redirect.dependabot.com/googleapis",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12529:11743,test,test,11743,https://hail.is,https://github.com/hail-is/hail/pull/12529,1,['test'],['test']
Testability,"D`, possibly with some non-empty key. This is consistent with the rule that the `rvd` must always have a stronger/longer key than the `TableType`.; * **small tweaks** - Now I start working through the `TableIR` nodes, rewriting them to remove explicit uses of `UnpartitionedRVD`. The general plan is to sandwich the rvd logic between `toOrderedRVD` and `toOldStyleRVD`. The first takes an `UnpartitionedRVD` to an `OrderedRVD` with empty key (and leaves `OrderedRVD`s alone), and the second takes an `OrderedRVD` to an `UnpartitionedRVD` if its key was empty, and leaves it alone otherwise. Once they're all rewritten this way, I redefine `toOldStyleRVD` to always return `OrderedRVD`, and `UnpartitionedRVD` is no longer used.; * **remove `TableUnkey`** - With `UnpartitionedRVD` going away, `TableUnkey` is no longer necessary, it's equivalent to keying by an empty key.; * **small tweaks** - these next two rewrite more `TableIR` nodes; * **Merge master** - the big one; * **tweak MatrixColsTable** - 1) Optimize `coerce` by checking if the requested key is empty, avoiding a scan in that case. 2) Optimize `sortedColsValue` by checking if the column key is empty, avoiding the sort in that case. 3) Simplify `colsRVD`, removing the case on the type of the `RVD`, just calling `coerce` and letting the previous optimizations avoid unnecessary work.; * **`distinctByKey` fix** - While looking over `TableIR` implementations, I noticed a bug in `distinctByKey`: you need to be sure no key is split across multiple partitions. To be sure the empty key edge case still works, I added a test to check that `strictify` on an empty-key partitioner will always collapse everything to one partition.; * **Flipped switch** - redifines `toOldStyleRVD` to just return the `OrderedRVD` unchanged, and asserts that `TableValue.rvd` is always an `OrderedRVD`.; * **rest of the `TableIR` tweaks** - added a factory method `OrderedRVD.unkeyed` to replace `UnpartitionedRVD.apply`.; * the rest are simple tidying up",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4319:2411,test,test,2411,https://hail.is,https://github.com/hail-is/hail/pull/4319,2,"['assert', 'test']","['asserts', 'test']"
Testability,"Dan thanks for the comments, some great suggestions. I've addressed some, will get to the rest by Monday. I owe you at least one unit test. You can check the app out at app.hail.is (no SSL yet). Let me know if you have a problem logging in. Currently no one knows the workshop password but me (we can set this to whatever needed), but all team members, besides maybe Dan Goldstein should have access through the normal login. . Login will appear a bit slow because we've decided to not go the popup route, so there's an extra 2 apparent redirects. Also, safari causes some issues if ""Cross-site tracking"" protection is on. A satisfactory solution will be made in time, until then, either another browser, or disable that protection.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5215#issuecomment-460040036:134,test,test,134,https://hail.is,https://github.com/hail-is/hail/pull/5215#issuecomment-460040036,4,"['Log', 'log', 'test']","['Login', 'logging', 'login', 'test']"
Testability,Daniel -- I haven't tested this beyond dev deploy. Can you take a look first to make sure everything makes sense before I do the last test of both the attempt_resources format version < 3 PR changes and these changes to populate the by_date tables?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11996#issuecomment-1178112385:20,test,tested,20,https://hail.is,https://github.com/hail-is/hail/pull/11996#issuecomment-1178112385,2,['test'],"['test', 'tested']"
Testability,Daniels tested omnibus,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11527:8,test,tested,8,https://hail.is,https://github.com/hail-is/hail/pull/11527,1,['test'],['tested']
Testability,"Databases that are not created fail currently without this change; because they try to connect to a database called None. This; is only visible in PR builds and dev deploys. PR builds do; not test this behavior, so I do not think anyone else; has observed it.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8407:192,test,test,192,https://hail.is,https://github.com/hail-is/hail/pull/8407,1,['test'],['test']
Testability,"Dataproc tests passed, woohoo!. I'm gonna hold off on merging until some bug fixes land:; 1. https://github.com/hail-is/hail/pull/13505; 2. https://github.com/hail-is/hail/pull/13500; 3. https://github.com/hail-is/hail/pull/13523; 4. https://github.com/hail-is/hail/pull/13536",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13529#issuecomment-1701663726:9,test,tests,9,https://hail.is,https://github.com/hail-is/hail/pull/13529#issuecomment-1701663726,1,['test'],['tests']
Testability,Decided to tackle this as it was causing noise in the logs. There is no reason this read-only select query should lock any rows.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14443:54,log,logs,54,https://hail.is,https://github.com/hail-is/hail/pull/14443,1,['log'],['logs']
Testability,Defines (but doesn't implement) WritePartition and WriteMetadata nodes as well as stub classes for the writers needed for native TableWrite lowering. WriteMetadata uses IEmitCode; WritePartition is implemented with EmitCode because it consumes a stream.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8925:82,stub,stub,82,https://hail.is,https://github.com/hail-is/hail/pull/8925,1,['stub'],['stub']
Testability,"Defines a TStream/PStream type stub. I've omitted some number of things that other types need to define, as the purpose of the stream type is going to be to ensure that we're never fully instantiating collections where we shouldn't be, e.g. all the rows in a table partition. To that end, I've omitted definitions for ordering since I don't forsee a need for ordering on the entire stream (as opposed to on the element, or a subset thereof), as well as generators for annotations, etc. It basically otherwise mimics the PArray/TArray definitions, but I've made it extend Type/PType directly since most of the extra methods on containers seem irrelevant to streams, having mostly to do with e.g. length and loading specific elements. cc @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5610:31,stub,stub,31,https://hail.is,https://github.com/hail-is/hail/pull/5610,1,['stub'],['stub']
Testability,"Defines, but does not implement, a BlockMatrixCollect value IR node. This is kind of an awkward node currently. We cannot compile nodes with BlockMatrixIRs. We cannot interpret nodes with NDArrayIRs. So we can't compile this or interpret this, unless we define an interpreted version of NDArray (or a compilable version of BlockMatrix). I think this node might eventually be useful for Hail BlockMatrix -> Hail NDArray -> Python ndarray conversions, but for now the intention is to use this as a quick way to start testing BlockMatrix lowering.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8089:515,test,testing,515,https://hail.is,https://github.com/hail-is/hail/pull/8089,1,['test'],['testing']
Testability,Definitely need a benchmark. Will write one. How long is a benchmark allowed to take?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7962#issuecomment-578311507:18,benchmark,benchmark,18,https://hail.is,https://github.com/hail-is/hail/pull/7962#issuecomment-578311507,2,['benchmark'],['benchmark']
Testability,DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:696); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:882); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1189); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:767); at org.testng.TestRunner.run(TestRunner.java:617); at org.testng.SuiteRunner.runTest(SuiteRunner.java:348); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:343); at org.testng.SuiteRunner.privateRun(SuiteRunner.java:305); at org.testng.SuiteRunner.run(SuiteRunner.java:254); at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); at org.testng.TestNG.runSuitesSequentially(TestNG.java:1224); at org.testng.TestNG.runSuitesLocally(TestNG.java:1149); at org.testng.TestNG.run(TestNG.java:1057); at org.testng.IDEARemoteTestNG.run(IDEARemoteTestNG.java:72); at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:122); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at com.intellij.rt.execution.application.AppMain.main(AppMain.java:144); Caused by: java.lang.reflect.InvocationTargetException; at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43),MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/68#issuecomment-155304880:2137,test,testng,2137,https://hail.is,https://github.com/hail-is/hail/pull/68#issuecomment-155304880,1,['test'],['testng']
Testability,Delete TestRDDBuilder and gqDpStatsSuite,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3606:7,Test,TestRDDBuilder,7,https://hail.is,https://github.com/hail-is/hail/pull/3606,1,['Test'],['TestRDDBuilder']
Testability,"Deleting in col key branch. ```. def test_trio_matrix(self):; """"""; This test depends on certain properties of the trio matrix VCF; and pedigree structure. This test is NOT a valid test if the pedigree includes quads:; the trio_matrix method will duplicate the parents appropriately,; but the genotypes_table and samples_table orthogonal paths would; require another duplication/explode that we haven't written.; """"""; ped = Pedigree.read(test_file('triomatrix.fam')); famkt = KeyTable.import_fam(test_file('triomatrix.fam')). vds = hc.import_vcf(test_file('triomatrix.vcf'))\; .annotate_samples_table(famkt, root='sa.fam'). dads = famkt.filter('isDefined(pat_id)')\; .annotate('is_dad = true')\; .select(['pat_id', 'is_dad'])\; .key_by('pat_id'). moms = famkt.filter('isDefined(mat_id)') \; .annotate('is_mom = true') \; .select(['mat_id', 'is_mom']) \; .key_by('mat_id'). # test genotypes; gkt = (vds.genotypes_table(); .key_by('s'); .join(dads, how='left'); .join(moms, how='left'); .annotate('is_dad = isDefined(is_dad), is_mom = isDefined(is_mom)'); .aggregate_by_key('v = v, fam = fam.fam_id',; 'data = GT.map(_ => {role: if (is_dad) 1 else if (is_mom) 2 else 0, g: {GT: GT, AD: AD, GQ: GQ, DP: DP, PL: PL}}).collect()'); .filter('data.length() == 3'); .explode('data'); .select(['v', 'fam', 'data'])). tkt = (vds.trio_matrix(ped, complete_trios=True); .genotypes_table(); .annotate('fam = proband.fields.fam.fam_id, data = [{role: 0, g: proband}, {role: 1, g: father}, {role: 2, g: mother}]'); .select(['v', 'fam', 'data']); .explode('data'); .filter('isDefined(data.g)'); .key_by(['v', 'fam'])). self.assertTrue(gkt.same(tkt)). # test annotations; g_sa = (vds.samples_table(); .join(dads, how='left'); .join(moms, how='left'); .annotate('is_dad = isDefined(is_dad), is_mom = isDefined(is_mom)'); .aggregate_by_key('fam = fam.fam_id',; 'data = map(sa => {role: if (is_dad) 1 else if (is_mom) 2 else 0, sa: sa}).collect()'); .filter('data.length() == 3'); .explode('data'); .select(['fam', 'data']",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2814:72,test,test,72,https://hail.is,https://github.com/hail-is/hail/issues/2814,4,['test'],['test']
Testability,"Depending on how long the benchmark takes, you might want to make it work harder by setting k to something bigger, like 500 to 1000.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9888#issuecomment-761060616:26,benchmark,benchmark,26,https://hail.is,https://github.com/hail-is/hail/pull/9888#issuecomment-761060616,1,['benchmark'],['benchmark']
Testability,"Depends on #2848 and #2861, I'll rebase once those are in. LocalMatrix has pointwise +,-,*,% ops with broadcasting, matrix ops, etc. It's meant to mirror NumPy restricted to always having 2 axes (we may eventually want to introduce np.array into the expression language). Vectors are identified with a single column rather than having a separate class. Once this is in, I'll rename the distributedmatrix package to linalg. Next step is to build Python interface starting with those ops I need to pull over much of LMM pipeline, with testing on the Python side against Numpy.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2860:533,test,testing,533,https://hail.is,https://github.com/hail-is/hail/pull/2860,1,['test'],['testing']
Testability,"Depends on #3539. (first new commit is ""filled out block-sparse matrix support""). Third and final major PR to introduce block-sparse matrices. All block matrix operations are now supported apart from the following cases that are most likely user error (and even these can be forced by applying the new method `densify` first):; - Division between two block matrices.; - Multiplication by a scalar or broadcasted vector which includes an infinite or ``nan`` value.; - Division by a scalar or broadcasted vector which includes a zero, infinite or ``nan`` value.; - Division of a scalar or broadcasted vector by a block matrix.; - Exponentiation by a negative exponent. The following operations are newly supported:; - Addition and subtraction of block matrices, resulting in ""union"" of realized blocks.; - Addition and subtraction of a scalar or broadcasted vector, resulting in a block-dense matrix.; - Slicing, and more generally row/column filtering, resulting in a block-dense matrix. New infrastructure includes:; - `supersetPartitions` in RichRDD, analogue of `subsetPartitions`, used to densify/realizeBlocks; - `BlockMatrixUnionOpRDD`, so far applied for `+` and `-` but able to support more general ops. Throughout I've aimed to support the block-sparse case while minimizing overhead on the more common block-dense case, particularly with `maybeSparse = None` when block-dense. Docs and tests updated accordingly.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3636:1395,test,tests,1395,https://hail.is,https://github.com/hail-is/hail/pull/3636,1,['test'],['tests']
Testability,"Depends on #4049 and #4121. . @danking I'm concerned I changed the meaning of your `file_row_index` field and the code you specialized for Caitlin is broken with this PR. That field is always sorted now from 0 to nVariants. Before, the indices were the order in the BGEN file. Now they're the variant index into the actual index file. I had to change/delete some of the Python tests because they didn't make sense anymore. Next PR will support push down by locus, alleles rather than row index and this shouldn't be a concern anymore (and we can delete file_row_index). If you think the change in behavior will cause problems, I'll close this PR.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4102:377,test,tests,377,https://hail.is,https://github.com/hail-is/hail/pull/4102,1,['test'],['tests']
Testability,"Depends on (and includes changes in) #2661. This PR adds:; RowPartitioner and RowPartitionerSuite; RowMatrix.readBlockMatrix and tests in RowMatrixSuite; forceRowMajor parameter to BlockMatrix.write, included in tests; forceRowMajor to richDenseMatrixDouble. Currently I use skipBytes (which reads and throws away) to advance the DataInputStream. @cseed do you have advice on how to use seek instead?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2665:129,test,tests,129,https://hail.is,https://github.com/hail-is/hail/pull/2665,2,['test'],['tests']
Testability,"Deploy commits don't need to cleanup which adds some latency to this PR. We should probably use xargs -P4 to delete instances 4-way parallel. This PR is ~46 minutes, including all the cleanup time, where as deploys are 46 minutes *without the cleanup time*. Notice two things: (1) the service backend is again the critical path (2) some local backend tests took quite a while to get scheduled. Seems fishy to me that it took ~16 minutes to find a core for the local backend tests to run on. Anyway, seems good to use more fine-grained parallelism. This should help keep the cluster large-ish and turning over fast so that users get a great experience during the work day. ---. A deploy commit:. <img width=""2032"" alt=""Screen Shot 2023-05-17 at 17 30 55"" src=""https://github.com/hail-is/hail/assets/106194/9c00365e-1079-451c-bd85-e10561e715c1"">. This PR:. <img width=""2032"" alt=""Screen Shot 2023-05-17 at 17 34 40"" src=""https://github.com/hail-is/hail/assets/106194/fa7751be-3986-4361-89ea-e322760176bf"">",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13076#issuecomment-1552119464:351,test,tests,351,https://hail.is,https://github.com/hail-is/hail/pull/13076#issuecomment-1552119464,2,['test'],['tests']
Testability,"Deploying grafana in our GKE cluster gives us instant and easy access to the stackdriver backend with the same querying capabilities of our current front-end, but without the clutter and insanely slow load times. See [here](https://internal.hail.is/dgoldste/grafana/d/TVkleyLMk/detailed-service-resource-utilization?orgId=1) for some example dashboards I set up to look at resources across our services (credentials are the default admin/admin). This alleviates the immediate pain of using the console (for metrics only, not logging), but my longer aim is that getting more regular use out of our metrics can reveal deeper pain points of our monitoring stack and if/where we need to eat up more responsibility from google monitoring. This is a StatefulSet, so configuration through the UI will persist and is done manually. If we find that our dashboards are stable and boilerplate enough, I'd like to move to a code-based dashboard configuration. Sadly, `check-yaml` does not appreciate our jinja templating in yaml, so I've removed it for now. cc: @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10013:525,log,logging,525,https://hail.is,https://github.com/hail-is/hail/pull/10013,1,['log'],['logging']
Testability,"Despite the pretty daunting diff I think this is a pretty ""small"" change and perhaps an easier one start out with in the migration from nginx -> envoy than gateway/internal-gateway (certainly less risky). I've tested these manually by make deploying and they work both in dev namespaces and default. Currently, the grafana and prometheus pods have two containers: the app itself (grafana or prometheus) and an nginx container that sits in front of it. The flow is as follows, and since this works the exact same for both prometheus and grafana I will just talk about grafana as the example and the same thing should apply to both:. 1. User sends request to grafana.hail.is; 2. Gateway sees an HTTP request going to a production service and forwards that request to the grafana k8s Service port 443; 3. The grafana K8s Service forwards that request to the grafana pod port 443; 4. Nginx is listening on port 443 in the grafana pod and receives that request. It makes an authorization check to auth to make sure that the request is coming from a developer; 5. Nginx forwards that request to 127.0.0.1:3000, which is where grafana is listening. This PR does not change any behavior, just replaces Nginx with Envoy. Currently, building the nginx container involves running jinja on its config files and building a docker image. With envoy, we can just use the `envoyproxy/envoy` image from DockerHub (which I have copied into our container registries) and feed it a single configmap. The big mess of yaml that is the new configmap for envoy has a lot of boilerplate, but it comprises of the following sections which hopefully on their own are not too bad. ### Envoy config; 1. The top of the `listeners` section shows that Envoy is listening on port 8443 (which is the port that the k8s `Service` will now forward traffic to); 2. The `virtual_hosts` section shows that Envoy will send all paths (prefix ""/"") to the cluster `grafana`; 3. The `http_filters` section says that Envoy will first send an author",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12364:210,test,tested,210,https://hail.is,https://github.com/hail-is/hail/pull/12364,1,['test'],['tested']
Testability,"Dev certificates expire in 30 days, and rerunning `kubectl create secret` doesn't update the secret if it already exists. So adding a `kubectl delete secret` line to make sure the new secret will be added. Though I'm not familiar with the `test` scope and not sure if it will break something for it?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10188:240,test,test,240,https://hail.is,https://github.com/hail-is/hail/pull/10188,1,['test'],['test']
Testability,"Did I never PR the VEP splitting logic? I don't see it, so I must not have. I'll wait for this to go in and then do it then",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4076#issuecomment-411258192:33,log,logic,33,https://hail.is,https://github.com/hail-is/hail/pull/4076#issuecomment-411258192,1,['log'],['logic']
Testability,"Did a local test of prometheus_async on a tiny aiohttp server, turns out the order of the decorators does matter. The timing decorator has to be on the bottom to actually time anything successfully. Does the order of any of the other decorators matter?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6570:12,test,test,12,https://hail.is,https://github.com/hail-is/hail/pull/6570,1,['test'],['test']
Testability,"Did my best, the behavior of this lowering functionality is complex, and it's hard to come up with a universal solution. The current issue I'm struggling with is the failure it testArrayAggContexts, which finds a ToArray(StreamRange()) being passed to EmitStream, instead of a StreamRange. TLDR: my ArrayAgg rule is stupid and fucked. Options: 1) Fix this rule, 2) (Seems not as good) In Emit have ArrayAgg needs to pass its child through Emit.emit a second time to match on ToArray, 3) make unstreamify more specific, such that ArrayAgg is allowed to take streams directly. ToArray definitely needs to wrap StreamRange in some cases (for instance MakeTuple(ToArray(StreamRange)), else get issues with the stream passed to SRVB. it would be helpful to have the intended (but currently applicable) design of stream/array semantics written down for all nodes (maybe it exists, I'll dig through design docs). Besides this 2 more failures.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8063#issuecomment-583795904:177,test,testArrayAggContexts,177,https://hail.is,https://github.com/hail-is/hail/pull/8063#issuecomment-583795904,1,['test'],['testArrayAggContexts']
Testability,Did you add the example above or similar as a regression test?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3763#issuecomment-400038312:57,test,test,57,https://hail.is,https://github.com/hail-is/hail/issues/3763#issuecomment-400038312,1,['test'],['test']
Testability,"Did you confirm that the behaviors being tested in the deleted `checkedConvertFrom` tests are tested elsewhere for `copyFromType`? Otherwise, looks good.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9503#issuecomment-699076394:41,test,tested,41,https://hail.is,https://github.com/hail-is/hail/pull/9503#issuecomment-699076394,3,['test'],"['tested', 'tests']"
Testability,Did you do a benchmark on this one vs main? Might be interesting after the first splitting caused general improvements.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10566#issuecomment-856828775:13,benchmark,benchmark,13,https://hail.is,https://github.com/hail-is/hail/pull/10566#issuecomment-856828775,1,['benchmark'],['benchmark']
Testability,"Directly run the pipeline tests, instead of launching a pod to run them. This is the first of a bunch of these (create accounts, various create tables, various tests). The only hard one is test-batch, since it needs to handle a callback.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7507:26,test,tests,26,https://hail.is,https://github.com/hail-is/hail/pull/7507,3,['test'],"['test-batch', 'tests']"
Testability,Directly test CI instead of going through pod.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7590:9,test,test,9,https://hail.is,https://github.com/hail-is/hail/pull/7590,1,['test'],['test']
Testability,Disable CXX tests to alleviate test times,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5547:12,test,tests,12,https://hail.is,https://github.com/hail-is/hail/pull/5547,2,['test'],"['test', 'tests']"
Testability,Disable PC-Relate test,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3274:18,test,test,18,https://hail.is,https://github.com/hail-is/hail/pull/3274,1,['test'],['test']
Testability,Disable dataproc vep tests,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6126:21,test,tests,21,https://hail.is,https://github.com/hail-is/hail/pull/6126,1,['test'],['tests']
Testability,"Disables the test `test_tree_matmul_splits`, which seems to be leaking memory, and causing tests run after it to timeout. Disabling to allow CI to make progress on other PRs, but we do need to diagnose the actual issue here.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14550:13,test,test,13,https://hail.is,https://github.com/hail-is/hail/pull/14550,2,['test'],"['test', 'tests']"
Testability,Discovered in azure when it couldn't run the auth copy-paste token tests. We don't see this in google because we use Cloud DNS for resolving *.hail to internal gateway for private jobs (we use /etc/hosts and a public resolver for public jobs). In Azure I decided to forego azure dns and just use the /etc/hosts route for all of our jobs.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11098:67,test,tests,67,https://hail.is,https://github.com/hail-is/hail/pull/11098,1,['test'],['tests']
Testability,"Dismissed the review so that CI would focus on other PRs, but feel free to re-enable. We can chat tomorrow about how to test the query service with a custom JAR",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11345#issuecomment-1057659976:120,test,test,120,https://hail.is,https://github.com/hail-is/hail/pull/11345#issuecomment-1057659976,1,['test'],['test']
Testability,"Disregard the message above. The auto increment would not work. Now the critical check to make sure no duplicates are added is this line:. ```python3; job_id = parameters.get('job_id'); has_record = await db.jobs.has_record(batch_id, job_id); if has_record:; log.info(f""database has record for ({batch_id}, {job_id})""); abort(400, f'invalid request: batch {batch_id} already has a job_id={job_id}'); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6238#issuecomment-498043583:259,log,log,259,https://hail.is,https://github.com/hail-is/hail/pull/6238#issuecomment-498043583,1,['log'],['log']
Testability,"Do I need to do something on my end in order to test copying from my computer rather than through CI? I keep getting a 400 regardless of whether I use my bucket `hail-jigold` or the test bucket `hail-test-dmk9z`. The only information I can get is ""Bad Request"" which I think is from this:. > The request cannot be completed based on your current Cloud Storage settings. For example, you cannot lock a retention policy if the requested bucket doesn't have a retention policy, and you cannot set ACLs if the requested bucket has Bucket Policy Only enabled. I don't think this is the real error as we know copying works fine with the Hail test bucket.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10218#issuecomment-813514852:48,test,test,48,https://hail.is,https://github.com/hail-is/hail/pull/10218#issuecomment-813514852,4,['test'],"['test', 'test-']"
Testability,Do I need to take action on this PR? I'm OK with this change if it passes the tests.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11397#issuecomment-1070987703:78,test,tests,78,https://hail.is,https://github.com/hail-is/hail/pull/11397#issuecomment-1070987703,1,['test'],['tests']
Testability,Do java tests run with the debug allocator? I'm just getting a segfault.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10583#issuecomment-859774905:8,test,tests,8,https://hail.is,https://github.com/hail-is/hail/pull/10583#issuecomment-859774905,1,['test'],['tests']
Testability,Do not approve this if test_backwards_compatibility dramatically inflates test time,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11589:74,test,test,74,https://hail.is,https://github.com/hail-is/hail/pull/11589,1,['test'],['test']
Testability,Do not merge this. Should fail one test.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/656:35,test,test,35,https://hail.is,https://github.com/hail-is/hail/pull/656,1,['test'],['test']
Testability,Do not print JSON literal values in the log,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4911:40,log,log,40,https://hail.is,https://github.com/hail-is/hail/pull/4911,1,['log'],['log']
Testability,Do our tests pass with the flag on?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11302#issuecomment-1026259006:7,test,tests,7,https://hail.is,https://github.com/hail-is/hail/pull/11302#issuecomment-1026259006,1,['test'],['tests']
Testability,Do we have a benchmark or similar to show the improvement here?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9011#issuecomment-648947947:13,benchmark,benchmark,13,https://hail.is,https://github.com/hail-is/hail/pull/9011#issuecomment-648947947,1,['benchmark'],['benchmark']
Testability,Do we have a logging agent installed inside the containers themselves? I'd have thought that was on the worker VM. Seems like we could go to 22.04 in all the containers. It does mean our worker VM is out of sync with the containers.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11859#issuecomment-1138723739:13,log,logging,13,https://hail.is,https://github.com/hail-is/hail/pull/11859#issuecomment-1138723739,1,['log'],['logging']
Testability,"Do you have an alternative suggestion? We test export/import is the identity, which is a nice property.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4147#issuecomment-415026464:42,test,test,42,https://hail.is,https://github.com/hail-is/hail/issues/4147#issuecomment-415026464,1,['test'],['test']
Testability,"Do you have an error message other than that failed post? I'm not seeing why that would stop a deploy. In #13115, the PR healing code is after the `_heal_deploy` code, so I don't know why an exception when healing a PR would stop a deploy from occurring. This POST error is also occurring on GCP. Definitely something to fix but I'm not sure why it's related. > This caused problems because the next merge candidates CI was selecting was causing bad GitHub rate limit requests for exceeding the number of statuses. So it kept retrying that same merge candidate. Unfortunately I'm not sure if this is relevant in Azure. Azure CI thinks about merge candidate when it comes to testing PRs, but it doesn't merge any PRs and whether or not it does a deploy just depends if there's a new commit on `main`, it shouldn't have to do with PRs.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13050#issuecomment-1561903065:674,test,testing,674,https://hail.is,https://github.com/hail-is/hail/issues/13050#issuecomment-1561903065,1,['test'],['testing']
Testability,Do you have the log handy?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/446#issuecomment-234642726:16,log,log,16,https://hail.is,https://github.com/hail-is/hail/pull/446#issuecomment-234642726,1,['log'],['log']
Testability,"Do you mean when showing the log in the UI or the final upload to blob storage?. I think that's a great idea for the UI, where we show a truncated view in the page and the download button provides a way to stream the log file without loading it into memory on the front-end. In terms of the final upload, I'm a little wary about making a breaking change like that. It's probably true that if you're spewing tons of logs as a user you probably want to not do that. But if we move later to hosting logs in user-provided buckets instead of our own bucket there's no reason why they shouldn't be able to write large logs if they want to.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12852#issuecomment-1570846197:29,log,log,29,https://hail.is,https://github.com/hail-is/hail/issues/12852#issuecomment-1570846197,5,['log'],"['log', 'logs']"
Testability,"Do you the cumulative transmitted and untransmitted counts per trio? If so,; what would you do with said information?. On Nov 3, 2016 5:40 PM, ""Tarjinder Singh"" notifications@github.com wrote:. > The current TDT command tests for transmission disequilibrium for each; > variant across a number of trios. However, it would be helpful to get; > transmission information on each parent-proband trio as well, similar to; > how Mendelian-inconsistent variants are identified on Hail. Would this be; > possible?; > Thanks :); > ; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > https://github.com/hail-is/hail/issues/1055, or mute the thread; > https://github.com/notifications/unsubscribe-auth/AFZ8NdTOzvtMjAnFJ5N9Ann-ohY0EM8Iks5q6lTdgaJpZM4Ko8yy; > .",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1055#issuecomment-258307806:220,test,tests,220,https://hail.is,https://github.com/hail-is/hail/issues/1055#issuecomment-258307806,1,['test'],['tests']
Testability,Do you want me to create a user in the test namespace? The user creation script supports arbitrary namespaces.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5866#issuecomment-482268052:39,test,test,39,https://hail.is,https://github.com/hail-is/hail/pull/5866#issuecomment-482268052,1,['test'],['test']
Testability,"Docker jobs were cleaning up after themselves by including the entire directory for that job which removed the old container files. This PR makes it so `Container.remove()` removes the directory for the container. Before we merge this, I want to check the logs for this PR and make sure there aren't error messages that don't show up in tests.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12397:256,log,logs,256,https://hail.is,https://github.com/hail-is/hail/pull/12397,2,"['log', 'test']","['logs', 'tests']"
Testability,Docker requires the `-f` tag to purge an image from its cache if multiple tags reference the same image ID. Checked to make sure that this couldn't accidentally disturb the worker container and added an assert because we should never even try to remove the worker image.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10681:203,assert,assert,203,https://hail.is,https://github.com/hail-is/hail/pull/10681,1,['assert'],['assert']
Testability,"Docs and a bunch of other updates are done. Ready for review!. Once it's in, I'll refactor linreg, logreg, and lmmreg commands to put the phenotype and covariate extraction logic in one place under stats.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1064#issuecomment-260219957:99,log,logreg,99,https://hail.is,https://github.com/hail-is/hail/pull/1064#issuecomment-260219957,2,['log'],"['logic', 'logreg']"
Testability,"Does not work (passes) with PL present in all rows, which surprised me since type should be virtual type should be taken as stated, I believe. Haven't investigated further (stats day) to see what the IR generated is. Also does not work if I edit the VCF file and insert a bogus PL of .,.,. for each sample. An upcast seems to be happening in the mt1 child, because PL is clearly missing in mt2:. <img width=""705"" alt=""Screenshot 2020-01-31 12 40 13"" src=""https://user-images.githubusercontent.com/5543229/73561429-f9e1eb00-4426-11ea-9bb8-0cec77398d92.png"">. code in updated, pushed test. edit, to show that mt1 does have expected entries (though this shouldn't matter unless array_elements_required doesn't loosen requiredeness over the imputed type):. MT1:; <img width=""170"" alt=""Screenshot 2020-01-31 12 47 00"" src=""https://user-images.githubusercontent.com/5543229/73561943-07e43b80-4428-11ea-847e-65f2f3771af8.png"">; MT2:; <img width=""208"" alt=""Screenshot 2020-01-31 12 47 05"" src=""https://user-images.githubusercontent.com/5543229/73561944-087cd200-4428-11ea-8968-6daf53291d83.png"">",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8008#issuecomment-580834992:582,test,test,582,https://hail.is,https://github.com/hail-is/hail/pull/8008#issuecomment-580834992,2,['test'],['test']
Testability,Does the Hail local backend hold things in memory longer than it should? Or maybe the tests do?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12981#issuecomment-1562909597:86,test,tests,86,https://hail.is,https://github.com/hail-is/hail/pull/12981#issuecomment-1562909597,1,['test'],['tests']
Testability,"Does this fix https://github.com/hail-is/hail/blob/master/hail/python/test/hail/expr/test_expr.py#L1829 ?. ```; # FIXME: this next line triggers a bug: None should be sorted last!; # self.assertEqual(hl.sorted([0, 1, 4, hl.null(tint), 3, 2], lambda x: x, reverse=True).collect()[0], [4, 3, 2, 1, 0, None]); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5084#issuecomment-453185348:70,test,test,70,https://hail.is,https://github.com/hail-is/hail/pull/5084#issuecomment-453185348,2,"['assert', 'test']","['assertEqual', 'test']"
Testability,"Does this look right? We aren't including the test repo on deploy, so we shouldn't create it/can't test against it.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7814:46,test,test,46,https://hail.is,https://github.com/hail-is/hail/pull/7814,2,['test'],['test']
Testability,Does this need a test?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1972#issuecomment-315444947:17,test,test,17,https://hail.is,https://github.com/hail-is/hail/pull/1972#issuecomment-315444947,1,['test'],['test']
Testability,Doing and administrator merge override because I'm afraid CI won't be alive long enough to successfully test this PR.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4572#issuecomment-430813198:104,test,test,104,https://hail.is,https://github.com/hail-is/hail/pull/4572#issuecomment-430813198,1,['test'],['test']
Testability,"Don't convert variant to locus/alleles in fromLegacy.; Fix from legacy callers. VSM.gen is the only place that needs that logic now.; Remove Variant/AltAllele methods from FunctionRegistry. Removed combineVariants. Can be done in Python now.; Removed unused LDMatrix. The list of places (T)Variant is used now is very small: VSM generators, VEP/Nirvana and some importers.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2934:122,log,logic,122,https://hail.is,https://github.com/hail-is/hail/pull/2934,1,['log'],['logic']
Testability,Don't forget to remind me that we need to look at the CI logs and make sure the test suite actually got ran.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11227#issuecomment-1013357056:57,log,logs,57,https://hail.is,https://github.com/hail-is/hail/pull/11227#issuecomment-1013357056,2,"['log', 'test']","['logs', 'test']"
Testability,Don't know why the diff looks so weird -- I just dropped benchmark down one level into `benchmark/run`.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6588#issuecomment-509640521:57,benchmark,benchmark,57,https://hail.is,https://github.com/hail-is/hail/pull/6588#issuecomment-509640521,2,['benchmark'],['benchmark']
Testability,"Don't merge it yet, I want to sort out the testing issues even though I think that's a local problem.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/294#issuecomment-210115731:43,test,testing,43,https://hail.is,https://github.com/hail-is/hail/pull/294#issuecomment-210115731,1,['test'],['testing']
Testability,"Don't think all the tests pass yet, but its single digit python tests failing now.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9825#issuecomment-769978628:20,test,tests,20,https://hail.is,https://github.com/hail-is/hail/pull/9825#issuecomment-769978628,2,['test'],['tests']
Testability,Don't worry about approving this yet. I still need to test it.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4836#issuecomment-444967849:54,test,test,54,https://hail.is,https://github.com/hail-is/hail/pull/4836#issuecomment-444967849,1,['test'],['test']
Testability,Done: https://github.com/broadinstitute/hail/commit/5a3981eec849e5b2046d62fb867cfc18eb22952c. Can run tests with gradle -Dhail.master=<master> or with spark-submit.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/130#issuecomment-172673947:102,test,tests,102,https://hail.is,https://github.com/hail-is/hail/issues/130#issuecomment-172673947,1,['test'],['tests']
Testability,Done: see ExprSuite.testTypePretty.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/230#issuecomment-208688839:20,test,testTypePretty,20,https://hail.is,https://github.com/hail-is/hail/issues/230#issuecomment-208688839,1,['test'],['testTypePretty']
Testability,Double check that the test is what you want. I made the bounds pretty wide to make sure we never had an unlucky sporadic test failure.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10748#issuecomment-893816262:22,test,test,22,https://hail.is,https://github.com/hail-is/hail/pull/10748#issuecomment-893816262,2,['test'],['test']
Testability,"Drat, it appears that pyspark doesn't work with Python 3.8. https://stackoverflow.com/a/58849063/342839. A simpler reproduction to demonstrate that this is a pyspark issues:. ```; snafu$ python -m pyspark.cloudpickle; Traceback (most recent call last):; File ""/usr/lib/python3.8/runpy.py"", line 185, in _run_module_as_main; mod_name, mod_spec, code = _get_module_details(mod_name, _Error); File ""/usr/lib/python3.8/runpy.py"", line 111, in _get_module_details; __import__(pkg_name); File ""/home/reece/sandbox/hail/venv/3.8/lib/python3.8/site-packages/pyspark/__init__.py"", line 51, in <module>; from pyspark.context import SparkContext; File ""/home/reece/sandbox/hail/venv/3.8/lib/python3.8/site-packages/pyspark/context.py"", line 31, in <module>; from pyspark import accumulators; File ""/home/reece/sandbox/hail/venv/3.8/lib/python3.8/site-packages/pyspark/accumulators.py"", line 97, in <module>; from pyspark.serializers import read_int, PickleSerializer; File ""/home/reece/sandbox/hail/venv/3.8/lib/python3.8/site-packages/pyspark/serializers.py"", line 71, in <module>; from pyspark import cloudpickle; File ""/home/reece/sandbox/hail/venv/3.8/lib/python3.8/site-packages/pyspark/cloudpickle.py"", line 145, in <module>; _cell_set_template_code = _make_cell_set_template_code(); File ""/home/reece/sandbox/hail/venv/3.8/lib/python3.8/site-packages/pyspark/cloudpickle.py"", line 126, in _make_cell_set_template_code; return types.CodeType(; TypeError: an integer is required (got type bytes); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/10197#issuecomment-800647452:500,sandbox,sandbox,500,https://hail.is,https://github.com/hail-is/hail/issues/10197#issuecomment-800647452,12,['sandbox'],['sandbox']
Testability,"Due to a noisy co-occurring batch from a user, we discovered several of our tests that assumed they could burst into mostly unused cpu. I backed off on their timeouts and also restricted them to their limited number of cores.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13277#issuecomment-1644771781:76,test,tests,76,https://hail.is,https://github.com/hail-is/hail/pull/13277#issuecomment-1644771781,1,['test'],['tests']
Testability,Due to most of these failures being due to service tests. Feel free to revert when you see fit,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10178:51,test,tests,51,https://hail.is,https://github.com/hail-is/hail/pull/10178,1,['test'],['tests']
Testability,Duplicated R code for fisher.test and C code from here: https://github.com/wch/r-source/blob/e5b21d0397c607883ff25cca379687b86933d730/src/library/stats/src/zeroin.c,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/409:29,test,test,29,https://hail.is,https://github.com/hail-is/hail/pull/409,1,['test'],['test']
Testability,"During a test that created 30,000 pods a number of pods timed out waiting for `gsa-key` or `default-token-8h99c` to mount. Example:; ```; 9m13s Warning FailedMount Pod Unable to mount volumes for pod ""batch-278-job-10258-a49a81_batch-pods(82ea5910-9ccb-11e9-ad88-42010a800049)"": timeout expired waiting for volumes to attach or mount for pod ""batch-pods""/""batch-278-job-10258-a49a81"". list of unmounted volumes=[gsa-key default-token-8h99c]. list of unattached volumes=[gsa-key default-token-8h99c]; ```. All events not containing the string ""Successfully created batch-pods"" [events.log](https://github.com/hail-is/hail/files/3350369/events.log)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6546:9,test,test,9,https://hail.is,https://github.com/hail-is/hail/issues/6546,3,"['log', 'test']","['log', 'test']"
Testability,During testing of our gnomAD v4 exome dataset we determined that there was better separation of x-ploidy values by using only the variant dataset to determine the mean DP of chromosome X rather than the reference blocks. This PR is my attempt to add an option to the the VDS `impute_sex_chromosome_ploidy` method that will only compute the ploidy estimates using the variant dataset instead of the default option of using the reference blocks. The code should still filter to variants that fall within the `calling_intervals`.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11701:7,test,testing,7,https://hail.is,https://github.com/hail-is/hail/pull/11701,1,['test'],['testing']
Testability,"E/python:`echo $SPARK_HOME/python/lib/py4j*-src.zip`""; export SPARK_CLASSPATH=$HAIL_HOME/build/libs/hail-all-spark.jar; ```; I put the vcf file in hadoop， as follows:; ```; [hdfs@tele-1 root]$ hdfs dfs -ls /hail/test; Found 1 items; -rw-r--r-- 3 hdfs supergroup 21194 2017-08-08 18:20 /hail/test/BRCA1.raw_indel.vcf; ```; But when I excuted the command:; ```; hc.import_vcf('/hail/test/BRCA1.raw_indel.vcf').write('/hail/test/brca1.vds'); ```; there are some errors：; ```; [hdfs@tele-1 root]$ python; Python 2.7.13 |Anaconda 4.4.0 (64-bit)| (default, Dec 20 2016, 23:09:15) ; [GCC 4.4.7 20120313 (Red Hat 4.4.7-1)] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; Anaconda is brought to you by Continuum Analytics.; Please check out: http://continuum.io/thanks and https://anaconda.org; >>> import hail; >>> hc = hail.HailContext(); Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; hail: info: SparkUI: http://192.168.1.4:4041; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.1-0320a61; >>> hc.import_vcf('/hail/test/BRCA1.raw_indel.vcf').write('/hail/test/brca1.vds'); hail: warning: `/hail/test/BRCA1.raw_indel.vcf' refers to no files; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-483>"", line 2, in import_vcf; File ""/opt/Software/hail/python/hail/java.py"", line 112, in handle_py4j; 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)); hail.java.FatalError: HailException: arguments refer to no files. Java stack trace:; is.hail.utils.HailException: arguments refer to no files; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:6); 	at is.hail.utils.package$.fatal(package.scala:25); 	at is.hail.io.vcf.LoadVCF$.globAllVCFs(LoadVCF.scala:105); 	at is.hail.HailContext.importVCFs(HailContext.scala:523); 	at sun.reflect.Nativ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2076:1398,log,logging,1398,https://hail.is,https://github.com/hail-is/hail/issues/2076,1,['log'],['logging']
Testability,"E=hadoop; QTLIB=/usr/lib64/qt-3.3/lib; SSH_CONNECTION=103.37.196.84 60539 192.168.124.160 22; LESSOPEN=||/usr/bin/lesspipe.sh %s; XDG_RUNTIME_DIR=/run/user/995; _=/usr/bin/env; ```; </p>; </details> . ```sh ; /usr/bin/which: no scala in (/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/aws/puppet/bin/); ```. ## Debug mode. ```sh; $ set -x; ++ printf '\033]0;%s@%s:%s\007' hadoop ip-192-168-124-160 '~'; $ spark-shell; + spark-shell; SLF4J: No SLF4J providers were found.; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See https://www.slf4j.org/codes.html#noProviders for further details.; SLF4J: Class path contains SLF4J bindings targeting slf4j-api versions 1.7.x or earlier.; SLF4J: Ignoring binding found at [jar:file:/usr/lib/spark/jars/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: See https://www.slf4j.org/codes.html#ignoredBindings for an explanation.; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Exception in thread ""main"" java.lang.NoSuchMethodError: 'scala.reflect.internal.settings.MutableSettings scala.reflect.internal.settings.MutableSettings$.SettingsOps(scala.reflect.internal.settings.MutableSettings)'; at scala.tools.nsc.interpreter.ILoop.$anonfun$chooseReader$1(ILoop.scala:914); at scala.tools.nsc.interpreter.ILoop.mkReader$1(ILoop.scala:920); at scala.tools.nsc.interpreter.ILoop.$anonfun$chooseReader$4(ILoop.scala:926); at scala.tools.nsc.interpreter.ILoop.$anonfun$chooseReader$3(ILoop.scala:926); at scala.tools.nsc.interpreter.ILoop.chooseReader(ILoop.scala:926); at org.apache.spark.repl.SparkILoop.$anonfun$process$1(SparkILoop.scala:138); at scala.Option.fold(Option.scala:251); at org.apache.spark.repl.SparkILoop.newReader$1(SparkILoop.scala:138); at org.apache.spark.repl.SparkILoop.preLoop$1(SparkILoop.scala:142); at org.apache.spark.repl.SparkILoop.$anonfun$process$10(SparkILoop.scala:20",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13837#issuecomment-1772153045:9470,log,logging,9470,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1772153045,1,['log'],['logging']
Testability,"EDIT: We changed the behavior of wait in this PR to use the same backoff we use in the rest of the code base. Context: The list_jobs_v2 test failed in production because SQL treats NULL values as False and those records don't end up in the result set. For example, a ready job will not be in the result set for `start_time != 1970-01-01`. So we need to ensure the job is actually running before executing the tests.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13289:136,test,test,136,https://hail.is,https://github.com/hail-is/hail/pull/13289,2,['test'],"['test', 'tests']"
Testability,"ERSION=3.3.0; ```. Here I get an error. ```sh ; + pip-compile --quiet python/requirements.txt python/pinned-requirements.txt --output-file=/tmp/tmp.aWUFJ1BMnP; ../check_pip_requirements.sh: line 13: pip-compile: command not found; ```. While I do have pip-compile installed. ```sh ; pip-compile --help; Usage: pip-compile [OPTIONS] [SRC_FILES]... Compiles requirements.txt from requirements.in, pyproject.toml, setup.cfg,; or setup.py specs. Options:; ```. Note that `make clean` did not solve the issue. see logs attached. ### Version. 0.2.120. ### Relevant log output. ```shell; BUILD SUCCESSFUL in 2m 46s; 4 actionable tasks: 4 executed; cp -f build/libs/hail-all-spark.jar python/hail/backend/hail-all-spark.jar; rm -rf build/deploy; mkdir -p build/deploy; mkdir -p build/deploy/src; cp ../README.md build/deploy/; rsync -r \; --exclude '.eggs/' \; --exclude '.pytest_cache/' \; --exclude '__pycache__/' \; --exclude 'benchmark_hail/' \; --exclude '.mypy_cache/' \; --exclude 'docs/' \; --exclude 'dist/' \; --exclude 'test/' \; --exclude '*.log' \; python/ build/deploy/; # Clear the bdist build cache before building the wheel; cd build/deploy; rm -rf build; python3 setup.py -q sdist bdist_wheel; /usr/lib64/python3.8/distutils/dist.py:274: UserWarning: Unknown distribution option: 'long_description_content_type'; warnings.warn(msg); installing to build/bdist.linux-x86_64/wheel; creating build/bdist.linux-x86_64/wheel/hail-0.2.120.dist-info/WHEEL; creating 'dist/hail-0.2.120-py3-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it; adding 'hail/__init__.py'; adding 'hail/builtin_references.py'; adding 'hail/conftest.py'; adding 'hail/context.py'; adding 'hail/hail_logging.py'; adding 'hail/hail_pip_version'; adding 'hail/hail_revision'; adding 'hail/hail_version'; adding 'hail/matrixtable.py'; adding 'hail/table.py'; adding 'hail/backend/__init__.py'; adding 'hail/backend/backend.py'; adding 'hail/backend/hail-all-spark.jar'; adding 'hail/backend/local_backend.py'; ad",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13445:1335,test,test,1335,https://hail.is,https://github.com/hail-is/hail/issues/13445,1,['test'],['test']
Testability,"ETUPTOOLS-3180412) | `setuptools:` <br> `39.0.1 -> 65.5.1` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | Open Redirect <br/>[SNYK-PYTHON-TORNADO-5537286](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5537286) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-5840803](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5840803) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-6041512](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-6041512) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit . Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI1ZGE3Y2E3NS1mMTYxLTRmN2EtYWU3Zi1jOTJiYjc0N2VjYTkiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjVkYTdjYTc1LWYxNjEtNGY3YS1hZTdmLWM5MmJiNzQ3ZWNhOSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14074:4137,test,tested,4137,https://hail.is,https://github.com/hail-is/hail/pull/14074,1,['test'],['tested']
Testability,"ETUPTOOLS-3180412) | `setuptools:` <br> `39.0.1 -> 65.5.1` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | Open Redirect <br/>[SNYK-PYTHON-TORNADO-5537286](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5537286) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-5840803](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5840803) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-6041512](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-6041512) | `tornado:` <br> `6.2 -> 6.3.3` <br> | No | No Known Exploit . Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJmMDZmMzgzNi1lYTNhLTQxNDMtYmE5OS0xMmI3YWQzMzc1M2QiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImYwNmYzODM2LWVhM2EtNDE0My1iYTk5LTEyYjdhZDMzNzUzZCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14259:4793,test,tested,4793,https://hail.is,https://github.com/hail-is/hail/pull/14259,1,['test'],['tested']
Testability,"E_FILE__20} '; '--sparseSigmaFile=${__RESOURCE_FILE__9} '; '--IsSingleVarinGroupTest=TRUE '; '--IsOutputAFinCaseCtrl=TRUE 2>&1 | tee '; '${__RESOURCE_FILE__749}'],; 'env': [{'name': 'POD_IP',; 'value': None,; 'value_from': {'config_map_key_ref': None,; 'field_ref': {'api_version': 'v1',; 'field_path': 'status.podIP'},; 'resource_field_ref': None,; 'secret_key_ref': None}},; {'name': 'POD_NAME',; 'value': None,; 'value_from': {'config_map_key_ref': None,; 'field_ref': {'api_version': 'v1',; 'field_path': 'metadata.name'},; 'resource_field_ref': None,; 'secret_key_ref': None}}],; 'env_from': None,; 'image': 'konradjk/saige:0.35.8.2.2',; 'image_pull_policy': 'IfNotPresent',; 'lifecycle': None,; 'liveness_probe': None,; 'name': 'main',; 'ports': None,; 'readiness_probe': None,; 'resources': {'limits': None,; 'requests': {'cpu': '1',; 'memory': '500M'}},; 'security_context': None,; 'stdin': None,; 'stdin_once': None,; 'termination_message_path': '/dev/termination-log',; 'termination_message_policy': 'File',; 'tty': None,; 'volume_devices': None,; 'volume_mounts': [{'mount_path': '/gsa-key',; 'mount_propagation': None,; 'name': 'gsa-key',; 'read_only': None,; 'sub_path': None},; {'mount_path': '/io',; 'mount_propagation': None,; 'name': 'batch-2554-job-4-8vvgl',; 'read_only': None,; 'sub_path': None},; {'mount_path': '/var/run/secrets/kubernetes.io/serviceaccount',; 'mount_propagation': None,; 'name': 'default-token-8h99c',; 'read_only': True,; 'sub_path': None}],; 'working_dir': None}],; 'dns_config': None,; 'dns_policy': 'ClusterFirst',; 'enable_service_links': True,; 'host_aliases': None,; 'host_ipc': None,; 'host_network': None,; 'host_pid': None,; 'hostname': None,; 'image_pull_secrets': None,; 'init_containers': None,; 'node_name': 'gke-vdc-preemptible-pool-9c7148b2-4gq2',; 'node_selector': None,; 'priority': 500000,; 'priority_class_name': 'user',; 'readiness_gates': None,; 'restart_policy': 'Never',; 'runtime_class_name': None,; 'scheduler_name': 'default-schedule",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6466#issuecomment-505429649:3931,log,log,3931,https://hail.is,https://github.com/hail-is/hail/issues/6466#issuecomment-505429649,1,['log'],['log']
Testability,"Edit: Ready for a look, besides google sa key secret creation, because I'm not completely sure what the use case is, and whether it should be a namespaced secret. Since speaking with Cotton, I've moved to using our cloud mysql instance to track user resources, to ensure that a single user id results in a single resource. We can use auth0, but that would add complexity, and would really only make sense in the context of notebook (or whatever we end up managing users) I think: while auth0 allows you to add custom claims, I believe you need to first get the user's access token (via authentication), then call (server side, no user input needed) the /management api endpoint to check the existence of the claims, and update if they do not exist. So this requires user interaction. Would need to confirm this, if proven true, we will eventually be able to circumvent this by connecting our own database to their service ([they allow this](https://auth0.com/docs/connections/database/custom-db)). Still separately tracking mapping between user id and our resources feels relatively natural, and simpler. . Right now you could supply any identifier for the user_id, as long as its globally unique. I think using the auth0 id makes the most sense, since that is a guaranteed-unique id. I will need to provide you a way to get those ids if you want to use this outside of notebook2. edit: I opted not to separate user table from resources the user owns, because I expect one row per user, so not denormalized. Also, still needs some tests written (mysql related). cc @jigold, @cseed, @danking",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5618:1531,test,tests,1531,https://hail.is,https://github.com/hail-is/hail/pull/5618,1,['test'],['tests']
Testability,Eh. This has gotten pretty easy with `http://ci.hail.is/ui/job-log/NUMBER`. I'm not sure the rest of this is all that important.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4620#issuecomment-451593136:63,log,log,63,https://hail.is,https://github.com/hail-is/hail/issues/4620#issuecomment-451593136,1,['log'],['log']
Testability,Eliminates the two log entries for unclosed connections/sessions on shutdown,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9932:19,log,log,19,https://hail.is,https://github.com/hail-is/hail/pull/9932,1,['log'],['log']
Testability,"Enabling NDArray tests revealed a bug relative to the test suite: MakeNDArray doesn't actually consider row/column major. I added a simple fix for this, predicated on rowMajorIR being a literal, which seems like a reasonable choice.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9094:17,test,tests,17,https://hail.is,https://github.com/hail-is/hail/pull/9094,2,['test'],"['test', 'tests']"
Testability,Endpoints FAILED; java.lang.AssertionError at IndexSuite.scala:42; Running test: Test method testIterateFromUntil(is.hail.io.IndexSuite). Gradle suite > Gradle test > is.hail.io.IndexSuite.testIterateFromUntil FAILED; java.lang.AssertionError at IndexSuite.scala:42; Running test: Test method testLowerBound(is.hail.io.IndexSuite). Gradle suite > Gradle test > is.hail.io.IndexSuite.testLowerBound FAILED; java.lang.AssertionError at IndexSuite.scala:42; Running test: Test method testQueryByKey(is.hail.io.IndexSuite). Gradle suite > Gradle test > is.hail.io.IndexSuite.testQueryByKey FAILED; java.lang.AssertionError at IndexSuite.scala:42; Running test: Test method testRangeIterator(is.hail.io.IndexSuite). Gradle suite > Gradle test > is.hail.io.IndexSuite.testRangeIterator FAILED; java.lang.AssertionError at IndexSuite.scala:42; Running test: Test method testUpperBound(is.hail.io.IndexSuite). Gradle suite > Gradle test > is.hail.io.IndexSuite.testUpperBound FAILED; java.lang.AssertionError at IndexSuite.scala:42; Running test: Test method writeReadGivesSameAsInput[0]([Ljava.lang.String;@49613eb0)(is.hail.io.IndexSuite). Gradle suite > Gradle test > is.hail.io.IndexSuite.writeReadGivesSameAsInput[0]([Ljava.lang.String;@49613eb0) FAILED; java.lang.AssertionError at IndexSuite.scala:42; Running test: Test method writeReadGivesSameAsInput[1]([Ljava.lang.String;@326709be)(is.hail.io.IndexSuite). Gradle suite > Gradle test > is.hail.io.IndexSuite.writeReadGivesSameAsInput[1]([Ljava.lang.String;@326709be) FAILED; java.lang.AssertionError at IndexSuite.scala:42; Running test: Test method writeReadGivesSameAsInput[2]([Ljava.lang.String;@7c5e570e)(is.hail.io.IndexSuite). Gradle suite > Gradle test > is.hail.io.IndexSuite.writeReadGivesSameAsInput[2]([Ljava.lang.String;@7c5e570e) FAILED; java.lang.AssertionError at IndexSuite.scala:42; Running test: Test method writeReadGivesSameAsInput[3]([Ljava.lang.String;@3c90c5dc)(is.hail.io.IndexSuite). Gradle suite > Gradle test > is.hail.io,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4718:2366,Assert,AssertionError,2366,https://hail.is,https://github.com/hail-is/hail/issues/4718,1,['Assert'],['AssertionError']
Testability,"Environment:; - Spark 3.2.0; - Scala 2.12.15. Running: ; ```; make install-on-cluster HAIL_COMPILE_NATIVES=1 SCALA_VERSION=2.12.15 SPARK_VERSION=3.2.0; ```; I get the error:; ```BUILD SUCCESSFUL in 2m 5s; 3 actionable tasks: 3 executed; cp -f build/libs/hail-all-spark.jar python/hail/backend/hail-all-spark.jar; rm -rf build/deploy; mkdir -p build/deploy; mkdir -p build/deploy/src; cp ../README.md build/deploy/; rsync -r \; --exclude '.eggs/' \; --exclude '.pytest_cache/' \; --exclude '__pycache__/' \; --exclude 'benchmark_hail/' \; --exclude '.mypy_cache/' \; --exclude 'docs/' \; --exclude 'dist/' \; --exclude 'test/' \; --exclude '*.log' \; python/ build/deploy/; # Clear the bdist build cache before building the wheel; cd build/deploy; rm -rf build; python3 setup.py -q sdist bdist_wheel; make: *** No rule to make target 'check-pip-lockfiles', needed by 'install-on-cluster'. Stop.; ```. Issue is fixed for me by renaming `install-on-cluster: $(WHEEL) check-pip-lockfiles` -> `install-on-cluster: $(WHEEL) check-pip-lockfile` on line 344 of hail/Makefile. Many thanks,; Barney",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12568:619,test,test,619,https://hail.is,https://github.com/hail-is/hail/issues/12568,2,"['log', 'test']","['log', 'test']"
Testability,"Er, wait, sorry, this thread was about the JAR. That indeed should have been deployed under the current steps (because we run QoB tests). So this is a separate issue, but leaving my comment up for posterity",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13050#issuecomment-1572661584:130,test,tests,130,https://hail.is,https://github.com/hail-is/hail/issues/13050#issuecomment-1572661584,1,['test'],['tests']
Testability,"Erm, actually our tests never upload such a large file.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7024#issuecomment-529590702:18,test,tests,18,https://hail.is,https://github.com/hail-is/hail/pull/7024#issuecomment-529590702,1,['test'],['tests']
Testability,Error at IndexSuite.scala:42; Running test: Test method testQueryByKey(is.hail.io.IndexSuite). Gradle suite > Gradle test > is.hail.io.IndexSuite.testQueryByKey FAILED; java.lang.AssertionError at IndexSuite.scala:42; Running test: Test method testRangeIterator(is.hail.io.IndexSuite). Gradle suite > Gradle test > is.hail.io.IndexSuite.testRangeIterator FAILED; java.lang.AssertionError at IndexSuite.scala:42; Running test: Test method testUpperBound(is.hail.io.IndexSuite). Gradle suite > Gradle test > is.hail.io.IndexSuite.testUpperBound FAILED; java.lang.AssertionError at IndexSuite.scala:42; Running test: Test method writeReadGivesSameAsInput[0]([Ljava.lang.String;@49613eb0)(is.hail.io.IndexSuite). Gradle suite > Gradle test > is.hail.io.IndexSuite.writeReadGivesSameAsInput[0]([Ljava.lang.String;@49613eb0) FAILED; java.lang.AssertionError at IndexSuite.scala:42; Running test: Test method writeReadGivesSameAsInput[1]([Ljava.lang.String;@326709be)(is.hail.io.IndexSuite). Gradle suite > Gradle test > is.hail.io.IndexSuite.writeReadGivesSameAsInput[1]([Ljava.lang.String;@326709be) FAILED; java.lang.AssertionError at IndexSuite.scala:42; Running test: Test method writeReadGivesSameAsInput[2]([Ljava.lang.String;@7c5e570e)(is.hail.io.IndexSuite). Gradle suite > Gradle test > is.hail.io.IndexSuite.writeReadGivesSameAsInput[2]([Ljava.lang.String;@7c5e570e) FAILED; java.lang.AssertionError at IndexSuite.scala:42; Running test: Test method writeReadGivesSameAsInput[3]([Ljava.lang.String;@3c90c5dc)(is.hail.io.IndexSuite). Gradle suite > Gradle test > is.hail.io.IndexSuite.writeReadGivesSameAsInput[3]([Ljava.lang.String;@3c90c5dc) FAILED; java.lang.AssertionError at IndexSuite.scala:42; Running test: Test method writeReadGivesSameAsInput[4]([Ljava.lang.String;@165d0f2d)(is.hail.io.IndexSuite). Gradle suite > Gradle test > is.hail.io.IndexSuite.writeReadGivesSameAsInput[4]([Ljava.lang.String;@165d0f2d) FAILED; java.lang.AssertionError at IndexSuite.scala:42; Running test: Test me,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4718:2812,test,test,2812,https://hail.is,https://github.com/hail-is/hail/issues/4718,1,['test'],['test']
Testability,"Error message is this:. ```; org.apache.spark.SparkException: Task not serializable. Caused by: java.io.NotSerializableException: htsjdk.samtools.reference.FastaSequenceIndex; Serialization stack:; 	- object not serializable (class: htsjdk.samtools.reference.FastaSequenceIndex, value: htsjdk.samtools.reference.FastaSequenceIndex@e7b265e); 	- writeObject data (class: java.util.HashMap); 	- object (class is.hail.io.reference.FastaReader$$anon$1, {}); 	- field (class: is.hail.io.reference.FastaReader, name: cache, type: class java.util.LinkedHashMap); 	- object (class is.hail.io.reference.FastaReader, is.hail.io.reference.FastaReader@5a0e0886); 	- field (class: is.hail.variant.GenomeReference, name: fastaReader, type: class is.hail.io.reference.FastaReader); 	- object (class is.hail.variant.GenomeReference, test); 	- field (class: is.hail.expr.FunctionRegistry$$anonfun$160$$anonfun$apply$94, name: gr$13, type: class is.hail.variant.GRBase); 	- object (class is.hail.expr.FunctionRegistry$$anonfun$160$$anonfun$apply$94, <function2>). plus many more lines; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2881:816,test,test,816,https://hail.is,https://github.com/hail-is/hail/pull/2881,1,['test'],['test']
Testability,"Error message starting up Batch:. ```; raise ApiException(http_resp=r); kubernetes.client.rest.ApiException: (403); Reason: Forbidden; HTTP response headers: HTTPHeaderDict({'Audit-Id': 'fc886821-4fc7-4697-b8d2-a4bc656b45f6', 'Content-Type': 'application/json', 'X-Content-Type-Options': 'nosniff', 'Date': 'Thu, 25 Apr 2019 22:18:26 GMT', 'Content-Length': '252'}); HTTP response body: b'{""kind"":""Status"",""apiVersion"":""v1"",""metadata"":{},""status"":""Failure"",""message"":""pods is forbidden: User \\""system:serviceaccount:batch-pods:default\\"" cannot watch pods in the namespace \\""test\\"""",""reason"":""Forbidden"",""details"":{""kind"":""pods""},""code"":403}\n'; ```. Going to retest, but it seems like this was a one time thing...",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5956#issuecomment-487075273:577,test,test,577,https://hail.is,https://github.com/hail-is/hail/pull/5956#issuecomment-487075273,1,['test'],['test']
Testability,"Especially when issuing a lot of requests, the logging for these can get very spammy. We already back off at an appropriate rate when encoutering rate limits, we have no need to log them for anything other than debugging.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14595:47,log,logging,47,https://hail.is,https://github.com/hail-is/hail/issues/14595,2,['log'],"['log', 'logging']"
Testability,Every PR should run the tests in the Google Cloud Platform,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/744:24,test,tests,24,https://hail.is,https://github.com/hail-is/hail/issues/744,1,['test'],['tests']
Testability,"Every run_image_step that was changed tests hail using `hl.init(master='local[2]')`. This means they all use at least two cores (for some reason, some appear to use >2 cores, I don't know why, I'll investigate as I gather more data about this). This change makes the pod's CPU requests reflect their real usage. This change was motivated by watching the Grafana metric for ""CPU Oversubscription"" and seeing these pods constantly using more than their request.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7022#issuecomment-529556683:38,test,tests,38,https://hail.is,https://github.com/hail-is/hail/pull/7022#issuecomment-529556683,1,['test'],['tests']
Testability,"Every suite is allocated by the gradle test framework, and then only those matching the requested filters are executed. Ergo, non-lazy fields on a suite will be executed (and may trigger errors) even though the suite wasn't requested by the gradle user.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2262:39,test,test,39,https://hail.is,https://github.com/hail-is/hail/pull/2262,1,['test'],['test']
Testability,"Everytime we write a vds could we (optionally, though probably default on) also append all the commands that led to that write to a `global.log`?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1105:140,log,log,140,https://hail.is,https://github.com/hail-is/hail/issues/1105,1,['log'],['log']
Testability,"Exactly, this always works in local mode. We definitely need more ways to test behavior in the non-local environment, but I have no concrete ideas right now.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5033#issuecomment-449473700:74,test,test,74,https://hail.is,https://github.com/hail-is/hail/pull/5033#issuecomment-449473700,1,['test'],['test']
Testability,"Example VCF parse error now looks like:. ```; Error summary: HailException: sample.vcf:column 1862: invalid character 'x' in integer literal; ... :80,0:80:13:0,13,2219 0/1:65,19:94:9x9:233,0,1732 0/0:34,3:45:74:0,74,12 ...; ^; offending line: 20	10273694	.	CT	C	29059.60	VQSRTrancheINDEL97.00to99.00	HWP...; see the Hail log for the full offending line; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2421#issuecomment-343983297:321,log,log,321,https://hail.is,https://github.com/hail-is/hail/pull/2421#issuecomment-343983297,1,['log'],['log']
Testability,"Example batch job created (1 burn in, 1 iteration, 1 job per benchmark). Failures are legit test failures.; https://batch.hail.is/batches/8181721",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14565#issuecomment-2142867787:61,benchmark,benchmark,61,https://hail.is,https://github.com/hail-is/hail/pull/14565#issuecomment-2142867787,2,"['benchmark', 'test']","['benchmark', 'test']"
Testability,"Example logged timings:; ```; timing is.hail.backend.BackendHttpHandler#handle x$3 total 1.426s self 157.884ms children 1.268s %children 88.93%; timing is.hail.backend.BackendHttpHandler#handle x$3/is.hail.expr.ir.TypeCheck.apply total 23.246ms self 23.246ms children 0.000ms %children 0.00%; timing is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute total 1.245s self 3.019ms children 1.242s %children 99.76%; timing is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.TypeCheck.apply total 0.327ms self 0.327ms children 0.000ms %children 0.00%; timing is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.analyses.SemanticHash.apply total 29.792ms self 6.254ms children 23.538ms %children 79.01%; timing is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.analyses.SemanticHash.apply/is.hail.expr.ir.NormalizeNames.apply total 23.538ms self 23.538ms children 0.000ms %children 0.00%; timing is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.backend.spark.SparkBackend#_jvmLowerAndExecute total 0.053ms self 0.053ms children 0.000ms %children 0.00%; timing is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply total 1.211s self 27.866ms children 1.183s %children 97.70%; timing is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/Optimize: relationalLowerer, initial IR total 37.247ms self 0.358ms children 36.889ms %children 99.04%; timing is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/Optimize: relationalLowerer, initial IR/Verify total 0.268ms self 0.268ms children 0.000ms %children 0.00%; timing is.hail.backe",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14679#issuecomment-2341990966:8,log,logged,8,https://hail.is,https://github.com/hail-is/hail/pull/14679#issuecomment-2341990966,1,['log'],['logged']
Testability,Example output in logs:; ```; INFO: timing is.hail.backend.BackendHttpHandler#handle x$3 total 1m42.0s self 20.824ms children 1m42.0s %children 99.98%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.expr.ir.IRParser.parse_value_ir total 179.902ms self 157.170ms children 22.733ms %children 12.64%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.expr.ir.IRParser.parse_value_ir/is.hail.expr.ir.TypeCheck.apply total 22.733ms self 22.733ms children 0.000ms %children 0.00%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute total 1m41.8s self 3.404ms children 1m41.8s %children 100.00%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.TypeCheck.apply total 0.211ms self 0.211ms children 0.000ms %children 0.00%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.analyses.SemanticHash.apply total 31.924ms self 6.413ms children 25.511ms %children 79.91%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.analyses.SemanticHash.apply/is.hail.expr.ir.NormalizeNames.apply total 25.511ms self 25.511ms children 0.000ms %children 0.00%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.backend.spark.SparkBackend#_jvmLowerAndExecute total 0.073ms self 0.073ms children 0.000ms %children 0.00%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply total 1m41.8s self 1m40.6s children 1.127s %children 1.11%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAndEvaluate._apply/is.hail.expr.ir.lowering.LoweringPipeline#apply total 1.106s self 33.060ms children 1.072s %children 97.01%; is.hail.backend.BackendHttpHandler#handle x$3/is.hail.backend.spark.SparkBackend#execute/is.hail.expr.ir.CompileAnd,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14731#issuecomment-2417774141:18,log,logs,18,https://hail.is,https://github.com/hail-is/hail/pull/14731#issuecomment-2417774141,1,['log'],['logs']
Testability,"Example: ```$ hail ... exportvariants -o foo.btsv -c '""this is a \""'`. ```; Exception in thread ""main"" java.lang.AssertionError: assertion failed; at scala.Predef$.assert(Predef.scala:165); at org.broadinstitute.hail.expr.Parser$$anonfun$stringLiteral$2$$anonfun$apply$136.apply(Parser.scala:326); at org.broadinstitute.hail.expr.Parser$$anonfun$stringLiteral$2$$anonfun$apply$136.apply(Parser.scala:323); at scala.util.parsing.combinator.Parsers$Success.map(Parsers.scala:136); ...; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/493:113,Assert,AssertionError,113,https://hail.is,https://github.com/hail-is/hail/issues/493,3,"['Assert', 'assert']","['AssertionError', 'assert', 'assertion']"
Testability,"Example:. ```; 2018-05-09 17:30:41 root: WARN: [is.hail.variant.MatrixTable.selectRows(MatrixTable.scala:1176) found no AST to IR conversion for:; Apply[annotate](; SymRef[va]; StructConstructor(; Select[toFloat64](; Select[position](; Select[locus](; SymRef[va]; ); ); ); ); ). due to the following errors:; locus<GRCh37> should be a subtype of TStruct, Select[locus](SymRef[va] ), is.hail.expr.Select$$anonfun$toIR$1.apply(AST.scala:371); in; is.hail.variant.MatrixTable.selectRows(MatrixTable.scala:1176); is.hail.testUtils.RichMatrixTable.annotateRowsExpr(RichMatrixTable.scala:57); is.hail.variant.vsm.GroupBySuite.testLinregBurden(GroupBySuite.scala:107); sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); ```. With multiple failures:. ```; 2018-05-09 17:43:03 root: WARN: [is.hail.variant.MatrixTable.aggregateRowsByKey(MatrixTable.scala:810) found no AST to IR conversion for:; StructConstructor(; ApplyMethod[sum](; ApplyMethod[map](; SymRef[AGG]; Lambda[g](; Apply[*](; Select[weight](; SymRef[va]; ); Select[toFloat64](; ApplyMethod[nNonRefAlleles](; Select[GT](; SymRef[g]; ); ); ); ); ); ); ); ). due to the following errors:; float64 should be a subtype of TStruct, Select[weight](SymRef[va] ), is.hail.expr.Select$$anonfun$toIR$1.apply(AST.scala:371); call should be a subtype of TStruct, Select[GT](SymRef[g] ), is.hail.expr.Select$$anonfun$toIR$1.apply(AST.scala:371); in; is.hail.variant.MatrixTable.aggregateRowsByKey(MatrixTable.scala:810); is.hail.variant.vsm.GroupBySuite.testLinregBurden(GroupBySuite.scala:113); sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3545:517,test,testUtils,517,https://hail.is,https://github.com/hail-is/hail/pull/3545,3,['test'],"['testLinregBurden', 'testUtils']"
Testability,"Exciting, first code-related pull request review! It seems correct. I was wondering how you're testing table.py, backend.py, java.py, and would it be worthwhile to write unit or integration tests for these sections? I'd be happy to work on that if desired.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5019#issuecomment-449156617:95,test,testing,95,https://hail.is,https://github.com/hail-is/hail/pull/5019#issuecomment-449156617,2,['test'],"['testing', 'tests']"
Testability,"Execute TableWriter and MatrixWriter via lowering pipeline instead of spark execution.; Removed support for checkpoint files for now - plan is to implement something more general purpose somewhat akin to call-caching. Plot of top 20 affected benchmarks, none of which use writing, interestingly...; ![image](https://user-images.githubusercontent.com/8223952/231855633-84ddbe64-1dba-4e62-bfa0-b9e2b041d588.png); You can view these results yourself in [benchmarks.zip](https://github.com/hail-is/hail/files/11225644/benchmarks.zip)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12879:242,benchmark,benchmarks,242,https://hail.is,https://github.com/hail-is/hail/pull/12879,3,['benchmark'],['benchmarks']
Testability,"Exports BGEN 1.2 with 8 bits per probability. Needs docs and more tests, not quite ready yet.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6462:66,test,tests,66,https://hail.is,https://github.com/hail-is/hail/pull/6462,1,['test'],['tests']
Testability,"Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SPHINX-5812109](https://snyk.io/vuln/SNYK-PYTHON-SPHINX-5812109) | `sphinx:` <br> `1.8.6 -> 3.3.0` <br> | No | Proof of Concept ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **384/1000** <br/> **Why?** Has a fix available, CVSS 3.4 | Open Redirect <br/>[SNYK-PYTHON-TORNADO-5537286](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5537286) | `tornado:` <br> `5.1.1 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **494/1000** <br/> **Why?** Has a fix available, CVSS 5.6 | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-5840803](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5840803) | `tornado:` <br> `5.1.1 -> 6.3.3` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIyMjlkNGUyNC0xMDE4LTQ5ZDItYTQ3NC04MmViZDVhNzZlMDEiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjIyOWQ0ZTI0LTEwMTgtNDlkMi1hNDc0LTgyZWJkNWE3NmUwMSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13717:8824,test,tested,8824,https://hail.is,https://github.com/hail-is/hail/pull/13717,1,['test'],['tested']
Testability,"Extend `FunctionChecker` to assert that at least the number of non-default parameters are specified, up to the maximum number of parameters.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12814:28,assert,assert,28,https://hail.is,https://github.com/hail-is/hail/pull/12814,1,['assert'],['assert']
Testability,Extend option to skip Scala tests requiring plink/Rscript executables,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5126:28,test,tests,28,https://hail.is,https://github.com/hail-is/hail/pull/5126,1,['test'],['tests']
Testability,"Extremely nice @lfrancioli, very elegantly done. Rebase and address the minor comments, and it should be good to go. A simple test would be nice, too, but I'll put that on our todo list if you don't get to it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1147#issuecomment-265653872:126,test,test,126,https://hail.is,https://github.com/hail-is/hail/pull/1147#issuecomment-265653872,2,['test'],['test']
Testability,F build/ibs.d -MT build/ibs.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux FS.cpp -MG -M -MF build/FS.d -MT build/FS.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux Encoder.cpp -MG -M -MF build/Encoder.d -MT build/Encoder.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux Decoder.cpp -MG -M -MF build/Decoder.d -MT build/Decoder.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux cache-tests.cpp -MG -M -MF build/cache-tests.d -MT build/cache-tests.o; g++ -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux ApproximateQuantiles_test.cpp -MG -M -MF build/ApproximateQuantiles_test.d -MT build/ApproximateQuantiles_te; st.o; make[1]: Leaving directory `/mnt/tmp/hail/hail/src/main/c'; make[1]: Entering directory `/mnt/tmp/hail/hail/src/main/c'; g++ -o build/NativeBoot.o -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux -MD -MF build/NativeBoot.d -MT build/NativeBoot.o -c NativeBoot.cpp; g++ -fvisibility=default -rdynamic -shared -march=sandybridge -O3 -std=c++14 -Ilibsimdpp-2.1 -Wall -Wextra -fPIC -ggdb -fno-strict-aliasing -I../resources/include -I/etc/alternatives/jre/include -I/etc/alternatives/jre/include/linux build/Na,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221:9527,test,tests,9527,https://hail.is,https://github.com/hail-is/hail/issues/13837#issuecomment-1770502221,1,['test'],['tests']
Testability,"FO: RegionPool: REPORT_THRESHOLD: 128.2M allocated (192.0K blocks / 128.0M chunks), regions.size = 3, 0 current java objects, thread 8: pool-1-thread-1\n2022-11-15 20:31:41.506 root: INFO: RegionPool: REPORT_THRESHOLD: 256.2M allocated (192.0K blocks / 256.0M chunks), regions.size = 3, 0 current java objects, thread 8: pool-1-thread-1\n2022-11-15 20:31:41.910 root: INFO: RegionPool: REPORT_THRESHOLD: 512.0M allocated (111.9M blocks / 400.1M chunks), regions.size = 5, 0 current java objects, thread 8: pool-1-thread-1\n2022-11-15 20:31:42.730 root: INFO: RegionPool: REPORT_THRESHOLD: 1.2G allocated (439.1M blocks / 781.5M chunks), regions.size = 5, 0 current java objects, thread 8: pool-1-thread-1""}, 'service_backend_debug_info': {'batch_attributes': {'name': 'test_tiny_driver_has_tiny_memory'}, 'billing_project': 'test', 'driver_cores': None, 'driver_memory': None, ...}} or 'batch.worker.jvm_entryway_protocol.EndOfStream' in {'batch_status': {'attributes': {'name': 'test_tiny_driver_has_tiny_memory'}, 'billing_project': 'test', 'closed': True, 'complete': True, ...}, 'job_status': {'attributes': {'name': 'driver'}, 'batch_id': 6627669, 'billing_project': 'test', 'cost': 0.0015413897092729028, ...}, 'log': {'main': ""2022-11-15 20:30:18.004 Tokens: INFO: tokens found for namespaces {default}\n2022-11-15 20:30:18.004 tls: INFO: ssl config file found at /batch/2bbb233e4e3c4a96bbffb515019daac9/secrets/ssl-config/ssl-config.json\n2022-11-15 20:30:18.006 GoogleStorageFS$: INFO: Initializing google storage client from service account key\n2022-11-15 20:30:18.114 root: INFO: RegionPool: initialized for thread 8: pool-1-thread-1\n2022-11-15 20:30:18.114 ServiceBackend$: INFO: executing: cEPZ5IV9gUtSnCiAiHXOPs None\n2022-11-15 20:30:18.127 root: INFO: optimize optimize: darrayLowerer, initial IR: before: IR size 17: \n(Let __rng_state\n (RNGStateLiteral (0 0 0 0))\n (MakeTuple (0)\n (TableAggregate\n (TableMapRows\n (TableOrderBy (Aidx) (TableRange 100000000 50))\n (InsertField",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12470#issuecomment-1315959284:64671,test,test,64671,https://hail.is,https://github.com/hail-is/hail/pull/12470#issuecomment-1315959284,1,['test'],['test']
Testability,FOR TESTING ONLY,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5990:4,TEST,TESTING,4,https://hail.is,https://github.com/hail-is/hail/pull/5990,1,['TEST'],['TESTING']
Testability,"FWIW it does go into the container logs which is how I've always pulled out the true error, but I'm not sure how to get that on every system. For future reference, there's an even more pernicious issue, which is that when running VEP with `-o STDOUT` it actually suppresses certain error messages too - and there's not much you can do about that unless you actually go in and run VEP manually without that, in the environment that hail uses.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8146#issuecomment-591009197:35,log,logs,35,https://hail.is,https://github.com/hail-is/hail/issues/8146#issuecomment-591009197,1,['log'],['logs']
Testability,"FWIW, I often grab the PR name from the `default_ns` job and search like this in the logs viewer:; ```; resource.labels.namespace_name=""PR_NAME""; labels.""k8s-pod/app"":""batch""; ```. EDIT: Maybe the default_ns should just include a URL that links directly to logs viewer with that search?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11352#issuecomment-1049107749:85,log,logs,85,https://hail.is,https://github.com/hail-is/hail/pull/11352#issuecomment-1049107749,2,['log'],['logs']
Testability,"FWIW, when I added the MySQL pods I made sure to install the client config in them so you don't need the admin-pod for test namespaces, just `kssh db <NAMESPACE>` and `mysql` should work",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13150#issuecomment-1581414024:119,test,test,119,https://hail.is,https://github.com/hail-is/hail/pull/13150#issuecomment-1581414024,1,['test'],['test']
Testability,"FWIW:; ```sh; echo 'this is \; a test'; this is \; a test; # vs; echo ""this is \; a test""; this is a test; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6956#issuecomment-525798414:33,test,test,33,https://hail.is,https://github.com/hail-is/hail/pull/6956#issuecomment-525798414,4,['test'],['test']
Testability,"FYI @cseed . I tested this locally, but we may have to merge it and see if it works.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7353:15,test,tested,15,https://hail.is,https://github.com/hail-is/hail/pull/7353,1,['test'],['tested']
Testability,"FYI @daniel-goldstein . I created three new abstract classes that act as the interface between different cloud compute implementations: `BaseZoneMonitor`, `BaseActivityMonitor`, and `BaseDiskMonitor`. There's a new `BaseComputeManager` that wraps the different monitors and also provides an interface for creating, deleting, and getting instances. I added an `InstanceState` that represents a common instance state between clouds (Running, Creating, Terminating). . I created a new `gcp` module that mirrors the structure of the batch module. I put all of the GCP specific implementations in there. In a future PR, I'll add the WorkerConfig for GCP and all of the GCP cost utility functions. I tested everything by hand looking for errors in the Logs Viewer. I'd like to do more testing of the disk monitor if you are good with the structure of this PR.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10860:694,test,tested,694,https://hail.is,https://github.com/hail-is/hail/pull/10860,3,"['Log', 'test']","['Logs', 'tested', 'testing']"
Testability,FYI @danking . I tested this is all working by making max_pods = 1 and queue_size = 5 and having a test that created 20 jobs.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6694#issuecomment-513396135:17,test,tested,17,https://hail.is,https://github.com/hail-is/hail/pull/6694#issuecomment-513396135,2,['test'],"['test', 'tested']"
Testability,"FYI @danking . We needed to reduce logging output again. The memory service was printing logs for every request so I got rid of that. We were missing a new endpoint in the batch driver that didn't need to be logged. Finally, a lot of logs looked like syslog from the worker so I made sure to turn off the syslog Fluentd logging as the first thing we do on the worker. Not sure if it will help, but worth a try.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12355:35,log,logging,35,https://hail.is,https://github.com/hail-is/hail/pull/12355,5,['log'],"['logged', 'logging', 'logs']"
Testability,FYI @konradjk . I tested this with dev deploy for the batch pages. I assume the ci page is the same. This changes the behavior of CI focus to require to enter slash first. I think it's better to be consistent.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8809:18,test,tested,18,https://hail.is,https://github.com/hail-is/hail/pull/8809,1,['test'],['tested']
Testability,"FYI @konradjk . I want to do a bit more testing but this should be ready later today for you to play with. I will ping you when it is ready and send instructions and some potential gotchas. For the most part it is self-explanatory:. ```; from hailtop import pipeline. p = pipeline.Pipeline(; backend=pipeline.GoogleBackend(; service_account='...',; scratch_dir='gs://hail-cseed/pipeline/tmp',; worker_cores=1,; worker_disk_size_gb='20',; pool_size=3,; max_instances=1000),; default_image='ubuntu:18.04'). input = p.read_input('gs://hail-cseed/cs-hack/input.txt'). t1 = p.new_task('concat'); t1.command(f'cp {input} {t1.ofile} && echo ""end"" >> {t1.ofile}'). t2 = p.new_task('sum'); t2.command(f'sum {t1.ofile} > {t2.sum}'). p.write_output(t2.sum, 'gs://hail-cseed/cs-hack/sum.txt'). p.run(); ```. You have to run this in a VM with a custom image. pool_size is the (maximum) number of active workers. max_instances is a cap on running instances to avoid blowing out CPU quota if you're close to the limit and we're creating new instances while others are shutting down. @jigold I'm not 100% sure this should go in. It stores resources in gs://hail-common (worker startup scripts, etc.) and to do this right we'll need to test deployments, version files, etc. It might make sense just to keep this as a reference and steal what you can from it for batch.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6772:40,test,testing,40,https://hail.is,https://github.com/hail-is/hail/pull/6772,2,['test'],"['test', 'testing']"
Testability,"FYI @tpoterba . Rework `ExecutionTimer` with two goals in mind:. Report total time, children time, self time (total - children) and % in children for each timed section. I think this improves clarity of reporting vs the old format. The timing log lines now look like:. ```; 2020-10-20 12:10:38 root: INFO: timing SparkBackend.executeJSON total 43.597ms self 0.941ms children 42.655ms %children 97.84%; ```. Decouple the timer from the execution context so we can time more than just the execution. In particular, I want timings starting from entering the JVM from Python (and in fact, I plan to write an ExecutionTimer in Python so we can time e.g. a call to Backend.execute and include timings from the JVM, but also printing the IR, unserializing the response, etc.)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9616:243,log,log,243,https://hail.is,https://github.com/hail-is/hail/pull/9616,1,['log'],['log']
Testability,"FYI @tpoterba . moved everything to hail/. deleted changes.md (completely out of date) and acknowledgements.txt (not maintained and subsumed by git history, I think). the test scripts (still at the top-level) cd into hail",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4301:171,test,test,171,https://hail.is,https://github.com/hail-is/hail/pull/4301,1,['test'],['test']
Testability,"FYI @tpoterba you can see this in action in my namespace (for the moment). @akotlar and I agree this is not ideal, but it is done and better than nothing. I will continue to play with alternatives and make a PR when I have something better. Remaining tasks:; - make notebook like non-clickable until ready; - write up test playbook. @akotlar let me know if/when you get tired of these, I'll send them to Dan or Jackie. Probably good for them to engage with this stuff, too.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7154:318,test,test,318,https://hail.is,https://github.com/hail-is/hail/pull/7154,1,['test'],['test']
Testability,FYI The last build failed due to a transient error (aiohttp.ServerDisconnectedError). I added it to the retry logic.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7605#issuecomment-557905128:110,log,logic,110,https://hail.is,https://github.com/hail-is/hail/pull/7605#issuecomment-557905128,1,['log'],['logic']
Testability,"FYI, I performance tested this + https://github.com/hail-is/hail/pull/8326 and gained a few percent:. ```; Harmonic mean: 91.0%; Geometric mean: 95.3%; Arithmetic mean: 96.8%; Median: 97.8%; ```. So this should go in and we leave the memoization optimization as a TODO.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8245#issuecomment-601652867:19,test,tested,19,https://hail.is,https://github.com/hail-is/hail/pull/8245#issuecomment-601652867,1,['test'],['tested']
Testability,"FYI, I tested this by hand on a small example against ES 6.2.4.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3455#issuecomment-385023610:7,test,tested,7,https://hail.is,https://github.com/hail-is/hail/pull/3455#issuecomment-385023610,1,['test'],['tested']
Testability,"FYI, I tested this with a deploy.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7994:7,test,tested,7,https://hail.is,https://github.com/hail-is/hail/pull/7994,1,['test'],['tested']
Testability,"FYI, I'm getting the scale test working and pushing some additional changes. I will follow up when it is stable.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7112#issuecomment-534569631:27,test,test,27,https://hail.is,https://github.com/hail-is/hail/pull/7112#issuecomment-534569631,1,['test'],['test']
Testability,"FYI, git clone can clone a single branch: https://stackoverflow.com/questions/1778088/how-do-i-clone-a-single-branch-in-git. > k run. Might be worth benchmarking in batch2, since that is where it will run. (k run! Shame on you!). > But the download drops from 4.7 to ~1.5. I don't understand this. Drops compared to what? Where'd the 4.7 come from?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7626#issuecomment-560446660:149,benchmark,benchmarking,149,https://hail.is,https://github.com/hail-is/hail/pull/7626#issuecomment-560446660,1,['benchmark'],['benchmarking']
Testability,Failed log here: [constraint_pipeline.log](https://github.com/hail-is/hail/files/12486909/constraint_pipeline.log),MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13486#issuecomment-1701112173:7,log,log,7,https://hail.is,https://github.com/hail-is/hail/issues/13486#issuecomment-1701112173,3,['log'],['log']
Testability,"Failed to annotate a large vcf with vep. Command:; hail-new-vep read -i /user/aganna/CANCER.vds \; vep --config /psych/genetics_data/working/cseed/vep.properties \; write -o /user/aganna/CANCER.vep.vds. Error:; Exception in thread ""main"" java.lang.NoClassDefFoundError: org/broadinstitute/hail/methods/VCFReport$; at org.broadinstitute.hail.driver.Main$.runCommands(Main.scala:125); at org.broadinstitute.hail.driver.Main$.main(Main.scala:276); at org.broadinstitute.hail.driver.Main.main(Main.scala); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.ClassNotFoundException: org.broadinstitute.hail.methods.VCFReport$; at java.net.URLClassLoader.findClass(URLClassLoader.java:381); at java.lang.ClassLoader.loadClass(ClassLoader.java:424); at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331); at java.lang.ClassLoader.loadClass(ClassLoader.java:357); ... 12 more. [hail.log.txt](https://github.com/broadinstitute/hail/files/222874/hail.log.txt)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/303:1533,log,log,1533,https://hail.is,https://github.com/hail-is/hail/issues/303,2,['log'],['log']
Testability,Failing Java tests,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7578#issuecomment-557229025:13,test,tests,13,https://hail.is,https://github.com/hail-is/hail/pull/7578#issuecomment-557229025,1,['test'],['tests']
Testability,"Failing Java tests (also, looking at the `test_hail_java` log, looks like we print a lot during this stream stuff?)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8520#issuecomment-612907568:13,test,tests,13,https://hail.is,https://github.com/hail-is/hail/pull/8520#issuecomment-612907568,2,"['log', 'test']","['log', 'tests']"
Testability,Failing a local backend test,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9549#issuecomment-702888995:24,test,test,24,https://hail.is,https://github.com/hail-is/hail/pull/9549#issuecomment-702888995,1,['test'],['test']
Testability,Failing all the hail tests,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8345#issuecomment-603569487:21,test,tests,21,https://hail.is,https://github.com/hail-is/hail/pull/8345#issuecomment-603569487,1,['test'],['tests']
Testability,Failing due to some mypy silliness but only in the pip installed images. Need to somehow modify this to make sure we have all appropriate stubs available and/or ignore missing stubs?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11502#issuecomment-1059677772:138,stub,stubs,138,https://hail.is,https://github.com/hail-is/hail/pull/11502#issuecomment-1059677772,2,['stub'],['stubs']
Testability,Failing flake tests,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7213#issuecomment-539510518:14,test,tests,14,https://hail.is,https://github.com/hail-is/hail/pull/7213#issuecomment-539510518,1,['test'],['tests']
Testability,Failing hail tests,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8565#issuecomment-615221048:13,test,tests,13,https://hail.is,https://github.com/hail-is/hail/pull/8565#issuecomment-615221048,1,['test'],['tests']
Testability,Failing java test,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8692#issuecomment-623511128:13,test,test,13,https://hail.is,https://github.com/hail-is/hail/pull/8692#issuecomment-623511128,1,['test'],['test']
Testability,"Failing pipeline with data available here: gs://hail-jigold/ibd-exomes-part4471.mt. [Zulip conversation](https://hail.zulipchat.com/#narrow/stream/123010-Hail-0.2E2.20support/subject/Working.20on.20translating.20a.20QC.20step.20from.200.2E1.20to.200.2E2). ```; import hail as hl. mt = hl.read_matrix_table('/Users/jigold/ibd-exomes-part4471.mt'). vars_of_interest = hl.set([""frameshift_variant"", ""inframe_deletion"", ""inframe_insertion"", ""stop_lost"", ""stop_gained"", ""start_lost"",\; ""splice_acceptor_variant"", ""splice_donor_variant"", ""splice_region_variant"", ""missense_variant"", ""synonymous_variant""]). mt = mt.annotate_globals(x = vars_of_interest); filtered = mt.filter_rows(mt.x.contains(mt.vep.most_severe_consequence)). filtered.write('/tmp/guhan.mt', overwrite=True); ```. This causes a segmentation fault that can be replicated with the first variant only `head(1)`. Filtering out rows where `mt.vep.most_severe_consequence` is missing will make the pipeline succeed. Tried this IR in IRSuite to replicate error with no success:; ```; @Test def debugGuhan() {; val s = ToSet(MakeArray(FastIndexedSeq(Str(""frameshift_variant""), Str(""inframe_deletion""), Str(""inframe_insertion""),; Str(""stop_lost""), Str(""stop_gained""), Str(""start_lost""), Str(""splice_acceptor_variant""), Str(""splice_donor_variant""),; Str(""splice_region_variant""), Str(""missense_variant""), Str(""synonymous_variant"")), TArray(TString()))). assertEvalsTo(LowerBoundOnOrderedCollection(s, NA(TString()), onKey = false), 11); }; ```. Separately, @tpoterba thinks the IR needs to have a Let statement for `set` in the IR implementation. I tried this, but it didn't fix the segmentation fault.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4522:1041,Test,Test,1041,https://hail.is,https://github.com/hail-is/hail/issues/4522,2,"['Test', 'assert']","['Test', 'assertEvalsTo']"
Testability,Failing scala tests in PruneSuite,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7792#issuecomment-570291808:14,test,tests,14,https://hail.is,https://github.com/hail-is/hail/pull/7792#issuecomment-570291808,1,['test'],['tests']
Testability,"Failing some python tests, I had only run Scala tests, which all passed, will look Tuesday",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7958#issuecomment-578252764:20,test,tests,20,https://hail.is,https://github.com/hail-is/hail/pull/7958#issuecomment-578252764,2,['test'],['tests']
Testability,"Failing test, otherwise looks great! Exciting stuff.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1116#issuecomment-262237543:8,test,test,8,https://hail.is,https://github.com/hail-is/hail/pull/1116#issuecomment-262237543,1,['test'],['test']
Testability,Failing tests,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8230#issuecomment-597107650:8,test,tests,8,https://hail.is,https://github.com/hail-is/hail/pull/8230#issuecomment-597107650,2,['test'],['tests']
Testability,"Failing tests are resolved, should be good to review again.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11381#issuecomment-1067233262:8,test,tests,8,https://hail.is,https://github.com/hail-is/hail/pull/11381#issuecomment-1067233262,1,['test'],['tests']
Testability,Failing tests for real,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8156#issuecomment-594139749:8,test,tests,8,https://hail.is,https://github.com/hail-is/hail/pull/8156#issuecomment-594139749,1,['test'],['tests']
Testability,"Failing tests likely due to recent commit, should be simple fix and re-push.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1648#issuecomment-294171904:8,test,tests,8,https://hail.is,https://github.com/hail-is/hail/pull/1648#issuecomment-294171904,2,['test'],['tests']
Testability,Failing tests.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10202#issuecomment-810242199:8,test,tests,8,https://hail.is,https://github.com/hail-is/hail/pull/10202#issuecomment-810242199,1,['test'],['tests']
Testability,Failing the NDArray tests,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8633#issuecomment-619997334:20,test,tests,20,https://hail.is,https://github.com/hail-is/hail/pull/8633#issuecomment-619997334,1,['test'],['tests']
Testability,Failures:; - a Java test I created that should fail to make sure the memory checks are happening; - Python test_ld_score; - A docs test,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8878#issuecomment-635336858:20,test,test,20,https://hail.is,https://github.com/hail-is/hail/pull/8878#issuecomment-635336858,2,['test'],['test']
Testability,Fair point. I think asserting this behavior works on a local FS is good. I think a follow up to this PR that parameterized the other tests by filesystem is also great. That follow up PR can just leave the local-only test unchanged.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11227#issuecomment-1015881708:20,assert,asserting,20,https://hail.is,https://github.com/hail-is/hail/pull/11227#issuecomment-1015881708,3,"['assert', 'test']","['asserting', 'test', 'tests']"
Testability,"Faster versions for the record:; ``` ; // returns all blocks intersecting the rectangle [firstRow, lastRow] x [firstCol, lastCol]; def rectangularBlocks(firstRow: Long, lastRow: Long, firstCol: Long, lastCol: Long): Array[Int] = {; require(firstRow >= 0 && firstRow <= lastRow && lastRow <= nRows); require(firstCol >= 0 && firstCol <= lastCol && lastCol <= nCols); ; val firstBlockRow = blockIndex(firstRow); val lastBlockRow = blockIndex(lastRow); val firstBlockCol = blockIndex(firstCol); val lastBlockCol = blockIndex(lastCol). val blocks = new Array[Int]((lastBlockRow - firstBlockRow + 1) * (lastBlockCol - firstBlockCol + 1)); ; var k = 0; var j = firstBlockCol; while (j <= lastBlockCol) {; val offset = j * nBlockRows; var i = firstBlockRow; while (i <= lastBlockRow) {; blocks(k) = offset + i; k += 1; i += 1; }; j += 1; }; ; blocks; }. // returns all blocks intersecting the union of rectangles; def rectangularBlocks(rectangles: Array[Array[Long]]): Array[Int] = {; val keep = new Array[Boolean](numPartitions); ; rectangles.foreach { r =>; assert(r.length == 4); val rBlocks = rectangularBlocks(r(0), r(1), r(2), r(3)); var i = 0; while (i < rBlocks.length) {; keep(rBlocks(i)) = true; i += 1; }; }; ; val blocks = new ArrayBuilder[Int](); var block = 0; while (block < numPartitions) {; if (keep(block)); blocks += block; block += 1; }; ; blocks.result(); }; }; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3094#issuecomment-372728393:1053,assert,assert,1053,https://hail.is,https://github.com/hail-is/hail/pull/3094#issuecomment-372728393,1,['assert'],['assert']
Testability,Feature/ci test,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12111:11,test,test,11,https://hail.is,https://github.com/hail-is/hail/pull/12111,1,['test'],['test']
Testability,"Few more variables are expected to be in `config.mk` for manual bootstrap:. * `DOCKER_ROOT_IMAGE` used to build batch workers and benchmark; * `HAIL_TEST_GCS_BUCKET` used to build query; * `KUBERNETES_SERVER_URL` used to build amundsen; * `PROJECT`, `ZONE`, `REGION` are probably not need, but might make sense to add for consistency. Also match the order from `global-config`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11371:130,benchmark,benchmark,130,https://hail.is,https://github.com/hail-is/hail/pull/11371,1,['benchmark'],['benchmark']
Testability,"Few things:. If we get rid of annotatevariants json, how do we deal with _0 problem? (Related, but not directly, to this PR.). To use this to export/reimport annotations, it seems not quite trivial to get the annotations back in the right place. What's the intended command line? Can we get that as a test case?. Otherwise, back to you.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/488#issuecomment-235089575:301,test,test,301,https://hail.is,https://github.com/hail-is/hail/pull/488#issuecomment-235089575,1,['test'],['test']
Testability,"FileSystem(conf)](https://ci2.hail.is/jobs/17044/log). This calls hadoop.fs.FileSystem.get , which in turn calls Configuration.get (instance method). ```java; // In Path.java; public FileSystem getFileSystem(Configuration conf) throws IOException {; return FileSystem.get(this.toUri(), conf);; }. // In FileSystem.java; public static FileSystem get(Configuration conf) throws IOException {; return get(getDefaultUri(conf), conf);; }. public static FileSystem get(final URI uri, final Configuration conf,; final String user) throws IOException, InterruptedException {; String ticketCachePath =; conf.get(CommonConfigurationKeys.KERBEROS_TICKET_CACHE_PATH);; UserGroupInformation ugi =; UserGroupInformation.getBestUGI(ticketCachePath, user);; return ugi.doAs(new PrivilegedExceptionAction<FileSystem>() {; @Override; public FileSystem run() throws IOException {; return get(uri, conf);; }; });; }; ```. For some reasons the line numbers reported in CI log don't quite match up (using either IntelliJ's goto def - which could say be the result of referencing a different copy on the system - or the [2.7.1 branch on GitHub](https://github.com/apache/hadoop/blob/branch-2.7.1/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileSystem.java)), so I followed the parameterization. Still need to figure out why lines reported don't match, but I've seen line number differences before between that reported for the compiled binary, and the uncompiled source. Lines of evidence:; 1) The line specified in the ci log suggests that Hadoop's fileSystem.open() command fails. It appears from examining the line and source, that the Hadoop Configuration object could be null, which suggests a serialization error in HadoopFS. However, there are many others tests that by touch HadoopFS serialization, and none of them have problems. If it's not a serialization error (say the URI object that hadoop looks for is null, or CACHE is null), it would not seem PR specific. 2) On local, with or wi",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6083#issuecomment-494037803:1292,log,log,1292,https://hail.is,https://github.com/hail-is/hail/pull/6083#issuecomment-494037803,1,['log'],['log']
Testability,"FileSystem>() {; @Override; public FileSystem run() throws IOException {; return get(uri, conf);; }; });; }; ```. For some reasons the line numbers reported in CI log don't quite match up (using either IntelliJ's goto def - which could say be the result of referencing a different copy on the system - or the [2.7.1 branch on GitHub](https://github.com/apache/hadoop/blob/branch-2.7.1/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/FileSystem.java)), so I followed the parameterization. Still need to figure out why lines reported don't match, but I've seen line number differences before between that reported for the compiled binary, and the uncompiled source. Lines of evidence:; 1) The line specified in the ci log suggests that Hadoop's fileSystem.open() command fails. It appears from examining the line and source, that the Hadoop Configuration object could be null, which suggests a serialization error in HadoopFS. However, there are many others tests that by touch HadoopFS serialization, and none of them have problems. If it's not a serialization error (say the URI object that hadoop looks for is null, or CACHE is null), it would not seem PR specific. 2) On local, with or without the google storage connector, I cannot replicate the error in cluster-read-vcfs.py. Attempts to replicate:; 1) Local hail install, not using google storage connector, and reading 2 local vcfs:. ```python; gvcfs = ['./HG00096.g.vcf.gz',; './HG00268.g.vcf.gz']; hl.init(default_reference='GRCh38'); parts = [; {'start': {'locus': {'contig': 'chr20', 'position': 17821257}},; 'end': {'locus': {'contig': 'chr20', 'position': 18708366}},; 'includeStart': True,; 'includeEnd': True},; {'start': {'locus': {'contig': 'chr20', 'position': 18708367}},; 'end': {'locus': {'contig': 'chr20', 'position': 19776611}},; 'includeStart': True,; 'includeEnd': True},; {'start': {'locus': {'contig': 'chr20', 'position': 19776612}},; 'end': {'locus': {'contig': 'chr20', 'position': 21144633}},; 'in",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6083#issuecomment-494037803:2108,test,tests,2108,https://hail.is,https://github.com/hail-is/hail/pull/6083#issuecomment-494037803,1,['test'],['tests']
Testability,Filebeat and JSON log parsing,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6659:18,log,log,18,https://hail.is,https://github.com/hail-is/hail/pull/6659,1,['log'],['log']
Testability,Filtered before collect in py tests,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1665:30,test,tests,30,https://hail.is,https://github.com/hail-is/hail/pull/1665,1,['test'],['tests']
Testability,"Final conclusion here: Since batch 1 is discontinued in favor of batch 2, and we don't know how prometheus will react to batch 2's logging load (should be better since there's not constant kubernetes junk), let's not start a new node pool for now, and request 20 Gbs of memory as done here.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6774#issuecomment-521758111:131,log,logging,131,https://hail.is,https://github.com/hail-is/hail/pull/6774#issuecomment-521758111,1,['log'],['logging']
Testability,"Finally got a lead on Christina's bug:; ```; # hailctl dataproc submit dk foo.py; Submitting to cluster 'dk'...; gcloud command:; gcloud dataproc jobs submit pyspark foo.py \; --cluster=dk \; --files= \; --py-files=/var/folders/cq/p_l4jm3x72j7wkxqxswccs180000gq/T/pyscripts_yg_wzlu0.zip \; --properties=; Job [66c1d088108948b2b76bb607f61d7b3f] submitted.; Waiting for job output...; Initializing Spark and Hail with default parameters...; using hail jar at /opt/conda/default/lib/python3.6/site-packages/hail/hail-all-spark.jar; Running on Apache Spark version 2.4.3; SparkUI available at http://dk-m.c.broad-ctsa.internal:4041; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.16-277ccc7aec45; LOGGING: writing to /tmp/66c1d088108948b2b76bb607f61d7b3f/hail-20190703-2330-0.2.16-277ccc7aec45.log; yo dawg. [Stage 0:> (0 + 1) / 1]OpenJDK 64-Bit Server VM warning: INFO: os::commit_memory(0x00007f2e73b00000, 1035468800, 0) failed; error='Cannot allocate memory' (errno=12); #; # There is insufficient memory for the Java Runtime Environment to continue.; # Native memory allocation (mmap) failed to map 1035468800 bytes for committing reserved memory.; # An error report file with more information is saved as:; # /tmp/66c1d088108948b2b76bb607f61d7b3f/hs_err_pid10896.log; ERROR: (gcloud.dataproc.jobs.submit.pyspark) Job [66c1d088108948b2b76bb607f61d7b3f] failed with error:; Google Cloud Dataproc Agent reports job failure. If logs are available, they can be found in 'gs://dataproc-7f9e9d5e-03bd-4e95-bea1-fe0321239b35-us/google-cloud-dataproc-metainfo/f03fbc39-c07f-4e3e-8f21-47ffa986058e/jobs/66c1d088108948b2b76bb607f61d7b3f/driveroutput'.; Traceback (most recent call last):; File ""/usr/local/bin/hailctl"", line 10, in <module>; sys.exit(main()); File ""/usr/local/lib/python3.7/site-packages/hailtop/hailctl/__main__.py"", line 91, in main; cli.main(args); File ""/usr/local/lib/python3.7/site-packages/hailtop/hailctl/dataproc/cli.py"", line 99, in main; jmp[",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6565#issuecomment-508289815:733,LOG,LOGGING,733,https://hail.is,https://github.com/hail-is/hail/issues/6565#issuecomment-508289815,2,"['LOG', 'log']","['LOGGING', 'log']"
Testability,"Finally got around to adding the tests, should be good now.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8038#issuecomment-585830759:33,test,tests,33,https://hail.is,https://github.com/hail-is/hail/pull/8038#issuecomment-585830759,1,['test'],['tests']
Testability,"Finally working! Ugh, that was painful. Changes I made since I closed:; - You can't broadcast an object which has a reference to its own broadcast (e.g. ReferenceGenome => locusType => rgBc). I made locusType transient and recompute after serialization.; - Removed BroadcastSerializable. I can't figure out how to check ReferenceGenome/RVDPartitioner are only serialized during partitioning. This is basically a failure of the Kryo interface. I might try again sometime when I'm feeling beat down by serialization.; - Removed removeReference. This just isn't something we can support (except in isolated situations like tests, and I fixed those.) Now, if you add a reference, it only throws an error if an existing reference exists by that name and is incompatible.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5512#issuecomment-473088362:620,test,tests,620,https://hail.is,https://github.com/hail-is/hail/pull/5512#issuecomment-473088362,1,['test'],['tests']
Testability,"First crack at supporting multi phenotype logistic regression. No matrix optimizations, as is implemented in multi phenotype linear regression, but I attempt to follow a similar approach as far as far as API and single call of mapPartitions.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5072:42,log,logistic,42,https://hail.is,https://github.com/hail-is/hail/pull/5072,1,['log'],['logistic']
Testability,"First cut: https://github.com/broadinstitute/hail/commit/f5e93963844656449259ad893ec3ce7ddcef2f3c. Still needed: testing, implicit option manipulation, access to INFO field and QC results.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/16#issuecomment-156226289:113,test,testing,113,https://hail.is,https://github.com/hail-is/hail/issues/16#issuecomment-156226289,1,['test'],['testing']
Testability,"First draft of a helm chart for packaging up Hail Batch as a Terra on Azure App. This will likely need numerous bug fixes as we set up a proper testing strategy, but the rough shape of everything should be pretty stable.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13944:144,test,testing,144,https://hail.is,https://github.com/hail-is/hail/pull/13944,1,['test'],['testing']
Testability,"First step in RVD changes. Rewrites `Interval` to support endpoints that are `Row`s of different lengths. Hopefully comments and test suite are enough to make the semantics clear. If not, let me know what is unclear and I'll add documentation and/or test cases.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4072:129,test,test,129,https://hail.is,https://github.com/hail-is/hail/pull/4072,2,['test'],['test']
Testability,"First step: #4347 automates VEP testing (for vep85, GRCh37)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4021#issuecomment-422545491:32,test,testing,32,https://hail.is,https://github.com/hail-is/hail/issues/4021#issuecomment-422545491,1,['test'],['testing']
Testability,"First test-passing version with Array[Array[GenotypeType]] drops time to 1m37s, not as much as expected. I'll look more closely to see if there are obvious inefficiencies, and may try unboxing GenotypeType to Int. If you look, let me know if you see something obvious. Output looks good. But there are only 6 complete trios in profile225, so after filtering out samples not in complete trios in .filterSamples(isTrioSample) , there is very little data to process. Here is the contents of profile225.fmendel:. ```; FID PAT MAT CHLD N; VN049 HG02026 HG02025 1 2009; SH074 HG00656 HG00657 1 5669; m009 NA19679 NA19678 1 3953; m008 NA19661 NA19660 1 5240; Y117 NA19239 NA19238 1 6499; PR05 HG00731 HG00732 1 1506; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/68#issuecomment-154742941:6,test,test-passing,6,https://hail.is,https://github.com/hail-is/hail/pull/68#issuecomment-154742941,1,['test'],['test-passing']
Testability,"First, I changed import_vcfs to return a MatrixTable only keyed by locus, and removed the MatrixKeyRowsBy in combine_gvcfs. To goal here is to avoid re-buidling an re-broadcasting the partitioner once for each gVCF. We'll need to re-key at the very end. I'm not so familiar with the end of the joint calling pipeline. @chrisvittal can you take care of that?. Second, I don't repartition in TableMultiWayZipJoin if the partitioners all match (which they should in in the joint calling pipeline). For that to work right, I need allowedOverlap == 0 (or to verify the partitions are in fact disjoint). Turns out allowedOverlap wasn't being propagated in various places. I fixed that. @patrick-schultz can you look at the RVDPartitioner changes? They just look like oversights to me, but maybe there was a reason why, for example, copy and coarsen wasn't preserving allowedOverlap?. Finally, now the joint calling pipeline/test_combiner_works segfaults, ugh:. ```; $ hail -m unittest test.hail.methods.test_impex.VCFTests.test_combiner_works; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x000000010e5fa090, pid=64905, tid=33795; #; # JRE version: Java(TM) SE Runtime Environment (8.0_45-b14) (build 1.8.0_45-b14); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.45-b02 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # J 8877 C1 is.hail.expr.types.physical.PLocus$$anon$1.compare(Lis/hail/annotations/Region;JLis/hail/annotations/Region;J)I (117 bytes) @ 0x000000010e5fa090 [0x000000010e5f9de0+0x2b0]; #; ```. The rest of the tests pass (the other Python failures are cascaded failures from test_combiner_works, I double-checked in the hopes of finding an easier example to debug.) It is pretty clearly related to the no repartition optimization. If I disable it, test_combiner_works passes. I haven't tracked this down, but I do have one question @chrisvittal: who's responsible for freeing the inputs (that is, clearing the input regions)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5424:979,test,test,979,https://hail.is,https://github.com/hail-is/hail/pull/5424,1,['test'],['test']
Testability,"First, I'm seeing transient (but common, maybe 10% of the time?! Have you seen this before, Jackie?) gsutil errors in the setup/cleanup containers that look like: [Errno 2] No such file or directory. I ran with -DD, the file is there in gs://, something is going wrong in the container. It happens with and without -m. I tried to upgrade google/cloud-sdk, but ran into a problem: after updating the instance base image, the worker container can no longer get credentials from the metadata server and therefore gets permission denied when trying to copy out the logs. Upon reflection, in our setup, containers being able to access the metadata server seems very insecure! So we should (1) make sure containers we run can't access the metadata service, (2) run the instance as no service account, or an account with no privileges. Then we need to figure out how to get the credentials to to the worker to copy out logs. I also added a retry (3x) to the setup/cleanup scripts. I think ultimately using the client libraries directly instead of gsutil might ultimately be the way to go (and it makes it easier for us to see what errors we're getting and which we want to retry). Changes:; - retry in setup/cleanup; - fix ""make deploy"" in batch2 (build worker image); - I fixed up the worker Google image builder logic. There was a race condition with the step command. I broke it into two manual steps. The instance steps itself in the first step. The user should verify the instance is stopped and then run the second step. This can be automated later.; - Fixed bug in mark_jobs_complete updating ready_cores. It counted all children, not just children that are going to transition to ready.; - fixed bug in delete tables script: batch => batches",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7445:561,log,logs,561,https://hail.is,https://github.com/hail-is/hail/pull/7445,3,['log'],"['logic', 'logs']"
Testability,Fisher Exact Test,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/455:13,Test,Test,13,https://hail.is,https://github.com/hail-is/hail/pull/455,1,['Test'],['Test']
Testability,"FitLMM FAILED`. It fails out with 244 tests completed and 5 failed. I've attached the test report ; [tests.zip](https://github.com/hail-is/hail/files/795132/tests.zip). There are two differences that I can tell between the current build and the previous times I've tried. 1. I was using a local installation of spark when it worked, whereas now I am using the HPC's version of spark 2.1.0. However, it passed the tests just fine when I was using a local copy of spark 2.0.2 on both my laptop and HPC. . 2. Initially I followed the recommendations on the doc pages to setup the python path references to py4j under `alias hail=""PYTHONPATH=$SPARK_HOME/python:$SPARK_HOME/python/lib/py4j-0.10.4-src.zip:$HAIL_HOME/python SPARK_CLASSPATH=$HAIL_HOME/build/libs/hail-all-spark.jar python""` This perhaps didn't export the PYTHONPATH to the py4j 10.4 .zip library if I hadn't run the `hail` command before I tried testing. My initial reaction was to just install a local copy of py4j via pip in my local copy of python since the tests were failing out with complaints about missing py4j module. That worked to get a little farther in the test script, to the point where it was failing out with the breeze function. But, since then I've re-jiggered the PYTHONPATH in the .bash_profile to always be defined to point to the SPARK_HOME version of py4j. This doesn't seem like it would be a problem as the py4j versions via pip and and SPARK_HOME are both 10.4, and moreover this setup worked with spark 2.0.2, but a possible confound. Perhaps change the getting started docs so the PYTHONPATH is always defined to point to the spark version of py4j?. Anyway, here are the current paths as you requested. . `echo $SPARK_HOME /share/sw/free/spark.2.1.0/spark-2.1.0-bin-hadoop2.7`. `echo $PYTHONPATH; /home/stockham/bin/python/Python-2.7.12:/share/sw/free/spark.2.1.0/spark-2.1.0-bin-hadoop2.7/python:/share/sw/free/spark.2.1.0/spark-2.1.0-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip:/scratch/PI/dpwall/computeEnvi",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1419#issuecomment-281846721:1645,test,tests,1645,https://hail.is,https://github.com/hail-is/hail/issues/1419#issuecomment-281846721,1,['test'],['tests']
Testability,Fix AbstractBinaryReader.readLong and add test for it,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3914:42,test,test,42,https://hail.is,https://github.com/hail-is/hail/pull/3914,1,['test'],['test']
Testability,Fix Env logic in PruneDeadFields.rebuild,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5729:8,log,logic,8,https://hail.is,https://github.com/hail-is/hail/pull/5729,1,['log'],['logic']
Testability,Fix Genotype tests,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/649:13,test,tests,13,https://hail.is,https://github.com/hail-is/hail/pull/649,1,['test'],['tests']
Testability,Fix IR size printed in log statement after optimize,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5441:23,log,log,23,https://hail.is,https://github.com/hail-is/hail/pull/5441,1,['log'],['log']
Testability,Fix LiftLiterals rewriting logic,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5109:27,log,logic,27,https://hail.is,https://github.com/hail-is/hail/pull/5109,1,['log'],['logic']
Testability,Fix OrderedRVD assertion,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4071:15,assert,assertion,15,https://hail.is,https://github.com/hail-is/hail/pull/4071,1,['assert'],['assertion']
Testability,Fix TestNG report link on CI artifacts page,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5106:4,Test,TestNG,4,https://hail.is,https://github.com/hail-is/hail/issues/5106,1,['Test'],['TestNG']
Testability,Fix Tim Join Logic™ for good,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2884:13,Log,Logic,13,https://hail.is,https://github.com/hail-is/hail/pull/2884,1,['Log'],['Logic']
Testability,"Fix any, all, mean. Add tests.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2911:24,test,tests,24,https://hail.is,https://github.com/hail-is/hail/pull/2911,1,['test'],['tests']
Testability,Fix asm4s test failures on Cray.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1372:10,test,test,10,https://hail.is,https://github.com/hail-is/hail/pull/1372,1,['test'],['test']
Testability,Fix blockmatrix_write_from_entry_expr_range_mt_standardize benchmark,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9807:59,benchmark,benchmark,59,https://hail.is,https://github.com/hail-is/hail/pull/9807,1,['benchmark'],['benchmark']
Testability,"Fix bug in Genotype.gtFromLinear. We had a destructive bug in this function that; caused dosages to never result in a HomRef call.; Our tests were inadequate because we used this; function both in the generator and import, i.e.; testing it against itself. I added a unit test for; this method. Fixes #714",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/722:136,test,tests,136,https://hail.is,https://github.com/hail-is/hail/pull/722,3,['test'],"['test', 'testing', 'tests']"
Testability,"Fix bug in allele_type, add tests, add Symbolic category.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3494:28,test,tests,28,https://hail.is,https://github.com/hail-is/hail/pull/3494,1,['test'],['tests']
Testability,"Fix bugs that show up when we typecheck the literal value on construction. The assert is commented out for now because it is expensive. Later, I'll add a flag to control expensive checks like this and checkRVDKeys and the tests should be run with expensive checks turned on.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8653:79,assert,assert,79,https://hail.is,https://github.com/hail-is/hail/pull/8653,2,"['assert', 'test']","['assert', 'tests']"
Testability,Fix cloud tests,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2119:10,test,tests,10,https://hail.is,https://github.com/hail-is/hail/pull/2119,1,['test'],['tests']
Testability,"Fix docs and tests to be consistent about using `hl.agg`, not `agg`",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5725:13,test,tests,13,https://hail.is,https://github.com/hail-is/hail/pull/5725,1,['test'],['tests']
Testability,Fix exporting of env vars in build.yaml for `release`. ; Make `release`:; - depend on tests; - use tested wheel (dont rebuild).,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14434:86,test,tests,86,https://hail.is,https://github.com/hail-is/hail/pull/14434,2,['test'],"['tested', 'tests']"
Testability,Fix genotype array & add round-tripping tests,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/627:40,test,tests,40,https://hail.is,https://github.com/hail-is/hail/pull/627,1,['test'],['tests']
Testability,Fix getOrCreate method and add regression test,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5871:42,test,test,42,https://hail.is,https://github.com/hail-is/hail/pull/5871,1,['test'],['test']
Testability,Fix infinite loop from testing outside directory,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3408:23,test,testing,23,https://hail.is,https://github.com/hail-is/hail/pull/3408,1,['test'],['testing']
Testability,Fix output precision of export gen for tests,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1762:39,test,tests,39,https://hail.is,https://github.com/hail-is/hail/pull/1762,1,['test'],['tests']
Testability,Fix pc relate test,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5305:14,test,test,14,https://hail.is,https://github.com/hail-is/hail/pull/5305,1,['test'],['test']
Testability,"Fix python methods, expose samples_to_pandas, integrate logging",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1085:56,log,logging,56,https://hail.is,https://github.com/hail-is/hail/pull/1085,1,['log'],['logging']
Testability,Fix test bug comment,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4124:4,test,test,4,https://hail.is,https://github.com/hail-is/hail/pull/4124,1,['test'],['test']
Testability,Fix tests so that they can be run with IntelliJ / PyCharm,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2770:4,test,tests,4,https://hail.is,https://github.com/hail-is/hail/pull/2770,1,['test'],['tests']
Testability,Fix write_matrix_tables in Python and add test,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5411:42,test,test,42,https://hail.is,https://github.com/hail-is/hail/pull/5411,1,['test'],['test']
Testability,"Fixed LMM global annotations, added test so it won't break again",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1388:36,test,test,36,https://hail.is,https://github.com/hail-is/hail/pull/1388,1,['test'],['test']
Testability,Fixed Solr retry logic.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/778:17,log,logic,17,https://hail.is,https://github.com/hail-is/hail/pull/778,1,['log'],['logic']
Testability,"Fixed a bunch of things, improved it a bit, ~30s for the small test now. when combined with the changes from #5107",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5078#issuecomment-455017270:63,test,test,63,https://hail.is,https://github.com/hail-is/hail/pull/5078#issuecomment-455017270,1,['test'],['test']
Testability,Fixed all the tests.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1872#issuecomment-305741770:14,test,tests,14,https://hail.is,https://github.com/hail-is/hail/pull/1872#issuecomment-305741770,1,['test'],['tests']
Testability,Fixed and test updated.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12990#issuecomment-1540350149:10,test,test,10,https://hail.is,https://github.com/hail-is/hail/pull/12990#issuecomment-1540350149,1,['test'],['test']
Testability,"Fixed arbitrary maps on BlockMatrix, added test",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10501:43,test,test,43,https://hail.is,https://github.com/hail-is/hail/pull/10501,1,['test'],['test']
Testability,Fixed incorrect types when constructing VSMs in tests.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2294:48,test,tests,48,https://hail.is,https://github.com/hail-is/hail/pull/2294,1,['test'],['tests']
Testability,Fixed the following things:; 1. initOp was in wrong place for AggregateRows; 2. no clearing of rv aggregators between groups in AggregateRows; 3. The post-agg function wasn't being used in AggregateCols. I added more tests in Python.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3724:217,test,tests,217,https://hail.is,https://github.com/hail-is/hail/pull/3724,1,['test'],['tests']
Testability,Fixed the test. Feel free to look over whenever,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1590#issuecomment-288834232:10,test,test,10,https://hail.is,https://github.com/hail-is/hail/pull/1590#issuecomment-288834232,1,['test'],['test']
Testability,Fixed. I'll debug the tests shortly.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2459#issuecomment-346149083:22,test,tests,22,https://hail.is,https://github.com/hail-is/hail/pull/2459#issuecomment-346149083,1,['test'],['tests']
Testability,"Fixes #11335. @tpoterba made the replicating test, with that it was easy to find the source of the bug. The error was in; ```; pkPartitioned; .strictify(); ...; .changePartitionerNoRepartition(partitioner.extendKeySamePartitions(keyType)); ```; where `pkPartitioned` is keyed by the partition key. In the test case, all rows have the same partition key, so the partitioner looks like `[x, x], [x, x], ...`. In that case, `strictify` correctly collapses all those partitions into one, but `partitioner.extendKeySamePartitions(keyType)` tries to extend the key type without changing the partitioning, which in this case creates an invalid partitioner. The fix is to use `pkPartitioned.extendKeyPreservesPartitioning(key)`, which does the `strictify` and creates the correct partitioner.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11355:45,test,test,45,https://hail.is,https://github.com/hail-is/hail/pull/11355,2,['test'],['test']
Testability,Fixes #13191 and replaces #13192. See discussion there. I decided the `mentioned` checks in the tests weren't very useful and I'm not sure what the intent was there. We have so many other tests now that I don't think we really need them anyways.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14352:96,test,tests,96,https://hail.is,https://github.com/hail-is/hail/pull/14352,2,['test'],['tests']
Testability,Fixes #13328. See that issue for context. See [here](https://internal.hail.is/dgoldste/batch/batches/5/jobs/1) for an example of a job log that would currently OOM production pods.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13322:135,log,log,135,https://hail.is,https://github.com/hail-is/hail/pull/13322,1,['log'],['log']
Testability,Fixes #13556. I haven't tested these changes -- would like to get initial feedback first.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13744:24,test,tested,24,https://hail.is,https://github.com/hail-is/hail/pull/13744,1,['test'],['tested']
Testability,"Fixes #13706. When I reworked `build.gradle` to be simpler and conform with modern gradle standards, I forgot to dump all of our dependencies into our test runtime classpath. This PR ensures that the test runtime classpath is the same as our runtime classpath in QoB and in QoS.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13740:151,test,test,151,https://hail.is,https://github.com/hail-is/hail/pull/13740,2,['test'],['test']
Testability,"Fixes #13716. This finally block is currently located after `gather.take()` but *before* we cancel (aka shutdown) all threads. As a result, it is possible for us to shudown the logging (thus flushing, closing, and destorying old appenders) then restart logging (thus opening the file in overwrite mode) and blow away whatever was there. I have verified in my namespace across 10s of thosuands of JVM Jobs that this never blows away the log.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13729:177,log,logging,177,https://hail.is,https://github.com/hail-is/hail/pull/13729,3,['log'],"['log', 'logging']"
Testability,"Fixes #13971. CHANGELOG: Hail now supports and primarily tests against Dataproc 2.2.5, Spark 3.5.0, and Java 11. We strongly recommend updating to Spark 3.5.0 and Java 11. You should also update your GCS connector *after installing Hail*: `curl https://broad.io/install-gcs-connector | python3`. Do not try to update before installing Hail 0.2.131. https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-release-2.2",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14158:57,test,tests,57,https://hail.is,https://github.com/hail-is/hail/pull/14158,1,['test'],['tests']
Testability,"Fixes #14262. Ever since starting to control job network namespaces ourselves, we run the worker container with `--network host`. But running with the host's network namespace means there's no need (nor meaning) to use port forwarding rules with `-p`. Docker safely ignores this redundant setting but emit some log messages like:. ```; WARNING: Published ports are discarded when using host network mode; ```. The solution here is to just remove the old port publishing settings.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14252:311,log,log,311,https://hail.is,https://github.com/hail-is/hail/pull/14252,1,['log'],['log']
Testability,Fixes #14634. Always prompt for which google account to use during login. Avoids confusion over whether logout succeeded or not (especially considering #14635),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14636:67,log,login,67,https://hail.is,https://github.com/hail-is/hail/pull/14636,2,['log'],"['login', 'logout']"
Testability,Fixes #14635. Logout is only possible from `auth` pages due to per-subdomain CRSF tokens. Security/design thought process as documented in a comment on the issue: https://github.com/hail-is/hail/issues/14635#issuecomment-2253086187,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14639:14,Log,Logout,14,https://hail.is,https://github.com/hail-is/hail/pull/14639,1,['Log'],['Logout']
Testability,"Fixes #14660 by using the graphQL API to query github directly. Replaces our current parallel interpretation of reviews into a review decision, which is brittle if we ever change review requirements in github again. Tested by manually updating the live CI to use the test batch generated image. Results:; - Review decisions correctly fetched from github, not based on CI's parallel interpretation of individual reviews:; ![image](https://github.com/user-attachments/assets/67c03aa9-000a-44e7-91aa-3a42d04238dc); - No merge candidate was being incorrectly nominated (in particular, #14645 is now considered pending, rather than approved, which is what we are currently, incorrectly, calculating)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14661:216,Test,Tested,216,https://hail.is,https://github.com/hail-is/hail/pull/14661,2,"['Test', 'test']","['Tested', 'test']"
Testability,Fixes #2949. I'm going to add some more comprehensive tests also so that these cases get tested.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2950:54,test,tests,54,https://hail.is,https://github.com/hail-is/hail/pull/2950,2,['test'],"['tested', 'tests']"
Testability,"Fixes #3692. I also factored out some of the TableKeyBy logic and tweaked it. If a table is already backed by an OrderedRVD with key (""a"", ""b"", ""c"") and partition key (""a""), and we do a keyBy([""a"", ""b""], [""a"", ""b""]), then no work needs to be done, but we want the OrderedRVDType of the underlying OrderedRVD to remember the stronger invariants it satisfies. That way if we later keyBy([""a"", ""b"", ""c""], [""a""]), we don't have to do any work.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3694:56,log,logic,56,https://hail.is,https://github.com/hail-is/hail/pull/3694,1,['log'],['logic']
Testability,"Fixes #3729. The problem with the If in the array emitting logic was that the lengths were being stored in two different local variables, which were only being evaluated/stored depending on which branch was taken. Because we store that information in another local variable, `xvcond`, and check it again when we're actually consuming the array, the analyzer was checking both branches again for that step, and being unhappy that the local variable where the length is stored could have been unpopulated. I have fixed this by only having one branch and doing both the length calculation and the rest of the stuff there.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4234:59,log,logic,59,https://hail.is,https://github.com/hail-is/hail/pull/4234,1,['log'],['logic']
Testability,"Fixes #4018. @danking @cseed I'm sorry for how big this PR has gotten. I implemented everything we discussed and it's working, but there are still a number of issues to address. 1. The IndexReader is initialized for each partition (via a path that is passed as a String). This means that the decoder in the IndexReader is compiled on the workers. To make this work, I had to comment out the assertion that FunctionBuilder can only emit code on the master node. If we create the indexReaders on the master node, then we'll have to make them serializable and I was having trouble getting that to work with the decoder and the region in the reader. I could make every problematic field `@transient`, but I'm not sure that actually solves the problem. 2. The underlying iterator that is used in 2 / 3 of the new BgenRecordIterators use iterators from the IndexReader. However, there is no way to specify when to close them. Is `close()` called automatically on the IndexReader when the partition is garbage collected?. 3. The way I wrote this was to make the table that is being joined with the BgenRDD when filtering variants to contain duplicate values if the same key appears in multiple partitions on the BGEN side. This means that the iterator is going through each index in the partition and comparing it to the variants in the filter. Therefore, it is `O(nVariants in Partition)` rather than approximately `O(nVariants in Filter in Partition)`. I think this is okay, since I expect iterating through the keys in the index reader is much faster than downstream operations, but it is something to be aware of. 4. My code for checking whether two BGEN files overlap uses `isDisjoint` on intervals. This means that we don't allow files whose endpoints overlap. I think as a first pass this is fine, but I may need to write more complicated code to test whether the files given by the user are compatible. 5. The MatrixImportBGEN IR in Python is currently wrong -- there's no way to pass the requested t",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4291:391,assert,assertion,391,https://hail.is,https://github.com/hail-is/hail/pull/4291,1,['assert'],['assertion']
Testability,"Fixes #4816. I pulled this out of the other PR, since it's still failing the CI tests, so I'll remove this part there.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4847:80,test,tests,80,https://hail.is,https://github.com/hail-is/hail/pull/4847,1,['test'],['tests']
Testability,"Fixes #5106. (I realized halfway through that cseed fixed the problem with the artifacts not getting copied in a PR a few weeks ago, but I think the codegen tests should probably be writing to their own directory and not overwriting other tests.)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5275:157,test,tests,157,https://hail.is,https://github.com/hail-is/hail/pull/5275,2,['test'],['tests']
Testability,"Fixes #5449. We don't have machinery for testing performance behavior of something; like show() right now, so I can't test it easily. But I did verify by; hand.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5468:41,test,testing,41,https://hail.is,https://github.com/hail-is/hail/pull/5468,2,['test'],"['test', 'testing']"
Testability,"Fixes #5777. Timing in master for benchmark/matrix_table_entries_table:. run 1 took 91.15s; run 2 took 86.58s; run 3 took 85.45s; Mean, Median: 87.73s, 86.58s. Timing on this branch:. run 1 took 20.33s; run 2 took 20.98s; run 3 took 21.28s; Mean, Median: 20.86s, 20.98s",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5799:34,benchmark,benchmark,34,https://hail.is,https://github.com/hail-is/hail/pull/5799,1,['benchmark'],['benchmark']
Testability,"Fixes #5830. Jon, can you test this?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5835:26,test,test,26,https://hail.is,https://github.com/hail-is/hail/pull/5835,1,['test'],['test']
Testability,Fixes #7044. (tested on cluster),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7046:14,test,tested,14,https://hail.is,https://github.com/hail-is/hail/pull/7046,1,['test'],['tested']
Testability,"Fixes #8316 . I honestly don't know really know how this env/agg_env stuff works, I just know that this makes the tests pass. It's possible that this is an improvement but not a fully correct substitution rule, would appreciate if you could check it / tell me how you figured out what it's supposed to be.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8322:114,test,tests,114,https://hail.is,https://github.com/hail-is/hail/pull/8322,1,['test'],['tests']
Testability,"Fixes #8325. Got rid of dummy_table logic, which is unnecessary with `parallelize`. Agg/Scan envs were being mishandled in Extract/liftScan.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8350:36,log,logic,36,https://hail.is,https://github.com/hail-is/hail/pull/8350,1,['log'],['logic']
Testability,"Fixes connection timeout after 8 hours. . When we transition to aiomysql, will port well to a pooled connection version (`async with self.pool.acquire() as conn:`. Even now however, the time it takes to acquire a connection is not the bottleneck during login. cc @danking assigned you as well in case you're on.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5815:253,log,login,253,https://hail.is,https://github.com/hail-is/hail/pull/5815,1,['log'],['login']
Testability,"Fixes https://github.com/hail-is/hail/issues/14130. We pervasively assume:; 1. That our entire system is used within a single Python thread.; 2. That once an event loop is created that's the only event loop that will exist forever. Pytest (and newer version of IPython, afaict) violate this pretty liberally. ~~pytest_asyncio has [explicit instructions on how to run every test in the same event loop](https://pytest-asyncio.readthedocs.io/en/latest/how-to-guides/run_session_tests_in_same_loop.html). I've implemented those here.~~ [These instructions don't work](https://github.com/pytest-dev/pytest-asyncio/issues/744). It seems that the reliable way to ensure we're using one event loop everywhere is to use pytest-asyncio < 0.23 and to define an event_loop fixture with scope `'session'`. I also switched test_batch.py into pytest-only style. This allows me to use session-scoped fixtures so that they exist exactly once for the entire test suite execution. Also:; - `RouterAsyncFS` methods must either be a static method or an async method. We must not create an FS in a sync method. Both `parse_url` and `copy_part_size` now both do not allocate an FS.; - `httpx.py` now eagerly errors if the running event loop in `request` differs from that at allocation time. Annoying but much better error message than this nonsense about timeout context managers.; - `hail_event_loop` either gets the current thread's event loop (running or not, doesn't matter to us) or creates a fresh event loop and sets it as the current thread's event loop. The previous code didn't guarantee we'd get an event loop b/c `get_event_loop` fails if `set_event_loop` was previously called.; - `conftest.py` is inherited downward, so I lifted fixtures out of test_copy.py and friends and into a common `hailtop/conftest.py`; - I added `make -C hail pytest-inter-cloud` for testing the inter cloud directory. You still need appropriate permissions and authn.; - I removed extraneous pytest.mark.asyncio since we use auto mo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14097:373,test,test,373,https://hail.is,https://github.com/hail-is/hail/pull/14097,2,['test'],['test']
Testability,Fixes https://github.com/hail-is/hail/issues/2802. fixed a bug where a matrix with duplicated row keys would join incorrectly witha table via a computed key (vds_key); added test for this case; moved the vds_key logic and tests to python in api2; removed vds_key from api1,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2807:174,test,test,174,https://hail.is,https://github.com/hail-is/hail/pull/2807,3,"['log', 'test']","['logic', 'test', 'tests']"
Testability,"Fixes https://github.com/hail-is/hail/issues/3969. This was quite a subtle one. I was able to replicate:. before:. ```; >>> ht = hl.utils.range_table(1000); >>> ht = ht.annotate(tp = True); >>> ht = ht.annotate(x = hl.cond(~ht.tp, ht.tp, ht.tp & hl.rand_bool(0.5))); >>> ht.aggregate(hl.agg.counter(ht.x)); {False: 755, True: 245}; >>> ht = hl.utils.range_table(1000); >>> ht = ht.annotate(tp = True); >>> ht = ht.annotate(x = ht.tp & hl.rand_bool(0.5)); >>> ht.aggregate(hl.agg.counter(ht.x)); {False: 490, True: 510}; ```. after. ```; >>> ht = ht.annotate(tp = True); >>> ht = ht.annotate(x = hl.cond(~ht.tp, ht.tp, ht.tp & hl.rand_bool(0.5))); >>> ht.aggregate(hl.agg.counter(ht.x)); {False: 498, True: 502}; >>> ht = hl.utils.range_table(1000); >>> ht = ht.annotate(tp = True); >>> ht = ht.annotate(x = ht.tp & hl.rand_bool(0.5)); >>> ht.aggregate(hl.agg.counter(ht.x)); {False: 489, True: 511}; ```. Rather than put in a probabilistic test, I directly test the number of executions of the parts of the EmitTriplet of the children of the conditional. I verified the test catches the bug.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4029:940,test,test,940,https://hail.is,https://github.com/hail-is/hail/pull/4029,3,['test'],['test']
Testability,Fixes the test where 'ERROR: could not find file' is in the message.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11692:10,test,test,10,https://hail.is,https://github.com/hail-is/hail/pull/11692,1,['test'],['test']
Testability,"Fixes this assertion error in ci2 logs:; ```; ERROR | 2019-05-21 20:22:56,019 | ci.py | update_loop:239 | hail-is/hail:master update failed due to exception: Traceback (most recent call last):; File ""/ci/ci.py"", line 235, in update_loop; await wb.update(app); File ""/ci/github.py"", line 465, in update; await self._update(app); File ""/ci/github.py"", line 481, in _update; await self._update_github(gh); File ""/ci/github.py"", line 543, in _update_github; await pr._update_github_review_state(gh); File ""/ci/github.py"", line 261, in _update_github_review_state; assert state in ('DISMISSED', 'COMMENTED'), state; AssertionError: PENDING; PENDING; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6152:11,assert,assertion,11,https://hail.is,https://github.com/hail-is/hail/pull/6152,4,"['Assert', 'assert', 'log']","['AssertionError', 'assert', 'assertion', 'logs']"
Testability,"Fixes this error in a deploy batch:. ```; io/test/test_batch.py::Test::test_authorized_users_only ; -------------------------------- live log setup --------------------------------; 2020-03-03T21:02:22 INFO test.conftest conftest.py:8:log_before_after starting test; FAILED; _______________________ Test.test_authorized_users_only ________________________. self = <test.test_batch.Test testMethod=test_authorized_users_only>. def test_authorized_users_only(self):; endpoints = [; (requests.get, '/api/v1alpha/batches/0/jobs/0', 401),; (requests.get, '/api/v1alpha/batches/0/jobs/0/log', 401),; (requests.get, '/api/v1alpha/batches', 401),; (requests.post, '/api/v1alpha/batches/create', 401),; (requests.post, '/api/v1alpha/batches/0/jobs/create', 401),; (requests.get, '/api/v1alpha/batches/0', 401),; (requests.delete, '/api/v1alpha/batches/0', 401),; (requests.patch, '/api/v1alpha/batches/0/close', 401),; # redirect to auth/login; (requests.get, '/batches', 302),; (requests.get, '/batches/0', 302),; (requests.post, '/batches/0/cancel', 401),; (requests.get, '/batches/0/jobs/0', 302)]; for f, url, expected in endpoints:; full_url = deploy_config.url('batch', url); r = f(full_url, allow_redirects=False); > assert r.status_code == expected, (full_url, r, expected); E AssertionError: ('http://batch.hail/api/v1alpha/batches/0/jobs/0/log', <Response [503]>, 401); E assert 503 == 401; E -503; E +401. io/test/test_batch.py:415: AssertionError; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8230:45,test,test,45,https://hail.is,https://github.com/hail-is/hail/pull/8230,17,"['Assert', 'Test', 'assert', 'log', 'test']","['AssertionError', 'Test', 'assert', 'log', 'login', 'test', 'testMethod']"
Testability,"Fixes this error message in logs:. ```; Traceback (most recent call last):; File ""/usr/local/lib/python3.6/dist-packages/aiohttp/web_protocol.py"", line 418, in start; resp = await task; File ""/usr/local/lib/python3.6/dist-packages/aiohttp/web_app.py"", line 458, in _handle; resp = await handler(request); File ""/usr/local/lib/python3.6/dist-packages/aiohttp/web_middlewares.py"", line 119, in impl; return await handler(request); File ""/usr/local/lib/python3.6/dist-packages/aiohttp_session/__init__.py"", line 152, in factory; response = await handler(request); File ""/usr/local/lib/python3.6/dist-packages/ci/ci.py"", line 302, in batch_callback; await asyncio.shield(batch_callback_handler(request)); File ""/usr/local/lib/python3.6/dist-packages/ci/ci.py"", line 276, in batch_callback_handler; await wb.notify_batch_changed(); TypeError: notify_batch_changed() missing 1 required positional argument: 'app'; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7399:28,log,logs,28,https://hail.is,https://github.com/hail-is/hail/pull/7399,1,['log'],['logs']
Testability,"Fixes: #14247. Issues resolved herein:. 1. build.yaml tests must not use `exit 0` as it exits the test early.; 2. Always prefer `orjson` to `json`.; 3. Add `--wait` which waits for the submitted batch to complete and exits success only when the batch is success.; 4. Whenever working with paths, we must use the `realpath` which resolves symlinks. In particular, on Mac OS X, `/tmp` is a symlink to `/private/tmp` and Python's APIs are inconsistent on whether they return a realpath or a path with symlinks. [1]; 5. If the destination looks like a directory (e.g. ""bar:/foo/"", ""bar:/""), the tests all suggest we should copy *into* not *to*. We now check for a trailing slash and copy *into*.; 6. `ln -s src dst` means different things depending on whether dst is an extant folder or not. In this PR, I prefer to always be fully explicit so I never rely on `ln` detecting the destination is a directory and acting differently. Put differently: `file_input_to_src_dest` now never returns a file source and a destination folder.; 7. We need to create the `real_absolute_cwd()` on the job before we `cd` into it.; 8. `test_dir_outside_curdir` suggests that `--file foo/:/` is meant to copy the contents of foo into the root. This cannot be implemented with our symlink strategy (you can't replace the root with a symlink), so I changed the interpretation: a trailing slash on the source is meaningless. If the destination ends in a slash, we ""copy into"", otherwise we ""copy to"".; 9. Add examples of --files usage. [1]:. ```ipython3; In [1]: import tempfile; ...: tempfile.TemporaryDirectory(); Out[1]: <TemporaryDirectory '/var/folders/x1/601098gx0v11qjx2l_7qfw2c0000gq/T/tmp_pmj3lr9'>. In [2]: import os; ...: os.getcwd(); Out[2]: '/private/tmp'. In [3]: !ls -al /tmp; lrwxr-xr-x@ 1 root wheel 11 Aug 2 05:44 /tmp -> private/tmp; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14186:54,test,tests,54,https://hail.is,https://github.com/hail-is/hail/pull/14186,3,['test'],"['test', 'tests']"
Testability,"Fixes: https://github.com/broadinstitute/hail/issues/321. I just tested it on the Cray against 20K exomes. Took ~6m, worked like a charm.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/532:65,test,tested,65,https://hail.is,https://github.com/hail-is/hail/pull/532,1,['test'],['tested']
Testability,"Fixes:. ```. async def test_billing_monitoring():; deploy_config = get_deploy_config(); monitoring_deploy_config_url = deploy_config.url('monitoring', '/api/v1alpha/billing'); headers = service_auth_headers(deploy_config, 'monitoring'); async with in_cluster_ssl_client_session(; raise_for_status=True,; timeout=aiohttp.ClientTimeout(total=60)) as session:; ; async def wait_forever():; data = None; while data is None:; resp = await utils.request_retry_transient_errors(; session, 'GET', f'{monitoring_deploy_config_url}', headers=headers); data = await resp.json(); await asyncio.sleep(5); return data; ; data = await asyncio.wait_for(wait_forever(), timeout=30 * 60); > assert data['cost_by_service'], str(data); E AssertionError: {'cost_by_service': [], 'compute_cost_breakdown': [], 'cost_by_sku_label': [], 'time_period_query': '09/2020'}; E assert []; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9389:673,assert,assert,673,https://hail.is,https://github.com/hail-is/hail/pull/9389,3,"['Assert', 'assert']","['AssertionError', 'assert']"
Testability,"Fixing MakeNDArray to not double allocate cut my laptop benchmark time by more than 50%, it's only a bit slower than main now (~5-10%), so we should probably try and get it in. Feel free to review again when you get a chance.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10001#issuecomment-781709108:56,benchmark,benchmark,56,https://hail.is,https://github.com/hail-is/hail/pull/10001#issuecomment-781709108,1,['benchmark'],['benchmark']
Testability,Flaky Test: :testHail > vds_assoc.lmmreg,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1416:6,Test,Test,6,https://hail.is,https://github.com/hail-is/hail/issues/1416,2,"['Test', 'test']","['Test', 'testHail']"
Testability,"Float64,InbreedingCoeff:Float64,MLEAC:Array[Int32],MLEAF:Array[Float64],MQ:Float64,MQ0:Int32,MQRankSum:Float64,QD:Float64,ReadPosRankSum:Float64,set:String}}"",""_bufferSpec"":{""name"":""LEB128BufferSpec"",""child"":{""name"":""BlockingBufferSpec"",""blockSize"":32768,""child"":{""name"":""LZ4HCBlockBufferSpec"",""blockSize"":32768,""child"":{""name"":""StreamBlockBufferSpec""}}}}},gs://danking/workshop-test/1kg.mt/rows/rows/parts/,{""name"":""TypedCodecSpec"",""_eType"":""+EBaseStruct{`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:+EArray[+EBaseStruct{GT:EInt32,AD:EArray[+EInt32],DP:EInt32,GQ:EInt32,PL:EArray[+EInt32]}]}"",""_vType"":""Struct{`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:Array[Struct{GT:Call,AD:Array[Int32],DP:Int32,GQ:Int32,PL:Array[Int32]}]}"",""_bufferSpec"":{""name"":""LEB128BufferSpec"",""child"":{""name"":""BlockingBufferSpec"",""blockSize"":32768,""child"":{""name"":""LZ4HCBlockBufferSpec"",""blockSize"":32768,""child"":{""name"":""StreamBlockBufferSpec""}}}}},gs://danking/workshop-test/1kg.mt/entries/rows/parts/,Some((gs://danking/workshop-test/1kg.mt/index/,+PCStruct{locus:+PCLocus(GRCh37),alleles:+PCArray[+PCString]})),None)),Some(TableStageDependency(WrappedArray()))),Begin(ArrayBuffer(WriteMetadata(MakeArray(ArrayBuffer(GetField(WritePartition(MakeStream(ArrayBuffer(Literal(struct{},[])),stream<struct{}>,false),Str(""part-0""),PartitionNativeWriter({""name"":""TypedCodecSpec"",""_eType"":""+EBaseStruct{}"",""_vType"":""Struct{}"",""_bufferSpec"":{""name"":""LEB128BufferSpec"",""child"":{""name"":""BlockingBufferSpec"",""blockSize"":32768,""child"":{""name"":""LZ4HCBlockBufferSpec"",""blockSize"":32768,""child"":{""name"":""StreamBlockBufferSpec""}}}}},gs://danking/workshop-test/1kg.mt/globals/globals/parts/,None,None)),filePath)),array<str>),RVDSpecWriter(gs://danking/workshop-test/1kg.mt/globals/globals,RVDSpecMaker({""name"":""TypedCodecSpec"",""_eType"":""+EBaseStruct{}"",""_vType"":""Struct{}"",""_bufferSpec"":{""name"":""LEB128BufferSpec"",""child"":{""name"":""BlockingBufferSpec"",""blockSize"":32768,""child"":{""name"":""LZ4HCBlockBufferSpec"",""blockSize"":32768,",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9856:9231,test,test,9231,https://hail.is,https://github.com/hail-is/hail/issues/9856,1,['test'],['test']
Testability,"Float64] ; !103 = GetField(%89) [n_hom_var]; !104 = Cast(!103) [Float64]; ApplyBinaryPrimOp(!102, !104) [FloatingPointDivide]; } else {; NA [Float64]; } ; !106 = GetField(%89) [n_deletion] ; !107 = I64 [0]; !108 = ApplyComparisonOp(!106, !107) [NEQ]; !113 = If !108 then {; !109 = GetField(%89) [n_insertion]; !110 = Cast(!109) [Float64] ; !111 = GetField(%89) [n_deletion]; !112 = Cast(!111) [Float64]; ApplyBinaryPrimOp(!110, !112) [FloatingPointDivide]; } else {; NA [Float64]; }; !114 = InsertFields %89 (r_ti_tv: !97, r_het_hom_var: !105, r_insertion_deletion: !113); InsertFields !31 (mt_sample_qc: !114); }; !115 = ToArray(!s4); %116 = InsertFields %21 (__cols: !115); !117 = Literal [Array[Struct{leftContext:Struct{partitionIndex:Int64,partitionPath:String},rightContext:Struct{partitionIndex:Int64,partitionPath:String}}], <literal value>]; !s5 = ToStream(!117) [False] ; !118 = Literal [Array[String], <literal value>]; !s6 = ToStream(!118) [False]; !s7 = StreamZip(!s5, !s6) [-1, AssertSameLength] {; (%elt2, %elt3) =>; MakeStruct(oldCtx: %elt2, writeCtx: %elt3); } ; !119 = MakeStruct(__iruid_13045: %16, __iruid_13047: %20, __iruid_13049: %116) ; !120 = NA [String]; %144 = CollectDistributedArray(!s7, !119, !120) {; (%ctx, %g) =>; %121 = GetField(%g) [__iruid_13049]; %122 = GetField(%g) [__iruid_13047]; %123 = GetField(%g) [__iruid_13045]; %124 = GetField(%ctx) [oldCtx]; %125 = Ref [__iruid_13054]; %126 = Ref [__iruid_13049]; %127 = Ref [__iruid_13047]; %128 = Ref [__iruid_13047]; !s8 = ReadPartition(%125) [Struct{locus:Locus(GRCh38),alleles:Array[String],filters:Set[String],a_index:Int32,was_split:Boolean,variant_qc:Struct{gq_stats:Struct{mean:Float64,stdev:Float64,min:Float64,max:Float64},call_rate:Float64,n_called:Int64,n_not_called:Int64,n_filtered:Int64,n_het:Int64,n_non_ref:Int64,het_freq_hwe:Float64,p_value_hwe:Float64,p_value_excess_het:Float64},info:Struct{AC:Array[Int32],AF:Array[Float64],AN:Int32,homozygote_count:Array[Int32]},`the entries! [877f12a8827e18f612",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13809:23086,Assert,AssertSameLength,23086,https://hail.is,https://github.com/hail-is/hail/issues/13809,1,['Assert'],['AssertSameLength']
Testability,Follow on to #9066. Still todo: tests for `--update-hail-version`. Those will require a mock for deploy metadata.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9078:32,test,tests,32,https://hail.is,https://github.com/hail-is/hail/pull/9078,2,"['mock', 'test']","['mock', 'tests']"
Testability,"Following up on the last PR, that didn't actually solve the general problem. See the test at the bottom for an example of an IR that wasn't matching the rule.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7096:85,test,test,85,https://hail.is,https://github.com/hail-is/hail/pull/7096,1,['test'],['test']
Testability,"For Hail Batch on Terra Azure, the production artifact is Helm chart containing the necessary kubernetes resources to run a Hail Batch deployment in a Terra k8s cluster. This deployment contains slightly modified containers of the batch front-end, batch driver and a mysql database. This chart is currently built manually using the targets in `batch/terra-chart/Makefile`. As this process is not currently automatically tested, it's very prone to bit rot. This PR is an amalgamation of fixes that I needed to make to get `main` to build in the current Terra. A non-exhaustive list of the changes are:. - After changing from gradle to mill, the some Dockerfiles and make targets needed to change to account for the new location of the JAR.; - I removed some redundancy in invocations of `docker build` by relying on the generic targets that we now have in the top level Makefile.; - Terra changed how they handle identity management for the kubernetes deployment, from `aadpodidentity` to `workloadIdentity`. This changes the chart to work with their new inputs they provide. Ultimately, terra should have a CI system that we can push charts to and receive feedback on whether it passed our test suite in their test environment.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14450:420,test,tested,420,https://hail.is,https://github.com/hail-is/hail/pull/14450,3,['test'],"['test', 'tested']"
Testability,"For a bit of extra confidence, I ran test-dataproc on this branch: https://ci.hail.is/batches/7960963. The clusters created successfully and the tests are running now.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13573#issuecomment-1709195201:37,test,test-dataproc,37,https://hail.is,https://github.com/hail-is/hail/pull/13573#issuecomment-1709195201,2,['test'],"['test-dataproc', 'tests']"
Testability,"For added context see: https://github.com/hail-is/hail/issues/13351. cc: @patrick-schultz @chrisvittal @daniel-goldstein @ehigham @iris-garden . I actually don't think we need to notify anyone because we'll still get errors if something goes wrong in default. If main starts failing, we have the slightly annoying situation of needing to run tests in a one-off manner to verify and we might need to block a release until we can revert.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13353:342,test,tests,342,https://hail.is,https://github.com/hail-is/hail/pull/13353,1,['test'],['tests']
Testability,For benchmarking.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/963:4,benchmark,benchmarking,4,https://hail.is,https://github.com/hail-is/hail/pull/963,1,['benchmark'],['benchmarking']
Testability,"For block matrices, we apparently have a notion of ""tensor shape"" vs ""matrix shape"". I am so far not a huge fan of this, as I don't think `BlockMatrix` was really designed to be anything other than a matrix. Anyway, the bug here is that the types contain the ""tensor shape"", and the block matrix filtering code was acting under the assumption that the types contained the ""matrix shape"". I've tried to be explicit when naming them below. . I also added some python tests to catch this. We have Scala filtering tests as well, so just added enough python tests to convince myself this bug was fixed.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8021:465,test,tests,465,https://hail.is,https://github.com/hail-is/hail/pull/8021,3,['test'],['tests']
Testability,"For example, fisher's exact test should look something like this:. fet(0, 100, 5, 1000, t, oddsRatio = 2, confidence_level = 0.1, alternative = ""two.sided"")",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/431:28,test,test,28,https://hail.is,https://github.com/hail-is/hail/issues/431,1,['test'],['test']
Testability,For example:; https://ci.hail.is/batches/756/jobs/7. used to have the log:; ```; +python3 scale_test.py dbuf-0.dbuf 10 40000 1000; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7758:70,log,log,70,https://hail.is,https://github.com/hail-is/hail/issues/7758,1,['log'],['log']
Testability,"For linreg, logrem, lmmreg, and skat:; - changed Python implementation to annotate or select on `x` if not a field and always pass `x_field`, which must be float64 but may have missing values.; - changed Scala linreg, logrem, lmmreg, and skat to take `xField` rather than `xExpr`. Updated Scala tests with selectEntry accordingly.; - replaced RegressionUtils `inputVector` with `setMeanImputedDoubles`; - removed `dataset` parameter from Python. Now all methods that take a dataset and one or more required expressions on that dataset now only take the expressions. Updated docs, tests, tutorial accordingly.; - added `req_tstring` to linear_mixed_regression and `We plan to change the interface to this method in Hail 0.2 while maintaining its functionality.` The constraint is due to string assumption made when comparing and filtering column keys against keys on KinshipMatrix. Since the latter is going away (and marked as such), I don't think it's worth more changes to remove the constraint.; - made docs more consistent and variable names more generic (sample=>col, variant=>row, etc)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3289:12,log,logrem,12,https://hail.is,https://github.com/hail-is/hail/pull/3289,4,"['log', 'test']","['logrem', 'tests']"
Testability,"For my pipeline code, I need a way to iterate through the list of jobs submitted and collect their error codes to determine if a pipeline failed and if so print out the log.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5200:169,log,log,169,https://hail.is,https://github.com/hail-is/hail/pull/5200,1,['log'],['log']
Testability,"For posterity, I ran this test:; ```python; ds = hl.read_matrix_table('gs://danking/ALL.chip.omni_broad_sanger_combined.20140818.snps.genotypes-hail-bff300d475ac.mt'); gp = (ds.group_rows_by(contig=ds.locus.contig, pos=ds.locus.position/1000); .aggregate(n_non_ref = hl.agg.count_where(ds.GT.is_non_ref()))); gp = gp.filter_entries((gp.n_non_ref != 0) & hl.is_defined(gp.n_non_ref)); gp.n_non_ref.show(); ```; ```bash; (hail) 1 dking@wmb16-359 # gsutil du -sh gs://danking/ALL.chip.omni_broad_sanger_combined.20140818.snps.genotypes-hail-bff300d475ac.mt; 1.23 GiB gs://danking/ALL.chip.omni_broad_sanger_combined.20140818.snps.genotypes-hail-bff300d475ac.mt; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3546#issuecomment-389964885:26,test,test,26,https://hail.is,https://github.com/hail-is/hail/pull/3546#issuecomment-389964885,1,['test'],['test']
Testability,"For posterity, update the date in the change log to reflect when PR #12987 was merged and the release made. Very minor, and probably already less important than it was last week, but for future readers it's useful for these to be aligned…",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13047:45,log,log,45,https://hail.is,https://github.com/hail-is/hail/pull/13047,1,['log'],['log']
Testability,"For reference, here was the plink output from one of those tests:. ```. @----------------------------------------------------------@; | PLINK! | v1.07 | 10/Aug/2009 |; |----------------------------------------------------------|; | (C) 2009 Shaun Purcell, GNU General Public License, v2 |; |----------------------------------------------------------|; | For documentation, citation & bug-report instructions: |; | http://pngu.mgh.harvard.edu/purcell/plink/ |; @----------------------------------------------------------@. Web-based version check ( --noweb to skip ); Recent cached web-check found...Problem connecting to web. Writing this text to log file [ /tmp/hail.3ouc7OzAKpSQ/plink.00001.log ]; Analysis started: Mon Jul 4 11:38:41 2016. ** Unused command line option: --vcf; ** Unused command line option: src/test/resources/sample.vcf; ** Unused command line option: --const-fid; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/457#issuecomment-230289474:59,test,tests,59,https://hail.is,https://github.com/hail-is/hail/issues/457#issuecomment-230289474,4,"['log', 'test']","['log', 'test', 'tests']"
Testability,For some reason either artifact registry or aiodocker returns a 500 instead of a 403 when a service account does not have access to pull an image. Had to add another special case for handling this error. https://console.cloud.google.com/logs/query;query=%22ys6od%22;pinnedLogId=2022-10-03T13:09:09.430766581Z%2Fyw46w2divo5eqk0vv;cursorTimestamp=2022-10-03T13:09:09.430766581Z?project=hail-vdc,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12257:237,log,logs,237,https://hail.is,https://github.com/hail-is/hail/pull/12257,1,['log'],['logs']
Testability,"For testing ci2, not assigned yet.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5842:4,test,testing,4,https://hail.is,https://github.com/hail-is/hail/pull/5842,1,['test'],['testing']
Testability,"For testing, we start a server with `python ci/ci.py`. That doesn't appear to work. Do we need to pip install it instead?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4709#issuecomment-435169908:4,test,testing,4,https://hail.is,https://github.com/hail-is/hail/pull/4709#issuecomment-435169908,1,['test'],['testing']
Testability,For testing. Will peel off and PR pieces.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8310:4,test,testing,4,https://hail.is,https://github.com/hail-is/hail/pull/8310,1,['test'],['testing']
Testability,"For the `hail` python package, even if some things don't work great/at all, I think it would be nice if it at least installed on windows. `uvloop` is unsupported on windows, so I add a little logic to ensure that it's not requried on windows and the copy tool doesn't fail if it's not found.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11740:192,log,logic,192,https://hail.is,https://github.com/hail-is/hail/pull/11740,1,['log'],['logic']
Testability,"For the partitioning algorithm, I updated the test to confirm that all the individuals in the unrelated set are mutually unrelated. For PC-AiR, I updated the test to compare the loadings to PCA on just the unrelated individuals. The loadings are NumPy close. The scores are slightly different though because they are calculated differently. When there are related individuals, the scores are calculated by multiplying the loadings and the standardized genotypes. When there are no related individuals, the scores are calculated by multiplying the columns of the appropriate singular matrix with the eigenvalues. So for the scores, I just add a regression test. (In my testing, I observed that most of the scores were less than 1% different. However, there were a few differences that were larger around 20% or 30%. Not sure if this is a cause for concern because the calculation approaches are different and the SVD is approximate.)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14326#issuecomment-1977943502:46,test,test,46,https://hail.is,https://github.com/hail-is/hail/pull/14326#issuecomment-1977943502,4,['test'],"['test', 'testing']"
Testability,"For the record, mt.count, and mt.force_count in that test, both say that the matrix is empty. So I have no Idea what's going on",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11450#issuecomment-1059484035:53,test,test,53,https://hail.is,https://github.com/hail-is/hail/pull/11450#issuecomment-1059484035,1,['test'],['test']
Testability,"For the record, until we have a fix for GRCh38 VEP image building, we have to manually copy the 0.2.118 tag to the 0.2.119 tag for vep-grch38-95.; ```; skopeo copy docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch38-95:0.2.118 docker://us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch38-95:0.2.119 ; ```. I have done this and retried the ci-test.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13216#issuecomment-1608425471:359,test,test,359,https://hail.is,https://github.com/hail-is/hail/pull/13216#issuecomment-1608425471,1,['test'],['test']
Testability,"For ~1500 joint caller inputs, on what was a frankenbranch (I merged a bunch of stuff together, haven't pushed it). I saw that IR construction in python took around a minute. I'm not entirely sure where the time was being spent though. Also 1 minute is nothing compared to the amount of time we spend actually joint calling. Anyways, `run_combiner.py`; ```python3; def run_combiner(sample_list, json, out_path, tmp_path, summary_path=None, overwrite=False):; # make the temp path a directory, no matter what; tmp_path += f'/combiner-temporary/{uuid.uuid4()}/'; vcfs = [comb.transform_one(vcf); for vcf in hl.import_vcfs(sample_list, json, array_elements_required=False)]; combined = [comb.combine_gvcfs(mts) for mts in chunks(vcfs, MAX_COMBINER_LENGTH)]; if len(combined) == 1:; combined[0].write(out_path, overwrite=overwrite); else:; hl.utils.java.info(f'Writing combiner temporary files to: {tmp_path}'); ... # do more, but this stage isn't huge yet so :man_shrugging: ; ```; Relevant log:; ```; 2019-03-01 22:09:20 DAGScheduler: INFO: Job 0 finished: collect at LoadVCF.scala:1295, took 88.076400 s; 2019-03-01 22:10:19 Hail: INFO: Writing combiner temporary files to: gs://cdv-hail/combiner/tmp//combiner-temporary/dc741728-fdfd-49d9-a66e-94bd7b541879/; ```; Stage zero is tabix reading `sc.parallelize`. The next line is the logging line that I added, almost a minute apart. After that it's 30 seconds for the Optimizer and Lowerer and (printing hundreds of thousands of lines of IR).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5465#issuecomment-469789122:988,log,log,988,https://hail.is,https://github.com/hail-is/hail/pull/5465#issuecomment-469789122,2,['log'],"['log', 'logging']"
Testability,Force merged because tests won't pass without this fix in production.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14549#issuecomment-2108111768:21,test,tests,21,https://hail.is,https://github.com/hail-is/hail/pull/14549#issuecomment-2108111768,1,['test'],['tests']
Testability,Force merging because we keep failing in service backend or in those damn copy tests.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10173#issuecomment-796819618:79,test,tests,79,https://hail.is,https://github.com/hail-is/hail/pull/10173#issuecomment-796819618,1,['test'],['tests']
Testability,Force merging since both this and https://github.com/hail-is/hail/pull/9390 are both needed for successful tests.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9389#issuecomment-684910606:107,test,tests,107,https://hail.is,https://github.com/hail-is/hail/pull/9389#issuecomment-684910606,1,['test'],['tests']
Testability,Force merging this. All other tests besides callback tests are passing.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10668#issuecomment-880963568:30,test,tests,30,https://hail.is,https://github.com/hail-is/hail/pull/10668#issuecomment-880963568,2,['test'],['tests']
Testability,Forgot about the difference between rmtree and remove. I fixed and improved the tests to distinguish between these two.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11599#issuecomment-1069658326:80,test,tests,80,https://hail.is,https://github.com/hail-is/hail/pull/11599#issuecomment-1069658326,1,['test'],['tests']
Testability,Forgot to rebase before adding the tasks for building docs without testing.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1480:67,test,testing,67,https://hail.is,https://github.com/hail-is/hail/pull/1480,1,['test'],['testing']
Testability,"From a fresh clone, the above (modified with `rm -f`) fails with: ; ```bash; $ rm -f hail/upload-remote-test-resources && make -C hail upload-remote-test-resources; make: Entering directory '/home/edmund/.local/src/hail/hail'; # # If hailtop.aiotools.copy gives you trouble:; # gcloud storage cp -r src/test/resources/\* gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/; # gcloud storage cp -r python/hail/docs/data/\* gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/; python3 -m hailtop.aiotools.copy -vvv 'null' '[\; {""from"":""src/test/resources"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/test/resources/""},\; {""from"":""python/hail/docs/data"",""to"":""gs://hail-test-ezlis/edmund/hail-test-resources/doctest/data/""}\; ]' --timeout 600; /home/edmund/.local/src/hail/.venv/bin/python3: Error while finding module specification for 'hailtop.aiotools.copy' (ModuleNotFoundError: No module named 'hailtop'); make: *** [Makefile:355: upload-remote-test-resources] Error 1; make: Leaving directory '/home/edmund/.local/src/hail/hail'; ```. I'll try again with `hailtop` installed - just wanted to point out the dependency failure in `Makefile`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14138#issuecomment-1887719777:104,test,test-resources,104,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1887719777,15,['test'],"['test', 'test-ezlis', 'test-resources']"
Testability,"From iPython:. ```; In [1]: d = {None: 5}. In [2]: d[None]; Out[2]: 5. In [3]: hl.dict({hl.null(hl.tstr): 5}).value; Out[3]: {None: 5}. In [5]: hl.dict({hl.null(hl.tstr): 5}).get(hl.null(hl.tstr)).value. In [6]:; ```. Also, I added a null key to the tests in DictFunctionsSuite to debug the behavior above and this now fails:. ```; val d = IRDict((1, 3), (2, 7), (3, null), (null, 5)); assertEvalsTo(invoke(""get"", d, 100, 50), 50) // returns null instead of 50; assertEvalsTo(invoke(""get"", d, na, 20), 5) // returns null instead of 5; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4445:250,test,tests,250,https://hail.is,https://github.com/hail-is/hail/issues/4445,3,"['assert', 'test']","['assertEvalsTo', 'tests']"
Testability,"From testing in Julia, I think this is critical for accuracy.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10257:5,test,testing,5,https://hail.is,https://github.com/hail-is/hail/pull/10257,1,['test'],['testing']
Testability,"From the logs:; ```; WARNING: --use-feature=2020-resolver no longer has any effect, since it is now the default dependency resolver in pip. This will become an error in pip 21.0.; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9771:9,log,logs,9,https://hail.is,https://github.com/hail-is/hail/pull/9771,1,['log'],['logs']
Testability,"From the man page:. ```; -t Don't run, just test the configuration file. The nginx; checks configuration for correct syntax and then tries; to open files referred in configuration.; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4429:44,test,test,44,https://hail.is,https://github.com/hail-is/hail/pull/4429,1,['test'],['test']
Testability,Funny I actually did this a few weeks ago and then realized it was logged further down. It's around line 76 in a random log I just looked at. I could move it to log from python early on?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7644#issuecomment-561201747:67,log,logged,67,https://hail.is,https://github.com/hail-is/hail/issues/7644#issuecomment-561201747,3,['log'],"['log', 'logged']"
Testability,"Further pruned. Removed all GraphQL libraries, besides graphql-tag, which I like, because 1) simple hash-based cache: no need to walk complex graph to normalize cache, because in most cases I'm perfectly fine with not re-using cache across different queries (that may have some shared fields). Apollo does something ""smarter"", but much slower: walks a query, checks that the requested fields for a node are the same, and that the node's id is the same, as some other query. 2) no runtime validation of query shape via graphql-tag...uses simple template strings, which are free. We don't care about schema validation in the client...because the server will error when schema is invalid. This should be compile time validated instead, in this case via integration tests. Also removed react-icons... I was going to use this in place of material-design-icons, because I thought loading the full font, when I needed only a few icons, would be unnecessarily expensive. It turns out that I cannot find a library where a single icon import (react-icons or MaterialUI) is smaller than Google's entire material design font: a single font (there are several needed to cover all icons) is ~500B. A single react-icons icon is ~2KB on dev (production may be smaller due to tree shaking). Also, am opposed to CSS-in-JS: slower, worse tooling, larger. Benefits are dynamic selectors, which are really no advantage that I can see (without them can still dynamically apply classes, as in the yee ol days of pleb vanilla js). Home page down to <2kb when not logged in, and 3.1KB logged in. This includes header, simple body, and dark mode button.; <img width=""2636"" alt=""screen shot 2018-12-19 at 11 49 59 pm"" src=""https://user-images.githubusercontent.com/5543229/50264482-ed4c3000-03e8-11e9-80d1-81d195a7b37a.png"">; <img width=""2636"" alt=""screen shot 2018-12-19 at 11 50 33 pm"" src=""https://user-images.githubusercontent.com/5543229/50264483-ed4c3000-03e8-11e9-8180-1409ca16573f.png"">. edit: Further .1KB shaved (gzipp",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4931#issuecomment-448868665:762,test,tests,762,https://hail.is,https://github.com/hail-is/hail/pull/4931#issuecomment-448868665,2,['test'],['tests']
Testability,"FutureTask.run(FutureTask.java:266); at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:750). Hail version: 0.2.124-87398e1b514e; Error summary: HailException: file already exists: gs://aou_analysis/250k/data/utils/aou_mt_sample_qc_250k.ht; ```; </details>. The code is simple and clearly is running against a path that does not already exist:; ```; if not hl.hadoop_exists(get_aou_util_path('mt_sample_qc')):; print('Run sample qc MT.....'); mt = hl.read_matrix_table(ACAF_MT_PATH); mt = mt.filter_rows(mt.locus.in_autosome()); # mt = mt.filter_rows(mt.locus.contig == 'chr1'); ht = hl.sample_qc(mt, name='mt_sample_qc'); ht.write(get_aou_util_path('mt_sample_qc'), overwrite=args.overwrite); ```. Job log: https://batch.hail.is/batches/8058522/jobs/171029. <details>; <summary>The last TableIR logged</summary>. ```; 2023-10-13 02:14:44.213 : INFO: after optimize: darrayLowerer, after LowerAndExecuteShuffles: IR size 232: . !ht = TableRead [Table{global:Struct{},key:[locus,alleles],row:Struct{locus:Locus(GRCh38),alleles:Array[String],filters:Set[String],a_index:Int32,was_split:Boolean,variant_qc:Struct{gq_stats:Struct{mean:Float64,stdev:Float64,min:Float64,max:Float64},call_rate:Float64,n_called:Int64,n_not_called:Int64,n_filtered:Int64,n_het:Int64,n_non_ref:Int64,het_freq_hwe:Float64,p_value_hwe:Float64,p_value_excess_het:Float64},info:Struct{AC:Array[Int32],AF:Array[Float64],AN:Int32,homozygote_count:Array[Int32]},`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:Array[Struct{GT:Call,GQ:Int32,RGQ:Int32,FT:String,AD:Array[Int32]}]}}, False, (TableNativeZippedReader gs://prod-drc-broad/aou-wgs-delta-small_callsets_gq0/v7.1/acaf_threshold_v7.1/splitMT/delta_basis_without_ext_aian_prod_gq0_3re",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13809:7568,log,log,7568,https://hail.is,https://github.com/hail-is/hail/issues/13809,1,['log'],['log']
Testability,"GCP Logging attempts to infer the severity of a log entry and defaults to labelling everything written to `stdout` as `INFO` and everything written to `stderr` as `ERROR`. There are some [LogEntry fields](https://cloud.google.com/logging/docs/structured-logging) that can be overwritten by fields in our JSON output, including `severity`. Until now we had been logging the severity level as `levelname`, which is the expectation of `jsonlogger`, but this means GCP's levels and ours do not necessarily match. This adds another `severity` field to the logs so GCP can pick up the level. This should get rid of a swath of non-error log messages written to `stderr` (only JSON though) and lets other levels like `WARNING` get marked as such. GCP does quite literally extract the severity field though, so it does not appear in the `jsonPayload`. I've kept the `levelname` in then as a sanity check but am also happy to try to remove it.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9910:4,Log,Logging,4,https://hail.is,https://github.com/hail-is/hail/pull/9910,8,"['Log', 'log']","['LogEntry', 'Logging', 'log', 'logging', 'logs']"
Testability,"Gah, OK, I think I have it now, but there was one more detail:. The gradle configuration `testCompileOnly` [1] *does not* inherit from the `shadow` configuration (as evidence see [this search](https://github.com/search?q=repo%3Ajohnrengelman%2Fshadow%20extendsFrom&type=code) of the shadow repo). We must explicitly request that `shadow` dependencies are included in the compile-time class path of the tests. This is as it should be: the things in `shadow` are things which are provided to us by our runtime environment. That's true of both the *test* runtime environment and the normal runtime environment. The Gradle Shadow plugin takes a different perspective by default, it suggests that `shadow` dependencies shouldn't be used in the tests at all. [1] NB: `testCompile` does not exist but you don't get an error if you try to use it, thanks for nothing gradle.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13551#issuecomment-1710414563:90,test,testCompileOnly,90,https://hail.is,https://github.com/hail-is/hail/pull/13551#issuecomment-1710414563,5,['test'],"['test', 'testCompile', 'testCompileOnly', 'tests']"
Testability,"Gateway receives the user IP (thanks to #8045). However, gateway is an HTTP; proxy, so packets from gateway necessarily come from gateway's IP. Gateway; places the user IP into the HTTP header `X-Real-IP`. All downstream servers; must: log `X-Real-IP` and forward `X-Real-IP` unadulterated. This PR makes that; change for `router`. - fix router Makefile (`domain` is now in `global`); - add `proxy.conf` which configures the standard proxy headers (importantly:; forwards `X-REAL-IP`); - for non-notebook servers, `include` the `proxy.conf`; - for notebook, update to include proxy headers; - override default `access_log` (which required checking in the default; `nginx.conf`); - lift other `http` directives into `nginx.conf` now that it is checked in",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8058:236,log,log,236,https://hail.is,https://github.com/hail-is/hail/pull/8058,1,['log'],['log']
Testability,Gear logging,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6439:5,log,logging,5,https://hail.is,https://github.com/hail-is/hail/pull/6439,1,['log'],['logging']
Testability,"Generalizes `OrderedRVD` and `OrderedRVDPartitioner`, and paves the way to removing partition keys and `UnpartitionedRVD`. There is a bug related to split_multi; I'm waiting on #4076, which may resolve the problem. I also want to add some more tests before review.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4094:244,test,tests,244,https://hail.is,https://github.com/hail-is/hail/pull/4094,1,['test'],['tests']
Testability,Get tests working with the service,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5121:4,test,tests,4,https://hail.is,https://github.com/hail-is/hail/pull/5121,1,['test'],['tests']
Testability,GetTupleElement and GetField IRSuite Tests,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4467:37,Test,Tests,37,https://hail.is,https://github.com/hail-is/hail/pull/4467,1,['Test'],['Tests']
Testability,"Getting a sporadic task failure, with the error:; ```; ExecutorLostFailure (executor 99 exited caused by one of the running tasks) Reason: Container marked as failed: container_1519994715701_0003_01_000102 on host: exomes-sw-pxt3.c.broad-mpg-gnomad.internal. Exit status: 134. Diagnostics: Exception from container-launch.; Container id: container_1519994715701_0003_01_000102; Exit code: 134; Exception message: /bin/bash: line 1: 6739 Aborted /usr/lib/jvm/java-8-openjdk-amd64/bin/java -server -Xmx11171m '-Xss4M' -Djava.io.tmpdir=/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1519994715701_0003/container_1519994715701_0003_01_000102/tmp '-Dspark.driver.port=41843' '-Dspark.rpc.message.maxSize=512' -Dspark.yarn.app.container.log.dir=/var/log/hadoop-yarn/userlogs/application_1519994715701_0003/container_1519994715701_0003_01_000102 -XX:OnOutOfMemoryError='kill %p' org.apache.spark.executor.CoarseGrainedExecutorBackend --driver-url spark://CoarseGrainedScheduler@10.128.0.4:41843 --executor-id 99 --hostname exomes-sw-pxt3.c.broad-mpg-gnomad.internal --cores 4 --app-id application_1519994715701_0003 --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1519994715701_0003/container_1519994715701_0003_01_000102/__app__.jar --user-class-path file:/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1519994715701_0003/container_1519994715701_0003_01_000102/hail.jar > /var/log/hadoop-yarn/userlogs/application_1519994715701_0003/container_1519994715701_0003_01_000102/stdout 2> /var/log/hadoop-yarn/userlogs/application_1519994715701_0003/container_1519994715701_0003_01_000102/stderr. Stack trace: ExitCodeException exitCode=134: /bin/bash: line 1: 6739 Aborted /usr/lib/jvm/java-8-openjdk-amd64/bin/java -server -Xmx11171m '-Xss4M' -Djava.io.tmpdir=/hadoop/yarn/nm-local-dir/usercache/root/appcache/application_1519994715701_0003/container_1519994715701_0003_01_000102/tmp '-Dspark.driver.port=41843' '-Dspark.rpc.message.maxSize=512'",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3053:746,log,log,746,https://hail.is,https://github.com/hail-is/hail/issues/3053,2,['log'],['log']
Testability,"Getting this over the past few days when doing, well, basically any query. Log: [hail.log.txt](https://github.com/hail-is/hail/files/755839/hail.log.txt). ```; Caused by: java.lang.ClassNotFoundException: is.hail.sparkextras.ReorderedPartitionsRDDPartition; 	at java.net.URLClassLoader.findClass(URLClassLoader.java:381); 	at java.lang.ClassLoader.loadClass(ClassLoader.java:424); 	at java.lang.ClassLoader.loadClass(ClassLoader.java:357); 	at java.lang.Class.forName0(Native Method); 	at java.lang.Class.forName(Class.java:348); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1360:75,Log,Log,75,https://hail.is,https://github.com/hail-is/hail/issues/1360,3,"['Log', 'log']","['Log', 'log']"
Testability,"Getting this with current master on the cloud:. ```; Use of uninitialized value in hash element at /vep/ensembl-tools-release-85/scripts/variant_effect_predictor/Bio/EnsEMBL/Variation/Utils/VEP.pm line 4255, <VARS> line 1.; [Stage 18:=> (273 + 410) / 13592]Traceback (most recent call last):; File ""/tmp/7ff73b01-6ea1-4254-a49d-01e9075ab5b0/subset.py"", line 75, in <module>; main(args, pops); File ""/tmp/7ff73b01-6ea1-4254-a49d-01e9075ab5b0/subset.py"", line 51, in main; 'va.rf').write(args.output + "".autosomes.vds"", overwrite=True); File ""/tmp/7ff73b01-6ea1-4254-a49d-01e9075ab5b0/utils.py"", line 452, in post_process_vds; vds = vds.vep(config=vep_config, csq=True, root='va.info.CSQ', force=True); File ""<decorator-gen-110>"", line 2, in vep; File ""/tmp/7ff73b01-6ea1-4254-a49d-01e9075ab5b0/pyhail-attr.zip/hail/java.py"", line 93, in handle_py4j; hail.java.FatalError: NoSuchElementException: None.get; [Stage 18:=> (277 + 409) / 13592]java.util.concurrent.RejectedExecutionException: Task scala.concurrent.impl.CallbackRunnable@2a632cbb rejected from java.util.concurrent.ThreadPoolExecutor@974d518[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 2913]; ```. Lmk if you need more log.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1518:1218,log,log,1218,https://hail.is,https://github.com/hail-is/hail/issues/1518,1,['log'],['log']
Testability,Getting two tests that region memory is being managed correctly,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8319:12,test,tests,12,https://hail.is,https://github.com/hail-is/hail/pull/8319,1,['test'],['tests']
Testability,Ghost does not respect the `X-Forwarded` headers. It should not have a `url` parameter but a `pathPrefix` and the protocol should be set from `X-Forwarded-Proto`. Thanks to this design bug we cannot test connectivity to the blog in PRs until the internal gateway is configured to use TLS. I'll revisit this PR when that happens.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8117#issuecomment-589741905:199,test,test,199,https://hail.is,https://github.com/hail-is/hail/pull/8117#issuecomment-589741905,1,['test'],['test']
Testability,Github test account disabled,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4517:7,test,test,7,https://hail.is,https://github.com/hail-is/hail/issues/4517,1,['test'],['test']
Testability,"Given a FAM file:; - Identify founders (to use e.g. as filter when testing HWE); - Compute coefficients of relationship and inbreeding, etc.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/102:67,test,testing,67,https://hail.is,https://github.com/hail-is/hail/issues/102,1,['test'],['testing']
Testability,"Given our rate limit increases and turning on additional service tests, 5 concurrent PR batches is too much for the 4-core database to handle. This is a mitigation while we figure out the right way to maintain that load.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11762:65,test,tests,65,https://hail.is,https://github.com/hail-is/hail/pull/11762,1,['test'],['tests']
Testability,"Glad to hear we're not crazy! Please let us know if there's any external; testing we can do to help. On Wed, Jun 24, 2020 at 1:21 PM John Compitello <notifications@github.com>; wrote:. > Confirmed that I'm able to replicate this, also seeing 354 as the cutoff.; > Looking into it.; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/hail-is/hail/issues/8944#issuecomment-649049500>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AAARLWJCO43V5BGEELQSWE3RYJN3BANCNFSM4N2T543Q>; > .; >",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8944#issuecomment-649050351:74,test,testing,74,https://hail.is,https://github.com/hail-is/hail/issues/8944#issuecomment-649050351,1,['test'],['testing']
Testability,"God it feels good to make a pull request again. The following operation copies every file in gs://danking/test/ into a folder named s3://hail-test-bucket/test/. python3 -m hailtop.aiotools.copy null '[{""from"": ""gs://danking/test"", ""to"": ""s3://hail-test-bucket/test""}]'. The `null` can be replaced with a quoted GCP project id if one of the sources is a Requester Pays bucket. For example:. python3 -m hailtop.aiotools.copy '""broad-ctsa""' '[{""from"": ""gs://hail-datasets-us/"", ""to"": ""s3://hail-datasets-us-east-1""}]'. As you can see, the syntax is rough, but expressive. Explicitly listing all the files to be transferred should not impair the throughput. python3 -m hailtop.aiotools.copy null '[; {""from"": ""gs://danking/test/data1"", ""to"": ""s3://hail-test-bucket/test/data1""},; {""from"": ""gs://danking/test/data2"", ""to"": ""s3://hail-test-bucket/test/data2""},; {""from"": ""gs://danking/test/sub-directory1"", ""to"": ""s3://hail-test-bucket/test/sub-directory1""},; ...; ]'. Better syntax is forthcoming: https://github.com/hail-is/hail/pull/9913",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10778:106,test,test,106,https://hail.is,https://github.com/hail-is/hail/pull/10778,15,['test'],"['test', 'test-bucket']"
Testability,"Going off a suspicion that the JVM jit won't compile methods containing irreducible control flow, I tried to fix StreamFlatMap to be reducible. A simple benchmark based on `testES2FlatMap` showed a 2x speedup, which seems to confirm the suspicion. What caused the irreducibility was the following set of control flow paths (pretend the `Lpull` label was defined in the old version too):; * `Lpull -> LinnerPull`; * `Lpull -> LouterPull`; * `LinnerPull -> innerSource.eos -> LinnerEos -> LouterPull`; * `LouterPull -> outerSource.push -> LinnerPull`. The later two paths form a loop, and the first two make two entries into the loop - the basic irreducible control flow pattern. The fix redirects the last path to go to `Lpull` instead, which will happen to branch to `LinnerPull`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9429:153,benchmark,benchmark,153,https://hail.is,https://github.com/hail-is/hail/pull/9429,1,['benchmark'],['benchmark']
Testability,"Going to need some testing, will assign when it is passing.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7226:19,test,testing,19,https://hail.is,https://github.com/hail-is/hail/pull/7226,1,['test'],['testing']
Testability,"Good catch! This is something that's not tested as part of CI, but we should do that (eventually). Will fix this bug, though.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4063#issuecomment-409737215:41,test,tested,41,https://hail.is,https://github.com/hail-is/hail/issues/4063#issuecomment-409737215,1,['test'],['tested']
Testability,Good comments. Addressed:. - renamed bit_flip to bit_not; - added logical flag to bit_rshift; - added more tests with negative numbers; - expanded docs around differences between Python and Hail,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5149#issuecomment-454862527:66,log,logical,66,https://hail.is,https://github.com/hail-is/hail/pull/5149#issuecomment-454862527,2,"['log', 'test']","['logical', 'tests']"
Testability,"Good idea, I'll check. I feel like I initially found this in deep in a redhat tutorial, but ultimately found it again at the bottom of the [man page](https://man7.org/linux/man-pages/man8/xfs_quota.8.html). I was following this example:; ```; Enabling project quota on an XFS filesystem (restrict files in; log file directories to only using 1 gigabyte of space). # mount -o prjquota /dev/xvm/var /var; # echo 42:/var/log >> /etc/projects; # echo logfiles:42 >> /etc/projid; # xfs_quota -x -c 'project -s logfiles' /var; # xfs_quota -x -c 'limit -p bhard=1g logfiles' /var. Same as above without a need for configuration files. # rm -f /etc/projects /etc/projid; # mount -o prjquota /dev/xvm/var /var; # xfs_quota -x -c 'project -s -p /var/log 42' /var; # xfs_quota -x -c 'limit -p bhard=1g 42' /var; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10467#issuecomment-834771396:307,log,log,307,https://hail.is,https://github.com/hail-is/hail/pull/10467#issuecomment-834771396,6,['log'],"['log', 'logfiles']"
Testability,"Good point, re: tests. OK, I'll go ahead and do the rest of the methods.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2590#issuecomment-352193460:16,test,tests,16,https://hail.is,https://github.com/hail-is/hail/pull/2590#issuecomment-352193460,1,['test'],['tests']
Testability,Good point. I'm going to first make sure that it would have failed on a sparse matrix with the `.get` and then show that the same test (hopefully!) passes for the updated PR.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5500#issuecomment-468696410:130,test,test,130,https://hail.is,https://github.com/hail-is/hail/issues/5500#issuecomment-468696410,1,['test'],['test']
Testability,Got it green. Going to benchmark.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12981#issuecomment-1540483249:23,benchmark,benchmark,23,https://hail.is,https://github.com/hail-is/hail/pull/12981#issuecomment-1540483249,1,['benchmark'],['benchmark']
Testability,"Got it! You need to add the loop device. Now how to parse the correct thing from the xfs_info output is another story... ```; jigold@jg-file-cache:~$ xfs_info /mnt/test_xfs; meta-data=/dev/loop2 isize=512 agcount=4, agsize=65536 blks; = sectsz=512 attr=2, projid32bit=1; = crc=1 finobt=1 spinodes=0 rmapbt=0; = reflink=1; data = bsize=4096 blocks=262144, imaxpct=25; = sunit=0 swidth=0 blks; naming =version 2 bsize=4096 ascii-ci=0 ftype=1; log =internal bsize=4096 blocks=2560, version=2; = sectsz=512 sunit=0 blks, lazy-count=1; realtime =none extsz=4096 blocks=0, rtextents=0; ```. ```; jigold@jg-file-cache:~$ sudo docker run --rm --mount type=bind,source=/mnt/test_xfs,target=/host --cap-add SYS_ADMIN --security-opt apparmor:unconfined --device ""/dev/loop2:/dev/loop2:rwm"" test-xfs /bin/bash -c 'xfs_quota -x -c ""report -h"" /host'; Project quota on /host (/dev/loop2); Blocks; Project ID Used Soft Hard Warn/Grace; ---------- ---------------------------------; #0 4K 0 0 00 [------]; #200 0 0 0 00 [------]; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9076#issuecomment-662462004:441,log,log,441,https://hail.is,https://github.com/hail-is/hail/pull/9076#issuecomment-662462004,2,"['log', 'test']","['log', 'test-xfs']"
Testability,"Got it, I just realized it hard way during the test run. Had no clue about that -Dspark.version option. Thanks for the prompt responses. 👍",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1327#issuecomment-302838927:47,test,test,47,https://hail.is,https://github.com/hail-is/hail/issues/1327#issuecomment-302838927,1,['test'],['test']
Testability,Got through that now. Now hitting:; ```; Java stack trace:; java.lang.AssertionError: assertion failed; 	at scala.Predef$.assert(Predef.scala:156); 	at is.hail.rvd.OrderedRVDPartitioner.getPartitionPK(OrderedRVDPartitioner.scala:59); 	at is.hail.sparkextras.OrderedDependency$.getDependencies(OrderedRDD2.scala:22); 	at is.hail.sparkextras.OrderedJoinDistinctRDD2$$anonfun$getPartitions$1.apply(OrderedRDD2.scala:42); 	at is.hail.sparkextras.OrderedJoinDistinctRDD2$$anonfun$getPartitions$1.apply(OrderedRDD2.scala:39); 	at scala.Array$.tabulate(Array.scala:331); 	at is.hail.sparkextras.OrderedJoinDistinctRDD2.getPartitions(OrderedRDD2.scala:39); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250); 	at scala.Option.getOrElse(Option.scala:121); 	at org.apache.spark.rdd.RDD.partitions(RDD.scala:250); 	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250); 	at scala.Option.getOrElse(Option.scala:121); 	at org.apache.spark.rdd.RDD.partitions(RDD.scala:250); 	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250); 	at scala.Option.getOrElse(Option.scala:121); 	at org.apache.spark.rdd.RDD.partitions(RDD.scala:250); 	at org.apache.spark.rdd.RDD.getNumPartitions(RDD.scala:266); 	at is.hail.rvd.RVD$class.getNumPartitions(RVD.scala:128); 	at is.hail.rvd.OrderedRVD.getNumPartitions(OrderedRVD.scala:19); 	at is.hail.sparkextras.OrderedJoinDistinctRDD2.getPartitions(OrderedRDD2.scala:39); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252); 	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250); 	at scala.Option.getOr,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3074#issuecomment-370494908:70,Assert,AssertionError,70,https://hail.is,https://github.com/hail-is/hail/issues/3074#issuecomment-370494908,3,"['Assert', 'assert']","['AssertionError', 'assert', 'assertion']"
Testability,"Gotcha. Yes, your test works. I'll throw an error for now, since this sounds like not a use case we want to support.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7384#issuecomment-546397181:18,test,test,18,https://hail.is,https://github.com/hail-is/hail/issues/7384#issuecomment-546397181,1,['test'],['test']
Testability,"Gradle test > org.broadinstitute.hail.methods.HWESuite.test PASSED. Gradle suite > Gradle test > org.broadinstitute.hail.variant.IntervalListSuite.test PASSED. Gradle suite > Gradle test > org.broadinstitute.hail.utils.LEB128Suite.test PASSED. Gradle suite > Gradle test > org.broadinstitute.hail.stats.LeveneHaldaneSuite.exactTestsTest PASSED. Gradle suite > Gradle test > org.broadinstitute.hail.stats.LeveneHaldaneSuite.meanTest PASSED. Gradle suite > Gradle test > org.broadinstitute.hail.stats.LeveneHaldaneSuite.modeTest PASSED. Gradle suite > Gradle test > org.broadinstitute.hail.stats.LeveneHaldaneSuite.pmfTest PASSED. Gradle suite > Gradle test > org.broadinstitute.hail.stats.LeveneHaldaneSuite.varianceTest PASSED. Gradle suite > Gradle test > org.broadinstitute.hail.methods.LinearRegressionSuite.test PASSED. Gradle suite > Gradle test > org.broadinstitute.hail.methods.MendelErrorsSuite.test PASSED. Gradle suite > Gradle test > org.broadinstitute.hail.methods.MultiArray2Suite.test PASSED. Gradle suite > Gradle test > org.broadinstitute.hail.methods.PedigreeSuite.test PASSED. Gradle suite > Gradle test > org.broadinstitute.hail.methods.SampleQCSuite.testStoreAfterFilter PASSED. Gradle suite > Gradle test > org.broadinstitute.hail.vcf.SplitSuite.SplitTest PASSED. Gradle suite > Gradle test > org.broadinstitute.hail.utils.UtilsSuite.testD_$eq$eq PASSED. Gradle suite > Gradle test > org.broadinstitute.hail.utils.UtilsSuite.testFlushDouble PASSED. Gradle suite > Gradle test > org.broadinstitute.hail.variant.vsm.VSMSuite.testFilterSamples PASSED. Gradle suite > Gradle test > org.broadinstitute.hail.variant.vsm.VSMSuite.testSame PASSED. Gradle suite > Gradle test > org.broadinstitute.hail.variant.VariantSuite.testVariant PASSED. Gradle suite > Gradle test > org.broadinstitute.hail.methods.gqDpStatsSuite.test PASSED; :check. BUILD SUCCESSFUL; ```. **TIMING**. import, write chr22; - Current master, best of 3: 1m48.5s; - map-any, best of 3: 1m43.1s. read, filtervariants --",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/158#issuecomment-173700450:2264,test,test,2264,https://hail.is,https://github.com/hail-is/hail/pull/158#issuecomment-173700450,1,['test'],['test']
Testability,"Great change. Still an error related to hail_pip_version in the tests, though. Can you make a discuss post when this goes in to alert people compiling their own builds?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5194#issuecomment-457196817:64,test,tests,64,https://hail.is,https://github.com/hail-is/hail/pull/5194#issuecomment-457196817,1,['test'],['tests']
Testability,"Great questions. The larger change here is that we're trying to decouple the Python front end from Scala/Java. Therefore, instead of calling directly into Python (e.g. getReferenceGenome), we're constructing a MatrixRead IR, which can either be passed to a service (ServiceBackend) or passed to Java as we did before (SparkBackend). I should also remark, py4j is incredibly slow, so batching calls to Python greatly improves performance in the current setup. So, for example, building an IR in Python, serializing it and parsing on Java is much faster than a series of py4j calls that builds the corresponding objects on the Java side one at a time. Some functions which used to be called from Python like importBgens are no longer used, but are still used by the Scala tests. Those got moved to TestUtils and are being phased out.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5150#issuecomment-456682522:770,test,tests,770,https://hail.is,https://github.com/hail-is/hail/pull/5150#issuecomment-456682522,2,"['Test', 'test']","['TestUtils', 'tests']"
Testability,"Great suggestion, I added an assertion and some code to the rmtree test to verify that deleting a subdirectory does not affect the sibling or avuncular directories.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11072#issuecomment-975908963:29,assert,assertion,29,https://hail.is,https://github.com/hail-is/hail/pull/11072#issuecomment-975908963,2,"['assert', 'test']","['assertion', 'test']"
Testability,Great! I think we should run the integration tests as part of `testAll` and kill the integration tests in the CI.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1827#issuecomment-302116530:45,test,tests,45,https://hail.is,https://github.com/hail-is/hail/pull/1827#issuecomment-302116530,3,['test'],"['testAll', 'tests']"
Testability,"Great! I will test it out on our cluster. First, I have question on the; Spark version that is recommended. At the very top of the *Getting Started; with Python API*, the document indicates the latest version of Spark 2; should be used. But later on under the *Running on a Spark cluster and in; the cloud section,* it indicates only Spark 1.5 and 1.6 are supported.; Which version would be the best to use? Or does it really depend on whether; it is run locally or on a cluster?. On Thu, Jan 12, 2017 at 11:21 PM, cseed <notifications@github.com> wrote:. > We now have a Getting Started the python API:; >; > https://hail.is/pyhail/getting_started.html; >; > Please give it a spin and let us know if you run into any problems. The; > documentation for the python API is nearly complete, but the Tutorial and; > General Reference section are still being ported to python and will need; > another week or so. Thanks for your patience!; >; > —; > You are receiving this because you authored the thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/hail-is/hail/issues/1218#issuecomment-272357689>, or mute; > the thread; > <https://github.com/notifications/unsubscribe-auth/AB3rDZjYATb82CmTNeP61RpKxMCFMhInks5rRvvYgaJpZM4La8Pf>; > .; >. -- ; John Farrell, Ph.D.; Biomedical Genetics-Evans 218; Boston University Medical School; 72 East Concord Street; Boston, MA. ph: 617-638-5491",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1218#issuecomment-272494749:14,test,test,14,https://hail.is,https://github.com/hail-is/hail/issues/1218#issuecomment-272494749,1,['test'],['test']
Testability,Great! I'll still test the changes by hand later if for no other reason to make sure the UI still works and I know how to use the query service.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11471#issuecomment-1058148308:18,test,test,18,https://hail.is,https://github.com/hail-is/hail/pull/11471#issuecomment-1058148308,1,['test'],['test']
Testability,Great! Looking forward to testing out PyHail.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1218#issuecomment-270732339:26,test,testing,26,https://hail.is,https://github.com/hail-is/hail/issues/1218#issuecomment-270732339,1,['test'],['testing']
Testability,"Great! So here's what the docs look like now:; https://hail.is/docs/devel/methods/genetics.html#hail.methods.nirvana. Here's the Python source:; https://github.com/hail-is/hail/blob/master/python/hail/methods/qc.py. You can see the built docs of this PR by clicking on Details next to the passing 2.2.0 test, and then clicking on Docs, e.g.:; https://ci.hail.is/viewLog.html?buildId=63354&buildTypeId=HailSourceCode_PRsOnly_HailTestJarSpark220&tab=report_project8_Docs. I'd appreciate if you could:; - ensure the docs are still accurate and add information on what version(s) of Nirvana is compatible.; - update the schema in the documentation to match your changes in Scala; - try running the same pipeline with a few block sizes to see whether its reasonable to reduce the default block size so that users will get more parallelism by default. I suspect a user with a 1 million variant VCF would prefer running 100 cores with 10k variants each to 2 cores with 500k variants each. I'd be surprised if the per-block overhead is so high to outweigh the benefit.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3266#issuecomment-379138339:303,test,test,303,https://hail.is,https://github.com/hail-is/hail/pull/3266#issuecomment-379138339,1,['test'],['test']
Testability,"Great, thank you! I've just checked out your branch and will do some manual testing this morning and let you know how that goes. I noticed that the VEP logic didn't have test coverage right now, but had a few ideas for some modest refactoring so unit tests are possible. I'll see if I can get that working!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3790#issuecomment-400314076:76,test,testing,76,https://hail.is,https://github.com/hail-is/hail/issues/3790#issuecomment-400314076,4,"['log', 'test']","['logic', 'test', 'testing', 'tests']"
Testability,"Great. So what I'm also interested in comparing is, if I just need, say, hail/pipeline/test, what's the download full tar and extract (of just hail/pipeline/test) vs download just hail/pipeline/test tar with full extract?. > There's something to be said for tar'ing everything except for .git, but I didn't carefully check which steps need it and which steps do not. I would have hoped no downstream steps need .git, but some build steps do trivially (e.g. look at the hash). Hrm.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7626#issuecomment-560458090:87,test,test,87,https://hail.is,https://github.com/hail-is/hail/pull/7626#issuecomment-560458090,3,['test'],['test']
Testability,"Greatly simplifies the `NormalizeNames` pass to be logically independent of the binding structure. This leaves the old implementation, and asserts that they agree. Will delete the old implementation in a follow up.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14514:51,log,logically,51,https://hail.is,https://github.com/hail-is/hail/pull/14514,2,"['assert', 'log']","['asserts', 'logically']"
Testability,"HAIL_TOKEN_FILE still exists in . ```sh; apiserver/test-apiserver-pod.yaml; 21: - name: HAIL_TOKEN_FILE. notebook2/notebook/notebook.py; 73: env=[kube.client.V1EnvVar(name='HAIL_TOKEN_FILE',. notebook2/notebook/kubeclient.py; 46: env=[kube.client.V1EnvVar(name='HAIL_TOKEN_FILE',. hail/python/hail/backend/backend.py; 216: os.environ.get('HAIL_TOKEN_FILE') or; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6892#issuecomment-528876155:51,test,test-apiserver-pod,51,https://hail.is,https://github.com/hail-is/hail/pull/6892#issuecomment-528876155,1,['test'],['test-apiserver-pod']
Testability,"Had this refractory Dataproc failure, that kind-of pointed to serialization errors, but which @tpoterba clearly saw wasn't due to serialization, as a test in which the HadoopFS class was explicitly serialized and deserialized succeeded. The problem appeared to be in something affecting sparkContext's ability to broadcast, as even the standard SerializableHadoopConfiguration would appear null in map-reduce operations. I therefore created a clean-slate branch from master, and have issued this here. It passes all tests, including a local reproduction of the Dataproc test, by spinning up 1 spark master, 2 workers, and passing initializing hail with master=spark-master:7077 (thanks @cseed).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6263:150,test,test,150,https://hail.is,https://github.com/hail-is/hail/pull/6263,3,['test'],"['test', 'tests']"
Testability,Hadn't tested bootstrapping since a recent PR made `NAMESPACE` required for any make steps that push images.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12044:7,test,tested,7,https://hail.is,https://github.com/hail-is/hail/pull/12044,1,['test'],['tested']
Testability,"Hail 0.1 isn't tested against or believed to work with Spark 2.2. Can you update to Hail 0.2 (devel)? 0.1 will be fully deprecated when 0.2 is released, and is already in its end of life process.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3946#issuecomment-405779642:15,test,tested,15,https://hail.is,https://github.com/hail-is/hail/issues/3946#issuecomment-405779642,1,['test'],['tested']
Testability,Hail Batch does not support logs larger than ~half a GB,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12852:28,log,logs,28,https://hail.is,https://github.com/hail-is/hail/issues/12852,1,['log'],['logs']
Testability,Hail Batch doesn't display logs that contain binary output,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12614:27,log,logs,27,https://hail.is,https://github.com/hail-is/hail/issues/12614,1,['log'],['logs']
Testability,"Hail appears to have executed the exact same write command twice. The first write driver ends at 2023-10-13T01:17:55Z and the next write driver starts at 2023-10-13T01:18:11Z, just 16 seconds later. Batch: https://batch.hail.is/batches/8058522; Just the drivers: https://batch.hail.is/batches/8058522?q=name%3Dexecute%28...%29_driver. Driver & frontend logs indicate the first driver job completed and was almost immediately followed by a resubmission of the entire pipeline. https://cloudlogging.app.goo.gl/1344nayXTgaqKhCz8. # OLD. ### What happened?. NB: This is a development build 87398e1b514e. I think my comments below might be misleading. We purposely `WriteMetadata` multiple times, but with different `MetadataWriter`s. Unfortunately, this information does not appear in the SSA IR for some reason?. ---. The ""Relevant log output"" contains the last IR printed before the code was executed. The observed error was:. <details>; <summary>Expand me for the full trace. ```; Hail version: 0.2.124-87398e1b514e; Error summary: HailException: file already exists: gs://aou_analysis/250k/data/utils/aou_mt_sample_qc_250k.ht; ```. </summary>. ```; Traceback (most recent call last):; File ""/Users/wlu/PycharmProjects/aou_gwas/scripts/pre_process_random_pheno.py"", line 345, in <module>; ); File ""/Users/wlu/PycharmProjects/aou_gwas/scripts/pre_process_random_pheno.py"", line 297, in main; mt = mt.filter_rows(mt.locus.in_autosome()); File ""<decorator-gen-1358>"", line 2, in write; File ""/usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages/hail/typecheck/check.py"", line 587, in wrapper; return __original_func(*args_, **kwargs_); File ""/usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages/hail/matrixtable.py"", line 2738, in write; Env.backend().execute(ir.MatrixWrite(self._mir, writer)); File ""/usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages/hail/backend/service_backend.py"", line 541, in execute; return self._cancel_on_ctrl_c(self._async_execute(ir, timed=time",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13809:353,log,logs,353,https://hail.is,https://github.com/hail-is/hail/issues/13809,2,['log'],"['log', 'logs']"
Testability,Hail defaults to logging to `hail.log` in the working directory of the Spark process. Apparently the user running spark doesn't have permission to create files in its working directory. You might try ; ```python; hc = hail.HailContext(log='/tmp/hail.log'); ```. Or any other file to which you have write access.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2076#issuecomment-337912555:17,log,logging,17,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-337912555,4,['log'],"['log', 'logging']"
Testability,Hail logreg doesn't converge when EPACTS does,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4933:5,log,logreg,5,https://hail.is,https://github.com/hail-is/hail/issues/4933,1,['log'],['logreg']
Testability,"Hail seems to always use the first reference genome that is used within an operation. Using this example file:; ```; contig_38	pos_38	contig_37	pos_37; chr1	10000	1	10000; ```. ---. The following code; ```; ds = hl.import_table(""test.tsv"", types={""pos_38"": hl.tint, ""pos_37"": hl.tint}); ds = ds.annotate(locus_37=hl.locus(ds.contig_37, ds.pos_37, reference_genome=""GRCh37"")); ds = ds.annotate(locus_38=hl.locus(ds.contig_38, ds.pos_38, reference_genome=""GRCh38"")); ds.show(); ```; Fails with ""HailException: Invalid locus 'chr1:10000' found. Contig 'chr1' is not in the reference genome 'GRCh37'."". ---. Reversing the order of those annotations changes the error message.; ```python; ds = hl.import_table(""test.tsv"", types={""pos_38"": hl.tint, ""pos_37"": hl.tint}); ds = ds.annotate(locus_38=hl.locus(ds.contig_38, ds.pos_38, reference_genome=""GRCh38"")); ds = ds.annotate(locus_37=hl.locus(ds.contig_37, ds.pos_37, reference_genome=""GRCh37"")); ds.show(); ```; Fails with ""HailException: Invalid locus '1:10000' found. Contig '1' is not in the reference genome 'GRCh38'."". ---. And it works with a `cache` in between the annotations.; ```python; ds = hl.import_table(""test.tsv"", types={""pos_38"": hl.tint, ""pos_37"": hl.tint}); ds = ds.annotate(locus_37=hl.locus(ds.contig_37, ds.pos_37, reference_genome=""GRCh37"")); ds = ds.cache(); ds = ds.annotate(locus_38=hl.locus(ds.contig_38, ds.pos_38, reference_genome=""GRCh38"")); ds.show(); ```. outputs; ```; +-----------+--------+-----------+--------+---------------+---------------+; | contig_38 | pos_38 | contig_37 | pos_37 | locus_37 | locus_38 |; +-----------+--------+-----------+--------+---------------+---------------+; | str | int32 | str | int32 | locus<GRCh37> | locus<GRCh38> |; +-----------+--------+-----------+--------+---------------+---------------+; | ""chr1"" | 10000 | ""1"" | 10000 | 1:10000 | chr1:10000 |; +-----------+--------+-----------+--------+---------------+---------------+; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7063:229,test,test,229,https://hail.is,https://github.com/hail-is/hail/issues/7063,3,['test'],['test']
Testability,Hail tests should better describe their failures,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1286:5,test,tests,5,https://hail.is,https://github.com/hail-is/hail/issues/1286,1,['test'],['tests']
Testability,Hail tool for printing job logs and job status,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4620:27,log,logs,27,https://hail.is,https://github.com/hail-is/hail/issues/4620,1,['log'],['logs']
Testability,"Hail's benchmarks were kind of their own thing and a little neglected.; This change moves the benchmarks into the `hail/python` folder and updates them to use pytest with a custom plugin/set of pytest hooks.; Now, benchmarks can be run from the command line like any pytest.; This change removes the `benchmark-hail` (or `hailbench`) utility. Benchmarks are marked by `pytest.mark.benchmark` (via the `@benchmark` decorator).; By convention, benchmarks are python tests whose names are prefixed by `benchmark_` and are located in files with the same prefix.; Nothing enforces this, however, so you could name your benchmarks `test_*` and put them in files named `test_*.py`.; Benchmarks may import and use any test code or utilities defined in `test/`.; The results of each benchmark are outputted as json lines (`.jsonl`) to the file specified by the `--output` pytest arg or stdout. The folder structure should be familiar, resembling our `test/` directory.; I believe this is flexible enough to add `hailtop` benchmarks should we so wish:; ```; pytest.ini - hoisted from `test/` to include benchmark marks; benchmark/; - conftest.py for custom pytest command line args ; - hail/; - confest.py for custom plugin that runs hail benchmarks; - benchmark_*.py hail query benchmark code; - tools/; - shared utilites, including the `@benchmark`; ```; Supporting pytest fixtures required writing a custom plugin to run benchmarks, as using off-the-shelf; solutions like `pytest-benchmark` would forbid method level fixtures like `tmp_path` etc.; The plugin is designed to run ""macro-benchmarks"" (ie long-running tests) and fully supports pytest parameterisation.; For each benchmark, the plugin initialises hail and then repeats (for a number of iterations defined by the pytest mark); acquiring fixtures, timing invocation and tearing-down fixtures, finally stopping hail. It is therefore unsuitable for; microbenchmarks, for which we currenly have none in python. If we add them we'd need to tweak this s",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14565:7,benchmark,benchmarks,7,https://hail.is,https://github.com/hail-is/hail/pull/14565,15,"['Benchmark', 'benchmark', 'test']","['Benchmarks', 'benchmark', 'benchmark-hail', 'benchmarks', 'test', 'tests']"
Testability,"HailContext initialization overrides any existing log4j configuration, which can lead to the logs ending up in an unexpected location. This PR adds an option to HailContext initialization to skip this configuration step. I also included two unrelated changes to this PR:; - Not bundling the transitive dependencies for `com.indeed:lsmtree-core:1.0.7`, which don't seem to be needed and can lead to classpath conflicts.; - Allowing the `quiet` option during initialization to silence the warning issued when initializing with pip-installed Hail.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8571:93,log,logs,93,https://hail.is,https://github.com/hail-is/hail/pull/8571,1,['log'],['logs']
Testability,"Half finished. SQL is probably wrong. Need to integrate the job filtering with the parameters into the api calls, write tests, integrate with batch_client. I'm sure there's more to do.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6607:120,test,tests,120,https://hail.is,https://github.com/hail-is/hail/pull/6607,1,['test'],['tests']
Testability,Hand deploy successful. Monitoring logs.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8424#issuecomment-607417090:35,log,logs,35,https://hail.is,https://github.com/hail-is/hail/pull/8424#issuecomment-607417090,1,['log'],['logs']
Testability,Happened again; [batch.log](https://github.com/hail-is/hail/files/2635158/batch.log),MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4608#issuecomment-443356287:23,log,log,23,https://hail.is,https://github.com/hail-is/hail/issues/4608#issuecomment-443356287,2,['log'],['log']
Testability,"Happy to commit this if it passes tests. Looks like you've got a rebase error, though",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5485#issuecomment-468401938:34,test,tests,34,https://hail.is,https://github.com/hail-is/hail/pull/5485#issuecomment-468401938,1,['test'],['tests']
Testability,"Happy to sit down and go through what this is about. This is current running on the cluster:. ```; $ kubectl get pods; NAME READY STATUS RESTARTS AGE; ...; spark-master-ffcfbf95c-gth5s 1/1 Running 0 4m; spark-worker-699db74c7-lsd9v 1/1 Running 0 11h; spark-worker-699db74c7-plgdd 1/1 Running 0 11h; ```. but I haven't automated deployment yet. I'm currently building the hail image from a distribution I hand built, but I'll switch over to the standard distribution once this goes in: https://github.com/hail-is/hail/pull/4554 (it fixed some bugs that showed up in this deployment). That's the `gs://hail-cseed/hail-test.zip` stuff. This was surprisingly difficult to get working. The main culprit, I think, is that Spark makes it impossible to bind and advertise different addresses for the Spark master. In the end I faked it out with:. > echo ""0.0.0.0 spark-master"" >> /etc/hosts. which works but seems a bit dubious.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4560:616,test,test,616,https://hail.is,https://github.com/hail-is/hail/pull/4560,1,['test'],['test']
Testability,Have a new test to target that will verify correct code generation. Also refactor parameterpack a bit to be more traceable. High prio because this is blocking ptypes work.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8084:11,test,test,11,https://hail.is,https://github.com/hail-is/hail/pull/8084,1,['test'],['test']
Testability,"Haven't been able to have pipeline benchmarks finish, but from the looks of things this change does not make things significantly slower or faster.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7060#issuecomment-535609382:35,benchmark,benchmarks,35,https://hail.is,https://github.com/hail-is/hail/pull/7060#issuecomment-535609382,1,['benchmark'],['benchmarks']
Testability,"Haven't stress tested it yet. But just did a quick check and yes, this is exactly what I've wanted. So so so so good. As I mentioned to @tpoterba, the ability to write this out as an object (granted, not necessarily trival) would officially close the book on the @konradjk 0.2 wishlist.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5044#issuecomment-450278433:15,test,tested,15,https://hail.is,https://github.com/hail-is/hail/pull/5044#issuecomment-450278433,1,['test'],['tested']
Testability,"Haven't tested at all yet, expect there will be things to fix.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8882:8,test,tested,8,https://hail.is,https://github.com/hail-is/hail/pull/8882,1,['test'],['tested']
Testability,"Having run through a test myself, it looks like we'll actually need to add back all the deleted config aside from the last bit that starts up the jupyter server. Aside from the last block that starts up jupyter, the rest is important logic to configure extensions and content management.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12788#issuecomment-1472586228:21,test,test,21,https://hail.is,https://github.com/hail-is/hail/pull/12788#issuecomment-1472586228,2,"['log', 'test']","['logic', 'test']"
Testability,"Heh, I separately discovered the test failure and fixed at https://github.com/hail-is/hail/pull/13477",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13470#issuecomment-1688883263:33,test,test,33,https://hail.is,https://github.com/hail-is/hail/pull/13470#issuecomment-1688883263,1,['test'],['test']
Testability,"Heh, so turns out that `test_weird_urls` is missing the `@pytest.mark.asyncio` decorator, and so it was getting skipped with a warning this whole time. The pytest upgrade added auto-detection of async tests and so it ran this broken test for the first time. I'm PR'ing to treat most warnings as errors in #12322.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11974#issuecomment-1278201498:201,test,tests,201,https://hail.is,https://github.com/hail-is/hail/pull/11974#issuecomment-1278201498,2,['test'],"['test', 'tests']"
Testability,"Heh. At least in my version of Docker, those are implicitly relative to the root not the WORKDIR:; ```; (base) dking@wm28c-761 /tmp % cat Dockerfile ; FROM ubuntu:20.04; WORKDIR /foo/bar; VOLUME baz; (base) dking@wm28c-761 /tmp % docker build -t foo . ; [+] Building 0.1s (6/6) FINISHED ; => [internal] load build definition from Dockerfile 0.0s; => => transferring dockerfile: 34B 0.0s; => [internal] load .dockerignore 0.0s; => => transferring context: 2B 0.0s; => [internal] load metadata for docker.io/library/ubuntu:20.04 0.0s; => [1/2] FROM docker.io/library/ubuntu:20.04 0.0s; => CACHED [2/2] WORKDIR /foo/bar 0.0s; => exporting to image 0.0s; => => exporting layers 0.0s; => => writing image sha256:217748640e5c53f72b8de9917010e5742fb8bef99a37dcb13ec59a903cb5834c 0.0s; => => naming to docker.io/library/foo 0.0s. Use 'docker scan' to run Snyk tests against images to find vulnerabilities and learn how to fix them; (base) dking@wm28c-761 /tmp % docker run foo /bin/sh -c 'pwd && ls -l . && ls -l / && ls -l /baz'; /foo/bar; total 0; total 56; drwxr-xr-x 2 root root 4096 May 9 15:06 baz; lrwxrwxrwx 1 root root 7 Oct 19 2022 bin -> usr/bin; drwxr-xr-x 2 root root 4096 Apr 15 2020 boot; drwxr-xr-x 5 root root 340 May 9 15:06 dev; drwxr-xr-x 1 root root 4096 May 9 15:06 etc; drwxr-xr-x 3 root root 4096 May 9 15:01 foo; drwxr-xr-x 2 root root 4096 Apr 15 2020 home; lrwxrwxrwx 1 root root 7 Oct 19 2022 lib -> usr/lib; drwxr-xr-x 2 root root 4096 Oct 19 2022 media; drwxr-xr-x 2 root root 4096 Oct 19 2022 mnt; drwxr-xr-x 2 root root 4096 Oct 19 2022 opt; dr-xr-xr-x 238 root root 0 May 9 15:06 proc; drwx------ 2 root root 4096 Oct 19 2022 root; drwxr-xr-x 5 root root 4096 Oct 19 2022 run; lrwxrwxrwx 1 root root 8 Oct 19 2022 sbin -> usr/sbin; drwxr-xr-x 2 root root 4096 Oct 19 2022 srv; dr-xr-xr-x 13 root root 0 May 9 15:06 sys; drwxrwxrwt 2 root root 4096 Oct 19 2022 tmp; drwxr-xr-x 10 root root 4096 Oct 19 2022 usr; drwxr-xr-x 11 root root 4096 Oct 19 2022 var; total 0; (base) dki",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12990#issuecomment-1540332989:852,test,tests,852,https://hail.is,https://github.com/hail-is/hail/pull/12990#issuecomment-1540332989,2,['test'],['tests']
Testability,"Heh. I checked the range test with `vcf.bgz` and it's embarrassingly slow. In terms of compressed output bytes, it's 251 KiB/s. In terms of decompressed output bytes it's 80 MiB/s. I guess this makes sense though: we can't generate data fast enough to keep up with bgzip. I seem to recall bgzip writes at ~50 MiB/s. At those compression ratios we'd need to generate data at ~15GiB/s, which we are _so_ far from doing.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12733#issuecomment-1444597452:25,test,test,25,https://hail.is,https://github.com/hail-is/hail/pull/12733#issuecomment-1444597452,1,['test'],['test']
Testability,"Heh. The fix is almost trivial, just gotta RTFM for http. Users will need to log out / clear cookies before this will take effect.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12379:77,log,log,77,https://hail.is,https://github.com/hail-is/hail/pull/12379,1,['log'],['log']
Testability,"Hello, ; It would be really great to have the following tests in Hail, as detailed on EPACTS: http://genome.sph.umich.edu/wiki/EPACTS#Single_Variant_Test. Most important for immediate analyses (with ~10K individuals WGS) are q.emmax, emmaxCMC, and mmskat, which all use mixed models (with kinship matrices or GRMs). . Furthermore, one step beyond running analysis is doing conditional analysis. Right now, in EPACTS, doing conditional analysis requires adding separate columns in the .ped file corresponding to GTs for each variant you'd like to condition on. Ideally, we'd be able to just list the variants (maybe in tab-delimited format with Chr, Pos, Ref, Alt. quantitative traits of interest: ; q.emmax ; mmskat. binary traits of interest: ; b.score (or b.wald); b.collapse ; emmaxCMC. Thanks again!",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/363:56,test,tests,56,https://hail.is,https://github.com/hail-is/hail/issues/363,1,['test'],['tests']
Testability,"Hello, when I test hail in the spark cluster, there is an error:. bash-4.2$ spark-submit --executor-memory 16g --executor-cores 4 --class org.broadinstitute.hail.driver.Main ***/hail-all-spark.jar --master yarn-client importvcf /user/hail/sample.vcf splitmulti write -o /user/hail/sample_1.vds exportvcf -o /user/hail/sample_1.vcf. Exception in thread ""main"" java.lang.UnsupportedClassVersionError: org/apache/solr/client/solrj/SolrClient : Unsupported major.minor version 52.0; at java.lang.ClassLoader.defineClass1(Native Method); at java.lang.ClassLoader.defineClass(ClassLoader.java:800); at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142); at java.net.URLClassLoader.defineClass(URLClassLoader.java:449); at java.net.URLClassLoader.access$100(URLClassLoader.java:71); at java.net.URLClassLoader$1.run(URLClassLoader.java:361); at java.net.URLClassLoader$1.run(URLClassLoader.java:355); at java.security.AccessController.doPrivileged(Native Method); at java.net.URLClassLoader.findClass(URLClassLoader.java:354); at java.lang.ClassLoader.loadClass(ClassLoader.java:425); at java.lang.ClassLoader.loadClass(ClassLoader.java:358); at org.broadinstitute.hail.driver.ToplevelCommands$.<init>(Command.scala:62); at org.broadinstitute.hail.driver.ToplevelCommands$.<clinit>(Command.scala); at org.broadinstitute.hail.driver.Main$.main(Main.scala:205); at org.broadinstitute.hail.driver.Main.main(Main.scala); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:606); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206); at org.apache.spark.deplo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/825:14,test,test,14,https://hail.is,https://github.com/hail-is/hail/issues/825,1,['test'],['test']
Testability,"Hello,when I build Hail to run locally,I encounter this problem,how can I fix it ? . [root@**\* hail]# gradle installDist; Using a seed of [1] for testing.; Build file '/**_/hail/build.gradle': line 188; useAnt has been deprecated and is scheduled to be removed in Gradle 3.0. The Ant-Based Scala compiler is deprecated, please see https://docs.gradle.org/current/userguide/scala_plugin.html.; :compileJava UP-TO-DATE; :compileScala; /**_/hail/src/main/scala/org/broadinstitute/hail/driver/ExportVCF.scala:3: object time is not a member of package java; import java.time._; ^; /***/hail/src/main/scala/org/broadinstitute/hail/driver/ExportVCF.scala:76: not found: value LocalDate; sb.append(s""##fileDate=${LocalDate.now}\n""); ^; two errors found; :compileScala FAILED. FAILURE: Build failed with an exception.; - What went wrong:; Execution failed for task ':compileScala'.; ; > Compilation failed; - Try:; Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. BUILD FAILED. Total time: 45.869 secs",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/453:147,test,testing,147,https://hail.is,https://github.com/hail-is/hail/issues/453,2,"['log', 'test']","['log', 'testing']"
Testability,Helps a little with benchmarks in whole stage codegen (which I'm working on in a different branch),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10566:20,benchmark,benchmarks,20,https://hail.is,https://github.com/hail-is/hail/pull/10566,1,['benchmark'],['benchmarks']
Testability,"Here are the alternatives that I see:. The original design:; ```scala; object LowerArrayToStream {; private def boundary(node: IR): IR = {; var streamified = streamify(node). if (streamified.typ.isInstanceOf[TStream] && node.typ.isInstanceOf[TArray]); streamified = ToArray(streamified). if (streamified.typ.isInstanceOf[TArray] && node.typ.isInstanceOf[TStream]); streamified = ToStream(streamified). assert(streamified.typ == node.typ); streamified; }. private def toStream(node: IR): IR = {; node match {; case _: ToStream => node; case _ => {; if(node.typ.isInstanceOf[TArray]); ToStream(node); else; node; }; }; }. private def streamify(node: IR): IR = {; node match {; //...; case _ =>; val newChildren = node.children.map(child => boundary(child.asInstanceOf[IR])); val x = if ((node.children, newChildren).zipped.forall(_ eq _)); node; else; node.copy(newChildren). if(x.typ.isInstanceOf[TArray]); ToStream(x); else; x; }; }. def apply(node: IR): IR = boundary(node); }; ````. the above has plenty of errors, surrounding attempts to cast PCanonicalArray to PStream. This can be fixed using TContainer instead of TArray. But as soon as you do this, you need to make sure you're never generating ToArray(ToStream(something of type TDict or TSet)), which means you need the if check in the present PR.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8063#issuecomment-586598280:402,assert,assert,402,https://hail.is,https://github.com/hail-is/hail/pull/8063#issuecomment-586598280,1,['assert'],['assert']
Testability,Here are the benchmarks: https://gist.github.com/johnc1231/3e576bf2e8a39cb73785af0faa451976. @tpoterba should be good for review.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9675#issuecomment-741826512:13,benchmark,benchmarks,13,https://hail.is,https://github.com/hail-is/hail/pull/9675#issuecomment-741826512,1,['benchmark'],['benchmarks']
Testability,"Here is a Hail log.... I will work on getting the YARN container logs next. . more /restricted/projectnb/ukbiobank/ad/analysis/ukb.v3/hail-20190122-1311-0.2.4-d602a3d7472d.log; ```; 2019-01-22 13:11:20 SparkContext: INFO: Running Spark version 2.2.1; 2019-01-22 13:11:20 NativeCodeLoader: WARN: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 2019-01-22 13:11:21 SparkContext: INFO: Submitted application: Hail; 2019-01-22 13:11:21 SparkContext: INFO: Spark configuration:; spark.app.name=Hail; spark.driver.extraClassPath=""/restricted/projectnb/genpro/github/hail/hail/build/libs/hail-all-spark.jar""; spark.driver.memory=5G; spark.executor.cores=4; spark.executor.extraClassPath=./hail-all-spark.jar; spark.executor.instances=10; spark.executor.memory=40G; spark.hadoop.io.compression.codecs=org.apache.hadoop.io.compress.DefaultCodec,is.hail.io.compress.BGzipCodec,is.hail.io.compress.BGzipCodecTbi,org.apache.hadoop.io.compress.GzipCodec; spark.hadoop.mapreduce.input.fileinputformat.split.minsize=1048576; spark.kryo.registrator=is.hail.kryo.HailKryoRegistrator; spark.logConf=true; spark.master=yarn; spark.repl.local.jars=file:/restricted/projectnb/genpro/github/hail/hail/build/libs/hail-all-spark.jar; spark.serializer=org.apache.spark.serializer.KryoSerializer; spark.submit.deployMode=client; spark.ui.showConsoleProgress=false; spark.yarn.appMasterEnv.LD_LIBRARY_PATH=/share/pkg/lz4/1.8.3/install/lib:/share/pkg/gcc/7.2.0/install/lib64:/share/pkg/gcc/7.2.0/install/lib; spark.yarn.appMasterEnv.PATH=/share/pkg/spark/2.2.1/install/bin:/share/pkg/lz4/1.8.3/install/bin:/share/pkg/gcc/7.2.0/install/bin:/usr3/bustaff/farrell/anaconda_envs/hail2/bin:/share/pkg/anaconda3/5.2.0/install/bin:/usr/java/default/jre/bin:/usr/java; /default/bin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/opt/dell/srvadmin/bin:/usr3/bustaff/farrell/bin:/usr3/bustaff/farrell/bin; spark.yarn.appMasterEnv.PYTHONPATH=/share",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587:15,log,log,15,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456534587,6,['log'],"['log', 'logs']"
Testability,Here is the problematic command:. `annotateglobal table \; -i file:///humgen/atgu1/fs03/wip/aganna/HCSCORE/genelists/all_scores.scores \; -r global.all_scores \; annotateglobal expr -c 'global.GWAS_height = global.all_scores.filter(x => x.GWAS_HEIGHT == '1').map(x => x.V1)' \; annotatevariants expr -c 'va.andrea.test = global.GWAS_height.toSet.contains(va.andrea.genename)' \`. The shell was eliding the single quote and we were comparing a String and an Int. That should be an error.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/388#issuecomment-219845067:314,test,test,314,https://hail.is,https://github.com/hail-is/hail/issues/388#issuecomment-219845067,1,['test'],['test']
Testability,"Here is what I get when invoking pyspark. $ pyspark; Python 2.7.13 (default, Jul 18 2017, 09:16:53) ; [GCC 4.2.1 Compatible Apple LLVM 8.0.0 (clang-800.0.42.1)] on darwin; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 17/08/02 13:56:47 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/08/02 13:56:47 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/Users/ih/languages/hail.is/build/libs/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/02 13:56:47 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/Users/ih/languages/hail.is/build/libs/hail-all-spark.jar' as a work-around.; 17/08/02 13:56:47 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/Users/ih/languages/hail.is/build/libs/hail-all-spark.jar' as a work-around.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 2.7.13 (default, Jul 18 2017 09:16:53); SparkSession available as 'spark'",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2062#issuecomment-319749996:341,log,log,341,https://hail.is,https://github.com/hail-is/hail/issues/2062#issuecomment-319749996,2,['log'],"['log', 'logging']"
Testability,Here's a clear instance of buffer corruption after a transient error (in this case an SSLException). https://batch.hail.is/batches/7996481/jobs/182741; ```; 2023-09-13 16:37:36.612 JVMEntryway: INFO: is.hail.JVMEntryway received arguments:; 2023-09-13 16:37:36.613 JVMEntryway: INFO: 0: /hail-jars/gs:__hail-query-ger0g_jars_be9d88a80695b04a2a9eb5826361e0897d94c042.jar.jar; 2023-09-13 16:37:36.613 JVMEntryway: INFO: 1: is.hail.backend.service.Main; 2023-09-13 16:37:36.613 JVMEntryway: INFO: 2: /batch/1c00c7157d4d41bcbf508f12d75329b1; 2023-09-13 16:37:36.613 JVMEntryway: INFO: 3: /batch/1c00c7157d4d41bcbf508f12d75329b1/log; 2023-09-13 16:37:36.613 JVMEntryway: INFO: 4: gs://hail-query-ger0g/jars/be9d88a80695b04a2a9eb5826361e0897d94c042.jar; 2023-09-13 16:37:36.613 JVMEntryway: INFO: 5: worker; 2023-09-13 16:37:36.613 JVMEntryway: INFO: 6: gs://gnomad-tmp-4day/parallelizeAndComputeWithIndex/s_yyHm37RY7YTSWH29gP5SM0RwKxgs9EXbg9_YMf7ho=; 2023-09-13 16:37:36.613 JVMEntryway: INFO: 7: 38854; 2023-09-13 16:37:36.613 JVMEntryway: INFO: 8: 47960; 2023-09-13 16:37:36.613 JVMEntryway: INFO: Yielding control to the QoB Job.; 2023-09-13 16:37:36.614 Worker$: INFO: is.hail.backend.service.Worker be9d88a80695b04a2a9eb5826361e0897d94c042; 2023-09-13 16:37:36.614 Worker$: INFO: running job 38854/47960 at root gs://gnomad-tmp-4day/parallelizeAndComputeWithIndex/s_yyHm37RY7YTSWH29gP5SM0RwKxgs9EXbg9_YMf7ho= with scratch directory '/batch/1c00c7157d4d41bcbf508f12d75329b1'; 2023-09-13 16:37:36.617 GoogleStorageFS$: INFO: Initializing google storage client from service account key; 2023-09-13 16:37:36.821 services: WARN: A limited retry error has occured. We will automatically retry 4 more times. Do not be alarmed. (next delay: 1938). The most recent error was javax.net.ssl.SSLException: Connection reset.; 2023-09-13 16:37:38.893 WorkerTimer$: INFO: readInputs took 2278.496020 ms.; 2023-09-13 16:37:38.893 : INFO: RegionPool: initialized for thread 9: pool-2-thread-1; 2023-09-13 16:37:38.903 ,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13356#issuecomment-1719508553:624,log,log,624,https://hail.is,https://github.com/hail-is/hail/issues/13356#issuecomment-1719508553,2,['log'],['log']
Testability,"Here's a diff of `hailctl dataproc start foo --dry-run` on main and on this branch. Notice that the properties and metadata arguments gain a leading and trailing single quote. This ensure that things like `sys_platform!=""win32""` are properly transmitted. In `start.py` we just use exec-style invocation, so there's no equivalent issue. ```; 7c7; < --properties=^|||^spark:spark.task.maxFailures=20|||spark:spark.driver.extraJavaOptions=-Xss4M|||spark:spark.executor.extraJavaOptions=-Xss4M|||spark:spark.speculation=true|||hdfs:dfs.replication=1|||dataproc:dataproc.logging.stackdriver.enable=false|||dataproc:dataproc.monitoring.stackdriver.enable=false|||spark:spark.driver.memory=36g|||yarn:yarn.nodemanager.resource.memory-mb=29184|||yarn:yarn.scheduler.maximum-allocation-mb=14592|||spark:spark.executor.cores=4|||spark:spark.executor.memory=5837m|||spark:spark.executor.memoryOverhead=8755m|||spark:spark.memory.storageFraction=0.2|||spark:spark.executorEnv.HAIL_WORKER_OFF_HEAP_MEMORY_PER_CORE_MB=3648 \; ---; > '--properties=^|||^spark:spark.task.maxFailures=20|||spark:spark.driver.extraJavaOptions=-Xss4M|||spark:spark.executor.extraJavaOptions=-Xss4M|||spark:spark.speculation=true|||hdfs:dfs.replication=1|||dataproc:dataproc.logging.stackdriver.enable=false|||dataproc:dataproc.monitoring.stackdriver.enable=false|||spark:spark.driver.memory=36g|||yarn:yarn.nodemanager.resource.memory-mb=29184|||yarn:yarn.scheduler.maximum-allocation-mb=14592|||spark:spark.executor.cores=4|||spark:spark.executor.memory=5837m|||spark:spark.executor.memoryOverhead=8755m|||spark:spark.memory.storageFraction=0.2|||spark:spark.executorEnv.HAIL_WORKER_OFF_HEAP_MEMORY_PER_CORE_MB=3648' \; 9c9; < --metadata=^|||^WHEEL=gs://hail-30-day/hailctl/dataproc/dking-dev/0.2.126-a51eabd65859/hail-0.2.126-py3-none-any.whl|||PKGS=aiodns==2.0.0|aiohttp==3.9.1|aiosignal==1.3.1|async-timeout==4.0.3|attrs==23.1.0|avro==1.11.3|azure-common==1.1.28|azure-core==1.29.5|azure-identity==1.15.0|azure-mgmt-core==1.4.0|azure",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14127:566,log,logging,566,https://hail.is,https://github.com/hail-is/hail/pull/14127,1,['log'],['logging']
Testability,"Here's a larger rewrite of Github readme, ready for feedback. The gitter links reflect hail and hail-dev as we want them to be, so before merging we should rename hail to hail-dev and create hail. I also think it'd be good to give a bit more context for users on what ""pre-alpha, very active dev"" does and does not mean. In particular, that Hail is usable and tested now, but liable to change in non backward-compatible ways. Thoughts on including / wording this?. We should also consider moving the Roadmap somewhere on the forum. I think the development forum is a good place for more detailed instructions on collaboration (forking, etc) and best practices.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/699#issuecomment-243136925:360,test,tested,360,https://hail.is,https://github.com/hail-is/hail/pull/699#issuecomment-243136925,2,['test'],['tested']
Testability,"Here's a link with an absolute time window: https://cloudlogging.app.goo.gl/gXAWZpZtUiV8jphXA. This is the assertion's stack trace:; ```; at scala.Predef$.assert(Predef.scala:208); at is.hail.QoBOutputStreamManager.createOutputStream(QoBAppender.scala:38); at org.apache.logging.log4j.core.appender.OutputStreamManager.getOutputStream(OutputStreamManager.java:165); at org.apache.logging.log4j.core.appender.OutputStreamManager.writeToDestination(OutputStreamManager.java:250); at org.apache.logging.log4j.core.appender.OutputStreamManager.flushBuffer(OutputStreamManager.java:283); at org.apache.logging.log4j.core.appender.OutputStreamManager.flush(OutputStreamManager.java:294); at org.apache.logging.log4j.core.appender.AbstractOutputStreamAppender.directEncodeEvent(AbstractOutputStreamAppender.java:217); at org.apache.logging.log4j.core.appender.AbstractOutputStreamAppender.tryAppend(AbstractOutputStreamAppender.java:208); at org.apache.logging.log4j.core.appender.AbstractOutputStreamAppender.append(AbstractOutputStreamAppender.java:199); at org.apache.logging.log4j.core.config.AppenderControl.tryCallAppender(AppenderControl.java:161); ```. And the line of our code that triggers the logger appender:; ```; is.hail.JVMEntryway$2.run(JVMEntryway.java:139); ```. On that line, we should have already evaluated line 97:; ```; QoBOutputStreamManager.changeFileInAllAppenders(logFile);; ```; Which updates the filename for all `QoBOutputStreamManager`s. We should be the only ones allocating `QoBOutputStreamManager` (it has no magic annotations, we don't pass its constructor anywhere). We should only allocate `QoBOutputStreamManager` in its associated object. We always put it into the map in `getInstance`. We don't synchronize the other methods though, so that could be the issue? If we have a stale version of that map?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13242#issuecomment-1703383030:107,assert,assertion,107,https://hail.is,https://github.com/hail-is/hail/issues/13242#issuecomment-1703383030,12,"['assert', 'log']","['assert', 'assertion', 'logFile', 'logger', 'logging']"
Testability,"Here's a typical interaction for a current 2.1.0 user:; ```bash; dking@wmb16-359 # gradle -Dspark.verison=2.1.0 compileScala. FAILURE: Build failed with an exception. * Where:; Build file '/Users/dking/projects/hail2/build.gradle' line: 39. * What went wrong:; A problem occurred evaluating root project 'hail'.; > Please generate a gradle.properties file first by executing ./configure. * Try:; Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. BUILD FAILED. Total time: 1.781 secs; 1 dking@wmb16-359 # ./configure; With what version of Spark will you run Hail? (default: 2.0.2); 2.1.0; dking@wmb16-359 # gradle -Dspark.version=2.1.0 compileScala. FAILURE: Build failed with an exception. * Where:; Build file '/Users/dking/projects/hail2/build.gradle' line: 42. * What went wrong:; A problem occurred evaluating root project 'hail'.; > The spark version must now be explicitly specified in the `gradle.properties`; file. Do *not* specify it with `-Dspark.version`. This version *must* match the; version of the spark installed on the machine or cluster that will execute; hail. You can override the setting in `gradle.properties` with a command line; like:. ./gradlew -PsparkVersion=2.1.1 shadowJar. The previous implicit, default spark version was 2.0.2. * Try:; Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. BUILD FAILED. Total time: 1.778 secs; dking@wmb16-359 # gradle compileScala; The Task.leftShift(Closure) method has been deprecated and is scheduled to be removed in Gradle 5.0. Please use Task.doLast(Action) instead.; at build_2mbp15794fq4sj14khxclz0wz.run(/Users/dking/projects/hail2/build.gradle:168); :compileJava UP-TO-DATE; :nativeLib; (cd libsimdpp-2.0-rc2 && cmake .); -- Configuring done; -- Generating done; -- Build files have been written to: /Users/dking/projects/hail2/src/main/c/libsimdpp-2.0-rc2; :compileScala UP-TO-DATE. BUILD SUCCESSFUL. Total ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1613#issuecomment-290201020:495,log,log,495,https://hail.is,https://github.com/hail-is/hail/pull/1613#issuecomment-290201020,1,['log'],['log']
Testability,"Here's an executable test script. ```; import timeit; import hail as hl. setup = '''; import hail as hl; '''; hl.utils.get_1kg('data/'). print(""variant QC""); vqc = timeit.timeit('''; mt = hl.read_matrix_table('data/1kg.mt'); mt = hl.variant_qc(mt); mt.write(""variant_qc.mt"", overwrite=True); ''', number=1, setup=setup); print(""filter variants for QC""); filter = timeit.timeit('''; mt = hl.read_matrix_table('variant_qc.mt'); non_autosomal = [hl.parse_locus_interval(x); for x in (hl.get_reference(""GRCh37"").mt_contigs +; hl.get_reference(""GRCh37"").x_contigs +; hl.get_reference(""GRCh37"").y_contigs)]; mt = hl.filter_intervals(mt, non_autosomal, keep=False); mt = mt.filter_rows(hl.is_snp(mt.alleles[0], mt.alleles[1])); mt = mt.filter_rows(~ hl.is_mnp(mt.alleles[0], mt.alleles[1])); mt = mt.filter_rows(~ hl.is_indel(mt.alleles[0], mt.alleles[1])); mt = mt.filter_rows(~ hl.is_complex(mt.alleles[0], mt.alleles[1])); mt = mt.filter_rows(mt.variant_qc.AF[1] >= 0.01); mt = mt.filter_rows(mt.variant_qc.AF[1] <= 0.99); mt = mt.filter_rows(mt.variant_qc.call_rate >= 0.98); mt.write(""mt.filtered"", overwrite=True); ''', number=1, setup=setup); print(""repartition""); repart = timeit.timeit('''; mt = hl.read_matrix_table('mt.filtered'); mt = mt.repartition(100); mt.write(""repartitioned.mt"", overwrite=True); ''', number=1, setup=setup); print(""extract pruned set of variants""); ldprune = timeit.timeit('''; mt = hl.read_matrix_table('repartitioned.mt'); pruned_tbl = hl.ld_prune(mt.GT, r2 = 0.2, bp_window_size = 1000000, memory_per_core = 1000); pruned_tbl.write(""pruned_tbl.ht""); ''', number=1, setup=setup); print(""write filtered matrix table""); writefilt = timeit.timeit('''; mt = hl.read_matrix_table('repartitioned.mt'); pruned_tbl = hl.read_table('pruned_tbl.ht'); mt = mt.filter_rows(hl.is_defined(pruned_tbl[mt.row_key])); mt.write('pruned.mt', overwrite=True); ''', number=1, setup=setup). print(f'''; vqc {vqc}; filter {filter}; repart {repart}; ldprune {ldprune}; writefilt {writefilt}; '''",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4506#issuecomment-451536640:21,test,test,21,https://hail.is,https://github.com/hail-is/hail/issues/4506#issuecomment-451536640,1,['test'],['test']
Testability,"Here's an implementation of a *split* SVCF-VCF courtesy of Tim P:; ```python3; import hail as hl. from constants import *. hl.init(log='/tmp/hail.log'). vds = hl.vds.read_vds(vds_path). hl.get_reference('GRCh38').add_sequence(get_fasta()). # load metadata structure from arbitrary input GVCF; metadata = hl.get_vcf_metadata(gvcf_paths[0]); metadata['format']['LEN'] = {; 'Description': 'Reference block length',; 'Number': '1',; 'Type': 'Integer',; }. # create reference VCF; rd = vds.reference_data; rd = rd.key_rows_by(locus=rd.locus, alleles=[rd.locus.sequence_context()]); rd = rd.transmute_entries(LEN=rd.END - rd.locus.position + 1); hl.export_vcf(rd, reference_svcr_vcf_path, metadata=metadata,; tabix=True). # create variant VCF; vd = vds.variant_data. # recode gvcf_info struct to top-level fields for compatibility with VCF format limitations; info_fields = list(vd.gvcf_info); mt = vd.transmute_entries(**{f'INFO_{x}': vd.gvcf_info[x] for x in info_fields}). # recode boolean info fields as integers to support VCF spec; bool_fields = [fd for fd in mt.entry if mt[fd].dtype == hl.tbool]; mt = mt.transmute_entries(**{fd: hl.int(mt[fd]) for fd in bool_fields}). def transform_number(number):; if number in {'A', 'R', 'G'}:; return f'LOCAL_{number}'; return number. for info_fd in info_fields:; info = metadata['info'][info_fd]; if info['Type'] == 'Flag':; info['Type'] = 'Integer'; info['Number'] = '1'; metadata['format'][f'INFO_{info_fd}'] = info. for d in metadata['format'].values():; d['Number'] = transform_number(d.get('Number')). hl.export_vcf(mt, variant_svcr_vcf_path, metadata=metadata,; tabix=True); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14010#issuecomment-1823581472:131,log,log,131,https://hail.is,https://github.com/hail-is/hail/issues/14010#issuecomment-1823581472,2,['log'],['log']
Testability,Here's another example batch of selecting all parameterisations of one benchmark and overriding the number of jobs and iterations to just one; https://batch.hail.is/batches/8182105,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14565#issuecomment-2145750060:71,benchmark,benchmark,71,https://hail.is,https://github.com/hail-is/hail/pull/14565#issuecomment-2145750060,1,['benchmark'],['benchmark']
Testability,"Here's my current rough list of things to be done before hail2 is as usable as hail1. It's still pretty long!. ## Necessary code work:; - Add the rest of the core methods from VDS/KT to api2 (#2591 does most for KT, order_by is the only outstanding KT method that's not moved to table there. Same needs to be done for VDS, this isn't too hard); - Add the non-core methods to `hail.methods` / `hail.genetics.methods`; - some stuff here is much harder than the rest, like `filter_alleles`; - This is mostly just labor, but some require more thought than others, like moving TDT to use hail2 expr; - Support intervals in the `index_*` methods. It's possible now to join by locus, but not using the `annotateLociTable` fast path.; - Move to Python 3 so argument order is preserved; - Test the hail2 api much more rigorously than we do now (at the very least, call each parameter branch for each method!; - Typecheck the expression language. This isn't super trivial, and making a nice system to integrate our `typecheck` module and expressions will require some thoughtful design work.; - Some more organization around the package: monkey patching with `import hail.genetics` is an idea I like, but want to think about the edge cases first. ## Documentation; - Document the `index_*` methods / joins; - Translate the _Hail Overview_ tutorial; - Make new tutorials to replace the 2 expr ones we have; - Fill in docs on api2 methods (they're not all there yet); - Fill in docs on expression language (things like __mul__ on NumericExpression haven't been documented); - Write ""integrative docs"" that provide how-tos for common types of workflows. Show the power of annotate / select / group_by/aggregate, etc. ## Longer term QoL:; - Move over tests to Python as much as possible. I looked at the linear regression suite and it can be moved entirely into Python without many problems.; - Write a type parser in Python. The nested calls into the JVM for Type._from_java make the library feel extremely sluggis",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2588#issuecomment-352190554:780,Test,Test,780,https://hail.is,https://github.com/hail-is/hail/pull/2588#issuecomment-352190554,1,['Test'],['Test']
Testability,"Here's my proposed interface (names to be changed, I'm terrible at those). ```; case class WithSource[T](value: T, source: InputSource) {; def map[U](f: T => U): WithSource[U] = {; try {; copy[U](value = f(value)); } catch {; case e: Exception => source.wrapError(e); }; }; }. abstract class InputSource {; def wrapError(e: Exception): Nothing; }. case class TextSource(line: String, file: String, position: Option[Int]) extends InputSource {; def wrapError(e: Exception): Nothing = {; val msg = e match {; case _: FatalException => e.getMessage; case _ => s""caught $e""; }; val lineToPrint =; if (line.length > 62); line.take(59) + ""...""; else; line. log.error(; s""""""; |$file${position.map(ln => "":"" + (ln + 1)).getOrElse("""")}: $msg; | offending line: $line"""""".stripMargin); fatal(; s""""""; |$file${position.map(ln => "":"" + (ln + 1)).getOrElse("""")}: $msg; | offending line: $lineToPrint"""""".stripMargin); }; }; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/462#issuecomment-233012302:651,log,log,651,https://hail.is,https://github.com/hail-is/hail/pull/462#issuecomment-233012302,1,['log'],['log']
Testability,"Here's some examples:. Original:; ```; from hail import *; hc = HailContext(min_block_size=6); test_resources = 'src/test/resources'. cov = hc.import_table(test_resources + '/regressionLinear.cov',; types={'Cov1': TDouble(), 'Cov2': TDouble()}).key_by('Sample'). phen1 = hc.import_table(test_resources + '/regressionLinear.pheno', missing='0',; types={'Pheno': TDouble()}).key_by('Sample'); phen2 = hc.import_table(test_resources + '/regressionLogisticBoolean.pheno', missing='0',; types={'isCase': TBoolean()}).key_by('Sample'). regression = (hc.import_vcf(test_resources + '/regressionLinear.vcf'); .split_multi(); .annotate_samples_table(cov, root='sa.cov'); .annotate_samples_table(phen1, root='sa.pheno.Pheno'); .annotate_samples_table(phen2, root='sa.pheno.isCase')).with_id('regression'). vds_assoc = (regression; .annotate_samples_expr('sa.culprit = gs.filter(g => v == Variant(""1"", 1, ""C"", ""T"")).map(g => g.gt).collect()[0]'); .annotate_samples_expr('sa.pheno.PhenoLMM = (1 + 0.1 * sa.cov.Cov1 * sa.cov.Cov2) * sa.culprit').with_id('vds_assoc')). vds_kinship = vds_assoc.filter_variants_expr('v.start < 4'); km = vds_kinship.rrm(False, False).with_id('km'); vds_assoc = vds_assoc.lmmreg(km, 'sa.pheno.PhenoLMM', ['sa.cov.Cov1', 'sa.cov.Cov2']); vds_assoc.export_variants('/tmp/lmmreg3.tsv', 'Variant = v, va.lmmreg.*'); ```. History output:; ```; # 2017-08-01T20:23:38.202686; # version: devel-37d32d3. hc = (HailContext(min_block_size=6)). regression = (hc; .import_vcf('src/test/resources/regressionLinear.vcf'); .split_multi(); .annotate_samples_table(hc; .import_table('src/test/resources/regressionLinear.cov', types={'Cov1': TDouble(), 'Cov2': TDouble()}); .key_by('Sample'), root='sa.cov'); .annotate_samples_table(hc; .import_table('src/test/resources/regressionLinear.pheno', types={'Pheno': TDouble()}, missing='0'); .key_by('Sample'), root='sa.pheno.Pheno'); .annotate_samples_table(hc; .import_table('src/test/resources/regressionLogisticBoolean.pheno', types={'isCase': TBoolean(",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2060#issuecomment-319533736:117,test,test,117,https://hail.is,https://github.com/hail-is/hail/pull/2060#issuecomment-319533736,1,['test'],['test']
Testability,"Here's the error:. ```; 2427:2016-12-07 16:34:33 ERROR TaskSetManager:75 - Task 257 in stage 3.0 failed 4 times; aborting job; 2435:2016-12-07 16:34:33 ERROR Hail:93 - hail: annotatesamples expr: caught exception: org.apache.spark.SparkException: Job aborted due to stage failure: Task 257 in stage 3.0 failed 4 times, most recent failure: Lost task 257.3 in stage 3.0 (TID 590, nid00026.urika.com): scala.MatchError: ArrayBuffer(3.549E-4) (of class scala.collection.mutable.ArrayBuffer); ```. Log: /mnt/lustre/gtiao/hail_logs/PCAWG.iteration_test_compare_methods.log. Here's the full pipeline:. ```; /mnt/lustre/tpoterba/bin/hail -l /mnt/lustre/gtiao/hail_logs/PCAWG.iteration_test_compare_methods.log \; 	read -i file:///mnt/lustre/gtiao/PCAWG/data/PCAWG.full_callset.chr_ALL.GQ20_AB.split.updated.WGS_1KG_tissue_annot.promoters.QCed.vds \; 	annotatesamples table -i file:///mnt/lustre/gtiao/PCAWG/germline_callset/housekeeping/Broad_callset.115k_SNP.8PC.ethnicity_inference.txt \; 	-e Sample -c 'sa.annots.Ethnicity = table.Ethnicity' \; 	annotatesamples expr -c 'sa.AF_hist = gs.filter(g => g.isCalledNonRef).map(g => va.info.AF).hist(0, 1, 100)' \; 	annotateglobal expr -c 'global.AF_hist = samples.map(s => sa.AF_hist.binFrequencies).sum()' \; 	exportsamples -c 'SAMPLE = s.id, AF_hist = sa.AF_hist, Ethnicity = sa.annots.Ethnicity, Tissue = sa.annots.tissue_type' \; 	-o file:///mnt/lustre/gtiao/PCAWG/hist_AFs_by_sample.txt \; 	filtersamples expr -c '(sa.annots.tissue_type != ""BRCA"") && (sa.annots.Ethnicity == ""EUR"")' --keep \; 	filtersamples expr --keep -c 'samples.collect().sortBy(x => runif(0.0, 1.0))[:250]' \; 	annotateglobal expr -c 'global.AF_hist.iter1 = samples.map(s => sa.AF_hist.binFrequencies).sum()' \; 	variantqc filtervariants expr -c 'va.qc.AC >= 1' --keep \; 	exportvariants -o file:///mnt/lustre/gtiao/PCAWG/hist_AFs_by_sample.iter1.promoter_variants.txt \; 	-c 'CHROM = v.contig, POS = v.start, REF = v.ref, ALT = v.alt, TARGET = va.promoter_target, AC = va.qc.AC, AC_To",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1151:494,Log,Log,494,https://hail.is,https://github.com/hail-is/hail/issues/1151,3,"['Log', 'log']","['Log', 'log']"
Testability,Here's the output of grepping for `dmk9z` in the root of the hail repo:; ```; config.mk:HAIL_TEST_GCS_BUCKET := hail-test-dmk9z. ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10807#issuecomment-905867503:117,test,test-,117,https://hail.is,https://github.com/hail-is/hail/pull/10807#issuecomment-905867503,1,['test'],['test-']
Testability,"Here's what _local_ looks like now. Note that I've already converted to a `vds` this time. ```; dking@wmb16-359 # rm -rf foo && time ../hail/build/install/hail/bin/hail read -i profile.vds ibd -o 'foo' ; hail: info: running: read -i profile.vds; [Stage 1:> (0 + 0) / 4]SLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"".; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.; [Stage 1:============================================> (3 + 1) / 4]hail: info: running: ibd -o foo; [Stage 8:=====================================================> (210 + 4) / 214]hail: info: timing:; read: 3.047s; ibd: 4m35.1s; ../hail/build/install/hail/bin/hail read -i profile.vds ibd -o 'foo' 924.50s user 16.11s system 333% cpu 4:42.04 total; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/738#issuecomment-249995538:375,log,logger,375,https://hail.is,https://github.com/hail-is/hail/pull/738#issuecomment-249995538,1,['log'],['logger']
Testability,"Hey @cseed,. I tried running it as I need a test version of the 5.5K WGS data but it fails:; `hail-spark-lf read -i MacArthur_Merck_Finns.vds head --keep 10000 write -o MacArthur_Merck_Finns.head.vds; hail: info: running: read -i MacArthur_Merck_Finns.vds; [Stage 0:======================================================>(134 + 1) / 135]hail: info: running: head --keep 10000; hail: info: running: write -o MacArthur_Merck_Finns.head.vds; hail: write: caught exception: Job aborted.`. Got the same error on both dataflow and Cray. Also, my implementation somehow fails on Cray (different error) but not on dataflow....yay!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/446#issuecomment-234642054:44,test,test,44,https://hail.is,https://github.com/hail-is/hail/pull/446#issuecomment-234642054,1,['test'],['test']
Testability,"Hey @daniel-goldstein, super keen for this fix! Anything we can do on our side to test this, or ease this PR getting merged and triggering a release?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14576#issuecomment-2177245584:82,test,test,82,https://hail.is,https://github.com/hail-is/hail/pull/14576#issuecomment-2177245584,1,['test'],['test']
Testability,"Hey @daniel-goldstein, the `ci-test` is marked as failing on GitHub, but the CI job looks like it finished in a complete state.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12889#issuecomment-1512194141:31,test,test,31,https://hail.is,https://github.com/hail-is/hail/pull/12889#issuecomment-1512194141,1,['test'],['test']
Testability,"Hey @natestockham,. I'm glad you resolved the breeze issue. I imagine you were encountering a situation where the native libraries were not extant / not where expected / not the correct architecture. Three of the newly failing tests are related to plink. The output included in `tests.zip` indicates that you're using a fairly old version of plink,; ```; PLINK v1.90b1b 64-bit (20 May 2014); ```; Our testing server uses versions of plink from 2016. It's possible these tests are over constrained and need to be relaxed. I will investigate the precision required to pass the two tests in `IBDSuite`. However, part of one failure in the `IBDSuite` and the failure in the `ImputeSexSuite` are both caused by plink failing to produce output on certain input files. I strongly suspect these are bugs in plink version `1.90b1b` because plink `1.90b3.38` (from 2016, the version used on our test server) does not err on such files. This leaves one final test: `LinearMixedRegressionSuite.genAndFitLMM`. This is the test I have been writing about above and I can confirm that this is a bug (or, perhaps, overly precise test) **on our end** that we are actively investigating. Hail is usable even though the tests do not pass (you can run `./gradlew shadowJar` to produce a working jar), but I will advise you against relying on the results of `lmmreg` until we can confirm why this test is failing.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1419#issuecomment-281861771:227,test,tests,227,https://hail.is,https://github.com/hail-is/hail/issues/1419#issuecomment-281861771,22,['test'],"['test', 'testing', 'tests']"
Testability,"Hey @poneill !. `-O`/`PYTHONOPTIMIZE` is explicitly defined as the ""turn off asserts"" option in [the docs](https://docs.python.org/3/using/cmdline.html#cmdoption-O). If you disable asserts, you'll get even more inscrutable errors. I recommend against doing that. If you see any `assert(x, y)` in the code base, please file a PR or a bug. We'll fix it. We will not replace asserts with if-raise. ---. As to the bug you've found: yes this is a bug in Hail. We incorrectly assume that if there is at least one dataset with the right version and at least one dataset with the right reference genome that there's a dataset with the right version *and* reference genome. That logic is obviously false. I'll have someone fix this in the next couple weeks. As to the root issue: the Hail annotation database doesn't have a GRCh38 version of `gnomad_pca_variant_loadings` version 2.1. This is because [gnomAD](https://gnomad.broadinstitute.org/downloads#v2-liftover) hasn't published a GRCh38 version of their 2.1 variant loadings.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12952#issuecomment-1530239230:77,assert,asserts,77,https://hail.is,https://github.com/hail-is/hail/issues/12952#issuecomment-1530239230,5,"['assert', 'log']","['assert', 'asserts', 'logic']"
Testability,"Hey @tmwong2003, we recently changed our CI setup and there's a little more work to do to test external PRs. I'll try to have someone finish this in the next couple of days. Thanks for your patience.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6262#issuecomment-500610415:90,test,test,90,https://hail.is,https://github.com/hail-is/hail/pull/6262#issuecomment-500610415,1,['test'],['test']
Testability,"Hey @tomwhite, sorry for the massive delay. There was some concern about not having instructions generic to any cluster in the docs, so I've restructured your PR a bit more to capture the generic Spark cluster instructions and then have a separate section on getting started with a Cloudera cluster. I also opted for ""Cloudera"" instead of ""CDH"" because I don't think our users will recognize the acronym. Does that seem OK to you?. I made my changes as [a PR into your branch](https://github.com/tomwhite/hail/pull/1/files). Also, don't worry about the failing integration test, that's a CI issue on our end. It should resolve it self after the next new commit to your branch.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1452#issuecomment-290546429:573,test,test,573,https://hail.is,https://github.com/hail-is/hail/pull/1452#issuecomment-290546429,1,['test'],['test']
Testability,"Hey Hail,; I've been trying to get Hail working in a HPC environment. I was hoping to get multiple users to work on hail at the same time using the same shared filesystem. My design was to use a central code and library repository where there is a $CODE_HOME/hail/ and a $CODE_HOME/miniconda/ python installation, which all users PATHs are pointing to. This worked fine for both interactive and spark-submit uses with a single user, but today when I was testing with multiple users the HailContext would fail to form intermittently on a call to hc = HailContext() with either one of two errors. Note, each user today was ssh'ed into a different node and we were all using different jupyter notebooks simultaneously. There were five of us, and everytime we would all try to start HailContext at least one of us would fail out with these errors. Most of the time all five of us would fail out. Also note that concurrent calls to python only would be fine, with from hail import * working fine. Any help at all would be wonderful, as we would really like to work collaboratively on the cluster at the same time and all be referencing the same hail and python installations so we can keep our code synchronized. The first error that we would get would be. ---------; OSError Traceback (most recent call last); <ipython-input-11-2841f1963bb0> in <module>(); ----> 1 hc_rav = HailContext(). /scratch/PI/dpwall/computeEnvironments/hail/python/hail/context.pyc in __init__(self, sc, appName, master, local, log, quiet, append, parquet_compression, min_block_size, branching_factor, tmp_dir); 45; 46 from pyspark import SparkContext; ---> 47 SparkContext._ensure_initialized(); 48; 49 self._gateway = SparkContext._gateway. /share/sw/free/spark.2.1.0/spark-2.1.0-bin-hadoop2.7/python/pyspark/context.py in _ensure_initialized(cls, instance, gateway, conf); 254 with SparkContext._lock:; 255 if not SparkContext._gateway:; --> 256 SparkContext._gateway = gateway or launch_gateway(conf); 257 SparkContext._jvm =",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1525:454,test,testing,454,https://hail.is,https://github.com/hail-is/hail/issues/1525,1,['test'],['testing']
Testability,"Hi @Sun-shan,. First, I should note that we do not currently test hail against Spark version 2.2.0, I recommend using Spark 2.1.1 or 2.0.2. Spark versions aside, the error you encountered is unrelated to Spark, as far as I know. What version of the `decorator` package is installed on your machine? `decorator` version 4.0.10 should work correctly. Unfortunately, we are still looking for a python dependency management solution. My apologies that you've run into this issue.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2076#issuecomment-336903534:61,test,test,61,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-336903534,1,['test'],['test']
Testability,"Hi @Sun-shan,. I am unsure what is wrong. I tried to replicate your environment as follows:; - I downloaded the CentOS 7.2 1511 [""everything ISO""](http://isoredirect.centos.org/centos/7/isos/x86_64/CentOS-7-x86_64-Everything-1511.iso); - On a VM, I installed CentOS using that iso; - I downloaded the Gradle ""Binary distribution"" from the [Gradle website](https://gradle.org/gradle-download/); - I downloaded a zip file of the hail repository from github; - In the hail directory, I issued `gradle installDist`, which succeeded; - In the hail directory, I issued `gradle check`, which succeeded except for the five tests that require PLINK or R. I did not see any undefined symbol errors. Unfortunately, further debugging your environment is outside of the scope of this project. The only remaining recommendation I can give is to use the (slow) reference implementations of BLAS functions. To use the reference implementations, run the following command instead of `gradle check`:. ``` bash; gradle -Dcom.github.fommil.netlib.BLAS=com.github.fommil.netlib.NativeRefBLAS check; ```. ---. The following details about the VM may be helpful if you attempt to modify your system. ```; [dking@cg-router1 hail-master]$ rpm --query centos-release; centos-release-7-2.1511.el7.centos.2.10.x86_64; ```. ```; [dking@cg-router1 hail-master]$ hostnamectl; Static hostname: cg-router1.broadinstitute.org; Icon name: computer-vm; Chassis: vm; Machine ID: 0d856e1616ee4961bfc1b76c6ec420a1; Boot ID: 1fc0d1ffc3d24218a81ea8fc5abd9776; Virtualization: kvm; Operating System: CentOS Linux 7 (Core); CPE OS Name: cpe:/o:centos:centos:7; Kernel: Linux 3.10.0-327.el7.x86_64; Architecture: x86-64; ```. The output of `yum list installed` is in [installed-packages.txt](https://github.com/broadinstitute/hail/files/422887/installed-packages.txt)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/565#issuecomment-240446097:615,test,tests,615,https://hail.is,https://github.com/hail-is/hail/issues/565#issuecomment-240446097,1,['test'],['tests']
Testability,Hi @daniel-goldstein! I'm actually running this through Amazon CodeBuild so these are logs from an actual Amazon Linux 2 Image running on an EC2 instance build... So I don't know if that makes a difference here. I see what you're saying about the `xargs -0` however wouldn't this still be a change to the installation files for Hail or is that something that's likely happening in one of the files that I'm using and just haven't found it yet?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12136#issuecomment-1255333669:86,log,logs,86,https://hail.is,https://github.com/hail-is/hail/pull/12136#issuecomment-1255333669,1,['log'],['logs']
Testability,Hi @danking! Do you know which test is failing?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10647#issuecomment-876152547:31,test,test,31,https://hail.is,https://github.com/hail-is/hail/pull/10647#issuecomment-876152547,1,['test'],['test']
Testability,"Hi @danking, I see the initial CI result failed, but I'm unable to login and see what the failure is. I signed in to google with my popgen account, and get 504 Gateway Time-out on the `auth.hail.is/oauth2callback`, I imagine because I don't have an account there.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10085#issuecomment-784542735:67,log,login,67,https://hail.is,https://github.com/hail-is/hail/pull/10085#issuecomment-784542735,1,['log'],['login']
Testability,"Hi @danking, sorry this took me a little to test. I think there's a problem with the latest changes, in my dev-deploy, it failed on the '`create_certs` and `create_accounts`, with the error:. ```; FileNotFoundError: [Errno 2] No such file or directory: '/usr/local/lib/python3.7/dist-packages/hailtop/hail_version'; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10085#issuecomment-791067814:44,test,test,44,https://hail.is,https://github.com/hail-is/hail/pull/10085#issuecomment-791067814,1,['test'],['test']
Testability,"Hi @danking, thanks for this. On the topic of asserts, there are really two interacting issues:. 1. Asserts are intended to ensure invariants, i.e. conditions that should always be true. In correct code, assertions should never raise so disabling them should have no consequences at runtime. In practice, however, they are often casually used to catch value errors, which can be expected to occur if a user-facing method receives bad/nonsensical inputs (e.g. here: https://github.com/hail-is/hail/blob/1940547d35ddddb084ad52684e36153c1e03a331/hail/python/hailtop/hailctl/dataproc/diagnose.py#L62); 2. Python's language design allows anyone calling your code to disable asserts for optimization purposes, because disabling asserts should never change the semantics of the program. Putting these two features together, you can arrive at a situation where a user thinks they're turning off asserts (which should never raise anyway) and instead stops catching value errors (whose absence can never be guaranteed). All that said, if the final answer is: ""if you invoke `-O` you deserve what's coming"", I'm happy to drop it :). Thanks for taking a look at the example. If I understand you correctly, it sounds like I passed the wrong inputs to the function, in which case it might be clearer to raise a ValueError instead of an AssertionError in the end. On a closer look, it seems like most of the instances of `assert(x, y)` are actually in scala code-- my mistake. Thanks again for looking into this.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12952#issuecomment-1531675665:46,assert,asserts,46,https://hail.is,https://github.com/hail-is/hail/issues/12952#issuecomment-1531675665,14,"['Assert', 'assert']","['AssertionError', 'Asserts', 'assert', 'assertions', 'asserts']"
Testability,"Hi @pettyalex, thank you for the detailed and thoughtful issue. Hopefully I can shed some light and address all your concerns. I think the assertion on Java 8 and 11 was an overly defensive precaution put in place some time ago, as hail uses some unsafe JVM APIs that have been deprecated for a while. But as you noted, the world goes on in Java 17 and I don't see a reason Hail shouldn't be compatible. Since most of our closest users use Hail on GCP Dataproc, we generally keep in lock-step with their platform which is unfortunately still on Java 11 so that is what we test against and officially support. Nevertheless, we should remove the restriction and add some light validation in CI against Java 17 and advertise it as unofficially supported until such a time that Dataproc moves to Java 17. Hopefully Spark 3.6 will force their hand. The release process for 0.2.129 is already underway but expect this to be resolved in 0.2.130. Thanks for your suggestions regarding bundling the JRE and the GC options, we'll definitely consider them. Regarding the `module-info.class` nonsense, my apologies. That just seems like a bug we should fix. I will create a separate tracking issue for that but I'm not yet sure where that will get prioritized. If it is more than an annoyance for you, please let us know. Regarding conda-forge, I don't think we currently have the bandwidth or demand (that we know of) to add more distribution systems. Again, this is something where hearing from the community is the best way to figure out how to direct our efforts. Hopefully this addresses your concerns. Please do follow up if I've missed anything or open more issues if you encounter new problems.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14433#issuecomment-2030358704:139,assert,assertion,139,https://hail.is,https://github.com/hail-is/hail/issues/14433#issuecomment-2030358704,2,"['assert', 'test']","['assertion', 'test']"
Testability,"Hi @williambrandler, it does seem like everyone is getting hit with this issue. We pinned Jinja2 to 3.0.3 once this broke our tests and it should be fixed now. I'm going to close this issue but if you still experience these problems on the latest release please re-open and we'll address it promptly.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11705#issuecomment-1099734097:126,test,tests,126,https://hail.is,https://github.com/hail-is/hail/issues/11705#issuecomment-1099734097,1,['test'],['tests']
Testability,"Hi Chris, would you mind taking a look when you get a chance? I believe you might know the most about the functionality these are exercising. Do the new implementations look ok? Are they benchmarking equivalent functionality?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13956#issuecomment-1787480719:187,benchmark,benchmarking,187,https://hail.is,https://github.com/hail-is/hail/pull/13956#issuecomment-1787480719,1,['benchmark'],['benchmarking']
Testability,"Hi Cotton,. I ended up having to duplicate some of the tests to make sure everything got tested (ex: apply and applyIdentity, zip and zipIdentity). This way I know there won't be undetermined status and I know both cases got tested (correct and incorrect arguments).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/98:55,test,tests,55,https://hail.is,https://github.com/hail-is/hail/pull/98,3,['test'],"['tested', 'tests']"
Testability,"Hi Jerome, this `AnnotationPathException` issue is something we've seen before. It seems to be caused sporadically by gradle's build caching, and can usually be fixed by running `gradle clean`. The tests that failed are probably the ones that require external tools available on the command line:; FisherExactSuite (requires Rscript); ImportPlinkSuite (requires plink 1.9); ExportPlinkSuite (requires plink 1.9); LoadBgenSuite (requires qctool)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/594#issuecomment-240384398:198,test,tests,198,https://hail.is,https://github.com/hail-is/hail/issues/594#issuecomment-240384398,1,['test'],['tests']
Testability,"Hi Tim,. What's the problem with this implementation? I've tested it and it works... On Wed, Sep 21, 2016 at 11:07 AM, Tim Poterba notifications@github.com; wrote:. > Laurent, I was totally wrong about being able to do this per-command --; > I'm really sorry. I thought that it would be possible to create a new; > configuration just for this command and use that, but this is only possible; > for HadoopConfigurations and not SparkContexts. Can you reopen the old; > PR? That model is our only option.; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > https://github.com/hail-is/hail/pull/826#issuecomment-248641543, or mute; > the thread; > https://github.com/notifications/unsubscribe-auth/ADVxgcPW4xK16W3DlZfdE5U6RTcVmJthks5qsUhMgaJpZM4KC1O-; > .",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/826#issuecomment-248643185:59,test,tested,59,https://hail.is,https://github.com/hail-is/hail/pull/826#issuecomment-248643185,1,['test'],['tested']
Testability,"Hi Vlad, thanks for the PR! I'm afraid there are some internal migrations we're making that are probably not clear from just looking at the codebase. Are you up to date on our `main`? We've found working with `config.mk` cumbersome because it can be stale if you switch between different instances of Batch (e.g. one deployed in azure and the other in GCP). > DOCKER_ROOT_IMAGE used to build batch workers and benchmark. I've recently updated the scripts for building the batch worker VM image to query kubernetes directly and we should probably do the same for benchmark. > HAIL_TEST_GCS_BUCKET used to build query; KUBERNETES_SERVER_URL used to build amundsen. These services are both currently deleted in our `main`. > PROJECT, ZONE, REGION are probably not need, but might make sense to add for consistency. These will fail in an Azure deployment, and while we want to move away from `config.mk` entirely, we would at least want it to contain configurations that are valid across clouds.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11371#issuecomment-1041941055:410,benchmark,benchmark,410,https://hail.is,https://github.com/hail-is/hail/pull/11371#issuecomment-1041941055,4,['benchmark'],['benchmark']
Testability,"Hi all,. Here's the error message that I get when I go to install all of my python packages (scipy/uvloop/etc). ```; cp -f build/libs/hail-all-spark.jar python/hail/backend/hail-all-spark.jar; --; 872 | amazon-ebs: rm -rf build/deploy; 873 | amazon-ebs: mkdir -p build/deploy; 874 | amazon-ebs: mkdir -p build/deploy/src; 875 | amazon-ebs: cp ../README.md build/deploy/; 876 | amazon-ebs: rsync -r \; 877 | amazon-ebs: --exclude '.eggs/' \; 878 | amazon-ebs: --exclude '.pytest_cache/' \; 879 | amazon-ebs: --exclude '__pycache__/' \; 880 | amazon-ebs: --exclude 'benchmark_hail/' \; 881 | amazon-ebs: --exclude '.mypy_cache/' \; 882 | amazon-ebs: --exclude 'docs/' \; 883 | amazon-ebs: --exclude 'dist/' \; 884 | amazon-ebs: --exclude 'test/' \; 885 | amazon-ebs: --exclude '*.log' \; 886 | amazon-ebs: python/ build/deploy/; 887 | amazon-ebs: # Clear the bdist build cache before building the wheel; 888 | amazon-ebs: cd build/deploy; rm -rf build; python3 setup.py -q sdist bdist_wheel; 889 | ==> amazon-ebs: /usr/local/lib/python3.7/site-packages/setuptools/installer.py:30: SetuptoolsDeprecationWarning: setuptools.installer is deprecated. Requirements should be satisfied by a PEP 517 installer.; 890 | ==> amazon-ebs: SetuptoolsDeprecationWarning,; 891 | ==> amazon-ebs: /usr/local/lib/python3.7/site-packages/setuptools/command/install.py:37: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.; 892 | ==> amazon-ebs: setuptools.SetuptoolsDeprecationWarning,; 893 | amazon-ebs: sed '/^pyspark/d' python/requirements.txt \| grep -v '^#' \| xargs python3 -m pip install -U; 894 | amazon-ebs: Collecting aiohttp==3.8.1; 895 | amazon-ebs: Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB); 896 | amazon-ebs: ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 68.3 MB/s eta 0:00:00; 897 | amazon-ebs: Collecting aiohttp_session<2.8,>=2.7; 898 | amazon-eb",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12136#issuecomment-1255177691:737,test,test,737,https://hail.is,https://github.com/hail-is/hail/pull/12136#issuecomment-1255177691,2,"['log', 'test']","['log', 'test']"
Testability,"Hi everyone, ; I've been trying to get Hail up and running on my laptop and our HPC cluster and I keep running into the same problem. The install goes fine, but when I run the tests it fails out on both my laptop and our cluster at the same point, here : . > 14:17:27.809; [ERROR] [system.err] hail: info: while writing:; 14:17:27.809 [ERROR] [system.err] /tmp/testExportKT.tsv; 14:17:27.810 [ERROR] [system.err] merge time: 7.677ms; 14:17:28.591 [ERROR] [system.err] hail: info: Coerced sorted dataset; 14:17:30.368 [ERROR] [system.err] .hail: info: Coerced sorted dataset; 14:17:31.306 [ERROR] [system.err] ...; 14:17:31.904 [ERROR] [system.err] ==================================================================; 14:17:31.905 [ERROR] [system.err] ERROR: test_dataset (hail.tests.ContextTests); 14:17:31.905 [ERROR] [system.err] ----------------------------------------------------------------------; 14:17:31.905 [ERROR] [system.err] Traceback (most recent call last):; 14:17:31.905 [ERROR] [system.err] File ""/scratch/PI/dpwall/computeEnvironments/hail/python/hail/tests.py"", line 181, in test_dataset; 14:17:31.906 [ERROR] [system.err] sample2.grm('gcta-grm-bin', '/tmp/sample2.grm'); 14:17:31.906 [ERROR] [system.err] File ""/scratch/PI/dpwall/computeEnvironments/hail/python/hail/dataset.py"", line 1988, in grm; 14:17:31.906 [ERROR] [system.err] self.hc._run_command(self, pargs); 14:17:31.906 [ERROR] [system.err] File ""/scratch/PI/dpwall/computeEnvironments/hail/python/hail/context.py"", line 90, in _run_command; 14:17:31.907 [ERROR] [system.err] raise_py4j_exception(e); 14:17:31.907 [ERROR] [system.err] File ""/scratch/PI/dpwall/computeEnvironments/hail/python/hail/java.py"", line 87, in raise_py4j_exception; 14:17:31.907 [ERROR] [system.err] raise FatalError(msg, e.java_exception); 14:17:31.908 [ERROR] [system.err] FatalError: NoSuchMethodError: breeze.linalg.DenseVector$.canSetD()Lbreeze/generic/UFunc$InPlaceImpl2;; 14:17:31.908 [ERROR] [system.err]; 14:17:31.908 [ERROR] [system.err",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1419:176,test,tests,176,https://hail.is,https://github.com/hail-is/hail/issues/1419,3,['test'],"['testExportKT', 'tests']"
Testability,"Hi thanks for the bug report, I'm investigating now. Unfortunately, Spark 2.1.0 is not included in our automated testing system. I will also set up automated testing of Spark 2.1.0 to prevent future regressions like this.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1419#issuecomment-281713988:113,test,testing,113,https://hail.is,https://github.com/hail-is/hail/issues/1419#issuecomment-281713988,2,['test'],['testing']
Testability,"Hi there @BioDCH, I reformatted your comment using [markdown code blocks](https://guides.github.com/features/mastering-markdown/#syntax). It looks like the unix user running `hail` does not have permission to edit `hail.log` file, this likely caused the other two errors. Please add `--log-file PATH` where `PATH` is a file path to which you have write access. For example:. ```; spark-submit --executor-memory 16g --executor-cores 4 --class org.broadinstitute.hail.driver.Main ******/hail-all-spark.jar ; --master yarn-client importvcf --log-file /user/hail/hail.log /user/hail/split_test.vcf splitmulti write -o /user/hail/split_test_1_1.vds exportvcf -o /user/hail/split_test_1_1.vcf; ```. Assuming you have write access to `/user/hail/hail.log`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/825#issuecomment-250746848:220,log,log,220,https://hail.is,https://github.com/hail-is/hail/issues/825#issuecomment-250746848,10,['log'],"['log', 'log-file']"
Testability,"Hi! . I know this is out of the blue, but we would like the ability to fetch resource_usage data from an endpoint programmatically to evaluate our job performance. I thought it might be worth suggesting this upstream to see if it's something you'd like too :). This PR:; 1. Use the internal method to fetch the dataframes for a job; 2. Transform the data frame to dictionary with `orient='split'`. And FWIW, here's how to convert it back into a dataframe:. ```python; import pandas as pd. response = {} # response from Hail Batch; dataframes = {; key: pd.DataFrame(data=values['data'], columns=values['columns']); for key, values in response.items(); }; ```. I tested this in on a dev deploy and it worked pretty well, but happy to add testing if you can direct me to a place to add it.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14328:661,test,tested,661,https://hail.is,https://github.com/hail-is/hail/pull/14328,2,['test'],"['tested', 'testing']"
Testability,"Hi!; This is an odd error message to get -- is your repository updated to the current master? There was an update to the `importannotations table` module a few weeks ago, before which the `-e` option didn't exist. . We are in the midst of a documentation reorganization, so I apologize if it's difficult to find things at the moment. From the cloned repository, all test files are at `src/test/resources/*`. . This command worked for me just now:. ```; hail importannotations table src/test/resources/variantAnnotations.alternateformat.tsv --impute -e '`Chromosome:Position:Ref:Alt`' write -o tmp.vds; ```. The `-e` argument uses an expression to specify how to construct a `Variant`, which in this case is just the column name since the type of that column is `Variant`. If we don't use the `--impute` argument, we can construct it with . ```; -e 'Variant(`Chromosome:Position:Ref:Alt`)'; ```. More info on that [here](https://github.com/broadinstitute/hail/blob/master/docs/commands/ImportAnnotations.md)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/561#issuecomment-238502640:366,test,test,366,https://hail.is,https://github.com/hail-is/hail/issues/561#issuecomment-238502640,3,['test'],['test']
Testability,"Hi, . I'm using the concordance function to compare two sets of data, and I feel the n_discordant (last column) is not correct. . For example: ; ```; chr1:930314 [""C"",""T""] {""locus"":{""contig"":""chr1"",""position"":930314},""alleles"":[""C"",""T""]} {""locus"":{""contig"":""chr1"",""position"":930314},""alleles"":[""C"",""T""]} [[0,0,0,0,0],[0,0,21,1,0],[0,0,2057,0,0],[0,0,0,91,0],[0,0,0,0,3]] 2172; chr1:946538 [""G"",""A""] {""locus"":{""contig"":""chr1"",""position"":946538},""alleles"":[""G"",""A""]} {""locus"":{""contig"":""chr1"",""position"":946538},""alleles"":[""G"",""A""]} [[0,0,0,0,0],[0,0,5,3,0],[0,0,1868,1,1],[0,0,0,279,0],[0,0,0,0,16]] 2170; chr1:946653 [""G"",""A""] {""locus"":{""contig"":""chr1"",""position"":946653},""alleles"":[""G"",""A""]} {""locus"":{""contig"":""chr1"",""position"":946653},""alleles"":[""G"",""A""]} [[0,0,0,0,0],[0,0,856,275,66],[0,0,386,74,7],[0,0,16,415,33],[0,0,0,3,42]] 1898; ```. In the first example, I thought the n_discordant should be 0 if the `concordance` field is correct, isn't it?. The code I was using: ; `global_GA_both, samples_GA_both, SNPs_GA_both = hl.concordance(mt_exome, mt_GAsP_ft)`. The Hail version:; ```Running on Apache Spark version 2.4.3; SparkUI available at http://spark-master:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.26-2dcc3d963867; LOGGING: writing to Concordance_2019_11_28_hail.log; ```. When I was using google Terra Hail 0.2.11-daed180b84d8, I didn't have this issue. The output didn't have `left_row` or `right_row`. Cheers,; Qinqin",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7632:1280,LOG,LOGGING,1280,https://hail.is,https://github.com/hail-is/hail/issues/7632,2,"['LOG', 'log']","['LOGGING', 'log']"
Testability,"Hi, @danking ; I reconfigurated the spark cluster, with the cloudera spark : version 2.2.0.cloudera1; But I can't import hail this time, How can I fix it?. The test:; ```; >>> spark.sparkContext.master; u'yarn'. bash-4.2$ pyspark; WARNING: User-defined SPARK_HOME (/opt/cloudera/parcels/SPARK2-2.2.0.cloudera1-1.cdh5.12.0.p0.142354/lib/spark2) overrides detected (/opt/cloudera/parcels/SPARK2/lib/spark2).; WARNING: Running pyspark from user-defined location.; Python 2.7.5 (default, Nov 6 2016, 00:28:07) ; [GCC 4.8.5 20150623 (Red Hat 4.8.5-11)] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.2.0.cloudera1; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; >>> spark.sparkContext.master; u'yarn'; >>> import hail; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/opt/Software/hail/python/hail/__init__.py"", line 1, in <module>; import hail.expr; File ""/opt/Software/hail/python/hail/expr.py"", line 3, in <module>; from hail.representation import Variant, AltAllele, Genotype, Locus, Interval, Struct, Call; File ""/opt/Software/hail/python/hail/representation/__init__.py"", line 1, in <module>; from hail.representation.variant import Variant, Locus, AltAllele; File ""/opt/Software/hail/python/hail/representation/variant.py"", line 2, in <module>; from hail.typecheck import *; File ""/opt/Software/hail/python/hail/typecheck/__init__.py"", line 1, in <module>; from check import *; File ""/opt/Software/hail/python/hail/typecheck/check.py"", line 1, in <module>; from decorator import decorator, getargspec; ImportError: cannot import name getargspec; >>> ; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2076#issuecomment-336722486:160,test,test,160,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-336722486,3,"['log', 'test']","['log', 'logging', 'test']"
Testability,"Hi, @danking; I follow the instruction in hail website to set the environment:; export SPARK_HOME=/opt/cloudera/parcels/SPARK2/lib/spark2;; Actually, the SPARK2 above is a soft link of the ""SPARK2-2.2.0.cloudera1-1.cdh5.12.0.p0.142354/"" in the same directory; Anyway,I will try to change it and test later",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2076#issuecomment-337627831:295,test,test,295,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-337627831,1,['test'],['test']
Testability,"Hi, I am a staff in DCH. Now, we are testing the hail software and meet some test errors .; 1. How to check the results of some commands? such as, annotatesamples. For example, if you run this command:; hail importvcf sample.vcf annotatesamples expr -c 'sa.nHet = gs.count(g.isHet)‘ exportsamples –c ‘s.id’ –o sample_tmp.tsv ; you can get the sample_tmp file including the names of genes satisfying the screen , but how to check the output as a number in the terminal, like the format shown in showglobals command?. If you run the command:; hail read -i tmp.vds imputesex -m 0.01 exportsamples –o impute_tmp.tsv -c “ID=s.id” exportvcf –o impute_tmp.vcf ; how to obtain the inbreeding coefficient from the impute_tmp file?; 1. The Structure has no filed ***. During the test, there are some similar errors in different modules. For example, if you run the command , ; hail importvcf sample.vcf filtersamples expr --keep -c 'sa.qc.callRate > 0.99' write -o output.vds exportvcf -o sample1.vcf ; hail read -i output.vds exportgenotypes -c 'SAMPLE=s,VARIANT=v,GQ=g.gq,DP=g.dp,ANNO1=va.MyAnnotations.anno1,ANNO2=va.MyAnnotations.anno2' -o file.tsv -o sample.tsv ; hail read -i output.vds exportvariants -c 'v,va.pass,va.qc.AF' -o file.tsv ; hail read -i output.vds exportsamples -c 's.id, sa.qc.rTiTv' -o file.tsv; you will get the same fatal error: ‘Struct’ has no field ‘qc’. Is it because the qc isn`t defined in “sa” struct? ; The same problems appeared in sa.pheno, global.genes, va.Myannotations and va.qc . ; hail importvcf sample.vcf annotatevariants expr -c 'va.minorCase = gs.count(sa.pheno.Pheno1 == ""Case"" && g.isHet)’ )‘ exportvcf -o fet_tmp.vcf ; hail importvcf sample.vcf annotateglobal expr -c ‘global.first10genens = global.genes[:10]‘ exportvcf -o global_tmp.vcf ; hail importvcf sample.vcf annotateglobal expr -c 'global.nCase = samples.count(sa.pheno.isCase)’ exportvcf -o global_tmp.vcf ; hail read -i output.vds exportgenotypes -c 'SAMPLE=s,VARIANT=v,GQ=g.gq,DP=g.dp,ANNO1=va.MyAnnota",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/683:37,test,testing,37,https://hail.is,https://github.com/hail-is/hail/issues/683,3,['test'],"['test', 'testing']"
Testability,"Hi, I am using hail in spark, but encounter some problem.; I followed the ""Getting Started"" to deploy hail , and build Hail from source; (https://hail.is/docs/stable/getting_started.html). I set the environmental variables as follows:; ```; export SPARK_HOME=/opt/Software/spark/spark-2.0.2-bin-hadoop2.6; export HAIL_HOME=/opt/Software/hail; export PYTHONPATH=""$PYTHONPATH:$HAIL_HOME/python:$SPARK_HOME/python:`echo $SPARK_HOME/python/lib/py4j*-src.zip`""; export SPARK_CLASSPATH=$HAIL_HOME/build/libs/hail-all-spark.jar; ```; I put the vcf file in hadoop， as follows:; ```; [hdfs@tele-1 root]$ hdfs dfs -ls /hail/test; Found 1 items; -rw-r--r-- 3 hdfs supergroup 21194 2017-08-08 18:20 /hail/test/BRCA1.raw_indel.vcf; ```; But when I excuted the command:; ```; hc.import_vcf('/hail/test/BRCA1.raw_indel.vcf').write('/hail/test/brca1.vds'); ```; there are some errors：; ```; [hdfs@tele-1 root]$ python; Python 2.7.13 |Anaconda 4.4.0 (64-bit)| (default, Dec 20 2016, 23:09:15) ; [GCC 4.4.7 20120313 (Red Hat 4.4.7-1)] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; Anaconda is brought to you by Continuum Analytics.; Please check out: http://continuum.io/thanks and https://anaconda.org; >>> import hail; >>> hc = hail.HailContext(); Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; hail: info: SparkUI: http://192.168.1.4:4041; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.1-0320a61; >>> hc.import_vcf('/hail/test/BRCA1.raw_indel.vcf').write('/hail/test/brca1.vds'); hail: warning: `/hail/test/BRCA1.raw_indel.vcf' refers to no files; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-483>"", line 2, in import_vcf; File ""/opt/Software/hail/python/hail/java.py"", line 112, in handle_py4j; 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)); h",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2076:614,test,test,614,https://hail.is,https://github.com/hail-is/hail/issues/2076,4,['test'],['test']
Testability,"Hi, I found hl.init(sc=sc) returns error since hail-0.2.92.; It can reproduce simply run as following.; Is it a bug ??; Or should I run other ways ?. - Environments I tested. ; Hail version : 0.2.92 or later.; Mac book air (M1) , spark local mode; Rocky Linux 8.5 , spark local mode; Rocky Linux 8.5 , spark yarn cluster mode. - how to reproduce; ```; import os; os.environ['PYSPARK_SUBMIT_ARGS'] = ' \; --jars \; /Users/username/miniforge3/envs/hail/lib/python3.9/site-packages/hail/backend/hail-all-spark.jar \; --conf spark.executor.extraClassPath=./hail-all-spark.jar \; --conf spark.kryo.registrator=is.hail.kryo.HailKryoRegistrator \; --conf spark.serializer=org.apache.spark.serializer.KryoSerializer \; pyspark-shell '. from pyspark import SparkContext; sc=SparkContext.getOrCreate(). import hail as hl; hl.init(sc=sc); ```. - Error logs ; ```; 22/05/11 14:31:21 WARN Utils: Your hostname, spacerider.local resolves to a loopback address: 127.0.0.1; using 172.20.10.4 instead (on interface en6); 22/05/11 14:31:21 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address; WARNING: An illegal reflective access operation has occurred; WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/username/miniforge3/envs/hail/lib/python3.9/site-packages/pyspark/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int); WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; 22/05/11 14:31:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use set",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11827:167,test,tested,167,https://hail.is,https://github.com/hail-is/hail/issues/11827,2,"['log', 'test']","['logs', 'tested']"
Testability,"Hi, I tried the following command , and configured the log path , but it still not worked, are there any suggestions?. spark-submit --executor-memory 16g --executor-cores 4 --class org.broadinstitute.hail.driver.Main ******/hail-all-spark.jar --master yarn-client importvcf --log-file /user/hail/hail.log /user/hail/split_test.vcf splitmulti write -o /user/hail/split_test_1_1.vds exportvcf -o /user/hail/split_test_1_1.vcf. ERROR:; WARNING: Running spark-class from user-defined location.; hail: info: running: importvcf /user/hail/sample.vcf; hail: info: Coerced sorted dataset; hail: info: running: splitmulti; hail: info: running: write -o /user/hail/sample_1008.vds; hail: write: caught exception: org.apache.spark.SparkException: Job aborted.; .........; at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 2.0 failed 4 times, most recent failure: Lost task 0.3 in stage 2.0 (TID 5, bio-x-3): java.io.IOException: The file being written is in an invalid state. Probably caused by an error thrown previously. Current state: COLUMN; ...........; at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)java.io.IOException: The file being written is in an invalid state. Probably caused by an error thrown previously. Current state: COLUMN. [splitmulti_1_1.txt](https://github.com/hail-is/hail/files/550095/splitmulti_1_1.txt)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1003:55,log,log,55,https://hail.is,https://github.com/hail-is/hail/issues/1003,3,['log'],"['log', 'log-file']"
Testability,"Hi, Is there a plan to merge this branch in soon? We are testing out HAIL for some of our in-house pipelines and an ability to import bgens would be really handy.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/243#issuecomment-233953902:57,test,testing,57,https://hail.is,https://github.com/hail-is/hail/pull/243#issuecomment-233953902,1,['test'],['testing']
Testability,"Hi, danking, @danking I tried two log file pathes ,all had access permission, but the error still appeared. （1）HDFS file path ：/user/hail/hail.log， have access permission; -rwxrwxrwx 3 hdfs supergroup 0 2016-10-08 10:54 /user/hail/hail.log; （2）log file：local PATH， hava access permission; -rwxrwxrwx 1 root root 48523 Oct 8 11:42 hail.log. The error message was attached as follows ; [splitmulti_1_1.txt](https://github.com/hail-is/hail/files/517467/splitmulti_1_1.txt)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/825#issuecomment-252404979:34,log,log,34,https://hail.is,https://github.com/hail-is/hail/issues/825#issuecomment-252404979,5,['log'],['log']
Testability,"Hi, danking, the result is as follows:; ```; [root@tele-1 ~]# pyspark; Python 2.7.5 (default, Nov 6 2016, 00:28:07) ; [GCC 4.8.5 20150623 (Red Hat 4.8.5-11)] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 17/08/15 08:58:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/08/15 08:58:31 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/opt/Software/hail/build/libs/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/15 08:58:31 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/15 08:58:31 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; >>> sc.textFile(""/hail/test/BRCA1.raw_indel.vcf"").count(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/pyspark/rdd.py"", line 1008, in count; return self.mapPartitions(lambda i: [sum(1 for _ in i)]).sum(); File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/pyspark/rdd.py"", line 999, in sum; return self.mapPartitions(lambda x: [sum(x)]).fold(0, operator.add); File ""/opt/Software/spark/spark-2.0.2-bin-hadoop2.6/python/pyspark/rdd.py"", line 873, in fold; vals = self.mapPartitions(func).collect(); File ""/opt/Software/",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2076#issuecomment-322349367:338,log,log,338,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-322349367,2,['log'],"['log', 'logging']"
Testability,"Hi, i've been giving hail a first go today. It looks great, thanks. I've come across a problem. The worker nodes on our cluster only have 2GB `/tmp` dir which fills up on some hail operations. Using the `-t` flag doesn't help. E.g. ```; hail --tmpdir /local read $invds splitmulti write -o $outvds; ```. Will still fill the dir `/tmp/blockmgr-<uuid>/` and crash. Is there a simple solution to this?. [hail.log.txt](https://github.com/hail-is/hail/files/511675/hail.log.txt)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/902:406,log,log,406,https://hail.is,https://github.com/hail-is/hail/issues/902,2,['log'],['log']
Testability,"Hi, not sure if this is the right avenue, but I'd also like to report a similar `orjson.JSONDecodeError: unexpected character: line 1 column 1 (char 0)` bug first reported by https://discuss.hail.is/t/hail-fails-after-installing-it-on-a-single-computer/3653. Hail installed from https://anaconda.org/sfe1ed40/hail; EDIT: the same error occurs after `pip install hail` into a fresh conda env, which produced hail `version 0.2.130-bea04d9c79b5`. Terminal output: ; ```; Python 3.10.13 | packaged by conda-forge | (main, Dec 23 2023, 15:36:39) [GCC 12.3.0] on linux; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; >>> import hail as hl; hl.init(); >>> hl.init(); SLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"".; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.; Running on Apache Spark version 3.4.1; SparkUI available at http://xxxx:xxxx; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.127-d18228b9bc5b; LOGGING: writing to xxxx.log; >>> hl.utils.range_table(10).collect(); Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-1234>"", line 2, in collect; File ""/xxxx/lib/python3.10/site-packages/hail/typecheck/check.py"", line 584, in wrapper; return __original_func(*args_, **kwargs_); File ""/xxxx/lib/python3.10/site-packages/hail/table.py"", line 2213, in collect; return Env.backend().execute(e._ir, timed=_timed); File ""/xxxx/lib/python3.10/site-packages/hail/backend/backend.py"", line 188, in execute; result, timings = self._rpc(ActionTag.EXECUTE, payload); File ""/xxxx/lib/python3.10/site-packages/hail/backend/py4j_backend.py"", line 219, in _rpc; error_json = orjson.loads(resp.content); orjson.JSONDecodeError: unexpected character: line 1 column 1 (char 0); ```. Log file:; ```; 2024-04-25 16:07:16.773 Hail: INFO: SparkUI: http://xxxx:xxxx; 2024-04-25 16:07:21.589 Hail: I",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14049#issuecomment-2077624076:791,log,logger,791,https://hail.is,https://github.com/hail-is/hail/issues/14049#issuecomment-2077624076,1,['log'],['logger']
Testability,"Hi,. I’m trying to annotate a vcf with another vcf (gnomAD annotations), and the steps I follow are:. annotation_vds = hc.import_vcf(“annotations_vcf.vcf”).split_multi(); sample_vds = hc.import_vcf(“sample_vcf.vcf”).split_multi(). annotated_vds = sample_vds.annotate_variants_vds(annotation_vds,"" va.gnomAD_Ex_AF = vds.info.gnomAD_Ex_AF[vds.aIndex-1]""). Where vds.info.gnomAD_Ex_AF is an array with as many positions as alleles. But when the annotation file (with gnomAD annotations) doesn’t have multiallelic variants, the ‘aIndex’ field doesn’t exist in the ‘va’ annotations. However, if I run ‘annotation_vds.was_split()’ it returns true. So I can’t find a way to annotate the sample vcf if the annotation vcf doesn’t have multiallelic variants and the info field does. I’ve tried the following (without success):. annotated_vds = sample_vds.annotate_variants_vds(annotation_vds,“va.test = if(! isMissing(va.aIndex)) va.info.AC[va.aIndex-1] else va.info.AC[0]”); annotated_vds = sample_vds.annotate_variants_vds(annotation_vds,“va.test = orElse(va.info.AC[va.aIndex-1],va.info.AC[0])”). Is this normal behaviour and there’s a way to annotate without knowing whether the vcf has multiallelic variants? Or is it not the expected behaviour?. The Hail version I'm using is 0.1. Thanks in advance,. Cristina.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3469:886,test,test,886,https://hail.is,https://github.com/hail-is/hail/issues/3469,2,['test'],['test']
Testability,"Hi,; When I remove plink from my path I get a bit of a different error. Can you rerun `gradle check` with the `--info` argument? It'll vomit a bunch of details, but the output from those tests should tell us what's going on.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/457#issuecomment-230192783:187,test,tests,187,https://hail.is,https://github.com/hail-is/hail/issues/457#issuecomment-230192783,1,['test'],['tests']
Testability,"Hi,; While loading a plink binary file generated by plink2, I receive the following error in my hail.log: . hail: info: running: importplink --bfile plinktest_chr21 --delimiter ' '; hail: info: Found 152249 samples in fam file.; hail: info: Found 982854 variants in bim file.; ^M[Stage 0:> (0 + 0) / 279]^M[Stage 0:> (0 + 31) / 279]hail: importplink: caught exception: org.apache.spark.SparkException: Job aborted due to stage failure: Task 18 in stage 0.0 failed 4 times, most recent failure: Lost task 18.3 in stage 0.0 (TID 60, 10.93.109.80): java.io.EOFException: Cannot seek to a negative offset; at org.apache.hadoop.fs.FSInputChecker.seek(FSInputChecker.java:399); at org.apache.hadoop.fs.FSDataInputStream.seek(FSDataInputStream.java:62); at org.apache.hadoop.fs.ChecksumFileSystem$FSDataBoundedInputStream.seek(ChecksumFileSystem.java:325); at org.apache.hadoop.fs.FSDataInputStream.seek(FSDataInputStream.java:62); at org.broadinstitute.hail.io.HadoopFSDataBinaryReader.seek(HadoopFSDataBinaryReader.scala:17); at org.broadinstitute.hail.io.plink.PlinkBlockReader.seekToFirstBlockInSplit(PlinkBlockReader.scala:34); at org.broadinstitute.hail.io.plink.PlinkBlockReader.<init>(PlinkBlockReader.scala:23); at org.broadinstitute.hail.io.plink.PlinkInputFormat.getRecordReader(PlinkInputFormat.scala:11); at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:237); at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:208); at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:101); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); at org.apache.spark.rdd.RDD.iterator(RDD.scala:270); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:306); at org.apache.spark.rdd.RDD",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/715:101,log,log,101,https://hail.is,https://github.com/hail-is/hail/issues/715,1,['log'],['log']
Testability,"Hi,; here the log, it failed again (after ~12h running).; cheers,. > > On Apr 17, 2016, at 11:03 PM, cseed <notifications@github.com <mailto:notifications@github.com>> wrote:; > > ; > > Is the attached log file correct? It is for a job that never got assigned cores on the cluster. I don't see anything about NoClassDefFoundError in it.; > > ; > > —; > > You are receiving this because you authored the thread.; > > Reply to this email directly or view it on GitHub https://github.com/broadinstitute/hail/issues/303#issuecomment-211167105",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/303#issuecomment-211658957:14,log,log,14,https://hail.is,https://github.com/hail-is/hail/issues/303#issuecomment-211658957,2,['log'],['log']
Testability,"High level and the tests look great. I'll try to take a closer look tonight, but I'm basically ready to approve once the tests pass. I thought about throwing an error on hl.agg.filter if there isn't an aggregator inside, and I think I agree with you now. At least, if you use an hl.agg.filter, etc. inside an aggregation, like hl.agg.sum(hl.agg.filter(...)), that should given error rather than doing nothing. This is important given that this was the old syntax.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4555#issuecomment-430448109:19,test,tests,19,https://hail.is,https://github.com/hail-is/hail/pull/4555#issuecomment-430448109,2,['test'],['tests']
Testability,"High level changes:; * `TableRead` and `MatrixRead` text representation change: where before the requested type could be `None`, it can now also be `DropRowUIDs`, or for `MatrixRead` `DropColUIDs` or `DropRowColUIDs`. That way in the common case of not needing the read to produce uids, we don't need to pollute the printed IR with large types.; * `hl.read_table` gets an option `_create_row_uids`, to allow for testing uids in python, and similarly for `hl.read_matrix_table`; * There are globally fixed default field names `TableReader.uidFieldName`, `MatrixReader.rowUIDFieldName`, and `MatrixReader.colUIDFieldName`. The full type of any `TableReader`/`MatrixReader` must contain these fields. If a consumer doesn't want uids, it just doesn't include them in the requested type. If it wants different field names, it must use a `TableRename`/`MatrixRename` node. This design ensures that the field pruner doesn't need any awareness of uids.; * An exception to this rule is if the written data already contains any of these special fields, in which case they are just read as usual. This ensures that a write/read in the middle of a pipeline can't change uid fields. We're making the assumption that these reserved field names are never used in user data, so if written data contains one of these fields, it must have been created by us, and so has the correct uid semantics. (Note that this was a late change, and I may have missed converting some readers to handle this case.); * The uids fields always come last in the row/col struct. Note that this requires some care when lowering MatrixTable, to make sure the row uid field comes after the entries field.; * `PartitionReader`s, on the other hand, must specify the name of their uid field. If this field is in the requested type, it will always be generated by the reader, even if the field already existed in the written data. It is now the responsibility of the consumer to choose the uid field name so as not to clobber an existing field.; ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12031:412,test,testing,412,https://hail.is,https://github.com/hail-is/hail/pull/12031,1,['test'],['testing']
Testability,"High level take-aways:. - Hail docs now have syntax highlighting (we just needed to import pygments.css).; - Search works again.; - There are now only two root HTML templates: `site/templates/base.html` and; `web_common/web_common/templates/layout.html`. I cannot unify these further; because our services and our main websites actually differ significantly.; - The search/nav bar is now present in the HTML, no JS nonsense to; asynchronously load it into place after HTML rendering.; - Site now has a `make watch` which watches for changes and automatically; re-renders the HTML.; - Site now has a few make rules that facilitate experimenting with how the docs; are displayed within the context of the current development version of site's; CSS & HTML.; - XSLT is now only used by the C++ tests. Smaller things:. - Removed bootstrap dependencies. Did we ever actually use these?; - Removed ""clipboard.js"" dependency. Also not clear from where this came.; - Removed use of the `subtitle` tag, which isn't actually an HTML tag?. Future work:. - Simplify our CSS. It's not possible to logically reason about our CSS. And it; interacts in bad ways with the latent RTD themes. I want a unified Hail visual; theme.; - Clean up the search-related JavaScript in nav-bottom.html and; search.html. These both seem too complicated to just make search work. ---. The thrust of this PR is to restructure Hail's website and documentation to; entirely rely on Jinja2 templates. Previously, we used a mix of Jinja2, XSLT,; and in-browser JavaScript DOM manipulation to piece together a web page. Now, all of Hail's non-service website derives from; `site/templates/base.html`. It is a Jinja2 template with four blocks: title,; meta_description, head, and content. It ensures that:; - Hail's CSS is loaded,; - the Hail icon is set,; - the fonts are loaded,; - the source code highlighter is loaded (prism.js, only used outside the docs); - the nav bar is present and configured.; The nav bar is somewhat complicated. ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9597:790,test,tests,790,https://hail.is,https://github.com/hail-is/hail/pull/9597,1,['test'],['tests']
Testability,Hist2d log,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5980:7,log,log,7,https://hail.is,https://github.com/hail-is/hail/pull/5980,1,['log'],['log']
Testability,"Hi，cseed @cseed , I configured the java related to the Spark cluster, as follows：. ```; scala> System.getProperty(""java.version""); res0: String = 1.8.0_91. scala> val rdd = sc.parallelize(0 to 1000, 4); rdd: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[0] at parallelize at <console>:27. scala> rdd.mapPartitions { it => Iterator(System.getProperty(""java.version"")) }.collect(); res1: Array[String] = Array(1.8.0_91, 1.8.0_91, 1.8.0_91, 1.8.0_91) ; ```. but when testing the `split multi` command， use the `split_test.vcf` in the test file hail offered:. ```; spark-submit --executor-memory 16g --executor-cores 4 --class org.broadinstitute.hail.driver.Main ******/hail-all-spark.jar ; --master yarn-client importvcf /user/hail/split_test.vcf splitmulti write -o /user/hail/split_test_1_1.vds exportvcf -o /user/hail/split_test_1_1.vcf; ```. there appeared some errors：; 1. `java.io.FileNotFoundException: hail.log (Permission denied)`; 2. `Job aborted due to stage failure: Task 0 in stage 2.0 failed 4 times, most recent failure: Lost task 0.3 in stage 2.0 (TID 5, bio-x-3): ; java.io.IOException: The file being written is in an invalid state. Probably caused by an error thrown previously. Current state: COLUMN`; 3. `The file being written is in an invalid state. Probably caused by an error thrown previously. Current state: COLUMN`. I tested several different vcf files, the errors always existed.; The whole error message was attached as follows ; [splitmulti.txt](https://github.com/hail-is/hail/files/502516/splitmulti.txt) . How can I solve it ?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/825#issuecomment-250697347:472,test,testing,472,https://hail.is,https://github.com/hail-is/hail/issues/825#issuecomment-250697347,4,"['log', 'test']","['log', 'test', 'tested', 'testing']"
Testability,"Hm, I added timestamper and merged main and the tests passed… getting retested now though",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12731#issuecomment-1513805552:48,test,tests,48,https://hail.is,https://github.com/hail-is/hail/pull/12731#issuecomment-1513805552,1,['test'],['tests']
Testability,"Hm, I guess I just don't personally see the value in one command instead of two. If the workshop is meant to teach users how to use batch, and one aspect of using batch is knowing how to log in, shouldn't they go through the motions?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13279#issuecomment-1662872608:187,log,log,187,https://hail.is,https://github.com/hail-is/hail/pull/13279#issuecomment-1662872608,1,['log'],['log']
Testability,"Hm, weird. When I try these tests out against default I get:. ```; FatalError: batch id was 2271614; HailException: Hail off-heap memory exceeded maximum threshold: limit 2.25 GiB, allocated 3.35 GiB; Report: 3.4G allocated (192.0K blocks / 3.4G chunks), regions.size = 3, 0 current java objects, thread 9: pool-1-thread-2; is.hail.utils.HailException: Hail off-heap memory exceeded maximum threshold: limit 2.25 GiB, allocated 3.35 GiB; Report: 3.4G allocated (192.0K blocks / 3.4G chunks), regions.size = 3, 0 current java objects, thread 9: pool-1-thread-2; 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:17); 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:17); 	at is.hail.utils.package$.fatal(package.scala:78); 	at is.hail.annotations.RegionPool.closeAndThrow(RegionPool.scala:58); 	at is.hail.annotations.RegionPool.incrementAllocatedBytes(RegionPool.scala:73); 	at is.hail.annotations.ChunkCache.newChunk(ChunkCache.scala:75); 	at is.hail.annotations.ChunkCache.getChunk(ChunkCache.scala:130); 	at is.hail.annotations.RegionPool.getChunk(RegionPool.scala:96); 	at is.hail.annotations.RegionMemory.allocateBigChunk(RegionMemory.scala:62); 	at is.hail.annotations.RegionMemory.allocate(RegionMemory.scala:96); 	at is.hail.annotations.Region.allocate(Region.scala:332); 	at __C35collect_distributed_array.__m61split_ToArray(Unknown Source); 	at __C35collect_distributed_array.__m54split_StreamFor(Unknown Source); 	at __C35collect_distributed_array.__m49begin_group_0(Unknown Source); 	at __C35collect_distributed_array.apply(Unknown Source); 	at __C35collect_distributed_array.apply(Unknown Source); 	at is.hail.backend.BackendUtils.$anonfun$collectDArray$2(BackendUtils.scala:31); 	at is.hail.utils.package$.using(package.scala:638); 	at is.hail.annotations.RegionPool.scopedRegion(RegionPool.scala:162); 	at is.hail.backend.BackendUtils.$anonfun$collectDArray$1(BackendUtils.scala:30); 	at is.hail.backend.service.Worker$.$anonfun$main$13(Worker.scala:142); 	at scala.ru",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11777#issuecomment-1110147573:28,test,tests,28,https://hail.is,https://github.com/hail-is/hail/pull/11777#issuecomment-1110147573,1,['test'],['tests']
Testability,"Hm:. <img width=""484"" alt=""Screen Shot 2020-01-31 at 10 17 03 AM"" src=""https://user-images.githubusercontent.com/5543229/73550580-d614aa00-4412-11ea-82b9-4dd11825cc59.png"">. (for the pushed test). specifying the type as hl.null(hl.tint32), neither did hl.null('int32') (which doesn't feel as ergonomic, but is advertised under the [Missingness section](https://hail.is/docs/0.2/overview/expressions.html#missingness)), doesn't work sadly. As a dev using Hail I miss being able to specify data types exactly. I may want to specify that data is dense, or sparse.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8008#issuecomment-580774813:190,test,test,190,https://hail.is,https://github.com/hail-is/hail/pull/8008#issuecomment-580774813,1,['test'],['test']
Testability,"Hmm, so I've been using a branch to run some 10k and 100k scale tests of /bin/true https://github.com/hail-is/hail/pull/7783 and I've found deadlocks to be rather rare?. In that PR, I only changed the known deadlocking calls to be deadlock resilient. However, deadlock errors seem to be a feature of mysql and it seems were always intended to retry them, so I think this PR (7782) is the right solution.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7782#issuecomment-568579582:64,test,tests,64,https://hail.is,https://github.com/hail-is/hail/pull/7782#issuecomment-568579582,1,['test'],['tests']
Testability,"Hmm, some issue with logs of a running job.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11652#issuecomment-1080092497:21,log,logs,21,https://hail.is,https://github.com/hail-is/hail/pull/11652#issuecomment-1080092497,1,['log'],['logs']
Testability,"Hmm, tested locally and this didn't work. Will investigate. Marking WIP.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8448#issuecomment-608331163:5,test,tested,5,https://hail.is,https://github.com/hail-is/hail/pull/8448#issuecomment-608331163,1,['test'],['tested']
Testability,"Hmm. @johnc1231, We should probably pick some time to go through all the BM functionality and verify that we have adequate tests for it all. It feels like we've had a never ending series of bugs discovered by users.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7146#issuecomment-536017411:123,test,tests,123,https://hail.is,https://github.com/hail-is/hail/pull/7146#issuecomment-536017411,1,['test'],['tests']
Testability,Hmm. I thought we made you a full fledged developer. If you log in via https://auth.hail.is/login first does it work?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8805#issuecomment-629377509:60,log,log,60,https://hail.is,https://github.com/hail-is/hail/pull/8805#issuecomment-629377509,2,['log'],"['log', 'login']"
Testability,"Hmm. I trust the code now. I test against several R SKAT runs. I'm not sure I understand how we derive that Q is generalized chi-squared distributed. We use the residual phenotypes in the calculation of Q, but those are inverse-logit transformed normal variables. The derivation for the linear case doesn't apply, as far as I can tell. I assume the residuals are Bernoulli distributed? Maybe not. I guess the phenotypes are Bernoulli but the errors aren't? I'm not sure.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12643#issuecomment-1419295599:29,test,test,29,https://hail.is,https://github.com/hail-is/hail/pull/12643#issuecomment-1419295599,2,"['log', 'test']","['logit', 'test']"
Testability,"Hmm. I'd think that Int + Float would be promoted to Double, is that not so? Maybe we've got an issue somewhere else. . I think putting that example in the expr test you added would be a great idea!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/758#issuecomment-245462802:161,test,test,161,https://hail.is,https://github.com/hail-is/hail/pull/758#issuecomment-245462802,1,['test'],['test']
Testability,"Hmm. I'm having a real hard time figuring out how the fast path has affected this new test. Checkpointing before the group by makes this pass. Removing the union/filter_partitions line makes it pass.; ```; t = hl.utils.range_table(8, n_partitions=8); t = t._filter_partitions([7]).union(t._filter_partitions([7], keep=False)); t = t.group_by(_key=t.idx).aggregate(t_value=hl.agg.collect(t.row_value)); expected = [; hl.Struct(_key=0, t_value=[hl.Struct()]),; hl.Struct(_key=1, t_value=[hl.Struct()]),; hl.Struct(_key=2, t_value=[hl.Struct()]),; hl.Struct(_key=3, t_value=[hl.Struct()]),; hl.Struct(_key=4, t_value=[hl.Struct()]),; hl.Struct(_key=5, t_value=[hl.Struct()]),; hl.Struct(_key=6, t_value=[hl.Struct()]),; hl.Struct(_key=7, t_value=[hl.Struct()]); ]; actual = t.collect(); assert actual == expected. ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11785#issuecomment-1106757367:86,test,test,86,https://hail.is,https://github.com/hail-is/hail/pull/11785#issuecomment-1106757367,2,"['assert', 'test']","['assert', 'test']"
Testability,Hmm. I'm perhaps a bit too clever with my image tests. They differ between linux and OS X and its not easy to see the difference given the way our CI works.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12768#issuecomment-1478610969:48,test,tests,48,https://hail.is,https://github.com/hail-is/hail/pull/12768#issuecomment-1478610969,1,['test'],['tests']
Testability,Hmm. I’ll have to sort this out tomorrow. Not sure what’s going on with that. It seems like the shadowTestJar target is probably not correctly pulling in the testImolemebtation configuration.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13551#issuecomment-1709453126:158,test,testImolemebtation,158,https://hail.is,https://github.com/hail-is/hail/pull/13551#issuecomment-1709453126,1,['test'],['testImolemebtation']
Testability,"Hmm. One of the test PR builds appears to have taken 6 minutes to run. These [don't really do anything](https://github.com/hail-is/hail/blob/master/ci/test-repo/hail-ci-build.sh), so it's likely the k8s nodes were overloaded and it couldn't start the job for a while. `kubectl describe pod job-29-z5mpw` (based on the job number in the logs, I'm pretty sure this is the pod in question), doesn't show any useful information.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4474#issuecomment-425942111:16,test,test,16,https://hail.is,https://github.com/hail-is/hail/pull/4474#issuecomment-425942111,3,"['log', 'test']","['logs', 'test', 'test-repo']"
Testability,"Hmm. Seems like the ArraySorter still isn't quite right?. I also saw some issues with sockets timing out but I don't know what to make of those yet.; ```; _______________________________ test_union_rows1 _______________________________. @test_timeout(local=3 * 60); def test_union_rows1():; vds = hl.vds.read_vds(os.path.join(resource('vds'), '1kg_chr22_5_samples.vds')); ; vds1 = hl.vds.filter_intervals(vds,; [hl.parse_locus_interval('chr22:start-10754094', reference_genome='GRCh38')],; split_reference_blocks=True); vds2 = hl.vds.filter_intervals(vds,; [hl.parse_locus_interval('chr22:10754094-end', reference_genome='GRCh38')],; split_reference_blocks=True); ; ; vds_union = vds1.union_rows(vds2); > assert hl.vds.to_dense_mt(vds)._same(hl.vds.to_dense_mt(vds_union)). test/hail/vds/test_vds.py:597: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ; <decorator-gen-1386>:2: in _same; ???; /usr/local/lib/python3.9/dist-packages/hail/typecheck/check.py:587: in wrapper; return __original_func(*args_, **kwargs_); /usr/local/lib/python3.9/dist-packages/hail/matrixtable.py:3762: in _same; return self._localize_entries(entries_name, cols_name)._same(; <decorator-gen-1276>:2: in _same; ???; /usr/local/lib/python3.9/dist-packages/hail/typecheck/check.py:587: in wrapper; return __original_func(*args_, **kwargs_); /usr/local/lib/python3.9/dist-packages/hail/table.py:3658: in _same; mismatched_globals, mismatched_rows = t.aggregate(hl.tuple((; <decorator-gen-1216>:2: in aggregate; ???; /usr/local/lib/python3.9/dist-packages/hail/typecheck/check.py:587: in wrapper; return __original_func(*args_, **kwargs_); /usr/local/lib/python3.9/dist-packages/hail/table.py:1285: in aggregate; return Env.backend().execute(hl.ir.MakeTuple([agg_ir]))[0]; /usr/local/lib/python3.9/dist-packages/hail/backend/py4j_backend.py:86: in execute; raise e.maybe_user_error(ir) from None; /usr/local/lib/python3.9/dist-packages/hail/backend/py4j_backend.py:76: in execute; result_tuple",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198:705,assert,assert,705,https://hail.is,https://github.com/hail-is/hail/pull/13814#issuecomment-1771905198,2,"['assert', 'test']","['assert', 'test']"
Testability,Hmm. Those two tests still fail. They don't fail on my laptop when I run them in isolation.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12423#issuecomment-1314243953:15,test,tests,15,https://hail.is,https://github.com/hail-is/hail/pull/12423#issuecomment-1314243953,1,['test'],['tests']
Testability,"Hope you don't mind, I fixed a bug (rename conflict) and merged in the last two stages. Final tests running now.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2386#issuecomment-342701706:94,test,tests,94,https://hail.is,https://github.com/hail-is/hail/pull/2386#issuecomment-342701706,1,['test'],['tests']
Testability,Horrible diff but it's mainly just a de-indentation of the `insert_jobs_into_db` function and lifting the try/except block to the callsite of the transaction. By handling that error externally to the transaction we don't stifle errors that would be caught by the `@transaction` retry logic.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14370:284,log,logic,284,https://hail.is,https://github.com/hail-is/hail/pull/14370,1,['log'],['logic']
Testability,"How are you running the tests? We have the following in `hail/testng.xml`:. ```; <suite name=""SuiteAll"" verbose=""1"">; <test name=""TestAll""> ; <packages> ; <package name=""is.hail.*"">; <exclude name=""is.hail.scheduler""></exclude>; <exclude name=""is.hail.backend.distributed""></exclude>; 	 </package>; </packages>; </test>; </suite>; ```. These tests are explicitly executed by `scheduler/testng.xml`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6734#issuecomment-514880263:24,test,tests,24,https://hail.is,https://github.com/hail-is/hail/pull/6734#issuecomment-514880263,7,"['Test', 'test']","['TestAll', 'test', 'testng', 'tests']"
Testability,How do I test this? I don't know how to make vep fail.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8150#issuecomment-590993084:9,test,test,9,https://hail.is,https://github.com/hail-is/hail/pull/8150#issuecomment-590993084,1,['test'],['test']
Testability,"How do we want to handle the case where one of the tasks does not have timing information?. ```; log.warning(f'job {self.id} has pod {pod.metadata.name} which is '; f'terminated but has no timing information. {pod}'); ```. I think it should be None for all tasks, which is not the behavior I have now.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6129#issuecomment-493776631:97,log,log,97,https://hail.is,https://github.com/hail-is/hail/pull/6129#issuecomment-493776631,1,['log'],['log']
Testability,How does this prevent logging in to the workers?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7978#issuecomment-578955557:22,log,logging,22,https://hail.is,https://github.com/hail-is/hail/pull/7978#issuecomment-578955557,1,['log'],['logging']
Testability,"However, somehow the job did transition to `Running` even though there's no log of it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6617#issuecomment-510673350:76,log,log,76,https://hail.is,https://github.com/hail-is/hail/issues/6617#issuecomment-510673350,1,['log'],['log']
Testability,"Hrm. ci-test is ""Pending"" but it should actually say ""Success"" (click through to the status page). Who would like to grant the final approval to the glorious future of Hail?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11194#issuecomment-1035106987:8,test,test,8,https://hail.is,https://github.com/hail-is/hail/pull/11194#issuecomment-1035106987,1,['test'],['test']
Testability,"Huh! I seem to have reliably broken unicode ordering and/or en/de-coding. I've marked as fails for now. Hopefully all the remaining tests will now pass.; ```; _________________________ Tests.test_unicode_ordering __________________________; [gw1] linux -- Python 3.7.12 /usr/bin/python3. self = <test.hail.table.test_table.Tests testMethod=test_unicode_ordering>. def test_unicode_ordering(self):; a = hl.literal([""é"", ""e""]); ht = hl.utils.range_table(1, 1); ht = ht.annotate(fd=hl.sorted(a)); > assert ht.fd.collect()[0] == [""e"", ""é""]; E AssertionError: assert ['?', 'e'] == ['e', 'é']; E At index 0 diff: '?' != 'e'; E Full diff:; E - ['e', 'é']; E + ['?', 'e']. ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11194#issuecomment-1034968369:132,test,tests,132,https://hail.is,https://github.com/hail-is/hail/pull/11194#issuecomment-1034968369,8,"['Assert', 'Test', 'assert', 'test']","['AssertionError', 'Tests', 'assert', 'test', 'testMethod', 'tests']"
Testability,"Huh, quite confused as to why the local backend test hung in GCP and not azure. As far as I can tell the test that hung is `test/hail/utils/test_utils.py::Tests::test_hadoop_ls_glob_2` but it passed in azure and locally. Any ideas?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12731#issuecomment-1507043318:48,test,test,48,https://hail.is,https://github.com/hail-is/hail/pull/12731#issuecomment-1507043318,4,"['Test', 'test']","['Tests', 'test']"
Testability,"Huh, you can't request changes on your own PR. So, right now the hail/apiserver dependency is cyclic. I'll need to fix that to get testing and deploying working right.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5624#issuecomment-473961308:131,test,testing,131,https://hail.is,https://github.com/hail-is/hail/pull/5624#issuecomment-473961308,1,['test'],['testing']
Testability,"Huh. Theories on what happened to shuffles?. > On May 16, 2023, at 17:39, Christopher Vittal ***@***.***> wrote:; > ; > ; > 1 is main, 2 is this branch; > ; > $ python -m benchmark_hail compare 2023-05-16-0.2.116-a2b070f715d8-zstd-main-cmp.json 2023-05-16-0.2.116-78a43d968e7b-zstd.json; > Failed benchmarks in run 1:; > pc_relate; > king; > Failed benchmarks in run 2:; > king; > Benchmark Name Ratio Time 1 Time 2 Mem Ratio Mem 1 (MB) Mem 2 (MB); > -------------- ----- ------ ------ --------- ---------- ----------; > table_foreign_key_join_same_cardinality 302.7% 13.710 41.502 100.0% 3 3; > table_foreign_key_join_left_higher_cardinality 280.9% 13.990 39.294 100.0% 3 3; > table_key_by_shuffle 250.0% 5.910 14.778 100.0% 2 2; > shuffle_order_by_10m_int 235.5% 61.407 144.602 100.0% 2 2; > shuffle_key_by_aggregate_bad_locality 195.9% 67.872 132.991 100.0% 2 2; > table_take 155.3% 1.018 1.581 100.0% 1 1; > shuffle_key_rows_by_4096_byte_rows 151.9% 10.150 15.412 100.0% 2 2; > read_force_count_p1000 142.0% 3.998 5.678 100.0% 1 1; > read_force_count_p10 140.8% 1.803 2.539 100.0% 1 1; > join_p100_p100 138.4% 3.702 5.123 100.0% 1 1; > join_p100_p10 134.2% 13.166 17.671 100.0% 1 1; > test_inner_join_region_memory 129.9% 2.362 3.069 100.0% 382 382; > large_range_matrix_table_sum 129.1% 206.853 266.961 100.0% 17 17; > table_annotate_many_flat 125.9% 1.134 1.428 100.0% 1 1; > test_map_filter_region_memory 121.7% 2.176 2.647 100.0% 382 382; > import_vcf_count_rows 121.5% 7.532 9.150 100.0% 1 1; > join_p10_p100 121.1% 14.040 17.000 100.0% 1 1; > shuffle_key_rows_by_mt 119.1% 33.339 39.722 100.0% 3 3; > table_aggregate_downsample_worst_case 118.3% 21.323 25.229 100.0% 1 1; > variant_and_sample_qc_nested_with_filters_2 118.2% 25.267 29.873 100.0% 1 1; > union_p1000_p1000 118.0% 8.160 9.625 100.0% 1 1; > read_force_count_p100 117.9% 2.336 2.754 100.0% 1 1; > mt_group_by_memory_usage 117.5% 25.597 30.069 100.0% 136 136; > matrix_table_filter_entries_unfilter 116.9% 10.308 12.052 100.0% 1 1",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12981#issuecomment-1550513642:297,benchmark,benchmarks,297,https://hail.is,https://github.com/hail-is/hail/pull/12981#issuecomment-1550513642,3,"['Benchmark', 'benchmark']","['Benchmark', 'benchmarks']"
Testability,I *think* I've addressed all concerns. It would help if @danking could test all functions; I only have a partially configured environment.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4994#issuecomment-448388700:71,test,test,71,https://hail.is,https://github.com/hail-is/hail/pull/4994#issuecomment-448388700,1,['test'],['test']
Testability,"I accidentally got the dimensions wrong in one of the `matmulShape` cases, causing this issue: #7982. This didn't come out in testing because in my 2 dimensional by 1 dimensional ndarray test, I used a square 2 dimensional array, so the shape was the same on either side. This PR adds another test and makes the fix.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7986:126,test,testing,126,https://hail.is,https://github.com/hail-is/hail/pull/7986,3,['test'],"['test', 'testing']"
Testability,"I accidentally passed a list instead of a string as the hb.Batch name and got this error; ```; Traceback (most recent call last):; File ""outrider_batch_pipeline.py"", line 216, in <module>; main(); File ""outrider_batch_pipeline.py"", line 212, in main; logger.info(f""Output: {output_file}""); File ""/usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/contextlib.py"", line 119, in __exit__; next(self.gen); File ""/Users/weisburd/code/methods/batch/batch_utils.py"", line 66, in run_batch; batch.run(dry_run=args.dry_run, verbose=args.verbose); File ""/usr/local/lib/python3.7/site-packages/hailtop/batch/batch.py"", line 423, in run; return self._backend._run(self, dry_run, verbose, delete_scratch_on_exit, **backend_kwargs); File ""/usr/local/lib/python3.7/site-packages/hailtop/batch/backend.py"", line 435, in _run; bc_batch = bc_batch.submit(disable_progress_bar=disable_progress_bar); File ""/usr/local/lib/python3.7/site-packages/hailtop/batch_client/client.py"", line 167, in submit; async_batch = async_to_blocking(self._async_builder.submit(*args, **kwargs)); File ""/usr/local/lib/python3.7/site-packages/hailtop/batch_client/client.py"", line 7, in async_to_blocking; return asyncio.get_event_loop().run_until_complete(coro); File ""/usr/local/lib/python3.7/site-packages/nest_asyncio.py"", line 63, in run_until_complete; return self._run_until_complete_orig(future); File ""/usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/asyncio/base_events.py"", line 587, in run_until_complete; return future.result(); File ""/usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/asyncio/futures.py"", line 181, in result; raise self._exception; File ""/usr/local/Cellar/python/3.7.7/Frameworks/Python.framework/Versions/3.7/lib/python3.7/asyncio/tasks.py"", line 249, in __step; result = coro.send(None); File ""/usr/local/lib/python3.7/site-packages/hailtop/batch_client/aioclient.py"", line 492, in submit; batch = aw",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9050:251,log,logger,251,https://hail.is,https://github.com/hail-is/hail/issues/9050,1,['log'],['logger']
Testability,I added a BGEN cluster test to this PR.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5676#issuecomment-475758539:23,test,test,23,https://hail.is,https://github.com/hail-is/hail/pull/5676#issuecomment-475758539,1,['test'],['test']
Testability,"I added a Scala test like we discussed, but it's not as thorough as I want it to be. `totalAllocatedBytes` checking just checks that we cleaned up all the intermediate garbage before returning. It doesn't ensure that we never used more than a certain amount of memory.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10233#issuecomment-811969275:16,test,test,16,https://hail.is,https://github.com/hail-is/hail/pull/10233#issuecomment-811969275,1,['test'],['test']
Testability,"I added a `PropertySuite` and deleted the `check` business. I feel this is an improvement, but also that we can do better. You can still have an orphaned `Prop` by writing:. ```; class MyProperties extends PropertySuite {; forAll ... // no property(""name"") = ...; }; ```. I think better would be for `PropretySuite` to declare `forAll` and make `forAll` take a name. `PropertySuite` extends `SparkSuite`. I was seeing some strange behavior that I don't fully understand if I made it extend `TestNGSuite` and then mixed `PropertySuite` and `SparkSuite` in a test suite. Thoughts?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/732:491,Test,TestNGSuite,491,https://hail.is,https://github.com/hail-is/hail/pull/732,2,"['Test', 'test']","['TestNGSuite', 'test']"
Testability,I added a basic test.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7306#issuecomment-543238818:16,test,test,16,https://hail.is,https://github.com/hail-is/hail/pull/7306#issuecomment-543238818,1,['test'],['test']
Testability,I added a cloudtools version pin in the cluster tests.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5756#issuecomment-480369608:48,test,tests,48,https://hail.is,https://github.com/hail-is/hail/pull/5756#issuecomment-480369608,1,['test'],['tests']
Testability,I added a front-end batch test. I think we should delete the test I added in this PR in favor of the one in #8961 once we know it's working. This PR as it stands passed the tests.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8960#issuecomment-644225287:26,test,test,26,https://hail.is,https://github.com/hail-is/hail/pull/8960#issuecomment-644225287,3,['test'],"['test', 'tests']"
Testability,"I added a new field to the global config that is gs:// + hail_test_gcs_bucket named test_blob_storage_uri and use that wherever it doesn't matter that the backend be google storage, which is essentially everywhere except for the FS/copy tests, where we specifically want a test gcs bucket.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10960:237,test,tests,237,https://hail.is,https://github.com/hail-is/hail/pull/10960,2,['test'],"['test', 'tests']"
Testability,I added a separate stress test of the aggregator state.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6942#issuecomment-525946036:26,test,test,26,https://hail.is,https://github.com/hail-is/hail/pull/6942#issuecomment-525946036,1,['test'],['test']
Testability,I added a test for always run job private cancellation.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13372#issuecomment-1673767815:10,test,test,10,https://hail.is,https://github.com/hail-is/hail/pull/13372#issuecomment-1673767815,1,['test'],['test']
Testability,"I added a test in StagedRegionValue suite, with the rest of the SRVB tests. It only generates structs, but since all of the deepCopy methods will call into each other and will get tested on the struct fields, I cranked the test up to run 1000 times to ensure we were (probably) hitting all the edge cases.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6500#issuecomment-506790438:10,test,test,10,https://hail.is,https://github.com/hail-is/hail/pull/6500#issuecomment-506790438,4,['test'],"['test', 'tested', 'tests']"
Testability,"I added a test to demonstrate the problem. The `InsertFields` is overwriting the type of a field that is not part of the requested type. Previously we would just not insert anything and leave the rebuilt child alone. But when the child is a `Ref` or a `Literal` or something that doesn't actually get rebuilt differently, the old way would lead to a situation where the rebuilt IR is not a supertype of the original IR. By inserting a `SelectFields` to subset away the fields that would have been overwritten, we avoid this problem. . Happy to further elaborate if the above isn't clear.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9633:10,test,test,10,https://hail.is,https://github.com/hail-is/hail/pull/9633,1,['test'],['test']
Testability,"I added a tiny 0.1 VDS formed from regressionLinear.vcf, forcing 2 partitions, and a test in VSMSuite. Back to you.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2173#issuecomment-327335081:85,test,test,85,https://hail.is,https://github.com/hail-is/hail/pull/2173#issuecomment-327335081,1,['test'],['test']
Testability,I added an separate test of correctness of toKeyGsWeightRdd since this function is used in both the Hail and R routes in the end-to-end comparison,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2248#issuecomment-332873098:20,test,test,20,https://hail.is,https://github.com/hail-is/hail/pull/2248#issuecomment-332873098,1,['test'],['test']
Testability,"I added some more logic since the criteria (at the IR level) of ""this works as an interval join"" is different if you're joining to a Table vs joining to a MatrixTable. I also feel like the interval logic MatrixAnnotateRowsTable IR node should get pulled out into its own separate node (and be the same as a table interval join?), but I will follow up with that later and not here.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4197#issuecomment-416761645:18,log,logic,18,https://hail.is,https://github.com/hail-is/hail/pull/4197#issuecomment-416761645,2,['log'],['logic']
Testability,I added some old vs. new tests.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5828#issuecomment-482244062:25,test,tests,25,https://hail.is,https://github.com/hail-is/hail/pull/5828#issuecomment-482244062,1,['test'],['tests']
Testability,"I added the capability for the deploy config to find the domain from setting it in the config.ini file. This way users only use `hailctl config set domain` rather than `hailctl dev config set domain`. In addition, we use this new capability to make a test in Batch work on Azure. CC: @danking",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11113:251,test,test,251,https://hail.is,https://github.com/hail-is/hail/pull/11113,1,['test'],['test']
Testability,"I added the cli. I kind of winged it looking at how `hailctl dev deploy` was done. It seems to work though:. ```; (base) wmecc-475:hail jigold$ hailctl batch billing; usage: hailctl batch billing [-h] {list,get} ... Manage billing on the service managed by the Hail team. positional arguments:; {list,get}; list List billing projects; get Get a particular billing project's info. optional arguments:; -h, --help show this help message and exit; (base) wmecc-475:hail jigold$ hailctl batch billing fake; usage: hailctl batch billing [-h] {list,get} ...; hailctl batch billing: error: invalid choice: 'fake' (choose from 'list', 'get'); Unclosed client session; client_session: <aiohttp.client.ClientSession object at 0x111288208>; (base) wmecc-475:hail jigold$ hailctl batch billing list; - accrued_cost: 0.0; billing_project: ci; cost: null; limit: null; users: [ci]; - accrued_cost: 0.0012024241022130966; billing_project: test; cost: 0.0012024241022130966; limit: null; users: [test]; - accrued_cost: 9.62974093086927e-05; billing_project: test-tiny-limit; cost: 9.62974093086927e-05; limit: 1.0e-05; users: [test]; - accrued_cost: 0.0; billing_project: test-zero-limit; cost: null; limit: 0.0; users: [test]. (base) wmecc-475:hail jigold$ hailctl batch billing get; usage: hailctl batch billing get [-h] [-o {yaml,json}] billing_project; hailctl batch billing get: error: the following arguments are required: billing_project; Unclosed client session; client_session: <aiohttp.client.ClientSession object at 0x10a635208>; (base) wmecc-475:hail jigold$ hailctl batch billing get test-tiny-limit; accrued_cost: 9.62974093086927e-05; billing_project: test-tiny-limit; cost: 9.62974093086927e-05; limit: 1.0e-05; users: [test]. (base) wmecc-475:hail jigold$ hailctl batch billing get test-tiny-limit; accrued_cost: 9.62974093086927e-05; billing_project: test-tiny-limit; cost: 9.62974093086927e-05; limit: 1.0e-05; users: [test]. Unclosed client session; client_session: <aiohttp.client.ClientSession o",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9385#issuecomment-684964006:924,test,test,924,https://hail.is,https://github.com/hail-is/hail/pull/9385#issuecomment-684964006,2,['test'],['test']
Testability,"I added the command name, and switched to printing the readable string rather than the `StorageLevel(true, false, false, false, 1)` by adding a RichStorageLevel with toReadableString(). Also added a test in UtilsSuite. @tpoterba back to you",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1028#issuecomment-257649514:199,test,test,199,https://hail.is,https://github.com/hail-is/hail/pull/1028#issuecomment-257649514,1,['test'],['test']
Testability,"I added the configuration option for the minimum number of workers that should be present at any time. I tested this in my namespace. I'd like you to double check the logic is correct for the number of workers needed as I derived it by working through examples:. ```python3; n_live_instances = self.n_instances_by_state['pending'] + self.n_instances_by_state['active']; n_standing_instances_needed = max(0, self.min_instances - self.n_instances); n_standing_instances_needed = min(; n_standing_instances_needed,; self.max_live_instances - n_live_instances,; self.max_instances - self.n_instances,; remaining_instances_per_autoscaler_loop,; # 20 queries/s; our GCE long-run quota; 300,; ); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12742:105,test,tested,105,https://hail.is,https://github.com/hail-is/hail/pull/12742,2,"['log', 'test']","['logic', 'tested']"
Testability,"I added the error for each container to the logs output. I think that's fine, but maybe we need separate section for errors?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10545#issuecomment-853153867:44,log,logs,44,https://hail.is,https://github.com/hail-is/hail/pull/10545#issuecomment-853153867,1,['log'],['logs']
Testability,"I added this feature because I am tired of every time I want to dev deploy and try out new changes, it triggers a new build in CI. I'd prefer to put a new label on the PR rather than close it each time or make a copy of the branch and test the copy.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13540:235,test,test,235,https://hail.is,https://github.com/hail-is/hail/pull/13540,1,['test'],['test']
Testability,"I addressed comments apart from improving the tests on VSM. There are two options regarding plan for writing out a Spark IRM:; 1) just delete it; 2) keep it, pass partStarts through for efficiency, and cut down on code duplication. I tried the latter, creating KeyedIndexedRowMatrix as abstraction to handle both PCA and writing, and pushing common structure to an object WriteBlocksRDD.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2559#issuecomment-351252274:46,test,tests,46,https://hail.is,https://github.com/hail-is/hail/pull/2559#issuecomment-351252274,1,['test'],['tests']
Testability,"I addressed the comment and made a data source that's a GB (defined like: . ```; n_rows = 60_000; n_cols = 4_000; mt = hl.utils.range_matrix_table(n_rows, n_cols); mt = mt.annotate_entries(unif = hl.rand_unif(0, 1)); ```; ). Tests only take like 20 seconds though.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8050#issuecomment-583136594:225,Test,Tests,225,https://hail.is,https://github.com/hail-is/hail/pull/8050#issuecomment-583136594,1,['Test'],['Tests']
Testability,I addressed the grafana situation. I dev deployed into my namespace and I'm able to log in. I cannot test that I've addressed the issue because the default namespace is still using the old version and thus I hit 401s there before even reaching the dev namespace.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12380#issuecomment-1297584226:84,log,log,84,https://hail.is,https://github.com/hail-is/hail/pull/12380#issuecomment-1297584226,2,"['log', 'test']","['log', 'test']"
Testability,"I agree it shouldn't be able to write to a production bucket. But right now, we only have 1 test service account with 1 bucket.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5866#issuecomment-485466724:92,test,test,92,https://hail.is,https://github.com/hail-is/hail/pull/5866#issuecomment-485466724,1,['test'],['test']
Testability,"I agree! The docs are being tested in 2 places. The first is easy to fix; make a new build task that is identical to `makeHailDocs` with a command line of `make clean html` instead. The second place is the tutorial iPython notebook. There is an option `nbsphinx_execute = 'never'` that could be added to `conf.py`, but I haven't figured out what the best way to pass a custom parameter argument to Sphinx is as we are not running `conf.py` directly when we call Sphinx.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1472#issuecomment-284199231:28,test,tested,28,https://hail.is,https://github.com/hail-is/hail/issues/1472#issuecomment-284199231,1,['test'],['tested']
Testability,"I agree. I'll study up on testing this stuff. Scorecard isn't tested, either. A few thoughts:; - I don't feel quite so bad having some of this untested (scorecard, etc.) while we get up to speed since they are internal tools (and not too complicated, unlike ci), but at the very least we need to test hl.upload_log() since that's the user facing bit.; - It will get easier to run tests if we can deploy the service in a test namespace to mirror the production namespace. I'll bump up the priority on looking into this.; - We need authentication without oauth2 for the tests. I'm at a total loss about how to automate testing of oauth2 login. The internet has some thoughts: https://stackoverflow.com/questions/39180008/automated-api-testing-of-oauth2-openid-connect-protected-api, including using headless automation: https://medium.com/@vicusbass/api-testing-with-rest-assured-oauth2-flow-with-redirect-uri-ba48b5953823; - Flask has a test fixture, so at least I can write local tests: http://flask.pocoo.org/docs/1.0/testing/; - Created an issue to track these: https://github.com/hail-is/hail/issues/4539",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4509#issuecomment-429338595:26,test,testing,26,https://hail.is,https://github.com/hail-is/hail/pull/4509#issuecomment-429338595,13,"['log', 'test']","['login', 'test', 'tested', 'testing', 'testing-of-', 'testing-with-rest-assured-', 'tests']"
Testability,"I already had cases in tests that ran the underscore version tests if it's on the service or local backends, so tests didn't need changing.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11648#issuecomment-1076567913:23,test,tests,23,https://hail.is,https://github.com/hail-is/hail/pull/11648#issuecomment-1076567913,3,['test'],['tests']
Testability,"I already have these packages installed, and there was no `netcdf` issue with my version of R. @maccum is going to install the latest version of R fresh and try to add all the packages and see if tests pass. Thanks Meredith!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3281#issuecomment-379056688:196,test,tests,196,https://hail.is,https://github.com/hail-is/hail/pull/3281#issuecomment-379056688,1,['test'],['tests']
Testability,I already moved the monitoring namespace by hand. The monitoring web UI header dropdown now has links to the Google; Cloud console for monitoring and logs.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8703:150,log,logs,150,https://hail.is,https://github.com/hail-is/hail/pull/8703,1,['log'],['logs']
Testability,I already updated the test namespace secret.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5972:22,test,test,22,https://hail.is,https://github.com/hail-is/hail/pull/5972,1,['test'],['test']
Testability,"I also added VariantDataset.make_keytable. With this, one can create keytables with genotype-level values, for example:. ```; vds = hc.import_vcf('/home/cotton/sample.vcf'); (vds.make_keytable('v = v, info = va.info', 'gt = g.gt', ['v']); .export('test.txt')); ```. test.txt will have a `s.gt` column, one for each sample `s`. This functionality was already in the Solr and Cassandra export modules, which should now be moved to KeyTable. The user needs more control over how the KeyTable column names are formed in flatten and make_keytable.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1157#issuecomment-266346469:248,test,test,248,https://hail.is,https://github.com/hail-is/hail/pull/1157#issuecomment-266346469,2,['test'],['test']
Testability,I also added several tests. I'm interested in your comments on how best to write tests of expressions that manipulate aggregators. Resolves #1758. **WARNING:** This is a breaking change.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1764:21,test,tests,21,https://hail.is,https://github.com/hail-is/hail/pull/1764,2,['test'],['tests']
Testability,I also added some debugging logs to try and figure out why you were getting a batch with no jobs when you dev deployed.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6670#issuecomment-512577477:28,log,logs,28,https://hail.is,https://github.com/hail-is/hail/pull/6670#issuecomment-512577477,1,['log'],['logs']
Testability,"I also added some flair to our ""integration tests"" (test.sh).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9821:44,test,tests,44,https://hail.is,https://github.com/hail-is/hail/pull/9821,2,['test'],"['test', 'tests']"
Testability,I also added some more tests since I accidentally broke things while developing this and would like that to happen less in the future.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11380#issuecomment-1045069860:23,test,tests,23,https://hail.is,https://github.com/hail-is/hail/pull/11380#issuecomment-1045069860,1,['test'],['tests']
Testability,I also added some tests that would have caught this infinite recursion.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11599:18,test,tests,18,https://hail.is,https://github.com/hail-is/hail/pull/11599,1,['test'],['tests']
Testability,"I also broke out routines to create examples of values (tables, matrix tables) with all types, and added a test case that runs expand_types on the table of values of all types.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5021#issuecomment-451248463:107,test,test,107,https://hail.is,https://github.com/hail-is/hail/pull/5021#issuecomment-451248463,1,['test'],['test']
Testability,"I also compared `variant_and_sample_qc_nested_with_filters_2` (33% worse on batch) between the two branches on my laptop, and could not detect a difference. I do think the make_ndarray range speedup is real -- there are a few benchmarks that indicate improvement that all are heavily dependent on the performance of the `StreamRange` implementation, which I think slightly improved.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10229#issuecomment-814325646:226,benchmark,benchmarks,226,https://hail.is,https://github.com/hail-is/hail/pull/10229#issuecomment-814325646,1,['benchmark'],['benchmarks']
Testability,I also converted a no-message assertion into an if with an AssertionError; because I found it difficult to debug without the added information. This removes the duplication of the list of supported types for RPrimitive.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8765:30,assert,assertion,30,https://hail.is,https://github.com/hail-is/hail/pull/8765,2,"['Assert', 'assert']","['AssertionError', 'assertion']"
Testability,"I also converted stress into a proper test which we can start running on every PR. I'll PR that separately. I'm currently running that test on my changes. You can see all the changes here: https://github.com/hail-is/hail/pull/11029/commits/8d4c7a22a19ae0a79527eae790d537cf020c1cca. The diff is bad because I merged in main. I removed all the global_config things and tried to keep the minimal diff from main. We can make those changes, if desired, at a later date.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10920#issuecomment-956501512:38,test,test,38,https://hail.is,https://github.com/hail-is/hail/pull/10920#issuecomment-956501512,2,['test'],['test']
Testability,I also couldn't remove the flags from Scala because of the Scala tests.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12423#issuecomment-1302624425:65,test,tests,65,https://hail.is,https://github.com/hail-is/hail/pull/12423#issuecomment-1302624425,1,['test'],['tests']
Testability,"I also created a Starlette branch; which may be preferable, as Sanic brings with it a bit of controversy and a bunch of errors generate on Techempower benchmarks. I took a brief look at the bench source didn't see an immediate issue, so worry a bit about. Sanic. Starlette is a light layer on top of Uvicorn, one of the leading ASGI web servers. Similar to Sanic/Flaks interface:. https://www.techempower.com/benchmarks/#section=data-r17&hw=ph&test=fortune&l=zijzen-1. Branch here, can issue a separate pr and close this one: https://github.com/akotlar/hail/tree/scorecard-starlette",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5242#issuecomment-461188115:151,benchmark,benchmarks,151,https://hail.is,https://github.com/hail-is/hail/pull/5242#issuecomment-461188115,3,"['benchmark', 'test']","['benchmarks', 'test']"
Testability,"I also did a bit of refactoring in lmmreg to make this change more organic. I will add a test asap, but want to simultaneously give @alexb-3 a chance to look over the math.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1720:89,test,test,89,https://hail.is,https://github.com/hail-is/hail/pull/1720,1,['test'],['test']
Testability,I also disabled Spark 1 tests in CI.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1266:24,test,tests,24,https://hail.is,https://github.com/hail-is/hail/pull/1266,1,['test'],['tests']
Testability,"I also do not know how to run our tests in cluster-mode, but I know how to add a python file to this repo and submit it to the cluster in hail-ci-build.sh ;)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5033#issuecomment-449506106:34,test,tests,34,https://hail.is,https://github.com/hail-is/hail/pull/5033#issuecomment-449506106,1,['test'],['tests']
Testability,"I also feel like we should have some tests that assert correctness of very simple comparisons. Like 0 < 1, NA != 1, NA == NA. Do these exist in python?. In the pain of my recent work on contextrdd and off heap regions I've spent a lot of time reducing our test cases to actual minimal examples. It would save engineering time in the long run to add simple, tiny examples every time we make changes or add functionality.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3582#issuecomment-389883212:37,test,tests,37,https://hail.is,https://github.com/hail-is/hail/pull/3582#issuecomment-389883212,6,"['assert', 'test']","['assert', 'test', 'tests']"
Testability,I also made a new test bucket specifically for the tests -- gs://hail-services-requester-pays/,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9096#issuecomment-660163759:18,test,test,18,https://hail.is,https://github.com/hail-is/hail/pull/9096#issuecomment-660163759,2,['test'],"['test', 'tests']"
Testability,I also need to test this on dataproc.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14071#issuecomment-1875981027:15,test,test,15,https://hail.is,https://github.com/hail-is/hail/pull/14071#issuecomment-1875981027,1,['test'],['test']
Testability,I also noticed a bug in the process where the python client uses create-fast only if there is one *job* not one *bunch*. I fixed that and threw in a test.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12554:149,test,test,149,https://hail.is,https://github.com/hail-is/hail/pull/12554,1,['test'],['test']
Testability,"I also now suspect that the strange behavior I was seeing was due to caching on Chrome's side. This would explain why I was seeing nothing in server logs, and why behavior was inconsistent between browsers. I even watched logs of all 6 gateways (3 gateway, 3 internal), and the monitoring router, nothing. I also saw differences in redirect behavior between Safari and Chrome. Cleared browser cache (hard refreshes weren't doing anything), and started also testing in Firefox. Lastly, the proxy_set_header Host does not appear to be needed for Grafana or Prometheus to operate, so I have excluded it (tested with the Cluster dashboard). This also reduces the number of places we need to specify which external domain Grafana/Prometheus sit behind. edit: To be clear I also tried to find documentation on the use of GF_SERVER_DOMAIN and could not. GF_SERVER_DOMAIN doesn't even appear in Grafan's repository (at least, GitHub search doesn't find it, although it does find GF_SERVER_ROOT_URL)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7015#issuecomment-541336418:149,log,logs,149,https://hail.is,https://github.com/hail-is/hail/pull/7015#issuecomment-541336418,8,"['log', 'test']","['logs', 'tested', 'testing']"
Testability,I also suggested gist.github.com for large logs. This will allow us to quickly see new issues from users. We might want other forms / to generalize this form if we want support requests to go to GitHub too. cc: @jigold,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13417:43,log,logs,43,https://hail.is,https://github.com/hail-is/hail/pull/13417,1,['log'],['logs']
Testability,"I also verified the test fails against current batch, both in dev namespace and in default.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7886#issuecomment-574780144:20,test,test,20,https://hail.is,https://github.com/hail-is/hail/pull/7886#issuecomment-574780144,1,['test'],['test']
Testability,"I am a fresh user for hail.; I try this command ""hail importannotations table variantAnnotations.alternateformat.tsv -e Variant --impute write -o consequences.vds"", but I received an error message as follow ""hail: fatal: importannotations table: parse error: ""-e"" is not a valid option"", why?; additionally, I can not find the corresponding test file in the test file of hail download from here and it is really very inconvenient for me to test it!; thanks a lot!",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/561:341,test,test,341,https://hail.is,https://github.com/hail-is/hail/issues/561,3,['test'],['test']
Testability,I am encountering a bug in TestNG version 6.8.21 that is resovled in 7.1.0. For; more detail see https://stackoverflow.com/questions/39613927/testng-with-dataprovider-skips-all-tests.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8801:27,Test,TestNG,27,https://hail.is,https://github.com/hail-is/hail/pull/8801,2,"['Test', 'test']","['TestNG', 'testng-with-dataprovider-skips-all-tests']"
Testability,"I am getting following error while using spark submit with --class ""is.hail.driver.Main"" /test/spark/hail15may.jar. java.lang.ClassNotFoundException: is.hail.driver.Main; 	at java.net.URLClassLoader.findClass(URLClassLoader.java:381); 	at java.lang.ClassLoader.loadClass(ClassLoader.java:424); 	at java.lang.ClassLoader.loadClass(ClassLoader.java:357); 	at java.lang.Class.forName0(Native Method); 	at java.lang.Class.forName(Class.java:348); 	at org.apache.spark.util.Utils$.classForName(Utils.scala:228); 	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:693); 	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:185); 	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:210); 	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:124); 	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1807:90,test,test,90,https://hail.is,https://github.com/hail-is/hail/issues/1807,1,['test'],['test']
Testability,"I am proposing a new iterator abstraction that I think should be preferred to Scala `Iterator` throughout most of the codebase, especially for iterators of region values. This is a low-level change, which could affect all code involving iterators, so I welcome feedback from everybody. The new abstractions are what I called `FlipbookIterator` and `StagingIterator` (I'm open to name suggestions). My goal was to simplify and raise the level of abstraction of most of the iterator manipulating code in the codebase—which can be subtle and bug-prone, and difficult to read—while paying as minimal as possible a performance overhead for the abstraction. This was surprisingly subtle to find the right abstractions and get their implementation right, and my hope is that all the non-obvious iterator code will now be concentrated in a small, well tested, component. `FlipbookIterator` solves the confusing behavior where `hasNext` potentially wipes out the current value. (All methods on `FlipbookIterator` and `StagingIterator` should obey the rule that methods defined without trailing `()` do not change the state of the iterator in any way detectable through the API.) The core interface of `FlipbookIterator[A]` consists of the methods. * `isValid: Boolean`; * `value: A`; * `advance(): Unit`. The metaphor is a flipbook, where when you turn the page, you no longer have access to the previous page; where you can read the current page as many times as you want (no need to copy it); and where you only know you've reached the end of the flipbook when you turn the page and find that the next page is empty. In `FlipbookIterator`, `advance()` turns the page, `isValid` asks if the page you are on is non-empty, and `value` gives you the value on the current page (which is an error if the page is empty). `StagingIterator` is a subtype of `FlipbookIterator` which adds a bit of state to each page, together with the methods `consume()` and `stage()`. The bit of state on each page tracks whether the",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3016:844,test,tested,844,https://hail.is,https://github.com/hail-is/hail/pull/3016,1,['test'],['tested']
Testability,I am so glad I added those requester pays tests. They changed the exception type for requester pays failures and that broke our try-catch. The requester pays situation in GCP is so harebrained.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12555#issuecomment-1397345833:42,test,tests,42,https://hail.is,https://github.com/hail-is/hail/pull/12555#issuecomment-1397345833,1,['test'],['tests']
Testability,"I am testing hail build on spark3 (v0.2.89, spark 3.1.2) and getting the following error with jinja2 (see below).; From the error it seems like this is due to Hail's dependency of bokeh using the latest version of jinja2. Downgrading jinja2 to 3.0.0 solves the problem, and it seems like other people have seen this too with the latest release of jinja2:. https://github.com/holoviz/panel/issues/3260. This may be transient and may be solved by bokeh / jinja2 folks but thought I'd let you know in case you hit this issue. ```; ../conda/envs/glow/lib/python3.7/site-packages/bokeh/core/templates.py:43: in <module>; from jinja2 import Environment, Markup, FileSystemLoader; E ImportError: cannot import name 'Markup' from 'jinja2' (/home/circleci/conda/envs/lib/python3.7/site-packages/jinja2/__init__.py); [error] java.lang.IllegalArgumentException: requirement failed: Python tests in Hail environment failed; [error] 	at scala.Predef$.require(Predef.scala:281); [error] 	at $1fb87e3247134917ca70$.$anonfun$pythonSettings$14(build.sbt:288); [error] 	at $1fb87e3247134917ca70$.$anonfun$pythonSettings$14$adapted(build.sbt:278); [error] 	at scala.Function1.$anonfun$compose$1(Function1.scala:49); [error] 	at sbt.internal.util.$tilde$greater.$anonfun$$u2219$1(TypeFunctions.scala:62); [error] 	at sbt.std.Transform$$anon$4.work(Transform.scala:67); [error] 	at sbt.Execute.$anonfun$submit$2(Execute.scala:280); [error] 	at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:19); [error] 	at sbt.Execute.work(Execute.scala:289); [error] 	at sbt.Execute.$anonfun$submit$1(Execute.scala:280); [error] 	at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); [error] 	at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); [error] 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); [error] 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); [error] 	at java.util.concurrent.FutureTask.run(FutureTask.ja",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11705:5,test,testing,5,https://hail.is,https://github.com/hail-is/hail/issues/11705,2,['test'],"['testing', 'tests']"
Testability,"I am trying to move towards removing the `fundamentalType` interface from `PType`s. As a first pass, this PR will remove RVB's use of `fundamentalType` by delegating the `addAnnotation`'s implementation to a new method, `unstagedStoreJavaObjectAtAddress`. WIP until I see tests are passing and clean up comments.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9892:272,test,tests,272,https://hail.is,https://github.com/hail-is/hail/pull/9892,1,['test'],['tests']
Testability,I am unfamiliar with Hail's test infrastructure so it would be more time efficient for the maintainers to add a test themselves.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14700#issuecomment-2397555427:28,test,test,28,https://hail.is,https://github.com/hail-is/hail/pull/14700#issuecomment-2397555427,2,['test'],['test']
Testability,"I am using Hail 0.2.54. However, I also tested with the latest build.gradle file. I run the following make install command:; `make install HAIL_COMPILE_NATIVES=1 SCALA_VERSION=2.11.12 SPARK_VERSION=2.4.2`. However, I got this error message which did not appear before. ` > Could not resolve org.scalanlp:breeze-natives_2.11:+.; Required by:; project :; > Failed to list versions for org.scalanlp:breeze-natives_2.11.; > Unable to load Maven meta-data from https://repo.hortonworks.com/content/repositories/releases/org/scalanlp/breeze-natives_2.11/maven-metadata.xml.; > Could not get resource 'https://repo.hortonworks.com/content/repositories/releases/org/scalanlp/breeze-natives_2.11/maven-metadata.xml'.; > Could not GET 'https://repo.hortonworks.com/content/repositories/releases/org/scalanlp/breeze-natives_2.11/maven-metadata.xml'. Received status code 500 from server: Server Error; * Try:; Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. Run with --scan to get full insights.; * Get more help at https://help.gradle.org. BUILD FAILED in 29s; make: *** [build/libs/hail-all-spark.jar] Error 1`. It seems that is caused by https://repo.hortonworks.com/content/repositories/releases/ server is done.; I am wondering whether there is any maven substitute can be used temporarily to compile hail.jar?. Thanks in advance for your help.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9419:40,test,tested,40,https://hail.is,https://github.com/hail-is/hail/issues/9419,2,"['log', 'test']","['log', 'tested']"
Testability,"I apologize for not responding sooner to this. I've been mulling over what to do here as it's been over 4 years since I wrote the first interface. I think your changes are fine, but I need to go through the tests again and figure out what `_mentioned` was originally intended for to make sure this change doesn't break anything subtle. I'm going to have our CI run this SHA so I can see what the failures are.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13192#issuecomment-1603274953:207,test,tests,207,https://hail.is,https://github.com/hail-is/hail/pull/13192#issuecomment-1603274953,1,['test'],['tests']
Testability,"I assert that if you create a directory structure by recursively applying this rule:; - create a file named a, recur into it, then; - create a file named b, recur into it. up to some maximum depth D, then the following call will take O(2^D) time:; ```; blobs = bucket.list_blobs(prefix=""dsub-magma-out-maf01/"", max_results=1, delimiter='/'); list(islice(blobs, 1)); ```. In particular, the second operation will take all the time. The first operation returns almost instantaneously. I do not fully understand how Google Cloud Storage is implemented. I conjecture that it uses some ordered structure of keys/paths. The main issue is the `delimiter` argument. When that argument is specified, the returned object will have a `prefixes` property which is populated with one page's worth of ""prefixes"" or strings matching `dsub-magma-out-mfa01/[^/]+/`. Unfortunately, it appears that even with `max_results=1`, the API calls takes a lot of time (as long as 30s). Removing `delimiter` causes the API return immediately. This seems like a bug on Google's end. If `max_results=1`, then Google's API docs claim you'll receive at most 1 prefix per page. If retrieving a single object (`list_blobs(prefix=""foo/"", max_results=1)`) takes time `t`, then retrieving the first prefix should also take time `t` (calculate it from that single object).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8586:2,assert,assert,2,https://hail.is,https://github.com/hail-is/hail/issues/8586,1,['assert'],['assert']
Testability,I assume the local file reads are somehow more tolerant to being closed? I don't know why this doesn't fail like every single matrix read test.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3512:138,test,test,138,https://hail.is,https://github.com/hail-is/hail/pull/3512,1,['test'],['test']
Testability,"I attempted to use the TLS stuff and I've decided against it for this PR. It appears that the batch tests do not work locally at all. The whole essence of this PR is getting the shuffler IR tested and into the mainline. I started making the fixes necessary to support local testing of a local server and when that proved complicated investigated how BatchClientSuite works locally. It seems that using the existing TLS stuff would require fixing all the TLS stuff to allow for at least local->remote testing, if not local->local testing. This PR is already very complex, I'd like to get it merged so we can move forward separately with deploying and eventually harmonizing with the existing TLS infrastructure.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8726#issuecomment-650380852:100,test,tests,100,https://hail.is,https://github.com/hail-is/hail/pull/8726#issuecomment-650380852,5,['test'],"['tested', 'testing', 'tests']"
Testability,"I backed off the support for treating deep NAs as nonequal. That makes the change simpler, and also easier to test.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8859#issuecomment-634159069:110,test,test,110,https://hail.is,https://github.com/hail-is/hail/pull/8859#issuecomment-634159069,2,['test'],['test']
Testability,I backed out the iota optimzations to make this PR less controversial -- it now only introduces and tests StreamTakeWhile and StreamDropWhile. The other functionality will be a stacked PR.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10773#issuecomment-900335924:100,test,tests,100,https://hail.is,https://github.com/hail-is/hail/pull/10773#issuecomment-900335924,1,['test'],['tests']
Testability,"I believe #14547 introduced a bug that broke IR function deserialization in QoB by changing `value_parameter_names` from `Array[String]` to `Array[Name]`. This fixes the issue by pushing the introduction of the `Name` wrapper object to after deserialization. Another option is to incorporate the `{ str: String }` structure of `Name` into the python -> scala payload, but I'm not sure I see a use case for that and we can always do that later (there is no issue of backwards compatibility with this communication between python and scala). My main concern here is that clearly this isn't tested. I'd appreciate guidance on the current advised practice for testing this behavior.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14579:588,test,tested,588,https://hail.is,https://github.com/hail-is/hail/pull/14579,2,['test'],"['tested', 'testing']"
Testability,"I believe I addressed all the comments from #2431. The one thing I couldn't quite figure out is that you suggested testing using a randomly generated vsm and then calling make_table().export() (which in Scala, best as I can figure, is makeKT().export(f)). This does some things that makes re-importing using LoadMatrix non-identical:; - the exported header includes a header entry for the row ID column also, which the data we were looking at before didn't (n entries in the first line, n + 1 entries in subsequent lines), which seems like a reasonable thing to want to deal with---I added a flag in LoadMatrix called hasRowKeyLabel which drops the first item of the header line if that's the case, although it's not exposed to HailContext/the Python interface.; - the exported sample IDs somehow get "".g""s tacked on the ends (presumably because they came from the ""g"" struct), so the sample IDs would never match.; I ended up writing my own export function for the test (since I assume we don't really want to be exporting to this format IRL)---please let me know if I should handle that differently.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2440:115,test,testing,115,https://hail.is,https://github.com/hail-is/hail/pull/2440,2,['test'],"['test', 'testing']"
Testability,I believe I've addressed all of your comments now. The test failure is some spurious batch thing. I'll rerun when it's approved.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9487#issuecomment-697554339:55,test,test,55,https://hail.is,https://github.com/hail-is/hail/pull/9487#issuecomment-697554339,1,['test'],['test']
Testability,"I believe I've addressed your comments, the benchmarks against 0.2.34 look normal, somehow there are no conflicts at this exact moment. Once #8474 goes in let's get this in.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8315#issuecomment-609962053:44,benchmark,benchmarks,44,https://hail.is,https://github.com/hail-is/hail/pull/8315#issuecomment-609962053,1,['benchmark'],['benchmarks']
Testability,I believe it is. I did some tests taking that part of my script out and they didn't get generated,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5266#issuecomment-460788621:28,test,tests,28,https://hail.is,https://github.com/hail-is/hail/issues/5266#issuecomment-460788621,1,['test'],['tests']
Testability,I believe this will be covered by doc tests.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14572#issuecomment-2150952491:38,test,tests,38,https://hail.is,https://github.com/hail-is/hail/pull/14572#issuecomment-2150952491,1,['test'],['tests']
Testability,"I broke my previous PR into littler pieces some of which has already merged. This PR adds developers from production to test namespaces (only programmatic access, browser OAuth flow does not work yet for test namespaces) and makes it easier to add developers to dev namespaces.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13331:120,test,test,120,https://hail.is,https://github.com/hail-is/hail/pull/13331,2,['test'],['test']
Testability,"I broke out the underlying BTree implementation and wrote some tests for it, so this is now stacked on #6771.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6727#issuecomment-516690783:63,test,tests,63,https://hail.is,https://github.com/hail-is/hail/pull/6727#issuecomment-516690783,1,['test'],['tests']
Testability,I broke the UI so this needs to get in ASAP. I added a test so hopefully this doesn't happen again.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11512:55,test,test,55,https://hail.is,https://github.com/hail-is/hail/pull/11512,1,['test'],['test']
Testability,I broke this assertion when I fixed the bug that was caught by it.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4071:13,assert,assertion,13,https://hail.is,https://github.com/hail-is/hail/pull/4071,1,['assert'],['assertion']
Testability,"I broke this when I separated out the dependencies for hail into two layers:. 1. hailtop dependencies; 2. hail dependencies, which builds on top of the hailtop dependencies. This fix does two things:; - Use the full dependencies in 1 & 2; - Use fully pinned dependencies when installing on clusters which seems better than using our wide-range dependencies. I left the `install-deps` and `install-dev-deps` as the normal requirements files as those are meant for development (I think?) but am happy to take opinions on whether we should use fully pinned deps there as well. I have so far been going by the rule of thumb of fully-pinned for CI and production environments, more lax rules for dev environments. See [here](https://github.com/hail-is/hail/pull/12446#discussion_r1030986069) for additional context. cc: @tpoterba, any idea why the test dataproc test succeeded?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12510:843,test,test,843,https://hail.is,https://github.com/hail-is/hail/pull/12510,2,['test'],['test']
Testability,I can break this up further if you want. Big changes:. - change batch.py to support multi-line commands (use `{\n...\n}`); - change batch.py and job.py to support per-job environment variables (and add tests to test_batch.py); - add `partition` to hail top mirroring the implementation in Scala; - implement BatchPoolExecutor which attempts to faithfully implement the interface of concurrent.futures.Executor,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9035:202,test,tests,202,https://hail.is,https://github.com/hail-is/hail/pull/9035,1,['test'],['tests']
Testability,"I can see a fix using _annotate_all and then a select directly before entering the logreg, though.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4941#issuecomment-446173200:83,log,logreg,83,https://hail.is,https://github.com/hail-is/hail/issues/4941#issuecomment-446173200,1,['log'],['logreg']
Testability,"I can stack this change with the change that defines the function, I do test that the `vcf_combiner` pipeline runs in `test_impex.py::VCFTests::test_combiner_works`. That may be sufficient, since it would fail without this change.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5471#issuecomment-469340908:72,test,test,72,https://hail.is,https://github.com/hail-is/hail/pull/5471#issuecomment-469340908,1,['test'],['test']
Testability,I can take a look tomorrow - can you point me to the test that's failing?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9604#issuecomment-713144645:53,test,test,53,https://hail.is,https://github.com/hail-is/hail/pull/9604#issuecomment-713144645,1,['test'],['test']
Testability,"I can test whether I'm finding natives for NDArray expressions, but that doesn't mean I know what natives netlib is using.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5040#issuecomment-570313646:6,test,test,6,https://hail.is,https://github.com/hail-is/hail/issues/5040#issuecomment-570313646,1,['test'],['test']
Testability,"I can try and be clever with how to test this by hand by not writing the spec to cloud storage, but before I do that, I'd like feedback first.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11391:36,test,test,36,https://hail.is,https://github.com/hail-is/hail/pull/11391,1,['test'],['test']
Testability,"I can't easily tell whether the change to emitted code does not change behavior, looked a bit, so will wait for tests, but besides that, looks good",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8057#issuecomment-583558504:112,test,tests,112,https://hail.is,https://github.com/hail-is/hail/pull/8057#issuecomment-583558504,1,['test'],['tests']
Testability,"I can't figure out why I'm getting an error in one test. But I also am not sure what to do with the `/batches` endpoint. I want the UI default to only show you your batches with the default query string 'user:jigold`. However, what should the REST endpoint be? All batches in all billing projects you have access for?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9954#issuecomment-770063101:51,test,test,51,https://hail.is,https://github.com/hail-is/hail/pull/9954#issuecomment-770063101,1,['test'],['test']
Testability,"I can't figure out why my out of memory test isn't working. It's reporting exit code 0 and no out of memory error even though when I do the same thing locally on my computer with docker run or on an instance in the cluster, I get exit code 137 and out of memory. I'm limiting the docker run command to the same amount of bytes that the docker command in the worker should be limiting it to (looked at the docker output in the worker logs). I think the next step is to try using curl to run docker containers rather than the docker cli.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7583#issuecomment-557686216:40,test,test,40,https://hail.is,https://github.com/hail-is/hail/pull/7583#issuecomment-557686216,2,"['log', 'test']","['logs', 'test']"
Testability,"I can't figure out why the tests aren't passing yet. It's failing on test_ci because the code to remove files is failing (KeyError???). Otherwise, I'm good with it, except I might take out the run_if_done_or_deleted for now so we don't get infinite loops while this code is still in flux.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11397#issuecomment-1071030226:27,test,tests,27,https://hail.is,https://github.com/hail-is/hail/pull/11397#issuecomment-1071030226,1,['test'],['tests']
Testability,"I can't find good tests either, can you add some tests in the spirit of my shared ipython session?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13405#issuecomment-1673732741:18,test,tests,18,https://hail.is,https://github.com/hail-is/hail/pull/13405#issuecomment-1673732741,2,['test'],['tests']
Testability,I can't see the test logs though and what is failing exactly :(,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11747#issuecomment-1096596402:16,test,test,16,https://hail.is,https://github.com/hail-is/hail/pull/11747#issuecomment-1096596402,2,"['log', 'test']","['logs', 'test']"
Testability,"I can't use `hailctl batch list`; ```; Last login: Wed Dec 18 15:05:20 on ttys001; # hailctl batch list; Traceback (most recent call last):; File ""/usr/local/bin/hailctl"", line 8, in <module>; sys.exit(main()); File ""/usr/local/lib/python3.7/site-packages/hailtop/hailctl/__main__.py"", line 103, in main; cli.main(args); File ""/usr/local/lib/python3.7/site-packages/hailtop/hailctl/batch/cli.py"", line 97, in main; jmp[args.module].main(args, pass_through_args, client); File ""/usr/local/lib/python3.7/site-packages/hailtop/hailctl/batch/list_batches.py"", line 39, in main; batch_list = client.list_batches(success=success, complete=complete, attributes=attributes); TypeError: list_batches() got an unexpected keyword argument 'success'; # ; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7756:44,log,login,44,https://hail.is,https://github.com/hail-is/hail/issues/7756,1,['log'],['login']
Testability,I cannot enable these tests because both the local and service backend fail due to this error:. ```; E Java stack trace:; E java.lang.AssertionError: assertion failed:; E ir key: [Ljava.lang.String;@28f4484b; E lowered key: WrappedArray(); E 	at scala.Predef$.assert(Predef.scala:223); E 	at is.hail.expr.ir.lowering.LowerTableIR$.lower$1(LowerTableIR.scala:1101); E 	at is.hail.expr.ir.lowering.LowerTableIR$.apply(LowerTableIR.scala:1118); E 	at is.hail.expr.ir.lowering.LowerToCDA$.lower(LowerToCDA.scala:67); E 	at is.hail.expr.ir.lowering.LowerToCDA$.lower(LowerToCDA.scala:36); E 	at is.hail.expr.ir.lowering.LowerToCDA$.apply(LowerToCDA.scala:16); E 	at is.hail.expr.ir.lowering.LowerToDistributedArrayPass.transform(LoweringPass.scala:75); E 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:15); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:15); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:13); E 	at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:12); E 	at is.hail.expr.ir.lowering.LowerToDistributedArrayPass.apply(LoweringPass.scala:70); E 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:14); E 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:12); E 	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36); E 	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33); E 	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:38); E 	at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:12); E 	at is.hail.backend.local.LocalBackend._jvmLowerAndExecute(LocalBackend.scala:88); E 	at is.hail.backend.local.LocalBackend._execute(LocalBackend.scala:124); E 	at is.hail.backend.local.LocalBac,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10379:22,test,tests,22,https://hail.is,https://github.com/hail-is/hail/pull/10379,4,"['Assert', 'assert', 'test']","['AssertionError', 'assert', 'assertion', 'tests']"
Testability,"I changed ci.hail.is to point to kubernetes, so this won't work any more. The new web site is ready to go (live at test.hail.is) and I will switch it over hail.is over late tonight. It needs to go down for a short while to get new Let's Encrypt credentials.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4399:115,test,test,115,https://hail.is,https://github.com/hail-is/hail/pull/4399,1,['test'],['test']
Testability,I changed my PR so the tests will run. I narrowed down the change in behavior occurs when removing just the commit #3426. Should we look into this further?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3417#issuecomment-385512355:23,test,tests,23,https://hail.is,https://github.com/hail-is/hail/pull/3417#issuecomment-385512355,1,['test'],['tests']
Testability,"I changed the fam_expr string argument to **fam_args that are checked in Python. I also changed the args to Python stye (is_case instead of isCase) and updated the import_fam and importFam docs/tests. Porting of import_plink will need similar translation. I've temporarily commented out the last two `assertRaises` tests as they've uncovered a bug in other code, talking to Tim about it.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2750:194,test,tests,194,https://hail.is,https://github.com/hail-is/hail/pull/2750,3,"['assert', 'test']","['assertRaises', 'tests']"
Testability,I changed this from 2=>1 in April of last year unintentionally while debugging; (it's easy to get interleaved prints/logs with 2 concurrent worker threads). https://github.com/hail-is/hail/pull/8535/files#diff-bf51d09b286fddaa730b426824ccb12dac8b9032e0c88bde81882f3cb1423df8R14,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10710:117,log,logs,117,https://hail.is,https://github.com/hail-is/hail/pull/10710,1,['log'],['logs']
Testability,"I checked CI, the test is run in test_hail_python.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11227#issuecomment-1013474804:18,test,test,18,https://hail.is,https://github.com/hail-is/hail/pull/11227#issuecomment-1013474804,1,['test'],['test']
Testability,"I checked the [logs for this PR](https://console.cloud.google.com/logs/query;query=logName:%22worker%22%0Alabels.namespace:%22pr-10467%22;timeRange=PT6H;cursorTimestamp=2021-05-07T19:35:43.101282634Z?project=hail-vdc&folder=true&organizationId=548622027621&query=%0A), both normal logs and just ERRORs and didn't see anything abnormal. If there's a particular stress test you'd like me to try out I'm happy to test it",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10467#issuecomment-834787593:15,log,logs,15,https://hail.is,https://github.com/hail-is/hail/pull/10467#issuecomment-834787593,6,"['log', 'test']","['logName', 'logs', 'test']"
Testability,I checked the test failure should be fixed by #8131,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8193#issuecomment-592584656:14,test,test,14,https://hail.is,https://github.com/hail-is/hail/pull/8193#issuecomment-592584656,1,['test'],['test']
Testability,"I conducted tests on my laptop and on the cluster. I made these comments at https://github.com/hail-is/hail/pull/7534 and on [Zulip](https://hail.zulipchat.com/#narrow/stream/123011-Hail-Dev/topic/ci/near/180856479). From Zulip:; > By comparison, on my wired laptop (which should be strictly slower than in GCP), I can download and extract a tar -cvzf archive in 7.2 seconds; > ...; > The 20 seconds is: clone from github.com, git-merge; > The 7.2 seconds is: download from GCS, untar; > Just ran the test in the cloud using the google cloud sdk image started by k run, 3.7 seconds; > The download is super fast, like a second; > the untar is about the same in both contexts, 1.2 seconds; > But the download drops from 4.7 to ~1.5. Chris pointed out I should skip going to disk and pipe into tar, I have not timed that yet. I was seeing fetch being more like 8 minutes to my repository. My repository is significantly larger than Alex's. I could delete some old branches to address this. ---. > for inputs/outputs, I wonder if we should have a flag that indicates it is an archive and do the archive/extract automatically (like you've done here but more generally), and stop using cp -r. I almost went down this route. It would save a couple lines of tar/untar in runImage steps. I felt the savings wasn't worth the effort of implementing it. In the buildImage case (what this PR addressed), I think it's worth it to keep images small. > for downstream steps that only need a small part of the repo, is it better to copy out different pieces (archived or no) rather than copy the whole thing and extra the parts you need?. I haven't investigated this. I agree, there exists an inflection point where the size of data overcomes GCS latency and GCS-throughput / tar-decompress is the bottleneck. There's something to be said for tar'ing everything except for `.git`, but I didn't carefully check which steps need it and which steps do not. ---. In conclusion, I'd say this PR is necessary for #7534, and",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7626#issuecomment-560442927:12,test,tests,12,https://hail.is,https://github.com/hail-is/hail/pull/7626#issuecomment-560442927,4,['test'],"['test', 'tests']"
Testability,I confirmed the test_utils test I added is being run.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8679#issuecomment-622567618:27,test,test,27,https://hail.is,https://github.com/hail-is/hail/pull/8679#issuecomment-622567618,1,['test'],['test']
Testability,I confirmed with @jbloom22 the tests I modified should be `absolute=True`.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3364#issuecomment-380973165:31,test,tests,31,https://hail.is,https://github.com/hail-is/hail/pull/3364#issuecomment-380973165,1,['test'],['tests']
Testability,"I copied all the secrets from batch-pods into default that (1) didn't already exist (by name) in default, and (2) weren't k8s service account tokens (which are batch-pods specific). I also fixed the remaining test failures so this should be ready to go.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9718#issuecomment-729993692:209,test,test,209,https://hail.is,https://github.com/hail-is/hail/pull/9718#issuecomment-729993692,1,['test'],['test']
Testability,"I could not re-open [the old PR](https://github.com/hail-is/hail/pull/3392) because I force-pushed after a rebase. ---. We want all allocations of `Region` to be controlled with a `using` or within a `RVDContext` (which will be appropriately closed). When we have achieved this, we can move the `Region` off-heap which provides a number of benefits including the use of raw-pointers in our Hail Object Representation as well as allocation free communication with other languages. This PR makes `LoadVCF` and `HailContext.readRows` use the regions in the `RVDContext`. Note that the _consumer_ is responsible for clearing the region when they're done with the current values. This is why `writePartitions` now includes `ctx.clear()`. Moreover, _producers_ must _not_ clear the region. These changes are tested by our whole infrastructure, but in particular, `is.hail.annotations.AnnotationsSuite.testReadWrite` exercises a lot of this. NB: We no longer clear the region between each read of a row. This means we could blow memory if we don't clear in the consumer. The other consumers are: aggregations, collects, shuffles, and joins. The tests pass though, so I guess I'm not too concerned for now. Once this is merged, I'll follow swiftly with uses of the RVDContext's region else where in our infrastructure. cc: @cseed . ---. I also included a couple miscellaneous clean ups like unifying `OrderedRVD.rdd` and `UnpartitionedRVD.rdd` as well as adding a use of `Region.scoped` in `HailContext`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3394:802,test,tested,802,https://hail.is,https://github.com/hail-is/hail/pull/3394,3,['test'],"['testReadWrite', 'tested', 'tests']"
Testability,"I couldn't find any tests of `sample_variants` in either the Python or Scala suites, nor could I think of any good tests. But it's such a direct interface to `RDD.sample`, that seems okay to me. I can add tests if anyone has suggestions.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2696:20,test,tests,20,https://hail.is,https://github.com/hail-is/hail/pull/2696,3,['test'],['tests']
Testability,"I cover the two primary methods: PC-Relate and KING. # PC-Relate. Suppose:. 1. We have $X_1$, an $M$ -by- $N$ matrix of genotypes, with $M$ variants and $N$ samples. Suppose we have a new dataset $X_2$ which strictly adds $l$ new variants and $k$ new samples to $X_1$. 2. We have a truncated-SVD of $U S V^T = X_1$ [1]. 3. We believe the ancestry space represented by the truncated-SVD still accurately represents the ancestry space of $X_2$. 4. We have already calculated the PC-Relate kinship matrix $\phi_1$ of $X_1$. We would like to calculate $\phi_2$ the kinship matrix of $X_2$ while only performing $O(k^2 M + kNM)$ work. ---. [1] PC-Relate, as presented in Conomos, et al., uses the PC scores and linear regression to define the ancestry space as follows.; 1. Calculate the first $k$ (different from $k$ above) PC scores of $X$ (which are defined in terms of the $k$-truncated SVD: $S V^T$).; 2. For each variant $s$, find the best linear fit using ordinary least squares for the equation $x_s = \alpha_s + \beta_s S V^T$. $\alpha$ is a scalar intercept term. $\beta_s$ is a $N$-vector. $x_s$ is the vector of genotypes for variant $s$ (the $s$-th row of $X$); 3. Defined the individual specific allele frequency for sample $i$ at variant $s$: $\mu_{is} = \widehat{\alpha_s} + \widehat{\beta_s} S V^T$. At one point, Patrick noticed that this rigamarole is unnecessary. The $k$-truncated SVD is the best rank $k$ approximation of $X$. I think our conclusion was that defining $\mu$ in terms of the $k$-truncated SVD is equivalent: $\mu = U S V^T$. # KING. Suppose again (1) and that we already have the $\phi_1$ KING's kinship estimator on $X_1$. We would like to calculate $\phi_2$, the KING kinship estimator matrix of $X_2$ while only performing $O(k^2 M + kNM)$ work. ### Version. 0.2.124. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13808:1816,log,log,1816,https://hail.is,https://github.com/hail-is/hail/issues/13808,1,['log'],['log']
Testability,"I created a modified version of `profile225.vds`:. ```; from hail import *; hc = HailContext(); (hc.read('/Users/jbloom/data/profile225.vds'); .filter_multi(); .variant_qc(); .hardcalls(); .annotate_samples_expr('sa.pheno = pcoin(0.5), sa.cov1 = rnorm(0,1), sa.cov2 = rnorm(0,1), sa.cov3 = rnorm(0,1), sa.cov4 = rnorm(0,1), sa.cov5 = rnorm(0,1), sa.cov6 = rnorm(0,1), sa.cov7 = rnorm(0,1), sa.cov8 = rnorm(0,1)'); .write('/Users/jbloom/data/profile225.prelogreg.vds')); ```. And ran all the tests with two samples covariates (note these are all mapVariants so just stacking tranformations):; ```; (hc.read('/Users/jbloom/data/profile225.prelogreg.vds'); 	.linreg('sa.pheno', ['sa.cov1', 'sa.cov2']); 	.logreg('wald', 'sa.pheno', ['sa.cov1', 'sa.cov2'], root='va.wald'); 	.logreg('lrt', 'sa.pheno', ['sa.cov1', 'sa.cov2'], root='va.lrt'); 	.logreg('score', 'sa.pheno', ['sa.cov1', 'sa.cov2'], root='va.score'); 	.logreg('firth', 'sa.pheno', ['sa.cov1', 'sa.cov2'], root='va.firth'); 	.export_variants('/Users/jbloom/data/logreg.tsv', 'Variant = v, va.qc.*, linBeta = va.linreg.beta, waldBeta = va.wald.wald.beta, lrtBeta = va.lrt.lrt.beta, firthBeta = va.firth.firth.beta, linPval = va.linreg.pval, waldPval = va.wald.wald.pval, lrtPval = va.lrt.lrt.pval, firthPval = va.firth.firth.pval, scorePval = va.score.score.pval, waldIter = va.wald.fit.nIter, lrtIter = va.lrt.fit.nIter, firthIter = va.firth.fit.nIter')); ```. Beta for all variants, note that Firth resolves quasi-separation issues and regresses toward the zero:; ![logregbetalrtfirth](https://cloud.githubusercontent.com/assets/3201642/22867286/9e219bc2-f153-11e6-896a-c49e55593312.png). Pvals for all variants, note that Firth is more conservative:; ![logregpvallrtfirth](https://cloud.githubusercontent.com/assets/3201642/22867294/a86b012c-f153-11e6-8155-23004f9127fe.png). Beta for variants with at least 20 hets, basically the same:; ![logregbeta20hets](https://cloud.githubusercontent.com/assets/3201642/22859644/23feabb6-f0b1-11e6-88d5",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1375#issuecomment-279196409:491,test,tests,491,https://hail.is,https://github.com/hail-is/hail/pull/1375#issuecomment-279196409,5,"['log', 'test']","['logreg', 'tests']"
Testability,"I created a new multi-branch configuration that should be better for what we are trying to accomplish. This should fix issues 2 and 3. . For the reproducibility of errors, that will probably take both setting the random seed parameter in Hail for all random tests and getting Jenkins to give better error messages.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/335#issuecomment-214377125:258,test,tests,258,https://hail.is,https://github.com/hail-is/hail/issues/335#issuecomment-214377125,1,['test'],['tests']
Testability,"I created and exported two genomicsdb shards using GATK. The test compares genomicsdb import to importing the exported VCFs from GATK (modulo some minor differences). This PR includes an 18MB compressed FASTA file for h38 chr20 (import_genomicsdb needs a FASTA file). Github has a 100MB file size limit. This seems fine, but if there is an objection we can switch to using git-lfs: https://git-lfs.github.com/. @lfrancioli I will test against gnomADv3 test data next and post some timings.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3537:61,test,test,61,https://hail.is,https://github.com/hail-is/hail/pull/3537,3,['test'],['test']
Testability,"I created the `hl._nd` module, and gave it 4 functions:. 1. `hl._nd.array`: This is an alias for the current `hl._ndarray`. Once this PR goes in, there will be a follow up PR that pulls out this old function and fixes up all the tests. . 2. `hl._nd.full`: Same as `np.full`. Takes two arguments. First argument is the shape, second argument is the argument to fill the ndarray with. . 3. `hl._nd.zeros`: Same as `np.zeros`. Make array full of 0s. . 4. `hl._nd.ones`: Same as `np.ones`. Make array full of 1s. . One weird thing is it seems like doing `hl.nd` also works, in addition to `hl._nd`. Not sure why that is.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7391:229,test,tests,229,https://hail.is,https://github.com/hail-is/hail/pull/7391,1,['test'],['tests']
Testability,"I decided to break off this chunk from another PR that has stalled. That PR will ultimately build on this to add all developers automatically to dev AND test namespaces, but this should be an improvement for now. A few things in here:. - Deleted all the `DatabaseResource` stuff in the auth driver. Since databases now are created and destroyed with the namespace and not the developer, this is basically dead code.; - Added the ability to add a user for an existing hail identity. This is only permitted in dev namespaces and serves as a way for developers to use the same hail identity across namespaces. There is one caveat here: `create_initial_account.py` tries to copy the `<dev-name>-gsa-key` secret from default into the developer namespace and this code will *not* do that anymore. For the developer to submit jobs to the namespace, they must first manually copy in the secret from `default` if it does not already exist inside the namespace. This is awkward, but IMO acceptable because:; - the copying code in `create_initial_account.py` is already broken anyway because when that script is run in a dev deploy it does not have access to production secrets; - I hope that when we eventually go keyless we can delete the gsa key secrets and this whole problem goes away.; - I feel like it's not too bad to do this manual one time copy as opposed to maintaining code that is privileged enough to reach across namespaces. Seems error prone and like a security headache.; - Deletes `create_initial_account.py` in favor of using our actual API to create the dev user.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13180:153,test,test,153,https://hail.is,https://github.com/hail-is/hail/pull/13180,1,['test'],['test']
Testability,"I decided to try to do this in two passes since making changes to deploy logic always finnicky on its own. I think this does the right thing though. . Does build.yaml support a way to say ""depend on this step x if we are doing x at all""? Redeploying the website will have to happen after the `deploy` step runs in the future and publishes the latest version of the docs to hail-common.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11294#issuecomment-1024606310:73,log,logic,73,https://hail.is,https://github.com/hail-is/hail/pull/11294#issuecomment-1024606310,1,['log'],['logic']
Testability,"I deleted the LinearRegressionFromHcsCommand and associated tests as it'd fallen out of sync with how hcs evolved for T2D, it's independent of the rest of the PR and I can add this functionality back later (at which point I imagine there will be other changes both to hcs and to the stats interfaces more generally).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/517#issuecomment-236385122:60,test,tests,60,https://hail.is,https://github.com/hail-is/hail/pull/517#issuecomment-236385122,1,['test'],['tests']
Testability,"I deleted the pod; ```; # k delete pod batch-2554-job-4-main-cc8d4 -n batch-pods; ```; Batch logs when batch discovered 2554 task 4 ""failed"":; ```; INFO | 2019-06-25 12:37:07,611 | batch.py | update_job_with_pod:976 | update job (2554, 4) with pod batch-2554-job-4-main-cc8d4; INFO | 2019-06-25 12:37:07,671 | batch.py | update_job_with_pod:976 | update job (2554, 4) with pod batch-2554-job-4-main-cc8d4; INFO | 2019-06-25 12:37:07,671 | batch.py | update_job_with_pod:989 | job (2554, 4) mark complete; WARNING | 2019-06-25 12:37:07,676 | batch.py | mark_complete:495 | job (2554, 4) has pod batch-2554-job-4-main-cc8d4 which is terminated but has no timing information. {'api_version': 'v1',; 'kind': 'Pod',; 'metadata': {'annotations': None,; 'cluster_name': None,; 'creation_timestamp': datetime.datetime(2019, 6, 25, 3, 9, 4, tzinfo=tzlocal()),; 'deletion_grace_period_seconds': 30,; 'deletion_timestamp': datetime.datetime(2019, 6, 25, 12, 37, 37, tzinfo=tzlocal()),; 'finalizers': None,; 'generate_name': 'batch-2554-job-4-main-',; 'generation': None,; 'initializers': None,; 'labels': {'app': 'batch-job',; 'hail.is/batch-instance': 'cd50b95a89914efb897965a5e982a29d',; 'uuid': '3bf0b121f62d4cfea15cf187a21bc0ed'},; 'name': 'batch-2554-job-4-main-cc8d4',; 'namespace': 'batch-pods',; 'owner_references': None,; 'resource_version': '72793521',; 'self_link': '/api/v1/namespaces/batch-pods/pods/batch-2554-job-4-main-cc8d4',; 'uid': '968b4ba5-96f6-11e9-8aa3-42010a80015f'},; 'spec': {'active_deadline_seconds': None,; 'affinity': None,; 'automount_service_account_token': None,; 'containers': [{'args': None,; 'command': ['/bin/bash',; '-c',; 'set -ex; mkdir -p '; '/io/pipeline/pipeline-f559bb010746/__TASK__3/; '; '__RESOURCE_FILE__747=/io/pipeline/pipeline-f559bb010746/inputs/5fa554a9; '; '__RESOURCE_FILE__19=/io/pipeline/pipeline-f559bb010746/inputs/eaaeaee5.vcf.gz.tbi; '; '__RESOURCE_FILE__18=/io/pipeline/pipeline-f559bb010746/inputs/eaaeaee5.vcf.gz; '; '__RESOURCE_FILE__6=/io/pipelin",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6466#issuecomment-505429649:93,log,logs,93,https://hail.is,https://github.com/hail-is/hail/issues/6466#issuecomment-505429649,1,['log'],['logs']
Testability,"I detect no performance difference on blanczos running the benchmark; locally. This pattern appears a lot in the NDArrayEmitter, though,; so we should fix it everywhere and see what happens!",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9708:59,benchmark,benchmark,59,https://hail.is,https://github.com/hail-is/hail/pull/9708,1,['benchmark'],['benchmark']
Testability,"I did a benchmarking experiment.; My inputs:; **VDS**: vds created from `seq 1 100 300000000` mapped to ""1 $i A T NA"", and imported with `hail importannotations`. This is a 3M variant sites vds.; **interval file**: exome capture regions provided by Monkol. Seems like pretty random non-overlapping interval over chr1. 39K variants fall in these intervals, slightly over 1%. My cmd line:; `hail read -i <vds> filtervariants intervals --keep -i <interval list> count`, with the read/filter/count repeated 10 times. I ran this on the current master and this branch on one core on my laptop. I then calculated the time per iteration. **Benchmark results**; current master: 4.876s, with a std dev of 0.18; this branch: 4.716s, with a std dev of 0.18; mean ratio: 0.967. **Conclusion**: this branch is faster than master for interval queries by a minimum of 3-4%",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/441#issuecomment-231229379:8,benchmark,benchmarking,8,https://hail.is,https://github.com/hail-is/hail/pull/441#issuecomment-231229379,2,"['Benchmark', 'benchmark']","['Benchmark', 'benchmarking']"
Testability,"I did a little more digging into this today. I tried printing the size of the largest method in a class before splitting, before emitting bytecode. In the failing `test_can_process_wide_tables` test, the comparison of before/after this pr was consistent across all table widths in the test: some methods stay the same size, some increase by 7.4%. Only the largest table width triggers a ClassTooLarge exception. It's looking like this just created a small constant increase in code size, which we could make up with optimizations like constant folding, or longer term just fix the root problem by splitting up these giant classes. @tpoterba What are your thoughts on just disabling the largest wide-table test, vs spending more time understanding exactly how this is generating larger classes?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10905#issuecomment-937106437:194,test,test,194,https://hail.is,https://github.com/hail-is/hail/pull/10905#issuecomment-937106437,3,['test'],['test']
Testability,"I did debug this, though. The failing test (which succeeds in Spark, but fails in local backend) collects a table and asserts that the result is equal to a list of expected rows. The failure is caused by an ordering issue - the rows are the same, but the order is slightly different between the Spark backend (which produces the expected output) and the local backend. However, I think that actually *both* orders are valid under Hail's guarantees. I'll bring this to our next team meeting for group discussion.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9618#issuecomment-777080408:38,test,test,38,https://hail.is,https://github.com/hail-is/hail/pull/9618#issuecomment-777080408,2,"['assert', 'test']","['asserts', 'test']"
Testability,"I did make sure it renders as I intended, and the round trip test means it produces valid type grammar. but I'm hesitant to add a test for exact characters, since if we want to change spacing or something cosmetic then we have to change the test. I feel the same way about assertRaisesRegex checks -- we should be able to make error messages nicer.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2998#issuecomment-368885849:61,test,test,61,https://hail.is,https://github.com/hail-is/hail/pull/2998#issuecomment-368885849,4,"['assert', 'test']","['assertRaisesRegex', 'test']"
Testability,I did not rebuild the shared libraries. I do not understand why; the tests did not fail. I will look into that separately. This; should unblock TJ.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5508:69,test,tests,69,https://hail.is,https://github.com/hail-is/hail/pull/5508,1,['test'],['tests']
Testability,I did not test these changes at all. Let me know if you have suggestions for doing so.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13137:10,test,test,10,https://hail.is,https://github.com/hail-is/hail/pull/13137,1,['test'],['test']
Testability,"I did the check against MMAP results using this R code on the grids in global from lmmreg analysis:; ```; ##### delta.tsv has two columns; # logDelta given by global.lmmreg.fit.logDeltaGrid; # logLkhd given by global.lmmreg.fit.logLkhdVals; df = read.table('delta.m.25.tsv', header=T, sep=""\t""). ##### method to estimate sigma, the standard deviation of normal approximation of confidence interval for h2; ### h2 = sigmoid(-ln(delta)); df$h2 = 1 / (1 + exp(df$logDelta)). ### fit parabola near maximum logLkhd of h2; maxRow = which.max(df$logLkhd). # h2; x1 = df$h2[maxRow - 1]; x2 = df$h2[maxRow]; x3 = df$h2[maxRow + 1]. # logLkhd at h2; y1 = df$logLkhd[maxRow - 1]; y2 = df$logLkhd[maxRow]; y3 = df$logLkhd[maxRow + 1]. # find a in logLkhd = a * x^2 + b * x + c; a = (x3 * (y2 - y1) + x2 * (y1 - y3) + x1 * (y3 - y2)) / ((x2 - x1) * (x1 - x3) * (x3 - x2)). # logLkhd = - (x - mu)^2 / (2 * sigma^2) + const = -1 / (2 * sigma^2) * x^2 + lower order terms; sigma2 = 1 / (-2 * a); sigma = sqrt(sigma2). ##### Method to plot normalized likelihood function of h2 and normal approximation; # shift log lkhd to have max of 0, to prevent numerical issues; maxLogLkhd = max(df$logLkhd); df$logLkhd = df$logLkhd - maxLogLkhd. ### integrate in h2 coordinates; df$width = df$h2 * (1 - df$h2) # d(h2) / d (ln(delta)) = - h2 * (1 - h2); total = sum(exp(df$logLkhd) * df$width) # normalization constant; df$posterior = exp(df$logLkhd) * df$width / total # normalized likelihood of h2 = posterior of h2 with uniform prior. ### normal approximation; meanPost = sum(df$h2 * df$posterior); sdPost = sqrt(sum((df$h2 - meanPost)**2 * df$posterior)); df$normalApproxPost = dnorm(df$h2, meanPost, sdPost). ### plots; qplot(x = logDelta, y = logLkhd, data = df, geom = 'line', xlab='ln(delta)', ylab='logLkhd(delta)'); qplot(x = h2 , y = logLkhd, data = df, xlim =c(0,1), geom = 'line', xlab = 'h2', ylab='logLkhd(h2)'); qplot(x = h2 , y = posterior, data = df, xlim =c(0,1), geom = 'line', xlab = 'h2', ylab='posterior(h2)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1720#issuecomment-297590538:141,log,logDelta,141,https://hail.is,https://github.com/hail-is/hail/pull/1720#issuecomment-297590538,13,['log'],"['logDelta', 'logDeltaGrid', 'logLkhd', 'logLkhdVals']"
Testability,"I did this and then realized unfilterEntries is only used in a test. @tpoterba, did you intend to expose this in Python?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3528:63,test,test,63,https://hail.is,https://github.com/hail-is/hail/pull/3528,1,['test'],['test']
Testability,"I did update all the random tests in the randomness PR, if I disabled any it was definitely unintentional.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12588#issuecomment-1397385080:28,test,tests,28,https://hail.is,https://github.com/hail-is/hail/pull/12588#issuecomment-1397385080,1,['test'],['tests']
Testability,"I didn't bust js yet because there are some external libraries (MathJax) that cary their own version strings and I don't want to break them. In testing seems safe, although I admit the regex isn't the most specific. In the worst case I believe we would append an unnecessary version string, which shouldn't break anything (just will cache the browser to reload the css instead of using cache)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6997:144,test,testing,144,https://hail.is,https://github.com/hail-is/hail/pull/6997,1,['test'],['testing']
Testability,I didn't claim to have fixed this one yet. Mentioned I had not pushed because it will fail tests due to per-variant beta being wrong.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1929#issuecomment-311341764:91,test,tests,91,https://hail.is,https://github.com/hail-is/hail/pull/1929#issuecomment-311341764,1,['test'],['tests']
Testability,I didn't know if we should have the k8s server URL in the repo. I left it out for now just in case. I haven't tested the service account changes yet. Stacked on #7434,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7454:110,test,tested,110,https://hail.is,https://github.com/hail-is/hail/pull/7454,1,['test'],['tested']
Testability,I didn't test the getting the logs code.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9765:9,test,test,9,https://hail.is,https://github.com/hail-is/hail/pull/9765,2,"['log', 'test']","['logs', 'test']"
Testability,I didn't test this yet -- do you want me to try the updated docs or should we wait until we redeploy the infrastructure next? Documentation is [here](https://registry.terraform.io/providers/hashicorp/azurerm/latest/docs/resources/network_security_group).,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11027:9,test,test,9,https://hail.is,https://github.com/hail-is/hail/pull/11027,1,['test'],['test']
Testability,I disabled the two tests that are failing because of this set/dict comparison issue.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6050#issuecomment-491048694:19,test,tests,19,https://hail.is,https://github.com/hail-is/hail/pull/6050#issuecomment-491048694,1,['test'],['tests']
Testability,"I discovered [issue forms](https://github.blog/changelog/2021-06-23-issues-forms-beta-for-public-repositories/) the other day and thought it might be helpful for directing users to the discussion forum / Zulip chatroom. With this configuration, when someone opens an issue, they'll be presented with some options:; ![Screen Shot 2023-01-13 at 8 01 11 AM](https://user-images.githubusercontent.com/1156625/212326189-214fb8b2-e210-4c96-8b52-7000d5025148.png). If they choose to report a bug, they'll be presented with a form prompting for Hail version and log output.; ![Screen Shot 2023-01-13 at 8 01 46 AM](https://user-images.githubusercontent.com/1156625/212326274-affeaa80-adec-45c9-b436-73059c6fc841.png)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12595:554,log,log,554,https://hail.is,https://github.com/hail-is/hail/pull/12595,1,['log'],['log']
Testability,"I discovered this when I tried to run a vcf combiner pipeline. To me, this signals that we need better knowledge of where integration tests live and how to add to them.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5033#issuecomment-449468618:134,test,tests,134,https://hail.is,https://github.com/hail-is/hail/pull/5033#issuecomment-449468618,1,['test'],['tests']
Testability,"I do not know why but /etc triggers errors about:; ```; archive/tar: write too long; ```; Even though /etc is not very large (1.4MB). I suspect there is some symlink; or other nonsense which is breaking Kaniko. The solution, after much trial and error, was simple: copy over directories that do not; cause issues and copy only the necessary files out of etc. A mix of speculation and; binary search lead me to the conclusion that /etc/ld.so.* are the only files necessary; from /etc for python to run correctly. These files tell the kernel how to link python3.7; to the various libraries on which it depends (which live in lib and lib64). Anyway, I've tested that this image can build itself, so it should be good enough for; our purposes.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10399:652,test,tested,652,https://hail.is,https://github.com/hail-is/hail/pull/10399,1,['test'],['tested']
Testability,"I do not know why. ```; # k logs -l app=batch | head; INFO	| 2018-10-26 17:04:45,840 	| server.py 	| <module>:44 | REFRESH_INTERVAL_IN_SECONDS 300; INFO	| 2018-10-26 17:04:45,844 	| server.py 	| <module>:53 | instance_id = 168f090933ba4db4ac6ba8d0add8460d; INFO	| 2018-10-26 17:04:45,849 	| server.py 	| run_forever:416 | run_forever: run target kube_event_loop; INFO	| 2018-10-26 17:04:45,850 	| server.py 	| run_forever:416 | run_forever: run target polling_event_loop; INFO	| 2018-10-26 17:04:45,850 	| server.py 	| run_forever:416 | run_forever: run target flask_event_loop; * Serving Flask app ""batch"" (lazy loading); * Environment: production; WARNING: Do not use the development server in a production environment.; Use a production WSGI server instead.; * Debug mode: off; # k logs -l app=hail-ci | head; INFO	| 2018-10-26 16:47:18,826 	| environment.py 	| <module>:51 | BATCH_SERVER_URL http://batch.default; INFO	| 2018-10-26 16:47:18,827 	| environment.py 	| <module>:52 | SELF_HOSTNAME http://hail-ci; INFO	| 2018-10-26 16:47:18,827 	| environment.py 	| <module>:53 | REFRESH_INTERVAL_IN_SECONDS 60; INFO	| 2018-10-26 16:47:18,827 	| environment.py 	| <module>:54 | WATCHED_TARGETS [('hail-is/hail:master', True), ('hail-is/hail:0.1', True), ('hail-is/hail:bgen-changes', False), ('Nealelab/cloudtools:master', True)]; INFO	| 2018-10-26 16:47:18,827 	| environment.py 	| <module>:55 | INSTANCE_ID = ef1bb52a88dd49fb893869bf49063980; INFO	| 2018-10-26 16:47:18,827 	| environment.py 	| <module>:56 | CONTEXT = hail-ci-0-1; * Serving Flask app ""ci"" (lazy loading); * Environment: production; WARNING: Do not use the development server in a production environment.; Use a production WSGI server instead.; ```. This obviously causes issues because CI is still waiting for batch jobs to finish.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4653:28,log,logs,28,https://hail.is,https://github.com/hail-is/hail/issues/4653,2,['log'],['logs']
Testability,"I do not understand how this passed the PR tests, but this fix makes regenie not; use the metadata server to authenticate itself.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9390:43,test,tests,43,https://hail.is,https://github.com/hail-is/hail/pull/9390,1,['test'],['tests']
Testability,"I don't believe I have access to look at the test failures. If you let me know what failed, I'll do my best to fix it!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13129#issuecomment-1581212490:45,test,test,45,https://hail.is,https://github.com/hail-is/hail/pull/13129#issuecomment-1581212490,1,['test'],['test']
Testability,"I don't believe there were any glaring problems on the Spark 2 side, but some the Python tests on Spark 3 are failing, notably in `test/hail/linalg/test_linalg.py`. I can't quite diagnose the issue off the top of my head.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9524#issuecomment-701074089:89,test,tests,89,https://hail.is,https://github.com/hail-is/hail/pull/9524#issuecomment-701074089,2,['test'],"['test', 'tests']"
Testability,"I don't disagree. However, we need toString on (scalar) Type because they are used for error messages all over. MatrixTable used to have a bunch of separate types, now it just has a MatrixType. I think some error messages could now use the matrix type. Python also has some matrix type printing logic, these should probably get unified. Once I have printing for the user, it seemed easier to write a (admittedly small) parser than a separate to/from JSON. I admit, apart from user error messages, JSON is natural since that's what we're storing in the metadata file. Do you have a concrete suggestion? I'm not sure quite what to do that's better than this.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2825#issuecomment-362082473:295,log,logic,295,https://hail.is,https://github.com/hail-is/hail/pull/2825#issuecomment-362082473,1,['log'],['logic']
Testability,"I don't have evidence that it matters, feel like it would though. If it's out for now that's fine, I'll do a test on Friday if needed.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2040#issuecomment-319677861:109,test,test,109,https://hail.is,https://github.com/hail-is/hail/pull/2040#issuecomment-319677861,1,['test'],['test']
Testability,"I don't know how to test this works unless I can dev deploy to my own copy of CI that's running with the new changes. The issue I was seeing is the database step runs fine, but the new tables weren't actually created.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9249:20,test,test,20,https://hail.is,https://github.com/hail-is/hail/pull/9249,1,['test'],['test']
Testability,"I don't know the system or the test suite well any more. What parts of our system are not well tested by the automated tests?. No need for adoption, just review!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13372#issuecomment-1673676748:31,test,test,31,https://hail.is,https://github.com/hail-is/hail/pull/13372#issuecomment-1673676748,3,['test'],"['test', 'tested', 'tests']"
Testability,"I don't quite understand this. To take advantage of this, it seems like we need also parallelize the tests. Where's the test parallelism set? Can we get a performance comparison, e.g. this PR test vs master?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7022#issuecomment-529491736:101,test,tests,101,https://hail.is,https://github.com/hail-is/hail/pull/7022#issuecomment-529491736,3,['test'],"['test', 'tests']"
Testability,"I don't see an assert in the linked code. Either way, I'll try to look at this tonight or after my talk in the morning.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5435#issuecomment-467652863:15,assert,assert,15,https://hail.is,https://github.com/hail-is/hail/pull/5435#issuecomment-467652863,1,['assert'],['assert']
Testability,"I don't see the issue. ```scala; def stringSampleIds: IndexedSeq[String] = {; val colKeyTypes = typ.colKeyStruct.types; assert(colKeyTypes.length == 1 && colKeyTypes(0).isInstanceOf[TString], colKeyTypes.toSeq); val querier = typ.colType.query(typ.colKey(0)); colValues.value.map(querier(_).asInstanceOf[String]); }. def requireUniqueSamples(method: String) {; val dups = stringSampleIds.counter().filter(_._2 > 1).toArray; if (dups.nonEmpty); fatal(s""Method '$method' does not support duplicate column keys. Duplicates:"" +; s""\n @1"", dups.sortBy(-_._2).map { case (id, count) => s""""""($count) ""$id"""""""" }.truncatable(""\n "")); }; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6062#issuecomment-490088444:120,assert,assert,120,https://hail.is,https://github.com/hail-is/hail/issues/6062#issuecomment-490088444,1,['assert'],['assert']
Testability,"I don't think I need extra tests for the additional nonpreemptible pools because the service tests will do so. However, they won't use the highmem or highcpu pools. We can add tests for these, but it will add additional time to the batch tests. We might want to split the batch tests up more in that case. On second thought, maybe it would be good to specifically have tests for these inside the batch module.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11594:27,test,tests,27,https://hail.is,https://github.com/hail-is/hail/pull/11594,6,['test'],['tests']
Testability,"I don't think it is bad to have both. They have two different use cases. I envisioned `head` as being a mechanism to test pipelines on small amounts of data. `take` seems to be useful if someone actually wants to look at each object in the first n rows of data. However, it does add extra methods to VariantDataset when `take` is equivalent to `head().collect()`. Thinking back to the group/ungroup discussion, we decided to add those methods even though they could be implemented by the user in expr. However, I think those operations were more complicated than `take`. I don't have strong feelings either way.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2204#issuecomment-328148402:117,test,test,117,https://hail.is,https://github.com/hail-is/hail/pull/2204#issuecomment-328148402,1,['test'],['test']
Testability,"I don't think so. The change is clearly fixes an issue and is an improvement. That said, write failures are rare and I just want to flush out any other rare errors so the tests are reliable.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10023#issuecomment-776868666:171,test,tests,171,https://hail.is,https://github.com/hail-is/hail/pull/10023#issuecomment-776868666,2,['test'],['tests']
Testability,I don't think these tests will pass. I'll address the issues when I come back from vacation. Feel free to reopen if you want.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10218#issuecomment-807414189:20,test,tests,20,https://hail.is,https://github.com/hail-is/hail/pull/10218#issuecomment-807414189,1,['test'],['tests']
Testability,I don't think we should hold up this PR for that. Benchmarks are run rarely and they should be setting their limits using PYSPARK_SUBMIT_ARGS anyway.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9076#issuecomment-664654683:50,Benchmark,Benchmarks,50,https://hail.is,https://github.com/hail-is/hail/pull/9076#issuecomment-664654683,1,['Benchmark'],['Benchmarks']
Testability,"I don't think we should merge this. This PR got a bit out of hand and then died when I changed focus to the query service. There are two distinct changes that I had hoped to unify: nicely rendered dev-docs *and* generated docs for gear, web_common, & hailtop. I got stuck after getting each one rendering OK but not integrated with one another. I also never got to dynamic rendering of the header (i.e. logged in users see batch > batches, etc.). The first thing you should check out are the rendered library docs:; ```; (cd docs && make html && (cd build/html && python3 -m http.server)); # now navigate to http://localhost:8000/; ```; You'll notice the Hail CSS is missing a bunch of styles to make functions render nicely. Take a look at the generated HTML. Sphinx includes a few style tags that we should probably define. I also fixed a few docs issues. There are many more broken references to fix. ![Screen Shot 2021-02-09 at 11 07 34 PM](https://user-images.githubusercontent.com/106194/107463257-acb15280-6b2b-11eb-8a26-129697009ef8.png); ![Screen Shot 2021-02-09 at 11 07 50 PM](https://user-images.githubusercontent.com/106194/107463256-acb15280-6b2b-11eb-82ff-48b6d83f2f0f.png). Now you should check out the rendered dev docs:; ```; (cd site && make render && cd docs && python3 -m http.server); ```; ![Screen Shot 2021-02-09 at 11 11 07 PM](https://user-images.githubusercontent.com/106194/107463544-555fb200-6b2c-11eb-9b23-39f66f0f4b12.png); ![Screen Shot 2021-02-09 at 11 11 16 PM](https://user-images.githubusercontent.com/106194/107463545-555fb200-6b2c-11eb-9901-5af07effc814.png). ---. What's left to do?. 1. Make the header dynamic (i.e. logged-in users see their name, etc.)?; 2. Move the dev-docs and the python library docs into one location.; 3. Finish modifying `site` so that it hosts two servers: `hail.is` and `docs.hail.is`. `docs.hail.is` displays some landing page from which we can navigate to dev-docs or python library docs.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10027:403,log,logged,403,https://hail.is,https://github.com/hail-is/hail/pull/10027,2,['log'],"['logged', 'logged-in']"
Testability,"I don't understand how this PR can have the following test failures!. ```; =================================== FAILURES ===================================; ____________________________ Test.test_list_batches ____________________________. self = <test.test_batch.Test testMethod=test_list_batches>. def test_list_batches(self):; tag = secrets.token_urlsafe(64); b1 = self.client.create_batch(attributes={'tag': tag, 'name': 'b1'}); b1.create_job('alpine', ['sleep', '30']); b1.close(); ; b2 = self.client.create_batch(attributes={'tag': tag, 'name': 'b2'}); b2.create_job('alpine', ['echo', 'test']); b2.close(); ; def assert_batch_ids(expected, complete=None, success=None, attributes=None):; batches = self.client.list_batches(complete=complete, success=success, attributes=attributes); # list_batches returns all batches for all prev run tests; actual = set([batch.id for batch in batches]).intersection({b1.id, b2.id}); self.assertEqual(actual, expected); ; assert_batch_ids({b1.id, b2.id}, attributes={'tag': tag}); ; b2.wait(); ; > assert_batch_ids({b1.id}, complete=False, attributes={'tag': tag}). test/test_batch.py:93: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ; test/test_batch.py:87: in assert_batch_ids; self.assertEqual(actual, expected); E AssertionError: Items in the second set but not the first:; E 19; ________________________________ test_callback _________________________________. client = <batch.client.BatchClient object at 0x7f0d1363ee80>. def test_callback(client):; from flask import Flask, request; app = Flask('test-client'); output = []; ; @app.route('/test', methods=['POST']); def test():; output.append(request.get_json()); return Response(status=200); ; try:; server = ServerThread(app); server.start(); batch = client.create_batch(callback=server.url_for('/test')); head = batch.create_job('alpine:3.8', command=['echo', 'head']); left = batch.create_job('alpine:3.8', command=['echo', 'left'], parents=[head]); right = batch.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6260#issuecomment-498852506:54,test,test,54,https://hail.is,https://github.com/hail-is/hail/pull/6260#issuecomment-498852506,8,"['Test', 'assert', 'test']","['Test', 'assertEqual', 'test', 'testMethod', 'tests']"
Testability,"I don't understand why my code is causing timeouts, and only in that one test slice.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14391#issuecomment-2098885167:73,test,test,73,https://hail.is,https://github.com/hail-is/hail/pull/14391#issuecomment-2098885167,1,['test'],['test']
Testability,"I don't understand why the Python tests are failing yet. They are failing on master as well, and at least some of the errors are identical (NullPointerException in HailContext.apply). Scala tests are passing. Wondering if this is due to py4j version mismatch.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6083#issuecomment-493192123:34,test,tests,34,https://hail.is,https://github.com/hail-is/hail/pull/6083#issuecomment-493192123,2,['test'],['tests']
Testability,"I don't want to add a larger test to scala, since we're ripping it all out of scala soon. Currently this functionality isn't exposed to Python, and it should be tested when it's exposed.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2884#issuecomment-365378540:29,test,test,29,https://hail.is,https://github.com/hail-is/hail/pull/2884#issuecomment-365378540,2,['test'],"['test', 'tested']"
Testability,I double checked the test database.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9668#issuecomment-722676096:21,test,test,21,https://hail.is,https://github.com/hail-is/hail/pull/9668#issuecomment-722676096,1,['test'],['test']
Testability,I duplicated globals.py so I can get the tests going. I'll think about how to organize sharing between the client in the server. Might just be to install the client on the server image.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6423#issuecomment-504153212:41,test,tests,41,https://hail.is,https://github.com/hail-is/hail/pull/6423#issuecomment-504153212,1,['test'],['tests']
Testability,"I endorse such a feature! In the meantime, I think we now have a PR that restores job logs for new versions of Hail. Let's get it out to the users post-haste!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12941#issuecomment-1529980071:86,log,logs,86,https://hail.is,https://github.com/hail-is/hail/pull/12941#issuecomment-1529980071,1,['log'],['logs']
Testability,"I eventually found the command line below that worked. It would be helpful to update the Getting Started page to include any necessary command line --conf parameters. ` spark-submit --jars build/libs/hail-all-spark.jar --conf ""spark.driver.extraClassPath=file:///restricted/projectnb/genpro/github/hail/build/libs/hail-all-spark.jar"" --conf ""spark.executor.extraClassPath=file:////restricted/projectnb/genpro/github/hail/build/libs/hail-all-spark.jar"" --conf spark.kryo.registrator=is.hail.kryo.HailKryoRegistrator --py-files build/distributions/hail-python.zip --num-executors 6 test.py; `",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3342#issuecomment-380210064:580,test,test,580,https://hail.is,https://github.com/hail-is/hail/issues/3342#issuecomment-380210064,1,['test'],['test']
Testability,"I expect this to fail tests, then I'll go debug and fix up the IRs that serialize children.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5142#issuecomment-454423215:22,test,tests,22,https://hail.is,https://github.com/hail-is/hail/pull/5142#issuecomment-454423215,1,['test'],['tests']
Testability,"I feel like I probably ought to have more tests, but wasn't sure what else to include. I didn't want to make the `StreamLen` tests depend on the correctness of more complicated IR nodes like `StreamZip`",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8783#issuecomment-628105025:42,test,tests,42,https://hail.is,https://github.com/hail-is/hail/pull/8783#issuecomment-628105025,2,['test'],['tests']
Testability,"I feel pretty good about pc_relate at this point. It's stood up to interrogation on a few real world datasets. We have automated testing of it. I think it's still a tricky method to use if you don't understand the underlying assumptions (which are listed here, specifically the limitations of PC Relate's estimator for ""individual-specific allele frequency""). @cseed @tpoterba @jbloom22",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4411:129,test,testing,129,https://hail.is,https://github.com/hail-is/hail/pull/4411,1,['test'],['testing']
Testability,"I figured I'd make this PR while I try and figure out what is causing #2436. This PR fixes the problem. There's a new test for it. The code for the new aggregator is based on `TakeByAggregator`. The reason for having 36! versions of TakeBy is the seqOp types need to match up with the primitive types. Both annotation and Long have the second argument is a Long, so we can't add the seqOps to one class.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3805:118,test,test,118,https://hail.is,https://github.com/hail-is/hail/pull/3805,1,['test'],['test']
Testability,"I figured, noticed the double post :). ```; The exception in your above message is coming from the Apply node being inferred as a PVoid by your case _ => PVoid code. Writing the rule for the apply node should fix that.; ```. Right. It's just that I tried to write the rule, and quickly ran across the fact that Seq[IR] would be inferred such that the first IR had a different type from the 2nd or Nth. This is what I had written:. ```scala; case ApplySpecial(name, irs) => {; val it = irs.iterator; val head = it.next(); head.inferSetPType(env). while(it.hasNext) {; val value = it.next(). value.inferSetPType(env); assert(value.pType2 == head.pType2); }. head.pType2; }; ```. With the result in one case that `head.pType2` was bool, `value.pType2` was something else. Without a type union, it wasn't clear to me what to return. One possibility was that I shouldn't handle this node, so I started with that possibility, which I know understand isn't right. The other was that the implementation was wrong, and my first guess there is that one of the IRs dictates the type (say the first), the 2nd is that there is a simple precedence rule, the 3rd is that the type inference procedure has some branching logic over the collection.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6594#issuecomment-513007861:616,assert,assert,616,https://hail.is,https://github.com/hail-is/hail/pull/6594#issuecomment-513007861,4,"['assert', 'log']","['assert', 'logic']"
Testability,"I find it compelling that this fixed the downloads. But I'd also like to understand why this changed worked. I will approve it to see if it unblocks Lindo while we keep discussing. > We needed to await cancelled tasks to handle the error that was raised inside the task. Right. We want to cancel the task and wait for it to finish, but we don't want any exceptions to be raised out. Your code appears to do that, but so does the previous code. Nothing in the documentation for `asyncio.wait` indicates it will raise exceptions: https://docs.python.org/3/library/asyncio-task.html#asyncio.wait. I also tested a short example:. ```; import asyncio; import sys. async def foo():; try:; print('A'); await asyncio.sleep(5); print('B'); return 5; finally:; print(sys.exc_info()). async def async_main():; print('creating task...'); t = asyncio.ensure_future(foo()); # wait for foo to sleep; await asyncio.sleep(1). # cancel foo in sleep; print('cancelling task...'); t.cancel(). print('waiting for task...'); await asyncio.wait([t]). print('done.'). asyncio.run(async_main()); ```. which prints:. ```; $ python3 foo.py; creating task...; A; cancelling task...; waiting for task...; (<class 'concurrent.futures._base.CancelledError'>, CancelledError(), <traceback object at 0x7f8cdef65e10>); done.; ```. The task is cancelled, and CancelledError is raised, but not propagated out. > 75% of his jobs would fail with this error. I'm actually confused where the cancellation error is coming from in the first place. If the code you're changing is the issue (and I think it is, too) then we only cancel if some other exception was raised, either by a task or in `__aexit__`. What's that exception? Can we print it out (enable more logging) in your test setup?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10534#issuecomment-853115655:601,test,tested,601,https://hail.is,https://github.com/hail-is/hail/pull/10534#issuecomment-853115655,3,"['log', 'test']","['logging', 'test', 'tested']"
Testability,"I fixed that last thing, I will add benchmark comment when I have it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1457#issuecomment-286524152:36,benchmark,benchmark,36,https://hail.is,https://github.com/hail-is/hail/pull/1457#issuecomment-286524152,1,['benchmark'],['benchmark']
Testability,I fixed the failing test by merging in #8142. This will have to wait for that to go in.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8156#issuecomment-594161055:20,test,test,20,https://hail.is,https://github.com/hail-is/hail/pull/8156#issuecomment-594161055,1,['test'],['test']
Testability,I followed the rabbit hole form https://github.com/hail-is/hail/pull/7922 and was a bit concerned that we weren't verifying the stream met our expectations. I don't think we need to handle errors more gracefully (these assertions should only fail on malformed files).,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7932:219,assert,assertions,219,https://hail.is,https://github.com/hail-is/hail/pull/7932,1,['assert'],['assertions']
Testability,"I forget why I added this, but I came across something in; Uniroot that either was not or made me think that Uniroot; was not strict in max and min, so I added a test.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3776:162,test,test,162,https://hail.is,https://github.com/hail-is/hail/pull/3776,1,['test'],['test']
Testability,"I forgot that we still had cron jobs running gcr-cleaner daily. This could have been conflicting with the new cleanup policy deletion settings. Let's reopen if this occurs again. Posting the job configurations here before I delete the jobs. ```; {""repos"":[""us-docker.pkg.dev/hail-vdc/hail/auth"",""us-docker.pkg.dev/hail-vdc/hail/base"",""us-docker.pkg.dev/hail-vdc/hail/base_spark_3_2"",""us-docker.pkg.dev/hail-vdc/hail/batch"",""us-docker.pkg.dev/hail-vdc/hail/batch-driver-nginx"",""us-docker.pkg.dev/hail-vdc/hail/batch-worker"",""us-docker.pkg.dev/hail-vdc/hail/benchmark"",""us-docker.pkg.dev/hail-vdc/hail/blog_nginx"",""us-docker.pkg.dev/hail-vdc/hail/ci"",""us-docker.pkg.dev/hail-vdc/hail/ci-intermediate"",""us-docker.pkg.dev/hail-vdc/hail/ci-utils"",""us-docker.pkg.dev/hail-vdc/hail/create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/echo"",""us-docker.pkg.dev/hail-vdc/hail/grafana"",""us-docker.pkg.dev/hail-vdc/hail/hail-base"",""us-docker.pkg.dev/hail-vdc/hail/hail-build"",""us-docker.pkg.dev/hail-vdc/hail/hail-buildkit"",""us-docker.pkg.dev/hail-vdc/hail/hail-run"",""us-docker.pkg.dev/hail-vdc/hail/hail-run-tests"",""us-docker.pkg.dev/hail-vdc/hail/hail-pip-installed-python37"",""us-docker.pkg.dev/hail-vdc/hail/hail-pip-installed-python38"",""us-docker.pkg.dev/hail-vdc/hail/hail-ubuntu"",""us-docker.pkg.dev/hail-vdc/hail/memory"",""us-docker.pkg.dev/hail-vdc/hail/monitoring"",""us-docker.pkg.dev/hail-vdc/hail/notebook"",""us-docker.pkg.dev/hail-vdc/hail/notebook_nginx"",""us-docker.pkg.dev/hail-vdc/hail/prometheus"",""us-docker.pkg.dev/hail-vdc/hail/service-base"",""us-docker.pkg.dev/hail-vdc/hail/service-java-run-base"",""us-docker.pkg.dev/hail-vdc/hail/test-ci"",""us-docker.pkg.dev/hail-vdc/hail/test-monitoring"",""us-docker.pkg.dev/hail-vdc/hail/test-benchmark"",""us-docker.pkg.dev/hail-vdc/hail/test_hello_create_certs_image"",""us-docker.pkg.dev/hail-vdc/hail/website"",""us-docker.pkg.dev/hail-vdc/hail/ci-hello"",""us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep-grch37-85"",""us-docker.pkg.dev/hail-vdc/hail/hailgenetics/vep",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13603#issuecomment-1734249545:556,benchmark,benchmark,556,https://hail.is,https://github.com/hail-is/hail/issues/13603#issuecomment-1734249545,1,['benchmark'],['benchmark']
Testability,I forgot the Java tests were split in the same way as the batch tests and had forgot to add the new env variable in each split.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10807#issuecomment-905458230:18,test,tests,18,https://hail.is,https://github.com/hail-is/hail/pull/10807#issuecomment-905458230,2,['test'],['tests']
Testability,"I forgot to add the restructured text files to the new doctest framework, so right now they aren't being tested. This fix will test the python commands in all of the `.rst` files in `python/hail`. Also, I removed the obsolete doctest directive strings `.. doctest::` and `.. testsetup::`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3703:105,test,tested,105,https://hail.is,https://github.com/hail-is/hail/pull/3703,3,['test'],"['test', 'tested', 'testsetup']"
Testability,I forgot to check in the tests for #12901. I found them on my filesystem today while cleaning up untracked files.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13005:25,test,tests,25,https://hail.is,https://github.com/hail-is/hail/pull/13005,1,['test'],['tests']
Testability,"I found this logging helpful but not noisy. The blockSize change; is inspired by @rcownie. It means that things that take half or more of the block will get a custom block, rather than possibly having a block half-occupied with something big and not have a lot of room for new stuff. (At least, that's my understanding of the rational)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3777:13,log,logging,13,https://hail.is,https://github.com/hail-is/hail/pull/3777,1,['log'],['logging']
Testability,"I got `Aggregators2Suite.testTakeBy` to pass, so we're probably good?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8671#issuecomment-622046822:25,test,testTakeBy,25,https://hail.is,https://github.com/hail-is/hail/pull/8671#issuecomment-622046822,1,['test'],['testTakeBy']
Testability,"I got an email saying the activity logs are no longer supported after September 30th. Here's the [migration instructions](https://cloud.google.com/compute/docs/logging/migrating-from-activity-logs-to-audit-logs#log_entry_field_mappings). I figured out how to map the fields mostly by trial and error looking at the JSON for an event. The only thing that didn't map at all was the operationType. I hardcoded that as 'insert'. There are different event_subtype names such as 'v1.compute.instances.insert' or 'beta.compute.instances.insert'. So I did what they suggested and looked for a partial match such as 'compute.instances.insert'. I can send you the full JSON for the events if you want to double check anything. I also double checked that the activity logs aren't used anywhere else in the repo, but it might be good for you to confirm that since you wrote a lot of this.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9439:35,log,logs,35,https://hail.is,https://github.com/hail-is/hail/pull/9439,4,['log'],"['logging', 'logs', 'logs-to-audit-logs']"
Testability,"I got sick of having things fail without sufficient debug information. This ensures; that the batch status and every job status and log is presented, untruncated, in; the assertion message from pylint.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10953:132,log,log,132,https://hail.is,https://github.com/hail-is/hail/pull/10953,2,"['assert', 'log']","['assertion', 'log']"
Testability,I got the error message while importing VCFs in dataflow01. `hail -l /medpop/afib/schoi/projects/TOPMed/Script/log/TopMed.Chr22.QC.vds.test.log \; importvcf file:///medpop/afib/schoi/projects/TOPMed/Data/BROAD/Link/Chr22/TopMed_8k.853.vcf.bgz \ splitmulti \; write -o TOPMed.6998.chr22.vds`. `[Stage 0:====================================================> (52 + 4) / 56]hail: info: Ordering unsorted dataset with network shuffle; hail: importvcf: caught exception: java.lang.ClassCastException: java.lang.Long cannot be cast to java.lang.Integer; at scala.runtime.BoxesRunTime.unboxToInt(BoxesRunTime.java:106); at org.apache.spark.rdd.OrderedRDD$$anonfun$calculateKeyRanges$1.apply(OrderedRDD.scala:143); at org.apache.spark.rdd.OrderedRDD$$anonfun$calculateKeyRanges$1.apply(OrderedRDD.scala:142); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:108); at org.apache.spark.rdd.OrderedRDD$.calculateKeyRanges(OrderedRDD.scala:142); at org.apache.spark.rdd.OrderedRDD$.apply(OrderedRDD.scala:117); at org.broadinstitute.hail.RichPairRDD$.toOrderedRDD$extension(Utils.scala:482); at org.broadinstitute.hail.io.vcf.LoadVCF$.apply(LoadVCF.scala:267); at org.broadinstitute.hail.driver.ImportVCF$.run(ImportVCF.scala:85); at org.broadinstitute.hail.driver.ImportVCF$.run(ImportVCF.scala:31); at org.broadinstitute.hail.driver.Command.runCommand(Command.scala:239); at org.broadinstitute.hail.driver.Main$.runCommand(Main.scala:120); at org.broadinstitute.hail.driver.Main$$anonfun$runCommands$1$$anonfun$1.apply(Main.scala:144); at org.broadinstitute.hail.driver.Main$$anonfun$runCommands$1$$anonfun$1.apply(Main.scala:144); at org.broadinstitute.hail.Utils$.time(Utils.scala:1282); at org.broadinstitute.hail.driver.Main$$anonfun$runCommands$1.apply(Main.scala:143); at org.broadinstitute.hail.driver.Main$$anonfun$runCommands$1.apply(Main.scala:137); at scala.collection.IndexedSeqOptimized$class.fold,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/669:111,log,log,111,https://hail.is,https://github.com/hail-is/hail/issues/669,3,"['log', 'test']","['log', 'test']"
Testability,"I gotta figure out how to write tests for this, but I've pushed so that Ally can take a look.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12768#issuecomment-1458962137:32,test,tests,32,https://hail.is,https://github.com/hail-is/hail/pull/12768#issuecomment-1458962137,1,['test'],['tests']
Testability,"I guess it depends whether you want up to date or just compatible, the maintainers seem to be of the opinion that you should either always update the lock file immediately or set upper bounds if you're not ok with a certain upgrade, seen [here](https://github.com/jazzband/pip-tools/issues/882). Continuous work, but maybe the right way to go honestly. In that case trivially make a build.yaml step that asserts the lock file is valid and up to date.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11842#issuecomment-1131859471:404,assert,asserts,404,https://hail.is,https://github.com/hail-is/hail/pull/11842#issuecomment-1131859471,1,['assert'],['asserts']
Testability,I guess the design of the whole artifacts system doesn't really account for anything but hail/hail. We need to fix up the index page to account for other projects and add another level of testing indirection,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4514#issuecomment-428563325:188,test,testing,188,https://hail.is,https://github.com/hail-is/hail/issues/4514#issuecomment-428563325,1,['test'],['testing']
Testability,"I had a brief worry that the key distinctness analysis didn't handle missing keys correctly, so I added some tests. It does seem to work so that's good.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11263:109,test,tests,109,https://hail.is,https://github.com/hail-is/hail/pull/11263,1,['test'],['tests']
Testability,"I had a choice on how to implement this and I decided to add a JobTask class that takes care of a single pod and the Job changes to just be a manager of the pods. However, I could have done it all within the Job if you think that is clearer. Happy to refactor if needed. Please look and see if I have enough tests. The tests are passing, but I'm getting this error message. Is this expected or a bug in my code? . ```; INFO	| 2019-02-22 11:48:48,126 	| _internal.py 	| _log:87 | 127.0.0.1 - - [22/Feb/2019 11:48:48] ""POST /pod_changed HTTP/1.1"" 204 -; INFO	| 2019-02-22 11:48:48,210 	| _internal.py 	| _log:87 | 127.0.0.1 - - [22/Feb/2019 11:48:48] ""POST /pod_changed HTTP/1.1"" 204 -; INFO	| 2019-02-22 11:48:48,833 	| server.py 	| mark_complete:190 | wrote log for job 61, main task to logs/job-61-main.log; INFO	| 2019-02-22 11:48:48,845 	| server.py 	| set_state:272 | job 61 changed state: Created -> Complete; INFO	| 2019-02-22 11:48:48,851 	| server.py 	| parent_new_state:287 | parent 61 successfully complete for 63; INFO	| 2019-02-22 11:48:48,857 	| server.py 	| parent_new_state:292 | all parents successfully complete for 63, creating pod; INFO	| 2019-02-22 11:48:48,918 	| server.py 	| create_pod:135 | created pod name: job-63-main-qqwb2 for job 63, main task; INFO	| 2019-02-22 11:48:48,929 	| server.py 	| mark_complete:330 | job 61 complete, exit_code 0; INFO	| 2019-02-22 11:48:48,995 	| _internal.py 	| _log:87 | 127.0.0.1 - - [22/Feb/2019 11:48:48] ""POST /pod_changed HTTP/1.1"" 204 -; [2019-02-22 11:48:49,043] ERROR in app: Exception on /test [POST]; Traceback (most recent call last):; File ""//anaconda/envs/hail-batch/lib/python3.6/site-packages/flask/app.py"", line 1982, in wsgi_app; response = self.full_dispatch_request(); File ""//anaconda/envs/hail-batch/lib/python3.6/site-packages/flask/app.py"", line 1615, in full_dispatch_request; return self.finalize_request(rv); File ""//anaconda/envs/hail-batch/lib/python3.6/site-packages/flask/app.py"", line 1630, in finalize_request",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5418:308,test,tests,308,https://hail.is,https://github.com/hail-is/hail/pull/5418,5,"['log', 'test']","['log', 'logs', 'tests']"
Testability,I had done this a while ago in a throwaway after talking to Tim. This causes more failures than just the new test that I added. I'm at a loss for how to proceed.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4585#issuecomment-434111128:109,test,test,109,https://hail.is,https://github.com/hail-is/hail/pull/4585#issuecomment-434111128,1,['test'],['test']
Testability,I had to add `TrivialContext` which is just a dummy context for when I'm not really using regions. I guess I could also add tests that use the context in some meaningful way. The tension is that the context-using-functionality should already be tested via MatrixTable and Table.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3310#issuecomment-379903357:124,test,tests,124,https://hail.is,https://github.com/hail-is/hail/pull/3310#issuecomment-379903357,2,['test'],"['tested', 'tests']"
Testability,I had to change the delete log test in my SQL branch because I changed the meaning of delete. I haven't had problems with that test previously. The only one I have problems with is `test_callback`. I ran `test_callback` 100 times and it seems like it failed approx 2 times locally. So that's going to be a pain to figure out if I can't make it happen more often...,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5852#issuecomment-481823759:27,log,log,27,https://hail.is,https://github.com/hail-is/hail/pull/5852#issuecomment-481823759,3,"['log', 'test']","['log', 'test']"
Testability,I had to fix the tests to test equality rather than the expected set itself.; https://docs.python.org/3.5/library/doctest.html#warnings,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6028#issuecomment-491035884:17,test,tests,17,https://hail.is,https://github.com/hail-is/hail/pull/6028#issuecomment-491035884,2,['test'],"['test', 'tests']"
Testability,"I had to make a few changes to CI to make it test against a local version of the latest batch. Long term, we'll actually deploy batch and CI into a fresh namespace to do testing. For now, we explicitly start batch in the test container for CI to test against.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4930#issuecomment-446008184:45,test,test,45,https://hail.is,https://github.com/hail-is/hail/pull/4930#issuecomment-446008184,4,['test'],"['test', 'testing']"
Testability,I had to merge https://github.com/hail-is/hail/pull/11589 into this one to pass all the tests,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11599#issuecomment-1073060172:88,test,tests,88,https://hail.is,https://github.com/hail-is/hail/pull/11599#issuecomment-1073060172,1,['test'],['tests']
Testability,"I had to remove the ui tests for now. The ui is protected by a session ID in the aiohttp session cookie (not the auth header I was trying to use), and I need a bit more infrastructure to cook up a valid one of those in the tests.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7270#issuecomment-541263068:23,test,tests,23,https://hail.is,https://github.com/hail-is/hail/pull/7270#issuecomment-541263068,2,['test'],['tests']
Testability,"I ham fingered the name of the credentials. Unfortunately, PR tests do not test the deployment script.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4266:62,test,tests,62,https://hail.is,https://github.com/hail-is/hail/pull/4266,2,['test'],"['test', 'tests']"
Testability,I hand-tested the UI and everything looks good.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7606#issuecomment-557902950:7,test,tested,7,https://hail.is,https://github.com/hail-is/hail/pull/7606#issuecomment-557902950,1,['test'],['tested']
Testability,"I have a branch where I've upgraded the dependency to libsimdpp-2.1 and resolved issues around depreciation warnings, this does solve the issue. We would need to discuss if we want to upgrade the dependency, and benchmark against the new version to see if it causes any performance regression. Branch is [here](https://github.com/chrisvittal/hail/tree/libsimdpp-2.1)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3955#issuecomment-406297780:212,benchmark,benchmark,212,https://hail.is,https://github.com/hail-is/hail/issues/3955#issuecomment-406297780,1,['benchmark'],['benchmark']
Testability,"I have a fix for this. We shouldn't run these tests in production. I added the `pytest.mark.test_scope_only`. Then I added this flag to the existing test_batch_* jobs: `-m ""not test_scope_only""`. Finally, I added a new step that just runs those tests in the test and dev scopes. `-m ""test_scope_only""` with. ```; + scopes:; + - dev; + - test; ```. If you're okay with this strategy, I'll make a separate PR so that we can both use this in our respective PRs. Can you also make a separate PR for the `_token_file` change and having the dev and regular client?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9553#issuecomment-705604419:46,test,tests,46,https://hail.is,https://github.com/hail-is/hail/pull/9553#issuecomment-705604419,4,['test'],"['test', 'tests']"
Testability,I have a follow-up PR that ~halves the run-time of the service backend tests: https://github.com/hail-is/hail/pull/11212,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11194#issuecomment-1015479543:71,test,tests,71,https://hail.is,https://github.com/hail-is/hail/pull/11194#issuecomment-1015479543,1,['test'],['tests']
Testability,"I have a implemented a highly concurrent Python asyncio filesystem that supports GCS and the local file system (and soon S3). It is my intention to ultimately replace the hadoop_* functions with this. The new thing feels pretty fast: copy benchmarks 2-5x faster than gsutil for example, esp. when working with lots of files. Some remarks:; - It is designed to do the minimal number of system calls/API calls per operation so there is serial loops like this anywhere in the code.; - Our short term goal is to use this for the input/output steps in Batch.; - It doesn't support Hadoop (and I'm not super exciting about maintaining that).; - Some things will be much faster because no round trip the JVM. ; - The interface is fully async, so we'll need to build some wrappers if you want a synchronous interface. The async interface will get you concurrency within operations (copy, rmtree), the sync interface only gets you currency within operations.; - The list files operation doesn't support globbing yet.; - There are no docs yet.; - Compared to Hadoop/POSIX, the interface is slightly lower level but it was designed to map well onto the filesystems we want to support. There is no `stat`, for example, but is statfile (which requires the input to be a file) and listfiles (which requires it to be a directory), although we could build that.; - I'd say the code is beta and not quite completely solid but getting close. Here is the AsyncFS interface: https://github.com/hail-is/hail/blob/main/hail/python/hailtop/aiotools/fs.py#L70. Here is an example creating a router filesystem that supports GCS and the local file system: https://github.com/hail-is/hail/blob/main/hail/python/test/hailtop/test_aiogoogle.py#L17. I'd be happy to chat more about what would make this attractive for you guys to switch to.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10043#issuecomment-778364838:239,benchmark,benchmarks,239,https://hail.is,https://github.com/hail-is/hail/pull/10043#issuecomment-778364838,2,"['benchmark', 'test']","['benchmarks', 'test']"
Testability,"I have added the examples and just created the pull request so I am working off that branch, but it has not been tested yet.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11394:113,test,tested,113,https://hail.is,https://github.com/hail-is/hail/pull/11394,1,['test'],['tested']
Testability,"I have an RFC proposal to just handle the ambiguity: https://github.com/hail-is/hail-rfcs/blob/main/rfc/0008-handle-vcf-array-field-ambiguity. I proposed a PR to fix this: https://github.com/hail-is/hail/pull/13465 However, I missed a key issue: many VCF's *elide* fields to indicate missingness. That is not ambiguous: a field that is entirely elided is clearly missing, not an array of one missing value. You can't do this in a FORMAT (aka entry aka genotype) field, but you can do this in an INFO field a la:; ```; ##fileformat=VCFv4.2; ##INFO=<ID=AC,Number=A,Type=Integer,Description=""Allele count in genotypes, for each ALT allele, in the same order as listed"">; ##INFO=<ID=NUMS,Number=*,Type=Float,Description=""some numbers"">; ##INFO=<ID=AN,Number=1,Type=Integer,Description=""Total number of alleles in called genotypes"">; #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT ...; ... AC=1,1;AN=1 ...; ```; the `NUMS` field should be read as missing. My PR considered it unacceptably ambiguous because it thought it had been `NUMS=.`. I don't think we can fix this problem entirely from Python. We need to use Scala-side logic because after we parse in Scala, we lose the knowledge that a field was entirely elided versus a single missing dot.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13346#issuecomment-1773555545:1120,log,logic,1120,https://hail.is,https://github.com/hail-is/hail/issues/13346#issuecomment-1773555545,2,['log'],['logic']
Testability,"I have build hail ,using ""gradle installDist"", the ""./hail -h"" can display:. [root@**\* bin]# ./hail -h; usage: hail [global options] <cmd1> [cmd1 args]; [<cmd2> [cmd2 args] ... <cmdN> [cmdN args]]. But ,When excuting “gradle check” and ""gradle coverage"", encounter ""100 tests completed, 3 failed :test FAILED"" ""Build FAILED"" , how to fix ? Thanks . [root@**\* hail]# gradle check; Using a seed of [1] for testing.; Build file '*****/hail/build.gradle': line 188; useAnt has been deprecated and is scheduled to be removed in Gradle 3.0. The Ant-Based Scala compiler is deprecated, please see https://docs.gradle.org/current/userguide/scala_plugin.html.; :compileJava UP-TO-DATE; :compileScala UP-TO-DATE; :processResources UP-TO-DATE; :classes UP-TO-DATE; :compileTestJava UP-TO-DATE; :compileTestScala UP-TO-DATE; :processTestResources UP-TO-DATE; :testClasses UP-TO-DATE; :test. ........... FAILED; Gradle suite > Gradle test > org.broadinstitute.hail.methods.ExportPlinkSuite.testBiallelic FAILED; java.io.FileNotFoundException at ExportPlinkSuite.scala:17; Running test: Test method test(org.broadinstitute.hail.methods.ExportSuite); ........... FAILED; Gradle suite > Gradle test > org.broadinstitute.hail.driver.GRMSuite.test FAILED; java.io.FileNotFoundException at GRMSuite.scala:20; Running test: Test method testGenotypeStream(org.broadinstitute.hail.variant.GenotypeStreamSuite); ........... FAILED; Gradle suite > Gradle test > org.broadinstitute.hail.methods.ImputeSexSuite.testImputeSexPlinkVersion FAILED; java.io.FileNotFoundException at ImputeSexSuite.scala:17; Running test: Test method test(org.broadinstitute.hail.variant.IntervalListSuite). ..........; 100 tests completed, 3 failed; :test FAILED. FAILURE: Build failed with an exception.; - What went wrong:; Execution failed for task ':test'.; ; > There were failing tests. See the report at: file:///****/hail/build/reports/tests/index.html; - Try:; Run with --stacktrace option to get the stack trace. Run with --info or --deb",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/457:271,test,tests,271,https://hail.is,https://github.com/hail-is/hail/issues/457,7,['test'],"['test', 'testBiallelic', 'testClasses', 'testing', 'tests']"
Testability,"I have commit `a451e1aaa5d1dd4cc055f8e7c1e261aa59eabeca`, I built the jar as `cd hail && ./gradlew shadowJar`. I have this file:; ```; (foo) # cat /tmp/failure.R ; data(mtcars); hail_jar <- ""/Users/bking/projects/hail/hail/build/libs/hail-all-spark.jar""; classpath_vars <-; c(spark.driver.extraClassPath=paste(hail_jar, collapse=.Platform$path.sep),; spark.executor.extraClassPath=paste(basename(hail_jar),; collapse=.Platform$path.sep)); config <- list(sparklyr.jars.default=hail_jar,; sparklyr.shell.conf=paste0(names(classpath_vars), ""='"",; classpath_vars, ""'""),; spark.serializer=""org.apache.spark.serializer.KryoSerializer"",; spark.kryo.registrator=""is.hail.kryo.HailKryoRegistrator""); sc <- sparklyr::spark_connect(""local"", version=""2.2.0"", config=config); sdf <- sparklyr::spark_dataframe(dplyr::copy_to(sc, mtcars)); hc <- sparklyr::invoke_static(sc, ""is.hail.HailContext"", ""apply"",; sparklyr::spark_context(sc), ""Hail"", NULL,; ""local[*]"", ""hail.log"", TRUE, FALSE, 1L, 50L,; tempdir()); keys <- sparklyr:::invoke_static(sc, ""is.hail.utils"", ""arrayToArrayList"",; array(character(0L))); ht <- sparklyr::invoke_static(sc, ""is.hail.table.Table"", ""fromDF"", hc, sdf,; keys); sessionInfo(); sparklyr::invoke(ht, ""count""); ```. it generates this output:; ```; (foo) # Rscript /tmp/failure.R; R version 3.5.1 (2018-07-02); Platform: x86_64-apple-darwin17.6.0 (64-bit); Running under: macOS High Sierra 10.13.6. Matrix products: default; BLAS: /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib; LAPACK: /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libLAPACK.dylib. locale:; [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8. attached base packages:; [1] stats graphics grDevices utils datasets methods base . loaded via a namespace (and not attached):; [1] Rcpp_0.12.19 dbplyr_1.2.2 compiler_3.5.1 pillar_1.3.0 ; [5] later_0.7.5 bindr_0.1.1 r2d3_0.2.2 base64enc_0.1-3 ; [9",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4513#issuecomment-430702977:954,log,log,954,https://hail.is,https://github.com/hail-is/hail/issues/4513#issuecomment-430702977,1,['log'],['log']
Testability,"I have core tests in place and would appreciate feedback on more exotic tests to add. There are similarities between `buildSampleAggregations` and `makeSampleFunctions` in Aggregators but differences throughout as well, so I'm not sure how hard to push on pulling out elements.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1708:12,test,tests,12,https://hail.is,https://github.com/hail-is/hail/pull/1708,2,['test'],['tests']
Testability,"I have forthcoming changes that make the router only accept HTTPS. I've been testing this in my dev namespace. Unfortunately, my batch workers cannot speak to my batch instance anymore. The workers speak to internal-gateway who then tries to proxy to my router over HTTP, but nobody is listening on that port. As long as there is a mix of HTTP-only and HTTPS-only routers, internal-gateway needs a way to know which protocol to use with which router. It's temporary because I intend everyone to speak HTTPS.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8490#issuecomment-610644390:77,test,testing,77,https://hail.is,https://github.com/hail-is/hail/pull/8490#issuecomment-610644390,1,['test'],['testing']
Testability,I have no idea how to test this. Any ideas @danking @cseed?. I should also disable the button after a successful request goes through.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6261:22,test,test,22,https://hail.is,https://github.com/hail-is/hail/pull/6261,1,['test'],['test']
Testability,"I have no idea what this means. ```; Caused by: is.hail.shadedazure.com.azure.storage.blob.models.BlobStorageException: If you are using a StorageSharedKeyCredential, and the server returned an error message that says 'Signature did not match', you can compare the string to sign with the one generated by the SDK. To log the string to sign, pass in the context key value pair 'Azure-Storage-Log-String-To-Sign': true to the appropriate method call.; If you are using a SAS token, and the server returned an error message that says 'Signature did not match', you can compare the string to sign with the one generated by the SDK. To log the string to sign, pass in the context key value pair 'Azure-Storage-Log-String-To-Sign': true to the appropriate generateSas method call.; Please remember to disable 'Azure-Storage-Log-String-To-Sign' before going to production as this string can potentially contain PII.; Status code 403, (empty body); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13032#issuecomment-1542906073:318,log,log,318,https://hail.is,https://github.com/hail-is/hail/pull/13032#issuecomment-1542906073,5,"['Log', 'log']","['Log-String-To-Sign', 'log']"
Testability,"I have no idea why we were skipping this test, but it was not a good idea to skip it, as the example was incorrect. We can't use `**split_ds.info` because that will contain `AC`, and so we will be trying to make a struct with two fields called `AC`. . I also replaced `vds` with `mt`, which we should do pervasively everywhere at some point.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9687:41,test,test,41,https://hail.is,https://github.com/hail-is/hail/pull/9687,1,['test'],['test']
Testability,"I have not tested this, though I faithfully copied the commands from existing; deploy scripts (except for creating a github release). A change that I think is valuable regardless of automation is the conversion of; deploy from a series of Makefile targets to a bash script. I also add a deploy build.yaml step which simply calls the deploy script,; setting up appropriate credentials. I only had to add one set of credentials: the PyPI credentials. I've already; created that secret in the cluster. Hand deploys are still very easy. You need curl >=7.55.0 (that version; implemented reading headers from a file). You need to set up two things:; 1. create $HOME/.pypirc and put this there:; ```; [pypi]; username: hailteam; password: GET_THIS_FROM_THE_USUAL_PLACE; ```; 2. get a github access token with repo; privileges (https://github.com/settings/tokens), create; $HOME/.github-oauth-header, and put this there:; ```; Authorization: token YOUR_ACCESS_TOKEN_HERE; ```; Now, to do a hand deploy run:; ```; make deploy GITHUB_OAUTH_HEADER_FILE=$HOME/.github-oauth-header DEPLOY_REMOTE=THE_REMOTE_FOR_hail-is/hail; ```. The github credentials are used to create a GitHub release.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8533:11,test,tested,11,https://hail.is,https://github.com/hail-is/hail/pull/8533,1,['test'],['tested']
Testability,I have on my list to test Nirvana but need a couple days so let's get it in now.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5835#issuecomment-481736843:21,test,test,21,https://hail.is,https://github.com/hail-is/hail/pull/5835#issuecomment-481736843,1,['test'],['test']
Testability,I have one thing left to do: I need to rebuild pr-builder because the apiserver test depends on Flask. I'll do that shortly. Rest of it is ready for review.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5386#issuecomment-466480945:80,test,test,80,https://hail.is,https://github.com/hail-is/hail/pull/5386#issuecomment-466480945,1,['test'],['test']
Testability,"I have the FET in the expr language done. Also in this branch is the linear regression code refactoring. I removed the docs for the group tests, but left the code for creating groups and the FET and linear regression group tests in this branch.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/423#issuecomment-226914280:138,test,tests,138,https://hail.is,https://github.com/hail-is/hail/pull/423#issuecomment-226914280,2,['test'],['tests']
Testability,"I have the dry-run flag on as default just to test it first. Then I just manually removed that line to actually delete things. I think we could potentially make this nicer with a flag, but I'm not sure how to do that easily.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12444:46,test,test,46,https://hail.is,https://github.com/hail-is/hail/pull/12444,1,['test'],['test']
Testability,"I have this up for right now to see if this decreases service backend test times at all. Right now, we could be waiting up to 45 seconds per batch to complete if we get unlucky on the exponential backoff. I changed it to have the same behavior as the Scala service backend.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13177:70,test,test,70,https://hail.is,https://github.com/hail-is/hail/pull/13177,1,['test'],['test']
Testability,"I have to add some tests, but where I got hung up on this a few months ago is that it created a ton of code duplication that I wasn't sure how to abstract away",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7795#issuecomment-570321116:19,test,tests,19,https://hail.is,https://github.com/hail-is/hail/pull/7795#issuecomment-570321116,1,['test'],['tests']
Testability,I have yet to successfully create a VCF that doesn't hit another error before hitting this one. But user hit this here: https://discuss.hail.is/t/assertionerror-exception/1700,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9494:146,assert,assertionerror-exception,146,https://hail.is,https://github.com/hail-is/hail/pull/9494,1,['assert'],['assertionerror-exception']
Testability,"I haven't checked for performance regressions. Tim, do you have a standard way of doing this? Given that you're on vacation tomorrow, @danking, could you help me understand your performance testing procedures?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5075#issuecomment-453376506:190,test,testing,190,https://hail.is,https://github.com/hail-is/hail/pull/5075#issuecomment-453376506,1,['test'],['testing']
Testability,"I haven't looked into it, but it looks like the libhail for cpp5 got built differently than the other prebuilt .so in a way that's incompatible with dataproc. If we rebuild it on a dataproc head node, for example, it should probably be good to go. Before we do that, I would like to see dataproc testing get set up ... which of course @danking is already on: https://github.com/hail-is/hail/pull/4241. Nice!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4240#issuecomment-417521786:296,test,testing,296,https://hail.is,https://github.com/hail-is/hail/pull/4240#issuecomment-417521786,1,['test'],['testing']
Testability,"I haven't read over this, but I don't like the behavior. Assert and friends are for unexpected errors, and fatal is for expected errors. How is abort different from assert?. All errors should give full JVM + Python stack traces. I see this necessary for two reasons: It makes it much easier for users to report bugs to us, which means they get faster turnaround and we spend less time going back and forth about log files (which usually were ephemeral or they've overwritten) and often ""expected"" bugs are actually correct behavior on the user's end and a bug on our side, but no context is given for us to diagnose the real problem. For usability, it is obviously best if the user-visible error appears at the bottom.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1552#issuecomment-287147990:57,Assert,Assert,57,https://hail.is,https://github.com/hail-is/hail/pull/1552#issuecomment-287147990,5,"['Assert', 'assert', 'log']","['Assert', 'assert', 'log']"
Testability,I haven't tested at all yet. Might have a catastrophic problem.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1558#issuecomment-287173180:10,test,tested,10,https://hail.is,https://github.com/hail-is/hail/pull/1558#issuecomment-287173180,1,['test'],['tested']
Testability,"I haven't tested it, but I think that should work",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7536#issuecomment-555197402:10,test,tested,10,https://hail.is,https://github.com/hail-is/hail/pull/7536#issuecomment-555197402,1,['test'],['tested']
Testability,I haven't tested the refactored code yet -- would like to see if this was the refactoring you had in mind with Enums.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13224#issuecomment-1664685352:10,test,tested,10,https://hail.is,https://github.com/hail-is/hail/pull/13224#issuecomment-1664685352,1,['test'],['tested']
Testability,"I haven't tested this error message, as I'm not sure how to replicate the bug scenario, but I think it should work.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11321#issuecomment-1031552946:10,test,tested,10,https://hail.is,https://github.com/hail-is/hail/pull/11321#issuecomment-1031552946,1,['test'],['tested']
Testability,"I haven't tested this yet because I wanted to see if you liked the idea. Not as flexible as a python loop, but possibly the easiest way to get rid of *a lot* of yaml.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11771:10,test,tested,10,https://hail.is,https://github.com/hail-is/hail/pull/11771,1,['test'],['tested']
Testability,I haven’t seen the callback test be flaky. I’m mildly concerned that it’s become flaky.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5563#issuecomment-473569649:28,test,test,28,https://hail.is,https://github.com/hail-is/hail/pull/5563#issuecomment-473569649,1,['test'],['test']
Testability,I hope I finally squashed this issue for good where cancelled jobs wouldn't have data to show in the UI. I apologize that the diff is not great for this change. I tested all 5 possible cases in the UI by hand.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11353:163,test,tested,163,https://hail.is,https://github.com/hail-is/hail/pull/11353,1,['test'],['tested']
Testability,"I hope this is the last one. Instead of assert (since the catch doesn't catch assertion errors), I just use an `if`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1383:40,assert,assert,40,https://hail.is,https://github.com/hail-is/hail/pull/1383,2,['assert'],"['assert', 'assertion']"
Testability,"I implemented Table.globals, too, and added a couple tests.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3027#issuecomment-369460837:53,test,tests,53,https://hail.is,https://github.com/hail-is/hail/pull/3027#issuecomment-369460837,1,['test'],['tests']
Testability,I implemented it in python and just moved filter entries to tests in scala,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3354#issuecomment-380560289:60,test,tests,60,https://hail.is,https://github.com/hail-is/hail/pull/3354#issuecomment-380560289,1,['test'],['tests']
Testability,I installed hail and finally everything went well without any missing package.; When I ran it to test it. It gave me the following error. Check the screen capture for more details.; `./build/install/hail/bin/hail \; importvcf src/test/resources/sample.vcf \; write -o ~/sample.vds`; ![error](https://cloud.githubusercontent.com/assets/2621305/22890051/0a0a737c-f203-11e6-84f1-aa51c8278ca5.png),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1377:97,test,test,97,https://hail.is,https://github.com/hail-is/hail/issues/1377,2,['test'],['test']
Testability,"I installed latest hail (0.2.120-f00f916faf78), gnomad (e6f042a74c91e462b77fca24d070c815e02f6f5b), and gnomad_qc (0c52cf47e48fa5b503d874e96482ea4286474c71). I cloned the repo in question; ```bash; pip3 uninstall hail gnomad gnomad_qc. pip3 install -U \; hail \; git+https://github.com/broadinstitute/gnomad_methods.git \; git+https://github.com/broadinstitute/gnomad_qc.git. git clone git@github.com:broadinstitute/gnomad-readviz.git; ```. I applied this patch:; ```diff; diff --git a/step1__select_samples.py b/step1__select_samples.py; index c159207..9ba1812 100644; --- a/step1__select_samples.py; +++ b/step1__select_samples.py; @@ -38,14 +38,7 @@ def hemi_expr(mt):; ; def main(args):; ; - hl.init(log=""/select_samples"", default_reference=""GRCh38"", idempotent=True, tmp_dir=args.temp_bucket); - meta_ht = hl.import_table(args.sample_metadata_tsv, force_bgz=True); - meta_ht = meta_ht.key_by(""s""); - meta_ht = meta_ht.filter(hl.is_defined(meta_ht.cram_path) & hl.is_defined(meta_ht.crai_path), keep=True); - meta_ht = meta_ht.repartition(1000); - meta_ht = meta_ht.checkpoint(; - re.sub("".tsv(.b?gz)?"", """", args.sample_metadata_tsv) + "".ht"", overwrite=True, _read_if_exists=True); -; + hl.init(log=""/tmp/select_samples"", default_reference=""GRCh38"", idempotent=True, tmp_dir=args.temp_bucket); vds = gnomad_v4_genotypes.vds(); ; # see https://github.com/broadinstitute/ukbb_qc/pull/227/files; @@ -55,19 +48,8 @@ def main(args):; ; v4_qc_meta_ht = meta.ht(); ; - mt = vds.variant_data; - #mt = vds.variant_data._filter_partitions([41229]); -; - mt = mt.filter_cols(v4_qc_meta_ht[mt.s].release); -; - meta_join = meta_ht[mt.s]; - mt = mt.annotate_cols(; - meta=hl.struct(; - sex_karyotype=meta_join.sex_karyotype,; - cram=meta_join.cram_path,; - crai=meta_join.crai_path,; - ); - ); + #mt = vds.variant_data; + mt = vds.variant_data._filter_partitions([41229]); ; logger.info(""Adjusting samples' sex ploidy""); lgt_expr = hl.if_else(; @@ -88,9 +70,9 @@ def main(args):; logger.info(""Filter variants wi",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13248#issuecomment-1703383664:703,log,log,703,https://hail.is,https://github.com/hail-is/hail/issues/13248#issuecomment-1703383664,1,['log'],['log']
Testability,"I installed pandas 1.5.2 and ran every test with the word pandas in the name:; ```; =============================================== short test summary info ===============================================; PASSED test/hail/table/test_table.py::Tests::test_from_pandas_mismatched_object_rows; PASSED test/hail/table/test_table.py::Tests::test_from_pandas_missing_and_nans; PASSED test/hail/table/test_table.py::Tests::test_from_pandas_objects; PASSED test/hail/table/test_table.py::Tests::test_from_pandas_works; PASSED test/hail/table/test_table.py::test_to_pandas; PASSED test/hail/table/test_table.py::test_to_pandas_flatten; PASSED test/hail/table/test_table.py::test_to_pandas_null_ints; PASSED test/hail/table/test_table.py::test_to_pandas_nd_array; PASSED test/hail/table/test_table.py::test_literal_of_pandas_NA_and_numpy_int64; PASSED test/hail/table/test_table.py::test_literal_of_pandas_NA_and_numpy_int32; ======================================== 10 passed, 1357 deselected in 40.40s =========================================; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12580#issuecomment-1396345811:39,test,test,39,https://hail.is,https://github.com/hail-is/hail/pull/12580#issuecomment-1396345811,16,"['Test', 'test']","['Tests', 'test']"
Testability,"I just finished up the test suite for time functions that Milo had written in Scala, but we should probably move the whole thing to python.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7806:23,test,test,23,https://hail.is,https://github.com/hail-is/hail/issues/7806,1,['test'],['test']
Testability,I just had this test fail in another PR. This change gives me the information; necessary to debug the issue.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10948:16,test,test,16,https://hail.is,https://github.com/hail-is/hail/pull/10948,1,['test'],['test']
Testability,"I just meant we should test that VEP still works on this branch. Like, do we have automated tests for VEP?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8150#issuecomment-591007231:23,test,test,23,https://hail.is,https://github.com/hail-is/hail/pull/8150#issuecomment-591007231,2,['test'],"['test', 'tests']"
Testability,"I just pulled in a library specifically for json log formatting that handles escaping nicely + makes it easy to add anything else we might want to do. I've obviously not run batch locally but I've tested this code locally by running . ```from hailtop.gear import configure_logging; import logging; configure_logging(); logging.info('""Foo""'); ```. We are definitely going to want more than this eventually, but this should at least let us start to break up our logs in Kibana. And it's hard to test more complicated things without some way to run my own batch.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6453:49,log,log,49,https://hail.is,https://github.com/hail-is/hail/pull/6453,6,"['log', 'test']","['log', 'logging', 'logs', 'test', 'tested']"
Testability,I just tested on Dataproc and it works there just fine.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2063#issuecomment-319959888:7,test,tested,7,https://hail.is,https://github.com/hail-is/hail/pull/2063#issuecomment-319959888,1,['test'],['tested']
Testability,"I kept having issues with non-local `sc.broadcast`; the @transient conf wouldn't be populated. Serialization worked fine, but this wouldn't. The solution I implemented was to pass a serializableHadoopConfiguration, but it feels like there should be a more elegant solution. However, given that Spark is leaving us forever, I'm not sure it's worth further investigation. Still, if there is a use case for this, I would like to find out why the previous solution was insufficient. . Edit:nvm, not the cause I don’t believe. There’s a bug somewhere, but maybe not serialization. Need to find a better way to replicate locally; has been getting stuck at 0/2 stage. . edit2: resolved testing issue, will find root of bug. cc @cseed",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6083#issuecomment-496305166:679,test,testing,679,https://hail.is,https://github.com/hail-is/hail/pull/6083#issuecomment-496305166,1,['test'],['testing']
Testability,"I knew I was missing tests of greater than two layers. Sure enough there were more bugs lurking. I think >3 layers won't find any new bugs given that there are basically three kinds of b-trees:. - 1 layer: all leaf nodes, <=1024 elements; - 2 layers: one internal/key layer, one leaf layer [1025, 1024^2] elements; - n layers: n-1 internal/key layers, one leaf layer [1024^(n-1)+1, 1024^n] elements. The last case is the first case where we have to do two levels of internal layers. This traversal is defined inductively, so I suspect succeeding on 3 layers tests all the functionality of >3 layers.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3807:21,test,tests,21,https://hail.is,https://github.com/hail-is/hail/pull/3807,2,['test'],['tests']
Testability,"I know how to fix this this, but why didn't it fail in the PR that made this change?; ```; ________________________________ test_callback _________________________________. client = <hailtop.batch_client.client.BatchClient object at 0x7f9cbc23b610>. async def test_callback(client):; import nest_asyncio # pylint: disable=import-outside-toplevel; ; nest_asyncio.apply(); ; app = web.Application(); callback_bodies = []; callback_event = asyncio.Event(); ; def url_for(uri):; host = os.environ['HAIL_BATCH_WORKER_IP']; port = os.environ['HAIL_BATCH_WORKER_PORT']; return f'http://{host}:{port}{uri}'; ; async def callback(request):; body = await request.json(); callback_bodies.append(body); callback_event.set(); return web.Response(); ; app.add_routes([web.post('/test', callback)]); runner = web.AppRunner(app); await runner.setup(); site = web.TCPSite(runner, '0.0.0.0', 5000); await site.start(); ; try:; token = secrets.token_urlsafe(32); b = create_batch(; client, callback=url_for('/test'), attributes={'foo': 'bar', 'name': 'test_callback'}, token=token; ); head = b.create_job('alpine:3.8', command=['echo', 'head']); b.create_job('alpine:3.8', command=['echo', 'tail'], parents=[head]); b.submit(); await asyncio.wait_for(callback_event.wait(), 5 * 60); callback_body = callback_bodies[0]; ; # verify required fields present; callback_body.pop('cost'); callback_body.pop('msec_mcpu'); callback_body.pop('time_created'); callback_body.pop('time_closed'); callback_body.pop('time_completed'); callback_body.pop('duration'); callback_body.pop('duration_ms'); callback_body.pop('cost_breakdown'); > assert callback_body == {; 'id': b.id,; 'user': 'test',; 'billing_project': 'test',; 'token': token,; 'state': 'success',; 'complete': True,; 'closed': True,; 'n_jobs': 2,; 'n_completed': 2,; 'n_succeeded': 2,; 'n_failed': 0,; 'n_cancelled': 0,; 'attributes': {'foo': 'bar', 'name': 'test_callback'},; }, callback_body; E AssertionError: {'attributes': {'client_job': '8051758-182', 'foo': 'bar'",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13739#issuecomment-1739224427:1004,test,test,1004,https://hail.is,https://github.com/hail-is/hail/pull/13739#issuecomment-1739224427,1,['test'],['test']
Testability,"I left a parameter on the StagedBTree implementation to be able to adjust the number of elements a node can hold, but we were never testing this (we currently never use anything except the default). I'm modifying the BTree test to run on trees of size 2, 3, 5, 6, and 22; 2 is the default, and 22 is the check for when the max number of possible elements doesn't exceed half the size of the node. The others are mainly just to check that both even and odd numbers work correctly for a size that we'd conceivably want to use.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7119:132,test,testing,132,https://hail.is,https://github.com/hail-is/hail/pull/7119,2,['test'],"['test', 'testing']"
Testability,I left in google_storage.py in for now because Benchmark uses it and I didn't want to rewrite that right now.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10331#issuecomment-820662160:47,Benchmark,Benchmark,47,https://hail.is,https://github.com/hail-is/hail/pull/10331#issuecomment-820662160,1,['Benchmark'],['Benchmark']
Testability,"I left in the previous one for testing purposes. When we're confident the new one dominates, I will remove it. This is the first of several PRs to speed up densify (and scans and aggregates in general). The rough plan is:; - add CompiledPackEncoder so we aren't interpreting types in the prev_nonnull seqOp,; - make RegionValueAggregator.result staged so we don't use RegionValueBuilder to construct aggregator and scan results. I will do some more benchmarking at that point.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5414:31,test,testing,31,https://hail.is,https://github.com/hail-is/hail/pull/5414,2,"['benchmark', 'test']","['benchmarking', 'testing']"
Testability,"I left the changes to Query and Batch in separate commits for ease of review. I put these in the same PR because we don't really have standalone testing for JVM Jobs outside of Query-on-Batch so the FASTA use-case serves as a test here that cloudfuse is working properly for JVM Jobs. Would be great if Jackie you could review the batch commit and Tim could review the query commit. ## Hail Query; - Added support for the `FROM_FASTA_FILE` rpc and the service backend now passes sequence file information from RGs in every rpc; - Refactored the liftover handling in service_backend to not redundantly store liftover maps and just take them from the ReferenceGenome objects like I did for sequence files. This means that add/remove liftover/sequence functions on the Backend are just intended to sync up the backend with python, which is a no-op for the service backend.; - Don't localize the index file on fromFASTAFile/addSequence before creating the index object. `FastaSequenceIndex` just loads the whole file on construction so might as well stream it in from whatever storage it's in.; - FASTA caching is left alone because those files will be mounted and unmounted from the jvm container over the life of the job. JVM doesn't have to worry about disk usage because that's handled by Batch XFS quotas, so long as the service backend requests enough storage to fit the FASTA file. Batch will make sure that a given bucket (and therefore a given FASTA file) is mounted once per-user on a batch worker. ## Hail Batch; - Added support for read-only cloudfuse mounts for JVM jobs; - These mounts are shared between jobs on the same machine from the same user; - I did not change DockerJobs, but they could be very easily adapted to use this new mount-sharing code.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12736:145,test,testing,145,https://hail.is,https://github.com/hail-is/hail/pull/12736,2,['test'],"['test', 'testing']"
Testability,"I left the exception log statements in because it's not like these are driving up our logging costs, but let me know whether you want to keep them or not. Can make a Grafana alert after this goes in based on this metric.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12622:21,log,log,21,https://hail.is,https://github.com/hail-is/hail/pull/12622,2,['log'],"['log', 'logging']"
Testability,"I let it go at the end of a long string of commands overnight and it looked to get stuck in the same place, still at (0 + 25) / 25 after what I estimate was about three hours on the grm. A glance at the log shows the same error. I killed it to free up the cluster. . Log here: humgen/atgu1/fs03/satterst/DBS_v2.3/hail.kryo.log",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/321#issuecomment-212885679:203,log,log,203,https://hail.is,https://github.com/hail-is/hail/issues/321#issuecomment-212885679,3,"['Log', 'log']","['Log', 'log']"
Testability,I like the tests,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12275#issuecomment-1268734693:11,test,tests,11,https://hail.is,https://github.com/hail-is/hail/pull/12275#issuecomment-1268734693,1,['test'],['tests']
Testability,"I like this. That + depending on the `release` step ensures that we only submit the benchmarks on the exact sha that we release. When we eventually split these steps out into their own release pipeline, we can just delete the file and use the normal `depends_on: release` behavior to achieve the same result.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14398#issuecomment-2027251314:84,benchmark,benchmarks,84,https://hail.is,https://github.com/hail-is/hail/pull/14398#issuecomment-2027251314,1,['benchmark'],['benchmarks']
Testability,"I liked your diff idea, so I added a new file: batch/sql/estimated-current.txt. This is meant to be the SQL we'd use for initial.sql if we recreated the batch database. It should have collective migrations applied to it. So when we add a new migration, we should update the estimated current which will give informative documentation for the current change. I use ""estimated"" and ""txt"" because it isn't tested or validated in any way.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7916:403,test,tested,403,https://hail.is,https://github.com/hail-is/hail/pull/7916,1,['test'],['tested']
Testability,I looked at the Spark worker logs by setting up the SSH tunnel (according to laurent's cloud post) and going to the Executor tab of the spark history server page. It seems we're running into this issue: https://issues.apache.org/jira/browse/SPARK-16845. This is definitely because Andrea's VDS has lots of annotations. Here's a quote from that Spark issue:. > I've been struggling to duplicate this and finally came up with a strategy that duplicates it in a spark-shell. It's a combination of a wide dataset with nested (array) structures and performing a union that seem to trigger it.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1186#issuecomment-267428726:29,log,logs,29,https://hail.is,https://github.com/hail-is/hail/issues/1186#issuecomment-267428726,1,['log'],['logs']
Testability,I looked at the log. Looks like it is running fine. Is it running slowly? How long do you expect it to take? How many variants in the DILI controls?. VEP is never going to run fast in this form. We're going to merge pre-computed annotations for SNPs and only run VEP on indels. That should make it about 20x faster.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/302#issuecomment-210947424:16,log,log,16,https://hail.is,https://github.com/hail-is/hail/issues/302#issuecomment-210947424,1,['log'],['log']
Testability,"I looked at the picard tests and realized they just made a fake chain file with one interval that mapped to the negative strand in the destination reference. My existing test covers this scenario -- one interval maps to the positive strand of the destination and the other to the negative strand. Since I'm only passing the strand information from Picard, I'm happy with the tests I have already.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4895#issuecomment-445015697:23,test,tests,23,https://hail.is,https://github.com/hail-is/hail/pull/4895#issuecomment-445015697,3,['test'],"['test', 'tests']"
Testability,"I looked at the yarn logs. It looks like it is not finding the GLIBCXX_3.4.18 lib. This is how the hail script is being submitted... ```; module load anaconda3/5.2.0; source activate hail2; module load gcc/7.2.0; module load lz4/1.8.3; module load spark/2.2.1; echo ""Export env vars""; export HAIL_HOME=/restricted/projectnb/genpro/github/hail/hail; export PYTHONPATH=""${PYTHONPATH:+$PYTHONPATH:}$HAIL_HOME/build/distributions/hail-python.zip""; export PYTHONPATH=""$PYTHONPATH:$SPARK_HOME/python""; export PYTHONPATH=""$PYTHONPATH:$SPARK_HOME/python/lib/py4j-*-src.zip""; echo ""Submitting Spark job""; spark-submit\; --executor-cores 4\; --executor-memory 40G\; --driver-memory 10g\; --driver-cores 2\; --num-executors 10\; --conf spark.yarn.appMasterEnv.LD_LIBRARY_PATH=$LD_LIBRARY_PATH\; --conf spark.yarn.appMasterEnv.PYTHONPATH=$PYTHONPATH\; --conf spark.yarn.appMasterEnv.PATH=$PATH\; --jars $HAIL_HOME/build/libs/hail-all-spark.jar \; --master yarn\; --deploy-mode client \; --conf spark.driver.memory=5G\; --conf spark.executor.memory=30G\; --conf spark.driver.extraClassPath=\""$HAIL_HOME/build/libs/hail-all-spark.jar\"" \; --conf spark.executor.extraClassPath=./hail-all-spark.jar \; --conf spark.serializer=org.apache.spark.serializer.KryoSerializer \; --conf spark.kryo.registrator=is.hail.kryo.HailKryoRegistrator\; ""$@"". spark-submit\; --executor-cores 4\; --executor-memory 40G\; --driver-memory 10g\; --driver-cores 2\; --num-executors 10\; --conf spark.yarn.appMasterEnv.LD_LIBRARY_PATH=$LD_LIBRARY_PATH\; --conf spark.yarn.appMasterEnv.PYTHONPATH=$PYTHONPATH\; --conf spark.yarn.appMasterEnv.PATH=$PATH\; --jars $HAIL_HOME/build/libs/hail-all-spark.jar \; --master yarn\; --deploy-mode client \; --conf spark.driver.memory=5G\; --conf spark.executor.memory=30G\; --conf spark.driver.extraClassPath=\""$HAIL_HOME/build/libs/hail-all-spark.jar\"" \; --conf spark.executor.extraClassPath=./hail-all-spark.jar \; --conf spark.serializer=org.apache.spark.serializer.KryoSerializer \; --conf spark.k",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733#issuecomment-456518258:21,log,logs,21,https://hail.is,https://github.com/hail-is/hail/issues/4733#issuecomment-456518258,1,['log'],['logs']
Testability,"I looked closer at the logic in the old combiner and realized it was permitting things within 1 window-size of the window to be binned. I wasn't doing this at all, so implemented it. This has nice performance properties, but uses more memory than the user requests, so I'm using just a 25% ""grace window"" plus the buffer to have both good performance and low memory usage. ```; Name Ratio Time 1 Time 2; ---- ----- ------ ------; table_aggregate_downsample_worst_case 39.5% 57.617 22.773; table_aggregate_downsample_dense 26.6% 127.079 33.843; ----------------------; Geometric mean: 32.4%; Simple mean: 33.1%; Median: 33.1%; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7197#issuecomment-538549413:23,log,logic,23,https://hail.is,https://github.com/hail-is/hail/pull/7197#issuecomment-538549413,1,['log'],['logic']
Testability,"I looked over the code and it looks fine, but I'm having trouble understanding the bigger picture of what you're trying to accomplish. I see that you have a new step that creates a test database in the default namespace in the test scope. Then you create the database config secret from this new database. And then deploy_ci depends on it, which makes sense because it needs the secret to be able to create new databases. And this is all only in the test scope. It looks like you cleaned up the build database in the case of dev deploy, which is fine too. > we also create a ""test_instance"" database that will be used as the database instance inside the tests. I don't understand what you wrote here because test_instance database doesn't seem to be used at all. Aren't we still creating the same batch and ci databases? I don't see what the test_instance database is buying you except to be able to make the database config secret that doesn't have the root username and password. I also don't quite understand what's going on in the build_cant_create_database build step. Shouldn't those secrets already exist? Won't this fail?. I'm sorry if I'm missing something obvious.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7683#issuecomment-562887906:181,test,test,181,https://hail.is,https://github.com/hail-is/hail/pull/7683#issuecomment-562887906,4,['test'],"['test', 'tests']"
Testability,"I made `_prev_nonnull` private since it's pretty specific to this use case, but I can imagine we'll want to generalize it to something like `take` which aggregates the last `n` values instead of the first `n` values. Here is an example pipeline against `test-chr22.mt`:. ```; import hail as hl. mt = hl.read_matrix_table('test-chr22.mt'); mt = mt._filter_partitions(range(8)) # make small. # restrict to two samples; mt = mt.filter_cols((mt.s == 'V33335') | (mt.s == 'NWD157935')); mt = mt.annotate_rows(__n = hl.agg.count_where(hl.is_defined(mt.GT))); mt = mt.filter_rows(mt.__n > 0). print(; mt.count()). def show_mt(mt):; entry_fields = ['GT']; if 'END' in mt.entry:; entry_fields.append('END'); (mt.select_rows(); .select_entries(*entry_fields); ._localize_entries('__entries', '__cols'); .show()). show_mt(mt). mt = hl.experimental.densify(mt); show_mt(mt). mt.describe(); ```. which produces sparse and dense samples:. ```; +----------------+-------------------------------------+; | locus | __entries |; +----------------+-------------------------------------+; | locus<GRCh38> | array<struct{GT: call, END: int32}> |; +----------------+-------------------------------------+; | chr22:10510746 | [NA,(0/0,10510769)] |; | chr22:10510770 | [NA,(1/1,NA)] |; | chr22:10510771 | [NA,(0/0,10510891)] |; | chr22:10511207 | [NA,(0/0,10511390)] |; | chr22:10511272 | [(0/0,10511390),NA] |; | chr22:10511391 | [NA,(1/1,NA)] |; | chr22:10511392 | [(0/0,10511393),(0/0,10511477)] |; | chr22:10511397 | [(0/0,10511403),NA] |; | chr22:10511406 | [(0/0,10511418),NA] |; | chr22:10511420 | [(0/0,10511420),NA] |; +----------------+-------------------------------------+; showing top 10 rows. +----------------+-------------------------+; | locus | __entries |; +----------------+-------------------------+; | locus<GRCh38> | array<struct{GT: call}> |; +----------------+-------------------------+; | chr22:10510746 | [NA,(0/0)] |; | chr22:10510770 | [NA,(1/1)] |; | chr22:10510771 | [NA,(0/0)] |; | chr22:10511",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5281:254,test,test-,254,https://hail.is,https://github.com/hail-is/hail/pull/5281,2,['test'],['test-']
Testability,"I made a branch which I think fixes this (and makes the 'root' variable actually used), but will PR once I have testing going.; https://github.com/jbloom22/hail/tree/vep_csq_global",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4050#issuecomment-409401666:112,test,testing,112,https://hail.is,https://github.com/hail-is/hail/issues/4050#issuecomment-409401666,1,['test'],['testing']
Testability,I made a new PR from #7833 because I know this has been tested except for the three extra commits to remove testing infrastructure.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7838#issuecomment-573179477:56,test,tested,56,https://hail.is,https://github.com/hail-is/hail/pull/7838#issuecomment-573179477,2,['test'],"['tested', 'testing']"
Testability,"I made a small test example that fails. Still in Python -- couldn't replicate it in the IRSuite. ```; t = hl.utils.range_table(1); t = t.annotate(s=hl.set({'foo'}), nested=hl.null(hl.tstruct(elt=hl.tstr))); t = t.key_by().drop('idx'); t.filter(t.s.contains(t.nested.elt))._force_count(); ```. - Doesn't matter if the set has one element or is empty; - Doesn't matter if it's an `annotate_globals` versus `annotate`; - If `nested` is a string, null value, or a struct with a null value, it works",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4522#issuecomment-430000941:15,test,test,15,https://hail.is,https://github.com/hail-is/hail/issues/4522#issuecomment-430000941,1,['test'],['test']
Testability,I made some changes. I had to rewrite the audits to not fill up the temp disk space and account for a bug in billing that was fixed for job private instances #10069. I'll test this afternoon after I figure out how to revert my first attempt.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11996#issuecomment-1201421379:171,test,test,171,https://hail.is,https://github.com/hail-is/hail/pull/11996#issuecomment-1201421379,1,['test'],['test']
Testability,"I made some edits that I think helped to reduce the number of places that are aware of the notion of a default_region. It's really now just isolated to the `InstanceCollectionManager`, since that's the piece of code that's making the decision ""use the default region when the cluster is small"". I didn't quite like the pattern of retrieving a default from a `LocationMonitor` just to give it right back to the location monitor in the next line. I think this way the `LocationMonitor` API is much simpler, and we can actually remove its `default_location` method entirely as I believe it is no longer used. I can do that in a follow-up PR if you like this approach. One other thing is I wanted to articulate the distinction between the ""region CI needs its jobs in"" and the ""default region that batch will spin up workers in for small clusters"". While they are in practice the same, I found that treating them both as the ""default_region"" tied the logic around jobs for CI closely with internal Batch decisions and made it more confusing for me to reason about. I tried to separate out these two concepts so that in the future when jobs support region-specific scheduling it will be easier to excise the CI-specific code from the Batch scheduler. Another thing that I realized during this process is that Azure has regions and zones just like GCP, though they may differ slightly since we don't need to specify a zone for a VM and such. I am fine with using the term ""location"" to mean ""where we scheduled the VM, either zone or region depending on the cloud provider"", but I would also like to follow up with a sweep that makes this language more precise where possible. For example, the `possible_cloud_locations` function is really just `possible_cloud_regions`, and we could even go so far as mandating a `region` field in the global config instead of having `azure_location` and `gcp_region`, which are synonymous even though named differently. It also leads me to wonder why we only schedule in a",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12078#issuecomment-1207095240:947,log,logic,947,https://hail.is,https://github.com/hail-is/hail/pull/12078#issuecomment-1207095240,2,['log'],['logic']
Testability,"I made some mostly minor, stylistic comments. Back to you!. Also, there are conflicts so you will need to rebase against the current master. You'll also need to do that to pick up ""Jenkinsfile"" so the automated tests get run. Finally, we're trying to keep the git history clean, so single conceptual changes should go in as single commits. Can you squash all these commits into a single one? (Use `git rebase -i` and squash.)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/446#issuecomment-237269843:211,test,tests,211,https://hail.is,https://github.com/hail-is/hail/pull/446#issuecomment-237269843,1,['test'],['tests']
Testability,"I made the requested changes, improved the docs a bit more, removed the rank testing for now (may bring back in later PR), and am keeping the covariate field as list of expressions, even for one expression. I feel this is more natural in the regression setting, where one can even have no covariates (default is []), and I prefer to pass an array of string into RegressionUtils, though we should make another pass on parsing later (right now, I do still concatenate with ',' just before sending into the parser but would to not merge only to split).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1259#issuecomment-275096710:77,test,testing,77,https://hail.is,https://github.com/hail-is/hail/pull/1259#issuecomment-275096710,1,['test'],['testing']
Testability,I made the timeout for the standing workers to be 5 minutes for the test scope and 2 hours for the deploy scope.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8850#issuecomment-632344001:68,test,test,68,https://hail.is,https://github.com/hail-is/hail/pull/8850#issuecomment-632344001,1,['test'],['test']
Testability,"I manually added a `hail_test_gcs_bucket` field to the k8s global config and use that value wherever we have our current test bucket hard coded. I also added the necessary terraform to make that in a new cluster, though I have not done a new terraform run in my project. Once this and a couple more refactoring PRs go in I'll be able to run ci tests in a separate cluster and validate that the terraform is working correctly. cc: @danking",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10807:121,test,test,121,https://hail.is,https://github.com/hail-is/hail/pull/10807,2,['test'],"['test', 'tests']"
Testability,I manually added a field to the global-config for the requester pays bucket used in batch tests. Adding it here to build.py's view of global fields so that CI can template #10866 in the future and actually test it.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10870:90,test,tests,90,https://hail.is,https://github.com/hail-is/hail/pull/10870,2,['test'],"['test', 'tests']"
Testability,I marked the balding Nichols test as failing for now because its far more important that we actually run the statgen tests.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12588#issuecomment-1407889708:29,test,test,29,https://hail.is,https://github.com/hail-is/hail/pull/12588#issuecomment-1407889708,2,['test'],"['test', 'tests']"
Testability,"I mean, anything that's touching the BTree is broken, so the following works:. is.hail.expr.ir.Aggregators2Suite.testCollectAsSet",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9604#issuecomment-713603033:113,test,testCollectAsSet,113,https://hail.is,https://github.com/hail-is/hail/pull/9604#issuecomment-713603033,1,['test'],['testCollectAsSet']
Testability,I merged these branches and resolved one (false) conflict. - [dependabot/pip/docker/async-timeout-4.0.2](/hail-is/hail/tree/dependabot/pip/docker/async-timeout-4.0.2); - [dependabot/pip/docker/pylint-2.12.2](/hail-is/hail/tree/dependabot/pip/docker/pylint-2.12.2); - [dependabot/pip/docker/python-json-logger-2.0.2](/hail-is/hail/tree/dependabot/pip/docker/python-json-logger-2.0.2); - [dependabot/pip/hail/python/avro-gte-1.10-and-lt-1.12](/hail-is/hail/tree/dependabot/pip/hail/python/avro-gte-1.10-and-lt-1.12); - [dependabot/pip/hail/python/dev/nbsphinx-0.8.8](/hail-is/hail/tree/dependabot/pip/hail/python/dev/nbsphinx-0.8.8); - [dependabot/pip/hail/python/dev/pylint-2.12.2](/hail-is/hail/tree/dependabot/pip/hail/python/dev/pylint-2.12.2); - [dependabot/pip/hail/python/dev/sphinxcontrib-katex-0.8.6](/hail-is/hail/tree/dependabot/pip/hail/python/dev/sphinxcontrib-katex-0.8.6); - [dependabot/pip/hail/python/janus-gte-0.6-and-lt-1.1](/hail-is/hail/tree/dependabot/pip/hail/python/janus-gte-0.6-and-lt-1.1); - [dependabot/pip/hail/python/pre-commit-2.17.0](/hail-is/hail/tree/dependabot/pip/hail/python/pre-commit-2.17.0); - [dependabot/pip/hail/python/tabulate-0.8.9](/hail-is/hail/tree/dependabot/pip/hail/python/tabulate-0.8.9),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11481:302,log,logger-,302,https://hail.is,https://github.com/hail-is/hail/pull/11481,2,['log'],['logger-']
Testability,I might see the issue. The group by in the test queries doesn't actually do a group by like I wanted because there's no aggregation...,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14282#issuecomment-1941714742:43,test,test,43,https://hail.is,https://github.com/hail-is/hail/pull/14282#issuecomment-1941714742,1,['test'],['test']
Testability,I missed a few places where CI tries to get the logs of a service.; All of these can fail if the pod has multiple containers. I added; `--all-containers` to ensure it never fails for multi-container Pods.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8542:48,log,logs,48,https://hail.is,https://github.com/hail-is/hail/pull/8542,1,['log'],['logs']
Testability,I missed the `pod_status` thing in the rebase. The container log is just a mistake on my part.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6708:61,log,log,61,https://hail.is,https://github.com/hail-is/hail/pull/6708,1,['log'],['log']
Testability,"I misunderstood what `//` and `/` meant. `//` is used for things like `//google.com/index.html` which resolves to `https://google.com/index.html` when served by `https` and `http://google.com/index.html` when served by `http`. `/` is the same but for local URLs. For example, `/index.html` resolves to `https://hail.is/index.html` on our website but `http://localhost:8080/index.html` if I'm testing locally.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4953:392,test,testing,392,https://hail.is,https://github.com/hail-is/hail/pull/4953,1,['test'],['testing']
Testability,"I mixed the required changes with some cosmetic changes to, e.g. docs and comments. I also added a missing </div> in references.md. AFAICT, there's no way to change the default branch yet, so I didn't change the PR test CI's test repo's branch yet. This change will change the references page on the site as soon as its merged, so we should be prepared to switch over when we merge it.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9185:215,test,test,215,https://hail.is,https://github.com/hail-is/hail/pull/9185,2,['test'],['test']
Testability,"I modified the artifacts to include the two uber jars:. ```; +:build/docs => docs; +:build/libs/hail-all-spark.jar; +:build/libs/hail-all-spark-test.jar; ```. The latest successful master build of `hail-all-spark.jar` is available at:. https://ci.hail.is/httpAuth/app/rest/builds/buildType:(id:HailSourceCode_HailCi),count:1,status:SUCCESS/artifacts/content/hail-all-spark.jar",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/754#issuecomment-245692697:144,test,test,144,https://hail.is,https://github.com/hail-is/hail/issues/754#issuecomment-245692697,1,['test'],['test']
Testability,"I mostly think if we're actually using reprs meaningfully, we need to test them. At least for types, variants + loci + intervals, etc.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2060#issuecomment-322267032:70,test,test,70,https://hail.is,https://github.com/hail-is/hail/pull/2060#issuecomment-322267032,1,['test'],['test']
Testability,"I moved the info score calculation to the stats package, got rid of the combiner class, and used `mapAnnotations` to modify the VDS. Let me know if I should use `mapAnnotationsWithAggregate` instead. I also removed the RDD join in the test suite. The reason for not comparing to QCTOOL is how Cotton and I decided to handle missing values (0,0,0). QCTOOL uses the MAF estimate from the other samples to mean impute the dosage for samples with missing values. We do not include those samples at all in the computation.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/765#issuecomment-248466826:235,test,test,235,https://hail.is,https://github.com/hail-is/hail/pull/765#issuecomment-248466826,1,['test'],['test']
Testability,"I need to investigate further, but now I see a segfault and I think it's coming from the LMM tests. I need to fix the `test-gcp.sh` script so that it looks for the coredump file in the case of a seg fault. ```; [Stage 2225:==========================================> (3 + 1) / 4]2017-08-28 21:47:32 Hail: INFO: No multiallelics detected.; 2017-08-28 21:47:32 Hail: INFO: Ordering unsorted dataset with network shuffle; 2017-08-28 21:47:33 Hail: WARN: called redundant split on an already split VDS; 2017-08-28 21:47:33 Hail: INFO: using 2 trios for transmission analysis; [Stage 2229:==========================================> (3 + 1) / 4]2017-08-28 21:47:35 Hail: INFO: while writing:; file:/tmp/hail.16cpq9RzwI7a/out.00000.txt; merge time: 65.459ms; 2017-08-28 21:47:35 Hail: INFO: No multiallelics detected.; 2017-08-28 21:47:35 Hail: INFO: Ordering unsorted dataset with network shuffle; [Stage 2234:============================================> (4 + 1) / 5]2017-08-28 21:47:37 Hail: WARN: Found 2 samples with missing sex information (not 1 or 2).; Missing sex identifiers: [ 0 ]; 2017-08-28 21:47:37 Hail: WARN: 2 samples discarded from .fam: sex of child is missing.; 2017-08-28 21:47:38 Hail: INFO: Found 250 samples in fam file.; 2017-08-28 21:47:38 Hail: INFO: Found 2000 variants in bim file.; 2017-08-28 21:47:38 Hail: INFO: Coerced sorted dataset; 2017-08-28 21:47:38 Hail: INFO: Modified the genotype schema with annotateGenotypesExpr.; Original: Struct{GT:Call}; New: Genotype; 2017-08-28 21:47:38 Hail: INFO: Reading table to impute column types; [Stage 2258:============================> (1 + 1) / 2]2017-08-28 21:47:40 Hail: INFO: Finished type imputation; Loading column `f0' as type String (imputed); Loading column `f1' as type String (imputed); Loading column `f2' as type Float64 (imputed); 2017-08-28 21:47:41 Hail: INFO: Reading table to impute column types; 2017-08-28 21:47:41 Hail: INFO: Finished type imputation; Loading column `f0' as type String (imputed); Loading colu",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2132#issuecomment-325495835:93,test,tests,93,https://hail.is,https://github.com/hail-is/hail/pull/2132#issuecomment-325495835,2,['test'],"['test-gcp', 'tests']"
Testability,I need to make sure this all works when ci is deploying in a test namespace.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7101:61,test,test,61,https://hail.is,https://github.com/hail-is/hail/pull/7101,1,['test'],['test']
Testability,I need to rethink the test-tiny-limit and test-zero-limit. This is going to fail every time after the first merge on the deployment.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9354#issuecomment-705066148:22,test,test-tiny-limit,22,https://hail.is,https://github.com/hail-is/hail/pull/9354#issuecomment-705066148,2,['test'],"['test-tiny-limit', 'test-zero-limit']"
Testability,I need to see the index page (with the build log) to try to fix this. Everything on that page is rightfully green,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4514#issuecomment-428408138:45,log,log,45,https://hail.is,https://github.com/hail-is/hail/issues/4514#issuecomment-428408138,1,['log'],['log']
Testability,"I need to test out the last change I made to fix a potential forward compatibility issue when we do one last final test. But for now, I think it would be good to keep reviewing further up the stack to make sure we are happy with all of the changes before I do one last test.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11990#issuecomment-1176255053:10,test,test,10,https://hail.is,https://github.com/hail-is/hail/pull/11990#issuecomment-1176255053,3,['test'],['test']
Testability,I need to test this with dev deploy and make sure it actually works. But would appreciate feedback on the design before I start doing that.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8445:10,test,test,10,https://hail.is,https://github.com/hail-is/hail/pull/8445,1,['test'],['test']
Testability,"I need to write another scala test, but it's working as expected in; large test cases in benchmarks. ```; Name Ratio Time 1 Time 2; ---- ----- ------ ------; table_aggregate_downsample_worst_case 57.8% 57.617 33.278; table_aggregate_downsample_dense 30.0% 127.079 38.119; ----------------------; Geometric mean: 41.6%; Simple mean: 43.9%; Median: 43.9%; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7197:30,test,test,30,https://hail.is,https://github.com/hail-is/hail/pull/7197,3,"['benchmark', 'test']","['benchmarks', 'test']"
Testability,"I need to write the CI integration, but this is my proposed distributed buffer service. It's not resilient to failure at all. `python3 -m dbuf 8`. Will create an 8-process dbuf. You can start follower cores on another machine with `python3 -m dbuf 8 --leader http://LEADER:LEADER_PORT`. For a sense of the performance, the following has 10 co-routines each sending 10k messages of 40k bytes each using a buffer size of 5MB (so each co-routine holds about 5MB in memory before flushing):; ```; # python3 scale_test.py 10 5 40000 10000; create; write aggregate-throughput: 0.333 GiB/s; read aggregate-throughput: 0.213 GiB/s; ```; This is on my laptop over loopback with `python3 -m dbuf 4`. Note that we send 4 GB (10 * 10k * 40k bytes). Each core will buffer 512 MiB, so each server core will flush to disk twice (the scale test explicitly equally distributes the load, so each server core gets 1 GB). I've got a Scala client as well which I'll add in another PR. ---. Update: same as above benchmark but I had to reduce the maximum data sent in one HTTP request to 1MiB:. ```; write aggregate-throughput: 0.194 GiB/s; read aggregate-throughput: 0.135 GiB/s; ```. I can no longer run the test on my laptop due to all the changes I made to dbuf to make it run in k8s. I don't know how much of the reduced throughput is due to the HTTP window size. I'll increase all the NGINX max request sizes at some point and retest.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7523:824,test,test,824,https://hail.is,https://github.com/hail-is/hail/pull/7523,6,"['benchmark', 'test']","['benchmark', 'test']"
Testability,I needed this when running PR tests. It is also useful for dev deploys. I also fixed a minor bug in install-editable,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6805:30,test,tests,30,https://hail.is,https://github.com/hail-is/hail/pull/6805,1,['test'],['tests']
Testability,I never hit test before submitting. 😁,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1638#issuecomment-291888209:12,test,test,12,https://hail.is,https://github.com/hail-is/hail/pull/1638#issuecomment-291888209,1,['test'],['test']
Testability,"I never tested that PR that got merged (whoops!) and CI tests are insufficient; to catch this case (we should beef those up, asana task added). The issue was that I thought the method to issue an HTTP get request was `get`,; but it was `getitem`. This PR fixes that. This error occured during `update` and; thus prevented all forward progress of CI.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8402:8,test,tested,8,https://hail.is,https://github.com/hail-is/hail/pull/8402,2,['test'],"['tested', 'tests']"
Testability,"I noticed something else, really long running jobs don't look great. That second blue line is a 6 minute job and it extends past the end of the page. Can we maybe put all of these divs into something that scrolls? Maybe a `div` with an `overflow: scroll`? I'm not sure exactly what should happen or how to do it, but I think we need a solution for this situation.; ![Screen Shot 2021-02-26 at 1 57 37 AM](https://user-images.githubusercontent.com/106194/109244152-17be8280-77d6-11eb-8f00-c124f9c2a5c7.png). I created this example with:; ```; import hailtop.batch as hb ; b = hb.Batch(backend=hb.ServiceBackend('test')) ; for i in range(1): ; b.new_job().command('sleep 360') ; b.run() ; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10060#issuecomment-786356423:611,test,test,611,https://hail.is,https://github.com/hail-is/hail/pull/10060#issuecomment-786356423,1,['test'],['test']
Testability,"I noticed that jobs in test deployments were deadlocking because we weren't spinning up extra instances (compared to the production version of Batch). Although each job could fit on an open instance, its allocated share is still less than the core request for that job. This PR aims to increase the probability in which we ignore an exceed shares error the more we have these errors such that at a certain point the rate will be 100% and we'll be able to continue scheduling.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9464:23,test,test,23,https://hail.is,https://github.com/hail-is/hail/pull/9464,1,['test'],['test']
Testability,"I noticed that the `testIfWithDifferentRequiredness` and `testMakeArrayWithDifferentRequiredness` were failing after I added the assertion in `upcast` for #4585 . After discussing with @tpoterba , it seemed like it would be okay to allow a required type to be a subtype of an optional type. This PR also includes the assertion, which may cause other tests to fail, and so I have marked it as a WIP.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4747:20,test,testIfWithDifferentRequiredness,20,https://hail.is,https://github.com/hail-is/hail/pull/4747,5,"['assert', 'test']","['assertion', 'testIfWithDifferentRequiredness', 'testMakeArrayWithDifferentRequiredness', 'tests']"
Testability,"I noticed that the gnomAD mitochondria datasets were pointing at the `gs://gnomad-public-requester-pays` bucket. The Google Cloud Public Datasets version should be up to date now. Also updated the documented schema for chrM sites. Some information about those changes is available in the gnomAD change log: https://gnomad.broadinstitute.org/news/2021-08-rename-filter-in-mitochondria-dataset-and-minor-format-changes/. And finally, since these were the only two datasets that reference `gnomad-public-requester-pays`, removed `gnomad-public-requester-pays` from the list of annotation DB buckets used by `hailctl dataproc`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11282:302,log,log,302,https://hail.is,https://github.com/hail-is/hail/pull/11282,1,['log'],['log']
Testability,I noticed that this step blew up in the benchmarking PR and thought I'd provide a better error message.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12866:40,benchmark,benchmarking,40,https://hail.is,https://github.com/hail-is/hail/pull/12866,1,['benchmark'],['benchmarking']
Testability,I noticed this while xfail-ing a different test. It is possible this test now passes. We will see!,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12961:43,test,test,43,https://hail.is,https://github.com/hail-is/hail/pull/12961,2,['test'],['test']
Testability,"I now pass the scores_table through as a Table rather than localizing and passing through colKeys, colKeyType, and scores annotations. The column key can now be any type. Both string and integer keys are tested from Python. However, `requireUniqueSamples` still requires a single string ID (this was the remaining problem of going generic), so I've removed this check and would appreciate feedback on the best approach to checking uniqueness, preferably on the localized `keys` in PCRelate so as not to trigger additional actions. I could use keyType.valuesSimilar to compare any two elements...it's a bit weird to have a tolerance on floats here. As noted, I'm also a bit wary that I'm relying on `scores` from `pca` to be in the same order as the columns on the matrix table. This is currently true, but could change. @danking I think the joins in `fuse` should also be zipPartitions, I've noted it in a FIXME. I'm also concerned that the number of diagonal blocks is an upper bound on parallelism for the matrix multiply. We should be able to fix that by immediately writing and then reading phi.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3211#issuecomment-376385065:204,test,tested,204,https://hail.is,https://github.com/hail-is/hail/pull/3211#issuecomment-376385065,2,['test'],['tested']
Testability,"I now see an ""anyMissing"" method, which was merged yesterday, written by @patrick-schultz. It looks similar to your proposal, although my tests do not pass with it (using `sourceType.anyMissing(mb, sourceOffset).cne(const(false)).orEmpty(Code._fatal(msg))`). As an aside, I do not find it easier to read, although it is terser. There is the question of whether we want embed 4's in place of a class attribute (or instance attribute) representing that value. If that is made to work I'm ok with replacing the ensure function, although I would still prefer that align the address to 8 byte (reading bytes until that point) and check 8 byte sections for as long as possible",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7646#issuecomment-561492434:138,test,tests,138,https://hail.is,https://github.com/hail-is/hail/pull/7646#issuecomment-561492434,1,['test'],['tests']
Testability,"I observed this in my namespace while testing fixes for a different transient error.; https://internal.hail.is/dking/batch/batches/5/jobs/7034 (this URL will obviously not last long). The worker actually successfully wrote the correct output to GCS, but it received this error anyway which caused the job to fail. Since QoB checks for the results files first, it didn't even notice that the worker job had failed. That seems not great. We should probably fail if an worker job fails, even if we find output because that output could be corrupt. ```; (base) dking@wm28c-761 hail % hexdump -C foo ; 00000000 01 82 00 00 00 7e 00 00 00 67 73 3a 2f 2f 31 2d |.....~...gs://1-|; 00000010 64 61 79 2f 74 6d 70 2f 68 61 69 6c 2f 54 53 4f |day/tmp/hail/TSO|; 00000020 66 4f 72 67 5a 55 6d 62 56 69 78 6e 52 69 4b 57 |fOrgZUmbVixnRiKW|; 00000030 51 46 42 2f 61 67 67 72 65 67 61 74 65 5f 69 6e |QFB/aggregate_in|; 00000040 74 65 72 6d 65 64 69 61 74 65 73 2f 2d 50 74 33 |termediates/-Pt3|; 00000050 67 4e 74 51 57 35 57 6f 42 64 43 54 44 50 51 69 |gNtQW5WoBdCTDPQi|; 00000060 77 48 64 61 39 63 32 36 35 66 32 2d 66 62 64 38 |wHda9c265f2-fbd8|; 00000070 2d 34 66 31 62 2d 62 63 64 65 2d 66 62 66 32 39 |-4f1b-bcde-fbf29|; 00000080 31 38 30 63 33 34 37 00 00 00 00 |180c347....|; 0000008b; ```. code:; ```ipython3; In [1]: import hail as hl; ...: import gnomad.utils.sparse_mt; ...: ; ...: ; ...: tmp_dir = 'gs://danking/tmp/'; ...: vds_file = 'gs://neale-bge/bge-wave-1.vds'; ...: out = 'gs://danking/foo.vcf.bgz'; ...: ; ...: vds = hl.vds.read_vds(vds_file); ...: mt = hl.vds.to_dense_mt(vds); ...: t = gnomad.utils.sparse_mt.default_compute_info(mt); ...: t = t.annotate(info=t.info.drop('AS_SB_TABLE')); ...: t = t.annotate(info = t.info.drop(; ...: 'AS_QUALapprox', 'AS_VarDP', 'AS_SOR', 'AC_raw', 'AC', 'AS_SB'; ...: )); ...: t = t.drop('AS_lowqual'); ...: ; ...: hl.methods.export_vcf(dataset = t, output = out, tabix = True); ```; worker failure:; ```; 2023-09-27 16:43:10.389 JVMEntryway: INFO: is.hail",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943:38,test,testing,38,https://hail.is,https://github.com/hail-is/hail/issues/13721#issuecomment-1737788943,1,['test'],['testing']
Testability,I only use install-benchmark,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9567#issuecomment-704535423:19,benchmark,benchmark,19,https://hail.is,https://github.com/hail-is/hail/pull/9567#issuecomment-704535423,1,['benchmark'],['benchmark']
Testability,"I originally tried to test against SnpSift (another tool that does the same type of outer join on variants and inner join on samples), but encountered an inconsistent behavior in that tool and so wrote a slightly less rigorous unit test.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/972#issuecomment-254070715:22,test,test,22,https://hail.is,https://github.com/hail-is/hail/pull/972#issuecomment-254070715,2,['test'],['test']
Testability,I picked ld score regression and two randomish other tests to be the tests that we run with the unchecked allocator. Let me know if there are others you'd like to see added.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9568#issuecomment-704997544:53,test,tests,53,https://hail.is,https://github.com/hail-is/hail/pull/9568#issuecomment-704997544,2,['test'],['tests']
Testability,"I picked the name since Cronus is the father of Zeus. Perhaps Saturn is more appropriate. Open to suggestions here. The UX flow:. 1. User loads up `https://hail.is/cronus` and sees a form with a button.; 2. Pressing the button starts a pod running Jupyter for the user that no one else has access to; 3. refreshing the page or going to `https://hail.is/cronus` again redirects to the Jupiter instance; 4. to get a fresh Jupyter instance, the user can clear their cookies. The components:. - a flask app (`cronus/cronus.py`) which launches pods and handles authentication (via cookies); - an nginx reverse proxy which uses `auth_request` to check the permissions with the flask app; - a pod running `Jupyter notebook` with hail `pip` installed. TODO:. - [x] add make targets to generate the `cronus-job` image (the jupyter notebook image); - [ ] maybe simplify the directives used in nginx? I kept throwing shit at it until it worked; - [ ] figure out how to teach flask url_for to use a root other than `/`. I don't know what HTTP proxy headers to set to inform it that it lives at a subdirectory of `hail.is`; - [ ] get rid of the button? creating a new pod needs to be a `POST` so that the web browser doesn't access twice or eagerly access it, etc. maybe I can use javascript on the root page to make the post request and redirect the page.; - [ ] testing? I could add some basic things, but the most time consuming and annoying thing was getting the reverse proxy settings right and testing that requires an nginx instance. @cseed I randomly assigned, should I be picking from you and Tim? What's the plan for review on these new things?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4576:1351,test,testing,1351,https://hail.is,https://github.com/hail-is/hail/pull/4576,2,['test'],['testing']
Testability,I ported the `import_plink` test to methods/tests.py in #2843,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2841#issuecomment-362351992:28,test,test,28,https://hail.is,https://github.com/hail-is/hail/pull/2841#issuecomment-362351992,2,['test'],"['test', 'tests']"
Testability,"I prefer ""of"" to ""for"" (test of equilibrium like test of independence). I made all the other changes.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3875#issuecomment-401478918:24,test,test,24,https://hail.is,https://github.com/hail-is/hail/pull/3875#issuecomment-401478918,2,['test'],['test']
Testability,I prefer just hail.log.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/377#issuecomment-240002560:19,log,log,19,https://hail.is,https://github.com/hail-is/hail/issues/377#issuecomment-240002560,1,['log'],['log']
Testability,"I probably missed some, let's see what the tests find.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10119#issuecomment-786779371:43,test,tests,43,https://hail.is,https://github.com/hail-is/hail/pull/10119#issuecomment-786779371,1,['test'],['tests']
Testability,"I promise the tests all work. It's this TestNG nonsense. I'll back out my use of DataProvider, which is apparently breaking TestNG 6.8.21, but any newer version of TestNG breaks our test jar.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8803#issuecomment-629593748:14,test,tests,14,https://hail.is,https://github.com/hail-is/hail/pull/8803#issuecomment-629593748,5,"['Test', 'test']","['TestNG', 'test', 'tests']"
Testability,"I pulled out a flag to cache in java, but accidentally got rid of the thing it was actually doing. This should be fixed now; with a smaller test mt I'm seeing the number of allocated regions be consistent between combOps:. ```; ...; 2019-08-06 17:21:17 Hail: INFO: Region count for combOp; regions: 27; blocks: 28; free: 25; used: 2; 2019-08-06 17:21:17 Hail: INFO: Region count for combOp; regions: 27; blocks: 28; free: 25; used: 2; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6824:140,test,test,140,https://hail.is,https://github.com/hail-is/hail/pull/6824,1,['test'],['test']
Testability,"I pulled this out of my local whitening branch. It's being tested there, but I'm not sure the best way to write unit tests. Do we have any similar tests for STypes?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10614:59,test,tested,59,https://hail.is,https://github.com/hail-is/hail/pull/10614,3,['test'],"['tested', 'tests']"
Testability,I pushed a couple fixes for the errant tests and the drop key issue,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11665#issuecomment-1079501491:39,test,tests,39,https://hail.is,https://github.com/hail-is/hail/pull/11665#issuecomment-1079501491,1,['test'],['tests']
Testability,I pushed a test to this branch,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11675#issuecomment-1079495632:11,test,test,11,https://hail.is,https://github.com/hail-is/hail/pull/11675#issuecomment-1079495632,1,['test'],['test']
Testability,"I pushed some addition changes: push requestedType into TableRead, expose (private) in Python for performance testing. On a chunk of gnomAD sites file, read count went from 19s (all fields) to 12s (keys + 1 int field). The Python changes should get removed once prune dead fields goes in. MatrixRead will require a bit more work (with the recent unification of matrix read/import IR nodes).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3667#issuecomment-392303741:110,test,testing,110,https://hail.is,https://github.com/hail-is/hail/pull/3667#issuecomment-392303741,1,['test'],['testing']
Testability,"I pushed the logic #2861 down so I can remove this copy. I'll add that change to that PR once this is merged (good catch) since I may need to rebase anyway. See here:; https://github.com/hail-is/hail/pull/2861/files#diff-912e03c9c34a874ecdc0e520a13cb572R133. This avoids the copy if the BDM is compact, which blocks always are. If the BDM is not compact, then we could add logic to stream out the bytes without an intermediate compactification but I don't want to add that complexity now.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2848#issuecomment-363553946:13,log,logic,13,https://hail.is,https://github.com/hail-is/hail/pull/2848#issuecomment-363553946,2,['log'],['logic']
Testability,"I put point_type back. Should be ready to go now. Also, fixed the close definition, good catch. I also removed an additional use of _convert_to_j in import_bgen to get the tests to pass from this PR (sorry my stacking got a bit mixed up): https://github.com/hail-is/hail/pull/5150/files#diff-36d21c1427efe06a781cd36ef5aa8678R961. You can also wait for that to go in and I'll rebase if you're worried about the change. Finally, the imports are a bit of a mess since I wanted to use hail_type in interval.py which is also imported by the types and expr files. @tpoterba I think we should remove types from expr and remove java from utils (we're confusing user utils like hadoop_* and Interval from internal utils like Env and java stuff which don't seem related) and have a clear ""import"" graph: javautils > types > utils > expr.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5152#issuecomment-456684801:172,test,tests,172,https://hail.is,https://github.com/hail-is/hail/pull/5152#issuecomment-456684801,2,['test'],['tests']
Testability,I put the time_updated field in. I'll test it with dev deploy once everything else is ready to go.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12199#issuecomment-1252827587:38,test,test,38,https://hail.is,https://github.com/hail-is/hail/pull/12199#issuecomment-1252827587,1,['test'],['test']
Testability,I ran a full benchmark comparison and didn't see any significant changes. I realize now there are no benchmarks for `to_matrix_table_row_major`. I'm adding such a benchmark and running it now.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9328#issuecomment-679425628:13,benchmark,benchmark,13,https://hail.is,https://github.com/hail-is/hail/pull/9328#issuecomment-679425628,3,['benchmark'],"['benchmark', 'benchmarks']"
Testability,"I ran into issues when broadcasting a very large struct of ndarrays for a huge linear regression, where the the total size was more than `MAX_INT` bytes. To solve this, I've changed `SerializableRegionValue` to use `ArrayOfByteArrayOutputStream` and `ArrayOfByteInputStream`, which create nested arrays of bytes instead of just one array, removing any maximum length issues. . PRing now for tests, also running benchmarks.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10766:391,test,tests,391,https://hail.is,https://github.com/hail-is/hail/pull/10766,2,"['benchmark', 'test']","['benchmarks', 'tests']"
Testability,I ran into missing type information while I was writing the tests in https://github.com/hail-is/hail/pull/13400,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13401:60,test,tests,60,https://hail.is,https://github.com/hail-is/hail/pull/13401,1,['test'],['tests']
Testability,I ran into this today...spent a bit of time debugging and was able to ssh to one of the workers and poke around the `docker` logs. The issue appears to be some kind of race between the `docker` install that the `VEP` initialization script does and the limited number of retries by `systemd` to get the `docker` daemon up and running. . Adding `sudo service docker restart` at the end of the the `VEP` initialization bash script worked as a short term fix.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12936#issuecomment-1589956412:125,log,logs,125,https://hail.is,https://github.com/hail-is/hail/issues/12936#issuecomment-1589956412,1,['log'],['logs']
Testability,I ran my migration test. Worked perfectly. I say this is ready to go.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7997:19,test,test,19,https://hail.is,https://github.com/hail-is/hail/pull/7997,1,['test'],['test']
Testability,"I ran the python tests with my latest changes and they all passed. I'll work on addressing comments and adding tests, but this should be ready for another round of code review.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6266#issuecomment-504217666:17,test,tests,17,https://hail.is,https://github.com/hail-is/hail/pull/6266#issuecomment-504217666,2,['test'],['tests']
Testability,"I ran the stress test. It finished in 8 minutes which makes for a paltry 2 jobs per second. That was largely driven by three jobs that took 5 minutes (!!!) to upload their logs to GCS. No idea what's going on there, but clearly unrelated to these DB changes. If you ignore those jobs and the private jobs, which required VM spin up, it only took 3 minutes, which is still an unfortunate 6 jobs per second, but I have more speed coming.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10985#issuecomment-954864994:17,test,test,17,https://hail.is,https://github.com/hail-is/hail/pull/10985#issuecomment-954864994,4,"['log', 'test']","['logs', 'test']"
Testability,I ran the unit tests locally with no issues - what failed?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6676#issuecomment-512932609:15,test,tests,15,https://hail.is,https://github.com/hail-is/hail/pull/6676#issuecomment-512932609,1,['test'],['tests']
Testability,"I ran two tests. The one you suggested, 10k/10k, and one with a better work-to-partition ratio: 1M/1k. I was a bit surprised to see that the cost ratio is larger with fewer partitions and more work. We range from 15x to 3x slower. . This branch:; ```python; In [3]: %%time ; ...: ; ...: import hail as hl ; ...: ht = hl.utils.range_table(10000, n_partitions=10000) ; ...: ht = ht.annotate(rank = hl.scan.count())._force_count() ; CPU times: user 17 ms, sys: 6.36 ms, total: 23.4 ms; Wall time: 1min 16s. In [1]: %%time ; ...: ; ...: import hail as hl ; ...: ht = hl.utils.range_table(1000000, n_partitions=1000) ; ...: ht = ht.annotate(rank = hl.scan.count())._force_count() ; CPU times: user 1.42 s, sys: 303 ms, total: 1.73 s; Wall time: 15.2 s. ```. Master `0.2.14-4da055db5a7b`; ```python; In [1]: %%time ; ...: ; ...: import hail as hl ; ...: ht = hl.utils.range_table(10000, n_partitions=10000) ; ...: ht = ht.annotate(rank = hl.scan.count())._force_count() ; CPU times: user 1.45 s, sys: 333 ms, total: 1.78 s; Wall time: 24.6 s; In [3]: %%time ; ...: ; ...: import hail as hl ; ...: ht = hl.utils.range_table(1000000, n_partitions=1000) ; ...: ht = ht.annotate(rank = hl.scan.count())._force_count() ; CPU times: user 6.23 ms, sys: 1.96 ms, total: 8.19 ms; Wall time: 1.33 s; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6291#issuecomment-500453080:10,test,tests,10,https://hail.is,https://github.com/hail-is/hail/pull/6291#issuecomment-500453080,1,['test'],['tests']
Testability,"I realize this looks like a lot of code changes, but it's mostly copying and pasting two SQL procedures and changing one line in each. This adds 4 bits of metadata to requests that then can be queried as extra metadata:; - batch_id; - job_id; - batch_operation; - job_queue_time. Should be self-explanatory except job_queue time is the time in which the job is first set to ready to when it was scheduled on the worker (exact moment is when the job config is made to send to the worker). Example logging query. Note that the search on ""batch_id"" is not optimized so you definitely want to add some kind of time limit that's short on the window to search. I can add my Python script that scrapes these logs and makes a Plotly figure in a separate PR once this goes in. ```; (; resource.labels.container_name=""batch""; resource.labels.namespace_name=""{namespace}""; ) OR (; resource.labels.container_name=""batch-driver""; resource.labels.namespace_name=""{namespace}""; ) OR (; resource.type=""gce_instance""; logName:""worker.log""; labels.""compute.googleapis.com/resource_name"":""{namespace}""; ); jsonPayload.batch_id=""{batch_id}""; timestamp >= ""{start_timestamp}"" {end_timestamp}; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13219:496,log,logging,496,https://hail.is,https://github.com/hail-is/hail/pull/13219,4,['log'],"['log', 'logName', 'logging', 'logs']"
Testability,I really like that the test methods mirror the source code structure. Were there other changes? I see this `..helpers` thing collects a few different test related things. Seems good.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3887#issuecomment-402119610:23,test,test,23,https://hail.is,https://github.com/hail-is/hail/pull/3887#issuecomment-402119610,2,['test'],['test']
Testability,I received a 503 in one of my other PRs from one of these tests.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10947:58,test,tests,58,https://hail.is,https://github.com/hail-is/hail/pull/10947,1,['test'],['tests']
Testability,I remember having to fix the balding_nichols test multiple times. It's possible there's some issue with it I didn't properly diagnose.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12588#issuecomment-1397387396:45,test,test,45,https://hail.is,https://github.com/hail-is/hail/pull/12588#issuecomment-1397387396,1,['test'],['test']
Testability,I removed PSubsetStructSuite because it is testing functionality that won't really be part of the SCode interface and will go away soon.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10047:43,test,testing,43,https://hail.is,https://github.com/hail-is/hail/pull/10047,1,['test'],['testing']
Testability,"I removed `test_hail_java` parallelism since the array ordering both fails & segfaults when multiple threads are executing the tests. This seems really bad, but I also don't care to fix it in this PR.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6863#issuecomment-521659615:127,test,tests,127,https://hail.is,https://github.com/hail-is/hail/pull/6863#issuecomment-521659615,1,['test'],['tests']
Testability,I removed a test that asserted it didn't work on datasets with unknown fields. Maybe we should print a warning with the list of fields that weren't modified?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3625#issuecomment-390310387:12,test,test,12,https://hail.is,https://github.com/hail-is/hail/pull/3625#issuecomment-390310387,2,"['assert', 'test']","['asserted', 'test']"
Testability,"I removed the assertions about the chain of IRState properties. We could take the parameters in OptimizePass, but that seems a bit hacky/unnecessary. The IRStates are checked at runtime, so I'm confident we'll still be able to debug issues.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9030#issuecomment-651918109:14,assert,assertions,14,https://hail.is,https://github.com/hail-is/hail/pull/9030#issuecomment-651918109,1,['assert'],['assertions']
Testability,"I removed window.history.scrollRestoration = 'manual'. This has the effect of making Chrome and Firefox exhibit the same behavior (overshoot), and Safari show the ""correct"" behavior (no overshoot). 1 fewer change, the same amount of consistency across tested browsers.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7385#issuecomment-546427387:252,test,tested,252,https://hail.is,https://github.com/hail-is/hail/pull/7385#issuecomment-546427387,1,['test'],['tested']
Testability,"I reordered the tests so we can be confident that the files aren't overwriting each other, and changed the second assertion to use the correct filepath. However, I'm confused how main and this PR can both pass…",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12315:16,test,tests,16,https://hail.is,https://github.com/hail-is/hail/pull/12315,2,"['assert', 'test']","['assertion', 'tests']"
Testability,"I replicated the issue with this:; ```; In [1]: grch37 = hl.get_reference('GRCh37'). In [2]: grch37.add_liftover('src/test/resources/grch37_to_grch38_chr20.over.chain.gz', 'GRCh38'). In [3]: i = hl.parse_locus_interval('1:10000-10000'). In [4]: hl.eval(hl.liftover(i)); ```. The issue is this interval is `Interval(10000, 10000, includesStart=True, includesEnd=False)` which has a length of zero. @patrick-schultz Should this be a valid interval? i.e. start==end and includesStart = True and includesEnd = False. Otherwise, if it is a valid Hail interval, then I'll throw a nicer error message.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5174#issuecomment-455713308:118,test,test,118,https://hail.is,https://github.com/hail-is/hail/issues/5174#issuecomment-455713308,1,['test'],['test']
Testability,I reproduced this by running all the tests together. There's some inter-test leakage.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11637#issuecomment-1078451016:37,test,tests,37,https://hail.is,https://github.com/hail-is/hail/pull/11637#issuecomment-1078451016,2,['test'],"['test', 'tests']"
Testability,"I reran the benchmarks with nothing else running on my laptop. I think this should work right?. ```; git checkout pc-relate && \; git status && \; python3 -m benchmark_hail run -t pc_relate,pc_relate_big && \; git checkout master && \; (cd ../../hail && make install) && \; git status && \; git checkout pc-relate && \; python3 -m benchmark_hail run -t pc_relate,pc_relate_big; ```; Benchmark should import the installed hail. pc-relate branch:; ```; 2020-01-24 18:38:08,147: INFO: burn in: 30.09s; 2020-01-24 18:38:35,904: INFO: run 1: 27.75s; 2020-01-24 18:39:03,001: INFO: run 2: 27.09s; 2020-01-24 18:39:29,144: INFO: run 3: 26.14s; ```; master:; ```; 2020-01-24 18:41:08,254: INFO: burn in: 32.71s; 2020-01-24 18:41:37,239: INFO: run 1: 28.98s; 2020-01-24 18:42:05,393: INFO: run 2: 28.15s; 2020-01-24 18:42:33,411: INFO: run 3: 28.01s; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7962#issuecomment-578344916:12,benchmark,benchmarks,12,https://hail.is,https://github.com/hail-is/hail/pull/7962#issuecomment-578344916,2,"['Benchmark', 'benchmark']","['Benchmark', 'benchmarks']"
Testability,"I resolved conflicts. There were two issues in ir.py and one in aggregators.py. The former were resolved by: replace if with assert, add a new field about needing randomness. The latter is visible in the diff and switches from frozenset to set.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12139#issuecomment-1314255082:125,assert,assert,125,https://hail.is,https://github.com/hail-is/hail/pull/12139#issuecomment-1314255082,1,['assert'],['assert']
Testability,I restarted hail ci and then saw batch claim to create jobs that never appear in `kubectl get pods`. [batch.log](https://github.com/hail-is/hail/files/2498270/batch.log); [hail-ci.log](https://github.com/hail-is/hail/files/2498271/hail-ci.log),MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4591#issuecomment-431590377:108,log,log,108,https://hail.is,https://github.com/hail-is/hail/issues/4591#issuecomment-431590377,4,['log'],['log']
Testability,I reworked the test so no longer connected to this issue,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3785#issuecomment-399810479:15,test,test,15,https://hail.is,https://github.com/hail-is/hail/issues/3785#issuecomment-399810479,1,['test'],['test']
Testability,I saw a case where this loop was spinning generating $$$ logs.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7637:57,log,logs,57,https://hail.is,https://github.com/hail-is/hail/pull/7637,1,['log'],['logs']
Testability,"I saw this again today in a fairly simple and isolated test. I'm beginning to wonder if this is just a new form of transient error. We pick 22 random characters from a 62 character alphabet. Odds of collision are minuscule:; ```; In [2]: (1/62)**22; Out[2]: 3.693029961058969e-40; ```; I verified `SecureRandom` with no constructor uses a randomly chosen seed. There's three exceptions there (all the same one). The deepest one came during a write. The next two came during closes. The outermost exception is from the `using` cleaning up. I'm not sure where the middle exception comes from, I can't imagine who would try to `close` the stream other than `using`. Regardless, it appears that the upload fails in some unrecoverable way. We're writing 2GiB in 256 8MiB chunks in this test, so we have more chances for something to go wrong. Maybe we just have to retry the entire partition when this happens?. https://ci.hail.is/batches/7404773/jobs/145; ```; starting test is.hail.fs.gs.GoogleStorageFSSuite.testSeekMoreThanMaxInt...; Exception:; is.hail.relocated.com.google.cloud.storage.StorageException: Unable to recover in upload.; This may be a symptom of multiple clients uploading to the same upload session. For debugging purposes:; uploadId: https://storage.googleapis.com/upload/storage/v1/b/hail-test-ezlis/o?name=fs-suite-tmp-6BO4gZ18Lheigp3ir9RSOh&uploadType=resumable&upload_id=ADPycduiXx2Jtiy_0Ll131_pPeEYKnnA23Hlk28_9TFESUMaubA9OqLK_n8Td5rPhTXnlpssGo796Q4bJxUeblhmSaYcCSWAMg2k; chunkOffset: 16777216; chunkLength: 8388608; localOffset: 1325400064; remoteOffset: 1342177280; lastChunk: false. 	at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.unrecoverableState(BlobWriteChannel.java:131); 	at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.unrecoverableState(BlobWriteChannel.java:87); 	at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.access$1000(BlobWriteChannel.java:35); 	at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel$1.run",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12950#issuecomment-1544209756:55,test,test,55,https://hail.is,https://github.com/hail-is/hail/issues/12950#issuecomment-1544209756,6,['test'],['test']
Testability,I say we just merge it and then your change (with the test) will go in.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5471#issuecomment-469341988:54,test,test,54,https://hail.is,https://github.com/hail-is/hail/pull/5471#issuecomment-469341988,1,['test'],['test']
Testability,"I search the google logs for the pull request in question. For example,. ```; (resource.labels.namespace_name=""pr-11471-default-fn1xhr9ahy9v"" AND; labels.""k8s-pod/app"":""batch""; ) OR (; labels.""compute.googleapis.com/resource_name"":""batch-worker-pr-11471-default-fn1xhr9ahy9v"" AND; logName:""worker.log""); ```. That PR seems to have a worker stuck alive: `batch-worker-pr-11471-default-fn1xhr9ahy9v-standard-ux0sp`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11471#issuecomment-1059448548:20,log,logs,20,https://hail.is,https://github.com/hail-is/hail/pull/11471#issuecomment-1059448548,3,['log'],"['log', 'logName', 'logs']"
Testability,"I searched [here](https://portal.azure.com#@d6c9f2ea-d3bb-4ca9-8b14-231bac999aa6/blade/Microsoft_OperationsManagementSuite_Workspace/Logs.ReactView/resourceId/%2Fsubscriptions%2F22cd45fe-f996-4c51-af67-ef329d977519%2Fresourcegroups%2Fhaildev%2Fproviders%2Fmicrosoft.operationalinsights%2Fworkspaces%2Fhaildev-logs/source/LogsBlade.AnalyticsShareLinkToQuery/q/H4sIAAAAAAAAA21Sy27CMBC88xVbLiRSqNprUSpVgFpUVCraOzLxJhgcO7LNI2r7710nKRBoDokzmp2dnbVEB6%252FbJb5rPtWZhRiCQnPFciwMpuLwYJ0RKovAQ7ZgCR4RqTOJO5QNEMJXB%252BiRpDjUyjGh0Ez4VFhHqk2PidqhctqUFfUb9is0CG%252BkDdYx4%252BxeuBUdTcJc20gE3X43bJURTaIKTs1G4ePdlXBlGuL4NEFD4eRMqOTc7SgCHwRbooxOxRU4KWpkUFUfSyi0Rg4PDhUHGs%252BUccGMxcXaahUQY%252ByxsM0jbcsyjCv%252BbfPXMn9mC4SC4CLUdha1jKV9GOFKP%252B7fev6h4SFZCJVquElqTQvdj5enbkOVWm%252B2BWyE4rHE1OmtQ3PdH7Q699gUF0avMXF9tmclTHIaKqo%252Fn4zuzBwLbYW%252FAHWaEXyKHGfpUOc5U%252FxCw6DfmU%252Ffc2P%252Fuu%252F8DDpnFzboJaIXQY9jyrbS%252BeN4Pp%252FNeyHpaMPJ%252BLKsmjwj2WQOOXC0yS9DxlTe%252BAIAAA%253D%253D/timespan/2023-04-16T20%3A37%3A28.000Z%2F2023-04-28T20%3A37%3A28.000Z) and couldn't really find anything insightful. It does feel odd that we went that long with so *few* error messages, so maybe some silent error.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13050#issuecomment-1561910142:133,Log,Logs,133,https://hail.is,https://github.com/hail-is/hail/issues/13050#issuecomment-1561910142,3,"['Log', 'log']","['Logs', 'LogsBlade', 'logs']"
Testability,"I see this happening quite a bit. ```; =================================== FAILURES ===================================; ______________________________ Test.test_callback ______________________________. self = <test.test_batch.Test testMethod=test_callback>. def test_callback(self):; app = Flask('test-client'); ; d = {}; ; @app.route('/test', methods=['POST']); def test():; d['status'] = request.get_json(); return Response(status=200); ; server = ServerThread(app); try:; server.start(); ; j = self.batch.create_job(; 'alpine',; ['echo', 'test'],; attributes={'foo': 'bar'},; callback=server.url_for('/test')); j.wait(); ; > status = d['status']; E KeyError: 'status'; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5817:152,Test,Test,152,https://hail.is,https://github.com/hail-is/hail/issues/5817,9,"['Test', 'test']","['Test', 'test', 'test-client', 'testMethod']"
Testability,"I see what is happening. . The Hail cluster install instructions specify the following for a spark cluster:. export PYSPARK_SUBMIT_ARGS=""\; --jars $HAIL_HOME/build/libs/hail-all-spark.jar \; --conf spark.driver.extraClassPath=\""$HAIL_HOME/build/libs/hail-all-spark.jar\"" \; --conf spark.executor.extraClassPath=./hail-all-spark.jar \; --conf spark.serializer=org.apache.spark.serializer.KryoSerializer \; --conf spark.kryo.registrator=is.hail.kryo.HailKryoRegistrator; pyspark-shell"". On our cluster, this will run as a local job. It needs a ""--master yarn"" for an argument. Running it locally probably is related to the out of memory error and the limited cores. I will rerun this with the --master yarn argument. . Regarding the bgen file versus matrix table, are you suggesting, it would be faster to run an analysis such as a logistic regression starting with the bgen file instead of the imported bgen mt file. The phenotypes would need to annotated the imported bgen mt every time. Just trying to understand the trade offs.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4780#issuecomment-439414395:830,log,logistic,830,https://hail.is,https://github.com/hail-is/hail/issues/4780#issuecomment-439414395,1,['log'],['logistic']
Testability,"I see, so you receive an access denied when there are no artifacts. The build log has a long list of commands, starting with a git clone. It sounds like this isn't an issue then.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5546#issuecomment-472479806:78,log,log,78,https://hail.is,https://github.com/hail-is/hail/issues/5546#issuecomment-472479806,1,['log'],['log']
Testability,I see. It's a bug in that the debug information if the test had failed would have been wrong / thrown an error. But the actual test right now was testing the right thing. Is this correct?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11203#issuecomment-1006756945:55,test,test,55,https://hail.is,https://github.com/hail-is/hail/pull/11203#issuecomment-1006756945,3,['test'],"['test', 'testing']"
Testability,I semi-tested this as follows: deployed in auth and created a user. The logic then failed with 403 Forbidden because the dev namespace gsa can't create service accounts.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8798#issuecomment-628891104:7,test,tested,7,https://hail.is,https://github.com/hail-is/hail/pull/8798#issuecomment-628891104,2,"['log', 'test']","['logic', 'tested']"
Testability,I should add the test first!,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4846#issuecomment-442536971:17,test,test,17,https://hail.is,https://github.com/hail-is/hail/pull/4846#issuecomment-442536971,1,['test'],['test']
Testability,I should also note that I've already done this and verified that my IP appears in the logs.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8045#issuecomment-582620130:86,log,logs,86,https://hail.is,https://github.com/hail-is/hail/pull/8045#issuecomment-582620130,1,['log'],['logs']
Testability,"I should have removed it when I was done. I used it to debug a bunch of stuff. I do not understand why, but, by default, no messages are printed. Setting the level to WARNING at least got my `log.warn` messages to print, of which I temporarily added many during debugging of insert. Anyway, I agree with the latter statement.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7990#issuecomment-579967208:192,log,log,192,https://hail.is,https://github.com/hail-is/hail/pull/7990#issuecomment-579967208,1,['log'],['log']
Testability,"I should have tests in python for the functionality I need, so if those are passing it should be OK, but let's talk tomorrow. It turns out caitlin's hack is getting spread around a bit because lots of folks want to do PRS, it would be good to go from hack to the better solution in one PR.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4102#issuecomment-411237753:14,test,tests,14,https://hail.is,https://github.com/hail-is/hail/pull/4102#issuecomment-411237753,1,['test'],['tests']
Testability,"I should still add a whole bunch of Python tests before this goes in, but everything seems to work so review appreciated.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3164:43,test,tests,43,https://hail.is,https://github.com/hail-is/hail/pull/3164,1,['test'],['tests']
Testability,I should think more about how to benchmark this properly.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7962#issuecomment-578338479:33,benchmark,benchmark,33,https://hail.is,https://github.com/hail-is/hail/pull/7962#issuecomment-578338479,1,['benchmark'],['benchmark']
Testability,I sometimes iterate quickly with `pytest -k testname` from the `hail/python` directory. I cannot do that if the test directory is hard coded.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12795:44,test,testname,44,https://hail.is,https://github.com/hail-is/hail/pull/12795,2,['test'],"['test', 'testname']"
Testability,"I split it up into 5 separate tests, and I took away one of the 3 data sizes we test on, so it's faster and more easily split now. Let me know if you think there's other things we can remove/change without losing information.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10415:30,test,tests,30,https://hail.is,https://github.com/hail-is/hail/pull/10415,2,['test'],"['test', 'tests']"
Testability,"I spot checked, and noticed that [`log-b.png`](https://github.com/hail-is/hail/blob/aa3cd5c4a64247a550e9fd61e79c0b7de7713559/graphics/32x32/log-b.png) looks like just blue?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9382#issuecomment-684007827:35,log,log-b,35,https://hail.is,https://github.com/hail-is/hail/pull/9382#issuecomment-684007827,2,['log'],['log-b']
Testability,"I staged `import_matrix_table` and achieved substantial performance improvements. A few changes were necessary:; - `FunctionBuilder` now accepts `Code[Unit]` to be added to the `init` method of the function object; - SRVB now has an `init` method that should be called in the `init` method of a function object if many methods will share the SRVB; - `CodeChar` now exists. The main change is in `ImportMatrix.scala` which is both staged and based on scanning the string rather than using `String.split`. The approach is essentially a simplified, staged version of `import_vcf`. I benchmarked the change with:; ```; In [2]: %%time ; ...: import hail as hl ; ...: m = hl.import_matrix_table('/tmp/foo.tsv.gz', ; ...: row_fields={'f0': hl.tstr}, ; ...: no_header=True, ; ...: sep=' ', ; ...: min_partitions=16) ; ...: m = m.key_rows_by(locus=hl.parse_locus(m.f0)) ; ...: m._force_count_rows() ; ```. `/tmp/foo.tsv.gz` is a gzipped (not blocked) 1GB of 1000 rows each containing one row column and 500k sample columns. The entries are the integers from 0 to 499,999. The first column is the first run (when the JIT is warmed) and the second column is the mean of two subsequent runs. All times in seconds. Everything is necessarily executed on one core. | version | cold | warm |; | --- | --- | --- |; | this PR | 48 | 39.35 |; | this PR with one monolithic method | 235 | 73 |; | master (5fe6737263b4) | 91s | 83.5 |. I was disappointed with the performance of the monolithic method, so I dug in with `-XX:+PrintCompilation` and found that the JIT was having trouble doing on-stack replacement of the entry parsing loop. There was a cryptic message about the stack not being empty during an OSR compilation. I take this result as evidence that, in the JVM, small, fine-grained methods are critical for reliable performance. The new code, after JIT warming, is reading at 250 MB/s (1GB / 40 seconds) which is a half to a third of the performance of `cat`. It's more than twice as fast as the old code. Asi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6987:580,benchmark,benchmarked,580,https://hail.is,https://github.com/hail-is/hail/pull/6987,1,['benchmark'],['benchmarked']
Testability,"I started looking into the test failures last week, but I can't reproduce them locally; I'm very confused. Anyways, I'm working on it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7134#issuecomment-542281084:27,test,test,27,https://hail.is,https://github.com/hail-is/hail/pull/7134#issuecomment-542281084,1,['test'],['test']
Testability,I started to debug #13599 and found this feature of knowing which job spun off the test batch would have been helpful for debugging purposes.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13733:83,test,test,83,https://hail.is,https://github.com/hail-is/hail/pull/13733,1,['test'],['test']
Testability,"I still need to figure out where to move the pipeline tests to and whether to rename the BatchBackend to BatchServiceBackend. Making a PR now so I can see if there are any other bugs. Also, I didn't rename where the docs path is in the header navbar yet. This needs to be done when we release a new Hail release after this PR goes in. @johnc1231 @tpoterba",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8453:54,test,tests,54,https://hail.is,https://github.com/hail-is/hail/pull/8453,1,['test'],['tests']
Testability,I still need to test this on the real database. Will do once the PR this is stacked on goes in.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12006#issuecomment-1211067004:16,test,test,16,https://hail.is,https://github.com/hail-is/hail/pull/12006#issuecomment-1211067004,1,['test'],['test']
Testability,"I still need to test this with dev deploy, but at least it's on the radar again.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12848#issuecomment-1680688341:16,test,test,16,https://hail.is,https://github.com/hail-is/hail/pull/12848#issuecomment-1680688341,1,['test'],['test']
Testability,I still need to test this works with dev deploy.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11118:16,test,test,16,https://hail.is,https://github.com/hail-is/hail/pull/11118,1,['test'],['test']
Testability,"I suppose I'm a bit confused about what happens if you await the completion of yourself. We should probably filter out the `asyncio.current_task()`. I agree with the spirit of your sentence. It is problematic because somewhere *else* we're not properly stopping an infinite loop. Ideally we'll get to a place where we try to kill a pod and if it doesn't terminate in, say, 5 seconds, we fail the CI tests.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9944#issuecomment-769104764:399,test,tests,399,https://hail.is,https://github.com/hail-is/hail/pull/9944#issuecomment-769104764,1,['test'],['tests']
Testability,"I suppose this is where I started getting entangled with the domain issue. If the Australians run a workshop, what should happen if their users run `hailctl batch init`? Should they have to supply some additional argument so that _if_ they're not authenticated they get sent somewhere other than `hail.is`? Maybe that's ok, seems kind of awkward though. While it doesn't work this way today, I imagine that we should ultimately configure `hailctl auth login` to accept a domain. I feel like that would make the AUS scenario slightly less awkward, and the tool more consistent, though I admit it is conceding some of our own convenience.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13279#issuecomment-1663110567:452,log,login,452,https://hail.is,https://github.com/hail-is/hail/pull/13279#issuecomment-1663110567,1,['log'],['login']
Testability,"I suspect some of the inconsistent behavior we're seeing could be due to memory corruption. So I put in another debugging allocator. What does this do? It makes sure all memory accesses in `Memory` are valid. Also, for each allocation, it puts a sentinel values before and after the allocation, and verifies they are undisturbed on free. How will this work normally? Obviously, this will slow things down. This checked `Memory` will be stored outside the main source, and can be copied over `Memory` to run with checked memory. Once this is passing, I will organize it that way. We should probably always run a version of the tests with memory checking enabled. Am I seeing failures? Yes, a handful. Unfortunately, the failures themselves don't seem context dependent, and when I run all the tests things fail, but when I run the isolated test, they pass. Getting this on the board while we debug it.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8878:626,test,tests,626,https://hail.is,https://github.com/hail-is/hail/pull/8878,3,['test'],"['test', 'tests']"
Testability,I switched the test to use a balding_nichols_model dataset (positions are unique) with `r2=0.1`.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3704#issuecomment-394866711:15,test,test,15,https://hail.is,https://github.com/hail-is/hail/pull/3704#issuecomment-394866711,1,['test'],['test']
Testability,I talked to Cotton about it and he said not to. But it's not clear how much of a difference that makes yet anyway. I think this version is pretty good and an improvement. Plus it'll add a benchmark which we can work on optimizing.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9209#issuecomment-668622849:188,benchmark,benchmark,188,https://hail.is,https://github.com/hail-is/hail/pull/9209#issuecomment-668622849,2,['benchmark'],['benchmark']
Testability,"I temporarily added this test to `OrderedRDD.coerce`:. ```; fastKeys match {; case Some(fastKeys) =>; assert(fastKeys.partitions.length == rdd.partitions.length). val A = fastKeys.mapPartitionsWithIndex { case (i, it) =>; Iterator((i, it.toSet)); }.collectAsMap(); val B = rdd.map(_._1); .mapPartitionsWithIndex { case (i, it) =>; Iterator((i, it.toSet)); }.collectAsMap(); assert(A == B); case None =>; }; ```. It is too expensive to run all the time. It also fails for `LoadVCF`, which doesn't filter the symbolic variants in `justVariants`. This can be fixed by filtering once beforehand.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/824#issuecomment-248632396:25,test,test,25,https://hail.is,https://github.com/hail-is/hail/pull/824#issuecomment-248632396,3,"['assert', 'test']","['assert', 'test']"
Testability,"I tested `wget http://batch/jobs` from within the cluster...that works fine. However, I do see something potentially relevant in the output, pertaining to it seems a CI deployment attempt of batch (I don't see a timestamp, but this is the last job run). ```; deployment.yaml\nkubectl delete persistentvolumeclaim --all --namespace test\nError from server (Forbidden): persistentvolumeclaims is forbidden: User \""system:serviceaccount:batch-pods:deploy-svc\"" cannot list persistentvolumeclaims in the namespace \""test\""\nMakefile:70: recipe for target 'deploy' failed\nmake: *** [deploy] Error 1\n""},""state"":""Complete""}]; ```. Namely `system:serviceaccount:batch-pods:deploy-svc cannot list persistentvolumeclaims in the namespace \""test\`",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5503#issuecomment-468935751:2,test,tested,2,https://hail.is,https://github.com/hail-is/hail/pull/5503#issuecomment-468935751,4,['test'],"['test', 'tested']"
Testability,"I tested deploy locally, and things worked great.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6136#issuecomment-494081311:2,test,tested,2,https://hail.is,https://github.com/hail-is/hail/pull/6136#issuecomment-494081311,1,['test'],['tested']
Testability,I tested everything by hand in my namespace including the UI and it all looked good.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11397#issuecomment-1067362173:2,test,tested,2,https://hail.is,https://github.com/hail-is/hail/pull/11397#issuecomment-1067362173,1,['test'],['tested']
Testability,"I tested it against this:. ```; ht = hl.read_table('gs://danking/ALL.chip.omni_broad_sanger_combined.20140818.snps.genotypes-hail-bff300d475ac-sites.t'); context_mt = hl.read_matrix_table('gs://danking/ALL.chip.omni_broad_sanger_combined.20140818.snps.genotypes-hail-bff300d475ac.mt'); ht.annotate(**context_mt[ht.key, :])._force_count(); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3609#issuecomment-390215942:2,test,tested,2,https://hail.is,https://github.com/hail-is/hail/pull/3609#issuecomment-390215942,1,['test'],['tested']
Testability,I tested on my local machine and it indeed modified the native lib prebuilt file and did so before running `shadowJar`.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6134#issuecomment-494054260:2,test,tested,2,https://hail.is,https://github.com/hail-is/hail/pull/6134#issuecomment-494054260,1,['test'],['tested']
Testability,I tested the commands by creating a service account with 0 permissions and making sure that I could give it access and could read/write to the bucket and gcr.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8840#issuecomment-631733744:2,test,tested,2,https://hail.is,https://github.com/hail-is/hail/pull/8840#issuecomment-631733744,1,['test'],['tested']
Testability,I tested the config comes through correctly in my namespace.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10839:2,test,tested,2,https://hail.is,https://github.com/hail-is/hail/pull/10839,1,['test'],['tested']
Testability,I tested this a bit manually. I'm pretty confident its right but I'm sure we'll hit some snag on the next deploy.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11916:2,test,tested,2,https://hail.is,https://github.com/hail-is/hail/pull/11916,1,['test'],['tested']
Testability,"I tested this and it indeed has no conflicts if I include Daniel, Jackie, and I in the oauth2 callbacks list.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11322:2,test,tested,2,https://hail.is,https://github.com/hail-is/hail/pull/11322,1,['test'],['tested']
Testability,"I tested this by adding an assertion error that would get hit just before the while loop.With the old code, we always hit the assertion, with the new code, we do not.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8497#issuecomment-610732635:2,test,tested,2,https://hail.is,https://github.com/hail-is/hail/pull/8497#issuecomment-610732635,3,"['assert', 'test']","['assertion', 'tested']"
Testability,I tested this by adding the check_aggregated_resources loop which didn't throw any errors. I tested the cost by looking at the UI and submitting one job that cost $0.0004 and then two of that same job in a batch and it cost $0.0008. The database looked like this:. mysql> select * FROM aggregated_batch_resources where batch_id > 46;; +----------+--------------------------+-------------+-------+; | batch_id | resource | usage | token |; +----------+--------------------------+-------------+-------+; | 47 | compute/n1-preemptible/1 | 25867000 | 11 |; | 47 | compute/n1-preemptible/1 | 0 | 115 |; | 47 | compute/n1-preemptible/1 | 0 | 132 |; | 47 | disk/local-ssd/1 | 9932928000 | 11 |; | 47 | disk/local-ssd/1 | 0 | 54 |; | 47 | disk/local-ssd/1 | 0 | 132 |; | 47 | disk/pd-ssd/1 | 529756160 | 11 |; | 47 | disk/pd-ssd/1 | 0 | 132 |; | 47 | disk/pd-ssd/1 | 0 | 186 |; | 47 | ip-fee/1024/1 | 26487808 | 11 |; | 47 | ip-fee/1024/1 | 0 | 132 |; | 47 | ip-fee/1024/1 | 0 | 188 |; | 47 | memory/n1-preemptible/1 | 99329280 | 11 |; | 47 | memory/n1-preemptible/1 | 0 | 26 |; | 47 | memory/n1-preemptible/1 | 0 | 132 |; | 47 | service-fee/1 | 25867000 | 11 |; | 47 | service-fee/1 | 0 | 110 |; | 47 | service-fee/1 | 0 | 132 |; | 48 | compute/n1-preemptible/1 | 0 | 31 |; | 48 | compute/n1-preemptible/1 | 0 | 76 |; | 48 | compute/n1-preemptible/1 | 27659000 | 94 |; | 48 | compute/n1-preemptible/1 | 26520000 | 122 |; | 48 | compute/n1-preemptible/1 | 0 | 156 |; | 48 | compute/n1-preemptible/1 | 0 | 168 |; | 48 | disk/local-ssd/1 | 10621056000 | 94 |; | 48 | disk/local-ssd/1 | 10183680000 | 122 |; | 48 | disk/local-ssd/1 | 0 | 125 |; | 48 | disk/local-ssd/1 | 0 | 154 |; | 48 | disk/local-ssd/1 | 0 | 156 |; | 48 | disk/local-ssd/1 | 0 | 168 |; | 48 | disk/pd-ssd/1 | 0 | 69 |; | 48 | disk/pd-ssd/1 | 566456320 | 94 |; | 48 | disk/pd-ssd/1 | 0 | 102 |; | 48 | disk/pd-ssd/1 | 543129600 | 122 |; | 48 | disk/pd-ssd/1 | 0 | 156 |; | 48 | disk/pd-ssd/1 | 0 | 168 |; | 48 | ip-fee/1024/1 | 0 | 57 |; | 48 ,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9346:2,test,tested,2,https://hail.is,https://github.com/hail-is/hail/pull/9346,2,['test'],['tested']
Testability,I tested this by applying it to the cluster directly (I ran make deploy in the `gateway/` project). It will continue to run until a master deploy blows it away.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4645#issuecomment-433180843:2,test,tested,2,https://hail.is,https://github.com/hail-is/hail/pull/4645#issuecomment-433180843,1,['test'],['tested']
Testability,I tested this by applying it to the cluster directly (I ran make deploy in the gateway/ project). It will continue to run until a master deploy blows it away.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4648#issuecomment-433191315:2,test,tested,2,https://hail.is,https://github.com/hail-is/hail/pull/4648#issuecomment-433191315,1,['test'],['tested']
Testability,I tested this by creating 100 batches with my username and then running exactly the code here but with `dking` in place of `test`. It cancelled all 100 batches quickly (a couple seconds).,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11679#issuecomment-1079739091:2,test,tested,2,https://hail.is,https://github.com/hail-is/hail/pull/11679#issuecomment-1079739091,2,['test'],"['test', 'tested']"
Testability,I tested this by hand by replacing the actual function call with throwing a TimeoutError and making sure both the client and the batch-driver gave the appropriate warning in the log message and didn't proceed.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7850#issuecomment-573430599:2,test,tested,2,https://hail.is,https://github.com/hail-is/hail/pull/7850#issuecomment-573430599,2,"['log', 'test']","['log', 'tested']"
Testability,"I tested this by hand with the following schenario:. 1. Deployed this branch and set the standard pool to use 4-core workers. Then submitted two jobs, with a total of 3 cores requested between them. The state looked as follows after a worker spun up:; <img width=""643"" alt=""Screenshot 2023-05-15 at 5 16 30 PM"" src=""https://github.com/hail-is/hail/assets/24440116/28d94a41-ff37-4331-8f4f-c2e649fd1c62"">. 2. I then bumped the instance version and redeployed. Then submitted a 1 core job. This should be able to fit on the existing worker, but batch instead spins up a new worker because the instance version has changed to 25 and the existing worker is version 24.; <img width=""639"" alt=""Screenshot 2023-05-15 at 5 19 41 PM"" src=""https://github.com/hail-is/hail/assets/24440116/92460dae-6aee-40b6-b6f3-46363dbdb12a"">. <img width=""643"" alt=""Screenshot 2023-05-15 at 5 20 59 PM"" src=""https://github.com/hail-is/hail/assets/24440116/5256762f-b361-40a7-a6d2-1aaa61f7b4ae"">. 3. The following steps I consider additional verification. I submitted another job, and observed it falling on the new worker instead of the most utilized worker. <img width=""641"" alt=""Screenshot 2023-05-15 at 5 21 36 PM"" src=""https://github.com/hail-is/hail/assets/24440116/176a9055-6ba7-49f1-88dc-c8496147db07"">. 4. I then cancelled the first batch and submitted another job and observed it fell on the new worker instead of the least utilized worker. So this step and the previous step confirm that regardless of utilization the old worker is not considered. We also see that the old worker receives no more work and successfully deactivates.; <img width=""644"" alt=""Screenshot 2023-05-15 at 5 23 03 PM"" src=""https://github.com/hail-is/hail/assets/24440116/d671a947-da44-4f05-bcdb-2fe6df28a655"">",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13055#issuecomment-1548633947:2,test,tested,2,https://hail.is,https://github.com/hail-is/hail/pull/13055#issuecomment-1548633947,1,['test'],['tested']
Testability,"I tested this by running `make deploy` in the `image-fetcher/` directory. You can take a look at the pods with `kubectl`, they are in the default namespace.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4647#issuecomment-433188993:2,test,tested,2,https://hail.is,https://github.com/hail-is/hail/pull/4647#issuecomment-433188993,1,['test'],['tested']
Testability,"I tested this by submitting 64 true, 10 Gi 0.25 core jobs on one node with a local SSD. It took 7 minutes for the whole batch to finish. This is a bit disappointing, but at least there were no errors. We can potentially revisit using get instead of wait for the polling loop, but the default sleep backoff method we have quickly blew our quota.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10630#issuecomment-871705329:2,test,tested,2,https://hail.is,https://github.com/hail-is/hail/pull/10630#issuecomment-871705329,1,['test'],['tested']
Testability,I tested this in my namespace and everything seems to be working. I tried really hard to keep the order of the parameters the same everywhere to avoid putting values in the wrong places (i.e. 7200 for max_instances instead of for standing worker idle time).,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12575:2,test,tested,2,https://hail.is,https://github.com/hail-is/hail/pull/12575,1,['test'],['tested']
Testability,I tested this in my namespace and it should be good to go.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10732#issuecomment-895582030:2,test,tested,2,https://hail.is,https://github.com/hail-is/hail/pull/10732#issuecomment-895582030,1,['test'],['tested']
Testability,I tested this in my namespace. We can customize the parameters -- this implementation is aggressive at making sure we're at maximum efficiency.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10495:2,test,tested,2,https://hail.is,https://github.com/hail-is/hail/pull/10495,1,['test'],['tested']
Testability,I tested this locally by building the image.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4694#issuecomment-434726391:2,test,tested,2,https://hail.is,https://github.com/hail-is/hail/pull/4694#issuecomment-434726391,1,['test'],['tested']
Testability,I tested this locally by downloading the HTML for the UI page and tinkering.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6430#issuecomment-504241795:2,test,tested,2,https://hail.is,https://github.com/hail-is/hail/pull/6430#issuecomment-504241795,1,['test'],['tested']
Testability,I tested this on #3562 and `test_call_stats` passes now.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3598:2,test,tested,2,https://hail.is,https://github.com/hail-is/hail/pull/3598,1,['test'],['tested']
Testability,I tested this on a cluster on a bit of code that @konradjk provided. not super sure if we can actually write a test for this for our test suite. Fixes #3446,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3482:2,test,tested,2,https://hail.is,https://github.com/hail-is/hail/pull/3482,3,['test'],"['test', 'tested']"
Testability,"I tested this on my branch that had a bunch of deadlock errors and those were replaced with CallError in schedule job because the job was running, cancelled, or instance not active.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7782#issuecomment-568575288:2,test,tested,2,https://hail.is,https://github.com/hail-is/hail/pull/7782#issuecomment-568575288,1,['test'],['tested']
Testability,"I tested this on the latest version of master, and it seems it has been fixed since the docker image with the workshop tutorial was created.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5207#issuecomment-457700818:2,test,tested,2,https://hail.is,https://github.com/hail-is/hail/issues/5207#issuecomment-457700818,1,['test'],['tested']
Testability,"I tested this with a hard-hitting batch that used a bunch of storage, looked through the UI and didn't get any 500s, and checked the logs on both the k8s pods and the instances for errors. I also commented out each part of the garbage collection loops and made sure everything got cleaned up. For example, commenting out the activity logs loop or the monitor instances loop with the deactivate API point not doing anything.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10920#issuecomment-942374466:2,test,tested,2,https://hail.is,https://github.com/hail-is/hail/pull/10920#issuecomment-942374466,3,"['log', 'test']","['logs', 'tested']"
Testability,I tested this with dev deploy,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7907:2,test,tested,2,https://hail.is,https://github.com/hail-is/hail/pull/7907,1,['test'],['tested']
Testability,I tested this with dev deploy using both my broad developer account and my personal account to make sure regular users only saw their own billing information.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10656:2,test,tested,2,https://hail.is,https://github.com/hail-is/hail/pull/10656,1,['test'],['tested']
Testability,I tested this works on a debugging branch.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4503:2,test,tested,2,https://hail.is,https://github.com/hail-is/hail/pull/4503,1,['test'],['tested']
Testability,I tested this works with dev deploy.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8760#issuecomment-626929606:2,test,tested,2,https://hail.is,https://github.com/hail-is/hail/pull/8760#issuecomment-626929606,1,['test'],['tested']
Testability,"I tested with dev deploy, this looks good.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8002#issuecomment-580248649:2,test,tested,2,https://hail.is,https://github.com/hail-is/hail/pull/8002#issuecomment-580248649,1,['test'],['tested']
Testability,I think I addressed most of the comments. I haven't tested the new code -- I don't want to do that until we're happy with it. I don't know that I like how this is turning out. I think we're conflating what `hailctl config init` should be which is intitializing an environment configuration file versus a quick start to using Hail Batch and QoB. My intention for this feature was to idiot proof the latter especially for the ATGU workshop and make it as few commands as possible. I worry that needing to run `hailctl auth login` before this is not a just run this single command and then you can get going with little effort. I don't think `hailctl config init` is the right place for what I have written. Maybe it should be `hailctl batch quick-start`???,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13279#issuecomment-1662716382:52,test,tested,52,https://hail.is,https://github.com/hail-is/hail/pull/13279#issuecomment-1662716382,2,"['log', 'test']","['login', 'tested']"
Testability,I think I also fixed a couple bugs in the tests where we set `rv`; instead of `rv2`.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2511:42,test,tests,42,https://hail.is,https://github.com/hail-is/hail/pull/2511,1,['test'],['tests']
Testability,I think I blew it away when I rebased. All the index bgen tests fail anyway because the index bgen code hasn't been lowered yet.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11597#issuecomment-1076488428:58,test,tests,58,https://hail.is,https://github.com/hail-is/hail/pull/11597#issuecomment-1076488428,1,['test'],['tests']
Testability,I think I got all of the fixes. I tested the UI with dev deploy.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8916:34,test,tested,34,https://hail.is,https://github.com/hail-is/hail/pull/8916,1,['test'],['tested']
Testability,"I think I got everything, but I still want to test it again by hand in the morning once we're sure there's no other changes to make. I was testing the before migration by running dev deploy from master and cancelling a batch while it was submitting along with some completed ones and then tried to deploy the new version and made sure the ready cores etc. were now correct.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7851#issuecomment-574442792:46,test,test,46,https://hail.is,https://github.com/hail-is/hail/pull/7851#issuecomment-574442792,2,['test'],"['test', 'testing']"
Testability,"I think I had the misunderstanding. I know Prometheus dies when we do big tests, but I thought that was just because we requested no resources at all in the past. I didn't understand that it consistently uses 30Gb + of memory at those times. In that case, it seems constantly running a bigger node is unavoidable",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6774#issuecomment-519178381:74,test,tests,74,https://hail.is,https://github.com/hail-is/hail/pull/6774#issuecomment-519178381,1,['test'],['tests']
Testability,"I think I know the problem! We are testing against Plink 1.9, but you have the old version 1.07 (which is my fault for linking the plink base page). Install it from the link below and please try again:. [https://www.cog-genomics.org/plink2](https://www.cog-genomics.org/plink2)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/457#issuecomment-230288836:35,test,testing,35,https://hail.is,https://github.com/hail-is/hail/issues/457#issuecomment-230288836,1,['test'],['testing']
Testability,I think I now understand what you're looking for. I set out to build a drop-in replacement for the current AST so that when Jackie's python UI changes were done we could hook this up in place of AST. I will instead build something that will operate on the new Unsafe representations you're introducing. I'll close for now because after removing `DetailedTypeInfo` many tests are broken because the current IR has no way to return `NA` to its caller. I'll reopen when I have something that includes primitives for the Unsafe data.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2224#issuecomment-332360962:369,test,tests,369,https://hail.is,https://github.com/hail-is/hail/pull/2224#issuecomment-332360962,1,['test'],['tests']
Testability,"I think I'd flip the logic. I'm not sure if this one is wrong:. ```; In [9]: hl.eval((p, hl.range(2).map(lambda x: p))); Out[9]: (0.46124206583236194, [0.46124206583236194, 0.46124206583236194]); ```. But if it's right, clearly this one is wrong:. ```; In [7]: p = 1 - r. In [8]: hl.eval(hl.range(2).map(lambda x: p)); Out[8]: [0.46124206583236194, 0.06052003544873086]; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7572#issuecomment-557020739:21,log,logic,21,https://hail.is,https://github.com/hail-is/hail/issues/7572#issuecomment-557020739,2,['log'],['logic']
Testability,I think I'm just setting the docker script ones for now in this PR. Anything else seems out of scope of adding this random benchmark,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8050#issuecomment-583468345:123,benchmark,benchmark,123,https://hail.is,https://github.com/hail-is/hail/pull/8050#issuecomment-583468345,1,['benchmark'],['benchmark']
Testability,"I think it was wrong -- the buffered thing probably already implements it in terms of write. I didn't even define flush on the java side, so it wasn't getting called in my tests (or it would have errored)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1645#issuecomment-294269949:172,test,tests,172,https://hail.is,https://github.com/hail-is/hail/pull/1645#issuecomment-294269949,1,['test'],['tests']
Testability,"I think it will actually just work out of the box. In particular, the updated file paths that specify the full destination also work with gsutil. The build.yaml changes are being run by the production batch, so we already know those are working with gsutil. I'm running some benchmarks vs gsutil now and will have numbers in a while. If that all looks good, I vote to merge this.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10131#issuecomment-790877506:275,benchmark,benchmarks,275,https://hail.is,https://github.com/hail-is/hail/pull/10131#issuecomment-790877506,1,['benchmark'],['benchmarks']
Testability,"I think it's going to be too hard to test this PR in dgoldste. I think we should combine getting this PR to work with standing up the Azure production cluster. Until then, I need your help to finish this draft:. @danking -- Can you look over the oauth flow?; @daniel-goldstein -- Next week, can you help out with the necessary Terraform changes?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11147:37,test,test,37,https://hail.is,https://github.com/hail-is/hail/pull/11147,1,['test'],['test']
Testability,I think my ideal is a file with freshly written tests that state what we expect of QoB. The current state of our tests is just a kind of jungle of things we've ever thought were important at some point. I'm not sure how to incentivize us to curate our test suite a bit more intentionally.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13620#issuecomment-1721373570:48,test,tests,48,https://hail.is,https://github.com/hail-is/hail/pull/13620#issuecomment-1721373570,3,['test'],"['test', 'tests']"
Testability,"I think old repos still work, which is why CI is mostly fine, but I was seeing errors when testing locally.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5798:91,test,testing,91,https://hail.is,https://github.com/hail-is/hail/pull/5798,1,['test'],['testing']
Testability,"I think one of the following needs to happen:; 1. we document the pc relate setup sufficiently; 2. we precompute results somewhere that PC-Relate runs and test against that. I feel strongly that any PRs that introduce new testing dependencies must also include the relevant information to install those dependencies, probably in the ""getting started developing"" doc or somewhere like that.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3274#issuecomment-377932960:155,test,test,155,https://hail.is,https://github.com/hail-is/hail/pull/3274#issuecomment-377932960,2,['test'],"['test', 'testing']"
Testability,"I think scorecard has been broken for a while w.r.t. the ""failing tests"" category. That's just not showing up.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7134#issuecomment-555510546:66,test,tests,66,https://hail.is,https://github.com/hail-is/hail/pull/7134#issuecomment-555510546,1,['test'],['tests']
Testability,"I think test-test-gsa-key is pretty awful sounding but I'm not sure how better to call a test user for test namespaces and it's consistent with the test-auth, test-batch, etc. names.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13202#issuecomment-1603124469:8,test,test-test-gsa-key,8,https://hail.is,https://github.com/hail-is/hail/pull/13202#issuecomment-1603124469,5,['test'],"['test', 'test-auth', 'test-batch', 'test-test-gsa-key']"
Testability,"I think tests of services are failing during deployment because wait-for Service (which probes /healthcheck) hits the old service, then the service goes down during (re)deployment. Here is an example test failure: first few tests pass then the rest fail due to connection timeout: https://ci2.hail.is/jobs/1413/log. This doesn't quite make sense, because batch and apiserver both have readiness checks, so the rollout should be have now downtime (although some of the tests could hit the old service which could fail if there were differences). I think this is a good chance but I'm not totally confident. Interested in your thoughts. Also, I can't seem the find the different between `wait deployment` and `rollout status`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6011:8,test,tests,8,https://hail.is,https://github.com/hail-is/hail/pull/6011,5,"['log', 'test']","['log', 'test', 'tests']"
Testability,"I think that addresses the concerns. This is great, what other automated checks can we add to make us more confident in our tests?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13372#issuecomment-1673768514:124,test,tests,124,https://hail.is,https://github.com/hail-is/hail/pull/13372#issuecomment-1673768514,1,['test'],['tests']
Testability,"I think that brittleness is gone now, and was fixed by us doing method; splitting in compiler. But double checking would be great. On Wed, Nov 17, 2021, 5:04 PM Patrick Schultz ***@***.***>; wrote:. > Yeah, I guess I should benchmark, since you've observed some strange; > brittleness in the linreg performance before.; >; > —; > You are receiving this because you were assigned.; > Reply to this email directly, view it on GitHub; > <https://github.com/hail-is/hail/pull/11070#issuecomment-972121769>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ADJCWES5I5IHLD7O6ECMZIDUMQRFBANCNFSM5IICVNFQ>; > .; >",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11070#issuecomment-972127901:224,benchmark,benchmark,224,https://hail.is,https://github.com/hail-is/hail/pull/11070#issuecomment-972127901,1,['benchmark'],['benchmark']
Testability,"I think that should cover everything, however I am still failing one test. I think the current docker approach has a convenient quirk of retrying the docker daemon, which allows container deletion to stop a container while it's running, which in turn allows the loop that checks the running container to `raise` and exit. In the subprocess structure that I lifted from `JVMJob`, I'm unconvinced that this is happening correctly. What I thought would happen is that the `delete_container` coroutine would `kill` the container process while the coroutine running the container is still on `await self.process.wait()`. I would hope that means `self.process.wait` would soon raise but I'm now consistently seeing `test_cancel_left_after_tail` time out, indicating that it wasn't able to successfully cancel the sleeping job. EDIT: Jackie and I investigated and think that `kill` causes the `stdout/stderr` streams not to send EOF but rather set an exception, which means that the `run` coroutine can hang on gathering the output of the container. Going to run this test repeatedly to see if the intermittent timeouts stop and that this is actually the cause of the problem. EDIT2: ugh didn't seem to fix the problem. There's something still wrong in cancel/deleting containers where we intermittently wait until the job timeout regardless.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10376#issuecomment-857271742:69,test,test,69,https://hail.is,https://github.com/hail-is/hail/pull/10376#issuecomment-857271742,2,['test'],['test']
Testability,I think the `client_job` attribute is doing its intended job but we need to ignore uncontrollable attributes in this test in particular.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13741:117,test,test,117,https://hail.is,https://github.com/hail-is/hail/pull/13741,1,['test'],['test']
Testability,I think the callback test is the unreliable one? Looks like it got retested and is fine now.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5563#issuecomment-473473364:21,test,test,21,https://hail.is,https://github.com/hail-is/hail/pull/5563#issuecomment-473473364,1,['test'],['test']
Testability,I think the code looks fine. Somehow a setting on Jenkins got messed up and new branches weren't being built. It should be working now. Wait for the test results before merging with master.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/356#issuecomment-215227188:149,test,test,149,https://hail.is,https://github.com/hail-is/hail/pull/356#issuecomment-215227188,1,['test'],['test']
Testability,I think the current Scala tests I've written roughly do that,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11151#issuecomment-1018609478:26,test,tests,26,https://hail.is,https://github.com/hail-is/hail/pull/11151#issuecomment-1018609478,1,['test'],['tests']
Testability,I think the docs you're referencing aren't the Compute Engine API docs: https://cloud.google.com/compute/docs/api-rate-limits. The audit logs also show 403s: https://console.cloud.google.com/logs/query;query=%22403%22%0A%22Rate%20Limit%20Exceeded%22;timeRange=2021-05-04T00:05:00.000Z%2F2021-05-04T01:06:00.000Z;pinnedLogId=2021-05-04T00:40:25.985091Z%2F-1xc71ve6z9k6;cursorTimestamp=2021-05-04T00:40:31.308803Z?project=hail-vdc&query=%0A,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10432#issuecomment-833010496:137,log,logs,137,https://hail.is,https://github.com/hail-is/hail/pull/10432#issuecomment-833010496,2,['log'],['logs']
Testability,"I think the force_ir flag would be good. I had a hallway conversation with Dan today about how even though our changes are partially designed to give us control over memory, we actually have _no idea_ what our memory usage patterns look like. I think we should add some logging information about region sizes. It could be very illuminating.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3258#issuecomment-377379681:270,log,logging,270,https://hail.is,https://github.com/hail-is/hail/pull/3258#issuecomment-377379681,1,['log'],['logging']
Testability,"I think the interval and partitioner logic is all correct. I think the problem is that the `naiveCoalesce` implementation is wrong when the key is empty. In that case, it computes a new partitioner, which will just be fewer partitions with range bounds [[]-[]], then tries to repartition to that. It's right to refuse, because the repartitioner works under the assumption that each key is contained in at most one target partition's interval.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8138#issuecomment-597279382:37,log,logic,37,https://hail.is,https://github.com/hail-is/hail/issues/8138#issuecomment-597279382,1,['log'],['logic']
Testability,I think the tests are grinding to a halt due to a too low memory limit see service backend here: https://batch.hail.is/batches/7484164/jobs/108 and then local backend actually hits the hard limit: https://batch.hail.is/batches/7484164/jobs/69.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12981#issuecomment-1562908225:12,test,tests,12,https://hail.is,https://github.com/hail-is/hail/pull/12981#issuecomment-1562908225,1,['test'],['tests']
Testability,I think they're supposed to? The python tests definitely do.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10583#issuecomment-859777792:40,test,tests,40,https://hail.is,https://github.com/hail-is/hail/pull/10583#issuecomment-859777792,1,['test'],['tests']
Testability,"I think this PR is just about as good as it's going to get for now. From looking at the Grafana API metrics, I think I was hitting the maximum scheduler throughput. The get running cancellable jobs is around 40ms each call for 5000 jobs while the getting the job head queue is 123ms. If the 40ms becomes a problem, then we can pull less records (see explanation below) or we can not do a json array agg and figure out the regions using bit shifting. When we did the load tests yesterday getting the job head queue was around 1-2 seconds with us each having 20k records. I think we just have to keep an eye on it. I did some further optimization of the scheduler by allowing it to pull up to 10000 jobs from the database to try and schedule before it hits its fair share of jobs scheduled. This helps a lot with efficiency to use the existing capacity if there are jobs further down the queue that are schedulable. I know it's a bit of a departure from what we've done in the past, but I think since we're going in order of fair share now and pulling more jobs from the database isn't that expensive, then this is fine. Happy to make this number 1000 even. 300 was too small though. Jobs at the front of the queue will eventually be able to run because the next iteration of the autoscaler will create the correct instances for those jobs.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12221#issuecomment-1276546928:471,test,tests,471,https://hail.is,https://github.com/hail-is/hail/pull/12221#issuecomment-1276546928,1,['test'],['tests']
Testability,I think this PR is mostly there. We might want to make the docs more explicit. I didn't add any tests yet to assert everything is working. I was testing it by hand by not using a local SSD and making the disk size 25 GB so the reserved space is 0 GB. I watched the worker logs in stack driver to make sure it was working. I'd appreciate ideas for tests. Feel free to work on this while I'm away. I checked the disks in the google console to make sure I didn't have any garbage.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9598:96,test,tests,96,https://hail.is,https://github.com/hail-is/hail/pull/9598,5,"['assert', 'log', 'test']","['assert', 'logs', 'testing', 'tests']"
Testability,I think this builds. Gotta make it pass tests.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9825#issuecomment-754781031:40,test,tests,40,https://hail.is,https://github.com/hail-is/hail/pull/9825#issuecomment-754781031,1,['test'],['tests']
Testability,"I think this can go in instead of #8730. I ran dev deploy with master and then didn't delete the database and ran the tests with the new version. The billing UI page reported the correct values. I also ran the new version with the check functions in the background and got no errors. I can probably double check the UI batches cost are correct, but let's wait until we're happy with the code before I do anymore testing.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8759:118,test,tests,118,https://hail.is,https://github.com/hail-is/hail/pull/8759,2,['test'],"['testing', 'tests']"
Testability,"I think this change will help the number of operations we're making substantially. My Scala skills are not great, so I don't know if this is written correctly. Basically, we were making a call to list the blobs recursively to test if the path was a directory which was streaming through the first 5000 records. I made the page size equal to 1 record as we don't care about all records. The next thing I did was to just get the blob properties rather than calling exists + get blob properties. So that will cut the number of HTTP calls by half for every blob. Lastly, listing items in a directory which is used for globbing was making a call to get the metadata for each file and then it was making the 3 API calls above to check whether it's a directory, whether it exists, and what the blob properties are. All of this information is in the original result from listing the blobs in the hierarchy so I just use that information directly.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13368:226,test,test,226,https://hail.is,https://github.com/hail-is/hail/pull/13368,1,['test'],['test']
Testability,"I think this cleans up the array sorting logic a little bit (at least, moves the sorting logic into an actual scala function instead of keeping it in bytecode-land). The new ordering functions are to prevent the boxing of arguments and return values that happen with asmfunctions.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3719:41,log,logic,41,https://hail.is,https://github.com/hail-is/hail/pull/3719,2,['log'],['logic']
Testability,"I think this could interact badly with Spark's partitioning logic. That would appear in the text file imports. We should probably rewrite the text file stuff the same way we rewrote import_bgen to use our own, sensible, partitioning logic. I guess the worst thing that happens is a small text file is broken into one partition per-line.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5698#issuecomment-476796791:60,log,logic,60,https://hail.is,https://github.com/hail-is/hail/pull/5698#issuecomment-476796791,2,['log'],['logic']
Testability,I think this didn't get cleaned up when we deleted the benchmark service.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13393:55,benchmark,benchmark,55,https://hail.is,https://github.com/hail-is/hail/pull/13393,1,['benchmark'],['benchmark']
Testability,I think this improves on the experience of receiving a KeyError; when the default namespace has no tokens defined. Now the user; will recieve a NoTokenFileFound exception that indicates the; user should log in with `hailctl auth login`.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7020:203,log,log,203,https://hail.is,https://github.com/hail-is/hail/pull/7020,2,['log'],"['log', 'login']"
Testability,I think this is all that needs to be added to get benchmark in the header. There's no caret after so we don't need to format that at all.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9256:50,benchmark,benchmark,50,https://hail.is,https://github.com/hail-is/hail/pull/9256,1,['benchmark'],['benchmark']
Testability,"I think this is closer to the right interface, so I want to think about how to get it in while allowing for future changes that don't break interface. I think `RegressionModel` should be initialized with the data of `y` and `covariates`. It should have a `fit` method that returns a struct with the multivariate regression result, which I can add later without breaking interface. The underlying math is already there (e.g. when computing the null model), just a matter of packaging. It'd be nice for this to work on Tables too. And then `regress_rows`, renamed fit_rows, should only take `x` and other parameters like `test` and `block_size`. This is basically how LMM works, but with the multivariate global math all on the python side.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4535#issuecomment-429487447:620,test,test,620,https://hail.is,https://github.com/hail-is/hail/pull/4535#issuecomment-429487447,1,['test'],['test']
Testability,I think this is dependent on the authorization PR going in so I can test it's working.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6719#issuecomment-514341053:68,test,test,68,https://hail.is,https://github.com/hail-is/hail/pull/6719#issuecomment-514341053,1,['test'],['test']
Testability,"I think this is equivalent to the 0-1 knapsack problem. Think about doing it in log-space. Let s be the size. Let (x_i) be the scaled dirichlet that sums to log(s). Let l_i = log floor(e^x_i) and u_i = log (floor(e^x_i) + 1). Let f_i = l_i - x_i be the ""fractional"" part and F = sum f_i. You want to find a subset of d_i = u_i - l_i whose sum is maximized but <= F. A 1-pass greedy algorithm seems good enough.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1998#issuecomment-316252831:80,log,log-space,80,https://hail.is,https://github.com/hail-is/hail/issues/1998#issuecomment-316252831,4,['log'],"['log', 'log-space']"
Testability,I think this is fine without tests if the issues I was seeing were in the interpreter.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3745#issuecomment-396989892:29,test,tests,29,https://hail.is,https://github.com/hail-is/hail/pull/3745#issuecomment-396989892,1,['test'],['tests']
Testability,"I think this is good to go, once MatrixIR.scala comments pertaining to execute are removed. I would like to know, as an aside, more about execute. Coverage of modified join functionality seems good!. Breaking line 1505, using; ```python; join_table = src.rows(); ```. generates a test error in; test/hail/matrixtable/test_matrix_table.py:490. Breaking line 1529, using; ```python; joiner = lambda left: 1; ```; triggers an error in test/hail/matrixtable/test_matrix_table.py:905",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5075#issuecomment-453375974:280,test,test,280,https://hail.is,https://github.com/hail-is/hail/pull/5075#issuecomment-453375974,3,['test'],['test']
Testability,"I think this is happening from the below line in ci/ci.py (~674). When ci finds a `wait` step of `kind: Service`, its rollout command checks a `deployment` resource of `name` (name here is blog), which we of course don't have. I think we need to not hardcode `deployment` here, either through a config property in the wait step, or by checking whether the deploy `config` for the build step has a `StatefulSet`, or `Deployment`. ```python; if self.wait:; for w in self.wait:; # ... redacted ...; elif w['kind'] == 'Service':; assert w['for'] == 'alive', w['for']; port = w.get('port', 80); timeout = w.get('timeout', 60); script += f'''; set +e; kubectl -n {self.namespace} rollout status --timeout=1h deployment {name} && \; kubectl -n {self.namespace} wait --timeout=1h --for=condition=available deployment {name} && \; python3 wait-for.py {timeout} {self.namespace} Service -p {port} {name}; EC=$?; kubectl -n {self.namespace} logs --tail=999999 -l app={name} | {pretty_print_log}; set -e; (exit $EC); '''; ```. edit: A possible config/ci change:. build.yaml; ```yaml; wait:; - kind: Service; name: blog; for: alive; resource_type: statefulset; ```. ci/ci.py:. ```python; if self.wait:; for w in self.wait:; name = w['name']; resource_type = w.get(""resource_type"", ""deployment""); # ... redacted ...; elif w['kind'] == 'Service':; # ... redacted; script += f'''; set +e; kubectl -n {self.namespace} rollout status --timeout=1h {resource_type} {name} && \; kubectl -n {self.namespace} wait --timeout=1h --for=condition=available {resource_type} {name} && \; python3 wait-for.py {timeout} {self.namespace} Service -p {port} {name}; EC=$?; kubectl -n {self.namespace} logs --tail=999999 -l app={name} | {pretty_print_log}; set -e; (exit $EC); '''; ```. @cseed does this seem a reasonable change?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7381#issuecomment-546407626:526,assert,assert,526,https://hail.is,https://github.com/hail-is/hail/pull/7381#issuecomment-546407626,3,"['assert', 'log']","['assert', 'logs']"
Testability,"I think this is probably a bug, since we write out the reference genome and seem to support it just fine in Scala. I want to be able to do e.g.:. ```; >>> import hail as hl; >>> rg = hl.ReferenceGenome(""foo"", ['a', 'b'], {'a': 4, 'b': 6}); >>> t = hl.utils.range_table(10); >>> t = t.annotate(locus=hl.locus_from_global_position(t.idx, reference_genome='foo')); >>> t.write('test.t'); ```. and then, in a separate instance of hail, do:. ```; >>> import hail as hl; >>> t = hl.read_table('test.t'); ```. Currently, I get the following error:; ```; Traceback (most recent call last):; File ""/anaconda3/lib/python3.6/site-packages/parsimonious/nodes.py"", line 217, in visit; return method(node, [self.visit(n) for n in node]); File ""/Users/wang/code/hail/hail/python/hail/expr/type_parsing.py"", line 80, in visit_locus; return hl.tlocus(gr); File ""<decorator-gen-56>"", line 2, in __init__; File ""/Users/wang/code/hail/hail/python/hail/typecheck/check.py"", line 584, in wrapper; args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); File ""/Users/wang/code/hail/hail/python/hail/typecheck/check.py"", line 512, in check_all; args_.append(checker.check(arg, name, arg_name)); File ""/Users/wang/code/hail/hail/python/hail/typecheck/check.py"", line 56, in check; return tc.check(x, caller, param); File ""/Users/wang/code/hail/hail/python/hail/typecheck/check.py"", line 303, in check; return f(tc.check(x, caller, param)); File ""/Users/wang/code/hail/hail/python/hail/genetics/reference_genome.py"", line 10, in <lambda>; reference_genome_type = oneof(transformed((str, lambda x: hl.get_reference(x))), rg_type); File ""/Users/wang/code/hail/hail/python/hail/context.py"", line 362, in get_reference; return ReferenceGenome._references[name]; KeyError: 'foo'. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-1214>"", line 2, in read_table; File ""/Users/wang/code/h",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6907:375,test,test,375,https://hail.is,https://github.com/hail-is/hail/issues/6907,2,['test'],['test']
Testability,"I think this is ready for another look but I put a WIP label on it because I don't want to merge it today while there's still workshop things happening. After it goes in I'll run another scale test. The nginx config is mostly just lifted over from router, with a couple small changes. I wasn't able to just proxy to localhost because notebook couldn't figure out which subdomain the request was going to and everything would 404. Adding a Host header fixed the 404, but messed with the requests to notebook pods so instead I added `workshop.local` and `notebook.local` to `/etc/hosts` on the pod, which I kind of like, which did the trick. I needed two ssl configs, one for nginx and one for aiohttp to use internally, and ended up changing the `ssl-config-notebook` secret to `nginx` and creating a second `ssl-config-notebook-python`, but let me know if this seems off.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10204#issuecomment-806087347:193,test,test,193,https://hail.is,https://github.com/hail-is/hail/pull/10204#issuecomment-806087347,1,['test'],['test']
Testability,I think this is ready for another look. I'll cleanup the database once we're happy with everything and I no longer need to test with dev deploy (I don't want to have to nuke the database).,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12221#issuecomment-1276247643:123,test,test,123,https://hail.is,https://github.com/hail-is/hail/pull/12221#issuecomment-1276247643,1,['test'],['test']
Testability,"I think this is ready. Adds a createDatabase2 step that adds database migrations. What's a database migration? The idea is that a database starts as an empty database and is built up or modified over time by a series of patches or migrations. The database has a version which is the number of migrations applied (starting from 1). This is stored in the table `{database_name}_migration_version`. Each migration involves running a `.sql` or `.py` script. The logic that applies migrations computes a checksum of these scripts and stores them in the database in table `{database_name}_migrations`. When applying migrations again in the future, these checksums are verified. A create database step now looks like (from the CI tests):. ```; - kind: createDatabase2; name: hello2_database; databaseName: hello2; migrations:; - name: create-tables; script: /io/sql/create-hello2-tables.sql; - name: insert; script: /io/sql/insert.py; inputs:; - from: /repo/ci/test/resources/sql; to: /io/; namespace:; valueFrom: default_ns.name; dependsOn:; - default_ns; - copy_files; ```. migrations is a the list of migrations that need to be applied to get the current version. So the idea is, if you want to change the schema of the database, you just add another migration at the end to make the changes you want. After this goes in, I'll make a separate PR to switch everything to this new createDatabase2 step.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7674#issuecomment-562891346:458,log,logic,458,https://hail.is,https://github.com/hail-is/hail/pull/7674#issuecomment-562891346,3,"['log', 'test']","['logic', 'test', 'tests']"
Testability,I think this is the last one. The tests passed 30 times without a failure.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10044:34,test,tests,34,https://hail.is,https://github.com/hail-is/hail/pull/10044,1,['test'],['tests']
Testability,"I think this may fix it:. ```yaml; apiVersion: v1; kind: Role; apiVersion: rbac.authorization.k8s.io/v1; metadata:; namespace: test; name: list-test-pvc; rules:; - apiGroups: [""""]; resources: [""persistentvolumeclaims""]; verbs: [""list""]; ---; apiVersion: v1; kind: RoleBinding; apiVersion: rbac.authorization.k8s.io/v1; metadata:; name: deploy-svc-list-test-pvc; namespace: test; subjects:; - kind: ServiceAccount; name: deploy-svc; namespace: batch-pods; roleRef:; kind: Role; name: list-test-pvc; apiGroup: ""rbac.authorization.k8s.io""; ```. I don't have permissions to create the role however. Another solution would be to modify the existing role to include ""list"" permissions. ```yaml; ---; apiVersion: v1; kind: Role; apiVersion: rbac.authorization.k8s.io/v1; metadata:; namespace: test; name: delete-test-pvc; rules:; - apiGroups: [""""]; resources: [""persistentvolumeclaims""]; verbs: [""list"", ""delete""]; ---; ```. `""get""` may also be needed",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5503#issuecomment-468958060:127,test,test,127,https://hail.is,https://github.com/hail-is/hail/pull/5503#issuecomment-468958060,7,['test'],"['test', 'test-pvc']"
Testability,"I think this might break the one test where we query batches / jobs based on name. I'll take a look at the tests later, but otherwise, this seems fine to me.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12884#issuecomment-1507487049:33,test,test,33,https://hail.is,https://github.com/hail-is/hail/pull/12884#issuecomment-1507487049,2,['test'],"['test', 'tests']"
Testability,I think this might fail tests with an xpass on local backend.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10697#issuecomment-885855540:24,test,tests,24,https://hail.is,https://github.com/hail-is/hail/pull/10697#issuecomment-885855540,1,['test'],['tests']
Testability,"I think this should resolve the issues we were seeing with OnlineBoundedGather2. Changes:; - cancelled tasks (those that raise CancelledError) are ignored (we don't propagate cancelled out of background tasks); - Make sure all exceptions are either reraised or logged; - The first exception is raised out of exit, not call; - call raises PoolShutdownError if the pool is shutdown; - _shutdown doesn't signal _done_event until all cancelled tasks are complete; - call clears _done_event (not strictly necessary because exit checks pending, but seems safer); - added copious docstrings",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10342:261,log,logged,261,https://hail.is,https://github.com/hail-is/hail/pull/10342,1,['log'],['logged']
Testability,"I think this was inadvertantly broken. The `Progress.disable` property needs to be set *before* you start the progress bar, otherwise it has no effect. Clients of all these progress bars should not touch their `Progress` instance, that is an implementation detail. I have changed rich_progress_bar.py to use `_progress` to clearly communicate this. Unrelatedly, it seems that `add_task` accepts varargs which become arbitrary additional metadata for the task. There is no `disable` keyword, that is just added as additional metadata. Instead, we must use the `visible` keyword to enable/disable the task. I verified this looks right now:. ```python3; In [1]: import hailtop.batch_client.aioclient as ac; ...: try:; ...: client = await ac.BatchClient.create('hail'); ...: b = client.create_batch(); ...: resources = {'machine_type': ""g2-standard-4"", 'storage': '100Gi'}; ...: j = b.create_job(; ...: '2.0.1-debian-11-r122',; ...: ['python', '-c', 'import torch; assert torch.cuda.is_available()'],; ...: resources=resources,; ...: ); ...: await b.submit(); ...: await b.wait(); ...: finally:; ...: await client.close(); https://batch.hail.is/batches/8038881 ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100% 1/1 0:00:00 0:01:53; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13669:961,assert,assert,961,https://hail.is,https://github.com/hail-is/hail/pull/13669,1,['assert'],['assert']
Testability,"I think this will work, but I haven't tested it with dev deploy.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7917:38,test,tested,38,https://hail.is,https://github.com/hail-is/hail/pull/7917,1,['test'],['tested']
Testability,"I think tying the reset to the iterator is a mistake. First, iterator is the wrong abstraction here. Whole-stage code generation should use the aggregator/array strategy we're using in Emit to generate nothing, conditionals and loops for map, filter and flatMap, respectively. Ideally read ... do stuff ... write will generate an RDD with no per-element iterators at all. I want to make sure this picture is clear. Second, we want to vectorize in the database sense: we want to process multiple rows together in batches. Then overall structure of a stage is a loop over the batches, and and a loop within batches. Thus, the common case should not be we reset after every element, so I think it's the wrong direction to bake it in. The place where we do this should be interface points with the Spark stack which should be looked at with scorn and derision and as the organizing model. Finally, this points to an ongoing difference in our views about the meaning of context. I see context as serving two purposes (neither of which involve reset):. - First, context is a set of resources needed to process a partition that should be released when the partition is complete. For example, I'm working on GenomicsDB which needs to localize a GenomicsDB shard to a local file that needs to be cleaned up when the partition is complete. - Second, it is a way to tell an iterator where to return its value. (This is the ""current"" region business.). I'd be happy to separate these, but I don't see clean way. In no case do I see generic logic to manage the lifetime of regions (e.g. knowing when to call reset) inside the Context.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3365#issuecomment-381180739:1528,log,logic,1528,https://hail.is,https://github.com/hail-is/hail/pull/3365#issuecomment-381180739,2,['log'],['logic']
Testability,"I think we also need to be clear when installing something that will break everyone's local tests (email, dev post, something).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3273#issuecomment-377700023:92,test,tests,92,https://hail.is,https://github.com/hail-is/hail/issues/3273#issuecomment-377700023,2,['test'],['tests']
Testability,I think we are a very long way from any system that reserves resources for a test job and in the meantime knowing the ci works is valuable.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5639#issuecomment-474817750:77,test,test,77,https://hail.is,https://github.com/hail-is/hail/pull/5639#issuecomment-474817750,1,['test'],['test']
Testability,I think we may need to rethink our compat tests at some point -- a few more bumps and that test will take minutes to run,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7261#issuecomment-543191626:42,test,tests,42,https://hail.is,https://github.com/hail-is/hail/pull/7261#issuecomment-543191626,2,['test'],"['test', 'tests']"
Testability,"I think we need this fix:; ```; commit 4cb998d1c7cbc9954d66c6e39d7fd48b0e936f51 (HEAD -> add-version-endpoint); Author: Daniel King <dking@broadinstitute.org>; Date: Mon Mar 22 17:47:22 2021 -0400. fix. diff --git a/build.yaml b/build.yaml; index 7a100adec8..256ca99c91 100644; --- a/build.yaml; +++ b/build.yaml; @@ -86,7 +86,7 @@ steps:; mkdir repo; cd repo; {{ code.checkout_script }}; - make -C hail python/hail/hail_version python/hail/hail_pip_version; + make -C hail python-version-info; git rev-parse HEAD > git_version; outputs:; - from: /io/repo/auth/sql; diff --git a/ci/test/resources/build.yaml b/ci/test/resources/build.yaml; index 3b1df5214c..b994d2787c 100644; --- a/ci/test/resources/build.yaml; +++ b/ci/test/resources/build.yaml; @@ -27,10 +27,13 @@ steps:; mkdir repo; cd repo; {{ code.checkout_script }}; + make -C hail python-version-info; timeout: 300; outputs:; - from: /io/repo; to: /; + - from: /io/repo/hail/python/hail/hail_version; + to: /hail_version; dependsOn:; - inline_image; - kind: buildImage; @@ -52,6 +55,10 @@ steps:; publishAs: service-base; dependsOn:; - base_image; + - copy_files; + inputs:; + - from: /hail_version; + to: /hail_version; - kind: buildImage; name: hello_image; dockerFile: ci/test/resources/Dockerfile; ```; EDIT: updated with more changes",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10085#issuecomment-804418107:582,test,test,582,https://hail.is,https://github.com/hail-is/hail/pull/10085#issuecomment-804418107,5,['test'],['test']
Testability,I think we need to at least manually test it.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8150#issuecomment-590976833:37,test,test,37,https://hail.is,https://github.com/hail-is/hail/pull/8150#issuecomment-590976833,1,['test'],['test']
Testability,"I think we need to figure out how to get cblas on the broad cluster. ```; # use UGER; # ish -l os=RedHat7; # use Anaconda3; # use Java-1.8; # use OpenBLAS; # source activate hail; # ipython; In [1]: import hail as hl . In [2]: mt = hl.balding_nichols_model(3, 100, 100) ; Initializing Spark and Hail with default parameters...; using hail jar at /home/unix/dking/.conda/envs/hail/lib/python3.7/site-packages/hail/hail-all-spark.jar; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Running on Apache Spark version 2.2.3; SparkUI available at http://10.200.100.39:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.11-cf54f08305d1; LOGGING: writing to /home/unix/dking/hail-20190307-1908-0.2.11-cf54f08305d1.log; 2019-03-07 19:08:30 Hail: INFO: balding_nichols_model: generating genotypes for 3 populations, 100 samples, and 100 variants...; ^[[A; In [3]: t = hl.linear_regression_rows(x=mt.GT.n_alt_alleles(), y=mt.pop, covariates=[1]) ; [Stage 0:============================================> (6 + 1) / 8]2019-03-07 19:08:39 Hail: INFO: Coerced sorted dataset; 2019-03-07 19:08:40 Hail: INFO: linear_regression_rows: running on 100 samples for 1 response variable y,; with input variable x, and 1 additional covariate...; /broad/software/free/Linux/redhat_7_x86_64/pkgs/jdk1.8.0_181/bin/java: symbol lookup error: /tmp/jniloader1327638724610654731netlib-native_system-linux-x86_64.so: undefined symbol: cblas_dgemm; ERROR:root:Exception while sending command.; Traceback (most recent call last):; File ""/home/unix/dking/.conda/envs/hail/lib/python3.7/site-packages/py4j/java_gateway.py"", line 1159, in send_command; raise Py4JNetworkError(""Answer from Java side is empty""); py4j.protocol.Py4JNetworkError: Answer from Java side is empty. During handling of the above exception, another exception",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5559:530,log,log,530,https://hail.is,https://github.com/hail-is/hail/issues/5559,4,"['LOG', 'log']","['LOGGING', 'log', 'logging']"
Testability,I think we really just need to test/maintain this file and point to it in the docs:; https://github.com/hail-is/hail/blob/master/python/hail/environment.yml. Would that have helped?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2978#issuecomment-370498224:31,test,test,31,https://hail.is,https://github.com/hail-is/hail/issues/2978#issuecomment-370498224,1,['test'],['test']
Testability,"I think we should add a new check for `check_batch_invariants` that the counts all sum to 0 when the tests are all finished running in the `user_inst_coll_resources` table. I think we have enough tests with `always_run` and cancellation for pool jobs, but I don't think we test the interaction between always_run and job private (""creating"" jobs).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13372#issuecomment-1673724680:101,test,tests,101,https://hail.is,https://github.com/hail-is/hail/pull/13372#issuecomment-1673724680,3,['test'],"['test', 'tests']"
Testability,"I think we should continue with another review and then a load test. I'm still a bit hesitant about the query change, but we can keep an eye on it. I'm still get errors with the typing:. ```; (venv) jigold@wm349-8c4 hail % make -C hail/python check; python3 -m flake8 --config ../../setup.cfg hail; python3 -m flake8 --config ../../setup.cfg hailtop; python3 -m pylint --rcfile ../../pylintrc hailtop --score=n; python3 -m mypy --config-file ../../setup.cfg hailtop; hailtop/batch/backend.py:481: error: Incompatible types in assignment (expression has type ""Union[str, List[str], None]"", variable has type ""Optional[List[str]]""); Found 1 error in 1 file (checked 146 source files); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12221#issuecomment-1271807464:63,test,test,63,https://hail.is,https://github.com/hail-is/hail/pull/12221#issuecomment-1271807464,1,['test'],['test']
Testability,"I think we should have the following design that runs the benchmarks in k8s because then we are using google's internal network to transmit data (compared to running on my local computer via a cloud proxy):. - Have a `db-benchmark` namespace in k8s specifically for this. 1. create_db.py; a. This will take the parameters needed for `gcloud sql instances create` including database flags, disk space, cores, etc. and create an instance; b. Get the IP address of the instance (hopefully the REST API works for this); c. Create a database; d. Create user and password for the database; e. Create config file; f. Create secret in the db-benchmark namespace from the config file; ; 2. run.py; a. Build the docker image with the benchmark.py code and installs aiomysql, etc.; b. Create pod which mounts the correct secret with the sql config for the instance to use. Environment variables specify the n_replicates, etc. Print out the pod name.; c. Wait for the pod to complete (you have code in CI that does this); d. Download logs; e. Delete the pod. 3. cleanup.py; a. Delete mysql instance; b. Delete kubernetes secret in db-benchmark namespace. Thoughts? . I tried to think about how to use the current build system and what I would do is add a new CreateSQLInstance step, CreateDatabase takes the instance name and IP address as a parameter, and have CI take a path to the build.yaml file to build from. But this wasn't straightforward with how to do this, so I thought the above was simpler to reason about.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7181#issuecomment-538453887:58,benchmark,benchmarks,58,https://hail.is,https://github.com/hail-is/hail/pull/7181#issuecomment-538453887,12,"['benchmark', 'log']","['benchmark', 'benchmarks', 'logs']"
Testability,"I think we should just merge this, so we can do more read testing until the writes are fixed.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10111#issuecomment-790701123:58,test,testing,58,https://hail.is,https://github.com/hail-is/hail/pull/10111#issuecomment-790701123,1,['test'],['testing']
Testability,I think we're generally happy with TSV testing now.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/46#issuecomment-316222854:39,test,testing,39,https://hail.is,https://github.com/hail-is/hail/issues/46#issuecomment-316222854,1,['test'],['testing']
Testability,"I think you can push to this branch directly, then CI will test for you.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5354#issuecomment-464160988:59,test,test,59,https://hail.is,https://github.com/hail-is/hail/pull/5354#issuecomment-464160988,1,['test'],['test']
Testability,"I think your comment was good, I'm going to add asserts but haven't gotten to it yet. Thanks!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2476#issuecomment-347668454:48,assert,asserts,48,https://hail.is,https://github.com/hail-is/hail/pull/2476#issuecomment-347668454,1,['assert'],['asserts']
Testability,"I thought about changing this to a `log.info`, but I'm quite worried about what happens when the IR is large (possibly quadratic logging).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7691#issuecomment-563439003:36,log,log,36,https://hail.is,https://github.com/hail-is/hail/pull/7691#issuecomment-563439003,2,['log'],"['log', 'logging']"
Testability,"I thought about this some more. I think the correct solution is to have two values for `n_jobs` in the `job_groups` table. There should be `n_jobs` (direct child jobs) and `n_jobs_recursive` (all descendent jobs). This way the UI and the status will make sense for whichever use case is most applicable. To do this, we'll need to write a migration that adds the new column and backfills the column. Right now, those two values are the same so it's just a copy of one column to another column. We might actually be able to do this migration in one update command. The other tables had hundreds of millions of rows and would have taken days and crashed the db if there was not enough memory. I can test this locally on my laptop by creating a test database and inserting 10 million records and then seeing how long it takes to do the update. ```; mysql> select count(*) from job_groups limit 10;; +----------+; | count(*) |; +----------+; | 8122788 |; +----------+; 1 row in set (16.75 sec); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14170#issuecomment-1934138382:696,test,test,696,https://hail.is,https://github.com/hail-is/hail/pull/14170#issuecomment-1934138382,2,['test'],['test']
Testability,"I thought self.steps was still used. For example in `build`:. ```; def build(self, batch, code, scope):; assert scope in ('deploy', 'test', 'dev'). for step in self.steps:; if step.scopes is None or scope in step.scopes:; step.build(batch, code, scope). if scope == 'dev':; return. step_to_parent_steps = defaultdict(set); for step in self.steps:; for dep in step.all_deps():; step_to_parent_steps[dep].add(step). for step in self.steps:; parent_jobs = flatten([parent_step.wrapped_job() for parent_step in step_to_parent_steps[step]]). log.info(f""Cleanup {step.name} after running {[parent_step.name for parent_step in step_to_parent_steps[step]]}""). if step.scopes is None or scope in step.scopes:; step.cleanup(batch, scope, parent_jobs); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7722#issuecomment-568536375:105,assert,assert,105,https://hail.is,https://github.com/hail-is/hail/pull/7722#issuecomment-568536375,3,"['assert', 'log', 'test']","['assert', 'log', 'test']"
Testability,"I thought the fix was the void-typed logic for the service execute. Looks like that's not in main, is it in your branch?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9856#issuecomment-772014076:37,log,logic,37,https://hail.is,https://github.com/hail-is/hail/issues/9856#issuecomment-772014076,1,['log'],['logic']
Testability,"I thought the purpose of the cache was to cache the latest version in production. Let's take service-base as an example. There's the deployment in production that we care about. But every PR is now going to change the cache each time to what it thinks service-base is. This means that the last 4 layers for service-base will change for every time we run a test PR and it changes hailtop, gear, or web-common. If you don't like this change, then feel free to close it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11907#issuecomment-1152568213:356,test,test,356,https://hail.is,https://github.com/hail-is/hail/pull/11907#issuecomment-1152568213,1,['test'],['test']
Testability,"I thought there might be an easier way than changing the database schema / batch/ci logic to have ignored batches, but maybe not.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6582#issuecomment-509638201:84,log,logic,84,https://hail.is,https://github.com/hail-is/hail/issues/6582#issuecomment-509638201,1,['log'],['logic']
Testability,I took a look at what we are currently outputting. I think this is relatively straightforward except for the HWE test. I don't know of a multiallelic version of HWE. A simple approach would be to compute HWE for each alternate allele compared to the reference allele. Where this gets tricky is how to handle heterozygotes where the second allele is not the reference allele. Example: 1/2 genotype.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2206#issuecomment-328648857:113,test,test,113,https://hail.is,https://github.com/hail-is/hail/issues/2206#issuecomment-328648857,2,['test'],['test']
Testability,"I tossed this up in my namespace and this is what seems to be the issue:; ```. Job Step	Image Pulling Time (s)	Running Time (s)	Error Type	State; main	0.135	30.011	timed out	error; Logs; Main; Log; executable file `sleep 5` not found in $PATH: No such file or directory; Error; Traceback (most recent call last):; File ""/usr/local/lib/python3.7/dist-packages/batch/worker/worker.py"", line 680, in _run; raise ContainerTimeoutError(f'timed out after {self.timeout}s'); ContainerTimeoutError: timed out after Nones",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11397#issuecomment-1076793811:181,Log,Logs,181,https://hail.is,https://github.com/hail-is/hail/pull/11397#issuecomment-1076793811,2,['Log'],"['Log', 'Logs']"
Testability,I tried again:. hail-new-vep importvcf /user/satterst/DILI/DILI_controls.vcf.bgz repartition -n 1000 splitmulti vep --config /psych/genetics_data/working/cseed/vep.properties write -o /user/satterst/DILI/DILI_split_vep.vds. It's taking wayyyy too long. log here: /humgen/atgu1/fs03/satterst/hail.log,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/302#issuecomment-210941562:253,log,log,253,https://hail.is,https://github.com/hail-is/hail/issues/302#issuecomment-210941562,2,['log'],['log']
Testability,"I tried benchmarking this change and didn't see much of a difference in timings in my contrived high throughput example. However, I do think this index is better because I believe MySQL does the order by first and then filters records. @danking Can you take a look at this and make sure the index is actually an improvement. The speed of the query is linearly related to the number of records in the limit. So I think if we need to get the query speed back to under 10ms then we revert back to pulling a smaller number of records rather than 1000. I think 300 is fine and gets us to 10ms. I just didn't want to pull 10 jobs and then none of them are schedulable but the 100th one is. We can revisit this if the scheduler becomes the bottleneck after your changes to the gateway.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12350:8,benchmark,benchmarking,8,https://hail.is,https://github.com/hail-is/hail/pull/12350,1,['benchmark'],['benchmarking']
Testability,"I tried testing the output with pandoc, but that failed to render well.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9162:8,test,testing,8,https://hail.is,https://github.com/hail-is/hail/pull/9162,1,['test'],['testing']
Testability,I tried this locally. Let's see if the tests pass.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9784:39,test,tests,39,https://hail.is,https://github.com/hail-is/hail/pull/9784,1,['test'],['tests']
Testability,"I tried to benchmark 100M rows against Spark:. ```; $ spark-shell; scala> val df = spark.range(100000000); df: org.apache.spark.sql.Dataset[Long] = [id: bigint]. scala> val df2 = df.select(df.col(""id""), functions.rand().as(""x"")); df2: org.apache.spark.sql.DataFrame = [id: bigint, x: double]. scala> df2.write.parquet(""df2.parquet""); 18/07/29 13:47:09 ERROR Executor: Exception in task 2.0 in stage 0.0 (TID 2); Caused by: java.lang.OutOfMemoryError: Java heap space; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4030#issuecomment-408697268:11,benchmark,benchmark,11,https://hail.is,https://github.com/hail-is/hail/pull/4030#issuecomment-408697268,1,['benchmark'],['benchmark']
Testability,"I tried to run LOFTEE in Hail for ~2 million variants. It ran for about 2 days and failed (log attached, seems to be killed for running too long?). Just wonder if anything could be done to improve the efficiency. Thanks!. [hail.log.txt](https://github.com/broadinstitute/hail/files/252702/hail.log.txt)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/373:91,log,log,91,https://hail.is,https://github.com/hail-is/hail/issues/373,3,['log'],['log']
Testability,"I updated all packages in conda, ran all python tests, and then updated/added the versions.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4352:48,test,tests,48,https://hail.is,https://github.com/hail-is/hail/pull/4352,1,['test'],['tests']
Testability,"I updated terraform but. 1. GCP Terraform state is still local on my laptop. 2. GCP Terraform appears to not configure global-config. As such, I cannot thread the name of the bucket through to the tests the way we do with TEST_STORAGE_URI. For now, I've hardcoded the name (which is what we were doing previously). When we eventually get to testing recreation of GCP in a new project we'll have to address the global config then.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12964:197,test,tests,197,https://hail.is,https://github.com/hail-is/hail/pull/12964,2,['test'],"['testing', 'tests']"
Testability,"I use codec.py extensively for debugging the shuffler. Recently the Scala-side support for codec.py was deleted. This PR restores support and adds some simple tests. I need to thread the physical type back to the caller of compile, thus all the changes in CompileAndEvaluate and Backend. They should look better with whitespace changes hidden.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8197:159,test,tests,159,https://hail.is,https://github.com/hail-is/hail/pull/8197,1,['test'],['tests']
Testability,"I use text search for ""fail"" in the CI logs, and this always pops up.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7939:39,log,logs,39,https://hail.is,https://github.com/hail-is/hail/pull/7939,1,['log'],['logs']
Testability,"I used filters for the following images when I've run the Azure cleanup script, but we should double check these make sense still in light of changing how we use ""cache"" and there aren't any additional images or ones that we don't want to delete that are in this list:. ```; --filter 'auth:.*' \; --filter 'base:.*' \; --filter 'base_spark_3_2:.*' \; --filter 'batch:.*' \; --filter 'batch-driver-nginx:.*' \; --filter 'batch-worker:.*' \; --filter 'benchmark:.*' \; --filter 'blog_nginx:.*' \; --filter 'ci:.*' \; --filter 'ci-intermediate:.*' \; --filter 'ci-utils:.*' \; --filter 'create_certs_image:.*' \; --filter 'echo:.*' \; --filter 'grafana:.*' \; --filter 'hail-base:.*' \; --filter 'hail-build:.*' \; --filter 'hail-buildkit:.*' \; --filter 'hail-run:.*' \; --filter 'hail-run-tests:.*' \; --filter 'hail-pip-installed-python37:.*' \; --filter 'hail-pip-installed-python38:.*' \; --filter 'hail-ubuntu:.*' \; --filter 'memory:.*' \; --filter 'monitoring:.*' \; --filter 'notebook:.*' \; --filter 'notebook_nginx:.*' \; --filter 'prometheus:.*' \; --filter 'service-base:.*' \; --filter 'service-java-run-base:.*' \; --filter 'test-ci:.*' \; --filter 'test-monitoring:.*' \; --filter 'test-benchmark:.*' \; --filter 'website:.*' \; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12211#issuecomment-1255120349:450,benchmark,benchmark,450,https://hail.is,https://github.com/hail-is/hail/pull/12211#issuecomment-1255120349,5,"['benchmark', 'test']","['benchmark', 'test-benchmark', 'test-ci', 'test-monitoring', 'tests']"
Testability,I used the gsutil storage bandwidth tool and confirmed we get 1.2 Gibit / second upload and download speeds from within a 1 core job and 10 Gi storage. Adding more cores didn't change anything. I ran a test job with the copy tool on a 10 Gi random file and matched 1.2 Gibit / second. I'm wondering if the problem is actually workload-dependent and is based on the number of jobs / number of files. The GCS best practices states the initial capacity is 5000 read requests / second per bucket including list operations until the bucket has time to scale up its capacity. https://cloud.google.com/storage/docs/request-rate#best-practices. ```. ==============================================================================; DIAGNOSTIC RESULTS ; ==============================================================================. ------------------------------------------------------------------------------; Latency ; ------------------------------------------------------------------------------; Operation Size Trials Mean (ms) Std Dev (ms) Median (ms) 90th % (ms); ========= ========= ====== ========= ============ =========== ===========; Delete 0 B 5 43.1 6.4 40.9 50.9 ; Delete 1 KiB 5 44.2 12.7 42.5 58.1 ; Delete 100 KiB 5 44.7 10.4 42.8 56.3 ; Delete 1 MiB 5 41.5 3.7 40.2 45.7 ; Download 0 B 5 74.6 7.9 73.2 84.0 ; Download 1 KiB 5 84.3 15.9 80.6 103.4 ; Download 100 KiB 5 81.9 16.0 82.7 99.6 ; Download 1 MiB 5 90.6 6.5 94.5 96.8 ; Metadata 0 B 5 23.6 2.7 23.6 26.3 ; Metadata 1 KiB 5 25.5 2.1 26.9 27.4 ; Metadata 100 KiB 5 26.2 3.6 27.3 29.9 ; Metadata 1 MiB 5 24.0 3.7 23.3 28.4 ; Upload 0 B 5 98.1 16.6 95.5 117.9 ; Upload 1 KiB 5 116.7 21.8 115.5 142.1 ; Upload 100 KiB 5 116.5 17.8 115.1 135.1 ; Upload 1 MiB 5 168.2 18.5 179.6 185.6 . ------------------------------------------------------------------------------; Write Throughput ; ------------------------------------------------------------------------------; Copied 5 512 MiB file(s) for a total transfer size of 2.5 GiB.; Write thr,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12923#issuecomment-1577071597:202,test,test,202,https://hail.is,https://github.com/hail-is/hail/issues/12923#issuecomment-1577071597,1,['test'],['test']
Testability,I verified that I can now run the batch tests on my laptop from the hail directory with:; ```; hailctl config set batch/billing_project hail # only needed once; make pytest PYTEST_ARGS='-k BatchTests'; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8559#issuecomment-614205652:40,test,tests,40,https://hail.is,https://github.com/hail-is/hail/pull/8559#issuecomment-614205652,1,['test'],['tests']
Testability,I verified the test failed with the same [error as KC's](https://discuss.hail.is/t/repartition-on-read/2148/2) before my change.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10697:15,test,test,15,https://hail.is,https://github.com/hail-is/hail/pull/10697,1,['test'],['test']
Testability,I verified this by testing directly in my namespace,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12940#issuecomment-1524116301:19,test,testing,19,https://hail.is,https://github.com/hail-is/hail/pull/12940#issuecomment-1524116301,1,['test'],['testing']
Testability,"I verified this manually. The deploy account didn't exist when I started this PR, but it still had a role grant in the project's IAM policy. Now the account still does not exist *and* the role grant is gone. The `login` forces you to switch to your account since we're deleting the service account (as which you're probably authenticated).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8178:213,log,login,213,https://hail.is,https://github.com/hail-is/hail/pull/8178,1,['log'],['login']
Testability,"I verified this now works and also verified it fails on current main:; ```; In [2]: from hailtop.hail_logging import *; ...: import logging; ...: configure_logging(); ...: logging.getLogger('foo').info(""hello!""); ...: ; ...: try:; ...: raise ValueError('boom!'); ...: except:; ...: logging.getLogger('foo').exception(""hello!""); {""severity"":""INFO"",""levelname"":""INFO"",""asctime"":""2023-05-10 09:54:36,474"",""filename"":""<ipython-input-2-740eb5422cd6>"",""funcNameAndLine"":""<module>:4"",""message"":""hello!"",""hail_log"":1}; {""severity"":""ERROR"",""levelname"":""ERROR"",""asctime"":""2023-05-10 09:54:36,474"",""filename"":""<ipython-input-2-740eb5422cd6>"",""funcNameAndLine"":""<module>:9"",""message"":""hello!"",""exc_info"":""Traceback (most recent call last):\n File \""<ipython-input-2-740eb5422cd6>\"", line 7, in <module>\n raise ValueError('boom!')\nValueError: boom!"",""hail_log"":1}; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13023#issuecomment-1542260535:132,log,logging,132,https://hail.is,https://github.com/hail-is/hail/pull/13023#issuecomment-1542260535,3,['log'],['logging']
Testability,"I want cancel_after_n_failures to be on a job group. The things a job group doesn't have which maybe it should is:; - callback; - attributes; - updates. I think updates should be on a batch and not part of a job group. An update can add jobs to multiple job groups. Otherwise, the batches table should only have static fields that apply to the entire batch. I think we can do callbacks and attributes on a job group. I added a PATCH endpoint to be able to update a job group's cancel_after_n_attributes as the hailtop.batch interface was going to automatically generate job groups without any configuration settings. As for the full text search, I think prefix searches are faster with full text search than with a regular index, but I could be wrong. We'd have to benchmark it. > If we made batches simpler, does that ease complexity and decrease code duplication? In particular, what if batches didn't contain jobs at all? Instead, a batch contains exactly one job group. That job group contains zero or more job groups. Job groups manage: resource aggregation, cancellation, etc. I believe my plan is basically already doing this. It might not be clear because I didn't put the migrations in. But basically all of the current batches tables are now indexed by batch_id, job_group_id where the current ""batch"" has job_group_id = 1.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12697#issuecomment-1450603163:765,benchmark,benchmark,765,https://hail.is,https://github.com/hail-is/hail/pull/12697#issuecomment-1450603163,2,['benchmark'],['benchmark']
Testability,I want to add some tests first.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10314#issuecomment-819561603:19,test,tests,19,https://hail.is,https://github.com/hail-is/hail/pull/10314#issuecomment-819561603,1,['test'],['tests']
Testability,"I want to cleanup some of the old database functions as they're no longer used (`close_batch`) and not tested / not used in production / hard to maintain (`recompute_incremental`). The `recompute_incremental` was there in the early days of Batch when we needed to recompute the user_inst_coll_resources table etc. for a single migration to improve cancelling. We have not used it since. I double checked `close_batch` isn't used in the Python code, but would appreciate it if you could also check as well.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13510:103,test,tested,103,https://hail.is,https://github.com/hail-is/hail/pull/13510,1,['test'],['tested']
Testability,I want to do testing with dev deploy. Putting this up so I can get feedback.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7910:13,test,testing,13,https://hail.is,https://github.com/hail-is/hail/pull/7910,1,['test'],['testing']
Testability,"I want to finish the Hail Tables cheat sheet. These are things that have come up when discussing this. . These are the things I need to make this cheat sheet:; - [x] `to_matrix_table` needs examples. @tpoterba #7404 ; - [x] `to_matrix_table_row_major` needs examples. @danking (https://github.com/hail-is/hail/pull/7375). These are the things we decided in cheat sheet discussions that we ought to have based on pandas. Feel free to argue we don't want these or something, I'm mostly transcribing the zulip discussion with random assignees: ; - [ ] `count_missing` aggregator. Want to know if there's missing data in a column. @iitalics ; - [ ] `count_present` aggregator. The opposite of `count_missing` (assigned both to same person since it should be basically same, if I'm wrong feel free to reassign). @iitalics ; - [ ] `drop_missing`. The pandas version of this is ""drop any rows in the table with missing values"". Not sure if our version should take a specific column or something. One idea is that with no arguments it will drop any row that has any missing field, but it could also take a list of columns to consider. @catoverdrive ; - [ ] `hl.Table.parallelize` is not a good name. Let's just let there be a constructor for tables that allows you to make tables from local data. If possible, it would also be nice if we could do some better type inference here so that users don't have to pass in a type string the way they do in the current example. @akotlar . These are bugs I ran into while testing the cheat sheet:; - [ ] Calling `show()` on an empty table (I accidentally filtered out all the columns when I messed up a regex) throws some internal java index out of bounds exception. @chrisvittal",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7358:1504,test,testing,1504,https://hail.is,https://github.com/hail-is/hail/issues/7358,1,['test'],['testing']
Testability,"I want to repeat the same expression for all the columns of a keytable. For example doing something like this:. ```; (fin_vds_split_anno; .make_keytable('gene=va.geneann.gene','gt = g.gt',[]); .aggregate_by_key('gene=gene','SUMID=*.gt.sum'); .export(root + 'test.tsv')); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1319:258,test,test,258,https://hail.is,https://github.com/hail-is/hail/issues/1319,1,['test'],['test']
Testability,"I want to track performance of logistic regression. Currently, on my laptop these two benchmarks clock in at 11 seconds for Breeze and 62 seconds for ndarrays. Now that I have a metric I'll try and optimize.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10492:31,log,logistic,31,https://hail.is,https://github.com/hail-is/hail/pull/10492,2,"['benchmark', 'log']","['benchmarks', 'logistic']"
Testability,I want to use them to answer this bioinformatics.SE question:. https://bioinformatics.stackexchange.com/questions/974/selecting-sites-from-vcf-which-have-an-alt-ad-10. ```; from hail import *; hc = HailContext(); (hc.import_vcf('test.vcf'); .filter_variants_expr('gs.exists(g => g.ad[1:].exists(d => d > 10))'); .count()); ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1981:229,test,test,229,https://hail.is,https://github.com/hail-is/hail/pull/1981,1,['test'],['test']
Testability,I want to use this for unsafe testing.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2001:30,test,testing,30,https://hail.is,https://github.com/hail-is/hail/pull/2001,1,['test'],['testing']
Testability,I wanted a quick way to set global feature flags on the service backend. Also took the opportunity to move query tests into their own file.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9506:113,test,tests,113,https://hail.is,https://github.com/hail-is/hail/pull/9506,1,['test'],['tests']
Testability,"I wanted to add a tool that can compare more than two benchmark results and hacked this together today.; I decided to use a means of ""registering"" sub-programs with the main parser to eliminate manual arg parsing.; Make sure you clean and build before using this otherwise you may get collisions with stale package directories.; ```bash; $ hail-bench visualize --help; usage: hail-bench visualize [-h] [--metric {mean,median,stdev,max_memory}] [--head HEAD] [--abs] baseline runs [runs ...]. Visualize benchmark results. positional arguments:; baseline baseline benchmark results; runs benchmarks to compare against baseline. options:; -h, --help show this help message and exit; --metric {mean,median,stdev,max_memory}; --head HEAD number of most significant results to take; --abs plot absolute differences; ```; ![image](https://user-images.githubusercontent.com/8223952/231209244-97007be3-f0d7-4077-ab0e-3a551986a502.png)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12856:54,benchmark,benchmark,54,https://hail.is,https://github.com/hail-is/hail/pull/12856,4,['benchmark'],"['benchmark', 'benchmarks']"
Testability,I wanted to add some benchmarks to start tracking this. They take roughly 25 and 45 seconds respectively on my laptop currently,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9399:21,benchmark,benchmarks,21,https://hail.is,https://github.com/hail-is/hail/pull/9399,1,['benchmark'],['benchmarks']
Testability,I wanted to get feedback on the code I've written thus far before I start testing everything. I'm worried it might be too complicated / brittle to maintain. I also chose to blow away the entire existing environment rather than resetting the variables with new values. Not sure if that's what we want.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13279:74,test,testing,74,https://hail.is,https://github.com/hail-is/hail/pull/13279,1,['test'],['testing']
Testability,"I wanted to get this feature done quickly for Michael. But I do think we should think about having consistency in route names across services. Like when do we have `/delete` in the route name versus a 'DELETE' request or both?. Another question is whether to add the polling / waiting for the user to be created and if so, where should the polling go? I put it in the auth service for now rather than the CLI because I don't think we expose the state of the user in our API. I tested this as much as I could in my namespace. The most important thing is to make sure the decorators are correct and only developers can create / delete users. I want to add auth tests that make sure the routes are protected, but that's more work than I wanted to do in this PR.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11249:477,test,tested,477,https://hail.is,https://github.com/hail-is/hail/pull/11249,2,['test'],"['tested', 'tests']"
Testability,"I was able to assist Jackie in generating a core on my machine using the snipped she posted. In examining the core, I saw that we call `Unsafe_GetNativeLong` with an `addr` argument of 8. A quick examination of the JVM code showed that this addr is promptly cast to a `void*` via `uintptr_t`, and then deferenced. Attached is the jvm crash log showing the java stack trace. [hs_err_pid13461.log](https://github.com/hail-is/hail/files/2480716/hs_err_pid13461.log)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4522#issuecomment-430029805:340,log,log,340,https://hail.is,https://github.com/hail-is/hail/issues/4522#issuecomment-430029805,3,['log'],['log']
Testability,"I was able to figure out how to remove all the ""network shuffle""s and ""coerced sorted dataset""s and that improved the time down to 73 seconds, so a big improvement! I would still hope to improve performance a bit more, being reliably under a minute would be helpful. Here are the logs from that search, let me know what else I can do to help improve the performance or to help you figure it out: ; [hail-search.log](https://github.com/hail-is/hail/files/13310449/hail-search.log). PR is here if you are interested: https://github.com/broadinstitute/seqr/pull/3717",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13882#issuecomment-1804152779:280,log,logs,280,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1804152779,3,['log'],"['log', 'logs']"
Testability,"I was able to get the doctests running locally, and I got `PASSED hail/expr/functions.py::hail.expr.functions.cochran_mantel_haenszel_test`. As Dan mentioned, I cannot see the output of the CI tests. I will try rebasing onto the main branch.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14255#issuecomment-1984908694:193,test,tests,193,https://hail.is,https://github.com/hail-is/hail/pull/14255#issuecomment-1984908694,1,['test'],['tests']
Testability,"I was assigned:; ```; size(dict<T, U>): int32; size(set<T>): int32; isEmpty(dict<T, U>): bool; isEmpty(set<T>): bool; isEmpty(array<T>): bool; head(set<T>): T; head(array<T>): T; tail(set<T>): set<T>; tail(array<T>): array<T>; sum(set<tnum>): tnum; product(set<tnum>): tnum; map(set<T>,(T) => U): set<U>; exists(set<T>,(T) => bool): bool; forall(set<T>,(T) => bool): bool; filter(set<T>,(T) => bool): set<T>; length(array<T>): int32; sort(array<T>,bool): array<T>; sort(array<T>): array<str>; append(array<T>,T): array<T>; extend(array<T>,array<T>): array<T>; ```; I didn't do `head` or `tail`, because they weren't being used. I'm not sure how/where to test the new functions.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3554:654,test,test,654,https://hail.is,https://github.com/hail-is/hail/pull/3554,1,['test'],['test']
Testability,"I was having trouble figuring out how to handle the token and the attributes in hailtop.batch_client.aioclient.Batch. When we create an update from a Batch that already existed perhaps in a different process, we don't have the attributes and token. I made a contract where `commit_update` always returns the token and attributes regardless of whether the BatchBuilder already has that infromation. However, we could also get that information available lazily and cache the result. In addition, the `n_jobs` returned to the client are the number of jobs that are committed and not the same as the `n_jobs` in the batches table. Things to do before merging:; 1. Get rid of the batch updates additions to the UI2. ; 2. Double check the GCP LogsExplorer to make sure there are no silent error messages especially with regards to cancellation.; 3. Have @danking look over the SQL stored procedure for `commit_batch_update` to make sure that query is going to perform as good as what is possible given the complexity of the check.; 4. Run a test batch with the old client (I just checked out the current version of main). You need to make sure both create and create-fast are accounted for and succeed. I've been using the following script to make sure we're using the slow path in addition to the fast path with a regular small test job:. ```python3; from hailtop.batch import ServiceBackend, Batch; import secrets. backend = ServiceBackend(billing_project='hail'); b = Batch(backend=backend); # 8 * 256 * 1024 = 2 MiB > 1 MiB max bunch size; for i in range(8):; j1 = b.new_job(); long_str = secrets.token_urlsafe(256 * 1024); j1.command(f'echo ""{long_str}"" > /dev/null'); batch = b.run(); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12010#issuecomment-1226043347:737,Log,LogsExplorer,737,https://hail.is,https://github.com/hail-is/hail/pull/12010#issuecomment-1226043347,3,"['Log', 'test']","['LogsExplorer', 'test']"
Testability,I was just concerned that I hadn't tested dataproc after the changes and didn't want the release to fail. There wasn't anything about the actual release I changed.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14071#issuecomment-1885047981:35,test,tested,35,https://hail.is,https://github.com/hail-is/hail/pull/14071#issuecomment-1885047981,1,['test'],['tested']
Testability,"I was never clear on what `sign == 0` meant, but it appears not to be used: the tightened assertion passes everything.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8655#issuecomment-620651570:90,assert,assertion,90,https://hail.is,https://github.com/hail-is/hail/pull/8655#issuecomment-620651570,2,['assert'],['assertion']
Testability,I was playing whack-a-mole with randomness tests and adding the GCS_REQUESTER_PAYS_BUCKET flag and the flags interface and testing infrastructure was making it impossible for the VEP tests to pass or the other tests for randomness that were failing. I'll revisit this PR again next week to see if your flags PR actually fixed the issue.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12428#issuecomment-1426177281:43,test,tests,43,https://hail.is,https://github.com/hail-is/hail/pull/12428#issuecomment-1426177281,4,['test'],"['testing', 'tests']"
Testability,"I was surprised to see this didn't fail by fixing some fails_local_backend tests. It turns out that we're writing out invalid files with the lowered matrix writer:; ```; def test_indexed_read(self):; mt = hl.utils.range_matrix_table(2000, 100, 10); f = new_temp_file(extension='mt'); mt.write(f); mt2 = hl.read_matrix_table(f, _intervals=[; hl.Interval(start=150, end=250, includes_start=True, includes_end=False),; hl.Interval(start=250, end=500, includes_start=True, includes_end=False),; ]); self.assertEqual(mt2.n_partitions(), 2); self.assertTrue(mt.filter_rows((mt.row_idx >= 150) & (mt.row_idx < 500))._same(mt2)). mt2 = hl.read_matrix_table(f, _intervals=[; hl.Interval(start=150, end=250, includes_start=True, includes_end=False),; hl.Interval(start=250, end=500, includes_start=True, includes_end=False),; ], _filter_intervals=True); self.assertEqual(mt2.n_partitions(), 3); self.assertTrue(mt.filter_rows((mt.row_idx >= 150) & (mt.row_idx < 500))._same(mt2)). E Java stack trace:; E is.hail.utils.HailException: `intervals` specified on an unindexed matrix table.; E This matrix table was written using an older version of hail; E rewrite the matrix in order to create an index to proceed; E 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:11); E 	at is.hail.utils.package$.fatal(package.scala:77); E 	at is.hail.expr.ir.MatrixNativeReader$.apply(MatrixIR.scala:166); E 	at is.hail.expr.ir.MatrixNativeReader$.fromJValue(MatrixIR.scala:184); ...; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10111#issuecomment-790698282:75,test,tests,75,https://hail.is,https://github.com/hail-is/hail/pull/10111#issuecomment-790698282,5,"['assert', 'test']","['assertEqual', 'assertTrue', 'tests']"
Testability,I wasn't sure if we should print at least one Docker config or not. I'm worried about the test for out_of_memory where that prints out a bunch of the letter 'a' in the script.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9184:90,test,test,90,https://hail.is,https://github.com/hail-is/hail/pull/9184,1,['test'],['test']
Testability,"I wasn't sure what this should look like. For now it does this, would be open to suggestions on how it should look. Currently the tests just test that it doesn't crash, if you're good with how this output looks I'll figure out how to test the output. Some examples:. Boring case with 0 dimensional ndarrays; ```; t = hl.utils.range_table(6); t = t.annotate(a = hl._nd.array(t.idx)); t.show(); +-------+---------------------------+; | idx | a |; +-------+---------------------------+; | int32 | ndarray<int32, 0> |; +-------+---------------------------+; | 0 | ndarray{shape=(), data=0} |; | 1 | ndarray{shape=(), data=1} |; | 2 | ndarray{shape=(), data=2} |; | 3 | ndarray{shape=(), data=3} |; | 4 | ndarray{shape=(), data=4} |; | 5 | ndarray{shape=(), data=5} |; +-------+---------------------------+; ```. Less boring case with 1d ndarrays of length `idx`. ```; t = hl.utils.range_table(6); t = t.annotate(a = hl._nd.arange(t.idx)); t.show(); +-------+------------------------------------------+; | idx | a |; +-------+------------------------------------------+; | int32 | ndarray<int32, 1> |; +-------+------------------------------------------+; | 0 | ndarray{shape=(0), data=[]} |; | 1 | ndarray{shape=(1), data=[0]} |; | 2 | ndarray{shape=(2), data=[0, 1]} |; | 3 | ndarray{shape=(3), data=[0, 1, 2]} |; | 4 | ndarray{shape=(4), data=[0, 1, 2, 3]} |; | 5 | ndarray{shape=(5), data=[0, 1, 2, 3, 4]} |; +-------+------------------------------------------+; ```. Now, 2 dimensional:. ```; t = hl.utils.range_table(6); t = t.annotate(a = hl._nd.arange(t.idx).reshape((3, 2))); t.show(); +-------+------------------------------------------------------+; | idx | a |; +-------+------------------------------------------------------+; | int32 | ndarray<int32, 2> |; +-------+------------------------------------------------------+; | 0 | ndarray{shape=(3, 2), data=[[0, 1], [2, 3], [4, 5]]} |; | 1 | ndarray{shape=(3, 2), data=[[0, 1], [2, 3], [4, 5]]} |; | 2 | ndarray{shape=(3, 2), data=[[0, 1], [2,",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7516:130,test,tests,130,https://hail.is,https://github.com/hail-is/hail/pull/7516,3,['test'],"['test', 'tests']"
Testability,I will add a test for this as a separate PR bug I want to get it in to get Konrad unblocked.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2456#issuecomment-345867674:13,test,test,13,https://hail.is,https://github.com/hail-is/hail/pull/2456#issuecomment-345867674,1,['test'],['test']
Testability,I will add a test.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5895#issuecomment-483942926:13,test,test,13,https://hail.is,https://github.com/hail-is/hail/pull/5895#issuecomment-483942926,1,['test'],['test']
Testability,"I will do a quick sanity check on this before dismissing the review and requesting anew. Right now no tests cover this, but @jbloom22's framework could if we really wanted (annotate a multi-allelic, split it using this, and assert that each allele has at least one annotation)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4218#issuecomment-416754740:102,test,tests,102,https://hail.is,https://github.com/hail-is/hail/pull/4218#issuecomment-416754740,2,"['assert', 'test']","['assert', 'tests']"
Testability,I will follow up with tests to make sure I test this case.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10150#issuecomment-791836974:22,test,tests,22,https://hail.is,https://github.com/hail-is/hail/pull/10150#issuecomment-791836974,2,['test'],"['test', 'tests']"
Testability,I will make the sparsifying rename/doc update a separate PR. @konradjk I also added another test along the same vein but for a matrix that has been filtered for a subset of rows and columns.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5511#issuecomment-469262861:92,test,test,92,https://hail.is,https://github.com/hail-is/hail/pull/5511#issuecomment-469262861,1,['test'],['test']
Testability,"I will need deep copy for KeyedRegionValueAggregators. I only need deepCopy for aggregators with defined `initOp` methods (CallStats), but figured it would be better to add deepCopy to all aggregators so we have both types of copy. Feel free to push back on adding deep copy to all aggregators. I could change `Code.lookupMethod` to return an `Option[Invokeable[T, S]]` instead to test if `deepCopy` exists on the aggregator.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3822:381,test,test,381,https://hail.is,https://github.com/hail-is/hail/pull/3822,1,['test'],['test']
Testability,I will test this with a forthcoming PR which adds a TCP gateway.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9681:7,test,test,7,https://hail.is,https://github.com/hail-is/hail/pull/9681,1,['test'],['test']
Testability,"I will work on the test. . However, there’s a related issue: should we be designing the ToStream behavior in this lowering pass to comply with our type system’s invariant, or not?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8063#issuecomment-586586489:19,test,test,19,https://hail.is,https://github.com/hail-is/hail/pull/8063#issuecomment-586586489,1,['test'],['test']
Testability,"I would like to actually have a test, but nothing seemed to replicate the behavior.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13400#issuecomment-1684176484:32,test,test,32,https://hail.is,https://github.com/hail-is/hail/pull/13400#issuecomment-1684176484,1,['test'],['test']
Testability,"I wrote a pretty basic TableEmit structure that can handle basic read/map/filter stuff. It's still not hooked up to anything, but I wrote a small test for it. Still just passing in the region from outside the generated code, but that'll be the next step. @tpoterba I've assigned this to you again since you had the last one, but I can reassign if you'd like.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4774:146,test,test,146,https://hail.is,https://github.com/hail-is/hail/pull/4774,1,['test'],['test']
Testability,"I wrote this test when moving groupColsBy to the IR, to make sure the AST path was still working, but it's not adding much value, so I think it may as well be deleted now, rather than later.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3772:13,test,test,13,https://hail.is,https://github.com/hail-is/hail/pull/3772,1,['test'],['test']
Testability,I'd like to be able to save the screen printout from ht.show() in a logger file for recordkeeping purposes.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4299:68,log,logger,68,https://hail.is,https://github.com/hail-is/hail/issues/4299,1,['log'],['logger']
Testability,"I'd like to move master to Spark 2 and Scala 2.11. These changes get us as close as possible. They include:. - remove SparkExport, use reflection to get path of partition when loading from parquet; - remove SparkManager; - upgrade to Kudu 1.1.0 (Spark 2 support). The distance between this and Spark 2 is very small, see https://github.com/hail-is/hail/commit/95a588cfa72391d4303bf6891fd017ec211989db. When the master moves to Spark 2, we can maintain a spark1 branch until the on-prem machines get upgraded. Ideally, the spark1 branch could get rebased automatically as part of the CI, although I'm not quite sure how we'd handle conflicts. Alternatively, we could maintain a spark2 -> spark1 diff in the repo that gets applied as part of testing. Fixes https://github.com/hail-is/hail/issues/1117",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1124:740,test,testing,740,https://hail.is,https://github.com/hail-is/hail/pull/1124,1,['test'],['testing']
Testability,I'd like to test this on the real database just to make sure it all works first.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12365#issuecomment-1310795651:12,test,test,12,https://hail.is,https://github.com/hail-is/hail/pull/12365#issuecomment-1310795651,1,['test'],['test']
Testability,"I'd like your initial feedback before I start testing this on Azure. A substantially earlier version seemed to work fine on GCP with dev deploy. The major conceptual change I made is a `resource` now contains a `prefix` and a `version`. The `resource_name` is just `{prefix}/{version}`. The prefixes for GCP are the same as they were before and don't vary by region. However, the new prefixes for Azure are region specific. The version is `1` for all current resources. . I added a `latest_resource_versions` table that has the prefix mapped to the latest version. This is used to generate the current resource names. There is a new CloudResourceManager that is in charge of managing the spot billing pricing cache and updating the prices in the cache and the database from the cloud provider's API. Since I couldn't easily rename resources to products everywhere in the database due to anonymous foreign key constraints, I had to rename the existing `CloudResourceManager` to `CloudDriverAPI`. Feel free to suggest a better name. The GCPResourceManager is a skeleton right now, but we'll have to flesh it out in the new year when GCP moves to spot billing with varying prices. For the `AzureResourceManager`, I use a new pricing client to grab the latest vm and disk prices. I support all possible disk prices, but for now, I limited the VM query to just get the machine types we support right now. In the future, we could get all VM prices, but the query is around 40 seconds for that compared to 2 seconds now. I was worried if we had such a slow query that blocked driver startup, that would be bad and this is fine for now. There are two classes I added: a `Resource` and a `Price`. The Price is only implemented for Azure and is used to store cost results from the pricing API. The resource has a couple of different mixin classes with an abstract method to generate the quantified resource depending on the type (ex: ComputeResourceMixin). Then there's `AzureDiskResource`, `AzureVMResource`, e",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11092:46,test,testing,46,https://hail.is,https://github.com/hail-is/hail/pull/11092,1,['test'],['testing']
Testability,"I'd love feedback, especially on:; * How/whether to test these things; * How to organize a growing collection of hash families, with different speed/power tradeoffs, and different key and hash word-lengths. (These will be used in inner-most loops, so performance matters, and I don't have a good sense of what Scala abstractions hurt performance.)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2288:52,test,test,52,https://hail.is,https://github.com/hail-is/hail/pull/2288,1,['test'],['test']
Testability,"I'd propose to do an implicit dependency audit every time you push a new commit. You can still pin versions on published packages, but use unpinned dependencies for CI testing.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7299#issuecomment-542208997:168,test,testing,168,https://hail.is,https://github.com/hail-is/hail/issues/7299#issuecomment-542208997,1,['test'],['testing']
Testability,I'd really like to see size + performance benchmarks here -- I think the `matrix_table_decode_and_count` and `matrix_table_decode_and_count_just_gt` ones will be interesting.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7803#issuecomment-571308864:42,benchmark,benchmarks,42,https://hail.is,https://github.com/hail-is/hail/pull/7803#issuecomment-571308864,1,['benchmark'],['benchmarks']
Testability,I'll add a test.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8286#issuecomment-597354835:11,test,test,11,https://hail.is,https://github.com/hail-is/hail/pull/8286#issuecomment-597354835,1,['test'],['test']
Testability,"I'll add more tests, and I'm still considering whether to rip out or integrate WriteBlocksRDD for IRM. But given how similar this is to the latter, I'm ready for feedback on the new code.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2559:14,test,tests,14,https://hail.is,https://github.com/hail-is/hail/pull/2559,1,['test'],['tests']
Testability,"I'll add to the log of breaking changes. I've also updated the name from `position_morgan` to `cm_position`, as Plink 2.0 has settled on centimorgans: https://www.cog-genomics.org/plink/2.0/formats#bim. With this change, I can again import 1kg plink files.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3623:16,log,log,16,https://hail.is,https://github.com/hail-is/hail/pull/3623,1,['log'],['log']
Testability,I'll add your test on my branch. Sorry for the communication breakdown!,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2630#issuecomment-353795965:14,test,test,14,https://hail.is,https://github.com/hail-is/hail/pull/2630#issuecomment-353795965,1,['test'],['test']
Testability,"I'll admit I didn't test this since I'm currently debugging the deadlock PR, but this should quiet down the error logs that are being emitted whenever a test runs that intentionally throws an exception in Query.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11376:20,test,test,20,https://hail.is,https://github.com/hail-is/hail/pull/11376,3,"['log', 'test']","['logs', 'test']"
Testability,I'll change my test somehow.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8801#issuecomment-629593684:15,test,test,15,https://hail.is,https://github.com/hail-is/hail/pull/8801#issuecomment-629593684,1,['test'],['test']
Testability,"I'll close it for now, but if I have to test new changes and ci is overloaded again, then I'll reopen it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12263#issuecomment-1267530105:40,test,test,40,https://hail.is,https://github.com/hail-is/hail/pull/12263#issuecomment-1267530105,1,['test'],['test']
Testability,"I'll do a performance test, but there's still foreign key constraints on these rows. They're just redundant. We don't need a check on both `batches` and `attempts`. The rows in `attempts` wouldn't have been inserted without the check in `batches`. All of these proposed changes don't change anything about data integrity.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11938#issuecomment-1163224811:22,test,test,22,https://hail.is,https://github.com/hail-is/hail/pull/11938#issuecomment-1163224811,1,['test'],['test']
Testability,I'll get before/after benchmarks with compressed CDA vs Uncompressed.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12981#issuecomment-1570902781:22,benchmark,benchmarks,22,https://hail.is,https://github.com/hail-is/hail/pull/12981#issuecomment-1570902781,1,['benchmark'],['benchmarks']
Testability,"I'll leave the issue open for now, but this isn't really feasible. You'll get the same problem with GNU pipes: . ``` bash; wm9f1-8cf:tmp tpoterba$ echo ""hello"" > test; wm9f1-8cf:tmp tpoterba$ cat test; hello; wm9f1-8cf:tmp tpoterba$ cat test > test; wm9f1-8cf:tmp tpoterba$ cat test; wm9f1-8cf:tmp tpoterba$; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/747#issuecomment-256325883:162,test,test,162,https://hail.is,https://github.com/hail-is/hail/issues/747#issuecomment-256325883,5,['test'],['test']
Testability,I'll look at this when the tests are passing.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11044#issuecomment-961837291:27,test,tests,27,https://hail.is,https://github.com/hail-is/hail/pull/11044#issuecomment-961837291,1,['test'],['tests']
Testability,I'll make a PR now that axes this test in favor of a test that compares delta results with FastLMM,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1474#issuecomment-284267067:34,test,test,34,https://hail.is,https://github.com/hail-is/hail/pull/1474#issuecomment-284267067,2,['test'],['test']
Testability,"I'll make a quick Discuss post when this goes in. Here is a quick example of renaming as before with a mapping file:. ```; m2 = {r._0: r._1 for r in hc.import_keytable(test_resources + '/sample2_rename.tsv',; config=TextTableConfig(noheader=True)); .collect()}; self.assertEqual(sample2.join(sample2.rename_samples(m2)); .count()['nSamples'], 200); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1463#issuecomment-283826241:267,assert,assertEqual,267,https://hail.is,https://github.com/hail-is/hail/pull/1463#issuecomment-283826241,1,['assert'],['assertEqual']
Testability,"I'll merge this when the tests are done and announce on slack, gitter, and discourse.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1263#issuecomment-273224085:25,test,tests,25,https://hail.is,https://github.com/hail-is/hail/pull/1263#issuecomment-273224085,1,['test'],['tests']
Testability,I'll reopen this when benchmarks are done,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7736#issuecomment-574196142:22,benchmark,benchmarks,22,https://hail.is,https://github.com/hail-is/hail/pull/7736#issuecomment-574196142,1,['benchmark'],['benchmarks']
Testability,"I'll retry, but Azure is doing something weird right now:; ```; FAILED; _____________________ test_pool_highcpu_instance_cheapest ______________________. client = <hailtop.batch_client.client.BatchClient object at 0x7f97f907d690>. def test_pool_highcpu_instance_cheapest(client: BatchClient):; bb = create_batch(client); resources = {'cpu': '0.25', 'memory': '50Mi'}; j = bb.create_job(DOCKER_ROOT_IMAGE, ['true'], resources=resources); b = bb.submit(); status = j.wait(); assert status['state'] == 'Success', str((status, b.debug_info())); > assert 'highcpu' in status['status']['worker'], str((status, b.debug_info())); E AssertionError: ({'batch_id': 74, 'job_id': 1, 'name': None, 'user': 'test', 'billing_project': 'test', 'state': 'Success', 'exit_code': 0, 'duration': 609, 'cost': 1.1510333711392028e-06, 'msec_mcpu': 0, 'status': {'version': 5, 'worker': 'batch-worker-pr-12955-default-rrlcxki12v8r-standard-0e2wl', 'batch_id': 74, 'job_id': 1, 'attempt_id': 'gAaTm8', 'user': 'test', 'state': 'succeeded', 'format_version': 7, 'resources': [{'name': 'az/vm/Standard_D8ds_v4/spot/eastus/1682899200000', 'quantity': 32}, {'name': 'az/disk/E4_LRS/eastus/1546300800000', 'quantity': 1024}, {'name': 'az/ip-fee/1024/2021-12-01', 'quantity': 32}, {'name': 'az/service-fee/2021-12-01', 'quantity': 250}], 'region': 'eastus', 'start_time': 1682966178997, 'end_time': 1682966179606, 'container_statuses': {'main': {'name': 'batch-74-job-1-main', 'state': 'succeeded', 'timing': {'pulling': {'start_time': 1682966179035, 'finish_time': 1682966179224, 'duration': 189}, 'setting up overlay': {'start_time': 1682966179224, 'finish_time': 1682966179253, 'duration': 29}, 'setting up network': {'start_time': 1682966179253, 'finish_time': 1682966179253, 'duration': 0}, 'running': {'start_time': 1682966179253, 'finish_time': 1682966179340, 'duration': 87}, 'uploading_log': {'start_time': 1682966179340, 'finish_time': 1682966179361, 'duration': 21}, 'uploading_resource_usage': {'start_time': 1682966179",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12955#issuecomment-1530133228:473,assert,assert,473,https://hail.is,https://github.com/hail-is/hail/pull/12955#issuecomment-1530133228,5,"['Assert', 'assert', 'test']","['AssertionError', 'assert', 'test']"
Testability,"I'll run benchmarks this morning. Do we have benchmarks from an earlier commit saved somewhere, or do I need to run two?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10797#issuecomment-909140072:9,benchmark,benchmarks,9,https://hail.is,https://github.com/hail-is/hail/pull/10797#issuecomment-909140072,2,['benchmark'],['benchmarks']
Testability,I'll run benchmarks when I get to Broad.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8067#issuecomment-584124068:9,benchmark,benchmarks,9,https://hail.is,https://github.com/hail-is/hail/pull/8067#issuecomment-584124068,1,['benchmark'],['benchmarks']
Testability,I'll run the evil test case 😈,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1558#issuecomment-287174326:18,test,test,18,https://hail.is,https://github.com/hail-is/hail/pull/1558#issuecomment-287174326,1,['test'],['test']
Testability,I'll test manually when I rebase.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12318#issuecomment-1479855493:5,test,test,5,https://hail.is,https://github.com/hail-is/hail/pull/12318#issuecomment-1479855493,1,['test'],['test']
Testability,I'll test on VEP once you resolve the conflicts,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4189#issuecomment-414839713:5,test,test,5,https://hail.is,https://github.com/hail-is/hail/pull/4189#issuecomment-414839713,1,['test'],['test']
Testability,I'll unassign you and assign Chris when I finish testing it.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9217#issuecomment-669202128:49,test,testing,49,https://hail.is,https://github.com/hail-is/hail/pull/9217#issuecomment-669202128,1,['test'],['testing']
Testability,I'll verify in a namespace once the tests verify that this isn't completely insane.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11144#issuecomment-990016240:36,test,tests,36,https://hail.is,https://github.com/hail-is/hail/pull/11144#issuecomment-990016240,1,['test'],['tests']
Testability,I'll wait for benchmark-service to get rm -rf'ed. I addressed the other CDN issue and I dismissed the false positive. I'll check-in again once benchmark-service is removed.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12269#issuecomment-1270398986:14,benchmark,benchmark-service,14,https://hail.is,https://github.com/hail-is/hail/pull/12269#issuecomment-1270398986,2,['benchmark'],['benchmark-service']
Testability,I'll write a test,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3310#issuecomment-379888005:13,test,test,13,https://hail.is,https://github.com/hail-is/hail/pull/3310#issuecomment-379888005,1,['test'],['test']
Testability,"I'm PRing this because it's done / short / adds a good test, but it may be possible to eliminate `TableDistinct` in the future in favor of just `TableAggregateByKey`",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8776:55,test,test,55,https://hail.is,https://github.com/hail-is/hail/pull/8776,1,['test'],['test']
Testability,I'm a bit dubious on editing the change log. Seems like it should really be an append only log.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5960#issuecomment-487212648:40,log,log,40,https://hail.is,https://github.com/hail-is/hail/pull/5960#issuecomment-487212648,2,['log'],['log']
Testability,"I'm a bit perplexed why other keys changed. This is the setting for the non-secret keys.; ```json; 	""deploy_steps"": [],; 	""github_context"": ""ci-test"",; 	""storage_uri"": ""gs://hail-ci-bpk3h"",; 	""bucket_location"": ""us-central1"",; 	""bucket_storage_class"": ""STANDARD"",; 	""test_oauth2_callback_urls"": ""[\""https://internal.hail.is/alpha/oauth2callback\"",\""https://internal.hail.is/beta/oauth2callback\"",\""https://internal.hail.is/gamma/oauth2callback\"",\""https://internal.hail.is/delta/oauth2callback\"",\""https://internal.hail.is/epsilon/oauth2callback\"",\""https://internal.hail.is/zeta/oauth2callback\"",\""https://internal.hail.is/eta/oauth2callback\"",\""https://internal.hail.is/theta/oauth2callback\"",\""https://internal.hail.is/iota/oauth2callback\"",\""https://internal.hail.is/kappa/oauth2callback\"",\""https://internal.hail.is/lambda/oauth2callback\"",\""https://internal.hail.is/mu/oauth2callback\"",\""https://internal.hail.is/nu/oauth2callback\"",\""https://internal.hail.is/xi/oauth2callback\"",\""https://internal.hail.is/omicron/oauth2callback\"",\""https://internal.hail.is/pi/oauth2callback\"",\""https://internal.hail.is/rho/oauth2callback\"",\""https://internal.hail.is/sigma/oauth2callback\"",\""https://internal.hail.is/tau/oauth2callback\"",\""https://internal.hail.is/upsilon/oauth2callback\"",\""https://internal.hail.is/phi/oauth2callback\"",\""https://internal.hail.is/chi/oauth2callback\"",\""https://internal.hail.is/psi/oauth2callback\"",\""https://internal.hail.is/omega/oauth2callback\""]\n"",; 	""watched_branches"": [; 		[; 			""hail-is/hail:main"",; 			true,; 			true; 		]; 	],; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14384#issuecomment-1971802176:144,test,test,144,https://hail.is,https://github.com/hail-is/hail/pull/14384#issuecomment-1971802176,1,['test'],['test']
Testability,I'm also missing agglet extraction logic in StagedExtractAggs,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5307#issuecomment-462502047:35,log,logic,35,https://hail.is,https://github.com/hail-is/hail/pull/5307#issuecomment-462502047,1,['log'],['logic']
Testability,"I'm also running the tests in a loop on a VM to try to flush out any rare, sporadic bugs.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10023#issuecomment-776865190:21,test,tests,21,https://hail.is,https://github.com/hail-is/hail/pull/10023#issuecomment-776865190,1,['test'],['tests']
Testability,I'm also seeing this in my PR that removes most spark-only annotations (in favor of fails_service). I think we must have some logic that spins forever.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11345#issuecomment-1057656473:126,log,logic,126,https://hail.is,https://github.com/hail-is/hail/pull/11345#issuecomment-1057656473,1,['log'],['logic']
Testability,"I'm also surprised we didn't hit earlier. In doing my linear regression debugging, I had added assertions in every call to memoize and rebuild that we are maintaining the expected supertype relationships, which is how I found most of these. I originally thought all of the problems I found were uncovered by IR changes from #9633, but I now suspect that actually we just have/had cases in `PruneDeadFields` where we break the supertype rules temporarily, but it gets cancelled out by some higher IR and doesn't end up mattering. Would be nice if when debugging / testing we could run those asserts to make sure these things don't slip through in the future, as finding all of these bugs was a big headache.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9625#issuecomment-715578188:95,assert,assertions,95,https://hail.is,https://github.com/hail-is/hail/pull/9625#issuecomment-715578188,3,"['assert', 'test']","['assertions', 'asserts', 'testing']"
Testability,"I'm broadly OK with this, but I suspect we need to do something more careful to ensure that the worker exception is connected to the driver exception. It appears that some tests are failing for this reason.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12318#issuecomment-1278123036:172,test,tests,172,https://hail.is,https://github.com/hail-is/hail/pull/12318#issuecomment-1278123036,1,['test'],['tests']
Testability,"I'm closing because this ticket merely notes that the artifact page is only representative of hail. This is expected behavior. The build log is the source of truth, the artifact page is only helpful for the `hail` subproject. In the future, the CI can define a DAG of jobs for the different subproject. The associated UI will enable users to quickly see what failed.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4514#issuecomment-451512691:137,log,log,137,https://hail.is,https://github.com/hail-is/hail/issues/4514#issuecomment-451512691,1,['log'],['log']
Testability,"I'm closing for now. After more careful benchmarking, this is a slight regression. I think this is the right approach, but we don't have enough facilities for writing performant linear algebra in python/hail yet.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11070#issuecomment-973300626:40,benchmark,benchmarking,40,https://hail.is,https://github.com/hail-is/hail/pull/11070#issuecomment-973300626,1,['benchmark'],['benchmarking']
Testability,I'm closing this PR for now so that I'm not testing it for every commit I make.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7101#issuecomment-534707540:44,test,testing,44,https://hail.is,https://github.com/hail-is/hail/pull/7101#issuecomment-534707540,1,['test'],['testing']
Testability,"I'm concerned about merging this PR if it's going to resort the dataset. I don't see why I am getting that warning even with the code I have in TestUtils (below). Maybe there is a problem somewhere else?. ```; def exportPlink(mt: MatrixTable, path: String): Unit = {; mt.selectCols(""""""{fam_id: ""0"", id: sa.s, mat_id: ""0"", pat_id: ""0"", is_female: ""0"", pheno: ""NA""}""""""); .annotateRowsExpr(; ""varid"" -> """"""let l = va.locus and a = va.alleles in [l.contig, str(l.position), a[0], a[1]].mkString("":"")"""""",; ""pos_morgan"" -> ""0""); .exportPlink(path); }; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3417#issuecomment-383622964:144,Test,TestUtils,144,https://hail.is,https://github.com/hail-is/hail/pull/3417#issuecomment-383622964,1,['Test'],['TestUtils']
Testability,I'm confused. I was ready to approve this pending the test passing. Now there's stacked PRs that include these changes. What PR should I look at?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9862#issuecomment-759793573:54,test,test,54,https://hail.is,https://github.com/hail-is/hail/pull/9862#issuecomment-759793573,1,['test'],['test']
Testability,"I'm curious how you would test this. I've manually tested and confirmed it works with the currently commented out test. That test is kind of slow and heavy though, and it's hard to write a good version if I don't know how much memory someone has available. Do you think it's worth adding a new CI job to run certain tests in constrained memory environment to verify they stay below a prescribed limit?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10233#issuecomment-808504566:26,test,test,26,https://hail.is,https://github.com/hail-is/hail/pull/10233#issuecomment-808504566,5,['test'],"['test', 'tested', 'tests']"
Testability,"I'm currently running this branch of CI on a pull request of itself on my own fork of hail, and it nearly passes all tests except for hailtop_batch_* because of requester pays permissions issues and monitoring, because I don't have a service account in my project with all the permissions for broad-ctsa. So unfortunately haven't fully validated that it will _not_ merge a passing PR, but this seemed good enough that we can push it through for azure (since both of these errors are gcp-dependent). If this goes through I can put in a follow-up PR that mirrors the infra resources that CI needs in azure (blob storage, acr permissions, etc.)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11053#issuecomment-964437539:117,test,tests,117,https://hail.is,https://github.com/hail-is/hail/pull/11053#issuecomment-964437539,1,['test'],['tests']
Testability,"I'm fairly certain I know understand this and the AoU VDS creation issue. In Dataproc versions 1.5.74, 2.0.48, and 2.1.0, Dataproc introduced ""memory protection"" which is a euphemism for a newly aggressive OOMKiller. When the OOMKiller kills the JVM driver process, there is no hs_err_pid...log file, no exceptional log statements, and no clean shutdown of any sockets. The process is simply SIGTERM'ed and then SIGKILL'ed. From Hail 0.2.83 through Hail 0.2.109 (released February 2023), Hail was pinned to Dataproc 2.0.44. From Hail 0.2.15 onwards, `hailctl dataproc`, by default, reserves 80% of the advertised memory of the driver node for the use of the Hail Query Driver JVM process. For example, Google advertises that an n1-highmem-8 has 52 GiB of RAM, so Hail sets the `spark:spark.driver.memory` property to `41g` (we always round down). Before aggressive memory protection, this setting was sufficient to protect the driver from starving itself of memory. Unfortunately, Hail 0.2.110 upgraded to Dataproc 2.1.2 which enabled ""memory protection"". Moreover, in the years since Hail 0.2.15, the memory in use by system processes on Dataproc driver nodes appears to have increased. Due to these two circumstances, the driver VM's memory usage can grow high enough to trigger the OOMKiller before the JVM triggers a GC. Consider, for example, these slices of the syslog of the n1-highmem-8 driver VM of a Dataproc cluster:. ```; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: earlyoom v1.6.2; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: mem total: 52223 MiB, swap total: 0 MiB; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: sending SIGTERM when mem <= 0.12% and swap <= 1.00%,; Nov 22 14:26:51 vds-cluster-91f3f4c1-b737-m earlyoom[4115]: SIGKILL when mem <= 0.06% and swap <= 0.50%; ...; Nov 22 14:30:05 vds-cluster-91f3f4c1-b737-m post-hdfs-startup-script[7747]: + echo 'All done'; Nov 22 14:30:05 vds-cluster-91f3f4c1-b737-m post-hdfs-startup-script[7",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13960#issuecomment-1836844790:291,log,log,291,https://hail.is,https://github.com/hail-is/hail/issues/13960#issuecomment-1836844790,4,['log'],['log']
Testability,I'm fixing the failing tests now..,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1517#issuecomment-285446701:23,test,tests,23,https://hail.is,https://github.com/hail-is/hail/pull/1517#issuecomment-285446701,1,['test'],['tests']
Testability,"I'm going to benchmark this today and if nothing has changed since Cotton's benchmarks, I think we're good for a merge. I had hoped to begin working with Grace's team to use this tool on Thursday. I can build a wheel, since I don't anticipate a release happening so fast.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10752#issuecomment-896959032:13,benchmark,benchmark,13,https://hail.is,https://github.com/hail-is/hail/pull/10752#issuecomment-896959032,2,['benchmark'],"['benchmark', 'benchmarks']"
Testability,"I'm going to close this and break it up once I see how tests shake out. I think it's fixed now, but half of this PR has become pruner fixes that probably ought to be their own PR.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9578#issuecomment-713770349:55,test,tests,55,https://hail.is,https://github.com/hail-is/hail/pull/9578#issuecomment-713770349,1,['test'],['tests']
Testability,I'm going to merge select/drop/annotate on the scala side in a separate PR. For now annotateEntriesExpr uses the IR path if possible for testing.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3176:137,test,testing,137,https://hail.is,https://github.com/hail-is/hail/pull/3176,1,['test'],['testing']
Testability,"I'm going to run this migration again on my test database later this afternoon, but in the meantime, can you look over it again?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11990#issuecomment-1195696923:44,test,test,44,https://hail.is,https://github.com/hail-is/hail/pull/11990#issuecomment-1195696923,1,['test'],['test']
Testability,"I'm going to start testing, but I think the only thing that wasn't clear to me was how to resolve these sorts of comments. Do I try and fix them now or in a separate PR with an issue to make sure it gets noted? https://github.com/hail-is/hail/pull/14170#discussion_r1473442106",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14170#issuecomment-1929629871:19,test,testing,19,https://hail.is,https://github.com/hail-is/hail/pull/14170#issuecomment-1929629871,2,['test'],['testing']
Testability,I'm going to test this with dev deploy.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7909#issuecomment-575790241:13,test,test,13,https://hail.is,https://github.com/hail-is/hail/pull/7909#issuecomment-575790241,1,['test'],['test']
Testability,I'm gonna kill this in favor of something that also asserts the status is success.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8471#issuecomment-609873949:52,assert,asserts,52,https://hail.is,https://github.com/hail-is/hail/pull/8471#issuecomment-609873949,1,['assert'],['asserts']
Testability,"I'm gonna push a change that puts a hard 2 minute limit on all tests, we'll see which ones timeout, then I'll mark the ones that are legitimately slow with a per-test timeout. Hopefully this will isolate us down to both the test and particular portion of code that's getting stuck.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13122#issuecomment-1568417144:63,test,tests,63,https://hail.is,https://github.com/hail-is/hail/pull/13122#issuecomment-1568417144,3,['test'],"['test', 'tests']"
Testability,I'm gonna run test-dataproc-37 and -38 before I merge.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13529#issuecomment-1701490177:14,test,test-dataproc-,14,https://hail.is,https://github.com/hail-is/hail/pull/13529#issuecomment-1701490177,1,['test'],['test-dataproc-']
Testability,I'm gonna see if this code works on the full test suite. I'm finding it pretty tricky to work with this stuff. The code I wrote for the last remaining elements in the non-required case seems to be wrong.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13776#issuecomment-1749445909:45,test,test,45,https://hail.is,https://github.com/hail-is/hail/pull/13776#issuecomment-1749445909,1,['test'],['test']
Testability,I'm gonna submit a new PR which subsumes this and #12927 because they're both entangled in a bunch of the same issues and its increasingly apparent that I need them together to pass all the tests.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12908#issuecomment-1520876419:190,test,tests,190,https://hail.is,https://github.com/hail-is/hail/pull/12908#issuecomment-1520876419,1,['test'],['tests']
Testability,"I'm good with this, but I want my service PR to merge first so that we can adjust the test failure annotations accordingly.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10421#issuecomment-831299029:86,test,test,86,https://hail.is,https://github.com/hail-is/hail/pull/10421#issuecomment-831299029,1,['test'],['test']
Testability,"I'm happy to see if I can replace this with a more efficient observability solution, but according to the profiler these lines combined can take up to 8% of the driver's overall CPU time, which just seems like something we shouldn't do. The `get_instance` logging will be especially bad with big clusters because it builds up a whole histogram which then needs to get formatted and printed. I'm not sure how useful these log statements currently are. I never look at them but maybe others do. cc: @danking",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11357:256,log,logging,256,https://hail.is,https://github.com/hail-is/hail/pull/11357,2,['log'],"['log', 'logging']"
Testability,"I'm happy with the code here, and Jon and Alex have looked at math, so I think this is more or less good to go in. Will approve after discussing with Jon whether the possibility of the maximum log liklhood falling on a grid point is something worth worrying about.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1720#issuecomment-297446909:193,log,log,193,https://hail.is,https://github.com/hail-is/hail/pull/1720#issuecomment-297446909,1,['log'],['log']
Testability,"I'm happy with this. And as we move our tests out of Scala and into Python, things will make even more sense.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2590#issuecomment-352192930:40,test,tests,40,https://hail.is,https://github.com/hail-is/hail/pull/2590#issuecomment-352192930,1,['test'],['tests']
Testability,I'm having a lot of of trouble demonstrating that this is faster using the benchmark system. I can see a marked improvement in shuffle benchmarks using my laptop:; ```; $ hb compare /tmp/lz4-before.json /tmp/lz4-after.json; Benchmark Name Ratio Time 1 Time 2; -------------- ----- ------ ------; shuffle_order_by_10m_int 70.4% 47.193 33.245; ```. I also don't see any slowdown for the larger shuffles (which do get slower if we use one of the uncompressed codecs). Running benchmarks on batch have produced results where the median varies from 1% slower to 6% faster.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9292:75,benchmark,benchmark,75,https://hail.is,https://github.com/hail-is/hail/pull/9292,4,"['Benchmark', 'benchmark']","['Benchmark', 'benchmark', 'benchmarks']"
Testability,I'm having a lot of trouble getting the memory tests to pass...,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10331#issuecomment-837285025:47,test,tests,47,https://hail.is,https://github.com/hail-is/hail/pull/10331#issuecomment-837285025,1,['test'],['tests']
Testability,"I'm hitting default & my local build is latest hi/main (`15a45cfb9b0f8da01b2d0408993556f8391749e3`), still broke. I started hail this way:; ```; hailctl config set batch/billing_project hail; hailctl dev config set default_namespace default; HAIL_QUERY_BACKEND=service ipython; ```; ```ipython; In [1]: In [1]: import hail as hl ; ...: ...: ; ...: ...: temp = hl.utils.range_table(100) ; ...: ...: temp.write('gs://danking/workshop-test/1kg.mt', overwrite=True) ; ...: ; Initializing Hail with default parameters...; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.61-15a45cfb9b0f; LOGGING: writing to /Users/dking/projects/hail/hail-20210202-1642-0.2.61-15a45cfb9b0f.log; Traceback (most recent call last):; File ""<ipython-input-1-92be8dd8c99f>"", line 4, in <module>; temp.write('gs://danking/workshop-test/1kg.mt', overwrite=True); File ""</Users/dking/miniconda3/lib/python3.7/site-packages/decorator.py:decorator-gen-1094>"", line 2, in write; File ""/Users/dking/projects/hail/hail/python/hail/typecheck/check.py"", line 577, in wrapper; return __original_func(*args_, **kwargs_); File ""/Users/dking/projects/hail/hail/python/hail/table.py"", line 1271, in write; Env.backend().execute(ir.TableWrite(self._tir, ir.TableNativeWriter(output, overwrite, stage_locally, _codec_spec))); File ""/Users/dking/projects/hail/hail/python/hail/backend/service_backend.py"", line 103, in execute; bucket=self._bucket); File ""/Users/dking/projects/hail/hail/python/hail/backend/service_backend.py"", line 48, in request; return async_to_blocking(retry_transient_errors(self.async_request, endpoint, **data)); File ""/Users/dking/projects/hail/hail/python/hailtop/utils/utils.py"", line 116, in async_to_blocking; return asyncio.get_event_loop().run_until_complete(coro); File ""/Users/dking/miniconda3/lib/python3.7/asyncio/base_events.py"", line 587, in run_until_complete; return future.result(); File ""/Users/dking/projects/hail/hail/python/hailtop/utils/utils.py"", line 395, in ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9856#issuecomment-772011601:432,test,test,432,https://hail.is,https://github.com/hail-is/hail/issues/9856#issuecomment-772011601,4,"['LOG', 'log', 'test']","['LOGGING', 'log', 'test']"
Testability,I'm inclined to not change the test and fix the entries issue. this seems like a good smoke test.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4242#issuecomment-417780296:31,test,test,31,https://hail.is,https://github.com/hail-is/hail/pull/4242#issuecomment-417780296,2,['test'],['test']
Testability,"I'm just waiting for benchmarks to run, but otherwise I think so",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8315#issuecomment-604459713:21,benchmark,benchmarks,21,https://hail.is,https://github.com/hail-is/hail/pull/8315#issuecomment-604459713,1,['benchmark'],['benchmarks']
Testability,"I'm keeping my LD extension branch separate until we add a proper sparse block matrix implementation, but I pulled out these functions on GridPartitioner since (i) they're some of the logic we'll need to make sparse block matrix useful and (ii) Meredith just built a step to compute variant windows in LDPrune, which can then be combined with this logic as part of her optimization strategy to not compute unneeded blocks.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3094:184,log,logic,184,https://hail.is,https://github.com/hail-is/hail/pull/3094,2,['log'],['logic']
Testability,"I'm looking at `worker.py` now and it looks like you worked around this with the addition of `ignore_job_deletion`, which maybe Dan wasn't aware of but is still a workaround since Timings just shouldn't care about deletion in the first place. Without that flag you'd get this:. 1. Running step would start; 2. Job is cancelled, so `Job.deleted` would be set to `True`.; 3. Job would set the Container's `deleted_event`, which would abort the run function inside `run_until_done_or_deleted`; 4. Container would jump to the uploading logs step, which would raise a job deleted error before running `upload_log`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11429#issuecomment-1054613946:532,log,logs,532,https://hail.is,https://github.com/hail-is/hail/pull/11429#issuecomment-1054613946,1,['log'],['logs']
Testability,"I'm merging this so Sali can use the new interface and better performance, and I am going to add an additional test in another PR.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2544#issuecomment-351097552:111,test,test,111,https://hail.is,https://github.com/hail-is/hail/pull/2544#issuecomment-351097552,1,['test'],['test']
Testability,I'm missing something. Why shouldn't test deployments benefit from and contribute to the cache? Why isolate them somewhere else?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11907#issuecomment-1152542361:37,test,test,37,https://hail.is,https://github.com/hail-is/hail/pull/11907#issuecomment-1152542361,1,['test'],['test']
Testability,I'm not 100% confident in the glob code yet. Do you have any additional tests to add?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8626#issuecomment-619252781:72,test,tests,72,https://hail.is,https://github.com/hail-is/hail/pull/8626#issuecomment-619252781,1,['test'],['tests']
Testability,"I'm not 100% sure, but I did this locally. I'd like to test it with aiodocker as well to make sure and confirm on the worker before merging. I couldn't find anything online that 100% confirmed, but my understanding of associated volumes was those created by the container create command based on this behavior. ```; (base) wmecc-475:ci jigold$ docker volume ls; DRIVER VOLUME NAME; (base) wmecc-475:ci jigold$ docker volume create foo; foo; (base) wmecc-475:ci jigold$ docker volume ls; DRIVER VOLUME NAME; local foo; (base) wmecc-475:ci jigold$ docker create -v foo:/foo google/cloud-sdk:237.0.0-alpine echo hello; 1b10e2a6f6a2f7eb6a6fbe06ce5a6bcae85c00174aa3790267935f91714aa7f7; (base) wmecc-475:ci jigold$ docker volume ls; DRIVER VOLUME NAME; local b4b0706c4dfd3ed1907c1fd3325303578f4805a626b88ecbc4935852440577aa; local foo; (base) wmecc-475:ci jigold$ curl --unix-socket /var/run/docker.sock -H ""Content-Type: application/json"" -X DELETE http:/v1.40/containers/1b10e2a6f6a2f7eb6a6fbe06ce5a6bcae85c00174aa3790267935f91714aa7f7?v=true; (base) wmecc-475:ci jigold$ docker volume ls; DRIVER VOLUME NAME; local foo; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7359#issuecomment-545193658:55,test,test,55,https://hail.is,https://github.com/hail-is/hail/pull/7359#issuecomment-545193658,1,['test'],['test']
Testability,"I'm not able to test this against real-sized data yet due to UNIX permissions issues, but I want to start getting code critique.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/658#issuecomment-241537793:16,test,test,16,https://hail.is,https://github.com/hail-is/hail/pull/658#issuecomment-241537793,1,['test'],['test']
Testability,"I'm not entirely sure how to test this. I think I need to create a table with a row beginning exactly on a block boundary, not fully sure how to do that. I've tested this and it does work on the table that I found the issue. I will be making another change soon to prevent this ambiguity.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6633#issuecomment-511213010:29,test,test,29,https://hail.is,https://github.com/hail-is/hail/pull/6633#issuecomment-511213010,2,['test'],"['test', 'tested']"
Testability,I'm not going to read 7000 lines of deletions. Fine with me if it passes! And fine to delete tests conditional on audit soon.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3990#issuecomment-407914682:93,test,tests,93,https://hail.is,https://github.com/hail-is/hail/pull/3990#issuecomment-407914682,1,['test'],['tests']
Testability,I'm not in an environment where I can easily run tests right now. Let's see what CI has to say about these changes.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4891#issuecomment-444528789:49,test,tests,49,https://hail.is,https://github.com/hail-is/hail/pull/4891#issuecomment-444528789,1,['test'],['tests']
Testability,I'm not quite sure why there was the deletion logic intertwined with timings. Can you make sure this change is okay or is there something I am missing here?,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11429:46,log,logic,46,https://hail.is,https://github.com/hail-is/hail/pull/11429,1,['log'],['logic']
Testability,"I'm not really sure, either. I figured as long as every type was in there somewhere at least once and some things were missing, it would be fine. This is just to check backward compatibility, so it's hard to imagine that (1) the current version passes all the tests, (2) it can load a reasonable collections of types and values from an old version, but (3) only, say, missing calls are broken.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3043#issuecomment-369993008:260,test,tests,260,https://hail.is,https://github.com/hail-is/hail/pull/3043#issuecomment-369993008,1,['test'],['tests']
Testability,"I'm not sure I follow. Can you elaborate more on ""We aren't including the test repo on deploy""? I thought we were always testing everything on deploy (ie running Hail, batch, pipeline tests etc).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7814#issuecomment-571721872:74,test,test,74,https://hail.is,https://github.com/hail-is/hail/pull/7814#issuecomment-571721872,3,['test'],"['test', 'testing', 'tests']"
Testability,"I'm not sure I understand. `hail/python/hail/docs/_templates/layout.html` references `/navbar.css` which should be present on the deployed site. I might misunderstand `conf.py`, but, AFAICT, this makes unused copies of navbar.css and the PNG: https://hail.is/docs/0.2/navbar.css and https://hail.is/docs/0.2/hail-logo-cropped.png. The page at https://hail.is/docs/0.2/ loads `hail.is/navbar.css`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8956#issuecomment-644213411:313,log,logo-cropped,313,https://hail.is,https://github.com/hail-is/hail/pull/8956#issuecomment-644213411,1,['log'],['logo-cropped']
Testability,I'm not sure either. I want to keep the explicit logging of when this happens for now.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6477#issuecomment-505891762:49,log,logging,49,https://hail.is,https://github.com/hail-is/hail/pull/6477#issuecomment-505891762,1,['log'],['logging']
Testability,I'm not sure how to actually test these changes.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10732#issuecomment-891315108:29,test,test,29,https://hail.is,https://github.com/hail-is/hail/pull/10732#issuecomment-891315108,1,['test'],['test']
Testability,"I'm not sure the right way to test these. I certainly get errors when I don't have the memoization rules within my new linear regression rows pipeline, but I don't know what triggers the rebuild rules and a complicated linear algebra pipeline doesn't seem like a good way to unit test these anyway.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8038:30,test,test,30,https://hail.is,https://github.com/hail-is/hail/pull/8038,2,['test'],['test']
Testability,"I'm not sure this is the only reason why we're getting worker log errors when a user deletes jobs, but this code is definitely wrong in the case a container hasn't been started. I'm conflicted on whether we should do nothing or write empty files though.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13727:62,log,log,62,https://hail.is,https://github.com/hail-is/hail/pull/13727,1,['log'],['log']
Testability,"I'm not sure what the best/easiest thing to do is. I think we can accomplish the same thing by copying and pasting the delete tables step (runImage) into a dev branch while testing. . The other easiest thing I can think of is to add a `run_if_requested=True` option to each build step config and modify ci to skip over steps that aren't specifically requested in dev deploy. I don't think a new step is a good idea because what if I want an optional runImage step or an optional Deploy step, etc.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7705#issuecomment-565009061:173,test,testing,173,https://hail.is,https://github.com/hail-is/hail/pull/7705#issuecomment-565009061,1,['test'],['testing']
Testability,"I'm not sure what the problem is you're referring to with TStruct is. ```; In [1]: from hail import *; In [2]: from hail.expr import *; In [3]: hc = HailContext(); Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; hail: info: SparkUI: http://172.20.20.20:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version devel-5d97891. In [4]: s = TStruct(['a', 'b'], [TGenotype(), TStruct(['c', 'd'], [TInt32(), TString()])]); In [5]: s; Out[5]: TStruct(['a', 'b'], [TGenotype(), TStruct(['c', 'd'], [TInt(), TString()])]); In [6]: struct = Struct({'a': 5, 'b': 10, 'c': 'hello'}); In [7]: print(struct._history); # 2017-08-14T12:17:18.033131; # version: devel-5d97891. (Struct(attributes={'a': 5, 'c': 'hello', 'b': 10})). In [8]: struct._history; Out[8]: Struct(attributes={'a': 5, 'c': 'hello', 'b': 10}); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2060#issuecomment-322237507:261,log,log,261,https://hail.is,https://github.com/hail-is/hail/pull/2060#issuecomment-322237507,2,['log'],"['log', 'logging']"
Testability,"I'm not sure where these should live, but I wanted to move them off my laptop and into a place where people can access them, and the repo seems as good of a place as any. There are svgs for a bunch of icons in both blue and white, as well as high-ish resolution images of both versions of the logo and 32x32 icon pngs. I haven't started integrating them into website stuff yet, but I figured that raw images should have a central-ish place to live anyways. All of the images in the PR are as below:; ![all](https://user-images.githubusercontent.com/19789871/91755326-ece1d180-eb98-11ea-83ce-eec6b13ab18f.png)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9382:293,log,logo,293,https://hail.is,https://github.com/hail-is/hail/pull/9382,1,['log'],['logo']
Testability,"I'm not sure whether we should add this proactively or not, and to be clear I don't intend users to generally use this, but this is the best solution I can think of so far for @illusional's question about what to do when we have removed support for the old hail access tokens but users still are forced to run a pipeline on an old hail version. Old hail access tokens are stored in JSON in `~/.hail/tokens.json`, so I believe (though have not yet tested, that the following should allow a user to use an old version of hail against a version of batch that only supports cloud access tokens:. On the *new* version of hail, run. ```; hailctl auth login; hailctl auth print-access-token | jq -R -c '{ default: . }' > ~/.hail/tokens.json; ```. Then switch to an old version and proceed as usual (but don't run `hailctl auth login`!).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13934#issuecomment-1783136528:447,test,tested,447,https://hail.is,https://github.com/hail-is/hail/pull/13934#issuecomment-1783136528,6,"['log', 'test']","['login', 'tested']"
Testability,I'm not sure why the disk formatting failed. So I've added more logging to see if we can understand why this is happening.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11867:64,log,logging,64,https://hail.is,https://github.com/hail-is/hail/pull/11867,1,['log'],['logging']
Testability,"I'm not sure, but it's the only difference I could find between session messages that worked on the front end and the messages not showing up from the driver. I want to test this explicitly, but my namespace is currently messed up in Azure with previous database changes.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11094#issuecomment-984813805:169,test,test,169,https://hail.is,https://github.com/hail-is/hail/pull/11094#issuecomment-984813805,1,['test'],['test']
Testability,I'm posting to test that some tests that depend on lapack libraries still pass in CI,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7499:15,test,test,15,https://hail.is,https://github.com/hail-is/hail/pull/7499,2,['test'],"['test', 'tests']"
Testability,I'm pretty sure I fixed the issue. Yay for tests!,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12283#issuecomment-1271808059:43,test,tests,43,https://hail.is,https://github.com/hail-is/hail/pull/12283#issuecomment-1271808059,1,['test'],['tests']
Testability,I'm pretty sure this is broken and the batch tests are going into an infinite loop.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4586#issuecomment-433087824:45,test,tests,45,https://hail.is,https://github.com/hail-is/hail/pull/4586#issuecomment-433087824,1,['test'],['tests']
Testability,"I'm pretty sure we do need to fix evaluation, too -- the java type of the result needs to be consistent, because the way we box things means it can't be implicitly converted the way numeric types can in java. So if an `Int`/`Long` if statement is promoted to `Long`, the result of evaluation needs to be a long in both cases. I think you can add this case to ExprSuite and it'll show the problem:. ``` scala; def checkTypeConcordance(s: String) {; val (t, result) = evalWithType[Any](s); assert(t.asInstanceOf[Type].typeCheck(result)); }; checkTypeConcordance(""""""if (true) 0 else 0.toLong""""""); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/748#issuecomment-245383248:488,assert,assert,488,https://hail.is,https://github.com/hail-is/hail/pull/748#issuecomment-245383248,1,['assert'],['assert']
Testability,I'm putting a wip tag on this so we make sure we dev deploy and test the behavior one last time before merging.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10630#issuecomment-872355294:64,test,test,64,https://hail.is,https://github.com/hail-is/hail/pull/10630#issuecomment-872355294,1,['test'],['test']
Testability,I'm putting the WIP tag for Monday. I changed the code slightly from before. I checked and the test PR driver logs were at least clean.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12654#issuecomment-1426351960:95,test,test,95,https://hail.is,https://github.com/hail-is/hail/pull/12654#issuecomment-1426351960,2,"['log', 'test']","['logs', 'test']"
Testability,I'm putting the WIP tag to remind ourselves to turn off the Azure tests before merging.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13368#issuecomment-1664637939:66,test,tests,66,https://hail.is,https://github.com/hail-is/hail/pull/13368#issuecomment-1664637939,1,['test'],['tests']
Testability,"I'm ready to approve, but I'm not sure why the build is failing, and I don't know what the protocol is now for approving PRs failing tests. Seems like it increases the chances of merging a dumb mistake.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4123#issuecomment-412981153:133,test,tests,133,https://hail.is,https://github.com/hail-is/hail/pull/4123#issuecomment-412981153,1,['test'],['tests']
Testability,"I'm running the following script: . /psych/genetics_data/working/cseed/bin/hail read -i ${input_vds} \; annotatevariants tsv file:///medpop/esp2/mzekavat/Estonia/UPDATED_TOOLS/dbNSFPv3.2/dbNSFP3.2a.ALLChr.bgz \; -r va.dbNSFP \; -t 'SIFT_pred: String, PROVEAN_pred: String, Polyphen2_HDIV_pred: String, Polyphen2_HVAR_pred: String, LRT_pred: String, MutationTaster_pred: String, MutationAssessor_pred: String, FATHMM_pred: String, MetaSVM_pred: String, MetaLR_pred: String, CADD_phred: Double, `Eigen-raw`: Double, `Eigen-phred`: Double, `Eigen-raw_rankscore`: Double' \; -v ""#chr,pos(1-based),ref,alt"" \; -m ""."" \; annotatevariants expr -c 'va.of8 = (if (""D"" ~ va.dbNSFP.SIFT_pred) 1 else 0) + (if (""D"" ~ va.dbNSFP.PROVEAN_pred) 1 else 0) + (if (""D"" ~ va.dbNSFP.Polyphen2_HDIV_pred) 1 else 0) + (if (""D"" ~ va.dbNSFP.Polyphen2_HVAR_pred) 1 else 0) + (if (""D"" ~ va.dbNSFP.LRT_pred) 1 else 0) + (if (""H"" ~ va.dbNSFP.MutationAssessor_pred || ""M"" ~ va.dbNSFP.MutationAssessor_pred) 1 else 0) + (if (""D"" ~ va.dbNSFP.MutationTaster_pred) 1 else 0) + (if (""D"" ~ va.dbNSFP.FATHMM_pred) 1 else 0)' \; exportvariants -c 'v.contig,v.start,v.ref,v.alt,va.of8,va.dbNSFP.MetaSVM_pred,va.dbNSFP.MetaLR_pred,va.dbNSFP.CADD_phred,va.dbNSFP.`Eigen-raw`,va.dbNSFP.`Eigen-phred`,va.dbNSFP.`Eigen-raw_rankscore`' -o /user/mzekavat/MiGen/dbNSFP.MiGen.tsv. and I'm getting an error here: /medpop/esp2/mzekavat/MiGen/Annotation/hail.log; Would greatly appreciate thoughts on this as soon as possible!",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/317:1408,log,log,1408,https://hail.is,https://github.com/hail-is/hail/issues/317,1,['log'],['log']
Testability,"I'm seeing deploy failures where the tests start failing part way through because batch becomes unavailable, for example: https://ci2.hail.is/jobs/2886/log. However, this can't be the whole story, because batch has a readiness check and it isn't clear why it should go unavailable. Either way, this seems safer because it makes sure you pick up the intended version.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6093:37,test,tests,37,https://hail.is,https://github.com/hail-is/hail/pull/6093,2,"['log', 'test']","['log', 'tests']"
Testability,"I'm seeing this in the driver logs:. ```; ERROR 2020-06-16 23:37:18,446 in event loop Traceback (most recent call last):; File ""/usr/local/lib/python3.7/dist-packages/batch/driver/instance_pool.py"", line 500, in event_loop; await self.handle_event(event); File ""/usr/local/lib/python3.7/dist-packages/batch/driver/instance_pool.py"", line 430, in handle_event; timestamp = event.timestamp.timestamp() * 1000; AttributeError: 'dict' object has no attribute 'timestamp'; ```. `event['timestamp']` is in RFC3339 Zulu format with nanosecond precision, for example: 2020-06-08T16:49:53.374657381Z, see: https://cloud.google.com/logging/docs/reference/v2/rest/v2/LogEntry. There is no native RFC3339 Python parser. RFC3339 is nearly identicaly to ISO 8601, except maybe some timezone differences which aren't relevant in Zulu format, see: https://en.wikipedia.org/wiki/ISO_8601. There isn't a native Python ISO 8601 parser. dateutil.parser.isoparse is a ISO 8601 parser (and is maybe also supports RFC3339? I can't quite tell.). Note, Python datetime only has microsecond accuracy, but that's fine because we only store millisecond accuracy. Time is the worst.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8975:30,log,logs,30,https://hail.is,https://github.com/hail-is/hail/pull/8975,3,"['Log', 'log']","['LogEntry', 'logging', 'logs']"
Testability,I'm still looking at this. I'm having a hard time with the test code. I'll try and spend more time tomorrow so I can either figure out what's going on myself or have specific questions.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9822#issuecomment-759790742:59,test,test,59,https://hail.is,https://github.com/hail-is/hail/pull/9822#issuecomment-759790742,1,['test'],['test']
Testability,"I'm still looking, but I could only find the logs for PR 13509 as PR 13458 is too old. There are no batch worker logs at all for these two instances, but there are a bunch of sys logs. I didn't see an obvious error message, but there's 1000s of sys log messages in there. https://console.cloud.google.com/logs/query;query=resource.type%3D%22gce_instance%22%0Alabels.%22compute.googleapis.com%2Fresource_name%22:%22batch-worker-pr-13509-default-p2aogbaogrsp-highmem-np-zx6w4%22;summaryFields=:false:32:beginning;cursorTimestamp=2023-08-29T20:39:28Z;aroundTime=2023-08-29T20:16:33.950Z;duration=PT24H?project=hail-vdc",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13554#issuecomment-1736282516:45,log,logs,45,https://hail.is,https://github.com/hail-is/hail/issues/13554#issuecomment-1736282516,5,['log'],"['log', 'logs']"
Testability,"I'm still not really sure how to test this properly since it's not in the IR function registry, but I checked that the tests in is.hail.methods.AggregatorSuite that rely on this are going through IR.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3816:33,test,test,33,https://hail.is,https://github.com/hail-is/hail/pull/3816,2,['test'],"['test', 'tests']"
Testability,"I'm taking some old tickets from Jon. For this, we just want to combine the two tests into one test method instead of two?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4922#issuecomment-570346582:80,test,tests,80,https://hail.is,https://github.com/hail-is/hail/issues/4922#issuecomment-570346582,2,['test'],"['test', 'tests']"
Testability,"I'm testing out the dev deploy now, but realized this is super slow because Dan's PR changing how the base image is done with a new hail_ubuntu image is in now. Just FYI.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9684#issuecomment-723127410:4,test,testing,4,https://hail.is,https://github.com/hail-is/hail/pull/9684#issuecomment-723127410,1,['test'],['testing']
Testability,I'm testing the JPI real quick to make sure that is fine as well.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10617#issuecomment-869729427:4,test,testing,4,https://hail.is,https://github.com/hail-is/hail/pull/10617#issuecomment-869729427,1,['test'],['testing']
Testability,"I'm trying grm for the first time, and I ran:. hail-new read -i /user/satterst/DBS_v2.4/temp.vds \; filtervariants --keep -c /user/satterst/purcell5k_nodups.interval_list \; count \; grm -f rel -o /user/satterst/DBS_v2.4/temp_rel_grm.tsv. This is 6247 exomes and 5284 variants. . Log file is here: /humgen/atgu1/fs03/satterst/hail.grm.log. I tried this once and let it go for over 40 minutes, and it stayed stuck at Stage 4: (0 + 25) / 25. I accidentally overwrote that log, so I did it again just now, and I didn't let it go for as long, but I observed the same behavior. . When I look at the job's task status page, I see the error I copied in the issue title. The details say:; org.apache.spark.SparkException: Kryo serialization failed: Buffer overflow. Available: 6, required: 8; Serialization trace:; data$mcD$sp (breeze.linalg.DenseMatrix$mcD$sp). To avoid this, increase spark.kryoserializer.buffer.max value.; at org.apache.spark.serializer.KryoSerializerInstance.serialize(KryoSerializer.scala:263); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:240); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745). I'm curious if I'm doing something wrong or if grm is behaving badly.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/321:280,Log,Log,280,https://hail.is,https://github.com/hail-is/hail/issues/321,3,"['Log', 'log']","['Log', 'log']"
Testability,"I'm trying to address three separate error messages:. ```; /usr/local/lib/python3.7/dist-packages/aiomysql/cursors.py:458: Warning: This version of MySQL doesn't yet support 'sorting of non-scalar JSON values'; ```. Add more debug info to warning message with the query executed. ```; Traceback (most recent call last):; File ""/usr/local/lib/python3.7/dist-packages/hailtop/utils/utils.py"", line 775, in retry_long_running; return await f(*args, **kwargs); File ""/usr/local/lib/python3.7/dist-packages/hailtop/utils/utils.py"", line 812, in loop; await f(*args, **kwargs); File ""/usr/local/lib/python3.7/dist-packages/batch/driver/instance_collection.py"", line 181, in monitor_instances; await asyncio.gather(*[check(instance) for instance in instances]); File ""/usr/local/lib/python3.7/dist-packages/batch/driver/instance_collection.py"", line 179, in check; await self.check_on_instance(instance); File ""/usr/local/lib/python3.7/dist-packages/batch/driver/instance_collection.py"", line 157, in check_on_instance; assert last_start_timestamp is not None, f'lastStartTimestamp does not exist {spec}'; ```. Handle case where last_start_timestamp is None. ```; Failed to collect and upload profile: [Errno 32] Broken pipe; ```. This is from the google cloud profiler. I reduced the logging level from error to warning for messages from this module.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10702:1013,assert,assert,1013,https://hail.is,https://github.com/hail-is/hail/pull/10702,2,"['assert', 'log']","['assert', 'logging']"
Testability,"I'm trying to stop having us call `Region.loadBit` everywhere in `EBaseStruct.decode`. First step of that is not calling `setFieldMissing` and `setFieldPresent` everywhere. PRing for tests right now on first round of doing this, there are still some calls that need to be removed.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10994:183,test,tests,183,https://hail.is,https://github.com/hail-is/hail/pull/10994,1,['test'],['tests']
Testability,I'm using one hail environment or everything now and I need these to test hail. I also added twine which we'll need for deploying anything to PyPI including cloudtools.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5916:69,test,test,69,https://hail.is,https://github.com/hail-is/hail/pull/5916,1,['test'],['test']
Testability,"I'm waiting until the full stack is done so I can benchmark and make sure there aren't regressions. I have one more commit to go, I think.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10804#issuecomment-914546008:50,benchmark,benchmark,50,https://hail.is,https://github.com/hail-is/hail/pull/10804#issuecomment-914546008,1,['benchmark'],['benchmark']
Testability,"I'm yanking out this test in PR #1475 in favor of a direct comparison of h2 with FaST-LMM. That said, we should still understand what was causing different runs to give different values.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1416#issuecomment-284279573:21,test,test,21,https://hail.is,https://github.com/hail-is/hail/issues/1416#issuecomment-284279573,1,['test'],['test']
Testability,I've added a note to add a test for this later. Thanks John!,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9627#issuecomment-713899121:27,test,test,27,https://hail.is,https://github.com/hail-is/hail/pull/9627#issuecomment-713899121,1,['test'],['test']
Testability,"I've added a second commit that fixes the remainder of #13191, marking the individual JobResourceFiles within the ResourceGroup as `_mentioned` and hence preventing the “undefined resource” BatchException previously observed. (Some of the tests in _hail/python/test/hailtop/batch/test_batch.py_ would also need adjusting to account for the re-imagined `_mentioned`.). Having now studied f6fe19c085a9d9ebee23866961cb582a713cc1ad, which introduced `_mentioned` and this error message hint, IMHO this is a reasonable fix. Apart from the code in _backend.py_ to do with `symlink_input_resource_group`, which I haven't looked at, `_mentioned` is maintained solely to decide whether to emit this BatchException hinting to the user that the resource ought to be defined if you're going to use it in `write_output`. In this case, because the filenames are related, `foo.gz.tbi` may well have been created even though only `foo.gz` appears explicitly in the command text, so it may be a false positive (as in #13191's case) to raise the exception. So the conservative thing to do is to suppress the message in these `declare_resource_group` cases.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13192#issuecomment-1600755633:239,test,tests,239,https://hail.is,https://github.com/hail-is/hail/pull/13192#issuecomment-1600755633,2,['test'],"['test', 'tests']"
Testability,"I've added a test which catches the bug (using row rather than sparse index of row to fill in missing genotype values with the mean), and fixed it.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/345:13,test,test,13,https://hail.is,https://github.com/hail-is/hail/pull/345,1,['test'],['test']
Testability,"I've added real tests, that check that setup and finalization are correctly paired. If it's okay to wait on refactoring COption (which I don't think will be any harder to do later), then this should be ready for review.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8129#issuecomment-589715873:16,test,tests,16,https://hail.is,https://github.com/hail-is/hail/pull/8129#issuecomment-589715873,1,['test'],['tests']
Testability,"I've added some more information. I haven't quite figured out a good way to present all this. There seems to be three distinct things:; - the mounting of secrets to paths in the pods (documented as code in `deployment.yaml`s); - the name of k8s secrets, their contents, and the meaning of the contents (specifically what the applications expect of it). The latter would be best documented with scripts that regenerate the secrets from some root secret. We can [programmatically generate oauth tokens](https://developer.github.com/v3/oauth_authorizations/) (which are different from personal access tokens) with username and password authentication. A recreation script could use one privileged key that has access to username/password for each hail test user. That is used to generate auth-tokens (we might need to adapt our code to use oauth tokens instead of personal access tokens). GCP service account keys can be generated programmatically. Unfortunately, there seems to be a little bit of work involved in using OAuth instead of personal access tokens. We have to register our ""app"". I can look into this sometime soon. I'll create an issue.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4552#issuecomment-430432141:749,test,test,749,https://hail.is,https://github.com/hail-is/hail/pull/4552#issuecomment-430432141,1,['test'],['test']
Testability,"I've addressed the comments, but I can't run the benchmark anymore, I get weird errors about partitions being empty that I expected to be non-empty. I will continue to investigate.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2253#issuecomment-332664586:49,benchmark,benchmark,49,https://hail.is,https://github.com/hail-is/hail/pull/2253#issuecomment-332664586,1,['benchmark'],['benchmark']
Testability,"I've already deployed to the cluster to test. Unless master deploys, you can see it here: https://grafana.azure.hail.is/datasources/edit/kgzY5Io7k. I also fixed the grafana Makefile.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14106:40,test,test,40,https://hail.is,https://github.com/hail-is/hail/pull/14106,1,['test'],['test']
Testability,I've authorized another test of this PR.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6825#issuecomment-521290991:24,test,test,24,https://hail.is,https://github.com/hail-is/hail/pull/6825#issuecomment-521290991,1,['test'],['test']
Testability,I've authorized sha `600826710afb8dfef5fcbf19f440a43f263ec0ee` in CI so we should get a test run through soon.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14700#issuecomment-2407899242:88,test,test,88,https://hail.is,https://github.com/hail-is/hail/pull/14700#issuecomment-2407899242,1,['test'],['test']
Testability,"I've been supporting Hana as much as I can, but she needs someone who can be more dedicated and responsive than me. She uses a k8s cluster. She has a SEQR frontend deployment. She also has a Hail deployment (statefulset maybe?). The Hail pod has an SSD mounted read-only. That SSD has all the SEQR data in Hail Table form. There are many tables with annotations (variant metadata, like ""probability this variant is damaging"" or ""likely causes this to happen to the protein""). There are also ""per-family"" tables which contain all the sequences within a single family. Many queries are directly against a particular family. Those tables are small and quick to read. There's also one giant table containing all the sequences from all the families. That table is large and expensive to read. A lot of our engineering work has been around making sure queries against that table are fast. Tim, at one point, had enough of her system locally that he could experiment with running queries on his laptop against his SSD. He hacked on the queries themselves and on Hail itself until the bandwidth was fast enough that the queries should complete fast enough on the full dataset. Fast enough varies but generally a couple tens of seconds is OK. The work here is to pair with Hana to diagnose performance issues and make changes until the queries are acceptably fast. The first thing I would do is update her to the latest Hail (with the array decoder improvement as well as the memory overhead stuff on which Daniel is working). Then, with Hana's help, test the timing of some queries. If the queries are still too slow, your options are:; 1. Check the log files and the IR. Are there unnecessary shuffles? Is the code really large? Can we do less work maybe?; 2. Have Hana help you replicate her setup locally. You just need a slice of the data and enough of SEQR to run a query. Now hook up a profiler. What's slow? Can we do something about that?. ### Version. 0.2.124. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13882:1907,test,test,1907,https://hail.is,https://github.com/hail-is/hail/issues/13882,3,"['log', 'test']","['log', 'test']"
Testability,"I've done some extensive remodeling of Pedigree and MendelErrors, shorter and conceptually cleaner now, got to delete a bunch of code. But I'm having a serialization issue, which may be related to changing MendelError to include the CompleteTrio rather than the sample. For example, if I replace ""implicatedSample"" by pasting the body in the closure instead, then the serialization error at that point goes away. but there are a bunch of other ones from the toLine below. ```; org.apache.spark.SparkException: Task not serializable; at org.apache.spark.util.ClosureCleaner$.ensureSerializable(ClosureCleaner.scala:166); at org.apache.spark.util.ClosureCleaner$.clean(ClosureCleaner.scala:158); at org.apache.spark.SparkContext.clean(SparkContext.scala:1622); at org.apache.spark.rdd.RDD.map(RDD.scala:286); at org.broadinstitute.hail.methods.MendelErrors.writeMendel(MendelErrors.scala:143); at org.broadinstitute.hail.methods.MendelErrorsSuite.test(MendelErrorsSuite.scala:50); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); at org.testng.internal.Invoker.invokeMethod(Invoker.java:696); at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:882); at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1189); at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); at org.testng.TestRunner.privateRun(TestRunner.java:767); at org.testng.TestRunner.run(TestRunner.java:617); at org.testng.SuiteRunner.runTest(SuiteRunner.java:348); at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:343); at org.testng.SuiteRunner.privateRun(SuiteRunner.java",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/68#issuecomment-155304880:945,test,test,945,https://hail.is,https://github.com/hail-is/hail/pull/68#issuecomment-155304880,1,['test'],['test']
Testability,I've expanded the tests and fixed the join logic. It'll be much easier to test when we can easily define our own row/col keys with the `annotate/select` methods.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2605#issuecomment-352825562:18,test,tests,18,https://hail.is,https://github.com/hail-is/hail/pull/2605#issuecomment-352825562,3,"['log', 'test']","['logic', 'test', 'tests']"
Testability,"I've got some weird testing issues I'm working out. Once those are fixed, I'll kick it back to Jackie (probably today / early tomorrow)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/291#issuecomment-210106396:20,test,testing,20,https://hail.is,https://github.com/hail-is/hail/pull/291#issuecomment-210106396,1,['test'],['testing']
Testability,"I've gut-renovated the TDT implementation and improved docs and tests. The t=0, u=0 case is now handed generically, giving NaN and NaN instead of 0.0 and 1.0 for chi2 and pval. I've also normalized the pedigree and trio fields/functions to be consistent with the other changes.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2768#issuecomment-359282910:64,test,tests,64,https://hail.is,https://github.com/hail-is/hail/pull/2768#issuecomment-359282910,1,['test'],['tests']
Testability,I've hacked a 'solution' by adding an explicit check at https://github.com/hail-is/hail/blob/607d2b4aa032c24db033359eb6f92da976a8d9f2/src/main/scala/org/broadinstitute/hail/io/vcf/HtsjdkRecordReader.scala#L59 but am not sure of the performance penalty. All tests still pass at least! :). See pull request https://github.com/hail-is/hail/pull/1066,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1065#issuecomment-258770482:257,test,tests,257,https://hail.is,https://github.com/hail-is/hail/issues/1065#issuecomment-258770482,1,['test'],['tests']
Testability,"I've made the changes you suggested patrick, but now we have a failing test. I'm getting a situation where Vt is clearly orthonormal, and U@S@Vt multiplies back to the input matrix, but U@U.t is not particularly close to the identity matrix. It's not clear why this is. The test is:. ```; np_rank_2_wide_rectangle = np.arange(12).reshape((4, 3)); rank_2_wide_rectangle = hl.nd.array(np_rank_2_wide_rectangle). ......... assert_evals_to_same_svd(rank_2_wide_rectangle, np_rank_2_wide_rectangle, full_matrices=False); ```. (The 4th test in the `test_svd` method)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9727#issuecomment-733190588:71,test,test,71,https://hail.is,https://github.com/hail-is/hail/pull/9727#issuecomment-733190588,6,['test'],['test']
Testability,"I've merged a stack of changes to this branch including:; - Cleaned up tests, including refactoring, making Balding-Nichols covariates deterministic and removing lots of extra test code; - Reorder args in Scala to match Python, related bug fixes; - Improved large N performance by using single array D rather than A and B; - Moved dense versus sparse matching outside of loop; - Improved Python docs and Scala remarks; - Debugged test failure only occurring in Spark 2.1.0, which turned out to be related to accuracy of Davies. I've increased accuracy to 1e-8 which is enough to make current tests pass. Once this goes in, I'll make PRs to:; - Allow users to set accuracy and iterations on Davies, will use same defaults as R: 1e-6 and 10k.; - Add number of variants per key as column.; - Fix behavior to finish running even if some groups are too big upper bound, or if Cholesky fails. Document this behavior. Less urgently, but to keep in mind:; - If bottleneck, improve performance of Gramian computation in large N case using blocking; - Improve Davies C code",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2153#issuecomment-325388707:71,test,tests,71,https://hail.is,https://github.com/hail-is/hail/pull/2153#issuecomment-325388707,4,['test'],"['test', 'tests']"
Testability,"I've moved `check_entry_indexed` outside the conditional and added a note to remove the conditional entirely once select_entries on a field is free. I think it's reasonable to keep the conditional until then, at least in the block matrix case where needlessly invoking the compiler on every double may effect performance. If you feel strongly, I'll remove it from PCA and test the performance impact on write BlockMatrix (though I'd rather just leave the latter unperturbed).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3262#issuecomment-377698921:372,test,test,372,https://hail.is,https://github.com/hail-is/hail/pull/3262#issuecomment-377698921,1,['test'],['test']
Testability,"I've not written a test for this because we use this pattern a lot, and we haven't been writing explicit test cases for all of our simplify rules, but let me know if you want one.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9011:19,test,test,19,https://hail.is,https://github.com/hail-is/hail/pull/9011,2,['test'],['test']
Testability,I've realised that hailtop is not the place for contributed methods that use batch if we want to restrict hail imports. Think about how strange it is to exclude our own Batch cookbook example (gwas clumping) from a viable contributed module (in that case no tests on gwas.py could be performed directly).,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9194#issuecomment-670772749:258,test,tests,258,https://hail.is,https://github.com/hail-is/hail/pull/9194#issuecomment-670772749,1,['test'],['tests']
Testability,"I've rebased `jbloom22:lmm_getthisin` onto `jbloom22:py_reg` (which should go in first) and made the parallel modifications (LinearMixedModelCommand is gone, command line relics gone, refactored using RegressionUtils, tests modified to accommodate changing interface, etc). I'll do some command line testing next to be safe.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1064#issuecomment-272765058:218,test,tests,218,https://hail.is,https://github.com/hail-is/hail/pull/1064#issuecomment-272765058,2,['test'],"['testing', 'tests']"
Testability,"I've removed the Python `tempfile` approach in favor of adding `new_local_temp_file` to utils and a corresponding function to HailContext in Scala, which currently hardcodes `file:///temp` as the local temp directory. It may be more natural to have a localTmpDir on HailContext like we have tmpDir. ; I see there is a notion of local temp files on TempDir on the Scala side, but it doesn't seem to be used on the Python side. I also don't see if/where we wipe temp files on exit. In any case, I've tested that now it all works nicely on GCP, so ready for feedback/review. I think factoring through `tofile` and `fromfile` is useful for wider interoperability for the same reason that NumPy exposes them, but it's also good if you don’t want to actually load the NumPy array into driver memory but just save it to read/copy later, or to load it multiple time without recomputing the BlockMatrix. And I've provided the simpler interface of `to_numpy` and `from_numpy` for the common case. I suspect that (de)serializing over the network and building the local matrix dominates local read/write, so that using a socket isn't going to do much better. I can profile more closely if/when we feel it's high priority to make this faster still.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3114#issuecomment-372165433:498,test,tested,498,https://hail.is,https://github.com/hail-is/hail/pull/3114#issuecomment-372165433,2,['test'],['tested']
Testability,I've removed the `make test-deploy` stuff to simplify this PR.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5844#issuecomment-481837110:23,test,test-deploy,23,https://hail.is,https://github.com/hail-is/hail/pull/5844#issuecomment-481837110,2,['test'],['test-deploy']
Testability,"I've replicated the issue. invocation:; ```bash; ./pyhail-submit cluster-2 foo.py; ```; `foo.py`:; ```python; #!/usr/bin/python. from pyhail import *. hc = HailContext(log=""/tmp/hail.log""). (hc.read(<andrea's file here>); .write('gs://hail-1kg/trash.vds')); ```; first failure:; ```; 2016-12-15 19:05:43 ERROR Utils:91 - Uncaught exception in thread task-result-getter-1; java.lang.OutOfMemoryError: Java heap space; at java.util.Arrays.copyOf(Arrays.java:3332); at java.lang.AbstractStringBuilder.ensureCapacityInternal(AbstractStringBuilder.java:124); at java.lang.AbstractStringBuilder.append(AbstractStringBuilder.java:448); at java.lang.StringBuffer.append(StringBuffer.java:270); at org.apache.log4j.helpers.PatternParser$LiteralPatternConverter.format(PatternParser.java:419); at org.apache.log4j.PatternLayout.format(PatternLayout.java:506); at org.apache.log4j.WriterAppender.subAppend(WriterAppender.java:310); at org.apache.log4j.WriterAppender.append(WriterAppender.java:162); at org.apache.log4j.AppenderSkeleton.doAppend(AppenderSkeleton.java:251); at org.apache.log4j.helpers.AppenderAttachableImpl.appendLoopOnAppenders(AppenderAttachableImpl.java:66); at org.apache.log4j.Category.callAppenders(Category.java:206); at org.apache.log4j.Category.forcedLog(Category.java:391); at org.apache.log4j.Category.log(Category.java:856); at org.slf4j.impl.Log4jLoggerAdapter.warn(Log4jLoggerAdapter.java:400); at org.apache.spark.internal.Logging$class.logWarning(Logging.scala:66); at org.apache.spark.scheduler.TaskSetManager.logWarning(TaskSetManager.scala:52); at org.apache.spark.scheduler.TaskSetManager.handleFailedTask(TaskSetManager.scala:693); at org.apache.spark.scheduler.TaskSchedulerImpl.handleFailedTask(TaskSchedulerImpl.scala:421); at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$2.apply$mcV$sp(TaskResultGetter.scala:139); at org.apache.spark.scheduler.TaskResultGetter$$anon$3$$anonfun$run$2.apply(TaskResultGetter.scala:124); at org.apache.spark.scheduler",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1186#issuecomment-267416027:168,log,log,168,https://hail.is,https://github.com/hail-is/hail/issues/1186#issuecomment-267416027,4,['log'],['log']
Testability,I've simplified / improved the test to show both modes of failure that indeed occur on master.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3749#issuecomment-396754583:31,test,test,31,https://hail.is,https://github.com/hail-is/hail/pull/3749#issuecomment-396754583,2,['test'],['test']
Testability,"ILURES ===================================; ____________________________ Test.test_list_batches ____________________________. self = <test.test_batch.Test testMethod=test_list_batches>. def test_list_batches(self):; tag = secrets.token_urlsafe(64); b1 = self.client.create_batch(attributes={'tag': tag, 'name': 'b1'}); b1.create_job('alpine', ['sleep', '30']); b1.close(); ; b2 = self.client.create_batch(attributes={'tag': tag, 'name': 'b2'}); b2.create_job('alpine', ['echo', 'test']); b2.close(); ; def assert_batch_ids(expected, complete=None, success=None, attributes=None):; batches = self.client.list_batches(complete=complete, success=success, attributes=attributes); # list_batches returns all batches for all prev run tests; actual = set([batch.id for batch in batches]).intersection({b1.id, b2.id}); self.assertEqual(actual, expected); ; assert_batch_ids({b1.id, b2.id}, attributes={'tag': tag}); ; b2.wait(); ; > assert_batch_ids({b1.id}, complete=False, attributes={'tag': tag}). test/test_batch.py:93: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ; test/test_batch.py:87: in assert_batch_ids; self.assertEqual(actual, expected); E AssertionError: Items in the second set but not the first:; E 19; ________________________________ test_callback _________________________________. client = <batch.client.BatchClient object at 0x7f0d1363ee80>. def test_callback(client):; from flask import Flask, request; app = Flask('test-client'); output = []; ; @app.route('/test', methods=['POST']); def test():; output.append(request.get_json()); return Response(status=200); ; try:; server = ServerThread(app); server.start(); batch = client.create_batch(callback=server.url_for('/test')); head = batch.create_job('alpine:3.8', command=['echo', 'head']); left = batch.create_job('alpine:3.8', command=['echo', 'left'], parents=[head]); right = batch.create_job('alpine:3.8', command=['echo', 'right'], parents=[head]); tail = batch.create_job('alpine:3.8', comman",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6260#issuecomment-498852506:1106,test,test,1106,https://hail.is,https://github.com/hail-is/hail/pull/6260#issuecomment-498852506,1,['test'],['test']
Testability,"IMARY of table `dgoldste-batch`.`aggregated_billing_project_user_resources_v3` trx id 2486477 lock_mode X locks rec but not gap; Record lock, heap no 228 PHYSICAL RECORD: n_fields 7; compact format; info bits 0; 0: len 4; hex 74657374; asc test;;; 1: len 8; hex 64676f6c64737465; asc dgoldste;;; 2: len 4; hex 80000009; asc ;;; 3: len 4; hex 80000034; asc 4;;; 4: len 6; hex 00000025f0cd; asc % ;;; 5: len 7; hex 810000021b01cd; asc ;;; 6: len 8; hex 80000000001b09e0; asc ;;. Record lock, heap no 249 PHYSICAL RECORD: n_fields 7; compact format; info bits 0; 0: len 4; hex 74657374; asc test;;; 1: len 8; hex 64676f6c64737465; asc dgoldste;;; 2: len 4; hex 80000009; asc ;;; 3: len 4; hex 800000ad; asc ;;; 4: len 6; hex 00000025f0cd; asc % ;;; 5: len 7; hex 010000008c050d; asc ;;; 6: len 8; hex 8000000000471350; asc G P;;. Record lock, heap no 266 PHYSICAL RECORD: n_fields 7; compact format; info bits 0; 0: len 4; hex 74657374; asc test;;; 1: len 8; hex 64676f6c64737465; asc dgoldste;;; 2: len 4; hex 80000009; asc ;;; 3: len 4; hex 8000008b; asc ;;; 4: len 6; hex 00000025f0cd; asc % ;;; 5: len 7; hex 010000008c0bd1; asc ;;; 6: len 8; hex 80000000004c0108; asc L ;;. Record lock, heap no 273 PHYSICAL RECORD: n_fields 7; compact format; info bits 0; 0: len 4; hex 74657374; asc test;;; 1: len 8; hex 64676f6c64737465; asc dgoldste;;; 2: len 4; hex 8000000a; asc ;;; 3: len 4; hex 80000038; asc 8;;; 4: len 6; hex 00000025f0cd; asc % ;;; 5: len 7; hex 010000008c17e1; asc ;;; 6: len 8; hex 8000000000370dc0; asc 7 ;;. Record lock, heap no 284 PHYSICAL RECORD: n_fields 7; compact format; info bits 0; 0: len 4; hex 74657374; asc test;;; 1: len 8; hex 64676f6c64737465; asc dgoldste;;; 2: len 4; hex 80000009; asc ;;; 3: len 4; hex 800000bd; asc ;;; 4: len 6; hex 00000025f0cd; asc % ;;; 5: len 7; hex 010000008c204f; asc O;;; 6: len 8; hex 8000000000427f70; asc B p;;. Record lock, heap no 288 PHYSICAL RECORD: n_fields 7; compact format; info bits 0; 0: len 4; hex 74657374; asc test;;; 1: le",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14380:4906,test,test,4906,https://hail.is,https://github.com/hail-is/hail/issues/14380,1,['test'],['test']
Testability,"IMO, it's better to get this in with unsatisfying testing than to let it bit rot in a branch on my computer.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5332#issuecomment-462999269:50,test,testing,50,https://hail.is,https://github.com/hail-is/hail/pull/5332#issuecomment-462999269,1,['test'],['testing']
Testability,INFO: request GET http://batch.hail/api/v1alpha/batches/6627669 response 200\n2022-11-15 20:31:22.827 Requester: INFO: request GET http://batch.hail/api/v1alpha/batches/6627669\n2022-11-15 20:31:22.846 Requester: INFO: request GET http://batch.hail/api/v1alpha/batches/6627669 response 200\n2022-11-15 20:31:27.847 Requester: INFO: request GET http://batch.hail/api/v1alpha/batches/6627669\n2022-11-15 20:31:27.880 Requester: INFO: request GET http://batch.hail/api/v1alpha/batches/6627669 response 200\n2022-11-15 20:31:27.880 ServiceBackend$: INFO: parallelizeAndComputeWithIndex: pty4D81uzQk6XN9LVVebj6KNvkh8SC3EzvXjgv6-LMY=: reading results\n2022-11-15 20:31:27.881 Requester: INFO: request GET http://memory.hail/api/v1alpha/objects?q=gs%3A%2F%2Fhail-test-dmk9z%2FparallelizeAndComputeWithIndex%2Fpty4D81uzQk6XN9LVVebj6KNvkh8SC3EzvXjgv6-LMY%3D%2Fresult.0\n2022-11-15 20:31:28.080 Requester: INFO: request GET http://memory.hail/api/v1alpha/objects?q=gs%3A%2F%2Fhail-test-dmk9z%2FparallelizeAndComputeWithIndex%2Fpty4D81uzQk6XN9LVVebj6KNvkh8SC3EzvXjgv6-LMY%3D%2Fresult.0 response 200\n2022-11-15 20:31:28.104 ServiceBackend$: INFO: result 0 complete - 8157265 bytes\n2022-11-15 20:31:28.104 Requester: INFO: request GET http://memory.hail/api/v1alpha/objects?q=gs%3A%2F%2Fhail-test-dmk9z%2FparallelizeAndComputeWithIndex%2Fpty4D81uzQk6XN9LVVebj6KNvkh8SC3EzvXjgv6-LMY%3D%2Fresult.1\n2022-11-15 20:31:28.293 Requester: INFO: request GET http://memory.hail/api/v1alpha/objects?q=gs%3A%2F%2Fhail-test-dmk9z%2FparallelizeAndComputeWithIndex%2Fpty4D81uzQk6XN9LVVebj6KNvkh8SC3EzvXjgv6-LMY%3D%2Fresult.1 response 200\n2022-11-15 20:31:28.313 ServiceBackend$: INFO: result 1 complete - 8157265 bytes\n2022-11-15 20:31:28.313 Requester: INFO: request GET http://memory.hail/api/v1alpha/objects?q=gs%3A%2F%2Fhail-test-dmk9z%2FparallelizeAndComputeWithIndex%2Fpty4D81uzQk6XN9LVVebj6KNvkh8SC3EzvXjgv6-LMY%3D%2Fresult.2\n2022-11-15 20:31:28.522 Requester: INFO: request GET http://memory.hail/api/v1alpha/object,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12470#issuecomment-1315959284:35749,test,test-,35749,https://hail.is,https://github.com/hail-is/hail/pull/12470#issuecomment-1315959284,2,['test'],['test-']
Testability,IR test assertions,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3663:3,test,test,3,https://hail.is,https://github.com/hail-is/hail/pull/3663,2,"['assert', 'test']","['assertions', 'test']"
Testability,"IRSuite passes, but all tests do not. From test_docs:. ```. Java stack trace:; is.hail.utils.HailException: not a streamable IR: (ToArray; (ArrayMap __iruid_226; (ToStream; (ToArray; (GetTupleElement 0; (Ref __iruid_225)))); (MakeTuple (0 1); (GetField key; (Ref __iruid_226)); (GetTupleElement 0; (GetField value; (Ref __iruid_226)))))); 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:9); 	at is.hail.utils.package$.fatal(package.scala:74); 	at is.hail.expr.ir.EmitStream$.is$hail$expr$ir$EmitStream$$emitStream$1(EmitStream.scala:851); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8063#issuecomment-584224191:24,test,tests,24,https://hail.is,https://github.com/hail-is/hail/pull/8063#issuecomment-584224191,1,['test'],['tests']
Testability,IRSuite tests for ToDict and LowerBoundOrderedCollection,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4482:8,test,tests,8,https://hail.is,https://github.com/hail-is/hail/pull/4482,1,['test'],['tests']
Testability,"Identities in test namespaces cannot share the same underlying cloud identity if we want to identify requests with cloud access tokens. This also means the `test` account does not need to have the union of roles of the other robot accounts, but pruning of the `test` account's roles is left until after this PR merges so we can properly assess which roles are still in use by the `test` account.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13202:14,test,test,14,https://hail.is,https://github.com/hail-is/hail/pull/13202,4,['test'],['test']
Testability,"If I change my performance test to write using fast LZ4, the time drops to 26.2s and the profile looks like:. ![Screen Shot 2020-05-26 at 1 43 34 PM](https://user-images.githubusercontent.com/106194/82932751-e5d27400-9f56-11ea-9356-086f57d58fba.png)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8864#issuecomment-634173911:27,test,test,27,https://hail.is,https://github.com/hail-is/hail/pull/8864#issuecomment-634173911,1,['test'],['test']
Testability,"If a container is deleted before it ever runs, the log files won't exist. Fixes #13906; Fixes #13907",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13911:51,log,log,51,https://hail.is,https://github.com/hail-is/hail/pull/13911,1,['log'],['log']
Testability,"If a pod is unreachable for any reason, we previously retried forever. However,; a pods are ephemeral; we cannot assume they will return. Instead, if we fail to; contact a pod, we remove it from the pods list and log the error. If the pod; really does exist, the monitor_pods loop will attempt to initialize it again.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9858:213,log,log,213,https://hail.is,https://github.com/hail-is/hail/pull/9858,1,['log'],['log']
Testability,"If batch job fails we should still increment the _task_idx.; Otherwise, we ignore the log for the failing task.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5470:86,log,log,86,https://hail.is,https://github.com/hail-is/hail/pull/5470,1,['log'],['log']
Testability,"If hail and numpy use two different lapack implementations, might not get the same sign on the singular vectors. This PR switches our vector comparison tests to check the absolute values of the matrices, plus make sure they multiply back together properly.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9727:152,test,tests,152,https://hail.is,https://github.com/hail-is/hail/pull/9727,1,['test'],['tests']
Testability,"If it passes the CI tests, I'm cool with it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4262#issuecomment-419147345:20,test,tests,20,https://hail.is,https://github.com/hail-is/hail/pull/4262#issuecomment-419147345,1,['test'],['tests']
Testability,"If my hypothesis is true, then there should be evidence of API requests in the logs for different files having the same uploadId. I'll try and take a look at what the logs show for the failing file uploads.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12950#issuecomment-1564748285:79,log,logs,79,https://hail.is,https://github.com/hail-is/hail/issues/12950#issuecomment-1564748285,2,['log'],['logs']
Testability,"If only we had, y'know, a benchmarking system that could, y'know, run benchmarks.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6291#issuecomment-500153683:26,benchmark,benchmarking,26,https://hail.is,https://github.com/hail-is/hail/pull/6291#issuecomment-500153683,2,['benchmark'],"['benchmarking', 'benchmarks']"
Testability,If query has to pull its image fresh each job takes ~2 minutes. I also fixed some; whitespace issues in the tests and a little bug in `retry_response_returning_functions`.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9574:108,test,tests,108,https://hail.is,https://github.com/hail-is/hail/pull/9574,1,['test'],['tests']
Testability,"If there is an improvement, it is very small, running more tests now, but it looks like the new code is in the noise compared to other factors.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5828#issuecomment-481320024:59,test,tests,59,https://hail.is,https://github.com/hail-is/hail/pull/5828#issuecomment-481320024,1,['test'],['tests']
Testability,"If these tests are being run, I can't find them. Also, rename incorrectly named gear => config in hailtop tests.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9396:9,test,tests,9,https://hail.is,https://github.com/hail-is/hail/pull/9396,2,['test'],['tests']
Testability,"If we find out the write is complete during a status check, we would assert the buffer is empty before advancing the the offset to the end. This exit point now matches the exit point when we complete after a normal chunk write. Also assert _closed in _wait_closed. _write_chunk can only complete when we've closed and therefore know the final size, so make sure _closed so we don't accidentally get into an infinite loop waiting for _done.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10034:69,assert,assert,69,https://hail.is,https://github.com/hail-is/hail/pull/10034,2,['assert'],['assert']
Testability,If you fix that @vladsaveliev tests will pass and we'll be good to go.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10863#issuecomment-941145413:30,test,tests,30,https://hail.is,https://github.com/hail-is/hail/pull/10863#issuecomment-941145413,1,['test'],['tests']
Testability,"If you look at the driver logs, there should be a bunch of errors.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10920#issuecomment-956513975:26,log,logs,26,https://hail.is,https://github.com/hail-is/hail/pull/10920#issuecomment-956513975,1,['log'],['logs']
Testability,If you made one with `csq=True` it would be pretty easy (in your testing script) to take a line of the output and assert that it's the same length (after splitting both on `|`) as string in the header,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4150#issuecomment-413124680:65,test,testing,65,https://hail.is,https://github.com/hail-is/hail/pull/4150#issuecomment-413124680,2,"['assert', 'test']","['assert', 'testing']"
Testability,"If you sort the GitHub PRs by `is:pr is:open sort:updated-desc`, you'll see that some PRs which have merge conflicts are continuously tested by CI. Really old PRs that are stuck in this state reach a GitHub quota for status updates to a PR for a given SHA. It seems to me that we shouldn't retest any PR that is `source_sha_failed`, and I think this should resolve that particular issue, but am not sure if this is necessarily the best place to insert this logic.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10654:134,test,tested,134,https://hail.is,https://github.com/hail-is/hail/pull/10654,2,"['log', 'test']","['logic', 'tested']"
Testability,"If you want to wait for Daniel and I to test it in Azure later, that's fine in case something else shows up.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10986#issuecomment-948995865:40,test,test,40,https://hail.is,https://github.com/hail-is/hail/pull/10986#issuecomment-948995865,1,['test'],['test']
Testability,"If you're happy, I'll assign this for scala review and after it's in, the next step is figuring out how to set up the CI to test vep with both options for reproducing these files.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4150#issuecomment-415224730:124,test,test,124,https://hail.is,https://github.com/hail-is/hail/pull/4150#issuecomment-415224730,1,['test'],['test']
Testability,"If you're okay with this, I need to test backwards compatibility with the older version of resource usage files.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12542#issuecomment-1342840441:36,test,test,36,https://hail.is,https://github.com/hail-is/hail/pull/12542#issuecomment-1342840441,1,['test'],['test']
Testability,"Im also happy to let this in as mostly is (so no additional tests, api changes), and set the remainder that you find valid as issues. No need to stall something that isn't very user facing.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6892#issuecomment-528921065:60,test,tests,60,https://hail.is,https://github.com/hail-is/hail/pull/6892#issuecomment-528921065,1,['test'],['tests']
Testability,Implement a set of logging improvements,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4421:19,log,logging,19,https://hail.is,https://github.com/hail-is/hail/pull/4421,1,['log'],['logging']
Testability,"Implement the combiner in a ServiceBackend compatible way. query is not set up for ergonomic asynchronous programming in any way,; shape, or form. As such, this is very rough. However, blocking round; trips have been eliminated. Care has been taken to maximize amount of; work done in each job while still allowing reasonable save points. That; is, we run every gVCF combine first in one bounded_gather2 call. Then,; for every level of vds merging (that is, `floor(log(n_samples, branch_factor)) == 0, 1, 2, 3...`),; we run every combine at that level, until we have fewer than; branch_factor files to merge, and then we merge them all at once.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12382:465,log,log,465,https://hail.is,https://github.com/hail-is/hail/pull/12382,1,['log'],['log']
Testability,"Implemented image untagging for image cleanup steps (like is done in GCR) for Azure. Since old layers still should be used for caching, this just removes the tag used for an image in a test build. We can then do something like [here](https://docs.microsoft.com/en-us/azure/container-registry/container-registry-auto-purge#run-in-an-on-demand-task) where you can purge untagged layers that are older than some number of weeks where we believe they're no longer relevant to the layer cache. I also switched out the `registry-push-credentials` that CI uses to build images from the ACR admin login to CI's service principal and eliminated the admin login from the ACR terraform resource. I dev deployed CI and manually verified after a deploy that a tag that was cleaned up no longer showed up in acr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11100:185,test,test,185,https://hail.is,https://github.com/hail-is/hail/pull/11100,3,"['log', 'test']","['login', 'test']"
Testability,"Implemented the transmission disequilibrium test (TDT) in hail. TDT tests for variants that are inherited more or less than what would be expected by chance (i.e., 50%).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/753:44,test,test,44,https://hail.is,https://github.com/hail-is/hail/pull/753,2,['test'],"['test', 'tests']"
Testability,"Implements Katex. Changes to goto.js (and its position on the page) has to do with Firefox's apparently broken history.scrollRestoration = 'manual' handling on page refresh (in that it still automatically restores scroll position). Tested in Chrome, Firefox (latest), Safari 13.0.1, Microsoft Edge (Mac Beta 78.0.276.20). Edge should mostly behave like Chrome, runs now on Chromium.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7427:232,Test,Tested,232,https://hail.is,https://github.com/hail-is/hail/pull/7427,1,['Test'],['Tested']
Testability,Implements a DistributedBackend and uses it to run the subset of the TableIRSuite tests that can be lowered to execute on a backend.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6304:82,test,tests,82,https://hail.is,https://github.com/hail-is/hail/pull/6304,1,['test'],['tests']
Testability,"Implements a StagedIndexWriter with a very similar structure to the unstaged version. To test this, I threaded this through `IndexWriter.build` so that it now compiles a function that implements the CompiledIndexWriter interface:; ```; trait CompiledIndexWriter {; def init(path: String): Unit; def apply(x: Long, offset: Long, annotation: Long): Unit; def close(): Unit; }; ```; with a wrapper class that mimics the interface of the old IndexWriter. Eventually, we'll need this to lower TableWrite. (Kind of non-randomly assigning @chrisvittal, as I'd like feedback on whether the new-style imperative codegen looks right.)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8737:89,test,test,89,https://hail.is,https://github.com/hail-is/hail/pull/8737,1,['test'],['test']
Testability,ImportError: No module named hailjwt; Makefile:22: recipe for target 'test/jwt-test-user-token' failed; make: *** [test/jwt-test-user-token] Error 1,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5844#issuecomment-483899083:70,test,test,70,https://hail.is,https://github.com/hail-is/hail/pull/5844#issuecomment-483899083,4,['test'],"['test', 'test-user-token']"
Testability,Improve Python testing times,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5669:15,test,testing,15,https://hail.is,https://github.com/hail-is/hail/pull/5669,1,['test'],['testing']
Testability,Improve assert error message,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1878:8,assert,assert,8,https://hail.is,https://github.com/hail-is/hail/pull/1878,1,['assert'],['assert']
Testability,Improve deploy logic,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6042:15,log,logic,15,https://hail.is,https://github.com/hail-is/hail/pull/6042,1,['log'],['logic']
Testability,Improve robustness of export_plink and export_gen tests,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4528:50,test,tests,50,https://hail.is,https://github.com/hail-is/hail/pull/4528,1,['test'],['tests']
Testability,"Improved logreg code, added Firth",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1375:9,log,logreg,9,https://hail.is,https://github.com/hail-is/hail/pull/1375,1,['log'],['logreg']
Testability,Improvements before Scale Tests,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6491:26,Test,Tests,26,https://hail.is,https://github.com/hail-is/hail/issues/6491,1,['Test'],['Tests']
Testability,Improves performance of GVCF import significantly:; ```; Benchmark Name Ratio Time 1 Time 2; -------------- ----- ------ ------; import_gvcf_force_count 81.2% 68.737 55.833; import_and_transform_gvcf 79.9% 75.692 60.464; ----------------------; Harmonic mean: 80.5%; Geometric mean: 80.6%; Arithmetic mean: 80.6%; Median: 80.6%; ```. Stacked on #8382,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8383:57,Benchmark,Benchmark,57,https://hail.is,https://github.com/hail-is/hail/pull/8383,1,['Benchmark'],['Benchmark']
Testability,"In PR namespaces, it creates the database-server-config which is the root user which we use to set up everyone else. test_database_instance is cooked up by the createDatabase for the test database. In non-PR namespaces, it doesn't exist because that secret already exists",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11441#issuecomment-1056027209:183,test,test,183,https://hail.is,https://github.com/hail-is/hail/pull/11441#issuecomment-1056027209,1,['test'],['test']
Testability,"In Python, we check that the row.dtype and entry.dtype are the same for all MTs. In scala we assert that the RVDTypes are the same. This means that both requiredness and entry array location can cause problems.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4761:93,assert,assert,93,https://hail.is,https://github.com/hail-is/hail/issues/4761,1,['assert'],['assert']
Testability,"In `SparkBackend`, TableIRs get lowered into SparkStages and value IRs get lowered into SparkPipelines. `SparkStage` represents the necessary computation on a partition of a table, as well as the partitioning information. This can either directly represent a TableIR, in which case the partition IR (`body`) is an array of all the rows of that given partition, or whatever the downstream ValueIR needs---e.g. for `TableCount`, the length of that array; for `TableWrite`, the filename that the partition was written out to, etc. `SparkPipeline` represents a local value that can use the results from the referenced stages. One assumption that I've made in this PR is that none of the bindings across all `SparkStage.globals` will have the same name, and none of them will be named ""context"". (I think this is a fairly reasonably assumption, since we'll just use genUID() to generate unique IDs for all of them and then use unique symbols once #5080 goes in.). In this PR, I've lowered:; - TableCount; - TableCollect; - TableGetGlobals; - TableRange; - TableMapGlobals; - TableMapRows. in order to write some tests.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5127:1107,test,tests,1107,https://hail.is,https://github.com/hail-is/hail/pull/5127,1,['test'],['tests']
Testability,"In `httpx` the 5s is a ""total timeout"" which is applied to read and connect. I don't know what connection idle and write exactly refer to but setting to 5s and seeing how the tests react seems like a good start. In general, in a datacenter, I'd expect any ordinary network operation to be faster than 5s regardless of write vs read.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13344#issuecomment-1659278243:175,test,tests,175,https://hail.is,https://github.com/hail-is/hail/pull/13344#issuecomment-1659278243,1,['test'],['tests']
Testability,"In `relativeUpperIndexBounds`, the positions won't be sorted unless we sort them, so that cannot be an assertion. Yes, re-keying by contig means we don't have a guarantee that the positions aren't re-ordered within their groups, but since we sort inside `relativeUpperIndexBounds`, this ensures that they are sorted and that they therefore match the ordering in the block matrix. The sorting doesn't screw up the alignment with the block matrix, because the sorting is what guarantees the alignment with the block matrix.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3697#issuecomment-393929082:103,assert,assertion,103,https://hail.is,https://github.com/hail-is/hail/pull/3697#issuecomment-393929082,1,['assert'],['assertion']
Testability,"In a new environment,; ```; cd hail; make install; make pytest; ```; fails with; ```; ...; ERROR: usage: setup.py [options] [file_or_dir] [file_or_dir] [...]; setup.py: error: unrecognized arguments: --instafail --self-contained-html --html=../build/reports/pytest.html; inifile: None; rootdir: /path/to/hail/hail/python; ```. because the pytest plugins in hail/python/dev-requirements.txt are not installed. This documents the need to install them before running tests.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7942:464,test,tests,464,https://hail.is,https://github.com/hail-is/hail/pull/7942,1,['test'],['tests']
Testability,"In a previous PR we added exception logging when tasks on a `BackgroundTaskManager` fail. I'm not seeing any of those messages in the worker logs, suggesting that for some reason the Tasks to free a network namespace when a job is finished are not getting created in the first place. I don't see how in the code we could somehow *not* free the network namespace, but I'm hoping that some of these diagnostics shed some light. Also open to suggestions for where else might be a good spot to add more logging.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13509:36,log,logging,36,https://hail.is,https://github.com/hail-is/hail/pull/13509,3,['log'],"['logging', 'logs']"
Testability,"In a89d64a, I modified `build.yaml` to release the wheel we had already built and tested. Unbeknownst to me was that we rebuild the wheel with a different version of `hail/python/hailtop/hailctl/deploy.yaml` and releasing the version used for testing borked `hailctl dataproc` commands. To fix this, we'll rebuild the wheel but use the `jar` we've already built and tested. This is safe to do as far as I know because we don't bundle any information into the jar that depends on the make flag `DEPLOY_REMOTE`. Fixes: #14452",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14453:82,test,tested,82,https://hail.is,https://github.com/hail-is/hail/pull/14453,3,['test'],"['tested', 'testing']"
Testability,"In aiohttp, a task is cancelled when the requesting user drops the connection. This; is not an exception condition and should not be logged as such.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10929:133,log,logged,133,https://hail.is,https://github.com/hail-is/hail/pull/10929,2,['log'],['logged']
Testability,"In fact I had Firth mixed into this branch but ripped it out when it was making the update too complicated. Whereas Wald, LRT, and score only require fitting the null model once, the Firth LRT requires fitting the null and full models per variant. So plan is to add Firth, support for subsetting samples per variant (rather than imputing missing genotypes), and better tests by comparing Hail and R results for randomly generated datasets. I'd also like to add more [optional] user control on convergence criteria and on what's returned in annotations (for example, statistics for the other covariates...these are computed anyway...also on the null fit in globals). And there are ways to speed up the numerical linear algebra, this is a first pass. Do you have thoughts on Firth LRT versus Wald? My understanding is that LRT is better calibrated for p-value, but would the Wald standard error for Firth be a useful annotation as well? Also, check out v1 of doc: ; https://github.com/jbloom22/hail/blob/jb_logreg3/docs/LogisticRegression.md",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/585#issuecomment-239686959:369,test,tests,369,https://hail.is,https://github.com/hail-is/hail/pull/585#issuecomment-239686959,2,"['Log', 'test']","['LogisticRegression', 'tests']"
Testability,"In https://github.com/hail-is/hail/pull/9113, I forced the auth driver to use; the modern, TLS-required, SQL config format. I incorrectly forgot to specify the; TLS file paths. Luckily, when I tried to create a user account for Patrick; Cummings, instead of creating a broken secret, the auth driver; error'ed. Moreover, the clean up code was broken. As a result, Patrick's account; was stuck in `creating`. This PR fixes both the clean up code issue (I set `self.namespace` in; `K8sSecretResource`) and specifies the TLS file paths (see driver.py near; line 217). In addition, this PR attempts to avoid future problems with the sql; configuration by codifying the required components as a NamedTuple, `SQLConfig`. I also; co-located all the parsing and transformation logic between JSON, dicts, and CNF; in the `SQLConfig` class. I traced back all the users of `create_secret_data_from_config` to ensure they; all now use SQLConfig. I added lots of type annotations, but those won't do; anything right now because we don't have mypy enabled for hailtop.auth. ---. There's a separate issue of us not getting notified that Patrick's account was; not being created due to an error. The relevant logs are linked below. I'm glad; we're starting work on better monitoring. Hopefully error logs like these will; trigger emails to services team. https://console.cloud.google.com/logs/query;query=resource.type%3D%22k8s_container%22%0Aresource.labels.namespace_name%3D%22default%22%0Aresource.labels.container_name%3D%22auth-driver%22;timeRange=2020-08-11T15:44:00.000Z%2F2020-08-11T23:55:00.000Z?project=hail-vdc&query=%0A. Moreover, the infinite retry of his account created tens of google service; accounts that were not cleaned up. I do not yet understand why the google; service account clean up code failed. The clean up code bug that I *do* fix in; this PR addresses the GSA secret and the tokens secret.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9259:769,log,logic,769,https://hail.is,https://github.com/hail-is/hail/pull/9259,4,['log'],"['logic', 'logs']"
Testability,"In main, we assumed that if `self._batch is not None` then there is a Batch that needs cancelling, but that is no longer true. Now, we must track whether we have called `submit` or not. I made a few other minor cleanups of `ServiceBackend` while I was in there. There is no longer any need to have a `None` batch b/c there is no distinction between a builder and a batch now. Example error:; ```; INFO hailtop.aiocloud.aiogoogle.credentials:credentials.py:92 using credentials file /test-gsa-key/key.json: GoogleServiceAccountCredentials for testns-test-418@hail-vdc.iam.gserviceaccount.com; _________ ERROR at teardown of Tests.test_loop_with_struct_of_strings __________. init_hail = None; request = <SubRequest 'set_query_name' for <TestCaseFunction test_loop_with_struct_of_strings>>. @pytest.fixture(autouse=True); def set_query_name(init_hail, request):; backend = current_backend(); if isinstance(backend, ServiceBackend):; backend.batch_attributes = dict(name=request.node.name); yield; backend.batch_attributes = dict(); references = list(backend._references.keys()); for rg in references:; backend.remove_reference(rg); backend.initialize_references(); if backend._batch:; report: Dict[str, CollectReport] = request.node.stash[test_results_key]; if any(r.failed for r in report.values()):; > log.info(f'cancelling failed test batch {backend._batch.id}'). test/hail/conftest.py:81: ; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ; /usr/local/lib/python3.9/dist-packages/hailtop/batch_client/aioclient.py:347: in id; self._raise_if_not_created(); _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ . self = <hailtop.batch_client.aioclient.Batch object at 0x7ffae6f11bb0>. def _raise_if_not_created(self):; if not self.is_created:; > raise BatchNotCreatedError; E hailtop.batch_client.aioclient.BatchNotCreatedError. ```. https://batch.hail.is/batches/7950601/jobs/156",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13564:483,test,test-gsa-key,483,https://hail.is,https://github.com/hail-is/hail/pull/13564,7,"['Test', 'log', 'test']","['TestCaseFunction', 'Tests', 'log', 'test', 'test-gsa-key', 'testns-test-']"
Testability,"In many cases, we ignore? the dropRows parameter on TableRead. I have no idea how this test is passing on main, but I think I have a fix.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11562#issuecomment-1065493842:87,test,test,87,https://hail.is,https://github.com/hail-is/hail/issues/11562#issuecomment-1065493842,1,['test'],['test']
Testability,"In noticed this was missing when I tried to run the benchmarks, which use pipeline.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7018:52,benchmark,benchmarks,52,https://hail.is,https://github.com/hail-is/hail/pull/7018,1,['benchmark'],['benchmarks']
Testability,"In order to track partition bounds and distinctness, we report the first and last seen keys when writing (matrix) tables. Previously we were copying the last seen key into the partition region. This is incorrect as the partition region has a lifetime of the entire partition and cannot be cleared, leaking memory. Fix this by giving the last seen key its own region that can be cleared before a new last seen key is saved. Tested manually.; See the following zulip thread for initial report.; https://hail.zulipchat.com/#narrow/stream/123011-Hail-Query-Dev/topic/memory.20usage.20by.20range.20-.3E.20write/near/316404073",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12574:423,Test,Tested,423,https://hail.is,https://github.com/hail-is/hail/pull/12574,1,['Test'],['Tested']
Testability,"In particular, it appears that your Make might be invoking bash with the sixth argument starting with the three characters `'[\`. My Make sends a string whose first three characters are `'[ ` because it sees the `\` as a *make* line-continuation character. In particular, the full bash command that my Make invokes is:. ```; python3 -m hailtop.aiotools.copy -vvv 'null' '[ {""from"":""src/test/resources"",""to"":""gs://hail-test-ezlis/dking/hail-test-resources/test/resources/""}, {""from"":""python/hail/docs/data"",""to"":""gs://hail-test-ezlis/dking/hail-test-resources/doctest/data/""} ]'; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14138#issuecomment-1889779728:386,test,test,386,https://hail.is,https://github.com/hail-is/hail/pull/14138#issuecomment-1889779728,6,['test'],"['test', 'test-ezlis', 'test-resources']"
Testability,"In response to #7299. It would be nice to get to a more automated way of doing this, but for now we should just update this assuming it passes all tests.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7301:147,test,tests,147,https://hail.is,https://github.com/hail-is/hail/pull/7301,1,['test'],['tests']
Testability,"In testing batch, it looks like:. ```; ModuleNotFoundError: No module named 'hailjwt'; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5844#issuecomment-484972045:3,test,testing,3,https://hail.is,https://github.com/hail-is/hail/pull/5844#issuecomment-484972045,1,['test'],['testing']
Testability,"In the short term, a fix which makes the UI usable again for these kinds of jobs is to check blob size, if it's over some threshold, show no log and instruct the user to download it. Then fix the download to use aiohttp's StreamResponse. We should maybe split this issue into a frontend-side and worker-side.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12852#issuecomment-1653991936:141,log,log,141,https://hail.is,https://github.com/hail-is/hail/issues/12852#issuecomment-1653991936,2,['log'],['log']
Testability,"In the worst case of a fully connected graph it's O(n) insertions, at an average cost of O(1), followed by O(n) `extractMax` which are O(log n) each. For each `extractMax` we have to decrease priority on every other node, so thats O(n^2) decreasePriority which is O(log n) each. So the dominating factor is O(n^2 log(n)). We should almost never see fully connected graphs. I suspect we'll usually have disconnected graphs of fully connected subgraphs. Then the runtime is O(m * n^2 log(n)) where `m` is the number of families and `n` is the average family size. `n` should be rather small, probably not higher than 20? probably smaller. `m` could be quite large, but we're linear in `m`. Some timings for fully connected graphs of size `n`:. | `n` | time (minutes) |; |-|-|; | 1024 | 0.0051 |; | 8192 | 0.13 |; | 32767 | 3.0 |; | 65535 | 12.5 |. According to the profiler, the vast majority of the time is spent interacting with the hash table. We could probably get the constants a lot lower by using an array instead of a hash table (since we have a perfect hash function: sample index). ---. ```; def fullyConnected(n: Int) {; val biggestFirst = new BinaryHeap[Int](). var i = 0; while (i <= n) {; biggestFirst.insert(i, n); i += 1; }. val g = (i: Int) => 0 to n. while (biggestFirst.maxPriority() > 0) {; val current = biggestFirst.extractMax(); val neighbors = g(current); neighbors.foreach { x =>; if (biggestFirst.contains(x)); biggestFirst.decreasePriority(x, _ - 1); }; }. val actual = biggestFirst.toArray; assert(actual.length === 1); }; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2148#issuecomment-326072568:137,log,log,137,https://hail.is,https://github.com/hail-is/hail/pull/2148#issuecomment-326072568,5,"['assert', 'log']","['assert', 'log']"
Testability,"In this PR:. - I add `BlockMatrix.from_ndarray`. The implementation isn't great, it just basically just evals the ndarray and adds NDArray support to `ValueToBlockMatrix`. A better version wouldn't cross the Python / Java boundary at all, but I want something that works on all backends, so for now this will have to suffice. Any solution will at least need to communicate the shape of the ndarray back to python, since it's tracked in the block matrix type. ; - With this new method, I can now get many tests in `test_linalg.py` to run on the local / service backends. Most BM lowering was apparently untested before, so some bug fixes were necessary, including:; - Support requiredness analysis on BlockMatrix, even though the answer is always required. ; - Use `CompileAndEvaluate` rather than `Interpret` to evaluate the child node in `ValueToBlockMatrix`. ; - Casting between Int32 and Int64 in various places in lowering. Almost always the culprit was a bad interaction between ndarray shapes (which are Int64) and `StreamRange` argument (which is an Int32). This is sort of a pervasive ndarray problem that will need to be systematically addressed at some point. I don't anticipate anyone making a BlockMatrix with blocks big enough to blow 32 bits though. ; - Lots of fixes to the `BlockMatrixBroadcast` rule for getting diagonal of a BlockMatrix, as it was clearly never run. It had `MakeStream(StreamIR)` which was not allowed, it didn't update the context appropriately, and it used the wrong axis to determine if something was a row vector.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10447:504,test,tests,504,https://hail.is,https://github.com/hail-is/hail/pull/10447,1,['test'],['tests']
Testability,"In this particular case, it comes from `repartition` in RVD, the assertion that is failing is this one. ```scala; require(newPartitioner.satisfiesAllowedOverlap(newPartitioner.kType.size - 1)); ```; In this case `kType` is empty, so `kType.size` is 0.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8138#issuecomment-595460712:65,assert,assertion,65,https://hail.is,https://github.com/hail-is/hail/issues/8138#issuecomment-595460712,1,['assert'],['assertion']
Testability,"In trying to test this (from your branch, ran pip install on /hail/python just in case). ```sh; (hail) alex:~/projects/hail/hail/python:$ hailctl dev deploy -b cseed:batch-web -s deploy_auth,deploy_router,deploy_notebook2; Traceback (most recent call last):; File ""/miniconda3/envs/hail/bin/hailctl"", line 11, in <module>; sys.exit(main()); File ""/Users/alex/projects/hail/hail/python/hailtop/hailctl/__main__.py"", line 100, in main; cli.main(args); File ""/Users/alex/projects/hail/hail/python/hailtop/hailctl/dev/cli.py"", line 52, in main; cli.main(args); File ""/Users/alex/projects/hail/hail/python/hailtop/hailctl/dev/deploy/cli.py"", line 66, in main; loop.run_until_complete(submit(args)); File ""/miniconda3/envs/hail/lib/python3.6/asyncio/base_events.py"", line 484, in run_until_complete; return future.result(); File ""/Users/alex/projects/hail/hail/python/hailtop/hailctl/dev/deploy/cli.py"", line 57, in submit; batch_id = await ci_client.dev_deploy_branch(args.branch, steps); File ""/Users/alex/projects/hail/hail/python/hailtop/hailctl/dev/deploy/cli.py"", line 46, in dev_deploy_branch; self._deploy_config.url('ci', '/api/v1alpha/dev_deploy_branch'), json=data) as resp:; File ""/miniconda3/envs/hail/lib/python3.6/site-packages/aiohttp/client.py"", line 1005, in __aenter__; self._resp = await self._coro; File ""/miniconda3/envs/hail/lib/python3.6/site-packages/aiohttp/client.py"", line 581, in _request; resp.raise_for_status(); File ""/miniconda3/envs/hail/lib/python3.6/site-packages/aiohttp/client_reqrep.py"", line 942, in raise_for_status; headers=self.headers); aiohttp.client_exceptions.ClientResponseError: 500, message='Internal Server Error'; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7064#issuecomment-532037733:13,test,test,13,https://hail.is,https://github.com/hail-is/hail/pull/7064#issuecomment-532037733,1,['test'],['test']
Testability,"In(0,int32)),MakeStruct(WrappedArray((a,I32(1)), (b,ApplyBinaryPrimOp(Add(),Ref(x,int32),I32(2)))))))(is.hail.expr.ir.ForwardLetsSuite). Gradle suite > Gradle test > is.hail.expr.ir.ForwardLetsSuite.testForwardingOps[0](Let(x,ApplyBinaryPrimOp(Add(),In(0,int32),In(0,int32)),MakeStruct(WrappedArray((a,I32(1)), (b,ApplyBinaryPrimOp(Add(),Ref(x,int32),I32(2))))))) PASSED; Running test: Test method testForwardingOps[1](Let(x,ApplyBinaryPrimOp(Add(),In(0,int32),In(0,int32)),MakeTuple(WrappedArray(I32(1), ApplyBinaryPrimOp(Add(),Ref(x,int32),I32(2))))))(is.hail.expr.ir.ForwardLetsSuite). Gradle suite > Gradle test > is.hail.expr.ir.ForwardLetsSuite.testForwardingOps[1](Let(x,ApplyBinaryPrimOp(Add(),In(0,int32),In(0,int32)),MakeTuple(WrappedArray(I32(1), ApplyBinaryPrimOp(Add(),Ref(x,int32),I32(2)))))) PASSED; Running test: Test method testForwardingOps[2](Let(x,ApplyBinaryPrimOp(Add(),In(0,int32),In(0,int32)),If(True(),Ref(x,int32),I32(0))))(is.hail.expr.ir.ForwardLetsSuite). Gradle suite > Gradle test > is.hail.expr.ir.ForwardLetsSuite.testForwardingOps[2](Let(x,ApplyBinaryPrimOp(Add(),In(0,int32),In(0,int32)),If(True(),Ref(x,int32),I32(0)))) PASSED; Running test: Test method testForwardingOps[3](Let(x,ApplyBinaryPrimOp(Add(),In(0,int32),In(0,int32)),ApplyBinaryPrimOp(Add(),ApplyBinaryPrimOp(Add(),I32(2),Ref(x,int32)),I32(1))))(is.hail.expr.ir.ForwardLetsSuite). Gradle suite > Gradle test > is.hail.expr.ir.ForwardLetsSuite.testForwardingOps[3](Let(x,ApplyBinaryPrimOp(Add(),In(0,int32),In(0,int32)),ApplyBinaryPrimOp(Add(),ApplyBinaryPrimOp(Add(),I32(2),Ref(x,int32)),I32(1)))) PASSED; Running test: Test method testForwardingOps[4](Let(x,ApplyBinaryPrimOp(Add(),In(0,int32),In(0,int32)),ApplyUnaryPrimOp(Negate(),Ref(x,int32))))(is.hail.expr.ir.ForwardLetsSuite). Gradle suite > Gradle test > is.hail.expr.ir.ForwardLetsSuite.testForwardingOps[4](Let(x,ApplyBinaryPrimOp(Add(),In(0,int32),In(0,int32)),ApplyUnaryPrimOp(Negate(),Ref(x,int32)))) PASSED. BUILD SUCCESSFUL. Total time:",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6083#issuecomment-492893925:3596,test,test,3596,https://hail.is,https://github.com/hail-is/hail/pull/6083#issuecomment-492893925,1,['test'],['test']
Testability,Include NGINX logs in pod logs,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4428:14,log,logs,14,https://hail.is,https://github.com/hail-is/hail/pull/4428,2,['log'],['logs']
Testability,"Include the call-stack of the compiler when we emit assertions into generated code. This is useful for showing us the trace of the code that emitted a `.get` on `IEmitCode`, for example. To do this, add a `hailBuildConfiguration` enum {`release`|`debug`} into `build-info.properties`, parsed as `HAIL_BUILD_CONFIGURATION`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14372:52,assert,assertions,52,https://hail.is,https://github.com/hail-is/hail/pull/14372,1,['assert'],['assertions']
Testability,"Includes the logistic case of the SKAT algorithm. Changes include updates to the SKAT, SKATSuite, and SKATmodel Scala files including updating python tests and other documentation. . Another significant change in the code is that the tests in SKATSuite have been re-written to ensure less code is duplicated while also added in permutation and noise tests for the skat algorithm which are not apart of the CI testing.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2153:13,log,logistic,13,https://hail.is,https://github.com/hail-is/hail/pull/2153,5,"['log', 'test']","['logistic', 'testing', 'tests']"
Testability,"Includes:; - Type system in python that mirrors scala; - Annotation conversion system, and full support for all annotation objects in python; - query_variants and query_samples functions on VDS that return python objects; - implemented Variant, Genotype, etc as first class python objects and fully documented them; - tests for the above",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1297:318,test,tests,318,https://hail.is,https://github.com/hail-is/hail/pull/1297,1,['test'],['tests']
Testability,"Increase memory and cpu for test_hail_services_java to match java query tests. This contains tests of the shuffler IR, which runs the hail compiler, so it seems it should have the same resource limits as the other java query tests. #9401 is getting an out of memory error in `testShuffleIR`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9423:72,test,tests,72,https://hail.is,https://github.com/hail-is/hail/pull/9423,4,['test'],"['testShuffleIR', 'tests']"
Testability,Increase testing parallelism,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3620:9,test,testing,9,https://hail.is,https://github.com/hail-is/hail/pull/3620,1,['test'],['testing']
Testability,"Indeed in my streamify, forcing MakeArray to remain a MakeArray fixes the problem. Now to investigate why MakeStream is the wrong solution, and why the new streamify isn't handling this correctly. to be clear, this branch finds the MakeArray inside of the MakeTuple and generates a ToArray(MakeStream), which both seems not super wrong and redundant. But the fact that's it's a value issue, with an array reading garbage, also make it look like a requiredeness/ copy function issue (though this was previously tested)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8063#issuecomment-583813511:510,test,tested,510,https://hail.is,https://github.com/hail-is/hail/pull/8063#issuecomment-583813511,2,['test'],['tested']
Testability,"Indeed, the Grammian still fails on the Kyle's 20k genomes after filtering to Purcell 5k, whereas BlockMatrix succeeds in 8 minutes on 385 cores. Using 1.6K genomes with 100k variants, timing is 2min with Grammian and 4 minutes with BlockMatrix. I'm going to close this PR until I've done more testing on the tradeoff. We should keep BlockMatrix as master, but there should be an N under which we use Grammian. These experiments are relevant to LMM too.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/801#issuecomment-249927850:294,test,testing,294,https://hail.is,https://github.com/hail-is/hail/pull/801#issuecomment-249927850,1,['test'],['testing']
Testability,Indeed:. > 17 | build_hail | Complete | Success 🎉 (0) | 4 minutes | log. Nice work! I'll read over in more detail soon.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6248#issuecomment-498797460:68,log,log,68,https://hail.is,https://github.com/hail-is/hail/pull/6248#issuecomment-498797460,1,['log'],['log']
Testability,IndexSuite.testEmptyKeys FAILED; java.lang.AssertionError at IndexSuite.scala:42; Running test: Test method testIntervalIterator(is.hail.io.IndexSuite). Gradle suite > Gradle test > is.hail.io.IndexSuite.testIntervalIterator FAILED; java.lang.AssertionError at IndexSuite.scala:42; Running test: Test method testIntervalIteratorWorksWithGeneralEndpoints(is.hail.io.IndexSuite). Gradle suite > Gradle test > is.hail.io.IndexSuite.testIntervalIteratorWorksWithGeneralEndpoints FAILED; java.lang.AssertionError at IndexSuite.scala:42; Running test: Test method testIterateFromUntil(is.hail.io.IndexSuite). Gradle suite > Gradle test > is.hail.io.IndexSuite.testIterateFromUntil FAILED; java.lang.AssertionError at IndexSuite.scala:42; Running test: Test method testLowerBound(is.hail.io.IndexSuite). Gradle suite > Gradle test > is.hail.io.IndexSuite.testLowerBound FAILED; java.lang.AssertionError at IndexSuite.scala:42; Running test: Test method testQueryByKey(is.hail.io.IndexSuite). Gradle suite > Gradle test > is.hail.io.IndexSuite.testQueryByKey FAILED; java.lang.AssertionError at IndexSuite.scala:42; Running test: Test method testRangeIterator(is.hail.io.IndexSuite). Gradle suite > Gradle test > is.hail.io.IndexSuite.testRangeIterator FAILED; java.lang.AssertionError at IndexSuite.scala:42; Running test: Test method testUpperBound(is.hail.io.IndexSuite). Gradle suite > Gradle test > is.hail.io.IndexSuite.testUpperBound FAILED; java.lang.AssertionError at IndexSuite.scala:42; Running test: Test method writeReadGivesSameAsInput[0]([Ljava.lang.String;@49613eb0)(is.hail.io.IndexSuite). Gradle suite > Gradle test > is.hail.io.IndexSuite.writeReadGivesSameAsInput[0]([Ljava.lang.String;@49613eb0) FAILED; java.lang.AssertionError at IndexSuite.scala:42; Running test: Test method writeReadGivesSameAsInput[1]([Ljava.lang.String;@326709be)(is.hail.io.IndexSuite). Gradle suite > Gradle test > is.hail.io.IndexSuite.writeReadGivesSameAsInput[1]([Ljava.lang.String;@326709be) FAILED; java.lan,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4718:1922,test,test,1922,https://hail.is,https://github.com/hail-is/hail/issues/4718,1,['test'],['test']
Testability,"Indexing a table by a non-unique matrixtable field was broken (only joined with one row per distinct value). For example, in the test I added, `m4.filter_cols(hl.is_defined(m4.idx)).count_cols()` previously returned 1, now returns 9.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3716:129,test,test,129,https://hail.is,https://github.com/hail-is/hail/pull/3716,1,['test'],['test']
Testability,"Information below. It isn't totally clear what to do here. I think the k8s refresh loop should probably restart pods (mark_unscheduled) that have been scheduled but aren't running after a timeout (few mins). ```; $ kubectl -n batch-pods describe pods batch-3-job-41-39d17b; Name: batch-3-job-41-39d17b; Namespace: batch-pods; Priority: 500000; PriorityClassName: user; Node: gke-vdc-preemptible-pool-9c7148b2-1f89/10.128.0.101; Start Time: Fri, 12 Jul 2019 13:17:15 -0400; Labels: app=batch-job; batch_id=3; hail.is/batch-instance=cd50b95a89914efb897965a5e982a29d; job_id=41; task=main; user=ci; uuid=f53f127847864f1cbf7d4bdc911a6646; Annotations: <none>; Status: Pending; IP: ; Containers:; main:; Container ID: ; Image: gcr.io/hail-vdc/ci-intermediate:oyyg6y2um4kx; Image ID: ; Port: <none>; Host Port: <none>; Command:; bash; -c; set -e; gcloud -q auth activate-service-account --key-file=/test-gsa-key/privateKeyData; gsutil -m cp -r /test/resources/* gs://hail-test-1c9nm/sj0nb47zqys1/pipeline/input/; State: Waiting; Reason: ContainerCreating; Ready: False; Restart Count: 0; Requests:; cpu: 100m; memory: 500M; Environment:; POD_IP: (v1:status.podIP); POD_NAME: batch-3-job-41-39d17b (v1:metadata.name); Mounts:; /gsa-key from gsa-key (rw); /test-gsa-key from test-gsa-key (rw); /var/run/secrets/kubernetes.io/serviceaccount from default-token-8h99c (ro); Conditions:; Type Status; Initialized True ; Ready False ; ContainersReady False ; PodScheduled True ; Volumes:; test-gsa-key:; Type: Secret (a volume populated by a Secret); SecretName: test-gsa-key; Optional: false; gsa-key:; Type: Secret (a volume populated by a Secret); SecretName: ci-gsa-key; Optional: false; default-token-8h99c:; Type: Secret (a volume populated by a Secret); SecretName: default-token-8h99c; Optional: false; QoS Class: Burstable; Node-Selectors: <none>; Tolerations: node.kubernetes.io/not-ready:NoExecute for 300s; node.kubernetes.io/unreachable:NoExecute for 300s; preemptible=true; Events:; Type Reason Age F",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6625:893,test,test-gsa-key,893,https://hail.is,https://github.com/hail-is/hail/issues/6625,3,['test'],"['test', 'test-', 'test-gsa-key']"
Testability,"Initial version of python interface. Still need to:. - document python interface (working with @jigold about the best way to do that); - add tests run through gradle. The interface mostly wraps commands. The main difference is that python has first class VDS objects, so the environment isn't necessary. Therefore, I had to restructure commands that take VDS names as arguments. It can be run like this:. ```; $ gradle shadowJar; $ PYTHONPATH=/path/to/hail/python SPARK_CLASSPATH=/path/to/hail/build/libs/hail-all-spark.jar pyspark; ```. Here's a simple example:. ```; >>> from pyhail import *; >>> hc = HailContext(sc) # create Hail context; >>> vds = hc.import_vcf('/Users/cseed/sample.vcf', n_partitions = 8); >>> vds.count(); {u'nSample': 100, u'nVariants': 346L, u'nGenotypes': 34600L}; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1061:141,test,tests,141,https://hail.is,https://github.com/hail-is/hail/pull/1061,1,['test'],['tests']
Testability,Instead of building variant map (which is actually broken because variants are not necessarily unique!); Move MT.variants to test code. This eliminates another use of MT.rdd.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2712:125,test,test,125,https://hail.is,https://github.com/hail-is/hail/pull/2712,1,['test'],['test']
Testability,"Instead of using `gsutil` we use hailtop.aiotools.copy from the new `HAILGENETICS_HAIL_IMAGE`. Previously, deploying the pip-versioned image was a manual asynchronous step that mostly happened in response to user requests. 1. Actually build and test hailgenetics/hail and hailgenetics/genetics on every build.; 2. On deploy, push the newly built hailgenetics/hail and hailgenetics/genetics images to both docker hub and gcr.io/hail-vdc/; 3. Provide the built-for-this-PR hailgenetics/hail as an env var to the tests.; 4. By default use the hailgenetics/hail image for the currently published pip version for FS operations. Allow overriding by environment variable.; 5. Remove now unnecessary publish-public-images.sh.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11091:245,test,test,245,https://hail.is,https://github.com/hail-is/hail/pull/11091,2,['test'],"['test', 'tests']"
Testability,"Instead of using a fixed weighting, query the GCP /regions endpoint which includes the quota limit and usage. Use this to weight zones for new instance requests. Added a ComputeClient.list endpoint that should work with any GCE list endpoint that is paged. I'm working on improving this logic further by tracking how often instance create requests fail and then weighting zones by `capacity * p(create instance will succeed)`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9316:287,log,logic,287,https://hail.is,https://github.com/hail-is/hail/pull/9316,1,['log'],['logic']
Testability,Instead print summary. I am tired of scrolling past the 5k-field table output in the CI test logs.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7799:88,test,test,88,https://hail.is,https://github.com/hail-is/hail/pull/7799,2,"['log', 'test']","['logs', 'test']"
Testability,"Intention is two-fold:. - get ready to move the k8s cluster from broad-ctsa to hail-vdc; - automate as much of our infrastructure build out as possible. Ultimately, changing GCP or k8s infrastructure should involve pushing to something like vdc/. We should regularly test rebuild from scratch. Outline of changes:. - added a new project directory, vdc/; - parameterize projects by GCP project for GCR, set from gcloud project config; - parameterize site by domain name and IP address; - GCP resources are deployed using the Google Deployment Manager; - added a MySQL 5.6 instance (to be used by upload, others); - ugprades gke to latest version. Doesn't handle CI yet. I think we need a setting for CI where it runs the tests and tracks its internal state but doesn't do anything on Github.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4545:267,test,test,267,https://hail.is,https://github.com/hail-is/hail/pull/4545,2,['test'],"['test', 'tests']"
Testability,"Interesting to see the benchmarks, thanks. I didn't realize there were any per-variant usages, I figured these were per-RDD. That makes me more okay with the original, but it's completely up to you. On a side note, I can't wait until we can work in C++, where using library facilities to simplify code isn't such a performance hit!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3094#issuecomment-372723395:23,benchmark,benchmarks,23,https://hail.is,https://github.com/hail-is/hail/pull/3094#issuecomment-372723395,2,['benchmark'],['benchmarks']
Testability,"Interesting, looks like I broke the same two tests on GCP and Azure. I'll dig into that tomorrow.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11638#issuecomment-1074467906:45,test,tests,45,https://hail.is,https://github.com/hail-is/hail/pull/11638#issuecomment-1074467906,1,['test'],['tests']
Testability,"Interesting. When I was helping Sophie earlier, I was able to see them for workers in her namespace???; https://console.cloud.google.com/logs/query;query=resource.type%3D%22gce_instance%22%0AlogName:%22syslog%22%0Alabels.%22compute.googleapis.com%2Fresource_name%22:%22batch-worker-parsa-job-private-39d9d%22;summaryFields=:false:32:beginning;cursorTimestamp=2023-08-27T13:45:49Z;duration=P2D?project=hail-vdc",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13509#issuecomment-1696119375:137,log,logs,137,https://hail.is,https://github.com/hail-is/hail/pull/13509#issuecomment-1696119375,1,['log'],['logs']
Testability,Interestingly I was have a consistent test failure here but never got the chance to diagnose it. Would like to come back to it once the glut of PRs is through. Would you rather keep it open or closed?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11931#issuecomment-1266120559:38,test,test,38,https://hail.is,https://github.com/hail-is/hail/pull/11931#issuecomment-1266120559,1,['test'],['test']
Testability,"Introduce FASTAReaderConfig to act as a kind of factory for FASTAReader,; while all FASTAReaders themselves are confined to ThreadLocals (except; in tests). Furthermore, add a lock around the fasta file map to prevent more than; one fasta from being copied per jvm. The can be lock contention on the; map, but if there is large amounts of waiting for said lock, then it; usually means that a fasta is downloading and we definitely should be; waiting.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9435:149,test,tests,149,https://hail.is,https://github.com/hail-is/hail/pull/9435,1,['test'],['tests']
Testability,"Investigate whether possible to invert menu inclusion, such that each project injects its own menu alongside a common menu section (e.g login).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7276:136,log,login,136,https://hail.is,https://github.com/hail-is/hail/issues/7276,1,['log'],['login']
Testability,Invoker.invokeMethod(Invoker.java:696); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:882); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1189); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:767); 	at org.testng.TestRunner.run(TestRunner.java:617); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:348); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:343); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:305); 	at org.testng.SuiteRunner.run(SuiteRunner.java:254); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1224); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1149); 	at org.testng.TestNG.run(TestNG.java:1057); 	at org.testng.IDEARemoteTestNG.run(IDEARemoteTestNG.java:72); 	at org.testng.RemoteTestNGStarter.main(RemoteTestNGStarter.java:123); Caused by: java.lang.ArrayIndexOutOfBoundsException: 3; 	at scala.collection.mutable.WrappedArray$ofRef.apply(WrappedArray.scala:127); 	at is.hail.expr.ir.OrderingSuite$$anonfun$33$$anonfun$apply$19.getKey$1(OrderingSuite.scala:345); 	at is.hail.expr.ir.OrderingSuite$$anonfun$33$$anonfun$apply$19.apply(OrderingSuite.scala:347); 	at is.hail.expr.ir.OrderingSuite$$anonfun$33$$anonfun$apply$19.apply(OrderingSuite.scala:318); 	at is.hail.utils.package$.using(package.scala:613); 	at is.hail.annotations.Region$.scoped(Region.scala:13); 	at is.hail.expr.ir.OrderingSuite$$anonfun$33.apply(OrderingSuite.scala:318); 	at is.hail.expr.ir.OrderingSuite$$anonfun$33.apply(OrderingSuite.scala:314); 	at is.hail.check.GenProp1$$anonfun$apply$1$$anonfun$1.apply$mcZ$sp(Prop.scala:28); 	at is.hail.check.GenProp1$$anonfun$apply$1$$anonfun$1.apply(Prop.scala:28); 	at is.hail.check.GenProp,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5630:1995,test,testng,1995,https://hail.is,https://github.com/hail-is/hail/issues/5630,1,['test'],['testng']
Testability,Invoker.invokeMethod(Invoker.java:696); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:882); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1189); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:767); 	at org.testng.TestRunner.run(TestRunner.java:617); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:348); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:343); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:305); 	at org.testng.SuiteRunner.run(SuiteRunner.java:254); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1224); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1149); 	at org.testng.TestNG.run(TestNG.java:1057); 	at org.testng.TestNG.privateMain(TestNG.java:1364); 	at org.testng.TestNG.main(TestNG.java:1333); 	Suppressed: is.hail.relocated.com.google.cloud.storage.StorageException: Unable to recover in upload.; This may be a symptom of multiple clients uploading to the same upload session. For debugging purposes:; uploadId: https://storage.googleapis.com/upload/storage/v1/b/hail-test-ezlis/o?name=fs-suite-tmp-2LzGioRNy6RqIS2pfXIoSO&uploadType=resumable&upload_id=ADPycdvZ5HhnGfOKt5TE1qXWiHpqIpZnXVTYWuWUCXNPRF9HqyCB-4LvRsxNX6SUWRgk13pYrzYaa9-wXlvNZt1oct0ptaEz0bS3; chunkOffset: 16777216; chunkLength: 16777216; localOffset: 268435456; remoteOffset: 285212672; lastChunk: false. 		at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.unrecoverableState(BlobWriteChannel.java:131); 		at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.unrecoverableState(BlobWriteChannel.java:87); 		at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.access$1000(BlobWriteChannel.java:35); 		at is.hai,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12950#issuecomment-1704346911:4919,test,testng,4919,https://hail.is,https://github.com/hail-is/hail/issues/12950#issuecomment-1704346911,1,['test'],['testng']
Testability,Invoker.invokeMethod(Invoker.java:696); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:882); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1189); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:767); 	at org.testng.TestRunner.run(TestRunner.java:617); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:348); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:343); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:305); 	at org.testng.SuiteRunner.run(SuiteRunner.java:254); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1224); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1149); 	at org.testng.TestNG.run(TestNG.java:1057); 	at org.testng.TestNG.privateMain(TestNG.java:1364); 	at org.testng.TestNG.main(TestNG.java:1333); 	Suppressed: is.hail.relocated.com.google.cloud.storage.StorageException: Unable to recover in upload.; This may be a symptom of multiple clients uploading to the same upload session. For debugging purposes:; uploadId: https://storage.googleapis.com/upload/storage/v1/b/hail-test-ezlis/o?name=fs-suite-tmp-6BO4gZ18Lheigp3ir9RSOh&uploadType=resumable&upload_id=ADPycduiXx2Jtiy_0Ll131_pPeEYKnnA23Hlk28_9TFESUMaubA9OqLK_n8Td5rPhTXnlpssGo796Q4bJxUeblhmSaYcCSWAMg2k; chunkOffset: 16777216; chunkLength: 16777216; localOffset: 1325400064; remoteOffset: 1342177280; lastChunk: false. 		at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.unrecoverableState(BlobWriteChannel.java:131); 		at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.unrecoverableState(BlobWriteChannel.java:87); 		at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.access$1000(BlobWriteChannel.java:35); 		at is.h,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12950#issuecomment-1544209756:4726,test,testng,4726,https://hail.is,https://github.com/hail-is/hail/issues/12950#issuecomment-1544209756,2,['test'],['testng']
Testability,Is the attached log file correct? It is for a job that never got assigned cores on the cluster. I don't see anything about NoClassDefFoundError in it.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/303#issuecomment-211167105:16,log,log,16,https://hail.is,https://github.com/hail-is/hail/issues/303#issuecomment-211167105,1,['log'],['log']
Testability,Is there a benchmark test for this?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4516#issuecomment-613456757:11,benchmark,benchmark,11,https://hail.is,https://github.com/hail-is/hail/issues/4516#issuecomment-613456757,2,"['benchmark', 'test']","['benchmark', 'test']"
Testability,Is there a better way to communicate the Query logging bug and its fix?,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12853:47,log,logging,47,https://hail.is,https://github.com/hail-is/hail/pull/12853,1,['log'],['logging']
Testability,Is there a test for this?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7342#issuecomment-547016313:11,test,test,11,https://hail.is,https://github.com/hail-is/hail/pull/7342#issuecomment-547016313,1,['test'],['test']
Testability,"Is there a test of VariantQC on multi-allelics? You say it's an out-of-date requirement but I'm confused how this works. We match gt to 0, 1, 2 in the VariantQCCombiner.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2422#issuecomment-343950744:11,test,test,11,https://hail.is,https://github.com/hail-is/hail/pull/2422#issuecomment-343950744,1,['test'],['test']
Testability,Is there a test that catches this?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10111#issuecomment-786693540:11,test,test,11,https://hail.is,https://github.com/hail-is/hail/pull/10111#issuecomment-786693540,1,['test'],['test']
Testability,Is there a way for me to test this further? My experiments show that clone+merge is ~20 seconds but download from GCS is ~3s. This should seed up the feedback substantially for anyone working on an image that transitively depends on other images.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7534:25,test,test,25,https://hail.is,https://github.com/hail-is/hail/pull/7534,1,['test'],['test']
Testability,"Is there an easy way for me to write a test that's just ""Run some `Code[_] block and check what it returns""?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7587#issuecomment-560221403:39,test,test,39,https://hail.is,https://github.com/hail-is/hail/pull/7587#issuecomment-560221403,1,['test'],['test']
Testability,Is there an option to build an test assembly jar? I want to be able to run the Scala tests with just a assembly test jar.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5906#issuecomment-484622404:31,test,test,31,https://hail.is,https://github.com/hail-is/hail/pull/5906#issuecomment-484622404,3,['test'],"['test', 'tests']"
Testability,Is this working and ready for review? This would unlock quite a few more failing tests.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11450#issuecomment-1072685898:81,test,tests,81,https://hail.is,https://github.com/hail-is/hail/pull/11450#issuecomment-1072685898,1,['test'],['tests']
Testability,"Issue came up on doctest branch. Reproducible example:; ```; assoc_vds = hc.import_vcf('src/test/resources/sample.vcf'); .split_multi(); .variant_qc(); .annotate_samples_expr('sa.culprit = gs.filter(g => v == Variant(""20"", 13753124, ""A"", ""C"")).map(g => g.gt).collect()[0]'); .annotate_samples_expr('sa.pheno = rnorm(1,1) * sa.culprit'); .annotate_samples_expr('sa.cov1 = rnorm(0,1)'); .annotate_samples_expr('sa.cov2 = rnorm(0,1)'); .linreg('sa.pheno', ['sa.cov1', 'sa.cov2']).annotate_variants_expr('va.useInKinship = va.qc.AF > 0.05'). kinship_vds = assoc_vds.filter_variants_expr('va.useInKinship'); lmm_vds = assoc_vds.lmmreg(kinship_vds, 'sa.pheno', ['sa.cov1', 'sa.cov2']). lmm_vds.globals; ```. Error message:; ```; Failed example:; lmm_vds.globals; Exception raised:; Traceback (most recent call last):; File ""//anaconda/lib/python2.7/doctest.py"", line 1315, in __run; compileflags, 1) in test.globs; File ""<doctest default[1]>"", line 1, in <module>; lmm_vds.globals; File ""/Users/jigold/hail/python/hail/dataset.py"", line 1958, in globals; self._globals = self.global_schema._convert_to_py(self._jvds.globalAnnotation()); File ""/Users/jigold/hail/python/hail/type.py"", line 423, in _convert_to_py; d[f.name] = f.typ._convert_to_py(annotation.get(i)); File ""/Users/jigold/hail/python/hail/type.py"", line 423, in _convert_to_py; d[f.name] = f.typ._convert_to_py(annotation.get(i)); File ""/Users/jigold/hail/python/hail/type.py"", line 243, in _convert_to_py; lst = env.jutils.iterableToArrayList(annotation); File ""/Users/jigold/spark-2.0.2-bin-hadoop2.7/python/lib/py4j-0.10.3-src.zip/py4j/java_gateway.py"", line 1133, in __call__; answer, self.gateway_client, self.target_id, self.name); File ""/Users/jigold/spark-2.0.2-bin-hadoop2.7/python/pyspark/sql/utils.py"", line 63, in deco; return f(*a, **kw); File ""/Users/jigold/spark-2.0.2-bin-hadoop2.7/python/lib/py4j-0.10.3-src.zip/py4j/protocol.py"", line 323, in get_return_value; format(target_id, ""."", name, value)); Py4JError: An error occurr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1368:92,test,test,92,https://hail.is,https://github.com/hail-is/hail/issues/1368,2,['test'],['test']
Testability,"It also fails on this simpler example:; ```; In [1]: import hail as hl ; ...: ; ...: temp = hl.utils.range_table(100) ; ...: temp.write('gs://danking/workshop-test/1kg.mt', overwrite=True) ; Initializing Hail with default parameters...; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.61-c548354b6e81; LOGGING: writing to /Users/dking/projects/hail/hail-20210107-1038-0.2.61-c548354b6e81.log; Traceback (most recent call last):; File ""<ipython-input-1-a2e56feaf799>"", line 4, in <module>; temp.write('gs://danking/workshop-test/1kg.mt', overwrite=True); File ""</Users/dking/miniconda3/lib/python3.7/site-packages/decorator.py:decorator-gen-1092>"", line 2, in write; File ""/Users/dking/projects/hail/hail/python/hail/typecheck/check.py"", line 577, in wrapper; return __original_func(*args_, **kwargs_); File ""/Users/dking/projects/hail/hail/python/hail/table.py"", line 1271, in write; Env.backend().execute(ir.TableWrite(self._tir, ir.TableNativeWriter(output, overwrite, stage_locally, _codec_spec))); File ""/Users/dking/projects/hail/hail/python/hail/backend/service_backend.py"", line 103, in execute; bucket=self._bucket); File ""/Users/dking/projects/hail/hail/python/hail/backend/service_backend.py"", line 48, in request; return async_to_blocking(retry_transient_errors(self.async_request, endpoint, **data)); File ""/Users/dking/projects/hail/hail/python/hailtop/utils/utils.py"", line 114, in async_to_blocking; return asyncio.get_event_loop().run_until_complete(coro); File ""/Users/dking/miniconda3/lib/python3.7/asyncio/base_events.py"", line 587, in run_until_complete; return future.result(); File ""/Users/dking/projects/hail/hail/python/hailtop/utils/utils.py"", line 379, in retry_transient_errors; return await f(*args, **kwargs); File ""/Users/dking/projects/hail/hail/python/hail/backend/service_backend.py"", line 44, in async_request; raise FatalError(f'Error from server: {result[""value""]}'); FatalError: Error from server: java.util.NoSuchElementExce",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9856#issuecomment-756194693:159,test,test,159,https://hail.is,https://github.com/hail-is/hail/issues/9856#issuecomment-756194693,7,"['LOG', 'log', 'test']","['LOGGING', 'log', 'test']"
Testability,"It also fixes numeric promotion of TInt to TLong, which threw an; assertion error before.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/748:66,assert,assertion,66,https://hail.is,https://github.com/hail-is/hail/pull/748,2,['assert'],['assertion']
Testability,"It appears that the repository creation succeeded, the response to that REST call was a successful looking JSON object (which indicates a create repository with the expected name, `REPO_NAME=ci-test-p4a9fxo7`) [1]. It is unclear if repository deletion succeeded [2], I should find a way to make curl print the HTTP status code returned by cluster deletion. FWIW, the repository appears to be deleted now (https://github.com/hail-ci-test/ci-test-p4a9fxo7), and, AFAIK, no other part of our system deletes these repositories. [1]:; ```; {; ""id"": 152339517,; ""node_id"": ""MDEwOlJlcG9zaXRvcnkxNTIzMzk1MTc="",; ""name"": ""ci-test-p4a9fxo7"",; ""full_name"": ""hail-ci-test/ci-test-p4a9fxo7"",; ""private"": false,; ""owner"": {; ""login"": ""hail-ci-test"",; ""id"": 43152710,; ""node_id"": ""MDEyOk9yZ2FuaXphdGlvbjQzMTUyNzEw"",; ""avatar_url"": ""https://avatars1.githubusercontent.com/u/43152710?v=4"",; ""gravatar_id"": """",; ""url"": ""https://api.github.com/users/hail-ci-test"",; ""html_url"": ""https://github.com/hail-ci-test"",; ""followers_url"": ""https://api.github.com/users/hail-ci-test/followers"",; ""following_url"": ""https://api.github.com/users/hail-ci-test/following{/other_user}"",; ""gists_url"": ""https://api.github.com/users/hail-ci-test/gists{/gist_id}"",; ""starred_url"": ""https://api.github.com/users/hail-ci-test/starred{/owner}{/repo}"",; ""subscriptions_url"": ""https://api.github.com/users/hail-ci-test/subscriptions"",; ""organizations_url"": ""https://api.github.com/users/hail-ci-test/orgs"",; ""repos_url"": ""https://api.github.com/users/hail-ci-test/repos"",; ""events_url"": ""https://api.github.com/users/hail-ci-test/events{/privacy}"",; ""received_events_url"": ""https://api.github.com/users/hail-ci-test/received_events"",; ""type"": ""Organization"",; ""site_admin"": false; },; ""html_url"": ""https://github.com/hail-ci-test/ci-test-p4a9fxo7"",; ""description"": null,; ""fork"": false,; ""url"": ""https://api.github.com/repos/hail-ci-test/ci-test-p4a9fxo7"",; ""forks_url"": ""https://api.github.com/repos/hail-ci-test/ci-test-p4a9fxo7/forks"",; ""k",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4517#issuecomment-429024858:1342,test,test,1342,https://hail.is,https://github.com/hail-is/hail/issues/4517#issuecomment-429024858,1,['test'],['test']
Testability,"It definitely looks like ""ZONE_RESOURCE_POOL_EXHAUSTED"" is the cause of these GPU test failures. In this case it looks like it took ~4 minutes to successfully get a VM (after two exhaustion errors) & schedule the job. By then, our uniform 6 minute timeout per test left us with just two minutes. It looks like the job actually did succeed in the worker (seems to have taken ~2 minutes, seems long, does testing for CUDA do some kind of initialization work?). Looks like backing that off to 10 minutes might be just enough to eventually get us a GPU. Might be worth pulling that into its own build.yaml test job so that it does not block the queue of other tests.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13739:82,test,test,82,https://hail.is,https://github.com/hail-is/hail/pull/13739,5,['test'],"['test', 'testing', 'tests']"
Testability,"It didn't fail, it failed IR conversion. I don't have an automated strategy to test if something is going through the IR or not. In this case, I verified it works by checking the log for the Fraction IR.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3610#issuecomment-389733708:79,test,test,79,https://hail.is,https://github.com/hail-is/hail/pull/3610#issuecomment-389733708,2,"['log', 'test']","['log', 'test']"
Testability,It does though. That assertion returns true.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5435#issuecomment-467649154:21,assert,assertion,21,https://hail.is,https://github.com/hail-is/hail/pull/5435#issuecomment-467649154,1,['assert'],['assertion']
Testability,It doesn't make sense to be able to delete or cancel an individual job since they must be part of a batch now. I also deleted `list_jobs` since a job must be a part of a batch. I left in `job.wait()` because I felt the tests in `test_dag` were important and shouldn't be deleted and the wait functionality is needed for there not to be race conditions.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6023:219,test,tests,219,https://hail.is,https://github.com/hail-is/hail/pull/6023,1,['test'],['tests']
Testability,"It doesn't seem like headless mode is in effect, at least in the most recent published image. Will grab this and play around with it. Tested Dan's image in app.hail.is, seems to work, except for all of the .js/.css resources; first guess is SSL, but it's clearly a diff issue. I can't connect to your workers, can to his. Will update in a bit. Yours:; (notebook) alexkotlar:~/projects/hail-clone/notebook-api:$ k logs notebook-worker-5xq2w -f; [I 21:29:01.483 NotebookApp] Writing notebook server cookie secret to /home/jovian/.local/share/jupyter/runtime/notebook_cookie_secret; [I 21:29:03.742 NotebookApp] Serving notebooks from local directory: /home/jovian; [I 21:29:03.743 NotebookApp] The Jupyter Notebook is running at:; [I 21:29:03.743 NotebookApp] http://localhost:8888/instance/notebook-worker-service-qzppk/?token=...; [I 21:29:03.743 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).; [W 21:29:03.750 NotebookApp] No web browser found: could not locate runnable browser. Dan’s; [I 21:44:38.439 NotebookApp] Writing notebook server cookie secret to /home/jovyan/.local/share/jupyter/runtime/notebook_cookie_secret; [I 21:44:38.808 NotebookApp] [jupyter_nbextensions_configurator] enabled 0.4.1; [I 21:44:38.898 NotebookApp] Jupyter-Spark enabled!; [I 21:44:38.942 NotebookApp] JupyterLab extension loaded from /opt/conda/lib/python3.6/site-packages/jupyterlab; [I 21:44:38.942 NotebookApp] JupyterLab application directory is /opt/conda/share/jupyter/lab; [I 21:44:38.945 NotebookApp] Serving notebooks from local directory: /home/jovyan; [I 21:44:38.945 NotebookApp] The Jupyter Notebook is running at:; [I 21:44:38.946 NotebookApp] http://(notebook-worker-v7fr4 or 127.0.0.1):8888/instance/notebook-worker-service-sv5jl/?token=...; [I 21:44:38.946 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).; [I 21:44:55.324 NotebookApp] 302 GET /instance/notebook-worker-service-sv5jl/?acce",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5243#issuecomment-460092942:134,Test,Tested,134,https://hail.is,https://github.com/hail-is/hail/pull/5243#issuecomment-460092942,3,"['Test', 'log']","['Tested', 'logs']"
Testability,"It got removed temporarily moving to the new CI because the existing code couldn't handle the tests being in a jar. However, if the data providers do fail, the test will be skipped, which actually translated to a non-zero (2) exit code from testng. So in fact this case will fail in the tests.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6079:94,test,tests,94,https://hail.is,https://github.com/hail-is/hail/issues/6079,4,['test'],"['test', 'testng', 'tests']"
Testability,"It is able to execute a trivial pipeline without the JVM on the client. The countdown down to a fully functional Hail Query service begins now. I will start running the Python tests against the service to benchmark our progress. The main blockers are:; - Table lowering @tpoterba @patrick-schultz @catoverdrive ; - The shuffle service @tpoterba @danking ; - Reading, writing and threading the (per-user, for the query service) filesystem through execution. I'll be working on this.; - A Batch backend for distributed execution. I will do this once there is enough functionality to execute something big/interesting. It's happening!",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8468:176,test,tests,176,https://hail.is,https://github.com/hail-is/hail/pull/8468,2,"['benchmark', 'test']","['benchmark', 'tests']"
Testability,It is also just supremely annoying when one of these tests gets preempted 40 minutes in.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13004#issuecomment-1539017933:53,test,tests,53,https://hail.is,https://github.com/hail-is/hail/pull/13004#issuecomment-1539017933,1,['test'],['tests']
Testability,It is currently possible to write a blocked index where the virtual file; offset is exactly ((REAL_FILE_OFFSET << 16) | BLOCK_SIZE). This is a bug; and leads to assertion errors when trying to seek to the appropriate row; because `off == end` for that index.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6633:161,assert,assertion,161,https://hail.is,https://github.com/hail-is/hail/pull/6633,1,['assert'],['assertion']
Testability,"It is mighty fishy that both azure and google failed the callback test. What are we missing? If MJC returns, then the database was clearly updated. Subsequent DB queries should see those changes. total_jobs_in_batch won't change during the lifetime of the batch, so that should be correct (though we should probably LOCK IN SHARE MODE anyway). Assuming I'm reading the [reference manual](https://dev.mysql.com/doc/refman/5.7/en/innodb-consistent-read.html) correctly, that select should see the result of the UPDATE *or a later state*. The updates to a single row are serial. So there must exist a transaction that takes it from n_jobs-1 to n_jobs. That transaction thus must see n_jobs for new_n_completed. That transaction thus ought to update batches. Once that transaction is committed the subsequent query for notification should see the changes...",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11352#issuecomment-1040809121:66,test,test,66,https://hail.is,https://github.com/hail-is/hail/pull/11352#issuecomment-1040809121,2,['test'],['test']
Testability,"It is possible for socket connect to fail if the shuffle service is down (e.g. https://ci.hail.is/batches/91027/jobs/105).; This change ensure we retry forever, periodically logging that we are retrying",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9378:174,log,logging,174,https://hail.is,https://github.com/hail-is/hail/pull/9378,1,['log'],['logging']
Testability,"It looks like batch test was an infinite loop for: https://github.com/hail-is/hail/pull/4536. So I bumped off the pod running the test (this was maybe bad behavior on my part, but I was also curious how ci/batch would respond):. ```; $ kubectl delete pod job-17-lz6m5; ```. I thought CI would re-run the test, but it got merged!. Output did get uploaded, here it is: https://storage.googleapis.com/hail-ci-0-1/ci/ee92f64477f68737987fd8f21411b0348a3d3420/e4ae86ea520fbc5d98b84811b2cdb83640163910/index.html. In particular the job log consists of:. ```; failed to get container status {"""" """"}: rpc error: code = OutOfRange desc = EOF; ```. I had a `logs -f` running when I did this, so here is the log up to the failure:. [job-17-lz6m5.log](https://github.com/hail-is/hail/files/2474367/job-17-lz6m5.log)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4541:20,test,test,20,https://hail.is,https://github.com/hail-is/hail/issues/4541,8,"['log', 'test']","['log', 'logs', 'test']"
Testability,It looks like it's passing all the tests except the new test @chrisvittal added yesterday for testing skat on the cluster.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5512#issuecomment-472909343:35,test,tests,35,https://hail.is,https://github.com/hail-is/hail/pull/5512#issuecomment-472909343,3,['test'],"['test', 'testing', 'tests']"
Testability,It looks like my cache change is passing tests now. I'd like for you to take a look before I confirm one last time that the cache is actually working by submitting jobs downloading a 512 MB file and making sure the timings of the non-first job is a couple of seconds. It looks like the tests got a bit slower. I'm not sure if that's because of the docker image having gsutil in it. I don't see how the extra copying infrastructure would make a huge difference.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9095#issuecomment-660178082:41,test,tests,41,https://hail.is,https://github.com/hail-is/hail/pull/9095#issuecomment-660178082,2,['test'],['tests']
Testability,It looks like the batch tests failed unrelated to this. You'll need to bump it.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6925#issuecomment-524130051:24,test,tests,24,https://hail.is,https://github.com/hail-is/hail/pull/6925#issuecomment-524130051,1,['test'],['tests']
Testability,It looks like the tests are close to passing!,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11055#issuecomment-965091556:18,test,tests,18,https://hail.is,https://github.com/hail-is/hail/pull/11055#issuecomment-965091556,1,['test'],['tests']
Testability,It looks like there's a few tests whose expected values are using the old dtypes.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12218#issuecomment-1258155599:28,test,tests,28,https://hail.is,https://github.com/hail-is/hail/pull/12218#issuecomment-1258155599,1,['test'],['tests']
Testability,"It looks like this test just needed to be modified:. ```; def test_reference_genome_sequence(self):; gr3 = ReferenceGenome.read(resource(""fake_ref_genome.json"")); self.assertEqual(gr3.name, ""my_reference_genome""); self.assertFalse(gr3.has_sequence()). gr4 = ReferenceGenome.from_fasta_file(""test_rg"", resource(""fake_reference.fasta""),; resource(""fake_reference.fasta.fai""),; mt_contigs=[""b"", ""c""], x_contigs=[""a""]); self.assertTrue(gr4.has_sequence()); self.assertTrue(gr4.x_contigs == [""a""]). t = hl.import_table(resource(""fake_reference.tsv""), impute=True); self.assertTrue(hl.eval(t.all(hl.get_sequence(t.contig, t.pos, reference_genome=gr4) == t.base))). l = hl.locus(""a"", 7, gr4); self.assertTrue(hl.eval(l.sequence_context(before=3, after=3) == ""TTTCGAA"")); ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5308#issuecomment-462500751:19,test,test,19,https://hail.is,https://github.com/hail-is/hail/pull/5308#issuecomment-462500751,7,"['assert', 'test']","['assertEqual', 'assertFalse', 'assertTrue', 'test']"
Testability,It looks like we need more client tests to verify that things like duration and exit codes continue to work. I'll close and add an issue to fix this more thoroughly.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6721#issuecomment-514360904:34,test,tests,34,https://hail.is,https://github.com/hail-is/hail/pull/6721#issuecomment-514360904,1,['test'],['tests']
Testability,"It looks like you have two options:; 1. Install the Gradle ppa: https://launchpad.net/~cwchien/+archive/ubuntu/gradle; ; In a nutshell, uninstall the previous version of Gradle and then run:; ; ```; sudo add-apt-repository ppa:cwchien/gradle; sudo apt-get update; sudo apt-get install gradle-2.14.1; ```; 2. Download the the latest complete distribution of Gradle 2:; ; https://gradle.org/gradle-download/; ; Go to Previous Release and select 2.14.1 and download the complete distribution. Gradle is written in Java and it is pre-compiled. No need to build it. Run `gradle-2.14.1/bin/gradle` and you should be good to go.; ; Gradle 3 was just released a few days ago. We haven't tested against it, so I would recommend Gradle 2 for now.; ; I'll update the documentation to warn about Gradle 2.10. Let me know if either of these work for you.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/594#issuecomment-240306249:679,test,tested,679,https://hail.is,https://github.com/hail-is/hail/issues/594#issuecomment-240306249,1,['test'],['tested']
Testability,It looks likely to pass the service backend tests too!,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11450#issuecomment-1076821361:44,test,tests,44,https://hail.is,https://github.com/hail-is/hail/pull/11450#issuecomment-1076821361,1,['test'],['tests']
Testability,"It needs some more cleanup, I plan to make another review pass myself. I can definitely split it into multiple pieces if necessary. Will post latest benchmark numbers in a moment.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2154:149,benchmark,benchmark,149,https://hail.is,https://github.com/hail-is/hail/pull/2154,1,['benchmark'],['benchmark']
Testability,It passed the dataproc tests.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8576#issuecomment-615468636:23,test,tests,23,https://hail.is,https://github.com/hail-is/hail/pull/8576#issuecomment-615468636,1,['test'],['tests']
Testability,It seems odd that all the tests passed? And the logs look right? What else was that pod doing?. https://storage.googleapis.com/hail-ci-0-1/ci/ee92f64477f68737987fd8f21411b0348a3d3420/e4ae86ea520fbc5d98b84811b2cdb83640163910/artifacts/index.html,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4541#issuecomment-429915630:26,test,tests,26,https://hail.is,https://github.com/hail-is/hail/issues/4541#issuecomment-429915630,2,"['log', 'test']","['logs', 'tests']"
Testability,It seems that referencing a global function serializes a module named `test` which; does not exist on the worker.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10317:71,test,test,71,https://hail.is,https://github.com/hail-is/hail/pull/10317,1,['test'],['test']
Testability,"It seems that sessions sometimes become inaccessible to auth. Using some; logging, I realized that `/login` will set some session parameters that do not; reappear in `/oauth2callback`. While trying to debug this, I deleted my cookie; and everything started working again. Luckily, my phone was still borked. The; fix is to use `new_session` which I discovered with a big red warning in; aiohttp-session's docs: [Always use new_session() instead of get_session() in; your login views to guard against Session Fixation; attacks!](https://aiohttp-session.readthedocs.io/en/stable/reference.html#aiohttp_session.new_session). If nothing else, we are now safe from session fixation attacks. I do not; understand why this is necessary for correctness.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8052:74,log,logging,74,https://hail.is,https://github.com/hail-is/hail/pull/8052,3,['log'],"['logging', 'login']"
Testability,"It seems the biggest remaining issue is that CI doesn't have access to hail imports when testing hailtop. Could we address this? Do you want a PR?. edit: nvm, patched here.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9194#issuecomment-670044799:89,test,testing,89,https://hail.is,https://github.com/hail-is/hail/pull/9194#issuecomment-670044799,1,['test'],['testing']
Testability,"It seems the test failures are due to:; 1. TemporaryDirectory (and TemporaryFilename); 2. `hailtop.batch.backend.ServiceBackend` absolutely should not use sync `BatchClient`, the async one is right there!; 3. `hailctl batch submit` is broken because of (2); 4. `test_callback` should use async `BatchClient` b/c it is async. TemporaryDirectory & TemporaryFilename use `hailtop.fs`, which is sync. This is nearly the async FS API except:; 1. `isfile` vs `is_file`; 2. `isdir` vs `is_dir`; 3. `stat` returns a `FileListEntry` instead of a `FileStatus`.; 4. `listfiles` vs `ls`. `hailtop.fs.router_fs.RouterFS` is a sync shim between these APIs. So there's basically sync-vs-async and Python-vs-Hail FS APIs. We have:; 1. sync, Python: `hailtop.fs.FS`.; 2. async, Python: does not exist.; 3. async, Hail: `hailtop.aiotools.fs.FS`.; 4. sync, Hail: `hailtop.fs.router_fs.RouterFS`. If we had (2), we could write an async version of TemporaryDirectory and TemporaryFilename and use those in async methods (in particular, in `hail.backend.ServiceBackend`). The high-level need is that we gotta be careful about not interleaving async-sync-async. Your PR reveals that we were inadvertently violating that rule. It seems best to follow the rule and only use `nest_asyncio` when we're in a Jupyter Notebook.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13677#issuecomment-1743171933:13,test,test,13,https://hail.is,https://github.com/hail-is/hail/pull/13677#issuecomment-1743171933,1,['test'],['test']
Testability,"It seems this is probably a bit slower than the current code on GCP (but there is variation so I'm not completely sure, and it still seems fast). It does give a functional S3 fileystem, tho. I will post timings below. Timings were done with my `test-copy` timing framework. - Add size_hint to create_part, used by the S3 backend and passed by copy. - Add a weighted semaphore (that can acquire n instead of just 1) and use it to limit the data in flight. It isn't completely clear how to do this. I could do, say, use a semaphore with value 10 * PART_SIZE and acquire the size of the object (which will be up to PART_SIZE). That might be a good idea, but instead I used 10 * BUFFER_SIZE and acquire the minimum of the BUFFER_SIZE and object size. This specifically limits the total intermediate buffer size. 10 was a mostly random choice, so you might try benchmarking to see if it makes a difference. - I made the copy part size destination filesystem specific. This is because the S3 multi-part upload API calls the partition contents be loaded into memory and 128MiB is too much for parallel uploads. The S3 default is 8MiB. - I create a new async writeable paired with a syncronous byte collector. It is used for the S3 multi-part upload call, which requires an the body to be a bytes/bytearray. - I tried to use readinto/write instead of read/write in SourceCopier.{_copy_file, _copy_part}, but in S3, the get_object API call returns a StreamingBody:. https://botocore.amazonaws.com/v1/documentation/api/latest/reference/response.html. that doesn't support readinto(). - In SourceCopier._copy_part, it might be worth benchmarking reading the entire part into memory and then writing it out like we're forced to do on the AWS backend. To do this, we'd be forced to turn PART_SIZE down to ~8MiB.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10752:245,test,test-copy,245,https://hail.is,https://github.com/hail-is/hail/pull/10752,3,"['benchmark', 'test']","['benchmarking', 'test-copy']"
Testability,"It should never not be in the database. That's why it should be an error if we get an event for an instance we've never created before. The reason we keep getting these events is because when we run this query:. ```; filter = f'''; logName=""projects/{PROJECT}/logs/cloudaudit.googleapis.com%2Factivity"" AND; resource.type=gce_instance AND; protoPayload.resourceName:""{self.machine_name_prefix}"" AND; timestamp >= ""{mark}""; '''; ```. We have `timestamp >= {mark}`. This means if `mark` doesn't change each time the event polling loop reruns, then we'll always keep getting the same event as the last one processed. We need that `>=` though because different events can have the same timestamp. So the driver could have been shut down in the middle of processing multiple events with the same timestamp. So we do the conservative thing and try to reprocess the event again until the mark changes to a different timestamp. Does that make sense?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10325#issuecomment-819729595:232,log,logName,232,https://hail.is,https://github.com/hail-is/hail/pull/10325#issuecomment-819729595,2,['log'],"['logName', 'logs']"
Testability,"It uses `hasMissingValues` now, which already has a test. I'm beefing up that test now to be safe. `test_linreg` fails if you swap the intercept with the other covariate, I can add that too.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8575#issuecomment-615433780:52,test,test,52,https://hail.is,https://github.com/hail-is/hail/pull/8575#issuecomment-615433780,2,['test'],['test']
Testability,"It was wrong for the `elemRef` values in the emit code `NDArrayMap` and `NDArrayMap2` to use `mb` as opposed to `elemMB`. They were being emitted in a different method builder than they were being used in. In order to fix this, I had to fix `NDArrayEmitter` to take an `EmitMethodBuilder[C]` instead of `EmitMethodBuilder[_]`, so I did that. I also had to pass the arguments along from the `mb` method builder to the `innerMethod` method builder in the `NDArrayEmitter` emit method. Factored out `mb.getParamsList()` to make that easier. I also added a new test that is remedied by this change.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8496:557,test,test,557,https://hail.is,https://github.com/hail-is/hail/pull/8496,1,['test'],['test']
Testability,"It will be way better for us to be able to ensure Tim's outstanding PRs continue to be tested. Also, welcome to the rotation @ehigham.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13204:87,test,tested,87,https://hail.is,https://github.com/hail-is/hail/pull/13204,1,['test'],['tested']
Testability,"It's a bit confusing, but on the CI page you can navigate to the Artifacts tab from which you can open the [build report's index.html](https://ci.hail.is/repository/download/HailSourceCode_HailCi/33165:id/build/reports/tests/index.html). The error looks to me like a Hail problem, not a you problem. I'll investigate further.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2049#issuecomment-320333635:219,test,tests,219,https://hail.is,https://github.com/hail-is/hail/pull/2049#issuecomment-320333635,1,['test'],['tests']
Testability,It's a little concerning that this is necessary. Are there typecheck cases that don't make assertions about some of their children?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9974#issuecomment-772052307:91,assert,assertions,91,https://hail.is,https://github.com/hail-is/hail/pull/9974#issuecomment-772052307,1,['assert'],['assertions']
Testability,"It's already deployed, so, I guess that's how I tested it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9391#issuecomment-685116503:48,test,tested,48,https://hail.is,https://github.com/hail-is/hail/pull/9391#issuecomment-685116503,1,['test'],['tested']
Testability,It's already there: src/test/resources/fake_reference.fasta,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5308#issuecomment-462494294:24,test,test,24,https://hail.is,https://github.com/hail-is/hail/pull/5308#issuecomment-462494294,1,['test'],['test']
Testability,"It's an edge case, largely in the case of a network partition where a worker node becomes unreachable. I believe that the batch driver will at some point declare the node dead and reschedule its jobs even if the machine is still running. This might not be hard to change given that the batch driver subscribes to the audit log and can use the vm api to verify a worker's state. I also think this barely ever happens except in the case of actual bugs on the worker",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14460#issuecomment-2427210749:323,log,log,323,https://hail.is,https://github.com/hail-is/hail/issues/14460#issuecomment-2427210749,1,['log'],['log']
Testability,It's as if it was just spinning on `exit $BUILD_EXIT`. It had to have finished the last for loop because all the logs open in my browser instead of downloading.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4541#issuecomment-429915864:113,log,logs,113,https://hail.is,https://github.com/hail-is/hail/issues/4541#issuecomment-429915864,1,['log'],['logs']
Testability,It's definitely a bit unclear to met that we got everything and I'm not convinced the test checks everything. I don't think I'd feel much better unless we were randomly restarting the context mid tests.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5872#issuecomment-484583174:86,test,test,86,https://hail.is,https://github.com/hail-is/hail/pull/5872#issuecomment-484583174,2,['test'],"['test', 'tests']"
Testability,It's finally passing the tests!,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5615#issuecomment-476464978:25,test,tests,25,https://hail.is,https://github.com/hail-is/hail/pull/5615#issuecomment-476464978,1,['test'],['tests']
Testability,"It's hard to go through every line to look for bugs, but the structure looks great. You've got a couple test failures (code cast errors)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9926#issuecomment-767796221:104,test,test,104,https://hail.is,https://github.com/hail-is/hail/pull/9926#issuecomment-767796221,1,['test'],['test']
Testability,It's just a string so `json.loads` fails on it. Not sure why I did that anyway. This has been broken on CI for a bit now. CI still manages fine because it checks everything on an interval but the callback helps it respond immediately to when batches finish for a PR test or deploy.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12631:266,test,test,266,https://hail.is,https://github.com/hail-is/hail/pull/12631,1,['test'],['test']
Testability,It's not in pulling. It seems like it's actually in show based on the stack trace. I assumed it was in `create` because this appeared in the stack trace `name=f'batch-{self.job.batch_id}-job-{self.job.job_id}-{self.name}'` and that's the only place that's used. Let me look at the worker logs.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8193#issuecomment-592579928:288,log,logs,288,https://hail.is,https://github.com/hail-is/hail/pull/8193#issuecomment-592579928,1,['log'],['logs']
Testability,"It's obvious that I'm the only one using SBT 😉 . I removed this spark helper thing that data bricks has abandoned. It's not hard to specify the right spark dependencies manually. In fact, we do that in `build.gradle` already. I don't know what the deal with hadoopClient, but it didn't seem necessary for my tests to pass. We don't use SBT for deployment, so I'm not worried. I'm not sure how all the http4s and json4s stuff got pulled in. They're not present in grade, so I removed them. I also bumped the SBT version for no particular reason. 🤷‍♀ . It works.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8357:308,test,tests,308,https://hail.is,https://github.com/hail-is/hail/pull/8357,1,['test'],['tests']
Testability,It's only used for a few tests,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6628:25,test,tests,25,https://hail.is,https://github.com/hail-is/hail/pull/6628,1,['test'],['tests']
Testability,"It's only used in tests, and is not something we wish to maintain as part of the ptype interface.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10575:18,test,tests,18,https://hail.is,https://github.com/hail-is/hail/pull/10575,1,['test'],['tests']
Testability,"It's possible to get this error:; ```; ----> 5 hc.import_vcf('src/test/resources/sample.vcf').write('sample.vds'). /hail/python/hail/java.py in function_wrapper(*args, **kwargs); 92 except Py4JJavaError as e:; 93 msg = env.jutils.getMinimalMessage(e.java_exception); ---> 94 raise FatalError(msg); 95 except Py4JError as e:; 96 env.jutils.log().error('hail: caught python exception: ' + str(e)). FatalError: UnsupportedClassVersionError: htsjdk/tribble/TribbleException : Unsupported major.minor version 52.0; ```. I figure this change might be nicer, but am happy to hear input",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1406#issuecomment-280786286:66,test,test,66,https://hail.is,https://github.com/hail-is/hail/pull/1406#issuecomment-280786286,2,"['log', 'test']","['log', 'test']"
Testability,It's probably worth running benchmarks to make sure this didn't cause anything important to get deoptimized,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10797#issuecomment-908847093:28,benchmark,benchmarks,28,https://hail.is,https://github.com/hail-is/hail/pull/10797#issuecomment-908847093,1,['benchmark'],['benchmarks']
Testability,"It's sadly duplicated in each module's conftest, but yeah this is a classic Tim Python Hack. https://github.com/hail-is/hail/blob/main/batch/test/conftest.py",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11771#issuecomment-1100395763:141,test,test,141,https://hail.is,https://github.com/hail-is/hail/pull/11771#issuecomment-1100395763,1,['test'],['test']
Testability,"It's testing with the correct image, though?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4240#issuecomment-419488010:5,test,testing,5,https://hail.is,https://github.com/hail-is/hail/pull/4240#issuecomment-419488010,1,['test'],['testing']
Testability,Its definition is literally first so I do not think we need this test,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10082:65,test,test,65,https://hail.is,https://github.com/hail-is/hail/pull/10082,1,['test'],['test']
Testability,"It’s a random test, and it seems the current tolerance still allows rare sporadic failures.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14053:14,test,test,14,https://hail.is,https://github.com/hail-is/hail/pull/14053,1,['test'],['test']
Testability,"JObject(List((start,JObject(List())), (end,JObject(List())), (includeStart,JBool(true)), (includeEnd,JBool(true)))))),null,Map())))))), Let(__iruid_376,ToArray(StreamMap(ToStream(Ref(__iruid_369,array<struct{filePath: str, partitionCounts: int64}>),false),__iruid_377,GetField(Ref(__iruid_377,struct{filePath: str, partitionCounts: int64}),partitionCounts))),Begin(ArrayBuffer(WriteMetadata(Ref(__iruid_376,array<int64>),TableSpecWriter(gs://danking/workshop-test/1kg.mt/rows,Table{global:Struct{},key:[locus,alleles],row:Struct{locus:Locus(GRCh37),alleles:Array[String],rsid:String,qual:Float64,filters:Set[String],info:Struct{AC:Array[Int32],AF:Array[Float64],AN:Int32,BaseQRankSum:Float64,ClippingRankSum:Float64,DP:Int32,DS:Boolean,FS:Float64,HaplotypeScore:Float64,InbreedingCoeff:Float64,MLEAC:Array[Int32],MLEAF:Array[Float64],MQ:Float64,MQ0:Int32,MQRankSum:Float64,QD:Float64,ReadPosRankSum:Float64,set:String}}},rows,../globals/rows,../references,false)), WriteMetadata(Ref(__iruid_376,array<int64>),TableSpecWriter(gs://danking/workshop-test/1kg.mt/entries,Table{global:Struct{},key:[],row:Struct{`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:Array[Struct{GT:Call,AD:Array[Int32],DP:Int32,GQ:Int32,PL:Array[Int32]}]}},rows,../globals/rows,../references,false)), WriteMetadata(MakeStruct(ArrayBuffer((cols,GetField(Ref(__iruid_368,struct{filePath: str, partitionCounts: int64}),partitionCounts)), (rows,Ref(__iruid_376,array<int64>)))),MatrixSpecWriter(gs://danking/workshop-test/1kg.mt,Matrix{global:Struct{},col_key:[s],col:Struct{s:String},row_key:[[locus,alleles]],row:Struct{locus:Locus(GRCh37),alleles:Array[String],rsid:String,qual:Float64,filters:Set[String],info:Struct{AC:Array[Int32],AF:Array[Float64],AN:Int32,BaseQRankSum:Float64,ClippingRankSum:Float64,DP:Int32,DS:Boolean,FS:Float64,HaplotypeScore:Float64,InbreedingCoeff:Float64,MLEAC:Array[Int32],MLEAF:Array[Float64],MQ:Float64,MQ0:Int32,MQRankSum:Float64,QD:Float64,ReadPosRankSum:Float64,set:String}},entry:Struct{GT:",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9856:17570,test,test,17570,https://hail.is,https://github.com/hail-is/hail/issues/9856,1,['test'],['test']
Testability,"JUnit tests</li>; <li><a href=""https://github.com/cbeust/testng/commit/8630a7e8fe12985d71c00212f9362fd38fb0cb9e""><code>8630a7e</code></a> Ensure ITestContext available for JUnit4 tests</li>; <li><a href=""https://github.com/cbeust/testng/commit/7070b020def0089d0d9dc695a5762ad16e974ce6""><code>7070b02</code></a> Streamline dependsOnMethods for configurations</li>; <li><a href=""https://github.com/cbeust/testng/commit/d7e0bb1cbcd7933d34d704678e75cbaf42704505""><code>d7e0bb1</code></a> Deprecate support for running Spock Tests</li>; <li><a href=""https://github.com/cbeust/testng/commit/ca7a3a293008389096be75fea4936af8e5f79650""><code>ca7a3a2</code></a> Ensure All tests run all the time</li>; <li>Additional commits viewable in <a href=""https://github.com/cbeust/testng/compare/testng-6.8.21...7.7.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=org.testng:testng&package-manager=gradle&previous-version=6.8.21&new-version=7.7.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR i",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12665:16711,test,testng,16711,https://hail.is,https://github.com/hail-is/hail/pull/12665,2,['test'],['testng']
Testability,JVM tests pass,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7959#issuecomment-580018794:4,test,tests,4,https://hail.is,https://github.com/hail-is/hail/pull/7959#issuecomment-580018794,1,['test'],['tests']
Testability,Java UP-TO-DATE; :compileTestScala UP-TO-DATE; :processTestResources UP-TO-DATE; :testClasses UP-TO-DATE; :testCppCodegen; Running test: Test method testReadWrite(is.hail.annotations.AnnotationsSuite). Gradle suite > Gradle test > is.hail.annotations.AnnotationsSuite.testReadWrite FAILED; org.apache.spark.SparkException at AnnotationsSuite.scala:76; Caused by: java.lang.AssertionError; Running test: Test method testEmptyKeys(is.hail.io.IndexSuite). Gradle suite > Gradle test > is.hail.io.IndexSuite.testEmptyKeys FAILED; java.lang.AssertionError at IndexSuite.scala:42; Running test: Test method testIntervalIterator(is.hail.io.IndexSuite). Gradle suite > Gradle test > is.hail.io.IndexSuite.testIntervalIterator FAILED; java.lang.AssertionError at IndexSuite.scala:42; Running test: Test method testIntervalIteratorWorksWithGeneralEndpoints(is.hail.io.IndexSuite). Gradle suite > Gradle test > is.hail.io.IndexSuite.testIntervalIteratorWorksWithGeneralEndpoints FAILED; java.lang.AssertionError at IndexSuite.scala:42; Running test: Test method testIterateFromUntil(is.hail.io.IndexSuite). Gradle suite > Gradle test > is.hail.io.IndexSuite.testIterateFromUntil FAILED; java.lang.AssertionError at IndexSuite.scala:42; Running test: Test method testLowerBound(is.hail.io.IndexSuite). Gradle suite > Gradle test > is.hail.io.IndexSuite.testLowerBound FAILED; java.lang.AssertionError at IndexSuite.scala:42; Running test: Test method testQueryByKey(is.hail.io.IndexSuite). Gradle suite > Gradle test > is.hail.io.IndexSuite.testQueryByKey FAILED; java.lang.AssertionError at IndexSuite.scala:42; Running test: Test method testRangeIterator(is.hail.io.IndexSuite). Gradle suite > Gradle test > is.hail.io.IndexSuite.testRangeIterator FAILED; java.lang.AssertionError at IndexSuite.scala:42; Running test: Test method testUpperBound(is.hail.io.IndexSuite). Gradle suite > Gradle test > is.hail.io.IndexSuite.testUpperBound FAILED; java.lang.AssertionError at IndexSuite.scala:42; Running test: Test,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4718:1408,Assert,AssertionError,1408,https://hail.is,https://github.com/hail-is/hail/issues/4718,1,['Assert'],['AssertionError']
Testability,Job 40 seems to have disappeared? It was given the name `job-40-62pkp` by batch and then never mentioned again. [batch.log](https://github.com/hail-is/hail/files/2498262/batch.log); [hail-ci.log](https://github.com/hail-is/hail/files/2498263/hail-ci.log); [pods.txt](https://github.com/hail-is/hail/files/2498264/pods.txt),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4591:119,log,log,119,https://hail.is,https://github.com/hail-is/hail/issues/4591,4,['log'],['log']
Testability,Job Regions Testing for CI,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12263:12,Test,Testing,12,https://hail.is,https://github.com/hail-is/hail/pull/12263,1,['Test'],['Testing']
Testability,"Jobs with large logs (>2GiB-ish) can break workers because the current worker code attempts to load the whole log as `bytes` before uploading it to blob storage. This loading into `bytes` also plagues the batch front end when loading logs from blob storage to present to the user.; ; This updates the worker and front end to always stream through logs, never load them into memory. Additionally, in order to make page loads in the UI reasonable, we limit the length of the log that is shown in the UI, with some advice to download the file if it's too large to render on the page. Fixes #13329",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14076:16,log,logs,16,https://hail.is,https://github.com/hail-is/hail/pull/14076,5,['log'],"['log', 'logs']"
Testability,Johnc batch logging Experiment,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6525:12,log,logging,12,https://hail.is,https://github.com/hail-is/hail/pull/6525,1,['log'],['logging']
Testability,"Joining something with itself shouldn't be doing any repartitioning. If the problem does have something to do with repartitioning, it might be worth testing it on #4094.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4104#issuecomment-411397458:149,test,testing,149,https://hail.is,https://github.com/hail-is/hail/pull/4104#issuecomment-411397458,1,['test'],['testing']
Testability,"Joins were not being tested and fail with source mismatch if joins are present in both key and agg expressions. This fix is analogous to that on Table.group_by.aggregate in #3730, processing all joins at once, and not reprocessing later. I don't address here a deeper bug that throws a source error when processing more than one entry-indexed. I've made an issue #3763",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3762:21,test,tested,21,https://hail.is,https://github.com/hail-is/hail/pull/3762,1,['test'],['tested']
Testability,"Jupyter notebook by default uses random tokens to secure itself against public attackers. Let's just use that token and expose jupyter publicly. cloudtools can open the port:; ```; gcloud compute instances add-tags CLUSTER_NAME-m \; --zone [ZONE] \; --tags cloudtools-CLUSTER_NAME-jupyter; gcloud compute firewall-rules create CLUSTER_NAME-expose-jupyter \; --action allow \; --direction ingress \; --rules tcp:8123 \; --priority 1 \; --target-tags cloudtools-CLUSTER_NAME-jupyter; ```. Then cloudtools can ssh there and read the token from the jupyter logs, then it can direct the user to the instance's public IP (look at `gcloud compute instances describe CLUSTER_NAME-m`) with the appropriate token.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5236:553,log,logs,553,https://hail.is,https://github.com/hail-is/hail/issues/5236,1,['log'],['logs']
Testability,"Just a few comments. Looking good! Looking forward to tests. Also, need to abstract out the code you share with Mendel errors as we discussed.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/109#issuecomment-169135201:54,test,tests,54,https://hail.is,https://github.com/hail-is/hail/pull/109#issuecomment-169135201,1,['test'],['tests']
Testability,Just a heads up this is failing in `TestUtilsSuite.testDataProviders` but I can't reproduce it locally. I'll let you know once I figure out what's going on.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5150#issuecomment-454993793:36,Test,TestUtilsSuite,36,https://hail.is,https://github.com/hail-is/hail/pull/5150#issuecomment-454993793,2,"['Test', 'test']","['TestUtilsSuite', 'testDataProviders']"
Testability,"Just added tests, @jbloom22 !",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1373#issuecomment-279429110:11,test,tests,11,https://hail.is,https://github.com/hail-is/hail/pull/1373#issuecomment-279429110,1,['test'],['tests']
Testability,Just because an RDD is OrderedPartitioner partitioned doesn't mean it; is an OrderedRDD (might not be sorted within partitions). Users who; want this behavior should call OrderedRDD.apply to assert it is an; OrderedRDD.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1864:191,assert,assert,191,https://hail.is,https://github.com/hail-is/hail/pull/1864,1,['assert'],['assert']
Testability,Just cleaning up some old tests to use assertEvalsTo instead of manually constructing the functions.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6006:26,test,tests,26,https://hail.is,https://github.com/hail-is/hail/pull/6006,2,"['assert', 'test']","['assertEvalsTo', 'tests']"
Testability,"Just fixed, I forgot the parser rule. Yeah, I left in some printing in the stream stuff that I should probably at least flag to turn off in automated testing.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8520#issuecomment-612909469:150,test,testing,150,https://hail.is,https://github.com/hail-is/hail/pull/8520#issuecomment-612909469,1,['test'],['testing']
Testability,"Just for reference, this PR also moves copying the worker logs to the shutdown script and adds support for env in batch2. I also added a service account `ci-agent` in the default namespace for the test, dev scopes.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7454#issuecomment-550354045:58,log,logs,58,https://hail.is,https://github.com/hail-is/hail/pull/7454#issuecomment-550354045,2,"['log', 'test']","['logs', 'test']"
Testability,Just move delete_all_test_billing_projects into some file that isn't also full of tests.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11087#issuecomment-982038302:82,test,tests,82,https://hail.is,https://github.com/hail-is/hail/pull/11087#issuecomment-982038302,1,['test'],['tests']
Testability,Just now? It broke after switching to use `hadoop_copy` but should have fixed that this morning with my commit. I've been checking in and haven't seen it run tests yet.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5686#issuecomment-477169272:158,test,tests,158,https://hail.is,https://github.com/hail-is/hail/pull/5686#issuecomment-477169272,1,['test'],['tests']
Testability,"Just ran benchmarks locally, and it looks fine. Think there's any need to run on the cloud as well?. I also tried benchmarking without the binds, and that didn't appear to make any difference, so I'm going to get rid of those.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11070#issuecomment-973005657:9,benchmark,benchmarks,9,https://hail.is,https://github.com/hail-is/hail/pull/11070#issuecomment-973005657,2,['benchmark'],"['benchmarking', 'benchmarks']"
Testability,"Just re-ran it on the Cray. The log is here:; /home/users/lfran/hail.head.log. On Fri, Jul 22, 2016 at 4:05 PM, cseed notifications@github.com wrote:. > Do you have the log handy?; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > https://github.com/broadinstitute/hail/pull/446#issuecomment-234642726,; > or mute the thread; > https://github.com/notifications/unsubscribe-auth/ADVxgUdytKyjwJ5r3pp3-yEam3Xc6-xQks5qYSJ4gaJpZM4I-Oz9; > .",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/446#issuecomment-234979777:32,log,log,32,https://hail.is,https://github.com/hail-is/hail/pull/446#issuecomment-234979777,3,['log'],['log']
Testability,"Just skimmed the discussion. >> I've been working on an R interface to Hail through the sparklyr package; >; > this also sounds awesome. woah, hell yes. I'll look tomorrow. Our build situation is a bit messed up right now. I'll try to isolate your issue and fix it. Moreover, I should be fixing the build situation for good soon. Can you share a full executor log for an executor that fails? That should have some information about why the spark context got shut down.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4513#issuecomment-430451868:360,log,log,360,https://hail.is,https://github.com/hail-is/hail/issues/4513#issuecomment-430451868,1,['log'],['log']
Testability,"Just so I understand correctly (and sorry if this is obvious), the current job logs interface is still the same. But if you want a container's logs, then you'll get bytes which the user will have to decode themselves. How does that affect the file download button in the UI and the hailctl batch logs functionality you have? Will you see text or a random byte string?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12666#issuecomment-1426340756:79,log,logs,79,https://hail.is,https://github.com/hail-is/hail/pull/12666#issuecomment-1426340756,3,['log'],['logs']
Testability,"Just some cleanup, all in test files.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13503:26,test,test,26,https://hail.is,https://github.com/hail-is/hail/pull/13503,1,['test'],['test']
Testability,"Just starting to explore this PR. I compared this in-progress CI run to 7126798 (from #12737). The time to service backend starting is ~7 minutes. In the other PR, its ~8 minutes. I suppose that's because this PR isn't hitting any caches, right?. Hmm, it also seems like the critical path to the service backend test is through `build_hail_jar_and_wheel_only`. I wonder if we double the cores, would the time halve? On my laptop a fresh build is like 3m. <img width=""1512"" alt=""Screen Shot 2023-03-07 at 10 27 05"" src=""https://user-images.githubusercontent.com/106194/223501120-ea93c58b-f47f-4e49-8405-8a53d97d76e7.png"">",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12578#issuecomment-1458571966:312,test,test,312,https://hail.is,https://github.com/hail-is/hail/pull/12578#issuecomment-1458571966,1,['test'],['test']
Testability,"Just to be clear, this pipeline was what I wrote when trying to replicate the bug Duncan was seeing, but it hit a different assertion error than the one he was hitting. He was hitting ""local in the wrong method builder"" problems.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8325#issuecomment-603567150:124,assert,assertion,124,https://hail.is,https://github.com/hail-is/hail/issues/8325#issuecomment-603567150,2,['assert'],['assertion']
Testability,"Just to be sure, I checked the logs for errors and found none. I manually logged into the database and watched the compaction happen for both tables. I don't think we can do any more due diligence with this. Let's plan on merging on Tuesday when you're back from vacation. ```; mysql> select * from aggregated_billing_project_user_resources_v3 where resource_id = 6 limit 100;; +----------------------------------+------+-------------+-------+------------+; | billing_project | user | resource_id | token | usage |; +----------------------------------+------+-------------+-------+------------+; | __testproject_iizhz61z7543_FUitX | test | 6 | 0 | 1817536 |; | __testproject_iizhz61z7543_uvxWn | test | 6 | 0 | 11331136 |; | ci | ci | 6 | 0 | 79640784 |; | test | test | 6 | 0 | 4063028160 |; | test | test | 6 | 1 | 189760 |; | test | test | 6 | 3 | 607168 |; | test | test | 6 | 4 | 749952 |; | test | test | 6 | 5 | 46912 |; | test | test | 6 | 6 | 158336 |; | test | test | 6 | 7 | 70336 |; | test | test | 6 | 8 | 167680 |; | test | test | 6 | 9 | 523136 |; | test | test | 6 | 10 | 40640 |; | test | test | 6 | 11 | 616448 |; | test | test | 6 | 12 | 497024 |; | test | test | 6 | 14 | 87680 |; | test | test | 6 | 15 | 111104 |; | test | test | 6 | 16 | 120128 |; | test | test | 6 | 17 | 28736 |; | test | test | 6 | 19 | 42240 |; | test | test | 6 | 20 | 271232 |; | test | test | 6 | 21 | 88320 |; | test | test | 6 | 22 | 149760 |; | test | test | 6 | 23 | 47232 |; | test | test | 6 | 24 | 45888 |; | test | test | 6 | 25 | 41664 |; | test | test | 6 | 27 | 56704 |; | test | test | 6 | 28 | 36864 |; | test | test | 6 | 30 | 57792 |; | test | test | 6 | 31 | 62848 |; | test | test | 6 | 32 | 40320 |; | test | test | 6 | 33 | 61888 |; | test | test | 6 | 34 | 43520 |; | test | test | 6 | 35 | 219328 |; | test | test | 6 | 36 | 141760 |; | test | test | 6 | 38 | 157632 |; | test | test | 6 | 40 | 72064 |; | test | test | 6 | 41 | 317888 |; | test | test | 6 | 42 | 83648 |; | test | t",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13213#issuecomment-1634765785:31,log,logs,31,https://hail.is,https://github.com/hail-is/hail/pull/13213#issuecomment-1634765785,2,['log'],"['logged', 'logs']"
Testability,"K, sure.; Step1 : when start pyspark with the cons; ```; [root@tele-1 ~]# PYSPARK_PYTHON=""ipython"" pyspark --conf spark.sql.files.openCostInBytes=1099511627776 --conf spark.sql.files.maxPartitionBytes=1099511627776 --conf spark.hadoop.parquet.block.size=1099511627776 --conf spark.serializer=org.apache.spark.serializer.KryoSerializer; /usr/local/lib/python3.5/site-packages/IPython/core/history.py:228: UserWarning: IPython History requires SQLite, your history will not be saved; warn(""IPython History requires SQLite, your history will not be saved""); Python 3.5.2 (default, Jul 12 2017, 14:00:23) ; Type ""copyright"", ""credits"" or ""license"" for more information. IPython 5.1.0 -- An enhanced Interactive Python.; ? -> Introduction and overview of IPython's features.; %quickref -> Quick reference.; help -> Python's own help system.; object? -> Details about 'object', use 'object??' for extra details.; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 17/08/10 08:41:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/08/10 08:41:32 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/opt/Software/hail/build/libs/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/10 08:41:32 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/10 08:41:32 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 3.5.2 (default, Jul 1",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2076#issuecomment-321420160:1005,log,log,1005,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321420160,1,['log'],['log']
Testability,KING tests are failing,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9501#issuecomment-698590626:5,test,tests,5,https://hail.is,https://github.com/hail-is/hail/pull/9501#issuecomment-698590626,1,['test'],['tests']
Testability,KNvkh8SC3EzvXjgv6-LMY=: writing f and contexts\n2022-11-15 20:30:18.263 ServiceBackend$: INFO: parallelizeAndComputeWithIndex: pty4D81uzQk6XN9LVVebj6KNvkh8SC3EzvXjgv6-LMY=: writing contexts\n2022-11-15 20:30:18.264 Requester: INFO: request POST http://memory.hail/api/v1alpha/objects?q=gs%3A%2F%2Fhail-test-dmk9z%2FparallelizeAndComputeWithIndex%2Fpty4D81uzQk6XN9LVVebj6KNvkh8SC3EzvXjgv6-LMY%3D%2Ff\n2022-11-15 20:30:18.264 Requester: INFO: request POST http://memory.hail/api/v1alpha/objects?q=gs%3A%2F%2Fhail-test-dmk9z%2FparallelizeAndComputeWithIndex%2Fpty4D81uzQk6XN9LVVebj6KNvkh8SC3EzvXjgv6-LMY%3D%2Fcontexts\n2022-11-15 20:30:18.318 Requester: INFO: request POST http://memory.hail/api/v1alpha/objects?q=gs%3A%2F%2Fhail-test-dmk9z%2FparallelizeAndComputeWithIndex%2Fpty4D81uzQk6XN9LVVebj6KNvkh8SC3EzvXjgv6-LMY%3D%2Fcontexts response 200\n2022-11-15 20:30:18.331 Requester: INFO: request POST http://memory.hail/api/v1alpha/objects?q=gs%3A%2F%2Fhail-test-dmk9z%2FparallelizeAndComputeWithIndex%2Fpty4D81uzQk6XN9LVVebj6KNvkh8SC3EzvXjgv6-LMY%3D%2Ff response 200\n2022-11-15 20:30:18.332 ServiceBackend$: INFO: parallelizeAndComputeWithIndex: pty4D81uzQk6XN9LVVebj6KNvkh8SC3EzvXjgv6-LMY=: running job\n2022-11-15 20:30:18.333 Requester: INFO: request POST http://batch.hail/api/v1alpha/batches/6627669/update-fast\n2022-11-15 20:30:18.697 Requester: INFO: request POST http://batch.hail/api/v1alpha/batches/6627669/update-fast response 200\n2022-11-15 20:30:18.697 BatchClient: INFO: run: created update 2 for batch 6627669\n2022-11-15 20:30:18.697 Requester: INFO: request GET http://batch.hail/api/v1alpha/batches/6627669\n2022-11-15 20:30:18.802 Requester: INFO: request GET http://batch.hail/api/v1alpha/batches/6627669 response 200\n2022-11-15 20:30:18.852 Requester: INFO: request GET http://batch.hail/api/v1alpha/batches/6627669\n2022-11-15 20:30:18.866 Requester: INFO: request GET http://batch.hail/api/v1alpha/batches/6627669 response 200\n2022-11-15 20:30:18.917 Requester: INFO: reque,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12470#issuecomment-1315959284:24060,test,test-,24060,https://hail.is,https://github.com/hail-is/hail/pull/12470#issuecomment-1315959284,2,['test'],['test-']
Testability,"Keeping in mind Cotton's queries last week, researched and found much lighter alternative to ExprsesJS for the server api. A few years ago, Express had low impact on node performance; it has become bloated. Found a light (~200 LOC) ""framework"" called Polka, that is small enough to maintain ourselves. It mainly adds light route-matching capabilities, to avoid repeating boilerplate when writing the Node server. Easy to follow. It's also the fastest ""framework"" available, outside of C/Go/Rust. Matches Falcon, and allows 1 language for server/web. (Also Node has a far larger ecosystem).; * https://github.com/the-benchmarker/web-frameworks ; * Polka also nearly compatible with Express's middleware api, so many existing packages are either directly usable, or with minor modifications. This was a desire of mine, since nearly everything server-y for node is really written for Express. Last commit removes all Express, adds a rewritten express-jwt for access token verification, and shows client credential exchange, backed by Redis cache, for <=4ms fetching of",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4931#issuecomment-447583569:616,benchmark,benchmarker,616,https://hail.is,https://github.com/hail-is/hail/pull/4931#issuecomment-447583569,2,['benchmark'],['benchmarker']
Testability,"Killed errant code that snuck into this branch, tests passing again.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1338#issuecomment-278004376:48,test,tests,48,https://hail.is,https://github.com/hail-is/hail/pull/1338#issuecomment-278004376,1,['test'],['tests']
Testability,"Known facts:; - the last CI k8s deployment that started the deploy=1 batch on April 27th was active since at least April 25th.; - For a small window of time that I looked at on April 25th, it kept getting errors when trying to get the Github status for possible merge candidates: 12848, 12849, 12547. There might be other PRs at later dates. I saw at least the same errors for 12848 on April 27th. I'm going to throw out a hypothesis. I merged the dedup attempt resources PR on April 19th. The PRs that were stacked on previous commits of that PR now have merge conflicts with the set of commits that actually got merged. This caused problems because the next merge candidates CI was selecting was causing bad GitHub rate limit requests for exceeding the number of statuses. So it kept retrying that same merge candidate. CI didn't get restarted at least from the 25th to the 27th so the merge candidate never would have been refreshed. We know that there's less GKE node turnover in Azure, so not unexpected that the ci pod wouldn't get redeployed on its own. I'm thinking it's possible that I merged the database trigger fix on April 27th in response to the excessive deadlocks we noticed and then rebased the subsequent stacked PRs that had merge conflicts, thus unblocking CI, but I'm not sure (it's really hard to get what I want from the Azure log analytics system). I think the ""bug fix"" here is to reassess the code in CI and possibly harden it where we select the merge candidate and try to get the status so it doesn't block deployments. I have a screenshot from April 25th below in case it's helpful. The log analytics query that is helpful is:. ```; ContainerLog; | where ContainerID == ""273584134970cdae08cf0d412461862e2a0e558888a52c91870ca46a146cbb8a""; | order by TimeGenerated; ```. <img width=""1085"" alt=""Screen Shot 2023-05-24 at 12 58 18 PM"" src=""https://github.com/hail-is/hail/assets/1693348/e2da08b6-5982-46cb-9e2c-2178a19f2f86"">",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13050#issuecomment-1561641011:1350,log,log,1350,https://hail.is,https://github.com/hail-is/hail/issues/13050#issuecomment-1561641011,2,['log'],['log']
Testability,"Konrad hit:; ``` File ""<decorator-gen-816>"", line 2, in import_matrix_table; File ""/tmp/933dc754-b6e8-446f-986d-f4900becb0bd/hail-devel-ef2f48e719c3.zip/hail/utils/java.py"", line 208, in handle_py4j; hail.utils.java.FatalError: AssertionError: assertion failed: WrappedArray(): Struct{f0:String,f1:Int32}. Java stack trace:; java.lang.AssertionError: assertion failed: WrappedArray(): Struct{f0:String,f1:Int32}; at scala.Predef$.assert(Predef.scala:170); at is.hail.expr.types.MatrixType.<init>(MatrixType.scala:45); at is.hail.expr.types.MatrixType$.fromParts(MatrixType.scala:23); at is.hail.io.LoadMatrix$.apply(LoadMatrix.scala:343); at is.hail.HailContext$$anonfun$importMatrices$1.apply(HailContext.scala:555); at is.hail.HailContext$$anonfun$importMatrices$1.apply(HailContext.scala:555); at is.hail.HailContext.forceBGZip(HailContext.scala:498); at is.hail.HailContext.importMatrices(HailContext.scala:554); at is.hail.HailContext.importMatrix(HailContext.scala:540); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); at py4j.Gateway.invoke(Gateway.java:280); at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); at py4j.commands.CallCommand.execute(CallCommand.java:79); at py4j.GatewayConnection.run(GatewayConnection.java:214); at java.lang.Thread.run(Thread.java:748); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3017:228,Assert,AssertionError,228,https://hail.is,https://github.com/hail-is/hail/issues/3017,5,"['Assert', 'assert']","['AssertionError', 'assert', 'assertion']"
Testability,Konrad requested that we use a higher default. Above this some of the test case p-values do not converge,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12702:70,test,test,70,https://hail.is,https://github.com/hail-is/hail/pull/12702,1,['test'],['test']
Testability,Kubernetes apiserver logs,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6536:21,log,logs,21,https://hail.is,https://github.com/hail-is/hail/pull/6536,1,['log'],['logs']
Testability,Lack of test was me being lazy since I moved all the tests in my other ndarray PR. I'll just add one here and address the merge conflict in either direction.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7209#issuecomment-539184173:8,test,test,8,https://hail.is,https://github.com/hail-is/hail/pull/7209#issuecomment-539184173,2,['test'],"['test', 'tests']"
Testability,Later versions of IDEA can't run tests with our current testng and scalatest versions. Update to latest and fix fallout.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14277:33,test,tests,33,https://hail.is,https://github.com/hail-is/hail/pull/14277,2,['test'],"['testng', 'tests']"
Testability,"Latest build for spark failing. -- Performing Test CAN_COMPILE_POWER_ALTIVEC - Failed; -- Configuring done; -- Generating done; -- Build files have been written to: /gpfs/home/tpathare/hail_new/hail/src/main/c/libsimdpp-2.0-rc2; mkdir -p lib/linux-x86-64; g++ -fvisibility=hidden -rdynamic -shared -fPIC -ggdb -O3 -march=native -g -std=c++11 -Ilibsimdpp-2.0-rc2 ibs.cpp -o lib/linux-x86-64/libibs.so; cc1plus: error: unrecognized command line option ""-std=c++11""; make: *** [lib/linux-x86-64/libibs.so] Error 1; :nativeLib FAILED. FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':nativeLib'.; > Process 'command 'make'' finished with non-zero exit value 2. * Try:; Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. BUILD FAILED. Total time: 12.153 secs",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1327#issuecomment-276938635:46,Test,Test,46,https://hail.is,https://github.com/hail-is/hail/issues/1327#issuecomment-276938635,2,"['Test', 'log']","['Test', 'log']"
Testability,Let me know if you think this is good and whether I need to test the UI with dev deploy.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13262:60,test,test,60,https://hail.is,https://github.com/hail-is/hail/pull/13262,1,['test'],['test']
Testability,Let me know if you want me to dev deploy this one last time and test the changes. I haven't done so recently.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11750#issuecomment-1167512297:64,test,test,64,https://hail.is,https://github.com/hail-is/hail/pull/11750#issuecomment-1167512297,1,['test'],['test']
Testability,Let me know when this is good and I'll test the deploy script manually by commenting out everything not related to the GAR cleanup.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13703:39,test,test,39,https://hail.is,https://github.com/hail-is/hail/pull/13703,1,['test'],['test']
Testability,Let me try synchronizing on a lock object instead of this. It's possible that something else (logging?) may be synchronizing on `this`.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4068#issuecomment-411201627:94,log,logging,94,https://hail.is,https://github.com/hail-is/hail/pull/4068#issuecomment-411201627,1,['log'],['logging']
Testability,"Let's build it from scratch, but better, faster, ... Philosophy: Minimal magic, minimal reliance on outside work, don't use it unless we understand it. Goal: <16ms interactions, including <16ms page transitions. Should feel identical to a desktop app in terms of performance, but maintain state like a website (i.e `get` variables). TODO:; - [ ] Profile/logout should be responsive: no user icon / dropdown until narrow view; - [x] Default to redirect rather than popup; - [x] Clicking on login should clear state if auth failed; - [ ] Write test for token verification on backend; - [ ] Add profile page; - [ ] Finish auth/redirect notebook logic in gateway; - [ ] Add notebook state endpoints in gateway; - [ ] Add notebook state view in frontend; - [ ] Break this up into ~10 commits, targeting <= 200 LOC each (with first commit being checking in package-lock.json); - [ ] Deal with cross-origin tracking issues in Safari. This may require using the ""custom domains"" feature of auth0, paid. Workaround could be to poll/websocket request to api server to refresh tokens. . To run:; ```sh; cd packages/web-client; docker build . -t blah; docker run --env-file=env-example -p 3000:3000 blah npm run start; ```; then navigate to `http://localhost:3000`. \# lines: Most come from the package.json.lock files. These maintain versioning information.; * [It is recommended to check in .lock files]( https://stackoverflow.com/questions/44206782/do-i-commit-the-package-lock-json-file-created-by-npm-5); * They're huge, sorry.; # Documentation; ### JS; https://javascript.info. We use the subset termed [ES2018](https://flaviocopes.com/es2018/). Compatibility across all browsers is ensured by [transpilation using BabelJS, to some lower JS target](https://babeljs.io/docs/en/). Polyfills should not be used, except when impossible to support a browser (this is configurable). I mostly don't care about anything that isn't an evergreen browser, so I think we should support: Edge, Safari, Chrome, Firefox. A",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5162:354,log,logout,354,https://hail.is,https://github.com/hail-is/hail/pull/5162,4,"['log', 'test']","['logic', 'login', 'logout', 'test']"
Testability,"Let's chat today to make a plan for getting these reviewed. I certainly want to see size + performance benchmarks -- I'm more than a little concerned that this change by itself will be *slower* for the 1kg matrix tables -- you'll do several java object allocations per matrix entry to decode with these (for AD and PL arrays), where previously we were doing none.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7821#issuecomment-574201074:103,benchmark,benchmarks,103,https://hail.is,https://github.com/hail-is/hail/pull/7821#issuecomment-574201074,1,['benchmark'],['benchmarks']
Testability,"Let's compare 8093951-8854 to 8093977-8854. The latter is a failed task (partition 6914) the former is successful. We'll download the logs and make toss away some debug info that changed between the experiments. ```; cat log | rg StreamBlockInputBuffer: | sed 's/bytes.*//' > newlog; ```. Since the latter failed, the log obviously ends earlier, but there are *no differences* (besides timestamps) in the size of the blocks read from GCS. Since these block sizes are read from the input stream, this is pretty good evidence that the bytes aren't corrupted up until now. ```; # git diff --no-index --word-diff good bad ; ...; 2023-12-06 [-19:47:11.500-]{+21:39:00.885+} StreamBlockInputBuffer: INFO: reading 2081[-2023-12-06 19:47:11.531 StreamBlockInputBuffer: INFO: reading 2499-]; ```. The decompressed data size is the same: 65536. It's worth noting this is a relatively small compressed buffer after a series of much larger compressed buffers. This one is 2081 and the immediately previous one is 14675. Most of the ones before this are also in the 14k range. ---. Same experiment on job 7157 again shows no differences in bytes read before the exception occurs. ```; 2023-12-06 [-19:45:18.693-]{+21:36:52.116+} StreamBlockInputBuffer: INFO: reading 17923 ; 2023-12-06 [-19:45:18.809-]{+21:36:52.388+} StreamBlockInputBuffer: INFO: reading 17843[-2023-12-06 19:45:18.810 StreamBlockInputBuffer: INFO: reading 17657-]; [-2023-12-06 19:45:18.811 StreamBlockInputBuffer: INFO: reading 17646-]; ```. The network reads are identical other than the size of the first read. That first read is the serialized function. I'm not that surprised it differs in size between different commits of Hail. The byte counting is done in our code. If we're counting bytes correctly, then it seems like we're reading the same series of chunks from GCS. . ```; GoogleStorageFS$: INFO: read 1755052 (0 of 1755052) oldbb(0, 8388608) newbb(0, 1755052); GoogleStorageFS$: INFO: read 8388608 (62604 of 58870664) oldbb(0, 8388",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13979#issuecomment-1843799744:134,log,logs,134,https://hail.is,https://github.com/hail-is/hail/issues/13979#issuecomment-1843799744,3,['log'],"['log', 'logs']"
Testability,"Let's decide on the implemented functions that we want here, and then I will write the tests for those functions.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8518#issuecomment-611792254:87,test,tests,87,https://hail.is,https://github.com/hail-is/hail/pull/8518#issuecomment-611792254,1,['test'],['tests']
Testability,Let's get this in so we can try scaling up the service backend tests.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13030#issuecomment-1544607894:63,test,tests,63,https://hail.is,https://github.com/hail-is/hail/pull/13030#issuecomment-1544607894,1,['test'],['tests']
Testability,Let's keep the log statements as it's helpful for debugging order of events and context from the logs.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12622#issuecomment-1405267179:15,log,log,15,https://hail.is,https://github.com/hail-is/hail/pull/12622#issuecomment-1405267179,2,['log'],"['log', 'logs']"
Testability,"Let's make the change to avoid compression below a threshold, rerun benchmarks, and get this merged!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12981#issuecomment-1557742021:68,benchmark,benchmarks,68,https://hail.is,https://github.com/hail-is/hail/pull/12981#issuecomment-1557742021,1,['benchmark'],['benchmarks']
Testability,"Let's not turn off memory logs entirely. As we progress to NIST 800-53 compliance we need to log requests that use credentials like this. Instead, let's reduce the volume of bytes per-request. How much money do we spend on logs? We have to view them as necessary cost of business, but one that we can reduce in terms of reducing log volume.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12355#issuecomment-1284220591:26,log,logs,26,https://hail.is,https://github.com/hail-is/hail/pull/12355#issuecomment-1284220591,4,['log'],"['log', 'logs']"
Testability,Liftover logreg and lmmreg,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2783:9,log,logreg,9,https://hail.is,https://github.com/hail-is/hail/pull/2783,1,['log'],['logreg']
Testability,"Loader; E ImportError: cannot import name 'Markup' from 'jinja2' (/home/circleci/conda/envs/lib/python3.7/site-packages/jinja2/__init__.py); [error] java.lang.IllegalArgumentException: requirement failed: Python tests in Hail environment failed; [error] 	at scala.Predef$.require(Predef.scala:281); [error] 	at $1fb87e3247134917ca70$.$anonfun$pythonSettings$14(build.sbt:288); [error] 	at $1fb87e3247134917ca70$.$anonfun$pythonSettings$14$adapted(build.sbt:278); [error] 	at scala.Function1.$anonfun$compose$1(Function1.scala:49); [error] 	at sbt.internal.util.$tilde$greater.$anonfun$$u2219$1(TypeFunctions.scala:62); [error] 	at sbt.std.Transform$$anon$4.work(Transform.scala:67); [error] 	at sbt.Execute.$anonfun$submit$2(Execute.scala:280); [error] 	at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:19); [error] 	at sbt.Execute.work(Execute.scala:289); [error] 	at sbt.Execute.$anonfun$submit$1(Execute.scala:280); [error] 	at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178); [error] 	at sbt.CompletionService$$anon$2.call(CompletionService.scala:37); [error] 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); [error] 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); [error] 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); [error] 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); [error] 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); [error] 	at java.lang.Thread.run(Thread.java:748); [error] (hail / hailtest) java.lang.IllegalArgumentException: requirement failed: Python tests in Hail environment failed; ```. To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: ; https://discuss.hail.is/. Please include the full Hail version and as much detail as possible. -----------------------------------------------------------------------------",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11705:2336,test,tests,2336,https://hail.is,https://github.com/hail-is/hail/issues/11705,1,['test'],['tests']
Testability,"LocalMatrix follows NumPy's broadcast rules (restricted to two-dimensional ndarrays), and I've tried to mirror the Numpy interface for all functions where it's reasonable to do so. I still need time to add a bunch of Python tests of the interface, but I'd be glad for feedback/review in the meantime. In a subsequent PR, I'll expose the rest of BlockMatrix's binary ops in Python with the similar syntax and rules. These changes will provide the matrix functionality needed for a clean mixed models pipeline (modulo a few Scala black boxes that I can return to once I have something working) and will hopefully be generally useful for adding/porting more methods in Python. Current longer-term plan is to expose RowMatrix as well, and consider how to best unify the interfaces. And one day LocalMatrix will actually be a NumPy array...",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3064:224,test,tests,224,https://hail.is,https://github.com/hail-is/hail/pull/3064,1,['test'],['tests']
Testability,Log unsorted,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4207:0,Log,Log,0,https://hail.is,https://github.com/hail-is/hail/pull/4207,1,['Log'],['Log']
Testability,Logging improvements: log context calling Optimize and IR size,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5428:0,Log,Logging,0,https://hail.is,https://github.com/hail-is/hail/pull/5428,2,"['Log', 'log']","['Logging', 'log']"
Testability,Logging system,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/170:0,Log,Logging,0,https://hail.is,https://github.com/hail-is/hail/issues/170,1,['Log'],['Logging']
Testability,"Logic is: in case when data representation of a collection of fields doesn't change, and one simply needs a subset of those values, it makes no sense to copy all of those values to a different Region, instead cast. ```scala; val rvdLP = LocalLDPrune.pruneLocal(standardizedRDD, r2Threshold, windowSize, Some(maxQueueSize)). val fieldIndicesToAdd = Array(""locus"", ""alleles"", ""mean"", ""centered_length_rec""); .map(field => bpvType.fieldIdx(field)); val sitesOnly = rvdLP.mapPartitions(; tableType.canonicalRVDType; )({ it =>; val region = Region(); val rvb = new RegionValueBuilder(region); val newRV = RegionValue(region). it.map { rv =>; region.clear(); rvb.set(region); rvb.start(tableType.canonicalPType); rvb.startStruct(); // this should be a selected fields PStruct; rvb.addFields(bpvType, rv, fieldIndicesToAdd); rvb.endStruct(); newRV.setOffset(rvb.end()); newRV; }; }); ```. With something that looked more like this. ```scala; val rvdLP = LocalLDPrune.pruneLocal(standardizedRDD, r2Threshold, windowSize, Some(maxQueueSize)). val newRvdView = rvdLP.getViewFromSelectedFields(PSelectedFields(Array(""locus"", ""alleles"", ""mean"", ""centered_length_rec"".map(field => bpvType.fieldIdx(field))); ```. presumably the implementation would not only not copy, but also not re-partition the data; cc @tpoterba",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6601:0,Log,Logic,0,https://hail.is,https://github.com/hail-is/hail/issues/6601,1,['Log'],['Logic']
Testability,Login does not allow you to choose which user to log in as,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14634:0,Log,Login,0,https://hail.is,https://github.com/hail-is/hail/issues/14634,2,"['Log', 'log']","['Login', 'log']"
Testability,Logistic skat,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2153:0,Log,Logistic,0,https://hail.is,https://github.com/hail-is/hail/pull/2153,1,['Log'],['Logistic']
Testability,Logout is unauthorized except from auth.hail.is pages,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14635:0,Log,Logout,0,https://hail.is,https://github.com/hail-is/hail/issues/14635,1,['Log'],['Logout']
Testability,Look into the test failure.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1632#issuecomment-290947359:14,test,test,14,https://hail.is,https://github.com/hail-is/hail/pull/1632#issuecomment-290947359,1,['test'],['test']
Testability,"Looking at the corresponding `GEN` file, it looks like there's one missing value (first variant, first sample) and the rest of the values are close to 1. I think we're better off creating a new test dataset with random data. You can do this with `balding_nichols.export_gen` and then import/export with qctool.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3743#issuecomment-396568789:194,test,test,194,https://hail.is,https://github.com/hail-is/hail/pull/3743#issuecomment-396568789,1,['test'],['test']
Testability,"Looking at the logs, I think these two new states are because we added the log analytics agent based on when the PR merged and the absence of these errors before December 10th. ```; Unknown azure statuses [{'code': 'ProvisioningState/updating', 'level': 'Info', 'displayStatus': 'Updating'}, {'code': 'PowerState/running', 'level': 'Info', 'displayStatus': 'VM running'}] for instance batch-worker-default-standard-166xu; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11160:15,log,logs,15,https://hail.is,https://github.com/hail-is/hail/pull/11160,2,['log'],"['log', 'logs']"
Testability,Looking for some feedback and advice on what tests to build.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3285:45,test,tests,45,https://hail.is,https://github.com/hail-is/hail/pull/3285,1,['test'],['tests']
Testability,"Looking good. @daniel-goldstein follow up PR to enable service tests, yeah?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11617#issuecomment-1126245988:63,test,tests,63,https://hail.is,https://github.com/hail-is/hail/pull/11617#issuecomment-1126245988,1,['test'],['tests']
Testability,"Looking into this further. Python abstract methods are similar to Scala's in that they can have implementation, but less similar than my test had seemed to state. Python doc on abc:. """"""; Note Unlike Java abstract methods, these abstract methods may have an implementation. This implementation can be called via the super() mechanism from the class that overrides it. This could be useful as an end-point for a super-call in a framework that uses cooperative multiple-inheritance.; """""". However unlike Scala, even with an implementation, these need to be implemented by the subclass. I hadn't noticed the issue because our Backend didn't inherit from ABC. Fixed in https://github.com/hail-is/hail/pull/9192. ```python; In [25]: class Backend(abc.ABC): ; ...: """""" ; ...: Abstract class for backends. ; ...: """""" ; ...: @abc.abstractmethod ; ...: def close(self): ; ...: """""" ; ...: Close a Hail Batch backend. ; ...: """""" ; ...: return ""Parent"" ; ...: ; ...: ; ...: class LocalBackend(Backend): ; ...: """""" ; ...: Backend that executes batches on a local computer. ; ...: ; ...: Examples ; ...: -------- ; ...: ; ...: >>> local_backend = LocalBackend(tmp_dir='/tmp/user/') ; ...: >>> b = Batch(backend=local_backend) ; ...: ; ...: Parameters ; ...: ---------- ; ...: tmp_dir: :obj:`str`, optional ; ...: Temporary directory to use. ; ...: gsa_key_file: :obj:`str`, optional ; ...: Mount a file with a gsa key to `/gsa-key/key.json`. Only used if a ; ...: job specifies a docker image. This option will override the value set by ; ...: the environment variable `HAIL_BATCH_GSA_KEY_FILE`. ; ...: extra_docker_run_flags: :obj:`str`, optional ; ...: Additional flags to pass to `docker run`. Only used if a job specifies ; ...: a docker image. This option will override the value set by the environment ; ...: variable `HAIL_BATCH_EXTRA_DOCKER_RUN_FLAGS`. ; ...: """""" ; ...: ; ...: . In [26]: n = LocalBackend() ; ---------------------------------------------------------------------------; TypeError Traceback ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9191#issuecomment-667235187:137,test,test,137,https://hail.is,https://github.com/hail-is/hail/pull/9191#issuecomment-667235187,1,['test'],['test']
Testability,"Looking through the google doc I read Dan mentioning Iterators as returns types and since this is a list we are iterating through, I thought I should test it to see if the return type for Iterable would work and it did pass.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11438#issuecomment-1057178415:150,test,test,150,https://hail.is,https://github.com/hail-is/hail/pull/11438#issuecomment-1057178415,1,['test'],['test']
Testability,Looks fine to me. We pretty much just use MJS/MJC and rate limit logs from NGINX for monitoring,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11904#issuecomment-1164670659:65,log,logs,65,https://hail.is,https://github.com/hail-is/hail/pull/11904#issuecomment-1164670659,1,['log'],['logs']
Testability,"Looks good but tests are failing, maybe related to https://github.com/hail-is/hail/pull/1538?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1532#issuecomment-286491775:15,test,tests,15,https://hail.is,https://github.com/hail-is/hail/pull/1532#issuecomment-286491775,1,['test'],['tests']
Testability,"Looks good to me. > It's going to be painful to get logistic to take no covariates. This isn't immediately obvious to me. Can you say a word or two about why?. I think we thought default `covariates=[1.0]` was misleading because for no covariates with intercept you don't have to add it, but with multiple you do. You'll make a discuss post about the breaking change?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4067#issuecomment-410486374:52,log,logistic,52,https://hail.is,https://github.com/hail-is/hail/pull/4067#issuecomment-410486374,1,['log'],['logistic']
Testability,"Looks good! ; - There's a couple of places where we use `hl.array()` for our own methods, e.g. `Table.to_matrix_table` and the vcf_combiner that I think are just conceptually ""turn this set/dict into an array, please"" as opposed to casting out of convenience (like we did for filter, etc. before this PR).; - I think as we add more representations for array/set/dict the CastToArray logic will just need to take into account the pType that it's casting to/from accordingly; it'll therefore still ""work"" but won't always return a sorted array or guarantee an ordering (which I think we shouldn't consider part of the semantics anyways); - I don't know that ArrayRef makes sense on general Set/Dict objects directly anyways, since they don't conceptually have a well-defined element order (I think a lot of languages don't let you index into sets/dicts by index, right?). I think I'd agree that ArrayLen should work on everything.; - I'm kind of in favor of introducing companion StreamRef/StreamLen nodes for ArrayRef/ArrayLen to work on streams, just because they'll look very distinct in the generated code.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8171#issuecomment-592681047:383,log,logic,383,https://hail.is,https://github.com/hail-is/hail/pull/8171#issuecomment-592681047,1,['log'],['logic']
Testability,Looks good! Next steps:. - Use it!; - Test it! I'm not sure how much will break.; - Time it! Do something simple filter genotypes gq >= 20 and a sampleqc or something. Does it help? How much?; - Figure out how you're going to deal with annotations like `va.rare_genos = gs.filter(g => ... some rare condition ...).collect()`.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1322#issuecomment-276272639:38,Test,Test,38,https://hail.is,https://github.com/hail-is/hail/pull/1322#issuecomment-276272639,1,['Test'],['Test']
Testability,"Looks great, aside from Value.fromLIR stuff which I think is causing test failures.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10791#issuecomment-901427655:69,test,test,69,https://hail.is,https://github.com/hail-is/hail/pull/10791#issuecomment-901427655,1,['test'],['test']
Testability,"Looks great. Any chance you can add Firth's logistic regression?. Thanks,. Manny. On Sun, Aug 14, 2016 at 12:58 PM, jbloom22 notifications@github.com wrote:. > jenkins; > ; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > https://github.com/broadinstitute/hail/pull/585#issuecomment-239684133,; > or mute the thread; > https://github.com/notifications/unsubscribe-auth/ABPl2UH8kO3OSrp-6XTXAAacpxxSI9Z2ks5qf0kdgaJpZM4Jje3f; > .",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/585#issuecomment-239686067:44,log,logistic,44,https://hail.is,https://github.com/hail-is/hail/pull/585#issuecomment-239686067,1,['log'],['logistic']
Testability,"Looks like a typo: you wrote ""scr/test/resources/sample.vcf"" instead of ""src/test/resources/sample.vcf""",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1377#issuecomment-279429609:34,test,test,34,https://hail.is,https://github.com/hail-is/hail/issues/1377#issuecomment-279429609,2,['test'],['test']
Testability,Looks like it needs a rebase before it can rerun the tests. I'll take another look once it is passing.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2556#issuecomment-351586270:53,test,tests,53,https://hail.is,https://github.com/hail-is/hail/pull/2556#issuecomment-351586270,1,['test'],['tests']
Testability,Looks like some test are failing for real though.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6557#issuecomment-513264991:16,test,test,16,https://hail.is,https://github.com/hail-is/hail/pull/6557#issuecomment-513264991,1,['test'],['test']
Testability,Looks like something went wrong in the PR tests that seems unrelated to the PR. I haven't seen those tests fail before.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13399#issuecomment-1672018783:42,test,tests,42,https://hail.is,https://github.com/hail-is/hail/pull/13399#issuecomment-1672018783,2,['test'],['tests']
Testability,"Looks like something went wrong with an always_run cancel step, but there's not enough information in the logs to figure out why.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7886#issuecomment-574813098:106,log,logs,106,https://hail.is,https://github.com/hail-is/hail/pull/7886#issuecomment-574813098,1,['log'],['logs']
Testability,Looks like test failure is due to needing to wrap phenotype in array in this line; `top_5_pvals = (vds.linreg('sa.metadata.CaffeineConsumption')`; of; https://github.com/hail-is/hail/blob/master/python/hail/docs/tutorials/expression-language-part-2.ipynb,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2042#issuecomment-318833001:11,test,test,11,https://hail.is,https://github.com/hail-is/hail/pull/2042#issuecomment-318833001,1,['test'],['test']
Testability,"Looks like the ops agent [also does logging](https://cloud.google.com/stackdriver/docs/solutions/agents/ops-agent) in addition to monitoring. The logging agent we're using now is considered legacy, we should probably switch everything over to this new agent.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13949#issuecomment-1789790392:36,log,logging,36,https://hail.is,https://github.com/hail-is/hail/pull/13949#issuecomment-1789790392,2,['log'],['logging']
Testability,"Looks like there were some more `hl._nd`'s around in tests. Sorry about that, I can fix if you'd like.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9061#issuecomment-655652327:53,test,tests,53,https://hail.is,https://github.com/hail-is/hail/pull/9061#issuecomment-655652327,1,['test'],['tests']
Testability,Looks like there's a typo in the new test.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8286#issuecomment-597807644:37,test,test,37,https://hail.is,https://github.com/hail-is/hail/pull/8286#issuecomment-597807644,1,['test'],['test']
Testability,"Looks like this has failures and needs a rebase. Your PR stack is getting pretty high so let's keep the bottom moving. Also, I rebased my lir branch on Value[T] and now I'm passing the asm4s tests and most other tests are failing on joinpoint which I didn't port. So this stack is now a blocker for me to resume that thread.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8156#issuecomment-594495172:191,test,tests,191,https://hail.is,https://github.com/hail-is/hail/pull/8156#issuecomment-594495172,4,['test'],['tests']
Testability,"Looks like this:; ```; (py37) dking@wmb16-359 # ./install-gcs-connector.sh . To set the active account, run:; $ gcloud config set account `ACCOUNT`. created key [bd10c2da666d327144166cc71ba13075dbd7ea26] of type [json] as [/Users/dking/.hail/gcs-keys/gcs-connector-key.json] for [842871226259-compute@developer.gserviceaccount.com]; mkdir: /Users/dking/anaconda2/envs/py37/lib/python3.7/site-packages/pyspark/conf: File exists; success; ```; I tested it by running `python -c 'import hail as hl; hl.read_table(""gs://danking/gnomad-test.mt"").describe()'`",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4500:444,test,tested,444,https://hail.is,https://github.com/hail-is/hail/pull/4500,2,['test'],"['test', 'tested']"
Testability,"Looks like we have a test where we pass `missing=""""` that used to work, so I'm doing something wrong here or misunderstanding something. Will investigate and get back to you.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11078#issuecomment-975612089:21,test,test,21,https://hail.is,https://github.com/hail-is/hail/pull/11078#issuecomment-975612089,1,['test'],['test']
Testability,Looks like we need to update the tests too.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7361#issuecomment-545585187:33,test,tests,33,https://hail.is,https://github.com/hail-is/hail/pull/7361#issuecomment-545585187,1,['test'],['tests']
Testability,"Looks like we probably want to add the following to benchmark somewhere:. ```; export MKL_NUM_THREADS=1; export NUMEXPR_NUM_THREADS=1; export OPENBLAS_NUM_THREADS=1; export OMP_NUM_THREADS=1; export VECLIB_MAXIMUM_THREADS=1; ```. Trying to test if setting veclib lower fixes things, but apparently Apple caches the result of the environment variable somewhere so it's unclear whether me setting it is working",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8050#issuecomment-583412384:52,benchmark,benchmark,52,https://hail.is,https://github.com/hail-is/hail/pull/8050#issuecomment-583412384,2,"['benchmark', 'test']","['benchmark', 'test']"
Testability,Looks like you need the globals too. Two concerns:; 1. Does localize entries not produce a table aggregate?; 2. Does this preserve the column ordering that we all agreed on? Is that tested?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13405#issuecomment-1673279690:182,test,tested,182,https://hail.is,https://github.com/hail-is/hail/pull/13405#issuecomment-1673279690,1,['test'],['tested']
Testability,"Looks my comment got lost! Sorry. I said, I'd prefer we didn't copy the HailContext whole hog, but just write a simple wrapper that calls from hail2.HailContext to hail.HailContext, so something like:. ```; class HailContext:; def __init__(args...):; self.hc1 = hail.HailContext(args...). def import_bgen(args...):; return self.hc1.import_bgen(args...).to_hail2(); ```. etc. I don't think you even need docs unless there is something specifically different between the two. That way, we won't need to maintain two versions for things like doc changes and we won't get confused about which one is the ""real"" HailContext. Then, when we're ready to switch over, we can pull the docs across and throw away the stub.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2244#issuecomment-337717963:706,stub,stub,706,https://hail.is,https://github.com/hail-is/hail/pull/2244#issuecomment-337717963,2,['stub'],['stub']
Testability,Loop.onStop(DAGScheduler.scala:1732); at org.apache.spark.util.EventLoop.stop(EventLoop.scala:83); at org.apache.spark.scheduler.DAGScheduler.stop(DAGScheduler.scala:1651); at org.apache.spark.SparkContext$$anonfun$stop$8.apply$mcV$sp(SparkContext.scala:1921); at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1317); at org.apache.spark.SparkContext.stop(SparkContext.scala:1920); at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581); at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216); at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188); at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188); at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188); at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1954); at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188); at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188); at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188); at scala.util.Try$.apply(Try.scala:192); at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188); at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178); at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54); at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2022); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2043); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2062); at org.apache.spark.SparkContext.runJob(SparkContext.scala:2087); at ,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4755:4685,log,logUncaughtExceptions,4685,https://hail.is,https://github.com/hail-is/hail/issues/4755,1,['log'],['logUncaughtExceptions']
Testability,"Lots of tests failing, this isn't quite right yet.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9570#issuecomment-704990030:8,test,tests,8,https://hail.is,https://github.com/hail-is/hail/pull/9570#issuecomment-704990030,1,['test'],['tests']
Testability,"MER_HANDLES_FRACTION):; # Remove delayed calls that were cancelled if their number; # is too high; new_scheduled = []; for handle in self._scheduled:; if handle._cancelled:; handle._scheduled = False; else:; new_scheduled.append(handle); ; heapq.heapify(new_scheduled); self._scheduled = new_scheduled; self._timer_cancelled_count = 0; else:; # Remove delayed calls that were cancelled from head of queue.; while self._scheduled and self._scheduled[0]._cancelled:; self._timer_cancelled_count -= 1; handle = heapq.heappop(self._scheduled); handle._scheduled = False; ; timeout = None; if self._ready or self._stopping:; timeout = 0; elif self._scheduled:; # Compute the desired timeout.; when = self._scheduled[0]._when; timeout = min(max(0, when - self.time()), MAXIMUM_SELECT_TIMEOUT); ; if self._debug and timeout != 0:; t0 = self.time(); event_list = self._selector.select(timeout); dt = self.time() - t0; if dt >= 1.0:; level = logging.INFO; else:; level = logging.DEBUG; nevent = len(event_list); if timeout is None:; logger.log(level, 'poll took %.3f ms: %s events',; dt * 1e3, nevent); elif nevent:; logger.log(level,; 'poll %.3f ms took %.3f ms: %s events',; timeout * 1e3, dt * 1e3, nevent); elif dt >= 1.0:; logger.log(level,; 'poll %.3f ms took %.3f ms: timeout',; timeout * 1e3, dt * 1e3); else:; event_list = self._selector.select(timeout); self._process_events(event_list); ; # Handle 'later' callbacks that are ready.; end_time = self.time() + self._clock_resolution; while self._scheduled:; handle = self._scheduled[0]; if handle._when >= end_time:; break; handle = heapq.heappop(self._scheduled); handle._scheduled = False; self._ready.append(handle); ; # This is the only place where callbacks are actually *called*.; # All other places just add them to ready.; # Note: We run all currently scheduled callbacks, but not any; # callbacks scheduled by callbacks run this time around --; # they will be run the next time (after another I/O poll).; # Use an idiom that is thread-safe wi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10705:2869,log,logger,2869,https://hail.is,https://github.com/hail-is/hail/pull/10705,1,['log'],['logger']
Testability,"Mac didn't show these, missed it. I need to create a better testing system for UI. . overflow: scroll can force the browser to show scrollbars even when they are not necessary.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7992:60,test,testing,60,https://hail.is,https://github.com/hail-is/hail/pull/7992,1,['test'],['testing']
Testability,Made a new PR so I can test on CI without reauthorizing repeatedly. I'll assign Patrick again once I've finished addressing all his previous comments,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7823:23,test,test,23,https://hail.is,https://github.com/hail-is/hail/pull/7823,1,['test'],['test']
Testability,"Made all discussed changes and then some, except HailCheck tests. Added symbolic variant check / filter, but we should still talk about the PL(GT) != 0 genotypes in GoT2D.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/210#issuecomment-192798627:59,test,tests,59,https://hail.is,https://github.com/hail-is/hail/pull/210#issuecomment-192798627,1,['test'],['tests']
Testability,Made logreg completely generic.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2334:5,log,logreg,5,https://hail.is,https://github.com/hail-is/hail/pull/2334,1,['log'],['logreg']
Testability,Made relevant field and function names pythonic and consistent along the way. I've ported the TDT python implementation and test quite literally. The implementation should use sum on arrays but isn't yet properly exposed in api2. I'm confused why -1 is used as a ploidy but will leave further improvements for later.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2768:124,test,test,124,https://hail.is,https://github.com/hail-is/hail/pull/2768,1,['test'],['test']
Testability,"Made some logging improvements to the combiner in the process of; understanding the various components. Benchmarks, docs, perf.; improvements are next. Simple example of merging three GVCFs:. ```; 2020-03-27 15:17:58 Hail: INFO: GVCF combiner plan:; Branch factor: 2; Batch size: 2; Combining 3 input files in 2 phases with 2 total jobs.; Phase 1: 1 job corresponding to 2 intermediate output files.; Phase 2: 1 job corresponding to 1 final output file. 2020-03-27 15:17:58 Hail: INFO: Starting phase 1/2, merging 3 input GVCFs in 1 job.; 2020-03-27 15:17:58 Hail: INFO: Starting job 1/1 to create 2 merged files, corresponding to ~50.0% of total I/O.; 2020-03-27 15:21:20 Hail: INFO: Finished job 1/1, 50.0% of total I/O finished.; 2020-03-27 15:21:20 Hail: INFO: Finished phase 1/2.; 2020-03-27 15:21:20 Hail: INFO: Starting phase 2/2, merging 2 intermediate sparse matrix tables in 1 job.; 2020-03-27 15:21:27 Hail: INFO: Starting job 1/1 to create 1 merged file, corresponding to ~50.0% of total I/O.; 2020-03-27 15:24:47 Hail: INFO: wrote matrix table with 47031230 rows and 3 columns in 33 partitions to combiner_out.mt; 2020-03-27 15:24:47 Hail: INFO: Finished job 1/1, 100.0% of total I/O finished.; 2020-03-27 15:24:47 Hail: INFO: Finished phase 2/2.; 2020-03-27 15:24:47 Hail: INFO: Finished!; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8378:10,log,logging,10,https://hail.is,https://github.com/hail-is/hail/pull/8378,2,"['Benchmark', 'log']","['Benchmarks', 'logging']"
Testability,"Made the following changes:. - Disabled dataproc tests; - Moved dataproc tests to Makefile, to be run before manual deploys; - Add back VEP cluster test script; - Removed cloudtools config files; - Removed the latest-build functionality; - Added VEP scripts to hailctl/dataproc/resources; - Changed init_notebook to pip install hail wheels, picking up; dependencies automatically; - add out-of-date check (once per day) to hailctl startup",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6250:49,test,tests,49,https://hail.is,https://github.com/hail-is/hail/pull/6250,3,['test'],"['test', 'tests']"
Testability,"Made this change backwards compatible. Note that I have not made any changes to worker.py in this PR anymore, so there's no danger of incompatibility. I tested the JAR from this PR against default and ran a simple hail query to see that it behaved as usual. Separately, I made #12246, dev deployed it, then ran this same JAR against my dev namespace to see that it added all worker jobs to the same batch as the driver job.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12222#issuecomment-1262670715:153,test,tested,153,https://hail.is,https://github.com/hail-is/hail/pull/12222#issuecomment-1262670715,2,['test'],['tested']
Testability,"Made two small comments, but they're a typo and an organization of tests comment. I'm fine with the code here, and happy with the tests. Just leaves @cseed to sign off on this",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1895#issuecomment-312331956:67,test,tests,67,https://hail.is,https://github.com/hail-is/hail/pull/1895#issuecomment-312331956,2,['test'],['tests']
Testability,"Main change: add `var mark: Int` to `BaseIR`.; On profiling the benchmark `matrix_multi_write_nothing`, I noticed a significant amount of time was spent ; - iterating through zipped arrays in requiredness ; - Adding and removing elements from `HashSet`s.; In fact, half the time spent in requiredness was removing ir nodes from the `HashSet` set used as the queue! With this change, requiredness runs like a stabbed rat!. Explanation of `mark`:; This field acts as a flag that analyses can set. For example:; - `HasSharing` can use the field to see if it has visited a node before.; - `Requiredness` uses this field to tell if a node is currently enqueued. The `nextFlag` method in `IrMetadata` allows for analyses to get a fresh value they can set the `mark` field. ; This removes the need to traverse the IR after analyses to re-zero every `mark` field.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13991:64,benchmark,benchmark,64,https://hail.is,https://github.com/hail-is/hail/pull/13991,1,['benchmark'],['benchmark']
Testability,"Major Changes:; - never delete CI jobs, only cancel them; - Mergeable (success) and Failure build states include the job that triggered the build state; - if a PR's build state has a job, link to that job. Minor Changes:; - fix location of dk-test instance; - test that proxy processes are still alive (if proxy creation fails, the process usually exits); - provide `HAIL_CI_GCS_PATH` for developers to set an alternative deploy bucket and path-within-bucket (now that `gs://hail-ci-0-1` is protected)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5054:243,test,test,243,https://hail.is,https://github.com/hail-is/hail/pull/5054,2,['test'],['test']
Testability,Make gradle command to make hail docs without running tests,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1472:54,test,tests,54,https://hail.is,https://github.com/hail-is/hail/issues/1472,1,['test'],['tests']
Testability,Make it easier to get to the change log from Hail's PyPI project page.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10459:36,log,log,36,https://hail.is,https://github.com/hail-is/hail/pull/10459,1,['log'],['log']
Testability,Make it easy to test just scala or just python code,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1385:16,test,test,16,https://hail.is,https://github.com/hail-is/hail/issues/1385,1,['test'],['test']
Testability,"Makes it easy to see failing tests, stack traces, and timings.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4752:29,test,tests,29,https://hail.is,https://github.com/hail-is/hail/pull/4752,1,['test'],['tests']
Testability,"Makes some further progress on simplifying the `PruneDeadFields` pass, with the primary goal of decoupling it from the details of the binding structure. The primary change is to `memoizeValueIR`. Before, it passed in only the requested type of the node, and returned and environment containing all free variables and their requested types. Any bound variables would then need to be removed, and the environments of all children then merged. This low-level manipulation of environments made it closely tied to the binding structure, essentially redundantly encoding everything in `Binds.scala`. Now we pass an environment down into the children, which maps variables to a mutable state tracking the requested type. Each `Ref` node unions the requested type at the reference with the state in the environment. This lets us use the general environment infrastructure. I didn't do an assertion directly comparing the old and new implementations, as I've done with some other pass rewrites. But `PruneDeadFields` has pretty good test coverage.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14509:880,assert,assertion,880,https://hail.is,https://github.com/hail-is/hail/pull/14509,2,"['assert', 'test']","['assertion', 'test']"
Testability,Making one change with all of the SQL packages needed so I can speed up testing of other branches.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5616:72,test,testing,72,https://hail.is,https://github.com/hail-is/hail/pull/5616,1,['test'],['testing']
Testability,"Many of our tests look like:. ```scala; // ExprSuite.scala; assert(eval[Int](""a[0]"").contains(1)); assert(eval[Int](""a[1]"").contains(2)); assert(eval[Int](""a[2]"").isEmpty); assert(eval[Int](""a[3]"").contains(6)); assert(eval[Int](""a[-1]"").contains(8)); assert(eval[Int](""a[-2]"").contains(-1)); ```. Test failures from these expressions simply state that the result was not as expected. If these tests were instead written as below,. ```scala; assert(eval[Int](""a[0]"") == Some(1)); assert(eval[Int](""a[1]"") == Some(2)); assert(eval[Int](""a[2]"") == None); assert(eval[Int](""a[3]"") == Some(6)); assert(eval[Int](""a[-1]"") == Some(8)); assert(eval[Int](""a[-2]"") == Some(-1)); ```; then test failures would print both the expected value and the actual value:; ```; org.scalatest.exceptions.TestFailedException: Some(7) did not equal Some(1); ```. Furthermore, there are a tools in the [scalatest library](http://www.scalatest.org/at_a_glance/FlatSpec) which enable richer specifications. Suppose that Hail included a `randInt : (Int, Int) => Int` function, we might like to verify that this is true:. ```scala; eval[Int](""randInt(0, 10) * 2 + 1"") should (be > 0 and be (even)); ```. When this expression fails, the messages look like:. ```; org.scalatest.exceptions.TestFailedException: 7 was greater than 0, but 7 was odd; ```. These natural language matchers are a bit finicky. I'm not sure if I like them, but I do like having nice error messages.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1286:12,test,tests,12,https://hail.is,https://github.com/hail-is/hail/issues/1286,18,"['Test', 'assert', 'test']","['Test', 'TestFailedException', 'assert', 'test', 'tests']"
Testability,"Master fails with `read -i sample.vcf write -o sample.vds` in schema reflection in the Parquet writer:. ```; running: import -i /Users/cseed/sample.vcf; running: write -o /Users/cseed/sample.vds; Exception in thread ""main"" java.lang.AssertionError: assertion failed: Unsound substitution from List(type T) to List(); at scala.reflect.internal.Types$SubstMap.<init>(Types.scala:4644); at scala.reflect.internal.Types$SubstTypeMap.<init>(Types.scala:4761); at scala.reflect.internal.Types$Type.subst(Types.scala:796); at scala.reflect.internal.Types$TypeApiImpl.substituteTypes(Types.scala:321); at scala.reflect.internal.Types$TypeApiImpl.substituteTypes(Types.scala:298); ```. and so on. I'm guessing this has to do with the doubly-nested Maps. The following fixes the problem (but of course throws out all the annotations):. ```; diff --git a/src/main/scala/org/broadinstitute/hail/variant/VariantSampleMatrix.scala b/src/main/scala/org/broadinstitute/hail/variant/VariantSampleMatrix.scala; index 2c95bd0..c480c86 100644; --- a/src/main/scala/org/broadinstitute/hail/variant/VariantSampleMatrix.scala; +++ b/src/main/scala/org/broadinstitute/hail/variant/VariantSampleMatrix.scala; @@ -30,7 +30,7 @@ object VariantSampleMatrix {; // val df = sqlContext.read.parquet(dirname + ""/rdd.parquet""); val df = sqlContext.parquetFile(dirname + ""/rdd.parquet""); new VariantSampleMatrix[Genotype](metadata, df.rdd.map(r =>; - (r.getVariant(0), r.getVariantAnnotations(1), r.getGenotypeStream(2)))); + (r.getVariant(0), Annotations.emptyOfData(), r.getGenotypeStream(1)))); }; }. @@ -326,7 +326,7 @@ class RichVDS(vds: VariantDataset) {. // rdd.toDF().write.parquet(dirname + ""/rdd.parquet""); vds.rdd; - .map { case (v, va, gs) => (v, va, gs.toGenotypeStream(v, compress)) }; + .map[(Variant, GenotypeStream)] { case (v, va, gs) => (v, gs.toGenotypeStream(v, compress)) }; .toDF(); .saveAsParquetFile(dirname + ""/rdd.parquet""); }; ```. You should probably serialize the Annotations in some way in the map before",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/116:233,Assert,AssertionError,233,https://hail.is,https://github.com/hail-is/hail/issues/116,2,"['Assert', 'assert']","['AssertionError', 'assertion']"
Testability,Master is failing because of this. Somehow the CI server tested the wrong thing...,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3877#issuecomment-401561153:57,test,tested,57,https://hail.is,https://github.com/hail-is/hail/pull/3877#issuecomment-401561153,1,['test'],['tested']
Testability,MatrixEntriesTable didn't define `uid_field_name` in `_handle_randomness`. Downstream operations failed to fetch the field and inserted a NA into `RNGSplit`. Assert that TableIRs define `uid_field_name` when provided to `handle_randomness`. Fixes: #14303,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14371:158,Assert,Assert,158,https://hail.is,https://github.com/hail-is/hail/pull/14371,1,['Assert'],['Assert']
Testability,"Maximal independent set has had a bug/misfeature since https://github.com/hail-is/hail/pull/2975. That PR added an `hl.int64(...)` coercion around the tie_breaker function. This allowed users to pass tie_breakers that returned floating point numbers, but it *changed the meaning*. The sign of values with magnitude greater than or equal to one was preserved. All values in (-1, 1) were converted to 0, thus treating them as indistinguishable for the purposes of the MIS. This PR fixes this long standing bug and adds a simple test for that case. Supporting arbitrary numeric types is actually quite simple! The conversion from any Hail numeric type to float64 is sign-preserving (AFAIK), which is the only property we need to preserve the user's intended ordering. This change also introduces two mild, obvious performance improvements:; - Use one region for the entire MIS calculation, clearing for each invocation of tie_breaker (MIS is single-threaded); - Read the tie_breaker value using simple Region and type methods rather than allocating a new SafeRow each time the tie_breaker is invoked.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7729:526,test,test,526,https://hail.is,https://github.com/hail-is/hail/pull/7729,1,['test'],['test']
Testability,Maybe Redirect to Hail CI PR test pods,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4417:29,test,test,29,https://hail.is,https://github.com/hail-is/hail/pull/4417,1,['test'],['test']
Testability,Maybe just comment out the ndarray tests? I'm going to use them in near future,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7002#issuecomment-528628851:35,test,tests,35,https://hail.is,https://github.com/hail-is/hail/pull/7002#issuecomment-528628851,1,['test'],['tests']
Testability,Maybe ought to wait for #8649 to go in so I can add tests that depend on keying.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8665#issuecomment-621867329:52,test,tests,52,https://hail.is,https://github.com/hail-is/hail/pull/8665#issuecomment-621867329,1,['test'],['tests']
Testability,Maybe redirect test-ci to k8s pods,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4427:15,test,test-ci,15,https://hail.is,https://github.com/hail-is/hail/pull/4427,1,['test'],['test-ci']
Testability,Maybe we could keep a list here of things that we notice don't have a log message as we notice them?,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1616#issuecomment-294024200:70,log,log,70,https://hail.is,https://github.com/hail-is/hail/issues/1616#issuecomment-294024200,1,['log'],['log']
Testability,"Maybe? We have an assertion in `TextMatrixReader.parseOptionalValue` that the missing values are not empty strings. I didn't trace through why, I just moved the error up.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11078#issuecomment-975610252:18,assert,assertion,18,https://hail.is,https://github.com/hail-is/hail/pull/11078#issuecomment-975610252,1,['assert'],['assertion']
Testability,Memoize parseToAST to Improve Test Speed,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3450:30,Test,Test,30,https://hail.is,https://github.com/hail-is/hail/pull/3450,1,['Test'],['Test']
Testability,Memory is a major source of logs which we never look at.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11976:28,log,logs,28,https://hail.is,https://github.com/hail-is/hail/pull/11976,1,['log'],['logs']
Testability,Meredith needs the former and I need the latter. I'll add Python tests of all block matrix functionality in subsequent broadcasting PR.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3086:65,test,tests,65,https://hail.is,https://github.com/hail-is/hail/pull/3086,1,['test'],['tests']
Testability,Missed this when updating MatrixRead. Main goal; here is not to dump out JSON partition intervals; a bunch of times in the log files.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10560:123,log,log,123,https://hail.is,https://github.com/hail-is/hail/pull/10560,1,['log'],['log']
Testability,Mmm. Yes. I need a more robust IR testing plan. I think testing these individually will be more painful than testing them in the context of IR expressions.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2514#issuecomment-349092532:34,test,testing,34,https://hail.is,https://github.com/hail-is/hail/pull/2514#issuecomment-349092532,3,['test'],['testing']
Testability,More details at #8058. - Include the user's IP in the site logs.; - Fix out of date Makefile. I recognize there's duplication of log format. Abstracting over that doesn't seem *that* valuable and requires putting the shared configuration into a file in the root of hail and then arranging for the shared config file to be in the docker context. It's all kind of annoying and seems low value.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8059:59,log,logs,59,https://hail.is,https://github.com/hail-is/hail/pull/8059,2,['log'],"['log', 'logs']"
Testability,"More extensive cloud tests are showing speedups in the combiner pipeline compared to master, about 15-20 seconds per partition, but that adds up quickly at scale.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5828#issuecomment-481367173:21,test,tests,21,https://hail.is,https://github.com/hail-is/hail/pull/5828#issuecomment-481367173,1,['test'],['tests']
Testability,More index btree array position tests,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3807:32,test,tests,32,https://hail.is,https://github.com/hail-is/hail/pull/3807,1,['test'],['tests']
Testability,More informative assertion in MatrixNativeReader,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4749:17,assert,assertion,17,https://hail.is,https://github.com/hail-is/hail/pull/4749,1,['assert'],['assertion']
Testability,More logging messages.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9504:5,log,logging,5,https://hail.is,https://github.com/hail-is/hail/pull/9504,1,['log'],['logging']
Testability,More parallelism for service backend tests,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11860:37,test,tests,37,https://hail.is,https://github.com/hail-is/hail/pull/11860,1,['test'],['tests']
Testability,More tests => lower mean => more even distribution of time across jobs => lower mean test job time,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11449:5,test,tests,5,https://hail.is,https://github.com/hail-is/hail/pull/11449,2,['test'],"['test', 'tests']"
Testability,More thorough Blanczos Tests,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9513:23,Test,Tests,23,https://hail.is,https://github.com/hail-is/hail/pull/9513,1,['Test'],['Tests']
Testability,MoreThanMaxInt$(FSSuite.scala:321); 	at is.hail.fs.gs.GoogleStorageFSSuite.testSeekMoreThanMaxInt(GoogleStorageFSSuite.scala:12); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:696); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:882); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1189); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:767); 	at org.testng.TestRunner.run(TestRunner.java:617); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:348); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:343); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:305); 	at org.testng.SuiteRunner.run(SuiteRunner.java:254); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1224); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1149); 	at org.testng.TestNG.run(TestNG.java:1057); 	at org.testng.TestNG.privateMain(TestNG.java:1364); 	at org.testng.TestNG.main(TestNG.java:1333); 	Suppressed: is.hail.relocated.com.google.cloud.storage.StorageException: Unable to recover in upload.; This may be a symptom of multiple clients uploading to the same upload session. For debugging purposes:; uploadId: https://storage.googleapis.com/upload/storage/v1/b/hail-test-ezlis/o?name=fs-suite-tmp-6BO4gZ18Lheigp3ir9RSOh&uploadType=resumable&upload_id=ADPycduiXx2Jt,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12950#issuecomment-1544209756:4186,test,testng,4186,https://hail.is,https://github.com/hail-is/hail/issues/12950#issuecomment-1544209756,2,['test'],['testng']
Testability,MoreThanMaxInt$(FSSuite.scala:339); 	at is.hail.fs.gs.GoogleStorageFSSuite.testSeekMoreThanMaxInt(GoogleStorageFSSuite.scala:12); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:696); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:882); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1189); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:767); 	at org.testng.TestRunner.run(TestRunner.java:617); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:348); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:343); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:305); 	at org.testng.SuiteRunner.run(SuiteRunner.java:254); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1224); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1149); 	at org.testng.TestNG.run(TestNG.java:1057); 	at org.testng.TestNG.privateMain(TestNG.java:1364); 	at org.testng.TestNG.main(TestNG.java:1333); 	Suppressed: is.hail.relocated.com.google.cloud.storage.StorageException: Unable to recover in upload.; This may be a symptom of multiple clients uploading to the same upload session. For debugging purposes:; uploadId: https://storage.googleapis.com/upload/storage/v1/b/hail-test-ezlis/o?name=fs-suite-tmp-2LzGioRNy6RqIS2pfXIoSO&uploadType=resumable&upload_id=ADPycdvZ5HhnG,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12950#issuecomment-1704346911:4379,test,testng,4379,https://hail.is,https://github.com/hail-is/hail/issues/12950#issuecomment-1704346911,1,['test'],['testng']
Testability,"Moreover, this issue appears to not be due to Breeze 0.12 natives:. ```; SPARK_HOME=/Users/dking/borg/spark-2.1.0-bin-hadoop2.7 gradle test --tests 'is.hail.methods.LinearMixedRegressionSuite.genAndFitLMM' -Dspark.version=2.1.0 -Dcom.github.fommil.netlib.BLAS=com.github.fommil.netlib.F2jBLAS -Dcom.github.fommil.netlib.LAPACK=com.github.fommil.netlib.F2jLAPACK -Dcom.github.fommil.netlib.ARPACK=com.github.fommil.netlib.F2jARPACK; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1419#issuecomment-281763304:135,test,test,135,https://hail.is,https://github.com/hail-is/hail/issues/1419#issuecomment-281763304,2,['test'],"['test', 'tests']"
Testability,"Most of the functionality was already available in EmitFunctionBuilder, but Compile() didn't make it available. This PR creates a `PrintWriter` during assertEvalsTo if you set the `jvm_bytecode_dump` flag to a file path you want the bytecode to be written to. Example:; ```scala; HailContext.setFlag(""jvm_bytecode_dump"", ""arr_filter_bytecode.java""); assertEvalsTo(ArrayFilter(a, ""x"",; ApplyComparisonOp(LT(TInt32()), Ref(""x"", TInt32()), I32(6))), FastIndexedSeq(3)); HailContext.setFlag(""jvm_bytecode_dump"", null); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7199:151,assert,assertEvalsTo,151,https://hail.is,https://github.com/hail-is/hail/pull/7199,2,['assert'],['assertEvalsTo']
Testability,"Mostly code reorg. Also:. moved rewriters to ir objects; call Optimize before intepreting; removed Filter{Rows, Cols} rules (non-IR), those should get folded back into the MT methods like other AST-based rules; re-enabled Fitler{Rows, Cols}IR fusion rules since logical and/or is back",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3330:262,log,logical,262,https://hail.is,https://github.com/hail-is/hail/pull/3330,1,['log'],['logical']
Testability,"Mostly random bugs that didn't get flexed until trying to run CI jobs and batch tests within jobs.; - The IP addresses used for jobs immediately got out of sync with GCP and I needed to add an `internal.hail` entry to the worker and job's `/etc/hosts` so that default batch could submit to dev batch.; - GCP's metadata server and DNS nameserver are both 169.254.169.254. Azure has a separate IP address for the latter, so I added this configuration to the CloudWorkerAPI. Something that's not addressed here is that I needed to comment out the resource requirements for build image jobs to make them run on standards. The common 2 vCPU / 10 Gi storage / 7.5 Gi Mem lands on standards in GCP but highcpu on azure, which doesn't have disks implemented yet. I'm not sure what the correct step forward on that front is. Otherwise, dev deploying batch should be possible! I ran into multiple issues where my user's sql config was messed up because it was created from a buggy branch. I tried to fix these for the other dev namespaces (dan's which was made later was fine) but there may be some bits I missed. I got as far as running `test_batch_0` and the tests start (!) but fail quickly because of a blob permission issue on the dev driver.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11071:80,test,tests,80,https://hail.is,https://github.com/hail-is/hail/pull/11071,2,['test'],['tests']
Testability,"Mostly small, straightforward stuff. /auth must only return 2xx, 401 or 403, or nginx returns 500. Redirect auth failures connecting to instance to /error, too. Changed ""Create/Open Notebook"" to ""Launch/Open Jupyter"" and associated language throughout. I'll run through the whole test playbook again after these go in. Note to self, some improvements to consider:; - Validate image, memory, cpu values in workshop-admin. Right now, if you enter invalid values, you get a 500 on launch Jupyter with invalid pod spec.; - Could change notebook.hail.is/notebook URL to notebook.hail.is/jupyter now.; - A background loop to kill any notebook workers associated to inactive workshops. Then if you just inactivate the workshop at the end, everything gets cleaned up.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7162:280,test,test,280,https://hail.is,https://github.com/hail-is/hail/pull/7162,1,['test'],['test']
Testability,"Motivation for this change: I want to keep the global configuration information in one place, and that's going to be the K8s default/global-config secret. In particular, I want to get rid of config.mk and just pull the relevant information from K8s. The secret currently like this:. ```; $ k get -o json secret global-config | jq '.data | map_values(@base64d)'; {; ""default_namespace"": ""..."",; ""docker_root_image"": ""..."",; ""domain"": ""..."",; ""gcp_project"": ""..."",; ""gcp_region"": ""..."",; ""gcp_zone"": ""..."",; ""gsuite_organization"": ""..."",; ""internal_ip"": ""..."",; ""ip"": ""..."",; ""kubernetes_server_url"": ""...""; }; ```. default_namespace will always be the name of the namespace the secret is in. This adds gsuite_organization which will be used by auth to restrict logins to a fixed GSuite organization, e.g. broadinstitute.org. I have created this secret on our production K8s cluster. The Terraform script will also create it. With this change, CI creates global-config in test and dev ""default"" namespaces based on the one from where CI is operating. The only field that currently needs to be updated is default_namespace. The plan is to pull from global-config in deployments instead of threading these global configuration(s) through CI. I made this change in the CI tests. FYI @lgruen. I'm going to break up the infra-1 work into a few separate PRs to keep it all clear and manageable.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9777:760,log,logins,760,https://hail.is,https://github.com/hail-is/hail/pull/9777,3,"['log', 'test']","['logins', 'test', 'tests']"
Testability,"Move FilterSuite to Python, delete the part that tests VariantQC",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3607:49,test,tests,49,https://hail.is,https://github.com/hail-is/hail/pull/3607,1,['test'],['tests']
Testability,"Move full time test suite into python, audit coverage",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7806:15,test,test,15,https://hail.is,https://github.com/hail-is/hail/issues/7806,1,['test'],['test']
Testability,Move functions only used in tests to RichVariantSampleMatrix defined; in src/test.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2543:28,test,tests,28,https://hail.is,https://github.com/hail-is/hail/pull/2543,2,['test'],"['test', 'tests']"
Testability,Move linear and logistic regression tests to Python,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3377:16,log,logistic,16,https://hail.is,https://github.com/hail-is/hail/pull/3377,2,"['log', 'test']","['logistic', 'tests']"
Testability,Move some global references inside AST paths to clean up logs,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3553:57,log,logs,57,https://hail.is,https://github.com/hail-is/hail/pull/3553,1,['log'],['logs']
Testability,Moved ImportPlink tests to Python,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3411:18,test,tests,18,https://hail.is,https://github.com/hail-is/hail/pull/3411,1,['test'],['tests']
Testability,"Moved sample and variant QC methods from VDS to their own objects, and call the object apply methods from elsewhere (tests and python). If we're happy with this model (following the hail2 api) I'll change everything else. Long chains of `vds.f().g().h()` will need to get broken up as. ```; var vdss = ...; vds = f(vds); vds = g(vds); vds = h(vds); ```. to avoid unnecessary nesting (and clarity).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2590:117,test,tests,117,https://hail.is,https://github.com/hail-is/hail/pull/2590,1,['test'],['tests']
Testability,Moved the relevant Scala tests into python.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7776:25,test,tests,25,https://hail.is,https://github.com/hail-is/hail/pull/7776,1,['test'],['tests']
Testability,Multi-phenotype logistic regression,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5072:16,log,logistic,16,https://hail.is,https://github.com/hail-is/hail/pull/5072,1,['log'],['logistic']
Testability,"My attempts to restructure as a class led to more complexity, largely due to serialization of class values. I've instead moved logisticSkat and linearSkat into the apply def which removed parameter passing and code duplication. I left `computeKeyGsWeightRdd` outside the apply as moving it in complicates testing. I've also changed maxSize to default to 46340, which is `floor(sqrt(Int.MaxValue))`, and I set maxEntriesForSmallN to be the min of maxSize^2 and 8000^2.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2248#issuecomment-334005938:127,log,logisticSkat,127,https://hail.is,https://github.com/hail-is/hail/pull/2248#issuecomment-334005938,2,"['log', 'test']","['logisticSkat', 'testing']"
Testability,My frustration boiled over and I went to go fix this. This change will cause everyone to become logged out because they will lack the right cookie. That seems fine.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12380:96,log,logged,96,https://hail.is,https://github.com/hail-is/hail/pull/12380,1,['log'],['logged']
Testability,My inclination is to assume the arg parser works correctly and to just test calling a function that returns the information you need.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12471#issuecomment-1324238614:71,test,test,71,https://hail.is,https://github.com/hail-is/hail/pull/12471#issuecomment-1324238614,1,['test'],['test']
Testability,"My large test worked in my namespace. The docs were able to build. They're a bit confusing with the enum object, but I'm not sure how to easily fix it. The key things to look for are the scheduler query matches the sort order of the control loop query. If that's off, then instances will thrash. Once you're good with this then we can do a load test sometime tomorrow.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12221#issuecomment-1270642090:9,test,test,9,https://hail.is,https://github.com/hail-is/hail/pull/12221#issuecomment-1270642090,2,['test'],['test']
Testability,"My motivation here is that in Terra we aren't going to be using hail authentication tokens, rather an authentication from gcloud or az. So I want our batch client to be able to use a `CloudCredentials` just as easily as it uses the hail auth token that we store on the user's machine. So I introduce HailCredentials which subclasses CloudCredentials but the behavior is the same. It also lets us re-use some of the retry logic that we have baked into `aiocloud.common.Session`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12642:421,log,logic,421,https://hail.is,https://github.com/hail-is/hail/pull/12642,1,['log'],['logic']
Testability,"My original motivation for this was to speed up the following code in LD prune: . ```; related_nodes = edges.aggregate(agg.collect_as_set(agg.explode([edges['i'], edges['j']]))); related_nodes_to_keep = maximal_independent_set(edges['i'], edges['j']); related_nodes_to_remove = related_nodes - set(related_nodes_to_keep). pruned_ds = (locally_pruned_ds; .filter_rows(functions.broadcast(related_nodes_to_remove); .contains(locally_pruned_ds.variant_idx), ; keep=False)); ```; It's my understanding that the last line of this code is slow because passing a large python list over py4j is slow. Adding a keep/remove flag to maximal_independent_set would address the set logic and slowness of collecting the set of nodes, but not the other speed issue, since maximal_independent_set would still return a python list. . I could add the keep/remove flag, and also edit the method on the Scala side to create and return a new single-column Table of nodes to remove. Is this preferable?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2975#issuecomment-368139225:668,log,logic,668,https://hail.is,https://github.com/hail-is/hail/pull/2975#issuecomment-368139225,1,['log'],['logic']
Testability,"My plan is to add the JVM logs to disk for each job feature and debug the entire stack at once. If you see problems with the underlying stack, then it would be great to know that sooner rather than later.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11397#issuecomment-1048940715:26,log,logs,26,https://hail.is,https://github.com/hail-is/hail/pull/11397#issuecomment-1048940715,1,['log'],['logs']
Testability,My query service PR will replace these tests with a complete test suite anyway. No one relies on; query being correct. Let us stop interrupting PRs with flaky tests.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10114:39,test,tests,39,https://hail.is,https://github.com/hail-is/hail/pull/10114,3,['test'],"['test', 'tests']"
Testability,"My thought was no change was needed because it's an internal method and a convenience function to have approximately the same. If someone needs it, then they can add more complicated logic later. Whichever you think is best is fine with me.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3442#issuecomment-385975067:183,log,logic,183,https://hail.is,https://github.com/hail-is/hail/pull/3442#issuecomment-385975067,1,['log'],['logic']
Testability,"N: float64, POSITIVE_TRAIN_SITE: bool, VQSLOD: float64, ClippingRankSum: float64, BaseQRankSum: float64, MLEAF: array<float64>, MLEAC: array<int32>, MQ: float64, QD: float64, END: int32, DB: bool, HaplotypeScore: float64, MQRankSum: float64, CCC: int32, NCC: int32, DS: bool}, `the entries! [877f12a8827e18f61222c6c8c5fb04a8]`: array<struct{GT: call, AD: array<int32>, DP: int32, GQ: int32, PL: array<int32>}>}),the entries! [877f12a8827e18f61222c6c8c5fb04a8]),Ref(i,int32)),DP),I32(20)). Java stack trace:; java.lang.AssertionError: assertion failed: mismatch:; array<int32>; array<int32>; ApplyComparisonOp(GT(int32,int32),GetField(ArrayRef(GetField(Ref(va,struct{locus: locus<GRCh37>, alleles: array<str>, rsid: str, qual: float64, filters: set<str>, info: struct{NEGATIVE_TRAIN_SITE: bool, HWP: float64, AC: array<int32>, culprit: str, MQ0: int32, ReadPosRankSum: float64, AN: int32, InbreedingCoeff: float64, AF: array<float64>, GQ_STDDEV: float64, FS: float64, DP: int32, GQ_MEAN: float64, POSITIVE_TRAIN_SITE: bool, VQSLOD: float64, ClippingRankSum: float64, BaseQRankSum: float64, MLEAF: array<float64>, MLEAC: array<int32>, MQ: float64, QD: float64, END: int32, DB: bool, HaplotypeScore: float64, MQRankSum: float64, CCC: int32, NCC: int32, DS: bool}, `the entries! [877f12a8827e18f61222c6c8c5fb04a8]`: array<struct{GT: call, AD: array<int32>, DP: int32, GQ: int32, PL: array<int32>}>}),the entries! [877f12a8827e18f61222c6c8c5fb04a8]),Ref(i,int32)),DP),I32(20)); 	at scala.Predef$.assert(Predef.scala:170); 	at is.hail.expr.ir.Infer$.apply(Infer.scala:10); 	at is.hail.expr.ir.InferIR$class.typ(IR.scala:58); 	at is.hail.expr.ir.If.typ(IR.scala:77); 	at is.hail.expr.ir.Infer$$anonfun$apply$5.apply(Infer.scala:63); 	at is.hail.expr.ir.Infer$$anonfun$apply$5.apply(Infer.scala:59); 	at scala.collection.LinearSeqOptimized$class.foldLeft(LinearSeqOptimized.scala:124); 	at scala.collection.immutable.List.foldLeft(List.scala:84); 	at is.hail.expr.ir.Infer$.apply(Infer.scala:59); 	at is.hail.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4134:1928,Assert,AssertionError,1928,https://hail.is,https://github.com/hail-is/hail/issues/4134,2,"['Assert', 'assert']","['AssertionError', 'assertion']"
Testability,"NB, this is a stacked PR. To see just these changes see [this commit](https://github.com/hail-is/hail/pull/12883/commits/ae51e0a9af12e4c89a44e7ce3235f3f665ff4830). ---. [VPC Flow Logs](https://cloud.google.com/vpc/docs/flow-logs):. > VPC Flow Logs records a sample of network flows sent from and received by VM instances, including; > instances used as Google Kubernetes Engine nodes. These logs can be used for network monitoring,; > forensics, real-time security analysis, and expense optimization. I found the collection process the most elucidating part of the documentation. My summary of that; process follows:. 1. Packets are sampled on the network interface of a VM. Google claims an average sampling rate of; 1/30. This rate reduces if the VM is under load. This rate is immutable to us. 2. Within an ""aggregation interval"", packets are aggregated into ""records"" which are keyed (my term); by source & destination. There are currently six choices for aggregation interval: 5s, 30s, 1m,; 5m, 10m, and 15m. 3. Records are sampled. The sampling rate is a user configured floating point number (precision; unclear) between 0 and 1. 4. Metadata is optionally added to the records. The metadata captures information about the source; and destination VM such as project id, VM name, zone, region, GKE pod, GKE service, and geographic; information of external parties. The user may elect to receive all metadata, no metadata, or a; specific set of metadata fields. 5. The records are written to Google Cloud Logging. The pricing of VPC Flow Logs is described at the [network pricing page](https://cloud.google.com/vpc/network-pricing#network-telemetry). Notice that, if logs are only sent to Cloud Logging (not to BigQuery, Pub/Sub, or Cloud Storage):. > If you store your logs in Cloud Logging, logs generation charges are waived, and only Logging charges apply. I believe in this phrase ""logs generation charges"" refers to *VPC Flow logs* generation charges. The Google Cloud Logging [pricing page]",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12883:179,Log,Logs,179,https://hail.is,https://github.com/hail-is/hail/pull/12883,4,"['Log', 'log']","['Logs', 'logs']"
Testability,NFO: instruction count: 3: __C1235__m1112split_LetSpills.<init>\n2022-11-15 20:30:18.247 root: INFO: instruction count: 3: __C1182staticWrapperClass_1.<init>\n2022-11-15 20:30:18.247 root: INFO: instruction count: 3: __C1203Tuple3.<init>\n2022-11-15 20:30:18.247 root: INFO: instruction count: 12: __C1203Tuple3.<init>\n2022-11-15 20:30:18.262 root: INFO: executing D-Array [table_aggregate_singlestage] with 50 tasks\n2022-11-15 20:30:18.262 ServiceBackend$: INFO: parallelizeAndComputeWithIndex: pty4D81uzQk6XN9LVVebj6KNvkh8SC3EzvXjgv6-LMY=: nPartitions 50\n2022-11-15 20:30:18.262 ServiceBackend$: INFO: parallelizeAndComputeWithIndex: pty4D81uzQk6XN9LVVebj6KNvkh8SC3EzvXjgv6-LMY=: writing f and contexts\n2022-11-15 20:30:18.263 ServiceBackend$: INFO: parallelizeAndComputeWithIndex: pty4D81uzQk6XN9LVVebj6KNvkh8SC3EzvXjgv6-LMY=: writing contexts\n2022-11-15 20:30:18.264 Requester: INFO: request POST http://memory.hail/api/v1alpha/objects?q=gs%3A%2F%2Fhail-test-dmk9z%2FparallelizeAndComputeWithIndex%2Fpty4D81uzQk6XN9LVVebj6KNvkh8SC3EzvXjgv6-LMY%3D%2Ff\n2022-11-15 20:30:18.264 Requester: INFO: request POST http://memory.hail/api/v1alpha/objects?q=gs%3A%2F%2Fhail-test-dmk9z%2FparallelizeAndComputeWithIndex%2Fpty4D81uzQk6XN9LVVebj6KNvkh8SC3EzvXjgv6-LMY%3D%2Fcontexts\n2022-11-15 20:30:18.318 Requester: INFO: request POST http://memory.hail/api/v1alpha/objects?q=gs%3A%2F%2Fhail-test-dmk9z%2FparallelizeAndComputeWithIndex%2Fpty4D81uzQk6XN9LVVebj6KNvkh8SC3EzvXjgv6-LMY%3D%2Fcontexts response 200\n2022-11-15 20:30:18.331 Requester: INFO: request POST http://memory.hail/api/v1alpha/objects?q=gs%3A%2F%2Fhail-test-dmk9z%2FparallelizeAndComputeWithIndex%2Fpty4D81uzQk6XN9LVVebj6KNvkh8SC3EzvXjgv6-LMY%3D%2Ff response 200\n2022-11-15 20:30:18.332 ServiceBackend$: INFO: parallelizeAndComputeWithIndex: pty4D81uzQk6XN9LVVebj6KNvkh8SC3EzvXjgv6-LMY=: running job\n2022-11-15 20:30:18.333 Requester: INFO: request POST http://batch.hail/api/v1alpha/batches/6627669/update-fast\n2022-11-15 20:30:18.69,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12470#issuecomment-1315959284:23406,test,test-,23406,https://hail.is,https://github.com/hail-is/hail/pull/12470#issuecomment-1315959284,2,['test'],['test-']
Testability,"Name; | where Namespace == ""pr-13135-default-u5tt5011yt5w"" and PodName startswith ""batch-driver""; | distinct ContainerID, PodName, Namespace; | join (; ContainerLog; | where TimeGenerated > startTimestamp; ) on ContainerID; | project TimeGenerated, message=parse_json(LogEntry).message, LogEntry=parse_json(LogEntry); | where message contains ""hail-az://""; | order by TimeGenerated desc; ```. That revealed the batch logs path:. ```; EXAMPLE BATCH_JOB_LOGS_PATH hail-az://haildevtest/test/batch/logs/we5a79QlczzdluUx8kT2Vh/batch/1/1/abc123/main/log; ```. In the [failing PR test job logs](https://ci.azure.hail.is/batches/3956877/jobs/152), I found the batch id:. ```; [2023-06-09 12:43:34] test/hail/methods/test_impex.py::BGENTests::test_import_bgen_row_fields; -------------------------------- live log call ---------------------------------; INFO batch_client.aioclient:aioclient.py:753 created batch 1148. INFO batch_client.aioclient:aioclient.py:770 updated batch 1148. FAILED; ```. I listed the job logs:. ```; (base) dking@wm28c-761 hail % az storage blob list --account-name haildevtest --container test --prefix batch/logs/we5a79QlczzdluUx8kT2Vh/batch/1148/ -o table; Name Blob Type Blob Tier Length Content Type Last Modified Snapshot; ----------------------------------------------------------------------------- ----------- ----------- -------- ------------------------ ------------------------- ----------; batch/logs/we5a79QlczzdluUx8kT2Vh/batch/1148/1/i4CoSh/main/log BlockBlob Hot 11724 application/octet-stream 2023-06-09T12:43:36+00:00; batch/logs/we5a79QlczzdluUx8kT2Vh/batch/1148/1/i4CoSh/main/resource_usage BlockBlob Hot 64 application/octet-stream 2023-06-09T12:43:36+00:00; batch/logs/we5a79QlczzdluUx8kT2Vh/batch/1148/1/i4CoSh/status.json BlockBlob Hot 1240 application/octet-stream 2023-06-09T12:43:36+00:00; batch/logs/we5a79QlczzdluUx8kT2Vh/batch/1148/2/31Owgv/main/log BlockBlob Hot 16626 application/octet-stream 2023-06-09T12:44:22+00:00; batch/logs/we5a79QlczzdluUx8k",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13160:1615,log,logs,1615,https://hail.is,https://github.com/hail-is/hail/pull/13160,1,['log'],['logs']
Testability,Native code still works (tested by running `hl.identity_by_descent`).,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14093#issuecomment-1852290763:25,test,tested,25,https://hail.is,https://github.com/hail-is/hail/pull/14093#issuecomment-1852290763,1,['test'],['tested']
Testability,Necessary for the big aggregate benchmark to pass (albeit more slowly) in benchmarks.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10746:32,benchmark,benchmark,32,https://hail.is,https://github.com/hail-is/hail/pull/10746,2,['benchmark'],"['benchmark', 'benchmarks']"
Testability,"Need this to be able to test batch2 with non-production databases. Unfortunately, I have no way of testing whether this works with a test database until it merges...",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7283:24,test,test,24,https://hail.is,https://github.com/hail-is/hail/pull/7283,3,['test'],"['test', 'testing']"
Testability,Need to also double check the number for `n_ready` is correct with a better test case.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14100#issuecomment-1858589110:76,test,test,76,https://hail.is,https://github.com/hail-is/hail/pull/14100#issuecomment-1858589110,1,['test'],['test']
Testability,"Need to make a smaller set of avro example files to check into the repo for automated tests. I have been writing/running tests on 10 full samples, can't automate that. I suppose maybe that shouldn't block this from being merged, though I don't want to leave that thread too long.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12017#issuecomment-1333006912:86,test,tests,86,https://hail.is,https://github.com/hail-is/hail/pull/12017#issuecomment-1333006912,2,['test'],['tests']
Testability,"Need to understand ToStream and ToArray invariants. For ToArray, I'm considering the following invariant: if child is stream, leave as is, if child is not stream, streamify. Explicit ToArray match needed to pass TableSuite::testRangeRead. A bunch of tests fail in Aggregators2Suite; in testDownsample case it's an issue with ToStream missing from FoldConstants. Fixed this with a _: ToStream => None. Other Aggregators2Suite issues are stranger, here's the testArrayElementsAgg:. Cannot find __iruid_39 in Map(__iruid_22 -> PCStruct{stream:PCArray[PCArray[PCStruct{a:PCString,b:PInt64}]]}, __iruid_38 -> PCArray[PCArray[PCStruct{a:PCString,b:PInt64}]]); java.lang.RuntimeException: Cannot find __iruid_39 in Map(__iruid_22 -> PCStruct{stream:PCArray[PCArray[PCStruct{a:PCString,b:PInt64}]]}, __iruid_38 -> PCArray[PCArray[PCStruct{a:PCString,b:PInt64}]])",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8063#issuecomment-584445732:224,test,testRangeRead,224,https://hail.is,https://github.com/hail-is/hail/pull/8063#issuecomment-584445732,4,['test'],"['testArrayElementsAgg', 'testDownsample', 'testRangeRead', 'tests']"
Testability,Need to update build.gradle and test.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4578:32,test,test,32,https://hail.is,https://github.com/hail-is/hail/issues/4578,1,['test'],['test']
Testability,Needed so #5866 will pass tests.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5897:26,test,tests,26,https://hail.is,https://github.com/hail-is/hail/pull/5897,1,['test'],['tests']
Testability,Needed to debug Laurent's pipeline. And we should be logging everything anyway -- this is the only way we get to see the post-extract-aggregators executed IR,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5749:53,log,logging,53,https://hail.is,https://github.com/hail-is/hail/pull/5749,1,['log'],['logging']
Testability,Needs tests. And then the next step is to use this in the copier/sync tool.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14603#issuecomment-2204424918:6,test,tests,6,https://hail.is,https://github.com/hail-is/hail/pull/14603#issuecomment-2204424918,1,['test'],['tests']
Testability,Neither bucket nor remote_tmpdir had tests so I added tests for both.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10529#issuecomment-858697221:37,test,tests,37,https://hail.is,https://github.com/hail-is/hail/pull/10529#issuecomment-858697221,2,['test'],['tests']
Testability,Nested another section layer under `Implementation` so now there is `Environment / Tooling` and `Testing / Debugging` with space in both to outline shared steps and then compiler & services-specific steps,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9970:97,Test,Testing,97,https://hail.is,https://github.com/hail-is/hail/pull/9970,1,['Test'],['Testing']
Testability,Nested array element aggregations weren't working. This fixes it and adds a test for nested ArrayAggs. Caught by test failures from #6698.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6743:76,test,test,76,https://hail.is,https://github.com/hail-is/hail/pull/6743,2,['test'],['test']
Testability,"Nevermind, I can see that it hasn't. How do we expect to benchmark these?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5414#issuecomment-466563704:57,benchmark,benchmark,57,https://hail.is,https://github.com/hail-is/hail/pull/5414#issuecomment-466563704,1,['benchmark'],['benchmark']
Testability,Nevermind. Added tests for editing the limits to this PR. Will figure out the CLI after @catoverdrive has had a chance to do what they wanted to do with that for billing projects.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9354#issuecomment-705120445:17,test,tests,17,https://hail.is,https://github.com/hail-is/hail/pull/9354#issuecomment-705120445,1,['test'],['tests']
Testability,New IR node that makes an array of zeros. Good for initializing large things. Mostly I want this so I can do some memory leak tests that don't take multiple minutes.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8168:126,test,tests,126,https://hail.is,https://github.com/hail-is/hail/pull/8168,1,['test'],['tests']
Testability,"New Query Plan:. ```; mysql> EXPLAIN SELECT batches.*, batches_cancelled.id IS NOT NULL AS cancelled, COALESCE(SUM(`usage` * rate), 0) AS cost, batches_n_jobs_in_complete_states.n_completed, batches_n_jobs_in_complete_states.n_succeeded, batches_n_jobs_in_complete_states.n_failed, batches_n_jobs_in_complete_states.n_cancelled; -> FROM batches; -> LEFT JOIN batches_n_jobs_in_complete_states; -> ON batches.id = batches_n_jobs_in_complete_states.id; -> LEFT JOIN batches_cancelled; -> ON batches.id = batches_cancelled.id; -> LEFT JOIN aggregated_batch_resources; -> ON batches.id = aggregated_batch_resources.batch_id; -> LEFT JOIN resources; -> ON aggregated_batch_resources.resource = resources.resource; -> STRAIGHT_JOIN billing_project_users ON batches.billing_project = billing_project_users.billing_project; -> WHERE (billing_project_users.`user` = 'test' AND billing_project_users.billing_project = batches.billing_project) AND NOT deleted AND (batches.id < 1114186) AND ; -> (batches.`user` = 'test'); -> GROUP BY batches.id; -> ORDER BY batches.id DESC; -> LIMIT 51;; +----+-------------+-----------------------------------+------------+--------+---------------------------------------------------------------------------------------------------------------+---------+---------+-------------------------------------------+---------+----------+----------------------------------+; | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |; +----+-------------+-----------------------------------+------------+--------+---------------------------------------------------------------------------------------------------------------+---------+---------+-------------------------------------------+---------+----------+----------------------------------+; | 1 | SIMPLE | batches | NULL | range | PRIMARY,batches_deleted,batches_token,batches_user_state,batches_time_completed,batches_billing_project_state | PRIMARY | 8 | NULL | 1348998 | 5",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12057#issuecomment-1196612910:858,test,test,858,https://hail.is,https://github.com/hail-is/hail/pull/12057#issuecomment-1196612910,1,['test'],['test']
Testability,"New new failure mode:. AccessDeniedException: 403 hail-ci-0-1@broad-ctsa.iam.gserviceaccount.com does not have storage.objects.list access to hail-ci-test. Failing here in test-ci.py:. ```; deploy_artifact = run(['gsutil', 'cat', f'gs://hail-ci-test/{second_target_sha}'], stdout=subprocess.PIPE); deploy_artifact = deploy_artifact.stdout.decode('utf-8').strip(); assert f'commit {second_target_sha}' in deploy_artifact; ```. I don't know who's authorizing gcloud for hail-ci-0-1. Anyway, I gave hail-ci-0-1 permissions on hail-ci-test and am re-running.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4509#issuecomment-429196114:150,test,test,150,https://hail.is,https://github.com/hail-is/hail/pull/4509#issuecomment-429196114,5,"['assert', 'test']","['assert', 'test', 'test-ci']"
Testability,New plan. @catoverdrive already figured out how to have multiple users with different clients to be able to test the dev only endpoints such as editing a billing limit. I'm going to wait for their PR to go in and then reevaluate (#9553).,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9354#issuecomment-705156989:108,test,test,108,https://hail.is,https://github.com/hail-is/hail/pull/9354#issuecomment-705156989,1,['test'],['test']
Testability,New test failure mode:. ERROR: (gcloud.beta.dataproc.clusters.create) Operation [projects/broad-ctsa/regions/global/operations/07164d0e-6c27-35d9-8132-9960b0db6d43] failed: Internal server error.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4509#issuecomment-429176963:4,test,test,4,https://hail.is,https://github.com/hail-is/hail/pull/4509#issuecomment-429176963,1,['test'],['test']
Testability,"New test failure:. ```; + ./gradlew shadowJar archiveZip; Exception in thread ""main"" javax.net.ssl.SSLHandshakeException: Received fatal alert: handshake_failure; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:192); ```; Still not sure what to do about transient external dependency failures in the tests.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4536#issuecomment-429360417:4,test,test,4,https://hail.is,https://github.com/hail-is/hail/pull/4536#issuecomment-429360417,2,['test'],"['test', 'tests']"
Testability,Next PR will split service backend tests for better legibility so fixtures need to be in one place.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14313:35,test,tests,35,https://hail.is,https://github.com/hail-is/hail/pull/14313,1,['test'],['tests']
Testability,Next thing I would try is running the full split. Maybe we need to run that in a memory limited way?; ```; HAIL_RUN_IMAGE_SPLITS=14 \; HAIL_RUN_IMAGE_SPLIT_INDEX=2 \; HAIL_CLOUD=gcp \; HAIL_TEST_STORAGE_URI=/tmp/ \; HAIL_TEST_RESOURCES_DIR=./../src/test/resources/ \; HAIL_DOCTEST_DATA_DIR=./hail/docs/data \; HAIL_QUERY_BACKEND=local python3 -m pytest -Werror:::hail -Werror:::hailtop --log-cli-level=INFO -s -r A -vv --instafail --durations=50 --ignore=test/hailtop/ test; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12731#issuecomment-1507071339:249,test,test,249,https://hail.is,https://github.com/hail-is/hail/pull/12731#issuecomment-1507071339,4,"['log', 'test']","['log-cli-level', 'test']"
Testability,"Nice, I think this is a giant improvement. There are still spots where the pairing between source file and test file isn't exact, but hopefully having it most of the way there will encourage better modularization of both the source and tests over time (broken windows and all that).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3887#issuecomment-402164003:107,test,test,107,https://hail.is,https://github.com/hail-is/hail/pull/3887#issuecomment-402164003,2,['test'],"['test', 'tests']"
Testability,No new tests are passing because we need to implement VCF export first.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11598#issuecomment-1068604326:7,test,tests,7,https://hail.is,https://github.com/hail-is/hail/pull/11598#issuecomment-1068604326,1,['test'],['tests']
Testability,"No no, I reset the codecs afterwards. I tested and it works as intended; (loading a .gz annotation file with the Gzip codec). I'm trying to fix the; small letter / capital issue (thanks Daniel), but it Git seems to be; case-insensitive when it comes to files... On Wed, Sep 21, 2016 at 11:19 AM, Tim Poterba notifications@github.com; wrote:. > This sets the configuration permanently -- any following commands will use; > the overridden codecs. Setting a global option is almost certainly better; > than getting this kind of leakage, I think; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > https://github.com/hail-is/hail/pull/826#issuecomment-248645129, or mute; > the thread; > https://github.com/notifications/unsubscribe-auth/ADVxgYRNZnsCXFQnDx9z5wRR1WD4rr0cks5qsUr_gaJpZM4KC1O-; > .",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/826#issuecomment-248646084:40,test,tested,40,https://hail.is,https://github.com/hail-is/hail/pull/826#issuecomment-248646084,1,['test'],['tested']
Testability,"No state. I printed the session in the logs (I was deploying into prod to test while I had a broken cookie). My session had nothing set except that it was marked as created on January 7th. This despite that I saw a log statement from when I hit /login,m that clearly showed me session with all the right values. My guess is that there was some old signing key or somehow the session got corrupted so you can decode it to get an empty session and add new fields but they fail to be written back.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8052#issuecomment-583226388:39,log,logs,39,https://hail.is,https://github.com/hail-is/hail/pull/8052#issuecomment-583226388,8,"['log', 'test']","['log', 'login', 'logs', 'test']"
Testability,No worries @vladsaveliev! I put this PR up just to work through the CI tests. I meant once you merge my changes into your branch and your PR goes in I will close this one.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10347#issuecomment-824489394:71,test,tests,71,https://hail.is,https://github.com/hail-is/hail/pull/10347#issuecomment-824489394,1,['test'],['tests']
Testability,"No, I wanted to test the PR build path. As you can see it’s broken 😉",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8136#issuecomment-591472185:16,test,test,16,https://hail.is,https://github.com/hail-is/hail/pull/8136#issuecomment-591472185,1,['test'],['test']
Testability,"No, but its the same string I used to install hail dependencies for Terra's notebooks. I can run a test now",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9502#issuecomment-698497283:99,test,test,99,https://hail.is,https://github.com/hail-is/hail/pull/9502#issuecomment-698497283,1,['test'],['test']
Testability,"No, don't want to do that. I just looked at the log and it did what I expected https://ci.hail.is/jobs/29829/log",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6222#issuecomment-497511305:48,log,log,48,https://hail.is,https://github.com/hail-is/hail/pull/6222#issuecomment-497511305,2,['log'],['log']
Testability,"No, only step 1 up there has been completed. We currently accept both the old and new authentication tokens. We need to decide what kind of deprecation approach is appropriate here and then do it. Also as it currently stands copy-paste tokens require the old-style of authentication (I think because of an implementation detail that internally these tokens reference `session_id`s instead of users), so those either need to be migrated to be compatible with a user not having any `session_id`s in the database or removed entirely. A useful bit of context though, the only thing users need to do to get off the old tokens is `hailctl auth login` on a hail version with the changes in #13131.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13531#issuecomment-1766798562:638,log,login,638,https://hail.is,https://github.com/hail-is/hail/issues/13531#issuecomment-1766798562,1,['log'],['login']
Testability,"No, we're setting up a new test server and things are broken at the moment. We should get things sorted today, hopefully.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/654#issuecomment-242075913:27,test,test,27,https://hail.is,https://github.com/hail-is/hail/pull/654#issuecomment-242075913,1,['test'],['test']
Testability,No. Dirty. Indicies. After. Tests. Or. Builds.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4462:28,Test,Tests,28,https://hail.is,https://github.com/hail-is/hail/pull/4462,1,['Test'],['Tests']
Testability,"No. There's one test that only fails on Azure and I haven't figured out why yet. ```. =================================== FAILURES ===================================; ___________________________ test_dir_outside_curdir ____________________________. runner = <typer.testing.CliRunner object at 0x7f95b3d14b50>. def test_dir_outside_curdir(runner: CliRunner):; with tempfile.TemporaryDirectory() as dir:; os.mkdir(f'{dir}/working_dir'); os.chdir(f'{dir}/working_dir'); write_hello(f'{dir}/hello1.txt'); write_hello(f'{dir}/hello2.txt'); write_script(dir, '/hello1.txt'); res = runner.invoke(cli.app, ['submit', '--files', f'{dir}/:/', '../test_job.py']); > assert res.exit_code == 0; E AssertionError: assert 1 == 0; E + where 1 = <Result HttpResponseError('The specified block list is invalid.\nRequestId:86424c6a-d01e-004a-272b-0b6b10000000\nTime:2023-10-30T12:21:01.7415144Z\nErrorCode:InvalidBlockList')>.exit_code; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13785#issuecomment-1785325401:16,test,test,16,https://hail.is,https://github.com/hail-is/hail/issues/13785#issuecomment-1785325401,5,"['Assert', 'assert', 'test']","['AssertionError', 'assert', 'test', 'testing']"
Testability,"Non preemptible for that reason seems fine. . However, I think I have a fundamental misunderstanding. In my experience thus far, Prometheus will need more than 30GB of RAM if anyone runs thousands of pods on our cluster for an hour or more. Is that not your understanding? Last time I ran the test Prometheus wasn’t able to start after crashing. Also the per-pod Graphana graphs loaded noticeably slower than everything else.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6774#issuecomment-519120787:293,test,test,293,https://hail.is,https://github.com/hail-is/hail/pull/6774#issuecomment-519120787,1,['test'],['test']
Testability,Non-pseudo-autosomal variants (i.e. the part of the X which does not match the Y) are very unlikely to appear but can trigger significantly different behavior from pseudo-autosomal variants. Our tests should trigger this behavior more often.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/871:195,test,tests,195,https://hail.is,https://github.com/hail-is/hail/issues/871,1,['test'],['tests']
Testability,Not a correctness bug because we raise an assertion error in the partition function.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13550:42,assert,assertion,42,https://hail.is,https://github.com/hail-is/hail/pull/13550,1,['assert'],['assertion']
Testability,"Not helpful for debugging, we still get logs on errors",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11977:40,log,logs,40,https://hail.is,https://github.com/hail-is/hail/pull/11977,1,['log'],['logs']
Testability,"Not in the default script yet. Try running with this:. /psych/genetics_data/working/cseed/hail-inst/bin/hail. Cotton. On Mon, Apr 25, 2016 at 5:53 PM, ksatterstrom notifications@github.com; wrote:. > This afternoon I tried to run a series of commands that began with:; > ; > hail-new read -i /user/satterst/DBS_v2.4/temp3.vds \; > filtervariants --keep -c 'va.kyle.lof == ""HC""' \; > filtervariants --remove -c /user/satterst/exac.variant_list; > ; > and I got output that said:; > hail: info: running: filtervariants --remove -c; > /user/satterst/exac.variant_list; > Exception in thread ""main"" java.lang.OutOfMemoryError: Java heap space; > ; > log here:; > /humgen/atgu1/fs03/satterst/DBS_v2.4/hail.heapspace.log; > ; > Has the fix been incorporated into the jar on the cluster?; > ; > —; > You are receiving this because you authored the thread.; > Reply to this email directly or view it on GitHub; > https://github.com/broadinstitute/hail/issues/263#issuecomment-214538990",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/263#issuecomment-214545407:646,log,log,646,https://hail.is,https://github.com/hail-is/hail/issues/263#issuecomment-214545407,2,['log'],['log']
Testability,Not including a test since Patrick has an open PR that obviates this kind of error completely.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11181:16,test,test,16,https://hail.is,https://github.com/hail-is/hail/pull/11181,1,['test'],['test']
Testability,"Not sure this is better, but basically my logic is to kill the `crun run` process first. Wait for it to be killed. Set the process = None. Then check if a container exists. If the container exists, then do a deep kill of all child subprocesses. I'm not sure I completely understand where the race condition could occur here.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10855#issuecomment-942624612:42,log,logic,42,https://hail.is,https://github.com/hail-is/hail/pull/10855#issuecomment-942624612,1,['log'],['logic']
Testability,"Not sure who to assign this to since it spans everything. I targeted the slowest test jobs. Currently CI's PR page timings are wrong. If you scroll down to ""Build History"" and click on a batch, that page has the right timings. (The CI PR page timings will be fixed by #6746",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6863:81,test,test,81,https://hail.is,https://github.com/hail-is/hail/pull/6863,1,['test'],['test']
Testability,"Not sure why the BatchPoolExecutor test failed, but approving.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9862#issuecomment-760323340:35,test,test,35,https://hail.is,https://github.com/hail-is/hail/pull/9862#issuecomment-760323340,1,['test'],['test']
Testability,"Not that it helps in the commit history, but at least it's somewhere... this PR fixed that the secrets for batch deployment needed the deploy flag on which secret to use depending on whether we're testing or in production.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6168#issuecomment-495361303:197,test,testing,197,https://hail.is,https://github.com/hail-is/hail/pull/6168#issuecomment-495361303,1,['test'],['testing']
Testability,"Not used/tested anywhere, but it was broken.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4331:9,test,tested,9,https://hail.is,https://github.com/hail-is/hail/pull/4331,1,['test'],['tested']
Testability,"Note some highlights from the log:; ```; #12 42.27 ./Bio/tmp/Bio-DB-HTS-2.9 - moving files to ./biodbhts; #12 42.27 - making Bio::DB:HTS; #12 42.40 Checking prerequisites...; #12 42.40 requires:; #12 42.40 ! Bio::Root::Version is not installed; #12 42.40 ; #12 42.40 ERRORS/WARNINGS FOUND IN PREREQUISITES. You may wish to install the versions; #12 42.40 of the modules indicated above before proceeding with this installation; #12 42.40 ; #12 42.40 Run 'Build installdeps' to install missing prerequisites.; ```; ```; #13 138.3 Building and testing Test2-Suite-0.000152 ... ! Installing Test2::V0 failed. See /root/.cpanm/work/1682614674.13506/build.log for details. Retry with --force to force install it.; #13 150.9 FAIL; #13 150.9 --> Working on FFI::CheckLib; #13 150.9 Fetching http://www.cpan.org/authors/id/P/PL/PLICEASE/FFI-CheckLib-0.31.tar.gz ... OK; #13 150.9 Configuring FFI-CheckLib-0.31 ... OK; #13 151.1 ==> Found dependencies: Test2::V0, Test2::Require::EnvVar, Test2::Require::Module; #13 151.1 ! Installing the dependencies failed: Module 'Test2::Require::EnvVar' is not installed, Module 'Test2::V0' is not installed, Module 'Test2::Require::Module' is not installed; #13 151.1 ! Bailing out the installation for FFI-CheckLib-0.31. ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12946#issuecomment-1526412230:30,log,log,30,https://hail.is,https://github.com/hail-is/hail/issues/12946#issuecomment-1526412230,3,"['log', 'test']","['log', 'testing']"
Testability,Note that I am not at all convinced that the random tests are providing good coverage: https://github.com/hail-is/hail/issues/1894,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1893#issuecomment-305345167:52,test,tests,52,https://hail.is,https://github.com/hail-is/hail/pull/1893#issuecomment-305345167,1,['test'],['tests']
Testability,"Note that pandas 2.0.0 [removes the deprecated `DataFrame.iteritems()`](https://pandas.pydata.org/docs/whatsnew/v2.0.0.html#removal-of-prior-version-deprecations-changes), which is used by bokeh-1.4.0. That particular old version of bokeh is listed in _hail/python/requirements.txt_ but it is thus incompatible with pandas 2; so one or the other of these pinnings probably needs to be revisited. (This incompatibility has caused the [large_cohort unit test failure](https://github.com/populationgenomics/production-pipelines/actions/runs/4782280056/jobs/8501466504?pr=354#step:5:134) in populationgenomics/production-pipelines#354.)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12906#issuecomment-1519857581:452,test,test,452,https://hail.is,https://github.com/hail-is/hail/pull/12906#issuecomment-1519857581,1,['test'],['test']
Testability,"Note that this is passing tests, except for the timeout issue we're seeing everywhere.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14517#issuecomment-2107719350:26,test,tests,26,https://hail.is,https://github.com/hail-is/hail/pull/14517#issuecomment-2107719350,1,['test'],['tests']
Testability,Note to reviewer: Just changed per variant testing to be handled in blocks with matrix matrix multiplies. Hopefully a bit faster.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1984#issuecomment-320541669:43,test,testing,43,https://hail.is,https://github.com/hail-is/hail/pull/1984#issuecomment-320541669,1,['test'],['testing']
Testability,Note to self that the audit should test for equality here.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12761#issuecomment-1458597618:35,test,test,35,https://hail.is,https://github.com/hail-is/hail/pull/12761#issuecomment-1458597618,1,['test'],['test']
Testability,Note to self to check the logs for error messages before merging!,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12199#issuecomment-1254026870:26,log,logs,26,https://hail.is,https://github.com/hail-is/hail/pull/12199#issuecomment-1254026870,1,['log'],['logs']
Testability,Note to self to look at the logs for this PR before merging to make sure the metadata is actually there.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13219#issuecomment-1610264199:28,log,logs,28,https://hail.is,https://github.com/hail-is/hail/pull/13219#issuecomment-1610264199,1,['log'],['logs']
Testability,Notebook2 login,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5437:10,log,login,10,https://hail.is,https://github.com/hail-is/hail/pull/5437,1,['log'],['login']
Testability,"Notebook2 was _literally_ unusable (no favicon). Instead of copying and pasting the favicon link 5 times, I also extracted out the shared elements into a template, and extended it in all other views. How this works:; `layout.html`: contains all shared elements, and marks places where children can insert content (`{% block title %}{% endblock %}`, `{% block head %}{% endblock %}`, `{% block content %}{% endblock %}`). Every other file extends this. The 2 templates that weren't updated (admin-login.html, and workers.html) are placeholders from notebook1 that haven't been updated for notebook 2 yet; they should work, but don't use notebook2 styles, and therefore don't have shared elements to wrap in layout.html. This all works. cc @cseed, @jigold, @danking, @konradjk",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5827:496,log,login,496,https://hail.is,https://github.com/hail-is/hail/pull/5827,1,['log'],['login']
Testability,"Notes: ; #### 1st & 3rd set of errors. 1st and 3rd set identical, except in 3rd handler:200 (another response.post) hangs first... `ConnectionResetError` errorNum=104.; * May be related: https://github.com/kubernetes/kubernetes/pull/53947. Batch: `kube_event_loop` is always involved. Always:; ```log; Traceback (most recent call last):; File ""/usr/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 384, in _make_request; six.raise_from(e, None); File ""<string>"", line 2, in raise_from; File ""/usr/lib/python3.6/site-packages/urllib3/connectionpool.py"", line 380, in _make_request; httplib_response = conn.getresponse(); File ""/usr/lib/python3.6/http/client.py"", line 1331, in getresponse; response.begin(); File ""/usr/lib/python3.6/http/client.py"", line 297, in begin; version, status, reason = self._read_status(); File ""/usr/lib/python3.6/http/client.py"", line 258, in _read_status; line = str(self.fp.readline(_MAXLINE + 1), ""iso-8859-1""); File ""/usr/lib/python3.6/socket.py"", line 586, in readinto; return self._sock.recv_into(b); socket.timeout: timed out; ```. Seems that the simplest issue may be to increase `read_timeout` past 120 seconds, although depending on the causes of this issue, that may not eliminate the problem, and of course leaves a long delay, which may be unacceptable for the use-case. As for why read takes so long: not 100% sure yet, setting up batch and CI is still incomplete, and I have not triggered this error myself. My guess is that Kubernetes takes too long to generate the response, either due to garbage collection, or simply because the requested information takes N > 120 seconds to return. That would be a very long time for any reasonable response, so either the resource isn't ready and it waits, or there are network connectivity issues. If network issues, not sure what solutions are. If I were on AWS, I would think about using a larger instance, with a higher-bandwidth NIC.; * Possible connection: https://github.com/arangodb/arangodb/issues",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4984#issuecomment-450444389:297,log,log,297,https://hail.is,https://github.com/hail-is/hail/issues/4984#issuecomment-450444389,2,['log'],['log']
Testability,Nothing suspicious there. Something is going wrong in the executors. I think the only way we're gonna solve this is by running a pipeline and looking at the executor logs. I'm at a complete loss for how Jupyter could affect what happens on the executors.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13690#issuecomment-1731963811:166,log,logs,166,https://hail.is,https://github.com/hail-is/hail/issues/13690#issuecomment-1731963811,1,['log'],['logs']
Testability,Noticed dirty working tree after running tests,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4397:41,test,tests,41,https://hail.is,https://github.com/hail-is/hail/pull/4397,1,['test'],['tests']
Testability,Now passing tests,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3466#issuecomment-385812703:12,test,tests,12,https://hail.is,https://github.com/hail-is/hail/pull/3466#issuecomment-385812703,1,['test'],['tests']
Testability,Now raises an error instead of asserting. resolves #4770 by clarifying problem with old syntax introduced by [breaking change](https://discuss.hail.is/t/breaking-change-redesign-of-aggregator-interface/701),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5110:31,assert,asserting,31,https://hail.is,https://github.com/hail-is/hail/pull/5110,1,['assert'],['asserting']
Testability,Now tests are passing...,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5934#issuecomment-485610023:4,test,tests,4,https://hail.is,https://github.com/hail-is/hail/pull/5934#issuecomment-485610023,1,['test'],['tests']
Testability,"Now that createDatabase is gone, rename createDatabase2Step => createDatabase2, and accept createDatabase in build.yaml for creating database. In follow up PRs, I will:; - rename createDatabase2 => createDatabase in build.yaml,; - don't support createDatabase2, completing the change. I can't do this in one change because this PR is tested/deployed by the _previous_ CI, not the one in this PR, so it has to be done in stages. Such is the microservices life.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7887:334,test,tested,334,https://hail.is,https://github.com/hail-is/hail/pull/7887,1,['test'],['tested']
Testability,"Now that test databases are hosted on their own servers instead of the single cloud-hosted MySQL, we can ramp up the parallelism both in our tests and in the number of PRs that we run at once. I recall that even before we had this DB bottleneck we still restricted the number of PRs running at once for cost reasons, but if that's not the case we could remove that restriction entirely.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12974:9,test,test,9,https://hail.is,https://github.com/hail-is/hail/pull/12974,2,['test'],"['test', 'tests']"
Testability,"Now that we have the SQL query monitoring, I would love to also see just the simple comparison of the total number of queries we perform over a 1-minute period under high load. We have the tools now to see just what chunk of overall database communication we are cutting down on, which is an achievement in itself. Just need to run the test!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11346#issuecomment-1036284520:336,test,test,336,https://hail.is,https://github.com/hail-is/hail/pull/11346#issuecomment-1036284520,2,['test'],['test']
Testability,"Now the command:; ```; pca_vds.logreg('wald', 'sa.isCase', ['sa.scores.PC1, sa.scores.PC2']).count(); ```; gives the right error; ```; FatalError Traceback (most recent call last); <ipython-input-28-2fb5c41b2314> in <module>(); ----> 1 pca_vds.logreg('wald', 'sa.isCase', ['sa.scores.PC1, sa.scores.PC2']).count(). <decorator-gen-218> in logreg(self, test, y, covariates, root). /Users/jbloom/hail/python/hail/java.pyc in handle_py4j(func, *args, **kwargs); 105 except Py4JJavaError as e:; 106 msg = env.jutils.getMinimalMessage(e.java_exception); --> 107 raise FatalError(msg); 108 except Py4JError as e:; 109 env.jutils.log().error('hail: caught python exception: ' + str(e)). FatalError: `|' expected but `,' found; <input>:1:sa.scores.PC1, sa.scores.PC2; ^; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1502:31,log,logreg,31,https://hail.is,https://github.com/hail-is/hail/pull/1502,5,"['log', 'test']","['log', 'logreg', 'test']"
Testability,"Now the lmmreg python test is deterministic. And I found another bug in lmmreg by implementing the same test in LinearMixedRegressionSuite, which I then fixed, namely, kinshipVds should have been filtKinshipVds. Upon rebasing, that test failed again due to interaction of IntIterator and lazyFilterWith, which I've also fixed. I've added a regression test to LinearMixedRegressionSuite, paralleling the Python test, that catches both bugs.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1550:22,test,test,22,https://hail.is,https://github.com/hail-is/hail/pull/1550,5,['test'],['test']
Testability,"Now the lmmreg test is deterministic. And I found a bug in lmmreg by implementing the same test in LinearMixedRegressionSuite, which I then fixed. Namely: `kinshipVds` should have been `filtKinshipVds`. I've left this in as a regression test.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1548:15,test,test,15,https://hail.is,https://github.com/hail-is/hail/pull/1548,3,['test'],['test']
Testability,Now you should be able to do:; ```; make -C query test NAMESPACE=default PYTEST_ARGS='-k test_foo'; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11621:50,test,test,50,https://hail.is,https://github.com/hail-is/hail/pull/11621,1,['test'],['test']
Testability,"Now, as in, after this change, or now as in generally?. MatrixRead is now a parameterized IR. It has three public parameters: it has a requested type (typ) and it can drop the rows or columns. It also has a reader that produces a matrix value based on those parameters. There are currently two readers: MatrixRangeReader and MatrixNativeReader (reading a .mt file). MatrixIR.{read, range} produce these MatrixRead nodes from suitable inputs. I didn't follow this in Python, so Python has MatrixRead (corresponding to reading a .mt) and MatrixRange, which have the ""suitable"" inputs and the parser calls MatrixIR.{read, range} when parsing them. Although TableRead isn't organized this way, I did add a TableIR.read. The problem here is that MatrixNativeReader has the spec that comes from reading the metadata, so either I need to (1) open and read the metadata in Python (duplicating the metadata parsing logic), (2) call into Scala to read the metadata, but then re-encode it when I serialize the IR node, or (3) don't include the spec in the serialized form and let Scala read the metadata when parsing. I chose (3).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3896#issuecomment-403049982:906,log,logic,906,https://hail.is,https://github.com/hail-is/hail/pull/3896#issuecomment-403049982,1,['log'],['logic']
Testability,"Nuked GenotypeStream, which includes ""lz4 decompression logic"" (although LZ4Utils is still there in case we want to use it), pending: https://github.com/hail-is/hail/pull/2047. nuked constant vector handling and AC which I think resolves the linreg comment: https://github.com/hail-is/hail/pull/2042",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1140#issuecomment-319507752:56,log,logic,56,https://hail.is,https://github.com/hail-is/hail/issues/1140#issuecomment-319507752,1,['log'],['logic']
Testability,"Nuked `UnsafeRowBuilder` and associated tests. There was a bug in the tests that the stronger asserts in MemoryBuffer caught. Easier to nuke than fix, since we aren't planning to use it.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2074#issuecomment-321102215:40,test,tests,40,https://hail.is,https://github.com/hail-is/hail/pull/2074#issuecomment-321102215,3,"['assert', 'test']","['asserts', 'tests']"
Testability,"OK! Let's put this in. I'll continue to clean up batch today and make new PRs to do so. In the meantime, I'll also do some scale testing.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6600#issuecomment-513258164:129,test,testing,129,https://hail.is,https://github.com/hail-is/hail/pull/6600#issuecomment-513258164,1,['test'],['testing']
Testability,"OK, I added a 1min benchmark",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7962#issuecomment-578331901:19,benchmark,benchmark,19,https://hail.is,https://github.com/hail-is/hail/pull/7962#issuecomment-578331901,1,['benchmark'],['benchmark']
Testability,"OK, I added a pair of simple tests and got everything working. There's one wrinkle: I don't want to ship jars around so I need the executors to have the same jar as the client. That means the need the test jar for the tests. I'm not quite sure how to properly parameterize that in the build system yet, so I'm just leaving it with the test jar for the moment.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6221#issuecomment-499365037:29,test,tests,29,https://hail.is,https://github.com/hail-is/hail/pull/6221#issuecomment-499365037,8,['test'],"['test', 'tests']"
Testability,"OK, I changed _dest_type not to stat the destination if treat_dest_as=Transfer.FILE. I regenerated the copy specs (a few changed) and the test_copy_dest_target_file_is_dir test only fails on the local filesystem. Back to you.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9822#issuecomment-764875037:172,test,test,172,https://hail.is,https://github.com/hail-is/hail/pull/9822#issuecomment-764875037,1,['test'],['test']
Testability,"OK, I cleaned this up a bit. Now stacked on: https://github.com/hail-is/hail/pull/5826. Summary of changes:; - added heal; - pipeline is now batch rather than job centeric; - batch logs page shows logs for all batch jobs; - GET /batches/{id} endpoint now returns entire array of jobs, instead of the state counter and exit_codes",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5814#issuecomment-481079454:181,log,logs,181,https://hail.is,https://github.com/hail-is/hail/pull/5814#issuecomment-481079454,2,['log'],['logs']
Testability,"OK, I don't love specifying it in `hl.init`, but that is implemented here. Assuming the tests pass, then this should work and it also means that users don't have to restart the Dataproc clusters to turn on requester pays, they can `hl.stop` and `hl.init`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12133#issuecomment-1230566542:88,test,tests,88,https://hail.is,https://github.com/hail-is/hail/pull/12133#issuecomment-1230566542,1,['test'],['tests']
Testability,"OK, I eliminated a bunch of `log.exception` that are either retried or re-raised. I completely eliminated some of them and in other cases I downgraded them to warning.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9980#issuecomment-775247626:29,log,log,29,https://hail.is,https://github.com/hail-is/hail/pull/9980#issuecomment-775247626,1,['log'],['log']
Testability,"OK, I figured out what was happening. The problem wasn't with cerberus (although I'm happy to with my change), it is that json.dump always converts a dictionary key into a string. I had with a key None, and it got turned into the string 'null' in json, because json object values must string keys:. ```; >>> import json; >>> d = {None: 5, 'foo': None}; >>> json.loads(json.dumps(d)); {'null': 5, 'foo': None}; ```. I remove the broken test. Note, I pushed two more changes that probably need a proper review:; - moved jobs validation to batch (from batch_client), I'd been meaning to do that,; - and I wrote the batch validator explicit in the style of the jobs validator (I'd be meaning to do that, too).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7915#issuecomment-575944836:435,test,test,435,https://hail.is,https://github.com/hail-is/hail/pull/7915#issuecomment-575944836,1,['test'],['test']
Testability,"OK, I finally understand why this code change causes the test to pass, and am convinced that this is the wrong change. I removed the assertion in `upcast` (for value IRs) that checks that the requested type is a supertype of the IR type -- this assertion will definitely be violated.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4585#issuecomment-431703672:57,test,test,57,https://hail.is,https://github.com/hail-is/hail/pull/4585#issuecomment-431703672,3,"['assert', 'test']","['assertion', 'test']"
Testability,"OK, I gave you maximum spicy. I don't think it's so bad, but let me know if you want me to cut it up. Some remarks:; - This PR successfully tests (and it passes!) and then cleans up this branch: https://github.com/hail-is/hail/pull/5842. See `build.yaml`. It's a thing of beauty (I think).; - That branch has everything but Scala tests and dataproc/cloudtools tests. The latter are easy, the former are a little messy since I want to test against a test jar, and I've decided to switch to maven for that.; - No support for publish or deploy yet.; - There are synchronous calls it `git` in various places which can make the UI sluggish. I'll fix those in another PR.; - Work remains to validate build.yaml and the deploy step yaml.; - I currently run jinja2 if the file (Dockerfile or deployment yaml) ends in `.in`, but I think I'm going to make it unconditional. `.in` just seem error prone.; - In CreateDatabaseStep, I put secret credentials in the pod configuration. That's not ideal, but I don't think it is a serious problem, because nobody who isn't privileged can read the pods, and I can fix it in a later PR (the create database step should generate the passwords, not ci2).; - I disabled the fixme pylint message (on # FIXME comments), since are fixmes are longer lived than a single change sometimes.; - I'm slightly confused about runImage (which generates a batch job) and deploy of a pod spec (which runs kubectl apply as a batch job). Right now, runImage always runs in batch-pods, and a deploy job runs in whatever namespace you specify. Fixes https://github.com/hail-is/hail/issues/5903",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5891:140,test,tests,140,https://hail.is,https://github.com/hail-is/hail/pull/5891,5,['test'],"['test', 'tests']"
Testability,"OK, I improved the tests two ways:. 1. I allocate a random amount of memory in the region to start so things don't always start at offset 0. 2. I test addRegionValue adding a value at the top level and and a nested level (by allocating a non-unsafe Row when t == TStruct) so it calls through to RVB.addRow. I verified it would have caught the previous errors, and it caught another error (toOff was wrong in addRegionValue because we called currentOffset before allocateRoot). Hopefully good to go now.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2299#issuecomment-336949521:19,test,tests,19,https://hail.is,https://github.com/hail-is/hail/pull/2299#issuecomment-336949521,2,['test'],"['test', 'tests']"
Testability,"OK, I moved the file format test changes to https://github.com/hail-is/hail/pull/11906. This change can go in independently, but #11906 will even out the test job times and make developer experience better. Service backend tests on #11904 which should be representative of a normal PR:. id | name | state | exit_code | duration; -- | -- | -- | -- | --; 118 | test_hail_python_service_backend_0 | Success | Success 🎉 | 24 minutes; 119 | test_hail_python_service_backend_1 | Success | Success 🎉 | 27 minutes; 120 | test_hail_python_service_backend_2 | Success | Success 🎉 | 24 minutes; 121 | test_hail_python_service_backend_3 | Success | Success 🎉 | 41 minutes; 122 | test_hail_python_service_backend_4 | Success | Success 🎉 | 21 minutes. Service backend tests on this PR (albeit with #11906 which evens out test times):. id | name | state | exit_code | duration; -- | -- | -- | -- | --; 118 | test_hail_python_service_backend_0 | Failed | Failure 🤷‍♀️ (1) | 31 minutes; 119 | test_hail_python_service_backend_1 | Success | Success 🎉 | 31 minutes; 120 | test_hail_python_service_backend_2 | Success | Success 🎉 | 28 minutes; 121 | test_hail_python_service_backend_3 | Success | Success 🎉 | 33 minutes; 122 | test_hail_python_service_backend_4 | Success | Success 🎉 | 26 minutes. I think there is almost no effect on service backend test times! We should really see if there's a way to improve the autoscaler & schedule to achieve this on its own.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11902#issuecomment-1152508508:28,test,test,28,https://hail.is,https://github.com/hail-is/hail/pull/11902#issuecomment-1152508508,6,['test'],"['test', 'tests']"
Testability,"OK, I seem to have resolved this error, but now another transient error has dramatically increased; its frequency. I included my test code which was reliably reproducing this error approximately once per run. I ran; this three times using a commit very similar to `main` [1]. All three runs failed:. 1. In run 1, three partitions had this error.; 2. In run 2, one partition had a different error (#13721 to be exact).; 3. In run 3, two partitions had this error. After my fix [2] for this issues bug, the #13721 bug became super common! I saw it 50 times in my first run:; ```; Caused by: is.hail.relocated.com.google.cloud.storage.StorageException: Missing Range header in response; 	|> PUT https://storage.googleapis.com/upload/storage/v1/b/aou_tmp/o?name=tmp/hail/icullIwHC8dQXtq8JU2uDW/aggregate_intermediates/-ntpjdAQ9sKaR8lK26cV0p5790a4d87-9035-41ae-afc6-326f710d9a89&uploadType=resumable&upload_id=ADPycdtl5JSqwvftT4W190_-ueC032I_oZcwLAlVVMFkqp06W4eY8b-XMwf8DeT7If9I7uIgmI_PLCuFsExsT0aEh2b4FrHtAiUktumQbvgl1U0icw; 	|> content-range: bytes */*; 	| ; 	|< HTTP/1.1 308 Resume Incomplete; 	|< content-length: 0; 	|< content-type: text/plain; charset=utf-8; 	|< x-guploader-uploadid: ADPycdtl5JSqwvftT4W190_-ueC032I_oZcwLAlVVMFkqp06W4eY8b-XMwf8DeT7If9I7uIgmI_PLCuFsExsT0aEh2b4FrHtAiUktumQbvgl1U0icw; 	| ; ```. Luckily, that one is actually trivial to fix, we just need to [update to the latest GCS client; library](https://github.com/hail-is/hail/issues/13721#issuecomment-1737924344). # Test Code. ```python3; import hail as hl; import gnomad.utils.sparse_mt. tmp_dir = 'gs://danking/tmp/'; vds_file = 'gs://neale-bge/bge-wave-1.vds'; out = 'gs://danking/foo.vcf.bgz'. vds = hl.vds.read_vds(vds_file); mt = hl.vds.to_dense_mt(vds); t = gnomad.utils.sparse_mt.default_compute_info(mt); t = t.annotate(info=t.info.drop('AS_SB_TABLE')); t = t.annotate(info = t.info.drop(; 'AS_QUALapprox', 'AS_VarDP', 'AS_SOR', 'AC_raw', 'AC', 'AS_SB'; )); t = t.drop('AS_lowqual'). hl.methods.export_vcf(dataset = t,",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13409#issuecomment-1737926184:129,test,test,129,https://hail.is,https://github.com/hail-is/hail/issues/13409#issuecomment-1737926184,1,['test'],['test']
Testability,"OK, I tested my branch twice with stress. No error logs. Many warnings due to known deadlock errors. Otherwise it looks clean. I've pushed those changes onto this branch. Let's merge tomorrow first thing.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10920#issuecomment-956662015:6,test,tested,6,https://hail.is,https://github.com/hail-is/hail/pull/10920#issuecomment-956662015,2,"['log', 'test']","['logs', 'tested']"
Testability,"OK, I think I addressed all the comments. Here is a summary of the code changes I made:; - use *-tokens instead of *-jwt for the session tokens; - db event to clean up sessions,; - there was a bunch of legacy garbage in batch/ and batch/Makefile that I nuked,; - added hailtop test for deploy_config,; - fixed up hail ServiceBackend (which isn't actually tested now); - create_user => insert_user. I think there is still some legacy garbage in apiserver/, but that's not being deployed right now so I just left it. Let me know if I missed anything.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6892#issuecomment-528993572:277,test,test,277,https://hail.is,https://github.com/hail-is/hail/pull/6892#issuecomment-528993572,2,['test'],"['test', 'tested']"
Testability,"OK, I think I addressed the comments and it is ready for another look. I tested the batch2 UI witih deploy dev and it seems good.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7530#issuecomment-555241754:73,test,tested,73,https://hail.is,https://github.com/hail-is/hail/pull/7530#issuecomment-555241754,1,['test'],['tested']
Testability,"OK, I think I addressed the comments. I will do a dry run through to make everything is working. I will test this again from scratch, but I think it's more important to get this in and focus on building automated tests for it rather than spend time hand testing.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9713#issuecomment-782270602:104,test,test,104,https://hail.is,https://github.com/hail-is/hail/pull/9713#issuecomment-782270602,3,['test'],"['test', 'testing', 'tests']"
Testability,"OK, I think this is ready to go.; - Migration tested with passing colors (!); - I disabled the check incremental loop (but left the code in for future debugging); - I updated estimated-current.txt with the latest from improve-cancel.sql",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7933#issuecomment-577704626:46,test,tested,46,https://hail.is,https://github.com/hail-is/hail/pull/7933#issuecomment-577704626,1,['test'],['tested']
Testability,"OK, I verified python tests pass. Should be ready for a look.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2588#issuecomment-352128339:22,test,tests,22,https://hail.is,https://github.com/hail-is/hail/pull/2588#issuecomment-352128339,1,['test'],['tests']
Testability,"OK, I will run the stress test later this week. It sounds like the stress test is really important to convincing us that batch is correct. I want to migrate that from a manual process into a normal test. I'm going to add a performance test that requires a 10,000 or 1,000 job /bin/true batch to finish in ~8 or 0.8 minutes. Let's see if we can add correctness checks to that that satisfy the needs of stress.py",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10985#issuecomment-951320966:26,test,test,26,https://hail.is,https://github.com/hail-is/hail/pull/10985#issuecomment-951320966,4,['test'],['test']
Testability,"OK, I won't be able to fix this. @ehigham @patrick-schultz @daniel-goldstein some combo of you three can probably figure it out. The local backend tests that hit requester pays buckets are failing with new Spark. New Spark needs new GCS hadoop connector (see the Dockerfiles). New GCS hadoop connector has [brand new configuration parameters](https://github.com/GoogleCloudDataproc/hadoop-connectors/blob/v3.0.0/gcs/INSTALL.md). Somehow I managed to make the normal Spark backend work correctly but the Local backend (which still, afaik, uses Spark & Hadoop for filesystems) is still trying to pick up CI's credentials instead of the test account's credentials. ```; E hail.utils.java.FatalError: GoogleJsonResponseException: 403 Forbidden; E GET https://storage.googleapis.com/storage/v1/b/hail-test-requester-pays-fds32/o/zero-to-nine?fields=bucket,name,timeCreated,updated,generation,metageneration,size,contentType,contentEncoding,md5Hash,crc32c,metadata&userProject=hail-vdc; E {; E ""code"": 403,; E ""errors"": [; E {; E ""domain"": ""global"",; E ""message"": ""ci-910@hail-vdc.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project. Permission 'serviceusage.services.use' denied on resource (or it may not exist)."",; E ""reason"": ""forbidden""; E }; E ],; E ""message"": ""ci-910@hail-vdc.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project. Permission 'serviceusage.services.use' denied on resource (or it may not exist).""; E }; E ; E Java stack trace:; E java.io.IOException: Error accessing gs://hail-test-requester-pays-fds32/zero-to-nine; E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl.getObject(GoogleCloudStorageImpl.java:1986); E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloudStorageImpl.getItemInfo(GoogleCloudStorageImpl.java:1882); E 	at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.gcsio.GoogleCloud",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14158#issuecomment-1969609236:147,test,tests,147,https://hail.is,https://github.com/hail-is/hail/pull/14158#issuecomment-1969609236,3,['test'],"['test', 'test-requester-pays-', 'tests']"
Testability,"OK, I'm not sure how to fix this but the work is to explain to the GCS Hadoop Connector which credentials we want it to use. See the failure here: https://batch.hail.is/batches/8136069/jobs/49 . It uses CI's credentials instead of the test credentials. We use core-site.xml to do this in Spark <3.5, but the GCS connector is different in Spark 3.5 and it uses different configuration parameters. My most recent change did not successfully configure it. Daniel G can help you a bit with credentials in Batch if that's necessary but the real work is to figure out how to tell the GCS Hadoop Connector to use the /gsa-key/key.json file.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14158#issuecomment-1961672844:235,test,test,235,https://hail.is,https://github.com/hail-is/hail/pull/14158#issuecomment-1961672844,1,['test'],['test']
Testability,"OK, `batch-svc` has privileges to create/delete/list/get/etc. persistentvolumeclaims in batch-pods now. `test-svc` always had privileges to do everything in the `test` namespace.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5503#issuecomment-469421690:105,test,test-svc,105,https://hail.is,https://github.com/hail-is/hail/pull/5503#issuecomment-469421690,2,['test'],"['test', 'test-svc']"
Testability,"OK, benchmarks added for row, col, and entry export on an MT.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6841#issuecomment-521656677:4,benchmark,benchmarks,4,https://hail.is,https://github.com/hail-is/hail/pull/6841#issuecomment-521656677,1,['benchmark'],['benchmarks']
Testability,"OK, but I'm not sure it's the right change to make. Now some jobs will fail silently.; I think the right thing to do would be to change how benchmark jobs are run and always collect results, regardless of job outcome (making it resiliant to some benchmark files not being in their expected locations, which we'll have to do anyway). That way, you'd still see the failures in the batch.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12838#issuecomment-1527578232:140,benchmark,benchmark,140,https://hail.is,https://github.com/hail-is/hail/pull/12838#issuecomment-1527578232,2,['benchmark'],['benchmark']
Testability,"OK, code is stable again, scale tests are working. Run with:. ```; ~/hail/notebook $ PYTHONPATH=../hail/python:../gear python3 scale-test.py 10 <workshop> <password>; ```. ```; successes: 10 / 10 = 1.0; mean time: 2.3504347085952757; max time: 3.135228157043457; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7112#issuecomment-534603185:32,test,tests,32,https://hail.is,https://github.com/hail-is/hail/pull/7112#issuecomment-534603185,2,['test'],"['test', 'tests']"
Testability,"OK, cool. Thanks for adding the dataproc tests! I'll approve this once the current release goes in, then we'll try this out for the next release, 0.2.38.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8550#issuecomment-613603462:41,test,tests,41,https://hail.is,https://github.com/hail-is/hail/pull/8550#issuecomment-613603462,1,['test'],['tests']
Testability,"OK, got these changes in -- thanks @cseed! Still waiting for testing...",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/979#issuecomment-254556974:61,test,testing,61,https://hail.is,https://github.com/hail-is/hail/pull/979#issuecomment-254556974,1,['test'],['testing']
Testability,"OK, here's the most recent failure https://batch.hail.is/batches/8090848/jobs/21993. Don't be duped by my bad log message! There were zero transient errors. I added a log statement that increments the number of errors and prints that message after *every* error, even if it's not transient. . This time it was partition 20053 (we keep moving earlier?). I forgot to catch and rethrow the error with the toString of the input buffer, but I'm not sure there is much to learn from that anyway. FWIW, 20053 was successful in the two previous executions:; 1. https://batch.hail.is/batches/8069235/jobs/21993; 2. https://batch.hail.is/batches/8083195/jobs/21993. Interestingly the peak bytes are not consistent:; ```; 2023-10-24 19:59:47.756 : INFO: TaskReport: stage=0, partition=20053, attempt=0, peakBytes=58394624, peakBytesReadable=55.69 MiB, chunks requested=5513, cache hits=5501; 2023-10-24 19:59:47.759 : INFO: RegionPool: FREE: 55.7M allocated (7.7M blocks / 48.0M chunks), regions.size = 21, 0 current java objects, thread 9: pool-2-thread-1; ```; ```; 2023-11-08 19:42:40.000 : INFO: TaskReport: stage=0, partition=20053, attempt=0, peakBytes=61343744, peakBytesReadable=58.50 MiB, chunks requested=5513, cache hits=5501; 2023-11-08 19:42:40.000 : INFO: RegionPool: FREE: 58.5M allocated (10.5M blocks / 48.0M chunks), regions.size = 21, 0 current java objects, thread 10: pool-2-thread-2; ```. Whatever is causing this bug is rare. Approximately once every 31,000 partitions. The CDA IR is the same except for a couple iruid names and the order of the aggregators in the aggregator array is swapped (collect & take vs take & collect). AFAICT, the GCS Java library doesn't do any streaming verification of the hash. We could compute the CRC32c in a streaming manner and fail if/when we get to the end of the object, but this wouldn't work when we read intervals. I'm really mystified.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13979#issuecomment-1834606385:110,log,log,110,https://hail.is,https://github.com/hail-is/hail/issues/13979#issuecomment-1834606385,4,['log'],['log']
Testability,"OK, if I add the following additional dependencies in gradle:. ```; 	include(dependency('net.sourceforge.f2j:arpack_combined_all:0.1')); 	include(dependency('com.github.fommil.netlib:native_system-java:1.1')); 	include(dependency('com.github.fommil.netlib:netlib-native_system-linux-x86_64:1.1')); 	include(dependency('com.github.fommil.netlib:netlib-native_ref-linux-x86_64:1.1')); 	include(dependency('com.github.fommil:jniloader:1.1')); ```. it correctly loads on Linux:. > 2018-04-30 00:13:07 JniLoader: INFO: successfully loaded /tmp/jniloader8608320282306924695netlib-native_system-linux-x86_64.so. I'll test the analog on OSX tomorrow. Are you sure we're getting natives on Dataproc now? This definitely worked in the past. I get a 4x speedup (in the 1024 cases):. 214 ms ± 19.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each). Now we're only 35x slower.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3335#issuecomment-385310865:610,test,test,610,https://hail.is,https://github.com/hail-is/hail/pull/3335#issuecomment-385310865,1,['test'],['test']
Testability,"OK, if you merge https://github.com/danking/hail/tree/add-version-endpoint (`add-version-endpoint` in my repo, `github.com/danking/hail`) this should pass the tests and we can get it merged!",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10085#issuecomment-809670037:159,test,tests,159,https://hail.is,https://github.com/hail-is/hail/pull/10085#issuecomment-809670037,1,['test'],['tests']
Testability,"OK, in the interest of fixing these problems for people, let's merge without tests. Testing that two plots look the same will have to be future work. I think the environment/OS is influencing image generation in some subtle way such that the generated plots images are not the same.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12768#issuecomment-1480307816:77,test,tests,77,https://hail.is,https://github.com/hail-is/hail/pull/12768#issuecomment-1480307816,2,"['Test', 'test']","['Testing', 'tests']"
Testability,"OK, now passes the tests. Not sure if `minRep` should be called in `VariantSubgen` or in `LoadBGenTest` (as I did). All depends on how `VariantSubgen` is used (e.g. if testing minRep)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1656#issuecomment-293058402:19,test,tests,19,https://hail.is,https://github.com/hail-is/hail/pull/1656#issuecomment-293058402,2,['test'],"['testing', 'tests']"
Testability,"OK, plenty of tests. Just need to know where the benchmarks go.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6841#issuecomment-521651919:14,test,tests,14,https://hail.is,https://github.com/hail-is/hail/pull/6841#issuecomment-521651919,2,"['benchmark', 'test']","['benchmarks', 'tests']"
Testability,"OK, should be fixed. apiserver depends on hail, runs its own tests now.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5624#issuecomment-474138152:61,test,tests,61,https://hail.is,https://github.com/hail-is/hail/pull/5624#issuecomment-474138152,1,['test'],['tests']
Testability,"OK, so the big insight is that ""InstanceConfig"" is really just ""ResourcesForAParticularInstance"" (well, and, sometimes, ""ResourcesOfARepresentativeInstance""). I trimmed the InstanceConfig down *significantly* removing the ""vm_config"". Now the InstanceConfig is cheap and easy to create and there's no circularity between vm_config and instance config. I pushed that through everywhere and then abstracted the common create_instance logic for pool and job-private into InstanceCollection. With both of those changes, I was able to modify the ResourceManager's API to expose methods for constructing instance configs. However, the instance config isn't critical to the operation of the ResourceManager. It's just an interface for communicating an instance's resources to the rest of the code base.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10920#issuecomment-956500279:432,log,logic,432,https://hail.is,https://github.com/hail-is/hail/pull/10920#issuecomment-956500279,1,['log'],['logic']
Testability,"OK, so, I took the GRCh38 file that we test against and named it `bar`. I downloaded the gist and named it `foo`. | header | footer | success? |; |---|---|---|; |foo|bar|success|; |bar|bar|success|; |bar|foo|failure|; |foo|foo|failure|. So clearly the issue is the variants. Here's an example of running on just the first handful of variants: https://batch.hail.is/batches/8089052. ```; chr1	1339585	.	G	A	.	.	.; chr1	24907372	.	C	T	.	.	.; chr1	36859143	.	G	T	.	.	.; chr1	37969436	.	T	C	.	.	.; chr1	40416828	.	G	A	.	.	.; chr1	41581842	.	G	A	.	.	.; chr1	43920822	.	T	C	.	.	.; chr1	45327881	.	G	A	.	.	.; chr1	46817055	.	CT	C	.	.	.; chr1	54999203	.	C	T	.	.	.; chr1	65218884	.	C	T	.	.	.; chr1	102962250	.	G	T	.	.	.; chr1	111756087	.	G	C	.	.	.; chr1	113881802	.	G	A	.	.	.; chr1	117920205	.	G	A	.	.	.; chr1	151408784	.	G	C	.	.	.; chr1	151428261	.	C	T	.	.	.; chr1	152305539	.	G	C	.	.	.; chr1	152884596	.	C	A	.	.	.; chr1	153933240	.	C	T	.	.	.; chr1	156624012	.	G	A	.	.	.; chr1	159205821	.	CT	C	.	.	.; chr1	173803162	.	G	T	.	.	.; chr1	179813831	.	G	A	.	.	.; chr1	179917551	.	T	C	.	.	.; chr1	180935962	.	G	C	.	.	.; chr1	180941229	.	G	A	.	.	.; chr1	186893053	.	C	A	.	.	.; chr1	201363319	.	G	A	.	.	.; chr1	223749094	.	A	G	.	.	.; chr1	224294328	.	G	A	.	.	.; chr1	235809337	.	G	A	.	.	.; chr1	241592073	.	G	T	.	.	.; chr2	9376947	.	G	A	.	.	.; chr2	11618532	.	C	T	.	.	.; ```. We can see the characteristic super high memory use.; <img width=""570"" alt=""Screenshot 2023-11-28 at 16 35 26"" src=""https://github.com/hail-is/hail/assets/106194/e5dfa586-5c77-479b-8050-9b0b7d2fe319"">. ---. If we use the same header, but just one variant, it succeeds, but notice that the RAM use grows rapidly. https://batch.hail.is/batches/8089064/jobs/3; ```; chr1	241592073	.	G	T	.	.	.; ```; <img width=""577"" alt=""Screenshot 2023-11-28 at 16 37 39"" src=""https://github.com/hail-is/hail/assets/106194/90c5ab45-9ca4-43e0-9a97-bf6032863f32"">. ---. If we use the same header with this variant from our (successful) test VCF, the RAM use grows",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13989#issuecomment-1830846344:39,test,test,39,https://hail.is,https://github.com/hail-is/hail/issues/13989#issuecomment-1830846344,2,['test'],['test']
Testability,"OK, so, this is apparently an issue where browsers have not yet really implemented the standard correctly. From my reading of [HTML 2.6.4](https://html.spec.whatwg.org/#cors-settings-attributes), `crossorigin=""anonymous""` ought to be sufficient for requests to the same origin as the page containing the script tag. Jake Archibald has an informative [blog post](https://jakearchibald.com/2017/es-modules-in-browsers/) about modules. He links to a [demo](https://module-script-tests-sreyfhwvpq.now.sh/cookie-page) of three cross origin configurations. The three options are:; ```; <script type=""module"" src=""cookie-script""></script>; <script type=""module"" crossorigin="""" src=""cookie-script?1""></script>; <script type=""module"" crossorigin=""use-credentials"" src=""cookie-script?2""></script>; ```; I'm using Safari Version 13.1 (14609.1.20.111.8). I usually only see the very last script working. However, inexplicably, I have seen the first one very rarely work. All I've been doing is refreshing here and there as I try to understand this. The Safari inspector confirms that the cookie is only sent with thee last option. So, anyway, I'm adding `crossorigin=""use-credentials""`.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8928#issuecomment-639218007:476,test,tests-sreyfhwvpq,476,https://hail.is,https://github.com/hail-is/hail/pull/8928#issuecomment-639218007,1,['test'],['tests-sreyfhwvpq']
Testability,"OK, so, this really feels like bad data. We just merged https://github.com/hail-is/hail/commit/98adcce1d07001995b0819fd6afe161bf34ba840 which fixed https://github.com/hail-is/hail/issues/13979 . Google Cloud Storage's Java library was very rarely returning just flat-out bad data. The frequency of occurrence on one particularly large pipeline appears to be 1/30000 tasks (0.003% or 3 in 100,000). The tasks were reading two files, the larger of which was 131MiB. The Java library reads in 8MiB chunks so that's at least 17 network requests per partition. That puts the frequency of this closer to 1 in 1,000,000 requests or 1 in 10TiB of data read. Before we had Zstandard, it seems that this data corruption either (a) was unnoticed (b) caused a rare decoding error or (c) caused segfaults. After we added Zstandard (0.2.119), decompression often failed due to corrupt data. It seems to me that Zstandard more aggressively verifies integrity than LZ4 does. OK, so, when was this bug introduced in Hail? As far as I can tell, this new code path was added in google-cloud-storage 2.17.0 almost one year ago: https://github.com/googleapis/java-storage/commit/94cd2887f22f6d1bb82f9929b388c27c63353d77 . We upgraded to 2.17.1 (😭 ) in Hail 0.2.109 https://github.com/hail-is/hail/commit/fec0cc2263c04c00e02cef5dda8ec46916717152 . All of the attempts above could have been plagued by this rare transient data corruption error. OK, action items:. - [ ] Ask Cal and Lindo to try their pipelines again with the next release of Hail 0.2.127.; - [x] Hail must introduce large-scale testing before releases. We, sadly, cannot assume our underlying storage libraries are reliable. https://github.com/hail-is/hail/issues/14082. Once the first action item is successfully completed, I will close this issue. For the second action item, I have created a separate ticket.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13688#issuecomment-1845732114:1572,test,testing,1572,https://hail.is,https://github.com/hail-is/hail/issues/13688#issuecomment-1845732114,1,['test'],['testing']
Testability,"OK, so. I added test_dataproc as a separate build step and pulled that code out of the makefile into a script. I'm running a dev-deploy test of it here: ~~https://ci.hail.is/batches/32232~~. I added a commit to this branch (not present in the aforementioned dev deploy) that exits 0 if the git tag already exists. This prevents running the Dataproc tests on every master commit. I broadened the scope to include `dev`. This means that developers can run a deploy with `hailctl dev deploy hail-is/hail:master deploy`. I haven't tested the deploy step. I volunteer to do the next deploy and deal with whatever is broken. EDIT: Copying data between jobs loses the chmod settings so I had to switch away from `./`, that was why the last batch failed. https://ci.hail.is/batches/32237",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8533#issuecomment-613147506:136,test,test,136,https://hail.is,https://github.com/hail-is/hail/pull/8533#issuecomment-613147506,3,['test'],"['test', 'tested', 'tests']"
Testability,"OK, so. This continues to be a mammoth PR despite a day's worth of pruning. I think it would be good to start getting some eyes on it. Over all, I feel a bit weird about it. The intention is for this to be a functional but not scalable or reliable shuffler. It will allow Hail Query to exist, albeit in a limited way (keys cannot exceed shuffler memory). However, in parallel to getting this PR merged, I'm designing the real shuffler: a horizontally scalable sorting system. So. We have to live with this code for a few months, so let's make sure we feel good about it, but also know that this is all going away in a few months. 🤷‍♀ . # High Level Overview; - implement the shuffler as a single machine, multi-threaded service which buffers keys until the write phase of a shuffle is done, then sorts the keys, then serves them to clients.; - implement non-spark shuffling as: write records to `dbuf` and write pairs of (data key, dbuf key) to shuffler, then read back re-partitioned keys and fetch records from dbuf.; - I use SBT because the Akka examples use it, it's not obvious how to do this SBT assembly merging thing in Gradle; - I'm really not using Akka properly. There's all this DataSource stuff that I don't understand. I'll probably have to get this right to get good performance, but it doesn't seem critical now and the Akka docs are incredibly hard to understand.; - I turn the optimizer off in the tests because it often optimizes away shuffles into local sorts. There are some FIXMEs throughout the code that I would appreciate thoughts on.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8205:1416,test,tests,1416,https://hail.is,https://github.com/hail-is/hail/pull/8205,1,['test'],['tests']
Testability,"OK, thanks for the pushback. This is ready for another look. Here is my understanding of the semantics of partitioners and preserved keys:. 1. A TableStage from a lowered TableIR must have a partitioner that begins with the table key, but the partitioner can have a longer key. That partitioner need not be strict; consumers that require strictness like TableAggregateByKey or TableDistinct will strictify their lowered children. 2. The lowering rule for TableKeyBy makes no assertion about the number of preserved key fields. It is possible for client code to pass a TableKeyBy IR with 0 preserved key fields, which will result in a correct but possibly unperformant execution. We will document this when we document the IR system in several months.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8649#issuecomment-623771435:475,assert,assertion,475,https://hail.is,https://github.com/hail-is/hail/pull/8649#issuecomment-623771435,1,['assert'],['assertion']
Testability,"OK, thanks, will update the tests.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5509#issuecomment-468830620:28,test,tests,28,https://hail.is,https://github.com/hail-is/hail/pull/5509#issuecomment-468830620,1,['test'],['tests']
Testability,"OK, this PR basically works except we're encountering OOMs somewhat often. I'm trying to track down which tests are triggering the OOMs, but its a bit tricky because the OOMKiller doesn't necessarily kill the test which is using a ton of memory.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11194#issuecomment-1034272076:106,test,tests,106,https://hail.is,https://github.com/hail-is/hail/pull/11194#issuecomment-1034272076,2,['test'],"['test', 'tests']"
Testability,"OK, this is now higher priority for me. The Query-on-Batch tests are absolutely hammering the database with huge spikes in deadlock errors during working hours (when deploys trigger tests).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11352#issuecomment-1039618265:59,test,tests,59,https://hail.is,https://github.com/hail-is/hail/pull/11352#issuecomment-1039618265,2,['test'],['tests']
Testability,"OK, this is working and ready for review. I tested manually that on a variety of node types, we both (1) get the expected number of containers (all the cores in the cluster are used) and (2) we get the right OOM error instead of container crashing. Your comment is addressed -- we always call increment before actually allocating, so we won't exceed the threshold.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11016#issuecomment-964540617:44,test,tested,44,https://hail.is,https://github.com/hail-is/hail/pull/11016#issuecomment-964540617,1,['test'],['tested']
Testability,"OK, this passes all the tests except for `test_vcf_parser_golden_master__gvcf_GRCh37` which inexplicably hangs. I've marked that as skip. I've attached the WIP tag because the longest tests now take 47 minutes. I'll leave this PR up as a canary for when a `main` change fails service tests. However, I won't merge it until we improve test latency. cc: @tpoterba",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11444#issuecomment-1069516954:24,test,tests,24,https://hail.is,https://github.com/hail-is/hail/pull/11444#issuecomment-1069516954,4,['test'],"['test', 'tests']"
Testability,"OK, this should do it. I'm not sure why we passed the headers when logging in, we asked to login so the old creds are irrelevant.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7020#issuecomment-529152351:67,log,logging,67,https://hail.is,https://github.com/hail-is/hail/pull/7020#issuecomment-529152351,2,['log'],"['logging', 'login']"
Testability,"OK, well, I'll remove the variant inequality tests for now, but I think we should figure out how to interval query a string-keyed table.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12484#issuecomment-1320225527:45,test,tests,45,https://hail.is,https://github.com/hail-is/hail/pull/12484#issuecomment-1320225527,1,['test'],['tests']
Testability,"OK, well. This PR modifies those tests to use the new printed form, which was a significant improvement to my development experience of the Shuffler. I also fixed tuples to print with parentheses instead of brackets.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8191#issuecomment-592574334:33,test,tests,33,https://hail.is,https://github.com/hail-is/hail/pull/8191#issuecomment-592574334,1,['test'],['tests']
Testability,"OK.; ```; [root@tele-1 ~]# pyspark --conf spark.sql.files.openCostInBytes=1099511627776 --conf spark.sql.files.maxPartitionBytes=1099511627776 --conf spark.hadoop.parquet.block.size=1099511627776 --conf spark.serializer=org.apache.spark.serializer.KryoSerializer; Python 2.7.5 (default, Nov 6 2016, 00:28:07) ; [GCC 4.8.5 20150623 (Red Hat 4.8.5-11)] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; 17/08/10 09:10:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 17/08/10 09:10:21 WARN SparkConf: ; SPARK_CLASSPATH was detected (set to '/opt/Software/hail/build/libs/hail-all-spark.jar').; This is deprecated in Spark 1.0+. Please instead use:; - ./spark-submit with --driver-class-path to augment the driver classpath; - spark.executor.extraClassPath to augment the executor classpath; ; 17/08/10 09:10:21 WARN SparkConf: Setting 'spark.executor.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; 17/08/10 09:10:21 WARN SparkConf: Setting 'spark.driver.extraClassPath' to '/opt/Software/hail/build/libs/hail-all-spark.jar' as a work-around.; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /__ / .__/\_,_/_/ /_/\_\ version 2.0.2; /_/. Using Python version 2.7.5 (default, Nov 6 2016 00:28:07); SparkSession available as 'spark'.; ```; ----------------------------; ```; >>> rdd = sc.textFile('/hail/test/BRCA1.raw_indel.vcf'); >>> from hail import *; >>> hc = HailContext(sc); hail: info: SparkUI: http://192.168.1.4:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.1-0320a61; ```; ----------------------------------; ```; >>> vds = hc.import_vcf('/hail/test/BRCA1.raw_indel.vcf'); hail: warning: `/hail/test/",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2076#issuecomment-321424071:531,log,log,531,https://hail.is,https://github.com/hail-is/hail/issues/2076#issuecomment-321424071,2,['log'],"['log', 'logging']"
Testability,"Observed again https://batch.hail.is/batches/7942284/jobs/203. This method isn't threaded at all: https://github.com/hail-is/hail/blob/5d545c8d9fb474ea211e350c5dc48c599db6f5ea/hail/src/test/scala/is/hail/fs/FSSuite.scala#L339-L368. The temporary location is drawn as 62 choose 22. So, odds of collision are 3 * 10^16. ~~I can't find the referenced case analysis in Google's latest code. [It is present in this fork](https://github.com/leogamas/java-storage/blob/2af8dfd95cdebc9e4d8252b0bbe3f092844d9f2c/google-cloud-storage/src/main/java/com/google/cloud/storage/BlobWriteChannel.java#L68-L198) from a few years ago.~~. Here's the [referenced case analysis in 2.17.1](https://github.com/googleapis/java-storage/blame/v2.17.1/google-cloud-storage/src/main/java/com/google/cloud/storage/BlobWriteChannel.java). There seems to have been a rewrite [two months ago](https://github.com/googleapis/java-storage/blame/main/google-cloud-storage/src/main/java/com/google/cloud/storage/BlobWriteChannel.java) (here's [the main commit](https://github.com/googleapis/java-storage/commit/1b52a1053130620011515060787bada10c324c0b)). That landed in [2.25.0](https://github.com/googleapis/java-storage/releases/tag/v2.25.0) which was released in July. ```; is.hail.relocated.com.google.cloud.storage.StorageException: Unable to recover in upload.; This may be a symptom of multiple clients uploading to the same upload session. For debugging purposes:; uploadId: https://storage.googleapis.com/upload/storage/v1/b/hail-test-ezlis/o?name=fs-suite-tmp-2LzGioRNy6RqIS2pfXIoSO&uploadType=resumable&upload_id=ADPycdvZ5HhnGfOKt5TE1qXWiHpqIpZnXVTYWuWUCXNPRF9HqyCB-4LvRsxNX6SUWRgk13pYrzYaa9-wXlvNZt1oct0ptaEz0bS3; chunkOffset: 16777216; chunkLength: 8388608; localOffset: 268435456; remoteOffset: 285212672; lastChunk: false. 	at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.unrecoverableState(BlobWriteChannel.java:131); 	at is.hail.relocated.com.google.cloud.storage.BlobWriteChannel.unrecoverableState(BlobWr",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12950#issuecomment-1704346911:185,test,test,185,https://hail.is,https://github.com/hail-is/hail/issues/12950#issuecomment-1704346911,1,['test'],['test']
Testability,"Obviously, look forward to feedback on the UI and let me know if you run into any UI bugs. Another todo that I've started:; - write a UI testing playbook to enumerate all the UI interactions we want to test (by hand) to validate this code.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7112#issuecomment-534267706:137,test,testing,137,https://hail.is,https://github.com/hail-is/hail/pull/7112#issuecomment-534267706,4,['test'],"['test', 'testing']"
Testability,"Obviously. I think we've loosely decoupled review from passing tests in practice. If the code looks good, you can approve it, and I will merge in when it is fixed. If the fix is non-trivial, it is on the author to dismiss and request additional review.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3322#issuecomment-379576871:63,test,tests,63,https://hail.is,https://github.com/hail-is/hail/pull/3322#issuecomment-379576871,1,['test'],['tests']
Testability,"Oh I guess uniroot is wrong, that's why I added this test 😅. I'll fix.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3776#issuecomment-398354200:53,test,test,53,https://hail.is,https://github.com/hail-is/hail/pull/3776#issuecomment-398354200,1,['test'],['test']
Testability,"Oh right sorry that doesn't make the Linux prebuilt, which you need to build locally on Linux and check in. CI should build those before testing but doesn't yet. The workaround @catoverdrive showed me when I had to remake the prebuilt was to build it in a docker container with the CI image on my machine. Would be happy to help you get them built tomorrow and/or make the appropriate updates to CI and deploy",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6083#issuecomment-492911668:137,test,testing,137,https://hail.is,https://github.com/hail-is/hail/pull/6083#issuecomment-492911668,1,['test'],['testing']
Testability,"Oh, and the app is meant to operate behind HTTPS; when deployed, running the web app with ; `npm run start` instead of `npm run prod-test` will enable secureOnly cookies.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4931#issuecomment-454272121:133,test,test,133,https://hail.is,https://github.com/hail-is/hail/pull/4931#issuecomment-454272121,1,['test'],['test']
Testability,"Oh, breaking change ➡️ http://discuss.hail.is/t/log-of-breaking-changes-in-0-2-beta/454",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3629#issuecomment-392957336:48,log,log-of-breaking-changes-in-,48,https://hail.is,https://github.com/hail-is/hail/pull/3629#issuecomment-392957336,1,['log'],['log-of-breaking-changes-in-']
Testability,"Oh, good catch. This is something we can also test for in the performance test suite: compute and use twice.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5416#issuecomment-466480355:46,test,test,46,https://hail.is,https://github.com/hail-is/hail/pull/5416#issuecomment-466480355,2,['test'],['test']
Testability,"Oh, man. I think we should have a new kind of test suite, PropertySuite (and SparkPropertySuite, or a Spark mixin) which just declares a bunch of properties to verify, like the current check.Properties (which can maybe go away). Thoughts?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/649#issuecomment-241138084:46,test,test,46,https://hail.is,https://github.com/hail-is/hail/pull/649#issuecomment-241138084,1,['test'],['test']
Testability,"Oh, that's easy, `make test-dataproc`, doing that now.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8150#issuecomment-591010047:23,test,test-dataproc,23,https://hail.is,https://github.com/hail-is/hail/pull/8150#issuecomment-591010047,1,['test'],['test-dataproc']
Testability,"Oh, woah, that test does look wrong. It's concerning that its suddenly failing. I'm not sure I care too much about tracking down exactly which dependency change caused this. We should fix the test obviously. We should add a test that verifies both `?a` and `?` have the expected data (in particular, that we didn't overwrite one with the other!).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11974#issuecomment-1276854186:15,test,test,15,https://hail.is,https://github.com/hail-is/hail/pull/11974#issuecomment-1276854186,3,['test'],['test']
Testability,"Ok @chrisvittal, tests are passing now",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11847#issuecomment-1148532911:17,test,tests,17,https://hail.is,https://github.com/hail-is/hail/pull/11847#issuecomment-1148532911,1,['test'],['tests']
Testability,"Ok solved that and a related issue. Should be good to review, tests pass.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7687#issuecomment-563899553:62,test,tests,62,https://hail.is,https://github.com/hail-is/hail/pull/7687#issuecomment-563899553,1,['test'],['tests']
Testability,"Ok, I finally figured out why the test wasn't picking up the tokens. This is going to be fairly useless to users unless/until we also bundle in a dev config, although it definitely should suffice for what I need to do. Thoughts on doing that? (either here or in a separate PR?) I imagine the config would just be like {location: gce, namespace: $default_ns} but I'm not sure if that would leads to issues?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9437#issuecomment-691234229:34,test,test,34,https://hail.is,https://github.com/hail-is/hail/pull/9437#issuecomment-691234229,1,['test'],['test']
Testability,"Ok, I had to fix some shit with gradle so that it doesn't try to call git when configuring tasks. Should pass tests now. I _hate_ gradle.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4066#issuecomment-410318525:110,test,tests,110,https://hail.is,https://github.com/hail-is/hail/pull/4066#issuecomment-410318525,1,['test'],['tests']
Testability,"Ok, I think I'm getting a much better understanding of the situation, thank you! I think this is a lot easier for at least me to understand and if I'm not mistaken, it's mostly just moving around of the same code into `JobSpec`, right? I think `submit` is a lot easier to follow now, though I do sympathize with the pain of the three round-trips for small updates. What do you think about the following proposal?. 1. Jobs are always submitted to the server with job_ids relative to the update that is being submitted (sorry for the complete reversal, this is just an idea!). This shouldn't have any affect on the current create/create-fast since only 1 update means relative and absolute job ids are the same. This also means that the client doesn't need to know what the `start_job_id` is ahead of submitting a bunch. Submitting the update could return the `start_job_id` such that the client can rectify its local `Job` objects with absolute IDs like you do in `_get_job_specs_as_json` after the fact. The server will take care of doing `absolute_job_id = update_start_job_id + in_update_job_id`.; 2. parent_ids are represented as positive integers that are tagged with a type, either `in-update` or `absolute`. This is very similar to what you were previously doing with negative numbers, but I think baking it into the schema is going to be less foot-gunny than negative numbers, and the client doesn't have to do any special logic of counting backwards. Sorry if it's similar to what you were doing before but I think it has taken me a while to fully understand the limitations here. I also think it wouldn't take much changes to this current client implementation to do this.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12010#issuecomment-1217244185:1430,log,logic,1430,https://hail.is,https://github.com/hail-is/hail/pull/12010#issuecomment-1217244185,1,['log'],['logic']
Testability,"Ok, I've addressed your comment, corrected requiredness inference for `PartitionNativeWriter` and `SplitPartitionWriter` and revamped things so that the key is not determined based on whether or not there is an index. I've also bumped file version and regenerated files. . I'd be interested to see what you think about testing / whether there's more testing you would do. This is harmless change right now if all the normal tests pass since it's just adding a new metadata field that's unused save for a few tests, but we don't want to start marking files ""distinctlyKeyed"" that aren't and then run into problems down the road when we implement the new join behavior.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11151#issuecomment-1015626695:319,test,testing,319,https://hail.is,https://github.com/hail-is/hail/pull/11151#issuecomment-1015626695,4,['test'],"['testing', 'tests']"
Testability,"Ok, I've moved the tests from their own test suite into TableIR, and adjusted the `assertEvalsTo` stuff to go through `SparkBackend`. . @danking I had to add `ArrayFlatMap` to cxx.Emit in order to get the relevant tests to start actually getting compiled through the SparkBackend. It's a pretty straightforward modification of the ArrayMap logic above it, and it's being tested through all the IRSuite tests, but if you'd like me to break it out, please let me know.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5127#issuecomment-454913111:19,test,tests,19,https://hail.is,https://github.com/hail-is/hail/pull/5127#issuecomment-454913111,7,"['assert', 'log', 'test']","['assertEvalsTo', 'logic', 'test', 'tested', 'tests']"
Testability,"Ok, I've split out the element-wise special ops to their own test so now there are two logical groups. I also moved assert_eq and assert_close to the top level to reduce repetitive defs and `self.assertTrue(np.array_equal(...to.numpy(),...)`. Plus a bit more structure in the top docs.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3671#issuecomment-392871508:61,test,test,61,https://hail.is,https://github.com/hail-is/hail/pull/3671#issuecomment-392871508,3,"['assert', 'log', 'test']","['assertTrue', 'logical', 'test']"
Testability,"Ok, added test and rules. Back to you.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9487#issuecomment-701618938:10,test,test,10,https://hail.is,https://github.com/hail-is/hail/pull/9487#issuecomment-701618938,1,['test'],['test']
Testability,"Ok, all tests passing now. Removing WIP",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8268#issuecomment-596626657:8,test,tests,8,https://hail.is,https://github.com/hail-is/hail/pull/8268#issuecomment-596626657,1,['test'],['tests']
Testability,"Ok, benchmarks are pretty bad, these are the range table benchmarks from #6529. #### No Index; ```; running write_range_table_p1000...; Mean, Median: 11.79s, 11.18s; running write_range_table_p100...; Mean, Median: 4.76s, 4.67s; running write_range_table_p10...; Mean, Median: 3.28s, 3.03s; ```; #### Index; ```; running write_range_table_p1000...; Mean, Median: 28.60s, 28.88s; running write_range_table_p100...; Mean, Median: 10.17s, 10.20s; running write_range_table_p10...; Mean, Median: 9.52s, 9.44s; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6266#issuecomment-507403990:4,benchmark,benchmarks,4,https://hail.is,https://github.com/hail-is/hail/pull/6266#issuecomment-507403990,2,['benchmark'],['benchmarks']
Testability,"Ok, getting back up to speed on this. There've been a number of changes on either side of this project, so going to give new timings and profiling results for the two queries. Here are mean timings for the two queries, run 5 times, and taking the mean of all but the first. It seems there's been a considerable regression since November on the second query, highlighting our need to get automated benchmark runs in per release (https://github.com/hail-is/hail/issues/14221). | query	| spark |; |-------|-------|; | 0	| 7s |; | 1	| 87s |. Attached are YourKit profiler results of the two queries. 'fast' refers to query 0 and 'slow' to the longer-running query 1.; [seqr-profile-data.zip](https://github.com/hail-is/hail/files/14103185/seqr-profile-data.zip); [seqr-logs.zip](https://github.com/hail-is/hail/files/14104795/seqr-logs.zip)",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13882#issuecomment-1917732829:397,benchmark,benchmark,397,https://hail.is,https://github.com/hail-is/hail/issues/13882#issuecomment-1917732829,3,"['benchmark', 'log']","['benchmark', 'logs']"
Testability,"Ok, have the right branch being triggered (types not the same), but causes no issues. For:; ```scala; val typ: TableType = {; if (children.forall(_.typ == children.head.typ)) {; println(""SAME""); children.head.typ; } else {; println(""NOT THE SAME""); var i = 0; children.map(c => {; i+= 1; println(s""Child ${i}: ${PType.canonical(c.typ.rowType)}""). }); assert(children.forall(c => c.typ.rowType.isOfType(children.head.typ.rowType))); TableType(children.head.typ.rowType.deepOptional().asInstanceOf[TStruct], children.head.typ.key, children.head.typ.globalType); }; }; ```. Get. Child 1: PCStruct{locus:PCLocus(GRCh37),alleles:PCArray[PCString],rsid:PCString,qual:PFloat64,filters:PCSet[PCString],info:PCStruct{NEGATIVE_TRAIN_SITE:PBoolean,HWP:PFloat64,AC:PCArray[PInt32],culprit:PCString,MQ0:PInt32,ReadPosRankSum:PFloat64,AN:PInt32,InbreedingCoeff:PFloat64,AF:PCArray[PFloat64],GQ_STDDEV:PFloat64,FS:PFloat64,DP:PInt32,GQ_MEAN:PFloat64,POSITIVE_TRAIN_SITE:PBoolean,VQSLOD:PFloat64,ClippingRankSum:PFloat64,BaseQRankSum:PFloat64,MLEAF:PCArray[PFloat64],MLEAC:PCArray[PInt32],MQ:PFloat64,QD:PFloat64,END:PInt32,DB:PBoolean,HaplotypeScore:PFloat64,MQRankSum:PFloat64,CCC:PInt32,NCC:PInt32,DS:PBoolean},s:PCString,GT:PCCall,AD:PCArray[+PInt32],DP:PInt32,GQ:PInt32,PL:PCArray[+PInt32]}. Child 2: PCStruct{locus:PCLocus(GRCh37),alleles:PCArray[PCString],rsid:PCString,qual:PFloat64,filters:PCSet[PCString],info:PCStruct{NEGATIVE_TRAIN_SITE:PBoolean,HWP:PFloat64,AC:PCArray[PInt32],culprit:PCString,MQ0:PInt32,ReadPosRankSum:PFloat64,AN:PInt32,InbreedingCoeff:PFloat64,AF:PCArray[PFloat64],GQ_STDDEV:PFloat64,FS:PFloat64,DP:PInt32,GQ_MEAN:PFloat64,POSITIVE_TRAIN_SITE:PBoolean,VQSLOD:PFloat64,ClippingRankSum:PFloat64,BaseQRankSum:PFloat64,MLEAF:PCArray[PFloat64],MLEAC:PCArray[PInt32],MQ:PFloat64,QD:PFloat64,END:PInt32,DB:PBoolean,HaplotypeScore:PFloat64,MQRankSum:PFloat64,CCC:PInt32,NCC:PInt32,DS:PBoolean},s:PCString,GT:PCCall,AD:PCArray[PInt32],DP:PInt32,GQ:PInt32,PL:PCArray[PInt32]}. No problems doing",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8008#issuecomment-581048722:351,assert,assert,351,https://hail.is,https://github.com/hail-is/hail/pull/8008#issuecomment-581048722,1,['assert'],['assert']
Testability,"Ok, much better:; ```; Failed benchmarks in run 1:; king; pc_relate; Failed benchmarks in run 2:; king; Benchmark Name Ratio Time 1 Time 2 Mem Ratio Mem 1 (MB) Mem 2 (MB); -------------- ----- ------ ------ --------- ---------- ----------; large_range_matrix_table_sum 178.1% 206.853 368.473 100.0% 17 17; blockmatrix_write_from_entry_expr_range_mt_standardize 158.3% 871.529 1380.059 100.0% 386 386; pc_relate_5k_5k 146.9% 367.096 539.315 100.0% 385 385; ndarray_matmul_float64_benchmark 141.7% 2.984 4.227 100.0% 1 1; ld_prune_profile_25 124.9% 504.312 629.884 100.0% 208 208; join_p100_p100 121.3% 3.702 4.491 100.0% 1 1; union_p100_p100 119.7% 5.197 6.220 100.0% 1 1; block_matrix_to_matrix_table_row_major 119.5% 254.878 304.682 100.0% 385 385; read_force_count_p10 119.3% 1.803 2.150 100.0% 1 1; table_aggregate_int_stats 118.6% 17.328 20.552 100.0% 1 1; table_take 118.5% 1.018 1.206 100.0% 1 1; hwe_normalized_pca_blanczos_small_data_10_iterations 118.0% 77.412 91.313 100.0% 14 14; join_p100_p10 117.5% 13.166 15.468 100.0% 1 1; blockmatrix_write_from_entry_expr_range_mt 116.8% 228.205 266.443 100.0% 385 385; matrix_table_take_entry 114.6% 2.414 2.766 100.0% 1 1; matrix_multi_write_nothing 113.3% 252.278 285.802 100.0% 1 1; table_annotate_many_nested_dependence 112.3% 7.191 8.074 100.0% 1 1; compile_2k_merge 112.1% 236.165 264.728 100.0% 8 8; shuffle_key_rows_by_4096_byte_rows 111.5% 10.150 11.315 100.0% 2 2; union_p10_p100 111.5% 14.544 16.211 100.0% 1 1; table_aggregate_downsample_worst_case 111.3% 21.323 23.729 100.0% 1 1; read_force_count_p100 110.8% 2.336 2.589 100.0% 1 1; full_combiner_chr22 110.0% 304.996 335.580 99.6% 127 127; read_force_count_p1000 109.2% 3.998 4.367 100.0% 1 1; sentinel_cpu_hash_1 109.2% 31.027 33.884 100.0% 1 1; table_aggregate_array_sum 108.9% 12.197 13.283 100.0% 1 1; variant_and_sample_qc_nested_with_filters_2 108.4% 25.267 27.399 100.0% 1 1; read_with_index_p1000 107.8% 6.959 7.503 100.0% 1 1; union_p1000_p1000 106.2% 8.160 8.667 100.0% 1 1; ",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12981#issuecomment-1563772211:30,benchmark,benchmarks,30,https://hail.is,https://github.com/hail-is/hail/pull/12981#issuecomment-1563772211,3,"['Benchmark', 'benchmark']","['Benchmark', 'benchmarks']"
Testability,"Ok, so Cotton's new thing means emitting separate methods by hand is not a thing we do anymore. But there are two factors hurting the benchmark. . One is that the benchmark is hiding the fact that we are spending ~25 seconds serializing and de-serializing JSON for this ndarray. So the real comparison is more like 55 seconds vs 75 seconds, which is a roughly 25% speed improvement. . The other is that `hl.nd.ones` is just an alias for `hl.nd.array(hl.range(shape_product)).map(lambda x: 1).reshape((n_rows, n_cols))`. This is going to create a bunch of row major data, copy it to column major in a pretty cache inefficient way during the reshape, then do the additions. So that's eating some of the time too. We should probably have a way for all the constant methods to not go through regular array. . Anyway, 25% improvement + better interface is a win for now, we can revisit ways to make this faster in the future.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9209#issuecomment-668610293:134,benchmark,benchmark,134,https://hail.is,https://github.com/hail-is/hail/pull/9209#issuecomment-668610293,2,['benchmark'],['benchmark']
Testability,"Ok, so I thought I left a comment on here but I guess I didn't: when I tested this with dev deploy, I didn't see any plots show up, got JS console errors. So I'm not sure this was quite ready to be merged.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11712#issuecomment-1097208394:71,test,tested,71,https://hail.is,https://github.com/hail-is/hail/pull/11712#issuecomment-1097208394,1,['test'],['tested']
Testability,"Ok, what do you think of this?; ```; i = 0; while len(output) != 4:; time.sleep(0.100 * (3/2) ** i); i = i + 1; if i > 14:; break; assert len(output) != 4; ```. We exponentially back off with base 3/2. We break as soon as the condition is satisfied. If we wait more than a minute (`0.1 * (3/2)^14` is roughly 30s, so we've waited about a minute in total), we bail (and the assert will fail).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5503#issuecomment-470260178:131,assert,assert,131,https://hail.is,https://github.com/hail-is/hail/pull/5503#issuecomment-470260178,2,['assert'],['assert']
Testability,"Ok, wrote the multi byte versions, running benchmarks.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10766#issuecomment-912782196:43,benchmark,benchmarks,43,https://hail.is,https://github.com/hail-is/hail/pull/10766#issuecomment-912782196,1,['benchmark'],['benchmarks']
Testability,Ok. @akotlar this is why the secrets need to be duplicated in test.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5897#issuecomment-484122661:62,test,test,62,https://hail.is,https://github.com/hail-is/hail/pull/5897#issuecomment-484122661,1,['test'],['test']
Testability,Ok. Seems to work. Going to try cluster tests tomorrow to make sure things are ok in a distributed setting.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10523#issuecomment-879609434:40,test,tests,40,https://hail.is,https://github.com/hail-is/hail/pull/10523#issuecomment-879609434,1,['test'],['tests']
Testability,"Ok. Still working on getting the tests to pass and cleaning things up. However, I ran into a small snag. The code below needs to be ironed out. Should the number of jobs and state of the job group be recursive or specific to that job group? It's a bit weird for the billing and cancellation to be nested, but the number of jobs etc. are not. More concretely, if a child batch is running, should the parent also be running even if it has no direct child jobs that are running? Thoughts?. cc: @daniel-goldstein . ```mysql; UPDATE batches SET; `state` = 'running',; time_completed = NULL,; n_jobs = n_jobs + expected_n_jobs; WHERE id = in_batch_id;. ### FIXME FIXME what should the state be of nested job groups?; UPDATE job_groups; INNER JOIN (; SELECT batch_id, job_group_id, CAST(COALESCE(SUM(n_jobs), 0) AS SIGNED) AS staged_n_jobs; FROM job_groups_inst_coll_staging; WHERE batch_id = in_batch_id AND update_id = in_update_id; GROUP BY batch_id, job_group_id; ) AS t ON job_groups.batch_id = t.batch_id AND job_groups.job_group_id = t.job_group_id; SET `state` = 'running', time_completed = NULL, n_jobs = n_jobs + t.staged_n_jobs;; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14170#issuecomment-1932547516:33,test,tests,33,https://hail.is,https://github.com/hail-is/hail/pull/14170#issuecomment-1932547516,1,['test'],['tests']
Testability,"Ok. The limits for the tests will need to be fixed with a REST API for editing a billing limit and a new build step that is `setup_test_batch`. I'll work on that now. But I think this can go in while I'm working on that, but #9355 should depend on the new PR.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9354#issuecomment-705102869:23,test,tests,23,https://hail.is,https://github.com/hail-is/hail/pull/9354#issuecomment-705102869,1,['test'],['tests']
Testability,"Ok. This exact scenario is what I was worried about when we merge PRs without checking the logs by hand in a full testing scenario. I want a way to check the PR driver, front-end, and worker logs automatically that they don't have ERROR messages. Like test_invariants. For example, I'm still looking at your change for time_since_last_state_change. When I had the code you wanted, there were errors because time_since_last_state_change was None. The current tests would not have caught that. I think we need either a white list of acceptable front-end/driver errors or some kind of threshold for error types. I'll think about it some more once the batch porting is done.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10920#issuecomment-956522959:91,log,logs,91,https://hail.is,https://github.com/hail-is/hail/pull/10920#issuecomment-956522959,4,"['log', 'test']","['logs', 'testing', 'tests']"
Testability,"Ok. famous last words, but I think we're in good shape here. I think Daniel if you can do one last pass on the most recent changes, that would be great and then we'll have time to do a load test to make sure the behavior is still good and instances aren't thrashing.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12221#issuecomment-1271995498:190,test,test,190,https://hail.is,https://github.com/hail-is/hail/pull/12221#issuecomment-1271995498,1,['test'],['test']
Testability,"Okay, I think this is ready for re-review (assuming tests finally pass). Note the changes to `ld_score_regression`, which makes it generate smaller IR by using `AggArrayPerElement` instead of unrolled loops. That solved the blown stack in the parser and the class size issues, so I was able to put the linreg aggregator back the way it was (with `n` and `yty` computed in separate aggregations).",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7134#issuecomment-558180275:52,test,tests,52,https://hail.is,https://github.com/hail-is/hail/pull/7134#issuecomment-558180275,1,['test'],['tests']
Testability,"Okay, python tests in local mode now have the same number of failures as on main. I just needed to be more careful in preserving the information that determines the subregion relation",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9401#issuecomment-690716921:13,test,tests,13,https://hail.is,https://github.com/hail-is/hail/pull/9401#issuecomment-690716921,1,['test'],['tests']
Testability,"Okay, this isn't passing tests because Py4J actually catches Py4JErrors and uses them to stop iteration on java collections. Very frustrating.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1552#issuecomment-287453582:25,test,tests,25,https://hail.is,https://github.com/hail-is/hail/pull/1552#issuecomment-287453582,1,['test'],['tests']
Testability,"Okay, we can benchmark now.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10581#issuecomment-860802893:13,benchmark,benchmark,13,https://hail.is,https://github.com/hail-is/hail/pull/10581#issuecomment-860802893,1,['benchmark'],['benchmark']
Testability,"On Azure, one of the tests timed out with 500 responses from the server. I'll need to debug in GCP, but the PR queue is long right now.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14282#issuecomment-1960073457:21,test,tests,21,https://hail.is,https://github.com/hail-is/hail/pull/14282#issuecomment-1960073457,1,['test'],['tests']
Testability,"On Ubuntu 20.10, with Python 3.8.6 and hail 0.2.64 installed from pip, I get: ​I get `TypeError: an integer is required (got type bytes)` immediately upon importing hail. A full transcript is below. (pyve is an alias to create a python virtual env and activate it). ---. ```; snafu$ pyve; + python3.8 -m venv venv/3.8; + source venv/3.8/bin/activate; + pip install -U setuptools pip; Collecting setuptools; Using cached setuptools-54.1.2-py3-none-any.whl (785 kB); Collecting pip; Using cached pip-21.0.1-py3-none-any.whl (1.5 MB); Installing collected packages: setuptools, pip; Attempting uninstall: setuptools; Found existing installation: setuptools 44.0.0; Uninstalling setuptools-44.0.0:; Successfully uninstalled setuptools-44.0.0; Attempting uninstall: pip; Found existing installation: pip 20.1.1; Uninstalling pip-20.1.1:; Successfully uninstalled pip-20.1.1; Successfully installed pip-21.0.1 setuptools-54.1.2; (3.8) ✔ ~/sandbox/hail [master|𝚫8?2]; snafu$ pip install hail ipython; Collecting hail; Using cached hail-0.2.64-py3-none-any.whl (97.5 MB); Collecting ipython; Using cached ipython-7.21.0-py3-none-any.whl (784 kB); Collecting pandas<1.1.5,>=1.1.0; Using cached pandas-1.1.4-cp38-cp38-manylinux1_x86_64.whl (9.3 MB); Collecting python-json-logger==0.1.11; Using cached python_json_logger-0.1.11-py2.py3-none-any.whl; Collecting gcsfs==0.7.2; Using cached gcsfs-0.7.2-py2.py3-none-any.whl (22 kB); Collecting requests==2.22.0; Using cached requests-2.22.0-py2.py3-none-any.whl (57 kB); Collecting tabulate==0.8.3; Using cached tabulate-0.8.3-py3-none-any.whl; Collecting nest-asyncio; Using cached nest_asyncio-1.5.1-py3-none-any.whl (5.0 kB); Collecting parsimonious<0.9; Using cached parsimonious-0.8.1-py3-none-any.whl; Collecting pyspark<2.4.2,>=2.4; Using cached pyspark-2.4.1-py2.py3-none-any.whl; Collecting tqdm==4.42.1; Using cached tqdm-4.42.1-py2.py3-none-any.whl (59 kB); Collecting bokeh<2.0,>1.3; Using cached bokeh-1.4.0-py3-none-any.whl; Collecting Deprecated<1.3",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/10197:933,sandbox,sandbox,933,https://hail.is,https://github.com/hail-is/hail/issues/10197,1,['sandbox'],['sandbox']
Testability,"On a test of 1-2 partitions with 5000 samples, this takes the second stage of a densify from 2 minutes down to 1.4 minutes (only loading GT).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6967:5,test,test,5,https://hail.is,https://github.com/hail-is/hail/pull/6967,1,['test'],['test']
Testability,"On certain occasions, the file inside the FASTA reader can be closed. It; is not yet understood why. Tests indicate that simply reopening the file; seems to resolve the issue when we run the appropriate exception. This also removes the need for SerializableReferenceSequenceFile, and so; deletes it.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9436:101,Test,Tests,101,https://hail.is,https://github.com/hail-is/hail/pull/9436,1,['Test'],['Tests']
Testability,"On second thought, should there be at least one test where `expr != None`?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2662#issuecomment-355769072:48,test,test,48,https://hail.is,https://github.com/hail-is/hail/pull/2662#issuecomment-355769072,1,['test'],['test']
Testability,"Once #1475 is merged, tests will pass here too.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1474#issuecomment-284282339:22,test,tests,22,https://hail.is,https://github.com/hail-is/hail/pull/1474#issuecomment-284282339,1,['test'],['tests']
Testability,"Once we can draw from Cassandra (with the likes of `annotatevariants cass`, we can write/read/compare in the usual way. We need a Cassandra cluster for testing. There are three options: an embedded server as part of Hail, assume the user has installed Cassandra locally, or run against a fixed server. I set up a single-node Cassandra install on hail-ci. In the spirit of small commits, I want to be able to test in experimental/untested/in progress work so we don't get so much divergence. We need a way to mark it. I will investigate the options.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/282#issuecomment-208368921:152,test,testing,152,https://hail.is,https://github.com/hail-is/hail/pull/282#issuecomment-208368921,2,['test'],"['test', 'testing']"
Testability,"Once we fold in cloud tools, the CI will only be testing hail-is/hail, so all these questions of coupling between CI and hail-is/hail are moot. (Currently, these changes will introduce a few broken object links to the cloud tools repo. Which is mostly untidy rather than bad in anyway.). I created `artifacts/index.html` to work around a GCS limitation. Serving a bucket directly doesn't generate an `ls -l` style index.html for directories. nginx and apache are happy to do this. There are two layers:. - ci's ""job"" information (a log and a directory of artifacts); - project-specific artifacts. I think the friction is caused by CI & batch lacking a way to express a DAG of jobs. We've hacked this on via background processes, but now the ci's ""job"" page doesn't neatly correspond to one process log. Cotton's proposed batch DAG (& CI's use of it) resolves this by restoring the separation of ""job"" (or, now, ""jobs"") information and artifacts (which are truly just artifacts). All that said, if this makes your life easier, I don't mind the mild ugliness on cloud tools while we wait for batch DAG to land. Let me know and I'll approve.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4667#issuecomment-433954860:49,test,testing,49,https://hail.is,https://github.com/hail-is/hail/pull/4667#issuecomment-433954860,3,"['log', 'test']","['log', 'testing']"
Testability,"One final comment, the goal here was separate the normal user notebook flow from the workshop guest notebook flow, while sharing the main logic without impacting logic outside notebook. I think that was largely successful. I think the only impact outside was to layout.html in web_common, it checks a `workshop` variable to load the workshop header instead of the default one. This is necessary because you can't override a block in a included file from the file that includes it. The other design I considered was have auth support a guest user for workshops which was represented just like any other user, but this seemed both more complicated and more error prone from the security perspective. As we have other use cases for guest users (e.g. free tier), let's revisit this decision.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7112#issuecomment-534276842:138,log,logic,138,https://hail.is,https://github.com/hail-is/hail/pull/7112#issuecomment-534276842,2,['log'],['logic']
Testability,"One more time, with feeling! (was: #10072). - [x] (@tpoterba) a1f3b2a5c9 add fails_service_backend; - [ ] (@tpoterba, @cseed) dc0bee7ce1 [hail] introduce and use mktemp and mktempd; - [ ] (@tpoterba) 4b663be367 [hail] make is.hail.expr.ir.functions threadsafe; - [ ] (@tpoterba) d3c1f0987c [hail] fix use of row requiredness in lowerDistributedSort; - [ ] (@catoverdrive) aab6ba98be [query-service] handle void-typed IRs in query-service; - [ ] (@catoverdrive) a1619cff36 [query-service] make user cache thread-safe; - [ ] (@tpoterba) c315fcb0b1 [query-service] bugfix: preserve globals through a shuffle; - [ ] (@catoverdrive) 912c21f709 [shuffler] log ShuffleCodecSpec anytime it is created; - [x] (@daniel-goldstein) c2495837e7 [scala-lsm] bugfix: least key may equal greatest key; - [x] (@daniel-goldstein) 5fb3db703e [services] discovered new transient error; - [x] (@daniel-goldstein) 9cd0999938 [shuffler] more assertions in ShuffleClient; - [x] (@daniel-goldstein) a71a3c9b8c [shuffler] bugfix: shuffler needs a HailContext to decode loci; - [x] (@daniel-goldstein) 41b06aeaa8 [query-service] move hail.jar earlier in Dockerfile; - [x] (@daniel-goldstein) 8df4029698 [query-service] permit pod scaling and remove cpu limit; - [ ] (@catoverdrive) 0354e1f557 [query-service] simplify socket handling; - [x] (@jigold) 6690a4decc [batch] teach JVMJob where to find the hail configuration files; - [x] (@daniel-goldstein) ae2e3d2996 [query-service] switch to services team approved logging; - [ ] (@tpoterba) b18f86e647 [query-service] query workers need a hail context; - [ ] (@daniel-goldstein, @catoverdrive) 6d5d0b68af [query-service] use a UNIX Domain Socket for Py-Scala communication; - [ ] (@daniel-goldstein, @catoverdrive) 0d42df8b08 [query-service] run tests against query service; - [x] (@jigold) f9d361e686 [query-service] aiohttp.ClientSession must be created in async code; - [ ] (@cseed) c35f2e10e3 [query-service][hail][build.yaml] address miscellaneous comments from cotton; - [x]",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10100:650,log,log,650,https://hail.is,https://github.com/hail-is/hail/pull/10100,2,"['assert', 'log']","['assertions', 'log']"
Testability,"One of the problems with the new model is that tests on the deployed version are going to leave billing project poop everywhere unless we actually go in and delete them, hmmm....",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9553#issuecomment-705227991:47,test,tests,47,https://hail.is,https://github.com/hail-is/hail/pull/9553#issuecomment-705227991,1,['test'],['tests']
Testability,"One of the tests failed because I messed up some variable names, but if we compare the times:. https://storage.googleapis.com/hail-ci-0-1/ci/7cd5eec6ab8e669fe1adc3061039573c969eb16e/7eac2a154140017f6623db20f277563537b3e075/artifacts/test-report/index.html. vs . https://storage.googleapis.com/hail-ci-0-1/ci/abf0f7d9eebed9774b9b24f3e96fd74683becff4/9b150225332bdfca222715cf5cf6bb483192b54d/artifacts/test-report/index.html. there's a difference of about 9 minutes, most of which is in InterpretSuite (which contains a lot of duplicate tests now and is removed in #5579), so I expect the difference to be not so large once both of these are in. The C++ compile times are definitely a thing we need to keep thinking about, but 20 minutes for the scala tests (hopefully < 15 once the other PR lands) seems workable for now?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5578#issuecomment-471622174:11,test,tests,11,https://hail.is,https://github.com/hail-is/hail/pull/5578#issuecomment-471622174,5,['test'],"['test-report', 'tests']"
Testability,"One other snarl I've hit -- I'll need to reboot the jupyter service in the init script in order to use `jgscm` as the content manager, and need to find time to test that and make sure everything continues to work afterwards.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12788#issuecomment-1479689103:160,test,test,160,https://hail.is,https://github.com/hail-is/hail/pull/12788#issuecomment-1479689103,1,['test'],['test']
Testability,One that uses a glob though! I don’t see one at least. Maybe I missed (though I can’t imagine since it should have failed that test before this),MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7611#issuecomment-558457592:127,test,test,127,https://hail.is,https://github.com/hail-is/hail/pull/7611#issuecomment-558457592,1,['test'],['test']
Testability,"Only changes are as we discussed: rename/add notebook2 labels where appropriate. Tested in cluster, appears to work although the deployment is stuck in Desired == 1, so I may have missed one of the notebook labels, or maybe `make deploy` not enough (I find the makefile a bit confusing still). Describe shows `ReplicaFailure True FailedCreate`, will figure out tomorrow. cc @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5412:81,Test,Tested,81,https://hail.is,https://github.com/hail-is/hail/pull/5412,1,['Test'],['Tested']
Testability,Only test if changed,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4404:5,test,test,5,https://hail.is,https://github.com/hail-is/hail/pull/4404,1,['test'],['test']
Testability,"Oof, I'm failing one of the docs Pedigree tests. Surprising, but glad we have those. I'll investigate",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6438#issuecomment-504570971:42,test,tests,42,https://hail.is,https://github.com/hail-is/hail/pull/6438#issuecomment-504570971,1,['test'],['tests']
Testability,"Oof, good catch! The thing we're trying to avoid is `e^x` overflowing for large positive `x`. In double precision, the smallest `x` that overflows is 710. So to test that we handle overflow correctly, you can check `sigmoid(710) == 1.0` and `sigmoid(-710) == 0.0` (using approximate equality). Actually, after playing with this, if you just use the simple definition `sigmoid(x) = 1 / (1 + np.exp(-x))`, then `sigmoid(-710)` does overflow, but it returns the right answer since `np.exp(710)` returns `inf`, and `1 / inf == 0.0`. But `math.exp(710)` throws an exception. `hl.exp` seems to have the numpy behavior, so I think the simple version actually works. But we should add the above test. I think wrapping this in an exposed function is a good idea. I agree it should be called `expit`, both for consistency with scipy, and because as you say, `sigmoid` really just means an S shaped function. And if we do expose `expit`, we should probably expose its inverse `logit` too.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10606#issuecomment-866034244:161,test,test,161,https://hail.is,https://github.com/hail-is/hail/pull/10606#issuecomment-866034244,6,"['log', 'test']","['logit', 'test']"
Testability,"Oof, method verification error on one of the lowering tests",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9637#issuecomment-717239923:54,test,tests,54,https://hail.is,https://github.com/hail-is/hail/pull/9637#issuecomment-717239923,1,['test'],['tests']
Testability,"Oops, I had a bug where the readiness check was hitting the notebook service, not the actual notebook. Here is an updated scale test:. ```; successes: 10 / 10 = 1.0; mean time: 6.920137214660644; max time: 14.664504528045654; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7112#issuecomment-534707944:128,test,test,128,https://hail.is,https://github.com/hail-is/hail/pull/7112#issuecomment-534707944,1,['test'],['test']
Testability,"Oops, I had meant to include that. Fixed. > How do we expect to benchmark these?. I was planning to measure densify/force_count on your test spare MatrixTable. I was planning to finish the remaining staging improvements first.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5414#issuecomment-466570246:64,benchmark,benchmark,64,https://hail.is,https://github.com/hail-is/hail/pull/5414#issuecomment-466570246,2,"['benchmark', 'test']","['benchmark', 'test']"
Testability,"Oops, sorry. Although I really blame PruneSuite. It does a bunch of serious work on construction, and basically makes the tests unusable if there are any bugs and testng silently bails with a fatal error.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8629#issuecomment-619252768:122,test,tests,122,https://hail.is,https://github.com/hail-is/hail/pull/8629#issuecomment-619252768,2,['test'],"['testng', 'tests']"
Testability,"Oops, still have to add the benchmark.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7134#issuecomment-536038333:28,benchmark,benchmark,28,https://hail.is,https://github.com/hail-is/hail/pull/7134#issuecomment-536038333,1,['benchmark'],['benchmark']
Testability,"Open question: we're using ~20GiB on /prometheus for 15d. We request 150GiB (and get closer to 146GiB). Should we increase the storage to give ourselves more slack? Assuming linear scaling, 90d would use 120GiB (26GiB of slack). https://hail.zulipchat.com/#narrow/stream/300487-Hail-Batch-Dev/topic/Grafana.20retention.20period; ```; /prometheus $ df -h; Filesystem Size Used Available Use% Mounted on; overlay 94.3G 28.9G 65.3G 31% /; tmpfs 64.0M 0 64.0M 0% /dev; tmpfs 3.6G 0 3.6G 0% /sys/fs/cgroup; /dev/sdf 146.6G 18.9G 127.6G 13% /prometheus; /dev/sda1 94.3G 28.9G 65.3G 31% /etc/prometheus; /dev/sda1 94.3G 28.9G 65.3G 31% /etc/hosts; /dev/sda1 94.3G 28.9G 65.3G 31% /dev/termination-log; /dev/sda1 94.3G 28.9G 65.3G 31% /etc/hostname; /dev/sda1 94.3G 28.9G 65.3G 31% /etc/resolv.conf; shm 64.0M 4.0K 64.0M 0% /dev/shm; tmpfs 5.5G 12.0K 5.5G 0% /var/run/secrets/kubernetes.io/serviceaccount; tmpfs 3.6G 0 3.6G 0% /proc/acpi; tmpfs 64.0M 0 64.0M 0% /proc/kcore; tmpfs 64.0M 0 64.0M 0% /proc/keys; tmpfs 64.0M 0 64.0M 0% /proc/timer_list; tmpfs 3.6G 0 3.6G 0% /proc/scsi; tmpfs 3.6G 0 3.6G 0% /sys/firmware; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14194:690,log,log,690,https://hail.is,https://github.com/hail-is/hail/pull/14194,1,['log'],['log']
Testability,"Opening this PR and then closing it immediately. For reference when we decide to come back to this code. My testing script is here:. ```python3; #! /usr/bin/python. import hail as hl. #vcf = 'gs://my-bucket/vep/test_variant.vcf'; vcf = 'gs://my-bucket/vep/inputs/loftee_variant_grch37.vcf'; #vcf = 'gs://my-bucket/vep/inputs/loftee_variant_grch38.vcf'. hl.init(). #mt = hl.import_vcf(vcf, reference_genome='GRCh38'); mt = hl.import_vcf(vcf, reference_genome='GRCh37'); mt = hl.vep(mt, requester_pays_project='my-project', tolerate_parse_error=True); #mt.write('gs://my-bucket/vep/test-output-grch38.mt', overwrite=True); mt.write('gs://my-bucket/vep/test-output-grch37.mt', overwrite=True); ht = mt.rows(); print(ht.vep.collect()); print(mt.globals); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10454:108,test,testing,108,https://hail.is,https://github.com/hail-is/hail/pull/10454,3,['test'],"['test-output-', 'testing']"
Testability,"Operations for all interaction with blobs. This change ensures that QoB only uses Class A Operations when necessary. Inspired by @jigold 's file system improvement campaign, I pursued the avoidance of ""list"" operations. I anticipate this reduces flakiness in Azure (which is tracked in #13351) and cost in Azure. I enforced aiotools.fs terminology on hail.fs and Scala:. 1. `FileStatus`. Metadata about a blob or file. It does not know if a directory exists at this path. 2. `FileListEntry`. Metadata from a list operation. It knows if a directory exists at this path. Variable names were updated to reflect this distinction:. 1. `fileStatus` / `fileStatuses`. 2. `fle`/ `fles` / `fileListEntry` / `fileListEntries`, respectively. `listStatus` renamed to `listDirectory` for clarity. In both Azure and Google, `fileStatus` does not use a list operation. `fileListEntry` can be used when we must know if a directory exists. I just rewrote this from first principles because:; 1. In neither Google nor Azure did it check if the path was a directory and a file.; 2. In Google, if the directory entry wasn't in the first page, it would fail (NB: there are fifteen non-control characters in ASCII before `/`, if the page size is 15 or fewer, we'd miss the first entry with a `/` at the end).; 3. In Azure, we issued both a get and a list. There are now unit tests for this method. ---. 1. `copyMerge` and `concatenateFiles` previously used `O(N_FILES)` list operations, they now use `O(N_FILES)` get operations.; 2. Writers that used `exists` to check for a _SUCCESS file now use a get operation.; 3. Index readers, import BGEN, and import plink all now check file size with a get operation. That said, overall, the bulk of our Class A Operations are probably writes. fix test failures. passes tests. fixes. fix tests to not use fileStatus for folders. only file vs directory status matters. fix azure. azure dislikes %. finally get azure right. nix empty line. fix merge cruft. azure bug. lots of changes",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13883:1408,test,tests,1408,https://hail.is,https://github.com/hail-is/hail/pull/13883,4,['test'],"['test', 'tests']"
Testability,Or have both delete steps depend on both test jobs.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13353#issuecomment-1660787777:41,test,test,41,https://hail.is,https://github.com/hail-is/hail/pull/13353#issuecomment-1660787777,1,['test'],['test']
Testability,OrderedJoinDistinctRDD2 fails if the right side has no partitions (assertion failure in BinarySearch),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2876:67,assert,assertion,67,https://hail.is,https://github.com/hail-is/hail/issues/2876,1,['assert'],['assertion']
Testability,OrderedRVD assertion error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3998:11,assert,assertion,11,https://hail.is,https://github.com/hail-is/hail/issues/3998,1,['assert'],['assertion']
Testability,OrderingSuite.testBinarySearchOnDict fails sporadically,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5630:14,test,testBinarySearchOnDict,14,https://hail.is,https://github.com/hail-is/hail/issues/5630,1,['test'],['testBinarySearchOnDict']
Testability,Organizational changes to benchmark,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4928:26,benchmark,benchmark,26,https://hail.is,https://github.com/hail-is/hail/pull/4928,1,['benchmark'],['benchmark']
Testability,"Other things to add in separate PRs:; - logging; - concept of a ResourceDirectory where you want to copy the files in/out from a directory; - change the temp dir to be per task; - Support environment variables, cpu, memory",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4937#issuecomment-453621583:40,log,logging,40,https://hail.is,https://github.com/hail-is/hail/pull/4937#issuecomment-453621583,1,['log'],['logging']
Testability,Other to-do items are to make sure the stack has tests for authorization for all new endpoints in `test_batch.py` in the corresponding PR.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14170#issuecomment-1898818963:49,test,tests,49,https://hail.is,https://github.com/hail-is/hail/pull/14170#issuecomment-1898818963,1,['test'],['tests']
Testability,"Our CI service should really be logging a JSON format the way batch does. Easy to change, need to use configure logging in Gear.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6701:32,log,logging,32,https://hail.is,https://github.com/hail-is/hail/issues/6701,2,['log'],['logging']
Testability,"Our secret cache fails on ~1 in 10000 jobs. I observed this while running some; large scale tests which will soon become standard PR tests. In anticipation of this,; I fixed the k8s_cache. In particular, note how *everyone* who wins the lock tries to; remove it from the dictionary; however, only *one* task can do that successfully. The new code avoids locks entirely. It is a bit longer because I eagerly remove; out of date keys when I see them and use a future to notify all waiter simultaneouly. I also updated memory to use this cache for user credentials.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11040:92,test,tests,92,https://hail.is,https://github.com/hail-is/hail/pull/11040,2,['test'],['tests']
Testability,"Our team is currently trying to run kinship analysis with [king()](https://hail.is/docs/0.2/methods/relatedness.html#hail.methods.king) on just under 110k samples. We have run this successfully in the past on 10k samples using a google cloud cluster with the following configuration. ```; hailctl dataproc start cluster --vep GRCh38 \; 	--requester-pays-allow-annotation-db \; 	--packages gnomad --requester-pays-allow-buckets gnomad-public-requester-pays \; 	--master-machine-type=n1-highmem-8 --worker-machine-type=n1-highmem-8 \; 	--num-workers=300	--num-secondary-workers=0 \; 	--worker-boot-disk-size=1000 \; 	--properties=dataproc:dataproc.logging.stackdriver.enable=true,dataproc:dataproc.monitoring.stackdriver.enable=true; ```; We are currently receiving a spark error when using this cluster for our larger dataset. ```; [Stage 10:=====> (69 + 656) / 729]; raise err; File ""/opt/conda/default/lib/python3.8/site-packages/hail/backend/py4j_backend.py"", line 98, in execute; result_tuple = self._jbackend.executeEncode(jir, stream_codec, timed); File ""/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py"", line 1304, in __call__; File ""/opt/conda/default/lib/python3.8/site-packages/hail/backend/py4j_backend.py"", line 31, in deco; raise fatal_error_from_java_error_triplet(deepest, full, error_id) from None; hail.utils.java.FatalError: SparkException: Job aborted due to stage failure: Task 582 in stage 10.0 failed 20 times, most recent failure: Lost task 582.19 in stage 10.0 (TID 461381) (cluster-w-144.c.project-.internal executor 3568): ExecutorLostFailure (executor 3568 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 128936 ms; Driver stacktrace:. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 582 in stage 10.0 failed 20 times, most recent failure: Lost task 582.19 in stage 10.0 (TID 461381) (cluster-w-144.c.gbsc-project.internal executor 3568): ExecutorLostFailure (executor 3568 e",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12290:646,log,logging,646,https://hail.is,https://github.com/hail-is/hail/issues/12290,1,['log'],['logging']
Testability,Our users will interact with a KeyTable so the tests should too.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2264:47,test,tests,47,https://hail.is,https://github.com/hail-is/hail/pull/2264,1,['test'],['tests']
Testability,"Out of curiosity, what's different about `assert` and the `self.assertEqual`?",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7611#issuecomment-558865138:42,assert,assert,42,https://hail.is,https://github.com/hail-is/hail/pull/7611#issuecomment-558865138,2,['assert'],"['assert', 'assertEqual']"
Testability,Override merging this because it only touches deploy things (which aren't tested) and it was waiting on other approved PRs.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4616#issuecomment-432424552:74,test,tested,74,https://hail.is,https://github.com/hail-is/hail/pull/4616#issuecomment-432424552,1,['test'],['tested']
Testability,"Oy! If you `grep netlib hail.log`, do you see natives loading or failing to load? I'll check on my end too.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3335#issuecomment-385265623:29,log,log,29,https://hail.is,https://github.com/hail-is/hail/pull/3335#issuecomment-385265623,1,['log'],['log']
Testability,"PCA test failing, this is because https://github.com/apache/spark/blob/v3.0.1/mllib/src/main/scala/org/apache/spark/mllib/linalg/distributed/RowMatrix.scala#L795 is wrong prior to 3.1.1. `MAX_RESULT_SIZE` of 0 is supposed to be interpreted as ""unlimited"".",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10054#issuecomment-788979439:4,test,test,4,https://hail.is,https://github.com/hail-is/hail/pull/10054#issuecomment-788979439,1,['test'],['test']
Testability,"PDATE; ON DUPLICATE KEY UPDATE `usage` = aggregated_billing_project_user_resources_v3.`usage` + msec_diff_rollup * quantity. *** (1) HOLDS THE LOCK(S):; RECORD LOCKS space id 351 page no 4 n bits 248 index PRIMARY of table `dgoldste-batch`.`instances_free_cores_mcpu` trx id 2486515 lock_mode X locks rec but not gap; Record lock, heap no 176 PHYSICAL RECORD: n_fields 4; compact format; info bits 0; 0: len 30; hex 62617463682d776f726b65722d64676f6c647374652d7374616e64617264; asc batch-worker-dgoldste-standard; (total 36 bytes);; 1: len 6; hex 00000025f0ee; asc % ;;; 2: len 7; hex 01000000a90a9b; asc ;;; 3: len 4; hex 80000fa0; asc ;;. *** (1) WAITING FOR THIS LOCK TO BE GRANTED:; RECORD LOCKS space id 376 page no 8 n bits 408 index PRIMARY of table `dgoldste-batch`.`aggregated_billing_project_user_resources_v3` trx id 2486515 lock_mode X locks rec but not gap waiting; Record lock, heap no 228 PHYSICAL RECORD: n_fields 7; compact format; info bits 0; 0: len 4; hex 74657374; asc test;;; 1: len 8; hex 64676f6c64737465; asc dgoldste;;; 2: len 4; hex 80000009; asc ;;; 3: len 4; hex 80000034; asc 4;;; 4: len 6; hex 00000025f0cd; asc % ;;; 5: len 7; hex 810000021b01cd; asc ;;; 6: len 8; hex 80000000001b09e0; asc ;;. *** (2) TRANSACTION:; TRANSACTION 2486477, ACTIVE 0 sec starting index read; mysql tables in use 27, locked 27; LOCK WAIT 47 lock struct(s), heap size 8312, 215 row lock(s), undo log entries 211; MySQL thread id 682, OS thread handle 140330866251520, query id 4746389 10.32.3.39 dgoldste-batch-user executing; INSERT INTO aggregated_job_group_resources_v3 (batch_id, job_group_id, resource_id, token, `usage`); SELECT attempt_resources.batch_id,; job_group_self_and_ancestors.ancestor_id,; attempt_resources.deduped_resource_id,; NAME_CONST('rand_token',189),; NAME_CONST('msec_diff_rollup',1671) * quantity; FROM attempt_resources; LEFT JOIN jobs ON attempt_resources.batch_id = jobs.batch_id AND attempt_resources.job_id = jobs.job_id; LEFT JOIN job_group_self_and_ancest",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14380:2470,test,test,2470,https://hail.is,https://github.com/hail-is/hail/issues/14380,1,['test'],['test']
Testability,"PL:Array[Int32]}]}},rows,../globals/rows,../references,false)), WriteMetadata(MakeStruct(ArrayBuffer((cols,GetField(Ref(__iruid_368,struct{filePath: str, partitionCounts: int64}),partitionCounts)), (rows,Ref(__iruid_376,array<int64>)))),MatrixSpecWriter(gs://danking/workshop-test/1kg.mt,Matrix{global:Struct{},col_key:[s],col:Struct{s:String},row_key:[[locus,alleles]],row:Struct{locus:Locus(GRCh37),alleles:Array[String],rsid:String,qual:Float64,filters:Set[String],info:Struct{AC:Array[Int32],AF:Array[Float64],AN:Int32,BaseQRankSum:Float64,ClippingRankSum:Float64,DP:Int32,DS:Boolean,FS:Float64,HaplotypeScore:Float64,InbreedingCoeff:Float64,MLEAC:Array[Int32],MLEAF:Array[Float64],MQ:Float64,MQ0:Int32,MQRankSum:Float64,QD:Float64,ReadPosRankSum:Float64,set:String}},entry:Struct{GT:Call,AD:Array[Int32],DP:Int32,GQ:Int32,PL:Array[Int32]}},rows/rows,globals/rows,cols/rows,entries/rows,references,true))))))))),RelationalWriter(gs://danking/workshop-test/1kg.mt/entries,false,None)),RelationalWriter(gs://danking/workshop-test/1kg.mt/rows,false,None)),RelationalWriter(gs://danking/workshop-test/1kg.mt/cols,false,None)),RelationalWriter(gs://danking/workshop-test/1kg.mt/globals,false,None)),RelationalWriter(gs://danking/workshop-test/1kg.mt,true,Some((references,Set(GRCh37)))))); 	at scala.collection.MapLike$class.default(MapLike.scala:228); 	at scala.collection.AbstractMap.default(Map.scala:59); 	at scala.collection.mutable.HashMap.apply(HashMap.scala:65); 	at is.hail.expr.ir.Memo.lookup(RefEquality.scala:38); 	at is.hail.expr.ir.Memo.lookup(RefEquality.scala:37); 	at is.hail.expr.ir.Memo.apply(RefEquality.scala:40); 	at is.hail.expr.ir.Requiredness.lookup(Requiredness.scala:41); 	at is.hail.expr.ir.Requiredness$$anonfun$analyzeIR$16.apply(Requiredness.scala:616); 	at is.hail.expr.ir.Requiredness$$anonfun$analyzeIR$16.apply(Requiredness.scala:615); 	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59); 	at scala.collection.mutable.ArrayBuffer.forea",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9856:18762,test,test,18762,https://hail.is,https://github.com/hail-is/hail/issues/9856,1,['test'],['test']
Testability,"PR namespaces are destroyed after the tests pass, so ghost should be gone.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7381#issuecomment-548101042:38,test,tests,38,https://hail.is,https://github.com/hail-is/hail/pull/7381#issuecomment-548101042,1,['test'],['tests']
Testability,"PRing for test suite, but it's mostly working. . Todo:. - [x] Optimization for already sorted tables; - [x] ~~Handle sort by descending~~ (deferred to subsequent PR); - [x] Handle tables with no partitions",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11050:10,test,test,10,https://hail.is,https://github.com/hail-is/hail/pull/11050,1,['test'],['test']
Testability,"PRing to test, hopefully will fix Akhil's bug. . Akhil's stack trace top:. ```; Java stack trace:; java.lang.RuntimeException: invoke __m684btree_insert: arg 2: type mismatch:; got +PBoolean; expected PBoolean; 	at is.hail.expr.ir.EmitCodeBuilder$$anonfun$1.apply(EmitCodeBuilder.scala:132); 	at is.hail.expr.ir.EmitCodeBuilder$$anonfun$1.apply(EmitCodeBuilder.scala:114); 	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241); 	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241); 	at scala.collection.immutable.Range.foreach(Range.scala:160); 	at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241); 	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:104); 	at is.hail.expr.ir.EmitCodeBuilder._invoke(EmitCodeBuilder.scala:114); 	at is.hail.expr.ir.EmitCodeBuilder.invokeCode(EmitCodeBuilder.scala:164); 	at is.hail.expr.ir.agg.AppendOnlyBTree.is$hail$expr$ir$agg$AppendOnlyBTree$$insert(AppendOnlyBTree.scala:231); 	at is.hail.expr.ir.agg.AppendOnlyBTree$$anonfun$getF$1$$anonfun$is$hail$expr$ir$agg$AppendOnlyBTree$$anonfun$$insertOrGetAt$1$1.apply$mcV$sp(AppendOnlyBTree.scala:245); 	at is.hail.asm4s.CodeBuilderLike$class.ifx(CodeBuilder.scala:83); 	at is.hail.expr.ir.EmitCodeBuilder.ifx(EmitCodeBuilder.scala:37); 	at is.hail.expr.ir.agg.AppendOnlyBTree$$anonfun$getF$1.is$hail$expr$ir$agg$AppendOnlyBTree$$anonfun$$insertOrGetAt$1(AppendOnlyBTree.scala:244); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10133:9,test,test,9,https://hail.is,https://github.com/hail-is/hail/pull/10133,1,['test'],['test']
Testability,"P_Ti_count_Hom=hl.agg.count_where(; (hl.is_transition(mt.alleles[0], mt.alleles[1])) & (mt.GT.is_hom_var()); ),; SNP_Tv_count_Hom=hl.agg.count_where(; (hl.is_transversion(mt.alleles[0], mt.alleles[1])) & (mt.GT.is_hom_var()); ), ; ### Indel counts; INDEL_Ins_count_Het=hl.agg.count_where(; (hl.is_insertion(mt.alleles[0], mt.alleles[1])) & (mt.GT.is_het_ref()); ),; INDEL_Del_count_Het=hl.agg.count_where(; (hl.is_deletion(mt.alleles[0], mt.alleles[1])) & (mt.GT.is_het_ref()); ),; INDEL_Ins_count_Hom=hl.agg.count_where(; (hl.is_insertion(mt.alleles[0], mt.alleles[1])) & (mt.GT.is_hom_var()); ),; INDEL_Del_count_Hom=hl.agg.count_where(; (hl.is_deletion(mt.alleles[0], mt.alleles[1])) & (mt.GT.is_hom_var()); ),; )) for interval_name in interval_names}. mt2 = mt.annotate_cols(**annotate_dict); return mt2; ```; ```; interval_table_dict = dict(; zip(interval_names, [hl.is_defined(interval_table[filtered_mt.locus]) for interval_table in interval_tables]); ); ```. ### Version. 0.2.126. ### Relevant log output. ```shell; ---------------------------------------------------------------------------; RemoteDisconnected Traceback (most recent call last); File /opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py:703, in HTTPConnectionPool.urlopen(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw); 702 # Make the request on the httplib connection object.; --> 703 httplib_response = self._make_request(; 704 conn,; 705 method,; 706 url,; 707 timeout=timeout_obj,; 708 body=body,; 709 headers=headers,; 710 chunked=chunked,; 711 ); 713 # If we're going to release the connection in ``finally:``, then; 714 # the response doesn't need to know about the connection. Otherwise; 715 # it will also try to release it and we'll have a double-release; 716 # mess. File /opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py:449, in HTTPConnectionPool._make_request(self, conn, method, url, ti",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13960:3587,log,log,3587,https://hail.is,https://github.com/hail-is/hail/issues/13960,1,['log'],['log']
Testability,"Pandas missingness is crazy. `pd.isna` tells you if something is ""missing"", which means either `NaN`, or a special `NA` sentinel value. For floats they use `NaN`, and specifically for the pandas special `Int64DType` and `Int32DType` and nothing else they use this `NA` value. They don't have an easy way to distinguish between `NA` and `NaN`, so I first check if something `isna`, then check if it's a `float` to differentiate between the cases. . They also don't have a way to test if something is a `Int32DType` for some reason. So I use `is_int64_dtype`, and if that fails I fall back to `is_integer_dtype`, which is true for both `Int64DType` and `Int32DType`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11401:478,test,test,478,https://hail.is,https://github.com/hail-is/hail/pull/11401,1,['test'],['test']
Testability,Part 1 of chipping away at config.mk. This puts the two make targets for building the vm image in GCP into a single script. It loads variables that used to come from config.mk from kubernetes. Added a convenience function to offer a confirmation prompt before running the script. Here's an example:. ```; (hailenv) dgoldste@wmce3-cb7 hail % $HAIL/batch/gcp-create-worker-image.sh; Building image with properties:; Version: 12; Project: hail-vdc; Zone: us-central1-a; Are you sure? [y/N] n; (hailenv) dgoldste@wmce3-cb7 hail %; ```. Tested by running with a high image version number (3010 to be precise),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11327:532,Test,Tested,532,https://hail.is,https://github.com/hail-is/hail/pull/11327,1,['Test'],['Tested']
Testability,"Passing CI tests for Spark 2.4. Do you have a stack trace for a failure?. Sriram saw issues related to Breeze in #9199, but I think it was the bug you noted above.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9524#issuecomment-701358022:11,test,tests,11,https://hail.is,https://github.com/hail-is/hail/pull/9524#issuecomment-701358022,1,['test'],['tests']
Testability,"Patrick -- can you give this a careful look over? Once we're happy with it, I'll redo the benchmarking as a last sanity check.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12629:90,benchmark,benchmarking,90,https://hail.is,https://github.com/hail-is/hail/pull/12629,1,['benchmark'],['benchmarking']
Testability,"Pausing for a few hours. Error in testEmitLeftJoinDistinct is a bit strange. IR contains only constants, and appears correctly inferred as having required elements, but a missing element is found at emit time. <img width=""2270"" alt=""Screenshot 2020-02-21 20 38 52"" src=""https://user-images.githubusercontent.com/5543229/75083876-2f3f9d00-54ea-11ea-9bb8-45f9e708a50b.png"">",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8142#issuecomment-589902885:34,test,testEmitLeftJoinDistinct,34,https://hail.is,https://github.com/hail-is/hail/pull/8142#issuecomment-589902885,1,['test'],['testEmitLeftJoinDistinct']
Testability,"Performance is close, if slightly worse. Could be laptop load differences. Insignificant, this is a great balance. {""config"": {""cores"": 1, ""version"": ""0.2.28-42f5ab7d9617"", ""timestamp"": ""2019-12-04 19:20:11.757847"", ""system"": ""darwin""}, ""benchmarks"": [{""name"": ""make_ndarray_bench"", ""failed"": false, ""timed_out"": false, ""times"": [25.609369775000005, 25.694102771999994, 26.285334770000006]}]}",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7646#issuecomment-561908098:238,benchmark,benchmarks,238,https://hail.is,https://github.com/hail-is/hail/pull/7646#issuecomment-561908098,1,['benchmark'],['benchmarks']
Testability,Permissions issues. VEP test 2:; https://ci.hail.is/batches/8126309,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14286#issuecomment-1942034848:24,test,test,24,https://hail.is,https://github.com/hail-is/hail/pull/14286#issuecomment-1942034848,1,['test'],['test']
Testability,"Permits the big aggregate benchmarks to run...slowly:. ```; 2019-10-05 10:58:08,110: INFO: [1/2] Running table_big_aggregate_compilation...; 2019-10-05 10:58:24,685: INFO: burn in: 16.57s; 2019-10-05 10:58:28,664: INFO: run 1: 3.98s; 2019-10-05 10:58:32,558: INFO: run 2: 3.89s; 2019-10-05 10:58:36,332: INFO: run 3: 3.77s; 2019-10-05 10:58:36,335: INFO: [2/2] Running table_big_aggregate_compile_and_execute...; 2019-10-05 10:58:42,972: INFO: burn in: 6.64s; 2019-10-05 10:58:48,677: INFO: run 1: 5.71s; 2019-10-05 10:58:54,358: INFO: run 2: 5.68s; 2019-10-05 10:59:00,091: INFO: run 3: 5.73s; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7201:26,benchmark,benchmarks,26,https://hail.is,https://github.com/hail-is/hail/pull/7201,1,['benchmark'],['benchmarks']
Testability,Phew! I finally got to parity. I'm impressed how well the old method wrapping logic worked. Benchmarks with >20% change:. ```; $ hail-bench compare ./0.2.47-3f8cff262dcf-1.json 0.2.47-63dccdda2a44.json ; Failed benchmarks in run 1:; pc_relate_big; large_range_matrix_table_sum; Failed benchmarks in run 2:; pc_relate_big; large_range_matrix_table_sum; Benchmark Name Ratio Time 1 Time 2; -------------- ----- ------ ------; table_big_aggregate_compile_and_execute 334.8% 13.325 44.608; matrix_table_array_arithmetic 133.9% 10.208 13.665; matrix_table_many_aggs_col_wise 131.4% 34.847 45.781; table_aggregate_counter 126.4% 13.136 16.606; per_row_stats_star_star 124.5% 8.474 10.553; matrix_table_filter_entries_unfilter 123.7% 8.581 10.616; ...; shuffle_key_rows_by_mt 82.8% 35.932 29.742; full_combiner_chr22 23.6% 1644.907 388.414; ----------------------; Geometric mean: 100.0%; Median: 99.2%; ```,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8963#issuecomment-650638060:78,log,logic,78,https://hail.is,https://github.com/hail-is/hail/pull/8963#issuecomment-650638060,5,"['Benchmark', 'benchmark', 'log']","['Benchmark', 'Benchmarks', 'benchmarks', 'logic']"
Testability,"Pick a backwards compatibility test table, `1.5.0/6.ht` is the simplest one. ```; In [2]: ht = hl.read_table('hail/src/test/resources/backward_compatability/1.5.0/table/6.ht/'. In [3]: ht.aggregate(hl.agg.collect(ht.nd)); Out[3]:; [array([[0, 1, 2, 3, 4],; [5, 6, 7, 8, 9]], dtype=int32),; array([[0, 1, 2, 3, 4],; [5, 6, 7, 8, 9]], dtype=int32),; array([[0, 1, 2, 3, 4],; [5, 6, 7, 8, 9]], dtype=int32),; array([[0, 1, 2, 3, 4],; [5, 6, 7, 8, 9]], dtype=int32),; array([[0, 1, 2, 3, 4],; [5, 6, 7, 8, 9]], dtype=int32)]. In [4]: ht.select('nd').show(); +-------+----------------------------------------------------------------+; | idx | nd |; +-------+----------------------------------------------------------------+; | int32 | ndarray<int32, 2> |; +-------+----------------------------------------------------------------+; | 0 | ndarray{shape=(2, 5), data=[[0, 5, 1, 6, 2], [7, 3, 8, 4, 9]]} |; | 1 | ndarray{shape=(2, 5), data=[[0, 5, 1, 6, 2], [7, 3, 8, 4, 9]]} |; | 2 | ndarray{shape=(2, 5), data=[[0, 5, 1, 6, 2], [7, 3, 8, 4, 9]]} |; | 3 | ndarray{shape=(2, 5), data=[[0, 5, 1, 6, 2], [7, 3, 8, 4, 9]]} |; | 4 | ndarray{shape=(2, 5), data=[[0, 5, 1, 6, 2], [7, 3, 8, 4, 9]]} |; +-------+----------------------------------------------------------------+; ```. The first result looks more correct to mine eyes.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9640:31,test,test,31,https://hail.is,https://github.com/hail-is/hail/issues/9640,2,['test'],['test']
Testability,"Picking up where #13776 left off. CHANGELOG: improved speed of reading hail format datasets from disk. This PR speeds up decoding arrays in two main ways:; * instead of calling `arrayType.isElementDefined(array, i)` on every single array element, which expands to; ```scala; val b = aoff + lengthHeaderBytes + (i >> 3); !((Memory.loadByte(b) & (1 << (i & 7).toInt)) != 0); ```; process elements in groups of 64, and load the corresponding long of missing bits once; * once we have a whole long of missing bits, we can be smarter than branching on each bit. After flipping to get `presentBits`, we use the following psuedocode to extract the positions of the set bits, with time proportional to the number of set bits:; ```; while (presentBits != 0) {; val idx = java.lang.Long.numberOfTrailingZeroes(presentBits); // do something with idx; presentBits = presentBits & (presentBits - 1) // unsets the rightmost set bit; }; ```. To avoid needing to handle the last block of 64 elements differently, this PR changes the layout of `PCanonicalArray` to ensure the missing bits are always padded out to a multiple of 64 bits. They were already padded to a multiple of 32, and I don't expect this change to have much of an effect. But if needed, blocking by 32 elements instead had very similar performance in my benchmarks. I also experimented with unrolling loops. In the non-missing case, this is easy. In the missing case, I tried using `if (presentBits.bitCount >= 8)` to guard an unrolled inner loop. In both cases, unrolling was if anything slower. Dan observed benefit from unrolling, but that was combined with the first optimization above (not loading a bit from memory every element), which I beleive was the real source of improvement.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13787:1306,benchmark,benchmarks,1306,https://hail.is,https://github.com/hail-is/hail/pull/13787,1,['benchmark'],['benchmarks']
Testability,Please check the change log and git history to determine if removing persist from VEP.scala was intentional. Please respond to discuss forum upon completion. . https://discuss.hail.is/t/parallel-hail-tasks/865/16?u=danking. Dice says John.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8147:24,log,log,24,https://hail.is,https://github.com/hail-is/hail/issues/8147,1,['log'],['log']
Testability,"Please make the one change, pass tests, and merge.",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1875#issuecomment-303504943:33,test,tests,33,https://hail.is,https://github.com/hail-is/hail/pull/1875#issuecomment-303504943,1,['test'],['tests']
Testability,Please reopen when you finish cleanup and benchmarking and it is ready for another serious look.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1141#issuecomment-271011013:42,benchmark,benchmarking,42,https://hail.is,https://github.com/hail-is/hail/pull/1141#issuecomment-271011013,1,['benchmark'],['benchmarking']
Testability,Poached! I will benchmark my version too.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3354#issuecomment-380560073:16,benchmark,benchmark,16,https://hail.is,https://github.com/hail-is/hail/pull/3354#issuecomment-380560073,1,['benchmark'],['benchmark']
Testability,Pool$.scoped(RegionPool.scala:13); 	at is.hail.expr.ir.ExecuteContext$.scoped(ExecuteContext.scala:46); 	at is.hail.backend.spark.SparkBackend.withExecuteContext(SparkBackend.scala:276); 	at is.hail.expr.ir.ExecuteContext$.$anonfun$scoped$1(ExecuteContext.scala:40); 	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:52); 	at is.hail.expr.ir.ExecuteContext$.scoped(ExecuteContext.scala:39); 	at is.hail.TestUtils$.assertEvalsTo(TestUtils.scala:339); 	at is.hail.TestUtils$.assertEvalsTo(TestUtils.scala:314); 	at is.hail.expr.ir.IRSuite.testStreamLenUnconsumedInnerStream(IRSuite.scala:1800); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:85); 	at org.testng.internal.Invoker.invokeMethod(Invoker.java:696); 	at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:882); 	at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:1189); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:124); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:108); 	at org.testng.TestRunner.privateRun(TestRunner.java:767); 	at org.testng.TestRunner.run(TestRunner.java:617); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:348); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:343); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:305); 	at org.testng.SuiteRunner.run(SuiteRunner.java:254); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:86); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1224); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1149); 	at org.testng.TestNG.run(TestNG.java:1057);,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10330#issuecomment-827119604:3623,test,testng,3623,https://hail.is,https://github.com/hail-is/hail/pull/10330#issuecomment-827119604,1,['test'],['testng']
Testability,"Pool$.scoped(RegionPool.scala:17); 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:59); 	at is.hail.backend.spark.SparkBackend.withExecuteContext(SparkBackend.scala:339); 	at is.hail.backend.spark.SparkBackend.$anonfun$executeEncode$1(SparkBackend.scala:483); 	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:52); 	at is.hail.backend.spark.SparkBackend.executeEncode(SparkBackend.scala:482); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.lang.Thread.run(Thread.java:750). Hail version: 0.2.107-2387bb00ceee; Error summary: SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.4 in stage 1.0 (TID 10) (all-of-us-1774-w-0.c.terra-vpc-sc-23dfb1a3.internal executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Container from a bad node: container_e01_1690206305672_0001_01_000007 on host: all-of-us-1774-w-0.c.terra-vpc-sc-23dfb1a3.internal. Exit status: 137. Diagnostics: [2023-07-24 13:52:49.515]Container killed on request. Exit code is 137; [2023-07-24 13:52:49.517]Container exited with a non-zero exit code 137. ; [2023-07-24 13:52:49.518]Killed by external signal; .; Driver stacktrace:; ```; [hail-20230724-1347-0.2.107-2387bb00ceee.log](https://github.com/hail-is/hail/files/12146671/hail-20230724-1347-0.2.107-2387bb00ceee.log)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13287:12931,log,log,12931,https://hail.is,https://github.com/hail-is/hail/issues/13287,2,['log'],['log']
Testability,"Port `logreg` and `lmmreg` to api2. The tests in api1 weren't doing anything that the doctests don't already do, so I haven't added any more python tests.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2783:6,log,logreg,6,https://hail.is,https://github.com/hail-is/hail/pull/2783,3,"['log', 'test']","['logreg', 'tests']"
Testability,"Ported `ArrayFunctions.mean` to ArrayFold2. Benchmark:; ```python; @benchmark; def table_range_means():; ht = hl.utils.range_table(10_000_000, 16); ht = ht.annotate(m = hl.mean(hl.range(0, ht.idx % 1111))); ht._force_count(); ```. Master:; ```; 2019-09-03 09:39:05,777: INFO: [1/1] Running table_range_means...; 2019-09-03 09:40:52,557: INFO: burn in: 106.78s; 2019-09-03 09:42:34,333: INFO: run 1: 101.78s; 2019-09-03 09:44:14,982: INFO: run 2: 100.65s; 2019-09-03 09:45:53,590: INFO: run 3: 98.61s; ```. PR:; ```; 2019-09-03 09:47:26,110: INFO: [1/1] Running table_range_means...; 2019-09-03 09:47:29,465: INFO: burn in: 3.35s; 2019-09-03 09:47:32,615: INFO: run 1: 3.15s; 2019-09-03 09:47:35,703: INFO: run 2: 3.09s; 2019-09-03 09:47:38,840: INFO: run 3: 3.14s; ```",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6981#issuecomment-527467578:44,Benchmark,Benchmark,44,https://hail.is,https://github.com/hail-is/hail/pull/6981#issuecomment-527467578,2,"['Benchmark', 'benchmark']","['Benchmark', 'benchmark']"
Testability,"Ported support (from t2d branch) for filtering variants with symbolic alleles, and added a test.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/235:91,test,test,91,https://hail.is,https://github.com/hail-is/hail/pull/235,1,['test'],['test']
Testability,Ported trio_matrix test to 0.2,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3147:19,test,test,19,https://hail.is,https://github.com/hail-is/hail/pull/3147,1,['test'],['test']
Testability,"Possible. Let's make sure we add a test for this too, @iitalics .",MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6663#issuecomment-514795368:35,test,test,35,https://hail.is,https://github.com/hail-is/hail/issues/6663#issuecomment-514795368,1,['test'],['test']
Testability,Pradeep was seeing 2x larger output on VCF export after filtering/QC. This could explain some of it. Benchmark the improvement from this change and investigate further if this doesn't explain it.,MatchSource.ISSUE_COMMENT,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/563#issuecomment-238641595:101,Benchmark,Benchmark,101,https://hail.is,https://github.com/hail-is/hail/issues/563#issuecomment-238641595,1,['Benchmark'],['Benchmark']
Testability,"Pretty rough, not yet hooked into anything, but I wrote a test. This doesn't deal with the question of region management at the jvm/c++ interface, but it lays out a basic wrapper for passing iterators through c++.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4729:58,test,test,58,https://hail.is,https://github.com/hail-is/hail/pull/4729,1,['test'],['test']
Testability,Pretty() should not print the json representation of Literals to the log,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4907:69,log,log,69,https://hail.is,https://github.com/hail-is/hail/issues/4907,1,['log'],['log']
Testability,Prevent read if test isn't run,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1817:16,test,test,16,https://hail.is,https://github.com/hail-is/hail/pull/1817,1,['test'],['test']
