quality_attribute,sentence,source,author,repo,version,id,keyword,matched_word,match_idx,filename,wiki,url,total_similar,target_keywords,target_matched_words
Availability," _scanorama: https://github.com/brianhie/scanorama. Parameters; ----------; adata; The annotated data matrix.; key; The name of the column in ``adata.obs`` that differentiates; among experiments/batches. Cells from the same batch must be; contiguously stored in ``adata``.; basis; The name of the field in ``adata.obsm`` where the PCA table is; stored. Defaults to ``'X_pca'``, which is the default for; ``sc.pp.pca()``.; adjusted_basis; The name of the field in ``adata.obsm`` where the integrated; embeddings will be stored after running this function. Defaults; to ``X_scanorama``.; knn; Number of nearest neighbors to use for matching.; sigma; Correction smoothing parameter on Gaussian kernel.; approx; Use approximate nearest neighbors with Python ``annoy``;; greatly speeds up matching runtime.; alpha; Alignment score minimum cutoff.; batch_size; The batch size used in the alignment vector computation. Useful; when integrating very large (>100k samples) datasets. Set to; large value that runs within available memory.; kwargs; Any additional arguments will be passed to; ``scanorama.assemble()``. Returns; -------; Updates adata with the field ``adata.obsm[adjusted_basis]``,; containing Scanorama embeddings such that different experiments; are integrated. Example; -------; First, load libraries and example dataset, and preprocess. >>> import scanpy as sc; >>> import scanpy.external as sce; >>> adata = sc.datasets.pbmc3k(); >>> sc.pp.recipe_zheng17(adata); >>> sc.pp.pca(adata). We now arbitrarily assign a batch metadata variable to each cell; for the sake of example, but during real usage there would already; be a column in ``adata.obs`` giving the experiment each cell came; from. >>> adata.obs['batch'] = 1350*['a'] + 1350*['b']. Finally, run Scanorama. Afterwards, there will be a new table in; ``adata.obsm`` containing the Scanorama embeddings. >>> sce.pp.scanorama_integrate(adata, 'batch', verbose=1); Processing datasets a <=> b; >>> 'X_scanorama' in adata.obsm; True; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py:1411,avail,available,1411,src/scanpy/external/pp/_scanorama_integrate.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py,1,['avail'],['available']
Availability," final list of; neighbours for the cell. Aligns batches in a quick and lightweight manner. For use in the scanpy workflow as an alternative to :func:`~scanpy.pp.neighbors`. .. note::. This is just a wrapper of :func:`bbknn.bbknn`: up to date docstring,; more information and bug reports there. Params; ------; adata; Needs the PCA computed and stored in `adata.obsm[""X_pca""]`.; batch_key; `adata.obs` column name discriminating between your batches.; use_rep; The dimensionality reduction in `.obsm` to use for neighbour detection. Defaults to PCA.; approx; If `True`, use approximate neighbour finding - annoy or PyNNDescent. This results; in a quicker run time for large datasets while also potentially increasing the degree of; batch correction.; use_annoy; Only used when `approx=True`. If `True`, will use annoy for neighbour finding. If; `False`, will use pyNNDescent instead.; metric; What distance metric to use. The options depend on the choice of neighbour algorithm. ""euclidean"", the default, is always available. Annoy supports ""angular"", ""manhattan"" and ""hamming"". PyNNDescent supports metrics listed in `pynndescent.distances.named_distances`; and custom functions, including compiled Numba code. >>> import pynndescent; >>> pynndescent.distances.named_distances.keys() # doctest: +ELLIPSIS, +NORMALIZE_WHITESPACE; dict_keys(['euclidean', 'l2', 'sqeuclidean', 'manhattan', 'taxicab', 'l1', 'chebyshev', 'linfinity',; 'linfty', 'linf', 'minkowski', 'seuclidean', 'standardised_euclidean', 'wminkowski', ...]). KDTree supports members of :class:`sklearn.neighbors.KDTree`’s ``valid_metrics`` list, or parameterised; :class:`~sklearn.metrics.DistanceMetric` objects:. >>> import sklearn.neighbors; >>> sklearn.neighbors.KDTree.valid_metrics; ['euclidean', 'l2', 'minkowski', 'p', 'manhattan', 'cityblock', 'l1', 'chebyshev', 'infinity']. .. note:: check the relevant documentation for up-to-date lists.; copy; If `True`, return a copy instead of writing to the supplied adata.; neighbors_wi",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_bbknn.py:1300,avail,available,1300,src/scanpy/external/pp/_bbknn.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_bbknn.py,1,['avail'],['available']
Availability,"""""""(shape: n_cells); Boolean mask of predicted doublets in the observed transcriptomes.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/core.py:29,mask,mask,29,src/scanpy/preprocessing/_scrublet/core.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/core.py,1,['mask'],['mask']
Availability,"""""""(shape: n_cells); Standard error in the doublet scores for observed transcriptomes.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/core.py:30,error,error,30,src/scanpy/preprocessing/_scrublet/core.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/core.py,1,['error'],['error']
Availability,"""""""(shape: n_doublets); Standard error in the doublet scores for simulated doublets.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/core.py:33,error,error,33,src/scanpy/preprocessing/_scrublet/core.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/core.py,1,['error'],['error']
Availability,"""""""; Given a dictionary of plot parameters (kwds_dict) and a dict of kwds,; merge the parameters into a single consolidated dictionary to avoid; argument duplication errors. If kwds_dict an kwargs have the same key, only the value in kwds_dict is kept. Parameters; ----------; kwds_dict kwds_dictionary; kwargs. Returns; -------; kwds_dict merged with kwargs. Examples; --------. >>> def _example(**kwds):; ... return fix_kwds(kwds, key1=""value1"", key2=""value2""); >>> _example(key1=""value10"", key3=""value3""); {'key1': 'value10', 'key2': 'value2', 'key3': 'value3'}; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_utils.py:166,error,errors,166,src/scanpy/plotting/_utils.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_utils.py,1,['error'],['errors']
Availability,"""""""; Test if pca result is equal without highly variable and with-but mask is None; and if pca takes highly variable as mask as default; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py:70,mask,mask,70,tests/test_pca.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py,2,['mask'],['mask']
Availability,"""""""; Tests that these functions print to stdout and don't error. Checks that https://github.com/scverse/scanpy/issues/1437 is fixed.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_logging.py:58,error,error,58,tests/test_logging.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_logging.py,1,['error'],['error']
Availability,"""""""; Validate mask argument; Params; ------; data; Annotated data matrix or numpy array.; mask; The mask. Either an appropriatley sized boolean array, or name of a column which will be used to mask.; dim; The dimension being masked.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/get.py:14,mask,mask,14,src/scanpy/get/get.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/get.py,5,['mask'],"['mask', 'masked']"
Availability,"""""""; Verbosity level (default `warning`). Level 0: only show 'error' messages.; Level 1: also show 'warning' messages.; Level 2: also show 'info' messages.; Level 3: also show 'hint' messages.; Level 4: also show very detailed progress for 'debug'ging.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_settings.py:62,error,error,62,src/scanpy/_settings.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_settings.py,1,['error'],['error']
Availability,"""""""Available file formats for reading data. """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py:3,Avail,Available,3,src/scanpy/readwrite.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py,1,['Avail'],['Available']
Availability,"""""""Check error for n_obs / mask length mismatch.""""""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py:9,error,error,9,tests/test_pca.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py,2,"['error', 'mask']","['error', 'mask']"
Availability,"""""""Check if file is present otherwise download.""""""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/__init__.py:38,down,download,38,src/scanpy/_utils/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/__init__.py,1,['down'],['download']
Availability,"""""""Check if use_highly_variable=True throws an error if the annotation is missing.""""""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py:47,error,error,47,tests/test_pca.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py,1,['error'],['error']
Availability,"""""""Check that all desired cells are coloured and masked cells gray""""""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:49,mask,masked,49,tests/test_plotting.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py,1,['mask'],['masked']
Availability,"""""""Check that the same mask given as string or bool array provides the same result""""""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:23,mask,mask,23,tests/test_plotting.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py,1,['mask'],['mask']
Availability,"""""""Check whether the file is present, otherwise download.""""""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py:48,down,download,48,src/scanpy/readwrite.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py,1,['down'],['download']
Availability,"""""""Ensure that popping this as a `clustering_kwargs` and using it does not error out.""""""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_clustering.py:75,error,error,75,tests/test_clustering.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_clustering.py,1,['error'],['error']
Availability,"""""""Get boolean mask of genes with normalized dispersion in bounds.""""""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py:15,mask,mask,15,src/scanpy/preprocessing/_highly_variable_genes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py,1,['mask'],['mask']
Availability,"""""""Test if pca result is equal when given mask as boolarray vs string""""""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py:42,mask,mask,42,tests/test_pca.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py,1,['mask'],['mask']
Availability,"""""""Test that image download works and is does not have global effects.""""""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_datasets.py:19,down,download,19,tests/test_datasets.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_datasets.py,1,['down'],['download']
Availability,"""""""Tests that reading/ downloading works and is does not have global effects.""""""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_datasets.py:23,down,downloading,23,tests/test_datasets.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_datasets.py,1,['down'],['downloading']
Availability,"""""""\; 3k PBMCs from 10x Genomics. The data consists in 3k PBMCs from a Healthy Donor and is freely available; from 10x Genomics (file_ from this webpage_). The exact same data is also used in Seurat’s `basic clustering tutorial`_. .. _file: https://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz; .. _webpage: https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.1.0/pbmc3k; .. _basic clustering tutorial: https://satijalab.org/seurat/articles/pbmc3k_tutorial.html. .. note::; This downloads 5.9 MB of data upon the first call of the function and stores it in; :attr:`~scanpy._settings.ScanpyConfig.datasetdir`\\ `/pbmc3k_raw.h5ad`. The following code was run to produce the file. .. code:: python. adata = sc.read_10x_mtx(; # the directory with the `.mtx` file; './data/filtered_gene_bc_matrices/hg19/',; # use gene symbols for the variable names (variables-axis index); var_names='gene_symbols',; # write a cache file for faster subsequent reading; cache=True,; ). adata.var_names_make_unique() # this is unnecessary if using 'gene_ids'; adata.write('write/pbmc3k_raw.h5ad', compression='gzip'). Returns; -------; Annotated data matrix. Examples; --------; >>> import scanpy as sc; >>> sc.datasets.pbmc3k(); AnnData object with n_obs × n_vars = 2700 × 32738; var: 'gene_ids'; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py:99,avail,available,99,src/scanpy/datasets/_datasets.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py,2,"['avail', 'down']","['available', 'downloads']"
Availability,"""""""\; Aggregate data matrix based on some categorical grouping. This function is useful for pseudobulking as well as plotting. Aggregation to perform is specified by `func`, which can be a single metric or a; list of metrics. Each metric is computed over the group and results in a new layer; in the output `AnnData` object. If none of `layer`, `obsm`, or `varm` are passed in, `X` will be used for aggregation data. Params; ------; adata; :class:`~anndata.AnnData` to be aggregated.; by; Key of the column to be grouped-by.; func; How to aggregate.; axis; Axis on which to find group by column.; mask; Boolean mask (or key to column containing mask) to apply along the axis.; dof; Degrees of freedom for variance. Defaults to 1.; layer; If not None, key for aggregation data.; obsm; If not None, key for aggregation data.; varm; If not None, key for aggregation data. Returns; -------; Aggregated :class:`~anndata.AnnData`. Examples; --------. Calculating mean expression and number of nonzero entries per cluster:. >>> import scanpy as sc, pandas as pd; >>> pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(); >>> pbmc.shape; (2638, 13714); >>> aggregated = sc.get.aggregate(pbmc, by=""louvain"", func=[""mean"", ""count_nonzero""]); >>> aggregated; AnnData object with n_obs × n_vars = 8 × 13714; obs: 'louvain'; var: 'n_cells'; layers: 'mean', 'count_nonzero'. We can group over multiple columns:. >>> pbmc.obs[""percent_mito_binned""] = pd.cut(pbmc.obs[""percent_mito""], bins=5); >>> sc.get.aggregate(pbmc, by=[""louvain"", ""percent_mito_binned""], func=[""mean"", ""count_nonzero""]); AnnData object with n_obs × n_vars = 40 × 13714; obs: 'louvain', 'percent_mito_binned'; var: 'n_cells'; layers: 'mean', 'count_nonzero'. Note that this filters out any combination of groups that wasn't present in the original data.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/_aggregated.py:597,mask,mask,597,src/scanpy/get/_aggregated.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/_aggregated.py,3,['mask'],['mask']
Availability,"""""""\; Calculate correlation matrix. Calculate a correlation matrix for genes strored in sample annotation; using :func:`~scanpy.tl.rank_genes_groups`. Parameters; ----------; adata; Annotated data matrix.; name_list; Takes a list of genes for which to calculate the correlation matrix; groupby; If no name list is passed, genes are selected from the; results of rank_gene_groups. Then this is the key of the sample grouping to consider.; Note that in this case also a group index has to be specified.; group; Group index for which the correlation matrix for top_ranked genes should be calculated.; Currently only int is supported, will change very soon; n_genes; For how many genes to calculate correlation matrix? If specified, cuts the name list; (in whatever order it is passed).; data; At the moment, this is only relevant for the case that name_list is drawn from rank_gene_groups results.; If specified, collects mask for the called group and then takes only those cells specified.; If 'Complete', calculate correlation using full data; If 'Group', calculate correlation within the selected group.; If 'Rest', calculate corrlation for everything except the group; method; Which kind of correlation coefficient to use. pearson; standard correlation coefficient; kendall; Kendall Tau correlation coefficient; spearman; Spearman rank correlation; annotation_key; Allows to define the name of the anndata entry where results are stored.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_top_genes.py:919,mask,mask,919,src/scanpy/tools/_top_genes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_top_genes.py,1,['mask'],['mask']
Availability,"""""""\; Check that mask is applied successfully to data set \; where test statistics are already available (test stats overwritten).; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_rank_genes_groups.py:17,mask,mask,17,tests/test_rank_genes_groups.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_rank_genes_groups.py,2,"['avail', 'mask']","['available', 'mask']"
Availability,"""""""\; Check that no. genes in output is; 1. =n_genes when n_genes<sum(mask); 2. =sum(mask) when n_genes>sum(mask); """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_rank_genes_groups.py:70,mask,mask,70,tests/test_rank_genes_groups.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_rank_genes_groups.py,3,['mask'],['mask']
Availability,"""""""\; Compute transition matrix. Parameters; ----------; density_normalize; The density rescaling of Coifman and Lafon (2006): Then only the; geometry of the data matters, not the sampled density. Returns; -------; Makes attributes `.transitions_sym` and `.transitions` available.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/__init__.py:270,avail,available,270,src/scanpy/neighbors/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/__init__.py,1,['avail'],['available']
Availability,"""""""\; Computes a hierarchical clustering for the given `groupby` categories. By default, the PCA representation is used unless `.X`; has less than 50 variables. Alternatively, a list of `var_names` (e.g. genes) can be given. Average values of either `var_names` or components are used; to compute a correlation matrix. The hierarchical clustering can be visualized using; :func:`scanpy.pl.dendrogram` or multiple other visualizations that can; include a dendrogram: :func:`~scanpy.pl.matrixplot`,; :func:`~scanpy.pl.heatmap`, :func:`~scanpy.pl.dotplot`,; and :func:`~scanpy.pl.stacked_violin`. .. note::; The computation of the hierarchical clustering is based on predefined; groups and not per cell. The correlation matrix is computed using by; default pearson but other methods are available. Parameters; ----------; adata; Annotated data matrix; {n_pcs}; {use_rep}; var_names; List of var_names to use for computing the hierarchical clustering.; If `var_names` is given, then `use_rep` and `n_pcs` is ignored.; use_raw; Only when `var_names` is not None.; Use `raw` attribute of `adata` if present.; cor_method; correlation method to use.; Options are 'pearson', 'kendall', and 'spearman'; linkage_method; linkage method to use. See :func:`scipy.cluster.hierarchy.linkage`; for more information.; optimal_ordering; Same as the optimal_ordering argument of :func:`scipy.cluster.hierarchy.linkage`; which reorders the linkage matrix so that the distance between successive; leaves is minimal.; key_added; By default, the dendrogram information is added to; `.uns[f'dendrogram_{{groupby}}']`.; Notice that the `groupby` information is added to the dendrogram.; inplace; If `True`, adds dendrogram information to `adata.uns[key_added]`,; else this function returns the information. Returns; -------; Returns `None` if `inplace=True`, else returns a `dict` with dendrogram information. Sets the following field if `inplace=True`:. `adata.uns[f'dendrogram_{{group_by}}' | key_added]` : :class:`dict`; Den",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dendrogram.py:784,avail,available,784,src/scanpy/tools/_dendrogram.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dendrogram.py,1,['avail'],['available']
Availability,"""""""\; Creates a heatmap of the mean expression values per group of each var_names. This function provides a convenient interface to the :class:`~scanpy.pl.MatrixPlot`; class. If you need more flexibility, you should use :class:`~scanpy.pl.MatrixPlot`; directly. Parameters; ----------; {common_plot_args}; {groupby_plots_args}; {show_save_ax}; {vminmax}; kwds; Are passed to :func:`matplotlib.pyplot.pcolor`. Returns; -------; If `return_fig` is `True`, returns a :class:`~scanpy.pl.MatrixPlot` object,; else if `show` is false, return axes dict. See also; --------; :class:`~scanpy.pl.MatrixPlot`: The MatrixPlot class can be used to to control; several visual parameters not available in this function.; :func:`~scanpy.pl.rank_genes_groups_matrixplot`: to plot marker genes; identified using the :func:`~scanpy.tl.rank_genes_groups` function. Examples; --------. .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); markers = ['C1QA', 'PSAP', 'CD79A', 'CD79B', 'CST3', 'LYZ']; sc.pl.matrixplot(adata, markers, groupby='bulk_labels', dendrogram=True). Using var_names as dict:. .. plot::; :context: close-figs. markers = {{'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}}; sc.pl.matrixplot(adata, markers, groupby='bulk_labels', dendrogram=True). Get Matrix object for fine tuning:. .. plot::; :context: close-figs. mp = sc.pl.matrixplot(adata, markers, 'bulk_labels', return_fig=True); mp.add_totals().style(edge_color='black').show(). The axes used can be obtained using the get_axes() method. .. plot::; :context: close-figs. axes_dict = mp.get_axes(); """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_matrixplot.py:677,avail,available,677,src/scanpy/plotting/_matrixplot.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_matrixplot.py,1,['avail'],['available']
Availability,"""""""\; Default number of jobs/ CPUs to use for parallel computing. Set to `-1` in order to use all available cores.; Not all algorithms support special behavior for numbers < `-1`,; so make sure to leave this setting as >= `-1`.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_settings.py:98,avail,available,98,src/scanpy/_settings.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_settings.py,1,['avail'],['available']
Availability,"""""""\; Detect branchings and partition the data into corresponding segments. Detect all branchings up to `n_branchings`. Writes; ------; segs : :class:`~numpy.ndarray`; Array of dimension (number of segments) × (number of data; points). Each row stores a mask array that defines a segment.; segs_tips : :class:`~numpy.ndarray`; Array of dimension (number of segments) × 2. Each row stores the; indices of the two tip points of each segment.; segs_names : :class:`~numpy.ndarray`; Array of dimension (number of data points). Stores an integer label; for each segment.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py:254,mask,mask,254,src/scanpy/tools/_dpt.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py,1,['mask'],['mask']
Availability,"""""""\; Download Visium spatial data from 10x Genomics’ database. Params; ------; sample_id; String name of example visium dataset.; base_dir; Where to download the dataset to.; download_image; Whether to download the high-resolution tissue section.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py:6,Down,Download,6,src/scanpy/datasets/_datasets.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py,3,"['Down', 'down']","['Download', 'download']"
Availability,"""""""\; Downsample counts from count matrix. If `counts_per_cell` is specified, each cell will downsampled.; If `total_counts` is specified, expression matrix will be downsampled to; contain at most `total_counts`. Parameters; ----------; adata; Annotated data matrix.; counts_per_cell; Target total counts per cell. If a cell has more than 'counts_per_cell',; it will be downsampled to this number. Resulting counts can be specified; on a per cell basis by passing an array.Should be an integer or integer; ndarray with same length as number of obs.; total_counts; Target total counts. If the count matrix has more than `total_counts`; it will be downsampled to have this number.; random_state; Random seed for subsampling.; replace; Whether to sample the counts with replacement.; copy; Determines whether a copy of `adata` is returned. Returns; -------; Returns `None` if `copy=False`, else returns an `AnnData` object. Sets the following fields:. `adata.X` : :class:`numpy.ndarray` | :class:`scipy.sparse.spmatrix` (dtype `float`); Downsampled counts matrix.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:6,Down,Downsample,6,src/scanpy/preprocessing/_simple.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py,6,"['Down', 'down']","['Downsample', 'Downsampled', 'downsampled']"
Availability,"""""""\; Filter genes based on number of cells or counts. Keep genes that have at least `min_counts` counts or are expressed in at; least `min_cells` cells or have at most `max_counts` counts or are expressed; in at most `max_cells` cells. Only provide one of the optional parameters `min_counts`, `min_cells`,; `max_counts`, `max_cells` per call. Parameters; ----------; data; An annotated data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; min_counts; Minimum number of counts required for a gene to pass filtering.; min_cells; Minimum number of cells expressed required for a gene to pass filtering.; max_counts; Maximum number of counts required for a gene to pass filtering.; max_cells; Maximum number of cells expressed required for a gene to pass filtering.; inplace; Perform computation inplace or return result. Returns; -------; Depending on `inplace`, returns the following arrays or directly subsets; and annotates the data matrix. gene_subset; Boolean index mask that does filtering. `True` means that the; gene is kept. `False` means the gene is removed.; number_per_gene; Depending on what was thresholded (`counts` or `cells`), the array stores; `n_counts` or `n_cells` per gene.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:1007,mask,mask,1007,src/scanpy/preprocessing/_simple.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py,1,['mask'],['mask']
Availability,"""""""\; Force-directed graph drawing :cite:p:`Islam2011,Jacomy2014,Chippada2018`. An alternative to tSNE that often preserves the topology of the data; better. This requires to run :func:`~scanpy.pp.neighbors`, first. The default layout ('fa', `ForceAtlas2`, :cite:t:`Jacomy2014`) uses the package |fa2|_; :cite:p:`Chippada2018`, which can be installed via `pip install fa2`. `Force-directed graph drawing`_ describes a class of long-established; algorithms for visualizing graphs.; It has been suggested for visualizing single-cell data by :cite:t:`Islam2011`.; Many other layouts as implemented in igraph :cite:p:`Csardi2006` are available.; Similar approaches have been used by :cite:t:`Zunder2015` or :cite:t:`Weinreb2017`. .. |fa2| replace:: `fa2`; .. _fa2: https://github.com/bhargavchippada/forceatlas2; .. _Force-directed graph drawing: https://en.wikipedia.org/wiki/Force-directed_graph_drawing. Parameters; ----------; adata; Annotated data matrix.; layout; 'fa' (`ForceAtlas2`) or any valid `igraph layout; <https://igraph.org/c/doc/igraph-Layout.html>`__. Of particular interest; are 'fr' (Fruchterman Reingold), 'grid_fr' (Grid Fruchterman Reingold,; faster than 'fr'), 'kk' (Kamadi Kawai', slower than 'fr'), 'lgl' (Large; Graph, very fast), 'drl' (Distributed Recursive Layout, pretty fast) and; 'rt' (Reingold Tilford tree layout).; root; Root for tree layouts.; random_state; For layouts with random initialization like 'fr', change this to use; different intial states for the optimization. If `None`, no seed is set.; adjacency; Sparse adjacency matrix of the graph, defaults to neighbors connectivities.; key_added_ext; By default, append `layout`.; proceed; Continue computation, starting off with 'X_draw_graph_`layout`'.; init_pos; `'paga'`/`True`, `None`/`False`, or any valid 2d-`.obsm` key.; Use precomputed coordinates for initialization.; If `False`/`None` (the default), initialize randomly.; neighbors_key; If not specified, draw_graph looks .obsp['connectivities'] for con",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_draw_graph.py:630,avail,available,630,src/scanpy/tools/_draw_graph.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_draw_graph.py,1,['avail'],['available']
Availability,"""""""\; Functionality for generic grouping and aggregating. There is currently support for count_nonzero, sum, mean, and variance. **Implementation**. Moments are computed using weighted sum aggregation of data by some feature; via multiplication by a sparse coordinate matrix A. Runtime is effectively computation of the product `A @ X`, i.e. the count of (non-zero); entries in X with multiplicity the number of group memberships for that entry.; This is `O(data)` for partitions (each observation belonging to exactly one group),; independent of the number of groups. Params; ------; groupby; :class:`~pandas.Categorical` containing values for grouping by.; data; Data matrix for aggregation.; mask; Mask to be used for aggregation.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/_aggregated.py:695,mask,mask,695,src/scanpy/get/_aggregated.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/_aggregated.py,2,"['Mask', 'mask']","['Mask', 'mask']"
Availability,"""""""\; Image files did not match.; RMS Value: {rms}; Expected: {expected}; Actual: {actual}; Difference: {diff}; Tolerance: {tol}; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/conftest.py:112,Toler,Tolerance,112,tests/conftest.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/conftest.py,1,['Toler'],['Tolerance']
Availability,"""""""\; Load a dataset from the EBI Single Cell Expression Atlas. The atlas_ can be browsed online to find the ``accession`` you want.; Downloaded datasets are saved in the directory specified by; :attr:`~scanpy._settings.ScanpyConfig.datasetdir`. .. _atlas: https://www.ebi.ac.uk/gxa/sc/experiments. Params; ------; accession; Dataset accession. Like ``E-GEOD-98816`` or ``E-MTAB-4888``.; This can be found in the url on the datasets page, for example E-GEOD-98816_. .. _E-GEOD-98816: https://www.ebi.ac.uk/gxa/sc/experiments/E-GEOD-98816/results/tsne; filter_boring; Whether boring labels in `.obs` should be automatically removed, such as; labels with a single or :attr:`~anndata.AnnData.n_obs` distinct values. Returns; -------; Annotated data matrix. Example; -------; >>> import scanpy as sc; >>> sc.datasets.ebi_expression_atlas(""E-MTAB-4888"") # doctest: +ELLIPSIS; AnnData object with n_obs × n_vars = 2261 × 23899; obs: 'Sample Characteristic[organism]', 'Sample Characteristic Ontology Term[organism]', ..., 'Factor Value[cell type]', 'Factor Value Ontology Term[cell type]'; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_ebi_expression_atlas.py:134,Down,Downloaded,134,src/scanpy/datasets/_ebi_expression_atlas.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_ebi_expression_atlas.py,1,['Down'],['Downloaded']
Availability,"""""""\; Markov Affinity-based Graph Imputation of Cells (MAGIC) API :cite:p:`vanDijk2018`. MAGIC is an algorithm for denoising and transcript recover of single cells; applied to single-cell sequencing data. MAGIC builds a graph from the data; and uses diffusion to smooth out noise and recover the data manifold. The algorithm implemented here has changed primarily in two ways; compared to the algorithm described in :cite:t:`vanDijk2018`. Firstly, we use; the adaptive kernel described in :cite:t:`Moon2019` for; improved stability. Secondly, data diffusion is applied; in the PCA space, rather than the data space, for speed and; memory improvements. More information and bug reports; `here <https://github.com/KrishnaswamyLab/MAGIC>`__. For help, visit; <https://krishnaswamylab.org/get-help>. Parameters; ----------; adata; An anndata file with `.raw` attribute representing raw counts.; name_list; Denoised genes to return. The default `'all_genes'`/`None`; may require a large amount of memory if the input data is sparse.; Another possibility is `'pca_only'`.; knn; number of nearest neighbors on which to build kernel.; decay; sets decay rate of kernel tails.; If None, alpha decaying kernel is not used.; knn_max; maximum number of nearest neighbors with nonzero connection.; If `None`, will be set to 3 * `knn`.; t; power to which the diffusion operator is powered.; This sets the level of diffusion. If 'auto', t is selected; according to the Procrustes disparity of the diffused data.; n_pca; Number of principal components to use for calculating; neighborhoods. For extremely large datasets, using; n_pca < 20 allows neighborhoods to be calculated in; roughly log(n_samples) time. If `None`, no PCA is performed.; solver; Which solver to use. ""exact"" uses the implementation described; in :cite:t:`vanDijk2018`. ""approximate"" uses a faster; implementation that performs imputation in the PCA space and then; projects back to the gene space. Note, the ""approximate"" solver may; return negat",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_magic.py:140,recover,recover,140,src/scanpy/external/pp/_magic.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_magic.py,2,['recover'],['recover']
Availability,"""""""\; Processed Visium Spatial Gene Expression data from 10x Genomics’ database. The database_ can be browsed online to find the ``sample_id`` you want. .. _database: https://support.10xgenomics.com/spatial-gene-expression/datasets. Parameters; ----------; sample_id; The ID of the data sample in 10x’s spatial database.; include_hires_tiff; Download and include the high-resolution tissue image (tiff) in; `adata.uns[""spatial""][sample_id][""metadata""][""source_image_path""]`. Returns; -------; Annotated data matrix. Examples; --------. >>> import scanpy as sc; >>> sc.datasets.visium_sge(sample_id='V1_Breast_Cancer_Block_A_Section_1'); AnnData object with n_obs × n_vars = 3798 × 36601; obs: 'in_tissue', 'array_row', 'array_col'; var: 'gene_ids', 'feature_types', 'genome'; uns: 'spatial'; obsm: 'spatial'; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py:342,Down,Download,342,src/scanpy/datasets/_datasets.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py,1,['Down'],['Download']
Availability,"""""""\; Scale data to unit variance and zero mean. .. note::; Variables (genes) that do not display any variation (are constant across; all observations) are retained and (for zero_center==True) set to 0; during this operation. In the future, they might be set to NaNs. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; zero_center; If `False`, omit zero-centering variables, which allows to handle sparse; input efficiently.; max_value; Clip (truncate) to this value after scaling. If `None`, do not clip.; copy; Whether this function should be performed inplace. If an AnnData object; is passed, this also determines if a copy is returned.; layer; If provided, which element of layers to scale.; obsm; If provided, which element of obsm to scale.; mask_obs; Restrict both the derivation of scaling parameters and the scaling itself; to a certain set of observations. The mask is specified as a boolean array; or a string referring to an array in :attr:`~anndata.AnnData.obs`.; This will transform data from csc to csr format if `issparse(data)`. Returns; -------; Returns `None` if `copy=False`, else returns an updated `AnnData` object. Sets the following fields:. `adata.X` | `adata.layers[layer]` : :class:`numpy.ndarray` | :class:`scipy.sparse._csr.csr_matrix` (dtype `float`); Scaled count data matrix.; `adata.var['mean']` : :class:`pandas.Series` (dtype `float`); Means per gene before scaling.; `adata.var['std']` : :class:`pandas.Series` (dtype `float`); Standard deviations per gene before scaling.; `adata.var['var']` : :class:`pandas.Series` (dtype `float`); Variances per gene before scaling.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scale.py:957,mask,mask,957,src/scanpy/preprocessing/_scale.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scale.py,1,['mask'],['mask']
Availability,"""""""\; Unify new mask argument and deprecated use_highly_varible argument. Returns both the normalized mask parameter and the validated mask array.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py:16,mask,mask,16,src/scanpy/preprocessing/_pca.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py,3,['mask'],['mask']
Availability,"""""""\; adata; Annotated data matrix.; groups; The groups for which to show the gene ranking.; n_genes; Number of genes to show. This can be a negative number to show for; example the down regulated genes. eg: num_genes=-10. Is ignored if; `gene_names` is passed.; gene_symbols; Column name in `.var` DataFrame that stores gene symbols. By default `var_names`; refer to the index column of the `.var` DataFrame. Setting this option allows; alternative names to be used.; groupby; The key of the observation grouping to consider. By default,; the groupby is chosen from the rank genes groups parameter but; other groupby options can be used. It is expected that; groupby is a categorical. If groupby is not a categorical observation,; it would be subdivided into `num_categories` (see :func:`~scanpy.pl.dotplot`).; min_logfoldchange; Value to filter genes in groups if their logfoldchange is less than the; min_logfoldchange; key; Key used to store the ranking results in `adata.uns`.\; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_docs.py:182,down,down,182,src/scanpy/plotting/_docs.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_docs.py,1,['down'],['down']
Availability,"""""""\; mask_var; To run only on a certain set of genes given by a boolean array; or a string referring to an array in :attr:`~anndata.AnnData.var`.; By default, uses `.var['highly_variable']` if available, else everything.; use_highly_variable; Whether to use highly variable genes only, stored in; `.var['highly_variable']`.; By default uses them if they have been determined beforehand. .. deprecated:: 1.10.0; Use `mask_var` instead; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_docs.py:194,avail,available,194,src/scanpy/preprocessing/_docs.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_docs.py,1,['avail'],['available']
Availability,"# (still) Not equal to tolerance rtol=2e-05, atol=2e-05; # np.testing.assert_allclose(4, 3.9999, rtol=2e-05, atol=2e-05)",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_highly_variable_genes.py:23,toler,tolerance,23,tests/test_highly_variable_genes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_highly_variable_genes.py,1,['toler'],['tolerance']
Availability,"# *First compiled on May 5, 2017. Updated August 14, 2018.*; # # Clustering 3k PBMCs following a Seurat Tutorial; #; # This started out with a demonstration that Scanpy would allow to reproduce most of Seurat's; # ([Satija *et al.*, 2015](https://doi.org/10.1038/nbt.3192)) clustering tutorial as described on; # https://satijalab.org/seurat/articles/pbmc3k_tutorial.html (July 26, 2017), which we gratefully acknowledge.; # In the meanwhile, we have added and removed several pieces.; #; # The data consists in *3k PBMCs from a Healthy Donor* and is freely available from 10x Genomics; # ([here](https://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz); # from this [webpage](https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.1.0/pbmc3k)).",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/notebooks/test_pbmc3k.py:558,avail,available,558,tests/notebooks/test_pbmc3k.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/notebooks/test_pbmc3k.py,1,['avail'],['available']
Availability,"# Calculate rank sums for each chunk for the current mask",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py:53,mask,mask,53,src/scanpy/tools/_rank_genes_groups.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py,1,['mask'],['mask']
Availability,"# Checking the mask format and if used together with groups",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/scatterplots.py:15,mask,mask,15,src/scanpy/plotting/_tools/scatterplots.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/scatterplots.py,1,['mask'],['mask']
Availability,"# Circumvent pandas 0.23 bug. Both sides of the assignment have dtype==float32,; # but there’s still a dtype error without “.value”.",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py:109,error,error,109,src/scanpy/preprocessing/_deprecated/highly_variable_genes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py,1,['error'],['error']
Availability,"# Cutting down on size for plotting, tracksplot and stacked_violin are slow",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:10,down,down,10,tests/test_plotting.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py,1,['down'],['down']
Availability,"# Download counts",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py:2,Down,Download,2,src/scanpy/datasets/_datasets.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py,1,['Down'],['Download']
Availability,"# Download image",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py:2,Down,Download,2,src/scanpy/datasets/_datasets.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py,1,['Down'],['Download']
Availability,"# Download spatial data",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py:2,Down,Download,2,src/scanpy/datasets/_datasets.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py,1,['Down'],['Download']
Availability,"# If no reference group exists,; # ranking needs only to be done once (full mask)",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py:76,mask,mask,76,src/scanpy/tools/_rank_genes_groups.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py,1,['mask'],['mask']
Availability,"# If threshold hasn't been located successfully then we couldn't make any; # predictions. The user will get a warning from Scrublet, but we need to; # set the boolean so that any downstream filtering on; # predicted_doublet=False doesn't incorrectly filter cells. The user can; # still use this object to generate the plot and derive a threshold; # manually.",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py:179,down,downstream,179,src/scanpy/preprocessing/_scrublet/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py,1,['down'],['downstream']
Availability,"# Just tests for failure for now",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_preprocessing.py:17,failure,failure,17,tests/test_preprocessing.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_preprocessing.py,1,['failure'],['failure']
Availability,"# Make sure file doesn’t exist half-downloaded",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py:36,down,downloaded,36,src/scanpy/readwrite.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py,1,['down'],['downloaded']
Availability,"# Note that data is downloaded from gxa/sc/experiment, not experiments",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_ebi_expression_atlas.py:20,down,downloaded,20,src/scanpy/datasets/_ebi_expression_atlas.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_ebi_expression_atlas.py,1,['down'],['downloaded']
Availability,"# Simple method that can be called by rank_gene_group. It uses masks that have been passed to the function and; # calculates how much has to be subsampled in order to reach a certain precision with a certain probability; # Then it subsamples for mask, mask rest; # Since convergence speed varies, we take the slower one, i.e. the variance. This might have future speed-up; # potential",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_top_genes.py:63,mask,masks,63,src/scanpy/tools/_top_genes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_top_genes.py,3,['mask'],"['mask', 'masks']"
Availability,"# Singlet groups cause division by zero errors",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py:40,error,errors,40,src/scanpy/tools/_rank_genes_groups.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py,1,['error'],['errors']
Availability,"# TODO: Allow for sample weighting requires better mask access... later; # We store calculated data in dict, access it via dict to dict. Check if this is the best way.",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_top_genes.py:51,mask,mask,51,src/scanpy/tools/_top_genes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_top_genes.py,1,['mask'],['mask']
Availability,"# TODO: Come up with better solution. Mask unexpressed genes?; # See https://github.com/scipy/scipy/issues/10269",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py:38,Mask,Mask,38,src/scanpy/tools/_rank_genes_groups.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py,1,['Mask'],['Mask']
Availability,"# TODO: Report more context on the fields being compared on error; # TODO: Allow specifying paths to ignore on comparison; ###########################; # Representation choice; ###########################; # These functions can be used to check that functions are correctly using arugments like `layers`, `obsm`, etc.",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/testing/scanpy/_helpers/__init__.py:60,error,error,60,src/testing/scanpy/_helpers/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/testing/scanpy/_helpers/__init__.py,1,['error'],['error']
Availability,"# Test that changing random seed changes result; # Does not show up reliably with 32 bit computation",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py:68,reliab,reliably,68,tests/test_pca.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py,1,['reliab'],['reliably']
Availability,"# Test that downloading tissue image works",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_datasets.py:12,down,downloading,12,tests/test_datasets.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_datasets.py,1,['down'],['downloading']
Availability,"# Test that sc.pl.embedding_density() runs without error",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_embedding_density.py:51,error,error,51,tests/test_embedding_density.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_embedding_density.py,1,['error'],['error']
Availability,"# These shouldn't throw an error",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_preprocessing.py:27,error,error,27,tests/test_preprocessing.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_preprocessing.py,1,['error'],['error']
Availability,"# This is for backwards compat. Better behaviour would be to either error or use arpack.",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py:68,error,error,68,src/scanpy/preprocessing/_pca.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py,1,['error'],['error']
Availability,"# This should error",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py:14,error,error,14,tests/test_get.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py,1,['error'],['error']
Availability,"# This should not throw an error",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_preprocessing.py:27,error,error,27,tests/test_preprocessing.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_preprocessing.py,1,['error'],['error']
Availability,"# This shouldn't error",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py:17,error,error,17,tests/test_get.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py,1,['error'],['error']
Availability,"# Throws StopIteration Error if keys not present",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/scatterplots.py:23,Error,Error,23,src/scanpy/plotting/_tools/scatterplots.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/scatterplots.py,1,['Error'],['Error']
Availability,"# Tolerance",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/paga.py:2,Toler,Tolerance,2,src/scanpy/plotting/_tools/paga.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/paga.py,2,['Toler'],['Tolerance']
Availability,"# Unify new mask argument and deprecated use_highly_varible argument",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_normalization.py:12,mask,mask,12,src/scanpy/experimental/pp/_normalization.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_normalization.py,2,['mask'],['mask']
Availability,"# We should probably just make an index for this, and share it over runs; # TODO: Throw helpful error if this doesn't work",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/scatterplots.py:96,error,error,96,src/scanpy/plotting/_tools/scatterplots.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/scatterplots.py,1,['error'],['error']
Availability,"# We use all ARRAY_TYPES here since this error should be raised before; # PCA can realize that it got a Dask array",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py:41,error,error,41,tests/test_pca.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py,1,['error'],['error']
Availability,"# Without highly variable genes, we don’t use a mask by default",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py:48,mask,mask,48,src/scanpy/preprocessing/_pca.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py,1,['mask'],['mask']
Availability,"# cell_ranger flavor can raise error if many 0 genes",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_highly_variable_genes.py:31,error,error,31,tests/test_highly_variable_genes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_highly_variable_genes.py,1,['error'],['error']
Availability,"# check PC shape (non-hvgs are masked with 0s, so original number of genes)",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_normalization.py:31,mask,masked,31,tests/test_normalization.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_normalization.py,1,['mask'],['masked']
Availability,"# cut label to fit available space",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py:19,avail,available,19,src/scanpy/plotting/_anndata.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py,2,['avail'],['available']
Availability,"# define a set of available functions",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:18,avail,available,18,src/scanpy/tools/_sim.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py,1,['avail'],['available']
Availability,"# errors should be raised for invalid theta values",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_highly_variable_genes.py:2,error,errors,2,tests/test_highly_variable_genes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_highly_variable_genes.py,1,['error'],['errors']
Availability,"# get default image params if available",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/scatterplots.py:30,avail,available,30,src/scanpy/plotting/_tools/scatterplots.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/scatterplots.py,1,['avail'],['available']
Availability,"# gives a strange error, probably due to jitter or something; # sc.pl.rank_genes_groups_violin(adata, groups='0', n_genes=8); # save_and_compare_images('rank_genes_groups_4')",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/notebooks/test_pbmc3k.py:18,error,error,18,tests/notebooks/test_pbmc3k.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/notebooks/test_pbmc3k.py,1,['error'],['error']
Availability,"# https://github.com/scverse/scanpy/issues/1634; # Test for error where just passing obsm_keys, but not keys, would cause error.",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py:60,error,error,60,tests/test_get.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py,2,['error'],['error']
Availability,"# if all values are identical, the statsmodel.api.GLM throws an error;; # but then no regression is necessary anyways...",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:64,error,error,64,src/scanpy/preprocessing/_simple.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py,1,['error'],['error']
Availability,"# install dask if available",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scale.py:18,avail,available,18,src/scanpy/preprocessing/_scale.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scale.py,2,['avail'],['available']
Availability,"# make errors visible and the rest ignored",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/testing/scanpy/_pytest/fixtures/__init__.py:7,error,errors,7,src/testing/scanpy/_pytest/fixtures/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/testing/scanpy/_pytest/fixtures/__init__.py,1,['error'],['errors']
Availability,"# make link list, avoid redundant encoding (graph is undirected)",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/exporting.py:24,redundant,redundant,24,src/scanpy/external/exporting.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/exporting.py,1,['redundant'],['redundant']
Availability,"# make segs a list of mask arrays, it's easier to store; # as there is a hdf5 equivalent",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py:22,mask,mask,22,src/scanpy/tools/_dpt.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py,1,['mask'],['mask']
Availability,"# masked operations on sparse produce which numpy matrices gives the same API issues handled here",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/__init__.py:2,mask,masked,2,src/scanpy/_utils/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/__init__.py,1,['mask'],['masked']
Availability,"# remove the xticks labels except for the last processed plot.; # Because the plots share the x axis it is redundant and less compact; # to plot the axis for each plot",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py:107,redundant,redundant,107,src/scanpy/plotting/_anndata.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py,1,['redundant'],['redundant']
Availability,"# restrict number of neighbors to ~k; # build a symmetric mask",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/_connectivity.py:58,mask,mask,58,src/scanpy/neighbors/_connectivity.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/_connectivity.py,1,['mask'],['mask']
Availability,"# settings.m(0,availnodes); # settings.m(0,leafnodes); # settings.m(0,self.Adj); # settings.m(0,'-')",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:15,avail,availnodes,15,src/scanpy/tools/_sim.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py,1,['avail'],['availnodes']
Availability,"# settings.m(0,leafnodes,availnodes)",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:25,avail,availnodes,25,src/scanpy/tools/_sim.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py,1,['avail'],['availnodes']
Availability,"# standard errors, warnings etc.",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py:11,error,errors,11,src/scanpy/tools/_dpt.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py,1,['error'],['errors']
Availability,"# the pbmc68k was generated using rank_genes_groups with method='logreg'; # which does not generate 'logfoldchanges', although this field is; # required by `sc.get.rank_genes_groups_df`.; # After updating rank_genes_groups plots to use the latter function; # an error appears. Re-running rank_genes_groups with default method; # solves the problem.",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:262,error,error,262,tests/test_plotting.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py,1,['error'],['error']
Availability,"# update availnodes",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:9,avail,availnodes,9,src/scanpy/tools/_sim.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py,1,['avail'],['availnodes']
Availability,"##################################; # Test errors for obs_df, var_df #; ##################################",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py:43,error,errors,43,tests/test_get.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py,1,['error'],['errors']
Availability,".; svd_solver; SVD solver to use:. `None`; See `chunked` and `zero_center` descriptions to determine which class will be used.; Depending on the class and the type of X different values for default will be set.; If *scikit-learn* :class:`~sklearn.decomposition.PCA` is used, will give `'arpack'`,; if *scikit-learn* :class:`~sklearn.decomposition.TruncatedSVD` is used, will give `'randomized'`,; if *dask-ml* :class:`~dask_ml.decomposition.PCA` or :class:`~dask_ml.decomposition.IncrementalPCA` is used, will give `'auto'`,; if *dask-ml* :class:`~dask_ml.decomposition.TruncatedSVD` is used, will give `'tsqr'`; `'arpack'`; for the ARPACK wrapper in SciPy (:func:`~scipy.sparse.linalg.svds`); Not available with *dask* arrays.; `'randomized'`; for the randomized algorithm due to Halko (2009). For *dask* arrays,; this will use :func:`~dask.array.linalg.svd_compressed`.; `'auto'`; chooses automatically depending on the size of the problem.; `'lobpcg'`; An alternative SciPy solver. Not available with dask arrays.; `'tsqr'`; Only available with *dask* arrays. ""tsqr""; algorithm from Benson et. al. (2013). .. versionchanged:: 1.9.3; Default value changed from `'arpack'` to None.; .. versionchanged:: 1.4.5; Default value changed from `'auto'` to `'arpack'`. Efficient computation of the principal components of a sparse matrix; currently only works with the `'arpack`' or `'lobpcg'` solvers. If X is a *dask* array, *dask-ml* classes :class:`~dask_ml.decomposition.PCA`,; :class:`~dask_ml.decomposition.IncrementalPCA`, or; :class:`~dask_ml.decomposition.TruncatedSVD` will be used.; Otherwise their *scikit-learn* counterparts :class:`~sklearn.decomposition.PCA`,; :class:`~sklearn.decomposition.IncrementalPCA`, or; :class:`~sklearn.decomposition.TruncatedSVD` will be used.; random_state; Change to use different initial states for the optimization.; return_info; Only relevant when not passing an :class:`~anndata.AnnData`:; see “Returns”.; {mask_var_hvg}; layer; Layer of `adata` to use as e",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py:2193,avail,available,2193,src/scanpy/preprocessing/_pca.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py,1,['avail'],['available']
Availability,"; expressed only if the expression value is greater than this threshold.; mean_only_expressed; If True, gene expression is averaged only over the cells; expressing the given genes.; dot_max; If none, the maximum dot size is set to the maximum fraction value found; (e.g. 0.6). If given, the value should be a number between 0 and 1.; All fractions larger than dot_max are clipped to this value.; dot_min; If none, the minimum dot size is set to 0. If given,; the value should be a number between 0 and 1.; All fractions smaller than dot_min are clipped to this value.; smallest_dot; If none, the smallest dot has size 0.; All expression levels with `dot_min` are plotted with this size.; {show_save_ax}; {vminmax}; kwds; Are passed to :func:`matplotlib.pyplot.scatter`. Returns; -------; If `return_fig` is `True`, returns a :class:`~scanpy.pl.DotPlot` object,; else if `show` is false, return axes dict. See also; --------; :class:`~scanpy.pl.DotPlot`: The DotPlot class can be used to to control; several visual parameters not available in this function.; :func:`~scanpy.pl.rank_genes_groups_dotplot`: to plot marker genes; identified using the :func:`~scanpy.tl.rank_genes_groups` function. Examples; --------. Create a dot plot using the given markers and the PBMC example dataset grouped by; the category 'bulk_labels'. .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); markers = ['C1QA', 'PSAP', 'CD79A', 'CD79B', 'CST3', 'LYZ']; sc.pl.dotplot(adata, markers, groupby='bulk_labels', dendrogram=True). Using var_names as dict:. .. plot::; :context: close-figs. markers = {{'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}}; sc.pl.dotplot(adata, markers, groupby='bulk_labels', dendrogram=True). Get DotPlot object for fine tuning. .. plot::; :context: close-figs. dp = sc.pl.dotplot(adata, markers, 'bulk_labels', return_fig=True); dp.add_totals().style(dot_edge_color='black', dot_edge_lw=0.5).show(). The axes used can be obtained using the ge",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_dotplot.py:2241,avail,available,2241,src/scanpy/plotting/_dotplot.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_dotplot.py,1,['avail'],['available']
Availability,"ale the width of each violin.; If 'width' (the default), each violin will have the same width.; If 'area', each violin will have the same area.; If 'count', a violin’s width corresponds to the number of observations.; yticklabels; Set to true to view the y tick labels.; row_palette; Be default, median values are mapped to the violin color using a; color map (see `cmap` argument). Alternatively, a 'row_palette` can; be given to color each violin plot row using a different colors.; The value should be a valid seaborn or matplotlib palette name; (see :func:`~seaborn.color_palette`).; Alternatively, a single color name or hex value can be passed,; e.g. `'red'` or `'#cc33ff'`.; {show_save_ax}; {vminmax}; kwds; Are passed to :func:`~seaborn.violinplot`. Returns; -------; If `return_fig` is `True`, returns a :class:`~scanpy.pl.StackedViolin` object,; else if `show` is false, return axes dict. See also; --------; :class:`~scanpy.pl.StackedViolin`: The StackedViolin class can be used to to control; several visual parameters not available in this function.; :func:`~scanpy.pl.rank_genes_groups_stacked_violin` to plot marker genes identified; using the :func:`~scanpy.tl.rank_genes_groups` function. Examples; -------. Visualization of violin plots of a few genes grouped by the category `bulk_labels`:. .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); markers = ['C1QA', 'PSAP', 'CD79A', 'CD79B', 'CST3', 'LYZ']; sc.pl.stacked_violin(adata, markers, groupby='bulk_labels', dendrogram=True). Same visualization but passing var_names as dict, which adds a grouping of; the genes on top of the image:. .. plot::; :context: close-figs. markers = {{'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}}; sc.pl.stacked_violin(adata, markers, groupby='bulk_labels', dendrogram=True). Get StackedViolin object for fine tuning. .. plot::; :context: close-figs. vp = sc.pl.stacked_violin(adata, markers, 'bulk_labels', return_fig=True); vp.add_totals().sty",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_stacked_violin.py:1960,avail,available,1960,src/scanpy/plotting/_stacked_violin.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_stacked_violin.py,1,['avail'],['available']
Availability,"e kNN adjacency; matrix output by SAM. If built-in scanpy dimensionality reduction; methods are to be used using the SAM-output AnnData, users; should recompute the neighbors using `.obs['X_pca']` with; `scanpy.pp.neighbors`.; `.obsm['X_pca']`; The principal components output by SAM.; `.obsm['X_umap']`; The UMAP projection output by SAM.; `.layers['X_disp']`; The expression matrix used for nearest-neighbor averaging.; `.layers['X_knn_avg']`; The nearest-neighbor-averaged expression data used for computing the; spatial dispersions of genes. Example; -------; >>> import scanpy.external as sce; >>> import scanpy as sc. *** Running SAM ***. Assuming we are given an AnnData object called `adata`, we can run the SAM; algorithm as follows:. >>> sam_obj = sce.tl.sam(adata,inplace=True). The input AnnData object should contain unstandardized, non-negative; expression values. Preferably, the data should be log-normalized and no; genes should be filtered out. Please see the documentation for a description of all available parameters. For more detailed tutorials, please visit the original Github repository:; https://github.com/atarashansky/self-assembling-manifold/tree/master/tutorial. *** Plotting ***. To visualize the output, we can use:. >>> sce.pl.sam(adata,projection='X_umap'). `sce.pl.sam` accepts all keyword arguments used in the; `matplotlib.pyplot.scatter` function. *** SAMGUI ***. SAM comes with the SAMGUI module, a graphical-user interface written with; `Plotly` and `ipythonwidgets` for interactively exploring and annotating; the scRNAseq data and running SAM. Dependencies can be installed with Anaconda by following the instructions in; the self-assembling-manifold Github README:; https://github.com/atarashansky/self-assembling-manifold. In a Jupyter notebook, execute the following to launch the interface:. >>> from samalg.gui import SAMGUI; >>> sam_gui = SAMGUI(sam_obj) # sam_obj is your SAM object; >>> sam_gui.SamPlot. This can also be enabled in Jupyer Lab by foll",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_sam.py:4481,avail,available,4481,src/scanpy/external/tl/_sam.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_sam.py,1,['avail'],['available']
Availability,"e`; See `chunked` and `zero_center` descriptions to determine which class will be used.; Depending on the class and the type of X different values for default will be set.; If *scikit-learn* :class:`~sklearn.decomposition.PCA` is used, will give `'arpack'`,; if *scikit-learn* :class:`~sklearn.decomposition.TruncatedSVD` is used, will give `'randomized'`,; if *dask-ml* :class:`~dask_ml.decomposition.PCA` or :class:`~dask_ml.decomposition.IncrementalPCA` is used, will give `'auto'`,; if *dask-ml* :class:`~dask_ml.decomposition.TruncatedSVD` is used, will give `'tsqr'`; `'arpack'`; for the ARPACK wrapper in SciPy (:func:`~scipy.sparse.linalg.svds`); Not available with *dask* arrays.; `'randomized'`; for the randomized algorithm due to Halko (2009). For *dask* arrays,; this will use :func:`~dask.array.linalg.svd_compressed`.; `'auto'`; chooses automatically depending on the size of the problem.; `'lobpcg'`; An alternative SciPy solver. Not available with dask arrays.; `'tsqr'`; Only available with *dask* arrays. ""tsqr""; algorithm from Benson et. al. (2013). .. versionchanged:: 1.9.3; Default value changed from `'arpack'` to None.; .. versionchanged:: 1.4.5; Default value changed from `'auto'` to `'arpack'`. Efficient computation of the principal components of a sparse matrix; currently only works with the `'arpack`' or `'lobpcg'` solvers. If X is a *dask* array, *dask-ml* classes :class:`~dask_ml.decomposition.PCA`,; :class:`~dask_ml.decomposition.IncrementalPCA`, or; :class:`~dask_ml.decomposition.TruncatedSVD` will be used.; Otherwise their *scikit-learn* counterparts :class:`~sklearn.decomposition.PCA`,; :class:`~sklearn.decomposition.IncrementalPCA`, or; :class:`~sklearn.decomposition.TruncatedSVD` will be used.; random_state; Change to use different initial states for the optimization.; return_info; Only relevant when not passing an :class:`~anndata.AnnData`:; see “Returns”.; {mask_var_hvg}; layer; Layer of `adata` to use as expression values.; dtype; Numpy data ty",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py:2237,avail,available,2237,src/scanpy/preprocessing/_pca.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py,1,['avail'],['available']
Availability,"g one of two optional inputs:. *Principal component analysis*. >>> sc.pp.pca(adata, n_comps=300). or,. *Nearist neighbors graph*. >>> sc.pp.neighbors(adata, knn=30). *Diffusion maps*. Palantir determines the diffusion maps of the data as an estimate of the low; dimensional phenotypic manifold of the data. >>> sce.tl.palantir(adata, n_components=5, knn=30). if pre-computed distances are to be used,. >>> sce.tl.palantir(; ... adata,; ... n_components=5,; ... knn=30,; ... use_adjacency_matrix=True,; ... distances_key=""distances"",; ... ). **Visualizing Palantir results**. *tSNE visualization*. important for Palantir!. Palantir constructs the tSNE map in the embedded space since these maps better; represent the differentiation trajectories. >>> sc.tl.tsne(adata, n_pcs=2, use_rep='X_palantir_multiscale', perplexity=150). *tsne by cell size*. >>> sc.pl.tsne(adata, color=""n_counts""). *Imputed gene expression visualized on tSNE maps*. >>> sc.pl.tsne(; ... adata,; ... gene_symbols=['CD34', 'MPO', 'GATA1', 'IRF8'],; ... layer='palantir_imp',; ... color=['CD34', 'MPO', 'GATA1', 'IRF8']; ... ). **Running Palantir**. Palantir can be run by specifying an approximate early cell. While Palantir; automatically determines the terminal states, they can also be specified using the; `termine_states` parameter. >>> start_cell = 'Run5_164698952452459'; >>> pr_res = sce.tl.palantir_results(; ... adata,; ... early_cell=start_cell,; ... ms_data='X_palantir_multiscale',; ... num_waypoints=500,; ... ). .. note::; A `start_cell` must be defined for every data set. The start cell for; this dataset was chosen based on high expression of CD34. At this point the returned Palantir object `pr_res` can be used for all downstream; analysis and plotting. Please consult this notebook; `Palantir_sample_notebook.ipynb; <https://github.com/dpeerlab/Palantir/blob/master/notebooks/Palantir_sample_notebook.ipynb>`_.; It provides a comprehensive guide to draw *gene expression trends*, amongst other; things.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_palantir.py:4842,down,downstream,4842,src/scanpy/external/tl/_palantir.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_palantir.py,1,['down'],['downstream']
Availability,"ix.; If `False`, omit zero-centering variables; (uses *scikit-learn* :class:`~sklearn.decomposition.TruncatedSVD` or; *dask-ml* :class:`~dask_ml.decomposition.TruncatedSVD`),; which allows to handle sparse input efficiently.; Passing `None` decides automatically based on sparseness of the data.; svd_solver; SVD solver to use:. `None`; See `chunked` and `zero_center` descriptions to determine which class will be used.; Depending on the class and the type of X different values for default will be set.; If *scikit-learn* :class:`~sklearn.decomposition.PCA` is used, will give `'arpack'`,; if *scikit-learn* :class:`~sklearn.decomposition.TruncatedSVD` is used, will give `'randomized'`,; if *dask-ml* :class:`~dask_ml.decomposition.PCA` or :class:`~dask_ml.decomposition.IncrementalPCA` is used, will give `'auto'`,; if *dask-ml* :class:`~dask_ml.decomposition.TruncatedSVD` is used, will give `'tsqr'`; `'arpack'`; for the ARPACK wrapper in SciPy (:func:`~scipy.sparse.linalg.svds`); Not available with *dask* arrays.; `'randomized'`; for the randomized algorithm due to Halko (2009). For *dask* arrays,; this will use :func:`~dask.array.linalg.svd_compressed`.; `'auto'`; chooses automatically depending on the size of the problem.; `'lobpcg'`; An alternative SciPy solver. Not available with dask arrays.; `'tsqr'`; Only available with *dask* arrays. ""tsqr""; algorithm from Benson et. al. (2013). .. versionchanged:: 1.9.3; Default value changed from `'arpack'` to None.; .. versionchanged:: 1.4.5; Default value changed from `'auto'` to `'arpack'`. Efficient computation of the principal components of a sparse matrix; currently only works with the `'arpack`' or `'lobpcg'` solvers. If X is a *dask* array, *dask-ml* classes :class:`~dask_ml.decomposition.PCA`,; :class:`~dask_ml.decomposition.IncrementalPCA`, or; :class:`~dask_ml.decomposition.TruncatedSVD` will be used.; Otherwise their *scikit-learn* counterparts :class:`~sklearn.decomposition.PCA`,; :class:`~sklearn.decomposition.Increm",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py:1902,avail,available,1902,src/scanpy/preprocessing/_pca.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py,1,['avail'],['available']
Availability,"outliers based on counts and numbers of genes expressed. For instance, only keep cells with at least `min_counts` counts or; `min_genes` genes expressed. This is to filter measurement outliers,; i.e. “unreliable” observations. Only provide one of the optional parameters `min_counts`, `min_genes`,; `max_counts`, `max_genes` per call. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; min_counts; Minimum number of counts required for a cell to pass filtering.; min_genes; Minimum number of genes expressed required for a cell to pass filtering.; max_counts; Maximum number of counts required for a cell to pass filtering.; max_genes; Maximum number of genes expressed required for a cell to pass filtering.; inplace; Perform computation inplace or return result. Returns; -------; Depending on `inplace`, returns the following arrays or directly subsets; and annotates the data matrix:. cells_subset; Boolean index mask that does filtering. `True` means that the; cell is kept. `False` means the cell is removed.; number_per_cell; Depending on what was thresholded (`counts` or `genes`),; the array stores `n_counts` or `n_cells` per gene. Examples; --------; >>> import scanpy as sc; >>> adata = sc.datasets.krumsiek11(); UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; utils.warn_names_duplicates(""obs""); >>> adata.obs_names_make_unique(); >>> adata.n_obs; 640; >>> adata.var_names.tolist() # doctest: +NORMALIZE_WHITESPACE; ['Gata2', 'Gata1', 'Fog1', 'EKLF', 'Fli1', 'SCL',; 'Cebpa', 'Pu.1', 'cJun', 'EgrNab', 'Gfi1']; >>> # add some true zeros; >>> adata.X[adata.X < 0.3] = 0; >>> # simply compute the number of genes per cell; >>> sc.pp.filter_cells(adata, min_genes=0); >>> adata.n_obs; 640; >>> adata.obs['n_genes'].min(); 1; >>> # filter manually; >>> adata_copy = adata[adata.obs['n_genes'] >= 3]; >>> adata_copy.n_obs; 554; >>> adata_copy.obs['n_genes",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:1020,mask,mask,1020,src/scanpy/preprocessing/_simple.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py,1,['mask'],['mask']
Availability,"ted with pointers to these files.; As a result, each adata object should have its own project_dir.; data_name; Name of dataset in Cell Browser, a string without special characters.; This is written to `data_dir/cellbrowser.conf`.; Ideally this is a short unique name for the dataset,; like `""pbmc3k""` or `""tabulamuris""`.; embedding_keys; 2-D embeddings in `adata.obsm` to export.; The prefix `X_` or `X_draw_graph_` is not necessary.; Coordinates missing from `adata` are skipped.; By default (or when specifying `'all'` or `None`), these keys are tried:; [`""tsne""`, `""umap""`, `""pagaFa""`, `""pagaFr""`, `""pagaUmap""`, `""phate""`,; `""fa""`, `""fr""`, `""kk""`, `""drl""`, `""rt""`, `""trimap""`].; For these, default display labels are automatically used.; For other values, you can specify a mapping from coordinate name to; display label, e.g. `{""tsne"": ""t-SNE by Scanpy""}`.; annot_keys; Annotations in `adata.obsm` to export.; Can be a mapping from annotation column name to display label.; Specify `None` for all available columns in `.obs`.; skip_matrix; Do not export the matrix.; If you had previously exported this adata into the same `data_dir`,; then there is no need to export the whole matrix again.; This option will make the export a lot faster,; e.g. when only coordinates or meta data were changed.; html_dir; If this variable is set, the export will build html; files from `data_dir` to `html_dir`, creating html/js/json files.; Usually there is one global html output directory for all datasets.; Often, `html_dir` is located under a webserver's (like Apache); htdocs directory or is copied to one.; A directory `html_dir`/`project_name` will be created and; an index.html will be created under `html_dir` for all subdirectories.; Existing files will be overwritten.; If do not to use html_dir,; you can use the command line tool `cbBuild` to build the html directory.; port; If this variable and `html_dir` are set,; Python's built-in web server will be spawned as a daemon in the; background and ",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/exporting.py:1896,avail,available,1896,src/scanpy/external/exporting.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/exporting.py,1,['avail'],['available']
Availability,"the cluster labels.; jaccard; If `True`, use Jaccard metric between k-neighborhoods to build graph. If; `False`, use a Gaussian kernel.; primary_metric; Distance metric to define nearest neighbors. Note that performance will be; slower for correlation and cosine.; n_jobs; Nearest Neighbors and Jaccard coefficients will be computed in parallel using; n_jobs. If 1 is given, no parallelism is used. If set to -1, all CPUs are used.; For n_jobs below -1, `n_cpus + 1 + n_jobs` are used.; q_tol; Tolerance, i.e. precision, for monitoring modularity optimization.; louvain_time_limit; Maximum number of seconds to run modularity optimization. If exceeded the best; result so far is returned.; nn_method; Whether to use brute force or kdtree for nearest neighbor search.; For very large high-dimensional data sets, brute force, with parallel; computation, performs faster than kdtree.; partition_type; Defaults to :class:`~leidenalg.RBConfigurationVertexPartition`. For the; available options, consult the documentation for; :func:`~leidenalg.find_partition`.; resolution_parameter; A parameter value controlling the coarseness of the clustering in Leiden. Higher; values lead to more clusters. Set to `None` if overriding `partition_type` to; one that does not accept a `resolution_parameter`.; n_iterations; Number of iterations to run the Leiden algorithm. If the number of iterations is; negative, the Leiden algorithm is run until an iteration in which there was no; improvement.; use_weights; Use vertices in the Leiden computation.; seed; Leiden initialization of the optimization.; copy; Return a copy or write to `adata`.; kargs; Additional arguments passed to :func:`~leidenalg.find_partition` and the; constructor of the `partition_type`. Returns; -------; Depending on `copy`, returns or updates `adata` with the following fields:. **communities** - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.obs`, dtype `int`); integer array of community assignments for each row in data. **graph** - ",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phenograph.py:2445,avail,available,2445,src/scanpy/external/tl/_phenograph.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phenograph.py,1,['avail'],['available']
Availability,"ther to use a symmetric (default) or asymmetric (`'directed'`) graph.; The graph construction process produces a directed graph, which is symmetrized; by one of two methods (see `prune` below).; prune; `prune=False`, symmetrize by taking the average between the graph and its; transpose. `prune=True`, symmetrize by taking the product between the graph; and its transpose.; min_cluster_size; Cells that end up in a cluster smaller than min_cluster_size are considered; outliers and are assigned to -1 in the cluster labels.; jaccard; If `True`, use Jaccard metric between k-neighborhoods to build graph. If; `False`, use a Gaussian kernel.; primary_metric; Distance metric to define nearest neighbors. Note that performance will be; slower for correlation and cosine.; n_jobs; Nearest Neighbors and Jaccard coefficients will be computed in parallel using; n_jobs. If 1 is given, no parallelism is used. If set to -1, all CPUs are used.; For n_jobs below -1, `n_cpus + 1 + n_jobs` are used.; q_tol; Tolerance, i.e. precision, for monitoring modularity optimization.; louvain_time_limit; Maximum number of seconds to run modularity optimization. If exceeded the best; result so far is returned.; nn_method; Whether to use brute force or kdtree for nearest neighbor search.; For very large high-dimensional data sets, brute force, with parallel; computation, performs faster than kdtree.; partition_type; Defaults to :class:`~leidenalg.RBConfigurationVertexPartition`. For the; available options, consult the documentation for; :func:`~leidenalg.find_partition`.; resolution_parameter; A parameter value controlling the coarseness of the clustering in Leiden. Higher; values lead to more clusters. Set to `None` if overriding `partition_type` to; one that does not accept a `resolution_parameter`.; n_iterations; Number of iterations to run the Leiden algorithm. If the number of iterations is; negative, the Leiden algorithm is run until an iteration in which there was no; improvement.; use_weights; U",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phenograph.py:1968,Toler,Tolerance,1968,src/scanpy/external/tl/_phenograph.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phenograph.py,1,['Toler'],['Tolerance']
Availability,"ulti-scale data matrix,. - X_palantir_diff_comp - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.obsm`, dtype `float`); Array of Diffusion components.; - palantir_EigenValues - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.uns`, dtype `float`); Array of corresponding eigen values.; - palantir_diff_op - :class:`~scipy.sparse.spmatrix` (:attr:`~anndata.AnnData.obsp`, dtype `float`); The diffusion operator matrix. **Multi scale space results**,; used to build tsne on diffusion components, and to compute branch probabilities; and waypoints,. - X_palantir_multiscale - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.obsm`, dtype `float`); Multi scale data matrix. **MAGIC imputation**,; used for plotting gene expression on tsne, and gene expression trends,. - palantir_imp - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.layers`, dtype `float`); Imputed data matrix (MAGIC imputation). Example; -------; >>> import scanpy.external as sce; >>> import scanpy as sc. A sample data is available `here <https://github.com/dpeerlab/Palantir/tree/master/data>`_. **Load sample data**. >>> adata = sc.read_csv(filename=""Palantir/data/marrow_sample_scseq_counts.csv.gz""). *Cleanup and normalize*. >>> sc.pp.filter_cells(adata, min_counts=1000); >>> sc.pp.filter_genes(adata, min_counts=10); >>> sc.pp.normalize_per_cell(adata); >>> sc.pp.log1p(adata). **Data preprocessing**. Palantir builds diffusion maps using one of two optional inputs:. *Principal component analysis*. >>> sc.pp.pca(adata, n_comps=300). or,. *Nearist neighbors graph*. >>> sc.pp.neighbors(adata, knn=30). *Diffusion maps*. Palantir determines the diffusion maps of the data as an estimate of the low; dimensional phenotypic manifold of the data. >>> sce.tl.palantir(adata, n_components=5, knn=30). if pre-computed distances are to be used,. >>> sce.tl.palantir(; ... adata,; ... n_components=5,; ... knn=30,; ... use_adjacency_matrix=True,; ... distances_key=""distances"",; ... ). **Visualizing Palantir results**. *tSNE visua",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_palantir.py:2710,avail,available,2710,src/scanpy/external/tl/_palantir.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_palantir.py,1,['avail'],['available']
Availability,"uted in parallel using n_jobs.; copy; Return a copy instead of writing to `adata`. Returns; -------; Depending on `copy`, returns or updates `.obsm`, `.obsp` and `.uns` with the following:. **X_harmony** - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.obsm`, dtype `float`); force directed layout; **harmony_aff** - :class:`~scipy.sparse.spmatrix` (:attr:`~anndata.AnnData.obsp`, dtype `float`); affinity matrix; **harmony_aff_aug** - :class:`~scipy.sparse.spmatrix` (:attr:`~anndata.AnnData.obsp`, dtype `float`); augmented affinity matrix; **harmony_timepoint_var** - `str` (:attr:`~anndata.AnnData.uns`); The name of the variable passed as `tp`; **harmony_timepoint_connections** - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.uns`, dtype `str`); The links between time points. Example; -------. >>> from itertools import product; >>> import pandas as pd; >>> from anndata import AnnData; >>> import scanpy as sc; >>> import scanpy.external as sce. **Load** `AnnData`. A sample with real data is available here_. .. _here: https://github.com/dpeerlab/Harmony/tree/master/data. Random data sets of three time points with two replicates each:. >>> adata_ref = sc.datasets.pbmc3k(); >>> start = [596, 615, 1682, 1663, 1409, 1432]; >>> adata = AnnData.concatenate(; ... *(adata_ref[i : i + 1000] for i in start),; ... join=""outer"",; ... batch_key=""sample"",; ... batch_categories=[f""sa{i}_Rep{j}"" for i, j in product((1, 2, 3), (1, 2))],; ... ); >>> time_points = adata.obs[""sample""].str.split(""_"", expand=True)[0]; >>> adata.obs[""time_points""] = pd.Categorical(; ... time_points, categories=['sa1', 'sa2', 'sa3']; ... ). Normalize and filter for highly expressed genes. >>> sc.pp.normalize_total(adata, target_sum=10000); >>> sc.pp.log1p(adata); >>> sc.pp.highly_variable_genes(adata, n_top_genes=1000, subset=True). Run harmony_timeseries. >>> sce.tl.harmony_timeseries(adata, tp=""time_points"", n_components=500). Plot time points:. >>> sce.pl.harmony_timeseries(adata). For further demonstrat",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_harmony_timeseries.py:2582,avail,available,2582,src/scanpy/external/tl/_harmony_timeseries.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_harmony_timeseries.py,1,['avail'],['available']
Availability,"ution_parameter`.; random_state; Change the initialization of the optimization.; restrict_to; Restrict the clustering to the categories within the key for sample; annotation, tuple needs to contain `(obs_key, list_of_categories)`.; key_added; `adata.obs` key under which to add the cluster labels.; adjacency; Sparse adjacency matrix of the graph, defaults to neighbors connectivities.; directed; Whether to treat the graph as directed or undirected.; use_weights; If `True`, edge weights from the graph are used in the computation; (placing more emphasis on stronger edges).; n_iterations; How many iterations of the Leiden clustering algorithm to perform.; Positive values above 2 define the total number of iterations to perform,; -1 has the algorithm run until it reaches its optimal clustering.; 2 is faster and the default for underlying packages.; partition_type; Type of partition to use.; Defaults to :class:`~leidenalg.RBConfigurationVertexPartition`.; For the available options, consult the documentation for; :func:`~leidenalg.find_partition`.; neighbors_key; Use neighbors connectivities as adjacency.; If not specified, leiden looks .obsp['connectivities'] for connectivities; (default storage place for pp.neighbors).; If specified, leiden looks; .obsp[.uns[neighbors_key]['connectivities_key']] for connectivities.; obsp; Use .obsp[obsp] as adjacency. You can't specify both; `obsp` and `neighbors_key` at the same time.; copy; Whether to copy `adata` or modify it inplace.; flavor; Which package's implementation to use.; **clustering_args; Any further arguments to pass to :func:`~leidenalg.find_partition` (which in turn passes arguments to the `partition_type`); or :meth:`igraph.Graph.community_leiden` from `igraph`. Returns; -------; Returns `None` if `copy=False`, else returns an `AnnData` object. Sets the following fields:. `adata.obs['leiden' | key_added]` : :class:`pandas.Series` (dtype ``category``); Array of dim (number of samples) that stores the subgroup id; (``'0'",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_leiden.py:1584,avail,available,1584,src/scanpy/tools/_leiden.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_leiden.py,1,['avail'],['available']
Deployability," RNA-seq. .. note::; More information and bug reports `here <https://github.com/dpeerlab/Palantir>`__. Parameters; ----------; adata; An AnnData object.; n_components; Number of diffusion components.; knn; Number of nearest neighbors for graph construction.; alpha; Normalization parameter for the diffusion operator.; use_adjacency_matrix; Use adaptive anisotropic adjacency matrix, instead of PCA projections; (default) to compute diffusion components.; distances_key; With `use_adjacency_matrix=True`, use the indicated distances key for `.obsp`.; If `None`, `'distances'`.; n_eigs; Number of eigen vectors to use. If `None` specified, the number of eigen; vectors will be determined using eigen gap. Passed to; `palantir.utils.determine_multiscale_space`.; impute_data; Impute data using MAGIC.; n_steps; Number of steps in the diffusion operator. Passed to; `palantir.utils.run_magic_imputation`.; copy; Return a copy instead of writing to `adata`. Returns; -------; Depending on `copy`, returns or updates `adata` with the following fields:. **Diffusion maps**,; used for magic imputation, and to generate multi-scale data matrix,. - X_palantir_diff_comp - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.obsm`, dtype `float`); Array of Diffusion components.; - palantir_EigenValues - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.uns`, dtype `float`); Array of corresponding eigen values.; - palantir_diff_op - :class:`~scipy.sparse.spmatrix` (:attr:`~anndata.AnnData.obsp`, dtype `float`); The diffusion operator matrix. **Multi scale space results**,; used to build tsne on diffusion components, and to compute branch probabilities; and waypoints,. - X_palantir_multiscale - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.obsm`, dtype `float`); Multi scale data matrix. **MAGIC imputation**,; used for plotting gene expression on tsne, and gene expression trends,. - palantir_imp - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.layers`, dtype `float`); Imputed data matrix (MAGIC im",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_palantir.py:1608,update,updates,1608,src/scanpy/external/tl/_palantir.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_palantir.py,1,['update'],['updates']
Deployability," _scanorama: https://github.com/brianhie/scanorama. Parameters; ----------; adata; The annotated data matrix.; key; The name of the column in ``adata.obs`` that differentiates; among experiments/batches. Cells from the same batch must be; contiguously stored in ``adata``.; basis; The name of the field in ``adata.obsm`` where the PCA table is; stored. Defaults to ``'X_pca'``, which is the default for; ``sc.pp.pca()``.; adjusted_basis; The name of the field in ``adata.obsm`` where the integrated; embeddings will be stored after running this function. Defaults; to ``X_scanorama``.; knn; Number of nearest neighbors to use for matching.; sigma; Correction smoothing parameter on Gaussian kernel.; approx; Use approximate nearest neighbors with Python ``annoy``;; greatly speeds up matching runtime.; alpha; Alignment score minimum cutoff.; batch_size; The batch size used in the alignment vector computation. Useful; when integrating very large (>100k samples) datasets. Set to; large value that runs within available memory.; kwargs; Any additional arguments will be passed to; ``scanorama.assemble()``. Returns; -------; Updates adata with the field ``adata.obsm[adjusted_basis]``,; containing Scanorama embeddings such that different experiments; are integrated. Example; -------; First, load libraries and example dataset, and preprocess. >>> import scanpy as sc; >>> import scanpy.external as sce; >>> adata = sc.datasets.pbmc3k(); >>> sc.pp.recipe_zheng17(adata); >>> sc.pp.pca(adata). We now arbitrarily assign a batch metadata variable to each cell; for the sake of example, but during real usage there would already; be a column in ``adata.obs`` giving the experiment each cell came; from. >>> adata.obs['batch'] = 1350*['a'] + 1350*['b']. Finally, run Scanorama. Afterwards, there will be a new table in; ``adata.obsm`` containing the Scanorama embeddings. >>> sce.pp.scanorama_integrate(adata, 'batch', verbose=1); Processing datasets a <=> b; >>> 'X_scanorama' in adata.obsm; True; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py:1526,Update,Updates,1526,src/scanpy/external/pp/_scanorama_integrate.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py,2,"['Update', 'integrat']","['Updates', 'integrated']"
Deployability," to the knee point in the Von Neumann Entropy of; the diffusion operator; gamma; Informational distance constant between -1 and 1.; `gamma=1` gives the PHATE log potential, `gamma=0` gives; a square root potential.; n_pca; Number of principal components to use for calculating; neighborhoods. For extremely large datasets, using; n_pca < 20 allows neighborhoods to be calculated in; log(n_samples) time.; knn_dist; recommended values: 'euclidean' and 'cosine'; Any metric from `scipy.spatial.distance` can be used; distance metric for building kNN graph; mds_dist; recommended values: 'euclidean' and 'cosine'; Any metric from `scipy.spatial.distance` can be used; distance metric for MDS; mds; Selects which MDS algorithm is used for dimensionality reduction.; n_jobs; The number of jobs to use for the computation.; If `None`, `sc.settings.n_jobs` is used.; If -1 all CPUs are used. If 1 is given, no parallel computing code is; used at all, which is useful for debugging.; For n_jobs below -1, (n_cpus + 1 + n_jobs) are used. Thus for; n_jobs = -2, all CPUs but one are used; random_state; Random seed. Defaults to the global `numpy` random number generator; verbose; If `True` or an `int`/`Verbosity` ≥ 2/`hint`, print status messages.; If `None`, `sc.settings.verbosity` is used.; copy; Return a copy instead of writing to `adata`.; kwargs; Additional arguments to `phate.PHATE`. Returns; -------; Depending on `copy`, returns or updates `adata` with the following fields. **X_phate** : `np.ndarray`, (`adata.obs`, shape=[n_samples, n_components], dtype `float`); PHATE coordinates of data. Examples; --------; >>> from anndata import AnnData; >>> import scanpy.external as sce; >>> import phate; >>> tree_data, tree_clusters = phate.tree.gen_dla(; ... n_dim=100,; ... n_branch=20,; ... branch_length=100,; ... ); >>> tree_data.shape; (2000, 100); >>> adata = AnnData(tree_data); >>> sce.tl.phate(adata, k=5, a=20, t=150); >>> adata.obsm['X_phate'].shape; (2000, 2); >>> sce.pl.phate(adata); """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phate.py:2441,update,updates,2441,src/scanpy/external/tl/_phate.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phate.py,1,['update'],['updates']
Deployability,"""""""; HashSolo script provides a probabilistic cell hashing demultiplexing method; which generates a noise distribution and signal distribution for; each hashing barcode from empirically observed counts. These distributions; are updates from the global signal and noise barcode distributions, which; helps in the setting where not many cells are observed. Signal distributions; for a hashing barcode are estimated from samples where that hashing barcode; has the highest count. Noise distributions for a hashing barcode are estimated; from samples where that hashing barcode is one the k-2 lowest barcodes, where; k is the number of barcodes. A doublet should then have its two highest; barcode counts most likely coming from a signal distribution for those barcodes.; A singlet should have its highest barcode from a signal distribution, and its; second highest barcode from a noise distribution. A negative two highest; barcodes should come from noise distributions. We test each of these; hypotheses in a bayesian fashion, and select the most probable hypothesis.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py:228,update,updates,228,src/scanpy/external/pp/_hashsolo.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py,1,['update'],['updates']
Deployability,"""""""; Map array of values to array of hex (plus alpha) codes. For categorical data, the return value is list of colors taken; from the category palette or from the given `palette` value. For continuous values, the input array is returned (may change in future).; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/scatterplots.py:190,continuous,continuous,190,src/scanpy/plotting/_tools/scatterplots.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/scatterplots.py,1,['continuous'],['continuous']
Deployability,"""""""; Plots a horizontal colorbar given the ax an normalize values. Parameters; ----------; color_legend_ax; normalize. Returns; -------; `None`, updates color_legend_ax; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_baseplot_class.py:145,update,updates,145,src/scanpy/plotting/_baseplot_class.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_baseplot_class.py,1,['update'],['updates']
Deployability,"""""""; Test that Harmony integrate works. This is a very simple test that just checks to see if the Harmony; integrate wrapper succesfully added a new field to ``adata.obsm``; and makes sure it has the same dimensions as the original PCA table.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/external/test_harmony_integrate.py:23,integrat,integrate,23,tests/external/test_harmony_integrate.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/external/test_harmony_integrate.py,2,['integrat'],['integrate']
Deployability,"""""""; Test that Scanorama integration works. This is a very simple test that just checks to see if the Scanorama; integrate wrapper succesfully added a new field to ``adata.obsm``; and makes sure it has the same dimensions as the original PCA table.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/external/test_scanorama_integrate.py:25,integrat,integration,25,tests/external/test_scanorama_integrate.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/external/test_scanorama_integrate.py,2,['integrat'],"['integrate', 'integration']"
Deployability,"""""""; Update parser with tool specific arguments. This overwrites was is done in utils.uns_args.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:5,Update,Update,5,src/scanpy/tools/_sim.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py,1,['Update'],['Update']
Deployability,"""""""; Use Scanorama to integrate cells from different experiments.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py:22,integrat,integrate,22,src/scanpy/external/pp/_scanorama_integrate.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py,1,['integrat'],['integrate']
Deployability,"""""""; Use harmony to integrate cells from different experiments.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_harmony_integrate.py:20,integrat,integrate,20,src/scanpy/external/pp/_harmony_integrate.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_harmony_integrate.py,1,['integrat'],['integrate']
Deployability,"""""""; another check that _sparsemean behaves like np.nanmean!. monkeypatch the _score_genes._sparse_nanmean function to np.nanmean; and check that the result is the same as the non-patched (i.e. sparse_nanmean); function; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_score_genes.py:180,patch,patched,180,tests/test_score_genes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_score_genes.py,1,['patch'],['patched']
Deployability,"""""""; checks if the list of colors in adata.uns[f'{key}_colors'] is valid; and updates the color list in adata.uns[f'{key}_colors'] if needed. Not only valid matplotlib colors are checked but also if the color name; is a valid R color name, in which case it will be translated to a valid name; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_utils.py:78,update,updates,78,src/scanpy/plotting/_utils.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_utils.py,1,['update'],['updates']
Deployability,"""""""; checks if var_names is a dict. Is this is the cases, then set the; correct values for var_group_labels and var_group_positions. updates var_names, var_group_labels, var_group_positions; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_baseplot_class.py:133,update,updates,133,src/scanpy/plotting/_baseplot_class.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_baseplot_class.py,1,['update'],['updates']
Deployability,"""""""Determine parents based on boolean updaterule. Returns list of parents.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:38,update,updaterule,38,src/scanpy/tools/_sim.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py,1,['update'],['updaterule']
Deployability,"""""""Extension to patch https://github.com/executablebooks/MyST-NB/pull/599.""""""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/docs/extensions/patch_myst_nb.py:16,patch,patch,16,docs/extensions/patch_myst_nb.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/docs/extensions/patch_myst_nb.py,1,['patch'],['patch']
Deployability,"""""""Keyword arguments passed to a _KnownTransformer. IMPORTANT: when changing the parameters set here,; update the “*ignored*” part in the parameter docs!; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/__init__.py:103,update,update,103,src/scanpy/neighbors/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/__init__.py,1,['update'],['update']
Deployability,"""""""Parse a pyproject.toml file and output a list of minimum dependencies. Output is directly passable to `pip install`.""""""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/ci/scripts/min-deps.py:110,install,install,110,ci/scripts/min-deps.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/ci/scripts/min-deps.py,1,['install'],['install']
Deployability,"""""""Toggle switch.""""""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:3,Toggle,Toggle,3,src/scanpy/tools/_sim.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py,1,['Toggle'],['Toggle']
Deployability,"""""""Update parameters of your gaussian; https://www.cs.ubc.ca/~murphyk/Papers/bayesGauss.pdf. Parameters; ----------; data; 1-d array of counts; mu_o; global mean for hashing count distribution; std_o; global std for hashing count distribution. Returns; -------; mean; of gaussian; std; of gaussian; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py:3,Update,Update,3,src/scanpy/external/pp/_hashsolo.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py,1,['Update'],['Update']
Deployability,"""""""Update the wrapper function to use the correct signature.""""""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/scatterplots.py:3,Update,Update,3,src/scanpy/plotting/_tools/scatterplots.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/scatterplots.py,1,['Update'],['Update']
Deployability,"""""""Variant of toggle switch.""""""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:14,toggle,toggle,14,src/scanpy/tools/_sim.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py,3,['toggle'],['toggle']
Deployability,"""""""\; Annotate highly variable genes :cite:p:`Satija2015,Zheng2017,Stuart2019`. Expects logarithmized data, except when `flavor='seurat_v3'`/`'seurat_v3_paper'`, in which count; data is expected. Depending on `flavor`, this reproduces the R-implementations of Seurat; :cite:p:`Satija2015`, Cell Ranger :cite:p:`Zheng2017`, and Seurat v3 :cite:p:`Stuart2019`. `'seurat_v3'`/`'seurat_v3_paper'` requires `scikit-misc` package. If you plan to use this flavor, consider; installing `scanpy` with this optional dependency: `scanpy[skmisc]`. For the dispersion-based methods (`flavor='seurat'` :cite:t:`Satija2015` and; `flavor='cell_ranger'` :cite:t:`Zheng2017`), the normalized dispersion is obtained; by scaling with the mean and standard deviation of the dispersions for genes; falling into a given bin for mean expression of genes. This means that for each; bin of mean expression, highly variable genes are selected. For `flavor='seurat_v3'`/`'seurat_v3_paper'` :cite:p:`Stuart2019`, a normalized variance for each gene; is computed. First, the data are standardized (i.e., z-score normalization; per feature) with a regularized standard deviation. Next, the normalized variance; is computed as the variance of each gene after the transformation. Genes are ranked; by the normalized variance.; Only if `batch_key` is not `None`, the two flavors differ: For `flavor='seurat_v3'`, genes are first sorted by the median (across batches) rank, with ties broken by the number of batches a gene is a HVG.; For `flavor='seurat_v3_paper'`, genes are first sorted by the number of batches a gene is a HVG, with ties broken by the median (across batches) rank. The following may help when comparing to Seurat's naming:; If `batch_key=None` and `flavor='seurat'`, this mimics Seurat's `FindVariableFeatures(…, method='mean.var.plot')`.; If `batch_key=None` and `flavor='seurat_v3'`/`flavor='seurat_v3_paper'`, this mimics Seurat's `FindVariableFeatures(..., method='vst')`.; If `batch_key` is not `None` and `flav",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py:467,install,installing,467,src/scanpy/preprocessing/_highly_variable_genes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py,1,['install'],['installing']
Deployability,"""""""\; Applies analytic Pearson residual normalization and PCA, based on :cite:t:`Lause2021`. The residuals are based on a negative binomial offset model with overdispersion; `theta` shared across genes. By default, residuals are clipped to `sqrt(n_obs)`,; overdispersion `theta=100` is used, and PCA is run with 50 components. Operates on the subset of highly variable genes in `adata.var['highly_variable']`; by default. Expects raw count input. Params; ------; {adata}; {dist_params}; {pca_chunk}; {mask_var_hvg}; {check_values}; {inplace}. Returns; -------; If `inplace=False`, returns the Pearson residual-based PCA results (as :class:`~anndata.AnnData`; object). If `inplace=True`, updates `adata` with the following fields:. `.uns['pearson_residuals_normalization']['pearson_residuals_df']`; The subset of highly variable genes, normalized by Pearson residuals.; `.uns['pearson_residuals_normalization']['theta']`; The used value of the overdisperion parameter theta.; `.uns['pearson_residuals_normalization']['clip']`; The used value of the clipping parameter. `.obsm['X_pca']`; PCA representation of data after gene selection (if applicable) and Pearson; residual normalization.; `.varm['PCs']`; The principal components containing the loadings. When `inplace=True` and; `use_highly_variable=True`, this will contain empty rows for the genes not; selected.; `.uns['pca']['variance_ratio']`; Ratio of explained variance.; `.uns['pca']['variance']`; Explained variance, equivalent to the eigenvalues of the covariance matrix.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_normalization.py:687,update,updates,687,src/scanpy/experimental/pp/_normalization.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_normalization.py,1,['update'],['updates']
Deployability,"""""""\; Applies analytic Pearson residual normalization, based on :cite:t:`Lause2021`. The residuals are based on a negative binomial offset model with overdispersion; `theta` shared across genes. By default, residuals are clipped to `sqrt(n_obs)`; and overdispersion `theta=100` is used. Expects raw count input. Params; ------; {adata}; {dist_params}; {check_values}; {layer}; {inplace}; {copy}. Returns; -------; If `inplace=True`, `adata.X` or the selected layer in `adata.layers` is updated; with the normalized values. `adata.uns` is updated with the following fields.; If `inplace=False`, the same fields are returned as dictionary with the; normalized values in `results_dict['X']`. `.uns['pearson_residuals_normalization']['theta']`; The used value of the overdisperion parameter theta.; `.uns['pearson_residuals_normalization']['clip']`; The used value of the clipping parameter.; `.uns['pearson_residuals_normalization']['computed_on']`; The name of the layer on which the residuals were computed.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_normalization.py:486,update,updated,486,src/scanpy/experimental/pp/_normalization.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_normalization.py,2,['update'],['updated']
Deployability,"""""""\; Calculate quality control metrics. Calculates a number of qc metrics for an AnnData object, see section; `Returns` for specifics. Largely based on `calculateQCMetrics` from scater; :cite:p:`McCarthy2017`. Currently is most efficient on a sparse CSR or dense matrix. Note that this method can take a while to compile on the first call. That; result is then cached to disk to be used later. Parameters; ----------; {doc_adata_basic}; {doc_qc_metric_naming}; {doc_obs_qc_args}; {doc_expr_reps}; inplace; Whether to place calculated metrics in `adata`'s `.obs` and `.var`.; log1p; Set to `False` to skip computing `log1p` transformed annotations. Returns; -------; Depending on `inplace` returns calculated metrics; (as :class:`~pandas.DataFrame`) or updates `adata`'s `obs` and `var`. {doc_obs_qc_returns}. {doc_var_qc_returns}. Example; -------; Calculate qc metrics for visualization. .. plot::; :context: close-figs. import scanpy as sc; import seaborn as sns. pbmc = sc.datasets.pbmc3k(); pbmc.var[""mito""] = pbmc.var_names.str.startswith(""MT-""); sc.pp.calculate_qc_metrics(pbmc, qc_vars=[""mito""], inplace=True); sns.jointplot(; data=pbmc.obs,; x=""log1p_total_counts"",; y=""log1p_n_genes_by_counts"",; kind=""hex"",; ). .. plot::; :context: close-figs. sns.histplot(pbmc.obs[""pct_counts_mito""]); """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_qc.py:753,update,updates,753,src/scanpy/preprocessing/_qc.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_qc.py,1,['update'],['updates']
Deployability,"""""""\; Check whether time series branches. Parameters; ----------; X; current time series data.; Xsamples; list of previous branching samples.; restart; counts number of restart trials.; threshold; sets threshold for attractor identification. Returns; -------; check; true if branching realization; Xsamples; updated list; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:308,update,updated,308,src/scanpy/tools/_sim.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py,1,['update'],['updated']
Deployability,"""""""\; Detect branching on given segment. Updates all list parameters inplace. Call function _detect_branching and perform bookkeeping on segs and; segs_tips. Parameters; ----------; segs; Dchosen distance matrix restricted to segment.; segs_tips; Stores all tip points for the segments in segs.; iseg; Position of segment under study in segs.; tips3; The three tip points. They form a 'triangle' that contains the data.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py:41,Update,Updates,41,src/scanpy/tools/_dpt.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py,1,['Update'],['Updates']
Deployability,"""""""\; Exports to a SPRING project directory :cite:p:`Weinreb2017`. Visualize annotation present in `adata`. By default, export all gene expression data; from `adata.raw` and categorical and continuous annotations present in `adata.obs`. See `SPRING <https://github.com/AllonKleinLab/SPRING>`__ or :cite:t:`Weinreb2017` for details. Parameters; ----------; adata; Annotated data matrix: `adata.uns['neighbors']` needs to; be present.; project_dir; Path to directory for exported SPRING files.; embedding_method; Name of a 2-D embedding in `adata.obsm`; subplot_name; Name of subplot folder to be created at `project_dir+""/""+subplot_name`; cell_groupings; Instead of importing all categorical annotations when `None`,; pass a list of keys for `adata.obs`.; custom_color_tracks; Specify specific `adata.obs` keys for continuous coloring.; total_counts_key; Name of key for total transcript counts in `adata.obs`.; overwrite; When `True`, existing counts matrices in `project_dir` are overwritten. Examples; --------; See this `tutorial <https://github.com/scverse/scanpy_usage/tree/master/171111_SPRING_export>`__.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/exporting.py:190,continuous,continuous,190,src/scanpy/external/exporting.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/exporting.py,2,['continuous'],['continuous']
Deployability,"""""""\; Force-directed graph drawing :cite:p:`Islam2011,Jacomy2014,Chippada2018`. An alternative to tSNE that often preserves the topology of the data; better. This requires to run :func:`~scanpy.pp.neighbors`, first. The default layout ('fa', `ForceAtlas2`, :cite:t:`Jacomy2014`) uses the package |fa2|_; :cite:p:`Chippada2018`, which can be installed via `pip install fa2`. `Force-directed graph drawing`_ describes a class of long-established; algorithms for visualizing graphs.; It has been suggested for visualizing single-cell data by :cite:t:`Islam2011`.; Many other layouts as implemented in igraph :cite:p:`Csardi2006` are available.; Similar approaches have been used by :cite:t:`Zunder2015` or :cite:t:`Weinreb2017`. .. |fa2| replace:: `fa2`; .. _fa2: https://github.com/bhargavchippada/forceatlas2; .. _Force-directed graph drawing: https://en.wikipedia.org/wiki/Force-directed_graph_drawing. Parameters; ----------; adata; Annotated data matrix.; layout; 'fa' (`ForceAtlas2`) or any valid `igraph layout; <https://igraph.org/c/doc/igraph-Layout.html>`__. Of particular interest; are 'fr' (Fruchterman Reingold), 'grid_fr' (Grid Fruchterman Reingold,; faster than 'fr'), 'kk' (Kamadi Kawai', slower than 'fr'), 'lgl' (Large; Graph, very fast), 'drl' (Distributed Recursive Layout, pretty fast) and; 'rt' (Reingold Tilford tree layout).; root; Root for tree layouts.; random_state; For layouts with random initialization like 'fr', change this to use; different intial states for the optimization. If `None`, no seed is set.; adjacency; Sparse adjacency matrix of the graph, defaults to neighbors connectivities.; key_added_ext; By default, append `layout`.; proceed; Continue computation, starting off with 'X_draw_graph_`layout`'.; init_pos; `'paga'`/`True`, `None`/`False`, or any valid 2d-`.obsm` key.; Use precomputed coordinates for initialization.; If `False`/`None` (the default), initialize randomly.; neighbors_key; If not specified, draw_graph looks .obsp['connectivities'] for con",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_draw_graph.py:341,install,installed,341,src/scanpy/tools/_draw_graph.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_draw_graph.py,2,['install'],"['install', 'installed']"
Deployability,"""""""\; Full pipeline for HVG selection and normalization by analytic Pearson residuals :cite:p:`Lause2021`. Applies gene selection based on Pearson residuals. On the resulting subset,; Pearson residual normalization and PCA are performed. Expects raw count input. Params; ------; {adata}; {dist_params}; {genes_batch_chunk}; {pca_chunk}; {check_values}; {inplace}. Returns; -------; If `inplace=False`, separately returns the gene selection results (as; :class:`~pandas.DataFrame`) and Pearson residual-based PCA results (as; :class:`~anndata.AnnData`). If `inplace=True`, updates `adata` with the; following fields for gene selection results:. `.var['highly_variable']` : bool; boolean indicator of highly-variable genes.; `.var['means']` : float; means per gene.; `.var['variances']` : float; variances per gene.; `.var['residual_variances']` : float; Pearson residual variance per gene. Averaged in the case of multiple; batches.; `.var['highly_variable_rank']` : float; Rank of the gene according to residual variance, median rank in the; case of multiple batches.; `.var['highly_variable_nbatches']` : int; If batch_key is given, this denotes in how many batches genes are; detected as HVG.; `.var['highly_variable_intersection']` : bool; If batch_key is given, this denotes the genes that are highly variable; in all batches. The following fields contain Pearson residual-based PCA results and; normalization settings:. `.uns['pearson_residuals_normalization']['pearson_residuals_df']`; The subset of highly variable genes, normalized by Pearson residuals.; `.uns['pearson_residuals_normalization']['theta']`; The used value of the overdisperion parameter theta.; `.uns['pearson_residuals_normalization']['clip']`; The used value of the clipping parameter. `.obsm['X_pca']`; PCA representation of data after gene selection and Pearson residual; normalization.; `.varm['PCs']`; The principal components containing the loadings. When `inplace=True` this; will contain empty rows for the genes not s",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_recipes.py:11,pipeline,pipeline,11,src/scanpy/experimental/pp/_recipes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_recipes.py,2,"['pipeline', 'update']","['pipeline', 'updates']"
Deployability,"""""""\; Function used by plotting functions that need to reorder the the groupby; observations based on the dendrogram results. The function checks if a dendrogram has already been precomputed.; If not, `sc.tl.dendrogram` is run with default parameters. The results found in `.uns[dendrogram_key]` are used to reorder; `var_group_labels` and `var_group_positions`. Returns; -------; `None`, internally updates; 'categories_idx_ordered', 'var_group_names_idx_ordered',; 'var_group_labels' and 'var_group_positions'; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_baseplot_class.py:400,update,updates,400,src/scanpy/plotting/_baseplot_class.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_baseplot_class.py,1,['update'],['updates']
Deployability,"""""""\; Logarithmize the data matrix. Computes :math:`X = \\log(X + 1)`,; where :math:`log` denotes the natural logarithm unless a different base is given. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; base; Base of the logarithm. Natural logarithm is used by default.; copy; If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned.; chunked; Process the data matrix in chunks, which will save memory.; Applies only to :class:`~anndata.AnnData`.; chunk_size; `n_obs` of the chunks to process the data in.; layer; Entry of layers to transform.; obsm; Entry of obsm to transform. Returns; -------; Returns or updates `data`, depending on `copy`.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:721,update,updates,721,src/scanpy/preprocessing/_simple.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py,1,['update'],['updates']
Deployability,"""""""\; Map labels and embeddings from reference data to new data. :doc:`/tutorials/basics/integrating-data-using-ingest`. Integrates embeddings and annotations of an `adata` with a reference dataset; `adata_ref` through projecting on a PCA (or alternate; model) that has been fitted on the reference data. The function uses a knn; classifier for mapping labels and the UMAP package :cite:p:`McInnes2018` for mapping; the embeddings. .. note::. We refer to this *asymmetric* dataset integration as *ingesting*; annotations from reference data to new data. This is different from; learning a joint representation that integrates both datasets in an; unbiased way, as CCA (e.g. in Seurat) or a conditional VAE (e.g. in; scVI) would do. You need to run :func:`~scanpy.pp.neighbors` on `adata_ref` before; passing it. Parameters; ----------; adata; The annotated data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes. This is the dataset without labels and; embeddings.; adata_ref; The annotated data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; Variables (`n_vars` and `var_names`) of `adata_ref` should be the same; as in `adata`.; This is the dataset with labels and embeddings; which need to be mapped to `adata`.; obs; Labels' keys in `adata_ref.obs` which need to be mapped to `adata.obs`; (inferred for observation of `adata`).; embedding_method; Embeddings in `adata_ref` which need to be mapped to `adata`.; The only supported values are 'umap' and 'pca'.; labeling_method; The method to map labels in `adata_ref.obs` to `adata.obs`.; The only supported value is 'knn'.; neighbors_key; If not specified, ingest looks adata_ref.uns['neighbors']; for neighbors settings and adata_ref.obsp['distances'] for; distances (default storage places for pp.neighbors).; If specified, ingest looks adata_ref.uns[neighbors_key] for; neighbors settings and; adata_ref.obsp[adata_ref.uns[neighbors_key]['distances_key']] for distances.; in",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_ingest.py:89,integrat,integrating-data-using-ingest,89,src/scanpy/tools/_ingest.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_ingest.py,4,"['Integrat', 'integrat']","['Integrates', 'integrates', 'integrating-data-using-ingest', 'integration']"
Deployability,"""""""\; Normalization and filtering as of :cite:t:`Zheng2017`. Reproduces the preprocessing of :cite:t:`Zheng2017` – the Cell Ranger R Kit of 10x; Genomics. Expects non-logarithmized data.; If using logarithmized data, pass `log=False`. The recipe runs the following steps. .. code:: python. sc.pp.filter_genes(adata, min_counts=1) # only consider genes with more than 1 count; sc.pp.normalize_per_cell( # normalize with total UMI count per cell; adata, key_n_counts='n_counts_all'; ); filter_result = sc.pp.filter_genes_dispersion( # select highly-variable genes; adata.X, flavor='cell_ranger', n_top_genes=n_top_genes, log=False; ); adata = adata[:, filter_result.gene_subset] # subset the genes; sc.pp.normalize_per_cell(adata) # renormalize after filtering; if log: sc.pp.log1p(adata) # log transform: adata.X = log(adata.X + 1); sc.pp.scale(adata) # scale to unit variance and shift to zero mean. Parameters; ----------; adata; Annotated data matrix.; n_top_genes; Number of genes to keep.; log; Take logarithm.; plot; Show a plot of the gene dispersion vs. mean relation.; copy; Return a copy of `adata` instead of updating it. Returns; -------; Returns or updates `adata` depending on `copy`.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py:1161,update,updates,1161,src/scanpy/preprocessing/_recipes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py,1,['update'],['updates']
Deployability,"""""""\; Plot X. Parameters; ----------; X; Call this with:; X with one column, color categorical.; X with one column, color continuous.; X with n columns, color is of length n.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_utils.py:122,continuous,continuous,122,src/scanpy/plotting/_utils.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_utils.py,1,['continuous'],['continuous']
Deployability,"""""""\; Plot marker trends along trajectory, and return trajectory branches for further; analysis and visualization (heatmap, etc..). Parameters; ----------; adata; Annotated data matrix.; markers; Iterable of markers/genes to be plotted.; show_variance; Logical indicating if the trends should be accompanied with variance.; no_bins; Number of bins for calculating marker density.; smoothing_factor; Parameter controlling the degree of smoothing.; min_delta; Minimum difference in marker expression after normalization to show; separate trends for the two branches.; figsize; width, height; return_fig; Return the matplotlib figure.; {show_save_ax}. Returns; -------; Updates `adata` with the following fields:. `trunk_wishbone` : :class:`pandas.DataFrame` (`adata.uns`); Computed values before branching; `branch1_wishbone` : :class:`pandas.DataFrame` (`adata.uns`); Computed values for the first branch; `branch2_wishbone` : :class:`pandas.DataFrame` (`adata.uns`); Computed values for the second branch.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pl.py:667,Update,Updates,667,src/scanpy/external/pl.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pl.py,1,['Update'],['Updates']
Deployability,"""""""\; Read 10x-Genomics-formatted visum dataset. In addition to reading regular 10x output,; this looks for the `spatial` folder and loads images,; coordinates and scale factors.; Based on the `Space Ranger output docs`_. See :func:`~scanpy.pl.spatial` for a compatible plotting function. .. _Space Ranger output docs: https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/overview. Parameters; ----------; path; Path to directory for visium datafiles.; genome; Filter expression to genes within this genome.; count_file; Which file in the passed directory to use as the count file. Typically would be one of:; 'filtered_feature_bc_matrix.h5' or 'raw_feature_bc_matrix.h5'.; library_id; Identifier for the visium library. Can be modified when concatenating multiple adata objects.; source_image_path; Path to the high-resolution tissue image. Path will be included in; `.uns[""spatial""][library_id][""metadata""][""source_image_path""]`. Returns; -------; Annotated data matrix, where observations/cells are named by their; barcode and variables/genes by gene name. Stores the following information:. :attr:`~anndata.AnnData.X`; The data matrix is stored; :attr:`~anndata.AnnData.obs_names`; Cell names; :attr:`~anndata.AnnData.var_names`; Gene names for a feature barcode matrix, probe names for a probe bc matrix; :attr:`~anndata.AnnData.var`\\ `['gene_ids']`; Gene IDs; :attr:`~anndata.AnnData.var`\\ `['feature_types']`; Feature types; :attr:`~anndata.AnnData.obs`\\ `[filtered_barcodes]`; filtered barcodes if present in the matrix; :attr:`~anndata.AnnData.var`; Any additional metadata present in /matrix/features is read in.; :attr:`~anndata.AnnData.uns`\\ `['spatial']`; Dict of spaceranger output files with 'library_id' as key; :attr:`~anndata.AnnData.uns`\\ `['spatial'][library_id]['images']`; Dict of images (`'hires'` and `'lowres'`); :attr:`~anndata.AnnData.uns`\\ `['spatial'][library_id]['scalefactors']`; Scale factors for the spots; :attr:`~anndata.Ann",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py:384,pipeline,pipelines,384,src/scanpy/readwrite.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py,1,['pipeline'],['pipelines']
Deployability,"""""""\; Regress out (mostly) unwanted sources of variation. Uses simple linear regression. This is inspired by Seurat's `regressOut`; function in R :cite:p:`Satija2015`. Note that this function tends to overcorrect; in certain circumstances as described in :issue:`526`. Parameters; ----------; adata; The annotated data matrix.; keys; Keys for observation annotation on which to regress on.; layer; If provided, which element of layers to regress on.; n_jobs; Number of jobs for parallel computation.; `None` means using :attr:`scanpy._settings.ScanpyConfig.n_jobs`.; copy; Determines whether a copy of `adata` is returned. Returns; -------; Returns `None` if `copy=False`, else returns an updated `AnnData` object. Sets the following fields:. `adata.X` | `adata.layers[layer]` : :class:`numpy.ndarray` | :class:`scipy.sparse._csr.csr_matrix` (dtype `float`); Corrected count data matrix.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:689,update,updated,689,src/scanpy/preprocessing/_simple.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py,1,['update'],['updated']
Deployability,"""""""\; Returns `adata_new` with mapped embeddings and labels. If `inplace=False` returns a copy of `adata_new`; with mapped embeddings and labels in `obsm` and `obs` correspondingly.; If `inplace=True` returns nothing and updates `adata_new.obsm`; and `adata_new.obs` with mapped embeddings and labels.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_ingest.py:221,update,updates,221,src/scanpy/tools/_ingest.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_ingest.py,1,['update'],['updates']
Deployability,"""""""\; Scale data to unit variance and zero mean. .. note::; Variables (genes) that do not display any variation (are constant across; all observations) are retained and (for zero_center==True) set to 0; during this operation. In the future, they might be set to NaNs. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; zero_center; If `False`, omit zero-centering variables, which allows to handle sparse; input efficiently.; max_value; Clip (truncate) to this value after scaling. If `None`, do not clip.; copy; Whether this function should be performed inplace. If an AnnData object; is passed, this also determines if a copy is returned.; layer; If provided, which element of layers to scale.; obsm; If provided, which element of obsm to scale.; mask_obs; Restrict both the derivation of scaling parameters and the scaling itself; to a certain set of observations. The mask is specified as a boolean array; or a string referring to an array in :attr:`~anndata.AnnData.obs`.; This will transform data from csc to csr format if `issparse(data)`. Returns; -------; Returns `None` if `copy=False`, else returns an updated `AnnData` object. Sets the following fields:. `adata.X` | `adata.layers[layer]` : :class:`numpy.ndarray` | :class:`scipy.sparse._csr.csr_matrix` (dtype `float`); Scaled count data matrix.; `adata.var['mean']` : :class:`pandas.Series` (dtype `float`); Means per gene before scaling.; `adata.var['std']` : :class:`pandas.Series` (dtype `float`); Standard deviations per gene before scaling.; `adata.var['var']` : :class:`pandas.Series` (dtype `float`); Variances per gene before scaling.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scale.py:1198,update,updated,1198,src/scanpy/preprocessing/_scale.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scale.py,1,['update'],['updated']
Deployability,"""""""\; See `highly_variable_genes`. For further implementation details see https://www.overleaf.com/read/ckptrbgzzzpg. Returns; -------; Depending on `inplace` returns calculated metrics (:class:`~pd.DataFrame`) or; updates `.var` with the following fields:. highly_variable : :class:`bool`; boolean indicator of highly-variable genes.; **means**; means per gene.; **variances**; variance per gene.; **variances_norm**; normalized variance per gene, averaged in the case of multiple batches.; highly_variable_rank : :class:`float`; Rank of the gene according to normalized variance, median rank in the case of multiple batches.; highly_variable_nbatches : :class:`int`; If batch_key is given, this denotes in how many batches genes are detected as HVG.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py:215,update,updates,215,src/scanpy/preprocessing/_highly_variable_genes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py,1,['update'],['updates']
Deployability,"""""""\; Select highly variable genes using analytic Pearson residuals :cite:p:`Lause2021`. In :cite:t:`Lause2021`, Pearson residuals of a negative binomial offset model are computed; (with overdispersion `theta` shared across genes). By default, overdispersion; `theta=100` is used and residuals are clipped to `sqrt(n_obs)`. Finally, genes; are ranked by residual variance. Expects raw count input. Parameters; ----------; {adata}; {dist_params}; {genes_batch_chunk}; flavor; Choose the flavor for identifying highly variable genes. In this experimental; version, only 'pearson_residuals' is functional.; {check_values}; {layer}; subset; If `True`, subset the data to highly-variable genes after finding them.; Otherwise merely indicate highly variable genes in `adata.var` (see below).; {inplace}. Returns; -------; If `inplace=True`, `adata.var` is updated with the following fields. Otherwise,; returns the same fields as :class:`~pandas.DataFrame`. highly_variable : :class:`bool`; boolean indicator of highly-variable genes.; means : :class:`float`; means per gene.; variances : :class:`float`; variance per gene.; residual_variances : :class:`float`; For `flavor='pearson_residuals'`, residual variance per gene. Averaged in the; case of multiple batches.; highly_variable_rank : :class:`float`; For `flavor='pearson_residuals'`, rank of the gene according to residual.; variance, median rank in the case of multiple batches.; highly_variable_nbatches : :class:`int`; If `batch_key` given, denotes in how many batches genes are detected as HVG.; highly_variable_intersection : :class:`bool`; If `batch_key` given, denotes the genes that are highly variable in all batches. Notes; -----; Experimental version of `sc.pp.highly_variable_genes()`; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_highly_variable_genes.py:850,update,updated,850,src/scanpy/experimental/pp/_highly_variable_genes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_highly_variable_genes.py,1,['update'],['updated']
Deployability,"""""""\; Simulated toggleswitch. Data obtained simulating a simple toggleswitch :cite:p:`Gardner2000`. Simulate via :func:`~scanpy.tl.sim`. Returns; -------; Annotated data matrix. Examples; --------; >>> import scanpy as sc; >>> sc.datasets.toggleswitch(); UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; utils.warn_names_duplicates(""obs""); AnnData object with n_obs × n_vars = 200 × 2; uns: 'iroot'; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py:16,toggle,toggleswitch,16,src/scanpy/datasets/_datasets.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py,3,['toggle'],['toggleswitch']
Deployability,"""""""\; Square root the data matrix. Computes :math:`X = \\sqrt(X)`. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; copy; If an :class:`~anndata.AnnData` object is passed,; determines whether a copy is returned.; chunked; Process the data matrix in chunks, which will save memory.; Applies only to :class:`~anndata.AnnData`.; chunk_size; `n_obs` of the chunks to process the data in. Returns; -------; Returns or updates `data`, depending on `copy`.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:500,update,updates,500,src/scanpy/preprocessing/_simple.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py,1,['update'],['updates']
Deployability,"""""""\; TriMap: Large-scale Dimensionality Reduction Using Triplets :cite:p:`Amid2019`. TriMap is a dimensionality reduction method that uses triplet constraints; to form a low-dimensional embedding of a set of points. The triplet; constraints are of the form ""point i is closer to point j than point k"".; The triplets are sampled from the high-dimensional representation of the; points and a weighting scheme is used to reflect the importance of each; triplet. TriMap provides a significantly better global view of the data than the; other dimensionality reduction methods such t-SNE, LargeVis, and UMAP.; The global structure includes relative distances of the clusters, multiple; scales in the data, and the existence of possible outliers. We define a; global score to quantify the quality of an embedding in reflecting the; global structure of the data. Parameters; ----------; adata; Annotated data matrix.; n_components; Number of dimensions of the embedding.; n_inliers; Number of inlier points for triplet constraints.; n_outliers; Number of outlier points for triplet constraints.; n_random; Number of random triplet constraints per point.; metric; Distance measure: 'angular', 'euclidean', 'hamming', 'manhattan'.; weight_adj; Adjusting the weights using a non-linear transformation.; lr; Learning rate.; n_iters; Number of iterations.; verbose; If `True`, print the progress report.; If `None`, `sc.settings.verbosity` is used.; copy; Return a copy instead of writing to `adata`. Returns; -------; Depending on `copy`, returns or updates `adata` with the following fields. **X_trimap** : :class:`~numpy.ndarray`, (:attr:`~anndata.AnnData.obsm`, shape=(n_samples, n_components), dtype `float`); TriMap coordinates of data. Example; -------. >>> import scanpy as sc; >>> import scanpy.external as sce; >>> pbmc = sc.datasets.pbmc68k_reduced(); >>> pbmc = sce.tl.trimap(pbmc, copy=True); >>> sce.pl.trimap(pbmc, color=['bulk_labels'], s=10); """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_trimap.py:1539,update,updates,1539,src/scanpy/external/tl/_trimap.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_trimap.py,1,['update'],['updates']
Deployability,"""""""\; Update old_params with new_params. If check==False, this merely adds and overwrites the content of old_params. If check==True, this only allows updating of parameters that are already; present in old_params. Parameters; ----------; old_params; new_params; check. Returns; -------; updated_params; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/__init__.py:6,Update,Update,6,src/scanpy/_utils/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/__init__.py,1,['Update'],['Update']
Deployability,"""""""\; Use Scanorama :cite:p:`Hie2019` to integrate different experiments. Scanorama :cite:p:`Hie2019` is an algorithm for integrating single-cell; data from multiple experiments stored in an AnnData object. This; function should be run after performing PCA but before computing; the neighbor graph, as illustrated in the example below. This uses the implementation of scanorama_ :cite:p:`Hie2019`. .. _scanorama: https://github.com/brianhie/scanorama. Parameters; ----------; adata; The annotated data matrix.; key; The name of the column in ``adata.obs`` that differentiates; among experiments/batches. Cells from the same batch must be; contiguously stored in ``adata``.; basis; The name of the field in ``adata.obsm`` where the PCA table is; stored. Defaults to ``'X_pca'``, which is the default for; ``sc.pp.pca()``.; adjusted_basis; The name of the field in ``adata.obsm`` where the integrated; embeddings will be stored after running this function. Defaults; to ``X_scanorama``.; knn; Number of nearest neighbors to use for matching.; sigma; Correction smoothing parameter on Gaussian kernel.; approx; Use approximate nearest neighbors with Python ``annoy``;; greatly speeds up matching runtime.; alpha; Alignment score minimum cutoff.; batch_size; The batch size used in the alignment vector computation. Useful; when integrating very large (>100k samples) datasets. Set to; large value that runs within available memory.; kwargs; Any additional arguments will be passed to; ``scanorama.assemble()``. Returns; -------; Updates adata with the field ``adata.obsm[adjusted_basis]``,; containing Scanorama embeddings such that different experiments; are integrated. Example; -------; First, load libraries and example dataset, and preprocess. >>> import scanpy as sc; >>> import scanpy.external as sce; >>> adata = sc.datasets.pbmc3k(); >>> sc.pp.recipe_zheng17(adata); >>> sc.pp.pca(adata). We now arbitrarily assign a batch metadata variable to each cell; for the sake of example, but during real",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py:41,integrat,integrate,41,src/scanpy/external/pp/_scanorama_integrate.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py,3,['integrat'],"['integrate', 'integrated', 'integrating']"
Deployability,"""""""\; Use harmonypy :cite:p:`Korsunsky2019` to integrate different experiments. Harmony :cite:p:`Korsunsky2019` is an algorithm for integrating single-cell; data from multiple experiments. This function uses the python; port of Harmony, ``harmonypy``, to integrate single-cell data; stored in an AnnData object. As Harmony works by adjusting the; principal components, this function should be run after performing; PCA but before computing the neighbor graph, as illustrated in the; example below. Parameters; ----------; adata; The annotated data matrix.; key; The name of the column in ``adata.obs`` that differentiates; among experiments/batches.; basis; The name of the field in ``adata.obsm`` where the PCA table is; stored. Defaults to ``'X_pca'``, which is the default for; ``sc.pp.pca()``.; adjusted_basis; The name of the field in ``adata.obsm`` where the adjusted PCA; table will be stored after running this function. Defaults to; ``X_pca_harmony``.; kwargs; Any additional arguments will be passed to; ``harmonypy.run_harmony()``. Returns; -------; Updates adata with the field ``adata.obsm[obsm_out_field]``,; containing principal components adjusted by Harmony such that; different experiments are integrated. Example; -------; First, load libraries and example dataset, and preprocess. >>> import scanpy as sc; >>> import scanpy.external as sce; >>> adata = sc.datasets.pbmc3k(); >>> sc.pp.recipe_zheng17(adata); >>> sc.pp.pca(adata). We now arbitrarily assign a batch metadata variable to each cell; for the sake of example, but during real usage there would already; be a column in ``adata.obs`` giving the experiment each cell came; from. >>> adata.obs['batch'] = 1350*['a'] + 1350*['b']. Finally, run harmony. Afterwards, there will be a new table in; ``adata.obsm`` containing the adjusted PC's. >>> sce.pp.harmony_integrate(adata, 'batch'); >>> 'X_pca_harmony' in adata.obsm; True; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_harmony_integrate.py:47,integrat,integrate,47,src/scanpy/external/pp/_harmony_integrate.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_harmony_integrate.py,5,"['Update', 'integrat']","['Updates', 'integrate', 'integrated', 'integrating']"
Deployability,"""""""\; Wishbone identifies bifurcating developmental trajectories from single-cell data; :cite:p:`Setty2016`. Wishbone is an algorithm for positioning single cells along bifurcating; developmental trajectories with high resolution. Wishbone uses multi-dimensional; single-cell data, such as mass cytometry or RNA-Seq data, as input and orders cells; according to their developmental progression, and it pinpoints bifurcation points; by labeling each cell as pre-bifurcation or as one of two post-bifurcation cell; fates. .. note::; More information and bug reports `here; <https://github.com/dpeerlab/wishbone>`__. Parameters; ----------; adata; Annotated data matrix.; start_cell; Desired start cell from `obs_names`.; branch; Use True for Wishbone and False for Wanderlust.; k; Number of nearest neighbors for graph construction.; components; Components to use for running Wishbone.; num_waypoints; Number of waypoints to sample. Returns; -------; Updates `adata` with the following fields:. `trajectory_wishbone` : (`adata.obs`, dtype `float64`); Computed trajectory positions.; `branch_wishbone` : (`adata.obs`, dtype `int64`); Assigned branches. Example; -------. >>> import scanpy.external as sce; >>> import scanpy as sc. **Loading Data and Pre-processing**. >>> adata = sc.datasets.pbmc3k(); >>> sc.pp.normalize_per_cell(adata); >>> sc.pp.pca(adata); >>> sc.tl.tsne(adata=adata, n_pcs=5, perplexity=30); >>> sc.pp.neighbors(adata, n_pcs=15, n_neighbors=10); >>> sc.tl.diffmap(adata, n_comps=10). **Running Wishbone Core Function**. Usually, the start cell for a dataset should be chosen based on high expression of; the gene of interest:. >>> sce.tl.wishbone(; ... adata=adata, start_cell='ACAAGAGACTTATC-1',; ... components=[2, 3], num_waypoints=150,; ... ). **Visualizing Wishbone results**. >>> sc.pl.tsne(adata, color=['trajectory_wishbone', 'branch_wishbone']); >>> markers = ['C1QA', 'PSAP', 'CD79A', 'CD79B', 'CST3', 'LYZ', 'MALAT1']; >>> sce.pl.wishbone_marker_trajectory(adata, markers",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_wishbone.py:949,Update,Updates,949,src/scanpy/external/tl/_wishbone.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_wishbone.py,1,['Update'],['Updates']
Deployability,"""""""\; inplace; If `True`, update `adata` with results. Otherwise, return results. See below for; details of what is returned.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/_docs.py:26,update,update,26,src/scanpy/experimental/_docs.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/_docs.py,1,['update'],['update']
Deployability,"""""""\; t-SNE :cite:p:`vanDerMaaten2008,Amir2013,Pedregosa2011`. t-distributed stochastic neighborhood embedding (tSNE, :cite:t:`vanDerMaaten2008`) has been; proposed for visualizating single-cell data by :cite:t:`Amir2013`. Here, by default,; we use the implementation of *scikit-learn* :cite:p:`Pedregosa2011`. You can achieve; a huge speedup and better convergence if you install Multicore-tSNE_; by :cite:t:`Ulyanov2016`, which will be automatically detected by Scanpy. .. _multicore-tsne: https://github.com/DmitryUlyanov/Multicore-TSNE. Parameters; ----------; adata; Annotated data matrix.; {doc_n_pcs}; {use_rep}; perplexity; The perplexity is related to the number of nearest neighbors that; is used in other manifold learning algorithms. Larger datasets; usually require a larger perplexity. Consider selecting a value; between 5 and 50. The choice is not extremely critical since t-SNE; is quite insensitive to this parameter.; metric; Distance metric calculate neighbors on.; early_exaggeration; Controls how tight natural clusters in the original space are in the; embedded space and how much space will be between them. For larger; values, the space between natural clusters will be larger in the; embedded space. Again, the choice of this parameter is not very; critical. If the cost function increases during initial optimization,; the early exaggeration factor or the learning rate might be too high.; learning_rate; Note that the R-package ""Rtsne"" uses a default of 200.; The learning rate can be a critical parameter. It should be; between 100 and 1000. If the cost function increases during initial; optimization, the early exaggeration factor or the learning rate; might be too high. If the cost function gets stuck in a bad local; minimum increasing the learning rate helps sometimes.; random_state; Change this to use different intial states for the optimization.; If `None`, the initial state is not reproducible.; n_jobs; Number of jobs for parallel computation.; `None` means u",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_tsne.py:373,install,install,373,src/scanpy/tools/_tsne.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_tsne.py,1,['install'],['install']
Deployability,"# *First compiled on May 5, 2017. Updated August 14, 2018.*; # # Clustering 3k PBMCs following a Seurat Tutorial; #; # This started out with a demonstration that Scanpy would allow to reproduce most of Seurat's; # ([Satija *et al.*, 2015](https://doi.org/10.1038/nbt.3192)) clustering tutorial as described on; # https://satijalab.org/seurat/articles/pbmc3k_tutorial.html (July 26, 2017), which we gratefully acknowledge.; # In the meanwhile, we have added and removed several pieces.; #; # The data consists in *3k PBMCs from a Healthy Donor* and is freely available from 10x Genomics; # ([here](https://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz); # from this [webpage](https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.1.0/pbmc3k)).",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/notebooks/test_pbmc3k.py:34,Update,Updated,34,tests/notebooks/test_pbmc3k.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/notebooks/test_pbmc3k.py,1,['Update'],['Updated']
Deployability,"# -- General configuration ------------------------------------------------",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/docs/conf.py:13,configurat,configuration,13,docs/conf.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/docs/conf.py,1,['configurat'],['configuration']
Deployability,"# -- Options for HTML output ----------------------------------------------; # The theme is sphinx-book-theme, with patches for readthedocs-sphinx-search",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/docs/conf.py:116,patch,patches,116,docs/conf.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/docs/conf.py,1,['patch'],['patches']
Deployability,"# Bumping the version updates all docs, so don't do that",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/docs/conf.py:22,update,updates,22,docs/conf.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/docs/conf.py,1,['update'],['updates']
Deployability,"# Get categorical and continuous metadata",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/exporting.py:22,continuous,continuous,22,src/scanpy/external/exporting.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/exporting.py,1,['continuous'],['continuous']
Deployability,"# Integrate.",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py:2,Integrat,Integrate,2,src/scanpy/external/pp/_scanorama_integrate.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py,1,['Integrat'],['Integrate']
Deployability,"# TODO: currently needs skip if louvain isn't installed, do major rework; # Clustering and PAGA",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/notebooks/test_paga_paul15_subsampled.py:46,install,installed,46,tests/notebooks/test_paga_paul15_subsampled.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/notebooks/test_paga_paul15_subsampled.py,1,['install'],['installed']
Deployability,"# Test images are saved in the directory ./_images/<test-name>/; # If test images need to be updated, simply copy actual.png to expected.png.",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:93,update,updated,93,tests/test_plotting.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py,1,['update'],['updated']
Deployability,"# Will work once scipy 1.8 is released",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/docs/conf.py:30,release,released,30,docs/conf.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/docs/conf.py,1,['release'],['released']
Deployability,"# Write continuous colors",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/exporting.py:8,continuous,continuous,8,src/scanpy/external/exporting.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/exporting.py,1,['continuous'],['continuous']
Deployability,"# You can set `facecolor` with an array for each patch,; # while you can only set `facecolors` with a value for all.",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_utils.py:49,patch,patch,49,src/scanpy/plotting/_utils.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_utils.py,1,['patch'],['patch']
Deployability,"# [third start end]; # detect branching and update segs and segs_tips",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py:44,update,update,44,src/scanpy/tools/_dpt.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py,1,['update'],['update']
Deployability,"# by default, assume continuous or flat color",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py:21,continuous,continuous,21,src/scanpy/plotting/_anndata.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py,1,['continuous'],['continuous']
Deployability,"# coefficients for hill functions from boolean update rules",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:47,update,update,47,src/scanpy/tools/_sim.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py,1,['update'],['update']
Deployability,"# continuous",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_embedding_plots.py:2,continuous,continuous,2,tests/test_embedding_plots.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_embedding_plots.py,1,['continuous'],['continuous']
Deployability,"# due to 'update formulation' of model, there; # is always a diagonal dependence",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:10,update,update,10,src/scanpy/tools/_sim.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py,1,['update'],['update']
Deployability,"# epilog = (' 1: 2dim, causal direction X_1 -> X_0, constraint signs\n'; # + ' 2: 2dim, causal direction X_1 -> X_0, arbitrary signs\n'; # + ' 3: 2dim, causal direction X_1 <-> X_0, arbitrary signs\n'; # + ' 4: 2dim, mix of model 2 and 3\n'; # + ' 5: 6dim double toggle switch\n'; # + ' 6: two independent evolutions without repression, sync.\n'; # + ' 7: two independent evolutions without repression, random init\n'; # + ' 8: two independent evolutions directed repression, random init\n'; # + ' 9: two independent evolutions mutual repression, random init\n'; # + ' 10: two indep. evol., diff. self-loops possible, mut. repr., rand init\n')",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:263,toggle,toggle,263,src/scanpy/tools/_sim.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py,1,['toggle'],['toggle']
Deployability,"# get parameters of distribution, assuming lognormal do update from global values",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py:56,update,update,56,src/scanpy/external/pp/_hashsolo.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py,1,['update'],['update']
Deployability,"# https://graphicdesign.stackexchange.com/questions/3682/where-can-i-find-a-large-palette-set-of-contrasting-colors-for-coloring-many-d; # update 1; # orig reference https://research.wu.ac.at/en/publications/escaping-rgbland-selecting-colors-for-statistical-graphics-26",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/palettes.py:139,update,update,139,src/scanpy/plotting/palettes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/palettes.py,1,['update'],['update']
Deployability,"# install dask if available",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scale.py:2,install,install,2,src/scanpy/preprocessing/_scale.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scale.py,2,['install'],['install']
Deployability,"# loop over all tuples for which the boolean update; # rule returns true, these are stored in self.boolCoeff",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:45,update,update,45,src/scanpy/tools/_sim.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py,1,['update'],['update']
Deployability,"# now patch _sparse_nanmean by np.nanmean inside sc.tools",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_score_genes.py:6,patch,patch,6,tests/test_score_genes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_score_genes.py,1,['patch'],['patch']
Deployability,"# plot continuous annotation",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/paga.py:7,continuous,continuous,7,src/scanpy/plotting/_tools/paga.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/paga.py,1,['continuous'],['continuous']
Deployability,"# see whether fa2 is installed",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_draw_graph.py:21,install,installed,21,src/scanpy/tools/_draw_graph.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_draw_graph.py,1,['install'],['installed']
Deployability,"# special case – update adata.obsm with smoothed values",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_magic.py:17,update,update,17,src/scanpy/external/pp/_magic.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_magic.py,1,['update'],['update']
Deployability,"# test whether we have categorial or continuous annotation",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py:37,continuous,continuous,37,src/scanpy/plotting/_anndata.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py,1,['continuous'],['continuous']
Deployability,"# update AnnData instance",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_magic.py:2,update,update,2,src/scanpy/external/pp/_magic.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_magic.py,3,['update'],['update']
Deployability,"# update adata",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py:2,update,update,2,src/scanpy/preprocessing/_recipes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py,1,['update'],['update']
Deployability,"# update adjacency matrix within the loop!; # self.segs_adjacency[iseg, neighbor_segs > 0] = 0; # self.segs_adjacency[iseg, closest_segs] = np.array(distance_segs)[closest_segs]; # self.segs_adjacency[neighbor_segs > 0, iseg] = 0; # self.segs_adjacency[closest_segs, iseg] = np.array(distance_segs)[closest_segs].reshape(len(closest_segs), 1); # n_edges_per_seg = np.sum(self.segs_adjacency > 0, axis=1).A1",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py:2,update,update,2,src/scanpy/tools/_dpt.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py,1,['update'],['update']
Deployability,"# update availnodes",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:2,update,update,2,src/scanpy/tools/_sim.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py,1,['update'],['update']
Deployability,"# update file with sample ids",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:2,update,update,2,src/scanpy/tools/_sim.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py,1,['update'],['update']
Deployability,"# update iroot, might have changed when subsampling, for example",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py:2,update,update,2,src/scanpy/tools/_dpt.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py,1,['update'],['update']
Deployability,"# update leafnodes",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:2,update,update,2,src/scanpy/tools/_sim.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py,1,['update'],['update']
Deployability,"# update variables",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_utils.py:2,update,update,2,src/scanpy/plotting/_utils.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_utils.py,1,['update'],['update']
Deployability,"# we place a normally distributed prior on gamma and and inverse gamma prior on delta; # in the loop, gamma and delta are updated together. they depend on each other. we iterate until convergence.",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_combat.py:122,update,updated,122,src/scanpy/preprocessing/_combat.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_combat.py,1,['update'],['updated']
Deployability,"###; # when plotting, the color of the dots is determined for each plot; # the data is either categorical or continuous and the data could be in; # 'obs' or in 'var'",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/scatterplots.py:109,continuous,continuous,109,src/scanpy/plotting/_tools/scatterplots.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/scatterplots.py,1,['continuous'],['continuous']
Deployability,".; target_sum; If `None`, after normalization, each observation (cell) has a total; count equal to the median of total counts for observations (cells); before normalization.; exclude_highly_expressed; Exclude (very) highly expressed genes for the computation of the; normalization factor (size factor) for each cell. A gene is considered; highly expressed, if it has more than `max_fraction` of the total counts; in at least one cell. The not-excluded genes will sum up to; `target_sum`. Providing this argument when `adata.X` is a :class:`~dask.array.Array`; will incur blocking `.compute()` calls on the array.; max_fraction; If `exclude_highly_expressed=True`, consider cells as highly expressed; that have more counts than `max_fraction` of the original total counts; in at least one cell.; key_added; Name of the field in `adata.obs` where the normalization factor is; stored.; layer; Layer to normalize instead of `X`. If `None`, `X` is normalized.; inplace; Whether to update `adata` or return dictionary with normalized copies of; `adata.X` and `adata.layers`.; copy; Whether to modify copied input object. Not compatible with inplace=False. Returns; -------; Returns dictionary with normalized copies of `adata.X` and `adata.layers`; or updates `adata` with normalized version of the original; `adata.X` and `adata.layers`, depending on `inplace`. Example; --------; >>> import sys; >>> from anndata import AnnData; >>> import scanpy as sc; >>> sc.settings.verbosity = 'info'; >>> sc.settings.logfile = sys.stdout # for doctests; >>> np.set_printoptions(precision=2); >>> adata = AnnData(np.array([; ... [3, 3, 3, 6, 6],; ... [1, 1, 1, 2, 2],; ... [1, 22, 1, 2, 2],; ... ], dtype='float32')); >>> adata.X; array([[ 3., 3., 3., 6., 6.],; [ 1., 1., 1., 2., 2.],; [ 1., 22., 1., 2., 2.]], dtype=float32); >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']; normalizing counts per cell; finished (0:00:00); >>> X_norm; array([[0.14, 0.14, 0.14, 0.29, 0.29],; [0.14, 0.14",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_normalization.py:2007,update,update,2007,src/scanpy/preprocessing/_normalization.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_normalization.py,1,['update'],['update']
Deployability,".TruncatedSVD` will be used.; Otherwise their *scikit-learn* counterparts :class:`~sklearn.decomposition.PCA`,; :class:`~sklearn.decomposition.IncrementalPCA`, or; :class:`~sklearn.decomposition.TruncatedSVD` will be used.; random_state; Change to use different initial states for the optimization.; return_info; Only relevant when not passing an :class:`~anndata.AnnData`:; see “Returns”.; {mask_var_hvg}; layer; Layer of `adata` to use as expression values.; dtype; Numpy data type string to which to convert the result.; copy; If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned. Is ignored otherwise.; chunked; If `True`, perform an incremental PCA on segments of `chunk_size`.; The incremental PCA automatically zero centers and ignores settings of; `random_seed` and `svd_solver`. Uses sklearn :class:`~sklearn.decomposition.IncrementalPCA` or; *dask-ml* :class:`~dask_ml.decomposition.IncrementalPCA`. If `False`, perform a full PCA and; use sklearn :class:`~sklearn.decomposition.PCA` or; *dask-ml* :class:`~dask_ml.decomposition.PCA`; chunk_size; Number of observations to include in each chunk.; Required if `chunked=True` was passed. Returns; -------; If `data` is array-like and `return_info=False` was passed,; this function returns the PCA representation of `data` as an; array of the same type as the input array. Otherwise, it returns `None` if `copy=False`, else an updated `AnnData` object.; Sets the following fields:. `.obsm['X_pca']` : :class:`~scipy.sparse.spmatrix` | :class:`~numpy.ndarray` (shape `(adata.n_obs, n_comps)`); PCA representation of data.; `.varm['PCs']` : :class:`~numpy.ndarray` (shape `(adata.n_vars, n_comps)`); The principal components containing the loadings.; `.uns['pca']['variance_ratio']` : :class:`~numpy.ndarray` (shape `(n_comps,)`); Ratio of explained variance.; `.uns['pca']['variance']` : :class:`~numpy.ndarray` (shape `(n_comps,)`); Explained variance, equivalent to the eigenvalues of the; covariance matrix.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py:4175,update,updated,4175,src/scanpy/preprocessing/_pca.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py,1,['update'],['updated']
Deployability,"ality reduction; methods are to be used using the SAM-output AnnData, users; should recompute the neighbors using `.obs['X_pca']` with; `scanpy.pp.neighbors`.; `.obsm['X_pca']`; The principal components output by SAM.; `.obsm['X_umap']`; The UMAP projection output by SAM.; `.layers['X_disp']`; The expression matrix used for nearest-neighbor averaging.; `.layers['X_knn_avg']`; The nearest-neighbor-averaged expression data used for computing the; spatial dispersions of genes. Example; -------; >>> import scanpy.external as sce; >>> import scanpy as sc. *** Running SAM ***. Assuming we are given an AnnData object called `adata`, we can run the SAM; algorithm as follows:. >>> sam_obj = sce.tl.sam(adata,inplace=True). The input AnnData object should contain unstandardized, non-negative; expression values. Preferably, the data should be log-normalized and no; genes should be filtered out. Please see the documentation for a description of all available parameters. For more detailed tutorials, please visit the original Github repository:; https://github.com/atarashansky/self-assembling-manifold/tree/master/tutorial. *** Plotting ***. To visualize the output, we can use:. >>> sce.pl.sam(adata,projection='X_umap'). `sce.pl.sam` accepts all keyword arguments used in the; `matplotlib.pyplot.scatter` function. *** SAMGUI ***. SAM comes with the SAMGUI module, a graphical-user interface written with; `Plotly` and `ipythonwidgets` for interactively exploring and annotating; the scRNAseq data and running SAM. Dependencies can be installed with Anaconda by following the instructions in; the self-assembling-manifold Github README:; https://github.com/atarashansky/self-assembling-manifold. In a Jupyter notebook, execute the following to launch the interface:. >>> from samalg.gui import SAMGUI; >>> sam_gui = SAMGUI(sam_obj) # sam_obj is your SAM object; >>> sam_gui.SamPlot. This can also be enabled in Jupyer Lab by following the instructions in the; self-assembling-manifold README. """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_sam.py:5070,install,installed,5070,src/scanpy/external/tl/_sam.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_sam.py,1,['install'],['installed']
Deployability,"anger'` with care and in the same way as in; :func:`~scanpy.pp.recipe_zheng17`. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; flavor; Choose the flavor for computing normalized dispersion. If choosing; 'seurat', this expects non-logarithmized data – the logarithm of mean; and dispersion is taken internally when `log` is at its default value; `True`. For 'cell_ranger', this is usually called for logarithmized data; – in this case you should set `log` to `False`. In their default; workflows, Seurat passes the cutoffs whereas Cell Ranger passes; `n_top_genes`.; min_mean; max_mean; min_disp; max_disp; If `n_top_genes` unequals `None`, these cutoffs for the means and the; normalized dispersions are ignored.; n_bins; Number of bins for binning the mean gene expression. Normalization is; done with respect to each bin. If just a single gene falls into a bin,; the normalized dispersion is artificially set to 1. You'll be informed; about this if you set `settings.verbosity = 4`.; n_top_genes; Number of highly-variable genes to keep.; log; Use the logarithm of the mean to variance ratio.; subset; Keep highly-variable genes only (if True) else write a bool array for h; ighly-variable genes while keeping all genes; copy; If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned. Returns; -------; If an AnnData `adata` is passed, returns or updates `adata` depending on; `copy`. It filters the `adata` and adds the annotations. **means** : adata.var; Means per gene. Logarithmized when `log` is `True`.; **dispersions** : adata.var; Dispersions per gene. Logarithmized when `log` is `True`.; **dispersions_norm** : adata.var; Normalized dispersions per gene. Logarithmized when `log` is `True`. If a data matrix `X` is passed, the annotation is returned as `np.recarray`; with the same information stored in fields: `gene_subset`, `means`, `dispersions`, `dispersion_norm`.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py:2444,update,updates,2444,src/scanpy/preprocessing/_deprecated/highly_variable_genes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py,1,['update'],['updates']
Deployability,"arn.decomposition.PCA` will be used for dimensionality; reduction.; normalize_variance; If True, normalize the data such that each gene has a variance of 1.; `sklearn.decomposition.TruncatedSVD` will be used for dimensionality; reduction, unless `mean_center` is True.; n_prin_comps; Number of principal components used to embed the transcriptomes prior; to k-nearest-neighbor graph construction.; use_approx_neighbors; Use approximate nearest neighbor method (annoy) for the KNN; classifier.; knn_dist_metric; Distance metric used when finding nearest neighbors. For list of; valid values, see the documentation for annoy (if `use_approx_neighbors`; is True) or sklearn.neighbors.NearestNeighbors (if `use_approx_neighbors`; is False).; get_doublet_neighbor_parents; If True, return the parent transcriptomes that generated the; doublet neighbors of each observed transcriptome. This information can; be used to infer the cell states that generated a given; doublet state.; threshold; Doublet score threshold for calling a transcriptome a doublet. If; `None`, this is set automatically by looking for the minimum between; the two modes of the `doublet_scores_sim_` histogram. It is best; practice to check the threshold visually using the; `doublet_scores_sim_` histogram and/or based on co-localization of; predicted doublets in a 2-D embedding.; random_state; Initial state for doublet simulation and nearest neighbors.; verbose; If :data:`True`, log progress updates. Returns; -------; if ``copy=True`` it returns or else adds fields to ``adata``:. ``.obs['doublet_score']``; Doublet scores for each observed transcriptome. ``.obs['predicted_doublets']``; Boolean indicating predicted doublet status. ``.uns['scrublet']['doublet_scores_sim']``; Doublet scores for each simulated doublet transcriptome. ``.uns['scrublet']['doublet_parents']``; Pairs of ``.obs_names`` used to generate each simulated doublet transcriptome. ``.uns['scrublet']['parameters']``; Dictionary of Scrublet parameters; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py:2564,update,updates,2564,src/scanpy/preprocessing/_scrublet/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py,1,['update'],['updates']
Deployability,"e this number times the number; of batches. This then serves as the basis for the construction of a symmetrical; matrix of connectivities.; n_pcs; How many dimensions (in case of PCA, principal components) to use in the analysis.; trim; Trim the neighbours of each cell to these many top connectivities. May help with; population independence and improve the tidiness of clustering. The lower the value the; more independent the individual populations, at the cost of more conserved batch effect.; If `None`, sets the parameter value automatically to 10 times `neighbors_within_batch`; times the number of batches. Set to 0 to skip.; annoy_n_trees; Only used with annoy neighbour identification. The number of trees to construct in the; annoy forest. More trees give higher precision when querying, at the cost of increased; run time and resource intensity.; pynndescent_n_neighbors; Only used with pyNNDescent neighbour identification. The number of neighbours to include; in the approximate neighbour graph. More neighbours give higher precision when querying,; at the cost of increased run time and resource intensity.; pynndescent_random_state; Only used with pyNNDescent neighbour identification. The RNG seed to use when creating; the graph.; use_faiss; If `approx=False` and the metric is ""euclidean"", use the faiss package to compute; nearest neighbours if installed. This improves performance at a minor cost to numerical; precision as faiss operates on float32.; set_op_mix_ratio; UMAP connectivity computation parameter, float between 0 and 1, controlling the; blend between a connectivity matrix formed exclusively from mutual nearest neighbour; pairs (0) and a union of all observed neighbour relationships with the mutual pairs; emphasised (1); local_connectivity; UMAP connectivity computation parameter, how many nearest neighbors of each cell; are assumed to be fully connected (and given a connectivity value of 1). Returns; -------; The `adata` with the batch-corrected graph.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_bbknn.py:3796,install,installed,3796,src/scanpy/external/pp/_bbknn.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_bbknn.py,1,['install'],['installed']
Deployability,"ic demultiplexing of cell hashing data using HashSolo :cite:p:`Bernstein2020`. .. note::; More information and bug reports `here <https://github.com/calico/solo>`__. Parameters; ----------; adata; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; cell_hashing_columns; `.obs` columns that contain cell hashing counts.; priors; Prior probabilities of each hypothesis, in; the order `[negative, singlet, doublet]`. The default is set to; `[0.01, 0.8, 0.19]` assuming barcode counts are from cells that; have passed QC in the transcriptome space, e.g. UMI counts, pct; mito reads, etc.; pre_existing_clusters; The column in `.obs` containing pre-existing cluster assignments; (e.g. Leiden clusters or cell types, but not batch assignments).; If provided, demultiplexing will be performed separately for each; cluster.; number_of_noise_barcodes; The number of barcodes used to create the noise distribution.; Defaults to `len(cell_hashing_columns) - 2`.; inplace; Whether to update `adata` in-place or return a copy. Returns; -------; A copy of the input `adata` if `inplace=False`, otherwise the input; `adata`. The following fields are added:. `.obs[""most_likely_hypothesis""]`; Index of the most likely hypothesis, where `0` corresponds to negative,; `1` to singlet, and `2` to doublet.; `.obs[""cluster_feature""]`; The cluster assignments used for demultiplexing.; `.obs[""negative_hypothesis_probability""]`; Probability of the negative hypothesis.; `.obs[""singlet_hypothesis_probability""]`; Probability of the singlet hypothesis.; `.obs[""doublet_hypothesis_probability""]`; Probability of the doublet hypothesis.; `.obs[""Classification""]`:; Classification of the cell, one of the barcodes in `cell_hashing_columns`,; `""Negative""`, or `""Doublet""`. Examples; -------; >>> import anndata; >>> import scanpy.external as sce; >>> adata = anndata.read_h5ad(""data.h5ad""); >>> sce.pp.hashsolo(adata, [""Hash1"", ""Hash2"", ""Hash3""]); >>> adata.obs.head(); """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py:1041,update,update,1041,src/scanpy/external/pp/_hashsolo.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py,1,['update'],['update']
Deployability,"lization factor (size factor) for each cell. A gene is considered; highly expressed, if it has more than `max_fraction` of the total counts; in at least one cell. The not-excluded genes will sum up to; `target_sum`. Providing this argument when `adata.X` is a :class:`~dask.array.Array`; will incur blocking `.compute()` calls on the array.; max_fraction; If `exclude_highly_expressed=True`, consider cells as highly expressed; that have more counts than `max_fraction` of the original total counts; in at least one cell.; key_added; Name of the field in `adata.obs` where the normalization factor is; stored.; layer; Layer to normalize instead of `X`. If `None`, `X` is normalized.; inplace; Whether to update `adata` or return dictionary with normalized copies of; `adata.X` and `adata.layers`.; copy; Whether to modify copied input object. Not compatible with inplace=False. Returns; -------; Returns dictionary with normalized copies of `adata.X` and `adata.layers`; or updates `adata` with normalized version of the original; `adata.X` and `adata.layers`, depending on `inplace`. Example; --------; >>> import sys; >>> from anndata import AnnData; >>> import scanpy as sc; >>> sc.settings.verbosity = 'info'; >>> sc.settings.logfile = sys.stdout # for doctests; >>> np.set_printoptions(precision=2); >>> adata = AnnData(np.array([; ... [3, 3, 3, 6, 6],; ... [1, 1, 1, 2, 2],; ... [1, 22, 1, 2, 2],; ... ], dtype='float32')); >>> adata.X; array([[ 3., 3., 3., 6., 6.],; [ 1., 1., 1., 2., 2.],; [ 1., 22., 1., 2., 2.]], dtype=float32); >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']; normalizing counts per cell; finished (0:00:00); >>> X_norm; array([[0.14, 0.14, 0.14, 0.29, 0.29],; [0.14, 0.14, 0.14, 0.29, 0.29],; [0.04, 0.79, 0.04, 0.07, 0.07]], dtype=float32); >>> X_norm = sc.pp.normalize_total(; ... adata, target_sum=1, exclude_highly_expressed=True,; ... max_fraction=0.2, inplace=False; ... )['X']; normalizing counts per cell. The following highly-expresse",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_normalization.py:2277,update,updates,2277,src/scanpy/preprocessing/_normalization.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_normalization.py,1,['update'],['updates']
Deployability,"nsional data sets, brute force, with parallel; computation, performs faster than kdtree.; partition_type; Defaults to :class:`~leidenalg.RBConfigurationVertexPartition`. For the; available options, consult the documentation for; :func:`~leidenalg.find_partition`.; resolution_parameter; A parameter value controlling the coarseness of the clustering in Leiden. Higher; values lead to more clusters. Set to `None` if overriding `partition_type` to; one that does not accept a `resolution_parameter`.; n_iterations; Number of iterations to run the Leiden algorithm. If the number of iterations is; negative, the Leiden algorithm is run until an iteration in which there was no; improvement.; use_weights; Use vertices in the Leiden computation.; seed; Leiden initialization of the optimization.; copy; Return a copy or write to `adata`.; kargs; Additional arguments passed to :func:`~leidenalg.find_partition` and the; constructor of the `partition_type`. Returns; -------; Depending on `copy`, returns or updates `adata` with the following fields:. **communities** - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.obs`, dtype `int`); integer array of community assignments for each row in data. **graph** - :class:`~scipy.sparse.spmatrix` (:attr:`~anndata.AnnData.obsp`, dtype `float`); the graph that was used for clustering. **Q** - `float` (:attr:`~anndata.AnnData.uns`, dtype `float`); the modularity score for communities on graph. Example; -------; >>> from anndata import AnnData; >>> import scanpy as sc; >>> import scanpy.external as sce; >>> import numpy as np; >>> import pandas as pd. With annotated data as input:. >>> adata = sc.datasets.pbmc3k(); >>> sc.pp.normalize_per_cell(adata). Then do PCA:. >>> sc.pp.pca(adata, n_comps=100). Compute phenograph clusters:. **Louvain** community detection. >>> sce.tl.phenograph(adata, clustering_algo=""louvain"", k=30). **Leiden** community detection. >>> sce.tl.phenograph(adata, clustering_algo=""leiden"", k=30). Return only `Graph` object. >>>",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phenograph.py:3270,update,updates,3270,src/scanpy/external/tl/_phenograph.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phenograph.py,1,['update'],['updates']
Deployability,"ps://github.com/dpeerlab/Palantir. .. note::; More information and bug reports `here; <https://github.com/dpeerlab/Harmony>`__. Parameters; ----------; adata; Annotated data matrix of shape n_obs `×` n_vars. Rows correspond to; cells and columns to genes. Rows represent two or more time points,; where replicates of the same time point are consecutive in order.; tp; key name of observation annotation `.obs` representing time points. Time; points should be categorical of `dtype=category`. The unique categories for; the categorical will be used as the time points to construct the timepoint; connections.; n_neighbors; Number of nearest neighbors for graph construction.; n_components; Minimum number of principal components to use. Specify `None` to use; pre-computed components. The higher the value the better to capture 85% of the; variance.; n_jobs; Nearest Neighbors will be computed in parallel using n_jobs.; copy; Return a copy instead of writing to `adata`. Returns; -------; Depending on `copy`, returns or updates `.obsm`, `.obsp` and `.uns` with the following:. **X_harmony** - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.obsm`, dtype `float`); force directed layout; **harmony_aff** - :class:`~scipy.sparse.spmatrix` (:attr:`~anndata.AnnData.obsp`, dtype `float`); affinity matrix; **harmony_aff_aug** - :class:`~scipy.sparse.spmatrix` (:attr:`~anndata.AnnData.obsp`, dtype `float`); augmented affinity matrix; **harmony_timepoint_var** - `str` (:attr:`~anndata.AnnData.uns`); The name of the variable passed as `tp`; **harmony_timepoint_connections** - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.uns`, dtype `str`); The links between time points. Example; -------. >>> from itertools import product; >>> import pandas as pd; >>> from anndata import AnnData; >>> import scanpy as sc; >>> import scanpy.external as sce. **Load** `AnnData`. A sample with real data is available here_. .. _here: https://github.com/dpeerlab/Harmony/tree/master/data. Random data sets of three ",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_harmony_timeseries.py:1709,update,updates,1709,src/scanpy/external/tl/_harmony_timeseries.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_harmony_timeseries.py,1,['update'],['updates']
Deployability,"ses the implementation of scanorama_ :cite:p:`Hie2019`. .. _scanorama: https://github.com/brianhie/scanorama. Parameters; ----------; adata; The annotated data matrix.; key; The name of the column in ``adata.obs`` that differentiates; among experiments/batches. Cells from the same batch must be; contiguously stored in ``adata``.; basis; The name of the field in ``adata.obsm`` where the PCA table is; stored. Defaults to ``'X_pca'``, which is the default for; ``sc.pp.pca()``.; adjusted_basis; The name of the field in ``adata.obsm`` where the integrated; embeddings will be stored after running this function. Defaults; to ``X_scanorama``.; knn; Number of nearest neighbors to use for matching.; sigma; Correction smoothing parameter on Gaussian kernel.; approx; Use approximate nearest neighbors with Python ``annoy``;; greatly speeds up matching runtime.; alpha; Alignment score minimum cutoff.; batch_size; The batch size used in the alignment vector computation. Useful; when integrating very large (>100k samples) datasets. Set to; large value that runs within available memory.; kwargs; Any additional arguments will be passed to; ``scanorama.assemble()``. Returns; -------; Updates adata with the field ``adata.obsm[adjusted_basis]``,; containing Scanorama embeddings such that different experiments; are integrated. Example; -------; First, load libraries and example dataset, and preprocess. >>> import scanpy as sc; >>> import scanpy.external as sce; >>> adata = sc.datasets.pbmc3k(); >>> sc.pp.recipe_zheng17(adata); >>> sc.pp.pca(adata). We now arbitrarily assign a batch metadata variable to each cell; for the sake of example, but during real usage there would already; be a column in ``adata.obs`` giving the experiment each cell came; from. >>> adata.obs['batch'] = 1350*['a'] + 1350*['b']. Finally, run Scanorama. Afterwards, there will be a new table in; ``adata.obsm`` containing the Scanorama embeddings. >>> sce.pp.scanorama_integrate(adata, 'batch', verbose=1); Processing da",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py:1325,integrat,integrating,1325,src/scanpy/external/pp/_scanorama_integrate.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py,1,['integrat'],['integrating']
Deployability,"the matrix that stores the; arrows, for instance `'transitions_confidence'`.; solid_edges; Key for `.uns['paga']` that specifies the matrix that stores the edges; to be drawn solid black.; dashed_edges; Key for `.uns['paga']` that specifies the matrix that stores the edges; to be drawn dashed grey. If `None`, no dashed edges are drawn.; single_component; Restrict to largest connected component.; fontsize; Font size for node labels.; fontoutline; Width of the white outline around fonts.; text_kwds; Keywords for :meth:`~matplotlib.axes.Axes.text`.; node_size_scale; Increase or decrease the size of the nodes.; node_size_power; The power with which groups sizes influence the radius of the nodes.; edge_width_scale; Edge with scale in units of `rcParams['lines.linewidth']`.; min_edge_width; Min width of solid edges.; max_edge_width; Max width of solid and dashed edges.; arrowsize; For directed graphs, choose the size of the arrow head head's length and; width. See :py:class: `matplotlib.patches.FancyArrowPatch` for attribute; `mutation_scale` for more info.; export_to_gexf; Export to gexf format to be read by graph visualization programs such as; Gephi.; normalize_to_color; Whether to normalize categorical plots to `color` or the underlying; grouping.; cmap; The color map.; cax; A matplotlib axes object for a potential colorbar.; cb_kwds; Keyword arguments for :class:`~matplotlib.colorbar.Colorbar`,; for instance, `ticks`.; add_pos; Add the positions to `adata.uns['paga']`.; title; Provide a title.; frameon; Draw a frame around the PAGA graph.; plot; If `False`, do not create the figure, simply compute the layout.; save; If `True` or a `str`, save the figure.; A string is appended to the default filename.; Infer the filetype if ending on \\{`'.pdf'`, `'.png'`, `'.svg'`\\}.; ax; A matplotlib axes object. Returns; -------; If `show==False`, one or more :class:`~matplotlib.axes.Axes` objects.; Adds `'pos'` to `adata.uns['paga']` if `add_pos` is `True`. Examples; --------. ..",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/paga.py:3450,patch,patches,3450,src/scanpy/plotting/_tools/paga.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/paga.py,1,['patch'],['patches']
Deployability,"transcriptomes prior; to k-nearest-neighbor graph construction.; use_approx_neighbors; Use approximate nearest neighbor method (annoy) for the KNN; classifier.; get_doublet_neighbor_parents; If True, return (in .uns) the parent transcriptomes that generated the; doublet neighbors of each observed transcriptome. This information can; be used to infer the cell states that generated a given doublet state.; n_neighbors; Number of neighbors used to construct the KNN graph of observed; transcriptomes and simulated doublets. If ``None``, this is; automatically set to ``np.round(0.5 * np.sqrt(n_obs))``.; threshold; Doublet score threshold for calling a transcriptome a doublet. If; `None`, this is set automatically by looking for the minimum between; the two modes of the `doublet_scores_sim_` histogram. It is best; practice to check the threshold visually using the; `doublet_scores_sim_` histogram and/or based on co-localization of; predicted doublets in a 2-D embedding.; verbose; If :data:`True`, log progress updates.; copy; If :data:`True`, return a copy of the input ``adata`` with Scrublet results; added. Otherwise, Scrublet results are added in place.; random_state; Initial state for doublet simulation and nearest neighbors. Returns; -------; if ``copy=True`` it returns or else adds fields to ``adata``. Those fields:. ``.obs['doublet_score']``; Doublet scores for each observed transcriptome. ``.obs['predicted_doublet']``; Boolean indicating predicted doublet status. ``.uns['scrublet']['doublet_scores_sim']``; Doublet scores for each simulated doublet transcriptome. ``.uns['scrublet']['doublet_parents']``; Pairs of ``.obs_names`` used to generate each simulated doublet; transcriptome. ``.uns['scrublet']['parameters']``; Dictionary of Scrublet parameters. See also; --------; :func:`~scanpy.pp.scrublet_simulate_doublets`: Run Scrublet's doublet; simulation separately for advanced usage.; :func:`~scanpy.pl.scrublet_score_distribution`: Plot histogram of doublet; scores for ob",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py:3862,update,updates,3862,src/scanpy/preprocessing/_scrublet/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py,1,['update'],['updates']
Deployability,"ts per cell. .. warning::; .. deprecated:: 1.3.7; Use :func:`~scanpy.pp.normalize_total` instead.; The new function is equivalent to the present; function, except that. * the new function doesn't filter cells based on `min_counts`,; use :func:`~scanpy.pp.filter_cells` if filtering is needed.; * some arguments were renamed; * `copy` is replaced by `inplace`. Normalize each cell by total counts over all genes, so that every cell has; the same total count after normalization. Similar functions are used, for example, by Seurat :cite:p:`Satija2015`, Cell Ranger; :cite:p:`Zheng2017` or SPRING :cite:p:`Weinreb2017`. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; counts_per_cell_after; If `None`, after normalization, each cell has a total count equal; to the median of the *counts_per_cell* before normalization.; counts_per_cell; Precomputed counts per cell.; key_n_counts; Name of the field in `adata.obs` where the total counts per cell are; stored.; copy; If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned.; min_counts; Cells with counts less than `min_counts` are filtered out during; normalization. Returns; -------; Returns `None` if `copy=False`, else returns an updated `AnnData` object. Sets the following fields:. `adata.X` : :class:`numpy.ndarray` | :class:`scipy.sparse._csr.csr_matrix` (dtype `float`); Normalized count data matrix. Examples; --------; >>> import scanpy as sc; >>> adata = AnnData(np.array([[1, 0], [3, 0], [5, 6]], dtype=np.float32)); >>> print(adata.X.sum(axis=1)); [ 1. 3. 11.]; >>> sc.pp.normalize_per_cell(adata); >>> print(adata.obs); n_counts; 0 1.0; 1 3.0; 2 11.0; >>> print(adata.X.sum(axis=1)); [3. 3. 3.]; >>> sc.pp.normalize_per_cell(; ... adata, counts_per_cell_after=1,; ... key_n_counts='n_counts2',; ... ); >>> print(adata.obs); n_counts n_counts2; 0 1.0 3.0; 1 3.0 3.0; 2 11.0 3.0; >>> print(adata.X.sum(axis=1)); [1. 1. 1.]; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:1320,update,updated,1320,src/scanpy/preprocessing/_simple.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py,1,['update'],['updated']
Energy Efficiency," proposed for single-cell; analysis by :cite:t:`Levine2015`. This requires having ran :func:`~scanpy.pp.neighbors` or; :func:`~scanpy.external.pp.bbknn` first,; or explicitly passing a ``adjacency`` matrix. Parameters; ----------; adata; The annotated data matrix.; resolution; For the default flavor (``'vtraag'``) or for ```RAPIDS```, you can provide a; resolution (higher resolution means finding more and smaller clusters),; which defaults to 1.0.; See “Time as a resolution parameter” in :cite:t:`Lambiotte2014`.; random_state; Change the initialization of the optimization.; restrict_to; Restrict the clustering to the categories within the key for sample; annotation, tuple needs to contain ``(obs_key, list_of_categories)``.; key_added; Key under which to add the cluster labels. (default: ``'louvain'``); adjacency; Sparse adjacency matrix of the graph, defaults to neighbors connectivities.; flavor; Choose between to packages for computing the clustering. ``'vtraag'``; Much more powerful than ``'igraph'``, and the default.; ``'igraph'``; Built in ``igraph`` method.; ``'rapids'``; GPU accelerated implementation. .. deprecated:: 1.10.0; Use :func:`rapids_singlecell.tl.louvain` instead.; directed; Interpret the ``adjacency`` matrix as directed graph?; use_weights; Use weights from knn graph.; partition_type; Type of partition to use.; Only a valid argument if ``flavor`` is ``'vtraag'``.; partition_kwargs; Key word arguments to pass to partitioning,; if ``vtraag`` method is being used.; neighbors_key; Use neighbors connectivities as adjacency.; If not specified, louvain looks .obsp['connectivities'] for connectivities; (default storage place for pp.neighbors).; If specified, louvain looks; .obsp[.uns[neighbors_key]['connectivities_key']] for connectivities.; obsp; Use .obsp[obsp] as adjacency. You can't specify both; `obsp` and `neighbors_key` at the same time.; copy; Copy adata or modify it inplace. Returns; -------; Returns `None` if `copy=False`, else returns an `AnnData",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_louvain.py:1211,power,powerful,1211,src/scanpy/tools/_louvain.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_louvain.py,1,['power'],['powerful']
Energy Efficiency,"""""""; Check whether values in array are constant. Params; ------; a; Array to check; axis; Axis to reduce over. Returns; -------; Boolean array, True values were constant. Example; -------. >>> a = np.array([[0, 1], [0, 0]]); >>> a; array([[0, 1],; [0, 0]]); >>> is_constant(a); False; >>> is_constant(a, axis=0); array([ True, False]); >>> is_constant(a, axis=1); array([False, True]); """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/compute/is_constant.py:98,reduce,reduce,98,src/scanpy/_utils/compute/is_constant.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/compute/is_constant.py,1,['reduce'],['reduce']
Energy Efficiency,"""""""Inhibiting hill function. Is equivalent to 1-hill_a(self,x,power,threshold).; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:62,power,power,62,src/scanpy/tools/_sim.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py,1,['power'],['power']
Energy Efficiency,"""""""Normalized inhibiting hill function. Is equivalent to 1-nhill_a(self,x,power,threshold).; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:74,power,power,74,src/scanpy/tools/_sim.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py,1,['power'],['power']
Energy Efficiency,"""""""Tree layout for networkx graph. See https://stackoverflow.com/questions/29586520/can-one-get-hierarchical-graphs-from-networkx-with-python-3; answer by burubum. If there is a cycle that is reachable from root, then this will see; infinite recursion. Parameters; ----------; G: the graph; root: the root node; levels: a dictionary; key: level number (starting from 0); value: number of nodes in this level; width: horizontal space allocated for drawing; height: vertical space allocated for drawing; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_utils.py:433,allocate,allocated,433,src/scanpy/plotting/_utils.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_utils.py,2,['allocate'],['allocated']
Energy Efficiency,"""""""\; Calculate quality control metrics. Calculates a number of qc metrics for an AnnData object, see section; `Returns` for specifics. Largely based on `calculateQCMetrics` from scater; :cite:p:`McCarthy2017`. Currently is most efficient on a sparse CSR or dense matrix. Note that this method can take a while to compile on the first call. That; result is then cached to disk to be used later. Parameters; ----------; {doc_adata_basic}; {doc_qc_metric_naming}; {doc_obs_qc_args}; {doc_expr_reps}; inplace; Whether to place calculated metrics in `adata`'s `.obs` and `.var`.; log1p; Set to `False` to skip computing `log1p` transformed annotations. Returns; -------; Depending on `inplace` returns calculated metrics; (as :class:`~pandas.DataFrame`) or updates `adata`'s `obs` and `var`. {doc_obs_qc_returns}. {doc_var_qc_returns}. Example; -------; Calculate qc metrics for visualization. .. plot::; :context: close-figs. import scanpy as sc; import seaborn as sns. pbmc = sc.datasets.pbmc3k(); pbmc.var[""mito""] = pbmc.var_names.str.startswith(""MT-""); sc.pp.calculate_qc_metrics(pbmc, qc_vars=[""mito""], inplace=True); sns.jointplot(; data=pbmc.obs,; x=""log1p_total_counts"",; y=""log1p_n_genes_by_counts"",; kind=""hex"",; ). .. plot::; :context: close-figs. sns.histplot(pbmc.obs[""pct_counts_mito""]); """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_qc.py:229,efficient,efficient,229,src/scanpy/preprocessing/_qc.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_qc.py,1,['efficient'],['efficient']
Energy Efficiency,"""""""\; ComBat function for batch effect correction :cite:p:`Johnson2006,Leek2012,Pedersen2012`. Corrects for batch effects by fitting linear models, gains statistical power; via an EB framework where information is borrowed across genes.; This uses the implementation `combat.py`_ :cite:p:`Pedersen2012`. .. _combat.py: https://github.com/brentp/combat.py. Parameters; ----------; adata; Annotated data matrix; key; Key to a categorical annotation from :attr:`~anndata.AnnData.obs`; that will be used for batch effect removal.; covariates; Additional covariates besides the batch variable such as adjustment; variables or biological condition. This parameter refers to the design; matrix `X` in Equation 2.1 in :cite:t:`Johnson2006` and to the `mod` argument in; the original combat function in the sva R package.; Note that not including covariates may introduce bias or lead to the; removal of biological signal in unbalanced designs.; inplace; Whether to replace adata.X or to return the corrected data. Returns; -------; Returns :class:`numpy.ndarray` if `inplace=True`, else returns `None` and sets the following field in the `adata` object:. `adata.X` : :class:`numpy.ndarray` (dtype `float`); Corrected data matrix.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_combat.py:166,power,power,166,src/scanpy/preprocessing/_combat.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_combat.py,1,['power'],['power']
Energy Efficiency,"""""""\; Computes the nearest neighbors distance matrix and a neighborhood graph of observations :cite:p:`McInnes2018`. The neighbor search efficiency of this heavily relies on UMAP :cite:p:`McInnes2018`,; which also provides a method for estimating connectivities of data points -; the connectivity of the manifold (`method=='umap'`). If `method=='gauss'`,; connectivities are computed according to :cite:t:`Coifman2005`, in the adaption of; :cite:t:`Haghverdi2016`. Parameters; ----------; adata; Annotated data matrix.; n_neighbors; The size of local neighborhood (in terms of number of neighboring data; points) used for manifold approximation. Larger values result in more; global views of the manifold, while smaller values result in more local; data being preserved. In general values should be in the range 2 to 100.; If `knn` is `True`, number of nearest neighbors to be searched. If `knn`; is `False`, a Gaussian kernel width is set to the distance of the; `n_neighbors` neighbor. *ignored if ``transformer`` is an instance.*; {n_pcs}; {use_rep}; knn; If `True`, use a hard threshold to restrict the number of neighbors to; `n_neighbors`, that is, consider a knn graph. Otherwise, use a Gaussian; Kernel to assign low weights to neighbors more distant than the; `n_neighbors` nearest neighbor.; method; Use 'umap' :cite:p:`McInnes2018` or 'gauss' (Gauss kernel following :cite:t:`Coifman2005`; with adaptive width :cite:t:`Haghverdi2016`) for computing connectivities.; transformer; Approximate kNN search implementation following the API of; :class:`~sklearn.neighbors.KNeighborsTransformer`.; See :doc:`/how-to/knn-transformers` for more details.; Also accepts the following known options:. `None` (the default); Behavior depends on data size.; For small data, we will calculate exact kNN, otherwise we use; :class:`~pynndescent.pynndescent_.PyNNDescentTransformer`; `'pynndescent'`; :class:`~pynndescent.pynndescent_.PyNNDescentTransformer`; `'rapids'`; A transformer based on :class:`cuml.n",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/__init__.py:427,adapt,adaption,427,src/scanpy/neighbors/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/__init__.py,1,['adapt'],['adaption']
Energy Efficiency,"""""""\; Diffusion Maps :cite:p:`Coifman2005,Haghverdi2015,Wolf2018`. Diffusion maps :cite:p:`Coifman2005` has been proposed for visualizing single-cell; data by :cite:t:`Haghverdi2015`. The tool uses the adapted Gaussian kernel suggested; by :cite:t:`Haghverdi2016` in the implementation of :cite:t:`Wolf2018`. The width (""sigma"") of the connectivity kernel is implicitly determined by; the number of neighbors used to compute the single-cell graph in; :func:`~scanpy.pp.neighbors`. To reproduce the original implementation; using a Gaussian kernel, use `method=='gauss'` in; :func:`~scanpy.pp.neighbors`. To use an exponential kernel, use the default; `method=='umap'`. Differences between these options shouldn't usually be; dramatic. Parameters; ----------; adata; Annotated data matrix.; n_comps; The number of dimensions of the representation.; neighbors_key; If not specified, diffmap looks .uns['neighbors'] for neighbors settings; and .obsp['connectivities'], .obsp['distances'] for connectivities and; distances respectively (default storage places for pp.neighbors).; If specified, diffmap looks .uns[neighbors_key] for neighbors settings and; .obsp[.uns[neighbors_key]['connectivities_key']],; .obsp[.uns[neighbors_key]['distances_key']] for connectivities and distances; respectively.; random_state; A numpy random seed; copy; Return a copy instead of writing to adata. Returns; -------; Returns `None` if `copy=False`, else returns an `AnnData` object. Sets the following fields:. `adata.obsm['X_diffmap']` : :class:`numpy.ndarray` (dtype `float`); Diffusion map representation of data, which is the right eigen basis of; the transition matrix with eigenvectors as columns. `adata.uns['diffmap_evals']` : :class:`numpy.ndarray` (dtype `float`); Array of size (number of eigen vectors).; Eigenvalues of transition matrix. Notes; -----; The 0-th column in `adata.obsm[""X_diffmap""]` is the steady-state solution,; which is non-informative in diffusion maps.; Therefore, the first diffusion com",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_diffmap.py:202,adapt,adapted,202,src/scanpy/tools/_diffmap.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_diffmap.py,1,['adapt'],['adapted']
Energy Efficiency,"""""""\; Evenly reduce counts in cell to target amount. This is an internal function and has some restrictions:. * total counts in cell must be less than target; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:13,reduce,reduce,13,src/scanpy/preprocessing/_simple.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py,1,['reduce'],['reduce']
Energy Efficiency,"""""""\; Generate elementwise power of a matrix. Needed for non-square sparse matrices because they do not support `**` so the `.power` function is used. Params; ------; X; Matrix whose power is to be raised.; power; Integer power value. Returns; -------; Matrix whose power has been raised.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/_aggregated.py:27,power,power,27,src/scanpy/get/_aggregated.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/_aggregated.py,6,['power'],['power']
Energy Efficiency,"""""""\; Generic class for the visualization of AnnData categories and; selected `var` (features or genes). Takes care of the visual location of a main plot, additional plots; in the margins (e.g. dendrogram, margin totals) and legends. Also; understand how to adapt the visual parameter if the plot is rotated. Classed based on BasePlot implement their own _mainplot() method. The BasePlot works by method chaining. For example:; BasePlot(adata, ...).legend(title='legend').style(cmap='binary').show(); """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_baseplot_class.py:258,adapt,adapt,258,src/scanpy/plotting/_baseplot_class.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_baseplot_class.py,1,['adapt'],['adapt']
Energy Efficiency,"""""""\; Markov Affinity-based Graph Imputation of Cells (MAGIC) API :cite:p:`vanDijk2018`. MAGIC is an algorithm for denoising and transcript recover of single cells; applied to single-cell sequencing data. MAGIC builds a graph from the data; and uses diffusion to smooth out noise and recover the data manifold. The algorithm implemented here has changed primarily in two ways; compared to the algorithm described in :cite:t:`vanDijk2018`. Firstly, we use; the adaptive kernel described in :cite:t:`Moon2019` for; improved stability. Secondly, data diffusion is applied; in the PCA space, rather than the data space, for speed and; memory improvements. More information and bug reports; `here <https://github.com/KrishnaswamyLab/MAGIC>`__. For help, visit; <https://krishnaswamylab.org/get-help>. Parameters; ----------; adata; An anndata file with `.raw` attribute representing raw counts.; name_list; Denoised genes to return. The default `'all_genes'`/`None`; may require a large amount of memory if the input data is sparse.; Another possibility is `'pca_only'`.; knn; number of nearest neighbors on which to build kernel.; decay; sets decay rate of kernel tails.; If None, alpha decaying kernel is not used.; knn_max; maximum number of nearest neighbors with nonzero connection.; If `None`, will be set to 3 * `knn`.; t; power to which the diffusion operator is powered.; This sets the level of diffusion. If 'auto', t is selected; according to the Procrustes disparity of the diffused data.; n_pca; Number of principal components to use for calculating; neighborhoods. For extremely large datasets, using; n_pca < 20 allows neighborhoods to be calculated in; roughly log(n_samples) time. If `None`, no PCA is performed.; solver; Which solver to use. ""exact"" uses the implementation described; in :cite:t:`vanDijk2018`. ""approximate"" uses a faster; implementation that performs imputation in the PCA space and then; projects back to the gene space. Note, the ""approximate"" solver may; return negat",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_magic.py:460,adapt,adaptive,460,src/scanpy/external/pp/_magic.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_magic.py,1,['adapt'],['adaptive']
Energy Efficiency,"""""""\; PHATE :cite:p:`Moon2019`. Potential of Heat-diffusion for Affinity-based Trajectory Embedding (PHATE); embeds high dimensional single-cell data into two or three dimensions for; visualization of biological progressions. For more information and access to the object-oriented interface, read the; `PHATE documentation <https://phate.readthedocs.io/>`__. For; tutorials, bug reports, and R/MATLAB implementations, visit the `PHATE; GitHub page <https://github.com/KrishnaswamyLab/PHATE/>`__. For help; using PHATE, go `here <https://krishnaswamylab.org/get-help>`__. Parameters; ----------; adata; Annotated data matrix.; n_components; number of dimensions in which the data will be embedded; k; number of nearest neighbors on which to build kernel; a; sets decay rate of kernel tails.; If None, alpha decaying kernel is not used; n_landmark; number of landmarks to use in fast PHATE; t; power to which the diffusion operator is powered; sets the level of diffusion. If 'auto', t is selected; according to the knee point in the Von Neumann Entropy of; the diffusion operator; gamma; Informational distance constant between -1 and 1.; `gamma=1` gives the PHATE log potential, `gamma=0` gives; a square root potential.; n_pca; Number of principal components to use for calculating; neighborhoods. For extremely large datasets, using; n_pca < 20 allows neighborhoods to be calculated in; log(n_samples) time.; knn_dist; recommended values: 'euclidean' and 'cosine'; Any metric from `scipy.spatial.distance` can be used; distance metric for building kNN graph; mds_dist; recommended values: 'euclidean' and 'cosine'; Any metric from `scipy.spatial.distance` can be used; distance metric for MDS; mds; Selects which MDS algorithm is used for dimensionality reduction.; n_jobs; The number of jobs to use for the computation.; If `None`, `sc.settings.n_jobs` is used.; If -1 all CPUs are used. If 1 is given, no parallel computing code is; used at all, which is useful for debugging.; For n_jobs below -1",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phate.py:892,power,power,892,src/scanpy/external/tl/_phate.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phate.py,2,['power'],"['power', 'powered']"
Energy Efficiency,"""""""\; Run Diffusion maps using the adaptive anisotropic kernel :cite:p:`Setty2019`. Palantir is an algorithm to align cells along differentiation trajectories.; Palantir models differentiation as a stochastic process where stem cells; differentiate to terminally differentiated cells by a series of steps through; a low dimensional phenotypic manifold. Palantir effectively captures the; continuity in cell states and the stochasticity in cell fate determination.; Palantir has been designed to work with multidimensional single cell data; from diverse technologies such as Mass cytometry and single cell RNA-seq. .. note::; More information and bug reports `here <https://github.com/dpeerlab/Palantir>`__. Parameters; ----------; adata; An AnnData object.; n_components; Number of diffusion components.; knn; Number of nearest neighbors for graph construction.; alpha; Normalization parameter for the diffusion operator.; use_adjacency_matrix; Use adaptive anisotropic adjacency matrix, instead of PCA projections; (default) to compute diffusion components.; distances_key; With `use_adjacency_matrix=True`, use the indicated distances key for `.obsp`.; If `None`, `'distances'`.; n_eigs; Number of eigen vectors to use. If `None` specified, the number of eigen; vectors will be determined using eigen gap. Passed to; `palantir.utils.determine_multiscale_space`.; impute_data; Impute data using MAGIC.; n_steps; Number of steps in the diffusion operator. Passed to; `palantir.utils.run_magic_imputation`.; copy; Return a copy instead of writing to `adata`. Returns; -------; Depending on `copy`, returns or updates `adata` with the following fields:. **Diffusion maps**,; used for magic imputation, and to generate multi-scale data matrix,. - X_palantir_diff_comp - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.obsm`, dtype `float`); Array of Diffusion components.; - palantir_EigenValues - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.uns`, dtype `float`); Array of corresponding eigen value",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_palantir.py:35,adapt,adaptive,35,src/scanpy/external/tl/_palantir.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_palantir.py,2,['adapt'],['adaptive']
Energy Efficiency,"""""""\; Run Diffusion maps using the adaptive anisotropic kernel; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_palantir.py:35,adapt,adaptive,35,src/scanpy/external/tl/_palantir.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_palantir.py,1,['adapt'],['adaptive']
Energy Efficiency,"""""""\; Scale data to unit variance and zero mean. .. note::; Variables (genes) that do not display any variation (are constant across; all observations) are retained and (for zero_center==True) set to 0; during this operation. In the future, they might be set to NaNs. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; zero_center; If `False`, omit zero-centering variables, which allows to handle sparse; input efficiently.; max_value; Clip (truncate) to this value after scaling. If `None`, do not clip.; copy; Whether this function should be performed inplace. If an AnnData object; is passed, this also determines if a copy is returned.; layer; If provided, which element of layers to scale.; obsm; If provided, which element of obsm to scale.; mask_obs; Restrict both the derivation of scaling parameters and the scaling itself; to a certain set of observations. The mask is specified as a boolean array; or a string referring to an array in :attr:`~anndata.AnnData.obs`.; This will transform data from csc to csr format if `issparse(data)`. Returns; -------; Returns `None` if `copy=False`, else returns an updated `AnnData` object. Sets the following fields:. `adata.X` | `adata.layers[layer]` : :class:`numpy.ndarray` | :class:`scipy.sparse._csr.csr_matrix` (dtype `float`); Scaled count data matrix.; `adata.var['mean']` : :class:`pandas.Series` (dtype `float`); Means per gene before scaling.; `adata.var['std']` : :class:`pandas.Series` (dtype `float`); Standard deviations per gene before scaling.; `adata.var['var']` : :class:`pandas.Series` (dtype `float`); Variances per gene before scaling.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scale.py:497,efficient,efficiently,497,src/scanpy/preprocessing/_scale.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scale.py,1,['efficient'],['efficiently']
Energy Efficiency,"""""""\; n_top_genes; Number of highly-variable genes to keep. Mandatory if `flavor='seurat_v3'` or; `flavor='pearson_residuals'`.; batch_key; If specified, highly-variable genes are selected within each batch separately; and merged. This simple process avoids the selection of batch-specific genes; and acts as a lightweight batch correction method. Genes are first sorted by; how many batches they are a HVG. If `flavor='pearson_residuals'`, ties are; broken by the median rank (across batches) based on within-batch residual; variance.; chunksize; If `flavor='pearson_residuals'`, this dertermines how many genes are processed at; once while computing the residual variance. Choosing a smaller value will reduce; the required memory.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/_docs.py:705,reduce,reduce,705,src/scanpy/experimental/_docs.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/_docs.py,1,['reduce'],['reduce']
Energy Efficiency,"# Reduce diffmap components for labeling; # Note: plot_scatter takes care of correcting diffmap components; # for plotting automatically",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_embedding_density.py:2,Reduce,Reduce,2,src/scanpy/tools/_embedding_density.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_embedding_density.py,1,['Reduce'],['Reduce']
Energy Efficiency,"# Reduce size of input for faster test",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_scrublet.py:2,Reduce,Reduce,2,tests/test_scrublet.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_scrublet.py,1,['Reduce'],['Reduce']
Energy Efficiency,"# This is a quick and dirty way for adapting scales across several; # keys if groupby is None.",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py:36,adapt,adapting,36,src/scanpy/plotting/_anndata.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py,1,['adapt'],['adapting']
Energy Efficiency,"# This tool has the purpose to take a set of genes (possibly already pre-selected) and analyze AUC.; # Those and only those are eliminated who are dominated completely; # TODO: Potentially (But not till tomorrow), this can be adapted to only consider the AUC in the given; # TODO: optimization frame",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_top_genes.py:226,adapt,adapted,226,src/scanpy/tools/_top_genes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_top_genes.py,1,['adapt'],['adapted']
Energy Efficiency,"# adapt marker_genes for cluster (so as to have some form of reasonable input",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_rank_genes_groups.py:2,adapt,adapt,2,tests/test_rank_genes_groups.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_rank_genes_groups.py,1,['adapt'],['adapt']
Energy Efficiency,"# by default turn off edge color. Otherwise, for; # very small sizes the edge will not reduce its size; # (https://github.com/scverse/scanpy/issues/293)",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/scatterplots.py:87,reduce,reduce,87,src/scanpy/plotting/_tools/scatterplots.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/scatterplots.py,1,['reduce'],['reduce']
Energy Efficiency,"# do this more efficiently... just a quick solution",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py:15,efficient,efficiently,15,src/scanpy/plotting/_anndata.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py,1,['efficient'],['efficiently']
Energy Efficiency,"# green",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/palettes.py:2,green,green,2,src/scanpy/plotting/palettes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/palettes.py,1,['green'],['green']
Energy Efficiency,"# reduce the value of the coupling of the repressing genes; # otherwise completely unstable solutions are obtained",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:2,reduce,reduce,2,src/scanpy/tools/_sim.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py,1,['reduce'],['reduce']
Energy Efficiency,"# sparse matrices do not support ** for elementwise power.",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/_aggregated.py:52,power,power,52,src/scanpy/get/_aggregated.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/_aggregated.py,1,['power'],['power']
Energy Efficiency,"earn.decomposition.TruncatedSVD` is used, will give `'randomized'`,; if *dask-ml* :class:`~dask_ml.decomposition.PCA` or :class:`~dask_ml.decomposition.IncrementalPCA` is used, will give `'auto'`,; if *dask-ml* :class:`~dask_ml.decomposition.TruncatedSVD` is used, will give `'tsqr'`; `'arpack'`; for the ARPACK wrapper in SciPy (:func:`~scipy.sparse.linalg.svds`); Not available with *dask* arrays.; `'randomized'`; for the randomized algorithm due to Halko (2009). For *dask* arrays,; this will use :func:`~dask.array.linalg.svd_compressed`.; `'auto'`; chooses automatically depending on the size of the problem.; `'lobpcg'`; An alternative SciPy solver. Not available with dask arrays.; `'tsqr'`; Only available with *dask* arrays. ""tsqr""; algorithm from Benson et. al. (2013). .. versionchanged:: 1.9.3; Default value changed from `'arpack'` to None.; .. versionchanged:: 1.4.5; Default value changed from `'auto'` to `'arpack'`. Efficient computation of the principal components of a sparse matrix; currently only works with the `'arpack`' or `'lobpcg'` solvers. If X is a *dask* array, *dask-ml* classes :class:`~dask_ml.decomposition.PCA`,; :class:`~dask_ml.decomposition.IncrementalPCA`, or; :class:`~dask_ml.decomposition.TruncatedSVD` will be used.; Otherwise their *scikit-learn* counterparts :class:`~sklearn.decomposition.PCA`,; :class:`~sklearn.decomposition.IncrementalPCA`, or; :class:`~sklearn.decomposition.TruncatedSVD` will be used.; random_state; Change to use different initial states for the optimization.; return_info; Only relevant when not passing an :class:`~anndata.AnnData`:; see “Returns”.; {mask_var_hvg}; layer; Layer of `adata` to use as expression values.; dtype; Numpy data type string to which to convert the result.; copy; If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned. Is ignored otherwise.; chunked; If `True`, perform an incremental PCA on segments of `chunk_size`.; The incremental PCA automatically zero centers and ignore",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py:2466,Efficient,Efficient,2466,src/scanpy/preprocessing/_pca.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py,1,['Efficient'],['Efficient']
Energy Efficiency,"hanged primarily in two ways; compared to the algorithm described in :cite:t:`vanDijk2018`. Firstly, we use; the adaptive kernel described in :cite:t:`Moon2019` for; improved stability. Secondly, data diffusion is applied; in the PCA space, rather than the data space, for speed and; memory improvements. More information and bug reports; `here <https://github.com/KrishnaswamyLab/MAGIC>`__. For help, visit; <https://krishnaswamylab.org/get-help>. Parameters; ----------; adata; An anndata file with `.raw` attribute representing raw counts.; name_list; Denoised genes to return. The default `'all_genes'`/`None`; may require a large amount of memory if the input data is sparse.; Another possibility is `'pca_only'`.; knn; number of nearest neighbors on which to build kernel.; decay; sets decay rate of kernel tails.; If None, alpha decaying kernel is not used.; knn_max; maximum number of nearest neighbors with nonzero connection.; If `None`, will be set to 3 * `knn`.; t; power to which the diffusion operator is powered.; This sets the level of diffusion. If 'auto', t is selected; according to the Procrustes disparity of the diffused data.; n_pca; Number of principal components to use for calculating; neighborhoods. For extremely large datasets, using; n_pca < 20 allows neighborhoods to be calculated in; roughly log(n_samples) time. If `None`, no PCA is performed.; solver; Which solver to use. ""exact"" uses the implementation described; in :cite:t:`vanDijk2018`. ""approximate"" uses a faster; implementation that performs imputation in the PCA space and then; projects back to the gene space. Note, the ""approximate"" solver may; return negative values.; knn_dist; recommended values: 'euclidean', 'cosine', 'precomputed'; Any metric from `scipy.spatial.distance` can be used; distance metric for building kNN graph. If 'precomputed',; `data` should be an n_samples x n_samples distance or; affinity matrix.; random_state; Random seed. Defaults to the global `numpy` random number generat",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_magic.py:1325,power,power,1325,src/scanpy/external/pp/_magic.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_magic.py,2,['power'],"['power', 'powered']"
Energy Efficiency,"node or a list; of root node indices. If this is a non-empty vector then the supplied; node IDs are used as the roots of the trees (or a single tree if the; graph is connected). If this is `None` or an empty list, the root; vertices are automatically calculated based on topological sorting.; transitions; Key for `.uns['paga']` that specifies the matrix that stores the; arrows, for instance `'transitions_confidence'`.; solid_edges; Key for `.uns['paga']` that specifies the matrix that stores the edges; to be drawn solid black.; dashed_edges; Key for `.uns['paga']` that specifies the matrix that stores the edges; to be drawn dashed grey. If `None`, no dashed edges are drawn.; single_component; Restrict to largest connected component.; fontsize; Font size for node labels.; fontoutline; Width of the white outline around fonts.; text_kwds; Keywords for :meth:`~matplotlib.axes.Axes.text`.; node_size_scale; Increase or decrease the size of the nodes.; node_size_power; The power with which groups sizes influence the radius of the nodes.; edge_width_scale; Edge with scale in units of `rcParams['lines.linewidth']`.; min_edge_width; Min width of solid edges.; max_edge_width; Max width of solid and dashed edges.; arrowsize; For directed graphs, choose the size of the arrow head head's length and; width. See :py:class: `matplotlib.patches.FancyArrowPatch` for attribute; `mutation_scale` for more info.; export_to_gexf; Export to gexf format to be read by graph visualization programs such as; Gephi.; normalize_to_color; Whether to normalize categorical plots to `color` or the underlying; grouping.; cmap; The color map.; cax; A matplotlib axes object for a potential colorbar.; cb_kwds; Keyword arguments for :class:`~matplotlib.colorbar.Colorbar`,; for instance, `ticks`.; add_pos; Add the positions to `adata.uns['paga']`.; title; Provide a title.; frameon; Draw a frame around the PAGA graph.; plot; If `False`, do not create the figure, simply compute the layout.; save; If `True` or a",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/paga.py:3090,power,power,3090,src/scanpy/plotting/_tools/paga.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/paga.py,1,['power'],['power']
Energy Efficiency,"ording to :cite:t:`Coifman2005`, in the adaption of; :cite:t:`Haghverdi2016`. Parameters; ----------; adata; Annotated data matrix.; n_neighbors; The size of local neighborhood (in terms of number of neighboring data; points) used for manifold approximation. Larger values result in more; global views of the manifold, while smaller values result in more local; data being preserved. In general values should be in the range 2 to 100.; If `knn` is `True`, number of nearest neighbors to be searched. If `knn`; is `False`, a Gaussian kernel width is set to the distance of the; `n_neighbors` neighbor. *ignored if ``transformer`` is an instance.*; {n_pcs}; {use_rep}; knn; If `True`, use a hard threshold to restrict the number of neighbors to; `n_neighbors`, that is, consider a knn graph. Otherwise, use a Gaussian; Kernel to assign low weights to neighbors more distant than the; `n_neighbors` nearest neighbor.; method; Use 'umap' :cite:p:`McInnes2018` or 'gauss' (Gauss kernel following :cite:t:`Coifman2005`; with adaptive width :cite:t:`Haghverdi2016`) for computing connectivities.; transformer; Approximate kNN search implementation following the API of; :class:`~sklearn.neighbors.KNeighborsTransformer`.; See :doc:`/how-to/knn-transformers` for more details.; Also accepts the following known options:. `None` (the default); Behavior depends on data size.; For small data, we will calculate exact kNN, otherwise we use; :class:`~pynndescent.pynndescent_.PyNNDescentTransformer`; `'pynndescent'`; :class:`~pynndescent.pynndescent_.PyNNDescentTransformer`; `'rapids'`; A transformer based on :class:`cuml.neighbors.NearestNeighbors`. .. deprecated:: 1.10.0; Use :func:`rapids_singlecell.pp.neighbors` instead.; metric; A known metric’s name or a callable that returns a distance. *ignored if ``transformer`` is an instance.*; metric_kwds; Options for the metric. *ignored if ``transformer`` is an instance.*; random_state; A numpy random seed. *ignored if ``transformer`` is an instance.*; key",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/__init__.py:1406,adapt,adaptive,1406,src/scanpy/neighbors/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/__init__.py,1,['adapt'],['adaptive']
Energy Efficiency,"riance decomposition.; Uses the implementation of *scikit-learn* :cite:p:`Pedregosa2011`. .. versionchanged:: 1.5.0. In previous versions, computing a PCA on a sparse matrix would make; a dense copy of the array for mean centering.; As of scanpy 1.5.0, mean centering is implicit.; While results are extremely similar, they are not exactly the same.; If you would like to reproduce the old results, pass a dense array. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; n_comps; Number of principal components to compute. Defaults to 50, or 1 - minimum; dimension size of selected representation.; layer; If provided, which element of layers to use for PCA.; zero_center; If `True`, compute standard PCA from covariance matrix.; If `False`, omit zero-centering variables; (uses *scikit-learn* :class:`~sklearn.decomposition.TruncatedSVD` or; *dask-ml* :class:`~dask_ml.decomposition.TruncatedSVD`),; which allows to handle sparse input efficiently.; Passing `None` decides automatically based on sparseness of the data.; svd_solver; SVD solver to use:. `None`; See `chunked` and `zero_center` descriptions to determine which class will be used.; Depending on the class and the type of X different values for default will be set.; If *scikit-learn* :class:`~sklearn.decomposition.PCA` is used, will give `'arpack'`,; if *scikit-learn* :class:`~sklearn.decomposition.TruncatedSVD` is used, will give `'randomized'`,; if *dask-ml* :class:`~dask_ml.decomposition.PCA` or :class:`~dask_ml.decomposition.IncrementalPCA` is used, will give `'auto'`,; if *dask-ml* :class:`~dask_ml.decomposition.TruncatedSVD` is used, will give `'tsqr'`; `'arpack'`; for the ARPACK wrapper in SciPy (:func:`~scipy.sparse.linalg.svds`); Not available with *dask* arrays.; `'randomized'`; for the randomized algorithm due to Halko (2009). For *dask* arrays,; this will use :func:`~dask.array.linalg.svd_compressed`.; `'auto'`; chooses automat",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py:1122,efficient,efficiently,1122,src/scanpy/preprocessing/_pca.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py,1,['efficient'],['efficiently']
Energy Efficiency,"rmalize_per_cell` function in Scanpy and saved into adata; object. Mean layer is re-introduces library size differences by; scaling the mean value of each cell in the output layer. See the; manuscript for more details.; scale; If true, the input of the autoencoder is centered using; `sc.pp.scale` function of Scanpy. Note that the output is kept as raw; counts as loss functions are designed for the count data.; log1p; If true, the input of the autoencoder is log transformed with a; pseudocount of one using `sc.pp.log1p` function of Scanpy.; hidden_size; Width of hidden layers.; hidden_dropout; Probability of weight dropout in the autoencoder (per layer if list; or tuple).; batchnorm; If true, batch normalization is performed.; activation; Activation function of hidden layers.; init; Initialization method used to initialize weights.; network_kwds; Additional keyword arguments for the autoencoder.; epochs; Number of total epochs in training.; reduce_lr; Reduces learning rate if validation loss does not improve in given number of epochs.; early_stop; Stops training if validation loss does not improve in given number of epochs.; batch_size; Number of samples in the batch used for SGD.; optimizer; Type of optimization method used for training.; random_state; Seed for python, numpy and tensorflow.; threads; Number of threads to use in training. All cores are used by default.; learning_rate; Learning rate to use in the training.; verbose; If true, prints additional information about training and architecture.; training_kwds; Additional keyword arguments for the training process.; return_model; If true, trained autoencoder object is returned. See ""Returns"".; return_info; If true, all additional parameters of DCA are stored in `adata.obsm` such as dropout; probabilities (obsm['X_dca_dropout']) and estimated dispersion values; (obsm['X_dca_dispersion']), in case that autoencoder is of type; zinb or zinb-conddisp.; copy; If true, a copy of anndata is returned. Returns; -------; ",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_dca.py:1967,Reduce,Reduces,1967,src/scanpy/external/pp/_dca.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_dca.py,1,['Reduce'],['Reduces']
Energy Efficiency,"symmetric (`'directed'`) graph.; The graph construction process produces a directed graph, which is symmetrized; by one of two methods (see `prune` below).; prune; `prune=False`, symmetrize by taking the average between the graph and its; transpose. `prune=True`, symmetrize by taking the product between the graph; and its transpose.; min_cluster_size; Cells that end up in a cluster smaller than min_cluster_size are considered; outliers and are assigned to -1 in the cluster labels.; jaccard; If `True`, use Jaccard metric between k-neighborhoods to build graph. If; `False`, use a Gaussian kernel.; primary_metric; Distance metric to define nearest neighbors. Note that performance will be; slower for correlation and cosine.; n_jobs; Nearest Neighbors and Jaccard coefficients will be computed in parallel using; n_jobs. If 1 is given, no parallelism is used. If set to -1, all CPUs are used.; For n_jobs below -1, `n_cpus + 1 + n_jobs` are used.; q_tol; Tolerance, i.e. precision, for monitoring modularity optimization.; louvain_time_limit; Maximum number of seconds to run modularity optimization. If exceeded the best; result so far is returned.; nn_method; Whether to use brute force or kdtree for nearest neighbor search.; For very large high-dimensional data sets, brute force, with parallel; computation, performs faster than kdtree.; partition_type; Defaults to :class:`~leidenalg.RBConfigurationVertexPartition`. For the; available options, consult the documentation for; :func:`~leidenalg.find_partition`.; resolution_parameter; A parameter value controlling the coarseness of the clustering in Leiden. Higher; values lead to more clusters. Set to `None` if overriding `partition_type` to; one that does not accept a `resolution_parameter`.; n_iterations; Number of iterations to run the Leiden algorithm. If the number of iterations is; negative, the Leiden algorithm is run until an iteration in which there was no; improvement.; use_weights; Use vertices in the Leiden computation.;",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phenograph.py:1999,monitor,monitoring,1999,src/scanpy/external/tl/_phenograph.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phenograph.py,1,['monitor'],['monitoring']
Integrability," -------; Returns `None` if `copy=False`, else returns an `AnnData` object. Sets the following fields:. `adata.uns['rank_genes_groups' | key_added]['names']` : structured :class:`numpy.ndarray` (dtype `object`); Structured array to be indexed by group id storing the gene; names. Ordered according to scores.; `adata.uns['rank_genes_groups' | key_added]['scores']` : structured :class:`numpy.ndarray` (dtype `object`); Structured array to be indexed by group id storing the z-score; underlying the computation of a p-value for each gene for each; group. Ordered according to scores.; `adata.uns['rank_genes_groups' | key_added]['logfoldchanges']` : structured :class:`numpy.ndarray` (dtype `object`); Structured array to be indexed by group id storing the log2; fold change for each gene for each group. Ordered according to; scores. Only provided if method is 't-test' like.; Note: this is an approximation calculated from mean-log values.; `adata.uns['rank_genes_groups' | key_added]['pvals']` : structured :class:`numpy.ndarray` (dtype `float`); p-values.; `adata.uns['rank_genes_groups' | key_added]['pvals_adj']` : structured :class:`numpy.ndarray` (dtype `float`); Corrected p-values.; `adata.uns['rank_genes_groups' | key_added]['pts']` : :class:`pandas.DataFrame` (dtype `float`); Fraction of cells expressing the genes for each group.; `adata.uns['rank_genes_groups' | key_added]['pts_rest']` : :class:`pandas.DataFrame` (dtype `float`); Only if `reference` is set to `'rest'`.; Fraction of cells from the union of the rest of each group; expressing the genes. Notes; -----; There are slight inconsistencies depending on whether sparse; or dense data are passed. See `here <https://github.com/scverse/scanpy/blob/main/scanpy/tests/test_rank_genes_groups.py>`__. Examples; --------; >>> import scanpy as sc; >>> adata = sc.datasets.pbmc68k_reduced(); >>> sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'); >>> # to visualize the results; >>> sc.pl.rank_genes_groups(adata); """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py:3693,depend,depending,3693,src/scanpy/tools/_rank_genes_groups.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py,1,['depend'],['depending']
Integrability," RNA-seq. .. note::; More information and bug reports `here <https://github.com/dpeerlab/Palantir>`__. Parameters; ----------; adata; An AnnData object.; n_components; Number of diffusion components.; knn; Number of nearest neighbors for graph construction.; alpha; Normalization parameter for the diffusion operator.; use_adjacency_matrix; Use adaptive anisotropic adjacency matrix, instead of PCA projections; (default) to compute diffusion components.; distances_key; With `use_adjacency_matrix=True`, use the indicated distances key for `.obsp`.; If `None`, `'distances'`.; n_eigs; Number of eigen vectors to use. If `None` specified, the number of eigen; vectors will be determined using eigen gap. Passed to; `palantir.utils.determine_multiscale_space`.; impute_data; Impute data using MAGIC.; n_steps; Number of steps in the diffusion operator. Passed to; `palantir.utils.run_magic_imputation`.; copy; Return a copy instead of writing to `adata`. Returns; -------; Depending on `copy`, returns or updates `adata` with the following fields:. **Diffusion maps**,; used for magic imputation, and to generate multi-scale data matrix,. - X_palantir_diff_comp - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.obsm`, dtype `float`); Array of Diffusion components.; - palantir_EigenValues - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.uns`, dtype `float`); Array of corresponding eigen values.; - palantir_diff_op - :class:`~scipy.sparse.spmatrix` (:attr:`~anndata.AnnData.obsp`, dtype `float`); The diffusion operator matrix. **Multi scale space results**,; used to build tsne on diffusion components, and to compute branch probabilities; and waypoints,. - X_palantir_multiscale - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.obsm`, dtype `float`); Multi scale data matrix. **MAGIC imputation**,; used for plotting gene expression on tsne, and gene expression trends,. - palantir_imp - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.layers`, dtype `float`); Imputed data matrix (MAGIC im",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_palantir.py:1576,Depend,Depending,1576,src/scanpy/external/tl/_palantir.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_palantir.py,1,['Depend'],['Depending']
Integrability," _scanorama: https://github.com/brianhie/scanorama. Parameters; ----------; adata; The annotated data matrix.; key; The name of the column in ``adata.obs`` that differentiates; among experiments/batches. Cells from the same batch must be; contiguously stored in ``adata``.; basis; The name of the field in ``adata.obsm`` where the PCA table is; stored. Defaults to ``'X_pca'``, which is the default for; ``sc.pp.pca()``.; adjusted_basis; The name of the field in ``adata.obsm`` where the integrated; embeddings will be stored after running this function. Defaults; to ``X_scanorama``.; knn; Number of nearest neighbors to use for matching.; sigma; Correction smoothing parameter on Gaussian kernel.; approx; Use approximate nearest neighbors with Python ``annoy``;; greatly speeds up matching runtime.; alpha; Alignment score minimum cutoff.; batch_size; The batch size used in the alignment vector computation. Useful; when integrating very large (>100k samples) datasets. Set to; large value that runs within available memory.; kwargs; Any additional arguments will be passed to; ``scanorama.assemble()``. Returns; -------; Updates adata with the field ``adata.obsm[adjusted_basis]``,; containing Scanorama embeddings such that different experiments; are integrated. Example; -------; First, load libraries and example dataset, and preprocess. >>> import scanpy as sc; >>> import scanpy.external as sce; >>> adata = sc.datasets.pbmc3k(); >>> sc.pp.recipe_zheng17(adata); >>> sc.pp.pca(adata). We now arbitrarily assign a batch metadata variable to each cell; for the sake of example, but during real usage there would already; be a column in ``adata.obs`` giving the experiment each cell came; from. >>> adata.obs['batch'] = 1350*['a'] + 1350*['b']. Finally, run Scanorama. Afterwards, there will be a new table in; ``adata.obsm`` containing the Scanorama embeddings. >>> sce.pp.scanorama_integrate(adata, 'batch', verbose=1); Processing datasets a <=> b; >>> 'X_scanorama' in adata.obsm; True; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py:1657,integrat,integrated,1657,src/scanpy/external/pp/_scanorama_integrate.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py,1,['integrat'],['integrated']
Integrability," to the knee point in the Von Neumann Entropy of; the diffusion operator; gamma; Informational distance constant between -1 and 1.; `gamma=1` gives the PHATE log potential, `gamma=0` gives; a square root potential.; n_pca; Number of principal components to use for calculating; neighborhoods. For extremely large datasets, using; n_pca < 20 allows neighborhoods to be calculated in; log(n_samples) time.; knn_dist; recommended values: 'euclidean' and 'cosine'; Any metric from `scipy.spatial.distance` can be used; distance metric for building kNN graph; mds_dist; recommended values: 'euclidean' and 'cosine'; Any metric from `scipy.spatial.distance` can be used; distance metric for MDS; mds; Selects which MDS algorithm is used for dimensionality reduction.; n_jobs; The number of jobs to use for the computation.; If `None`, `sc.settings.n_jobs` is used.; If -1 all CPUs are used. If 1 is given, no parallel computing code is; used at all, which is useful for debugging.; For n_jobs below -1, (n_cpus + 1 + n_jobs) are used. Thus for; n_jobs = -2, all CPUs but one are used; random_state; Random seed. Defaults to the global `numpy` random number generator; verbose; If `True` or an `int`/`Verbosity` ≥ 2/`hint`, print status messages.; If `None`, `sc.settings.verbosity` is used.; copy; Return a copy instead of writing to `adata`.; kwargs; Additional arguments to `phate.PHATE`. Returns; -------; Depending on `copy`, returns or updates `adata` with the following fields. **X_phate** : `np.ndarray`, (`adata.obs`, shape=[n_samples, n_components], dtype `float`); PHATE coordinates of data. Examples; --------; >>> from anndata import AnnData; >>> import scanpy.external as sce; >>> import phate; >>> tree_data, tree_clusters = phate.tree.gen_dla(; ... n_dim=100,; ... n_branch=20,; ... branch_length=100,; ... ); >>> tree_data.shape; (2000, 100); >>> adata = AnnData(tree_data); >>> sce.tl.phate(adata, k=5, a=20, t=150); >>> adata.obsm['X_phate'].shape; (2000, 2); >>> sce.pl.phate(adata); """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phate.py:2236,message,messages,2236,src/scanpy/external/tl/_phate.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phate.py,2,"['Depend', 'message']","['Depending', 'messages']"
Integrability,"""""""; Filters anndata.OldFormatWarning from being thrown by the wrapped function.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_utils.py:63,wrap,wrapped,63,src/scanpy/datasets/_utils.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_utils.py,1,['wrap'],['wrapped']
Integrability,"""""""; Test that Harmony integrate works. This is a very simple test that just checks to see if the Harmony; integrate wrapper succesfully added a new field to ``adata.obsm``; and makes sure it has the same dimensions as the original PCA table.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/external/test_harmony_integrate.py:23,integrat,integrate,23,tests/external/test_harmony_integrate.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/external/test_harmony_integrate.py,3,"['integrat', 'wrap']","['integrate', 'wrapper']"
Integrability,"""""""; Test that Scanorama integration works. This is a very simple test that just checks to see if the Scanorama; integrate wrapper succesfully added a new field to ``adata.obsm``; and makes sure it has the same dimensions as the original PCA table.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/external/test_scanorama_integrate.py:25,integrat,integration,25,tests/external/test_scanorama_integrate.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/external/test_scanorama_integrate.py,3,"['integrat', 'wrap']","['integrate', 'integration', 'wrapper']"
Integrability,"""""""; Use Scanorama to integrate cells from different experiments.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py:22,integrat,integrate,22,src/scanpy/external/pp/_scanorama_integrate.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py,1,['integrat'],['integrate']
Integrability,"""""""; Use harmony to integrate cells from different experiments.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_harmony_integrate.py:20,integrat,integrate,20,src/scanpy/external/pp/_harmony_integrate.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_harmony_integrate.py,1,['integrat'],['integrate']
Integrability,"""""""; Verbosity level (default `warning`). Level 0: only show 'error' messages.; Level 1: also show 'warning' messages.; Level 2: also show 'info' messages.; Level 3: also show 'hint' messages.; Level 4: also show very detailed progress for 'debug'ging.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_settings.py:69,message,messages,69,src/scanpy/_settings.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_settings.py,4,['message'],['messages']
Integrability,"""""""Extension to inject ``html_theme_options[""repository_branch""]``.""""""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/docs/extensions/git_ref.py:16,inject,inject,16,docs/extensions/git_ref.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/docs/extensions/git_ref.py,1,['inject'],['inject']
Integrability,"""""""Mark function with doctest dependency.""""""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/_doctests.py:30,depend,dependency,30,src/scanpy/_utils/_doctests.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/_doctests.py,1,['depend'],['dependency']
Integrability,"""""""Parse a pyproject.toml file and output a list of minimum dependencies. Output is directly passable to `pip install`.""""""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/ci/scripts/min-deps.py:60,depend,dependencies,60,ci/scripts/min-deps.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/ci/scripts/min-deps.py,1,['depend'],['dependencies']
Integrability,"""""""Plot scatter plot of data. Parameters; ----------; Y; Data array.; projection. Returns; -------; Depending on whether supplying a single array or a list of arrays,; return a single axis or a list of axes.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_utils.py:100,Depend,Depending,100,src/scanpy/plotting/_utils.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_utils.py,1,['Depend'],['Depending']
Integrability,"""""""Set self.{means,vars,pts}{,_rest} depending on X.""""""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py:37,depend,depending,37,src/scanpy/tools/_rank_genes_groups.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py,1,['depend'],['depending']
Integrability,"""""""Update the wrapper function to use the correct signature.""""""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/scatterplots.py:14,wrap,wrapper,14,src/scanpy/plotting/_tools/scatterplots.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/scatterplots.py,1,['wrap'],['wrapper']
Integrability,"""""""\; **Running Palantir**. A convenience function that wraps `palantir.core.run_palantir` to compute branch; probabilities and waypoints. Parameters; ----------; adata; An AnnData object.; early_cell; Start cell for pseudotime construction.; ms_data; Palantir multi scale data matrix,; terminal_states; List of user defined terminal states; knn; Number of nearest neighbors for graph construction.; num_waypoints; Number of waypoints to sample.; n_jobs; Number of jobs for parallel processing.; scale_components; Transform features by scaling each feature to a given range. Consult the; documentation for `sklearn.preprocessing.minmax_scale`.; use_early_cell_as_start; Use `early_cell` as `start_cell`, instead of determining it from the boundary; cells closest to the defined `early_cell`.; max_iterations; Maximum number of iterations for pseudotime convergence. Returns; -------; PResults object with pseudotime, entropy, branch probabilities and waypoints.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_palantir.py:56,wrap,wraps,56,src/scanpy/external/tl/_palantir.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_palantir.py,1,['wrap'],['wraps']
Integrability,"""""""\; A simple interface to biomart. Params; ------; {doc_org}; attrs; What you want returned.; filters; What you want to pick out.; {doc_host}; {doc_use_cache}; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/queries/_queries.py:15,interface,interface,15,src/scanpy/queries/_queries.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/queries/_queries.py,1,['interface'],['interface']
Integrability,"""""""\; Annotate highly variable genes :cite:p:`Satija2015,Zheng2017,Stuart2019`. Expects logarithmized data, except when `flavor='seurat_v3'`/`'seurat_v3_paper'`, in which count; data is expected. Depending on `flavor`, this reproduces the R-implementations of Seurat; :cite:p:`Satija2015`, Cell Ranger :cite:p:`Zheng2017`, and Seurat v3 :cite:p:`Stuart2019`. `'seurat_v3'`/`'seurat_v3_paper'` requires `scikit-misc` package. If you plan to use this flavor, consider; installing `scanpy` with this optional dependency: `scanpy[skmisc]`. For the dispersion-based methods (`flavor='seurat'` :cite:t:`Satija2015` and; `flavor='cell_ranger'` :cite:t:`Zheng2017`), the normalized dispersion is obtained; by scaling with the mean and standard deviation of the dispersions for genes; falling into a given bin for mean expression of genes. This means that for each; bin of mean expression, highly variable genes are selected. For `flavor='seurat_v3'`/`'seurat_v3_paper'` :cite:p:`Stuart2019`, a normalized variance for each gene; is computed. First, the data are standardized (i.e., z-score normalization; per feature) with a regularized standard deviation. Next, the normalized variance; is computed as the variance of each gene after the transformation. Genes are ranked; by the normalized variance.; Only if `batch_key` is not `None`, the two flavors differ: For `flavor='seurat_v3'`, genes are first sorted by the median (across batches) rank, with ties broken by the number of batches a gene is a HVG.; For `flavor='seurat_v3_paper'`, genes are first sorted by the number of batches a gene is a HVG, with ties broken by the median (across batches) rank. The following may help when comparing to Seurat's naming:; If `batch_key=None` and `flavor='seurat'`, this mimics Seurat's `FindVariableFeatures(…, method='mean.var.plot')`.; If `batch_key=None` and `flavor='seurat_v3'`/`flavor='seurat_v3_paper'`, this mimics Seurat's `FindVariableFeatures(..., method='vst')`.; If `batch_key` is not `None` and `flav",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py:196,Depend,Depending,196,src/scanpy/preprocessing/_highly_variable_genes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py,2,"['Depend', 'depend']","['Depending', 'dependency']"
Integrability,"""""""\; Batch balanced kNN :cite:p:`Polanski2019`. Batch balanced kNN alters the kNN procedure to identify each cell's top neighbours in; each batch separately instead of the entire cell pool with no accounting for batch.; The nearest neighbours for each batch are then merged to create a final list of; neighbours for the cell. Aligns batches in a quick and lightweight manner. For use in the scanpy workflow as an alternative to :func:`~scanpy.pp.neighbors`. .. note::. This is just a wrapper of :func:`bbknn.bbknn`: up to date docstring,; more information and bug reports there. Params; ------; adata; Needs the PCA computed and stored in `adata.obsm[""X_pca""]`.; batch_key; `adata.obs` column name discriminating between your batches.; use_rep; The dimensionality reduction in `.obsm` to use for neighbour detection. Defaults to PCA.; approx; If `True`, use approximate neighbour finding - annoy or PyNNDescent. This results; in a quicker run time for large datasets while also potentially increasing the degree of; batch correction.; use_annoy; Only used when `approx=True`. If `True`, will use annoy for neighbour finding. If; `False`, will use pyNNDescent instead.; metric; What distance metric to use. The options depend on the choice of neighbour algorithm. ""euclidean"", the default, is always available. Annoy supports ""angular"", ""manhattan"" and ""hamming"". PyNNDescent supports metrics listed in `pynndescent.distances.named_distances`; and custom functions, including compiled Numba code. >>> import pynndescent; >>> pynndescent.distances.named_distances.keys() # doctest: +ELLIPSIS, +NORMALIZE_WHITESPACE; dict_keys(['euclidean', 'l2', 'sqeuclidean', 'manhattan', 'taxicab', 'l1', 'chebyshev', 'linfinity',; 'linfty', 'linf', 'minkowski', 'seuclidean', 'standardised_euclidean', 'wminkowski', ...]). KDTree supports members of :class:`sklearn.neighbors.KDTree`’s ``valid_metrics`` list, or parameterised; :class:`~sklearn.metrics.DistanceMetric` objects:. >>> import sklearn.neighbors; >>> sk",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_bbknn.py:485,wrap,wrapper,485,src/scanpy/external/pp/_bbknn.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_bbknn.py,1,['wrap'],['wrapper']
Integrability,"""""""\; Calculate quality control metrics. Calculates a number of qc metrics for an AnnData object, see section; `Returns` for specifics. Largely based on `calculateQCMetrics` from scater; :cite:p:`McCarthy2017`. Currently is most efficient on a sparse CSR or dense matrix. Note that this method can take a while to compile on the first call. That; result is then cached to disk to be used later. Parameters; ----------; {doc_adata_basic}; {doc_qc_metric_naming}; {doc_obs_qc_args}; {doc_expr_reps}; inplace; Whether to place calculated metrics in `adata`'s `.obs` and `.var`.; log1p; Set to `False` to skip computing `log1p` transformed annotations. Returns; -------; Depending on `inplace` returns calculated metrics; (as :class:`~pandas.DataFrame`) or updates `adata`'s `obs` and `var`. {doc_obs_qc_returns}. {doc_var_qc_returns}. Example; -------; Calculate qc metrics for visualization. .. plot::; :context: close-figs. import scanpy as sc; import seaborn as sns. pbmc = sc.datasets.pbmc3k(); pbmc.var[""mito""] = pbmc.var_names.str.startswith(""MT-""); sc.pp.calculate_qc_metrics(pbmc, qc_vars=[""mito""], inplace=True); sns.jointplot(; data=pbmc.obs,; x=""log1p_total_counts"",; y=""log1p_n_genes_by_counts"",; kind=""hex"",; ). .. plot::; :context: close-figs. sns.histplot(pbmc.obs[""pct_counts_mito""]); """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_qc.py:667,Depend,Depending,667,src/scanpy/preprocessing/_qc.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_qc.py,1,['Depend'],['Depending']
Integrability,"""""""\; Correct batch effects by matching mutual nearest neighbors :cite:p:`Haghverdi2018` :cite:p:`Kang2018`. This uses the implementation of mnnpy_ :cite:p:`Kang2018`. Depending on `do_concatenate`, returns matrices or `AnnData` objects in the; original order containing corrected expression values or a concatenated; matrix or AnnData object. Be reminded that it is not advised to use the corrected data matrices for; differential expression testing. More information and bug reports `here <mnnpy>`__. .. _mnnpy: https://github.com/chriscainx/mnnpy. Parameters; ----------; datas; Expression matrices or AnnData objects. Matrices should be shaped like; n_obs × n_vars (n_cell × n_gene) and have consistent number of columns.; AnnData objects should have same number of variables.; var_index; The index (list of str) of vars (genes). Necessary when using only a; subset of vars to perform MNN correction, and should be supplied with; `var_subset`. When `datas` are AnnData objects, `var_index` is ignored.; var_subset; The subset of vars (list of str) to be used when performing MNN; correction. Typically, a list of highly variable genes (HVGs).; When set to `None`, uses all vars.; batch_key; The `batch_key` for :meth:`~anndata.AnnData.concatenate`.; Only valid when `do_concatenate` and supplying `AnnData` objects.; index_unique; The `index_unique` for :meth:`~anndata.AnnData.concatenate`.; Only valid when `do_concatenate` and supplying `AnnData` objects.; batch_categories; The `batch_categories` for :meth:`~anndata.AnnData.concatenate`.; Only valid when `do_concatenate` and supplying AnnData objects.; k; Number of mutual nearest neighbors.; sigma; The bandwidth of the Gaussian smoothing kernel used to compute the; correction vectors. Default is 1.; cos_norm_in; Whether cosine normalization should be performed on the input data prior; to calculating distances between cells.; cos_norm_out; Whether cosine normalization should be performed prior to computing corrected expression values.",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_mnn_correct.py:168,Depend,Depending,168,src/scanpy/external/pp/_mnn_correct.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_mnn_correct.py,1,['Depend'],['Depending']
Integrability,"""""""\; Creates a heatmap of the mean expression values per group of each var_names. This function provides a convenient interface to the :class:`~scanpy.pl.MatrixPlot`; class. If you need more flexibility, you should use :class:`~scanpy.pl.MatrixPlot`; directly. Parameters; ----------; {common_plot_args}; {groupby_plots_args}; {show_save_ax}; {vminmax}; kwds; Are passed to :func:`matplotlib.pyplot.pcolor`. Returns; -------; If `return_fig` is `True`, returns a :class:`~scanpy.pl.MatrixPlot` object,; else if `show` is false, return axes dict. See also; --------; :class:`~scanpy.pl.MatrixPlot`: The MatrixPlot class can be used to to control; several visual parameters not available in this function.; :func:`~scanpy.pl.rank_genes_groups_matrixplot`: to plot marker genes; identified using the :func:`~scanpy.tl.rank_genes_groups` function. Examples; --------. .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); markers = ['C1QA', 'PSAP', 'CD79A', 'CD79B', 'CST3', 'LYZ']; sc.pl.matrixplot(adata, markers, groupby='bulk_labels', dendrogram=True). Using var_names as dict:. .. plot::; :context: close-figs. markers = {{'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}}; sc.pl.matrixplot(adata, markers, groupby='bulk_labels', dendrogram=True). Get Matrix object for fine tuning:. .. plot::; :context: close-figs. mp = sc.pl.matrixplot(adata, markers, 'bulk_labels', return_fig=True); mp.add_totals().style(edge_color='black').show(). The axes used can be obtained using the get_axes() method. .. plot::; :context: close-figs. axes_dict = mp.get_axes(); """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_matrixplot.py:119,interface,interface,119,src/scanpy/plotting/_matrixplot.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_matrixplot.py,1,['interface'],['interface']
Integrability,"""""""\; Deep count autoencoder :cite:p:`Eraslan2019`. Fits a count autoencoder to the raw count data given in the anndata object; in order to denoise the data and to capture hidden representation of; cells in low dimensions. Type of the autoencoder and return values are; determined by the parameters. .. note::; More information and bug reports `here <https://github.com/theislab/dca>`__. Parameters; ----------; adata; An anndata file with `.raw` attribute representing raw counts.; mode; `denoise` overwrites `adata.X` with denoised expression values.; In `latent` mode DCA adds `adata.obsm['X_dca']` to given adata; object. This matrix represent latent representation of cells via DCA.; ae_type; Type of the autoencoder. Return values and the architecture is; determined by the type e.g. `nb` does not provide dropout; probabilities. Types that end with ""-conddisp"", assumes that dispersion is mean dependant.; normalize_per_cell; If true, library size normalization is performed using; the `sc.pp.normalize_per_cell` function in Scanpy and saved into adata; object. Mean layer is re-introduces library size differences by; scaling the mean value of each cell in the output layer. See the; manuscript for more details.; scale; If true, the input of the autoencoder is centered using; `sc.pp.scale` function of Scanpy. Note that the output is kept as raw; counts as loss functions are designed for the count data.; log1p; If true, the input of the autoencoder is log transformed with a; pseudocount of one using `sc.pp.log1p` function of Scanpy.; hidden_size; Width of hidden layers.; hidden_dropout; Probability of weight dropout in the autoencoder (per layer if list; or tuple).; batchnorm; If true, batch normalization is performed.; activation; Activation function of hidden layers.; init; Initialization method used to initialize weights.; network_kwds; Additional keyword arguments for the autoencoder.; epochs; Number of total epochs in training.; reduce_lr; Reduces learning rate if validatio",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_dca.py:901,depend,dependant,901,src/scanpy/external/pp/_dca.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_dca.py,1,['depend'],['dependant']
Integrability,"""""""\; Extract highly variable genes :cite:p:`Satija2015,Zheng2017`. .. warning::; .. deprecated:: 1.3.6; Use :func:`~scanpy.pp.highly_variable_genes`; instead. The new function is equivalent to the present; function, except that. * the new function always expects logarithmized data; * `subset=False` in the new function, it suffices to; merely annotate the genes, tools like `pp.pca` will; detect the annotation; * you can now call: `sc.pl.highly_variable_genes(adata)`; * `copy` is replaced by `inplace`. If trying out parameters, pass the data matrix instead of AnnData. Depending on `flavor`, this reproduces the R-implementations of Seurat; :cite:p:`Satija2015` and Cell Ranger :cite:p:`Zheng2017`. The normalized dispersion is obtained by scaling with the mean and standard; deviation of the dispersions for genes falling into a given bin for mean; expression of genes. This means that for each bin of mean expression, highly; variable genes are selected. Use `flavor='cell_ranger'` with care and in the same way as in; :func:`~scanpy.pp.recipe_zheng17`. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; flavor; Choose the flavor for computing normalized dispersion. If choosing; 'seurat', this expects non-logarithmized data – the logarithm of mean; and dispersion is taken internally when `log` is at its default value; `True`. For 'cell_ranger', this is usually called for logarithmized data; – in this case you should set `log` to `False`. In their default; workflows, Seurat passes the cutoffs whereas Cell Ranger passes; `n_top_genes`.; min_mean; max_mean; min_disp; max_disp; If `n_top_genes` unequals `None`, these cutoffs for the means and the; normalized dispersions are ignored.; n_bins; Number of bins for binning the mean gene expression. Normalization is; done with respect to each bin. If just a single gene falls into a bin,; the normalized dispersion is artificially set to 1. You'll be info",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py:574,Depend,Depending,574,src/scanpy/preprocessing/_deprecated/highly_variable_genes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py,1,['Depend'],['Depending']
Integrability,"""""""\; Filter cell outliers based on counts and numbers of genes expressed. For instance, only keep cells with at least `min_counts` counts or; `min_genes` genes expressed. This is to filter measurement outliers,; i.e. “unreliable” observations. Only provide one of the optional parameters `min_counts`, `min_genes`,; `max_counts`, `max_genes` per call. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; min_counts; Minimum number of counts required for a cell to pass filtering.; min_genes; Minimum number of genes expressed required for a cell to pass filtering.; max_counts; Maximum number of counts required for a cell to pass filtering.; max_genes; Maximum number of genes expressed required for a cell to pass filtering.; inplace; Perform computation inplace or return result. Returns; -------; Depending on `inplace`, returns the following arrays or directly subsets; and annotates the data matrix:. cells_subset; Boolean index mask that does filtering. `True` means that the; cell is kept. `False` means the cell is removed.; number_per_cell; Depending on what was thresholded (`counts` or `genes`),; the array stores `n_counts` or `n_cells` per gene. Examples; --------; >>> import scanpy as sc; >>> adata = sc.datasets.krumsiek11(); UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; utils.warn_names_duplicates(""obs""); >>> adata.obs_names_make_unique(); >>> adata.n_obs; 640; >>> adata.var_names.tolist() # doctest: +NORMALIZE_WHITESPACE; ['Gata2', 'Gata1', 'Fog1', 'EKLF', 'Fli1', 'SCL',; 'Cebpa', 'Pu.1', 'cJun', 'EgrNab', 'Gfi1']; >>> # add some true zeros; >>> adata.X[adata.X < 0.3] = 0; >>> # simply compute the number of genes per cell; >>> sc.pp.filter_cells(adata, min_genes=0); >>> adata.n_obs; 640; >>> adata.obs['n_genes'].min(); 1; >>> # filter manually; >>> adata_copy = adata[adata.obs['n_genes'] >= 3]; >>> adata_copy.n_obs; 554; >>> adata_",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:886,Depend,Depending,886,src/scanpy/preprocessing/_simple.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py,1,['Depend'],['Depending']
Integrability,"""""""\; Filter genes based on number of cells or counts. Keep genes that have at least `min_counts` counts or are expressed in at; least `min_cells` cells or have at most `max_counts` counts or are expressed; in at most `max_cells` cells. Only provide one of the optional parameters `min_counts`, `min_cells`,; `max_counts`, `max_cells` per call. Parameters; ----------; data; An annotated data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; min_counts; Minimum number of counts required for a gene to pass filtering.; min_cells; Minimum number of cells expressed required for a gene to pass filtering.; max_counts; Maximum number of counts required for a gene to pass filtering.; max_cells; Maximum number of cells expressed required for a gene to pass filtering.; inplace; Perform computation inplace or return result. Returns; -------; Depending on `inplace`, returns the following arrays or directly subsets; and annotates the data matrix. gene_subset; Boolean index mask that does filtering. `True` means that the; gene is kept. `False` means the gene is removed.; number_per_gene; Depending on what was thresholded (`counts` or `cells`), the array stores; `n_counts` or `n_cells` per gene.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:875,Depend,Depending,875,src/scanpy/preprocessing/_simple.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py,2,['Depend'],['Depending']
Integrability,"""""""\; Get enrichment for DE results. This is a thin convenience wrapper around the very useful gprofiler_. This method dispatches on the first argument, leading to the following two; signatures::. enrich(container, ...); enrich(adata: AnnData, group, key: str, ...). Where::. enrich(adata, group, key, ...) = enrich(adata.uns[key][""names""][group], ...). .. _gprofiler: https://pypi.org/project/gprofiler-official/#description. Parameters; ----------; container; Contains list of genes you'd like to search. If container is a `dict` all; enrichment queries are made at once.; adata; AnnData object whose group will be looked for.; group; The group whose genes should be used for enrichment.; key; Key in `uns` to find group under.; {doc_org}; gprofiler_kwargs; Keyword arguments to pass to `GProfiler.profile`, see gprofiler_. Some; useful options are `no_evidences=False` which reports gene intersections,; `sources=['GO:BP']` which limits gene sets to only GO biological processes and; `all_results=True` which returns all results including the non-significant ones.; **kwargs; All other keyword arguments are passed to `sc.get.rank_genes_groups_df`. E.g.; pval_cutoff, log2fc_min. Returns; -------; Dataframe of enrichment results. Examples; --------; Using `sc.queries.enrich` on a list of genes:. >>> import scanpy as sc; >>> sc.queries.enrich(['KLF4', 'PAX5', 'SOX2', 'NANOG'], org=""hsapiens""); >>> sc.queries.enrich({{'set1':['KLF4', 'PAX5'], 'set2':['SOX2', 'NANOG']}}, org=""hsapiens""). Using `sc.queries.enrich` on an :class:`anndata.AnnData` object:. >>> pbmcs = sc.datasets.pbmc68k_reduced(); >>> sc.tl.rank_genes_groups(pbmcs, ""bulk_labels""); >>> sc.queries.enrich(pbmcs, ""CD34+""); """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/queries/_queries.py:64,wrap,wrapper,64,src/scanpy/queries/_queries.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/queries/_queries.py,1,['wrap'],['wrapper']
Integrability,"""""""\; Hierarchically-clustered heatmap. Wraps :func:`seaborn.clustermap` for :class:`~anndata.AnnData`. Parameters; ----------; adata; Annotated data matrix.; obs_keys; Categorical annotation to plot with a different color map.; Currently, only a single key is supported.; use_raw; Whether to use `raw` attribute of `adata`. Defaults to `True` if `.raw` is present.; {show_save_ax}; **kwds; Keyword arguments passed to :func:`~seaborn.clustermap`. Returns; -------; If `show` is `False`, a :class:`~seaborn.matrix.ClusterGrid` object; (see :func:`~seaborn.clustermap`). Examples; --------. .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.krumsiek11(); sc.pl.clustermap(adata). .. plot::; :context: close-figs. sc.pl.clustermap(adata, obs_keys='cell_type'); """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py:40,Wrap,Wraps,40,src/scanpy/plotting/_anndata.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py,1,['Wrap'],['Wraps']
Integrability,"""""""\; Iteratively compute the conditional posterior means for gamma and delta. gamma is an estimator for the additive batch effect, deltat is an estimator; for the multiplicative batch effect. We use an EB framework to estimate these; two. Analytical expressions exist for both parameters, which however depend on each other.; We therefore iteratively evalutate these two expressions until convergence is reached. Parameters; --------; s_data; Contains the standardized Data; g_hat; Initial guess for gamma; d_hat; Initial guess for delta; g_bar, t2, a, b; Hyperparameters; conv: float, optional (default: `0.0001`); convergence criterium. Returns:; --------; gamma; estimated value for gamma; delta; estimated value for delta; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_combat.py:304,depend,depend,304,src/scanpy/preprocessing/_combat.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_combat.py,1,['depend'],['depend']
Integrability,"""""""\; Log message with specific level and return current time. Parameters; ----------; msg; Message to display.; time; A time in the past. If this is passed, the time difference from then; to now is appended to `msg` as ` (HH:MM:SS)`.; If `msg` contains `{time_passed}`, the time difference is instead; inserted at that position.; deep; If the current verbosity is higher than the log function’s level,; this gets displayed as well; extra; Additional values you can specify in `msg` like `{time_passed}`.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/logging.py:10,message,message,10,src/scanpy/logging.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/logging.py,2,"['Message', 'message']","['Message', 'message']"
Integrability,"""""""\; Logarithmize the data matrix. Computes :math:`X = \\log(X + 1)`,; where :math:`log` denotes the natural logarithm unless a different base is given. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; base; Base of the logarithm. Natural logarithm is used by default.; copy; If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned.; chunked; Process the data matrix in chunks, which will save memory.; Applies only to :class:`~anndata.AnnData`.; chunk_size; `n_obs` of the chunks to process the data in.; layer; Entry of layers to transform.; obsm; Entry of obsm to transform. Returns; -------; Returns or updates `data`, depending on `copy`.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:737,depend,depending,737,src/scanpy/preprocessing/_simple.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py,1,['depend'],['depending']
Integrability,"""""""\; Makes a *dot plot* of the expression values of `var_names`. For each var_name and each `groupby` category a dot is plotted.; Each dot represents two values: mean expression within each category; (visualized by color) and fraction of cells expressing the `var_name` in the; category (visualized by the size of the dot). If `groupby` is not given,; the dotplot assumes that all data belongs to a single category. .. note::; A gene is considered expressed if the expression value in the `adata` (or; `adata.raw`) is above the specified threshold which is zero by default. An example of dotplot usage is to visualize, for multiple marker genes,; the mean value and the percentage of cells expressing the gene; across multiple clusters. This function provides a convenient interface to the :class:`~scanpy.pl.DotPlot`; class. If you need more flexibility, you should use :class:`~scanpy.pl.DotPlot`; directly. Parameters; ----------; {common_plot_args}; {groupby_plots_args}; size_title; Title for the size legend. New line character (\\n) can be used.; expression_cutoff; Expression cutoff that is used for binarizing the gene expression and; determining the fraction of cells expressing given genes. A gene is; expressed only if the expression value is greater than this threshold.; mean_only_expressed; If True, gene expression is averaged only over the cells; expressing the given genes.; dot_max; If none, the maximum dot size is set to the maximum fraction value found; (e.g. 0.6). If given, the value should be a number between 0 and 1.; All fractions larger than dot_max are clipped to this value.; dot_min; If none, the minimum dot size is set to 0. If given,; the value should be a number between 0 and 1.; All fractions smaller than dot_min are clipped to this value.; smallest_dot; If none, the smallest dot has size 0.; All expression levels with `dot_min` are plotted with this size.; {show_save_ax}; {vminmax}; kwds; Are passed to :func:`matplotlib.pyplot.scatter`. Returns; -------; I",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_dotplot.py:774,interface,interface,774,src/scanpy/plotting/_dotplot.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_dotplot.py,1,['interface'],['interface']
Integrability,"""""""\; Map labels and embeddings from reference data to new data. :doc:`/tutorials/basics/integrating-data-using-ingest`. Integrates embeddings and annotations of an `adata` with a reference dataset; `adata_ref` through projecting on a PCA (or alternate; model) that has been fitted on the reference data. The function uses a knn; classifier for mapping labels and the UMAP package :cite:p:`McInnes2018` for mapping; the embeddings. .. note::. We refer to this *asymmetric* dataset integration as *ingesting*; annotations from reference data to new data. This is different from; learning a joint representation that integrates both datasets in an; unbiased way, as CCA (e.g. in Seurat) or a conditional VAE (e.g. in; scVI) would do. You need to run :func:`~scanpy.pp.neighbors` on `adata_ref` before; passing it. Parameters; ----------; adata; The annotated data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes. This is the dataset without labels and; embeddings.; adata_ref; The annotated data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; Variables (`n_vars` and `var_names`) of `adata_ref` should be the same; as in `adata`.; This is the dataset with labels and embeddings; which need to be mapped to `adata`.; obs; Labels' keys in `adata_ref.obs` which need to be mapped to `adata.obs`; (inferred for observation of `adata`).; embedding_method; Embeddings in `adata_ref` which need to be mapped to `adata`.; The only supported values are 'umap' and 'pca'.; labeling_method; The method to map labels in `adata_ref.obs` to `adata.obs`.; The only supported value is 'knn'.; neighbors_key; If not specified, ingest looks adata_ref.uns['neighbors']; for neighbors settings and adata_ref.obsp['distances'] for; distances (default storage places for pp.neighbors).; If specified, ingest looks adata_ref.uns[neighbors_key] for; neighbors settings and; adata_ref.obsp[adata_ref.uns[neighbors_key]['distances_key']] for distances.; in",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_ingest.py:89,integrat,integrating-data-using-ingest,89,src/scanpy/tools/_ingest.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_ingest.py,4,"['Integrat', 'integrat']","['Integrates', 'integrates', 'integrating-data-using-ingest', 'integration']"
Integrability,"""""""\; Normalization and filtering as of :cite:t:`Zheng2017`. Reproduces the preprocessing of :cite:t:`Zheng2017` – the Cell Ranger R Kit of 10x; Genomics. Expects non-logarithmized data.; If using logarithmized data, pass `log=False`. The recipe runs the following steps. .. code:: python. sc.pp.filter_genes(adata, min_counts=1) # only consider genes with more than 1 count; sc.pp.normalize_per_cell( # normalize with total UMI count per cell; adata, key_n_counts='n_counts_all'; ); filter_result = sc.pp.filter_genes_dispersion( # select highly-variable genes; adata.X, flavor='cell_ranger', n_top_genes=n_top_genes, log=False; ); adata = adata[:, filter_result.gene_subset] # subset the genes; sc.pp.normalize_per_cell(adata) # renormalize after filtering; if log: sc.pp.log1p(adata) # log transform: adata.X = log(adata.X + 1); sc.pp.scale(adata) # scale to unit variance and shift to zero mean. Parameters; ----------; adata; Annotated data matrix.; n_top_genes; Number of genes to keep.; log; Take logarithm.; plot; Show a plot of the gene dispersion vs. mean relation.; copy; Return a copy of `adata` instead of updating it. Returns; -------; Returns or updates `adata` depending on `copy`.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py:1177,depend,depending,1177,src/scanpy/preprocessing/_recipes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py,1,['depend'],['depending']
Integrability,"""""""\; PHATE :cite:p:`Moon2019`. Potential of Heat-diffusion for Affinity-based Trajectory Embedding (PHATE); embeds high dimensional single-cell data into two or three dimensions for; visualization of biological progressions. For more information and access to the object-oriented interface, read the; `PHATE documentation <https://phate.readthedocs.io/>`__. For; tutorials, bug reports, and R/MATLAB implementations, visit the `PHATE; GitHub page <https://github.com/KrishnaswamyLab/PHATE/>`__. For help; using PHATE, go `here <https://krishnaswamylab.org/get-help>`__. Parameters; ----------; adata; Annotated data matrix.; n_components; number of dimensions in which the data will be embedded; k; number of nearest neighbors on which to build kernel; a; sets decay rate of kernel tails.; If None, alpha decaying kernel is not used; n_landmark; number of landmarks to use in fast PHATE; t; power to which the diffusion operator is powered; sets the level of diffusion. If 'auto', t is selected; according to the knee point in the Von Neumann Entropy of; the diffusion operator; gamma; Informational distance constant between -1 and 1.; `gamma=1` gives the PHATE log potential, `gamma=0` gives; a square root potential.; n_pca; Number of principal components to use for calculating; neighborhoods. For extremely large datasets, using; n_pca < 20 allows neighborhoods to be calculated in; log(n_samples) time.; knn_dist; recommended values: 'euclidean' and 'cosine'; Any metric from `scipy.spatial.distance` can be used; distance metric for building kNN graph; mds_dist; recommended values: 'euclidean' and 'cosine'; Any metric from `scipy.spatial.distance` can be used; distance metric for MDS; mds; Selects which MDS algorithm is used for dimensionality reduction.; n_jobs; The number of jobs to use for the computation.; If `None`, `sc.settings.n_jobs` is used.; If -1 all CPUs are used. If 1 is given, no parallel computing code is; used at all, which is useful for debugging.; For n_jobs below -1",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phate.py:281,interface,interface,281,src/scanpy/external/tl/_phate.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phate.py,1,['interface'],['interface']
Integrability,"""""""\; Predict doublets using Scrublet :cite:p:`Wolock2019`. Predict cell doublets using a nearest-neighbor classifier of observed; transcriptomes and simulated doublets. Works best if the input is a raw; (unnormalized) counts matrix from a single sample or a collection of; similar samples from the same experiment.; This function is a wrapper around functions that pre-process using Scanpy; and directly call functions of Scrublet(). You may also undertake your own; preprocessing, simulate doublets with; :func:`~scanpy.pp.scrublet_simulate_doublets`, and run the core scrublet; function :func:`~scanpy.pp.scrublet` with ``adata_sim`` set. Parameters; ----------; adata; The annotated data matrix of shape ``n_obs`` × ``n_vars``. Rows; correspond to cells and columns to genes. Expected to be un-normalised; where adata_sim is not supplied, in which case doublets will be; simulated and pre-processing applied to both objects. If adata_sim is; supplied, this should be the observed transcriptomes processed; consistently (filtering, transform, normalisaton, hvg) with adata_sim.; adata_sim; (Advanced use case) Optional annData object generated by; :func:`~scanpy.pp.scrublet_simulate_doublets`, with same number of vars; as adata. This should have been built from adata_obs after; filtering genes and cells and selcting highly-variable genes.; batch_key; Optional :attr:`~anndata.AnnData.obs` column name discriminating between batches.; sim_doublet_ratio; Number of doublets to simulate relative to the number of observed; transcriptomes.; expected_doublet_rate; Where adata_sim not suplied, the estimated doublet rate for the; experiment.; stdev_doublet_rate; Where adata_sim not suplied, uncertainty in the expected doublet rate.; synthetic_doublet_umi_subsampling; Where adata_sim not suplied, rate for sampling UMIs when creating; synthetic doublets. If 1.0, each doublet is created by simply adding; the UMI counts from two randomly sampled observed transcriptomes. For; values less than 1, t",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py:336,wrap,wrapper,336,src/scanpy/preprocessing/_scrublet/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py,1,['wrap'],['wrapper']
Integrability,"""""""\; See `highly_variable_genes`. For further implementation details see https://www.overleaf.com/read/ckptrbgzzzpg. Returns; -------; Depending on `inplace` returns calculated metrics (:class:`~pd.DataFrame`) or; updates `.var` with the following fields:. highly_variable : :class:`bool`; boolean indicator of highly-variable genes.; **means**; means per gene.; **variances**; variance per gene.; **variances_norm**; normalized variance per gene, averaged in the case of multiple batches.; highly_variable_rank : :class:`float`; Rank of the gene according to normalized variance, median rank in the case of multiple batches.; highly_variable_nbatches : :class:`int`; If batch_key is given, this denotes in how many batches genes are detected as HVG.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py:136,Depend,Depending,136,src/scanpy/preprocessing/_highly_variable_genes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py,1,['Depend'],['Depending']
Integrability,"""""""\; Simulate data given only an adjacancy matrix and a model. The model is a bivariate funtional dependence. The adjacancy matrix; needs to be acyclic. Parameters; ----------; Adj; adjacancy matrix of shape (dim,dim). Returns; -------; Data array of shape (n_samples,dim).; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:99,depend,dependence,99,src/scanpy/tools/_sim.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py,1,['depend'],['dependence']
Integrability,"""""""\; Square root the data matrix. Computes :math:`X = \\sqrt(X)`. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; copy; If an :class:`~anndata.AnnData` object is passed,; determines whether a copy is returned.; chunked; Process the data matrix in chunks, which will save memory.; Applies only to :class:`~anndata.AnnData`.; chunk_size; `n_obs` of the chunks to process the data in. Returns; -------; Returns or updates `data`, depending on `copy`.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:516,depend,depending,516,src/scanpy/preprocessing/_simple.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py,1,['depend'],['depending']
Integrability,"""""""\; Stacked violin plots. Makes a compact image composed of individual violin plots; (from :func:`~seaborn.violinplot`) stacked on top of each other.; Useful to visualize gene expression per cluster. Wraps :func:`seaborn.violinplot` for :class:`~anndata.AnnData`. Parameters; ----------; {common_plot_args}; title; Title for the figure; stripplot; Add a stripplot on top of the violin plot.; See :func:`~seaborn.stripplot`.; jitter; Add jitter to the stripplot (only when stripplot is True); See :func:`~seaborn.stripplot`.; size; Size of the jitter points.; order; Order in which to show the categories. Note: if `dendrogram=True`; the categories order will be given by the dendrogram and `order`; will be ignored.; density_norm; The method used to scale the width of each violin.; If 'width' (the default), each violin will have the same width.; If 'area', each violin will have the same area.; If 'count', a violin’s width corresponds to the number of observations.; row_palette; The row palette determines the colors to use for the stacked violins.; The value should be a valid seaborn or matplotlib palette name; (see :func:`~seaborn.color_palette`).; Alternatively, a single color name or hex value can be passed,; e.g. `'red'` or `'#cc33ff'`.; standard_scale; Whether or not to standardize a dimension between 0 and 1,; meaning for each variable or observation,; subtract the minimum and divide each by its maximum.; swap_axes; By default, the x axis contains `var_names` (e.g. genes) and the y axis; the `groupby` categories. By setting `swap_axes` then x are the `groupby`; categories and y the `var_names`. When swapping; axes var_group_positions are no longer used; kwds; Are passed to :func:`~seaborn.violinplot`. See also; --------; :func:`~scanpy.pl.stacked_violin`: simpler way to call StackedViolin but with less; options.; :func:`~scanpy.pl.violin` and :func:`~scanpy.pl.rank_genes_groups_stacked_violin`:; to plot marker genes identified using :func:`~scanpy.tl.rank_genes_groups`.",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_stacked_violin.py:202,Wrap,Wraps,202,src/scanpy/plotting/_stacked_violin.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_stacked_violin.py,1,['Wrap'],['Wraps']
Integrability,"""""""\; Stacked violin plots. Makes a compact image composed of individual violin plots; (from :func:`~seaborn.violinplot`) stacked on top of each other.; Useful to visualize gene expression per cluster. Wraps :func:`seaborn.violinplot` for :class:`~anndata.AnnData`. This function provides a convenient interface to the; :class:`~scanpy.pl.StackedViolin` class. If you need more flexibility,; you should use :class:`~scanpy.pl.StackedViolin` directly. Parameters; ----------; {common_plot_args}; {groupby_plots_args}; stripplot; Add a stripplot on top of the violin plot.; See :func:`~seaborn.stripplot`.; jitter; Add jitter to the stripplot (only when stripplot is True); See :func:`~seaborn.stripplot`.; size; Size of the jitter points.; order; Order in which to show the categories. Note: if `dendrogram=True`; the categories order will be given by the dendrogram and `order`; will be ignored.; scale; The method used to scale the width of each violin.; If 'width' (the default), each violin will have the same width.; If 'area', each violin will have the same area.; If 'count', a violin’s width corresponds to the number of observations.; yticklabels; Set to true to view the y tick labels.; row_palette; Be default, median values are mapped to the violin color using a; color map (see `cmap` argument). Alternatively, a 'row_palette` can; be given to color each violin plot row using a different colors.; The value should be a valid seaborn or matplotlib palette name; (see :func:`~seaborn.color_palette`).; Alternatively, a single color name or hex value can be passed,; e.g. `'red'` or `'#cc33ff'`.; {show_save_ax}; {vminmax}; kwds; Are passed to :func:`~seaborn.violinplot`. Returns; -------; If `return_fig` is `True`, returns a :class:`~scanpy.pl.StackedViolin` object,; else if `show` is false, return axes dict. See also; --------; :class:`~scanpy.pl.StackedViolin`: The StackedViolin class can be used to to control; several visual parameters not available in this function.; :func:`~scan",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_stacked_violin.py:202,Wrap,Wraps,202,src/scanpy/plotting/_stacked_violin.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_stacked_violin.py,2,"['Wrap', 'interface']","['Wraps', 'interface']"
Integrability,"""""""\; TriMap: Large-scale Dimensionality Reduction Using Triplets :cite:p:`Amid2019`. TriMap is a dimensionality reduction method that uses triplet constraints; to form a low-dimensional embedding of a set of points. The triplet; constraints are of the form ""point i is closer to point j than point k"".; The triplets are sampled from the high-dimensional representation of the; points and a weighting scheme is used to reflect the importance of each; triplet. TriMap provides a significantly better global view of the data than the; other dimensionality reduction methods such t-SNE, LargeVis, and UMAP.; The global structure includes relative distances of the clusters, multiple; scales in the data, and the existence of possible outliers. We define a; global score to quantify the quality of an embedding in reflecting the; global structure of the data. Parameters; ----------; adata; Annotated data matrix.; n_components; Number of dimensions of the embedding.; n_inliers; Number of inlier points for triplet constraints.; n_outliers; Number of outlier points for triplet constraints.; n_random; Number of random triplet constraints per point.; metric; Distance measure: 'angular', 'euclidean', 'hamming', 'manhattan'.; weight_adj; Adjusting the weights using a non-linear transformation.; lr; Learning rate.; n_iters; Number of iterations.; verbose; If `True`, print the progress report.; If `None`, `sc.settings.verbosity` is used.; copy; Return a copy instead of writing to `adata`. Returns; -------; Depending on `copy`, returns or updates `adata` with the following fields. **X_trimap** : :class:`~numpy.ndarray`, (:attr:`~anndata.AnnData.obsm`, shape=(n_samples, n_components), dtype `float`); TriMap coordinates of data. Example; -------. >>> import scanpy as sc; >>> import scanpy.external as sce; >>> pbmc = sc.datasets.pbmc68k_reduced(); >>> pbmc = sce.tl.trimap(pbmc, copy=True); >>> sce.pl.trimap(pbmc, color=['bulk_labels'], s=10); """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_trimap.py:1507,Depend,Depending,1507,src/scanpy/external/tl/_trimap.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_trimap.py,1,['Depend'],['Depending']
Integrability,"""""""\; Use Scanorama :cite:p:`Hie2019` to integrate different experiments. Scanorama :cite:p:`Hie2019` is an algorithm for integrating single-cell; data from multiple experiments stored in an AnnData object. This; function should be run after performing PCA but before computing; the neighbor graph, as illustrated in the example below. This uses the implementation of scanorama_ :cite:p:`Hie2019`. .. _scanorama: https://github.com/brianhie/scanorama. Parameters; ----------; adata; The annotated data matrix.; key; The name of the column in ``adata.obs`` that differentiates; among experiments/batches. Cells from the same batch must be; contiguously stored in ``adata``.; basis; The name of the field in ``adata.obsm`` where the PCA table is; stored. Defaults to ``'X_pca'``, which is the default for; ``sc.pp.pca()``.; adjusted_basis; The name of the field in ``adata.obsm`` where the integrated; embeddings will be stored after running this function. Defaults; to ``X_scanorama``.; knn; Number of nearest neighbors to use for matching.; sigma; Correction smoothing parameter on Gaussian kernel.; approx; Use approximate nearest neighbors with Python ``annoy``;; greatly speeds up matching runtime.; alpha; Alignment score minimum cutoff.; batch_size; The batch size used in the alignment vector computation. Useful; when integrating very large (>100k samples) datasets. Set to; large value that runs within available memory.; kwargs; Any additional arguments will be passed to; ``scanorama.assemble()``. Returns; -------; Updates adata with the field ``adata.obsm[adjusted_basis]``,; containing Scanorama embeddings such that different experiments; are integrated. Example; -------; First, load libraries and example dataset, and preprocess. >>> import scanpy as sc; >>> import scanpy.external as sce; >>> adata = sc.datasets.pbmc3k(); >>> sc.pp.recipe_zheng17(adata); >>> sc.pp.pca(adata). We now arbitrarily assign a batch metadata variable to each cell; for the sake of example, but during real",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py:41,integrat,integrate,41,src/scanpy/external/pp/_scanorama_integrate.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py,3,['integrat'],"['integrate', 'integrated', 'integrating']"
Integrability,"""""""\; Use harmonypy :cite:p:`Korsunsky2019` to integrate different experiments. Harmony :cite:p:`Korsunsky2019` is an algorithm for integrating single-cell; data from multiple experiments. This function uses the python; port of Harmony, ``harmonypy``, to integrate single-cell data; stored in an AnnData object. As Harmony works by adjusting the; principal components, this function should be run after performing; PCA but before computing the neighbor graph, as illustrated in the; example below. Parameters; ----------; adata; The annotated data matrix.; key; The name of the column in ``adata.obs`` that differentiates; among experiments/batches.; basis; The name of the field in ``adata.obsm`` where the PCA table is; stored. Defaults to ``'X_pca'``, which is the default for; ``sc.pp.pca()``.; adjusted_basis; The name of the field in ``adata.obsm`` where the adjusted PCA; table will be stored after running this function. Defaults to; ``X_pca_harmony``.; kwargs; Any additional arguments will be passed to; ``harmonypy.run_harmony()``. Returns; -------; Updates adata with the field ``adata.obsm[obsm_out_field]``,; containing principal components adjusted by Harmony such that; different experiments are integrated. Example; -------; First, load libraries and example dataset, and preprocess. >>> import scanpy as sc; >>> import scanpy.external as sce; >>> adata = sc.datasets.pbmc3k(); >>> sc.pp.recipe_zheng17(adata); >>> sc.pp.pca(adata). We now arbitrarily assign a batch metadata variable to each cell; for the sake of example, but during real usage there would already; be a column in ``adata.obs`` giving the experiment each cell came; from. >>> adata.obs['batch'] = 1350*['a'] + 1350*['b']. Finally, run harmony. Afterwards, there will be a new table in; ``adata.obsm`` containing the adjusted PC's. >>> sce.pp.harmony_integrate(adata, 'batch'); >>> 'X_pca_harmony' in adata.obsm; True; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_harmony_integrate.py:47,integrat,integrate,47,src/scanpy/external/pp/_harmony_integrate.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_harmony_integrate.py,4,['integrat'],"['integrate', 'integrated', 'integrating']"
Integrability,"""""""\; Versions that might influence the numerical results.; Matplotlib and Seaborn are excluded from this. Parameters; ----------; file; Optional path for dependency output.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/logging.py:155,depend,dependency,155,src/scanpy/logging.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/logging.py,1,['depend'],['dependency']
Integrability,"""""""\; Violin plot. Wraps :func:`seaborn.violinplot` for :class:`~anndata.AnnData`. Parameters; ----------; adata; Annotated data matrix.; keys; Keys for accessing variables of `.var_names` or fields of `.obs`.; groupby; The key of the observation grouping to consider.; log; Plot on logarithmic axis.; use_raw; Whether to use `raw` attribute of `adata`. Defaults to `True` if `.raw` is present.; stripplot; Add a stripplot on top of the violin plot.; See :func:`~seaborn.stripplot`.; jitter; Add jitter to the stripplot (only when stripplot is True); See :func:`~seaborn.stripplot`.; size; Size of the jitter points.; layer; Name of the AnnData object layer that wants to be plotted. By; default adata.raw.X is plotted. If `use_raw=False` is set,; then `adata.X` is plotted. If `layer` is set to a valid layer name,; then the layer is plotted. `layer` takes precedence over `use_raw`.; scale; The method used to scale the width of each violin.; If 'width' (the default), each violin will have the same width.; If 'area', each violin will have the same area.; If 'count', a violin’s width corresponds to the number of observations.; order; Order in which to show the categories.; multi_panel; Display keys in multiple panels also when `groupby is not None`.; xlabel; Label of the x axis. Defaults to `groupby` if `rotation` is `None`,; otherwise, no label is shown.; ylabel; Label of the y axis. If `None` and `groupby` is `None`, defaults; to `'value'`. If `None` and `groubpy` is not `None`, defaults to `keys`.; rotation; Rotation of xtick labels.; {show_save_ax}; **kwds; Are passed to :func:`~seaborn.violinplot`. Returns; -------; A :class:`~matplotlib.axes.Axes` object if `ax` is `None` else `None`. Examples; --------. .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); sc.pl.violin(adata, keys='S_score'). Plot by category. Rotate x-axis labels so that they do not overlap. .. plot::; :context: close-figs. sc.pl.violin(adata, keys='S_score', groupby",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py:19,Wrap,Wraps,19,src/scanpy/plotting/_anndata.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py,1,['Wrap'],['Wraps']
Integrability,"""""""\; adata; Annotated data matrix.; var_names; `var_names` should be a valid subset of `adata.var_names`.; If `var_names` is a mapping, then the key is used as label; to group the values (see `var_group_labels`). The mapping values; should be sequences of valid `adata.var_names`. In this; case either coloring or 'brackets' are used for the grouping; of var names depending on the plot. When `var_names` is a mapping,; then the `var_group_labels` and `var_group_positions` are set.; groupby; The key of the observation grouping to consider.; use_raw; Use `raw` attribute of `adata` if present.; log; Plot on logarithmic axis.; num_categories; Only used if groupby observation is not categorical. This value; determines the number of groups into which the groupby observation; should be subdivided.; categories_order; Order in which to show the categories. Note: add_dendrogram or add_totals; can change the categories order.; figsize; Figure size when `multi_panel=True`.; Otherwise the `rcParam['figure.figsize]` value is used.; Format is (width, height); dendrogram; If True or a valid dendrogram key, a dendrogram based on the hierarchical; clustering between the `groupby` categories is added.; The dendrogram information is computed using :func:`scanpy.tl.dendrogram`.; If `tl.dendrogram` has not been called previously the function is called; with default parameters.; gene_symbols; Column name in `.var` DataFrame that stores gene symbols.; By default `var_names` refer to the index column of the `.var` DataFrame.; Setting this option allows alternative names to be used.; var_group_positions; Use this parameter to highlight groups of `var_names`.; This will draw a 'bracket' or a color block between the given start and end; positions. If the parameter `var_group_labels` is set, the corresponding; labels are added on top/left. E.g. `var_group_positions=[(4,10)]`; will add a bracket between the fourth `var_name` and the tenth `var_name`.; By giving more positions, more brackets/color b",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_docs.py:366,depend,depending,366,src/scanpy/plotting/_docs.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_docs.py,1,['depend'],['depending']
Integrability,"""""""\; transforms the dendrogram coordinates to a given new position.; The xlabel_pos and orig_ticks should be of the same; length. This is mostly done for the heatmap case, where the position of the; dendrogram leaves needs to be adjusted depending on the category size. Parameters; ----------; pos_list; list of dendrogram positions that should be translated; new_ticks; sorted list of goal tick positions (e.g. [0,1,2,3] ); old_ticks; sorted list of original tick positions (e.g. [5, 15, 25, 35]),; This list is usually the default position used by; `scipy.cluster.hierarchy.dendrogram`. Returns; -------; translated list of positions. Examples; --------; >>> translate_pos(; ... [5, 15, 20, 21],; ... [0, 1, 2, 3 ],; ... [5, 15, 25, 35],; ... ); [0, 1, 1.5, 1.6]; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py:239,depend,depending,239,src/scanpy/plotting/_anndata.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py,1,['depend'],['depending']
Integrability,"""""""used to clean up warning message""""""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_baseplot_class.py:28,message,message,28,src/scanpy/plotting/_baseplot_class.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_baseplot_class.py,1,['message'],['message']
Integrability,"# Do PCA. Scrublet fits to the observed matrix and decomposes both observed; # and simulated based on that fit, so we'll just let it do its thing rather; # than trying to use Scanpy's PCA wrapper of the same functions.",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py:188,wrap,wrapper,188,src/scanpy/preprocessing/_scrublet/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py,1,['wrap'],['wrapper']
Integrability,"# Doesn't actually copy memory, just removes View class wrapper",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py:56,wrap,wrapper,56,src/scanpy/preprocessing/_highly_variable_genes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py,1,['wrap'],['wrapper']
Integrability,"# If we are referring to other optional dependency lists, resolve them",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/ci/scripts/min-deps.py:40,depend,dependency,40,ci/scripts/min-deps.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/ci/scripts/min-deps.py,1,['depend'],['dependency']
Integrability,"# Integrate.",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py:2,Integrat,Integrate,2,src/scanpy/external/pp/_scanorama_integrate.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py,1,['Integrat'],['Integrate']
Integrability,"# Wrapped in another fixture to avoid mutation",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:2,Wrap,Wrapped,2,tests/test_plotting.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py,1,['Wrap'],['Wrapped']
Integrability,"# depending on check_values, warnings should be raised for non-integer data",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_highly_variable_genes.py:2,depend,depending,2,tests/test_highly_variable_genes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_highly_variable_genes.py,2,['depend'],['depending']
Integrability,"# due to 'update formulation' of model, there; # is always a diagonal dependence",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:70,depend,dependence,70,src/scanpy/tools/_sim.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py,1,['depend'],['dependence']
Integrability,"# this is just a wrapper for the results",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py:17,wrap,wrapper,17,src/scanpy/preprocessing/_pca.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py,1,['wrap'],['wrapper']
Integrability,"# use either black or white for the edge color; # depending on the luminance of the background; # square color",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_dotplot.py:50,depend,depending,50,src/scanpy/plotting/_dotplot.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_dotplot.py,1,['depend'],['depending']
Integrability,"# we place a normally distributed prior on gamma and and inverse gamma prior on delta; # in the loop, gamma and delta are updated together. they depend on each other. we iterate until convergence.",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_combat.py:145,depend,depend,145,src/scanpy/preprocessing/_combat.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_combat.py,1,['depend'],['depend']
Integrability,"###############################################################################; # Interface (taken from gearys C); ###############################################################################",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/metrics/_morans_i.py:83,Interface,Interface,83,src/scanpy/metrics/_morans_i.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/metrics/_morans_i.py,1,['Interface'],['Interface']
Integrability,"###############################################################################; # Interface; ###############################################################################",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/metrics/_gearys_c.py:83,Interface,Interface,83,src/scanpy/metrics/_gearys_c.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/metrics/_gearys_c.py,1,['Interface'],['Interface']
Integrability,"ality reduction; methods are to be used using the SAM-output AnnData, users; should recompute the neighbors using `.obs['X_pca']` with; `scanpy.pp.neighbors`.; `.obsm['X_pca']`; The principal components output by SAM.; `.obsm['X_umap']`; The UMAP projection output by SAM.; `.layers['X_disp']`; The expression matrix used for nearest-neighbor averaging.; `.layers['X_knn_avg']`; The nearest-neighbor-averaged expression data used for computing the; spatial dispersions of genes. Example; -------; >>> import scanpy.external as sce; >>> import scanpy as sc. *** Running SAM ***. Assuming we are given an AnnData object called `adata`, we can run the SAM; algorithm as follows:. >>> sam_obj = sce.tl.sam(adata,inplace=True). The input AnnData object should contain unstandardized, non-negative; expression values. Preferably, the data should be log-normalized and no; genes should be filtered out. Please see the documentation for a description of all available parameters. For more detailed tutorials, please visit the original Github repository:; https://github.com/atarashansky/self-assembling-manifold/tree/master/tutorial. *** Plotting ***. To visualize the output, we can use:. >>> sce.pl.sam(adata,projection='X_umap'). `sce.pl.sam` accepts all keyword arguments used in the; `matplotlib.pyplot.scatter` function. *** SAMGUI ***. SAM comes with the SAMGUI module, a graphical-user interface written with; `Plotly` and `ipythonwidgets` for interactively exploring and annotating; the scRNAseq data and running SAM. Dependencies can be installed with Anaconda by following the instructions in; the self-assembling-manifold Github README:; https://github.com/atarashansky/self-assembling-manifold. In a Jupyter notebook, execute the following to launch the interface:. >>> from samalg.gui import SAMGUI; >>> sam_gui = SAMGUI(sam_obj) # sam_obj is your SAM object; >>> sam_gui.SamPlot. This can also be enabled in Jupyer Lab by following the instructions in the; self-assembling-manifold README. """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_sam.py:4917,interface,interface,4917,src/scanpy/external/tl/_sam.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_sam.py,3,"['Depend', 'interface']","['Dependencies', 'interface']"
Integrability,"anger'` with care and in the same way as in; :func:`~scanpy.pp.recipe_zheng17`. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; flavor; Choose the flavor for computing normalized dispersion. If choosing; 'seurat', this expects non-logarithmized data – the logarithm of mean; and dispersion is taken internally when `log` is at its default value; `True`. For 'cell_ranger', this is usually called for logarithmized data; – in this case you should set `log` to `False`. In their default; workflows, Seurat passes the cutoffs whereas Cell Ranger passes; `n_top_genes`.; min_mean; max_mean; min_disp; max_disp; If `n_top_genes` unequals `None`, these cutoffs for the means and the; normalized dispersions are ignored.; n_bins; Number of bins for binning the mean gene expression. Normalization is; done with respect to each bin. If just a single gene falls into a bin,; the normalized dispersion is artificially set to 1. You'll be informed; about this if you set `settings.verbosity = 4`.; n_top_genes; Number of highly-variable genes to keep.; log; Use the logarithm of the mean to variance ratio.; subset; Keep highly-variable genes only (if True) else write a bool array for h; ighly-variable genes while keeping all genes; copy; If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned. Returns; -------; If an AnnData `adata` is passed, returns or updates `adata` depending on; `copy`. It filters the `adata` and adds the annotations. **means** : adata.var; Means per gene. Logarithmized when `log` is `True`.; **dispersions** : adata.var; Dispersions per gene. Logarithmized when `log` is `True`.; **dispersions_norm** : adata.var; Normalized dispersions per gene. Logarithmized when `log` is `True`. If a data matrix `X` is passed, the annotation is returned as `np.recarray`; with the same information stored in fields: `gene_subset`, `means`, `dispersions`, `dispersion_norm`.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py:2460,depend,depending,2460,src/scanpy/preprocessing/_deprecated/highly_variable_genes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py,1,['depend'],['depending']
Integrability,"d. This is to filter measurement outliers,; i.e. “unreliable” observations. Only provide one of the optional parameters `min_counts`, `min_genes`,; `max_counts`, `max_genes` per call. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; min_counts; Minimum number of counts required for a cell to pass filtering.; min_genes; Minimum number of genes expressed required for a cell to pass filtering.; max_counts; Maximum number of counts required for a cell to pass filtering.; max_genes; Maximum number of genes expressed required for a cell to pass filtering.; inplace; Perform computation inplace or return result. Returns; -------; Depending on `inplace`, returns the following arrays or directly subsets; and annotates the data matrix:. cells_subset; Boolean index mask that does filtering. `True` means that the; cell is kept. `False` means the cell is removed.; number_per_cell; Depending on what was thresholded (`counts` or `genes`),; the array stores `n_counts` or `n_cells` per gene. Examples; --------; >>> import scanpy as sc; >>> adata = sc.datasets.krumsiek11(); UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; utils.warn_names_duplicates(""obs""); >>> adata.obs_names_make_unique(); >>> adata.n_obs; 640; >>> adata.var_names.tolist() # doctest: +NORMALIZE_WHITESPACE; ['Gata2', 'Gata1', 'Fog1', 'EKLF', 'Fli1', 'SCL',; 'Cebpa', 'Pu.1', 'cJun', 'EgrNab', 'Gfi1']; >>> # add some true zeros; >>> adata.X[adata.X < 0.3] = 0; >>> # simply compute the number of genes per cell; >>> sc.pp.filter_cells(adata, min_genes=0); >>> adata.n_obs; 640; >>> adata.obs['n_genes'].min(); 1; >>> # filter manually; >>> adata_copy = adata[adata.obs['n_genes'] >= 3]; >>> adata_copy.n_obs; 554; >>> adata_copy.obs['n_genes'].min(); 3; >>> # actually do some filtering; >>> sc.pp.filter_cells(adata, min_genes=3); >>> adata.n_obs; 554; >>> adata.obs['n_genes'].min(); 3; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:1136,Depend,Depending,1136,src/scanpy/preprocessing/_simple.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py,1,['Depend'],['Depending']
Integrability,"eighbours for each batch are then merged to create a final list of; neighbours for the cell. Aligns batches in a quick and lightweight manner. For use in the scanpy workflow as an alternative to :func:`~scanpy.pp.neighbors`. .. note::. This is just a wrapper of :func:`bbknn.bbknn`: up to date docstring,; more information and bug reports there. Params; ------; adata; Needs the PCA computed and stored in `adata.obsm[""X_pca""]`.; batch_key; `adata.obs` column name discriminating between your batches.; use_rep; The dimensionality reduction in `.obsm` to use for neighbour detection. Defaults to PCA.; approx; If `True`, use approximate neighbour finding - annoy or PyNNDescent. This results; in a quicker run time for large datasets while also potentially increasing the degree of; batch correction.; use_annoy; Only used when `approx=True`. If `True`, will use annoy for neighbour finding. If; `False`, will use pyNNDescent instead.; metric; What distance metric to use. The options depend on the choice of neighbour algorithm. ""euclidean"", the default, is always available. Annoy supports ""angular"", ""manhattan"" and ""hamming"". PyNNDescent supports metrics listed in `pynndescent.distances.named_distances`; and custom functions, including compiled Numba code. >>> import pynndescent; >>> pynndescent.distances.named_distances.keys() # doctest: +ELLIPSIS, +NORMALIZE_WHITESPACE; dict_keys(['euclidean', 'l2', 'sqeuclidean', 'manhattan', 'taxicab', 'l1', 'chebyshev', 'linfinity',; 'linfty', 'linf', 'minkowski', 'seuclidean', 'standardised_euclidean', 'wminkowski', ...]). KDTree supports members of :class:`sklearn.neighbors.KDTree`’s ``valid_metrics`` list, or parameterised; :class:`~sklearn.metrics.DistanceMetric` objects:. >>> import sklearn.neighbors; >>> sklearn.neighbors.KDTree.valid_metrics; ['euclidean', 'l2', 'minkowski', 'p', 'manhattan', 'cityblock', 'l1', 'chebyshev', 'infinity']. .. note:: check the relevant documentation for up-to-date lists.; copy; If `True`, return a copy ins",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_bbknn.py:1219,depend,depend,1219,src/scanpy/external/pp/_bbknn.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_bbknn.py,1,['depend'],['depend']
Integrability,"ighly expressed, if it has more than `max_fraction` of the total counts; in at least one cell. The not-excluded genes will sum up to; `target_sum`. Providing this argument when `adata.X` is a :class:`~dask.array.Array`; will incur blocking `.compute()` calls on the array.; max_fraction; If `exclude_highly_expressed=True`, consider cells as highly expressed; that have more counts than `max_fraction` of the original total counts; in at least one cell.; key_added; Name of the field in `adata.obs` where the normalization factor is; stored.; layer; Layer to normalize instead of `X`. If `None`, `X` is normalized.; inplace; Whether to update `adata` or return dictionary with normalized copies of; `adata.X` and `adata.layers`.; copy; Whether to modify copied input object. Not compatible with inplace=False. Returns; -------; Returns dictionary with normalized copies of `adata.X` and `adata.layers`; or updates `adata` with normalized version of the original; `adata.X` and `adata.layers`, depending on `inplace`. Example; --------; >>> import sys; >>> from anndata import AnnData; >>> import scanpy as sc; >>> sc.settings.verbosity = 'info'; >>> sc.settings.logfile = sys.stdout # for doctests; >>> np.set_printoptions(precision=2); >>> adata = AnnData(np.array([; ... [3, 3, 3, 6, 6],; ... [1, 1, 1, 2, 2],; ... [1, 22, 1, 2, 2],; ... ], dtype='float32')); >>> adata.X; array([[ 3., 3., 3., 6., 6.],; [ 1., 1., 1., 2., 2.],; [ 1., 22., 1., 2., 2.]], dtype=float32); >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']; normalizing counts per cell; finished (0:00:00); >>> X_norm; array([[0.14, 0.14, 0.14, 0.29, 0.29],; [0.14, 0.14, 0.14, 0.29, 0.29],; [0.04, 0.79, 0.04, 0.07, 0.07]], dtype=float32); >>> X_norm = sc.pp.normalize_total(; ... adata, target_sum=1, exclude_highly_expressed=True,; ... max_fraction=0.2, inplace=False; ... )['X']; normalizing counts per cell. The following highly-expressed genes are not considered during normalization factor computation:;",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_normalization.py:2364,depend,depending,2364,src/scanpy/preprocessing/_normalization.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_normalization.py,1,['depend'],['depending']
Integrability,"implicit.; While results are extremely similar, they are not exactly the same.; If you would like to reproduce the old results, pass a dense array. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; n_comps; Number of principal components to compute. Defaults to 50, or 1 - minimum; dimension size of selected representation.; layer; If provided, which element of layers to use for PCA.; zero_center; If `True`, compute standard PCA from covariance matrix.; If `False`, omit zero-centering variables; (uses *scikit-learn* :class:`~sklearn.decomposition.TruncatedSVD` or; *dask-ml* :class:`~dask_ml.decomposition.TruncatedSVD`),; which allows to handle sparse input efficiently.; Passing `None` decides automatically based on sparseness of the data.; svd_solver; SVD solver to use:. `None`; See `chunked` and `zero_center` descriptions to determine which class will be used.; Depending on the class and the type of X different values for default will be set.; If *scikit-learn* :class:`~sklearn.decomposition.PCA` is used, will give `'arpack'`,; if *scikit-learn* :class:`~sklearn.decomposition.TruncatedSVD` is used, will give `'randomized'`,; if *dask-ml* :class:`~dask_ml.decomposition.PCA` or :class:`~dask_ml.decomposition.IncrementalPCA` is used, will give `'auto'`,; if *dask-ml* :class:`~dask_ml.decomposition.TruncatedSVD` is used, will give `'tsqr'`; `'arpack'`; for the ARPACK wrapper in SciPy (:func:`~scipy.sparse.linalg.svds`); Not available with *dask* arrays.; `'randomized'`; for the randomized algorithm due to Halko (2009). For *dask* arrays,; this will use :func:`~dask.array.linalg.svd_compressed`.; `'auto'`; chooses automatically depending on the size of the problem.; `'lobpcg'`; An alternative SciPy solver. Not available with dask arrays.; `'tsqr'`; Only available with *dask* arrays. ""tsqr""; algorithm from Benson et. al. (2013). .. versionchanged:: 1.9.3; Default value changed from `'arp",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py:1332,Depend,Depending,1332,src/scanpy/preprocessing/_pca.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py,1,['Depend'],['Depending']
Integrability,"nsional data sets, brute force, with parallel; computation, performs faster than kdtree.; partition_type; Defaults to :class:`~leidenalg.RBConfigurationVertexPartition`. For the; available options, consult the documentation for; :func:`~leidenalg.find_partition`.; resolution_parameter; A parameter value controlling the coarseness of the clustering in Leiden. Higher; values lead to more clusters. Set to `None` if overriding `partition_type` to; one that does not accept a `resolution_parameter`.; n_iterations; Number of iterations to run the Leiden algorithm. If the number of iterations is; negative, the Leiden algorithm is run until an iteration in which there was no; improvement.; use_weights; Use vertices in the Leiden computation.; seed; Leiden initialization of the optimization.; copy; Return a copy or write to `adata`.; kargs; Additional arguments passed to :func:`~leidenalg.find_partition` and the; constructor of the `partition_type`. Returns; -------; Depending on `copy`, returns or updates `adata` with the following fields:. **communities** - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.obs`, dtype `int`); integer array of community assignments for each row in data. **graph** - :class:`~scipy.sparse.spmatrix` (:attr:`~anndata.AnnData.obsp`, dtype `float`); the graph that was used for clustering. **Q** - `float` (:attr:`~anndata.AnnData.uns`, dtype `float`); the modularity score for communities on graph. Example; -------; >>> from anndata import AnnData; >>> import scanpy as sc; >>> import scanpy.external as sce; >>> import numpy as np; >>> import pandas as pd. With annotated data as input:. >>> adata = sc.datasets.pbmc3k(); >>> sc.pp.normalize_per_cell(adata). Then do PCA:. >>> sc.pp.pca(adata, n_comps=100). Compute phenograph clusters:. **Louvain** community detection. >>> sce.tl.phenograph(adata, clustering_algo=""louvain"", k=30). **Leiden** community detection. >>> sce.tl.phenograph(adata, clustering_algo=""leiden"", k=30). Return only `Graph` object. >>>",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phenograph.py:3238,Depend,Depending,3238,src/scanpy/external/tl/_phenograph.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phenograph.py,1,['Depend'],['Depending']
Integrability,"parse input efficiently.; Passing `None` decides automatically based on sparseness of the data.; svd_solver; SVD solver to use:. `None`; See `chunked` and `zero_center` descriptions to determine which class will be used.; Depending on the class and the type of X different values for default will be set.; If *scikit-learn* :class:`~sklearn.decomposition.PCA` is used, will give `'arpack'`,; if *scikit-learn* :class:`~sklearn.decomposition.TruncatedSVD` is used, will give `'randomized'`,; if *dask-ml* :class:`~dask_ml.decomposition.PCA` or :class:`~dask_ml.decomposition.IncrementalPCA` is used, will give `'auto'`,; if *dask-ml* :class:`~dask_ml.decomposition.TruncatedSVD` is used, will give `'tsqr'`; `'arpack'`; for the ARPACK wrapper in SciPy (:func:`~scipy.sparse.linalg.svds`); Not available with *dask* arrays.; `'randomized'`; for the randomized algorithm due to Halko (2009). For *dask* arrays,; this will use :func:`~dask.array.linalg.svd_compressed`.; `'auto'`; chooses automatically depending on the size of the problem.; `'lobpcg'`; An alternative SciPy solver. Not available with dask arrays.; `'tsqr'`; Only available with *dask* arrays. ""tsqr""; algorithm from Benson et. al. (2013). .. versionchanged:: 1.9.3; Default value changed from `'arpack'` to None.; .. versionchanged:: 1.4.5; Default value changed from `'auto'` to `'arpack'`. Efficient computation of the principal components of a sparse matrix; currently only works with the `'arpack`' or `'lobpcg'` solvers. If X is a *dask* array, *dask-ml* classes :class:`~dask_ml.decomposition.PCA`,; :class:`~dask_ml.decomposition.IncrementalPCA`, or; :class:`~dask_ml.decomposition.TruncatedSVD` will be used.; Otherwise their *scikit-learn* counterparts :class:`~sklearn.decomposition.PCA`,; :class:`~sklearn.decomposition.IncrementalPCA`, or; :class:`~sklearn.decomposition.TruncatedSVD` will be used.; random_state; Change to use different initial states for the optimization.; return_info; Only relevant when not passing an :c",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py:2109,depend,depending,2109,src/scanpy/preprocessing/_pca.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py,1,['depend'],['depending']
Integrability,"pplying `AnnData` objects.; batch_categories; The `batch_categories` for :meth:`~anndata.AnnData.concatenate`.; Only valid when `do_concatenate` and supplying AnnData objects.; k; Number of mutual nearest neighbors.; sigma; The bandwidth of the Gaussian smoothing kernel used to compute the; correction vectors. Default is 1.; cos_norm_in; Whether cosine normalization should be performed on the input data prior; to calculating distances between cells.; cos_norm_out; Whether cosine normalization should be performed prior to computing corrected expression values.; svd_dim; The number of dimensions to use for summarizing biological substructure; within each batch. If None, biological components will not be removed; from the correction vectors.; var_adj; Whether to adjust variance of the correction vectors. Note this step; takes most computing time.; compute_angle; Whether to compute the angle between each cell’s correction vector and; the biological subspace of the reference batch.; mnn_order; The order in which batches are to be corrected. When set to None, datas; are corrected sequentially.; svd_mode; `'svd'` computes SVD using a non-randomized SVD-via-ID algorithm,; while `'rsvd'` uses a randomized version. `'irlb'` perfores; truncated SVD by implicitly restarted Lanczos bidiagonalization; (forked from https://github.com/airysen/irlbpy).; do_concatenate; Whether to concatenate the corrected matrices or AnnData objects. Default is True.; save_raw; Whether to save the original expression data in the; :attr:`~anndata.AnnData.raw` attribute.; n_jobs; The number of jobs. When set to `None`, automatically uses; :attr:`scanpy._settings.ScanpyConfig.n_jobs`.; kwargs; optional keyword arguments for irlb. Returns; -------; datas; Corrected matrix/matrices or AnnData object/objects, depending on the; input type and `do_concatenate`.; mnn_list; A list containing MNN pairing information as DataFrames in each iteration step.; angle_list; A list containing angles of each batch.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_mnn_correct.py:3237,depend,depending,3237,src/scanpy/external/pp/_mnn_correct.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_mnn_correct.py,1,['depend'],['depending']
Integrability,"ps://github.com/dpeerlab/Palantir. .. note::; More information and bug reports `here; <https://github.com/dpeerlab/Harmony>`__. Parameters; ----------; adata; Annotated data matrix of shape n_obs `×` n_vars. Rows correspond to; cells and columns to genes. Rows represent two or more time points,; where replicates of the same time point are consecutive in order.; tp; key name of observation annotation `.obs` representing time points. Time; points should be categorical of `dtype=category`. The unique categories for; the categorical will be used as the time points to construct the timepoint; connections.; n_neighbors; Number of nearest neighbors for graph construction.; n_components; Minimum number of principal components to use. Specify `None` to use; pre-computed components. The higher the value the better to capture 85% of the; variance.; n_jobs; Nearest Neighbors will be computed in parallel using n_jobs.; copy; Return a copy instead of writing to `adata`. Returns; -------; Depending on `copy`, returns or updates `.obsm`, `.obsp` and `.uns` with the following:. **X_harmony** - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.obsm`, dtype `float`); force directed layout; **harmony_aff** - :class:`~scipy.sparse.spmatrix` (:attr:`~anndata.AnnData.obsp`, dtype `float`); affinity matrix; **harmony_aff_aug** - :class:`~scipy.sparse.spmatrix` (:attr:`~anndata.AnnData.obsp`, dtype `float`); augmented affinity matrix; **harmony_timepoint_var** - `str` (:attr:`~anndata.AnnData.uns`); The name of the variable passed as `tp`; **harmony_timepoint_connections** - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.uns`, dtype `str`); The links between time points. Example; -------. >>> from itertools import product; >>> import pandas as pd; >>> from anndata import AnnData; >>> import scanpy as sc; >>> import scanpy.external as sce. **Load** `AnnData`. A sample with real data is available here_. .. _here: https://github.com/dpeerlab/Harmony/tree/master/data. Random data sets of three ",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_harmony_timeseries.py:1677,Depend,Depending,1677,src/scanpy/external/tl/_harmony_timeseries.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_harmony_timeseries.py,1,['Depend'],['Depending']
Integrability,"rs to use for PCA.; zero_center; If `True`, compute standard PCA from covariance matrix.; If `False`, omit zero-centering variables; (uses *scikit-learn* :class:`~sklearn.decomposition.TruncatedSVD` or; *dask-ml* :class:`~dask_ml.decomposition.TruncatedSVD`),; which allows to handle sparse input efficiently.; Passing `None` decides automatically based on sparseness of the data.; svd_solver; SVD solver to use:. `None`; See `chunked` and `zero_center` descriptions to determine which class will be used.; Depending on the class and the type of X different values for default will be set.; If *scikit-learn* :class:`~sklearn.decomposition.PCA` is used, will give `'arpack'`,; if *scikit-learn* :class:`~sklearn.decomposition.TruncatedSVD` is used, will give `'randomized'`,; if *dask-ml* :class:`~dask_ml.decomposition.PCA` or :class:`~dask_ml.decomposition.IncrementalPCA` is used, will give `'auto'`,; if *dask-ml* :class:`~dask_ml.decomposition.TruncatedSVD` is used, will give `'tsqr'`; `'arpack'`; for the ARPACK wrapper in SciPy (:func:`~scipy.sparse.linalg.svds`); Not available with *dask* arrays.; `'randomized'`; for the randomized algorithm due to Halko (2009). For *dask* arrays,; this will use :func:`~dask.array.linalg.svd_compressed`.; `'auto'`; chooses automatically depending on the size of the problem.; `'lobpcg'`; An alternative SciPy solver. Not available with dask arrays.; `'tsqr'`; Only available with *dask* arrays. ""tsqr""; algorithm from Benson et. al. (2013). .. versionchanged:: 1.9.3; Default value changed from `'arpack'` to None.; .. versionchanged:: 1.4.5; Default value changed from `'auto'` to `'arpack'`. Efficient computation of the principal components of a sparse matrix; currently only works with the `'arpack`' or `'lobpcg'` solvers. If X is a *dask* array, *dask-ml* classes :class:`~dask_ml.decomposition.PCA`,; :class:`~dask_ml.decomposition.IncrementalPCA`, or; :class:`~dask_ml.decomposition.TruncatedSVD` will be used.; Otherwise their *scikit-learn* co",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py:1844,wrap,wrapper,1844,src/scanpy/preprocessing/_pca.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py,1,['wrap'],['wrapper']
Integrability,"s result in more local; data being preserved. In general values should be in the range 2 to 100.; If `knn` is `True`, number of nearest neighbors to be searched. If `knn`; is `False`, a Gaussian kernel width is set to the distance of the; `n_neighbors` neighbor. *ignored if ``transformer`` is an instance.*; {n_pcs}; {use_rep}; knn; If `True`, use a hard threshold to restrict the number of neighbors to; `n_neighbors`, that is, consider a knn graph. Otherwise, use a Gaussian; Kernel to assign low weights to neighbors more distant than the; `n_neighbors` nearest neighbor.; method; Use 'umap' :cite:p:`McInnes2018` or 'gauss' (Gauss kernel following :cite:t:`Coifman2005`; with adaptive width :cite:t:`Haghverdi2016`) for computing connectivities.; transformer; Approximate kNN search implementation following the API of; :class:`~sklearn.neighbors.KNeighborsTransformer`.; See :doc:`/how-to/knn-transformers` for more details.; Also accepts the following known options:. `None` (the default); Behavior depends on data size.; For small data, we will calculate exact kNN, otherwise we use; :class:`~pynndescent.pynndescent_.PyNNDescentTransformer`; `'pynndescent'`; :class:`~pynndescent.pynndescent_.PyNNDescentTransformer`; `'rapids'`; A transformer based on :class:`cuml.neighbors.NearestNeighbors`. .. deprecated:: 1.10.0; Use :func:`rapids_singlecell.pp.neighbors` instead.; metric; A known metric’s name or a callable that returns a distance. *ignored if ``transformer`` is an instance.*; metric_kwds; Options for the metric. *ignored if ``transformer`` is an instance.*; random_state; A numpy random seed. *ignored if ``transformer`` is an instance.*; key_added; If not specified, the neighbors data is stored in `.uns['neighbors']`,; distances and connectivities are stored in `.obsp['distances']` and; `.obsp['connectivities']` respectively.; If specified, the neighbors data is added to .uns[key_added],; distances are stored in `.obsp[key_added+'_distances']` and; connectivities in `.obsp",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/__init__.py:1731,depend,depends,1731,src/scanpy/neighbors/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/__init__.py,1,['depend'],['depends']
Integrability,"ses the implementation of scanorama_ :cite:p:`Hie2019`. .. _scanorama: https://github.com/brianhie/scanorama. Parameters; ----------; adata; The annotated data matrix.; key; The name of the column in ``adata.obs`` that differentiates; among experiments/batches. Cells from the same batch must be; contiguously stored in ``adata``.; basis; The name of the field in ``adata.obsm`` where the PCA table is; stored. Defaults to ``'X_pca'``, which is the default for; ``sc.pp.pca()``.; adjusted_basis; The name of the field in ``adata.obsm`` where the integrated; embeddings will be stored after running this function. Defaults; to ``X_scanorama``.; knn; Number of nearest neighbors to use for matching.; sigma; Correction smoothing parameter on Gaussian kernel.; approx; Use approximate nearest neighbors with Python ``annoy``;; greatly speeds up matching runtime.; alpha; Alignment score minimum cutoff.; batch_size; The batch size used in the alignment vector computation. Useful; when integrating very large (>100k samples) datasets. Set to; large value that runs within available memory.; kwargs; Any additional arguments will be passed to; ``scanorama.assemble()``. Returns; -------; Updates adata with the field ``adata.obsm[adjusted_basis]``,; containing Scanorama embeddings such that different experiments; are integrated. Example; -------; First, load libraries and example dataset, and preprocess. >>> import scanpy as sc; >>> import scanpy.external as sce; >>> adata = sc.datasets.pbmc3k(); >>> sc.pp.recipe_zheng17(adata); >>> sc.pp.pca(adata). We now arbitrarily assign a batch metadata variable to each cell; for the sake of example, but during real usage there would already; be a column in ``adata.obs`` giving the experiment each cell came; from. >>> adata.obs['batch'] = 1350*['a'] + 1350*['b']. Finally, run Scanorama. Afterwards, there will be a new table in; ``adata.obsm`` containing the Scanorama embeddings. >>> sce.pp.scanorama_integrate(adata, 'batch', verbose=1); Processing da",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py:1325,integrat,integrating,1325,src/scanpy/external/pp/_scanorama_integrate.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py,1,['integrat'],['integrating']
Integrability,"tes disparity of the diffused data.; n_pca; Number of principal components to use for calculating; neighborhoods. For extremely large datasets, using; n_pca < 20 allows neighborhoods to be calculated in; roughly log(n_samples) time. If `None`, no PCA is performed.; solver; Which solver to use. ""exact"" uses the implementation described; in :cite:t:`vanDijk2018`. ""approximate"" uses a faster; implementation that performs imputation in the PCA space and then; projects back to the gene space. Note, the ""approximate"" solver may; return negative values.; knn_dist; recommended values: 'euclidean', 'cosine', 'precomputed'; Any metric from `scipy.spatial.distance` can be used; distance metric for building kNN graph. If 'precomputed',; `data` should be an n_samples x n_samples distance or; affinity matrix.; random_state; Random seed. Defaults to the global `numpy` random number generator.; n_jobs; Number of threads to use in training. All cores are used by default.; verbose; If `True` or an integer `>= 2`, print status messages.; If `None`, `sc.settings.verbosity` is used.; copy; If true, a copy of anndata is returned. If `None`, `copy` is True if; `genes` is not `'all_genes'` or `'pca_only'`. `copy` may only be False; if `genes` is `'all_genes'` or `'pca_only'`, as the resultant data; will otherwise have different column names from the input data.; kwargs; Additional arguments to `magic.MAGIC`. Returns; -------; If `copy` is True, AnnData object is returned. If `subset_genes` is not `all_genes`, PCA on MAGIC values of cells are; stored in `adata.obsm['X_magic']` and `adata.X` is not modified. The raw counts are stored in `.raw` attribute of AnnData object. Examples; --------; >>> import scanpy as sc; >>> import scanpy.external as sce; >>> adata = sc.datasets.paul15(); >>> sc.pp.normalize_per_cell(adata); >>> sc.pp.sqrt(adata) # or sc.pp.log1p(adata); >>> adata_magic = sce.pp.magic(adata, name_list=['Mpo', 'Klf1', 'Ifitm1'], knn=5); >>> adata_magic.shape; (2730, 3); >>> sce.pp.",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_magic.py:2484,message,messages,2484,src/scanpy/external/pp/_magic.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_magic.py,1,['message'],['messages']
Modifiability," _scanorama: https://github.com/brianhie/scanorama. Parameters; ----------; adata; The annotated data matrix.; key; The name of the column in ``adata.obs`` that differentiates; among experiments/batches. Cells from the same batch must be; contiguously stored in ``adata``.; basis; The name of the field in ``adata.obsm`` where the PCA table is; stored. Defaults to ``'X_pca'``, which is the default for; ``sc.pp.pca()``.; adjusted_basis; The name of the field in ``adata.obsm`` where the integrated; embeddings will be stored after running this function. Defaults; to ``X_scanorama``.; knn; Number of nearest neighbors to use for matching.; sigma; Correction smoothing parameter on Gaussian kernel.; approx; Use approximate nearest neighbors with Python ``annoy``;; greatly speeds up matching runtime.; alpha; Alignment score minimum cutoff.; batch_size; The batch size used in the alignment vector computation. Useful; when integrating very large (>100k samples) datasets. Set to; large value that runs within available memory.; kwargs; Any additional arguments will be passed to; ``scanorama.assemble()``. Returns; -------; Updates adata with the field ``adata.obsm[adjusted_basis]``,; containing Scanorama embeddings such that different experiments; are integrated. Example; -------; First, load libraries and example dataset, and preprocess. >>> import scanpy as sc; >>> import scanpy.external as sce; >>> adata = sc.datasets.pbmc3k(); >>> sc.pp.recipe_zheng17(adata); >>> sc.pp.pca(adata). We now arbitrarily assign a batch metadata variable to each cell; for the sake of example, but during real usage there would already; be a column in ``adata.obs`` giving the experiment each cell came; from. >>> adata.obs['batch'] = 1350*['a'] + 1350*['b']. Finally, run Scanorama. Afterwards, there will be a new table in; ``adata.obsm`` containing the Scanorama embeddings. >>> sce.pp.scanorama_integrate(adata, 'batch', verbose=1); Processing datasets a <=> b; >>> 'X_scanorama' in adata.obsm; True; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py:1938,variab,variable,1938,src/scanpy/external/pp/_scanorama_integrate.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py,1,['variab'],['variable']
Modifiability," determined by the type e.g. `nb` does not provide dropout; probabilities. Types that end with ""-conddisp"", assumes that dispersion is mean dependant.; normalize_per_cell; If true, library size normalization is performed using; the `sc.pp.normalize_per_cell` function in Scanpy and saved into adata; object. Mean layer is re-introduces library size differences by; scaling the mean value of each cell in the output layer. See the; manuscript for more details.; scale; If true, the input of the autoencoder is centered using; `sc.pp.scale` function of Scanpy. Note that the output is kept as raw; counts as loss functions are designed for the count data.; log1p; If true, the input of the autoencoder is log transformed with a; pseudocount of one using `sc.pp.log1p` function of Scanpy.; hidden_size; Width of hidden layers.; hidden_dropout; Probability of weight dropout in the autoencoder (per layer if list; or tuple).; batchnorm; If true, batch normalization is performed.; activation; Activation function of hidden layers.; init; Initialization method used to initialize weights.; network_kwds; Additional keyword arguments for the autoencoder.; epochs; Number of total epochs in training.; reduce_lr; Reduces learning rate if validation loss does not improve in given number of epochs.; early_stop; Stops training if validation loss does not improve in given number of epochs.; batch_size; Number of samples in the batch used for SGD.; optimizer; Type of optimization method used for training.; random_state; Seed for python, numpy and tensorflow.; threads; Number of threads to use in training. All cores are used by default.; learning_rate; Learning rate to use in the training.; verbose; If true, prints additional information about training and architecture.; training_kwds; Additional keyword arguments for the training process.; return_model; If true, trained autoencoder object is returned. See ""Returns"".; return_info; If true, all additional parameters of DCA are stored in `adata.obsm` ",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_dca.py:1780,layers,layers,1780,src/scanpy/external/pp/_dca.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_dca.py,1,['layers'],['layers']
Modifiability," from the same experiment.; This function is a wrapper around functions that pre-process using Scanpy; and directly call functions of Scrublet(). You may also undertake your own; preprocessing, simulate doublets with; :func:`~scanpy.pp.scrublet_simulate_doublets`, and run the core scrublet; function :func:`~scanpy.pp.scrublet` with ``adata_sim`` set. Parameters; ----------; adata; The annotated data matrix of shape ``n_obs`` × ``n_vars``. Rows; correspond to cells and columns to genes. Expected to be un-normalised; where adata_sim is not supplied, in which case doublets will be; simulated and pre-processing applied to both objects. If adata_sim is; supplied, this should be the observed transcriptomes processed; consistently (filtering, transform, normalisaton, hvg) with adata_sim.; adata_sim; (Advanced use case) Optional annData object generated by; :func:`~scanpy.pp.scrublet_simulate_doublets`, with same number of vars; as adata. This should have been built from adata_obs after; filtering genes and cells and selcting highly-variable genes.; batch_key; Optional :attr:`~anndata.AnnData.obs` column name discriminating between batches.; sim_doublet_ratio; Number of doublets to simulate relative to the number of observed; transcriptomes.; expected_doublet_rate; Where adata_sim not suplied, the estimated doublet rate for the; experiment.; stdev_doublet_rate; Where adata_sim not suplied, uncertainty in the expected doublet rate.; synthetic_doublet_umi_subsampling; Where adata_sim not suplied, rate for sampling UMIs when creating; synthetic doublets. If 1.0, each doublet is created by simply adding; the UMI counts from two randomly sampled observed transcriptomes. For; values less than 1, the UMI counts are added and then randomly sampled; at the specified rate.; knn_dist_metric; Distance metric used when finding nearest neighbors. For list of; valid values, see the documentation for annoy (if `use_approx_neighbors`; is True) or sklearn.neighbors.NearestNeighbors (if `use_",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py:1330,variab,variable,1330,src/scanpy/preprocessing/_scrublet/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py,1,['variab'],['variable']
Modifiability," mode DCA adds `adata.obsm['X_dca']` to given adata; object. This matrix represent latent representation of cells via DCA.; ae_type; Type of the autoencoder. Return values and the architecture is; determined by the type e.g. `nb` does not provide dropout; probabilities. Types that end with ""-conddisp"", assumes that dispersion is mean dependant.; normalize_per_cell; If true, library size normalization is performed using; the `sc.pp.normalize_per_cell` function in Scanpy and saved into adata; object. Mean layer is re-introduces library size differences by; scaling the mean value of each cell in the output layer. See the; manuscript for more details.; scale; If true, the input of the autoencoder is centered using; `sc.pp.scale` function of Scanpy. Note that the output is kept as raw; counts as loss functions are designed for the count data.; log1p; If true, the input of the autoencoder is log transformed with a; pseudocount of one using `sc.pp.log1p` function of Scanpy.; hidden_size; Width of hidden layers.; hidden_dropout; Probability of weight dropout in the autoencoder (per layer if list; or tuple).; batchnorm; If true, batch normalization is performed.; activation; Activation function of hidden layers.; init; Initialization method used to initialize weights.; network_kwds; Additional keyword arguments for the autoencoder.; epochs; Number of total epochs in training.; reduce_lr; Reduces learning rate if validation loss does not improve in given number of epochs.; early_stop; Stops training if validation loss does not improve in given number of epochs.; batch_size; Number of samples in the batch used for SGD.; optimizer; Type of optimization method used for training.; random_state; Seed for python, numpy and tensorflow.; threads; Number of threads to use in training. All cores are used by default.; learning_rate; Learning rate to use in the training.; verbose; If true, prints additional information about training and architecture.; training_kwds; Additional keyword a",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_dca.py:1577,layers,layers,1577,src/scanpy/external/pp/_dca.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_dca.py,1,['layers'],['layers']
Modifiability," plotted using :func:`matplotlib.pyplot.scatter`. Thus, additional; arguments can be passed. Parameters; ----------; dot_size: Data frame containing the dot_size.; dot_color: Data frame containing the dot_color, should have the same,; shape, columns and indices as dot_size.; dot_ax: matplotlib axis; cmap; String denoting matplotlib color map.; color_on; Options are 'dot' or 'square'. Be default the colomap is applied to; the color of the dot. Optionally, the colormap can be applied to an; square behind the dot, in which case the dot is transparent and only; the edge is shown.; y_label: String. Label for y axis; dot_max; If none, the maximum dot size is set to the maximum fraction value found; (e.g. 0.6). If given, the value should be a number between 0 and 1.; All fractions larger than dot_max are clipped to this value.; dot_min; If none, the minimum dot size is set to 0. If given,; the value should be a number between 0 and 1.; All fractions smaller than dot_min are clipped to this value.; standard_scale; Whether or not to standardize that dimension between 0 and 1,; meaning for each variable or group,; subtract the minimum and divide each by its maximum.; smallest_dot; If none, the smallest dot has size 0.; All expression levels with `dot_min` are plotted with this size.; edge_color; Dot edge color. When `color_on='dot'` the default is no edge. When; `color_on='square'`, edge color is white; edge_lw; Dot edge line width. When `color_on='dot'` the default is no edge. When; `color_on='square'`, line width = 1.5; grid; Adds a grid to the plot; x_paddding; Space between the plot left/right borders and the dots center. A unit; is the distance between the x ticks. Only applied when color_on = dot; y_paddding; Space between the plot top/bottom borders and the dots center. A unit is; the distance between the y ticks. Only applied when color_on = dot; kwds; Are passed to :func:`matplotlib.pyplot.scatter`. Returns; -------; matplotlib.colors.Normalize, dot_min, dot_max. """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_dotplot.py:1306,variab,variable,1306,src/scanpy/plotting/_dotplot.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_dotplot.py,1,['variab'],['variable']
Modifiability," rank, with ties broken by the number of batches a gene is a HVG.; For `flavor='seurat_v3_paper'`, genes are first sorted by the number of batches a gene is a HVG, with ties broken by the median (across batches) rank. The following may help when comparing to Seurat's naming:; If `batch_key=None` and `flavor='seurat'`, this mimics Seurat's `FindVariableFeatures(…, method='mean.var.plot')`.; If `batch_key=None` and `flavor='seurat_v3'`/`flavor='seurat_v3_paper'`, this mimics Seurat's `FindVariableFeatures(..., method='vst')`.; If `batch_key` is not `None` and `flavor='seurat_v3_paper'`, this mimics Seurat's `SelectIntegrationFeatures`. See also `scanpy.experimental.pp._highly_variable_genes` for additional flavors; (e.g. Pearson residuals). Parameters; ----------; adata; The annotated data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; layer; If provided, use `adata.layers[layer]` for expression values instead of `adata.X`.; n_top_genes; Number of highly-variable genes to keep. Mandatory if `flavor='seurat_v3'`.; min_mean; If `n_top_genes` unequals `None`, this and all other cutoffs for the means and the; normalized dispersions are ignored. Ignored if `flavor='seurat_v3'`.; max_mean; If `n_top_genes` unequals `None`, this and all other cutoffs for the means and the; normalized dispersions are ignored. Ignored if `flavor='seurat_v3'`.; min_disp; If `n_top_genes` unequals `None`, this and all other cutoffs for the means and the; normalized dispersions are ignored. Ignored if `flavor='seurat_v3'`.; max_disp; If `n_top_genes` unequals `None`, this and all other cutoffs for the means and the; normalized dispersions are ignored. Ignored if `flavor='seurat_v3'`.; span; The fraction of the data (cells) used when estimating the variance in the loess; model fit if `flavor='seurat_v3'`.; n_bins; Number of bins for binning the mean gene expression. Normalization is; done with respect to each bin. If just a single gene falls into a bin,; the no",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py:2437,variab,variable,2437,src/scanpy/preprocessing/_highly_variable_genes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py,1,['variab'],['variable']
Modifiability,"""""""; Configures each of the violin plot axes ticks like remove or add labels etc. """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_stacked_violin.py:5,Config,Configures,5,src/scanpy/plotting/_stacked_violin.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_stacked_violin.py,1,['Config'],['Configures']
Modifiability,"""""""; Test if pca result is equal without highly variable and with-but mask is None; and if pca takes highly variable as mask as default; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py:48,variab,variable,48,tests/test_pca.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py,2,['variab'],['variable']
Modifiability,"""""""; Tests that layers works the same way as .X; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py:16,layers,layers,16,tests/test_pca.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py,1,['layers'],['layers']
Modifiability,"""""""; adata.X is np.ones((2, 2)); adata.layers['double'] is sparse np.ones((2,2)) * 2 to also test sparse matrices; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py:39,layers,layers,39,tests/test_get.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py,1,['layers'],['layers']
Modifiability,"""""""A private pytest plugin""""""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/testing/scanpy/_pytest/__init__.py:20,plugin,plugin,20,src/testing/scanpy/_pytest/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/testing/scanpy/_pytest/__init__.py,1,['plugin'],['plugin']
Modifiability,"""""""Construct the coupling matrix (and adjacancy matrix) from predefined models; or via sampling.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:17,coupling,coupling,17,src/scanpy/tools/_sim.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py,1,['coupling'],['coupling']
Modifiability,"""""""In model 1, we want enforce the following signs; on the couplings. Model 2 has the same couplings; but arbitrary signs.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:59,coupling,couplings,59,src/scanpy/tools/_sim.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py,2,['coupling'],['couplings']
Modifiability,"""""""Like fixtures, but more flexible""""""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/testing/scanpy/_pytest/params.py:27,flexible,flexible,27,src/testing/scanpy/_pytest/params.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/testing/scanpy/_pytest/params.py,1,['flexible'],['flexible']
Modifiability,"""""""Plot dispersions or normalized variance versus means for genes. Produces Supp. Fig. 5c of Zheng et al. (2017) and MeanVarPlot() and; VariableFeaturePlot() of Seurat. Parameters; ----------; adata; Result of :func:`~scanpy.pp.highly_variable_genes`.; log; Plot on logarithmic axes.; show; Show the plot, do not return axis.; save; If `True` or a `str`, save the figure.; A string is appended to the default filename.; Infer the filetype if ending on {{`'.pdf'`, `'.png'`, `'.svg'`}}.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_preprocessing.py:136,Variab,VariableFeaturePlot,136,src/scanpy/plotting/_preprocessing.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_preprocessing.py,1,['Variab'],['VariableFeaturePlot']
Modifiability,"""""""Read the model and the couplings from the model file.""""""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:26,coupling,couplings,26,src/scanpy/tools/_sim.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py,1,['coupling'],['couplings']
Modifiability,"""""""Returns a Request object. Allows you to access names of parameterized tests from within a test.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_embedding_plots.py:59,parameteriz,parameterized,59,tests/test_embedding_plots.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_embedding_plots.py,1,['parameteriz'],['parameterized']
Modifiability,"""""""Setup global variables before each benchmark.""""""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/benchmarks/benchmarks/preprocessing_counts.py:16,variab,variables,16,benchmarks/benchmarks/preprocessing_counts.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/benchmarks/benchmarks/preprocessing_counts.py,2,['variab'],['variables']
Modifiability,"""""""Test that `scatter()` raises `ValueError` where appropriate. If `sc.pl.scatter()` receives variable labels that either cannot be; found or are incompatible with one another, the function should; raise a `ValueError`. This test checks that this happens as; expected.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:94,variab,variable,94,tests/test_plotting.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py,1,['variab'],['variable']
Modifiability,"""""""Using the adjacency matrix, sample a coupling matrix.""""""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:40,coupling,coupling,40,src/scanpy/tools/_sim.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py,1,['coupling'],['coupling']
Modifiability,"""""""Variable for timing program parts.""""""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_settings.py:3,Variab,Variable,3,src/scanpy/_settings.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_settings.py,1,['Variab'],['Variable']
Modifiability,"""""""\; 3k PBMCs from 10x Genomics. The data consists in 3k PBMCs from a Healthy Donor and is freely available; from 10x Genomics (file_ from this webpage_). The exact same data is also used in Seurat’s `basic clustering tutorial`_. .. _file: https://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz; .. _webpage: https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.1.0/pbmc3k; .. _basic clustering tutorial: https://satijalab.org/seurat/articles/pbmc3k_tutorial.html. .. note::; This downloads 5.9 MB of data upon the first call of the function and stores it in; :attr:`~scanpy._settings.ScanpyConfig.datasetdir`\\ `/pbmc3k_raw.h5ad`. The following code was run to produce the file. .. code:: python. adata = sc.read_10x_mtx(; # the directory with the `.mtx` file; './data/filtered_gene_bc_matrices/hg19/',; # use gene symbols for the variable names (variables-axis index); var_names='gene_symbols',; # write a cache file for faster subsequent reading; cache=True,; ). adata.var_names_make_unique() # this is unnecessary if using 'gene_ids'; adata.write('write/pbmc3k_raw.h5ad', compression='gzip'). Returns; -------; Annotated data matrix. Examples; --------; >>> import scanpy as sc; >>> sc.datasets.pbmc3k(); AnnData object with n_obs × n_vars = 2700 × 32738; var: 'gene_ids'; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py:893,variab,variable,893,src/scanpy/datasets/_datasets.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py,2,['variab'],"['variable', 'variables-axis']"
Modifiability,"""""""\; Aggregate data matrix based on some categorical grouping. This function is useful for pseudobulking as well as plotting. Aggregation to perform is specified by `func`, which can be a single metric or a; list of metrics. Each metric is computed over the group and results in a new layer; in the output `AnnData` object. If none of `layer`, `obsm`, or `varm` are passed in, `X` will be used for aggregation data. Params; ------; adata; :class:`~anndata.AnnData` to be aggregated.; by; Key of the column to be grouped-by.; func; How to aggregate.; axis; Axis on which to find group by column.; mask; Boolean mask (or key to column containing mask) to apply along the axis.; dof; Degrees of freedom for variance. Defaults to 1.; layer; If not None, key for aggregation data.; obsm; If not None, key for aggregation data.; varm; If not None, key for aggregation data. Returns; -------; Aggregated :class:`~anndata.AnnData`. Examples; --------. Calculating mean expression and number of nonzero entries per cluster:. >>> import scanpy as sc, pandas as pd; >>> pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(); >>> pbmc.shape; (2638, 13714); >>> aggregated = sc.get.aggregate(pbmc, by=""louvain"", func=[""mean"", ""count_nonzero""]); >>> aggregated; AnnData object with n_obs × n_vars = 8 × 13714; obs: 'louvain'; var: 'n_cells'; layers: 'mean', 'count_nonzero'. We can group over multiple columns:. >>> pbmc.obs[""percent_mito_binned""] = pd.cut(pbmc.obs[""percent_mito""], bins=5); >>> sc.get.aggregate(pbmc, by=[""louvain"", ""percent_mito_binned""], func=[""mean"", ""count_nonzero""]); AnnData object with n_obs × n_vars = 40 × 13714; obs: 'louvain', 'percent_mito_binned'; var: 'n_cells'; layers: 'mean', 'count_nonzero'. Note that this filters out any combination of groups that wasn't present in the original data.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/_aggregated.py:1328,layers,layers,1328,src/scanpy/get/_aggregated.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/_aggregated.py,2,['layers'],['layers']
Modifiability,"""""""\; Allows the visualization of values using a color map. Parameters; ----------; {common_plot_args}; title; Title for the figure.; expression_cutoff; Expression cutoff that is used for binarizing the gene expression and; determining the fraction of cells expressing given genes. A gene is; expressed only if the expression value is greater than this threshold.; mean_only_expressed; If True, gene expression is averaged only over the cells; expressing the given genes.; standard_scale; Whether or not to standardize that dimension between 0 and 1,; meaning for each variable or group,; subtract the minimum and divide each by its maximum.; values_df; Optionally, a dataframe with the values to plot can be given. The; index should be the grouby categories and the columns the genes names. kwds; Are passed to :func:`matplotlib.pyplot.scatter`. See also; --------; :func:`~scanpy.pl.matrixplot`: Simpler way to call MatrixPlot but with less options.; :func:`~scanpy.pl.rank_genes_groups_matrixplot`: to plot marker genes identified; using the :func:`~scanpy.tl.rank_genes_groups` function. Examples; --------. Simple visualization of the average expression of a few genes grouped by; the category 'bulk_labels'. .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); markers = ['C1QA', 'PSAP', 'CD79A', 'CD79B', 'CST3', 'LYZ']; sc.pl.MatrixPlot(adata, markers, groupby='bulk_labels').show(). Same visualization but passing var_names as dict, which adds a grouping of; the genes on top of the image:. .. plot::; :context: close-figs. markers = {{'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}}; sc.pl.MatrixPlot(adata, markers, groupby='bulk_labels').show(); """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_matrixplot.py:569,variab,variable,569,src/scanpy/plotting/_matrixplot.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_matrixplot.py,1,['variab'],['variable']
Modifiability,"""""""\; Annotate highly variable genes :cite:p:`Satija2015,Zheng2017,Stuart2019`. Expects logarithmized data, except when `flavor='seurat_v3'`/`'seurat_v3_paper'`, in which count; data is expected. Depending on `flavor`, this reproduces the R-implementations of Seurat; :cite:p:`Satija2015`, Cell Ranger :cite:p:`Zheng2017`, and Seurat v3 :cite:p:`Stuart2019`. `'seurat_v3'`/`'seurat_v3_paper'` requires `scikit-misc` package. If you plan to use this flavor, consider; installing `scanpy` with this optional dependency: `scanpy[skmisc]`. For the dispersion-based methods (`flavor='seurat'` :cite:t:`Satija2015` and; `flavor='cell_ranger'` :cite:t:`Zheng2017`), the normalized dispersion is obtained; by scaling with the mean and standard deviation of the dispersions for genes; falling into a given bin for mean expression of genes. This means that for each; bin of mean expression, highly variable genes are selected. For `flavor='seurat_v3'`/`'seurat_v3_paper'` :cite:p:`Stuart2019`, a normalized variance for each gene; is computed. First, the data are standardized (i.e., z-score normalization; per feature) with a regularized standard deviation. Next, the normalized variance; is computed as the variance of each gene after the transformation. Genes are ranked; by the normalized variance.; Only if `batch_key` is not `None`, the two flavors differ: For `flavor='seurat_v3'`, genes are first sorted by the median (across batches) rank, with ties broken by the number of batches a gene is a HVG.; For `flavor='seurat_v3_paper'`, genes are first sorted by the number of batches a gene is a HVG, with ties broken by the median (across batches) rank. The following may help when comparing to Seurat's naming:; If `batch_key=None` and `flavor='seurat'`, this mimics Seurat's `FindVariableFeatures(…, method='mean.var.plot')`.; If `batch_key=None` and `flavor='seurat_v3'`/`flavor='seurat_v3_paper'`, this mimics Seurat's `FindVariableFeatures(..., method='vst')`.; If `batch_key` is not `None` and `flav",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py:22,variab,variable,22,src/scanpy/preprocessing/_highly_variable_genes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py,2,['variab'],['variable']
Modifiability,"""""""\; Applies analytic Pearson residual normalization and PCA, based on :cite:t:`Lause2021`. The residuals are based on a negative binomial offset model with overdispersion; `theta` shared across genes. By default, residuals are clipped to `sqrt(n_obs)`,; overdispersion `theta=100` is used, and PCA is run with 50 components. Operates on the subset of highly variable genes in `adata.var['highly_variable']`; by default. Expects raw count input. Params; ------; {adata}; {dist_params}; {pca_chunk}; {mask_var_hvg}; {check_values}; {inplace}. Returns; -------; If `inplace=False`, returns the Pearson residual-based PCA results (as :class:`~anndata.AnnData`; object). If `inplace=True`, updates `adata` with the following fields:. `.uns['pearson_residuals_normalization']['pearson_residuals_df']`; The subset of highly variable genes, normalized by Pearson residuals.; `.uns['pearson_residuals_normalization']['theta']`; The used value of the overdisperion parameter theta.; `.uns['pearson_residuals_normalization']['clip']`; The used value of the clipping parameter. `.obsm['X_pca']`; PCA representation of data after gene selection (if applicable) and Pearson; residual normalization.; `.varm['PCs']`; The principal components containing the loadings. When `inplace=True` and; `use_highly_variable=True`, this will contain empty rows for the genes not; selected.; `.uns['pca']['variance_ratio']`; Ratio of explained variance.; `.uns['pca']['variance']`; Explained variance, equivalent to the eigenvalues of the covariance matrix.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_normalization.py:360,variab,variable,360,src/scanpy/experimental/pp/_normalization.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_normalization.py,2,['variab'],['variable']
Modifiability,"""""""\; Applies analytic Pearson residual normalization, based on :cite:t:`Lause2021`. The residuals are based on a negative binomial offset model with overdispersion; `theta` shared across genes. By default, residuals are clipped to `sqrt(n_obs)`; and overdispersion `theta=100` is used. Expects raw count input. Params; ------; {adata}; {dist_params}; {check_values}; {layer}; {inplace}; {copy}. Returns; -------; If `inplace=True`, `adata.X` or the selected layer in `adata.layers` is updated; with the normalized values. `adata.uns` is updated with the following fields.; If `inplace=False`, the same fields are returned as dictionary with the; normalized values in `results_dict['X']`. `.uns['pearson_residuals_normalization']['theta']`; The used value of the overdisperion parameter theta.; `.uns['pearson_residuals_normalization']['clip']`; The used value of the clipping parameter.; `.uns['pearson_residuals_normalization']['computed_on']`; The name of the layer on which the residuals were computed.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_normalization.py:475,layers,layers,475,src/scanpy/experimental/pp/_normalization.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_normalization.py,1,['layers'],['layers']
Modifiability,"""""""\; ComBat function for batch effect correction :cite:p:`Johnson2006,Leek2012,Pedersen2012`. Corrects for batch effects by fitting linear models, gains statistical power; via an EB framework where information is borrowed across genes.; This uses the implementation `combat.py`_ :cite:p:`Pedersen2012`. .. _combat.py: https://github.com/brentp/combat.py. Parameters; ----------; adata; Annotated data matrix; key; Key to a categorical annotation from :attr:`~anndata.AnnData.obs`; that will be used for batch effect removal.; covariates; Additional covariates besides the batch variable such as adjustment; variables or biological condition. This parameter refers to the design; matrix `X` in Equation 2.1 in :cite:t:`Johnson2006` and to the `mod` argument in; the original combat function in the sva R package.; Note that not including covariates may introduce bias or lead to the; removal of biological signal in unbalanced designs.; inplace; Whether to replace adata.X or to return the corrected data. Returns; -------; Returns :class:`numpy.ndarray` if `inplace=True`, else returns `None` and sets the following field in the `adata` object:. `adata.X` : :class:`numpy.ndarray` (dtype `float`); Corrected data matrix.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_combat.py:579,variab,variable,579,src/scanpy/preprocessing/_combat.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_combat.py,2,['variab'],"['variable', 'variables']"
Modifiability,"""""""\; Computes a hierarchical clustering for the given `groupby` categories. By default, the PCA representation is used unless `.X`; has less than 50 variables. Alternatively, a list of `var_names` (e.g. genes) can be given. Average values of either `var_names` or components are used; to compute a correlation matrix. The hierarchical clustering can be visualized using; :func:`scanpy.pl.dendrogram` or multiple other visualizations that can; include a dendrogram: :func:`~scanpy.pl.matrixplot`,; :func:`~scanpy.pl.heatmap`, :func:`~scanpy.pl.dotplot`,; and :func:`~scanpy.pl.stacked_violin`. .. note::; The computation of the hierarchical clustering is based on predefined; groups and not per cell. The correlation matrix is computed using by; default pearson but other methods are available. Parameters; ----------; adata; Annotated data matrix; {n_pcs}; {use_rep}; var_names; List of var_names to use for computing the hierarchical clustering.; If `var_names` is given, then `use_rep` and `n_pcs` is ignored.; use_raw; Only when `var_names` is not None.; Use `raw` attribute of `adata` if present.; cor_method; correlation method to use.; Options are 'pearson', 'kendall', and 'spearman'; linkage_method; linkage method to use. See :func:`scipy.cluster.hierarchy.linkage`; for more information.; optimal_ordering; Same as the optimal_ordering argument of :func:`scipy.cluster.hierarchy.linkage`; which reorders the linkage matrix so that the distance between successive; leaves is minimal.; key_added; By default, the dendrogram information is added to; `.uns[f'dendrogram_{{groupby}}']`.; Notice that the `groupby` information is added to the dendrogram.; inplace; If `True`, adds dendrogram information to `adata.uns[key_added]`,; else this function returns the information. Returns; -------; Returns `None` if `inplace=True`, else returns a `dict` with dendrogram information. Sets the following field if `inplace=True`:. `adata.uns[f'dendrogram_{{group_by}}' | key_added]` : :class:`dict`; Den",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dendrogram.py:150,variab,variables,150,src/scanpy/tools/_dendrogram.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dendrogram.py,1,['variab'],['variables']
Modifiability,"""""""\; Computes the nearest neighbors distance matrix and a neighborhood graph of observations :cite:p:`McInnes2018`. The neighbor search efficiency of this heavily relies on UMAP :cite:p:`McInnes2018`,; which also provides a method for estimating connectivities of data points -; the connectivity of the manifold (`method=='umap'`). If `method=='gauss'`,; connectivities are computed according to :cite:t:`Coifman2005`, in the adaption of; :cite:t:`Haghverdi2016`. Parameters; ----------; adata; Annotated data matrix.; n_neighbors; The size of local neighborhood (in terms of number of neighboring data; points) used for manifold approximation. Larger values result in more; global views of the manifold, while smaller values result in more local; data being preserved. In general values should be in the range 2 to 100.; If `knn` is `True`, number of nearest neighbors to be searched. If `knn`; is `False`, a Gaussian kernel width is set to the distance of the; `n_neighbors` neighbor. *ignored if ``transformer`` is an instance.*; {n_pcs}; {use_rep}; knn; If `True`, use a hard threshold to restrict the number of neighbors to; `n_neighbors`, that is, consider a knn graph. Otherwise, use a Gaussian; Kernel to assign low weights to neighbors more distant than the; `n_neighbors` nearest neighbor.; method; Use 'umap' :cite:p:`McInnes2018` or 'gauss' (Gauss kernel following :cite:t:`Coifman2005`; with adaptive width :cite:t:`Haghverdi2016`) for computing connectivities.; transformer; Approximate kNN search implementation following the API of; :class:`~sklearn.neighbors.KNeighborsTransformer`.; See :doc:`/how-to/knn-transformers` for more details.; Also accepts the following known options:. `None` (the default); Behavior depends on data size.; For small data, we will calculate exact kNN, otherwise we use; :class:`~pynndescent.pynndescent_.PyNNDescentTransformer`; `'pynndescent'`; :class:`~pynndescent.pynndescent_.PyNNDescentTransformer`; `'rapids'`; A transformer based on :class:`cuml.n",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/__init__.py:427,adapt,adaption,427,src/scanpy/neighbors/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/__init__.py,1,['adapt'],['adaption']
Modifiability,"""""""\; Config manager for scanpy.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_settings.py:6,Config,Config,6,src/scanpy/_settings.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_settings.py,1,['Config'],['Config']
Modifiability,"""""""\; Configures dot size and the colorbar legends. Parameters; ----------; show; Set to `False` to hide the default plot of the legends. This sets the; legend width to zero, which will result in a wider main plot.; show_size_legend; Set to `False` to hide the dot size legend; show_colorbar; Set to `False` to hide the colorbar legend; size_title; Title for the dot size legend. Use '\\n' to add line breaks. Appears on top; of dot sizes; colorbar_title; Title for the color bar. Use '\\n' to add line breaks. Appears on top of the; color bar; width; Width of the legends area. The unit is the same as in matplotlib (inches). Returns; -------; :class:`~scanpy.pl.DotPlot`. Examples; --------. Set color bar title:. >>> import scanpy as sc; >>> adata = sc.datasets.pbmc68k_reduced(); >>> markers = {'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}; >>> dp = sc.pl.DotPlot(adata, markers, groupby='bulk_labels'); >>> dp.legend(colorbar_title='log(UMI counts + 1)').show(); """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_dotplot.py:6,Config,Configures,6,src/scanpy/plotting/_dotplot.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_dotplot.py,1,['Config'],['Configures']
Modifiability,"""""""\; Core function for predicting doublets using Scrublet :cite:p:`Wolock2019`. Predict cell doublets using a nearest-neighbor classifier of observed; transcriptomes and simulated doublets. Parameters; ----------; adata_obs; The annotated data matrix of shape ``n_obs`` × ``n_vars``. Rows; correspond to cells and columns to genes. Should be normalised with; :func:`~scanpy.pp.normalize_total` and filtered to include only highly; variable genes.; adata_sim; Anndata object generated by; :func:`~scanpy.pp.scrublet_simulate_doublets`, with same number of vars; as adata_obs. This should have been built from adata_obs after; filtering genes and cells and selcting highly-variable genes.; n_neighbors; Number of neighbors used to construct the KNN graph of observed; transcriptomes and simulated doublets. If ``None``, this is; automatically set to ``np.round(0.5 * np.sqrt(n_obs))``.; expected_doublet_rate; The estimated doublet rate for the experiment.; stdev_doublet_rate; Uncertainty in the expected doublet rate.; mean_center; If True, center the data such that each gene has a mean of 0.; `sklearn.decomposition.PCA` will be used for dimensionality; reduction.; normalize_variance; If True, normalize the data such that each gene has a variance of 1.; `sklearn.decomposition.TruncatedSVD` will be used for dimensionality; reduction, unless `mean_center` is True.; n_prin_comps; Number of principal components used to embed the transcriptomes prior; to k-nearest-neighbor graph construction.; use_approx_neighbors; Use approximate nearest neighbor method (annoy) for the KNN; classifier.; knn_dist_metric; Distance metric used when finding nearest neighbors. For list of; valid values, see the documentation for annoy (if `use_approx_neighbors`; is True) or sklearn.neighbors.NearestNeighbors (if `use_approx_neighbors`; is False).; get_doublet_neighbor_parents; If True, return the parent transcriptomes that generated the; doublet neighbors of each observed transcriptome. This information can",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py:432,variab,variable,432,src/scanpy/preprocessing/_scrublet/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py,2,['variab'],['variable']
Modifiability,"""""""\; Correct batch effects by matching mutual nearest neighbors :cite:p:`Haghverdi2018` :cite:p:`Kang2018`. This uses the implementation of mnnpy_ :cite:p:`Kang2018`. Depending on `do_concatenate`, returns matrices or `AnnData` objects in the; original order containing corrected expression values or a concatenated; matrix or AnnData object. Be reminded that it is not advised to use the corrected data matrices for; differential expression testing. More information and bug reports `here <mnnpy>`__. .. _mnnpy: https://github.com/chriscainx/mnnpy. Parameters; ----------; datas; Expression matrices or AnnData objects. Matrices should be shaped like; n_obs × n_vars (n_cell × n_gene) and have consistent number of columns.; AnnData objects should have same number of variables.; var_index; The index (list of str) of vars (genes). Necessary when using only a; subset of vars to perform MNN correction, and should be supplied with; `var_subset`. When `datas` are AnnData objects, `var_index` is ignored.; var_subset; The subset of vars (list of str) to be used when performing MNN; correction. Typically, a list of highly variable genes (HVGs).; When set to `None`, uses all vars.; batch_key; The `batch_key` for :meth:`~anndata.AnnData.concatenate`.; Only valid when `do_concatenate` and supplying `AnnData` objects.; index_unique; The `index_unique` for :meth:`~anndata.AnnData.concatenate`.; Only valid when `do_concatenate` and supplying `AnnData` objects.; batch_categories; The `batch_categories` for :meth:`~anndata.AnnData.concatenate`.; Only valid when `do_concatenate` and supplying AnnData objects.; k; Number of mutual nearest neighbors.; sigma; The bandwidth of the Gaussian smoothing kernel used to compute the; correction vectors. Default is 1.; cos_norm_in; Whether cosine normalization should be performed on the input data prior; to calculating distances between cells.; cos_norm_out; Whether cosine normalization should be performed prior to computing corrected expression values.",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_mnn_correct.py:770,variab,variables,770,src/scanpy/external/pp/_mnn_correct.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_mnn_correct.py,1,['variab'],['variables']
Modifiability,"""""""\; Describe variables of anndata. Calculates a number of qc metrics for variables in AnnData object. See; section `Returns` for a description of those metrics. Params; ------; {doc_adata_basic}; {doc_qc_metric_naming}; {doc_expr_reps}; inplace; Whether to place calculated metrics in `adata.var`.; X; Matrix to calculate values on. Meant for internal usage. Returns; -------; QC metrics for variables in adata. If inplace, values are placed into the; AnnData's `.var` dataframe. {doc_var_qc_returns}; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_qc.py:15,variab,variables,15,src/scanpy/preprocessing/_qc.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_qc.py,3,['variab'],['variables']
Modifiability,"""""""\; Diffusion Maps :cite:p:`Coifman2005,Haghverdi2015,Wolf2018`. Diffusion maps :cite:p:`Coifman2005` has been proposed for visualizing single-cell; data by :cite:t:`Haghverdi2015`. The tool uses the adapted Gaussian kernel suggested; by :cite:t:`Haghverdi2016` in the implementation of :cite:t:`Wolf2018`. The width (""sigma"") of the connectivity kernel is implicitly determined by; the number of neighbors used to compute the single-cell graph in; :func:`~scanpy.pp.neighbors`. To reproduce the original implementation; using a Gaussian kernel, use `method=='gauss'` in; :func:`~scanpy.pp.neighbors`. To use an exponential kernel, use the default; `method=='umap'`. Differences between these options shouldn't usually be; dramatic. Parameters; ----------; adata; Annotated data matrix.; n_comps; The number of dimensions of the representation.; neighbors_key; If not specified, diffmap looks .uns['neighbors'] for neighbors settings; and .obsp['connectivities'], .obsp['distances'] for connectivities and; distances respectively (default storage places for pp.neighbors).; If specified, diffmap looks .uns[neighbors_key] for neighbors settings and; .obsp[.uns[neighbors_key]['connectivities_key']],; .obsp[.uns[neighbors_key]['distances_key']] for connectivities and distances; respectively.; random_state; A numpy random seed; copy; Return a copy instead of writing to adata. Returns; -------; Returns `None` if `copy=False`, else returns an `AnnData` object. Sets the following fields:. `adata.obsm['X_diffmap']` : :class:`numpy.ndarray` (dtype `float`); Diffusion map representation of data, which is the right eigen basis of; the transition matrix with eigenvectors as columns. `adata.uns['diffmap_evals']` : :class:`numpy.ndarray` (dtype `float`); Array of size (number of eigen vectors).; Eigenvalues of transition matrix. Notes; -----; The 0-th column in `adata.obsm[""X_diffmap""]` is the steady-state solution,; which is non-informative in diffusion maps.; Therefore, the first diffusion com",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_diffmap.py:202,adapt,adapted,202,src/scanpy/tools/_diffmap.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_diffmap.py,1,['adapt'],['adapted']
Modifiability,"""""""\; Extract highly variable genes :cite:p:`Satija2015,Zheng2017`. .. warning::; .. deprecated:: 1.3.6; Use :func:`~scanpy.pp.highly_variable_genes`; instead. The new function is equivalent to the present; function, except that. * the new function always expects logarithmized data; * `subset=False` in the new function, it suffices to; merely annotate the genes, tools like `pp.pca` will; detect the annotation; * you can now call: `sc.pl.highly_variable_genes(adata)`; * `copy` is replaced by `inplace`. If trying out parameters, pass the data matrix instead of AnnData. Depending on `flavor`, this reproduces the R-implementations of Seurat; :cite:p:`Satija2015` and Cell Ranger :cite:p:`Zheng2017`. The normalized dispersion is obtained by scaling with the mean and standard; deviation of the dispersions for genes falling into a given bin for mean; expression of genes. This means that for each bin of mean expression, highly; variable genes are selected. Use `flavor='cell_ranger'` with care and in the same way as in; :func:`~scanpy.pp.recipe_zheng17`. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; flavor; Choose the flavor for computing normalized dispersion. If choosing; 'seurat', this expects non-logarithmized data – the logarithm of mean; and dispersion is taken internally when `log` is at its default value; `True`. For 'cell_ranger', this is usually called for logarithmized data; – in this case you should set `log` to `False`. In their default; workflows, Seurat passes the cutoffs whereas Cell Ranger passes; `n_top_genes`.; min_mean; max_mean; min_disp; max_disp; If `n_top_genes` unequals `None`, these cutoffs for the means and the; normalized dispersions are ignored.; n_bins; Number of bins for binning the mean gene expression. Normalization is; done with respect to each bin. If just a single gene falls into a bin,; the normalized dispersion is artificially set to 1. You'll be info",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py:21,variab,variable,21,src/scanpy/preprocessing/_deprecated/highly_variable_genes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py,2,['variab'],['variable']
Modifiability,"""""""\; Full pipeline for HVG selection and normalization by analytic Pearson residuals :cite:p:`Lause2021`. Applies gene selection based on Pearson residuals. On the resulting subset,; Pearson residual normalization and PCA are performed. Expects raw count input. Params; ------; {adata}; {dist_params}; {genes_batch_chunk}; {pca_chunk}; {check_values}; {inplace}. Returns; -------; If `inplace=False`, separately returns the gene selection results (as; :class:`~pandas.DataFrame`) and Pearson residual-based PCA results (as; :class:`~anndata.AnnData`). If `inplace=True`, updates `adata` with the; following fields for gene selection results:. `.var['highly_variable']` : bool; boolean indicator of highly-variable genes.; `.var['means']` : float; means per gene.; `.var['variances']` : float; variances per gene.; `.var['residual_variances']` : float; Pearson residual variance per gene. Averaged in the case of multiple; batches.; `.var['highly_variable_rank']` : float; Rank of the gene according to residual variance, median rank in the; case of multiple batches.; `.var['highly_variable_nbatches']` : int; If batch_key is given, this denotes in how many batches genes are; detected as HVG.; `.var['highly_variable_intersection']` : bool; If batch_key is given, this denotes the genes that are highly variable; in all batches. The following fields contain Pearson residual-based PCA results and; normalization settings:. `.uns['pearson_residuals_normalization']['pearson_residuals_df']`; The subset of highly variable genes, normalized by Pearson residuals.; `.uns['pearson_residuals_normalization']['theta']`; The used value of the overdisperion parameter theta.; `.uns['pearson_residuals_normalization']['clip']`; The used value of the clipping parameter. `.obsm['X_pca']`; PCA representation of data after gene selection and Pearson residual; normalization.; `.varm['PCs']`; The principal components containing the loadings. When `inplace=True` this; will contain empty rows for the genes not s",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_recipes.py:706,variab,variable,706,src/scanpy/experimental/pp/_recipes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_recipes.py,1,['variab'],['variable']
Modifiability,"""""""\; Gene expression and annotation changes along paths in the abstracted graph. Parameters; ----------; adata; An annotated data matrix.; nodes; A path through nodes of the abstracted graph, that is, names or indices; (within `.categories`) of groups that have been used to run PAGA.; keys; Either variables in `adata.var_names` or annotations in; `adata.obs`. They are plotted using `color_map`.; use_raw; Use `adata.raw` for retrieving gene expressions if it has been set.; annotations; Plot these keys with `color_maps_annotations`. Need to be keys for; `adata.obs`.; color_map; Matplotlib colormap.; color_maps_annotations; Color maps for plotting the annotations. Keys of the dictionary must; appear in `annotations`.; palette_groups; Ususally, use the same `sc.pl.palettes...` as used for coloring the; abstracted graph.; n_avg; Number of data points to include in computation of running average.; groups_key; Key of the grouping used to run PAGA. If `None`, defaults to; `adata.uns['paga']['groups']`.; as_heatmap; Plot the timeseries as heatmap. If not plotting as heatmap,; `annotations` have no effect.; show_node_names; Plot the node names on the nodes bar.; show_colorbar; Show the colorbar.; show_yticks; Show the y ticks.; normalize_to_zero_one; Shift and scale the running average to [0, 1] per gene.; return_data; Return the timeseries data in addition to the axes if `True`.; show; Show the plot, do not return axis.; save; If `True` or a `str`, save the figure.; A string is appended to the default filename.; Infer the filetype if ending on \\{`'.pdf'`, `'.png'`, `'.svg'`\\}.; ax; A matplotlib axes object. Returns; -------; A :class:`~matplotlib.axes.Axes` object, if `ax` is `None`, else `None`.; If `return_data`, return the timeseries data in addition to an axes.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/paga.py:300,variab,variables,300,src/scanpy/plotting/_tools/paga.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/paga.py,1,['variab'],['variables']
Modifiability,"""""""\; Generic class for the visualization of AnnData categories and; selected `var` (features or genes). Takes care of the visual location of a main plot, additional plots; in the margins (e.g. dendrogram, margin totals) and legends. Also; understand how to adapt the visual parameter if the plot is rotated. Classed based on BasePlot implement their own _mainplot() method. The BasePlot works by method chaining. For example:; BasePlot(adata, ...).legend(title='legend').style(cmap='binary').show(); """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_baseplot_class.py:258,adapt,adapt,258,src/scanpy/plotting/_baseplot_class.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_baseplot_class.py,1,['adapt'],['adapt']
Modifiability,"""""""\; Heatmap of the expression values of genes. If `groupby` is given, the heatmap is ordered by the respective group. For; example, a list of marker genes can be plotted, ordered by clustering. If; the `groupby` observation annotation is not categorical the observation; annotation is turned into a categorical by binning the data into the number; specified in `num_categories`. Parameters; ----------; {common_plot_args}; standard_scale; Whether or not to standardize that dimension between 0 and 1, meaning for each variable or observation,; subtract the minimum and divide each by its maximum.; swap_axes; By default, the x axis contains `var_names` (e.g. genes) and the y axis the `groupby`; categories (if any). By setting `swap_axes` then x are the `groupby` categories and y the `var_names`.; show_gene_labels; By default gene labels are shown when there are 50 or less genes. Otherwise the labels are removed.; {show_save_ax}; {vminmax}; **kwds; Are passed to :func:`matplotlib.pyplot.imshow`. Returns; -------; Dict of :class:`~matplotlib.axes.Axes`. Examples; -------; .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); markers = ['C1QA', 'PSAP', 'CD79A', 'CD79B', 'CST3', 'LYZ']; sc.pl.heatmap(adata, markers, groupby='bulk_labels', swap_axes=True). .. currentmodule:: scanpy. See also; --------; pl.rank_genes_groups_heatmap; tl.rank_genes_groups; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py:520,variab,variable,520,src/scanpy/plotting/_anndata.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py,1,['variab'],['variable']
Modifiability,"""""""\; Logarithmize the data matrix. Computes :math:`X = \\log(X + 1)`,; where :math:`log` denotes the natural logarithm unless a different base is given. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; base; Base of the logarithm. Natural logarithm is used by default.; copy; If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned.; chunked; Process the data matrix in chunks, which will save memory.; Applies only to :class:`~anndata.AnnData`.; chunk_size; `n_obs` of the chunks to process the data in.; layer; Entry of layers to transform.; obsm; Entry of obsm to transform. Returns; -------; Returns or updates `data`, depending on `copy`.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:636,layers,layers,636,src/scanpy/preprocessing/_simple.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py,1,['layers'],['layers']
Modifiability,"""""""\; Map `adata_new` to the same representation as `adata`. This function identifies the representation which was used to; calculate neighbors in 'adata' and maps `adata_new` to; this representation.; Variables (`n_vars` and `var_names`) of `adata_new` should be the same; as in `adata`. `adata` refers to the :class:`~anndata.AnnData` object; that is passed during the initialization of an Ingest instance.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_ingest.py:202,Variab,Variables,202,src/scanpy/tools/_ingest.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_ingest.py,1,['Variab'],['Variables']
Modifiability,"""""""\; Markov Affinity-based Graph Imputation of Cells (MAGIC) API :cite:p:`vanDijk2018`. MAGIC is an algorithm for denoising and transcript recover of single cells; applied to single-cell sequencing data. MAGIC builds a graph from the data; and uses diffusion to smooth out noise and recover the data manifold. The algorithm implemented here has changed primarily in two ways; compared to the algorithm described in :cite:t:`vanDijk2018`. Firstly, we use; the adaptive kernel described in :cite:t:`Moon2019` for; improved stability. Secondly, data diffusion is applied; in the PCA space, rather than the data space, for speed and; memory improvements. More information and bug reports; `here <https://github.com/KrishnaswamyLab/MAGIC>`__. For help, visit; <https://krishnaswamylab.org/get-help>. Parameters; ----------; adata; An anndata file with `.raw` attribute representing raw counts.; name_list; Denoised genes to return. The default `'all_genes'`/`None`; may require a large amount of memory if the input data is sparse.; Another possibility is `'pca_only'`.; knn; number of nearest neighbors on which to build kernel.; decay; sets decay rate of kernel tails.; If None, alpha decaying kernel is not used.; knn_max; maximum number of nearest neighbors with nonzero connection.; If `None`, will be set to 3 * `knn`.; t; power to which the diffusion operator is powered.; This sets the level of diffusion. If 'auto', t is selected; according to the Procrustes disparity of the diffused data.; n_pca; Number of principal components to use for calculating; neighborhoods. For extremely large datasets, using; n_pca < 20 allows neighborhoods to be calculated in; roughly log(n_samples) time. If `None`, no PCA is performed.; solver; Which solver to use. ""exact"" uses the implementation described; in :cite:t:`vanDijk2018`. ""approximate"" uses a faster; implementation that performs imputation in the PCA space and then; projects back to the gene space. Note, the ""approximate"" solver may; return negat",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_magic.py:460,adapt,adaptive,460,src/scanpy/external/pp/_magic.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_magic.py,1,['adapt'],['adaptive']
Modifiability,"""""""\; Normalization and filtering as of :cite:t:`Zheng2017`. Reproduces the preprocessing of :cite:t:`Zheng2017` – the Cell Ranger R Kit of 10x; Genomics. Expects non-logarithmized data.; If using logarithmized data, pass `log=False`. The recipe runs the following steps. .. code:: python. sc.pp.filter_genes(adata, min_counts=1) # only consider genes with more than 1 count; sc.pp.normalize_per_cell( # normalize with total UMI count per cell; adata, key_n_counts='n_counts_all'; ); filter_result = sc.pp.filter_genes_dispersion( # select highly-variable genes; adata.X, flavor='cell_ranger', n_top_genes=n_top_genes, log=False; ); adata = adata[:, filter_result.gene_subset] # subset the genes; sc.pp.normalize_per_cell(adata) # renormalize after filtering; if log: sc.pp.log1p(adata) # log transform: adata.X = log(adata.X + 1); sc.pp.scale(adata) # scale to unit variance and shift to zero mean. Parameters; ----------; adata; Annotated data matrix.; n_top_genes; Number of genes to keep.; log; Take logarithm.; plot; Show a plot of the gene dispersion vs. mean relation.; copy; Return a copy of `adata` instead of updating it. Returns; -------; Returns or updates `adata` depending on `copy`.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py:547,variab,variable,547,src/scanpy/preprocessing/_recipes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py,1,['variab'],['variable']
Modifiability,"""""""\; Observation level metrics include:. `total_{var_type}_by_{expr_type}`; E.g. ""total_genes_by_counts"". Number of genes with positive counts in a cell.; `total_{expr_type}`; E.g. ""total_counts"". Total number of counts for a cell.; `pct_{expr_type}_in_top_{n}_{var_type}` – for `n` in `percent_top`; E.g. ""pct_counts_in_top_50_genes"". Cumulative percentage of counts; for 50 most expressed genes in a cell.; `total_{expr_type}_{qc_var}` – for `qc_var` in `qc_vars`; E.g. ""total_counts_mito"". Total number of counts for variables in; `qc_vars`.; `pct_{expr_type}_{qc_var}` – for `qc_var` in `qc_vars`; E.g. ""pct_counts_mito"". Proportion of total counts for a cell which; are mitochondrial.\; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_docs.py:521,variab,variables,521,src/scanpy/preprocessing/_docs.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_docs.py,1,['variab'],['variables']
Modifiability,"""""""\; Plot timeseries as heatmap. Parameters; ----------; X; Data array.; var_names; Array of strings naming variables stored in columns of X.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_utils.py:109,variab,variables,109,src/scanpy/plotting/_utils.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_utils.py,1,['variab'],['variables']
Modifiability,"""""""\; Principal component analysis :cite:p:`Pedregosa2011`. Computes PCA coordinates, loadings and variance decomposition.; Uses the implementation of *scikit-learn* :cite:p:`Pedregosa2011`. .. versionchanged:: 1.5.0. In previous versions, computing a PCA on a sparse matrix would make; a dense copy of the array for mean centering.; As of scanpy 1.5.0, mean centering is implicit.; While results are extremely similar, they are not exactly the same.; If you would like to reproduce the old results, pass a dense array. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; n_comps; Number of principal components to compute. Defaults to 50, or 1 - minimum; dimension size of selected representation.; layer; If provided, which element of layers to use for PCA.; zero_center; If `True`, compute standard PCA from covariance matrix.; If `False`, omit zero-centering variables; (uses *scikit-learn* :class:`~sklearn.decomposition.TruncatedSVD` or; *dask-ml* :class:`~dask_ml.decomposition.TruncatedSVD`),; which allows to handle sparse input efficiently.; Passing `None` decides automatically based on sparseness of the data.; svd_solver; SVD solver to use:. `None`; See `chunked` and `zero_center` descriptions to determine which class will be used.; Depending on the class and the type of X different values for default will be set.; If *scikit-learn* :class:`~sklearn.decomposition.PCA` is used, will give `'arpack'`,; if *scikit-learn* :class:`~sklearn.decomposition.TruncatedSVD` is used, will give `'randomized'`,; if *dask-ml* :class:`~dask_ml.decomposition.PCA` or :class:`~dask_ml.decomposition.IncrementalPCA` is used, will give `'auto'`,; if *dask-ml* :class:`~dask_ml.decomposition.TruncatedSVD` is used, will give `'tsqr'`; `'arpack'`; for the ARPACK wrapper in SciPy (:func:`~scipy.sparse.linalg.svds`); Not available with *dask* arrays.; `'randomized'`; for the randomized algorithm due to Halko (2009). Fo",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py:821,layers,layers,821,src/scanpy/preprocessing/_pca.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py,2,"['layers', 'variab']","['layers', 'variables']"
Modifiability,"""""""\; Processed 3k PBMCs from 10x Genomics. Processed using the basic tutorial :doc:`/tutorials/basics/clustering-2017`. For preprocessing, cells are filtered out that have few gene counts or too high a `percent_mito`.; The counts are logarithmized and only genes marked by :func:`~scanpy.pp.highly_variable_genes` are retained.; The :attr:`~anndata.AnnData.obs` variables `n_counts` and `percent_mito` are corrected for; using :func:`~scanpy.pp.regress_out`, and values are scaled and clipped by :func:`~scanpy.pp.scale`.; Finally, :func:`~scanpy.pp.pca` and :func:`~scanpy.pp.neighbors` are calculated. As analysis steps, the embeddings :func:`~scanpy.tl.tsne` and :func:`~scanpy.tl.umap` are performed.; Communities are identified using :func:`~scanpy.tl.louvain` and marker genes using :func:`~scanpy.tl.rank_genes_groups`. Returns; -------; Annotated data matrix. Examples; --------; >>> import scanpy as sc; >>> sc.datasets.pbmc3k_processed(); AnnData object with n_obs × n_vars = 2638 × 1838; obs: 'n_genes', 'percent_mito', 'n_counts', 'louvain'; var: 'n_cells'; uns: 'draw_graph', 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups'; obsm: 'X_pca', 'X_tsne', 'X_umap', 'X_draw_graph_fr'; varm: 'PCs'; obsp: 'distances', 'connectivities'; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py:363,variab,variables,363,src/scanpy/datasets/_datasets.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py,1,['variab'],['variables']
Modifiability,"""""""\; Rank genes according to contributions to PCs. Parameters; ----------; adata; Annotated data matrix.; components; For example, ``'1,2,3'`` means ``[1, 2, 3]``, first, second, third; principal component.; include_lowest; Whether to show the variables with both highest and lowest loadings.; show; Show the plot, do not return axis.; n_points; Number of variables to plot for each component.; save; If `True` or a `str`, save the figure.; A string is appended to the default filename.; Infer the filetype if ending on {`'.pdf'`, `'.png'`, `'.svg'`}. Examples; --------; .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc3k_processed(). Show first 3 components loadings. .. plot::; :context: close-figs. sc.pl.pca_loadings(adata, components = '1,2,3'). """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py:245,variab,variables,245,src/scanpy/plotting/_tools/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py,2,['variab'],['variables']
Modifiability,"""""""\; Rank genes for characterizing groups. Expects logarithmized data. Parameters; ----------; adata; Annotated data matrix.; groupby; The key of the observations grouping to consider.; mask_var; Select subset of genes to use in statistical tests.; use_raw; Use `raw` attribute of `adata` if present.; layer; Key from `adata.layers` whose value will be used to perform tests on.; groups; Subset of groups, e.g. [`'g1'`, `'g2'`, `'g3'`], to which comparison; shall be restricted, or `'all'` (default), for all groups. Note that if; `reference='rest'` all groups will still be used as the reference, not; just those specified in `groups`.; reference; If `'rest'`, compare each group to the union of the rest of the group.; If a group identifier, compare with respect to this group.; n_genes; The number of genes that appear in the returned tables.; Defaults to all genes.; method; The default method is `'t-test'`,; `'t-test_overestim_var'` overestimates variance of each group,; `'wilcoxon'` uses Wilcoxon rank-sum,; `'logreg'` uses logistic regression. See :cite:t:`Ntranos2019`,; `here <https://github.com/scverse/scanpy/issues/95>`__ and `here; <https://www.nxn.se/valent/2018/3/5/actionable-scrna-seq-clusters>`__,; for why this is meaningful.; corr_method; p-value correction method.; Used only for `'t-test'`, `'t-test_overestim_var'`, and `'wilcoxon'`.; tie_correct; Use tie correction for `'wilcoxon'` scores.; Used only for `'wilcoxon'`.; rankby_abs; Rank genes by the absolute value of the score, not by the; score. The returned scores are never the absolute values.; pts; Compute the fraction of cells expressing the genes.; key_added; The key in `adata.uns` information is saved to.; copy; Whether to copy `adata` or modify it inplace.; kwds; Are passed to test methods. Currently this affects only parameters that; are passed to :class:`sklearn.linear_model.LogisticRegression`.; For instance, you can pass `penalty='l1'` to try to come up with a; minimal set of genes that are good predi",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py:326,layers,layers,326,src/scanpy/tools/_rank_genes_groups.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py,1,['layers'],['layers']
Modifiability,"""""""\; Read 10x-Genomics-formatted hdf5 file. Parameters; ----------; filename; Path to a 10x hdf5 file.; genome; Filter expression to genes within this genome. For legacy 10x h5; files, this must be provided if the data contains more than one genome.; gex_only; Only keep 'Gene Expression' data and ignore other feature types,; e.g. 'Antibody Capture', 'CRISPR Guide Capture', or 'Custom'; backup_url; Retrieve the file from an URL if not present on disk. Returns; -------; Annotated data matrix, where observations/cells are named by their; barcode and variables/genes by gene name. Stores the following information:. :attr:`~anndata.AnnData.X`; The data matrix is stored; :attr:`~anndata.AnnData.obs_names`; Cell names; :attr:`~anndata.AnnData.var_names`; Gene names for a feature barcode matrix, probe names for a probe bc matrix; :attr:`~anndata.AnnData.var`\\ `['gene_ids']`; Gene IDs; :attr:`~anndata.AnnData.var`\\ `['feature_types']`; Feature types; :attr:`~anndata.AnnData.obs`\\ `[filtered_barcodes]`; filtered barcodes if present in the matrix; :attr:`~anndata.AnnData.var`; Any additional metadata present in /matrix/features is read in.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py:554,variab,variables,554,src/scanpy/readwrite.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py,1,['variab'],['variables']
Modifiability,"""""""\; Read 10x-Genomics-formatted mtx directory. Parameters; ----------; path; Path to directory for `.mtx` and `.tsv` files,; e.g. './filtered_gene_bc_matrices/hg19/'.; var_names; The variables index.; make_unique; Whether to make the variables index unique by appending '-1',; '-2' etc. or not.; cache; If `False`, read from source, if `True`, read from fast 'h5ad' cache.; cache_compression; See the h5py :ref:`dataset_compression`.; (Default: `settings.cache_compression`); gex_only; Only keep 'Gene Expression' data and ignore other feature types,; e.g. 'Antibody Capture', 'CRISPR Guide Capture', or 'Custom'; prefix; Any prefix before `matrix.mtx`, `genes.tsv` and `barcodes.tsv`. For instance,; if the files are named `patientA_matrix.mtx`, `patientA_genes.tsv` and; `patientA_barcodes.tsv` the prefix is `patientA_`.; (Default: no prefix). Returns; -------; An :class:`~anndata.AnnData` object; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py:185,variab,variables,185,src/scanpy/readwrite.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py,2,['variab'],['variables']
Modifiability,"""""""\; Regress out (mostly) unwanted sources of variation. Uses simple linear regression. This is inspired by Seurat's `regressOut`; function in R :cite:p:`Satija2015`. Note that this function tends to overcorrect; in certain circumstances as described in :issue:`526`. Parameters; ----------; adata; The annotated data matrix.; keys; Keys for observation annotation on which to regress on.; layer; If provided, which element of layers to regress on.; n_jobs; Number of jobs for parallel computation.; `None` means using :attr:`scanpy._settings.ScanpyConfig.n_jobs`.; copy; Determines whether a copy of `adata` is returned. Returns; -------; Returns `None` if `copy=False`, else returns an updated `AnnData` object. Sets the following fields:. `adata.X` | `adata.layers[layer]` : :class:`numpy.ndarray` | :class:`scipy.sparse._csr.csr_matrix` (dtype `float`); Corrected count data matrix.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:428,layers,layers,428,src/scanpy/preprocessing/_simple.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py,2,['layers'],['layers']
Modifiability,"""""""\; Run Diffusion maps using the adaptive anisotropic kernel :cite:p:`Setty2019`. Palantir is an algorithm to align cells along differentiation trajectories.; Palantir models differentiation as a stochastic process where stem cells; differentiate to terminally differentiated cells by a series of steps through; a low dimensional phenotypic manifold. Palantir effectively captures the; continuity in cell states and the stochasticity in cell fate determination.; Palantir has been designed to work with multidimensional single cell data; from diverse technologies such as Mass cytometry and single cell RNA-seq. .. note::; More information and bug reports `here <https://github.com/dpeerlab/Palantir>`__. Parameters; ----------; adata; An AnnData object.; n_components; Number of diffusion components.; knn; Number of nearest neighbors for graph construction.; alpha; Normalization parameter for the diffusion operator.; use_adjacency_matrix; Use adaptive anisotropic adjacency matrix, instead of PCA projections; (default) to compute diffusion components.; distances_key; With `use_adjacency_matrix=True`, use the indicated distances key for `.obsp`.; If `None`, `'distances'`.; n_eigs; Number of eigen vectors to use. If `None` specified, the number of eigen; vectors will be determined using eigen gap. Passed to; `palantir.utils.determine_multiscale_space`.; impute_data; Impute data using MAGIC.; n_steps; Number of steps in the diffusion operator. Passed to; `palantir.utils.run_magic_imputation`.; copy; Return a copy instead of writing to `adata`. Returns; -------; Depending on `copy`, returns or updates `adata` with the following fields:. **Diffusion maps**,; used for magic imputation, and to generate multi-scale data matrix,. - X_palantir_diff_comp - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.obsm`, dtype `float`); Array of Diffusion components.; - palantir_EigenValues - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.uns`, dtype `float`); Array of corresponding eigen value",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_palantir.py:35,adapt,adaptive,35,src/scanpy/external/tl/_palantir.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_palantir.py,2,['adapt'],['adaptive']
Modifiability,"""""""\; Run Diffusion maps using the adaptive anisotropic kernel; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_palantir.py:35,adapt,adaptive,35,src/scanpy/external/tl/_palantir.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_palantir.py,1,['adapt'],['adaptive']
Modifiability,"""""""\; Sample coupling matrix. Checks that returned graphs contain no self-cycles. Parameters; ----------; dim; dimension of coupling matrix.; connectivity; fraction of connectivity, fully connected means 1.,; not-connected means 0, in the case of fully connected, one has; dim*(dim-1)/2 edges in the graph. Returns; -------; coupl; coupling matrix; adj; adjancancy matrix; adj_signed; signed adjacancy matrix; n_edges; Number of edges; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:13,coupling,coupling,13,src/scanpy/tools/_sim.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py,3,['coupling'],['coupling']
Modifiability,"""""""\; Scale data to unit variance and zero mean. .. note::; Variables (genes) that do not display any variation (are constant across; all observations) are retained and (for zero_center==True) set to 0; during this operation. In the future, they might be set to NaNs. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; zero_center; If `False`, omit zero-centering variables, which allows to handle sparse; input efficiently.; max_value; Clip (truncate) to this value after scaling. If `None`, do not clip.; copy; Whether this function should be performed inplace. If an AnnData object; is passed, this also determines if a copy is returned.; layer; If provided, which element of layers to scale.; obsm; If provided, which element of obsm to scale.; mask_obs; Restrict both the derivation of scaling parameters and the scaling itself; to a certain set of observations. The mask is specified as a boolean array; or a string referring to an array in :attr:`~anndata.AnnData.obs`.; This will transform data from csc to csr format if `issparse(data)`. Returns; -------; Returns `None` if `copy=False`, else returns an updated `AnnData` object. Sets the following fields:. `adata.X` | `adata.layers[layer]` : :class:`numpy.ndarray` | :class:`scipy.sparse._csr.csr_matrix` (dtype `float`); Scaled count data matrix.; `adata.var['mean']` : :class:`pandas.Series` (dtype `float`); Means per gene before scaling.; `adata.var['std']` : :class:`pandas.Series` (dtype `float`); Standard deviations per gene before scaling.; `adata.var['var']` : :class:`pandas.Series` (dtype `float`); Variances per gene before scaling.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scale.py:60,Variab,Variables,60,src/scanpy/preprocessing/_scale.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scale.py,4,"['Variab', 'layers', 'variab']","['Variables', 'layers', 'variables']"
Modifiability,"""""""\; Scatter plot along observations or variables axes. Color the plot using annotations of observations (`.obs`), variables; (`.var`) or expression of genes (`.var_names`). Parameters; ----------; adata; Annotated data matrix.; x; x coordinate.; y; y coordinate.; color; Keys for annotations of observations/cells or variables/genes,; or a hex color specification, e.g.,; `'ann1'`, `'#fe57a1'`, or `['ann1', 'ann2']`.; use_raw; Whether to use `raw` attribute of `adata`. Defaults to `True` if `.raw` is present.; layers; Use the `layers` attribute of `adata` if present: specify the layer for; `x`, `y` and `color`. If `layers` is a string, then it is expanded to; `(layers, layers, layers)`.; basis; String that denotes a plotting tool that computed coordinates.; {scatter_temp}; {show_save_ax}. Returns; -------; If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py:41,variab,variables,41,src/scanpy/plotting/_anndata.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py,9,"['layers', 'variab']","['layers', 'variables']"
Modifiability,"""""""\; Scatter plot in PCA coordinates. Use the parameter `annotate_var_explained` to annotate the explained variance. Parameters; ----------; {adata_color_etc}; annotate_var_explained; {scatter_bulk}; {show_save_ax}. Returns; -------; If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. Examples; --------. .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc3k_processed(); sc.pl.pca(adata). Colour points by discrete variable (Louvain clusters). .. plot::; :context: close-figs. sc.pl.pca(adata, color=""louvain""). Colour points by gene expression. .. plot::; :context: close-figs. sc.pl.pca(adata, color=""CST3""). .. currentmodule:: scanpy. See also; --------; pp.pca; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/scatterplots.py:460,variab,variable,460,src/scanpy/plotting/_tools/scatterplots.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/scatterplots.py,1,['variab'],['variable']
Modifiability,"""""""\; Scatter plot in UMAP basis. Parameters; ----------; {adata_color_etc}; {edges_arrows}; {scatter_bulk}; {show_save_ax}. Returns; -------; If `show==False` a :class:`~matplotlib.axes.Axes` or a list of it. Examples; --------. .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); sc.pl.umap(adata). Colour points by discrete variable (Louvain clusters). .. plot::; :context: close-figs. sc.pl.umap(adata, color=""louvain""). Colour points by gene expression. .. plot::; :context: close-figs. sc.pl.umap(adata, color=""HES4""). Plot muliple umaps for different gene expressions. .. plot::; :context: close-figs. sc.pl.umap(adata, color=[""HES4"", ""TNFRSF4""]). .. currentmodule:: scanpy. See also; --------; tl.umap; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/scatterplots.py:368,variab,variable,368,src/scanpy/plotting/_tools/scatterplots.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/scatterplots.py,1,['variab'],['variable']
Modifiability,"""""""\; See `highly_variable_genes`. For further implementation details see https://www.overleaf.com/read/ckptrbgzzzpg. Returns; -------; Depending on `inplace` returns calculated metrics (:class:`~pd.DataFrame`) or; updates `.var` with the following fields:. highly_variable : :class:`bool`; boolean indicator of highly-variable genes.; **means**; means per gene.; **variances**; variance per gene.; **variances_norm**; normalized variance per gene, averaged in the case of multiple batches.; highly_variable_rank : :class:`float`; Rank of the gene according to normalized variance, median rank in the case of multiple batches.; highly_variable_nbatches : :class:`int`; If batch_key is given, this denotes in how many batches genes are detected as HVG.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py:319,variab,variable,319,src/scanpy/preprocessing/_highly_variable_genes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py,1,['variab'],['variable']
Modifiability,"""""""\; Select highly variable genes using analytic Pearson residuals :cite:p:`Lause2021`. In :cite:t:`Lause2021`, Pearson residuals of a negative binomial offset model are computed; (with overdispersion `theta` shared across genes). By default, overdispersion; `theta=100` is used and residuals are clipped to `sqrt(n_obs)`. Finally, genes; are ranked by residual variance. Expects raw count input. Parameters; ----------; {adata}; {dist_params}; {genes_batch_chunk}; flavor; Choose the flavor for identifying highly variable genes. In this experimental; version, only 'pearson_residuals' is functional.; {check_values}; {layer}; subset; If `True`, subset the data to highly-variable genes after finding them.; Otherwise merely indicate highly variable genes in `adata.var` (see below).; {inplace}. Returns; -------; If `inplace=True`, `adata.var` is updated with the following fields. Otherwise,; returns the same fields as :class:`~pandas.DataFrame`. highly_variable : :class:`bool`; boolean indicator of highly-variable genes.; means : :class:`float`; means per gene.; variances : :class:`float`; variance per gene.; residual_variances : :class:`float`; For `flavor='pearson_residuals'`, residual variance per gene. Averaged in the; case of multiple batches.; highly_variable_rank : :class:`float`; For `flavor='pearson_residuals'`, rank of the gene according to residual.; variance, median rank in the case of multiple batches.; highly_variable_nbatches : :class:`int`; If `batch_key` given, denotes in how many batches genes are detected as HVG.; highly_variable_intersection : :class:`bool`; If `batch_key` given, denotes the genes that are highly variable in all batches. Notes; -----; Experimental version of `sc.pp.highly_variable_genes()`; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_highly_variable_genes.py:20,variab,variable,20,src/scanpy/experimental/pp/_highly_variable_genes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_highly_variable_genes.py,6,['variab'],['variable']
Modifiability,"""""""\; Self-Assembling Manifolds single-cell RNA sequencing analysis tool :cite:p:`Tarashansky2019`. SAM iteratively rescales the input gene expression matrix to emphasize; genes that are spatially variable along the intrinsic manifold of the data.; It outputs the gene weights, nearest neighbor matrix, and a 2D projection. The AnnData input should contain unstandardized, non-negative values.; Preferably, the data should be log-normalized and no genes should be filtered out. Parameters; ----------. k; The number of nearest neighbors to identify for each cell. distance; The distance metric to use when identifying nearest neighbors.; Can be any of the distance metrics supported by; :func:`~scipy.spatial.distance.pdist`. max_iter; The maximum number of iterations SAM will run. projection; If 'tsne', generates a t-SNE embedding. If 'umap', generates a UMAP; embedding. If 'None', no embedding will be generated. standardization; If 'Normalizer', use sklearn.preprocessing.Normalizer, which; normalizes expression data prior to PCA such that each cell has; unit L2 norm. If 'StandardScaler', use; sklearn.preprocessing.StandardScaler, which normalizes expression; data prior to PCA such that each gene has zero mean and unit; variance. Otherwise, do not normalize the expression data. We; recommend using 'StandardScaler' for large datasets with many; expected cell types and 'Normalizer' otherwise. If 'None', no; transformation is applied. num_norm_avg; The top 'num_norm_avg' dispersions are averaged to determine the; normalization factor when calculating the weights. This prevents; genes with large spatial dispersions from skewing the distribution; of weights. weight_pcs; If True, scale the principal components by their eigenvalues. In; datasets with many expected cell types, setting this to False might; improve the resolution as these cell types might be encoded by lower-; variance principal components. sparse_pca; If True, uses an implementation of PCA that accepts sparse inputs.;",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_sam.py:197,variab,variable,197,src/scanpy/external/tl/_sam.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_sam.py,1,['variab'],['variable']
Modifiability,"""""""\; Simulate doublets by adding the counts of random observed transcriptome pairs. Parameters; ----------; adata; The annotated data matrix of shape ``n_obs`` × ``n_vars``. Rows; correspond to cells and columns to genes. Genes should have been; filtered for expression and variability, and the object should contain; raw expression of the same dimensions.; layer; Layer of adata where raw values are stored, or 'X' if values are in .X.; sim_doublet_ratio; Number of doublets to simulate relative to the number of observed; transcriptomes. If `None`, self.sim_doublet_ratio is used.; synthetic_doublet_umi_subsampling; Rate for sampling UMIs when creating synthetic doublets. If 1.0,; each doublet is created by simply adding the UMIs from two randomly; sampled observed transcriptomes. For values less than 1, the; UMI counts are added and then randomly sampled at the specified; rate. Returns; -------; adata : anndata.AnnData with simulated doublets in .X; Adds fields to ``adata``:. ``.obsm['scrublet']['doublet_parents']``; Pairs of ``.obs_names`` used to generate each simulated doublet transcriptome. ``.uns['scrublet']['parameters']``; Dictionary of Scrublet parameters. See also; --------; :func:`~scanpy.pp.scrublet`: Main way of running Scrublet, runs; preprocessing, doublet simulation (this function) and calling.; :func:`~scanpy.pl.scrublet_score_distribution`: Plot histogram of doublet; scores for observed transcriptomes and simulated doublets.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py:275,variab,variability,275,src/scanpy/preprocessing/_scrublet/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py,1,['variab'],['variability']
Modifiability,"""""""\; Subsampled and processed 68k PBMCs. `PBMC 68k dataset`_ from 10x Genomics. The original PBMC 68k dataset was preprocessed with steps including; :func:`~scanpy.pp.normalize_total`\\ [#norm]_ and :func:`~scanpy.pp.scale`.; It was saved keeping only 724 cells and 221 highly variable genes. The saved file contains the annotation of cell types (key: `'bulk_labels'`),; UMAP coordinates, louvain clustering and gene rankings based on the; `bulk_labels`. .. [#norm] Back when the dataset was created, :func:`~scanpy.pp.normalize_per_cell` was used instead.; .. _PBMC 68k dataset: https://www.10xgenomics.com/datasets/fresh-68-k-pbm-cs-donor-a-1-standard-1-1-0. Returns; -------; Annotated data matrix. Examples; --------; >>> import scanpy as sc; >>> sc.datasets.pbmc68k_reduced(); AnnData object with n_obs × n_vars = 700 × 765; obs: 'bulk_labels', 'n_genes', 'percent_mito', 'n_counts', 'S_score', 'G2M_score', 'phase', 'louvain'; var: 'n_counts', 'means', 'dispersions', 'dispersions_norm', 'highly_variable'; uns: 'bulk_labels_colors', 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups'; obsm: 'X_pca', 'X_umap'; varm: 'PCs'; obsp: 'distances', 'connectivities'; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py:278,variab,variable,278,src/scanpy/datasets/_datasets.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py,1,['variab'],['variable']
Modifiability,"""""""\; Use harmonypy :cite:p:`Korsunsky2019` to integrate different experiments. Harmony :cite:p:`Korsunsky2019` is an algorithm for integrating single-cell; data from multiple experiments. This function uses the python; port of Harmony, ``harmonypy``, to integrate single-cell data; stored in an AnnData object. As Harmony works by adjusting the; principal components, this function should be run after performing; PCA but before computing the neighbor graph, as illustrated in the; example below. Parameters; ----------; adata; The annotated data matrix.; key; The name of the column in ``adata.obs`` that differentiates; among experiments/batches.; basis; The name of the field in ``adata.obsm`` where the PCA table is; stored. Defaults to ``'X_pca'``, which is the default for; ``sc.pp.pca()``.; adjusted_basis; The name of the field in ``adata.obsm`` where the adjusted PCA; table will be stored after running this function. Defaults to; ``X_pca_harmony``.; kwargs; Any additional arguments will be passed to; ``harmonypy.run_harmony()``. Returns; -------; Updates adata with the field ``adata.obsm[obsm_out_field]``,; containing principal components adjusted by Harmony such that; different experiments are integrated. Example; -------; First, load libraries and example dataset, and preprocess. >>> import scanpy as sc; >>> import scanpy.external as sce; >>> adata = sc.datasets.pbmc3k(); >>> sc.pp.recipe_zheng17(adata); >>> sc.pp.pca(adata). We now arbitrarily assign a batch metadata variable to each cell; for the sake of example, but during real usage there would already; be a column in ``adata.obs`` giving the experiment each cell came; from. >>> adata.obs['batch'] = 1350*['a'] + 1350*['b']. Finally, run harmony. Afterwards, there will be a new table in; ``adata.obsm`` containing the adjusted PC's. >>> sce.pp.harmony_integrate(adata, 'batch'); >>> 'X_pca_harmony' in adata.obsm; True; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_harmony_integrate.py:1493,variab,variable,1493,src/scanpy/external/pp/_harmony_integrate.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_harmony_integrate.py,1,['variab'],['variable']
Modifiability,"""""""\; Variable level metrics include:. `total_{expr_type}`; E.g. ""total_counts"". Sum of counts for a gene.; `n_genes_by_{expr_type}`; E.g. ""n_genes_by_counts"". The number of genes with at least 1 count in a cell. Calculated for all cells.; `mean_{expr_type}`; E.g. ""mean_counts"". Mean expression over all cells.; `n_cells_by_{expr_type}`; E.g. ""n_cells_by_counts"". Number of cells this expression is; measured in.; `pct_dropout_by_{expr_type}`; E.g. ""pct_dropout_by_counts"". Percentage of cells this feature does; not appear in.\; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_docs.py:6,Variab,Variable,6,src/scanpy/preprocessing/_docs.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_docs.py,1,['Variab'],['Variable']
Modifiability,"""""""\; Violin plot. Wraps :func:`seaborn.violinplot` for :class:`~anndata.AnnData`. Parameters; ----------; adata; Annotated data matrix.; keys; Keys for accessing variables of `.var_names` or fields of `.obs`.; groupby; The key of the observation grouping to consider.; log; Plot on logarithmic axis.; use_raw; Whether to use `raw` attribute of `adata`. Defaults to `True` if `.raw` is present.; stripplot; Add a stripplot on top of the violin plot.; See :func:`~seaborn.stripplot`.; jitter; Add jitter to the stripplot (only when stripplot is True); See :func:`~seaborn.stripplot`.; size; Size of the jitter points.; layer; Name of the AnnData object layer that wants to be plotted. By; default adata.raw.X is plotted. If `use_raw=False` is set,; then `adata.X` is plotted. If `layer` is set to a valid layer name,; then the layer is plotted. `layer` takes precedence over `use_raw`.; scale; The method used to scale the width of each violin.; If 'width' (the default), each violin will have the same width.; If 'area', each violin will have the same area.; If 'count', a violin’s width corresponds to the number of observations.; order; Order in which to show the categories.; multi_panel; Display keys in multiple panels also when `groupby is not None`.; xlabel; Label of the x axis. Defaults to `groupby` if `rotation` is `None`,; otherwise, no label is shown.; ylabel; Label of the y axis. If `None` and `groupby` is `None`, defaults; to `'value'`. If `None` and `groubpy` is not `None`, defaults to `keys`.; rotation; Rotation of xtick labels.; {show_save_ax}; **kwds; Are passed to :func:`~seaborn.violinplot`. Returns; -------; A :class:`~matplotlib.axes.Axes` object if `ax` is `None` else `None`. Examples; --------. .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); sc.pl.violin(adata, keys='S_score'). Plot by category. Rotate x-axis labels so that they do not overlap. .. plot::; :context: close-figs. sc.pl.violin(adata, keys='S_score', groupby",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py:163,variab,variables,163,src/scanpy/plotting/_anndata.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py,1,['variab'],['variables']
Modifiability,"""""""\; Z-score standardize each variable/gene in X :cite:p:`Weinreb2017`. Use `scale` instead. Parameters; ----------; X; Data matrix. Rows correspond to cells and columns to genes. Returns; -------; Z-score standardized version of the data matrix.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/__init__.py:31,variab,variable,31,src/scanpy/preprocessing/_deprecated/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/__init__.py,1,['variab'],['variable']
Modifiability,"""""""\; adata; Annotated data matrix.; color; Keys for annotations of observations/cells or variables/genes, e.g.,; `'ann1'` or `['ann1', 'ann2']`.; gene_symbols; Column name in `.var` DataFrame that stores gene symbols. By default `var_names`; refer to the index column of the `.var` DataFrame. Setting this option allows; alternative names to be used.; use_raw; Use `.raw` attribute of `adata` for coloring with gene expression. If `None`,; defaults to `True` if `layer` isn't provided and `adata.raw` is present.; layer; Name of the AnnData object layer that wants to be plotted. By default; adata.raw.X is plotted. If `use_raw=False` is set, then `adata.X` is plotted.; If `layer` is set to a valid layer name, then the layer is plotted. `layer`; takes precedence over `use_raw`.\; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_docs.py:90,variab,variables,90,src/scanpy/plotting/_docs.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_docs.py,1,['variab'],['variables']
Modifiability,"""""""\; add_outline; If set to True, this will add a thin border around groups of dots. In some situations; this can enhance the aesthetics of the resulting image; outline_color; Tuple with two valid color names used to adjust the add_outline. The first color is the; border color (default: black), while the second color is a gap color between the; border color and the scatter dot (default: white).; outline_width; Tuple with two width numbers used to adjust the outline. The first value is the width; of the border color as a fraction of the scatter dot size (default: 0.3). The second value is; width of the gap color (default: 0.05).\; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_docs.py:115,enhance,enhance,115,src/scanpy/plotting/_docs.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_docs.py,1,['enhance'],['enhance']
Modifiability,"""""""\; color_map; Color map to use for continous variables. Can be a name or a; :class:`~matplotlib.colors.Colormap` instance (e.g. `""magma`"", `""viridis""`; or `mpl.cm.cividis`), see :func:`~matplotlib.pyplot.get_cmap`.; If `None`, the value of `mpl.rcParams[""image.cmap""]` is used.; The default `color_map` can be set using :func:`~scanpy.set_figure_params`.; palette; Colors to use for plotting categorical annotation groups.; The palette can be a valid :class:`~matplotlib.colors.ListedColormap` name; (`'Set2'`, `'tab20'`, …), a :class:`~cycler.Cycler` object, a dict mapping; categories to colors, or a sequence of colors. Colors must be valid to; matplotlib. (see :func:`~matplotlib.colors.is_color_like`).; If `None`, `mpl.rcParams[""axes.prop_cycle""]` is used unless the categorical; variable already has colors stored in `adata.uns[""{var}_colors""]`.; If provided, values of `adata.uns[""{var}_colors""]` will be set.\; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_docs.py:48,variab,variables,48,src/scanpy/plotting/_docs.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_docs.py,2,['variab'],"['variable', 'variables']"
Modifiability,"""""""\; expr_type; Name of kind of values in X.; var_type; The kind of thing the variables are.\; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_docs.py:79,variab,variables,79,src/scanpy/preprocessing/_docs.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_docs.py,1,['variab'],['variables']
Modifiability,"""""""\; layer; If provided, use `adata.layers[layer]` for expression values instead; of `adata.X`.; use_raw; If True, use `adata.raw.X` for expression values instead of `adata.X`.\; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_docs.py:37,layers,layers,37,src/scanpy/preprocessing/_docs.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_docs.py,1,['layers'],['layers']
Modifiability,"""""""\; mask_var; To run only on a certain set of genes given by a boolean array; or a string referring to an array in :attr:`~anndata.AnnData.var`.; By default, uses `.var['highly_variable']` if available, else everything.; use_highly_variable; Whether to use highly variable genes only, stored in; `.var['highly_variable']`.; By default uses them if they have been determined beforehand. .. deprecated:: 1.10.0; Use `mask_var` instead; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_docs.py:266,variab,variable,266,src/scanpy/preprocessing/_docs.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_docs.py,1,['variab'],['variable']
Modifiability,"""""""\; n_top_genes; Number of highly-variable genes to keep. Mandatory if `flavor='seurat_v3'` or; `flavor='pearson_residuals'`.; batch_key; If specified, highly-variable genes are selected within each batch separately; and merged. This simple process avoids the selection of batch-specific genes; and acts as a lightweight batch correction method. Genes are first sorted by; how many batches they are a HVG. If `flavor='pearson_residuals'`, ties are; broken by the median rank (across batches) based on within-batch residual; variance.; chunksize; If `flavor='pearson_residuals'`, this dertermines how many genes are processed at; once while computing the residual variance. Choosing a smaller value will reduce; the required memory.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/_docs.py:36,variab,variable,36,src/scanpy/experimental/_docs.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/_docs.py,2,['variab'],['variable']
Modifiability,"""""""\; qc_vars; Keys for boolean columns of `.var` which identify variables you could; want to control for (e.g. ""ERCC"" or ""mito"").; percent_top; List of ranks (where genes are ranked by expression) at which the cumulative; proportion of expression will be reported as a percentage. This can be used to; assess library complexity. Ranks are considered 1-indexed, and if empty or None; don't calculate. E.g. `percent_top=[50]` finds cumulative proportion to the 50th most expressed gene.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_docs.py:65,variab,variables,65,src/scanpy/preprocessing/_docs.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_docs.py,1,['variab'],['variables']
Modifiability,"""""""\; subset; Inplace subset to highly-variable genes if `True` otherwise merely indicate; highly variable genes.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/_docs.py:39,variab,variable,39,src/scanpy/experimental/_docs.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/_docs.py,2,['variab'],['variable']
Modifiability,"""""""\; title; Title for the figure; colorbar_title; Title for the color bar. New line character (\\n) can be used.; cmap; String denoting matplotlib color map.; standard_scale; Whether or not to standardize the given dimension between 0 and 1, meaning for; each variable or group, subtract the minimum and divide each by its maximum.; swap_axes; By default, the x axis contains `var_names` (e.g. genes) and the y axis; the `groupby` categories. By setting `swap_axes` then x are the; `groupby` categories and y the `var_names`.; return_fig; Returns :class:`DotPlot` object. Useful for fine-tuning; the plot. Takes precedence over `show=False`.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_baseplot_class.py:261,variab,variable,261,src/scanpy/plotting/_baseplot_class.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_baseplot_class.py,1,['variab'],['variable']
Modifiability,"# -- General configuration ------------------------------------------------",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/docs/conf.py:13,config,configuration,13,docs/conf.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/docs/conf.py,1,['config'],['configuration']
Modifiability,"# Convert the Python list of lists to a Numpy array and transpose to match; # the Scanpy convention of storing samples in rows and variables in colums.",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py:131,variab,variables,131,src/scanpy/readwrite.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py,1,['variab'],['variables']
Modifiability,"# Doublet simulation will be based on the un-normalised counts, but on the; # selection of genes following normalisation and variability filtering. So; # we need to save the raw and subset at the same time.",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py:125,variab,variability,125,src/scanpy/preprocessing/_scrublet/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py,1,['variab'],['variability']
Modifiability,"# Get rank per gene within each batch; # argsort twice gives ranks, small rank means most variable",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_highly_variable_genes.py:90,variab,variable,90,src/scanpy/experimental/pp/_highly_variable_genes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_highly_variable_genes.py,1,['variab'],['variable']
Modifiability,"# If the second largest element is smaller than threshold; # set check to False, i.e. at least two elements; # need to change in order to have a branching.; # If we observe all parameters of the system,; # a new attractor state must involve changes in two; # variables.",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:259,variab,variables,259,src/scanpy/tools/_sim.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py,1,['variab'],['variables']
Modifiability,"# Process layers",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py:10,layers,layers,10,src/scanpy/plotting/_anndata.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py,1,['layers'],['layers']
Modifiability,"# Project root; # extlinks config",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/docs/conf.py:27,config,config,27,docs/conf.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/docs/conf.py,1,['config'],['config']
Modifiability,"# TODO Evaluate whether to assign the variable or not",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py:38,variab,variable,38,src/scanpy/tools/_dpt.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py,1,['variab'],['variable']
Modifiability,"# TODO: Report more context on the fields being compared on error; # TODO: Allow specifying paths to ignore on comparison; ###########################; # Representation choice; ###########################; # These functions can be used to check that functions are correctly using arugments like `layers`, `obsm`, etc.",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/testing/scanpy/_helpers/__init__.py:296,layers,layers,296,src/testing/scanpy/_helpers/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/testing/scanpy/_helpers/__init__.py,1,['layers'],['layers']
Modifiability,"# This is a quick and dirty way for adapting scales across several; # keys if groupby is None.",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py:36,adapt,adapting,36,src/scanpy/plotting/_anndata.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py,1,['adapt'],['adapting']
Modifiability,"# This tool has the purpose to take a set of genes (possibly already pre-selected) and analyze AUC.; # Those and only those are eliminated who are dominated completely; # TODO: Potentially (But not till tomorrow), this can be adapted to only consider the AUC in the given; # TODO: optimization frame",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_top_genes.py:226,adapt,adapted,226,src/scanpy/tools/_top_genes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_top_genes.py,1,['adapt'],['adapted']
Modifiability,"# Without highly variable genes, we don’t use a mask by default",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py:17,variab,variable,17,src/scanpy/preprocessing/_pca.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py,1,['variab'],['variable']
Modifiability,"# a unit is the distance between two y-axis ticks; # set by default the violin plot cut=0 to limit the extend; # of the violin plot as this produces better plots that wont extend; # to negative values for example. From seaborn.violin documentation:; #; # cut: Distance, in units of bandwidth size, to extend the density past; # the extreme datapoints. Set to 0 to limit the violin range within; # the range of the observed data (i.e., to have the same effect as; # trim=True in ggplot.",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_stacked_violin.py:103,extend,extend,103,src/scanpy/plotting/_stacked_violin.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_stacked_violin.py,3,['extend'],['extend']
Modifiability,"# adapt marker_genes for cluster (so as to have some form of reasonable input",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_rank_genes_groups.py:2,adapt,adapt,2,tests/test_rank_genes_groups.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_rank_genes_groups.py,1,['adapt'],['adapt']
Modifiability,"# argsort twice gives ranks, small rank means most variable",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py:51,variab,variable,51,src/scanpy/preprocessing/_highly_variable_genes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py,1,['variab'],['variable']
Modifiability,"# check that the coupling matrix does not have eigenvalues; # greater than 1, which would lead to an exploding var process",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:17,coupling,coupling,17,src/scanpy/tools/_sim.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py,1,['coupling'],['coupling']
Modifiability,"# check whether there are coupling matrix entries for each parent",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:26,coupling,coupling,26,src/scanpy/tools/_sim.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py,1,['coupling'],['coupling']
Modifiability,"# coupling function / model",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:2,coupling,coupling,2,src/scanpy/tools/_sim.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py,1,['coupling'],['coupling']
Modifiability,"# for clarity, rename variable",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py:22,variab,variable,22,src/scanpy/tools/_rank_genes_groups.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py,2,['variab'],['variable']
Modifiability,"# for each barcode get empirical noise and signal distribution parameterization",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py:63,parameteriz,parameterization,63,src/scanpy/external/pp/_hashsolo.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py,1,['parameteriz'],['parameterization']
Modifiability,"# i.e., all of `varm`, `obsm`, `layers` are None so we use `X` which must be transposed",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/_aggregated.py:32,layers,layers,32,src/scanpy/get/_aggregated.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/_aggregated.py,1,['layers'],['layers']
Modifiability,"# init variables",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:7,variab,variables,7,src/scanpy/tools/_sim.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py,1,['variab'],['variables']
Modifiability,"# make line a bit ticker to see the extend of the yaxis in the; # final plot",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_stacked_violin.py:36,extend,extend,36,src/scanpy/plotting/_stacked_violin.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_stacked_violin.py,1,['extend'],['extend']
Modifiability,"# noqa: F841 TODO Evaluate whether to assign the variable or not",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py:49,variab,variable,49,src/scanpy/tools/_dpt.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py,1,['variab'],['variable']
Modifiability,"# number of variables in output if inplace=False",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_normalization.py:12,variab,variables,12,tests/test_normalization.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_normalization.py,1,['variab'],['variables']
Modifiability,"# read couplings via names",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:7,coupling,couplings,7,src/scanpy/tools/_sim.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py,1,['coupling'],['couplings']
Modifiability,"# reduce the value of the coupling of the repressing genes; # otherwise completely unstable solutions are obtained",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:26,coupling,coupling,26,src/scanpy/tools/_sim.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py,1,['coupling'],['coupling']
Modifiability,"# regress on a single categorical variable",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:34,variab,variable,34,src/scanpy/preprocessing/_simple.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py,1,['variab'],['variable']
Modifiability,"# regress on one or several ordinal variables",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:36,variab,variables,36,src/scanpy/preprocessing/_simple.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py,1,['variab'],['variables']
Modifiability,"# set a lower bound for the coupling parameters; # they ought not to be smaller than 0.1; # and not be larger than 0.4",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:28,coupling,coupling,28,src/scanpy/tools/_sim.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py,1,['coupling'],['coupling']
Modifiability,"# set by default the violin plot cut=0 to limit the extend; # of the violin plot (see stacked_violin code) for more info.",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py:52,extend,extend,52,src/scanpy/plotting/_anndata.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py,1,['extend'],['extend']
Modifiability,"# set sign for coupling",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:15,coupling,coupling,15,src/scanpy/tools/_sim.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py,1,['coupling'],['coupling']
Modifiability,"# set the coupling matrix, and with that the adjacency matrix",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:10,coupling,coupling,10,src/scanpy/tools/_sim.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py,1,['coupling'],['coupling']
Modifiability,"# setup variables",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/benchmarks/benchmarks/preprocessing_counts.py:8,variab,variables,8,benchmarks/benchmarks/preprocessing_counts.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/benchmarks/benchmarks/preprocessing_counts.py,3,['variab'],['variables']
Modifiability,"# this number includes parents (other variables); # and the variable itself, therefore its; # self.maxnpar+2 in the following line",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:38,variab,variables,38,src/scanpy/tools/_sim.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py,2,['variab'],"['variable', 'variables']"
Modifiability,"# to maintain the fixed height size of the legends, a; # spacer of variable height is added at the bottom.; # The structure for the legends is:; # first row: variable space to keep the other rows of; # the same size (avoid stretching); # second row: legend for dot size; # third row: spacer to avoid color and size legend titles to overlap; # fourth row: colorbar",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_dotplot.py:67,variab,variable,67,src/scanpy/plotting/_dotplot.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_dotplot.py,2,['variab'],['variable']
Modifiability,"# to maintain the fixed height size of the legends, a; # spacer of variable height is added at top and bottom.; # The structure for the legends is:; # first row: variable space to keep the first rows of the same size; # second row: size legend",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_baseplot_class.py:67,variab,variable,67,src/scanpy/plotting/_baseplot_class.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_baseplot_class.py,2,['variab'],['variable']
Modifiability,"# update variables",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_utils.py:9,variab,variables,9,src/scanpy/plotting/_utils.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_utils.py,1,['variab'],['variables']
Modifiability,"# we already built the coupling matrix in set_coupl20()",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:23,coupling,coupling,23,src/scanpy/tools/_sim.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py,1,['coupling'],['coupling']
Modifiability,"# write coupling via names",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:8,coupling,coupling,8,src/scanpy/tools/_sim.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py,1,['coupling'],['coupling']
Modifiability,"# write files with adjacancy and coupling matrices",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:33,coupling,coupling,33,src/scanpy/tools/_sim.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py,1,['coupling'],['coupling']
Modifiability,"# write simulated data; # the binary mode option in the following line is a fix for python 3; # variable names",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:96,variab,variable,96,src/scanpy/tools/_sim.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py,1,['variab'],['variable']
Modifiability,"(cell) has a total; count equal to the median of total counts for observations (cells); before normalization.; exclude_highly_expressed; Exclude (very) highly expressed genes for the computation of the; normalization factor (size factor) for each cell. A gene is considered; highly expressed, if it has more than `max_fraction` of the total counts; in at least one cell. The not-excluded genes will sum up to; `target_sum`. Providing this argument when `adata.X` is a :class:`~dask.array.Array`; will incur blocking `.compute()` calls on the array.; max_fraction; If `exclude_highly_expressed=True`, consider cells as highly expressed; that have more counts than `max_fraction` of the original total counts; in at least one cell.; key_added; Name of the field in `adata.obs` where the normalization factor is; stored.; layer; Layer to normalize instead of `X`. If `None`, `X` is normalized.; inplace; Whether to update `adata` or return dictionary with normalized copies of; `adata.X` and `adata.layers`.; copy; Whether to modify copied input object. Not compatible with inplace=False. Returns; -------; Returns dictionary with normalized copies of `adata.X` and `adata.layers`; or updates `adata` with normalized version of the original; `adata.X` and `adata.layers`, depending on `inplace`. Example; --------; >>> import sys; >>> from anndata import AnnData; >>> import scanpy as sc; >>> sc.settings.verbosity = 'info'; >>> sc.settings.logfile = sys.stdout # for doctests; >>> np.set_printoptions(precision=2); >>> adata = AnnData(np.array([; ... [3, 3, 3, 6, 6],; ... [1, 1, 1, 2, 2],; ... [1, 22, 1, 2, 2],; ... ], dtype='float32')); >>> adata.X; array([[ 3., 3., 3., 6., 6.],; [ 1., 1., 1., 2., 2.],; [ 1., 22., 1., 2., 2.]], dtype=float32); >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']; normalizing counts per cell; finished (0:00:00); >>> X_norm; array([[0.14, 0.14, 0.14, 0.29, 0.29],; [0.14, 0.14, 0.14, 0.29, 0.29],; [0.04, 0.79, 0.04, 0.07, 0.07]], dtype=flo",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_normalization.py:2091,layers,layers,2091,src/scanpy/preprocessing/_normalization.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_normalization.py,1,['layers'],['layers']
Modifiability,"3'`, genes are first sorted by the median (across batches) rank, with ties broken by the number of batches a gene is a HVG.; For `flavor='seurat_v3_paper'`, genes are first sorted by the number of batches a gene is a HVG, with ties broken by the median (across batches) rank. The following may help when comparing to Seurat's naming:; If `batch_key=None` and `flavor='seurat'`, this mimics Seurat's `FindVariableFeatures(…, method='mean.var.plot')`.; If `batch_key=None` and `flavor='seurat_v3'`/`flavor='seurat_v3_paper'`, this mimics Seurat's `FindVariableFeatures(..., method='vst')`.; If `batch_key` is not `None` and `flavor='seurat_v3_paper'`, this mimics Seurat's `SelectIntegrationFeatures`. See also `scanpy.experimental.pp._highly_variable_genes` for additional flavors; (e.g. Pearson residuals). Parameters; ----------; adata; The annotated data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; layer; If provided, use `adata.layers[layer]` for expression values instead of `adata.X`.; n_top_genes; Number of highly-variable genes to keep. Mandatory if `flavor='seurat_v3'`.; min_mean; If `n_top_genes` unequals `None`, this and all other cutoffs for the means and the; normalized dispersions are ignored. Ignored if `flavor='seurat_v3'`.; max_mean; If `n_top_genes` unequals `None`, this and all other cutoffs for the means and the; normalized dispersions are ignored. Ignored if `flavor='seurat_v3'`.; min_disp; If `n_top_genes` unequals `None`, this and all other cutoffs for the means and the; normalized dispersions are ignored. Ignored if `flavor='seurat_v3'`.; max_disp; If `n_top_genes` unequals `None`, this and all other cutoffs for the means and the; normalized dispersions are ignored. Ignored if `flavor='seurat_v3'`.; span; The fraction of the data (cells) used when estimating the variance in the loess; model fit if `flavor='seurat_v3'`.; n_bins; Number of bins for binning the mean gene expression. Normalization is; done with respect to",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py:2347,layers,layers,2347,src/scanpy/preprocessing/_highly_variable_genes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py,1,['layers'],['layers']
Modifiability,"; inplace; Whether to place calculated metrics in `.var` or return them.; batch_key; If specified, highly-variable genes are selected within each batch separately and merged.; This simple process avoids the selection of batch-specific genes and acts as a; lightweight batch correction method. For all flavors, except `seurat_v3`, genes are first sorted; by how many batches they are a HVG. For dispersion-based flavors ties are broken; by normalized dispersion. For `flavor = 'seurat_v3_paper'`, ties are broken by the median; (across batches) rank based on within-batch normalized variance.; check_values; Check if counts in selected layer are integers. A Warning is returned if set to True.; Only used if `flavor='seurat_v3'`/`'seurat_v3_paper'`. Returns; -------; Returns a :class:`pandas.DataFrame` with calculated metrics if `inplace=True`, else returns an `AnnData` object where it sets the following field:. `adata.var['highly_variable']` : :class:`pandas.Series` (dtype `bool`); boolean indicator of highly-variable genes; `adata.var['means']` : :class:`pandas.Series` (dtype `float`); means per gene; `adata.var['dispersions']` : :class:`pandas.Series` (dtype `float`); For dispersion-based flavors, dispersions per gene; `adata.var['dispersions_norm']` : :class:`pandas.Series` (dtype `float`); For dispersion-based flavors, normalized dispersions per gene; `adata.var['variances']` : :class:`pandas.Series` (dtype `float`); For `flavor='seurat_v3'`/`'seurat_v3_paper'`, variance per gene; `adata.var['variances_norm']`/`'seurat_v3_paper'` : :class:`pandas.Series` (dtype `float`); For `flavor='seurat_v3'`/`'seurat_v3_paper'`, normalized variance per gene, averaged in; the case of multiple batches; `adata.var['highly_variable_rank']` : :class:`pandas.Series` (dtype `float`); For `flavor='seurat_v3'`/`'seurat_v3_paper'`, rank of the gene according to normalized; variance, in case of multiple batches description above; `adata.var['highly_variable_nbatches']` : :class:`pandas.Series` (d",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py:4867,variab,variable,4867,src/scanpy/preprocessing/_highly_variable_genes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py,1,['variab'],['variable']
Modifiability,"; stripplot; Add a stripplot on top of the violin plot.; See :func:`~seaborn.stripplot`.; jitter; Add jitter to the stripplot (only when stripplot is True); See :func:`~seaborn.stripplot`.; size; Size of the jitter points.; order; Order in which to show the categories. Note: if `dendrogram=True`; the categories order will be given by the dendrogram and `order`; will be ignored.; density_norm; The method used to scale the width of each violin.; If 'width' (the default), each violin will have the same width.; If 'area', each violin will have the same area.; If 'count', a violin’s width corresponds to the number of observations.; row_palette; The row palette determines the colors to use for the stacked violins.; The value should be a valid seaborn or matplotlib palette name; (see :func:`~seaborn.color_palette`).; Alternatively, a single color name or hex value can be passed,; e.g. `'red'` or `'#cc33ff'`.; standard_scale; Whether or not to standardize a dimension between 0 and 1,; meaning for each variable or observation,; subtract the minimum and divide each by its maximum.; swap_axes; By default, the x axis contains `var_names` (e.g. genes) and the y axis; the `groupby` categories. By setting `swap_axes` then x are the `groupby`; categories and y the `var_names`. When swapping; axes var_group_positions are no longer used; kwds; Are passed to :func:`~seaborn.violinplot`. See also; --------; :func:`~scanpy.pl.stacked_violin`: simpler way to call StackedViolin but with less; options.; :func:`~scanpy.pl.violin` and :func:`~scanpy.pl.rank_genes_groups_stacked_violin`:; to plot marker genes identified using :func:`~scanpy.tl.rank_genes_groups`. Examples; -------. >>> import scanpy as sc; >>> adata = sc.datasets.pbmc68k_reduced(); >>> markers = ['C1QA', 'PSAP', 'CD79A', 'CD79B', 'CST3', 'LYZ']; >>> sc.pl.StackedViolin(adata, markers, groupby='bulk_labels', dendrogram=True) # doctest: +ELLIPSIS; <scanpy.plotting._stacked_violin.StackedViolin object at 0x...>. Using var_names a",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_stacked_violin.py:1346,variab,variable,1346,src/scanpy/plotting/_stacked_violin.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_stacked_violin.py,1,['variab'],['variable']
Modifiability,"anger'` with care and in the same way as in; :func:`~scanpy.pp.recipe_zheng17`. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; flavor; Choose the flavor for computing normalized dispersion. If choosing; 'seurat', this expects non-logarithmized data – the logarithm of mean; and dispersion is taken internally when `log` is at its default value; `True`. For 'cell_ranger', this is usually called for logarithmized data; – in this case you should set `log` to `False`. In their default; workflows, Seurat passes the cutoffs whereas Cell Ranger passes; `n_top_genes`.; min_mean; max_mean; min_disp; max_disp; If `n_top_genes` unequals `None`, these cutoffs for the means and the; normalized dispersions are ignored.; n_bins; Number of bins for binning the mean gene expression. Normalization is; done with respect to each bin. If just a single gene falls into a bin,; the normalized dispersion is artificially set to 1. You'll be informed; about this if you set `settings.verbosity = 4`.; n_top_genes; Number of highly-variable genes to keep.; log; Use the logarithm of the mean to variance ratio.; subset; Keep highly-variable genes only (if True) else write a bool array for h; ighly-variable genes while keeping all genes; copy; If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned. Returns; -------; If an AnnData `adata` is passed, returns or updates `adata` depending on; `copy`. It filters the `adata` and adds the annotations. **means** : adata.var; Means per gene. Logarithmized when `log` is `True`.; **dispersions** : adata.var; Dispersions per gene. Logarithmized when `log` is `True`.; **dispersions_norm** : adata.var; Normalized dispersions per gene. Logarithmized when `log` is `True`. If a data matrix `X` is passed, the annotation is returned as `np.recarray`; with the same information stored in fields: `gene_subset`, `means`, `dispersions`, `dispersion_norm`.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py:2086,variab,variable,2086,src/scanpy/preprocessing/_deprecated/highly_variable_genes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py,3,['variab'],['variable']
Modifiability,"d if `flavor='seurat_v3'`.; min_disp; If `n_top_genes` unequals `None`, this and all other cutoffs for the means and the; normalized dispersions are ignored. Ignored if `flavor='seurat_v3'`.; max_disp; If `n_top_genes` unequals `None`, this and all other cutoffs for the means and the; normalized dispersions are ignored. Ignored if `flavor='seurat_v3'`.; span; The fraction of the data (cells) used when estimating the variance in the loess; model fit if `flavor='seurat_v3'`.; n_bins; Number of bins for binning the mean gene expression. Normalization is; done with respect to each bin. If just a single gene falls into a bin,; the normalized dispersion is artificially set to 1. You'll be informed; about this if you set `settings.verbosity = 4`.; flavor; Choose the flavor for identifying highly variable genes. For the dispersion; based methods in their default workflows, Seurat passes the cutoffs whereas; Cell Ranger passes `n_top_genes`.; subset; Inplace subset to highly-variable genes if `True` otherwise merely indicate; highly variable genes.; inplace; Whether to place calculated metrics in `.var` or return them.; batch_key; If specified, highly-variable genes are selected within each batch separately and merged.; This simple process avoids the selection of batch-specific genes and acts as a; lightweight batch correction method. For all flavors, except `seurat_v3`, genes are first sorted; by how many batches they are a HVG. For dispersion-based flavors ties are broken; by normalized dispersion. For `flavor = 'seurat_v3_paper'`, ties are broken by the median; (across batches) rank based on within-batch normalized variance.; check_values; Check if counts in selected layer are integers. A Warning is returned if set to True.; Only used if `flavor='seurat_v3'`/`'seurat_v3_paper'`. Returns; -------; Returns a :class:`pandas.DataFrame` with calculated metrics if `inplace=True`, else returns an `AnnData` object where it sets the following field:. `adata.var['highly_variable']` ",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py:3778,variab,variable,3778,src/scanpy/preprocessing/_highly_variable_genes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py,2,['variab'],['variable']
Modifiability,"e used as the time points to construct the timepoint; connections.; n_neighbors; Number of nearest neighbors for graph construction.; n_components; Minimum number of principal components to use. Specify `None` to use; pre-computed components. The higher the value the better to capture 85% of the; variance.; n_jobs; Nearest Neighbors will be computed in parallel using n_jobs.; copy; Return a copy instead of writing to `adata`. Returns; -------; Depending on `copy`, returns or updates `.obsm`, `.obsp` and `.uns` with the following:. **X_harmony** - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.obsm`, dtype `float`); force directed layout; **harmony_aff** - :class:`~scipy.sparse.spmatrix` (:attr:`~anndata.AnnData.obsp`, dtype `float`); affinity matrix; **harmony_aff_aug** - :class:`~scipy.sparse.spmatrix` (:attr:`~anndata.AnnData.obsp`, dtype `float`); augmented affinity matrix; **harmony_timepoint_var** - `str` (:attr:`~anndata.AnnData.uns`); The name of the variable passed as `tp`; **harmony_timepoint_connections** - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.uns`, dtype `str`); The links between time points. Example; -------. >>> from itertools import product; >>> import pandas as pd; >>> from anndata import AnnData; >>> import scanpy as sc; >>> import scanpy.external as sce. **Load** `AnnData`. A sample with real data is available here_. .. _here: https://github.com/dpeerlab/Harmony/tree/master/data. Random data sets of three time points with two replicates each:. >>> adata_ref = sc.datasets.pbmc3k(); >>> start = [596, 615, 1682, 1663, 1409, 1432]; >>> adata = AnnData.concatenate(; ... *(adata_ref[i : i + 1000] for i in start),; ... join=""outer"",; ... batch_key=""sample"",; ... batch_categories=[f""sa{i}_Rep{j}"" for i, j in product((1, 2, 3), (1, 2))],; ... ); >>> time_points = adata.obs[""sample""].str.split(""_"", expand=True)[0]; >>> adata.obs[""time_points""] = pd.Categorical(; ... time_points, categories=['sa1', 'sa2', 'sa3']; ... ). Normalize and filter for hi",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_harmony_timeseries.py:2203,variab,variable,2203,src/scanpy/external/tl/_harmony_timeseries.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_harmony_timeseries.py,1,['variab'],['variable']
Modifiability,"e; If True, displays SAM log statements. Returns; -------; sam_obj if inplace is True or (sam_obj,AnnData) otherwise. adata - AnnData; `.var['weights']`; SAM weights for each gene.; `.var['spatial_dispersions']`; Spatial dispersions for each gene (these are used to compute the; SAM weights); `.uns['sam']`; Dictionary of SAM-specific outputs, such as the parameters; used for preprocessing ('preprocess_args') and running; ('run_args') SAM.; `.uns['neighbors']`; A dictionary with key 'connectivities' containing the kNN adjacency; matrix output by SAM. If built-in scanpy dimensionality reduction; methods are to be used using the SAM-output AnnData, users; should recompute the neighbors using `.obs['X_pca']` with; `scanpy.pp.neighbors`.; `.obsm['X_pca']`; The principal components output by SAM.; `.obsm['X_umap']`; The UMAP projection output by SAM.; `.layers['X_disp']`; The expression matrix used for nearest-neighbor averaging.; `.layers['X_knn_avg']`; The nearest-neighbor-averaged expression data used for computing the; spatial dispersions of genes. Example; -------; >>> import scanpy.external as sce; >>> import scanpy as sc. *** Running SAM ***. Assuming we are given an AnnData object called `adata`, we can run the SAM; algorithm as follows:. >>> sam_obj = sce.tl.sam(adata,inplace=True). The input AnnData object should contain unstandardized, non-negative; expression values. Preferably, the data should be log-normalized and no; genes should be filtered out. Please see the documentation for a description of all available parameters. For more detailed tutorials, please visit the original Github repository:; https://github.com/atarashansky/self-assembling-manifold/tree/master/tutorial. *** Plotting ***. To visualize the output, we can use:. >>> sce.pl.sam(adata,projection='X_umap'). `sce.pl.sam` accepts all keyword arguments used in the; `matplotlib.pyplot.scatter` function. *** SAMGUI ***. SAM comes with the SAMGUI module, a graphical-user interface written with; `Plotly`",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_sam.py:3888,layers,layers,3888,src/scanpy/external/tl/_sam.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_sam.py,1,['layers'],['layers']
Modifiability,"ed visum dataset. In addition to reading regular 10x output,; this looks for the `spatial` folder and loads images,; coordinates and scale factors.; Based on the `Space Ranger output docs`_. See :func:`~scanpy.pl.spatial` for a compatible plotting function. .. _Space Ranger output docs: https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/overview. Parameters; ----------; path; Path to directory for visium datafiles.; genome; Filter expression to genes within this genome.; count_file; Which file in the passed directory to use as the count file. Typically would be one of:; 'filtered_feature_bc_matrix.h5' or 'raw_feature_bc_matrix.h5'.; library_id; Identifier for the visium library. Can be modified when concatenating multiple adata objects.; source_image_path; Path to the high-resolution tissue image. Path will be included in; `.uns[""spatial""][library_id][""metadata""][""source_image_path""]`. Returns; -------; Annotated data matrix, where observations/cells are named by their; barcode and variables/genes by gene name. Stores the following information:. :attr:`~anndata.AnnData.X`; The data matrix is stored; :attr:`~anndata.AnnData.obs_names`; Cell names; :attr:`~anndata.AnnData.var_names`; Gene names for a feature barcode matrix, probe names for a probe bc matrix; :attr:`~anndata.AnnData.var`\\ `['gene_ids']`; Gene IDs; :attr:`~anndata.AnnData.var`\\ `['feature_types']`; Feature types; :attr:`~anndata.AnnData.obs`\\ `[filtered_barcodes]`; filtered barcodes if present in the matrix; :attr:`~anndata.AnnData.var`; Any additional metadata present in /matrix/features is read in.; :attr:`~anndata.AnnData.uns`\\ `['spatial']`; Dict of spaceranger output files with 'library_id' as key; :attr:`~anndata.AnnData.uns`\\ `['spatial'][library_id]['images']`; Dict of images (`'hires'` and `'lowres'`); :attr:`~anndata.AnnData.uns`\\ `['spatial'][library_id]['scalefactors']`; Scale factors for the spots; :attr:`~anndata.AnnData.uns`\\ `['spatial'][libra",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py:1066,variab,variables,1066,src/scanpy/readwrite.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py,1,['variab'],['variables']
Modifiability,"fraction; of cells (obs) that have a non-zero value for genes (var). For each var_name and each `groupby` category a dot is plotted.; Each dot represents two values: mean expression within each category; (visualized by color) and fraction of cells expressing the `var_name` in the; category (visualized by the size of the dot). If `groupby` is not given,; the dotplot assumes that all data belongs to a single category. .. note::; A gene is considered expressed if the expression value in the `adata` (or; `adata.raw`) is above the specified threshold which is zero by default. An example of dotplot usage is to visualize, for multiple marker genes,; the mean value and the percentage of cells expressing the gene; across multiple clusters. Parameters; ----------; {common_plot_args}; title; Title for the figure; expression_cutoff; Expression cutoff that is used for binarizing the gene expression and; determining the fraction of cells expressing given genes. A gene is; expressed only if the expression value is greater than this threshold.; mean_only_expressed; If True, gene expression is averaged only over the cells; expressing the given genes.; standard_scale; Whether or not to standardize that dimension between 0 and 1,; meaning for each variable or group,; subtract the minimum and divide each by its maximum.; kwds; Are passed to :func:`matplotlib.pyplot.scatter`. See also; --------; :func:`~scanpy.pl.dotplot`: Simpler way to call DotPlot but with less options.; :func:`~scanpy.pl.rank_genes_groups_dotplot`: to plot marker; genes identified using the :func:`~scanpy.tl.rank_genes_groups` function. Examples; --------. >>> import scanpy as sc; >>> adata = sc.datasets.pbmc68k_reduced(); >>> markers = ['C1QA', 'PSAP', 'CD79A', 'CD79B', 'CST3', 'LYZ']; >>> sc.pl.DotPlot(adata, markers, groupby='bulk_labels').show(). Using var_names as dict:. >>> markers = {{'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}}; >>> sc.pl.DotPlot(adata, markers, groupby='bulk_labels').show(). """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_dotplot.py:1367,variab,variable,1367,src/scanpy/plotting/_dotplot.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_dotplot.py,1,['variab'],['variable']
Modifiability,"he implementation of mnnpy_ :cite:p:`Kang2018`. Depending on `do_concatenate`, returns matrices or `AnnData` objects in the; original order containing corrected expression values or a concatenated; matrix or AnnData object. Be reminded that it is not advised to use the corrected data matrices for; differential expression testing. More information and bug reports `here <mnnpy>`__. .. _mnnpy: https://github.com/chriscainx/mnnpy. Parameters; ----------; datas; Expression matrices or AnnData objects. Matrices should be shaped like; n_obs × n_vars (n_cell × n_gene) and have consistent number of columns.; AnnData objects should have same number of variables.; var_index; The index (list of str) of vars (genes). Necessary when using only a; subset of vars to perform MNN correction, and should be supplied with; `var_subset`. When `datas` are AnnData objects, `var_index` is ignored.; var_subset; The subset of vars (list of str) to be used when performing MNN; correction. Typically, a list of highly variable genes (HVGs).; When set to `None`, uses all vars.; batch_key; The `batch_key` for :meth:`~anndata.AnnData.concatenate`.; Only valid when `do_concatenate` and supplying `AnnData` objects.; index_unique; The `index_unique` for :meth:`~anndata.AnnData.concatenate`.; Only valid when `do_concatenate` and supplying `AnnData` objects.; batch_categories; The `batch_categories` for :meth:`~anndata.AnnData.concatenate`.; Only valid when `do_concatenate` and supplying AnnData objects.; k; Number of mutual nearest neighbors.; sigma; The bandwidth of the Gaussian smoothing kernel used to compute the; correction vectors. Default is 1.; cos_norm_in; Whether cosine normalization should be performed on the input data prior; to calculating distances between cells.; cos_norm_out; Whether cosine normalization should be performed prior to computing corrected expression values.; svd_dim; The number of dimensions to use for summarizing biological substructure; within each batch. If None, biologic",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_mnn_correct.py:1124,variab,variable,1124,src/scanpy/external/pp/_mnn_correct.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_mnn_correct.py,1,['variab'],['variable']
Modifiability,"ighly expressed, if it has more than `max_fraction` of the total counts; in at least one cell. The not-excluded genes will sum up to; `target_sum`. Providing this argument when `adata.X` is a :class:`~dask.array.Array`; will incur blocking `.compute()` calls on the array.; max_fraction; If `exclude_highly_expressed=True`, consider cells as highly expressed; that have more counts than `max_fraction` of the original total counts; in at least one cell.; key_added; Name of the field in `adata.obs` where the normalization factor is; stored.; layer; Layer to normalize instead of `X`. If `None`, `X` is normalized.; inplace; Whether to update `adata` or return dictionary with normalized copies of; `adata.X` and `adata.layers`.; copy; Whether to modify copied input object. Not compatible with inplace=False. Returns; -------; Returns dictionary with normalized copies of `adata.X` and `adata.layers`; or updates `adata` with normalized version of the original; `adata.X` and `adata.layers`, depending on `inplace`. Example; --------; >>> import sys; >>> from anndata import AnnData; >>> import scanpy as sc; >>> sc.settings.verbosity = 'info'; >>> sc.settings.logfile = sys.stdout # for doctests; >>> np.set_printoptions(precision=2); >>> adata = AnnData(np.array([; ... [3, 3, 3, 6, 6],; ... [1, 1, 1, 2, 2],; ... [1, 22, 1, 2, 2],; ... ], dtype='float32')); >>> adata.X; array([[ 3., 3., 3., 6., 6.],; [ 1., 1., 1., 2., 2.],; [ 1., 22., 1., 2., 2.]], dtype=float32); >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']; normalizing counts per cell; finished (0:00:00); >>> X_norm; array([[0.14, 0.14, 0.14, 0.29, 0.29],; [0.14, 0.14, 0.14, 0.29, 0.29],; [0.04, 0.79, 0.04, 0.07, 0.07]], dtype=float32); >>> X_norm = sc.pp.normalize_total(; ... adata, target_sum=1, exclude_highly_expressed=True,; ... max_fraction=0.2, inplace=False; ... )['X']; normalizing counts per cell. The following highly-expressed genes are not considered during normalization factor computation:;",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_normalization.py:2355,layers,layers,2355,src/scanpy/preprocessing/_normalization.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_normalization.py,1,['layers'],['layers']
Modifiability,"ing on `copy`, returns or updates `adata` with the following fields:. **Diffusion maps**,; used for magic imputation, and to generate multi-scale data matrix,. - X_palantir_diff_comp - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.obsm`, dtype `float`); Array of Diffusion components.; - palantir_EigenValues - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.uns`, dtype `float`); Array of corresponding eigen values.; - palantir_diff_op - :class:`~scipy.sparse.spmatrix` (:attr:`~anndata.AnnData.obsp`, dtype `float`); The diffusion operator matrix. **Multi scale space results**,; used to build tsne on diffusion components, and to compute branch probabilities; and waypoints,. - X_palantir_multiscale - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.obsm`, dtype `float`); Multi scale data matrix. **MAGIC imputation**,; used for plotting gene expression on tsne, and gene expression trends,. - palantir_imp - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.layers`, dtype `float`); Imputed data matrix (MAGIC imputation). Example; -------; >>> import scanpy.external as sce; >>> import scanpy as sc. A sample data is available `here <https://github.com/dpeerlab/Palantir/tree/master/data>`_. **Load sample data**. >>> adata = sc.read_csv(filename=""Palantir/data/marrow_sample_scseq_counts.csv.gz""). *Cleanup and normalize*. >>> sc.pp.filter_cells(adata, min_counts=1000); >>> sc.pp.filter_genes(adata, min_counts=10); >>> sc.pp.normalize_per_cell(adata); >>> sc.pp.log1p(adata). **Data preprocessing**. Palantir builds diffusion maps using one of two optional inputs:. *Principal component analysis*. >>> sc.pp.pca(adata, n_comps=300). or,. *Nearist neighbors graph*. >>> sc.pp.neighbors(adata, knn=30). *Diffusion maps*. Palantir determines the diffusion maps of the data as an estimate of the low; dimensional phenotypic manifold of the data. >>> sce.tl.palantir(adata, n_components=5, knn=30). if pre-computed distances are to be used,. >>> sce.tl.palantir(; ... adata,; ... n_component",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_palantir.py:2550,layers,layers,2550,src/scanpy/external/tl/_palantir.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_palantir.py,1,['layers'],['layers']
Modifiability,"lization factor (size factor) for each cell. A gene is considered; highly expressed, if it has more than `max_fraction` of the total counts; in at least one cell. The not-excluded genes will sum up to; `target_sum`. Providing this argument when `adata.X` is a :class:`~dask.array.Array`; will incur blocking `.compute()` calls on the array.; max_fraction; If `exclude_highly_expressed=True`, consider cells as highly expressed; that have more counts than `max_fraction` of the original total counts; in at least one cell.; key_added; Name of the field in `adata.obs` where the normalization factor is; stored.; layer; Layer to normalize instead of `X`. If `None`, `X` is normalized.; inplace; Whether to update `adata` or return dictionary with normalized copies of; `adata.X` and `adata.layers`.; copy; Whether to modify copied input object. Not compatible with inplace=False. Returns; -------; Returns dictionary with normalized copies of `adata.X` and `adata.layers`; or updates `adata` with normalized version of the original; `adata.X` and `adata.layers`, depending on `inplace`. Example; --------; >>> import sys; >>> from anndata import AnnData; >>> import scanpy as sc; >>> sc.settings.verbosity = 'info'; >>> sc.settings.logfile = sys.stdout # for doctests; >>> np.set_printoptions(precision=2); >>> adata = AnnData(np.array([; ... [3, 3, 3, 6, 6],; ... [1, 1, 1, 2, 2],; ... [1, 22, 1, 2, 2],; ... ], dtype='float32')); >>> adata.X; array([[ 3., 3., 3., 6., 6.],; [ 1., 1., 1., 2., 2.],; [ 1., 22., 1., 2., 2.]], dtype=float32); >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']; normalizing counts per cell; finished (0:00:00); >>> X_norm; array([[0.14, 0.14, 0.14, 0.29, 0.29],; [0.14, 0.14, 0.14, 0.29, 0.29],; [0.04, 0.79, 0.04, 0.07, 0.07]], dtype=float32); >>> X_norm = sc.pp.normalize_total(; ... adata, target_sum=1, exclude_highly_expressed=True,; ... max_fraction=0.2, inplace=False; ... )['X']; normalizing counts per cell. The following highly-expresse",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_normalization.py:2265,layers,layers,2265,src/scanpy/preprocessing/_normalization.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_normalization.py,1,['layers'],['layers']
Modifiability,"name for the dataset,; like `""pbmc3k""` or `""tabulamuris""`.; embedding_keys; 2-D embeddings in `adata.obsm` to export.; The prefix `X_` or `X_draw_graph_` is not necessary.; Coordinates missing from `adata` are skipped.; By default (or when specifying `'all'` or `None`), these keys are tried:; [`""tsne""`, `""umap""`, `""pagaFa""`, `""pagaFr""`, `""pagaUmap""`, `""phate""`,; `""fa""`, `""fr""`, `""kk""`, `""drl""`, `""rt""`, `""trimap""`].; For these, default display labels are automatically used.; For other values, you can specify a mapping from coordinate name to; display label, e.g. `{""tsne"": ""t-SNE by Scanpy""}`.; annot_keys; Annotations in `adata.obsm` to export.; Can be a mapping from annotation column name to display label.; Specify `None` for all available columns in `.obs`.; skip_matrix; Do not export the matrix.; If you had previously exported this adata into the same `data_dir`,; then there is no need to export the whole matrix again.; This option will make the export a lot faster,; e.g. when only coordinates or meta data were changed.; html_dir; If this variable is set, the export will build html; files from `data_dir` to `html_dir`, creating html/js/json files.; Usually there is one global html output directory for all datasets.; Often, `html_dir` is located under a webserver's (like Apache); htdocs directory or is copied to one.; A directory `html_dir`/`project_name` will be created and; an index.html will be created under `html_dir` for all subdirectories.; Existing files will be overwritten.; If do not to use html_dir,; you can use the command line tool `cbBuild` to build the html directory.; port; If this variable and `html_dir` are set,; Python's built-in web server will be spawned as a daemon in the; background and serve the files under `html_dir`.; To kill the process, call `cellbrowser.cellbrowser.stop()`.; do_debug; Activate debugging output. Examples; --------; See this; `tutorial <https://github.com/scverse/scanpy_usage/tree/master/181126_Cellbrowser_exports>`__.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/exporting.py:2213,variab,variable,2213,src/scanpy/external/exporting.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/exporting.py,2,['variab'],['variable']
Modifiability,"ns and the; normalized dispersions are ignored. Ignored if `flavor='seurat_v3'`.; max_mean; If `n_top_genes` unequals `None`, this and all other cutoffs for the means and the; normalized dispersions are ignored. Ignored if `flavor='seurat_v3'`.; min_disp; If `n_top_genes` unequals `None`, this and all other cutoffs for the means and the; normalized dispersions are ignored. Ignored if `flavor='seurat_v3'`.; max_disp; If `n_top_genes` unequals `None`, this and all other cutoffs for the means and the; normalized dispersions are ignored. Ignored if `flavor='seurat_v3'`.; span; The fraction of the data (cells) used when estimating the variance in the loess; model fit if `flavor='seurat_v3'`.; n_bins; Number of bins for binning the mean gene expression. Normalization is; done with respect to each bin. If just a single gene falls into a bin,; the normalized dispersion is artificially set to 1. You'll be informed; about this if you set `settings.verbosity = 4`.; flavor; Choose the flavor for identifying highly variable genes. For the dispersion; based methods in their default workflows, Seurat passes the cutoffs whereas; Cell Ranger passes `n_top_genes`.; subset; Inplace subset to highly-variable genes if `True` otherwise merely indicate; highly variable genes.; inplace; Whether to place calculated metrics in `.var` or return them.; batch_key; If specified, highly-variable genes are selected within each batch separately and merged.; This simple process avoids the selection of batch-specific genes and acts as a; lightweight batch correction method. For all flavors, except `seurat_v3`, genes are first sorted; by how many batches they are a HVG. For dispersion-based flavors ties are broken; by normalized dispersion. For `flavor = 'seurat_v3_paper'`, ties are broken by the median; (across batches) rank based on within-batch normalized variance.; check_values; Check if counts in selected layer are integers. A Warning is returned if set to True.; Only used if `flavor='seurat_v3'`",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py:3597,variab,variable,3597,src/scanpy/preprocessing/_highly_variable_genes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py,1,['variab'],['variable']
Modifiability,"ns of an `adata` with a reference dataset; `adata_ref` through projecting on a PCA (or alternate; model) that has been fitted on the reference data. The function uses a knn; classifier for mapping labels and the UMAP package :cite:p:`McInnes2018` for mapping; the embeddings. .. note::. We refer to this *asymmetric* dataset integration as *ingesting*; annotations from reference data to new data. This is different from; learning a joint representation that integrates both datasets in an; unbiased way, as CCA (e.g. in Seurat) or a conditional VAE (e.g. in; scVI) would do. You need to run :func:`~scanpy.pp.neighbors` on `adata_ref` before; passing it. Parameters; ----------; adata; The annotated data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes. This is the dataset without labels and; embeddings.; adata_ref; The annotated data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; Variables (`n_vars` and `var_names`) of `adata_ref` should be the same; as in `adata`.; This is the dataset with labels and embeddings; which need to be mapped to `adata`.; obs; Labels' keys in `adata_ref.obs` which need to be mapped to `adata.obs`; (inferred for observation of `adata`).; embedding_method; Embeddings in `adata_ref` which need to be mapped to `adata`.; The only supported values are 'umap' and 'pca'.; labeling_method; The method to map labels in `adata_ref.obs` to `adata.obs`.; The only supported value is 'knn'.; neighbors_key; If not specified, ingest looks adata_ref.uns['neighbors']; for neighbors settings and adata_ref.obsp['distances'] for; distances (default storage places for pp.neighbors).; If specified, ingest looks adata_ref.uns[neighbors_key] for; neighbors settings and; adata_ref.obsp[adata_ref.uns[neighbors_key]['distances_key']] for distances.; inplace; Only works if `return_joint=False`.; Add labels and embeddings to the passed `adata` (if `True`); or return a copy of `adata` with mapped embeddings",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_ingest.py:1114,Variab,Variables,1114,src/scanpy/tools/_ingest.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_ingest.py,1,['Variab'],['Variables']
Modifiability,"ording to :cite:t:`Coifman2005`, in the adaption of; :cite:t:`Haghverdi2016`. Parameters; ----------; adata; Annotated data matrix.; n_neighbors; The size of local neighborhood (in terms of number of neighboring data; points) used for manifold approximation. Larger values result in more; global views of the manifold, while smaller values result in more local; data being preserved. In general values should be in the range 2 to 100.; If `knn` is `True`, number of nearest neighbors to be searched. If `knn`; is `False`, a Gaussian kernel width is set to the distance of the; `n_neighbors` neighbor. *ignored if ``transformer`` is an instance.*; {n_pcs}; {use_rep}; knn; If `True`, use a hard threshold to restrict the number of neighbors to; `n_neighbors`, that is, consider a knn graph. Otherwise, use a Gaussian; Kernel to assign low weights to neighbors more distant than the; `n_neighbors` nearest neighbor.; method; Use 'umap' :cite:p:`McInnes2018` or 'gauss' (Gauss kernel following :cite:t:`Coifman2005`; with adaptive width :cite:t:`Haghverdi2016`) for computing connectivities.; transformer; Approximate kNN search implementation following the API of; :class:`~sklearn.neighbors.KNeighborsTransformer`.; See :doc:`/how-to/knn-transformers` for more details.; Also accepts the following known options:. `None` (the default); Behavior depends on data size.; For small data, we will calculate exact kNN, otherwise we use; :class:`~pynndescent.pynndescent_.PyNNDescentTransformer`; `'pynndescent'`; :class:`~pynndescent.pynndescent_.PyNNDescentTransformer`; `'rapids'`; A transformer based on :class:`cuml.neighbors.NearestNeighbors`. .. deprecated:: 1.10.0; Use :func:`rapids_singlecell.pp.neighbors` instead.; metric; A known metric’s name or a callable that returns a distance. *ignored if ``transformer`` is an instance.*; metric_kwds; Options for the metric. *ignored if ``transformer`` is an instance.*; random_state; A numpy random seed. *ignored if ``transformer`` is an instance.*; key",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/__init__.py:1406,adapt,adaptive,1406,src/scanpy/neighbors/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/__init__.py,1,['adapt'],['adaptive']
Modifiability,"ormalization and PCA are performed. Expects raw count input. Params; ------; {adata}; {dist_params}; {genes_batch_chunk}; {pca_chunk}; {check_values}; {inplace}. Returns; -------; If `inplace=False`, separately returns the gene selection results (as; :class:`~pandas.DataFrame`) and Pearson residual-based PCA results (as; :class:`~anndata.AnnData`). If `inplace=True`, updates `adata` with the; following fields for gene selection results:. `.var['highly_variable']` : bool; boolean indicator of highly-variable genes.; `.var['means']` : float; means per gene.; `.var['variances']` : float; variances per gene.; `.var['residual_variances']` : float; Pearson residual variance per gene. Averaged in the case of multiple; batches.; `.var['highly_variable_rank']` : float; Rank of the gene according to residual variance, median rank in the; case of multiple batches.; `.var['highly_variable_nbatches']` : int; If batch_key is given, this denotes in how many batches genes are; detected as HVG.; `.var['highly_variable_intersection']` : bool; If batch_key is given, this denotes the genes that are highly variable; in all batches. The following fields contain Pearson residual-based PCA results and; normalization settings:. `.uns['pearson_residuals_normalization']['pearson_residuals_df']`; The subset of highly variable genes, normalized by Pearson residuals.; `.uns['pearson_residuals_normalization']['theta']`; The used value of the overdisperion parameter theta.; `.uns['pearson_residuals_normalization']['clip']`; The used value of the clipping parameter. `.obsm['X_pca']`; PCA representation of data after gene selection and Pearson residual; normalization.; `.varm['PCs']`; The principal components containing the loadings. When `inplace=True` this; will contain empty rows for the genes not selected during HVG selection.; `.uns['pca']['variance_ratio']`; Ratio of explained variance.; `.uns['pca']['variance']`; Explained variance, equivalent to the eigenvalues of the covariance matrix.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_recipes.py:1305,variab,variable,1305,src/scanpy/experimental/pp/_recipes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_recipes.py,2,['variab'],['variable']
Modifiability,"ow many batches they are a HVG. For dispersion-based flavors ties are broken; by normalized dispersion. For `flavor = 'seurat_v3_paper'`, ties are broken by the median; (across batches) rank based on within-batch normalized variance.; check_values; Check if counts in selected layer are integers. A Warning is returned if set to True.; Only used if `flavor='seurat_v3'`/`'seurat_v3_paper'`. Returns; -------; Returns a :class:`pandas.DataFrame` with calculated metrics if `inplace=True`, else returns an `AnnData` object where it sets the following field:. `adata.var['highly_variable']` : :class:`pandas.Series` (dtype `bool`); boolean indicator of highly-variable genes; `adata.var['means']` : :class:`pandas.Series` (dtype `float`); means per gene; `adata.var['dispersions']` : :class:`pandas.Series` (dtype `float`); For dispersion-based flavors, dispersions per gene; `adata.var['dispersions_norm']` : :class:`pandas.Series` (dtype `float`); For dispersion-based flavors, normalized dispersions per gene; `adata.var['variances']` : :class:`pandas.Series` (dtype `float`); For `flavor='seurat_v3'`/`'seurat_v3_paper'`, variance per gene; `adata.var['variances_norm']`/`'seurat_v3_paper'` : :class:`pandas.Series` (dtype `float`); For `flavor='seurat_v3'`/`'seurat_v3_paper'`, normalized variance per gene, averaged in; the case of multiple batches; `adata.var['highly_variable_rank']` : :class:`pandas.Series` (dtype `float`); For `flavor='seurat_v3'`/`'seurat_v3_paper'`, rank of the gene according to normalized; variance, in case of multiple batches description above; `adata.var['highly_variable_nbatches']` : :class:`pandas.Series` (dtype `int`); If `batch_key` is given, this denotes in how many batches genes are detected as HVG; `adata.var['highly_variable_intersection']` : :class:`pandas.Series` (dtype `bool`); If `batch_key` is given, this denotes the genes that are highly variable in all batches. Notes; -----; This function replaces :func:`~scanpy.pp.filter_genes_dispersion`.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py:6100,variab,variable,6100,src/scanpy/preprocessing/_highly_variable_genes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py,1,['variab'],['variable']
Modifiability,"prove; clustering resolution. inplace; Set fields in `adata` if True. Otherwise, returns a copy. verbose; If True, displays SAM log statements. Returns; -------; sam_obj if inplace is True or (sam_obj,AnnData) otherwise. adata - AnnData; `.var['weights']`; SAM weights for each gene.; `.var['spatial_dispersions']`; Spatial dispersions for each gene (these are used to compute the; SAM weights); `.uns['sam']`; Dictionary of SAM-specific outputs, such as the parameters; used for preprocessing ('preprocess_args') and running; ('run_args') SAM.; `.uns['neighbors']`; A dictionary with key 'connectivities' containing the kNN adjacency; matrix output by SAM. If built-in scanpy dimensionality reduction; methods are to be used using the SAM-output AnnData, users; should recompute the neighbors using `.obs['X_pca']` with; `scanpy.pp.neighbors`.; `.obsm['X_pca']`; The principal components output by SAM.; `.obsm['X_umap']`; The UMAP projection output by SAM.; `.layers['X_disp']`; The expression matrix used for nearest-neighbor averaging.; `.layers['X_knn_avg']`; The nearest-neighbor-averaged expression data used for computing the; spatial dispersions of genes. Example; -------; >>> import scanpy.external as sce; >>> import scanpy as sc. *** Running SAM ***. Assuming we are given an AnnData object called `adata`, we can run the SAM; algorithm as follows:. >>> sam_obj = sce.tl.sam(adata,inplace=True). The input AnnData object should contain unstandardized, non-negative; expression values. Preferably, the data should be log-normalized and no; genes should be filtered out. Please see the documentation for a description of all available parameters. For more detailed tutorials, please visit the original Github repository:; https://github.com/atarashansky/self-assembling-manifold/tree/master/tutorial. *** Plotting ***. To visualize the output, we can use:. >>> sce.pl.sam(adata,projection='X_umap'). `sce.pl.sam` accepts all keyword arguments used in the; `matplotlib.pyplot.scatter` functi",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_sam.py:3807,layers,layers,3807,src/scanpy/external/tl/_sam.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_sam.py,1,['layers'],['layers']
Modifiability,"seurat_v3'`.; max_disp; If `n_top_genes` unequals `None`, this and all other cutoffs for the means and the; normalized dispersions are ignored. Ignored if `flavor='seurat_v3'`.; span; The fraction of the data (cells) used when estimating the variance in the loess; model fit if `flavor='seurat_v3'`.; n_bins; Number of bins for binning the mean gene expression. Normalization is; done with respect to each bin. If just a single gene falls into a bin,; the normalized dispersion is artificially set to 1. You'll be informed; about this if you set `settings.verbosity = 4`.; flavor; Choose the flavor for identifying highly variable genes. For the dispersion; based methods in their default workflows, Seurat passes the cutoffs whereas; Cell Ranger passes `n_top_genes`.; subset; Inplace subset to highly-variable genes if `True` otherwise merely indicate; highly variable genes.; inplace; Whether to place calculated metrics in `.var` or return them.; batch_key; If specified, highly-variable genes are selected within each batch separately and merged.; This simple process avoids the selection of batch-specific genes and acts as a; lightweight batch correction method. For all flavors, except `seurat_v3`, genes are first sorted; by how many batches they are a HVG. For dispersion-based flavors ties are broken; by normalized dispersion. For `flavor = 'seurat_v3_paper'`, ties are broken by the median; (across batches) rank based on within-batch normalized variance.; check_values; Check if counts in selected layer are integers. A Warning is returned if set to True.; Only used if `flavor='seurat_v3'`/`'seurat_v3_paper'`. Returns; -------; Returns a :class:`pandas.DataFrame` with calculated metrics if `inplace=True`, else returns an `AnnData` object where it sets the following field:. `adata.var['highly_variable']` : :class:`pandas.Series` (dtype `bool`); boolean indicator of highly-variable genes; `adata.var['means']` : :class:`pandas.Series` (dtype `float`); means per gene; `adata.var['d",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py:3958,variab,variable,3958,src/scanpy/preprocessing/_highly_variable_genes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py,1,['variab'],['variable']
Performance," _scanorama: https://github.com/brianhie/scanorama. Parameters; ----------; adata; The annotated data matrix.; key; The name of the column in ``adata.obs`` that differentiates; among experiments/batches. Cells from the same batch must be; contiguously stored in ``adata``.; basis; The name of the field in ``adata.obsm`` where the PCA table is; stored. Defaults to ``'X_pca'``, which is the default for; ``sc.pp.pca()``.; adjusted_basis; The name of the field in ``adata.obsm`` where the integrated; embeddings will be stored after running this function. Defaults; to ``X_scanorama``.; knn; Number of nearest neighbors to use for matching.; sigma; Correction smoothing parameter on Gaussian kernel.; approx; Use approximate nearest neighbors with Python ``annoy``;; greatly speeds up matching runtime.; alpha; Alignment score minimum cutoff.; batch_size; The batch size used in the alignment vector computation. Useful; when integrating very large (>100k samples) datasets. Set to; large value that runs within available memory.; kwargs; Any additional arguments will be passed to; ``scanorama.assemble()``. Returns; -------; Updates adata with the field ``adata.obsm[adjusted_basis]``,; containing Scanorama embeddings such that different experiments; are integrated. Example; -------; First, load libraries and example dataset, and preprocess. >>> import scanpy as sc; >>> import scanpy.external as sce; >>> adata = sc.datasets.pbmc3k(); >>> sc.pp.recipe_zheng17(adata); >>> sc.pp.pca(adata). We now arbitrarily assign a batch metadata variable to each cell; for the sake of example, but during real usage there would already; be a column in ``adata.obs`` giving the experiment each cell came; from. >>> adata.obs['batch'] = 1350*['a'] + 1350*['b']. Finally, run Scanorama. Afterwards, there will be a new table in; ``adata.obsm`` containing the Scanorama embeddings. >>> sce.pp.scanorama_integrate(adata, 'batch', verbose=1); Processing datasets a <=> b; >>> 'X_scanorama' in adata.obsm; True; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py:1694,load,load,1694,src/scanpy/external/pp/_scanorama_integrate.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py,1,['load'],['load']
Performance," if you install Multicore-tSNE_; by :cite:t:`Ulyanov2016`, which will be automatically detected by Scanpy. .. _multicore-tsne: https://github.com/DmitryUlyanov/Multicore-TSNE. Parameters; ----------; adata; Annotated data matrix.; {doc_n_pcs}; {use_rep}; perplexity; The perplexity is related to the number of nearest neighbors that; is used in other manifold learning algorithms. Larger datasets; usually require a larger perplexity. Consider selecting a value; between 5 and 50. The choice is not extremely critical since t-SNE; is quite insensitive to this parameter.; metric; Distance metric calculate neighbors on.; early_exaggeration; Controls how tight natural clusters in the original space are in the; embedded space and how much space will be between them. For larger; values, the space between natural clusters will be larger in the; embedded space. Again, the choice of this parameter is not very; critical. If the cost function increases during initial optimization,; the early exaggeration factor or the learning rate might be too high.; learning_rate; Note that the R-package ""Rtsne"" uses a default of 200.; The learning rate can be a critical parameter. It should be; between 100 and 1000. If the cost function increases during initial; optimization, the early exaggeration factor or the learning rate; might be too high. If the cost function gets stuck in a bad local; minimum increasing the learning rate helps sometimes.; random_state; Change this to use different intial states for the optimization.; If `None`, the initial state is not reproducible.; n_jobs; Number of jobs for parallel computation.; `None` means using :attr:`scanpy._settings.ScanpyConfig.n_jobs`.; copy; Return a copy instead of writing to `adata`. Returns; -------; Returns `None` if `copy=False`, else returns an `AnnData` object. Sets the following fields:. `adata.obsm['X_tsne']` : :class:`numpy.ndarray` (dtype `float`); tSNE coordinates of data.; `adata.uns['tsne']` : :class:`dict`; tSNE parameters. """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_tsne.py:1618,optimiz,optimization,1618,src/scanpy/tools/_tsne.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_tsne.py,2,['optimiz'],['optimization']
Performance," of umap-learn_ :cite:p:`McInnes2018`.; For a few comparisons of UMAP with tSNE, see :cite:t:`Becht2018`. .. _umap-learn: https://github.com/lmcinnes/umap. Parameters; ----------; adata; Annotated data matrix.; min_dist; The effective minimum distance between embedded points. Smaller values; will result in a more clustered/clumped embedding where nearby points on; the manifold are drawn closer together, while larger values will result; on a more even dispersal of points. The value should be set relative to; the ``spread`` value, which determines the scale at which embedded; points will be spread out. The default of in the `umap-learn` package is; 0.1.; spread; The effective scale of embedded points. In combination with `min_dist`; this determines how clustered/clumped the embedded points are.; n_components; The number of dimensions of the embedding.; maxiter; The number of iterations (epochs) of the optimization. Called `n_epochs`; in the original UMAP.; alpha; The initial learning rate for the embedding optimization.; gamma; Weighting applied to negative samples in low dimensional embedding; optimization. Values higher than one will result in greater weight; being given to negative samples.; negative_sample_rate; The number of negative edge/1-simplex samples to use per positive; edge/1-simplex sample in optimizing the low dimensional embedding.; init_pos; How to initialize the low dimensional embedding. Called `init` in the; original UMAP. Options are:. * Any key for `adata.obsm`.; * 'paga': positions from :func:`~scanpy.pl.paga`.; * 'spectral': use a spectral embedding of the graph.; * 'random': assign initial embedding positions at random.; * A numpy array of initial embedding positions.; random_state; If `int`, `random_state` is the seed used by the random number generator;; If `RandomState` or `Generator`, `random_state` is the random number generator;; If `None`, the random number generator is the `RandomState` instance used; by `np.random`.; a; More specific ",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_umap.py:1621,optimiz,optimization,1621,src/scanpy/tools/_umap.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_umap.py,1,['optimiz'],['optimization']
Performance,"""""""; Tests to make sure the example datasets load.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_datasets.py:45,load,load,45,tests/test_datasets.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_datasets.py,1,['load'],['load']
Performance,"""""""Perform knn search on the index.""""""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/_backends/rapids.py:3,Perform,Perform,3,src/scanpy/neighbors/_backends/rapids.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/_backends/rapids.py,1,['Perform'],['Perform']
Performance,"""""""Probabilistic demultiplexing of cell hashing data using HashSolo :cite:p:`Bernstein2020`. .. note::; More information and bug reports `here <https://github.com/calico/solo>`__. Parameters; ----------; adata; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; cell_hashing_columns; `.obs` columns that contain cell hashing counts.; priors; Prior probabilities of each hypothesis, in; the order `[negative, singlet, doublet]`. The default is set to; `[0.01, 0.8, 0.19]` assuming barcode counts are from cells that; have passed QC in the transcriptome space, e.g. UMI counts, pct; mito reads, etc.; pre_existing_clusters; The column in `.obs` containing pre-existing cluster assignments; (e.g. Leiden clusters or cell types, but not batch assignments).; If provided, demultiplexing will be performed separately for each; cluster.; number_of_noise_barcodes; The number of barcodes used to create the noise distribution.; Defaults to `len(cell_hashing_columns) - 2`.; inplace; Whether to update `adata` in-place or return a copy. Returns; -------; A copy of the input `adata` if `inplace=False`, otherwise the input; `adata`. The following fields are added:. `.obs[""most_likely_hypothesis""]`; Index of the most likely hypothesis, where `0` corresponds to negative,; `1` to singlet, and `2` to doublet.; `.obs[""cluster_feature""]`; The cluster assignments used for demultiplexing.; `.obs[""negative_hypothesis_probability""]`; Probability of the negative hypothesis.; `.obs[""singlet_hypothesis_probability""]`; Probability of the singlet hypothesis.; `.obs[""doublet_hypothesis_probability""]`; Probability of the doublet hypothesis.; `.obs[""Classification""]`:; Classification of the cell, one of the barcodes in `cell_hashing_columns`,; `""Negative""`, or `""Doublet""`. Examples; -------; >>> import anndata; >>> import scanpy.external as sce; >>> adata = anndata.read_h5ad(""data.h5ad""); >>> sce.pp.hashsolo(adata, [""Hash1"", ""Hash2"", ""Hash3""]); >>> adata.ob",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py:845,perform,performed,845,src/scanpy/external/pp/_hashsolo.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py,1,['perform'],['performed']
Performance,"""""""\; 3k PBMCs from 10x Genomics. The data consists in 3k PBMCs from a Healthy Donor and is freely available; from 10x Genomics (file_ from this webpage_). The exact same data is also used in Seurat’s `basic clustering tutorial`_. .. _file: https://cf.10xgenomics.com/samples/cell-exp/1.1.0/pbmc3k/pbmc3k_filtered_gene_bc_matrices.tar.gz; .. _webpage: https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.1.0/pbmc3k; .. _basic clustering tutorial: https://satijalab.org/seurat/articles/pbmc3k_tutorial.html. .. note::; This downloads 5.9 MB of data upon the first call of the function and stores it in; :attr:`~scanpy._settings.ScanpyConfig.datasetdir`\\ `/pbmc3k_raw.h5ad`. The following code was run to produce the file. .. code:: python. adata = sc.read_10x_mtx(; # the directory with the `.mtx` file; './data/filtered_gene_bc_matrices/hg19/',; # use gene symbols for the variable names (variables-axis index); var_names='gene_symbols',; # write a cache file for faster subsequent reading; cache=True,; ). adata.var_names_make_unique() # this is unnecessary if using 'gene_ids'; adata.write('write/pbmc3k_raw.h5ad', compression='gzip'). Returns; -------; Annotated data matrix. Examples; --------; >>> import scanpy as sc; >>> sc.datasets.pbmc3k(); AnnData object with n_obs × n_vars = 2700 × 32738; var: 'gene_ids'; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py:969,cache,cache,969,src/scanpy/datasets/_datasets.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py,2,['cache'],['cache']
Performance,"""""""\; Aggregate data matrix based on some categorical grouping. This function is useful for pseudobulking as well as plotting. Aggregation to perform is specified by `func`, which can be a single metric or a; list of metrics. Each metric is computed over the group and results in a new layer; in the output `AnnData` object. If none of `layer`, `obsm`, or `varm` are passed in, `X` will be used for aggregation data. Params; ------; adata; :class:`~anndata.AnnData` to be aggregated.; by; Key of the column to be grouped-by.; func; How to aggregate.; axis; Axis on which to find group by column.; mask; Boolean mask (or key to column containing mask) to apply along the axis.; dof; Degrees of freedom for variance. Defaults to 1.; layer; If not None, key for aggregation data.; obsm; If not None, key for aggregation data.; varm; If not None, key for aggregation data. Returns; -------; Aggregated :class:`~anndata.AnnData`. Examples; --------. Calculating mean expression and number of nonzero entries per cluster:. >>> import scanpy as sc, pandas as pd; >>> pbmc = sc.datasets.pbmc3k_processed().raw.to_adata(); >>> pbmc.shape; (2638, 13714); >>> aggregated = sc.get.aggregate(pbmc, by=""louvain"", func=[""mean"", ""count_nonzero""]); >>> aggregated; AnnData object with n_obs × n_vars = 8 × 13714; obs: 'louvain'; var: 'n_cells'; layers: 'mean', 'count_nonzero'. We can group over multiple columns:. >>> pbmc.obs[""percent_mito_binned""] = pd.cut(pbmc.obs[""percent_mito""], bins=5); >>> sc.get.aggregate(pbmc, by=[""louvain"", ""percent_mito_binned""], func=[""mean"", ""count_nonzero""]); AnnData object with n_obs × n_vars = 40 × 13714; obs: 'louvain', 'percent_mito_binned'; var: 'n_cells'; layers: 'mean', 'count_nonzero'. Note that this filters out any combination of groups that wasn't present in the original data.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/_aggregated.py:142,perform,perform,142,src/scanpy/get/_aggregated.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/_aggregated.py,1,['perform'],['perform']
Performance,"""""""\; Applies analytic Pearson residual normalization and PCA, based on :cite:t:`Lause2021`. The residuals are based on a negative binomial offset model with overdispersion; `theta` shared across genes. By default, residuals are clipped to `sqrt(n_obs)`,; overdispersion `theta=100` is used, and PCA is run with 50 components. Operates on the subset of highly variable genes in `adata.var['highly_variable']`; by default. Expects raw count input. Params; ------; {adata}; {dist_params}; {pca_chunk}; {mask_var_hvg}; {check_values}; {inplace}. Returns; -------; If `inplace=False`, returns the Pearson residual-based PCA results (as :class:`~anndata.AnnData`; object). If `inplace=True`, updates `adata` with the following fields:. `.uns['pearson_residuals_normalization']['pearson_residuals_df']`; The subset of highly variable genes, normalized by Pearson residuals.; `.uns['pearson_residuals_normalization']['theta']`; The used value of the overdisperion parameter theta.; `.uns['pearson_residuals_normalization']['clip']`; The used value of the clipping parameter. `.obsm['X_pca']`; PCA representation of data after gene selection (if applicable) and Pearson; residual normalization.; `.varm['PCs']`; The principal components containing the loadings. When `inplace=True` and; `use_highly_variable=True`, this will contain empty rows for the genes not; selected.; `.uns['pca']['variance_ratio']`; Ratio of explained variance.; `.uns['pca']['variance']`; Explained variance, equivalent to the eigenvalues of the covariance matrix.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_normalization.py:1244,load,loadings,1244,src/scanpy/experimental/pp/_normalization.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_normalization.py,1,['load'],['loadings']
Performance,"""""""\; Calculate quality control metrics. Calculates a number of qc metrics for an AnnData object, see section; `Returns` for specifics. Largely based on `calculateQCMetrics` from scater; :cite:p:`McCarthy2017`. Currently is most efficient on a sparse CSR or dense matrix. Note that this method can take a while to compile on the first call. That; result is then cached to disk to be used later. Parameters; ----------; {doc_adata_basic}; {doc_qc_metric_naming}; {doc_obs_qc_args}; {doc_expr_reps}; inplace; Whether to place calculated metrics in `adata`'s `.obs` and `.var`.; log1p; Set to `False` to skip computing `log1p` transformed annotations. Returns; -------; Depending on `inplace` returns calculated metrics; (as :class:`~pandas.DataFrame`) or updates `adata`'s `obs` and `var`. {doc_obs_qc_returns}. {doc_var_qc_returns}. Example; -------; Calculate qc metrics for visualization. .. plot::; :context: close-figs. import scanpy as sc; import seaborn as sns. pbmc = sc.datasets.pbmc3k(); pbmc.var[""mito""] = pbmc.var_names.str.startswith(""MT-""); sc.pp.calculate_qc_metrics(pbmc, qc_vars=[""mito""], inplace=True); sns.jointplot(; data=pbmc.obs,; x=""log1p_total_counts"",; y=""log1p_n_genes_by_counts"",; kind=""hex"",; ). .. plot::; :context: close-figs. sns.histplot(pbmc.obs[""pct_counts_mito""]); """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_qc.py:362,cache,cached,362,src/scanpy/preprocessing/_qc.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_qc.py,1,['cache'],['cached']
Performance,"""""""\; Calculate the density of cells in an embedding (per condition). Gaussian kernel density estimation is used to calculate the density of; cells in an embedded space. This can be performed per category over a; categorical cell annotation. The cell density can be plotted using the; `pl.embedding_density` function. Note that density values are scaled to be between 0 and 1. Thus, the; density value at each cell is only comparable to densities in; the same category. Beware that the KDE estimate used (`scipy.stats.gaussian_kde`) becomes; unreliable if you don't have enough cells in a category. This function was written by Sophie Tritschler and implemented into; Scanpy by Malte Luecken. Parameters; ----------; adata; The annotated data matrix.; basis; The embedding over which the density will be calculated. This embedded; representation should be found in `adata.obsm['X_[basis]']``.; groupby; Key for categorical observation/cell annotation for which densities; are calculated per category.; key_added; Name of the `.obs` covariate that will be added with the density; estimates.; components; The embedding dimensions over which the density should be calculated.; This is limited to two components. Returns; -------; Sets the following fields (`key_added` defaults to `[basis]_density_[groupby]`, where `[basis]` is one of `umap`, `diffmap`, `pca`, `tsne`, or `draw_graph_fa` and `[groupby]` denotes the parameter input):. `adata.obs[key_added]` : :class:`numpy.ndarray` (dtype `float`); Embedding density values for each cell.; `adata.uns['[key_added]_params']` : :class:`dict`; A dict with the values for the parameters `covariate` (for the `groupby` parameter) and `components`. Examples; --------. .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); sc.tl.umap(adata); sc.tl.embedding_density(adata, basis='umap', groupby='phase'); sc.pl.embedding_density(; adata, basis='umap', key='umap_density_phase', group='G1'; ). .. plot::; :context: close",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_embedding_density.py:182,perform,performed,182,src/scanpy/tools/_embedding_density.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_embedding_density.py,1,['perform'],['performed']
Performance,"""""""\; Cluster cells into subgroups :cite:p:`Blondel2008,Levine2015,Traag2017`. Cluster cells using the Louvain algorithm :cite:p:`Blondel2008` in the implementation; of :cite:t:`Traag2017`. The Louvain algorithm has been proposed for single-cell; analysis by :cite:t:`Levine2015`. This requires having ran :func:`~scanpy.pp.neighbors` or; :func:`~scanpy.external.pp.bbknn` first,; or explicitly passing a ``adjacency`` matrix. Parameters; ----------; adata; The annotated data matrix.; resolution; For the default flavor (``'vtraag'``) or for ```RAPIDS```, you can provide a; resolution (higher resolution means finding more and smaller clusters),; which defaults to 1.0.; See “Time as a resolution parameter” in :cite:t:`Lambiotte2014`.; random_state; Change the initialization of the optimization.; restrict_to; Restrict the clustering to the categories within the key for sample; annotation, tuple needs to contain ``(obs_key, list_of_categories)``.; key_added; Key under which to add the cluster labels. (default: ``'louvain'``); adjacency; Sparse adjacency matrix of the graph, defaults to neighbors connectivities.; flavor; Choose between to packages for computing the clustering. ``'vtraag'``; Much more powerful than ``'igraph'``, and the default.; ``'igraph'``; Built in ``igraph`` method.; ``'rapids'``; GPU accelerated implementation. .. deprecated:: 1.10.0; Use :func:`rapids_singlecell.tl.louvain` instead.; directed; Interpret the ``adjacency`` matrix as directed graph?; use_weights; Use weights from knn graph.; partition_type; Type of partition to use.; Only a valid argument if ``flavor`` is ``'vtraag'``.; partition_kwargs; Key word arguments to pass to partitioning,; if ``vtraag`` method is being used.; neighbors_key; Use neighbors connectivities as adjacency.; If not specified, louvain looks .obsp['connectivities'] for connectivities; (default storage place for pp.neighbors).; If specified, louvain looks; .obsp[.uns[neighbors_key]['connectivities_key']] for connectivities.;",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_louvain.py:786,optimiz,optimization,786,src/scanpy/tools/_louvain.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_louvain.py,1,['optimiz'],['optimization']
Performance,"""""""\; Cluster cells into subgroups :cite:p:`Traag2019`. Cluster cells using the Leiden algorithm :cite:p:`Traag2019`,; an improved version of the Louvain algorithm :cite:p:`Blondel2008`.; It has been proposed for single-cell analysis by :cite:t:`Levine2015`. This requires having ran :func:`~scanpy.pp.neighbors` or; :func:`~scanpy.external.pp.bbknn` first. Parameters; ----------; adata; The annotated data matrix.; resolution; A parameter value controlling the coarseness of the clustering.; Higher values lead to more clusters.; Set to `None` if overriding `partition_type`; to one that doesn’t accept a `resolution_parameter`.; random_state; Change the initialization of the optimization.; restrict_to; Restrict the clustering to the categories within the key for sample; annotation, tuple needs to contain `(obs_key, list_of_categories)`.; key_added; `adata.obs` key under which to add the cluster labels.; adjacency; Sparse adjacency matrix of the graph, defaults to neighbors connectivities.; directed; Whether to treat the graph as directed or undirected.; use_weights; If `True`, edge weights from the graph are used in the computation; (placing more emphasis on stronger edges).; n_iterations; How many iterations of the Leiden clustering algorithm to perform.; Positive values above 2 define the total number of iterations to perform,; -1 has the algorithm run until it reaches its optimal clustering.; 2 is faster and the default for underlying packages.; partition_type; Type of partition to use.; Defaults to :class:`~leidenalg.RBConfigurationVertexPartition`.; For the available options, consult the documentation for; :func:`~leidenalg.find_partition`.; neighbors_key; Use neighbors connectivities as adjacency.; If not specified, leiden looks .obsp['connectivities'] for connectivities; (default storage place for pp.neighbors).; If specified, leiden looks; .obsp[.uns[neighbors_key]['connectivities_key']] for connectivities.; obsp; Use .obsp[obsp] as adjacency. You can't specify bo",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_leiden.py:679,optimiz,optimization,679,src/scanpy/tools/_leiden.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_leiden.py,1,['optimiz'],['optimization']
Performance,"""""""\; Compression for `sc.read(..., cache=True)` (default `'lzf'`). May be `'lzf'`, `'gzip'`, or `None`.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_settings.py:36,cache,cache,36,src/scanpy/_settings.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_settings.py,1,['cache'],['cache']
Performance,"""""""\; Correct batch effects by matching mutual nearest neighbors :cite:p:`Haghverdi2018` :cite:p:`Kang2018`. This uses the implementation of mnnpy_ :cite:p:`Kang2018`. Depending on `do_concatenate`, returns matrices or `AnnData` objects in the; original order containing corrected expression values or a concatenated; matrix or AnnData object. Be reminded that it is not advised to use the corrected data matrices for; differential expression testing. More information and bug reports `here <mnnpy>`__. .. _mnnpy: https://github.com/chriscainx/mnnpy. Parameters; ----------; datas; Expression matrices or AnnData objects. Matrices should be shaped like; n_obs × n_vars (n_cell × n_gene) and have consistent number of columns.; AnnData objects should have same number of variables.; var_index; The index (list of str) of vars (genes). Necessary when using only a; subset of vars to perform MNN correction, and should be supplied with; `var_subset`. When `datas` are AnnData objects, `var_index` is ignored.; var_subset; The subset of vars (list of str) to be used when performing MNN; correction. Typically, a list of highly variable genes (HVGs).; When set to `None`, uses all vars.; batch_key; The `batch_key` for :meth:`~anndata.AnnData.concatenate`.; Only valid when `do_concatenate` and supplying `AnnData` objects.; index_unique; The `index_unique` for :meth:`~anndata.AnnData.concatenate`.; Only valid when `do_concatenate` and supplying `AnnData` objects.; batch_categories; The `batch_categories` for :meth:`~anndata.AnnData.concatenate`.; Only valid when `do_concatenate` and supplying AnnData objects.; k; Number of mutual nearest neighbors.; sigma; The bandwidth of the Gaussian smoothing kernel used to compute the; correction vectors. Default is 1.; cos_norm_in; Whether cosine normalization should be performed on the input data prior; to calculating distances between cells.; cos_norm_out; Whether cosine normalization should be performed prior to computing corrected expression values.",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_mnn_correct.py:881,perform,perform,881,src/scanpy/external/pp/_mnn_correct.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_mnn_correct.py,1,['perform'],['perform']
Performance,"""""""\; Deep count autoencoder :cite:p:`Eraslan2019`. Fits a count autoencoder to the raw count data given in the anndata object; in order to denoise the data and to capture hidden representation of; cells in low dimensions. Type of the autoencoder and return values are; determined by the parameters. .. note::; More information and bug reports `here <https://github.com/theislab/dca>`__. Parameters; ----------; adata; An anndata file with `.raw` attribute representing raw counts.; mode; `denoise` overwrites `adata.X` with denoised expression values.; In `latent` mode DCA adds `adata.obsm['X_dca']` to given adata; object. This matrix represent latent representation of cells via DCA.; ae_type; Type of the autoencoder. Return values and the architecture is; determined by the type e.g. `nb` does not provide dropout; probabilities. Types that end with ""-conddisp"", assumes that dispersion is mean dependant.; normalize_per_cell; If true, library size normalization is performed using; the `sc.pp.normalize_per_cell` function in Scanpy and saved into adata; object. Mean layer is re-introduces library size differences by; scaling the mean value of each cell in the output layer. See the; manuscript for more details.; scale; If true, the input of the autoencoder is centered using; `sc.pp.scale` function of Scanpy. Note that the output is kept as raw; counts as loss functions are designed for the count data.; log1p; If true, the input of the autoencoder is log transformed with a; pseudocount of one using `sc.pp.log1p` function of Scanpy.; hidden_size; Width of hidden layers.; hidden_dropout; Probability of weight dropout in the autoencoder (per layer if list; or tuple).; batchnorm; If true, batch normalization is performed.; activation; Activation function of hidden layers.; init; Initialization method used to initialize weights.; network_kwds; Additional keyword arguments for the autoencoder.; epochs; Number of total epochs in training.; reduce_lr; Reduces learning rate if validatio",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_dca.py:972,perform,performed,972,src/scanpy/external/pp/_dca.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_dca.py,1,['perform'],['performed']
Performance,"""""""\; Describe observations of anndata. Calculates a number of qc metrics for observations in AnnData object. See; section `Returns` for a description of those metrics. Note that this method can take a while to compile on the first call. That; result is then cached to disk to be used later. Params; ------; {doc_adata_basic}; {doc_qc_metric_naming}; {doc_obs_qc_args}; {doc_expr_reps}; log1p; Add `log1p` transformed metrics.; inplace; Whether to place calculated metrics in `adata.obs`.; X; Matrix to calculate values on. Meant for internal usage. Returns; -------; QC metrics for observations in adata. If inplace, values are placed into; the AnnData's `.obs` dataframe. {doc_obs_qc_returns}; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_qc.py:259,cache,cached,259,src/scanpy/preprocessing/_qc.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_qc.py,1,['cache'],['cached']
Performance,"""""""\; Detect branching on given segment. Updates all list parameters inplace. Call function _detect_branching and perform bookkeeping on segs and; segs_tips. Parameters; ----------; segs; Dchosen distance matrix restricted to segment.; segs_tips; Stores all tip points for the segments in segs.; iseg; Position of segment under study in segs.; tips3; The three tip points. They form a 'triangle' that contains the data.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py:114,perform,perform,114,src/scanpy/tools/_dpt.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py,1,['perform'],['perform']
Performance,"""""""\; Development of Myeloid Progenitors :cite:p:`Paul2015`. Non-logarithmized raw data. The data has been sent out by Email from the Amit Lab. An R version for; loading the data can be found `here; <https://github.com/theislab/scAnalysisTutorial>`_. Returns; -------; Annotated data matrix. Examples; --------; >>> import scanpy as sc; >>> sc.datasets.paul15(); AnnData object with n_obs × n_vars = 2730 × 3451; obs: 'paul15_clusters'; uns: 'iroot'; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py:162,load,loading,162,src/scanpy/datasets/_datasets.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py,1,['load'],['loading']
Performance,"""""""\; Directory for cache files (default `'./cache/'`).; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_settings.py:20,cache,cache,20,src/scanpy/_settings.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_settings.py,2,['cache'],['cache']
Performance,"""""""\; Embed the neighborhood graph using UMAP :cite:p:`McInnes2018`. UMAP (Uniform Manifold Approximation and Projection) is a manifold learning; technique suitable for visualizing high-dimensional data. Besides tending to; be faster than tSNE, it optimizes the embedding such that it best reflects; the topology of the data, which we represent throughout Scanpy using a; neighborhood graph. tSNE, by contrast, optimizes the distribution of; nearest-neighbor distances in the embedding such that these best match the; distribution of distances in the high-dimensional space.; We use the implementation of umap-learn_ :cite:p:`McInnes2018`.; For a few comparisons of UMAP with tSNE, see :cite:t:`Becht2018`. .. _umap-learn: https://github.com/lmcinnes/umap. Parameters; ----------; adata; Annotated data matrix.; min_dist; The effective minimum distance between embedded points. Smaller values; will result in a more clustered/clumped embedding where nearby points on; the manifold are drawn closer together, while larger values will result; on a more even dispersal of points. The value should be set relative to; the ``spread`` value, which determines the scale at which embedded; points will be spread out. The default of in the `umap-learn` package is; 0.1.; spread; The effective scale of embedded points. In combination with `min_dist`; this determines how clustered/clumped the embedded points are.; n_components; The number of dimensions of the embedding.; maxiter; The number of iterations (epochs) of the optimization. Called `n_epochs`; in the original UMAP.; alpha; The initial learning rate for the embedding optimization.; gamma; Weighting applied to negative samples in low dimensional embedding; optimization. Values higher than one will result in greater weight; being given to negative samples.; negative_sample_rate; The number of negative edge/1-simplex samples to use per positive; edge/1-simplex sample in optimizing the low dimensional embedding.; init_pos; How to initialize the",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_umap.py:248,optimiz,optimizes,248,src/scanpy/tools/_umap.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_umap.py,2,['optimiz'],['optimizes']
Performance,"""""""\; Filter cell outliers based on counts and numbers of genes expressed. For instance, only keep cells with at least `min_counts` counts or; `min_genes` genes expressed. This is to filter measurement outliers,; i.e. “unreliable” observations. Only provide one of the optional parameters `min_counts`, `min_genes`,; `max_counts`, `max_genes` per call. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; min_counts; Minimum number of counts required for a cell to pass filtering.; min_genes; Minimum number of genes expressed required for a cell to pass filtering.; max_counts; Maximum number of counts required for a cell to pass filtering.; max_genes; Maximum number of genes expressed required for a cell to pass filtering.; inplace; Perform computation inplace or return result. Returns; -------; Depending on `inplace`, returns the following arrays or directly subsets; and annotates the data matrix:. cells_subset; Boolean index mask that does filtering. `True` means that the; cell is kept. `False` means the cell is removed.; number_per_cell; Depending on what was thresholded (`counts` or `genes`),; the array stores `n_counts` or `n_cells` per gene. Examples; --------; >>> import scanpy as sc; >>> adata = sc.datasets.krumsiek11(); UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; utils.warn_names_duplicates(""obs""); >>> adata.obs_names_make_unique(); >>> adata.n_obs; 640; >>> adata.var_names.tolist() # doctest: +NORMALIZE_WHITESPACE; ['Gata2', 'Gata1', 'Fog1', 'EKLF', 'Fli1', 'SCL',; 'Cebpa', 'Pu.1', 'cJun', 'EgrNab', 'Gfi1']; >>> # add some true zeros; >>> adata.X[adata.X < 0.3] = 0; >>> # simply compute the number of genes per cell; >>> sc.pp.filter_cells(adata, min_genes=0); >>> adata.n_obs; 640; >>> adata.obs['n_genes'].min(); 1; >>> # filter manually; >>> adata_copy = adata[adata.obs['n_genes'] >= 3]; >>> adata_copy.n_obs; 554; >>> adata_",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:822,Perform,Perform,822,src/scanpy/preprocessing/_simple.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py,1,['Perform'],['Perform']
Performance,"""""""\; Filter genes based on number of cells or counts. Keep genes that have at least `min_counts` counts or are expressed in at; least `min_cells` cells or have at most `max_counts` counts or are expressed; in at most `max_cells` cells. Only provide one of the optional parameters `min_counts`, `min_cells`,; `max_counts`, `max_cells` per call. Parameters; ----------; data; An annotated data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; min_counts; Minimum number of counts required for a gene to pass filtering.; min_cells; Minimum number of cells expressed required for a gene to pass filtering.; max_counts; Maximum number of counts required for a gene to pass filtering.; max_cells; Maximum number of cells expressed required for a gene to pass filtering.; inplace; Perform computation inplace or return result. Returns; -------; Depending on `inplace`, returns the following arrays or directly subsets; and annotates the data matrix. gene_subset; Boolean index mask that does filtering. `True` means that the; gene is kept. `False` means the gene is removed.; number_per_gene; Depending on what was thresholded (`counts` or `cells`), the array stores; `n_counts` or `n_cells` per gene.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:811,Perform,Perform,811,src/scanpy/preprocessing/_simple.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py,1,['Perform'],['Perform']
Performance,"""""""\; Full pipeline for HVG selection and normalization by analytic Pearson residuals :cite:p:`Lause2021`. Applies gene selection based on Pearson residuals. On the resulting subset,; Pearson residual normalization and PCA are performed. Expects raw count input. Params; ------; {adata}; {dist_params}; {genes_batch_chunk}; {pca_chunk}; {check_values}; {inplace}. Returns; -------; If `inplace=False`, separately returns the gene selection results (as; :class:`~pandas.DataFrame`) and Pearson residual-based PCA results (as; :class:`~anndata.AnnData`). If `inplace=True`, updates `adata` with the; following fields for gene selection results:. `.var['highly_variable']` : bool; boolean indicator of highly-variable genes.; `.var['means']` : float; means per gene.; `.var['variances']` : float; variances per gene.; `.var['residual_variances']` : float; Pearson residual variance per gene. Averaged in the case of multiple; batches.; `.var['highly_variable_rank']` : float; Rank of the gene according to residual variance, median rank in the; case of multiple batches.; `.var['highly_variable_nbatches']` : int; If batch_key is given, this denotes in how many batches genes are; detected as HVG.; `.var['highly_variable_intersection']` : bool; If batch_key is given, this denotes the genes that are highly variable; in all batches. The following fields contain Pearson residual-based PCA results and; normalization settings:. `.uns['pearson_residuals_normalization']['pearson_residuals_df']`; The subset of highly variable genes, normalized by Pearson residuals.; `.uns['pearson_residuals_normalization']['theta']`; The used value of the overdisperion parameter theta.; `.uns['pearson_residuals_normalization']['clip']`; The used value of the clipping parameter. `.obsm['X_pca']`; PCA representation of data after gene selection and Pearson residual; normalization.; `.varm['PCs']`; The principal components containing the loadings. When `inplace=True` this; will contain empty rows for the genes not s",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_recipes.py:227,perform,performed,227,src/scanpy/experimental/pp/_recipes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_recipes.py,1,['perform'],['performed']
Performance,"""""""\; Load a dataset from the EBI Single Cell Expression Atlas. The atlas_ can be browsed online to find the ``accession`` you want.; Downloaded datasets are saved in the directory specified by; :attr:`~scanpy._settings.ScanpyConfig.datasetdir`. .. _atlas: https://www.ebi.ac.uk/gxa/sc/experiments. Params; ------; accession; Dataset accession. Like ``E-GEOD-98816`` or ``E-MTAB-4888``.; This can be found in the url on the datasets page, for example E-GEOD-98816_. .. _E-GEOD-98816: https://www.ebi.ac.uk/gxa/sc/experiments/E-GEOD-98816/results/tsne; filter_boring; Whether boring labels in `.obs` should be automatically removed, such as; labels with a single or :attr:`~anndata.AnnData.n_obs` distinct values. Returns; -------; Annotated data matrix. Example; -------; >>> import scanpy as sc; >>> sc.datasets.ebi_expression_atlas(""E-MTAB-4888"") # doctest: +ELLIPSIS; AnnData object with n_obs × n_vars = 2261 × 23899; obs: 'Sample Characteristic[organism]', 'Sample Characteristic Ontology Term[organism]', ..., 'Factor Value[cell type]', 'Factor Value Ontology Term[cell type]'; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_ebi_expression_atlas.py:6,Load,Load,6,src/scanpy/datasets/_ebi_expression_atlas.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_ebi_expression_atlas.py,1,['Load'],['Load']
Performance,"""""""\; Perform clustering using PhenoGraph; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phenograph.py:6,Perform,Perform,6,src/scanpy/external/tl/_phenograph.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phenograph.py,1,['Perform'],['Perform']
Performance,"""""""\; Principal component analysis :cite:p:`Pedregosa2011`. Computes PCA coordinates, loadings and variance decomposition.; Uses the implementation of *scikit-learn* :cite:p:`Pedregosa2011`. .. versionchanged:: 1.5.0. In previous versions, computing a PCA on a sparse matrix would make; a dense copy of the array for mean centering.; As of scanpy 1.5.0, mean centering is implicit.; While results are extremely similar, they are not exactly the same.; If you would like to reproduce the old results, pass a dense array. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; n_comps; Number of principal components to compute. Defaults to 50, or 1 - minimum; dimension size of selected representation.; layer; If provided, which element of layers to use for PCA.; zero_center; If `True`, compute standard PCA from covariance matrix.; If `False`, omit zero-centering variables; (uses *scikit-learn* :class:`~sklearn.decomposition.TruncatedSVD` or; *dask-ml* :class:`~dask_ml.decomposition.TruncatedSVD`),; which allows to handle sparse input efficiently.; Passing `None` decides automatically based on sparseness of the data.; svd_solver; SVD solver to use:. `None`; See `chunked` and `zero_center` descriptions to determine which class will be used.; Depending on the class and the type of X different values for default will be set.; If *scikit-learn* :class:`~sklearn.decomposition.PCA` is used, will give `'arpack'`,; if *scikit-learn* :class:`~sklearn.decomposition.TruncatedSVD` is used, will give `'randomized'`,; if *dask-ml* :class:`~dask_ml.decomposition.PCA` or :class:`~dask_ml.decomposition.IncrementalPCA` is used, will give `'auto'`,; if *dask-ml* :class:`~dask_ml.decomposition.TruncatedSVD` is used, will give `'tsqr'`; `'arpack'`; for the ARPACK wrapper in SciPy (:func:`~scipy.sparse.linalg.svds`); Not available with *dask* arrays.; `'randomized'`; for the randomized algorithm due to Halko (2009). Fo",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py:86,load,loadings,86,src/scanpy/preprocessing/_pca.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py,1,['load'],['loadings']
Performance,"""""""\; Processed 3k PBMCs from 10x Genomics. Processed using the basic tutorial :doc:`/tutorials/basics/clustering-2017`. For preprocessing, cells are filtered out that have few gene counts or too high a `percent_mito`.; The counts are logarithmized and only genes marked by :func:`~scanpy.pp.highly_variable_genes` are retained.; The :attr:`~anndata.AnnData.obs` variables `n_counts` and `percent_mito` are corrected for; using :func:`~scanpy.pp.regress_out`, and values are scaled and clipped by :func:`~scanpy.pp.scale`.; Finally, :func:`~scanpy.pp.pca` and :func:`~scanpy.pp.neighbors` are calculated. As analysis steps, the embeddings :func:`~scanpy.tl.tsne` and :func:`~scanpy.tl.umap` are performed.; Communities are identified using :func:`~scanpy.tl.louvain` and marker genes using :func:`~scanpy.tl.rank_genes_groups`. Returns; -------; Annotated data matrix. Examples; --------; >>> import scanpy as sc; >>> sc.datasets.pbmc3k_processed(); AnnData object with n_obs × n_vars = 2638 × 1838; obs: 'n_genes', 'percent_mito', 'n_counts', 'louvain'; var: 'n_cells'; uns: 'draw_graph', 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups'; obsm: 'X_pca', 'X_tsne', 'X_umap', 'X_draw_graph_fr'; varm: 'PCs'; obsp: 'distances', 'connectivities'; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py:695,perform,performed,695,src/scanpy/datasets/_datasets.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py,1,['perform'],['performed']
Performance,"""""""\; Rank genes according to contributions to PCs. Parameters; ----------; adata; Annotated data matrix.; components; For example, ``'1,2,3'`` means ``[1, 2, 3]``, first, second, third; principal component.; include_lowest; Whether to show the variables with both highest and lowest loadings.; show; Show the plot, do not return axis.; n_points; Number of variables to plot for each component.; save; If `True` or a `str`, save the figure.; A string is appended to the default filename.; Infer the filetype if ending on {`'.pdf'`, `'.png'`, `'.svg'`}. Examples; --------; .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc3k_processed(). Show first 3 components loadings. .. plot::; :context: close-figs. sc.pl.pca_loadings(adata, components = '1,2,3'). """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py:284,load,loadings,284,src/scanpy/plotting/_tools/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py,2,['load'],['loadings']
Performance,"""""""\; Rank genes for characterizing groups. Expects logarithmized data. Parameters; ----------; adata; Annotated data matrix.; groupby; The key of the observations grouping to consider.; mask_var; Select subset of genes to use in statistical tests.; use_raw; Use `raw` attribute of `adata` if present.; layer; Key from `adata.layers` whose value will be used to perform tests on.; groups; Subset of groups, e.g. [`'g1'`, `'g2'`, `'g3'`], to which comparison; shall be restricted, or `'all'` (default), for all groups. Note that if; `reference='rest'` all groups will still be used as the reference, not; just those specified in `groups`.; reference; If `'rest'`, compare each group to the union of the rest of the group.; If a group identifier, compare with respect to this group.; n_genes; The number of genes that appear in the returned tables.; Defaults to all genes.; method; The default method is `'t-test'`,; `'t-test_overestim_var'` overestimates variance of each group,; `'wilcoxon'` uses Wilcoxon rank-sum,; `'logreg'` uses logistic regression. See :cite:t:`Ntranos2019`,; `here <https://github.com/scverse/scanpy/issues/95>`__ and `here; <https://www.nxn.se/valent/2018/3/5/actionable-scrna-seq-clusters>`__,; for why this is meaningful.; corr_method; p-value correction method.; Used only for `'t-test'`, `'t-test_overestim_var'`, and `'wilcoxon'`.; tie_correct; Use tie correction for `'wilcoxon'` scores.; Used only for `'wilcoxon'`.; rankby_abs; Rank genes by the absolute value of the score, not by the; score. The returned scores are never the absolute values.; pts; Compute the fraction of cells expressing the genes.; key_added; The key in `adata.uns` information is saved to.; copy; Whether to copy `adata` or modify it inplace.; kwds; Are passed to test methods. Currently this affects only parameters that; are passed to :class:`sklearn.linear_model.LogisticRegression`.; For instance, you can pass `penalty='l1'` to try to come up with a; minimal set of genes that are good predi",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py:362,perform,perform,362,src/scanpy/tools/_rank_genes_groups.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py,1,['perform'],['perform']
Performance,"""""""\; Read 10x-Genomics-formatted mtx directory. Parameters; ----------; path; Path to directory for `.mtx` and `.tsv` files,; e.g. './filtered_gene_bc_matrices/hg19/'.; var_names; The variables index.; make_unique; Whether to make the variables index unique by appending '-1',; '-2' etc. or not.; cache; If `False`, read from source, if `True`, read from fast 'h5ad' cache.; cache_compression; See the h5py :ref:`dataset_compression`.; (Default: `settings.cache_compression`); gex_only; Only keep 'Gene Expression' data and ignore other feature types,; e.g. 'Antibody Capture', 'CRISPR Guide Capture', or 'Custom'; prefix; Any prefix before `matrix.mtx`, `genes.tsv` and `barcodes.tsv`. For instance,; if the files are named `patientA_matrix.mtx`, `patientA_genes.tsv` and; `patientA_barcodes.tsv` the prefix is `patientA_`.; (Default: no prefix). Returns; -------; An :class:`~anndata.AnnData` object; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py:298,cache,cache,298,src/scanpy/readwrite.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py,2,['cache'],['cache']
Performance,"""""""\; Read 10x-Genomics-formatted visum dataset. In addition to reading regular 10x output,; this looks for the `spatial` folder and loads images,; coordinates and scale factors.; Based on the `Space Ranger output docs`_. See :func:`~scanpy.pl.spatial` for a compatible plotting function. .. _Space Ranger output docs: https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/overview. Parameters; ----------; path; Path to directory for visium datafiles.; genome; Filter expression to genes within this genome.; count_file; Which file in the passed directory to use as the count file. Typically would be one of:; 'filtered_feature_bc_matrix.h5' or 'raw_feature_bc_matrix.h5'.; library_id; Identifier for the visium library. Can be modified when concatenating multiple adata objects.; source_image_path; Path to the high-resolution tissue image. Path will be included in; `.uns[""spatial""][library_id][""metadata""][""source_image_path""]`. Returns; -------; Annotated data matrix, where observations/cells are named by their; barcode and variables/genes by gene name. Stores the following information:. :attr:`~anndata.AnnData.X`; The data matrix is stored; :attr:`~anndata.AnnData.obs_names`; Cell names; :attr:`~anndata.AnnData.var_names`; Gene names for a feature barcode matrix, probe names for a probe bc matrix; :attr:`~anndata.AnnData.var`\\ `['gene_ids']`; Gene IDs; :attr:`~anndata.AnnData.var`\\ `['feature_types']`; Feature types; :attr:`~anndata.AnnData.obs`\\ `[filtered_barcodes]`; filtered barcodes if present in the matrix; :attr:`~anndata.AnnData.var`; Any additional metadata present in /matrix/features is read in.; :attr:`~anndata.AnnData.uns`\\ `['spatial']`; Dict of spaceranger output files with 'library_id' as key; :attr:`~anndata.AnnData.uns`\\ `['spatial'][library_id]['images']`; Dict of images (`'hires'` and `'lowres'`); :attr:`~anndata.AnnData.uns`\\ `['spatial'][library_id]['scalefactors']`; Scale factors for the spots; :attr:`~anndata.Ann",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py:133,load,loads,133,src/scanpy/readwrite.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py,1,['load'],['loads']
Performance,"""""""\; Read file and return :class:`~anndata.AnnData` object. To speed up reading, consider passing ``cache=True``, which creates an hdf5; cache file. Parameters; ----------; filename; If the filename has no file extension, it is interpreted as a key for; generating a filename via ``sc.settings.writedir / (filename +; sc.settings.file_format_data)``. This is the same behavior as in; ``sc.read(filename, ...)``.; backed; If ``'r'``, load :class:`~anndata.AnnData` in ``backed`` mode instead; of fully loading it into memory (`memory` mode). If you want to modify; backed attributes of the AnnData object, you need to choose ``'r+'``.; sheet; Name of sheet/table in hdf5 or Excel file.; ext; Extension that indicates the file type. If ``None``, uses extension of; filename.; delimiter; Delimiter that separates data within text file. If ``None``, will split at; arbitrary number of white spaces, which is different from enforcing; splitting at any single white space ``' '``.; first_column_names; Assume the first column stores row names. This is only necessary if; these are not strings: strings in the first column are automatically; assumed to be row names.; backup_url; Retrieve the file from an URL if not present on disk.; cache; If `False`, read from source, if `True`, read from fast 'h5ad' cache.; cache_compression; See the h5py :ref:`dataset_compression`.; (Default: `settings.cache_compression`); kwargs; Parameters passed to :func:`~anndata.read_loom`. Returns; -------; An :class:`~anndata.AnnData` object; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py:101,cache,cache,101,src/scanpy/readwrite.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py,6,"['cache', 'load']","['cache', 'load', 'loading']"
Performance,"""""""\; Scale data to unit variance and zero mean. .. note::; Variables (genes) that do not display any variation (are constant across; all observations) are retained and (for zero_center==True) set to 0; during this operation. In the future, they might be set to NaNs. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; zero_center; If `False`, omit zero-centering variables, which allows to handle sparse; input efficiently.; max_value; Clip (truncate) to this value after scaling. If `None`, do not clip.; copy; Whether this function should be performed inplace. If an AnnData object; is passed, this also determines if a copy is returned.; layer; If provided, which element of layers to scale.; obsm; If provided, which element of obsm to scale.; mask_obs; Restrict both the derivation of scaling parameters and the scaling itself; to a certain set of observations. The mask is specified as a boolean array; or a string referring to an array in :attr:`~anndata.AnnData.obs`.; This will transform data from csc to csr format if `issparse(data)`. Returns; -------; Returns `None` if `copy=False`, else returns an updated `AnnData` object. Sets the following fields:. `adata.X` | `adata.layers[layer]` : :class:`numpy.ndarray` | :class:`scipy.sparse._csr.csr_matrix` (dtype `float`); Scaled count data matrix.; `adata.var['mean']` : :class:`pandas.Series` (dtype `float`); Means per gene before scaling.; `adata.var['std']` : :class:`pandas.Series` (dtype `float`); Standard deviations per gene before scaling.; `adata.var['var']` : :class:`pandas.Series` (dtype `float`); Variances per gene before scaling.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scale.py:630,perform,performed,630,src/scanpy/preprocessing/_scale.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scale.py,1,['perform'],['performed']
Performance,"""""""\; Use Scanorama :cite:p:`Hie2019` to integrate different experiments. Scanorama :cite:p:`Hie2019` is an algorithm for integrating single-cell; data from multiple experiments stored in an AnnData object. This; function should be run after performing PCA but before computing; the neighbor graph, as illustrated in the example below. This uses the implementation of scanorama_ :cite:p:`Hie2019`. .. _scanorama: https://github.com/brianhie/scanorama. Parameters; ----------; adata; The annotated data matrix.; key; The name of the column in ``adata.obs`` that differentiates; among experiments/batches. Cells from the same batch must be; contiguously stored in ``adata``.; basis; The name of the field in ``adata.obsm`` where the PCA table is; stored. Defaults to ``'X_pca'``, which is the default for; ``sc.pp.pca()``.; adjusted_basis; The name of the field in ``adata.obsm`` where the integrated; embeddings will be stored after running this function. Defaults; to ``X_scanorama``.; knn; Number of nearest neighbors to use for matching.; sigma; Correction smoothing parameter on Gaussian kernel.; approx; Use approximate nearest neighbors with Python ``annoy``;; greatly speeds up matching runtime.; alpha; Alignment score minimum cutoff.; batch_size; The batch size used in the alignment vector computation. Useful; when integrating very large (>100k samples) datasets. Set to; large value that runs within available memory.; kwargs; Any additional arguments will be passed to; ``scanorama.assemble()``. Returns; -------; Updates adata with the field ``adata.obsm[adjusted_basis]``,; containing Scanorama embeddings such that different experiments; are integrated. Example; -------; First, load libraries and example dataset, and preprocess. >>> import scanpy as sc; >>> import scanpy.external as sce; >>> adata = sc.datasets.pbmc3k(); >>> sc.pp.recipe_zheng17(adata); >>> sc.pp.pca(adata). We now arbitrarily assign a batch metadata variable to each cell; for the sake of example, but during real",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py:242,perform,performing,242,src/scanpy/external/pp/_scanorama_integrate.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_scanorama_integrate.py,1,['perform'],['performing']
Performance,"""""""\; Use harmonypy :cite:p:`Korsunsky2019` to integrate different experiments. Harmony :cite:p:`Korsunsky2019` is an algorithm for integrating single-cell; data from multiple experiments. This function uses the python; port of Harmony, ``harmonypy``, to integrate single-cell data; stored in an AnnData object. As Harmony works by adjusting the; principal components, this function should be run after performing; PCA but before computing the neighbor graph, as illustrated in the; example below. Parameters; ----------; adata; The annotated data matrix.; key; The name of the column in ``adata.obs`` that differentiates; among experiments/batches.; basis; The name of the field in ``adata.obsm`` where the PCA table is; stored. Defaults to ``'X_pca'``, which is the default for; ``sc.pp.pca()``.; adjusted_basis; The name of the field in ``adata.obsm`` where the adjusted PCA; table will be stored after running this function. Defaults to; ``X_pca_harmony``.; kwargs; Any additional arguments will be passed to; ``harmonypy.run_harmony()``. Returns; -------; Updates adata with the field ``adata.obsm[obsm_out_field]``,; containing principal components adjusted by Harmony such that; different experiments are integrated. Example; -------; First, load libraries and example dataset, and preprocess. >>> import scanpy as sc; >>> import scanpy.external as sce; >>> adata = sc.datasets.pbmc3k(); >>> sc.pp.recipe_zheng17(adata); >>> sc.pp.pca(adata). We now arbitrarily assign a batch metadata variable to each cell; for the sake of example, but during real usage there would already; be a column in ``adata.obs`` giving the experiment each cell came; from. >>> adata.obs['batch'] = 1350*['a'] + 1350*['b']. Finally, run harmony. Afterwards, there will be a new table in; ``adata.obsm`` containing the adjusted PC's. >>> sce.pp.harmony_integrate(adata, 'batch'); >>> 'X_pca_harmony' in adata.obsm; True; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_harmony_integrate.py:403,perform,performing,403,src/scanpy/external/pp/_harmony_integrate.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_harmony_integrate.py,2,"['load', 'perform']","['load', 'performing']"
Performance,"""""""\; n_comps; Number of principal components to compute in the PCA step.; random_state; Random seed for setting the initial states for the optimization in the PCA step.; kwargs_pca; Dictionary of further keyword arguments passed on to `scanpy.pp.pca()`.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/_docs.py:140,optimiz,optimization,140,src/scanpy/experimental/_docs.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/_docs.py,1,['optimiz'],['optimization']
Performance,"""""""\; use_cache; Whether pybiomart should use a cache for requests. Will create a; `.pybiomart.sqlite` file in current directory if used.\; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/queries/_queries.py:48,cache,cache,48,src/scanpy/queries/_queries.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/queries/_queries.py,1,['cache'],['cache']
Performance,"""""""tests the sequence log1p→save→load→rank_genes_groups""""""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_rank_genes_groups.py:33,load,load,33,tests/test_rank_genes_groups.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_rank_genes_groups.py,1,['load'],['load']
Performance,"# Current memory bottleneck for csr matrices:",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_qc.py:17,bottleneck,bottleneck,17,src/scanpy/preprocessing/_qc.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_qc.py,1,['bottleneck'],['bottleneck']
Performance,"# Performance",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/paga.py:2,Perform,Performance,2,src/scanpy/plotting/_tools/paga.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/paga.py,2,['Perform'],['Performance']
Performance,"# This catches a race condition where a process ends; # before we can examine its files",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py:17,race condition,race condition,17,src/scanpy/readwrite.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py,1,['race condition'],['race condition']
Performance,"# This tool has the purpose to take a set of genes (possibly already pre-selected) and analyze AUC.; # Those and only those are eliminated who are dominated completely; # TODO: Potentially (But not till tomorrow), this can be adapted to only consider the AUC in the given; # TODO: optimization frame",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_top_genes.py:281,optimiz,optimization,281,src/scanpy/tools/_top_genes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_top_genes.py,1,['optimiz'],['optimization']
Performance,"# Write counts matrices as hdf5 files and npz if they do not already exist; # or if user requires overwrite.; # To do: check if Alex's h5sparse format will allow fast loading from just; # one file.",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/exporting.py:167,load,loading,167,src/scanpy/external/exporting.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/exporting.py,1,['load'],['loading']
Performance,"# calculate eigenvectors & eigenvalues of the covariance matrix; # use 'eigh' rather than 'eig' since C is symmetric,; # the performance gain is substantial; # evals, evecs = np.linalg.eigh(C)",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:125,perform,performance,125,src/scanpy/preprocessing/_simple.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py,1,['perform'],['performance']
Performance,"# do not use the cached rp_forest",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/__init__.py:17,cache,cached,17,src/scanpy/neighbors/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/__init__.py,1,['cache'],['cached']
Performance,"# load the last simulation file",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:2,load,load,2,src/scanpy/tools/_sim.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py,1,['load'],['load']
Performance,"# this test checks wether combat can align data from several gaussians; # it checks this by computing the silhouette coefficient in a pca embedding; # load in data",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_combat.py:151,load,load,151,tests/test_combat.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_combat.py,1,['load'],['load']
Performance,"# this test trivially checks whether mean normalisation worked; # load in data",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_combat.py:66,load,load,66,tests/test_combat.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_combat.py,1,['load'],['load']
Performance,"###############################################################################; # Calculation; ###############################################################################; # Some notes on the implementation:; # * This could be phrased as tensor multiplication. However that does not get; # parallelized, which boosts performance almost linearly with cores.; # * Due to the umap setting the default threading backend, a parallel numba; # function that calls another parallel numba function can get stuck. This; # ends up meaning code re-use will be limited until umap 0.4.; # See: https://github.com/lmcinnes/umap/issues/306; # * There can be a fair amount of numerical instability here (big reductions),; # so data is cast to float64. Removing these casts/ conversion will cause the; # tests to fail.",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/metrics/_gearys_c.py:322,perform,performance,322,src/scanpy/metrics/_gearys_c.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/metrics/_gearys_c.py,1,['perform'],['performance']
Performance,"(genes). Necessary when using only a; subset of vars to perform MNN correction, and should be supplied with; `var_subset`. When `datas` are AnnData objects, `var_index` is ignored.; var_subset; The subset of vars (list of str) to be used when performing MNN; correction. Typically, a list of highly variable genes (HVGs).; When set to `None`, uses all vars.; batch_key; The `batch_key` for :meth:`~anndata.AnnData.concatenate`.; Only valid when `do_concatenate` and supplying `AnnData` objects.; index_unique; The `index_unique` for :meth:`~anndata.AnnData.concatenate`.; Only valid when `do_concatenate` and supplying `AnnData` objects.; batch_categories; The `batch_categories` for :meth:`~anndata.AnnData.concatenate`.; Only valid when `do_concatenate` and supplying AnnData objects.; k; Number of mutual nearest neighbors.; sigma; The bandwidth of the Gaussian smoothing kernel used to compute the; correction vectors. Default is 1.; cos_norm_in; Whether cosine normalization should be performed on the input data prior; to calculating distances between cells.; cos_norm_out; Whether cosine normalization should be performed prior to computing corrected expression values.; svd_dim; The number of dimensions to use for summarizing biological substructure; within each batch. If None, biological components will not be removed; from the correction vectors.; var_adj; Whether to adjust variance of the correction vectors. Note this step; takes most computing time.; compute_angle; Whether to compute the angle between each cell’s correction vector and; the biological subspace of the reference batch.; mnn_order; The order in which batches are to be corrected. When set to None, datas; are corrected sequentially.; svd_mode; `'svd'` computes SVD using a non-randomized SVD-via-ID algorithm,; while `'rsvd'` uses a randomized version. `'irlb'` perfores; truncated SVD by implicitly restarted Lanczos bidiagonalization; (forked from https://github.com/airysen/irlbpy).; do_concatenate; Whether to con",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_mnn_correct.py:1815,perform,performed,1815,src/scanpy/external/pp/_mnn_correct.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_mnn_correct.py,1,['perform'],['performed']
Performance,".; louvain_time_limit; Maximum number of seconds to run modularity optimization. If exceeded the best; result so far is returned.; nn_method; Whether to use brute force or kdtree for nearest neighbor search.; For very large high-dimensional data sets, brute force, with parallel; computation, performs faster than kdtree.; partition_type; Defaults to :class:`~leidenalg.RBConfigurationVertexPartition`. For the; available options, consult the documentation for; :func:`~leidenalg.find_partition`.; resolution_parameter; A parameter value controlling the coarseness of the clustering in Leiden. Higher; values lead to more clusters. Set to `None` if overriding `partition_type` to; one that does not accept a `resolution_parameter`.; n_iterations; Number of iterations to run the Leiden algorithm. If the number of iterations is; negative, the Leiden algorithm is run until an iteration in which there was no; improvement.; use_weights; Use vertices in the Leiden computation.; seed; Leiden initialization of the optimization.; copy; Return a copy or write to `adata`.; kargs; Additional arguments passed to :func:`~leidenalg.find_partition` and the; constructor of the `partition_type`. Returns; -------; Depending on `copy`, returns or updates `adata` with the following fields:. **communities** - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.obs`, dtype `int`); integer array of community assignments for each row in data. **graph** - :class:`~scipy.sparse.spmatrix` (:attr:`~anndata.AnnData.obsp`, dtype `float`); the graph that was used for clustering. **Q** - `float` (:attr:`~anndata.AnnData.uns`, dtype `float`); the modularity score for communities on graph. Example; -------; >>> from anndata import AnnData; >>> import scanpy as sc; >>> import scanpy.external as sce; >>> import numpy as np; >>> import pandas as pd. With annotated data as input:. >>> adata = sc.datasets.pbmc3k(); >>> sc.pp.normalize_per_cell(adata). Then do PCA:. >>> sc.pp.pca(adata, n_comps=100). Compute phenograph",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phenograph.py:3045,optimiz,optimization,3045,src/scanpy/external/tl/_phenograph.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phenograph.py,1,['optimiz'],['optimization']
Performance,".TruncatedSVD` will be used.; Otherwise their *scikit-learn* counterparts :class:`~sklearn.decomposition.PCA`,; :class:`~sklearn.decomposition.IncrementalPCA`, or; :class:`~sklearn.decomposition.TruncatedSVD` will be used.; random_state; Change to use different initial states for the optimization.; return_info; Only relevant when not passing an :class:`~anndata.AnnData`:; see “Returns”.; {mask_var_hvg}; layer; Layer of `adata` to use as expression values.; dtype; Numpy data type string to which to convert the result.; copy; If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned. Is ignored otherwise.; chunked; If `True`, perform an incremental PCA on segments of `chunk_size`.; The incremental PCA automatically zero centers and ignores settings of; `random_seed` and `svd_solver`. Uses sklearn :class:`~sklearn.decomposition.IncrementalPCA` or; *dask-ml* :class:`~dask_ml.decomposition.IncrementalPCA`. If `False`, perform a full PCA and; use sklearn :class:`~sklearn.decomposition.PCA` or; *dask-ml* :class:`~dask_ml.decomposition.PCA`; chunk_size; Number of observations to include in each chunk.; Required if `chunked=True` was passed. Returns; -------; If `data` is array-like and `return_info=False` was passed,; this function returns the PCA representation of `data` as an; array of the same type as the input array. Otherwise, it returns `None` if `copy=False`, else an updated `AnnData` object.; Sets the following fields:. `.obsm['X_pca']` : :class:`~scipy.sparse.spmatrix` | :class:`~numpy.ndarray` (shape `(adata.n_obs, n_comps)`); PCA representation of data.; `.varm['PCs']` : :class:`~numpy.ndarray` (shape `(adata.n_vars, n_comps)`); The principal components containing the loadings.; `.uns['pca']['variance_ratio']` : :class:`~numpy.ndarray` (shape `(n_comps,)`); Ratio of explained variance.; `.uns['pca']['variance']` : :class:`~numpy.ndarray` (shape `(n_comps,)`); Explained variance, equivalent to the eigenvalues of the; covariance matrix.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py:4486,load,loadings,4486,src/scanpy/preprocessing/_pca.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py,1,['load'],['loadings']
Performance,"; Nearest Neighbors will be computed in parallel using n_jobs.; copy; Return a copy instead of writing to `adata`. Returns; -------; Depending on `copy`, returns or updates `.obsm`, `.obsp` and `.uns` with the following:. **X_harmony** - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.obsm`, dtype `float`); force directed layout; **harmony_aff** - :class:`~scipy.sparse.spmatrix` (:attr:`~anndata.AnnData.obsp`, dtype `float`); affinity matrix; **harmony_aff_aug** - :class:`~scipy.sparse.spmatrix` (:attr:`~anndata.AnnData.obsp`, dtype `float`); augmented affinity matrix; **harmony_timepoint_var** - `str` (:attr:`~anndata.AnnData.uns`); The name of the variable passed as `tp`; **harmony_timepoint_connections** - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.uns`, dtype `str`); The links between time points. Example; -------. >>> from itertools import product; >>> import pandas as pd; >>> from anndata import AnnData; >>> import scanpy as sc; >>> import scanpy.external as sce. **Load** `AnnData`. A sample with real data is available here_. .. _here: https://github.com/dpeerlab/Harmony/tree/master/data. Random data sets of three time points with two replicates each:. >>> adata_ref = sc.datasets.pbmc3k(); >>> start = [596, 615, 1682, 1663, 1409, 1432]; >>> adata = AnnData.concatenate(; ... *(adata_ref[i : i + 1000] for i in start),; ... join=""outer"",; ... batch_key=""sample"",; ... batch_categories=[f""sa{i}_Rep{j}"" for i, j in product((1, 2, 3), (1, 2))],; ... ); >>> time_points = adata.obs[""sample""].str.split(""_"", expand=True)[0]; >>> adata.obs[""time_points""] = pd.Categorical(; ... time_points, categories=['sa1', 'sa2', 'sa3']; ... ). Normalize and filter for highly expressed genes. >>> sc.pp.normalize_total(adata, target_sum=10000); >>> sc.pp.log1p(adata); >>> sc.pp.highly_variable_genes(adata, n_top_genes=1000, subset=True). Run harmony_timeseries. >>> sce.tl.harmony_timeseries(adata, tp=""time_points"", n_components=500). Plot time points:. >>> sce.pl.harmony_timeserie",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_harmony_timeseries.py:2537,Load,Load,2537,src/scanpy/external/tl/_harmony_timeseries.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_harmony_timeseries.py,1,['Load'],['Load']
Performance,"E, see :cite:t:`Becht2018`. .. _umap-learn: https://github.com/lmcinnes/umap. Parameters; ----------; adata; Annotated data matrix.; min_dist; The effective minimum distance between embedded points. Smaller values; will result in a more clustered/clumped embedding where nearby points on; the manifold are drawn closer together, while larger values will result; on a more even dispersal of points. The value should be set relative to; the ``spread`` value, which determines the scale at which embedded; points will be spread out. The default of in the `umap-learn` package is; 0.1.; spread; The effective scale of embedded points. In combination with `min_dist`; this determines how clustered/clumped the embedded points are.; n_components; The number of dimensions of the embedding.; maxiter; The number of iterations (epochs) of the optimization. Called `n_epochs`; in the original UMAP.; alpha; The initial learning rate for the embedding optimization.; gamma; Weighting applied to negative samples in low dimensional embedding; optimization. Values higher than one will result in greater weight; being given to negative samples.; negative_sample_rate; The number of negative edge/1-simplex samples to use per positive; edge/1-simplex sample in optimizing the low dimensional embedding.; init_pos; How to initialize the low dimensional embedding. Called `init` in the; original UMAP. Options are:. * Any key for `adata.obsm`.; * 'paga': positions from :func:`~scanpy.pl.paga`.; * 'spectral': use a spectral embedding of the graph.; * 'random': assign initial embedding positions at random.; * A numpy array of initial embedding positions.; random_state; If `int`, `random_state` is the seed used by the random number generator;; If `RandomState` or `Generator`, `random_state` is the random number generator;; If `None`, the random number generator is the `RandomState` instance used; by `np.random`.; a; More specific parameters controlling the embedding. If `None` these; values are set automati",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_umap.py:1711,optimiz,optimization,1711,src/scanpy/tools/_umap.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_umap.py,1,['optimiz'],['optimization']
Performance,"If true, the input of the autoencoder is centered using; `sc.pp.scale` function of Scanpy. Note that the output is kept as raw; counts as loss functions are designed for the count data.; log1p; If true, the input of the autoencoder is log transformed with a; pseudocount of one using `sc.pp.log1p` function of Scanpy.; hidden_size; Width of hidden layers.; hidden_dropout; Probability of weight dropout in the autoencoder (per layer if list; or tuple).; batchnorm; If true, batch normalization is performed.; activation; Activation function of hidden layers.; init; Initialization method used to initialize weights.; network_kwds; Additional keyword arguments for the autoencoder.; epochs; Number of total epochs in training.; reduce_lr; Reduces learning rate if validation loss does not improve in given number of epochs.; early_stop; Stops training if validation loss does not improve in given number of epochs.; batch_size; Number of samples in the batch used for SGD.; optimizer; Type of optimization method used for training.; random_state; Seed for python, numpy and tensorflow.; threads; Number of threads to use in training. All cores are used by default.; learning_rate; Learning rate to use in the training.; verbose; If true, prints additional information about training and architecture.; training_kwds; Additional keyword arguments for the training process.; return_model; If true, trained autoencoder object is returned. See ""Returns"".; return_info; If true, all additional parameters of DCA are stored in `adata.obsm` such as dropout; probabilities (obsm['X_dca_dropout']) and estimated dispersion values; (obsm['X_dca_dispersion']), in case that autoencoder is of type; zinb or zinb-conddisp.; copy; If true, a copy of anndata is returned. Returns; -------; If `copy` is true and `return_model` is false, AnnData object is returned. In ""denoise"" mode, `adata.X` is overwritten with the denoised values.; In ""latent"" mode, latent low dimensional representation of cells are stored; in `",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_dca.py:2202,optimiz,optimizer,2202,src/scanpy/external/pp/_dca.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_dca.py,2,['optimiz'],"['optimization', 'optimizer']"
Performance,"`. If the fractions; do not sum to 1, a new category called `'rest'` colored grey will be created.; labels; The node labels. If `None`, this defaults to the group labels stored in; the categorical for which :func:`~scanpy.tl.paga` has been computed.; pos; Two-column array-like storing the x and y coordinates for drawing.; Otherwise, path to a `.gdf` file that has been exported from Gephi or; a similar graph visualization software.; layout; Plotting layout that computes positions.; `'fa'` stands for “ForceAtlas2”,; `'fr'` stands for “Fruchterman-Reingold”,; `'rt'` stands for “Reingold-Tilford”,; `'eq_tree'` stands for “eqally spaced tree”.; All but `'fa'` and `'eq_tree'` are igraph layouts.; All other igraph layouts are also permitted.; See also parameter `pos` and :func:`~scanpy.tl.draw_graph`.; layout_kwds; Keywords for the layout.; init_pos; Two-column array storing the x and y coordinates for initializing the; layout.; random_state; For layouts with random initialization like `'fr'`, change this to use; different intial states for the optimization. If `None`, the initial; state is not reproducible.; root; If choosing a tree layout, this is the index of the root node or a list; of root node indices. If this is a non-empty vector then the supplied; node IDs are used as the roots of the trees (or a single tree if the; graph is connected). If this is `None` or an empty list, the root; vertices are automatically calculated based on topological sorting.; transitions; Key for `.uns['paga']` that specifies the matrix that stores the; arrows, for instance `'transitions_confidence'`.; solid_edges; Key for `.uns['paga']` that specifies the matrix that stores the edges; to be drawn solid black.; dashed_edges; Key for `.uns['paga']` that specifies the matrix that stores the edges; to be drawn dashed grey. If `None`, no dashed edges are drawn.; single_component; Restrict to largest connected component.; fontsize; Font size for node labels.; fontoutline; Width of the white outli",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/paga.py:1981,optimiz,optimization,1981,src/scanpy/plotting/_tools/paga.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/paga.py,1,['optimiz'],['optimization']
Performance,"`. When `datas` are AnnData objects, `var_index` is ignored.; var_subset; The subset of vars (list of str) to be used when performing MNN; correction. Typically, a list of highly variable genes (HVGs).; When set to `None`, uses all vars.; batch_key; The `batch_key` for :meth:`~anndata.AnnData.concatenate`.; Only valid when `do_concatenate` and supplying `AnnData` objects.; index_unique; The `index_unique` for :meth:`~anndata.AnnData.concatenate`.; Only valid when `do_concatenate` and supplying `AnnData` objects.; batch_categories; The `batch_categories` for :meth:`~anndata.AnnData.concatenate`.; Only valid when `do_concatenate` and supplying AnnData objects.; k; Number of mutual nearest neighbors.; sigma; The bandwidth of the Gaussian smoothing kernel used to compute the; correction vectors. Default is 1.; cos_norm_in; Whether cosine normalization should be performed on the input data prior; to calculating distances between cells.; cos_norm_out; Whether cosine normalization should be performed prior to computing corrected expression values.; svd_dim; The number of dimensions to use for summarizing biological substructure; within each batch. If None, biological components will not be removed; from the correction vectors.; var_adj; Whether to adjust variance of the correction vectors. Note this step; takes most computing time.; compute_angle; Whether to compute the angle between each cell’s correction vector and; the biological subspace of the reference batch.; mnn_order; The order in which batches are to be corrected. When set to None, datas; are corrected sequentially.; svd_mode; `'svd'` computes SVD using a non-randomized SVD-via-ID algorithm,; while `'rsvd'` uses a randomized version. `'irlb'` perfores; truncated SVD by implicitly restarted Lanczos bidiagonalization; (forked from https://github.com/airysen/irlbpy).; do_concatenate; Whether to concatenate the corrected matrices or AnnData objects. Default is True.; save_raw; Whether to save the original expression ",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_mnn_correct.py:1944,perform,performed,1944,src/scanpy/external/pp/_mnn_correct.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_mnn_correct.py,1,['perform'],['performed']
Performance,"aph` via; `init_pos='paga'` to get single-cell embeddings that are typically more; faithful to the global topology. Parameters; ----------; adata; An annotated data matrix.; groups; Key for categorical in `adata.obs`. You can pass your predefined groups; by choosing any categorical annotation of observations. Default:; The first present key of `'leiden'` or `'louvain'`.; use_rna_velocity; Use RNA velocity to orient edges in the abstracted graph and estimate; transitions. Requires that `adata.uns` contains a directed single-cell; graph with key `['velocity_graph']`. This feature might be subject; to change in the future.; model; The PAGA connectivity model.; neighbors_key; If not specified, paga looks `.uns['neighbors']` for neighbors settings; and `.obsp['connectivities']`, `.obsp['distances']` for connectivities and; distances respectively (default storage places for `pp.neighbors`).; If specified, paga looks `.uns[neighbors_key]` for neighbors settings and; `.obsp[.uns[neighbors_key]['connectivities_key']]`,; `.obsp[.uns[neighbors_key]['distances_key']]` for connectivities and distances; respectively.; copy; Copy `adata` before computation and return a copy. Otherwise, perform; computation inplace and return `None`. Returns; -------; Returns `None` if `copy=False`, else returns an `AnnData` object. Sets the following fields:. `adata.uns['connectivities']` : :class:`numpy.ndarray` (dtype `float`); The full adjacency matrix of the abstracted graph, weights correspond to; confidence in the connectivities of partitions.; `adata.uns['connectivities_tree']` : :class:`scipy.sparse.csr_matrix` (dtype `float`); The adjacency matrix of the tree-like subgraph that best explains; the topology. Notes; -----; Together with a random walk-based distance measure; (e.g. :func:`scanpy.tl.dpt`) this generates a partial coordinatization of; data useful for exploring and explaining its variation. .. currentmodule:: scanpy. See Also; --------; pl.paga; pl.paga_path; pl.paga_compare; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_paga.py:2293,perform,perform,2293,src/scanpy/tools/_paga.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_paga.py,1,['perform'],['perform']
Performance,"class:`~dask_ml.decomposition.TruncatedSVD` will be used.; Otherwise their *scikit-learn* counterparts :class:`~sklearn.decomposition.PCA`,; :class:`~sklearn.decomposition.IncrementalPCA`, or; :class:`~sklearn.decomposition.TruncatedSVD` will be used.; random_state; Change to use different initial states for the optimization.; return_info; Only relevant when not passing an :class:`~anndata.AnnData`:; see “Returns”.; {mask_var_hvg}; layer; Layer of `adata` to use as expression values.; dtype; Numpy data type string to which to convert the result.; copy; If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned. Is ignored otherwise.; chunked; If `True`, perform an incremental PCA on segments of `chunk_size`.; The incremental PCA automatically zero centers and ignores settings of; `random_seed` and `svd_solver`. Uses sklearn :class:`~sklearn.decomposition.IncrementalPCA` or; *dask-ml* :class:`~dask_ml.decomposition.IncrementalPCA`. If `False`, perform a full PCA and; use sklearn :class:`~sklearn.decomposition.PCA` or; *dask-ml* :class:`~dask_ml.decomposition.PCA`; chunk_size; Number of observations to include in each chunk.; Required if `chunked=True` was passed. Returns; -------; If `data` is array-like and `return_info=False` was passed,; this function returns the PCA representation of `data` as an; array of the same type as the input array. Otherwise, it returns `None` if `copy=False`, else an updated `AnnData` object.; Sets the following fields:. `.obsm['X_pca']` : :class:`~scipy.sparse.spmatrix` | :class:`~numpy.ndarray` (shape `(adata.n_obs, n_comps)`); PCA representation of data.; `.varm['PCs']` : :class:`~numpy.ndarray` (shape `(adata.n_vars, n_comps)`); The principal components containing the loadings.; `.uns['pca']['variance_ratio']` : :class:`~numpy.ndarray` (shape `(n_comps,)`); Ratio of explained variance.; `.uns['pca']['variance']` : :class:`~numpy.ndarray` (shape `(n_comps,)`); Explained variance, equivalent to the eigenvalues of",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py:3713,perform,perform,3713,src/scanpy/preprocessing/_pca.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py,1,['perform'],['perform']
Performance,"com/KrishnaswamyLab/MAGIC>`__. For help, visit; <https://krishnaswamylab.org/get-help>. Parameters; ----------; adata; An anndata file with `.raw` attribute representing raw counts.; name_list; Denoised genes to return. The default `'all_genes'`/`None`; may require a large amount of memory if the input data is sparse.; Another possibility is `'pca_only'`.; knn; number of nearest neighbors on which to build kernel.; decay; sets decay rate of kernel tails.; If None, alpha decaying kernel is not used.; knn_max; maximum number of nearest neighbors with nonzero connection.; If `None`, will be set to 3 * `knn`.; t; power to which the diffusion operator is powered.; This sets the level of diffusion. If 'auto', t is selected; according to the Procrustes disparity of the diffused data.; n_pca; Number of principal components to use for calculating; neighborhoods. For extremely large datasets, using; n_pca < 20 allows neighborhoods to be calculated in; roughly log(n_samples) time. If `None`, no PCA is performed.; solver; Which solver to use. ""exact"" uses the implementation described; in :cite:t:`vanDijk2018`. ""approximate"" uses a faster; implementation that performs imputation in the PCA space and then; projects back to the gene space. Note, the ""approximate"" solver may; return negative values.; knn_dist; recommended values: 'euclidean', 'cosine', 'precomputed'; Any metric from `scipy.spatial.distance` can be used; distance metric for building kNN graph. If 'precomputed',; `data` should be an n_samples x n_samples distance or; affinity matrix.; random_state; Random seed. Defaults to the global `numpy` random number generator.; n_jobs; Number of threads to use in training. All cores are used by default.; verbose; If `True` or an integer `>= 2`, print status messages.; If `None`, `sc.settings.verbosity` is used.; copy; If true, a copy of anndata is returned. If `None`, `copy` is True if; `genes` is not `'all_genes'` or `'pca_only'`. `copy` may only be False; if `genes` is `'all_",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_magic.py:1714,perform,performed,1714,src/scanpy/external/pp/_magic.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_magic.py,1,['perform'],['performed']
Performance,"e autoencoder. Return values and the architecture is; determined by the type e.g. `nb` does not provide dropout; probabilities. Types that end with ""-conddisp"", assumes that dispersion is mean dependant.; normalize_per_cell; If true, library size normalization is performed using; the `sc.pp.normalize_per_cell` function in Scanpy and saved into adata; object. Mean layer is re-introduces library size differences by; scaling the mean value of each cell in the output layer. See the; manuscript for more details.; scale; If true, the input of the autoencoder is centered using; `sc.pp.scale` function of Scanpy. Note that the output is kept as raw; counts as loss functions are designed for the count data.; log1p; If true, the input of the autoencoder is log transformed with a; pseudocount of one using `sc.pp.log1p` function of Scanpy.; hidden_size; Width of hidden layers.; hidden_dropout; Probability of weight dropout in the autoencoder (per layer if list; or tuple).; batchnorm; If true, batch normalization is performed.; activation; Activation function of hidden layers.; init; Initialization method used to initialize weights.; network_kwds; Additional keyword arguments for the autoencoder.; epochs; Number of total epochs in training.; reduce_lr; Reduces learning rate if validation loss does not improve in given number of epochs.; early_stop; Stops training if validation loss does not improve in given number of epochs.; batch_size; Number of samples in the batch used for SGD.; optimizer; Type of optimization method used for training.; random_state; Seed for python, numpy and tensorflow.; threads; Number of threads to use in training. All cores are used by default.; learning_rate; Learning rate to use in the training.; verbose; If true, prints additional information about training and architecture.; training_kwds; Additional keyword arguments for the training process.; return_model; If true, trained autoencoder object is returned. See ""Returns"".; return_info; If true, all add",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_dca.py:1726,perform,performed,1726,src/scanpy/external/pp/_dca.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_dca.py,1,['perform'],['performed']
Performance,"e this number times the number; of batches. This then serves as the basis for the construction of a symmetrical; matrix of connectivities.; n_pcs; How many dimensions (in case of PCA, principal components) to use in the analysis.; trim; Trim the neighbours of each cell to these many top connectivities. May help with; population independence and improve the tidiness of clustering. The lower the value the; more independent the individual populations, at the cost of more conserved batch effect.; If `None`, sets the parameter value automatically to 10 times `neighbors_within_batch`; times the number of batches. Set to 0 to skip.; annoy_n_trees; Only used with annoy neighbour identification. The number of trees to construct in the; annoy forest. More trees give higher precision when querying, at the cost of increased; run time and resource intensity.; pynndescent_n_neighbors; Only used with pyNNDescent neighbour identification. The number of neighbours to include; in the approximate neighbour graph. More neighbours give higher precision when querying,; at the cost of increased run time and resource intensity.; pynndescent_random_state; Only used with pyNNDescent neighbour identification. The RNG seed to use when creating; the graph.; use_faiss; If `approx=False` and the metric is ""euclidean"", use the faiss package to compute; nearest neighbours if installed. This improves performance at a minor cost to numerical; precision as faiss operates on float32.; set_op_mix_ratio; UMAP connectivity computation parameter, float between 0 and 1, controlling the; blend between a connectivity matrix formed exclusively from mutual nearest neighbour; pairs (0) and a union of all observed neighbour relationships with the mutual pairs; emphasised (1); local_connectivity; UMAP connectivity computation parameter, how many nearest neighbors of each cell; are assumed to be fully connected (and given a connectivity value of 1). Returns; -------; The `adata` with the batch-corrected graph.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_bbknn.py:3821,perform,performance,3821,src/scanpy/external/pp/_bbknn.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_bbknn.py,1,['perform'],['performance']
Performance,"ed from `'auto'` to `'arpack'`. Efficient computation of the principal components of a sparse matrix; currently only works with the `'arpack`' or `'lobpcg'` solvers. If X is a *dask* array, *dask-ml* classes :class:`~dask_ml.decomposition.PCA`,; :class:`~dask_ml.decomposition.IncrementalPCA`, or; :class:`~dask_ml.decomposition.TruncatedSVD` will be used.; Otherwise their *scikit-learn* counterparts :class:`~sklearn.decomposition.PCA`,; :class:`~sklearn.decomposition.IncrementalPCA`, or; :class:`~sklearn.decomposition.TruncatedSVD` will be used.; random_state; Change to use different initial states for the optimization.; return_info; Only relevant when not passing an :class:`~anndata.AnnData`:; see “Returns”.; {mask_var_hvg}; layer; Layer of `adata` to use as expression values.; dtype; Numpy data type string to which to convert the result.; copy; If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned. Is ignored otherwise.; chunked; If `True`, perform an incremental PCA on segments of `chunk_size`.; The incremental PCA automatically zero centers and ignores settings of; `random_seed` and `svd_solver`. Uses sklearn :class:`~sklearn.decomposition.IncrementalPCA` or; *dask-ml* :class:`~dask_ml.decomposition.IncrementalPCA`. If `False`, perform a full PCA and; use sklearn :class:`~sklearn.decomposition.PCA` or; *dask-ml* :class:`~dask_ml.decomposition.PCA`; chunk_size; Number of observations to include in each chunk.; Required if `chunked=True` was passed. Returns; -------; If `data` is array-like and `return_info=False` was passed,; this function returns the PCA representation of `data` as an; array of the same type as the input array. Otherwise, it returns `None` if `copy=False`, else an updated `AnnData` object.; Sets the following fields:. `.obsm['X_pca']` : :class:`~scipy.sparse.spmatrix` | :class:`~numpy.ndarray` (shape `(adata.n_obs, n_comps)`); PCA representation of data.; `.varm['PCs']` : :class:`~numpy.ndarray` (shape `(adata.n_vars, n",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py:3418,perform,perform,3418,src/scanpy/preprocessing/_pca.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py,1,['perform'],['perform']
Performance,"hed; algorithms for visualizing graphs.; It has been suggested for visualizing single-cell data by :cite:t:`Islam2011`.; Many other layouts as implemented in igraph :cite:p:`Csardi2006` are available.; Similar approaches have been used by :cite:t:`Zunder2015` or :cite:t:`Weinreb2017`. .. |fa2| replace:: `fa2`; .. _fa2: https://github.com/bhargavchippada/forceatlas2; .. _Force-directed graph drawing: https://en.wikipedia.org/wiki/Force-directed_graph_drawing. Parameters; ----------; adata; Annotated data matrix.; layout; 'fa' (`ForceAtlas2`) or any valid `igraph layout; <https://igraph.org/c/doc/igraph-Layout.html>`__. Of particular interest; are 'fr' (Fruchterman Reingold), 'grid_fr' (Grid Fruchterman Reingold,; faster than 'fr'), 'kk' (Kamadi Kawai', slower than 'fr'), 'lgl' (Large; Graph, very fast), 'drl' (Distributed Recursive Layout, pretty fast) and; 'rt' (Reingold Tilford tree layout).; root; Root for tree layouts.; random_state; For layouts with random initialization like 'fr', change this to use; different intial states for the optimization. If `None`, no seed is set.; adjacency; Sparse adjacency matrix of the graph, defaults to neighbors connectivities.; key_added_ext; By default, append `layout`.; proceed; Continue computation, starting off with 'X_draw_graph_`layout`'.; init_pos; `'paga'`/`True`, `None`/`False`, or any valid 2d-`.obsm` key.; Use precomputed coordinates for initialization.; If `False`/`None` (the default), initialize randomly.; neighbors_key; If not specified, draw_graph looks .obsp['connectivities'] for connectivities; (default storage place for pp.neighbors).; If specified, draw_graph looks; .obsp[.uns[neighbors_key]['connectivities_key']] for connectivities.; obsp; Use .obsp[obsp] as adjacency. You can't specify both; `obsp` and `neighbors_key` at the same time.; copy; Return a copy instead of writing to adata.; **kwds; Parameters of chosen igraph layout. See e.g.; :meth:`~igraph.GraphBase.layout_fruchterman_reingold` :cite:p:`Fruchterm",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_draw_graph.py:1493,optimiz,optimization,1493,src/scanpy/tools/_draw_graph.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_draw_graph.py,1,['optimiz'],['optimization']
Performance,"ishbone uses multi-dimensional; single-cell data, such as mass cytometry or RNA-Seq data, as input and orders cells; according to their developmental progression, and it pinpoints bifurcation points; by labeling each cell as pre-bifurcation or as one of two post-bifurcation cell; fates. .. note::; More information and bug reports `here; <https://github.com/dpeerlab/wishbone>`__. Parameters; ----------; adata; Annotated data matrix.; start_cell; Desired start cell from `obs_names`.; branch; Use True for Wishbone and False for Wanderlust.; k; Number of nearest neighbors for graph construction.; components; Components to use for running Wishbone.; num_waypoints; Number of waypoints to sample. Returns; -------; Updates `adata` with the following fields:. `trajectory_wishbone` : (`adata.obs`, dtype `float64`); Computed trajectory positions.; `branch_wishbone` : (`adata.obs`, dtype `int64`); Assigned branches. Example; -------. >>> import scanpy.external as sce; >>> import scanpy as sc. **Loading Data and Pre-processing**. >>> adata = sc.datasets.pbmc3k(); >>> sc.pp.normalize_per_cell(adata); >>> sc.pp.pca(adata); >>> sc.tl.tsne(adata=adata, n_pcs=5, perplexity=30); >>> sc.pp.neighbors(adata, n_pcs=15, n_neighbors=10); >>> sc.tl.diffmap(adata, n_comps=10). **Running Wishbone Core Function**. Usually, the start cell for a dataset should be chosen based on high expression of; the gene of interest:. >>> sce.tl.wishbone(; ... adata=adata, start_cell='ACAAGAGACTTATC-1',; ... components=[2, 3], num_waypoints=150,; ... ). **Visualizing Wishbone results**. >>> sc.pl.tsne(adata, color=['trajectory_wishbone', 'branch_wishbone']); >>> markers = ['C1QA', 'PSAP', 'CD79A', 'CD79B', 'CST3', 'LYZ', 'MALAT1']; >>> sce.pl.wishbone_marker_trajectory(adata, markers, show=True). For further demonstration of Wishbone methods and visualization please follow the; notebooks in the package `Wishbone_for_single_cell_RNAseq.ipynb; <https://github.com/dpeerlab/wishbone/tree/master/notebooks>`_.\; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_wishbone.py:1230,Load,Loading,1230,src/scanpy/external/tl/_wishbone.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_wishbone.py,1,['Load'],['Loading']
Performance,"ormalization and PCA are performed. Expects raw count input. Params; ------; {adata}; {dist_params}; {genes_batch_chunk}; {pca_chunk}; {check_values}; {inplace}. Returns; -------; If `inplace=False`, separately returns the gene selection results (as; :class:`~pandas.DataFrame`) and Pearson residual-based PCA results (as; :class:`~anndata.AnnData`). If `inplace=True`, updates `adata` with the; following fields for gene selection results:. `.var['highly_variable']` : bool; boolean indicator of highly-variable genes.; `.var['means']` : float; means per gene.; `.var['variances']` : float; variances per gene.; `.var['residual_variances']` : float; Pearson residual variance per gene. Averaged in the case of multiple; batches.; `.var['highly_variable_rank']` : float; Rank of the gene according to residual variance, median rank in the; case of multiple batches.; `.var['highly_variable_nbatches']` : int; If batch_key is given, this denotes in how many batches genes are; detected as HVG.; `.var['highly_variable_intersection']` : bool; If batch_key is given, this denotes the genes that are highly variable; in all batches. The following fields contain Pearson residual-based PCA results and; normalization settings:. `.uns['pearson_residuals_normalization']['pearson_residuals_df']`; The subset of highly variable genes, normalized by Pearson residuals.; `.uns['pearson_residuals_normalization']['theta']`; The used value of the overdisperion parameter theta.; `.uns['pearson_residuals_normalization']['clip']`; The used value of the clipping parameter. `.obsm['X_pca']`; PCA representation of data after gene selection and Pearson residual; normalization.; `.varm['PCs']`; The principal components containing the loadings. When `inplace=True` this; will contain empty rows for the genes not selected during HVG selection.; `.uns['pca']['variance_ratio']`; Ratio of explained variance.; `.uns['pca']['variance']`; Explained variance, equivalent to the eigenvalues of the covariance matrix.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_recipes.py:1922,load,loadings,1922,src/scanpy/experimental/pp/_recipes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_recipes.py,1,['load'],['loadings']
Performance,"pp.bbknn` first. Parameters; ----------; adata; The annotated data matrix.; resolution; A parameter value controlling the coarseness of the clustering.; Higher values lead to more clusters.; Set to `None` if overriding `partition_type`; to one that doesn’t accept a `resolution_parameter`.; random_state; Change the initialization of the optimization.; restrict_to; Restrict the clustering to the categories within the key for sample; annotation, tuple needs to contain `(obs_key, list_of_categories)`.; key_added; `adata.obs` key under which to add the cluster labels.; adjacency; Sparse adjacency matrix of the graph, defaults to neighbors connectivities.; directed; Whether to treat the graph as directed or undirected.; use_weights; If `True`, edge weights from the graph are used in the computation; (placing more emphasis on stronger edges).; n_iterations; How many iterations of the Leiden clustering algorithm to perform.; Positive values above 2 define the total number of iterations to perform,; -1 has the algorithm run until it reaches its optimal clustering.; 2 is faster and the default for underlying packages.; partition_type; Type of partition to use.; Defaults to :class:`~leidenalg.RBConfigurationVertexPartition`.; For the available options, consult the documentation for; :func:`~leidenalg.find_partition`.; neighbors_key; Use neighbors connectivities as adjacency.; If not specified, leiden looks .obsp['connectivities'] for connectivities; (default storage place for pp.neighbors).; If specified, leiden looks; .obsp[.uns[neighbors_key]['connectivities_key']] for connectivities.; obsp; Use .obsp[obsp] as adjacency. You can't specify both; `obsp` and `neighbors_key` at the same time.; copy; Whether to copy `adata` or modify it inplace.; flavor; Which package's implementation to use.; **clustering_args; Any further arguments to pass to :func:`~leidenalg.find_partition` (which in turn passes arguments to the `partition_type`); or :meth:`igraph.Graph.community_leiden` from",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_leiden.py:1337,perform,perform,1337,src/scanpy/tools/_leiden.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_leiden.py,1,['perform'],['perform']
Performance,"product between the graph; and its transpose.; min_cluster_size; Cells that end up in a cluster smaller than min_cluster_size are considered; outliers and are assigned to -1 in the cluster labels.; jaccard; If `True`, use Jaccard metric between k-neighborhoods to build graph. If; `False`, use a Gaussian kernel.; primary_metric; Distance metric to define nearest neighbors. Note that performance will be; slower for correlation and cosine.; n_jobs; Nearest Neighbors and Jaccard coefficients will be computed in parallel using; n_jobs. If 1 is given, no parallelism is used. If set to -1, all CPUs are used.; For n_jobs below -1, `n_cpus + 1 + n_jobs` are used.; q_tol; Tolerance, i.e. precision, for monitoring modularity optimization.; louvain_time_limit; Maximum number of seconds to run modularity optimization. If exceeded the best; result so far is returned.; nn_method; Whether to use brute force or kdtree for nearest neighbor search.; For very large high-dimensional data sets, brute force, with parallel; computation, performs faster than kdtree.; partition_type; Defaults to :class:`~leidenalg.RBConfigurationVertexPartition`. For the; available options, consult the documentation for; :func:`~leidenalg.find_partition`.; resolution_parameter; A parameter value controlling the coarseness of the clustering in Leiden. Higher; values lead to more clusters. Set to `None` if overriding `partition_type` to; one that does not accept a `resolution_parameter`.; n_iterations; Number of iterations to run the Leiden algorithm. If the number of iterations is; negative, the Leiden algorithm is run until an iteration in which there was no; improvement.; use_weights; Use vertices in the Leiden computation.; seed; Leiden initialization of the optimization.; copy; Return a copy or write to `adata`.; kargs; Additional arguments passed to :func:`~leidenalg.find_partition` and the; constructor of the `partition_type`. Returns; -------; Depending on `copy`, returns or updates `adata` with the fo",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phenograph.py:2326,perform,performs,2326,src/scanpy/external/tl/_phenograph.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phenograph.py,1,['perform'],['performs']
Performance,"rest neighbors :cite:p:`Haghverdi2018` :cite:p:`Kang2018`. This uses the implementation of mnnpy_ :cite:p:`Kang2018`. Depending on `do_concatenate`, returns matrices or `AnnData` objects in the; original order containing corrected expression values or a concatenated; matrix or AnnData object. Be reminded that it is not advised to use the corrected data matrices for; differential expression testing. More information and bug reports `here <mnnpy>`__. .. _mnnpy: https://github.com/chriscainx/mnnpy. Parameters; ----------; datas; Expression matrices or AnnData objects. Matrices should be shaped like; n_obs × n_vars (n_cell × n_gene) and have consistent number of columns.; AnnData objects should have same number of variables.; var_index; The index (list of str) of vars (genes). Necessary when using only a; subset of vars to perform MNN correction, and should be supplied with; `var_subset`. When `datas` are AnnData objects, `var_index` is ignored.; var_subset; The subset of vars (list of str) to be used when performing MNN; correction. Typically, a list of highly variable genes (HVGs).; When set to `None`, uses all vars.; batch_key; The `batch_key` for :meth:`~anndata.AnnData.concatenate`.; Only valid when `do_concatenate` and supplying `AnnData` objects.; index_unique; The `index_unique` for :meth:`~anndata.AnnData.concatenate`.; Only valid when `do_concatenate` and supplying `AnnData` objects.; batch_categories; The `batch_categories` for :meth:`~anndata.AnnData.concatenate`.; Only valid when `do_concatenate` and supplying AnnData objects.; k; Number of mutual nearest neighbors.; sigma; The bandwidth of the Gaussian smoothing kernel used to compute the; correction vectors. Default is 1.; cos_norm_in; Whether cosine normalization should be performed on the input data prior; to calculating distances between cells.; cos_norm_out; Whether cosine normalization should be performed prior to computing corrected expression values.; svd_dim; The number of dimensions to use for su",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_mnn_correct.py:1068,perform,performing,1068,src/scanpy/external/pp/_mnn_correct.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_mnn_correct.py,1,['perform'],['performing']
Performance,"roduces a directed graph, which is symmetrized; by one of two methods (see `prune` below).; prune; `prune=False`, symmetrize by taking the average between the graph and its; transpose. `prune=True`, symmetrize by taking the product between the graph; and its transpose.; min_cluster_size; Cells that end up in a cluster smaller than min_cluster_size are considered; outliers and are assigned to -1 in the cluster labels.; jaccard; If `True`, use Jaccard metric between k-neighborhoods to build graph. If; `False`, use a Gaussian kernel.; primary_metric; Distance metric to define nearest neighbors. Note that performance will be; slower for correlation and cosine.; n_jobs; Nearest Neighbors and Jaccard coefficients will be computed in parallel using; n_jobs. If 1 is given, no parallelism is used. If set to -1, all CPUs are used.; For n_jobs below -1, `n_cpus + 1 + n_jobs` are used.; q_tol; Tolerance, i.e. precision, for monitoring modularity optimization.; louvain_time_limit; Maximum number of seconds to run modularity optimization. If exceeded the best; result so far is returned.; nn_method; Whether to use brute force or kdtree for nearest neighbor search.; For very large high-dimensional data sets, brute force, with parallel; computation, performs faster than kdtree.; partition_type; Defaults to :class:`~leidenalg.RBConfigurationVertexPartition`. For the; available options, consult the documentation for; :func:`~leidenalg.find_partition`.; resolution_parameter; A parameter value controlling the coarseness of the clustering in Leiden. Higher; values lead to more clusters. Set to `None` if overriding `partition_type` to; one that does not accept a `resolution_parameter`.; n_iterations; Number of iterations to run the Leiden algorithm. If the number of iterations is; negative, the Leiden algorithm is run until an iteration in which there was no; improvement.; use_weights; Use vertices in the Leiden computation.; seed; Leiden initialization of the optimization.; copy; Return a",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phenograph.py:2100,optimiz,optimization,2100,src/scanpy/external/tl/_phenograph.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phenograph.py,1,['optimiz'],['optimization']
Performance,"rray, n-by-d array of n cells in d dimensions. if sparse matrix,; n-by-n adjacency matrix.; clustering_algo; Choose between `'Louvain'` or `'Leiden'` algorithm for clustering.; k; Number of nearest neighbors to use in first step of graph construction.; directed; Whether to use a symmetric (default) or asymmetric (`'directed'`) graph.; The graph construction process produces a directed graph, which is symmetrized; by one of two methods (see `prune` below).; prune; `prune=False`, symmetrize by taking the average between the graph and its; transpose. `prune=True`, symmetrize by taking the product between the graph; and its transpose.; min_cluster_size; Cells that end up in a cluster smaller than min_cluster_size are considered; outliers and are assigned to -1 in the cluster labels.; jaccard; If `True`, use Jaccard metric between k-neighborhoods to build graph. If; `False`, use a Gaussian kernel.; primary_metric; Distance metric to define nearest neighbors. Note that performance will be; slower for correlation and cosine.; n_jobs; Nearest Neighbors and Jaccard coefficients will be computed in parallel using; n_jobs. If 1 is given, no parallelism is used. If set to -1, all CPUs are used.; For n_jobs below -1, `n_cpus + 1 + n_jobs` are used.; q_tol; Tolerance, i.e. precision, for monitoring modularity optimization.; louvain_time_limit; Maximum number of seconds to run modularity optimization. If exceeded the best; result so far is returned.; nn_method; Whether to use brute force or kdtree for nearest neighbor search.; For very large high-dimensional data sets, brute force, with parallel; computation, performs faster than kdtree.; partition_type; Defaults to :class:`~leidenalg.RBConfigurationVertexPartition`. For the; available options, consult the documentation for; :func:`~leidenalg.find_partition`.; resolution_parameter; A parameter value controlling the coarseness of the clustering in Leiden. Higher; values lead to more clusters. Set to `None` if overriding `partition_",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phenograph.py:1682,perform,performance,1682,src/scanpy/external/tl/_phenograph.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phenograph.py,1,['perform'],['performance']
Performance,"s will use :func:`~dask.array.linalg.svd_compressed`.; `'auto'`; chooses automatically depending on the size of the problem.; `'lobpcg'`; An alternative SciPy solver. Not available with dask arrays.; `'tsqr'`; Only available with *dask* arrays. ""tsqr""; algorithm from Benson et. al. (2013). .. versionchanged:: 1.9.3; Default value changed from `'arpack'` to None.; .. versionchanged:: 1.4.5; Default value changed from `'auto'` to `'arpack'`. Efficient computation of the principal components of a sparse matrix; currently only works with the `'arpack`' or `'lobpcg'` solvers. If X is a *dask* array, *dask-ml* classes :class:`~dask_ml.decomposition.PCA`,; :class:`~dask_ml.decomposition.IncrementalPCA`, or; :class:`~dask_ml.decomposition.TruncatedSVD` will be used.; Otherwise their *scikit-learn* counterparts :class:`~sklearn.decomposition.PCA`,; :class:`~sklearn.decomposition.IncrementalPCA`, or; :class:`~sklearn.decomposition.TruncatedSVD` will be used.; random_state; Change to use different initial states for the optimization.; return_info; Only relevant when not passing an :class:`~anndata.AnnData`:; see “Returns”.; {mask_var_hvg}; layer; Layer of `adata` to use as expression values.; dtype; Numpy data type string to which to convert the result.; copy; If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned. Is ignored otherwise.; chunked; If `True`, perform an incremental PCA on segments of `chunk_size`.; The incremental PCA automatically zero centers and ignores settings of; `random_seed` and `svd_solver`. Uses sklearn :class:`~sklearn.decomposition.IncrementalPCA` or; *dask-ml* :class:`~dask_ml.decomposition.IncrementalPCA`. If `False`, perform a full PCA and; use sklearn :class:`~sklearn.decomposition.PCA` or; *dask-ml* :class:`~dask_ml.decomposition.PCA`; chunk_size; Number of observations to include in each chunk.; Required if `chunked=True` was passed. Returns; -------; If `data` is array-like and `return_info=False` was passed,; this f",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py:3047,optimiz,optimization,3047,src/scanpy/preprocessing/_pca.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py,1,['optimiz'],['optimization']
Performance,"s.; name_list; Denoised genes to return. The default `'all_genes'`/`None`; may require a large amount of memory if the input data is sparse.; Another possibility is `'pca_only'`.; knn; number of nearest neighbors on which to build kernel.; decay; sets decay rate of kernel tails.; If None, alpha decaying kernel is not used.; knn_max; maximum number of nearest neighbors with nonzero connection.; If `None`, will be set to 3 * `knn`.; t; power to which the diffusion operator is powered.; This sets the level of diffusion. If 'auto', t is selected; according to the Procrustes disparity of the diffused data.; n_pca; Number of principal components to use for calculating; neighborhoods. For extremely large datasets, using; n_pca < 20 allows neighborhoods to be calculated in; roughly log(n_samples) time. If `None`, no PCA is performed.; solver; Which solver to use. ""exact"" uses the implementation described; in :cite:t:`vanDijk2018`. ""approximate"" uses a faster; implementation that performs imputation in the PCA space and then; projects back to the gene space. Note, the ""approximate"" solver may; return negative values.; knn_dist; recommended values: 'euclidean', 'cosine', 'precomputed'; Any metric from `scipy.spatial.distance` can be used; distance metric for building kNN graph. If 'precomputed',; `data` should be an n_samples x n_samples distance or; affinity matrix.; random_state; Random seed. Defaults to the global `numpy` random number generator.; n_jobs; Number of threads to use in training. All cores are used by default.; verbose; If `True` or an integer `>= 2`, print status messages.; If `None`, `sc.settings.verbosity` is used.; copy; If true, a copy of anndata is returned. If `None`, `copy` is True if; `genes` is not `'all_genes'` or `'pca_only'`. `copy` may only be False; if `genes` is `'all_genes'` or `'pca_only'`, as the resultant data; will otherwise have different column names from the input data.; kwargs; Additional arguments to `magic.MAGIC`. Returns; -------; If",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_magic.py:1873,perform,performs,1873,src/scanpy/external/pp/_magic.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_magic.py,1,['perform'],['performs']
Performance,"symmetric (`'directed'`) graph.; The graph construction process produces a directed graph, which is symmetrized; by one of two methods (see `prune` below).; prune; `prune=False`, symmetrize by taking the average between the graph and its; transpose. `prune=True`, symmetrize by taking the product between the graph; and its transpose.; min_cluster_size; Cells that end up in a cluster smaller than min_cluster_size are considered; outliers and are assigned to -1 in the cluster labels.; jaccard; If `True`, use Jaccard metric between k-neighborhoods to build graph. If; `False`, use a Gaussian kernel.; primary_metric; Distance metric to define nearest neighbors. Note that performance will be; slower for correlation and cosine.; n_jobs; Nearest Neighbors and Jaccard coefficients will be computed in parallel using; n_jobs. If 1 is given, no parallelism is used. If set to -1, all CPUs are used.; For n_jobs below -1, `n_cpus + 1 + n_jobs` are used.; q_tol; Tolerance, i.e. precision, for monitoring modularity optimization.; louvain_time_limit; Maximum number of seconds to run modularity optimization. If exceeded the best; result so far is returned.; nn_method; Whether to use brute force or kdtree for nearest neighbor search.; For very large high-dimensional data sets, brute force, with parallel; computation, performs faster than kdtree.; partition_type; Defaults to :class:`~leidenalg.RBConfigurationVertexPartition`. For the; available options, consult the documentation for; :func:`~leidenalg.find_partition`.; resolution_parameter; A parameter value controlling the coarseness of the clustering in Leiden. Higher; values lead to more clusters. Set to `None` if overriding `partition_type` to; one that does not accept a `resolution_parameter`.; n_iterations; Number of iterations to run the Leiden algorithm. If the number of iterations is; negative, the Leiden algorithm is run until an iteration in which there was no; improvement.; use_weights; Use vertices in the Leiden computation.;",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phenograph.py:2021,optimiz,optimization,2021,src/scanpy/external/tl/_phenograph.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phenograph.py,1,['optimiz'],['optimization']
Performance,"t these best match the; distribution of distances in the high-dimensional space.; We use the implementation of umap-learn_ :cite:p:`McInnes2018`.; For a few comparisons of UMAP with tSNE, see :cite:t:`Becht2018`. .. _umap-learn: https://github.com/lmcinnes/umap. Parameters; ----------; adata; Annotated data matrix.; min_dist; The effective minimum distance between embedded points. Smaller values; will result in a more clustered/clumped embedding where nearby points on; the manifold are drawn closer together, while larger values will result; on a more even dispersal of points. The value should be set relative to; the ``spread`` value, which determines the scale at which embedded; points will be spread out. The default of in the `umap-learn` package is; 0.1.; spread; The effective scale of embedded points. In combination with `min_dist`; this determines how clustered/clumped the embedded points are.; n_components; The number of dimensions of the embedding.; maxiter; The number of iterations (epochs) of the optimization. Called `n_epochs`; in the original UMAP.; alpha; The initial learning rate for the embedding optimization.; gamma; Weighting applied to negative samples in low dimensional embedding; optimization. Values higher than one will result in greater weight; being given to negative samples.; negative_sample_rate; The number of negative edge/1-simplex samples to use per positive; edge/1-simplex sample in optimizing the low dimensional embedding.; init_pos; How to initialize the low dimensional embedding. Called `init` in the; original UMAP. Options are:. * Any key for `adata.obsm`.; * 'paga': positions from :func:`~scanpy.pl.paga`.; * 'spectral': use a spectral embedding of the graph.; * 'random': assign initial embedding positions at random.; * A numpy array of initial embedding positions.; random_state; If `int`, `random_state` is the seed used by the random number generator;; If `RandomState` or `Generator`, `random_state` is the random number generator;; If ",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_umap.py:1514,optimiz,optimization,1514,src/scanpy/tools/_umap.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_umap.py,1,['optimiz'],['optimization']
Performance,"tr:`~anndata.AnnData.obsm`, dtype `float`); Array of Diffusion components.; - palantir_EigenValues - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.uns`, dtype `float`); Array of corresponding eigen values.; - palantir_diff_op - :class:`~scipy.sparse.spmatrix` (:attr:`~anndata.AnnData.obsp`, dtype `float`); The diffusion operator matrix. **Multi scale space results**,; used to build tsne on diffusion components, and to compute branch probabilities; and waypoints,. - X_palantir_multiscale - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.obsm`, dtype `float`); Multi scale data matrix. **MAGIC imputation**,; used for plotting gene expression on tsne, and gene expression trends,. - palantir_imp - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.layers`, dtype `float`); Imputed data matrix (MAGIC imputation). Example; -------; >>> import scanpy.external as sce; >>> import scanpy as sc. A sample data is available `here <https://github.com/dpeerlab/Palantir/tree/master/data>`_. **Load sample data**. >>> adata = sc.read_csv(filename=""Palantir/data/marrow_sample_scseq_counts.csv.gz""). *Cleanup and normalize*. >>> sc.pp.filter_cells(adata, min_counts=1000); >>> sc.pp.filter_genes(adata, min_counts=10); >>> sc.pp.normalize_per_cell(adata); >>> sc.pp.log1p(adata). **Data preprocessing**. Palantir builds diffusion maps using one of two optional inputs:. *Principal component analysis*. >>> sc.pp.pca(adata, n_comps=300). or,. *Nearist neighbors graph*. >>> sc.pp.neighbors(adata, knn=30). *Diffusion maps*. Palantir determines the diffusion maps of the data as an estimate of the low; dimensional phenotypic manifold of the data. >>> sce.tl.palantir(adata, n_components=5, knn=30). if pre-computed distances are to be used,. >>> sce.tl.palantir(; ... adata,; ... n_components=5,; ... knn=30,; ... use_adjacency_matrix=True,; ... distances_key=""distances"",; ... ). **Visualizing Palantir results**. *tSNE visualization*. important for Palantir!. Palantir constructs the tSNE map in the em",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_palantir.py:2787,Load,Load,2787,src/scanpy/external/tl/_palantir.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_palantir.py,1,['Load'],['Load']
Performance,"tter convergence if you install Multicore-tSNE_; by :cite:t:`Ulyanov2016`, which will be automatically detected by Scanpy. .. _multicore-tsne: https://github.com/DmitryUlyanov/Multicore-TSNE. Parameters; ----------; adata; Annotated data matrix.; {doc_n_pcs}; {use_rep}; perplexity; The perplexity is related to the number of nearest neighbors that; is used in other manifold learning algorithms. Larger datasets; usually require a larger perplexity. Consider selecting a value; between 5 and 50. The choice is not extremely critical since t-SNE; is quite insensitive to this parameter.; metric; Distance metric calculate neighbors on.; early_exaggeration; Controls how tight natural clusters in the original space are in the; embedded space and how much space will be between them. For larger; values, the space between natural clusters will be larger in the; embedded space. Again, the choice of this parameter is not very; critical. If the cost function increases during initial optimization,; the early exaggeration factor or the learning rate might be too high.; learning_rate; Note that the R-package ""Rtsne"" uses a default of 200.; The learning rate can be a critical parameter. It should be; between 100 and 1000. If the cost function increases during initial; optimization, the early exaggeration factor or the learning rate; might be too high. If the cost function gets stuck in a bad local; minimum increasing the learning rate helps sometimes.; random_state; Change this to use different intial states for the optimization.; If `None`, the initial state is not reproducible.; n_jobs; Number of jobs for parallel computation.; `None` means using :attr:`scanpy._settings.ScanpyConfig.n_jobs`.; copy; Return a copy instead of writing to `adata`. Returns; -------; Returns `None` if `copy=False`, else returns an `AnnData` object. Sets the following fields:. `adata.obsm['X_tsne']` : :class:`numpy.ndarray` (dtype `float`); tSNE coordinates of data.; `adata.uns['tsne']` : :class:`dict`; tSNE ",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_tsne.py:1331,optimiz,optimization,1331,src/scanpy/tools/_tsne.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_tsne.py,1,['optimiz'],['optimization']
Performance,"ues; will result in a more clustered/clumped embedding where nearby points on; the manifold are drawn closer together, while larger values will result; on a more even dispersal of points. The value should be set relative to; the ``spread`` value, which determines the scale at which embedded; points will be spread out. The default of in the `umap-learn` package is; 0.1.; spread; The effective scale of embedded points. In combination with `min_dist`; this determines how clustered/clumped the embedded points are.; n_components; The number of dimensions of the embedding.; maxiter; The number of iterations (epochs) of the optimization. Called `n_epochs`; in the original UMAP.; alpha; The initial learning rate for the embedding optimization.; gamma; Weighting applied to negative samples in low dimensional embedding; optimization. Values higher than one will result in greater weight; being given to negative samples.; negative_sample_rate; The number of negative edge/1-simplex samples to use per positive; edge/1-simplex sample in optimizing the low dimensional embedding.; init_pos; How to initialize the low dimensional embedding. Called `init` in the; original UMAP. Options are:. * Any key for `adata.obsm`.; * 'paga': positions from :func:`~scanpy.pl.paga`.; * 'spectral': use a spectral embedding of the graph.; * 'random': assign initial embedding positions at random.; * A numpy array of initial embedding positions.; random_state; If `int`, `random_state` is the seed used by the random number generator;; If `RandomState` or `Generator`, `random_state` is the random number generator;; If `None`, the random number generator is the `RandomState` instance used; by `np.random`.; a; More specific parameters controlling the embedding. If `None` these; values are set automatically as determined by `min_dist` and; `spread`.; b; More specific parameters controlling the embedding. If `None` these; values are set automatically as determined by `min_dist` and; `spread`.; copy; Return a c",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_umap.py:1927,optimiz,optimizing,1927,src/scanpy/tools/_umap.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_umap.py,1,['optimiz'],['optimizing']
Performance,"y.tl.diffmap` in order; to exactly reproduce previous :func:`~scanpy.tl.dpt` results. Parameters; ----------; adata; Annotated data matrix.; n_dcs; The number of diffusion components to use.; n_branchings; Number of branchings to detect.; min_group_size; During recursive splitting of branches ('dpt groups') for `n_branchings`; > 1, do not consider groups that contain less than `min_group_size` data; points. If a float, `min_group_size` refers to a fraction of the total; number of data points.; allow_kendall_tau_shift; If a very small branch is detected upon splitting, shift away from; maximum correlation in Kendall tau criterion of :cite:t:`Haghverdi2016` to; stabilize the splitting.; neighbors_key; If not specified, dpt looks .uns['neighbors'] for neighbors settings; and .obsp['connectivities'], .obsp['distances'] for connectivities and; distances respectively (default storage places for pp.neighbors).; If specified, dpt looks .uns[neighbors_key] for neighbors settings and; .obsp[.uns[neighbors_key]['connectivities_key']],; .obsp[.uns[neighbors_key]['distances_key']] for connectivities and distances; respectively.; copy; Copy instance before computation and return a copy.; Otherwise, perform computation inplace and return `None`. Returns; -------; Returns `None` if `copy=False`, else returns an `AnnData` object. Sets the following fields (If `n_branchings==0`, no field `adata.obs['dpt_groups']` will be written):. `adata.obs['dpt_pseudotime']` : :class:`pandas.Series` (dtype `float`); Array of dim (number of samples) that stores the pseudotime of each; cell, that is, the DPT distance with respect to the root cell.; `adata.obs['dpt_groups']` : :class:`pandas.Series` (dtype `category`); Array of dim (number of samples) that stores the subgroup id ('0',; '1', ...) for each cell. The groups typically correspond to; 'progenitor cells', 'undecided cells' or 'branches' of a process. Notes; -----; The tool is similar to the R package `destiny` of :cite:t:`Angerer2015`.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py:2567,perform,perform,2567,src/scanpy/tools/_dpt.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py,1,['perform'],['perform']
Performance,"ysis by :cite:t:`Levine2015`. This requires having ran :func:`~scanpy.pp.neighbors` or; :func:`~scanpy.external.pp.bbknn` first. Parameters; ----------; adata; The annotated data matrix.; resolution; A parameter value controlling the coarseness of the clustering.; Higher values lead to more clusters.; Set to `None` if overriding `partition_type`; to one that doesn’t accept a `resolution_parameter`.; random_state; Change the initialization of the optimization.; restrict_to; Restrict the clustering to the categories within the key for sample; annotation, tuple needs to contain `(obs_key, list_of_categories)`.; key_added; `adata.obs` key under which to add the cluster labels.; adjacency; Sparse adjacency matrix of the graph, defaults to neighbors connectivities.; directed; Whether to treat the graph as directed or undirected.; use_weights; If `True`, edge weights from the graph are used in the computation; (placing more emphasis on stronger edges).; n_iterations; How many iterations of the Leiden clustering algorithm to perform.; Positive values above 2 define the total number of iterations to perform,; -1 has the algorithm run until it reaches its optimal clustering.; 2 is faster and the default for underlying packages.; partition_type; Type of partition to use.; Defaults to :class:`~leidenalg.RBConfigurationVertexPartition`.; For the available options, consult the documentation for; :func:`~leidenalg.find_partition`.; neighbors_key; Use neighbors connectivities as adjacency.; If not specified, leiden looks .obsp['connectivities'] for connectivities; (default storage place for pp.neighbors).; If specified, leiden looks; .obsp[.uns[neighbors_key]['connectivities_key']] for connectivities.; obsp; Use .obsp[obsp] as adjacency. You can't specify both; `obsp` and `neighbors_key` at the same time.; copy; Whether to copy `adata` or modify it inplace.; flavor; Which package's implementation to use.; **clustering_args; Any further arguments to pass to :func:`~leidenalg.find_pa",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_leiden.py:1262,perform,perform,1262,src/scanpy/tools/_leiden.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_leiden.py,1,['perform'],['perform']
Safety,"""""""(shape: n_cells); Boolean mask of predicted doublets in the observed transcriptomes.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/core.py:37,predict,predicted,37,src/scanpy/preprocessing/_scrublet/core.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/core.py,1,['predict'],['predicted']
Safety,"""""""; Given a dictionary of plot parameters (kwds_dict) and a dict of kwds,; merge the parameters into a single consolidated dictionary to avoid; argument duplication errors. If kwds_dict an kwargs have the same key, only the value in kwds_dict is kept. Parameters; ----------; kwds_dict kwds_dictionary; kwargs. Returns; -------; kwds_dict merged with kwargs. Examples; --------. >>> def _example(**kwds):; ... return fix_kwds(kwds, key1=""value1"", key2=""value2""); >>> _example(key1=""value10"", key3=""value3""); {'key1': 'value10', 'key2': 'value2', 'key3': 'value3'}; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_utils.py:138,avoid,avoid,138,src/scanpy/plotting/_utils.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_utils.py,1,['avoid'],['avoid']
Safety,"""""""; Save the current figure. Parameters; ----------; filename; Figure filename. Figure *format* is taken from the file ending unless; the parameter `format` is given.; bbox_inches; By default is set to 'tight' to avoid cropping of the legends.; kwargs; Passed to :func:`matplotlib.pyplot.savefig`. See also; --------; `render()`: Renders the plot but does not call :func:`matplotlib.pyplot.show`; `show()`: Renders and shows the plot. Examples; -------; >>> import scanpy as sc; >>> adata = sc.datasets.pbmc68k_reduced(); >>> markers = [""C1QA"", ""PSAP"", ""CD79A"", ""CD79B"", ""CST3"", ""LYZ""]; >>> sc.pl._baseplot_class.BasePlot(; ... adata, markers, groupby=""bulk_labels""; ... ).savefig(""plot.pdf""); """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_baseplot_class.py:214,avoid,avoid,214,src/scanpy/plotting/_baseplot_class.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_baseplot_class.py,1,['avoid'],['avoid']
Safety,"""""""; Test to make sure I can predict when scatter reps should be the same; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:29,predict,predict,29,tests/test_plotting.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py,1,['predict'],['predict']
Safety,"""""""Check that scrublet runs and detects some doublets.""""""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_scrublet.py:32,detect,detects,32,tests/test_scrublet.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_scrublet.py,1,['detect'],['detects']
Safety,"""""""Compute overlaps between groups. See ``identify_groups`` for identifying the groups. Parameters; ----------; adata; prediction; Field name of adata.obs.; reference; Field name of adata.obs.; normalization; Whether to normalize with respect to the predicted groups or the; reference groups.; threshold; Do not consider associations whose overlap is below this fraction.; max_n_names; Control how many reference names you want to be associated with per; predicted name. Set to `None`, if you want all. Returns; -------; asso_names; List of associated reference names; (`max_n_names` for each predicted name).; asso_matrix; Matrix where rows correspond to the predicted labels and columns to the; reference labels, entries are proportional to degree of association.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/__init__.py:119,predict,prediction,119,src/scanpy/_utils/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/__init__.py,5,['predict'],"['predicted', 'prediction']"
Safety,"""""""Detect branching on given segment.""""""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py:3,Detect,Detect,3,src/scanpy/tools/_dpt.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py,1,['Detect'],['Detect']
Safety,"""""""Estimated fraction of doublets that are detectable, i.e.,; fraction of simulated doublets with doublet scores above `threshold_`; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/core.py:43,detect,detectable,43,src/scanpy/preprocessing/_scrublet/core.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/core.py,1,['detect'],['detectable']
Safety,"""""""Which predicted label explains which reference label?. A predicted label explains the reference label which maximizes the minimum; of ``relative_overlaps_pred`` and ``relative_overlaps_ref``. Compare this with ``compute_association_matrix_of_groups``. Returns; -------; A dictionary of length ``len(np.unique(ref_labels))`` that stores for each; reference label the predicted label that best explains it. If ``return_overlaps`` is ``True``, this will in addition return the overlap; of the reference group with the predicted group; normalized with respect to; the reference group size and the predicted group size, respectively.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/__init__.py:9,predict,predicted,9,src/scanpy/_utils/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/__init__.py,5,['predict'],['predicted']
Safety,"""""""\; Assigns scores and predicted class to observations :cite:p:`Scialdone2015` :cite:p:`Fechtner2018`. Calculates scores for each observation and each phase and assigns prediction; based on marker pairs indentified by :func:`~scanpy.external.tl.sandbag`. This reproduces the approach of :cite:t:`Scialdone2015` in the implementation of; :cite:t:`Fechtner2018`. Parameters; ----------; adata; The annotated data matrix.; marker_pairs; Mapping of categories to lists of marker pairs.; See :func:`~scanpy.external.tl.sandbag` output.; iterations; An integer scalar specifying the number of; iterations for random sampling to obtain a cycle score.; min_iter; An integer scalar specifying the minimum number of iterations; for score estimation.; min_pairs; An integer scalar specifying the minimum number of pairs; for score estimation. Returns; -------; A :class:`~pandas.DataFrame` with samples as index and categories as columns; with scores for each category for each sample and a additional column with; the name of the max scoring category for each sample. If `marker_pairs` contains only the cell cycle categories G1, S and G2M an; additional column `pypairs_cc_prediction` will be added.; Where category S is assigned to samples where G1 and G2M score are < 0.5.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_pypairs.py:25,predict,predicted,25,src/scanpy/external/tl/_pypairs.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_pypairs.py,2,['predict'],"['predicted', 'prediction']"
Safety,"""""""\; Batch balanced kNN :cite:p:`Polanski2019`. Batch balanced kNN alters the kNN procedure to identify each cell's top neighbours in; each batch separately instead of the entire cell pool with no accounting for batch.; The nearest neighbours for each batch are then merged to create a final list of; neighbours for the cell. Aligns batches in a quick and lightweight manner. For use in the scanpy workflow as an alternative to :func:`~scanpy.pp.neighbors`. .. note::. This is just a wrapper of :func:`bbknn.bbknn`: up to date docstring,; more information and bug reports there. Params; ------; adata; Needs the PCA computed and stored in `adata.obsm[""X_pca""]`.; batch_key; `adata.obs` column name discriminating between your batches.; use_rep; The dimensionality reduction in `.obsm` to use for neighbour detection. Defaults to PCA.; approx; If `True`, use approximate neighbour finding - annoy or PyNNDescent. This results; in a quicker run time for large datasets while also potentially increasing the degree of; batch correction.; use_annoy; Only used when `approx=True`. If `True`, will use annoy for neighbour finding. If; `False`, will use pyNNDescent instead.; metric; What distance metric to use. The options depend on the choice of neighbour algorithm. ""euclidean"", the default, is always available. Annoy supports ""angular"", ""manhattan"" and ""hamming"". PyNNDescent supports metrics listed in `pynndescent.distances.named_distances`; and custom functions, including compiled Numba code. >>> import pynndescent; >>> pynndescent.distances.named_distances.keys() # doctest: +ELLIPSIS, +NORMALIZE_WHITESPACE; dict_keys(['euclidean', 'l2', 'sqeuclidean', 'manhattan', 'taxicab', 'l1', 'chebyshev', 'linfinity',; 'linfty', 'linf', 'minkowski', 'seuclidean', 'standardised_euclidean', 'wminkowski', ...]). KDTree supports members of :class:`sklearn.neighbors.KDTree`’s ``valid_metrics`` list, or parameterised; :class:`~sklearn.metrics.DistanceMetric` objects:. >>> import sklearn.neighbors; >>> sk",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_bbknn.py:807,detect,detection,807,src/scanpy/external/pp/_bbknn.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_bbknn.py,1,['detect'],['detection']
Safety,"""""""\; Call trancriptomes as doublets or singlets. Arguments; ---------; threshold; Doublet score threshold for calling a transcriptome; a doublet. If `None`, this is set automatically by looking; for the minimum between the two modes of the `doublet_scores_sim_`; histogram. It is best practice to check the threshold visually; using the `doublet_scores_sim_` histogram and/or based on; co-localization of predicted doublets in a 2-D embedding. verbose; If True, log summary statistics. Sets; ----; predicted_doublets_, z_scores_, threshold_,; detected_doublet_rate_, detectable_doublet_fraction,; overall_doublet_rate_; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/core.py:406,predict,predicted,406,src/scanpy/preprocessing/_scrublet/core.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/core.py,1,['predict'],['predicted']
Safety,"""""""\; Core function for predicting doublets using Scrublet :cite:p:`Wolock2019`. Predict cell doublets using a nearest-neighbor classifier of observed; transcriptomes and simulated doublets. Parameters; ----------; adata_obs; The annotated data matrix of shape ``n_obs`` × ``n_vars``. Rows; correspond to cells and columns to genes. Should be normalised with; :func:`~scanpy.pp.normalize_total` and filtered to include only highly; variable genes.; adata_sim; Anndata object generated by; :func:`~scanpy.pp.scrublet_simulate_doublets`, with same number of vars; as adata_obs. This should have been built from adata_obs after; filtering genes and cells and selcting highly-variable genes.; n_neighbors; Number of neighbors used to construct the KNN graph of observed; transcriptomes and simulated doublets. If ``None``, this is; automatically set to ``np.round(0.5 * np.sqrt(n_obs))``.; expected_doublet_rate; The estimated doublet rate for the experiment.; stdev_doublet_rate; Uncertainty in the expected doublet rate.; mean_center; If True, center the data such that each gene has a mean of 0.; `sklearn.decomposition.PCA` will be used for dimensionality; reduction.; normalize_variance; If True, normalize the data such that each gene has a variance of 1.; `sklearn.decomposition.TruncatedSVD` will be used for dimensionality; reduction, unless `mean_center` is True.; n_prin_comps; Number of principal components used to embed the transcriptomes prior; to k-nearest-neighbor graph construction.; use_approx_neighbors; Use approximate nearest neighbor method (annoy) for the KNN; classifier.; knn_dist_metric; Distance metric used when finding nearest neighbors. For list of; valid values, see the documentation for annoy (if `use_approx_neighbors`; is True) or sklearn.neighbors.NearestNeighbors (if `use_approx_neighbors`; is False).; get_doublet_neighbor_parents; If True, return the parent transcriptomes that generated the; doublet neighbors of each observed transcriptome. This information can",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py:24,predict,predicting,24,src/scanpy/preprocessing/_scrublet/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py,2,"['Predict', 'predict']","['Predict', 'predicting']"
Safety,"""""""\; Detect all branchings up to `n_branchings`. Writes Attributes; -----------------; segs : :class:`~numpy.ndarray`; List of integer index arrays.; segs_tips : :class:`~numpy.ndarray`; List of indices of the tips of segments.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py:6,Detect,Detect,6,src/scanpy/tools/_dpt.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py,1,['Detect'],['Detect']
Safety,"""""""\; Detect branching on given segment. Call function __detect_branching three times for all three orderings of; tips. Points that do not belong to the same segment in all three; orderings are assigned to a fourth segment. The latter is, by Haghverdi; et al. (2016) referred to as 'undecided cells'. Parameters; ----------; Dseg; Dchosen distance matrix restricted to segment.; tips; The three tip points. They form a 'triangle' that contains the data. Returns; -------; ssegs; List of segments obtained from splitting the single segment defined; via the first two tip cells.; ssegs_tips; List of tips of segments in ssegs.; ssegs_adjacency; ?; ssegs_connects; ?; trunk; ?; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py:6,Detect,Detect,6,src/scanpy/tools/_dpt.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py,1,['Detect'],['Detect']
Safety,"""""""\; Detect branching on given segment. Compute point that maximizes kendall tau correlation of the sequences of; distances to the second and the third tip, respectively, when 'moving; away' from the first tip: tips[0]. 'Moving away' means moving in the; direction of increasing distance from the first tip. Parameters; ----------; Dseg; Dchosen distance matrix restricted to segment.; tips; The three tip points. They form a 'triangle' that contains the data. Returns; -------; Segments obtained from ""splitting away the first tip cell"".; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py:6,Detect,Detect,6,src/scanpy/tools/_dpt.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py,1,['Detect'],['Detect']
Safety,"""""""\; Detect branching on given segment. Updates all list parameters inplace. Call function _detect_branching and perform bookkeeping on segs and; segs_tips. Parameters; ----------; segs; Dchosen distance matrix restricted to segment.; segs_tips; Stores all tip points for the segments in segs.; iseg; Position of segment under study in segs.; tips3; The three tip points. They form a 'triangle' that contains the data.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py:6,Detect,Detect,6,src/scanpy/tools/_dpt.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py,1,['Detect'],['Detect']
Safety,"""""""\; Detect branchings and partition the data into corresponding segments. Detect all branchings up to `n_branchings`. Writes; ------; segs : :class:`~numpy.ndarray`; Array of dimension (number of segments) × (number of data; points). Each row stores a mask array that defines a segment.; segs_tips : :class:`~numpy.ndarray`; Array of dimension (number of segments) × 2. Each row stores the; indices of the two tip points of each segment.; segs_names : :class:`~numpy.ndarray`; Array of dimension (number of data points). Stores an integer label; for each segment.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py:6,Detect,Detect,6,src/scanpy/tools/_dpt.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py,2,['Detect'],['Detect']
Safety,"""""""\; Extract highly variable genes :cite:p:`Satija2015,Zheng2017`. .. warning::; .. deprecated:: 1.3.6; Use :func:`~scanpy.pp.highly_variable_genes`; instead. The new function is equivalent to the present; function, except that. * the new function always expects logarithmized data; * `subset=False` in the new function, it suffices to; merely annotate the genes, tools like `pp.pca` will; detect the annotation; * you can now call: `sc.pl.highly_variable_genes(adata)`; * `copy` is replaced by `inplace`. If trying out parameters, pass the data matrix instead of AnnData. Depending on `flavor`, this reproduces the R-implementations of Seurat; :cite:p:`Satija2015` and Cell Ranger :cite:p:`Zheng2017`. The normalized dispersion is obtained by scaling with the mean and standard; deviation of the dispersions for genes falling into a given bin for mean; expression of genes. This means that for each bin of mean expression, highly; variable genes are selected. Use `flavor='cell_ranger'` with care and in the same way as in; :func:`~scanpy.pp.recipe_zheng17`. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; flavor; Choose the flavor for computing normalized dispersion. If choosing; 'seurat', this expects non-logarithmized data – the logarithm of mean; and dispersion is taken internally when `log` is at its default value; `True`. For 'cell_ranger', this is usually called for logarithmized data; – in this case you should set `log` to `False`. In their default; workflows, Seurat passes the cutoffs whereas Cell Ranger passes; `n_top_genes`.; min_mean; max_mean; min_disp; max_disp; If `n_top_genes` unequals `None`, these cutoffs for the means and the; normalized dispersions are ignored.; n_bins; Number of bins for binning the mean gene expression. Normalization is; done with respect to each bin. If just a single gene falls into a bin,; the normalized dispersion is artificially set to 1. You'll be info",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py:391,detect,detect,391,src/scanpy/preprocessing/_deprecated/highly_variable_genes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py,1,['detect'],['detect']
Safety,"""""""\; Fraction of counts assigned to each gene over all cells. Computes, for each gene, the fraction of counts assigned to that gene within; a cell. The `n_top` genes with the highest mean fraction over all cells are; plotted as boxplots. This plot is similar to the `scater` package function `plotHighestExprs(type; = ""highest-expression"")`, see `here; <https://bioconductor.org/packages/devel/bioc/vignettes/scater/inst/doc/vignette-qc.html>`__. Quoting; from there:. *We expect to see the “usual suspects”, i.e., mitochondrial genes, actin,; ribosomal protein, MALAT1. A few spike-in transcripts may also be; present here, though if all of the spike-ins are in the top 50, it; suggests that too much spike-in RNA was added. A large number of; pseudo-genes or predicted genes may indicate problems with alignment.*; -- Davis McCarthy and Aaron Lun. Parameters; ----------; adata; Annotated data matrix.; n_top; Number of top; {show_save_ax}; gene_symbols; Key for field in .var that stores gene symbols if you do not want to use .var_names.; log; Plot x-axis in log scale; **kwds; Are passed to :func:`~seaborn.boxplot`. Returns; -------; If `show==False` a :class:`~matplotlib.axes.Axes`.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_qc.py:762,predict,predicted,762,src/scanpy/plotting/_qc.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_qc.py,1,['predict'],['predicted']
Safety,"""""""\; Harmony time series for data visualization with augmented affinity matrix; at discrete time points :cite:p:`Nowotschin2019`. Harmony time series is a framework for data visualization, trajectory; detection and interpretation for scRNA-seq data measured at discrete; time points. Harmony constructs an augmented affinity matrix by augmenting; the kNN graph affinity matrix with mutually nearest neighbors between; successive time points. This augmented affinity matrix forms the basis for; generated a force directed layout for visualization and also serves as input; for computing the diffusion operator which can be used for trajectory; detection using Palantir_. .. _Palantir: https://github.com/dpeerlab/Palantir. .. note::; More information and bug reports `here; <https://github.com/dpeerlab/Harmony>`__. Parameters; ----------; adata; Annotated data matrix of shape n_obs `×` n_vars. Rows correspond to; cells and columns to genes. Rows represent two or more time points,; where replicates of the same time point are consecutive in order.; tp; key name of observation annotation `.obs` representing time points. Time; points should be categorical of `dtype=category`. The unique categories for; the categorical will be used as the time points to construct the timepoint; connections.; n_neighbors; Number of nearest neighbors for graph construction.; n_components; Minimum number of principal components to use. Specify `None` to use; pre-computed components. The higher the value the better to capture 85% of the; variance.; n_jobs; Nearest Neighbors will be computed in parallel using n_jobs.; copy; Return a copy instead of writing to `adata`. Returns; -------; Depending on `copy`, returns or updates `.obsm`, `.obsp` and `.uns` with the following:. **X_harmony** - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.obsm`, dtype `float`); force directed layout; **harmony_aff** - :class:`~scipy.sparse.spmatrix` (:attr:`~anndata.AnnData.obsp`, dtype `float`); affinity matrix; **harmony",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_harmony_timeseries.py:202,detect,detection,202,src/scanpy/external/tl/_harmony_timeseries.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_harmony_timeseries.py,2,['detect'],['detection']
Safety,"""""""\; Infer progression of cells through geodesic distance along the graph; :cite:p:`Haghverdi2016,Wolf2019`. Reconstruct the progression of a biological process from snapshot; data. `Diffusion Pseudotime` has been introduced by :cite:t:`Haghverdi2016` and; implemented within Scanpy :cite:p:`Wolf2018`. Here, we use a further developed; version, which is able to deal with disconnected graphs :cite:p:`Wolf2019` and can; be run in a `hierarchical` mode by setting the parameter; `n_branchings>1`. We recommend, however, to only use; :func:`~scanpy.tl.dpt` for computing pseudotime (`n_branchings=0`) and; to detect branchings via :func:`~scanpy.tl.paga`. For pseudotime, you need; to annotate your data with a root cell. For instance::. adata.uns['iroot'] = np.flatnonzero(adata.obs['cell_types'] == 'Stem')[0]. This requires to run :func:`~scanpy.pp.neighbors`, first. In order to; reproduce the original implementation of DPT, use `method=='gauss'` in; this. Using the default `method=='umap'` only leads to minor quantitative; differences, though. .. versionadded:: 1.1. :func:`~scanpy.tl.dpt` also requires to run; :func:`~scanpy.tl.diffmap` first. As previously,; :func:`~scanpy.tl.dpt` came with a default parameter of ``n_dcs=10`` but; :func:`~scanpy.tl.diffmap` has a default parameter of ``n_comps=15``,; you need to pass ``n_comps=10`` in :func:`~scanpy.tl.diffmap` in order; to exactly reproduce previous :func:`~scanpy.tl.dpt` results. Parameters; ----------; adata; Annotated data matrix.; n_dcs; The number of diffusion components to use.; n_branchings; Number of branchings to detect.; min_group_size; During recursive splitting of branches ('dpt groups') for `n_branchings`; > 1, do not consider groups that contain less than `min_group_size` data; points. If a float, `min_group_size` refers to a fraction of the total; number of data points.; allow_kendall_tau_shift; If a very small branch is detected upon splitting, shift away from; maximum correlation in Kendall tau criterion o",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py:609,detect,detect,609,src/scanpy/tools/_dpt.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py,1,['detect'],['detect']
Safety,"""""""\; Initialize Scrublet object with counts matrix and doublet prediction parameters. Parameters; ----------; counts_obs; Matrix with shape (n_cells, n_genes) containing raw (unnormalized); UMI-based transcript counts.; Converted into a :class:`scipy.sparse.csc_matrix`. total_counts_obs; Array with shape (n_cells,) of total UMI counts per cell.; If `None`, this is calculated as the row sums of `counts_obs`. sim_doublet_ratio; Number of doublets to simulate relative to the number of observed; transcriptomes. n_neighbors; Number of neighbors used to construct the KNN graph of observed; transcriptomes and simulated doublets.; If `None`, this is set to round(0.5 * sqrt(n_cells)). expected_doublet_rate; The estimated doublet rate for the experiment. stdev_doublet_rate; Uncertainty in the expected doublet rate. random_state; Random state for doublet simulation, approximate; nearest neighbor search, and PCA/TruncatedSVD.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/core.py:64,predict,prediction,64,src/scanpy/preprocessing/_scrublet/core.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/core.py,1,['predict'],['prediction']
Safety,"""""""\; Markov Affinity-based Graph Imputation of Cells (MAGIC) API :cite:p:`vanDijk2018`. MAGIC is an algorithm for denoising and transcript recover of single cells; applied to single-cell sequencing data. MAGIC builds a graph from the data; and uses diffusion to smooth out noise and recover the data manifold. The algorithm implemented here has changed primarily in two ways; compared to the algorithm described in :cite:t:`vanDijk2018`. Firstly, we use; the adaptive kernel described in :cite:t:`Moon2019` for; improved stability. Secondly, data diffusion is applied; in the PCA space, rather than the data space, for speed and; memory improvements. More information and bug reports; `here <https://github.com/KrishnaswamyLab/MAGIC>`__. For help, visit; <https://krishnaswamylab.org/get-help>. Parameters; ----------; adata; An anndata file with `.raw` attribute representing raw counts.; name_list; Denoised genes to return. The default `'all_genes'`/`None`; may require a large amount of memory if the input data is sparse.; Another possibility is `'pca_only'`.; knn; number of nearest neighbors on which to build kernel.; decay; sets decay rate of kernel tails.; If None, alpha decaying kernel is not used.; knn_max; maximum number of nearest neighbors with nonzero connection.; If `None`, will be set to 3 * `knn`.; t; power to which the diffusion operator is powered.; This sets the level of diffusion. If 'auto', t is selected; according to the Procrustes disparity of the diffused data.; n_pca; Number of principal components to use for calculating; neighborhoods. For extremely large datasets, using; n_pca < 20 allows neighborhoods to be calculated in; roughly log(n_samples) time. If `None`, no PCA is performed.; solver; Which solver to use. ""exact"" uses the implementation described; in :cite:t:`vanDijk2018`. ""approximate"" uses a faster; implementation that performs imputation in the PCA space and then; projects back to the gene space. Note, the ""approximate"" solver may; return negat",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_magic.py:140,recover,recover,140,src/scanpy/external/pp/_magic.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_magic.py,2,['recover'],['recover']
Safety,"""""""\; PhenoGraph clustering :cite:p:`Levine2015`. **PhenoGraph** is a clustering method designed for high-dimensional single-cell; data. It works by creating a graph (""network"") representing phenotypic similarities; between cells and then identifying communities in this graph. It supports both; Louvain_ and Leiden_ algorithms for community detection. .. _Louvain: https://louvain-igraph.readthedocs.io/en/latest/. .. _Leiden: https://leidenalg.readthedocs.io/en/latest/reference.html. .. note::; More information and bug reports `here; <https://github.com/dpeerlab/PhenoGraph>`__. Parameters; ----------; data; AnnData, or Array of data to cluster, or sparse matrix of k-nearest neighbor; graph. If ndarray, n-by-d array of n cells in d dimensions. if sparse matrix,; n-by-n adjacency matrix.; clustering_algo; Choose between `'Louvain'` or `'Leiden'` algorithm for clustering.; k; Number of nearest neighbors to use in first step of graph construction.; directed; Whether to use a symmetric (default) or asymmetric (`'directed'`) graph.; The graph construction process produces a directed graph, which is symmetrized; by one of two methods (see `prune` below).; prune; `prune=False`, symmetrize by taking the average between the graph and its; transpose. `prune=True`, symmetrize by taking the product between the graph; and its transpose.; min_cluster_size; Cells that end up in a cluster smaller than min_cluster_size are considered; outliers and are assigned to -1 in the cluster labels.; jaccard; If `True`, use Jaccard metric between k-neighborhoods to build graph. If; `False`, use a Gaussian kernel.; primary_metric; Distance metric to define nearest neighbors. Note that performance will be; slower for correlation and cosine.; n_jobs; Nearest Neighbors and Jaccard coefficients will be computed in parallel using; n_jobs. If 1 is given, no parallelism is used. If set to -1, all CPUs are used.; For n_jobs below -1, `n_cpus + 1 + n_jobs` are used.; q_tol; Tolerance, i.e. precision, for mo",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phenograph.py:342,detect,detection,342,src/scanpy/external/tl/_phenograph.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phenograph.py,1,['detect'],['detection']
Safety,"""""""\; Predict doublets using Scrublet :cite:p:`Wolock2019`. Predict cell doublets using a nearest-neighbor classifier of observed; transcriptomes and simulated doublets. Works best if the input is a raw; (unnormalized) counts matrix from a single sample or a collection of; similar samples from the same experiment.; This function is a wrapper around functions that pre-process using Scanpy; and directly call functions of Scrublet(). You may also undertake your own; preprocessing, simulate doublets with; :func:`~scanpy.pp.scrublet_simulate_doublets`, and run the core scrublet; function :func:`~scanpy.pp.scrublet` with ``adata_sim`` set. Parameters; ----------; adata; The annotated data matrix of shape ``n_obs`` × ``n_vars``. Rows; correspond to cells and columns to genes. Expected to be un-normalised; where adata_sim is not supplied, in which case doublets will be; simulated and pre-processing applied to both objects. If adata_sim is; supplied, this should be the observed transcriptomes processed; consistently (filtering, transform, normalisaton, hvg) with adata_sim.; adata_sim; (Advanced use case) Optional annData object generated by; :func:`~scanpy.pp.scrublet_simulate_doublets`, with same number of vars; as adata. This should have been built from adata_obs after; filtering genes and cells and selcting highly-variable genes.; batch_key; Optional :attr:`~anndata.AnnData.obs` column name discriminating between batches.; sim_doublet_ratio; Number of doublets to simulate relative to the number of observed; transcriptomes.; expected_doublet_rate; Where adata_sim not suplied, the estimated doublet rate for the; experiment.; stdev_doublet_rate; Where adata_sim not suplied, uncertainty in the expected doublet rate.; synthetic_doublet_umi_subsampling; Where adata_sim not suplied, rate for sampling UMIs when creating; synthetic doublets. If 1.0, each doublet is created by simply adding; the UMI counts from two randomly sampled observed transcriptomes. For; values less than 1, t",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py:6,Predict,Predict,6,src/scanpy/preprocessing/_scrublet/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py,2,['Predict'],['Predict']
Safety,"""""""\; See `highly_variable_genes`. For further implementation details see https://www.overleaf.com/read/ckptrbgzzzpg. Returns; -------; Depending on `inplace` returns calculated metrics (:class:`~pd.DataFrame`) or; updates `.var` with the following fields:. highly_variable : :class:`bool`; boolean indicator of highly-variable genes.; **means**; means per gene.; **variances**; variance per gene.; **variances_norm**; normalized variance per gene, averaged in the case of multiple batches.; highly_variable_rank : :class:`float`; Rank of the gene according to normalized variance, median rank in the case of multiple batches.; highly_variable_nbatches : :class:`int`; If batch_key is given, this denotes in how many batches genes are detected as HVG.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py:735,detect,detected,735,src/scanpy/preprocessing/_highly_variable_genes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py,1,['detect'],['detected']
Safety,"""""""\; Select highly variable genes using analytic Pearson residuals :cite:p:`Lause2021`. In :cite:t:`Lause2021`, Pearson residuals of a negative binomial offset model are computed; (with overdispersion `theta` shared across genes). By default, overdispersion; `theta=100` is used and residuals are clipped to `sqrt(n_obs)`. Finally, genes; are ranked by residual variance. Expects raw count input. Parameters; ----------; {adata}; {dist_params}; {genes_batch_chunk}; flavor; Choose the flavor for identifying highly variable genes. In this experimental; version, only 'pearson_residuals' is functional.; {check_values}; {layer}; subset; If `True`, subset the data to highly-variable genes after finding them.; Otherwise merely indicate highly variable genes in `adata.var` (see below).; {inplace}. Returns; -------; If `inplace=True`, `adata.var` is updated with the following fields. Otherwise,; returns the same fields as :class:`~pandas.DataFrame`. highly_variable : :class:`bool`; boolean indicator of highly-variable genes.; means : :class:`float`; means per gene.; variances : :class:`float`; variance per gene.; residual_variances : :class:`float`; For `flavor='pearson_residuals'`, residual variance per gene. Averaged in the; case of multiple batches.; highly_variable_rank : :class:`float`; For `flavor='pearson_residuals'`, rank of the gene according to residual.; variance, median rank in the case of multiple batches.; highly_variable_nbatches : :class:`int`; If `batch_key` given, denotes in how many batches genes are detected as HVG.; highly_variable_intersection : :class:`bool`; If `batch_key` given, denotes the genes that are highly variable in all batches. Notes; -----; Experimental version of `sc.pp.highly_variable_genes()`; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_highly_variable_genes.py:1533,detect,detected,1533,src/scanpy/experimental/pp/_highly_variable_genes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_highly_variable_genes.py,1,['detect'],['detected']
Safety,"""""""\; n_top_genes; Number of highly-variable genes to keep. Mandatory if `flavor='seurat_v3'` or; `flavor='pearson_residuals'`.; batch_key; If specified, highly-variable genes are selected within each batch separately; and merged. This simple process avoids the selection of batch-specific genes; and acts as a lightweight batch correction method. Genes are first sorted by; how many batches they are a HVG. If `flavor='pearson_residuals'`, ties are; broken by the median rank (across batches) based on within-batch residual; variance.; chunksize; If `flavor='pearson_residuals'`, this dertermines how many genes are processed at; once while computing the residual variance. Choosing a smaller value will reduce; the required memory.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/_docs.py:251,avoid,avoids,251,src/scanpy/experimental/_docs.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/_docs.py,1,['avoid'],['avoids']
Safety,"""""""\; t-SNE :cite:p:`vanDerMaaten2008,Amir2013,Pedregosa2011`. t-distributed stochastic neighborhood embedding (tSNE, :cite:t:`vanDerMaaten2008`) has been; proposed for visualizating single-cell data by :cite:t:`Amir2013`. Here, by default,; we use the implementation of *scikit-learn* :cite:p:`Pedregosa2011`. You can achieve; a huge speedup and better convergence if you install Multicore-tSNE_; by :cite:t:`Ulyanov2016`, which will be automatically detected by Scanpy. .. _multicore-tsne: https://github.com/DmitryUlyanov/Multicore-TSNE. Parameters; ----------; adata; Annotated data matrix.; {doc_n_pcs}; {use_rep}; perplexity; The perplexity is related to the number of nearest neighbors that; is used in other manifold learning algorithms. Larger datasets; usually require a larger perplexity. Consider selecting a value; between 5 and 50. The choice is not extremely critical since t-SNE; is quite insensitive to this parameter.; metric; Distance metric calculate neighbors on.; early_exaggeration; Controls how tight natural clusters in the original space are in the; embedded space and how much space will be between them. For larger; values, the space between natural clusters will be larger in the; embedded space. Again, the choice of this parameter is not very; critical. If the cost function increases during initial optimization,; the early exaggeration factor or the learning rate might be too high.; learning_rate; Note that the R-package ""Rtsne"" uses a default of 200.; The learning rate can be a critical parameter. It should be; between 100 and 1000. If the cost function increases during initial; optimization, the early exaggeration factor or the learning rate; might be too high. If the cost function gets stuck in a bad local; minimum increasing the learning rate helps sometimes.; random_state; Change this to use different intial states for the optimization.; If `None`, the initial state is not reproducible.; n_jobs; Number of jobs for parallel computation.; `None` means u",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_tsne.py:452,detect,detected,452,src/scanpy/tools/_tsne.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_tsne.py,1,['detect'],['detected']
Safety,"# If threshold hasn't been located successfully then we couldn't make any; # predictions. The user will get a warning from Scrublet, but we need to; # set the boolean so that any downstream filtering on; # predicted_doublet=False doesn't incorrectly filter cells. The user can; # still use this object to generate the plot and derive a threshold; # manually.",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py:77,predict,predictions,77,src/scanpy/preprocessing/_scrublet/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py,1,['predict'],['predictions']
Safety,"# Only plotting one group at a time to avoid generating dendrogram; # TODO: Generating a dendrogram modifies the object, this should be; # optional and also maybe not modify the object.",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:39,avoid,avoid,39,tests/test_plotting.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py,1,['avoid'],['avoid']
Safety,"# Wrapped in another fixture to avoid mutation",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:32,avoid,avoid,32,tests/test_plotting.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py,1,['avoid'],['avoid']
Safety,"# [third start end]; # detect branching and update segs and segs_tips",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py:23,detect,detect,23,src/scanpy/tools/_dpt.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py,1,['detect'],['detect']
Safety,"# a name to store the density values is needed. To avoid; # overwriting a user name a new random name is created",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py:51,avoid,avoid,51,src/scanpy/plotting/_tools/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py,1,['avoid'],['avoid']
Safety,"# account for the fact that there might be more than n_neighbors; # due to an approximate search; # [the point itself was not detected as its own neighbor during the search]",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/_common.py:126,detect,detected,126,src/scanpy/neighbors/_common.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/_common.py,1,['detect'],['detected']
Safety,"# automatic threshold detection; # http://scikit-image.org/docs/dev/api/skimage.filters.html",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/core.py:22,detect,detection,22,src/scanpy/preprocessing/_scrublet/core.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/core.py,1,['detect'],['detection']
Safety,"# compute which fraction of the predicted group is contained in; # the ref group",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/__init__.py:32,predict,predicted,32,src/scanpy/_utils/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/__init__.py,1,['predict'],['predicted']
Safety,"# compute which fraction of the reference group is contained in; # the predicted group",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/__init__.py:71,predict,predicted,71,src/scanpy/_utils/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/__init__.py,1,['predict'],['predicted']
Safety,"# detect branchings and partition the data into segments",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py:2,detect,detect,2,src/scanpy/tools/_dpt.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py,1,['detect'],['detect']
Safety,"# detects loss of precision in mean_sq - sq_mean, which suggests variance is 0",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/_aggregated.py:2,detect,detects,2,src/scanpy/get/_aggregated.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/_aggregated.py,1,['detect'],['detects']
Safety,"# given the three tip points and the distance matrix detect the; # branching on the segment, return the list ssegs of segments that; # are defined by splitting this segment",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py:53,detect,detect,53,src/scanpy/tools/_dpt.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py,1,['detect'],['detect']
Safety,"# make link list, avoid redundant encoding (graph is undirected)",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/exporting.py:18,avoid,avoid,18,src/scanpy/external/exporting.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/exporting.py,2,"['avoid', 'redund']","['avoid', 'redundant']"
Safety,"# remove the xticks labels except for the last processed plot.; # Because the plots share the x axis it is redundant and less compact; # to plot the axis for each plot",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py:107,redund,redundant,107,src/scanpy/plotting/_anndata.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py,1,['redund'],['redundant']
Safety,"# space needs to be added to avoid overlapping; # of labels and legend or dendrogram/totals.",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_stacked_violin.py:29,avoid,avoid,29,src/scanpy/plotting/_stacked_violin.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_stacked_violin.py,1,['avoid'],['avoid']
Safety,"# this is safe, but not compatible with on-the-fly computation",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py:10,safe,safe,10,src/scanpy/tools/_dpt.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py,1,['safe'],['safe']
Safety,"# to maintain the fixed height size of the legends, a; # spacer of variable height is added at the bottom.; # The structure for the legends is:; # first row: variable space to keep the other rows of; # the same size (avoid stretching); # second row: legend for dot size; # third row: spacer to avoid color and size legend titles to overlap; # fourth row: colorbar",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_dotplot.py:217,avoid,avoid,217,src/scanpy/plotting/_dotplot.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_dotplot.py,2,['avoid'],['avoid']
Safety,"# to make the stacked violin plots, the; # `ax` is subdivided horizontally and in each horizontal sub ax; # a seaborn violin plot is added.; # work on a copy of the dataframes. This is to avoid changes; # on the original data frames after repetitive calls to the; # StackedViolin object, for example once with swap_axes and other without",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_stacked_violin.py:188,avoid,avoid,188,src/scanpy/plotting/_stacked_violin.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_stacked_violin.py,1,['avoid'],['avoid']
Safety,"# use only the smallest and the largest y ticks; # and align the firts label on top of the tick and; # the second below the tick. This avoid overlapping; # of nearby ticks",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_stacked_violin.py:135,avoid,avoid,135,src/scanpy/plotting/_stacked_violin.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_stacked_violin.py,1,['avoid'],['avoid']
Safety,"# work on a copy of the dataframes. This is to avoid changes; # on the original data frames after repetitive calls to the; # DotPlot object, for example once with swap_axes and other without",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_dotplot.py:47,avoid,avoid,47,src/scanpy/plotting/_dotplot.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_dotplot.py,1,['avoid'],['avoid']
Safety,"# work on a copy of the dataframes. This is to avoid changes; # on the original data frames after repetitive calls to the; # MatrixPlot object, for example once with swap_axes and other without",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_matrixplot.py:47,avoid,avoid,47,src/scanpy/plotting/_matrixplot.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_matrixplot.py,1,['avoid'],['avoid']
Safety,"` will be used for dimensionality; reduction.; n_prin_comps; Number of principal components used to embed the transcriptomes prior; to k-nearest-neighbor graph construction.; use_approx_neighbors; Use approximate nearest neighbor method (annoy) for the KNN; classifier.; get_doublet_neighbor_parents; If True, return (in .uns) the parent transcriptomes that generated the; doublet neighbors of each observed transcriptome. This information can; be used to infer the cell states that generated a given doublet state.; n_neighbors; Number of neighbors used to construct the KNN graph of observed; transcriptomes and simulated doublets. If ``None``, this is; automatically set to ``np.round(0.5 * np.sqrt(n_obs))``.; threshold; Doublet score threshold for calling a transcriptome a doublet. If; `None`, this is set automatically by looking for the minimum between; the two modes of the `doublet_scores_sim_` histogram. It is best; practice to check the threshold visually using the; `doublet_scores_sim_` histogram and/or based on co-localization of; predicted doublets in a 2-D embedding.; verbose; If :data:`True`, log progress updates.; copy; If :data:`True`, return a copy of the input ``adata`` with Scrublet results; added. Otherwise, Scrublet results are added in place.; random_state; Initial state for doublet simulation and nearest neighbors. Returns; -------; if ``copy=True`` it returns or else adds fields to ``adata``. Those fields:. ``.obs['doublet_score']``; Doublet scores for each observed transcriptome. ``.obs['predicted_doublet']``; Boolean indicating predicted doublet status. ``.uns['scrublet']['doublet_scores_sim']``; Doublet scores for each simulated doublet transcriptome. ``.uns['scrublet']['doublet_parents']``; Pairs of ``.obs_names`` used to generate each simulated doublet; transcriptome. ``.uns['scrublet']['parameters']``; Dictionary of Scrublet parameters. See also; --------; :func:`~scanpy.pp.scrublet_simulate_doublets`: Run Scrublet's doublet; simulation separately",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py:3783,predict,predicted,3783,src/scanpy/preprocessing/_scrublet/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py,1,['predict'],['predicted']
Safety,"`'wilcoxon'` uses Wilcoxon rank-sum,; `'logreg'` uses logistic regression. See :cite:t:`Ntranos2019`,; `here <https://github.com/scverse/scanpy/issues/95>`__ and `here; <https://www.nxn.se/valent/2018/3/5/actionable-scrna-seq-clusters>`__,; for why this is meaningful.; corr_method; p-value correction method.; Used only for `'t-test'`, `'t-test_overestim_var'`, and `'wilcoxon'`.; tie_correct; Use tie correction for `'wilcoxon'` scores.; Used only for `'wilcoxon'`.; rankby_abs; Rank genes by the absolute value of the score, not by the; score. The returned scores are never the absolute values.; pts; Compute the fraction of cells expressing the genes.; key_added; The key in `adata.uns` information is saved to.; copy; Whether to copy `adata` or modify it inplace.; kwds; Are passed to test methods. Currently this affects only parameters that; are passed to :class:`sklearn.linear_model.LogisticRegression`.; For instance, you can pass `penalty='l1'` to try to come up with a; minimal set of genes that are good predictors (sparse solution meaning; few non-zero fitted coefficients). Returns; -------; Returns `None` if `copy=False`, else returns an `AnnData` object. Sets the following fields:. `adata.uns['rank_genes_groups' | key_added]['names']` : structured :class:`numpy.ndarray` (dtype `object`); Structured array to be indexed by group id storing the gene; names. Ordered according to scores.; `adata.uns['rank_genes_groups' | key_added]['scores']` : structured :class:`numpy.ndarray` (dtype `object`); Structured array to be indexed by group id storing the z-score; underlying the computation of a p-value for each gene for each; group. Ordered according to scores.; `adata.uns['rank_genes_groups' | key_added]['logfoldchanges']` : structured :class:`numpy.ndarray` (dtype `object`); Structured array to be indexed by group id storing the log2; fold change for each gene for each group. Ordered according to; scores. Only provided if method is 't-test' like.; Note: this is an approxima",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py:1996,predict,predictors,1996,src/scanpy/tools/_rank_genes_groups.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py,1,['predict'],['predictors']
Safety,"al arguments passed to :func:`~leidenalg.find_partition` and the; constructor of the `partition_type`. Returns; -------; Depending on `copy`, returns or updates `adata` with the following fields:. **communities** - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.obs`, dtype `int`); integer array of community assignments for each row in data. **graph** - :class:`~scipy.sparse.spmatrix` (:attr:`~anndata.AnnData.obsp`, dtype `float`); the graph that was used for clustering. **Q** - `float` (:attr:`~anndata.AnnData.uns`, dtype `float`); the modularity score for communities on graph. Example; -------; >>> from anndata import AnnData; >>> import scanpy as sc; >>> import scanpy.external as sce; >>> import numpy as np; >>> import pandas as pd. With annotated data as input:. >>> adata = sc.datasets.pbmc3k(); >>> sc.pp.normalize_per_cell(adata). Then do PCA:. >>> sc.pp.pca(adata, n_comps=100). Compute phenograph clusters:. **Louvain** community detection. >>> sce.tl.phenograph(adata, clustering_algo=""louvain"", k=30). **Leiden** community detection. >>> sce.tl.phenograph(adata, clustering_algo=""leiden"", k=30). Return only `Graph` object. >>> sce.tl.phenograph(adata, clustering_algo=None, k=30). Now to show phenograph on tSNE (for example):. Compute tSNE:. >>> sc.tl.tsne(adata, random_state=7). Plot phenograph clusters on tSNE:. >>> sc.pl.tsne(; ... adata, color = [""pheno_louvain"", ""pheno_leiden""], s = 100,; ... palette = sc.pl.palettes.vega_20_scanpy, legend_fontsize = 10; ... ). Cluster and cluster centroids for input Numpy ndarray. >>> df = np.random.rand(1000, 40); >>> dframe = pd.DataFrame(df); >>> dframe.index, dframe.columns = (map(str, dframe.index), map(str, dframe.columns)); >>> adata = AnnData(dframe); >>> sc.pp.pca(adata, n_comps=20); >>> sce.tl.phenograph(adata, clustering_algo=""leiden"", k=50); >>> sc.tl.tsne(adata, random_state=1); >>> sc.pl.tsne(; ... adata, color=['pheno_leiden'], s=100,; ... palette=sc.pl.palettes.vega_20_scanpy, legend_fontsize=10; ... ); """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phenograph.py:4162,detect,detection,4162,src/scanpy/external/tl/_phenograph.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phenograph.py,1,['detect'],['detection']
Safety,"arn.decomposition.PCA` will be used for dimensionality; reduction.; normalize_variance; If True, normalize the data such that each gene has a variance of 1.; `sklearn.decomposition.TruncatedSVD` will be used for dimensionality; reduction, unless `mean_center` is True.; n_prin_comps; Number of principal components used to embed the transcriptomes prior; to k-nearest-neighbor graph construction.; use_approx_neighbors; Use approximate nearest neighbor method (annoy) for the KNN; classifier.; knn_dist_metric; Distance metric used when finding nearest neighbors. For list of; valid values, see the documentation for annoy (if `use_approx_neighbors`; is True) or sklearn.neighbors.NearestNeighbors (if `use_approx_neighbors`; is False).; get_doublet_neighbor_parents; If True, return the parent transcriptomes that generated the; doublet neighbors of each observed transcriptome. This information can; be used to infer the cell states that generated a given; doublet state.; threshold; Doublet score threshold for calling a transcriptome a doublet. If; `None`, this is set automatically by looking for the minimum between; the two modes of the `doublet_scores_sim_` histogram. It is best; practice to check the threshold visually using the; `doublet_scores_sim_` histogram and/or based on co-localization of; predicted doublets in a 2-D embedding.; random_state; Initial state for doublet simulation and nearest neighbors.; verbose; If :data:`True`, log progress updates. Returns; -------; if ``copy=True`` it returns or else adds fields to ``adata``:. ``.obs['doublet_score']``; Doublet scores for each observed transcriptome. ``.obs['predicted_doublets']``; Boolean indicating predicted doublet status. ``.uns['scrublet']['doublet_scores_sim']``; Doublet scores for each simulated doublet transcriptome. ``.uns['scrublet']['doublet_parents']``; Pairs of ``.obs_names`` used to generate each simulated doublet transcriptome. ``.uns['scrublet']['parameters']``; Dictionary of Scrublet parameters; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py:2410,predict,predicted,2410,src/scanpy/preprocessing/_scrublet/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py,2,['predict'],['predicted']
Safety,"copy; Return a copy or write to `adata`.; kargs; Additional arguments passed to :func:`~leidenalg.find_partition` and the; constructor of the `partition_type`. Returns; -------; Depending on `copy`, returns or updates `adata` with the following fields:. **communities** - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.obs`, dtype `int`); integer array of community assignments for each row in data. **graph** - :class:`~scipy.sparse.spmatrix` (:attr:`~anndata.AnnData.obsp`, dtype `float`); the graph that was used for clustering. **Q** - `float` (:attr:`~anndata.AnnData.uns`, dtype `float`); the modularity score for communities on graph. Example; -------; >>> from anndata import AnnData; >>> import scanpy as sc; >>> import scanpy.external as sce; >>> import numpy as np; >>> import pandas as pd. With annotated data as input:. >>> adata = sc.datasets.pbmc3k(); >>> sc.pp.normalize_per_cell(adata). Then do PCA:. >>> sc.pp.pca(adata, n_comps=100). Compute phenograph clusters:. **Louvain** community detection. >>> sce.tl.phenograph(adata, clustering_algo=""louvain"", k=30). **Leiden** community detection. >>> sce.tl.phenograph(adata, clustering_algo=""leiden"", k=30). Return only `Graph` object. >>> sce.tl.phenograph(adata, clustering_algo=None, k=30). Now to show phenograph on tSNE (for example):. Compute tSNE:. >>> sc.tl.tsne(adata, random_state=7). Plot phenograph clusters on tSNE:. >>> sc.pl.tsne(; ... adata, color = [""pheno_louvain"", ""pheno_leiden""], s = 100,; ... palette = sc.pl.palettes.vega_20_scanpy, legend_fontsize = 10; ... ). Cluster and cluster centroids for input Numpy ndarray. >>> df = np.random.rand(1000, 40); >>> dframe = pd.DataFrame(df); >>> dframe.index, dframe.columns = (map(str, dframe.index), map(str, dframe.columns)); >>> adata = AnnData(dframe); >>> sc.pp.pca(adata, n_comps=20); >>> sce.tl.phenograph(adata, clustering_algo=""leiden"", k=50); >>> sc.tl.tsne(adata, random_state=1); >>> sc.pl.tsne(; ... adata, color=['pheno_leiden'], s=100,; ... palette=sc.pl",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phenograph.py:4067,detect,detection,4067,src/scanpy/external/tl/_phenograph.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phenograph.py,1,['detect'],['detection']
Safety,"his. Using the default `method=='umap'` only leads to minor quantitative; differences, though. .. versionadded:: 1.1. :func:`~scanpy.tl.dpt` also requires to run; :func:`~scanpy.tl.diffmap` first. As previously,; :func:`~scanpy.tl.dpt` came with a default parameter of ``n_dcs=10`` but; :func:`~scanpy.tl.diffmap` has a default parameter of ``n_comps=15``,; you need to pass ``n_comps=10`` in :func:`~scanpy.tl.diffmap` in order; to exactly reproduce previous :func:`~scanpy.tl.dpt` results. Parameters; ----------; adata; Annotated data matrix.; n_dcs; The number of diffusion components to use.; n_branchings; Number of branchings to detect.; min_group_size; During recursive splitting of branches ('dpt groups') for `n_branchings`; > 1, do not consider groups that contain less than `min_group_size` data; points. If a float, `min_group_size` refers to a fraction of the total; number of data points.; allow_kendall_tau_shift; If a very small branch is detected upon splitting, shift away from; maximum correlation in Kendall tau criterion of :cite:t:`Haghverdi2016` to; stabilize the splitting.; neighbors_key; If not specified, dpt looks .uns['neighbors'] for neighbors settings; and .obsp['connectivities'], .obsp['distances'] for connectivities and; distances respectively (default storage places for pp.neighbors).; If specified, dpt looks .uns[neighbors_key] for neighbors settings and; .obsp[.uns[neighbors_key]['connectivities_key']],; .obsp[.uns[neighbors_key]['distances_key']] for connectivities and distances; respectively.; copy; Copy instance before computation and return a copy.; Otherwise, perform computation inplace and return `None`. Returns; -------; Returns `None` if `copy=False`, else returns an `AnnData` object. Sets the following fields (If `n_branchings==0`, no field `adata.obs['dpt_groups']` will be written):. `adata.obs['dpt_pseudotime']` : :class:`pandas.Series` (dtype `float`); Array of dim (number of samples) that stores the pseudotime of each; cell, that is, t",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py:1913,detect,detected,1913,src/scanpy/tools/_dpt.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py,1,['detect'],['detected']
Safety,"onstruction.; use_approx_neighbors; Use approximate nearest neighbor method (annoy) for the KNN; classifier.; get_doublet_neighbor_parents; If True, return (in .uns) the parent transcriptomes that generated the; doublet neighbors of each observed transcriptome. This information can; be used to infer the cell states that generated a given doublet state.; n_neighbors; Number of neighbors used to construct the KNN graph of observed; transcriptomes and simulated doublets. If ``None``, this is; automatically set to ``np.round(0.5 * np.sqrt(n_obs))``.; threshold; Doublet score threshold for calling a transcriptome a doublet. If; `None`, this is set automatically by looking for the minimum between; the two modes of the `doublet_scores_sim_` histogram. It is best; practice to check the threshold visually using the; `doublet_scores_sim_` histogram and/or based on co-localization of; predicted doublets in a 2-D embedding.; verbose; If :data:`True`, log progress updates.; copy; If :data:`True`, return a copy of the input ``adata`` with Scrublet results; added. Otherwise, Scrublet results are added in place.; random_state; Initial state for doublet simulation and nearest neighbors. Returns; -------; if ``copy=True`` it returns or else adds fields to ``adata``. Those fields:. ``.obs['doublet_score']``; Doublet scores for each observed transcriptome. ``.obs['predicted_doublet']``; Boolean indicating predicted doublet status. ``.uns['scrublet']['doublet_scores_sim']``; Doublet scores for each simulated doublet transcriptome. ``.uns['scrublet']['doublet_parents']``; Pairs of ``.obs_names`` used to generate each simulated doublet; transcriptome. ``.uns['scrublet']['parameters']``; Dictionary of Scrublet parameters. See also; --------; :func:`~scanpy.pp.scrublet_simulate_doublets`: Run Scrublet's doublet; simulation separately for advanced usage.; :func:`~scanpy.pl.scrublet_score_distribution`: Plot histogram of doublet; scores for observed transcriptomes and simulated doublets.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py:4305,predict,predicted,4305,src/scanpy/preprocessing/_scrublet/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py,1,['predict'],['predicted']
Safety,"otime (`n_branchings=0`) and; to detect branchings via :func:`~scanpy.tl.paga`. For pseudotime, you need; to annotate your data with a root cell. For instance::. adata.uns['iroot'] = np.flatnonzero(adata.obs['cell_types'] == 'Stem')[0]. This requires to run :func:`~scanpy.pp.neighbors`, first. In order to; reproduce the original implementation of DPT, use `method=='gauss'` in; this. Using the default `method=='umap'` only leads to minor quantitative; differences, though. .. versionadded:: 1.1. :func:`~scanpy.tl.dpt` also requires to run; :func:`~scanpy.tl.diffmap` first. As previously,; :func:`~scanpy.tl.dpt` came with a default parameter of ``n_dcs=10`` but; :func:`~scanpy.tl.diffmap` has a default parameter of ``n_comps=15``,; you need to pass ``n_comps=10`` in :func:`~scanpy.tl.diffmap` in order; to exactly reproduce previous :func:`~scanpy.tl.dpt` results. Parameters; ----------; adata; Annotated data matrix.; n_dcs; The number of diffusion components to use.; n_branchings; Number of branchings to detect.; min_group_size; During recursive splitting of branches ('dpt groups') for `n_branchings`; > 1, do not consider groups that contain less than `min_group_size` data; points. If a float, `min_group_size` refers to a fraction of the total; number of data points.; allow_kendall_tau_shift; If a very small branch is detected upon splitting, shift away from; maximum correlation in Kendall tau criterion of :cite:t:`Haghverdi2016` to; stabilize the splitting.; neighbors_key; If not specified, dpt looks .uns['neighbors'] for neighbors settings; and .obsp['connectivities'], .obsp['distances'] for connectivities and; distances respectively (default storage places for pp.neighbors).; If specified, dpt looks .uns[neighbors_key] for neighbors settings and; .obsp[.uns[neighbors_key]['connectivities_key']],; .obsp[.uns[neighbors_key]['distances_key']] for connectivities and distances; respectively.; copy; Copy instance before computation and return a copy.; Otherwise, perform co",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py:1593,detect,detect,1593,src/scanpy/tools/_dpt.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py,1,['detect'],['detect']
Safety,"ow many batches they are a HVG. For dispersion-based flavors ties are broken; by normalized dispersion. For `flavor = 'seurat_v3_paper'`, ties are broken by the median; (across batches) rank based on within-batch normalized variance.; check_values; Check if counts in selected layer are integers. A Warning is returned if set to True.; Only used if `flavor='seurat_v3'`/`'seurat_v3_paper'`. Returns; -------; Returns a :class:`pandas.DataFrame` with calculated metrics if `inplace=True`, else returns an `AnnData` object where it sets the following field:. `adata.var['highly_variable']` : :class:`pandas.Series` (dtype `bool`); boolean indicator of highly-variable genes; `adata.var['means']` : :class:`pandas.Series` (dtype `float`); means per gene; `adata.var['dispersions']` : :class:`pandas.Series` (dtype `float`); For dispersion-based flavors, dispersions per gene; `adata.var['dispersions_norm']` : :class:`pandas.Series` (dtype `float`); For dispersion-based flavors, normalized dispersions per gene; `adata.var['variances']` : :class:`pandas.Series` (dtype `float`); For `flavor='seurat_v3'`/`'seurat_v3_paper'`, variance per gene; `adata.var['variances_norm']`/`'seurat_v3_paper'` : :class:`pandas.Series` (dtype `float`); For `flavor='seurat_v3'`/`'seurat_v3_paper'`, normalized variance per gene, averaged in; the case of multiple batches; `adata.var['highly_variable_rank']` : :class:`pandas.Series` (dtype `float`); For `flavor='seurat_v3'`/`'seurat_v3_paper'`, rank of the gene according to normalized; variance, in case of multiple batches description above; `adata.var['highly_variable_nbatches']` : :class:`pandas.Series` (dtype `int`); If `batch_key` is given, this denotes in how many batches genes are detected as HVG; `adata.var['highly_variable_intersection']` : :class:`pandas.Series` (dtype `bool`); If `batch_key` is given, this denotes the genes that are highly variable in all batches. Notes; -----; This function replaces :func:`~scanpy.pp.filter_genes_dispersion`.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py:5934,detect,detected,5934,src/scanpy/preprocessing/_highly_variable_genes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py,1,['detect'],['detected']
Safety,"rmalized dispersions are ignored. Ignored if `flavor='seurat_v3'`.; span; The fraction of the data (cells) used when estimating the variance in the loess; model fit if `flavor='seurat_v3'`.; n_bins; Number of bins for binning the mean gene expression. Normalization is; done with respect to each bin. If just a single gene falls into a bin,; the normalized dispersion is artificially set to 1. You'll be informed; about this if you set `settings.verbosity = 4`.; flavor; Choose the flavor for identifying highly variable genes. For the dispersion; based methods in their default workflows, Seurat passes the cutoffs whereas; Cell Ranger passes `n_top_genes`.; subset; Inplace subset to highly-variable genes if `True` otherwise merely indicate; highly variable genes.; inplace; Whether to place calculated metrics in `.var` or return them.; batch_key; If specified, highly-variable genes are selected within each batch separately and merged.; This simple process avoids the selection of batch-specific genes and acts as a; lightweight batch correction method. For all flavors, except `seurat_v3`, genes are first sorted; by how many batches they are a HVG. For dispersion-based flavors ties are broken; by normalized dispersion. For `flavor = 'seurat_v3_paper'`, ties are broken by the median; (across batches) rank based on within-batch normalized variance.; check_values; Check if counts in selected layer are integers. A Warning is returned if set to True.; Only used if `flavor='seurat_v3'`/`'seurat_v3_paper'`. Returns; -------; Returns a :class:`pandas.DataFrame` with calculated metrics if `inplace=True`, else returns an `AnnData` object where it sets the following field:. `adata.var['highly_variable']` : :class:`pandas.Series` (dtype `bool`); boolean indicator of highly-variable genes; `adata.var['means']` : :class:`pandas.Series` (dtype `float`); means per gene; `adata.var['dispersions']` : :class:`pandas.Series` (dtype `float`); For dispersion-based flavors, dispersions per gene; `a",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py:4048,avoid,avoids,4048,src/scanpy/preprocessing/_highly_variable_genes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py,1,['avoid'],['avoids']
Safety,"sed on Pearson residuals. On the resulting subset,; Pearson residual normalization and PCA are performed. Expects raw count input. Params; ------; {adata}; {dist_params}; {genes_batch_chunk}; {pca_chunk}; {check_values}; {inplace}. Returns; -------; If `inplace=False`, separately returns the gene selection results (as; :class:`~pandas.DataFrame`) and Pearson residual-based PCA results (as; :class:`~anndata.AnnData`). If `inplace=True`, updates `adata` with the; following fields for gene selection results:. `.var['highly_variable']` : bool; boolean indicator of highly-variable genes.; `.var['means']` : float; means per gene.; `.var['variances']` : float; variances per gene.; `.var['residual_variances']` : float; Pearson residual variance per gene. Averaged in the case of multiple; batches.; `.var['highly_variable_rank']` : float; Rank of the gene according to residual variance, median rank in the; case of multiple batches.; `.var['highly_variable_nbatches']` : int; If batch_key is given, this denotes in how many batches genes are; detected as HVG.; `.var['highly_variable_intersection']` : bool; If batch_key is given, this denotes the genes that are highly variable; in all batches. The following fields contain Pearson residual-based PCA results and; normalization settings:. `.uns['pearson_residuals_normalization']['pearson_residuals_df']`; The subset of highly variable genes, normalized by Pearson residuals.; `.uns['pearson_residuals_normalization']['theta']`; The used value of the overdisperion parameter theta.; `.uns['pearson_residuals_normalization']['clip']`; The used value of the clipping parameter. `.obsm['X_pca']`; PCA representation of data after gene selection and Pearson residual; normalization.; `.varm['PCs']`; The principal components containing the loadings. When `inplace=True` this; will contain empty rows for the genes not selected during HVG selection.; `.uns['pca']['variance_ratio']`; Ratio of explained variance.; `.uns['pca']['variance']`; Explained v",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_recipes.py:1178,detect,detected,1178,src/scanpy/experimental/pp/_recipes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/pp/_recipes.py,1,['detect'],['detected']
Security," library size differences by; scaling the mean value of each cell in the output layer. See the; manuscript for more details.; scale; If true, the input of the autoencoder is centered using; `sc.pp.scale` function of Scanpy. Note that the output is kept as raw; counts as loss functions are designed for the count data.; log1p; If true, the input of the autoencoder is log transformed with a; pseudocount of one using `sc.pp.log1p` function of Scanpy.; hidden_size; Width of hidden layers.; hidden_dropout; Probability of weight dropout in the autoencoder (per layer if list; or tuple).; batchnorm; If true, batch normalization is performed.; activation; Activation function of hidden layers.; init; Initialization method used to initialize weights.; network_kwds; Additional keyword arguments for the autoencoder.; epochs; Number of total epochs in training.; reduce_lr; Reduces learning rate if validation loss does not improve in given number of epochs.; early_stop; Stops training if validation loss does not improve in given number of epochs.; batch_size; Number of samples in the batch used for SGD.; optimizer; Type of optimization method used for training.; random_state; Seed for python, numpy and tensorflow.; threads; Number of threads to use in training. All cores are used by default.; learning_rate; Learning rate to use in the training.; verbose; If true, prints additional information about training and architecture.; training_kwds; Additional keyword arguments for the training process.; return_model; If true, trained autoencoder object is returned. See ""Returns"".; return_info; If true, all additional parameters of DCA are stored in `adata.obsm` such as dropout; probabilities (obsm['X_dca_dropout']) and estimated dispersion values; (obsm['X_dca_dispersion']), in case that autoencoder is of type; zinb or zinb-conddisp.; copy; If true, a copy of anndata is returned. Returns; -------; If `copy` is true and `return_model` is false, AnnData object is returned. In ""denoise"" mode, ",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_dca.py:2083,validat,validation,2083,src/scanpy/external/pp/_dca.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_dca.py,1,['validat'],['validation']
Security,"""""""; Calculate bayes rule from log likelihoods. Parameters; ----------; data; Anndata object filled only with hashing counts; priors; a list of your prior for each hypothesis; first element is your prior for the negative hypothesis; second element is your prior for the singlet hypothesis; third element is your prior for the doublet hypothesis; We use [0.01, 0.8, 0.19] by default because we assume the barcodes; in your cell hashing matrix are those cells which have passed QC; in the transcriptome space, e.g. UMI counts, pct mito reads, etc.; number_of_noise_barcodes; number of barcodes to used to calculated noise distribution. Returns; -------; A dict of bayes key results with the following entries:. `""most_likely_hypothesis""`; A 1d np.array of the most likely hypothesis; `""probs_hypotheses""`; A 2d np.array probability of each hypothesis; `""log_likelihoods_for_each_hypothesis""`; A 2d np.array log likelihood of each hypothesis; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py:110,hash,hashing,110,src/scanpy/external/pp/_hashsolo.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py,2,['hash'],['hashing']
Security,"""""""; HashSolo script provides a probabilistic cell hashing demultiplexing method; which generates a noise distribution and signal distribution for; each hashing barcode from empirically observed counts. These distributions; are updates from the global signal and noise barcode distributions, which; helps in the setting where not many cells are observed. Signal distributions; for a hashing barcode are estimated from samples where that hashing barcode; has the highest count. Noise distributions for a hashing barcode are estimated; from samples where that hashing barcode is one the k-2 lowest barcodes, where; k is the number of barcodes. A doublet should then have its two highest; barcode counts most likely coming from a signal distribution for those barcodes.; A singlet should have its highest barcode from a signal distribution, and its; second highest barcode from a noise distribution. A negative two highest; barcodes should come from noise distributions. We test each of these; hypotheses in a bayesian fashion, and select the most probable hypothesis.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py:5,Hash,HashSolo,5,src/scanpy/external/pp/_hashsolo.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py,7,"['Hash', 'hash']","['HashSolo', 'hashing']"
Security,"""""""; Validate mask argument; Params; ------; data; Annotated data matrix or numpy array.; mask; The mask. Either an appropriatley sized boolean array, or name of a column which will be used to mask.; dim; The dimension being masked.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/get.py:5,Validat,Validate,5,src/scanpy/get/get.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/get.py,1,['Validat'],['Validate']
Security,"""""""Calculate log likelihoods for each hypothesis, negative, singlet, doublet. Parameters; ----------; data; cells by hashing counts matrix; number_of_noise_barcodes; number of barcodes to used to calculated noise distribution. Returns; -------; log_likelihoods_for_each_hypothesis; a 2d np.array log likelihood of each hypothesis; all_indices; counter_to_barcode_combo; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py:117,hash,hashing,117,src/scanpy/external/pp/_hashsolo.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py,1,['hash'],['hashing']
Security,"""""""Called unconditionally when accessing an instance attribute""""""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_stacked_violin.py:31,access,accessing,31,src/scanpy/plotting/_stacked_violin.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_stacked_violin.py,1,['access'],['accessing']
Security,"""""""Convenience class for accessing neighbors graph representations. Allows to access neighbors distances, connectivities and settings; dictionary in a uniform manner. Parameters; ----------. adata; AnnData object.; key; This defines where to look for neighbors dictionary,; connectivities, distances. neigh = NeighborsView(adata, key); neigh['distances']; neigh['connectivities']; neigh['params']; 'connectivities' in neigh; 'params' in neigh. is the same as. adata.obsp[adata.uns[key]['distances_key']]; adata.obsp[adata.uns[key]['connectivities_key']]; adata.uns[key]['params']; adata.uns[key]['connectivities_key'] in adata.obsp; 'params' in adata.uns[key]; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/__init__.py:25,access,accessing,25,src/scanpy/_utils/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/__init__.py,2,['access'],"['access', 'accessing']"
Security,"""""""Current git reference. Uses branch/tag name if found, otherwise uses commit hash""""""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/docs/extensions/git_ref.py:79,hash,hash,79,docs/extensions/git_ref.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/docs/extensions/git_ref.py,1,['hash'],['hash']
Security,"""""""Extension to inject ``html_theme_options[""repository_branch""]``.""""""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/docs/extensions/git_ref.py:16,inject,inject,16,docs/extensions/git_ref.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/docs/extensions/git_ref.py,1,['inject'],['inject']
Security,"""""""Imports a module in a way that it’s only executed on member access""""""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/__init__.py:63,access,access,63,src/scanpy/_utils/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/__init__.py,1,['access'],['access']
Security,"""""""Probabilistic demultiplexing of cell hashing data using HashSolo :cite:p:`Bernstein2020`. .. note::; More information and bug reports `here <https://github.com/calico/solo>`__. Parameters; ----------; adata; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; cell_hashing_columns; `.obs` columns that contain cell hashing counts.; priors; Prior probabilities of each hypothesis, in; the order `[negative, singlet, doublet]`. The default is set to; `[0.01, 0.8, 0.19]` assuming barcode counts are from cells that; have passed QC in the transcriptome space, e.g. UMI counts, pct; mito reads, etc.; pre_existing_clusters; The column in `.obs` containing pre-existing cluster assignments; (e.g. Leiden clusters or cell types, but not batch assignments).; If provided, demultiplexing will be performed separately for each; cluster.; number_of_noise_barcodes; The number of barcodes used to create the noise distribution.; Defaults to `len(cell_hashing_columns) - 2`.; inplace; Whether to update `adata` in-place or return a copy. Returns; -------; A copy of the input `adata` if `inplace=False`, otherwise the input; `adata`. The following fields are added:. `.obs[""most_likely_hypothesis""]`; Index of the most likely hypothesis, where `0` corresponds to negative,; `1` to singlet, and `2` to doublet.; `.obs[""cluster_feature""]`; The cluster assignments used for demultiplexing.; `.obs[""negative_hypothesis_probability""]`; Probability of the negative hypothesis.; `.obs[""singlet_hypothesis_probability""]`; Probability of the singlet hypothesis.; `.obs[""doublet_hypothesis_probability""]`; Probability of the doublet hypothesis.; `.obs[""Classification""]`:; Classification of the cell, one of the barcodes in `cell_hashing_columns`,; `""Negative""`, or `""Doublet""`. Examples; -------; >>> import anndata; >>> import scanpy.external as sce; >>> adata = anndata.read_h5ad(""data.h5ad""); >>> sce.pp.hashsolo(adata, [""Hash1"", ""Hash2"", ""Hash3""]); >>> adata.ob",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py:40,hash,hashing,40,src/scanpy/external/pp/_hashsolo.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py,3,"['Hash', 'hash']","['HashSolo', 'hashing']"
Security,"""""""Returns a Request object. Allows you to access names of parameterized tests from within a test.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_embedding_plots.py:43,access,access,43,tests/test_embedding_plots.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_embedding_plots.py,1,['access'],['access']
Security,"""""""This module contains helper functions for accessing data.""""""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/get.py:45,access,accessing,45,src/scanpy/get/get.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/get.py,1,['access'],['accessing']
Security,"""""""Update parameters of your gaussian; https://www.cs.ubc.ca/~murphyk/Papers/bayesGauss.pdf. Parameters; ----------; data; 1-d array of counts; mu_o; global mean for hashing count distribution; std_o; global std for hashing count distribution. Returns; -------; mean; of gaussian; std; of gaussian; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py:166,hash,hashing,166,src/scanpy/external/pp/_hashsolo.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py,2,['hash'],['hashing']
Security,"""""""Validation for projection argument.""""""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_utils.py:3,Validat,Validation,3,src/scanpy/plotting/_utils.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_utils.py,1,['Validat'],['Validation']
Security,"""""""\; Load a dataset from the EBI Single Cell Expression Atlas. The atlas_ can be browsed online to find the ``accession`` you want.; Downloaded datasets are saved in the directory specified by; :attr:`~scanpy._settings.ScanpyConfig.datasetdir`. .. _atlas: https://www.ebi.ac.uk/gxa/sc/experiments. Params; ------; accession; Dataset accession. Like ``E-GEOD-98816`` or ``E-MTAB-4888``.; This can be found in the url on the datasets page, for example E-GEOD-98816_. .. _E-GEOD-98816: https://www.ebi.ac.uk/gxa/sc/experiments/E-GEOD-98816/results/tsne; filter_boring; Whether boring labels in `.obs` should be automatically removed, such as; labels with a single or :attr:`~anndata.AnnData.n_obs` distinct values. Returns; -------; Annotated data matrix. Example; -------; >>> import scanpy as sc; >>> sc.datasets.ebi_expression_atlas(""E-MTAB-4888"") # doctest: +ELLIPSIS; AnnData object with n_obs × n_vars = 2261 × 23899; obs: 'Sample Characteristic[organism]', 'Sample Characteristic Ontology Term[organism]', ..., 'Factor Value[cell type]', 'Factor Value Ontology Term[cell type]'; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_ebi_expression_atlas.py:111,access,accession,111,src/scanpy/datasets/_ebi_expression_atlas.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_ebi_expression_atlas.py,3,['access'],['accession']
Security,"""""""\; PHATE :cite:p:`Moon2019`. Potential of Heat-diffusion for Affinity-based Trajectory Embedding (PHATE); embeds high dimensional single-cell data into two or three dimensions for; visualization of biological progressions. For more information and access to the object-oriented interface, read the; `PHATE documentation <https://phate.readthedocs.io/>`__. For; tutorials, bug reports, and R/MATLAB implementations, visit the `PHATE; GitHub page <https://github.com/KrishnaswamyLab/PHATE/>`__. For help; using PHATE, go `here <https://krishnaswamylab.org/get-help>`__. Parameters; ----------; adata; Annotated data matrix.; n_components; number of dimensions in which the data will be embedded; k; number of nearest neighbors on which to build kernel; a; sets decay rate of kernel tails.; If None, alpha decaying kernel is not used; n_landmark; number of landmarks to use in fast PHATE; t; power to which the diffusion operator is powered; sets the level of diffusion. If 'auto', t is selected; according to the knee point in the Von Neumann Entropy of; the diffusion operator; gamma; Informational distance constant between -1 and 1.; `gamma=1` gives the PHATE log potential, `gamma=0` gives; a square root potential.; n_pca; Number of principal components to use for calculating; neighborhoods. For extremely large datasets, using; n_pca < 20 allows neighborhoods to be calculated in; log(n_samples) time.; knn_dist; recommended values: 'euclidean' and 'cosine'; Any metric from `scipy.spatial.distance` can be used; distance metric for building kNN graph; mds_dist; recommended values: 'euclidean' and 'cosine'; Any metric from `scipy.spatial.distance` can be used; distance metric for MDS; mds; Selects which MDS algorithm is used for dimensionality reduction.; n_jobs; The number of jobs to use for the computation.; If `None`, `sc.settings.n_jobs` is used.; If -1 all CPUs are used. If 1 is given, no parallel computing code is; used at all, which is useful for debugging.; For n_jobs below -1",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phate.py:251,access,access,251,src/scanpy/external/tl/_phate.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phate.py,1,['access'],['access']
Security,"""""""\; Plot rankings. See, for example, how this is used in pl.pca_loadings. Parameters; ----------; adata; The data.; attr; The attribute of AnnData that contains the score.; keys; The scores to look up an array from the attribute of adata. Returns; -------; Returns matplotlib gridspec with access to the axes.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py:292,access,access,292,src/scanpy/plotting/_anndata.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py,1,['access'],['access']
Security,"""""""\; Unify new mask argument and deprecated use_highly_varible argument. Returns both the normalized mask parameter and the validated mask array.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py:125,validat,validated,125,src/scanpy/preprocessing/_pca.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py,1,['validat'],['validated']
Security,"""""""\; Violin plot. Wraps :func:`seaborn.violinplot` for :class:`~anndata.AnnData`. Parameters; ----------; adata; Annotated data matrix.; keys; Keys for accessing variables of `.var_names` or fields of `.obs`.; groupby; The key of the observation grouping to consider.; log; Plot on logarithmic axis.; use_raw; Whether to use `raw` attribute of `adata`. Defaults to `True` if `.raw` is present.; stripplot; Add a stripplot on top of the violin plot.; See :func:`~seaborn.stripplot`.; jitter; Add jitter to the stripplot (only when stripplot is True); See :func:`~seaborn.stripplot`.; size; Size of the jitter points.; layer; Name of the AnnData object layer that wants to be plotted. By; default adata.raw.X is plotted. If `use_raw=False` is set,; then `adata.X` is plotted. If `layer` is set to a valid layer name,; then the layer is plotted. `layer` takes precedence over `use_raw`.; scale; The method used to scale the width of each violin.; If 'width' (the default), each violin will have the same width.; If 'area', each violin will have the same area.; If 'count', a violin’s width corresponds to the number of observations.; order; Order in which to show the categories.; multi_panel; Display keys in multiple panels also when `groupby is not None`.; xlabel; Label of the x axis. Defaults to `groupby` if `rotation` is `None`,; otherwise, no label is shown.; ylabel; Label of the y axis. If `None` and `groupby` is `None`, defaults; to `'value'`. If `None` and `groubpy` is not `None`, defaults to `keys`.; rotation; Rotation of xtick labels.; {show_save_ax}; **kwds; Are passed to :func:`~seaborn.violinplot`. Returns; -------; A :class:`~matplotlib.axes.Axes` object if `ax` is `None` else `None`. Examples; --------. .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); sc.pl.violin(adata, keys='S_score'). Plot by category. Rotate x-axis labels so that they do not overlap. .. plot::; :context: close-figs. sc.pl.violin(adata, keys='S_score', groupby",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py:153,access,accessing,153,src/scanpy/plotting/_anndata.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py,1,['access'],['accessing']
Security,"# (if no name found or relative ref, use commit hash instead)",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/docs/extensions/git_ref.py:48,hash,hash,48,docs/extensions/git_ref.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/docs/extensions/git_ref.py,1,['hash'],['hash']
Security,"# If the user has set the deprecated version on the class,; # and our code accesses the new version from the instance,; # return the user-specified version instead and warn.; # This is done because class properties are hard to do.",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_stacked_violin.py:75,access,accesses,75,src/scanpy/plotting/_stacked_violin.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_stacked_violin.py,1,['access'],['accesses']
Security,"# TODO: Allow for sample weighting requires better mask access... later; # We store calculated data in dict, access it via dict to dict. Check if this is the best way.",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_top_genes.py:56,access,access,56,src/scanpy/tools/_top_genes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_top_genes.py,2,['access'],['access']
Security,"# This line just makes group_mask access easier. Nothing else but 'all' will stand here.",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_top_genes.py:34,access,access,34,src/scanpy/tools/_top_genes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_top_genes.py,1,['access'],['access']
Security,"# This tool serves to; # It is not thought to be addressed directly but rather using rank_genes_group or ROC analysis or comparable; # TODO: Pass back a truncated adata object with only those genes that fullfill thresholding criterias; # This function should be accessible by both rank_genes_groups and ROC_curve analysis",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_top_genes.py:262,access,accessible,262,src/scanpy/tools/_top_genes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_top_genes.py,1,['access'],['accessible']
Security,"# Validate `knn`",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/__init__.py:2,Validat,Validate,2,src/scanpy/neighbors/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/__init__.py,1,['Validat'],['Validate']
Security,"ic demultiplexing of cell hashing data using HashSolo :cite:p:`Bernstein2020`. .. note::; More information and bug reports `here <https://github.com/calico/solo>`__. Parameters; ----------; adata; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; cell_hashing_columns; `.obs` columns that contain cell hashing counts.; priors; Prior probabilities of each hypothesis, in; the order `[negative, singlet, doublet]`. The default is set to; `[0.01, 0.8, 0.19]` assuming barcode counts are from cells that; have passed QC in the transcriptome space, e.g. UMI counts, pct; mito reads, etc.; pre_existing_clusters; The column in `.obs` containing pre-existing cluster assignments; (e.g. Leiden clusters or cell types, but not batch assignments).; If provided, demultiplexing will be performed separately for each; cluster.; number_of_noise_barcodes; The number of barcodes used to create the noise distribution.; Defaults to `len(cell_hashing_columns) - 2`.; inplace; Whether to update `adata` in-place or return a copy. Returns; -------; A copy of the input `adata` if `inplace=False`, otherwise the input; `adata`. The following fields are added:. `.obs[""most_likely_hypothesis""]`; Index of the most likely hypothesis, where `0` corresponds to negative,; `1` to singlet, and `2` to doublet.; `.obs[""cluster_feature""]`; The cluster assignments used for demultiplexing.; `.obs[""negative_hypothesis_probability""]`; Probability of the negative hypothesis.; `.obs[""singlet_hypothesis_probability""]`; Probability of the singlet hypothesis.; `.obs[""doublet_hypothesis_probability""]`; Probability of the doublet hypothesis.; `.obs[""Classification""]`:; Classification of the cell, one of the barcodes in `cell_hashing_columns`,; `""Negative""`, or `""Doublet""`. Examples; -------; >>> import anndata; >>> import scanpy.external as sce; >>> adata = anndata.read_h5ad(""data.h5ad""); >>> sce.pp.hashsolo(adata, [""Hash1"", ""Hash2"", ""Hash3""]); >>> adata.obs.head(); """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py:1943,hash,hashsolo,1943,src/scanpy/external/pp/_hashsolo.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py,1,['hash'],['hashsolo']
Security,"ighbors` instead.; metric; A known metric’s name or a callable that returns a distance. *ignored if ``transformer`` is an instance.*; metric_kwds; Options for the metric. *ignored if ``transformer`` is an instance.*; random_state; A numpy random seed. *ignored if ``transformer`` is an instance.*; key_added; If not specified, the neighbors data is stored in `.uns['neighbors']`,; distances and connectivities are stored in `.obsp['distances']` and; `.obsp['connectivities']` respectively.; If specified, the neighbors data is added to .uns[key_added],; distances are stored in `.obsp[key_added+'_distances']` and; connectivities in `.obsp[key_added+'_connectivities']`.; copy; Return a copy instead of writing to adata. Returns; -------; Returns `None` if `copy=False`, else returns an `AnnData` object. Sets the following fields:. `adata.obsp['distances' | key_added+'_distances']` : :class:`scipy.sparse.csr_matrix` (dtype `float`); Distance matrix of the nearest neighbors search. Each row (cell) has `n_neighbors`-1 non-zero entries. These are the distances to their `n_neighbors`-1 nearest neighbors (excluding the cell itself).; `adata.obsp['connectivities' | key_added+'_connectivities']` : :class:`scipy.sparse._csr.csr_matrix` (dtype `float`); Weighted adjacency matrix of the neighborhood graph of data; points. Weights should be interpreted as connectivities.; `adata.uns['neighbors' | key_added]` : :class:`dict`; neighbors parameters. Examples; --------; >>> import scanpy as sc; >>> adata = sc.datasets.pbmc68k_reduced(); >>> # Basic usage; >>> sc.pp.neighbors(adata, 20, metric='cosine'); >>> # Provide your own transformer for more control and flexibility; >>> from sklearn.neighbors import KNeighborsTransformer; >>> transformer = KNeighborsTransformer(n_neighbors=10, metric='manhattan', algorithm='kd_tree'); >>> sc.pp.neighbors(adata, transformer=transformer); >>> # now you can e.g. access the index: `transformer._tree`. See also; --------; :doc:`/how-to/knn-transformers`; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/__init__.py:3992,access,access,3992,src/scanpy/neighbors/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/__init__.py,1,['access'],['access']
Security,"rmalize_per_cell` function in Scanpy and saved into adata; object. Mean layer is re-introduces library size differences by; scaling the mean value of each cell in the output layer. See the; manuscript for more details.; scale; If true, the input of the autoencoder is centered using; `sc.pp.scale` function of Scanpy. Note that the output is kept as raw; counts as loss functions are designed for the count data.; log1p; If true, the input of the autoencoder is log transformed with a; pseudocount of one using `sc.pp.log1p` function of Scanpy.; hidden_size; Width of hidden layers.; hidden_dropout; Probability of weight dropout in the autoencoder (per layer if list; or tuple).; batchnorm; If true, batch normalization is performed.; activation; Activation function of hidden layers.; init; Initialization method used to initialize weights.; network_kwds; Additional keyword arguments for the autoencoder.; epochs; Number of total epochs in training.; reduce_lr; Reduces learning rate if validation loss does not improve in given number of epochs.; early_stop; Stops training if validation loss does not improve in given number of epochs.; batch_size; Number of samples in the batch used for SGD.; optimizer; Type of optimization method used for training.; random_state; Seed for python, numpy and tensorflow.; threads; Number of threads to use in training. All cores are used by default.; learning_rate; Learning rate to use in the training.; verbose; If true, prints additional information about training and architecture.; training_kwds; Additional keyword arguments for the training process.; return_model; If true, trained autoencoder object is returned. See ""Returns"".; return_info; If true, all additional parameters of DCA are stored in `adata.obsm` such as dropout; probabilities (obsm['X_dca_dropout']) and estimated dispersion values; (obsm['X_dca_dispersion']), in case that autoencoder is of type; zinb or zinb-conddisp.; copy; If true, a copy of anndata is returned. Returns; -------; ",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_dca.py:1992,validat,validation,1992,src/scanpy/external/pp/_dca.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_dca.py,1,['validat'],['validation']
Testability," -------; Returns `None` if `copy=False`, else returns an `AnnData` object. Sets the following fields:. `adata.uns['rank_genes_groups' | key_added]['names']` : structured :class:`numpy.ndarray` (dtype `object`); Structured array to be indexed by group id storing the gene; names. Ordered according to scores.; `adata.uns['rank_genes_groups' | key_added]['scores']` : structured :class:`numpy.ndarray` (dtype `object`); Structured array to be indexed by group id storing the z-score; underlying the computation of a p-value for each gene for each; group. Ordered according to scores.; `adata.uns['rank_genes_groups' | key_added]['logfoldchanges']` : structured :class:`numpy.ndarray` (dtype `object`); Structured array to be indexed by group id storing the log2; fold change for each gene for each group. Ordered according to; scores. Only provided if method is 't-test' like.; Note: this is an approximation calculated from mean-log values.; `adata.uns['rank_genes_groups' | key_added]['pvals']` : structured :class:`numpy.ndarray` (dtype `float`); p-values.; `adata.uns['rank_genes_groups' | key_added]['pvals_adj']` : structured :class:`numpy.ndarray` (dtype `float`); Corrected p-values.; `adata.uns['rank_genes_groups' | key_added]['pts']` : :class:`pandas.DataFrame` (dtype `float`); Fraction of cells expressing the genes for each group.; `adata.uns['rank_genes_groups' | key_added]['pts_rest']` : :class:`pandas.DataFrame` (dtype `float`); Only if `reference` is set to `'rest'`.; Fraction of cells from the union of the rest of each group; expressing the genes. Notes; -----; There are slight inconsistencies depending on whether sparse; or dense data are passed. See `here <https://github.com/scverse/scanpy/blob/main/scanpy/tests/test_rank_genes_groups.py>`__. Examples; --------; >>> import scanpy as sc; >>> adata = sc.datasets.pbmc68k_reduced(); >>> sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'); >>> # to visualize the results; >>> sc.pl.rank_genes_groups(adata); """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py:3810,test,tests,3810,src/scanpy/tools/_rank_genes_groups.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py,1,['test'],['tests']
Testability," SAM.; `.uns['neighbors']`; A dictionary with key 'connectivities' containing the kNN adjacency; matrix output by SAM. If built-in scanpy dimensionality reduction; methods are to be used using the SAM-output AnnData, users; should recompute the neighbors using `.obs['X_pca']` with; `scanpy.pp.neighbors`.; `.obsm['X_pca']`; The principal components output by SAM.; `.obsm['X_umap']`; The UMAP projection output by SAM.; `.layers['X_disp']`; The expression matrix used for nearest-neighbor averaging.; `.layers['X_knn_avg']`; The nearest-neighbor-averaged expression data used for computing the; spatial dispersions of genes. Example; -------; >>> import scanpy.external as sce; >>> import scanpy as sc. *** Running SAM ***. Assuming we are given an AnnData object called `adata`, we can run the SAM; algorithm as follows:. >>> sam_obj = sce.tl.sam(adata,inplace=True). The input AnnData object should contain unstandardized, non-negative; expression values. Preferably, the data should be log-normalized and no; genes should be filtered out. Please see the documentation for a description of all available parameters. For more detailed tutorials, please visit the original Github repository:; https://github.com/atarashansky/self-assembling-manifold/tree/master/tutorial. *** Plotting ***. To visualize the output, we can use:. >>> sce.pl.sam(adata,projection='X_umap'). `sce.pl.sam` accepts all keyword arguments used in the; `matplotlib.pyplot.scatter` function. *** SAMGUI ***. SAM comes with the SAMGUI module, a graphical-user interface written with; `Plotly` and `ipythonwidgets` for interactively exploring and annotating; the scRNAseq data and running SAM. Dependencies can be installed with Anaconda by following the instructions in; the self-assembling-manifold Github README:; https://github.com/atarashansky/self-assembling-manifold. In a Jupyter notebook, execute the following to launch the interface:. >>> from samalg.gui import SAMGUI; >>> sam_gui = SAMGUI(sam_obj) # sam_obj is your",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_sam.py:4374,log,log-normalized,4374,src/scanpy/external/tl/_sam.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_sam.py,1,['log'],['log-normalized']
Testability," for; visualization of biological progressions. For more information and access to the object-oriented interface, read the; `PHATE documentation <https://phate.readthedocs.io/>`__. For; tutorials, bug reports, and R/MATLAB implementations, visit the `PHATE; GitHub page <https://github.com/KrishnaswamyLab/PHATE/>`__. For help; using PHATE, go `here <https://krishnaswamylab.org/get-help>`__. Parameters; ----------; adata; Annotated data matrix.; n_components; number of dimensions in which the data will be embedded; k; number of nearest neighbors on which to build kernel; a; sets decay rate of kernel tails.; If None, alpha decaying kernel is not used; n_landmark; number of landmarks to use in fast PHATE; t; power to which the diffusion operator is powered; sets the level of diffusion. If 'auto', t is selected; according to the knee point in the Von Neumann Entropy of; the diffusion operator; gamma; Informational distance constant between -1 and 1.; `gamma=1` gives the PHATE log potential, `gamma=0` gives; a square root potential.; n_pca; Number of principal components to use for calculating; neighborhoods. For extremely large datasets, using; n_pca < 20 allows neighborhoods to be calculated in; log(n_samples) time.; knn_dist; recommended values: 'euclidean' and 'cosine'; Any metric from `scipy.spatial.distance` can be used; distance metric for building kNN graph; mds_dist; recommended values: 'euclidean' and 'cosine'; Any metric from `scipy.spatial.distance` can be used; distance metric for MDS; mds; Selects which MDS algorithm is used for dimensionality reduction.; n_jobs; The number of jobs to use for the computation.; If `None`, `sc.settings.n_jobs` is used.; If -1 all CPUs are used. If 1 is given, no parallel computing code is; used at all, which is useful for debugging.; For n_jobs below -1, (n_cpus + 1 + n_jobs) are used. Thus for; n_jobs = -2, all CPUs but one are used; random_state; Random seed. Defaults to the global `numpy` random number generator; verbose; I",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phate.py:1164,log,log,1164,src/scanpy/external/tl/_phate.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phate.py,1,['log'],['log']
Testability,"""""""; Calculate bayes rule from log likelihoods. Parameters; ----------; data; Anndata object filled only with hashing counts; priors; a list of your prior for each hypothesis; first element is your prior for the negative hypothesis; second element is your prior for the singlet hypothesis; third element is your prior for the doublet hypothesis; We use [0.01, 0.8, 0.19] by default because we assume the barcodes; in your cell hashing matrix are those cells which have passed QC; in the transcriptome space, e.g. UMI counts, pct mito reads, etc.; number_of_noise_barcodes; number of barcodes to used to calculated noise distribution. Returns; -------; A dict of bayes key results with the following entries:. `""most_likely_hypothesis""`; A 1d np.array of the most likely hypothesis; `""probs_hypotheses""`; A 2d np.array probability of each hypothesis; `""log_likelihoods_for_each_hypothesis""`; A 2d np.array log likelihood of each hypothesis; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py:31,log,log,31,src/scanpy/external/pp/_hashsolo.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py,2,['log'],['log']
Testability,"""""""; Given the anndata object, prepares a data frame in which the row index are the categories; defined by group by and the columns correspond to var_names. Parameters; ----------; adata; Annotated data matrix.; var_names; `var_names` should be a valid subset of `adata.var_names`.; groupby; The key of the observation grouping to consider. It is expected that; groupby is a categorical. If groupby is not a categorical observation,; it would be subdivided into `num_categories`.; use_raw; Whether to use `raw` attribute of `adata`. Defaults to `True` if `.raw` is present.; log; Use the log of the values.; layer; AnnData layer to use. Takes precedence over `use_raw`; num_categories; Only used if groupby observation is not categorical. This value; determines the number of groups into which the groupby observation; should be subdivided.; gene_symbols; Key for field in .var that stores gene symbols. Returns; -------; Tuple of `pandas.DataFrame` and list of categories.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py:575,log,log,575,src/scanpy/plotting/_anndata.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py,2,['log'],['log']
Testability,"""""""; HashSolo script provides a probabilistic cell hashing demultiplexing method; which generates a noise distribution and signal distribution for; each hashing barcode from empirically observed counts. These distributions; are updates from the global signal and noise barcode distributions, which; helps in the setting where not many cells are observed. Signal distributions; for a hashing barcode are estimated from samples where that hashing barcode; has the highest count. Noise distributions for a hashing barcode are estimated; from samples where that hashing barcode is one the k-2 lowest barcodes, where; k is the number of barcodes. A doublet should then have its two highest; barcode counts most likely coming from a signal distribution for those barcodes.; A singlet should have its highest barcode from a signal distribution, and its; second highest barcode from a noise distribution. A negative two highest; barcodes should come from noise distributions. We test each of these; hypotheses in a bayesian fashion, and select the most probable hypothesis.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py:971,test,test,971,src/scanpy/external/pp/_hashsolo.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py,1,['test'],['test']
Testability,"""""""; If rank_genes_groups has been called, this function; prepares a dataframe containing scores, pvalues, logfoldchange etc to be plotted; as dotplot or matrixplot. The dataframe index are the given groups and the columns are the gene_names. used by rank_genes_groups_dotplot. Parameters; ----------; adata; values_to_plot; name of the value to plot; gene_names; gene names; groups; groupby categories; key; adata.uns key where the rank_genes_groups is stored.; By default 'rank_genes_groups'; gene_symbols; Key for field in .var that stores gene symbols.; Returns; -------; pandas DataFrame index=groups, columns=gene_names. """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py:107,log,logfoldchange,107,src/scanpy/plotting/_tools/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py,1,['log'],['logfoldchange']
Testability,"""""""; Pytest skip marker evaluated at module import. This allows us to see the amount of skipped tests at the start of a test run.; :func:`pytest.importorskip` skips tests after they started running.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/testing/scanpy/_pytest/marks.py:96,test,tests,96,src/testing/scanpy/_pytest/marks.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/testing/scanpy/_pytest/marks.py,3,['test'],"['test', 'tests']"
Testability,"""""""; See https://github.com/scverse/scanpy/issues/1590; But this is also a more general test; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py:88,test,test,88,tests/test_pca.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py,1,['test'],['test']
Testability,"""""""; Test if pca result is equal without highly variable and with-but mask is None; and if pca takes highly variable as mask as default; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py:5,Test,Test,5,tests/test_pca.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py,1,['Test'],['Test']
Testability,"""""""; Test that Harmony integrate works. This is a very simple test that just checks to see if the Harmony; integrate wrapper succesfully added a new field to ``adata.obsm``; and makes sure it has the same dimensions as the original PCA table.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/external/test_harmony_integrate.py:5,Test,Test,5,tests/external/test_harmony_integrate.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/external/test_harmony_integrate.py,2,"['Test', 'test']","['Test', 'test']"
Testability,"""""""; Test that Scanorama integration works. This is a very simple test that just checks to see if the Scanorama; integrate wrapper succesfully added a new field to ``adata.obsm``; and makes sure it has the same dimensions as the original PCA table.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/external/test_scanorama_integrate.py:5,Test,Test,5,tests/external/test_scanorama_integrate.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/external/test_scanorama_integrate.py,2,"['Test', 'test']","['Test', 'test']"
Testability,"""""""; Test that Scrublet args are passed. Check that changes to parameters change scrublet results.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_scrublet.py:5,Test,Test,5,tests/test_scrublet.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_scrublet.py,1,['Test'],['Test']
Testability,"""""""; Test that Scrublet processing is arranged correctly. Check that simulations run on raw data.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_scrublet.py:5,Test,Test,5,tests/test_scrublet.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_scrublet.py,1,['Test'],['Test']
Testability,"""""""; Test that it doesn't matter where the array being scaled is in the anndata object.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_preprocessing.py:5,Test,Test,5,tests/test_preprocessing.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_preprocessing.py,1,['Test'],['Test']
Testability,"""""""; Test that running sc.pp.scale on an anndata object and an array returns the same results.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_preprocessing.py:5,Test,Test,5,tests/test_preprocessing.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_preprocessing.py,1,['Test'],['Test']
Testability,"""""""; Test to make sure I can predict when scatter reps should be the same; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:5,Test,Test,5,tests/test_plotting.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py,1,['Test'],['Test']
Testability,"""""""; Tests that implicitly centered pca on sparse arrays returns equivalent results to; explicit centering on dense arrays.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py:5,Test,Tests,5,tests/test_pca.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py,1,['Test'],['Tests']
Testability,"""""""; Tests that layers works the same way as .X; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py:5,Test,Tests,5,tests/test_pca.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py,1,['Test'],['Tests']
Testability,"""""""; Tests that manually passing values to sc.pl.spatial is similar to automatic extraction.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_embedding_plots.py:5,Test,Tests,5,tests/test_embedding_plots.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_embedding_plots.py,1,['Test'],['Tests']
Testability,"""""""; Tests that n_comps behaves correctly; See https://github.com/scverse/scanpy/issues/1051; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py:5,Test,Tests,5,tests/test_pca.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py,1,['Test'],['Tests']
Testability,"""""""; Tests that the n_pcs parameter also works for; representations not called ""X_pca""; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py:5,Test,Tests,5,tests/test_pca.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py,1,['Test'],['Tests']
Testability,"""""""; Tests that these functions print to stdout and don't error. Checks that https://github.com/scverse/scanpy/issues/1437 is fixed.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_logging.py:5,Test,Tests,5,tests/test_logging.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_logging.py,1,['Test'],['Tests']
Testability,"""""""; Tests to make sure the example datasets load.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_datasets.py:5,Test,Tests,5,tests/test_datasets.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_datasets.py,1,['Test'],['Tests']
Testability,"""""""; This file contains helper functions for the scanpy test suite.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/testing/scanpy/_helpers/__init__.py:56,test,test,56,src/testing/scanpy/_helpers/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/testing/scanpy/_helpers/__init__.py,1,['test'],['test']
Testability,"""""""; This module will benchmark preprocessing operations in Scanpy that run on counts; API documentation: https://scanpy.readthedocs.io/en/stable/api/preprocessing.html; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/benchmarks/benchmarks/preprocessing_counts.py:22,benchmark,benchmark,22,benchmarks/benchmarks/preprocessing_counts.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/benchmarks/benchmarks/preprocessing_counts.py,1,['benchmark'],['benchmark']
Testability,"""""""; This module will benchmark preprocessing operations in Scanpy that run on log-transformed data; API documentation: https://scanpy.readthedocs.io/en/stable/api/preprocessing.html; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/benchmarks/benchmarks/preprocessing_log.py:22,benchmark,benchmark,22,benchmarks/benchmarks/preprocessing_log.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/benchmarks/benchmarks/preprocessing_log.py,2,"['benchmark', 'log']","['benchmark', 'log-transformed']"
Testability,"""""""; This module will benchmark tool operations in Scanpy; API documentation: https://scanpy.readthedocs.io/en/stable/api/tools.html; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/benchmarks/benchmarks/tools.py:22,benchmark,benchmark,22,benchmarks/benchmarks/tools.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/benchmarks/benchmarks/tools.py,1,['benchmark'],['benchmark']
Testability,"""""""; adata.X is np.ones((2, 2)); adata.layers['double'] is sparse np.ones((2,2)) * 2 to also test sparse matrices; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py:93,test,test,93,tests/test_get.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py,1,['test'],['test']
Testability,"""""""Allow use of scanpy’s logger with caplog""""""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/conftest.py:25,log,logger,25,tests/conftest.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/conftest.py,1,['log'],['logger']
Testability,"""""""Calculate log likelihoods for each hypothesis, negative, singlet, doublet. Parameters; ----------; data; cells by hashing counts matrix; number_of_noise_barcodes; number of barcodes to used to calculated noise distribution. Returns; -------; log_likelihoods_for_each_hypothesis; a 2d np.array log likelihood of each hypothesis; all_indices; counter_to_barcode_combo; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py:13,log,log,13,src/scanpy/external/pp/_hashsolo.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py,2,['log'],['log']
Testability,"""""""Common logic for checking indices for obs_df and var_df.""""""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/get.py:10,log,logic,10,src/scanpy/get/get.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/get.py,1,['log'],['logic']
Testability,"""""""Constructor for anndata that uses dtype of X for test compatibility with older versions of AnnData. Once the minimum version of AnnData is 0.9, this function can be replaced with the default constructor.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/testing/scanpy/_helpers/__init__.py:52,test,test,52,src/testing/scanpy/_helpers/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/testing/scanpy/_helpers/__init__.py,1,['test'],['test']
Testability,"""""""Limit number of threads used per worker when using pytest-xdist. Prevents oversubscription of the CPU when multiple tests with parallel code are; running at once.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/testing/scanpy/_pytest/__init__.py:119,test,tests,119,src/testing/scanpy/_pytest/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/testing/scanpy/_pytest/__init__.py,1,['test'],['tests']
Testability,"""""""Logging and Profiling""""""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/logging.py:3,Log,Logging,3,src/scanpy/logging.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/logging.py,1,['Log'],['Logging']
Testability,"""""""Logging verbosity levels.""""""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_settings.py:3,Log,Logging,3,src/scanpy/_settings.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_settings.py,1,['Log'],['Logging']
Testability,"""""""Plot dispersions or normalized variance versus means for genes. Produces Supp. Fig. 5c of Zheng et al. (2017) and MeanVarPlot() and; VariableFeaturePlot() of Seurat. Parameters; ----------; adata; Result of :func:`~scanpy.pp.highly_variable_genes`.; log; Plot on logarithmic axes.; show; Show the plot, do not return axis.; save; If `True` or a `str`, save the figure.; A string is appended to the default filename.; Infer the filetype if ending on {{`'.pdf'`, `'.png'`, `'.svg'`}}.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_preprocessing.py:253,log,log,253,src/scanpy/plotting/_preprocessing.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_preprocessing.py,2,['log'],"['log', 'logarithmic']"
Testability,"""""""Remove handlers from all loggers on session teardown. Fixes <https://github.com/scverse/scanpy/issues/1736>.; See also <https://github.com/pytest-dev/pytest/issues/5502>.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/conftest.py:28,log,loggers,28,tests/conftest.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/conftest.py,1,['log'],['loggers']
Testability,"""""""Returns a Request object. Allows you to access names of parameterized tests from within a test.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_embedding_plots.py:73,test,tests,73,tests/test_embedding_plots.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_embedding_plots.py,2,['test'],"['test', 'tests']"
Testability,"""""""Setup global variables before each benchmark.""""""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/benchmarks/benchmarks/preprocessing_counts.py:38,benchmark,benchmark,38,benchmarks/benchmarks/preprocessing_counts.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/benchmarks/benchmarks/preprocessing_counts.py,2,['benchmark'],['benchmark']
Testability,"""""""Test checking that read_visium reads the right genome""""""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_read_10x.py:3,Test,Test,3,tests/test_read_10x.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_read_10x.py,1,['Test'],['Test']
Testability,"""""""Test if pca result is equal when given mask as boolarray vs string""""""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py:3,Test,Test,3,tests/test_pca.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py,1,['Test'],['Test']
Testability,"""""""Test scatterplot of per-obs points with no basis""""""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:3,Test,Test,3,tests/test_plotting.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py,1,['Test'],['Test']
Testability,"""""""Test scatterplot of per-var points with no basis""""""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:3,Test,Test,3,tests/test_plotting.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py,1,['Test'],['Test']
Testability,"""""""Test scatterplots of raw layer with no basis.""""""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:3,Test,Test,3,tests/test_plotting.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py,1,['Test'],['Test']
Testability,"""""""Test that Scrublet run works with batched data.""""""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_scrublet.py:3,Test,Test,3,tests/test_scrublet.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_scrublet.py,1,['Test'],['Test']
Testability,"""""""Test that `scatter()` raises `ValueError` where appropriate. If `sc.pl.scatter()` receives variable labels that either cannot be; found or are incompatible with one another, the function should; raise a `ValueError`. This test checks that this happens as; expected.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:3,Test,Test,3,tests/test_plotting.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py,2,"['Test', 'test']","['Test', 'test']"
Testability,"""""""Test that changing the dataset dir doesn't break reading.""""""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_datasets.py:3,Test,Test,3,tests/test_datasets.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_datasets.py,1,['Test'],['Test']
Testability,"""""""Test that image download works and is does not have global effects.""""""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_datasets.py:3,Test,Test,3,tests/test_datasets.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_datasets.py,1,['Test'],['Test']
Testability,"""""""Tests that reading/ downloading works and is does not have global effects.""""""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_datasets.py:3,Test,Tests,3,tests/test_datasets.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_datasets.py,1,['Test'],['Tests']
Testability,"""""""Tests that, with `n_top_genes=None` the returned dataframe has the expected columns.""""""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_highly_variable_genes.py:3,Test,Tests,3,tests/test_highly_variable_genes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_highly_variable_genes.py,1,['Test'],['Tests']
Testability,"""""""Tests that, with `n_top_genes=n`; - `inplace` and `subset` interact correctly; - for both the `seurat` and `cell_ranger` flavors; - for dask arrays and non-dask arrays; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_highly_variable_genes.py:3,Test,Tests,3,tests/test_highly_variable_genes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_highly_variable_genes.py,1,['Test'],['Tests']
Testability,"""""""This file contains some common fixtures for use in tests. This is kept seperate from the helpers file because it relies on pytest.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/testing/scanpy/_pytest/fixtures/__init__.py:54,test,tests,54,src/testing/scanpy/_pytest/fixtures/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/testing/scanpy/_pytest/fixtures/__init__.py,1,['test'],['tests']
Testability,"""""""Transition matrix (sparse matrix). Is conjugate to the symmetrized transition matrix via::. self.transitions = self.Z * self.transitions_sym / self.Z. where ``self.Z`` is the diagonal matrix storing the normalization of the; underlying kernel matrix. Notes; -----; This has not been tested, in contrast to `transitions_sym`.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/__init__.py:286,test,tested,286,src/scanpy/neighbors/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/__init__.py,1,['test'],['tested']
Testability,"""""""\; :func:`scanpy.tl.rank_genes_groups` results in the form of a; :class:`~pandas.DataFrame`. Params; ------; adata; Object to get results from.; group; Which group (as in :func:`scanpy.tl.rank_genes_groups`'s `groupby`; argument) to return results from. Can be a list. All groups are; returned if groups is `None`.; key; Key differential expression groups were stored under.; pval_cutoff; Return only adjusted p-values below the cutoff.; log2fc_min; Minimum logfc to return.; log2fc_max; Maximum logfc to return.; gene_symbols; Column name in `.var` DataFrame that stores gene symbols. Specifying; this will add that column to the returned dataframe. Example; -------; >>> import scanpy as sc; >>> pbmc = sc.datasets.pbmc68k_reduced(); >>> sc.tl.rank_genes_groups(pbmc, groupby=""louvain"", use_raw=True); >>> dedf = sc.get.rank_genes_groups_df(pbmc, group=""0""); """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/get.py:461,log,logfc,461,src/scanpy/get/get.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/get/get.py,2,['log'],['logfc']
Testability,"""""""\; Annotate highly variable genes :cite:p:`Satija2015,Zheng2017,Stuart2019`. Expects logarithmized data, except when `flavor='seurat_v3'`/`'seurat_v3_paper'`, in which count; data is expected. Depending on `flavor`, this reproduces the R-implementations of Seurat; :cite:p:`Satija2015`, Cell Ranger :cite:p:`Zheng2017`, and Seurat v3 :cite:p:`Stuart2019`. `'seurat_v3'`/`'seurat_v3_paper'` requires `scikit-misc` package. If you plan to use this flavor, consider; installing `scanpy` with this optional dependency: `scanpy[skmisc]`. For the dispersion-based methods (`flavor='seurat'` :cite:t:`Satija2015` and; `flavor='cell_ranger'` :cite:t:`Zheng2017`), the normalized dispersion is obtained; by scaling with the mean and standard deviation of the dispersions for genes; falling into a given bin for mean expression of genes. This means that for each; bin of mean expression, highly variable genes are selected. For `flavor='seurat_v3'`/`'seurat_v3_paper'` :cite:p:`Stuart2019`, a normalized variance for each gene; is computed. First, the data are standardized (i.e., z-score normalization; per feature) with a regularized standard deviation. Next, the normalized variance; is computed as the variance of each gene after the transformation. Genes are ranked; by the normalized variance.; Only if `batch_key` is not `None`, the two flavors differ: For `flavor='seurat_v3'`, genes are first sorted by the median (across batches) rank, with ties broken by the number of batches a gene is a HVG.; For `flavor='seurat_v3_paper'`, genes are first sorted by the number of batches a gene is a HVG, with ties broken by the median (across batches) rank. The following may help when comparing to Seurat's naming:; If `batch_key=None` and `flavor='seurat'`, this mimics Seurat's `FindVariableFeatures(…, method='mean.var.plot')`.; If `batch_key=None` and `flavor='seurat_v3'`/`flavor='seurat_v3_paper'`, this mimics Seurat's `FindVariableFeatures(..., method='vst')`.; If `batch_key` is not `None` and `flav",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py:88,log,logarithmized,88,src/scanpy/preprocessing/_highly_variable_genes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py,1,['log'],['logarithmized']
Testability,"""""""\; Call trancriptomes as doublets or singlets. Arguments; ---------; threshold; Doublet score threshold for calling a transcriptome; a doublet. If `None`, this is set automatically by looking; for the minimum between the two modes of the `doublet_scores_sim_`; histogram. It is best practice to check the threshold visually; using the `doublet_scores_sim_` histogram and/or based on; co-localization of predicted doublets in a 2-D embedding. verbose; If True, log summary statistics. Sets; ----; predicted_doublets_, z_scores_, threshold_,; detected_doublet_rate_, detectable_doublet_fraction,; overall_doublet_rate_; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/core.py:463,log,log,463,src/scanpy/preprocessing/_scrublet/core.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/core.py,1,['log'],['log']
Testability,"""""""\; Check that mask is applied successfully to data set \; where test statistics are already available (test stats overwritten).; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_rank_genes_groups.py:67,test,test,67,tests/test_rank_genes_groups.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_rank_genes_groups.py,2,['test'],['test']
Testability,"""""""\; Configures dot size and the colorbar legends. Parameters; ----------; show; Set to `False` to hide the default plot of the legends. This sets the; legend width to zero, which will result in a wider main plot.; show_size_legend; Set to `False` to hide the dot size legend; show_colorbar; Set to `False` to hide the colorbar legend; size_title; Title for the dot size legend. Use '\\n' to add line breaks. Appears on top; of dot sizes; colorbar_title; Title for the color bar. Use '\\n' to add line breaks. Appears on top of the; color bar; width; Width of the legends area. The unit is the same as in matplotlib (inches). Returns; -------; :class:`~scanpy.pl.DotPlot`. Examples; --------. Set color bar title:. >>> import scanpy as sc; >>> adata = sc.datasets.pbmc68k_reduced(); >>> markers = {'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}; >>> dp = sc.pl.DotPlot(adata, markers, groupby='bulk_labels'); >>> dp.legend(colorbar_title='log(UMI counts + 1)').show(); """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_dotplot.py:949,log,log,949,src/scanpy/plotting/_dotplot.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_dotplot.py,1,['log'],['log']
Testability,"""""""\; Correct batch effects by matching mutual nearest neighbors :cite:p:`Haghverdi2018` :cite:p:`Kang2018`. This uses the implementation of mnnpy_ :cite:p:`Kang2018`. Depending on `do_concatenate`, returns matrices or `AnnData` objects in the; original order containing corrected expression values or a concatenated; matrix or AnnData object. Be reminded that it is not advised to use the corrected data matrices for; differential expression testing. More information and bug reports `here <mnnpy>`__. .. _mnnpy: https://github.com/chriscainx/mnnpy. Parameters; ----------; datas; Expression matrices or AnnData objects. Matrices should be shaped like; n_obs × n_vars (n_cell × n_gene) and have consistent number of columns.; AnnData objects should have same number of variables.; var_index; The index (list of str) of vars (genes). Necessary when using only a; subset of vars to perform MNN correction, and should be supplied with; `var_subset`. When `datas` are AnnData objects, `var_index` is ignored.; var_subset; The subset of vars (list of str) to be used when performing MNN; correction. Typically, a list of highly variable genes (HVGs).; When set to `None`, uses all vars.; batch_key; The `batch_key` for :meth:`~anndata.AnnData.concatenate`.; Only valid when `do_concatenate` and supplying `AnnData` objects.; index_unique; The `index_unique` for :meth:`~anndata.AnnData.concatenate`.; Only valid when `do_concatenate` and supplying `AnnData` objects.; batch_categories; The `batch_categories` for :meth:`~anndata.AnnData.concatenate`.; Only valid when `do_concatenate` and supplying AnnData objects.; k; Number of mutual nearest neighbors.; sigma; The bandwidth of the Gaussian smoothing kernel used to compute the; correction vectors. Default is 1.; cos_norm_in; Whether cosine normalization should be performed on the input data prior; to calculating distances between cells.; cos_norm_out; Whether cosine normalization should be performed prior to computing corrected expression values.",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_mnn_correct.py:443,test,testing,443,src/scanpy/external/pp/_mnn_correct.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_mnn_correct.py,1,['test'],['testing']
Testability,"""""""\; Development of Myeloid Progenitors :cite:p:`Paul2015`. Non-logarithmized raw data. The data has been sent out by Email from the Amit Lab. An R version for; loading the data can be found `here; <https://github.com/theislab/scAnalysisTutorial>`_. Returns; -------; Annotated data matrix. Examples; --------; >>> import scanpy as sc; >>> sc.datasets.paul15(); AnnData object with n_obs × n_vars = 2730 × 3451; obs: 'paul15_clusters'; uns: 'iroot'; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py:65,log,logarithmized,65,src/scanpy/datasets/_datasets.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py,1,['log'],['logarithmized']
Testability,"""""""\; Extract highly variable genes :cite:p:`Satija2015,Zheng2017`. .. warning::; .. deprecated:: 1.3.6; Use :func:`~scanpy.pp.highly_variable_genes`; instead. The new function is equivalent to the present; function, except that. * the new function always expects logarithmized data; * `subset=False` in the new function, it suffices to; merely annotate the genes, tools like `pp.pca` will; detect the annotation; * you can now call: `sc.pl.highly_variable_genes(adata)`; * `copy` is replaced by `inplace`. If trying out parameters, pass the data matrix instead of AnnData. Depending on `flavor`, this reproduces the R-implementations of Seurat; :cite:p:`Satija2015` and Cell Ranger :cite:p:`Zheng2017`. The normalized dispersion is obtained by scaling with the mean and standard; deviation of the dispersions for genes falling into a given bin for mean; expression of genes. This means that for each bin of mean expression, highly; variable genes are selected. Use `flavor='cell_ranger'` with care and in the same way as in; :func:`~scanpy.pp.recipe_zheng17`. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; flavor; Choose the flavor for computing normalized dispersion. If choosing; 'seurat', this expects non-logarithmized data – the logarithm of mean; and dispersion is taken internally when `log` is at its default value; `True`. For 'cell_ranger', this is usually called for logarithmized data; – in this case you should set `log` to `False`. In their default; workflows, Seurat passes the cutoffs whereas Cell Ranger passes; `n_top_genes`.; min_mean; max_mean; min_disp; max_disp; If `n_top_genes` unequals `None`, these cutoffs for the means and the; normalized dispersions are ignored.; n_bins; Number of bins for binning the mean gene expression. Normalization is; done with respect to each bin. If just a single gene falls into a bin,; the normalized dispersion is artificially set to 1. You'll be info",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py:264,log,logarithmized,264,src/scanpy/preprocessing/_deprecated/highly_variable_genes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py,1,['log'],['logarithmized']
Testability,"""""""\; Filters out genes based on log fold change and fraction of genes expressing the; gene within and outside the `groupby` categories. See :func:`~scanpy.tl.rank_genes_groups`. Results are stored in `adata.uns[key_added]`; (default: 'rank_genes_groups_filtered'). To preserve the original structure of adata.uns['rank_genes_groups'],; filtered genes are set to `NaN`. Parameters; ----------; adata; key; groupby; use_raw; key_added; min_in_group_fraction; min_fold_change; max_out_group_fraction; compare_abs; If `True`, compare absolute values of log fold change with `min_fold_change`. Returns; -------; Same output as :func:`scanpy.tl.rank_genes_groups` but with filtered genes names set to; `nan`. Examples; --------; >>> import scanpy as sc; >>> adata = sc.datasets.pbmc68k_reduced(); >>> sc.tl.rank_genes_groups(adata, 'bulk_labels', method='wilcoxon'); >>> sc.tl.filter_rank_genes_groups(adata, min_fold_change=3); >>> # visualize results; >>> sc.pl.rank_genes_groups(adata, key='rank_genes_groups_filtered'); >>> # visualize results using dotplot; >>> sc.pl.rank_genes_groups_dotplot(adata, key='rank_genes_groups_filtered'); """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py:33,log,log,33,src/scanpy/tools/_rank_genes_groups.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py,2,['log'],['log']
Testability,"""""""\; Fraction of counts assigned to each gene over all cells. Computes, for each gene, the fraction of counts assigned to that gene within; a cell. The `n_top` genes with the highest mean fraction over all cells are; plotted as boxplots. This plot is similar to the `scater` package function `plotHighestExprs(type; = ""highest-expression"")`, see `here; <https://bioconductor.org/packages/devel/bioc/vignettes/scater/inst/doc/vignette-qc.html>`__. Quoting; from there:. *We expect to see the “usual suspects”, i.e., mitochondrial genes, actin,; ribosomal protein, MALAT1. A few spike-in transcripts may also be; present here, though if all of the spike-ins are in the top 50, it; suggests that too much spike-in RNA was added. A large number of; pseudo-genes or predicted genes may indicate problems with alignment.*; -- Davis McCarthy and Aaron Lun. Parameters; ----------; adata; Annotated data matrix.; n_top; Number of top; {show_save_ax}; gene_symbols; Key for field in .var that stores gene symbols if you do not want to use .var_names.; log; Plot x-axis in log scale; **kwds; Are passed to :func:`~seaborn.boxplot`. Returns; -------; If `show==False` a :class:`~matplotlib.axes.Axes`.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_qc.py:1044,log,log,1044,src/scanpy/plotting/_qc.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_qc.py,2,['log'],['log']
Testability,"""""""\; In this type of plot each var_name is plotted as a filled line plot where the; y values correspond to the var_name values and x is each of the cells. Best results; are obtained when using raw counts that are not log. `groupby` is required to sort and order the values using the respective group; and should be a categorical value. Parameters; ----------; {common_plot_args}; {show_save_ax}; **kwds; Are passed to :func:`~seaborn.heatmap`. Returns; -------; A list of :class:`~matplotlib.axes.Axes`. Examples; --------. Using var_names as list:. .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); markers = ['C1QA', 'PSAP', 'CD79A', 'CD79B', 'CST3', 'LYZ']; sc.pl.tracksplot(adata, markers, groupby='bulk_labels', dendrogram=True). Using var_names as dict:. .. plot::; :context: close-figs. markers = {{'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}}; sc.pl.tracksplot(adata, markers, groupby='bulk_labels', dendrogram=True). .. currentmodule:: scanpy. See also; --------; pl.rank_genes_groups_tracksplot: to plot marker genes identified using the :func:`~scanpy.tl.rank_genes_groups` function.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py:218,log,log,218,src/scanpy/plotting/_anndata.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py,1,['log'],['log']
Testability,"""""""\; Log message with specific level and return current time. Parameters; ----------; msg; Message to display.; time; A time in the past. If this is passed, the time difference from then; to now is appended to `msg` as ` (HH:MM:SS)`.; If `msg` contains `{time_passed}`, the time difference is instead; inserted at that position.; deep; If the current verbosity is higher than the log function’s level,; this gets displayed as well; extra; Additional values you can specify in `msg` like `{time_passed}`.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/logging.py:6,Log,Log,6,src/scanpy/logging.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/logging.py,2,"['Log', 'log']","['Log', 'log']"
Testability,"""""""\; Logarithmize the data matrix. Computes :math:`X = \\log(X + 1)`,; where :math:`log` denotes the natural logarithm unless a different base is given. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; base; Base of the logarithm. Natural logarithm is used by default.; copy; If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned.; chunked; Process the data matrix in chunks, which will save memory.; Applies only to :class:`~anndata.AnnData`.; chunk_size; `n_obs` of the chunks to process the data in.; layer; Entry of layers to transform.; obsm; Entry of obsm to transform. Returns; -------; Returns or updates `data`, depending on `copy`.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:6,Log,Logarithmize,6,src/scanpy/preprocessing/_simple.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py,6,"['Log', 'log']","['Logarithmize', 'log', 'logarithm']"
Testability,"""""""\; Normalization and filtering as of :cite:p:`Weinreb2017`. Expects non-logarithmized data.; If using logarithmized data, pass `log=False`. Parameters; ----------; adata; Annotated data matrix.; log; Logarithmize data?; copy; Return a copy if true.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py:75,log,logarithmized,75,src/scanpy/preprocessing/_recipes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py,5,"['Log', 'log']","['Logarithmize', 'log', 'logarithmized']"
Testability,"""""""\; Normalization and filtering as of :cite:t:`Zheng2017`. Reproduces the preprocessing of :cite:t:`Zheng2017` – the Cell Ranger R Kit of 10x; Genomics. Expects non-logarithmized data.; If using logarithmized data, pass `log=False`. The recipe runs the following steps. .. code:: python. sc.pp.filter_genes(adata, min_counts=1) # only consider genes with more than 1 count; sc.pp.normalize_per_cell( # normalize with total UMI count per cell; adata, key_n_counts='n_counts_all'; ); filter_result = sc.pp.filter_genes_dispersion( # select highly-variable genes; adata.X, flavor='cell_ranger', n_top_genes=n_top_genes, log=False; ); adata = adata[:, filter_result.gene_subset] # subset the genes; sc.pp.normalize_per_cell(adata) # renormalize after filtering; if log: sc.pp.log1p(adata) # log transform: adata.X = log(adata.X + 1); sc.pp.scale(adata) # scale to unit variance and shift to zero mean. Parameters; ----------; adata; Annotated data matrix.; n_top_genes; Number of genes to keep.; log; Take logarithm.; plot; Show a plot of the gene dispersion vs. mean relation.; copy; Return a copy of `adata` instead of updating it. Returns; -------; Returns or updates `adata` depending on `copy`.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py:167,log,logarithmized,167,src/scanpy/preprocessing/_recipes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py,9,['log'],"['log', 'logarithm', 'logarithmized']"
Testability,"""""""\; Normalization and filtering as of Seurat :cite:p:`Satija2015`. This uses a particular preprocessing. Expects non-logarithmized data.; If using logarithmized data, pass `log=False`. Parameters; ----------; adata; Annotated data matrix.; log; Logarithmize data?; plot; Show a plot of the gene dispersion vs. mean relation.; copy; Return a copy if true.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py:119,log,logarithmized,119,src/scanpy/preprocessing/_recipes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py,5,"['Log', 'log']","['Logarithmize', 'log', 'logarithmized']"
Testability,"""""""\; Plot dispersions versus means for genes. Produces Supp. Fig. 5c of Zheng et al. (2017) and MeanVarPlot() of Seurat. Parameters; ----------; result; Result of :func:`~scanpy.pp.filter_genes_dispersion`.; log; Plot on logarithmic axes.; show; Show the plot, do not return axis.; save; If `True` or a `str`, save the figure.; A string is appended to the default filename.; Infer the filetype if ending on {{`'.pdf'`, `'.png'`, `'.svg'`}}.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_preprocessing.py:209,log,log,209,src/scanpy/plotting/_preprocessing.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_preprocessing.py,2,['log'],"['log', 'logarithmic']"
Testability,"""""""\; Plot marker trends along trajectory, and return trajectory branches for further; analysis and visualization (heatmap, etc..). Parameters; ----------; adata; Annotated data matrix.; markers; Iterable of markers/genes to be plotted.; show_variance; Logical indicating if the trends should be accompanied with variance.; no_bins; Number of bins for calculating marker density.; smoothing_factor; Parameter controlling the degree of smoothing.; min_delta; Minimum difference in marker expression after normalization to show; separate trends for the two branches.; figsize; width, height; return_fig; Return the matplotlib figure.; {show_save_ax}. Returns; -------; Updates `adata` with the following fields:. `trunk_wishbone` : :class:`pandas.DataFrame` (`adata.uns`); Computed values before branching; `branch1_wishbone` : :class:`pandas.DataFrame` (`adata.uns`); Computed values for the first branch; `branch2_wishbone` : :class:`pandas.DataFrame` (`adata.uns`); Computed values for the second branch.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pl.py:253,Log,Logical,253,src/scanpy/external/pl.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pl.py,1,['Log'],['Logical']
Testability,"""""""\; Plot ranking of genes for all tested comparisons. Parameters; ----------; adata; Annotated data matrix.; groups; List of group names.; n_genes; Number of genes to show. Is ignored if `gene_names` is passed.; gene_names; List of genes to plot. Is only useful if interested in a custom gene list,; which is not the result of :func:`scanpy.tl.rank_genes_groups`.; gene_symbols; Key for field in `.var` that stores gene symbols if you do not want to; use `.var_names` displayed in the plot.; use_raw; Use `raw` attribute of `adata` if present. Defaults to the value that; was used in :func:`~scanpy.tl.rank_genes_groups`.; split; Whether to split the violins or not.; density_norm; See :func:`~seaborn.violinplot`.; strip; Show a strip plot on top of the violin plot.; jitter; If set to 0, no points are drawn. See :func:`~seaborn.stripplot`.; size; Size of the jitter points.; {show_save_ax}; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py:36,test,tested,36,src/scanpy/plotting/_tools/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py,1,['test'],['tested']
Testability,"""""""\; Plot ranking of genes using dotplot plot (see :func:`~scanpy.pl.dotplot`). Parameters; ----------; {params}; {vals_to_plot}; {show_save_ax}; return_fig; Returns :class:`DotPlot` object. Useful for fine-tuning; the plot. Takes precedence over `show=False`.; **kwds; Are passed to :func:`~scanpy.pl.dotplot`. Returns; -------; If `return_fig` is `True`, returns a :class:`DotPlot` object,; else if `show` is false, return axes dict. Examples; --------. .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); sc.tl.rank_genes_groups(adata, 'bulk_labels', n_genes=adata.raw.shape[1]). Plot top 2 genes per group. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_dotplot(adata,n_genes=2). Plot with scaled expressions for easier identification of differences. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_dotplot(adata, n_genes=2, standard_scale='var'). Plot `logfoldchanges` instead of gene expression. In this case a diverging colormap; like `bwr` or `seismic` works better. To center the colormap in zero, the minimum; and maximum values to plot are set to -4 and 4 respectively.; Also, only genes with a log fold change of 3 or more are shown. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_dotplot(; adata,; n_genes=4,; values_to_plot=""logfoldchanges"", cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change'; ). Also, the last genes can be plotted. This can be useful to identify genes; that are lowly expressed in a group. For this `n_genes=-4` is used. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_dotplot(; adata,; n_genes=-4,; values_to_plot=""logfoldchanges"",; cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change',; ). A list specific genes can be given to check their log fold change. If a; dictionary, the dictionary keys will be added as labels in the plot. .. plot::; :context: close-figs. var_names = {{'T-cell': ['CD3D', 'CD3E', 'IL32'],; ",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py:919,log,logfoldchanges,919,src/scanpy/plotting/_tools/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py,1,['log'],['logfoldchanges']
Testability,"""""""\; Plot ranking of genes using matrixplot plot (see :func:`~scanpy.pl.matrixplot`). Parameters; ----------; {params}; {vals_to_plot}; {show_save_ax}; return_fig; Returns :class:`MatrixPlot` object. Useful for fine-tuning; the plot. Takes precedence over `show=False`.; **kwds; Are passed to :func:`~scanpy.pl.matrixplot`. Returns; -------; If `return_fig` is `True`, returns a :class:`MatrixPlot` object,; else if `show` is false, return axes dict. Examples; --------. .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); sc.tl.rank_genes_groups(adata, 'bulk_labels', n_genes=adata.raw.shape[1]). Plot `logfoldchanges` instead of gene expression. In this case a diverging colormap; like `bwr` or `seismic` works better. To center the colormap in zero, the minimum; and maximum values to plot are set to -4 and 4 respectively.; Also, only genes with a log fold change of 3 or more are shown. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_matrixplot(; adata,; n_genes=4,; values_to_plot=""logfoldchanges"",; cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change',; ). Also, the last genes can be plotted. This can be useful to identify genes; that are lowly expressed in a group. For this `n_genes=-4` is used. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_matrixplot(; adata,; n_genes=-4,; values_to_plot=""logfoldchanges"",; cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change',; ). A list specific genes can be given to check their log fold change. If a; dictionary, the dictionary keys will be added as labels in the plot. .. plot::; :context: close-figs. var_names = {{""T-cell"": ['CD3D', 'CD3E', 'IL32'],; 'B-cell': ['CD79A', 'CD79B', 'MS4A1'],; 'myeloid': ['CST3', 'LYZ'] }}; sc.pl.rank_genes_groups_matrixplot(; adata,; var_names=var_names,; values_to_plot=""logfoldchanges"",; cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change',; ); """,MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py:646,log,logfoldchanges,646,src/scanpy/plotting/_tools/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py,2,['log'],"['log', 'logfoldchanges']"
Testability,"""""""\; Plot the variance ratio. Parameters; ----------; n_pcs; Number of PCs to show.; log; Plot on logarithmic scale..; show; Show the plot, do not return axis.; save; If `True` or a `str`, save the figure.; A string is appended to the default filename.; Infer the filetype if ending on {`'.pdf'`, `'.png'`, `'.svg'`}.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py:86,log,log,86,src/scanpy/plotting/_tools/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py,2,['log'],"['log', 'logarithmic']"
Testability,"""""""\; Processed 3k PBMCs from 10x Genomics. Processed using the basic tutorial :doc:`/tutorials/basics/clustering-2017`. For preprocessing, cells are filtered out that have few gene counts or too high a `percent_mito`.; The counts are logarithmized and only genes marked by :func:`~scanpy.pp.highly_variable_genes` are retained.; The :attr:`~anndata.AnnData.obs` variables `n_counts` and `percent_mito` are corrected for; using :func:`~scanpy.pp.regress_out`, and values are scaled and clipped by :func:`~scanpy.pp.scale`.; Finally, :func:`~scanpy.pp.pca` and :func:`~scanpy.pp.neighbors` are calculated. As analysis steps, the embeddings :func:`~scanpy.tl.tsne` and :func:`~scanpy.tl.umap` are performed.; Communities are identified using :func:`~scanpy.tl.louvain` and marker genes using :func:`~scanpy.tl.rank_genes_groups`. Returns; -------; Annotated data matrix. Examples; --------; >>> import scanpy as sc; >>> sc.datasets.pbmc3k_processed(); AnnData object with n_obs × n_vars = 2638 × 1838; obs: 'n_genes', 'percent_mito', 'n_counts', 'louvain'; var: 'n_cells'; uns: 'draw_graph', 'louvain', 'louvain_colors', 'neighbors', 'pca', 'rank_genes_groups'; obsm: 'X_pca', 'X_tsne', 'X_umap', 'X_draw_graph_fr'; varm: 'PCs'; obsp: 'distances', 'connectivities'; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py:235,log,logarithmized,235,src/scanpy/datasets/_datasets.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py,1,['log'],['logarithmized']
Testability,"""""""\; Rank genes for characterizing groups. Expects logarithmized data. Parameters; ----------; adata; Annotated data matrix.; groupby; The key of the observations grouping to consider.; mask_var; Select subset of genes to use in statistical tests.; use_raw; Use `raw` attribute of `adata` if present.; layer; Key from `adata.layers` whose value will be used to perform tests on.; groups; Subset of groups, e.g. [`'g1'`, `'g2'`, `'g3'`], to which comparison; shall be restricted, or `'all'` (default), for all groups. Note that if; `reference='rest'` all groups will still be used as the reference, not; just those specified in `groups`.; reference; If `'rest'`, compare each group to the union of the rest of the group.; If a group identifier, compare with respect to this group.; n_genes; The number of genes that appear in the returned tables.; Defaults to all genes.; method; The default method is `'t-test'`,; `'t-test_overestim_var'` overestimates variance of each group,; `'wilcoxon'` uses Wilcoxon rank-sum,; `'logreg'` uses logistic regression. See :cite:t:`Ntranos2019`,; `here <https://github.com/scverse/scanpy/issues/95>`__ and `here; <https://www.nxn.se/valent/2018/3/5/actionable-scrna-seq-clusters>`__,; for why this is meaningful.; corr_method; p-value correction method.; Used only for `'t-test'`, `'t-test_overestim_var'`, and `'wilcoxon'`.; tie_correct; Use tie correction for `'wilcoxon'` scores.; Used only for `'wilcoxon'`.; rankby_abs; Rank genes by the absolute value of the score, not by the; score. The returned scores are never the absolute values.; pts; Compute the fraction of cells expressing the genes.; key_added; The key in `adata.uns` information is saved to.; copy; Whether to copy `adata` or modify it inplace.; kwds; Are passed to test methods. Currently this affects only parameters that; are passed to :class:`sklearn.linear_model.LogisticRegression`.; For instance, you can pass `penalty='l1'` to try to come up with a; minimal set of genes that are good predi",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py:52,log,logarithmized,52,src/scanpy/tools/_rank_genes_groups.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py,6,"['log', 'test']","['logarithmized', 'logistic', 'logreg', 'test', 'tests']"
Testability,"""""""\; Self-Assembling Manifolds single-cell RNA sequencing analysis tool :cite:p:`Tarashansky2019`. SAM iteratively rescales the input gene expression matrix to emphasize; genes that are spatially variable along the intrinsic manifold of the data.; It outputs the gene weights, nearest neighbor matrix, and a 2D projection. The AnnData input should contain unstandardized, non-negative values.; Preferably, the data should be log-normalized and no genes should be filtered out. Parameters; ----------. k; The number of nearest neighbors to identify for each cell. distance; The distance metric to use when identifying nearest neighbors.; Can be any of the distance metrics supported by; :func:`~scipy.spatial.distance.pdist`. max_iter; The maximum number of iterations SAM will run. projection; If 'tsne', generates a t-SNE embedding. If 'umap', generates a UMAP; embedding. If 'None', no embedding will be generated. standardization; If 'Normalizer', use sklearn.preprocessing.Normalizer, which; normalizes expression data prior to PCA such that each cell has; unit L2 norm. If 'StandardScaler', use; sklearn.preprocessing.StandardScaler, which normalizes expression; data prior to PCA such that each gene has zero mean and unit; variance. Otherwise, do not normalize the expression data. We; recommend using 'StandardScaler' for large datasets with many; expected cell types and 'Normalizer' otherwise. If 'None', no; transformation is applied. num_norm_avg; The top 'num_norm_avg' dispersions are averaged to determine the; normalization factor when calculating the weights. This prevents; genes with large spatial dispersions from skewing the distribution; of weights. weight_pcs; If True, scale the principal components by their eigenvalues. In; datasets with many expected cell types, setting this to False might; improve the resolution as these cell types might be encoded by lower-; variance principal components. sparse_pca; If True, uses an implementation of PCA that accepts sparse inputs.;",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_sam.py:426,log,log-normalized,426,src/scanpy/external/tl/_sam.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_sam.py,1,['log'],['log-normalized']
Testability,"""""""\; The file path `logfile` was set to.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_settings.py:21,log,logfile,21,src/scanpy/_settings.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_settings.py,1,['log'],['logfile']
Testability,"""""""\; The open file to write logs to. Set it to a :class:`~pathlib.Path` or :class:`str` to open a new one.; The default `None` corresponds to :obj:`sys.stdout` in jupyter notebooks; and to :obj:`sys.stderr` otherwise. For backwards compatibility, setting it to `''` behaves like setting it to `None`.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_settings.py:29,log,logs,29,src/scanpy/_settings.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_settings.py,1,['log'],['logs']
Testability,"""""""\; Violin plot. Wraps :func:`seaborn.violinplot` for :class:`~anndata.AnnData`. Parameters; ----------; adata; Annotated data matrix.; keys; Keys for accessing variables of `.var_names` or fields of `.obs`.; groupby; The key of the observation grouping to consider.; log; Plot on logarithmic axis.; use_raw; Whether to use `raw` attribute of `adata`. Defaults to `True` if `.raw` is present.; stripplot; Add a stripplot on top of the violin plot.; See :func:`~seaborn.stripplot`.; jitter; Add jitter to the stripplot (only when stripplot is True); See :func:`~seaborn.stripplot`.; size; Size of the jitter points.; layer; Name of the AnnData object layer that wants to be plotted. By; default adata.raw.X is plotted. If `use_raw=False` is set,; then `adata.X` is plotted. If `layer` is set to a valid layer name,; then the layer is plotted. `layer` takes precedence over `use_raw`.; scale; The method used to scale the width of each violin.; If 'width' (the default), each violin will have the same width.; If 'area', each violin will have the same area.; If 'count', a violin’s width corresponds to the number of observations.; order; Order in which to show the categories.; multi_panel; Display keys in multiple panels also when `groupby is not None`.; xlabel; Label of the x axis. Defaults to `groupby` if `rotation` is `None`,; otherwise, no label is shown.; ylabel; Label of the y axis. If `None` and `groupby` is `None`, defaults; to `'value'`. If `None` and `groubpy` is not `None`, defaults to `keys`.; rotation; Rotation of xtick labels.; {show_save_ax}; **kwds; Are passed to :func:`~seaborn.violinplot`. Returns; -------; A :class:`~matplotlib.axes.Axes` object if `ax` is `None` else `None`. Examples; --------. .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); sc.pl.violin(adata, keys='S_score'). Plot by category. Rotate x-axis labels so that they do not overlap. .. plot::; :context: close-figs. sc.pl.violin(adata, keys='S_score', groupby",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py:270,log,log,270,src/scanpy/plotting/_anndata.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py,2,['log'],"['log', 'logarithmic']"
Testability,"""""""\; adata; Annotated data matrix.; groups; The groups for which to show the gene ranking.; n_genes; Number of genes to show. This can be a negative number to show for; example the down regulated genes. eg: num_genes=-10. Is ignored if; `gene_names` is passed.; gene_symbols; Column name in `.var` DataFrame that stores gene symbols. By default `var_names`; refer to the index column of the `.var` DataFrame. Setting this option allows; alternative names to be used.; groupby; The key of the observation grouping to consider. By default,; the groupby is chosen from the rank genes groups parameter but; other groupby options can be used. It is expected that; groupby is a categorical. If groupby is not a categorical observation,; it would be subdivided into `num_categories` (see :func:`~scanpy.pl.dotplot`).; min_logfoldchange; Value to filter genes in groups if their logfoldchange is less than the; min_logfoldchange; key; Key used to store the ranking results in `adata.uns`.\; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_docs.py:872,log,logfoldchange,872,src/scanpy/plotting/_docs.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_docs.py,1,['log'],['logfoldchange']
Testability,"""""""\; adata; Annotated data matrix.; var_names; `var_names` should be a valid subset of `adata.var_names`.; If `var_names` is a mapping, then the key is used as label; to group the values (see `var_group_labels`). The mapping values; should be sequences of valid `adata.var_names`. In this; case either coloring or 'brackets' are used for the grouping; of var names depending on the plot. When `var_names` is a mapping,; then the `var_group_labels` and `var_group_positions` are set.; groupby; The key of the observation grouping to consider.; use_raw; Use `raw` attribute of `adata` if present.; log; Plot on logarithmic axis.; num_categories; Only used if groupby observation is not categorical. This value; determines the number of groups into which the groupby observation; should be subdivided.; categories_order; Order in which to show the categories. Note: add_dendrogram or add_totals; can change the categories order.; figsize; Figure size when `multi_panel=True`.; Otherwise the `rcParam['figure.figsize]` value is used.; Format is (width, height); dendrogram; If True or a valid dendrogram key, a dendrogram based on the hierarchical; clustering between the `groupby` categories is added.; The dendrogram information is computed using :func:`scanpy.tl.dendrogram`.; If `tl.dendrogram` has not been called previously the function is called; with default parameters.; gene_symbols; Column name in `.var` DataFrame that stores gene symbols.; By default `var_names` refer to the index column of the `.var` DataFrame.; Setting this option allows alternative names to be used.; var_group_positions; Use this parameter to highlight groups of `var_names`.; This will draw a 'bracket' or a color block between the given start and end; positions. If the parameter `var_group_labels` is set, the corresponding; labels are added on top/left. E.g. `var_group_positions=[(4,10)]`; will add a bracket between the fourth `var_name` and the tenth `var_name`.; By giving more positions, more brackets/color b",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_docs.py:597,log,log,597,src/scanpy/plotting/_docs.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_docs.py,2,['log'],"['log', 'logarithmic']"
Testability,"""""""\; values_to_plot; Instead of the mean gene value, plot the values computed by `sc.rank_genes_groups`.; The options are: ['scores', 'logfoldchanges', 'pvals', 'pvals_adj',; 'log10_pvals', 'log10_pvals_adj']. When plotting logfoldchanges a divergent; colormap is recommended. See examples below.; var_names; Genes to plot. Sometimes is useful to pass a specific list of var names (e.g. genes); to check their fold changes or p-values, instead of the top/bottom genes. The; var_names could be a dictionary or a list as in :func:`~scanpy.pl.dotplot` or; :func:`~scanpy.pl.matrixplot`. See examples below.\; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_docs.py:136,log,logfoldchanges,136,src/scanpy/plotting/_docs.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_docs.py,2,['log'],['logfoldchanges']
Testability,"""""""tests the sequence log1p→save→load→rank_genes_groups""""""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_rank_genes_groups.py:3,test,tests,3,tests/test_rank_genes_groups.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_rank_genes_groups.py,1,['test'],['tests']
Testability,"""""""uses a larger dataset to test column order and content""""""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py:28,test,test,28,tests/test_get.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py,1,['test'],['test']
Testability,"# "" 'paga/transitions_ttest', t-test on transitions (adata.uns)""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_paga.py:32,test,test,32,src/scanpy/tools/_paga.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_paga.py,1,['test'],['test']
Testability,"# (still) Not equal to tolerance rtol=2e-05, atol=2e-05; # np.testing.assert_allclose(4, 3.9999, rtol=2e-05, atol=2e-05)",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_highly_variable_genes.py:62,test,testing,62,tests/test_highly_variable_genes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_highly_variable_genes.py,1,['test'],['testing']
Testability,"# All tests marked with `pytest.mark.internet` get skipped unless; # `--run-internet` passed",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/testing/scanpy/_pytest/__init__.py:6,test,tests,6,src/testing/scanpy/_pytest/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/testing/scanpy/_pytest/__init__.py,1,['test'],['tests']
Testability,"# Dask AnnData tests require anndata > 0.10",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/testing/scanpy/_pytest/__init__.py:15,test,tests,15,src/testing/scanpy/_pytest/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/testing/scanpy/_pytest/__init__.py,1,['test'],['tests']
Testability,"# Finding marker genes; # Due to incosistency with our test runner vs local, these clusters need to; # be pre-annotated as the numbers for each cluster are not consistent.",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/notebooks/test_pbmc3k.py:55,test,test,55,tests/notebooks/test_pbmc3k.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/notebooks/test_pbmc3k.py,1,['test'],['test']
Testability,"# HVG process needs log'd data.",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py:20,log,log,20,src/scanpy/preprocessing/_scrublet/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py,1,['log'],['log']
Testability,"# Just tests for failure for now",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_preprocessing.py:7,test,tests,7,tests/test_preprocessing.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_preprocessing.py,1,['test'],['tests']
Testability,"# Log",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/paga.py:2,Log,Log,2,src/scanpy/plotting/_tools/paga.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/paga.py,2,['Log'],['Log']
Testability,"# Note:; # Could add an 'enrich' option here; # (fisher's exact test or hypergeometric test),; # but that would require knowledge of the size of the space from which; # the reference marker gene set was taken.; # This is at best approximately known.; # Create a pandas dataframe with the results",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_marker_gene_overlap.py:64,test,test,64,src/scanpy/tools/_marker_gene_overlap.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_marker_gene_overlap.py,2,['test'],['test']
Testability,"# PAGA for hematopoiesis in mouse [(Paul *et al.*, 2015)](https://doi.org/10.1016/j.cell.2015.11.013); # Hematopoiesis: trace myeloid and erythroid differentiation for data of [Paul *et al.* (2015)](https://doi.org/10.1016/j.cell.2015.11.013).; #; # This is the subsampled notebook for testing.",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/notebooks/test_paga_paul15_subsampled.py:286,test,testing,286,tests/notebooks/test_paga_paul15_subsampled.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/notebooks/test_paga_paul15_subsampled.py,1,['test'],['testing']
Testability,"# Reduce size of input for faster test",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_scrublet.py:34,test,test,34,tests/test_scrublet.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_scrublet.py,1,['test'],['test']
Testability,"# Special module present if test coverage being calculated; # https://gitlab.com/joelostblom/session_info/-/issues/10",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/logging.py:28,test,test,28,src/scanpy/logging.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/logging.py,1,['test'],['test']
Testability,"# Subsetting for speed of test",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py:26,test,test,26,tests/test_pca.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py,1,['test'],['test']
Testability,"# TODO: Fix this case, maybe by increasing test data size.; # https://github.com/scverse/scanpy/issues/2744",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py:43,test,test,43,tests/test_pca.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py,1,['test'],['test']
Testability,"# TODO: Generalize test to more plotting types",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:19,test,test,19,tests/test_plotting.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py,1,['test'],['test']
Testability,"# TODO: This would fail: assert ""log1p"" not in adata.uns, ""ASV bug?""; # https://github.com/scverse/scanpy/issues/3052",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/benchmarks/benchmarks/preprocessing_counts.py:25,assert,assert,25,benchmarks/benchmarks/preprocessing_counts.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/benchmarks/benchmarks/preprocessing_counts.py,1,['assert'],['assert']
Testability,"# TODO: figure out how to test that this doesn't oversubscribe resources",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:26,test,test,26,src/scanpy/preprocessing/_simple.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py,1,['test'],['test']
Testability,"# TODO: write a test that costs less resources and is more meaningful",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_score_genes.py:16,test,test,16,tests/test_score_genes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_score_genes.py,1,['test'],['test']
Testability,"# Test all overlap calculations on artificial data",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_marker_gene_overlap.py:2,Test,Test,2,tests/test_marker_gene_overlap.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_marker_gene_overlap.py,1,['Test'],['Test']
Testability,"# Test base",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_preprocessing.py:2,Test,Test,2,tests/test_preprocessing.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_preprocessing.py,1,['Test'],['Test']
Testability,"# Test case with perfectly seperated groups",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_metrics.py:2,Test,Test,2,tests/test_metrics.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_metrics.py,1,['Test'],['Test']
Testability,"# Test for fix to #1170",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_combat.py:2,Test,Test,2,tests/test_combat.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_combat.py,1,['Test'],['Test']
Testability,"# Test if functions with `copy` follow conventions",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_package_structure.py:2,Test,Test,2,tests/test_package_structure.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_package_structure.py,1,['Test'],['Test']
Testability,"# Test images are saved in the directory ./_images/<test-name>/; # If test images need to be updated, simply copy actual.png to expected.png.",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:2,Test,Test,2,tests/test_plotting.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py,3,"['Test', 'test']","['Test', 'test', 'test-name']"
Testability,"# Test that changing random seed changes result; # Does not show up reliably with 32 bit computation",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py:2,Test,Test,2,tests/test_pca.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py,1,['Test'],['Test']
Testability,"# Test that density values are scaled; # Test that the highest value is in the middle for a grid layout",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_embedding_density.py:2,Test,Test,2,tests/test_embedding_density.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_embedding_density.py,2,['Test'],['Test']
Testability,"# Test that downloading tissue image works",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_datasets.py:2,Test,Test,2,tests/test_datasets.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_datasets.py,1,['Test'],['Test']
Testability,"# Test that it can be written:",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_read_10x.py:2,Test,Test,2,tests/test_read_10x.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_read_10x.py,1,['Test'],['Test']
Testability,"# Test that layer kwarg works",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_normalization.py:2,Test,Test,2,tests/test_normalization.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_normalization.py,1,['Test'],['Test']
Testability,"# Test that results are similar for sparse and dense reps of same data",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_metrics.py:2,Test,Test,2,tests/test_metrics.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_metrics.py,1,['Test'],['Test']
Testability,"# Test that sc.pl.embedding_density() runs without error",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_embedding_density.py:2,Test,Test,2,tests/test_embedding_density.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_embedding_density.py,1,['Test'],['Test']
Testability,"# Test that series and vectors return same value",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_metrics.py:2,Test,Test,2,tests/test_metrics.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_metrics.py,1,['Test'],['Test']
Testability,"# Test that tissue image exists and is a valid image file",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_datasets.py:2,Test,Test,2,tests/test_datasets.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_datasets.py,1,['Test'],['Test']
Testability,"# Test that tissue image is a tif image file (using `file`)",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_datasets.py:2,Test,Test,2,tests/test_datasets.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_datasets.py,1,['Test'],['Test']
Testability,"# Test that we're equivalent for 64 bit",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_preprocessing.py:2,Test,Test,2,tests/test_preprocessing.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_preprocessing.py,1,['Test'],['Test']
Testability,"# Test user inputs",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py:2,Test,Test,2,src/scanpy/plotting/_tools/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py,3,['Test'],['Test']
Testability,"# Test whether ours is more accurate for 32 bit",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_preprocessing.py:2,Test,Test,2,tests/test_preprocessing.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_preprocessing.py,1,['Test'],['Test']
Testability,"# Tests that constant values don't change results; # (since support for constant values is implemented by us)",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_preprocessing.py:2,Test,Tests,2,tests/test_preprocessing.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_preprocessing.py,1,['Test'],['Tests']
Testability,"# Tests that gex option doesn't, say, make the function return None",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_read_10x.py:2,Test,Tests,2,tests/test_read_10x.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_read_10x.py,1,['Test'],['Tests']
Testability,"# Tests that https://github.com/scverse/scanpy/issues/1887 is fixed",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_paga.py:2,Test,Tests,2,tests/test_paga.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_paga.py,1,['Test'],['Tests']
Testability,"# Tests the 10x probe barcode matrix is read correctly",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_read_10x.py:2,Test,Tests,2,tests/test_read_10x.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_read_10x.py,1,['Test'],['Tests']
Testability,"# These are tested via doctest",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_datasets.py:12,test,tested,12,tests/test_datasets.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_datasets.py,1,['test'],['tested']
Testability,"# This logic is all dispatch",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:7,log,logic,7,src/scanpy/preprocessing/_simple.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py,1,['log'],['logic']
Testability,"# This warning test is out of the fixture because it is a special case in the logic of the function",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py:15,test,test,15,tests/test_pca.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_pca.py,2,"['log', 'test']","['logic', 'test']"
Testability,"# We test results for a simple generic example; # Tests are conducted for sparse and non-sparse AnnData objects.; # Due to minor changes in multiplication implementation for sparse and non-sparse objects,; # results differ (very) slightly",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_rank_genes_groups.py:5,test,test,5,tests/test_rank_genes_groups.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_rank_genes_groups.py,2,"['Test', 'test']","['Tests', 'test']"
Testability,"# add a test for this at some point; # data.to_csv('./write/paga_path_{}.csv'.format(descr))",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/notebooks/test_paga_paul15_subsampled.py:8,test,test,8,tests/notebooks/test_paga_paul15_subsampled.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/notebooks/test_paga_paul15_subsampled.py,1,['test'],['test']
Testability,"# assume log normal",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py:9,log,log,9,src/scanpy/external/pp/_hashsolo.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py,1,['log'],['log']
Testability,"# binary logistic regression",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py:9,log,logistic,9,src/scanpy/tools/_rank_genes_groups.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py,1,['log'],['logistic']
Testability,"# compute output to be tested",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_highly_variable_genes.py:23,test,tested,23,tests/test_highly_variable_genes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_highly_variable_genes.py,1,['test'],['tested']
Testability,"# compute output to test",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_normalization.py:20,test,test,20,tests/test_normalization.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_normalization.py,1,['test'],['test']
Testability,"# create test object",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_rank_genes_groups.py:9,test,test,9,tests/test_rank_genes_groups.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_rank_genes_groups.py,1,['test'],['test']
Testability,"# define this after importing scanpy but before running tests",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/conftest.py:56,test,tests,56,tests/conftest.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/conftest.py,1,['test'],['tests']
Testability,"# for logreg only",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py:6,log,logreg,6,src/scanpy/tools/_rank_genes_groups.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py,1,['log'],['logreg']
Testability,"# for method in ['logreg', 't-test']:",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_rank_genes_groups_logreg.py:18,log,logreg,18,tests/test_rank_genes_groups_logreg.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_rank_genes_groups_logreg.py,2,"['log', 'test']","['logreg', 'test']"
Testability,"# get location test h5ad file in datasets",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py:15,test,test,15,tests/test_get.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py,1,['test'],['test']
Testability,"# get parameters of distribution, assuming lognormal do update from global values",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py:43,log,lognormal,43,src/scanpy/external/pp/_hashsolo.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_hashsolo.py,1,['log'],['lognormal']
Testability,"# https://github.com/scverse/scanpy/issues/1000; # Tests that plotting functions don't make a copy from a view unless they; # actually have to",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:51,Test,Tests,51,tests/test_plotting.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py,1,['Test'],['Tests']
Testability,"# https://github.com/scverse/scanpy/issues/1634; # Test for error where just passing obsm_keys, but not keys, would cause error.",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py:51,Test,Test,51,tests/test_get.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py,1,['Test'],['Test']
Testability,"# https://jinja.palletsprojects.com/en/3.0.x/api/#custom-tests",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/docs/extensions/has_attr_test.py:57,test,tests,57,docs/extensions/has_attr_test.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/docs/extensions/has_attr_test.py,1,['test'],['tests']
Testability,"# legacy logic",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/__init__.py:9,log,logic,9,src/scanpy/neighbors/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/__init__.py,1,['log'],['logic']
Testability,"# log transform: X = log(X + 1)",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py:2,log,log,2,src/scanpy/preprocessing/_recipes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_recipes.py,2,['log'],['log']
Testability,"# logarithmized mean as in Seurat",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py:2,log,logarithmized,2,src/scanpy/preprocessing/_highly_variable_genes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py,2,['log'],['logarithmized']
Testability,"# logg.debug(; # ' group', iseg, 'with tip', segs_tips[iseg][itip],; # 'connects with', jseg, 'with tip', segs_tips[jseg][1],; # ); # logg.debug(' do not use the tip for ""triangulation""')",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py:2,log,logg,2,src/scanpy/tools/_dpt.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py,2,['log'],['logg']
Testability,"# loggerDict can contain `logging.Placeholder`s",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/conftest.py:2,log,loggerDict,2,tests/conftest.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/conftest.py,2,['log'],"['loggerDict', 'logging']"
Testability,"# logging",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_settings.py:2,log,logging,2,src/scanpy/_settings.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_settings.py,1,['log'],['logging']
Testability,"# need to add the following here to make inplace logic work",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scale.py:49,log,logic,49,src/scanpy/preprocessing/_scale.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scale.py,1,['log'],['logic']
Testability,"# np.testing.assert_allclose(reference, adata.obs[""Test""].to_numpy())",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_score_genes.py:5,test,testing,5,tests/test_score_genes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_score_genes.py,2,"['Test', 'test']","['Test', 'testing']"
Testability,"# only testing stacked_violin, matrixplot and dotplot",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:7,test,testing,7,tests/test_plotting.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py,1,['test'],['testing']
Testability,"# set via “file object” branch of logfile.setter",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_settings.py:34,log,logfile,34,src/scanpy/_settings.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_settings.py,1,['log'],['logfile']
Testability,"# setting a logfile removes all handlers",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_logging.py:12,log,logfile,12,tests/test_logging.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_logging.py,2,['log'],['logfile']
Testability,"# t-test",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_rank_genes_groups.py:4,test,test,4,tests/test_rank_genes_groups.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_rank_genes_groups.py,1,['test'],['test']
Testability,"# test ""data"" for 3 cells * 4 genes",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_scaling.py:2,test,test,2,tests/test_scaling.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_scaling.py,1,['test'],['test']
Testability,"# test AnnData arguments; # test scaling with default zero_center == True",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_scaling.py:2,test,test,2,tests/test_scaling.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_scaling.py,2,['test'],['test']
Testability,"# test against inplace",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_normalization.py:2,test,test,2,tests/test_normalization.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_normalization.py,1,['test'],['test']
Testability,"# test bare count arguments, for simplicity only with explicit copy=True; # test scaling with default zero_center == True",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_scaling.py:2,test,test,2,tests/test_scaling.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_scaling.py,2,['test'],['test']
Testability,"# test category order when groupby is a list (#1735)",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:2,test,test,2,tests/test_plotting.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py,1,['test'],['test']
Testability,"# test compare_abs",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_filter_rank_genes_groups.py:2,test,test,2,tests/test_filter_rank_genes_groups.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_filter_rank_genes_groups.py,1,['test'],['test']
Testability,"# test dotplot dot_min, dot_max, color_map, and var_groups",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:2,test,test,2,tests/test_plotting.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py,1,['test'],['test']
Testability,"# test functions with neighbors_key and obsp",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_neighbors_key_added.py:2,test,test,2,tests/test_neighbors_key_added.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_neighbors_key_added.py,1,['test'],['test']
Testability,"# test handling of duplicated keys (in this case repeated cell names)",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py:2,test,test,2,tests/test_get.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py,1,['test'],['test']
Testability,"# test handling of duplicated keys (in this case repeated gene names)",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py:2,test,test,2,tests/test_get.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py,1,['test'],['test']
Testability,"# test heatmap numeric column():; # set as numeric column the vales for the first gene on the matrix",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:2,test,test,2,tests/test_plotting.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py,1,['test'],['test']
Testability,"# test layer, var standardization, smallest_dot,; # color title, size_title return_fig and dot_edge",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:2,test,test,2,tests/test_plotting.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py,1,['test'],['test']
Testability,"# test non unique index",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py:2,test,test,2,tests/test_get.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py,1,['test'],['test']
Testability,"# test only cells",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py:2,test,test,2,tests/test_get.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py,1,['test'],['test']
Testability,"# test only obs",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py:2,test,test,2,tests/test_get.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py,1,['test'],['test']
Testability,"# test only var",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py:2,test,test,2,tests/test_get.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py,1,['test'],['test']
Testability,"# test only var columns",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py:2,test,test,2,tests/test_get.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py,1,['test'],['test']
Testability,"# test scaling with explicit zero_center == False",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_scaling.py:2,test,test,2,tests/test_scaling.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_scaling.py,2,['test'],['test']
Testability,"# test scaling with explicit zero_center == True",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_scaling.py:2,test,test,2,tests/test_scaling.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_scaling.py,3,['test'],['test']
Testability,"# test standard_scale_obs",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:2,test,test,2,tests/test_plotting.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py,1,['test'],['test']
Testability,"# test swap axes",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:2,test,test,2,tests/test_plotting.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py,1,['test'],['test']
Testability,"# test that columns content is correct for obs_df",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py:2,test,test,2,tests/test_get.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py,1,['test'],['test']
Testability,"# test that columns content is correct for var_df",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py:2,test,test,2,tests/test_get.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py,1,['test'],['test']
Testability,"# test that plot elements are well aligned; # small",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:2,test,test,2,tests/test_plotting.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py,1,['test'],['test']
Testability,"# test that plotting fails if one axis is a per-var value and the; # other is a per-obs value",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:2,test,test,2,tests/test_plotting.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py,1,['test'],['test']
Testability,"# test that plotting fails with a ValueError if trying to plot; # var_names only found in raw and use_raw is False",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:2,test,test,2,tests/test_plotting.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py,1,['test'],['test']
Testability,"# test that the 'groups' parameter sorts; # cells, such that the cells belonging to the groups are; # plotted on top. This new ordering requires that the size; # vector is also ordered (if given).",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:2,test,test,2,tests/test_plotting.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py,1,['test'],['test']
Testability,"# test use of layer",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:2,test,test,2,tests/test_plotting.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py,1,['test'],['test']
Testability,"# test var/obs standardization and layer",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:2,test,test,2,tests/test_plotting.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py,1,['test'],['test']
Testability,"# test var_names as dict",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:2,test,test,2,tests/test_plotting.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py,1,['test'],['test']
Testability,"# test whether we have categorial or continuous annotation",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py:2,test,test,2,src/scanpy/plotting/_anndata.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_anndata.py,1,['test'],['test']
Testability,"# the pbmc68k was generated using rank_genes_groups with method='logreg'; # which does not generate 'logfoldchanges', although this field is; # required by `sc.get.rank_genes_groups_df`.; # After updating rank_genes_groups plots to use the latter function; # an error appears. Re-running rank_genes_groups with default method; # solves the problem.",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:65,log,logreg,65,tests/test_plotting.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py,2,['log'],"['logfoldchanges', 'logreg']"
Testability,"# the test data are such that X is the same shape for both ""genomes"",; # but the values are different",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_read_10x.py:6,test,test,6,tests/test_read_10x.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_read_10x.py,1,['test'],['test']
Testability,"# these two types of plots can also; # show score, logfoldchange and pvalues, in general any value from rank; # genes groups",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py:51,log,logfoldchange,51,src/scanpy/plotting/_tools/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py,1,['log'],['logfoldchange']
Testability,"# this test checks wether combat can align data from several gaussians; # it checks this by computing the silhouette coefficient in a pca embedding; # load in data",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_combat.py:7,test,test,7,tests/test_combat.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_combat.py,1,['test'],['test']
Testability,"# this test trivially checks whether mean normalisation worked; # load in data",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_combat.py:7,test,test,7,tests/test_combat.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_combat.py,1,['test'],['test']
Testability,"# to ensure that newly created covariates are categorical; # to test for category numbers",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_embedding_density.py:64,test,test,64,src/scanpy/tools/_embedding_density.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_embedding_density.py,1,['test'],['test']
Testability,"### test with batch; # introduce a dummy ""technical covariate""; this is used in Seurat's SelectIntegrationFeatures",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_highly_variable_genes.py:4,test,test,4,tests/test_highly_variable_genes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_highly_variable_genes.py,1,['test'],['test']
Testability,"### test without batch",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_highly_variable_genes.py:4,test,test,4,tests/test_highly_variable_genes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_highly_variable_genes.py,1,['test'],['test']
Testability,"###############################################################################; # Calculation; ###############################################################################; # Some notes on the implementation:; # * This could be phrased as tensor multiplication. However that does not get; # parallelized, which boosts performance almost linearly with cores.; # * Due to the umap setting the default threading backend, a parallel numba; # function that calls another parallel numba function can get stuck. This; # ends up meaning code re-use will be limited until umap 0.4.; # See: https://github.com/lmcinnes/umap/issues/306; # * There can be a fair amount of numerical instability here (big reductions),; # so data is cast to float64. Removing these casts/ conversion will cause the; # tests to fail.",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/metrics/_gearys_c.py:791,test,tests,791,src/scanpy/metrics/_gearys_c.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/metrics/_gearys_c.py,1,['test'],['tests']
Testability,"##################################; # Test errors for obs_df, var_df #; ##################################",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py:38,Test,Test,38,tests/test_get.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py,1,['Test'],['Test']
Testability,"##############################; # rank_genes_groups_df tests #; ##############################",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py:55,test,tests,55,tests/test_get.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py,1,['test'],['tests']
Testability,"########################; # obs_df, var_df tests #; ########################",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py:43,test,tests,43,tests/test_get.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_get.py,1,['test'],['tests']
Testability,":`DotPlot` object. Useful for fine-tuning; the plot. Takes precedence over `show=False`.; **kwds; Are passed to :func:`~scanpy.pl.dotplot`. Returns; -------; If `return_fig` is `True`, returns a :class:`DotPlot` object,; else if `show` is false, return axes dict. Examples; --------. .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); sc.tl.rank_genes_groups(adata, 'bulk_labels', n_genes=adata.raw.shape[1]). Plot top 2 genes per group. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_dotplot(adata,n_genes=2). Plot with scaled expressions for easier identification of differences. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_dotplot(adata, n_genes=2, standard_scale='var'). Plot `logfoldchanges` instead of gene expression. In this case a diverging colormap; like `bwr` or `seismic` works better. To center the colormap in zero, the minimum; and maximum values to plot are set to -4 and 4 respectively.; Also, only genes with a log fold change of 3 or more are shown. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_dotplot(; adata,; n_genes=4,; values_to_plot=""logfoldchanges"", cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change'; ). Also, the last genes can be plotted. This can be useful to identify genes; that are lowly expressed in a group. For this `n_genes=-4` is used. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_dotplot(; adata,; n_genes=-4,; values_to_plot=""logfoldchanges"",; cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change',; ). A list specific genes can be given to check their log fold change. If a; dictionary, the dictionary keys will be added as labels in the plot. .. plot::; :context: close-figs. var_names = {{'T-cell': ['CD3D', 'CD3E', 'IL32'],; 'B-cell': ['CD79A', 'CD79B', 'MS4A1'],; 'myeloid': ['CST3', 'LYZ'] }}; sc.pl.rank_genes_groups_dotplot(; adata,; var_names=var_names,; values_to_plot=""logfoldchanges"",; cmap",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py:1167,log,log,1167,src/scanpy/plotting/_tools/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py,1,['log'],['log']
Testability,">`__. For; tutorials, bug reports, and R/MATLAB implementations, visit the `PHATE; GitHub page <https://github.com/KrishnaswamyLab/PHATE/>`__. For help; using PHATE, go `here <https://krishnaswamylab.org/get-help>`__. Parameters; ----------; adata; Annotated data matrix.; n_components; number of dimensions in which the data will be embedded; k; number of nearest neighbors on which to build kernel; a; sets decay rate of kernel tails.; If None, alpha decaying kernel is not used; n_landmark; number of landmarks to use in fast PHATE; t; power to which the diffusion operator is powered; sets the level of diffusion. If 'auto', t is selected; according to the knee point in the Von Neumann Entropy of; the diffusion operator; gamma; Informational distance constant between -1 and 1.; `gamma=1` gives the PHATE log potential, `gamma=0` gives; a square root potential.; n_pca; Number of principal components to use for calculating; neighborhoods. For extremely large datasets, using; n_pca < 20 allows neighborhoods to be calculated in; log(n_samples) time.; knn_dist; recommended values: 'euclidean' and 'cosine'; Any metric from `scipy.spatial.distance` can be used; distance metric for building kNN graph; mds_dist; recommended values: 'euclidean' and 'cosine'; Any metric from `scipy.spatial.distance` can be used; distance metric for MDS; mds; Selects which MDS algorithm is used for dimensionality reduction.; n_jobs; The number of jobs to use for the computation.; If `None`, `sc.settings.n_jobs` is used.; If -1 all CPUs are used. If 1 is given, no parallel computing code is; used at all, which is useful for debugging.; For n_jobs below -1, (n_cpus + 1 + n_jobs) are used. Thus for; n_jobs = -2, all CPUs but one are used; random_state; Random seed. Defaults to the global `numpy` random number generator; verbose; If `True` or an `int`/`Verbosity` ≥ 2/`hint`, print status messages.; If `None`, `sc.settings.verbosity` is used.; copy; Return a copy instead of writing to `adata`.; kwargs; Ad",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phate.py:1389,log,log,1389,src/scanpy/external/tl/_phate.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_phate.py,1,['log'],['log']
Testability,"If `return_fig` is `True`, returns a :class:`DotPlot` object,; else if `show` is false, return axes dict. Examples; --------. .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); sc.tl.rank_genes_groups(adata, 'bulk_labels', n_genes=adata.raw.shape[1]). Plot top 2 genes per group. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_dotplot(adata,n_genes=2). Plot with scaled expressions for easier identification of differences. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_dotplot(adata, n_genes=2, standard_scale='var'). Plot `logfoldchanges` instead of gene expression. In this case a diverging colormap; like `bwr` or `seismic` works better. To center the colormap in zero, the minimum; and maximum values to plot are set to -4 and 4 respectively.; Also, only genes with a log fold change of 3 or more are shown. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_dotplot(; adata,; n_genes=4,; values_to_plot=""logfoldchanges"", cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change'; ). Also, the last genes can be plotted. This can be useful to identify genes; that are lowly expressed in a group. For this `n_genes=-4` is used. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_dotplot(; adata,; n_genes=-4,; values_to_plot=""logfoldchanges"",; cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change',; ). A list specific genes can be given to check their log fold change. If a; dictionary, the dictionary keys will be added as labels in the plot. .. plot::; :context: close-figs. var_names = {{'T-cell': ['CD3D', 'CD3E', 'IL32'],; 'B-cell': ['CD79A', 'CD79B', 'MS4A1'],; 'myeloid': ['CST3', 'LYZ'] }}; sc.pl.rank_genes_groups_dotplot(; adata,; var_names=var_names,; values_to_plot=""logfoldchanges"",; cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change',; ). .. currentmodule:: scanpy. See also; --------; tl.rank_genes_groups; """,MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py:1310,log,logfoldchanges,1310,src/scanpy/plotting/_tools/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py,2,['log'],"['log', 'logfoldchanges']"
Testability,"\; Plot ranking of genes using matrixplot plot (see :func:`~scanpy.pl.matrixplot`). Parameters; ----------; {params}; {vals_to_plot}; {show_save_ax}; return_fig; Returns :class:`MatrixPlot` object. Useful for fine-tuning; the plot. Takes precedence over `show=False`.; **kwds; Are passed to :func:`~scanpy.pl.matrixplot`. Returns; -------; If `return_fig` is `True`, returns a :class:`MatrixPlot` object,; else if `show` is false, return axes dict. Examples; --------. .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); sc.tl.rank_genes_groups(adata, 'bulk_labels', n_genes=adata.raw.shape[1]). Plot `logfoldchanges` instead of gene expression. In this case a diverging colormap; like `bwr` or `seismic` works better. To center the colormap in zero, the minimum; and maximum values to plot are set to -4 and 4 respectively.; Also, only genes with a log fold change of 3 or more are shown. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_matrixplot(; adata,; n_genes=4,; values_to_plot=""logfoldchanges"",; cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change',; ). Also, the last genes can be plotted. This can be useful to identify genes; that are lowly expressed in a group. For this `n_genes=-4` is used. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_matrixplot(; adata,; n_genes=-4,; values_to_plot=""logfoldchanges"",; cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change',; ). A list specific genes can be given to check their log fold change. If a; dictionary, the dictionary keys will be added as labels in the plot. .. plot::; :context: close-figs. var_names = {{""T-cell"": ['CD3D', 'CD3E', 'IL32'],; 'B-cell': ['CD79A', 'CD79B', 'MS4A1'],; 'myeloid': ['CST3', 'LYZ'] }}; sc.pl.rank_genes_groups_matrixplot(; adata,; var_names=var_names,; values_to_plot=""logfoldchanges"",; cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change',; ); """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py:1040,log,logfoldchanges,1040,src/scanpy/plotting/_tools/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py,7,['log'],"['log', 'logfoldchanges']"
Testability,"` is replaced by `inplace`. If trying out parameters, pass the data matrix instead of AnnData. Depending on `flavor`, this reproduces the R-implementations of Seurat; :cite:p:`Satija2015` and Cell Ranger :cite:p:`Zheng2017`. The normalized dispersion is obtained by scaling with the mean and standard; deviation of the dispersions for genes falling into a given bin for mean; expression of genes. This means that for each bin of mean expression, highly; variable genes are selected. Use `flavor='cell_ranger'` with care and in the same way as in; :func:`~scanpy.pp.recipe_zheng17`. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; flavor; Choose the flavor for computing normalized dispersion. If choosing; 'seurat', this expects non-logarithmized data – the logarithm of mean; and dispersion is taken internally when `log` is at its default value; `True`. For 'cell_ranger', this is usually called for logarithmized data; – in this case you should set `log` to `False`. In their default; workflows, Seurat passes the cutoffs whereas Cell Ranger passes; `n_top_genes`.; min_mean; max_mean; min_disp; max_disp; If `n_top_genes` unequals `None`, these cutoffs for the means and the; normalized dispersions are ignored.; n_bins; Number of bins for binning the mean gene expression. Normalization is; done with respect to each bin. If just a single gene falls into a bin,; the normalized dispersion is artificially set to 1. You'll be informed; about this if you set `settings.verbosity = 4`.; n_top_genes; Number of highly-variable genes to keep.; log; Use the logarithm of the mean to variance ratio.; subset; Keep highly-variable genes only (if True) else write a bool array for h; ighly-variable genes while keeping all genes; copy; If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned. Returns; -------; If an AnnData `adata` is passed, returns or updates `adata` depending on; `copy",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py:1469,log,logarithmized,1469,src/scanpy/preprocessing/_deprecated/highly_variable_genes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py,2,['log'],"['log', 'logarithmized']"
Testability,"`return_fig` is `True`, returns a :class:`DotPlot` object,; else if `show` is false, return axes dict. Examples; --------. .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); sc.tl.rank_genes_groups(adata, 'bulk_labels', n_genes=adata.raw.shape[1]). Plot top 2 genes per group. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_dotplot(adata,n_genes=2). Plot with scaled expressions for easier identification of differences. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_dotplot(adata, n_genes=2, standard_scale='var'). Plot `logfoldchanges` instead of gene expression. In this case a diverging colormap; like `bwr` or `seismic` works better. To center the colormap in zero, the minimum; and maximum values to plot are set to -4 and 4 respectively.; Also, only genes with a log fold change of 3 or more are shown. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_dotplot(; adata,; n_genes=4,; values_to_plot=""logfoldchanges"", cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change'; ). Also, the last genes can be plotted. This can be useful to identify genes; that are lowly expressed in a group. For this `n_genes=-4` is used. .. plot::; :context: close-figs. sc.pl.rank_genes_groups_dotplot(; adata,; n_genes=-4,; values_to_plot=""logfoldchanges"",; cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change',; ). A list specific genes can be given to check their log fold change. If a; dictionary, the dictionary keys will be added as labels in the plot. .. plot::; :context: close-figs. var_names = {{'T-cell': ['CD3D', 'CD3E', 'IL32'],; 'B-cell': ['CD79A', 'CD79B', 'MS4A1'],; 'myeloid': ['CST3', 'LYZ'] }}; sc.pl.rank_genes_groups_dotplot(; adata,; var_names=var_names,; values_to_plot=""logfoldchanges"",; cmap='bwr',; vmin=-4,; vmax=4,; min_logfoldchange=3,; colorbar_title='log fold change',; ). .. currentmodule:: scanpy. See also; --------; tl.rank_genes_groups; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py:1665,log,logfoldchanges,1665,src/scanpy/plotting/_tools/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/__init__.py,5,['log'],"['log', 'logfoldchanges']"
Testability,"anger'` with care and in the same way as in; :func:`~scanpy.pp.recipe_zheng17`. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; flavor; Choose the flavor for computing normalized dispersion. If choosing; 'seurat', this expects non-logarithmized data – the logarithm of mean; and dispersion is taken internally when `log` is at its default value; `True`. For 'cell_ranger', this is usually called for logarithmized data; – in this case you should set `log` to `False`. In their default; workflows, Seurat passes the cutoffs whereas Cell Ranger passes; `n_top_genes`.; min_mean; max_mean; min_disp; max_disp; If `n_top_genes` unequals `None`, these cutoffs for the means and the; normalized dispersions are ignored.; n_bins; Number of bins for binning the mean gene expression. Normalization is; done with respect to each bin. If just a single gene falls into a bin,; the normalized dispersion is artificially set to 1. You'll be informed; about this if you set `settings.verbosity = 4`.; n_top_genes; Number of highly-variable genes to keep.; log; Use the logarithm of the mean to variance ratio.; subset; Keep highly-variable genes only (if True) else write a bool array for h; ighly-variable genes while keeping all genes; copy; If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned. Returns; -------; If an AnnData `adata` is passed, returns or updates `adata` depending on; `copy`. It filters the `adata` and adds the annotations. **means** : adata.var; Means per gene. Logarithmized when `log` is `True`.; **dispersions** : adata.var; Dispersions per gene. Logarithmized when `log` is `True`.; **dispersions_norm** : adata.var; Normalized dispersions per gene. Logarithmized when `log` is `True`. If a data matrix `X` is passed, the annotation is returned as `np.recarray`; with the same information stored in fields: `gene_subset`, `means`, `dispersions`, `dispersion_norm`.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py:2111,log,log,2111,src/scanpy/preprocessing/_deprecated/highly_variable_genes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py,8,"['Log', 'log']","['Logarithmized', 'log', 'logarithm']"
Testability,"arn.decomposition.PCA` will be used for dimensionality; reduction.; normalize_variance; If True, normalize the data such that each gene has a variance of 1.; `sklearn.decomposition.TruncatedSVD` will be used for dimensionality; reduction, unless `mean_center` is True.; n_prin_comps; Number of principal components used to embed the transcriptomes prior; to k-nearest-neighbor graph construction.; use_approx_neighbors; Use approximate nearest neighbor method (annoy) for the KNN; classifier.; knn_dist_metric; Distance metric used when finding nearest neighbors. For list of; valid values, see the documentation for annoy (if `use_approx_neighbors`; is True) or sklearn.neighbors.NearestNeighbors (if `use_approx_neighbors`; is False).; get_doublet_neighbor_parents; If True, return the parent transcriptomes that generated the; doublet neighbors of each observed transcriptome. This information can; be used to infer the cell states that generated a given; doublet state.; threshold; Doublet score threshold for calling a transcriptome a doublet. If; `None`, this is set automatically by looking for the minimum between; the two modes of the `doublet_scores_sim_` histogram. It is best; practice to check the threshold visually using the; `doublet_scores_sim_` histogram and/or based on co-localization of; predicted doublets in a 2-D embedding.; random_state; Initial state for doublet simulation and nearest neighbors.; verbose; If :data:`True`, log progress updates. Returns; -------; if ``copy=True`` it returns or else adds fields to ``adata``:. ``.obs['doublet_score']``; Doublet scores for each observed transcriptome. ``.obs['predicted_doublets']``; Boolean indicating predicted doublet status. ``.uns['scrublet']['doublet_scores_sim']``; Doublet scores for each simulated doublet transcriptome. ``.uns['scrublet']['doublet_parents']``; Pairs of ``.obs_names`` used to generate each simulated doublet transcriptome. ``.uns['scrublet']['parameters']``; Dictionary of Scrublet parameters; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py:2551,log,log,2551,src/scanpy/preprocessing/_scrublet/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py,1,['log'],['log']
Testability,"emory improvements. More information and bug reports; `here <https://github.com/KrishnaswamyLab/MAGIC>`__. For help, visit; <https://krishnaswamylab.org/get-help>. Parameters; ----------; adata; An anndata file with `.raw` attribute representing raw counts.; name_list; Denoised genes to return. The default `'all_genes'`/`None`; may require a large amount of memory if the input data is sparse.; Another possibility is `'pca_only'`.; knn; number of nearest neighbors on which to build kernel.; decay; sets decay rate of kernel tails.; If None, alpha decaying kernel is not used.; knn_max; maximum number of nearest neighbors with nonzero connection.; If `None`, will be set to 3 * `knn`.; t; power to which the diffusion operator is powered.; This sets the level of diffusion. If 'auto', t is selected; according to the Procrustes disparity of the diffused data.; n_pca; Number of principal components to use for calculating; neighborhoods. For extremely large datasets, using; n_pca < 20 allows neighborhoods to be calculated in; roughly log(n_samples) time. If `None`, no PCA is performed.; solver; Which solver to use. ""exact"" uses the implementation described; in :cite:t:`vanDijk2018`. ""approximate"" uses a faster; implementation that performs imputation in the PCA space and then; projects back to the gene space. Note, the ""approximate"" solver may; return negative values.; knn_dist; recommended values: 'euclidean', 'cosine', 'precomputed'; Any metric from `scipy.spatial.distance` can be used; distance metric for building kNN graph. If 'precomputed',; `data` should be an n_samples x n_samples distance or; affinity matrix.; random_state; Random seed. Defaults to the global `numpy` random number generator.; n_jobs; Number of threads to use in training. All cores are used by default.; verbose; If `True` or an integer `>= 2`, print status messages.; If `None`, `sc.settings.verbosity` is used.; copy; If true, a copy of anndata is returned. If `None`, `copy` is True if; `genes` is not `'",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_magic.py:1672,log,log,1672,src/scanpy/external/pp/_magic.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_magic.py,1,['log'],['log']
Testability,"estimated doublet rate for the; experiment.; stdev_doublet_rate; Where adata_sim not suplied, uncertainty in the expected doublet rate.; synthetic_doublet_umi_subsampling; Where adata_sim not suplied, rate for sampling UMIs when creating; synthetic doublets. If 1.0, each doublet is created by simply adding; the UMI counts from two randomly sampled observed transcriptomes. For; values less than 1, the UMI counts are added and then randomly sampled; at the specified rate.; knn_dist_metric; Distance metric used when finding nearest neighbors. For list of; valid values, see the documentation for annoy (if `use_approx_neighbors`; is True) or sklearn.neighbors.NearestNeighbors (if `use_approx_neighbors`; is False).; normalize_variance; If True, normalize the data such that each gene has a variance of 1.; :class:`sklearn.decomposition.TruncatedSVD` will be used for dimensionality; reduction, unless `mean_center` is True.; log_transform; Whether to use :func:`~scanpy.pp.log1p` to log-transform the data; prior to PCA.; mean_center; If True, center the data such that each gene has a mean of 0.; :class:`sklearn.decomposition.PCA` will be used for dimensionality; reduction.; n_prin_comps; Number of principal components used to embed the transcriptomes prior; to k-nearest-neighbor graph construction.; use_approx_neighbors; Use approximate nearest neighbor method (annoy) for the KNN; classifier.; get_doublet_neighbor_parents; If True, return (in .uns) the parent transcriptomes that generated the; doublet neighbors of each observed transcriptome. This information can; be used to infer the cell states that generated a given doublet state.; n_neighbors; Number of neighbors used to construct the KNN graph of observed; transcriptomes and simulated doublets. If ``None``, this is; automatically set to ``np.round(0.5 * np.sqrt(n_obs))``.; threshold; Doublet score threshold for calling a transcriptome a doublet. If; `None`, this is set automatically by looking for the minimum between; the ",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py:2587,log,log-transform,2587,src/scanpy/preprocessing/_scrublet/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py,1,['log'],['log-transform']
Testability,"hat are good predictors (sparse solution meaning; few non-zero fitted coefficients). Returns; -------; Returns `None` if `copy=False`, else returns an `AnnData` object. Sets the following fields:. `adata.uns['rank_genes_groups' | key_added]['names']` : structured :class:`numpy.ndarray` (dtype `object`); Structured array to be indexed by group id storing the gene; names. Ordered according to scores.; `adata.uns['rank_genes_groups' | key_added]['scores']` : structured :class:`numpy.ndarray` (dtype `object`); Structured array to be indexed by group id storing the z-score; underlying the computation of a p-value for each gene for each; group. Ordered according to scores.; `adata.uns['rank_genes_groups' | key_added]['logfoldchanges']` : structured :class:`numpy.ndarray` (dtype `object`); Structured array to be indexed by group id storing the log2; fold change for each gene for each group. Ordered according to; scores. Only provided if method is 't-test' like.; Note: this is an approximation calculated from mean-log values.; `adata.uns['rank_genes_groups' | key_added]['pvals']` : structured :class:`numpy.ndarray` (dtype `float`); p-values.; `adata.uns['rank_genes_groups' | key_added]['pvals_adj']` : structured :class:`numpy.ndarray` (dtype `float`); Corrected p-values.; `adata.uns['rank_genes_groups' | key_added]['pts']` : :class:`pandas.DataFrame` (dtype `float`); Fraction of cells expressing the genes for each group.; `adata.uns['rank_genes_groups' | key_added]['pts_rest']` : :class:`pandas.DataFrame` (dtype `float`); Only if `reference` is set to `'rest'`.; Fraction of cells from the union of the rest of each group; expressing the genes. Notes; -----; There are slight inconsistencies depending on whether sparse; or dense data are passed. See `here <https://github.com/scverse/scanpy/blob/main/scanpy/tests/test_rank_genes_groups.py>`__. Examples; --------; >>> import scanpy as sc; >>> adata = sc.datasets.pbmc68k_reduced(); >>> sc.tl.rank_genes_groups(adata, 'bulk_labels',",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py:3005,log,log,3005,src/scanpy/tools/_rank_genes_groups.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py,1,['log'],['log']
Testability,"he default method is `'t-test'`,; `'t-test_overestim_var'` overestimates variance of each group,; `'wilcoxon'` uses Wilcoxon rank-sum,; `'logreg'` uses logistic regression. See :cite:t:`Ntranos2019`,; `here <https://github.com/scverse/scanpy/issues/95>`__ and `here; <https://www.nxn.se/valent/2018/3/5/actionable-scrna-seq-clusters>`__,; for why this is meaningful.; corr_method; p-value correction method.; Used only for `'t-test'`, `'t-test_overestim_var'`, and `'wilcoxon'`.; tie_correct; Use tie correction for `'wilcoxon'` scores.; Used only for `'wilcoxon'`.; rankby_abs; Rank genes by the absolute value of the score, not by the; score. The returned scores are never the absolute values.; pts; Compute the fraction of cells expressing the genes.; key_added; The key in `adata.uns` information is saved to.; copy; Whether to copy `adata` or modify it inplace.; kwds; Are passed to test methods. Currently this affects only parameters that; are passed to :class:`sklearn.linear_model.LogisticRegression`.; For instance, you can pass `penalty='l1'` to try to come up with a; minimal set of genes that are good predictors (sparse solution meaning; few non-zero fitted coefficients). Returns; -------; Returns `None` if `copy=False`, else returns an `AnnData` object. Sets the following fields:. `adata.uns['rank_genes_groups' | key_added]['names']` : structured :class:`numpy.ndarray` (dtype `object`); Structured array to be indexed by group id storing the gene; names. Ordered according to scores.; `adata.uns['rank_genes_groups' | key_added]['scores']` : structured :class:`numpy.ndarray` (dtype `object`); Structured array to be indexed by group id storing the z-score; underlying the computation of a p-value for each gene for each; group. Ordered according to scores.; `adata.uns['rank_genes_groups' | key_added]['logfoldchanges']` : structured :class:`numpy.ndarray` (dtype `object`); Structured array to be indexed by group id storing the log2; fold change for each gene for each group. O",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py:1871,Log,LogisticRegression,1871,src/scanpy/tools/_rank_genes_groups.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py,1,['Log'],['LogisticRegression']
Testability,"l1'` to try to come up with a; minimal set of genes that are good predictors (sparse solution meaning; few non-zero fitted coefficients). Returns; -------; Returns `None` if `copy=False`, else returns an `AnnData` object. Sets the following fields:. `adata.uns['rank_genes_groups' | key_added]['names']` : structured :class:`numpy.ndarray` (dtype `object`); Structured array to be indexed by group id storing the gene; names. Ordered according to scores.; `adata.uns['rank_genes_groups' | key_added]['scores']` : structured :class:`numpy.ndarray` (dtype `object`); Structured array to be indexed by group id storing the z-score; underlying the computation of a p-value for each gene for each; group. Ordered according to scores.; `adata.uns['rank_genes_groups' | key_added]['logfoldchanges']` : structured :class:`numpy.ndarray` (dtype `object`); Structured array to be indexed by group id storing the log2; fold change for each gene for each group. Ordered according to; scores. Only provided if method is 't-test' like.; Note: this is an approximation calculated from mean-log values.; `adata.uns['rank_genes_groups' | key_added]['pvals']` : structured :class:`numpy.ndarray` (dtype `float`); p-values.; `adata.uns['rank_genes_groups' | key_added]['pvals_adj']` : structured :class:`numpy.ndarray` (dtype `float`); Corrected p-values.; `adata.uns['rank_genes_groups' | key_added]['pts']` : :class:`pandas.DataFrame` (dtype `float`); Fraction of cells expressing the genes for each group.; `adata.uns['rank_genes_groups' | key_added]['pts_rest']` : :class:`pandas.DataFrame` (dtype `float`); Only if `reference` is set to `'rest'`.; Fraction of cells from the union of the rest of each group; expressing the genes. Notes; -----; There are slight inconsistencies depending on whether sparse; or dense data are passed. See `here <https://github.com/scverse/scanpy/blob/main/scanpy/tests/test_rank_genes_groups.py>`__. Examples; --------; >>> import scanpy as sc; >>> adata = sc.datasets.pbmc68k_reduce",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py:2940,test,test,2940,src/scanpy/tools/_rank_genes_groups.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py,1,['test'],['test']
Testability,"n of PCA that accepts sparse inputs.; This way, we no longer need a temporary dense copy of the sparse data.; However, this implementation is slower and so is only worth using when; memory constraints become noticeable. n_pcs; Determines the number of top principal components selected at each; iteration of the SAM algorithm. If None, this number is chosen; automatically based on the size of the dataset. If weight_pcs is; set to True, this parameter primarily affects the runtime of the SAM; algorithm (more PCs = longer runtime). n_genes; Determines the number of top SAM-weighted genes to use at each iteration; of the SAM algorithm. If None, this number is chosen automatically; based on the size of the dataset. This parameter primarily affects; the runtime of the SAM algorithm (more genes = longer runtime). For; extremely homogeneous datasets, decreasing `n_genes` may improve; clustering resolution. inplace; Set fields in `adata` if True. Otherwise, returns a copy. verbose; If True, displays SAM log statements. Returns; -------; sam_obj if inplace is True or (sam_obj,AnnData) otherwise. adata - AnnData; `.var['weights']`; SAM weights for each gene.; `.var['spatial_dispersions']`; Spatial dispersions for each gene (these are used to compute the; SAM weights); `.uns['sam']`; Dictionary of SAM-specific outputs, such as the parameters; used for preprocessing ('preprocess_args') and running; ('run_args') SAM.; `.uns['neighbors']`; A dictionary with key 'connectivities' containing the kNN adjacency; matrix output by SAM. If built-in scanpy dimensionality reduction; methods are to be used using the SAM-output AnnData, users; should recompute the neighbors using `.obs['X_pca']` with; `scanpy.pp.neighbors`.; `.obsm['X_pca']`; The principal components output by SAM.; `.obsm['X_umap']`; The UMAP projection output by SAM.; `.layers['X_disp']`; The expression matrix used for nearest-neighbor averaging.; `.layers['X_knn_avg']`; The nearest-neighbor-averaged expression data used for ",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_sam.py:2973,log,log,2973,src/scanpy/external/tl/_sam.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_sam.py,1,['log'],['log']
Testability,"r to copy `adata` or modify it inplace.; kwds; Are passed to test methods. Currently this affects only parameters that; are passed to :class:`sklearn.linear_model.LogisticRegression`.; For instance, you can pass `penalty='l1'` to try to come up with a; minimal set of genes that are good predictors (sparse solution meaning; few non-zero fitted coefficients). Returns; -------; Returns `None` if `copy=False`, else returns an `AnnData` object. Sets the following fields:. `adata.uns['rank_genes_groups' | key_added]['names']` : structured :class:`numpy.ndarray` (dtype `object`); Structured array to be indexed by group id storing the gene; names. Ordered according to scores.; `adata.uns['rank_genes_groups' | key_added]['scores']` : structured :class:`numpy.ndarray` (dtype `object`); Structured array to be indexed by group id storing the z-score; underlying the computation of a p-value for each gene for each; group. Ordered according to scores.; `adata.uns['rank_genes_groups' | key_added]['logfoldchanges']` : structured :class:`numpy.ndarray` (dtype `object`); Structured array to be indexed by group id storing the log2; fold change for each gene for each group. Ordered according to; scores. Only provided if method is 't-test' like.; Note: this is an approximation calculated from mean-log values.; `adata.uns['rank_genes_groups' | key_added]['pvals']` : structured :class:`numpy.ndarray` (dtype `float`); p-values.; `adata.uns['rank_genes_groups' | key_added]['pvals_adj']` : structured :class:`numpy.ndarray` (dtype `float`); Corrected p-values.; `adata.uns['rank_genes_groups' | key_added]['pts']` : :class:`pandas.DataFrame` (dtype `float`); Fraction of cells expressing the genes for each group.; `adata.uns['rank_genes_groups' | key_added]['pts_rest']` : :class:`pandas.DataFrame` (dtype `float`); Only if `reference` is set to `'rest'`.; Fraction of cells from the union of the rest of each group; expressing the genes. Notes; -----; There are slight inconsistencies depending on whe",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py:2705,log,logfoldchanges,2705,src/scanpy/tools/_rank_genes_groups.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py,1,['log'],['logfoldchanges']
Testability,"rely annotate the genes, tools like `pp.pca` will; detect the annotation; * you can now call: `sc.pl.highly_variable_genes(adata)`; * `copy` is replaced by `inplace`. If trying out parameters, pass the data matrix instead of AnnData. Depending on `flavor`, this reproduces the R-implementations of Seurat; :cite:p:`Satija2015` and Cell Ranger :cite:p:`Zheng2017`. The normalized dispersion is obtained by scaling with the mean and standard; deviation of the dispersions for genes falling into a given bin for mean; expression of genes. This means that for each bin of mean expression, highly; variable genes are selected. Use `flavor='cell_ranger'` with care and in the same way as in; :func:`~scanpy.pp.recipe_zheng17`. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; flavor; Choose the flavor for computing normalized dispersion. If choosing; 'seurat', this expects non-logarithmized data – the logarithm of mean; and dispersion is taken internally when `log` is at its default value; `True`. For 'cell_ranger', this is usually called for logarithmized data; – in this case you should set `log` to `False`. In their default; workflows, Seurat passes the cutoffs whereas Cell Ranger passes; `n_top_genes`.; min_mean; max_mean; min_disp; max_disp; If `n_top_genes` unequals `None`, these cutoffs for the means and the; normalized dispersions are ignored.; n_bins; Number of bins for binning the mean gene expression. Normalization is; done with respect to each bin. If just a single gene falls into a bin,; the normalized dispersion is artificially set to 1. You'll be informed; about this if you set `settings.verbosity = 4`.; n_top_genes; Number of highly-variable genes to keep.; log; Use the logarithm of the mean to variance ratio.; subset; Keep highly-variable genes only (if True) else write a bool array for h; ighly-variable genes while keeping all genes; copy; If an :class:`~anndata.AnnData` is passed,",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py:1300,log,logarithmized,1300,src/scanpy/preprocessing/_deprecated/highly_variable_genes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_deprecated/highly_variable_genes.py,3,['log'],"['log', 'logarithm', 'logarithmized']"
Testability,"rgument when `adata.X` is a :class:`~dask.array.Array`; will incur blocking `.compute()` calls on the array.; max_fraction; If `exclude_highly_expressed=True`, consider cells as highly expressed; that have more counts than `max_fraction` of the original total counts; in at least one cell.; key_added; Name of the field in `adata.obs` where the normalization factor is; stored.; layer; Layer to normalize instead of `X`. If `None`, `X` is normalized.; inplace; Whether to update `adata` or return dictionary with normalized copies of; `adata.X` and `adata.layers`.; copy; Whether to modify copied input object. Not compatible with inplace=False. Returns; -------; Returns dictionary with normalized copies of `adata.X` and `adata.layers`; or updates `adata` with normalized version of the original; `adata.X` and `adata.layers`, depending on `inplace`. Example; --------; >>> import sys; >>> from anndata import AnnData; >>> import scanpy as sc; >>> sc.settings.verbosity = 'info'; >>> sc.settings.logfile = sys.stdout # for doctests; >>> np.set_printoptions(precision=2); >>> adata = AnnData(np.array([; ... [3, 3, 3, 6, 6],; ... [1, 1, 1, 2, 2],; ... [1, 22, 1, 2, 2],; ... ], dtype='float32')); >>> adata.X; array([[ 3., 3., 3., 6., 6.],; [ 1., 1., 1., 2., 2.],; [ 1., 22., 1., 2., 2.]], dtype=float32); >>> X_norm = sc.pp.normalize_total(adata, target_sum=1, inplace=False)['X']; normalizing counts per cell; finished (0:00:00); >>> X_norm; array([[0.14, 0.14, 0.14, 0.29, 0.29],; [0.14, 0.14, 0.14, 0.29, 0.29],; [0.04, 0.79, 0.04, 0.07, 0.07]], dtype=float32); >>> X_norm = sc.pp.normalize_total(; ... adata, target_sum=1, exclude_highly_expressed=True,; ... max_fraction=0.2, inplace=False; ... )['X']; normalizing counts per cell. The following highly-expressed genes are not considered during normalization factor computation:; ['1', '3', '4']; finished (0:00:00); >>> X_norm; array([[ 0.5, 0.5, 0.5, 1. , 1. ],; [ 0.5, 0.5, 0.5, 1. , 1. ],; [ 0.5, 11. , 0.5, 1. , 1. ]], dtype=float32); """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_normalization.py:2533,log,logfile,2533,src/scanpy/preprocessing/_normalization.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_normalization.py,1,['log'],['logfile']
Testability,"t to this group.; n_genes; The number of genes that appear in the returned tables.; Defaults to all genes.; method; The default method is `'t-test'`,; `'t-test_overestim_var'` overestimates variance of each group,; `'wilcoxon'` uses Wilcoxon rank-sum,; `'logreg'` uses logistic regression. See :cite:t:`Ntranos2019`,; `here <https://github.com/scverse/scanpy/issues/95>`__ and `here; <https://www.nxn.se/valent/2018/3/5/actionable-scrna-seq-clusters>`__,; for why this is meaningful.; corr_method; p-value correction method.; Used only for `'t-test'`, `'t-test_overestim_var'`, and `'wilcoxon'`.; tie_correct; Use tie correction for `'wilcoxon'` scores.; Used only for `'wilcoxon'`.; rankby_abs; Rank genes by the absolute value of the score, not by the; score. The returned scores are never the absolute values.; pts; Compute the fraction of cells expressing the genes.; key_added; The key in `adata.uns` information is saved to.; copy; Whether to copy `adata` or modify it inplace.; kwds; Are passed to test methods. Currently this affects only parameters that; are passed to :class:`sklearn.linear_model.LogisticRegression`.; For instance, you can pass `penalty='l1'` to try to come up with a; minimal set of genes that are good predictors (sparse solution meaning; few non-zero fitted coefficients). Returns; -------; Returns `None` if `copy=False`, else returns an `AnnData` object. Sets the following fields:. `adata.uns['rank_genes_groups' | key_added]['names']` : structured :class:`numpy.ndarray` (dtype `object`); Structured array to be indexed by group id storing the gene; names. Ordered according to scores.; `adata.uns['rank_genes_groups' | key_added]['scores']` : structured :class:`numpy.ndarray` (dtype `object`); Structured array to be indexed by group id storing the z-score; underlying the computation of a p-value for each gene for each; group. Ordered according to scores.; `adata.uns['rank_genes_groups' | key_added]['logfoldchanges']` : structured :class:`numpy.ndarray` (dtype",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py:1769,test,test,1769,src/scanpy/tools/_rank_genes_groups.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py,1,['test'],['test']
Testability,"ta.layers` whose value will be used to perform tests on.; groups; Subset of groups, e.g. [`'g1'`, `'g2'`, `'g3'`], to which comparison; shall be restricted, or `'all'` (default), for all groups. Note that if; `reference='rest'` all groups will still be used as the reference, not; just those specified in `groups`.; reference; If `'rest'`, compare each group to the union of the rest of the group.; If a group identifier, compare with respect to this group.; n_genes; The number of genes that appear in the returned tables.; Defaults to all genes.; method; The default method is `'t-test'`,; `'t-test_overestim_var'` overestimates variance of each group,; `'wilcoxon'` uses Wilcoxon rank-sum,; `'logreg'` uses logistic regression. See :cite:t:`Ntranos2019`,; `here <https://github.com/scverse/scanpy/issues/95>`__ and `here; <https://www.nxn.se/valent/2018/3/5/actionable-scrna-seq-clusters>`__,; for why this is meaningful.; corr_method; p-value correction method.; Used only for `'t-test'`, `'t-test_overestim_var'`, and `'wilcoxon'`.; tie_correct; Use tie correction for `'wilcoxon'` scores.; Used only for `'wilcoxon'`.; rankby_abs; Rank genes by the absolute value of the score, not by the; score. The returned scores are never the absolute values.; pts; Compute the fraction of cells expressing the genes.; key_added; The key in `adata.uns` information is saved to.; copy; Whether to copy `adata` or modify it inplace.; kwds; Are passed to test methods. Currently this affects only parameters that; are passed to :class:`sklearn.linear_model.LogisticRegression`.; For instance, you can pass `penalty='l1'` to try to come up with a; minimal set of genes that are good predictors (sparse solution meaning; few non-zero fitted coefficients). Returns; -------; Returns `None` if `copy=False`, else returns an `AnnData` object. Sets the following fields:. `adata.uns['rank_genes_groups' | key_added]['names']` : structured :class:`numpy.ndarray` (dtype `object`); Structured array to be indexed by gr",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py:1308,test,test,1308,src/scanpy/tools/_rank_genes_groups.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_rank_genes_groups.py,1,['test'],['test']
Testability,"ting raw counts.; mode; `denoise` overwrites `adata.X` with denoised expression values.; In `latent` mode DCA adds `adata.obsm['X_dca']` to given adata; object. This matrix represent latent representation of cells via DCA.; ae_type; Type of the autoencoder. Return values and the architecture is; determined by the type e.g. `nb` does not provide dropout; probabilities. Types that end with ""-conddisp"", assumes that dispersion is mean dependant.; normalize_per_cell; If true, library size normalization is performed using; the `sc.pp.normalize_per_cell` function in Scanpy and saved into adata; object. Mean layer is re-introduces library size differences by; scaling the mean value of each cell in the output layer. See the; manuscript for more details.; scale; If true, the input of the autoencoder is centered using; `sc.pp.scale` function of Scanpy. Note that the output is kept as raw; counts as loss functions are designed for the count data.; log1p; If true, the input of the autoencoder is log transformed with a; pseudocount of one using `sc.pp.log1p` function of Scanpy.; hidden_size; Width of hidden layers.; hidden_dropout; Probability of weight dropout in the autoencoder (per layer if list; or tuple).; batchnorm; If true, batch normalization is performed.; activation; Activation function of hidden layers.; init; Initialization method used to initialize weights.; network_kwds; Additional keyword arguments for the autoencoder.; epochs; Number of total epochs in training.; reduce_lr; Reduces learning rate if validation loss does not improve in given number of epochs.; early_stop; Stops training if validation loss does not improve in given number of epochs.; batch_size; Number of samples in the batch used for SGD.; optimizer; Type of optimization method used for training.; random_state; Seed for python, numpy and tensorflow.; threads; Number of threads to use in training. All cores are used by default.; learning_rate; Learning rate to use in the training.; verbose; If true, ",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_dca.py:1464,log,log,1464,src/scanpy/external/pp/_dca.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_dca.py,1,['log'],['log']
Testability,"transcriptomes prior; to k-nearest-neighbor graph construction.; use_approx_neighbors; Use approximate nearest neighbor method (annoy) for the KNN; classifier.; get_doublet_neighbor_parents; If True, return (in .uns) the parent transcriptomes that generated the; doublet neighbors of each observed transcriptome. This information can; be used to infer the cell states that generated a given doublet state.; n_neighbors; Number of neighbors used to construct the KNN graph of observed; transcriptomes and simulated doublets. If ``None``, this is; automatically set to ``np.round(0.5 * np.sqrt(n_obs))``.; threshold; Doublet score threshold for calling a transcriptome a doublet. If; `None`, this is set automatically by looking for the minimum between; the two modes of the `doublet_scores_sim_` histogram. It is best; practice to check the threshold visually using the; `doublet_scores_sim_` histogram and/or based on co-localization of; predicted doublets in a 2-D embedding.; verbose; If :data:`True`, log progress updates.; copy; If :data:`True`, return a copy of the input ``adata`` with Scrublet results; added. Otherwise, Scrublet results are added in place.; random_state; Initial state for doublet simulation and nearest neighbors. Returns; -------; if ``copy=True`` it returns or else adds fields to ``adata``. Those fields:. ``.obs['doublet_score']``; Doublet scores for each observed transcriptome. ``.obs['predicted_doublet']``; Boolean indicating predicted doublet status. ``.uns['scrublet']['doublet_scores_sim']``; Doublet scores for each simulated doublet transcriptome. ``.uns['scrublet']['doublet_parents']``; Pairs of ``.obs_names`` used to generate each simulated doublet; transcriptome. ``.uns['scrublet']['parameters']``; Dictionary of Scrublet parameters. See also; --------; :func:`~scanpy.pp.scrublet_simulate_doublets`: Run Scrublet's doublet; simulation separately for advanced usage.; :func:`~scanpy.pl.scrublet_score_distribution`: Plot histogram of doublet; scores for ob",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py:3849,log,log,3849,src/scanpy/preprocessing/_scrublet/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py,1,['log'],['log']
Usability," embedding; optimization. Values higher than one will result in greater weight; being given to negative samples.; negative_sample_rate; The number of negative edge/1-simplex samples to use per positive; edge/1-simplex sample in optimizing the low dimensional embedding.; init_pos; How to initialize the low dimensional embedding. Called `init` in the; original UMAP. Options are:. * Any key for `adata.obsm`.; * 'paga': positions from :func:`~scanpy.pl.paga`.; * 'spectral': use a spectral embedding of the graph.; * 'random': assign initial embedding positions at random.; * A numpy array of initial embedding positions.; random_state; If `int`, `random_state` is the seed used by the random number generator;; If `RandomState` or `Generator`, `random_state` is the random number generator;; If `None`, the random number generator is the `RandomState` instance used; by `np.random`.; a; More specific parameters controlling the embedding. If `None` these; values are set automatically as determined by `min_dist` and; `spread`.; b; More specific parameters controlling the embedding. If `None` these; values are set automatically as determined by `min_dist` and; `spread`.; copy; Return a copy instead of writing to adata.; method; Chosen implementation. ``'umap'``; Umap’s simplical set embedding.; ``'rapids'``; GPU accelerated implementation. .. deprecated:: 1.10.0; Use :func:`rapids_singlecell.tl.umap` instead.; neighbors_key; If not specified, umap looks .uns['neighbors'] for neighbors settings; and .obsp['connectivities'] for connectivities; (default storage places for pp.neighbors).; If specified, umap looks .uns[neighbors_key] for neighbors settings and; .obsp[.uns[neighbors_key]['connectivities_key']] for connectivities. Returns; -------; Returns `None` if `copy=False`, else returns an `AnnData` object. Sets the following fields:. `adata.obsm['X_umap']` : :class:`numpy.ndarray` (dtype `float`); UMAP coordinates of data.; `adata.uns['umap']` : :class:`dict`; UMAP parameters. """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_umap.py:2974,simpl,simplical,2974,src/scanpy/tools/_umap.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_umap.py,1,['simpl'],['simplical']
Usability," exactly the same.; If you would like to reproduce the old results, pass a dense array. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; n_comps; Number of principal components to compute. Defaults to 50, or 1 - minimum; dimension size of selected representation.; layer; If provided, which element of layers to use for PCA.; zero_center; If `True`, compute standard PCA from covariance matrix.; If `False`, omit zero-centering variables; (uses *scikit-learn* :class:`~sklearn.decomposition.TruncatedSVD` or; *dask-ml* :class:`~dask_ml.decomposition.TruncatedSVD`),; which allows to handle sparse input efficiently.; Passing `None` decides automatically based on sparseness of the data.; svd_solver; SVD solver to use:. `None`; See `chunked` and `zero_center` descriptions to determine which class will be used.; Depending on the class and the type of X different values for default will be set.; If *scikit-learn* :class:`~sklearn.decomposition.PCA` is used, will give `'arpack'`,; if *scikit-learn* :class:`~sklearn.decomposition.TruncatedSVD` is used, will give `'randomized'`,; if *dask-ml* :class:`~dask_ml.decomposition.PCA` or :class:`~dask_ml.decomposition.IncrementalPCA` is used, will give `'auto'`,; if *dask-ml* :class:`~dask_ml.decomposition.TruncatedSVD` is used, will give `'tsqr'`; `'arpack'`; for the ARPACK wrapper in SciPy (:func:`~scipy.sparse.linalg.svds`); Not available with *dask* arrays.; `'randomized'`; for the randomized algorithm due to Halko (2009). For *dask* arrays,; this will use :func:`~dask.array.linalg.svd_compressed`.; `'auto'`; chooses automatically depending on the size of the problem.; `'lobpcg'`; An alternative SciPy solver. Not available with dask arrays.; `'tsqr'`; Only available with *dask* arrays. ""tsqr""; algorithm from Benson et. al. (2013). .. versionchanged:: 1.9.3; Default value changed from `'arpack'` to None.; .. versionchanged:: 1.4.5; Default value chan",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py:1427,learn,learn,1427,src/scanpy/preprocessing/_pca.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py,1,['learn'],['learn']
Usability," if you install Multicore-tSNE_; by :cite:t:`Ulyanov2016`, which will be automatically detected by Scanpy. .. _multicore-tsne: https://github.com/DmitryUlyanov/Multicore-TSNE. Parameters; ----------; adata; Annotated data matrix.; {doc_n_pcs}; {use_rep}; perplexity; The perplexity is related to the number of nearest neighbors that; is used in other manifold learning algorithms. Larger datasets; usually require a larger perplexity. Consider selecting a value; between 5 and 50. The choice is not extremely critical since t-SNE; is quite insensitive to this parameter.; metric; Distance metric calculate neighbors on.; early_exaggeration; Controls how tight natural clusters in the original space are in the; embedded space and how much space will be between them. For larger; values, the space between natural clusters will be larger in the; embedded space. Again, the choice of this parameter is not very; critical. If the cost function increases during initial optimization,; the early exaggeration factor or the learning rate might be too high.; learning_rate; Note that the R-package ""Rtsne"" uses a default of 200.; The learning rate can be a critical parameter. It should be; between 100 and 1000. If the cost function increases during initial; optimization, the early exaggeration factor or the learning rate; might be too high. If the cost function gets stuck in a bad local; minimum increasing the learning rate helps sometimes.; random_state; Change this to use different intial states for the optimization.; If `None`, the initial state is not reproducible.; n_jobs; Number of jobs for parallel computation.; `None` means using :attr:`scanpy._settings.ScanpyConfig.n_jobs`.; copy; Return a copy instead of writing to `adata`. Returns; -------; Returns `None` if `copy=False`, else returns an `AnnData` object. Sets the following fields:. `adata.obsm['X_tsne']` : :class:`numpy.ndarray` (dtype `float`); tSNE coordinates of data.; `adata.uns['tsne']` : :class:`dict`; tSNE parameters. """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_tsne.py:1492,learn,learning,1492,src/scanpy/tools/_tsne.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_tsne.py,3,['learn'],['learning']
Usability," objects. If adata_sim is; supplied, this should be the observed transcriptomes processed; consistently (filtering, transform, normalisaton, hvg) with adata_sim.; adata_sim; (Advanced use case) Optional annData object generated by; :func:`~scanpy.pp.scrublet_simulate_doublets`, with same number of vars; as adata. This should have been built from adata_obs after; filtering genes and cells and selcting highly-variable genes.; batch_key; Optional :attr:`~anndata.AnnData.obs` column name discriminating between batches.; sim_doublet_ratio; Number of doublets to simulate relative to the number of observed; transcriptomes.; expected_doublet_rate; Where adata_sim not suplied, the estimated doublet rate for the; experiment.; stdev_doublet_rate; Where adata_sim not suplied, uncertainty in the expected doublet rate.; synthetic_doublet_umi_subsampling; Where adata_sim not suplied, rate for sampling UMIs when creating; synthetic doublets. If 1.0, each doublet is created by simply adding; the UMI counts from two randomly sampled observed transcriptomes. For; values less than 1, the UMI counts are added and then randomly sampled; at the specified rate.; knn_dist_metric; Distance metric used when finding nearest neighbors. For list of; valid values, see the documentation for annoy (if `use_approx_neighbors`; is True) or sklearn.neighbors.NearestNeighbors (if `use_approx_neighbors`; is False).; normalize_variance; If True, normalize the data such that each gene has a variance of 1.; :class:`sklearn.decomposition.TruncatedSVD` will be used for dimensionality; reduction, unless `mean_center` is True.; log_transform; Whether to use :func:`~scanpy.pp.log1p` to log-transform the data; prior to PCA.; mean_center; If True, center the data such that each gene has a mean of 0.; :class:`sklearn.decomposition.PCA` will be used for dimensionality; reduction.; n_prin_comps; Number of principal components used to embed the transcriptomes prior; to k-nearest-neighbor graph construction.; use_appro",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py:1894,simpl,simply,1894,src/scanpy/preprocessing/_scrublet/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py,1,['simpl'],['simply']
Usability," of the nodes.; node_size_power; The power with which groups sizes influence the radius of the nodes.; edge_width_scale; Edge with scale in units of `rcParams['lines.linewidth']`.; min_edge_width; Min width of solid edges.; max_edge_width; Max width of solid and dashed edges.; arrowsize; For directed graphs, choose the size of the arrow head head's length and; width. See :py:class: `matplotlib.patches.FancyArrowPatch` for attribute; `mutation_scale` for more info.; export_to_gexf; Export to gexf format to be read by graph visualization programs such as; Gephi.; normalize_to_color; Whether to normalize categorical plots to `color` or the underlying; grouping.; cmap; The color map.; cax; A matplotlib axes object for a potential colorbar.; cb_kwds; Keyword arguments for :class:`~matplotlib.colorbar.Colorbar`,; for instance, `ticks`.; add_pos; Add the positions to `adata.uns['paga']`.; title; Provide a title.; frameon; Draw a frame around the PAGA graph.; plot; If `False`, do not create the figure, simply compute the layout.; save; If `True` or a `str`, save the figure.; A string is appended to the default filename.; Infer the filetype if ending on \\{`'.pdf'`, `'.png'`, `'.svg'`\\}.; ax; A matplotlib axes object. Returns; -------; If `show==False`, one or more :class:`~matplotlib.axes.Axes` objects.; Adds `'pos'` to `adata.uns['paga']` if `add_pos` is `True`. Examples; --------. .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc3k_processed(); sc.tl.paga(adata, groups='louvain'); sc.pl.paga(adata). You can increase node and edge sizes by specifying additional arguments. .. plot::; :context: close-figs. sc.pl.paga(adata, node_size_scale=10, edge_width_scale=2). Notes; -----; When initializing the positions, note that – for some reason – igraph; mirrors coordinates along the x axis... that is, you should increase the; `maxiter` parameter by 1 if the layout is flipped. .. currentmodule:: scanpy. See also; --------; tl.paga; pl.paga_compare; pl.",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/paga.py:4063,simpl,simply,4063,src/scanpy/plotting/_tools/paga.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/paga.py,1,['simpl'],['simply']
Usability," of umap-learn_ :cite:p:`McInnes2018`.; For a few comparisons of UMAP with tSNE, see :cite:t:`Becht2018`. .. _umap-learn: https://github.com/lmcinnes/umap. Parameters; ----------; adata; Annotated data matrix.; min_dist; The effective minimum distance between embedded points. Smaller values; will result in a more clustered/clumped embedding where nearby points on; the manifold are drawn closer together, while larger values will result; on a more even dispersal of points. The value should be set relative to; the ``spread`` value, which determines the scale at which embedded; points will be spread out. The default of in the `umap-learn` package is; 0.1.; spread; The effective scale of embedded points. In combination with `min_dist`; this determines how clustered/clumped the embedded points are.; n_components; The number of dimensions of the embedding.; maxiter; The number of iterations (epochs) of the optimization. Called `n_epochs`; in the original UMAP.; alpha; The initial learning rate for the embedding optimization.; gamma; Weighting applied to negative samples in low dimensional embedding; optimization. Values higher than one will result in greater weight; being given to negative samples.; negative_sample_rate; The number of negative edge/1-simplex samples to use per positive; edge/1-simplex sample in optimizing the low dimensional embedding.; init_pos; How to initialize the low dimensional embedding. Called `init` in the; original UMAP. Options are:. * Any key for `adata.obsm`.; * 'paga': positions from :func:`~scanpy.pl.paga`.; * 'spectral': use a spectral embedding of the graph.; * 'random': assign initial embedding positions at random.; * A numpy array of initial embedding positions.; random_state; If `int`, `random_state` is the seed used by the random number generator;; If `RandomState` or `Generator`, `random_state` is the random number generator;; If `None`, the random number generator is the `RandomState` instance used; by `np.random`.; a; More specific ",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_umap.py:1589,learn,learning,1589,src/scanpy/tools/_umap.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_umap.py,1,['learn'],['learning']
Usability," than tSNE, it optimizes the embedding such that it best reflects; the topology of the data, which we represent throughout Scanpy using a; neighborhood graph. tSNE, by contrast, optimizes the distribution of; nearest-neighbor distances in the embedding such that these best match the; distribution of distances in the high-dimensional space.; We use the implementation of umap-learn_ :cite:p:`McInnes2018`.; For a few comparisons of UMAP with tSNE, see :cite:t:`Becht2018`. .. _umap-learn: https://github.com/lmcinnes/umap. Parameters; ----------; adata; Annotated data matrix.; min_dist; The effective minimum distance between embedded points. Smaller values; will result in a more clustered/clumped embedding where nearby points on; the manifold are drawn closer together, while larger values will result; on a more even dispersal of points. The value should be set relative to; the ``spread`` value, which determines the scale at which embedded; points will be spread out. The default of in the `umap-learn` package is; 0.1.; spread; The effective scale of embedded points. In combination with `min_dist`; this determines how clustered/clumped the embedded points are.; n_components; The number of dimensions of the embedding.; maxiter; The number of iterations (epochs) of the optimization. Called `n_epochs`; in the original UMAP.; alpha; The initial learning rate for the embedding optimization.; gamma; Weighting applied to negative samples in low dimensional embedding; optimization. Values higher than one will result in greater weight; being given to negative samples.; negative_sample_rate; The number of negative edge/1-simplex samples to use per positive; edge/1-simplex sample in optimizing the low dimensional embedding.; init_pos; How to initialize the low dimensional embedding. Called `init` in the; original UMAP. Options are:. * Any key for `adata.obsm`.; * 'paga': positions from :func:`~scanpy.pl.paga`.; * 'spectral': use a spectral embedding of the graph.; * 'random': assign ",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_umap.py:1237,learn,learn,1237,src/scanpy/tools/_umap.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_umap.py,1,['learn'],['learn']
Usability,"""""""; Simulates static data to investigate structure learning.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:52,learn,learning,52,src/scanpy/tools/_sim.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py,1,['learn'],['learning']
Usability,"""""""; Test that Harmony integrate works. This is a very simple test that just checks to see if the Harmony; integrate wrapper succesfully added a new field to ``adata.obsm``; and makes sure it has the same dimensions as the original PCA table.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/external/test_harmony_integrate.py:55,simpl,simple,55,tests/external/test_harmony_integrate.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/external/test_harmony_integrate.py,1,['simpl'],['simple']
Usability,"""""""; Test that Scanorama integration works. This is a very simple test that just checks to see if the Scanorama; integrate wrapper succesfully added a new field to ``adata.obsm``; and makes sure it has the same dimensions as the original PCA table.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/external/test_scanorama_integrate.py:59,simpl,simple,59,tests/external/test_scanorama_integrate.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/external/test_scanorama_integrate.py,1,['simpl'],['simple']
Usability,"""""""Simple Preprocessing Functions. Compositions of these functions are found in sc.preprocess.recipes.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:3,Simpl,Simple,3,src/scanpy/preprocessing/_simple.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py,1,['Simpl'],['Simple']
Usability,"""""""Simulate doublets by adding the counts of random observed transcriptome pairs. Arguments; ---------; sim_doublet_ratio; Number of doublets to simulate relative to the number of observed; transcriptomes. If `None`, self.sim_doublet_ratio is used. synthetic_doublet_umi_subsampling; Rate for sampling UMIs when creating synthetic doublets.; If 1.0, each doublet is created by simply adding the UMIs from two randomly; sampled observed transcriptomes.; For values less than 1, the UMI counts are added and then randomly sampled; at the specified rate. Sets; ----; doublet_parents_; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/core.py:377,simpl,simply,377,src/scanpy/preprocessing/_scrublet/core.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/core.py,1,['simpl'],['simply']
Usability,"""""""\; A simple interface to biomart. Params; ------; {doc_org}; attrs; What you want returned.; filters; What you want to pick out.; {doc_host}; {doc_use_cache}; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/queries/_queries.py:8,simpl,simple,8,src/scanpy/queries/_queries.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/queries/_queries.py,1,['simpl'],['simple']
Usability,"""""""\; Allows the visualization of values using a color map. Parameters; ----------; {common_plot_args}; title; Title for the figure.; expression_cutoff; Expression cutoff that is used for binarizing the gene expression and; determining the fraction of cells expressing given genes. A gene is; expressed only if the expression value is greater than this threshold.; mean_only_expressed; If True, gene expression is averaged only over the cells; expressing the given genes.; standard_scale; Whether or not to standardize that dimension between 0 and 1,; meaning for each variable or group,; subtract the minimum and divide each by its maximum.; values_df; Optionally, a dataframe with the values to plot can be given. The; index should be the grouby categories and the columns the genes names. kwds; Are passed to :func:`matplotlib.pyplot.scatter`. See also; --------; :func:`~scanpy.pl.matrixplot`: Simpler way to call MatrixPlot but with less options.; :func:`~scanpy.pl.rank_genes_groups_matrixplot`: to plot marker genes identified; using the :func:`~scanpy.tl.rank_genes_groups` function. Examples; --------. Simple visualization of the average expression of a few genes grouped by; the category 'bulk_labels'. .. plot::; :context: close-figs. import scanpy as sc; adata = sc.datasets.pbmc68k_reduced(); markers = ['C1QA', 'PSAP', 'CD79A', 'CD79B', 'CST3', 'LYZ']; sc.pl.MatrixPlot(adata, markers, groupby='bulk_labels').show(). Same visualization but passing var_names as dict, which adds a grouping of; the genes on top of the image:. .. plot::; :context: close-figs. markers = {{'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}}; sc.pl.MatrixPlot(adata, markers, groupby='bulk_labels').show(); """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_matrixplot.py:898,Simpl,Simpler,898,src/scanpy/plotting/_matrixplot.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_matrixplot.py,2,['Simpl'],"['Simple', 'Simpler']"
Usability,"""""""\; Compute eigen decomposition of transition matrix. Parameters; ----------; n_comps; Number of eigenvalues/vectors to be computed, set `n_comps = 0` if; you need all eigenvectors.; sym; Instead of computing the eigendecomposition of the assymetric; transition matrix, computed the eigendecomposition of the symmetric; Ktilde matrix.; random_state; A numpy random seed. Returns; -------; Writes the following attributes. eigen_values : :class:`~numpy.ndarray`; Eigenvalues of transition matrix.; eigen_basis : :class:`~numpy.ndarray`; Matrix of eigenvectors (stored in columns). `.eigen_basis` is; projection of data matrix on right eigenvectors, that is, the; projection on the diffusion components. these are simply the; components of the right eigenvectors and can directly be used for; plotting.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/__init__.py:714,simpl,simply,714,src/scanpy/neighbors/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/__init__.py,1,['simpl'],['simply']
Usability,"""""""\; Computes a simple design matrix. Parameters; --------; model; Contains the batch annotation; batch_key; Name of the batch column; batch_levels; Levels of the batch annotation. Returns; --------; The design matrix for the regression problem; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_combat.py:17,simpl,simple,17,src/scanpy/preprocessing/_combat.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_combat.py,1,['simpl'],['simple']
Usability,"""""""\; Embed the neighborhood graph using UMAP :cite:p:`McInnes2018`. UMAP (Uniform Manifold Approximation and Projection) is a manifold learning; technique suitable for visualizing high-dimensional data. Besides tending to; be faster than tSNE, it optimizes the embedding such that it best reflects; the topology of the data, which we represent throughout Scanpy using a; neighborhood graph. tSNE, by contrast, optimizes the distribution of; nearest-neighbor distances in the embedding such that these best match the; distribution of distances in the high-dimensional space.; We use the implementation of umap-learn_ :cite:p:`McInnes2018`.; For a few comparisons of UMAP with tSNE, see :cite:t:`Becht2018`. .. _umap-learn: https://github.com/lmcinnes/umap. Parameters; ----------; adata; Annotated data matrix.; min_dist; The effective minimum distance between embedded points. Smaller values; will result in a more clustered/clumped embedding where nearby points on; the manifold are drawn closer together, while larger values will result; on a more even dispersal of points. The value should be set relative to; the ``spread`` value, which determines the scale at which embedded; points will be spread out. The default of in the `umap-learn` package is; 0.1.; spread; The effective scale of embedded points. In combination with `min_dist`; this determines how clustered/clumped the embedded points are.; n_components; The number of dimensions of the embedding.; maxiter; The number of iterations (epochs) of the optimization. Called `n_epochs`; in the original UMAP.; alpha; The initial learning rate for the embedding optimization.; gamma; Weighting applied to negative samples in low dimensional embedding; optimization. Values higher than one will result in greater weight; being given to negative samples.; negative_sample_rate; The number of negative edge/1-simplex samples to use per positive; edge/1-simplex sample in optimizing the low dimensional embedding.; init_pos; How to initialize the",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_umap.py:136,learn,learning,136,src/scanpy/tools/_umap.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_umap.py,2,['learn'],"['learn', 'learning']"
Usability,"""""""\; Map labels and embeddings from reference data to new data. :doc:`/tutorials/basics/integrating-data-using-ingest`. Integrates embeddings and annotations of an `adata` with a reference dataset; `adata_ref` through projecting on a PCA (or alternate; model) that has been fitted on the reference data. The function uses a knn; classifier for mapping labels and the UMAP package :cite:p:`McInnes2018` for mapping; the embeddings. .. note::. We refer to this *asymmetric* dataset integration as *ingesting*; annotations from reference data to new data. This is different from; learning a joint representation that integrates both datasets in an; unbiased way, as CCA (e.g. in Seurat) or a conditional VAE (e.g. in; scVI) would do. You need to run :func:`~scanpy.pp.neighbors` on `adata_ref` before; passing it. Parameters; ----------; adata; The annotated data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes. This is the dataset without labels and; embeddings.; adata_ref; The annotated data matrix of shape `n_obs` × `n_vars`. Rows correspond; to cells and columns to genes.; Variables (`n_vars` and `var_names`) of `adata_ref` should be the same; as in `adata`.; This is the dataset with labels and embeddings; which need to be mapped to `adata`.; obs; Labels' keys in `adata_ref.obs` which need to be mapped to `adata.obs`; (inferred for observation of `adata`).; embedding_method; Embeddings in `adata_ref` which need to be mapped to `adata`.; The only supported values are 'umap' and 'pca'.; labeling_method; The method to map labels in `adata_ref.obs` to `adata.obs`.; The only supported value is 'knn'.; neighbors_key; If not specified, ingest looks adata_ref.uns['neighbors']; for neighbors settings and adata_ref.obsp['distances'] for; distances (default storage places for pp.neighbors).; If specified, ingest looks adata_ref.uns[neighbors_key] for; neighbors settings and; adata_ref.obsp[adata_ref.uns[neighbors_key]['distances_key']] for distances.; in",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_ingest.py:578,learn,learning,578,src/scanpy/tools/_ingest.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_ingest.py,1,['learn'],['learning']
Usability,"""""""\; Mapping out the coarse-grained connectivity structures of complex manifolds :cite:p:`Wolf2019`. By quantifying the connectivity of partitions (groups, clusters) of the; single-cell graph, partition-based graph abstraction (PAGA) generates a much; simpler abstracted graph (*PAGA graph*) of partitions, in which edge weights; represent confidence in the presence of connections. By thresholding this; confidence in :func:`~scanpy.pl.paga`, a much simpler representation of the; manifold data is obtained, which is nonetheless faithful to the topology of; the manifold. The confidence should be interpreted as the ratio of the actual versus the; expected value of connections under the null model of randomly connecting; partitions. We do not provide a p-value as this null model does not; precisely capture what one would consider ""connected"" in real data, hence it; strongly overestimates the expected value. See an extensive discussion of; this in :cite:t:`Wolf2019`. .. note::; Note that you can use the result of :func:`~scanpy.pl.paga` in; :func:`~scanpy.tl.umap` and :func:`~scanpy.tl.draw_graph` via; `init_pos='paga'` to get single-cell embeddings that are typically more; faithful to the global topology. Parameters; ----------; adata; An annotated data matrix.; groups; Key for categorical in `adata.obs`. You can pass your predefined groups; by choosing any categorical annotation of observations. Default:; The first present key of `'leiden'` or `'louvain'`.; use_rna_velocity; Use RNA velocity to orient edges in the abstracted graph and estimate; transitions. Requires that `adata.uns` contains a directed single-cell; graph with key `['velocity_graph']`. This feature might be subject; to change in the future.; model; The PAGA connectivity model.; neighbors_key; If not specified, paga looks `.uns['neighbors']` for neighbors settings; and `.obsp['connectivities']`, `.obsp['distances']` for connectivities and; distances respectively (default storage places for `pp.neighbors`).;",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_paga.py:253,simpl,simpler,253,src/scanpy/tools/_paga.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_paga.py,2,['simpl'],['simpler']
Usability,"""""""\; Plot the PAGA graph through thresholding low-connectivity edges. Compute a coarse-grained layout of the data. Reuse this by passing; `init_pos='paga'` to :func:`~scanpy.tl.umap` or; :func:`~scanpy.tl.draw_graph` and obtain embeddings with more meaningful; global topology :cite:p:`Wolf2019`. This uses ForceAtlas2 or igraph's layout algorithms for most layouts :cite:p:`Csardi2006`. Parameters; ----------; adata; Annotated data matrix.; threshold; Do not draw edges for weights below this threshold. Set to 0 if you want; all edges. Discarding low-connectivity edges helps in getting a much; clearer picture of the graph.; color; Gene name or `obs` annotation defining the node colors.; Also plots the degree of the abstracted graph when; passing {`'degree_dashed'`, `'degree_solid'`}. Can be also used to visualize pie chart at each node in the following form:; `{<group name or index>: {<color>: <fraction>, ...}, ...}`. If the fractions; do not sum to 1, a new category called `'rest'` colored grey will be created.; labels; The node labels. If `None`, this defaults to the group labels stored in; the categorical for which :func:`~scanpy.tl.paga` has been computed.; pos; Two-column array-like storing the x and y coordinates for drawing.; Otherwise, path to a `.gdf` file that has been exported from Gephi or; a similar graph visualization software.; layout; Plotting layout that computes positions.; `'fa'` stands for “ForceAtlas2”,; `'fr'` stands for “Fruchterman-Reingold”,; `'rt'` stands for “Reingold-Tilford”,; `'eq_tree'` stands for “eqally spaced tree”.; All but `'fa'` and `'eq_tree'` are igraph layouts.; All other igraph layouts are also permitted.; See also parameter `pos` and :func:`~scanpy.tl.draw_graph`.; layout_kwds; Keywords for the layout.; init_pos; Two-column array storing the x and y coordinates for initializing the; layout.; random_state; For layouts with random initialization like `'fr'`, change this to use; different intial states for the optimization. If `No",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/paga.py:599,clear,clearer,599,src/scanpy/plotting/_tools/paga.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_tools/paga.py,1,['clear'],['clearer']
Usability,"""""""\; Principal component analysis :cite:p:`Pedregosa2011`. Computes PCA coordinates, loadings and variance decomposition.; Uses the implementation of *scikit-learn* :cite:p:`Pedregosa2011`. .. versionchanged:: 1.5.0. In previous versions, computing a PCA on a sparse matrix would make; a dense copy of the array for mean centering.; As of scanpy 1.5.0, mean centering is implicit.; While results are extremely similar, they are not exactly the same.; If you would like to reproduce the old results, pass a dense array. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; n_comps; Number of principal components to compute. Defaults to 50, or 1 - minimum; dimension size of selected representation.; layer; If provided, which element of layers to use for PCA.; zero_center; If `True`, compute standard PCA from covariance matrix.; If `False`, omit zero-centering variables; (uses *scikit-learn* :class:`~sklearn.decomposition.TruncatedSVD` or; *dask-ml* :class:`~dask_ml.decomposition.TruncatedSVD`),; which allows to handle sparse input efficiently.; Passing `None` decides automatically based on sparseness of the data.; svd_solver; SVD solver to use:. `None`; See `chunked` and `zero_center` descriptions to determine which class will be used.; Depending on the class and the type of X different values for default will be set.; If *scikit-learn* :class:`~sklearn.decomposition.PCA` is used, will give `'arpack'`,; if *scikit-learn* :class:`~sklearn.decomposition.TruncatedSVD` is used, will give `'randomized'`,; if *dask-ml* :class:`~dask_ml.decomposition.PCA` or :class:`~dask_ml.decomposition.IncrementalPCA` is used, will give `'auto'`,; if *dask-ml* :class:`~dask_ml.decomposition.TruncatedSVD` is used, will give `'tsqr'`; `'arpack'`; for the ARPACK wrapper in SciPy (:func:`~scipy.sparse.linalg.svds`); Not available with *dask* arrays.; `'randomized'`; for the randomized algorithm due to Halko (2009). Fo",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py:159,learn,learn,159,src/scanpy/preprocessing/_pca.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py,2,['learn'],['learn']
Usability,"""""""\; Read 10x-Genomics-formatted hdf5 file. Parameters; ----------; filename; Path to a 10x hdf5 file.; genome; Filter expression to genes within this genome. For legacy 10x h5; files, this must be provided if the data contains more than one genome.; gex_only; Only keep 'Gene Expression' data and ignore other feature types,; e.g. 'Antibody Capture', 'CRISPR Guide Capture', or 'Custom'; backup_url; Retrieve the file from an URL if not present on disk. Returns; -------; Annotated data matrix, where observations/cells are named by their; barcode and variables/genes by gene name. Stores the following information:. :attr:`~anndata.AnnData.X`; The data matrix is stored; :attr:`~anndata.AnnData.obs_names`; Cell names; :attr:`~anndata.AnnData.var_names`; Gene names for a feature barcode matrix, probe names for a probe bc matrix; :attr:`~anndata.AnnData.var`\\ `['gene_ids']`; Gene IDs; :attr:`~anndata.AnnData.var`\\ `['feature_types']`; Feature types; :attr:`~anndata.AnnData.obs`\\ `[filtered_barcodes]`; filtered barcodes if present in the matrix; :attr:`~anndata.AnnData.var`; Any additional metadata present in /matrix/features is read in.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py:361,Guid,Guide,361,src/scanpy/readwrite.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py,1,['Guid'],['Guide']
Usability,"""""""\; Read 10x-Genomics-formatted mtx directory. Parameters; ----------; path; Path to directory for `.mtx` and `.tsv` files,; e.g. './filtered_gene_bc_matrices/hg19/'.; var_names; The variables index.; make_unique; Whether to make the variables index unique by appending '-1',; '-2' etc. or not.; cache; If `False`, read from source, if `True`, read from fast 'h5ad' cache.; cache_compression; See the h5py :ref:`dataset_compression`.; (Default: `settings.cache_compression`); gex_only; Only keep 'Gene Expression' data and ignore other feature types,; e.g. 'Antibody Capture', 'CRISPR Guide Capture', or 'Custom'; prefix; Any prefix before `matrix.mtx`, `genes.tsv` and `barcodes.tsv`. For instance,; if the files are named `patientA_matrix.mtx`, `patientA_genes.tsv` and; `patientA_barcodes.tsv` the prefix is `patientA_`.; (Default: no prefix). Returns; -------; An :class:`~anndata.AnnData` object; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py:587,Guid,Guide,587,src/scanpy/readwrite.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py,1,['Guid'],['Guide']
Usability,"""""""\; Regress out (mostly) unwanted sources of variation. Uses simple linear regression. This is inspired by Seurat's `regressOut`; function in R :cite:p:`Satija2015`. Note that this function tends to overcorrect; in certain circumstances as described in :issue:`526`. Parameters; ----------; adata; The annotated data matrix.; keys; Keys for observation annotation on which to regress on.; layer; If provided, which element of layers to regress on.; n_jobs; Number of jobs for parallel computation.; `None` means using :attr:`scanpy._settings.ScanpyConfig.n_jobs`.; copy; Determines whether a copy of `adata` is returned. Returns; -------; Returns `None` if `copy=False`, else returns an updated `AnnData` object. Sets the following fields:. `adata.X` | `adata.layers[layer]` : :class:`numpy.ndarray` | :class:`scipy.sparse._csr.csr_matrix` (dtype `float`); Corrected count data matrix.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:63,simpl,simple,63,src/scanpy/preprocessing/_simple.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py,1,['simpl'],['simple']
Usability,"""""""\; Simulate doublets by adding the counts of random observed transcriptome pairs. Parameters; ----------; adata; The annotated data matrix of shape ``n_obs`` × ``n_vars``. Rows; correspond to cells and columns to genes. Genes should have been; filtered for expression and variability, and the object should contain; raw expression of the same dimensions.; layer; Layer of adata where raw values are stored, or 'X' if values are in .X.; sim_doublet_ratio; Number of doublets to simulate relative to the number of observed; transcriptomes. If `None`, self.sim_doublet_ratio is used.; synthetic_doublet_umi_subsampling; Rate for sampling UMIs when creating synthetic doublets. If 1.0,; each doublet is created by simply adding the UMIs from two randomly; sampled observed transcriptomes. For values less than 1, the; UMI counts are added and then randomly sampled at the specified; rate. Returns; -------; adata : anndata.AnnData with simulated doublets in .X; Adds fields to ``adata``:. ``.obsm['scrublet']['doublet_parents']``; Pairs of ``.obs_names`` used to generate each simulated doublet transcriptome. ``.uns['scrublet']['parameters']``; Dictionary of Scrublet parameters. See also; --------; :func:`~scanpy.pp.scrublet`: Main way of running Scrublet, runs; preprocessing, doublet simulation (this function) and calling.; :func:`~scanpy.pl.scrublet_score_distribution`: Plot histogram of doublet; scores for observed transcriptomes and simulated doublets.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py:713,simpl,simply,713,src/scanpy/preprocessing/_scrublet/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_scrublet/__init__.py,1,['simpl'],['simply']
Usability,"""""""\; Simulated toggleswitch. Data obtained simulating a simple toggleswitch :cite:p:`Gardner2000`. Simulate via :func:`~scanpy.tl.sim`. Returns; -------; Annotated data matrix. Examples; --------; >>> import scanpy as sc; >>> sc.datasets.toggleswitch(); UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; utils.warn_names_duplicates(""obs""); AnnData object with n_obs × n_vars = 200 × 2; uns: 'iroot'; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py:57,simpl,simple,57,src/scanpy/datasets/_datasets.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/datasets/_datasets.py,1,['simpl'],['simple']
Usability,"""""""\; This is from umap.fuzzy_simplicial_set :cite:p:`McInnes2018`. Given a set of data X, a neighborhood size, and a measure of distance; compute the fuzzy simplicial set (here represented as a fuzzy graph in; the form of a sparse matrix) associated to the data. This is done by; locally approximating geodesic distance at each point, creating a fuzzy; simplicial set for each such point, and then combining all the local; fuzzy simplicial sets into a global one via a fuzzy union.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/_connectivity.py:157,simpl,simplicial,157,src/scanpy/neighbors/_connectivity.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/neighbors/_connectivity.py,3,['simpl'],['simplicial']
Usability,"""""""\; TriMap: Large-scale Dimensionality Reduction Using Triplets :cite:p:`Amid2019`. TriMap is a dimensionality reduction method that uses triplet constraints; to form a low-dimensional embedding of a set of points. The triplet; constraints are of the form ""point i is closer to point j than point k"".; The triplets are sampled from the high-dimensional representation of the; points and a weighting scheme is used to reflect the importance of each; triplet. TriMap provides a significantly better global view of the data than the; other dimensionality reduction methods such t-SNE, LargeVis, and UMAP.; The global structure includes relative distances of the clusters, multiple; scales in the data, and the existence of possible outliers. We define a; global score to quantify the quality of an embedding in reflecting the; global structure of the data. Parameters; ----------; adata; Annotated data matrix.; n_components; Number of dimensions of the embedding.; n_inliers; Number of inlier points for triplet constraints.; n_outliers; Number of outlier points for triplet constraints.; n_random; Number of random triplet constraints per point.; metric; Distance measure: 'angular', 'euclidean', 'hamming', 'manhattan'.; weight_adj; Adjusting the weights using a non-linear transformation.; lr; Learning rate.; n_iters; Number of iterations.; verbose; If `True`, print the progress report.; If `None`, `sc.settings.verbosity` is used.; copy; Return a copy instead of writing to `adata`. Returns; -------; Depending on `copy`, returns or updates `adata` with the following fields. **X_trimap** : :class:`~numpy.ndarray`, (:attr:`~anndata.AnnData.obsm`, shape=(n_samples, n_components), dtype `float`); TriMap coordinates of data. Example; -------. >>> import scanpy as sc; >>> import scanpy.external as sce; >>> pbmc = sc.datasets.pbmc68k_reduced(); >>> pbmc = sce.tl.trimap(pbmc, copy=True); >>> sce.pl.trimap(pbmc, color=['bulk_labels'], s=10); """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_trimap.py:1297,Learn,Learning,1297,src/scanpy/external/tl/_trimap.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_trimap.py,1,['Learn'],['Learning']
Usability,"""""""\; n_top_genes; Number of highly-variable genes to keep. Mandatory if `flavor='seurat_v3'` or; `flavor='pearson_residuals'`.; batch_key; If specified, highly-variable genes are selected within each batch separately; and merged. This simple process avoids the selection of batch-specific genes; and acts as a lightweight batch correction method. Genes are first sorted by; how many batches they are a HVG. If `flavor='pearson_residuals'`, ties are; broken by the median rank (across batches) based on within-batch residual; variance.; chunksize; If `flavor='pearson_residuals'`, this dertermines how many genes are processed at; once while computing the residual variance. Choosing a smaller value will reduce; the required memory.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/_docs.py:236,simpl,simple,236,src/scanpy/experimental/_docs.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/experimental/_docs.py,1,['simpl'],['simple']
Usability,"""""""\; t-SNE :cite:p:`vanDerMaaten2008,Amir2013,Pedregosa2011`. t-distributed stochastic neighborhood embedding (tSNE, :cite:t:`vanDerMaaten2008`) has been; proposed for visualizating single-cell data by :cite:t:`Amir2013`. Here, by default,; we use the implementation of *scikit-learn* :cite:p:`Pedregosa2011`. You can achieve; a huge speedup and better convergence if you install Multicore-tSNE_; by :cite:t:`Ulyanov2016`, which will be automatically detected by Scanpy. .. _multicore-tsne: https://github.com/DmitryUlyanov/Multicore-TSNE. Parameters; ----------; adata; Annotated data matrix.; {doc_n_pcs}; {use_rep}; perplexity; The perplexity is related to the number of nearest neighbors that; is used in other manifold learning algorithms. Larger datasets; usually require a larger perplexity. Consider selecting a value; between 5 and 50. The choice is not extremely critical since t-SNE; is quite insensitive to this parameter.; metric; Distance metric calculate neighbors on.; early_exaggeration; Controls how tight natural clusters in the original space are in the; embedded space and how much space will be between them. For larger; values, the space between natural clusters will be larger in the; embedded space. Again, the choice of this parameter is not very; critical. If the cost function increases during initial optimization,; the early exaggeration factor or the learning rate might be too high.; learning_rate; Note that the R-package ""Rtsne"" uses a default of 200.; The learning rate can be a critical parameter. It should be; between 100 and 1000. If the cost function increases during initial; optimization, the early exaggeration factor or the learning rate; might be too high. If the cost function gets stuck in a bad local; minimum increasing the learning rate helps sometimes.; random_state; Change this to use different intial states for the optimization.; If `None`, the initial state is not reproducible.; n_jobs; Number of jobs for parallel computation.; `None` means u",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_tsne.py:279,learn,learn,279,src/scanpy/tools/_tsne.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_tsne.py,2,['learn'],"['learn', 'learning']"
Usability,"# # allow negative feedback; # if self.model == 10:; # plus_minus = (np.random.randint(0,2,n_sinknodes) - 0.5)*2; # self.Adj_signed[sinknodes,sinknodes] = plus_minus",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:19,feedback,feedback,19,src/scanpy/tools/_sim.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py,1,['feedback'],['feedback']
Usability,"# -------------------------------------------------------------------------------; # Simple plotting functions; # -------------------------------------------------------------------------------",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_utils.py:85,Simpl,Simple,85,src/scanpy/plotting/_utils.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_utils.py,1,['Simpl'],['Simple']
Usability,"# Currently undocumented; # https://github.com/mwaskom/seaborn/issues/1810",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/docs/conf.py:12,undo,undocumented,12,docs/conf.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/docs/conf.py,1,['undo'],['undocumented']
Usability,"# Just to keep it simple, as a dense matrix",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_qc.py:18,simpl,simple,18,src/scanpy/preprocessing/_qc.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_qc.py,1,['simpl'],['simple']
Usability,"# Simple method that can be called by rank_gene_group. It uses masks that have been passed to the function and; # calculates how much has to be subsampled in order to reach a certain precision with a certain probability; # Then it subsamples for mask, mask rest; # Since convergence speed varies, we take the slower one, i.e. the variance. This might have future speed-up; # potential",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_top_genes.py:2,Simpl,Simple,2,src/scanpy/tools/_top_genes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_top_genes.py,1,['Simpl'],['Simple']
Usability,"# Test images are saved in the directory ./_images/<test-name>/; # If test images need to be updated, simply copy actual.png to expected.png.",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py:102,simpl,simply,102,tests/test_plotting.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_plotting.py,1,['simpl'],['simply']
Usability,"# We test results for a simple generic example; # Tests are conducted for sparse and non-sparse AnnData objects.; # Due to minor changes in multiplication implementation for sparse and non-sparse objects,; # results differ (very) slightly",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_rank_genes_groups.py:24,simpl,simple,24,tests/test_rank_genes_groups.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_rank_genes_groups.py,1,['simpl'],['simple']
Usability,"# clear figure",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_utils.py:2,clear,clear,2,src/scanpy/plotting/_utils.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_utils.py,1,['clear'],['clear']
Usability,"# compute the score as ratio of the added distance to the third tip,; # to what it would be if it were on the straight line between the; # two first tips, given by Dseg[tips[:2]]; # if we did not normalize, there would be a danger of simply; # assigning the highest score to the longest segment",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py:234,simpl,simply,234,src/scanpy/tools/_dpt.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py,1,['simpl'],['simply']
Usability,"# e.g. https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html; # maybe in the future random.Generator",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/__init__.py:22,learn,learn,22,src/scanpy/_utils/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/__init__.py,1,['learn'],['learn']
Usability,"# simple vector auto regressive process or; # hill kinetics process simulation",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py:2,simpl,simple,2,src/scanpy/tools/_sim.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_sim.py,1,['simpl'],['simple']
Usability,"# simply the number of points",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py:2,simpl,simply,2,src/scanpy/tools/_dpt.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_dpt.py,1,['simpl'],['simply']
Usability,"# test bare count arguments, for simplicity only with explicit copy=True; # test scaling with default zero_center == True",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_scaling.py:33,simpl,simplicity,33,tests/test_scaling.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/tests/test_scaling.py,1,['simpl'],['simplicity']
Usability,"# this is the boolean version that simply counts edges in the clustered graph",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_paga.py:35,simpl,simply,35,src/scanpy/tools/_paga.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_paga.py,1,['simpl'],['simply']
Usability,"# this sequence is defined simply by skipping rows; # is faster than sampling",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/__init__.py:27,simpl,simply,27,src/scanpy/_utils/__init__.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/_utils/__init__.py,1,['simpl'],['simply']
Usability,"# u_based_decision was changed in https://github.com/scikit-learn/scikit-learn/pull/27491",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py:60,learn,learn,60,src/scanpy/preprocessing/_pca.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py,2,['learn'],['learn']
Usability,"1p; If true, the input of the autoencoder is log transformed with a; pseudocount of one using `sc.pp.log1p` function of Scanpy.; hidden_size; Width of hidden layers.; hidden_dropout; Probability of weight dropout in the autoencoder (per layer if list; or tuple).; batchnorm; If true, batch normalization is performed.; activation; Activation function of hidden layers.; init; Initialization method used to initialize weights.; network_kwds; Additional keyword arguments for the autoencoder.; epochs; Number of total epochs in training.; reduce_lr; Reduces learning rate if validation loss does not improve in given number of epochs.; early_stop; Stops training if validation loss does not improve in given number of epochs.; batch_size; Number of samples in the batch used for SGD.; optimizer; Type of optimization method used for training.; random_state; Seed for python, numpy and tensorflow.; threads; Number of threads to use in training. All cores are used by default.; learning_rate; Learning rate to use in the training.; verbose; If true, prints additional information about training and architecture.; training_kwds; Additional keyword arguments for the training process.; return_model; If true, trained autoencoder object is returned. See ""Returns"".; return_info; If true, all additional parameters of DCA are stored in `adata.obsm` such as dropout; probabilities (obsm['X_dca_dropout']) and estimated dispersion values; (obsm['X_dca_dispersion']), in case that autoencoder is of type; zinb or zinb-conddisp.; copy; If true, a copy of anndata is returned. Returns; -------; If `copy` is true and `return_model` is false, AnnData object is returned. In ""denoise"" mode, `adata.X` is overwritten with the denoised values.; In ""latent"" mode, latent low dimensional representation of cells are stored; in `adata.obsm['X_dca']` and `adata.X` is not modified.; Note that these values are not corrected for library size effects. If `return_info` is true, all estimated distribution parameters are s",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_dca.py:2409,Learn,Learning,2409,src/scanpy/external/pp/_dca.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_dca.py,1,['Learn'],['Learning']
Usability,"ass a dense array. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; n_comps; Number of principal components to compute. Defaults to 50, or 1 - minimum; dimension size of selected representation.; layer; If provided, which element of layers to use for PCA.; zero_center; If `True`, compute standard PCA from covariance matrix.; If `False`, omit zero-centering variables; (uses *scikit-learn* :class:`~sklearn.decomposition.TruncatedSVD` or; *dask-ml* :class:`~dask_ml.decomposition.TruncatedSVD`),; which allows to handle sparse input efficiently.; Passing `None` decides automatically based on sparseness of the data.; svd_solver; SVD solver to use:. `None`; See `chunked` and `zero_center` descriptions to determine which class will be used.; Depending on the class and the type of X different values for default will be set.; If *scikit-learn* :class:`~sklearn.decomposition.PCA` is used, will give `'arpack'`,; if *scikit-learn* :class:`~sklearn.decomposition.TruncatedSVD` is used, will give `'randomized'`,; if *dask-ml* :class:`~dask_ml.decomposition.PCA` or :class:`~dask_ml.decomposition.IncrementalPCA` is used, will give `'auto'`,; if *dask-ml* :class:`~dask_ml.decomposition.TruncatedSVD` is used, will give `'tsqr'`; `'arpack'`; for the ARPACK wrapper in SciPy (:func:`~scipy.sparse.linalg.svds`); Not available with *dask* arrays.; `'randomized'`; for the randomized algorithm due to Halko (2009). For *dask* arrays,; this will use :func:`~dask.array.linalg.svd_compressed`.; `'auto'`; chooses automatically depending on the size of the problem.; `'lobpcg'`; An alternative SciPy solver. Not available with dask arrays.; `'tsqr'`; Only available with *dask* arrays. ""tsqr""; algorithm from Benson et. al. (2013). .. versionchanged:: 1.9.3; Default value changed from `'arpack'` to None.; .. versionchanged:: 1.4.5; Default value changed from `'auto'` to `'arpack'`. Efficient computation of the princi",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py:1513,learn,learn,1513,src/scanpy/preprocessing/_pca.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py,1,['learn'],['learn']
Usability,"ce directed layout; **harmony_aff** - :class:`~scipy.sparse.spmatrix` (:attr:`~anndata.AnnData.obsp`, dtype `float`); affinity matrix; **harmony_aff_aug** - :class:`~scipy.sparse.spmatrix` (:attr:`~anndata.AnnData.obsp`, dtype `float`); augmented affinity matrix; **harmony_timepoint_var** - `str` (:attr:`~anndata.AnnData.uns`); The name of the variable passed as `tp`; **harmony_timepoint_connections** - :class:`~numpy.ndarray` (:attr:`~anndata.AnnData.uns`, dtype `str`); The links between time points. Example; -------. >>> from itertools import product; >>> import pandas as pd; >>> from anndata import AnnData; >>> import scanpy as sc; >>> import scanpy.external as sce. **Load** `AnnData`. A sample with real data is available here_. .. _here: https://github.com/dpeerlab/Harmony/tree/master/data. Random data sets of three time points with two replicates each:. >>> adata_ref = sc.datasets.pbmc3k(); >>> start = [596, 615, 1682, 1663, 1409, 1432]; >>> adata = AnnData.concatenate(; ... *(adata_ref[i : i + 1000] for i in start),; ... join=""outer"",; ... batch_key=""sample"",; ... batch_categories=[f""sa{i}_Rep{j}"" for i, j in product((1, 2, 3), (1, 2))],; ... ); >>> time_points = adata.obs[""sample""].str.split(""_"", expand=True)[0]; >>> adata.obs[""time_points""] = pd.Categorical(; ... time_points, categories=['sa1', 'sa2', 'sa3']; ... ). Normalize and filter for highly expressed genes. >>> sc.pp.normalize_total(adata, target_sum=10000); >>> sc.pp.log1p(adata); >>> sc.pp.highly_variable_genes(adata, n_top_genes=1000, subset=True). Run harmony_timeseries. >>> sce.tl.harmony_timeseries(adata, tp=""time_points"", n_components=500). Plot time points:. >>> sce.pl.harmony_timeseries(adata). For further demonstration of Harmony visualizations please follow the notebook; `Harmony_sample_notebook.ipynb; <https://github.com/dpeerlab/Harmony/blob/master/notebooks/; Harmony_sample_notebook.ipynb>`_.; It provides a comprehensive guide to draw *gene expression trends*,; amongst other things.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_harmony_timeseries.py:3790,guid,guide,3790,src/scanpy/external/tl/_harmony_timeseries.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_harmony_timeseries.py,1,['guid'],['guide']
Usability,"d. This is to filter measurement outliers,; i.e. “unreliable” observations. Only provide one of the optional parameters `min_counts`, `min_genes`,; `max_counts`, `max_genes` per call. Parameters; ----------; data; The (annotated) data matrix of shape `n_obs` × `n_vars`.; Rows correspond to cells and columns to genes.; min_counts; Minimum number of counts required for a cell to pass filtering.; min_genes; Minimum number of genes expressed required for a cell to pass filtering.; max_counts; Maximum number of counts required for a cell to pass filtering.; max_genes; Maximum number of genes expressed required for a cell to pass filtering.; inplace; Perform computation inplace or return result. Returns; -------; Depending on `inplace`, returns the following arrays or directly subsets; and annotates the data matrix:. cells_subset; Boolean index mask that does filtering. `True` means that the; cell is kept. `False` means the cell is removed.; number_per_cell; Depending on what was thresholded (`counts` or `genes`),; the array stores `n_counts` or `n_cells` per gene. Examples; --------; >>> import scanpy as sc; >>> adata = sc.datasets.krumsiek11(); UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.; utils.warn_names_duplicates(""obs""); >>> adata.obs_names_make_unique(); >>> adata.n_obs; 640; >>> adata.var_names.tolist() # doctest: +NORMALIZE_WHITESPACE; ['Gata2', 'Gata1', 'Fog1', 'EKLF', 'Fli1', 'SCL',; 'Cebpa', 'Pu.1', 'cJun', 'EgrNab', 'Gfi1']; >>> # add some true zeros; >>> adata.X[adata.X < 0.3] = 0; >>> # simply compute the number of genes per cell; >>> sc.pp.filter_cells(adata, min_genes=0); >>> adata.n_obs; 640; >>> adata.obs['n_genes'].min(); 1; >>> # filter manually; >>> adata_copy = adata[adata.obs['n_genes'] >= 3]; >>> adata_copy.n_obs; 554; >>> adata_copy.obs['n_genes'].min(); 3; >>> # actually do some filtering; >>> sc.pp.filter_cells(adata, min_genes=3); >>> adata.n_obs; 554; >>> adata.obs['n_genes'].min(); 3; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py:1744,simpl,simply,1744,src/scanpy/preprocessing/_simple.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_simple.py,1,['simpl'],['simply']
Usability,"fraction; of cells (obs) that have a non-zero value for genes (var). For each var_name and each `groupby` category a dot is plotted.; Each dot represents two values: mean expression within each category; (visualized by color) and fraction of cells expressing the `var_name` in the; category (visualized by the size of the dot). If `groupby` is not given,; the dotplot assumes that all data belongs to a single category. .. note::; A gene is considered expressed if the expression value in the `adata` (or; `adata.raw`) is above the specified threshold which is zero by default. An example of dotplot usage is to visualize, for multiple marker genes,; the mean value and the percentage of cells expressing the gene; across multiple clusters. Parameters; ----------; {common_plot_args}; title; Title for the figure; expression_cutoff; Expression cutoff that is used for binarizing the gene expression and; determining the fraction of cells expressing given genes. A gene is; expressed only if the expression value is greater than this threshold.; mean_only_expressed; If True, gene expression is averaged only over the cells; expressing the given genes.; standard_scale; Whether or not to standardize that dimension between 0 and 1,; meaning for each variable or group,; subtract the minimum and divide each by its maximum.; kwds; Are passed to :func:`matplotlib.pyplot.scatter`. See also; --------; :func:`~scanpy.pl.dotplot`: Simpler way to call DotPlot but with less options.; :func:`~scanpy.pl.rank_genes_groups_dotplot`: to plot marker; genes identified using the :func:`~scanpy.tl.rank_genes_groups` function. Examples; --------. >>> import scanpy as sc; >>> adata = sc.datasets.pbmc68k_reduced(); >>> markers = ['C1QA', 'PSAP', 'CD79A', 'CD79B', 'CST3', 'LYZ']; >>> sc.pl.DotPlot(adata, markers, groupby='bulk_labels').show(). Using var_names as dict:. >>> markers = {{'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}}; >>> sc.pl.DotPlot(adata, markers, groupby='bulk_labels').show(). """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_dotplot.py:1544,Simpl,Simpler,1544,src/scanpy/plotting/_dotplot.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_dotplot.py,1,['Simpl'],['Simpler']
Usability,"g one of two optional inputs:. *Principal component analysis*. >>> sc.pp.pca(adata, n_comps=300). or,. *Nearist neighbors graph*. >>> sc.pp.neighbors(adata, knn=30). *Diffusion maps*. Palantir determines the diffusion maps of the data as an estimate of the low; dimensional phenotypic manifold of the data. >>> sce.tl.palantir(adata, n_components=5, knn=30). if pre-computed distances are to be used,. >>> sce.tl.palantir(; ... adata,; ... n_components=5,; ... knn=30,; ... use_adjacency_matrix=True,; ... distances_key=""distances"",; ... ). **Visualizing Palantir results**. *tSNE visualization*. important for Palantir!. Palantir constructs the tSNE map in the embedded space since these maps better; represent the differentiation trajectories. >>> sc.tl.tsne(adata, n_pcs=2, use_rep='X_palantir_multiscale', perplexity=150). *tsne by cell size*. >>> sc.pl.tsne(adata, color=""n_counts""). *Imputed gene expression visualized on tSNE maps*. >>> sc.pl.tsne(; ... adata,; ... gene_symbols=['CD34', 'MPO', 'GATA1', 'IRF8'],; ... layer='palantir_imp',; ... color=['CD34', 'MPO', 'GATA1', 'IRF8']; ... ). **Running Palantir**. Palantir can be run by specifying an approximate early cell. While Palantir; automatically determines the terminal states, they can also be specified using the; `termine_states` parameter. >>> start_cell = 'Run5_164698952452459'; >>> pr_res = sce.tl.palantir_results(; ... adata,; ... early_cell=start_cell,; ... ms_data='X_palantir_multiscale',; ... num_waypoints=500,; ... ). .. note::; A `start_cell` must be defined for every data set. The start cell for; this dataset was chosen based on high expression of CD34. At this point the returned Palantir object `pr_res` can be used for all downstream; analysis and plotting. Please consult this notebook; `Palantir_sample_notebook.ipynb; <https://github.com/dpeerlab/Palantir/blob/master/notebooks/Palantir_sample_notebook.ipynb>`_.; It provides a comprehensive guide to draw *gene expression trends*, amongst other; things.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_palantir.py:5064,guid,guide,5064,src/scanpy/external/tl/_palantir.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/tl/_palantir.py,1,['guid'],['guide']
Usability,"pack'`; for the ARPACK wrapper in SciPy (:func:`~scipy.sparse.linalg.svds`); Not available with *dask* arrays.; `'randomized'`; for the randomized algorithm due to Halko (2009). For *dask* arrays,; this will use :func:`~dask.array.linalg.svd_compressed`.; `'auto'`; chooses automatically depending on the size of the problem.; `'lobpcg'`; An alternative SciPy solver. Not available with dask arrays.; `'tsqr'`; Only available with *dask* arrays. ""tsqr""; algorithm from Benson et. al. (2013). .. versionchanged:: 1.9.3; Default value changed from `'arpack'` to None.; .. versionchanged:: 1.4.5; Default value changed from `'auto'` to `'arpack'`. Efficient computation of the principal components of a sparse matrix; currently only works with the `'arpack`' or `'lobpcg'` solvers. If X is a *dask* array, *dask-ml* classes :class:`~dask_ml.decomposition.PCA`,; :class:`~dask_ml.decomposition.IncrementalPCA`, or; :class:`~dask_ml.decomposition.TruncatedSVD` will be used.; Otherwise their *scikit-learn* counterparts :class:`~sklearn.decomposition.PCA`,; :class:`~sklearn.decomposition.IncrementalPCA`, or; :class:`~sklearn.decomposition.TruncatedSVD` will be used.; random_state; Change to use different initial states for the optimization.; return_info; Only relevant when not passing an :class:`~anndata.AnnData`:; see “Returns”.; {mask_var_hvg}; layer; Layer of `adata` to use as expression values.; dtype; Numpy data type string to which to convert the result.; copy; If an :class:`~anndata.AnnData` is passed, determines whether a copy; is returned. Is ignored otherwise.; chunked; If `True`, perform an incremental PCA on segments of `chunk_size`.; The incremental PCA automatically zero centers and ignores settings of; `random_seed` and `svd_solver`. Uses sklearn :class:`~sklearn.decomposition.IncrementalPCA` or; *dask-ml* :class:`~dask_ml.decomposition.IncrementalPCA`. If `False`, perform a full PCA and; use sklearn :class:`~sklearn.decomposition.PCA` or; *dask-ml* :class:`~dask_ml.decomp",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py:2816,learn,learn,2816,src/scanpy/preprocessing/_pca.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_pca.py,1,['learn'],['learn']
Usability,"patible plotting function. .. _Space Ranger output docs: https://support.10xgenomics.com/spatial-gene-expression/software/pipelines/latest/output/overview. Parameters; ----------; path; Path to directory for visium datafiles.; genome; Filter expression to genes within this genome.; count_file; Which file in the passed directory to use as the count file. Typically would be one of:; 'filtered_feature_bc_matrix.h5' or 'raw_feature_bc_matrix.h5'.; library_id; Identifier for the visium library. Can be modified when concatenating multiple adata objects.; source_image_path; Path to the high-resolution tissue image. Path will be included in; `.uns[""spatial""][library_id][""metadata""][""source_image_path""]`. Returns; -------; Annotated data matrix, where observations/cells are named by their; barcode and variables/genes by gene name. Stores the following information:. :attr:`~anndata.AnnData.X`; The data matrix is stored; :attr:`~anndata.AnnData.obs_names`; Cell names; :attr:`~anndata.AnnData.var_names`; Gene names for a feature barcode matrix, probe names for a probe bc matrix; :attr:`~anndata.AnnData.var`\\ `['gene_ids']`; Gene IDs; :attr:`~anndata.AnnData.var`\\ `['feature_types']`; Feature types; :attr:`~anndata.AnnData.obs`\\ `[filtered_barcodes]`; filtered barcodes if present in the matrix; :attr:`~anndata.AnnData.var`; Any additional metadata present in /matrix/features is read in.; :attr:`~anndata.AnnData.uns`\\ `['spatial']`; Dict of spaceranger output files with 'library_id' as key; :attr:`~anndata.AnnData.uns`\\ `['spatial'][library_id]['images']`; Dict of images (`'hires'` and `'lowres'`); :attr:`~anndata.AnnData.uns`\\ `['spatial'][library_id]['scalefactors']`; Scale factors for the spots; :attr:`~anndata.AnnData.uns`\\ `['spatial'][library_id]['metadata']`; Files metadata: 'chemistry_description', 'software_version', 'source_image_path'; :attr:`~anndata.AnnData.obsm`\\ `['spatial']`; Spatial spot coordinates, usable as `basis` by :func:`~scanpy.pl.embedding`.; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py:2207,usab,usable,2207,src/scanpy/readwrite.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/readwrite.py,1,['usab'],['usable']
Usability,"rmalize_per_cell` function in Scanpy and saved into adata; object. Mean layer is re-introduces library size differences by; scaling the mean value of each cell in the output layer. See the; manuscript for more details.; scale; If true, the input of the autoencoder is centered using; `sc.pp.scale` function of Scanpy. Note that the output is kept as raw; counts as loss functions are designed for the count data.; log1p; If true, the input of the autoencoder is log transformed with a; pseudocount of one using `sc.pp.log1p` function of Scanpy.; hidden_size; Width of hidden layers.; hidden_dropout; Probability of weight dropout in the autoencoder (per layer if list; or tuple).; batchnorm; If true, batch normalization is performed.; activation; Activation function of hidden layers.; init; Initialization method used to initialize weights.; network_kwds; Additional keyword arguments for the autoencoder.; epochs; Number of total epochs in training.; reduce_lr; Reduces learning rate if validation loss does not improve in given number of epochs.; early_stop; Stops training if validation loss does not improve in given number of epochs.; batch_size; Number of samples in the batch used for SGD.; optimizer; Type of optimization method used for training.; random_state; Seed for python, numpy and tensorflow.; threads; Number of threads to use in training. All cores are used by default.; learning_rate; Learning rate to use in the training.; verbose; If true, prints additional information about training and architecture.; training_kwds; Additional keyword arguments for the training process.; return_model; If true, trained autoencoder object is returned. See ""Returns"".; return_info; If true, all additional parameters of DCA are stored in `adata.obsm` such as dropout; probabilities (obsm['X_dca_dropout']) and estimated dispersion values; (obsm['X_dca_dispersion']), in case that autoencoder is of type; zinb or zinb-conddisp.; copy; If true, a copy of anndata is returned. Returns; -------; ",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_dca.py:1975,learn,learning,1975,src/scanpy/external/pp/_dca.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/external/pp/_dca.py,1,['learn'],['learning']
Usability,"rmalized dispersions are ignored. Ignored if `flavor='seurat_v3'`.; span; The fraction of the data (cells) used when estimating the variance in the loess; model fit if `flavor='seurat_v3'`.; n_bins; Number of bins for binning the mean gene expression. Normalization is; done with respect to each bin. If just a single gene falls into a bin,; the normalized dispersion is artificially set to 1. You'll be informed; about this if you set `settings.verbosity = 4`.; flavor; Choose the flavor for identifying highly variable genes. For the dispersion; based methods in their default workflows, Seurat passes the cutoffs whereas; Cell Ranger passes `n_top_genes`.; subset; Inplace subset to highly-variable genes if `True` otherwise merely indicate; highly variable genes.; inplace; Whether to place calculated metrics in `.var` or return them.; batch_key; If specified, highly-variable genes are selected within each batch separately and merged.; This simple process avoids the selection of batch-specific genes and acts as a; lightweight batch correction method. For all flavors, except `seurat_v3`, genes are first sorted; by how many batches they are a HVG. For dispersion-based flavors ties are broken; by normalized dispersion. For `flavor = 'seurat_v3_paper'`, ties are broken by the median; (across batches) rank based on within-batch normalized variance.; check_values; Check if counts in selected layer are integers. A Warning is returned if set to True.; Only used if `flavor='seurat_v3'`/`'seurat_v3_paper'`. Returns; -------; Returns a :class:`pandas.DataFrame` with calculated metrics if `inplace=True`, else returns an `AnnData` object where it sets the following field:. `adata.var['highly_variable']` : :class:`pandas.Series` (dtype `bool`); boolean indicator of highly-variable genes; `adata.var['means']` : :class:`pandas.Series` (dtype `float`); means per gene; `adata.var['dispersions']` : :class:`pandas.Series` (dtype `float`); For dispersion-based flavors, dispersions per gene; `a",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py:4033,simpl,simple,4033,src/scanpy/preprocessing/_highly_variable_genes.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/preprocessing/_highly_variable_genes.py,1,['simpl'],['simple']
Usability,"the categories. Note: if `dendrogram=True`; the categories order will be given by the dendrogram and `order`; will be ignored.; density_norm; The method used to scale the width of each violin.; If 'width' (the default), each violin will have the same width.; If 'area', each violin will have the same area.; If 'count', a violin’s width corresponds to the number of observations.; row_palette; The row palette determines the colors to use for the stacked violins.; The value should be a valid seaborn or matplotlib palette name; (see :func:`~seaborn.color_palette`).; Alternatively, a single color name or hex value can be passed,; e.g. `'red'` or `'#cc33ff'`.; standard_scale; Whether or not to standardize a dimension between 0 and 1,; meaning for each variable or observation,; subtract the minimum and divide each by its maximum.; swap_axes; By default, the x axis contains `var_names` (e.g. genes) and the y axis; the `groupby` categories. By setting `swap_axes` then x are the `groupby`; categories and y the `var_names`. When swapping; axes var_group_positions are no longer used; kwds; Are passed to :func:`~seaborn.violinplot`. See also; --------; :func:`~scanpy.pl.stacked_violin`: simpler way to call StackedViolin but with less; options.; :func:`~scanpy.pl.violin` and :func:`~scanpy.pl.rank_genes_groups_stacked_violin`:; to plot marker genes identified using :func:`~scanpy.tl.rank_genes_groups`. Examples; -------. >>> import scanpy as sc; >>> adata = sc.datasets.pbmc68k_reduced(); >>> markers = ['C1QA', 'PSAP', 'CD79A', 'CD79B', 'CST3', 'LYZ']; >>> sc.pl.StackedViolin(adata, markers, groupby='bulk_labels', dendrogram=True) # doctest: +ELLIPSIS; <scanpy.plotting._stacked_violin.StackedViolin object at 0x...>. Using var_names as dict:. >>> markers = {{'T-cell': 'CD3D', 'B-cell': 'CD79A', 'myeloid': 'CST3'}}; >>> sc.pl.StackedViolin(adata, markers, groupby='bulk_labels', dendrogram=True) # doctest: +ELLIPSIS; <scanpy.plotting._stacked_violin.StackedViolin object at 0x...>; """"""",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_stacked_violin.py:1783,simpl,simpler,1783,src/scanpy/plotting/_stacked_violin.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/plotting/_stacked_violin.py,1,['simpl'],['simpler']
Usability,"tter convergence if you install Multicore-tSNE_; by :cite:t:`Ulyanov2016`, which will be automatically detected by Scanpy. .. _multicore-tsne: https://github.com/DmitryUlyanov/Multicore-TSNE. Parameters; ----------; adata; Annotated data matrix.; {doc_n_pcs}; {use_rep}; perplexity; The perplexity is related to the number of nearest neighbors that; is used in other manifold learning algorithms. Larger datasets; usually require a larger perplexity. Consider selecting a value; between 5 and 50. The choice is not extremely critical since t-SNE; is quite insensitive to this parameter.; metric; Distance metric calculate neighbors on.; early_exaggeration; Controls how tight natural clusters in the original space are in the; embedded space and how much space will be between them. For larger; values, the space between natural clusters will be larger in the; embedded space. Again, the choice of this parameter is not very; critical. If the cost function increases during initial optimization,; the early exaggeration factor or the learning rate might be too high.; learning_rate; Note that the R-package ""Rtsne"" uses a default of 200.; The learning rate can be a critical parameter. It should be; between 100 and 1000. If the cost function increases during initial; optimization, the early exaggeration factor or the learning rate; might be too high. If the cost function gets stuck in a bad local; minimum increasing the learning rate helps sometimes.; random_state; Change this to use different intial states for the optimization.; If `None`, the initial state is not reproducible.; n_jobs; Number of jobs for parallel computation.; `None` means using :attr:`scanpy._settings.ScanpyConfig.n_jobs`.; copy; Return a copy instead of writing to `adata`. Returns; -------; Returns `None` if `copy=False`, else returns an `AnnData` object. Sets the following fields:. `adata.obsm['X_tsne']` : :class:`numpy.ndarray` (dtype `float`); tSNE coordinates of data.; `adata.uns['tsne']` : :class:`dict`; tSNE ",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_tsne.py:1383,learn,learning,1383,src/scanpy/tools/_tsne.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_tsne.py,1,['learn'],['learning']
Usability,"ues; will result in a more clustered/clumped embedding where nearby points on; the manifold are drawn closer together, while larger values will result; on a more even dispersal of points. The value should be set relative to; the ``spread`` value, which determines the scale at which embedded; points will be spread out. The default of in the `umap-learn` package is; 0.1.; spread; The effective scale of embedded points. In combination with `min_dist`; this determines how clustered/clumped the embedded points are.; n_components; The number of dimensions of the embedding.; maxiter; The number of iterations (epochs) of the optimization. Called `n_epochs`; in the original UMAP.; alpha; The initial learning rate for the embedding optimization.; gamma; Weighting applied to negative samples in low dimensional embedding; optimization. Values higher than one will result in greater weight; being given to negative samples.; negative_sample_rate; The number of negative edge/1-simplex samples to use per positive; edge/1-simplex sample in optimizing the low dimensional embedding.; init_pos; How to initialize the low dimensional embedding. Called `init` in the; original UMAP. Options are:. * Any key for `adata.obsm`.; * 'paga': positions from :func:`~scanpy.pl.paga`.; * 'spectral': use a spectral embedding of the graph.; * 'random': assign initial embedding positions at random.; * A numpy array of initial embedding positions.; random_state; If `int`, `random_state` is the seed used by the random number generator;; If `RandomState` or `Generator`, `random_state` is the random number generator;; If `None`, the random number generator is the `RandomState` instance used; by `np.random`.; a; More specific parameters controlling the embedding. If `None` these; values are set automatically as determined by `min_dist` and; `spread`.; b; More specific parameters controlling the embedding. If `None` these; values are set automatically as determined by `min_dist` and; `spread`.; copy; Return a c",MatchSource.CODE_COMMENT,scverse,scanpy,1.10.2,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_umap.py:1865,simpl,simplex,1865,src/scanpy/tools/_umap.py,https://scanpy.readthedocs.io,https://github.com/scverse/scanpy/tree/1.10.2/src/scanpy/tools/_umap.py,2,['simpl'],['simplex']
