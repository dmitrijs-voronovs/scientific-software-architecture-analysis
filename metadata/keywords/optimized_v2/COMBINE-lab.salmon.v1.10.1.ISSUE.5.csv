quality_attribute,sentence,source,author,repo,version,id,keyword,matched_word,match_idx,wiki,url,total_similar,target_keywords,target_matched_words
Testability,"Ch38.103.gtf; where the two genome files (fa and gtf) were used with STAR. ; When running Salmon with this fasta file, I get the following output and error message:. Version Info: This is the most recent version of salmon.; # salmon (alignment-based) v1.4.0; # [ program ] => salmon; # [ command ] => quant; # [ targets ] => { all_transcripts.fa }; # [ libType ] => { A }; # [ threads ] => { 10 }; # [ alignments ] => { /groups/inah/test_Salmon/4010760_5_mono_S58_L001_R1_001.fastq_AT_QT.fastq.gz.STAR_aligned.toTranscriptome.bam /groups/inah/test_Sal; mon/4010760_5_mono_S58_L002_R1_001.fastq_AT_QT.fastq.gz.STAR_aligned.toTranscriptome.bam /groups/inah/test_Salmon/4010760_5_mono_S58_L003_R1_001.fastq_AT; _QT.fastq.gz.STAR_aligned.toTranscriptome.bam /groups/inah/test_Salmon/4010760_5_mono_S58_L004_R1_001.fastq_AT_QT.fastq.gz.STAR_aligned.toTranscriptome.b; am }; # [ output ] => { 4010760_5_mono_S58_R1_001.fastq_AT_QT.fastq.gz.STAR_aligned.toTranscriptome.bam.salmon_quant }; Logs will be written to 4010760_5_mono_S58_R1_001.fastq_AT_QT.fastq.gz.STAR_aligned.toTranscriptome.bam.salmon_quant/logs; [2021-03-05 18:20:21.015] [jointLog] [info] setting maxHashResizeThreads to 10; [2021-03-05 18:20:21.015] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; Library format { type:paired end, relative orientation:inward, strandedness:unstranded }; parseThreads = 5; [2021-03-05 18:20:21.314] [jointLog] [info] numQuantThreads = 5; Checking that provided alignment files have consistent headers . . . done; Populating targets from aln = ""/groups/inah/test_Salmon/4010760_5_mono_S58_L001_R1_001.fastq_AT_QT.fastq.gz.STAR_aligned.toTranscriptome.bam"", fasta = ""a; ll_transcripts.fa"" . . .done; [2021-03-05 18:20:24.846] [jointLog] [info] replaced 1216 non-ACGT nucleotides with random nucleotides; processed 0 reads in current round[2021-03-05 18:20:25.180] [jointLog] [info] Automatically detected most likely library type as ISR; processed ",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/638:1373,Log,Logs,1373,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/638,1,['Log'],['Logs']
Testability,"Compilation of salmon fails under MX Linux 17, and I suspect this is related to pthreads. ```; $ cat /home/bli/src/salmon/CMakeFiles/CMakeError.log ; Determining if the pthread_create exist failed with the following output:; Change Dir: /home/bli/src/salmon/CMakeFiles/CMakeTmp. Run Build Command:""/usr/bin/make"" ""cmTC_dc0cd/fast""; /usr/bin/make -f CMakeFiles/cmTC_dc0cd.dir/build.make CMakeFiles/cmTC_dc0cd.dir/build; make[1]: Entering directory '/home/bli/src/salmon/CMakeFiles/CMakeTmp'; Building C object CMakeFiles/cmTC_dc0cd.dir/CheckSymbolExists.c.o; /usr/bin/cc -o CMakeFiles/cmTC_dc0cd.dir/CheckSymbolExists.c.o -c /home/bli/src/salmon/CMakeFiles/CMakeTmp/CheckSymbolExists.c; Linking C executable cmTC_dc0cd; /usr/bin/cmake -E cmake_link_script CMakeFiles/cmTC_dc0cd.dir/link.txt --verbose=1; /usr/bin/cc CMakeFiles/cmTC_dc0cd.dir/CheckSymbolExists.c.o -o cmTC_dc0cd -rdynamic ; CMakeFiles/cmTC_dc0cd.dir/CheckSymbolExists.c.o: In function `main':; CheckSymbolExists.c:(.text+0x1b): undefined reference to `pthread_create'; collect2: error: ld returned 1 exit status; CMakeFiles/cmTC_dc0cd.dir/build.make:97: recipe for target 'cmTC_dc0cd' failed; make[1]: *** [cmTC_dc0cd] Error 1; make[1]: Leaving directory '/home/bli/src/salmon/CMakeFiles/CMakeTmp'; Makefile:126: recipe for target 'cmTC_dc0cd/fast' failed; make: *** [cmTC_dc0cd/fast] Error 2. File /home/bli/src/salmon/CMakeFiles/CMakeTmp/CheckSymbolExists.c:; /* */; #include <pthread.h>. int main(int argc, char** argv); {; (void)argv;; #ifndef pthread_create; return ((int*)(&pthread_create))[argc];; #else; (void)argc;; return 0;; #endif; }. Determining if the function pthread_create exists in the pthreads failed with the following output:; Change Dir: /home/bli/src/salmon/CMakeFiles/CMakeTmp. Run Build Command:""/usr/bin/make"" ""cmTC_dd9f2/fast""; /usr/bin/make -f CMakeFiles/cmTC_dd9f2.dir/build.make CMakeFiles/cmTC_dd9f2.dir/build; make[1]: Entering directory '/home/bli/src/salmon/CMakeFiles/CMakeTmp'; Building C object CMak",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/207:144,log,log,144,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/207,1,['log'],['log']
Testability,"Confirmed with v0.6.0:. ```; Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; # salmon (mapping-based) v0.6.0; # [ program ] => salmon; # [ command ] => quant; # [ index ] => { ... }; # [ libType ] => { IU }; # [ mates1 ] => { ... }; # [ mates2 ] => { ... }; # [ output ] => {... }; # [ threads ] => { 16 }; Logs will be written to ...; there is 1 lib; [2016-01-22 17:59:17.894] [jointLog] [info] parsing read library format; Loading 32-bit quasi index[2016-01-22 17:59:18.735] [stderrLog] [info] Loading Suffix Array; [2016-01-22 17:59:18.736] [stderrLog] [info] Loading Position Hash; [2016-01-22 17:59:18.731] [jointLog] [info] Loading Quasi index; [2016-01-22 18:00:59.879] [stderrLog] [info] Loading Transcript Info; [2016-01-22 18:01:25.157] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-01-22 18:01:30.642] [stderrLog] [info] There were 552702 set bits in the bit a; [2016-01-22 18:01:31.487] [stderrLog] [info] Computing transcript lengths; [2016-01-22 18:01:31.491] [stderrLog] [info] Waiting to finish loading hash; Index contained 552702 targets; [2016-01-22 18:04:43.717] [jointLog] [info] done; [2016-01-22 18:04:43.717] [stderrLog] [info] Done loading index; ```. I'll check the index creation logs, but didn't notice anything out of the ordinary...",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/37#issuecomment-174082911:402,Log,Logs,402,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/37#issuecomment-174082911,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"Corner cases are hard to catch. The drop-seq dataset I was probing was from 2-3 years ago and it appeared very noisy. When I tried Alevin with a morden 10x V2 dataset there was no issue at all. ; Anyway, thank you for the quick fix. I tested it and it worked well.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/374#issuecomment-502230996:235,test,tested,235,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/374#issuecomment-502230996,1,['test'],['tested']
Testability,"Could you please share one of the output directories? It's not immediately obvious what the problem might be, since the log ends with . ```; [2020-06-03 23:47:15.955] [jointLog] [info] Computing gene-level abundance estimates; ```. which suggests the function to aggregate abundances to the gene level should be activated. On a related note, though we are definitely interesting in figuring out what might being going awry here, the recommended way to aggregate transcript-level abundances from salmon to the gene level is to use [tximport](https://bioconductor.org/packages/release/bioc/html/tximport.html), as it accounts for across-sample variability in expressed gene length, and makes it trivial to get your corresponding gene counts into a downstream DE tool like DESeq2, EdgeR, etc.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/530#issuecomment-638453196:120,log,log,120,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/530#issuecomment-638453196,1,['log'],['log']
Testability,"Currently on develop branch, there is a build error. https://travis-ci.org/COMBINE-lab/salmon/builds/418288039; https://api.travis-ci.org/v3/job/415232259/log.txt. ```; cd /home/travis/build/COMBINE-lab/salmon/external/boost_1_66_0 && CC=/usr/bin/gcc-7 CXX=/usr/bin/g++-7 /home/travis/build/COMBINE-lab/salmon/external/boost_1_66_0/b2 -d0 -j2 --with-iostreams --with-atomic --with-chrono --with-container --with-date_time --with-exception --with-filesystem --with-graph --with-graph_parallel --with-math --with-program_options --with-system --with-locale --with-timer toolset=gcc toolset=gcc cxxflags=-std=c++14 ""cxxflags= -std=c++14 -I/home/travis/build/COMBINE-lab/salmon/external/install/include -L/home/travis/build/COMBINE-lab/salmon/external/install/lib"" link=static install. g++: error: unrecognized command line option ‘-std=c++14’; ```. I suspect the `g++` (Not `g++-N`) is wrongly used for to build boost.; As a result, the old version `g++` version 4.8 does not support `-std=c++14`. Maybe. https://www.boost.org/doc/libs/1_66_0/more/getting_started/unix-variants.html; https://stackoverflow.com/questions/5346454/building-boost-with-different-gcc-version. Maybe below kind of process is necessary if CC=gcc-N. ```; $ echo ""using gcc : 7 : /usr/bin/g++-7 ; "" >> tools/build/src/user-config.jam; $ ./bootstrap.sh ...; $ ./b2 --toolset=gcc-7 ...; ```. Here is my work to fix the issue.; Still working in progress.; But you can imagine how I am trying to fix it. I am not familiar with the `cmake`.; https://github.com/junaruga/salmon/commit/6cb73098155f0e776d4eb68bc639f3d761dd8963. If possible, I want you to fix this issue :)",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/275:155,log,log,155,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/275,1,['log'],['log']
Testability,"Dear @callumparr,. Thank you for bringing this up. So you are correct that the `--noLengthCorrection` flag should be passed to salmon when quantifying data that does not have a ""fragmentation effect"", that is, where the number of fragments we expect to draw from a transcript is not dependent upon the length of that transcript. In the ONT protocols, it is usually the case that we get 1 read -> 1 transcript, even if we don't read the whole thing. We have tested the effect of this in ONT data with spike ins, and have verified that using `--noLengthCorrection` does generally lead to improved accuracy with respect to quantification estimates. We have informed ONT of this, and I would guess they may optimize the flags that are used soon (we have also developed an error model that works correctly for these long reads, and that should make it into the next release of salmon). Regarding the effect this has on the `NumReads` values reported by salmon, it's not as simple as with the `TPM` estimates. The length affects the assigned reads through the probabilistic model on which inference is done. With the length effect we have that P(f | t_i) ∝ P( position | f, t_i ) * P( alignment | f, t_i) --- forgetting the alignment term for the time being, we have that with length correction P( position | f, t_i ) ∝ 1 / l_i and without length correction the l_i term goes away. In other words, the probability of allocating reads has a term that depends on the effective length when the `--noLengthCorrection` flag is not passed, but that term goes away when it is passed. This is not quite as drastic as with TPM where the normalization includes the length directly in the normalization (note, however, that when the `--noLengthCorrection` flag is passed, this adjusts the TPM as well). Further, the `NumReads` is still better than TPM in this regard because it still encodes the effect size (i.e. `NumReads` will sum to the total number of aligned reads). Anyway TLDR: Passing the `--noLengthCorrectio",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/651#issuecomment-821995147:457,test,tested,457,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/651#issuecomment-821995147,2,['test'],['tested']
Testability,"Dear Rob,. Would you please explain why large number of reads have been discarded due to alignment?. This is bulk RNAseq on mouse tissue. I tried fastp and trim galore for trimming the reads but they hardly make any difference from untrimmed reads. I used STAR for alignment initially and I got an alignment rate of 90% . This is my Salmon code; this is to generate the index:; salmon index -t Mus_musculus.GRCm38.cdna.all.fa -i transcripts_index; this is to run salmon:; salmon quant -i transcripts_index -l IU -1 fastp_6BE_1.fq.gz -2 fastp_6BE_2.fq.gz -o sample6BE.salmon ; --validateMappings --softclip. This is the salmon log; ==================; Observed 42829220 total fragments (42829220 in most recent round). [2022-05-13 03:02:14.185] [jointLog] [info] Computed 384,282 rich equivalence classes for further processing; [2022-05-13 03:02:14.185] [jointLog] [info] Counted 27,069,942 total reads in the equivalence classes ; [2022-05-13 03:02:14.202] [jointLog] [info] Number of mappings discarded because of alignment score : 262,747,517; [2022-05-13 03:02:14.202] [jointLog] [info] Number of fragments entirely discarded because of alignment score : 2,776,678; [2022-05-13 03:02:14.202] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 0; [2022-05-13 03:02:14.202] [jointLog] [info] Number of fragments discarded because they have only dovetail (discordant) mappings to valid targets : 1,099,008; [2022-05-13 03:02:14.202] [jointLog] [info] Mapping rate = 63.2044%. [2022-05-13 03:02:14.202] [jointLog] [info] finished quantifyLibrary(); [2022-05-13 03:02:14.226] [jointLog] [info] Starting optimizer; [2022-05-13 03:02:14.308] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate; [2022-05-13 03:02:14.325] [jointLog] [info] iteration = 0 | max rel diff. = 10590.7; [2022-05-13 03:02:15.594] [jointLog] [info] iteration = 100 | max rel diff. = 16.0264; [2022-05-13 03:02:16.882] [jointLog] [info] iteration = 200 | max rel diff. = 7.7",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/775:626,log,log,626,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/775,1,['log'],['log']
Testability,"Dear Rob,; a brief update:; 1) with the flag -DNO_IPO=TRUE the compilation worked perfectly. thank you . 2)following a guide found at stackoverlow ([Find which assembly instruction caused an Illegal Instruction error without debugging], I discover that the illegal instruction is **vfmsubsd**. ; I am not an expert at all in the field, but googling it seems to be a standard SSE instruction.; I am surprised indeed.; cpus tested: ; Intel Xeon Gold 5220 (72) ; Intel Xeon Gold 5317 (48); Intel i7-10750H (12). Best and thanks again; Silvano. Program terminated with signal SIGILL, Illegal instruction.; #0 0x00007fa222c47396 in __ieee754_pow_fma4 () from /dataraw/mouse/salmon-1.8.0_linux_x86_64/bin/../lib/libm.so.6. 0x7fa222c47396 <__ieee754_pow_fma4+182> vfmsubsd %xmm3,%xmm6,%xmm3,%xmm7",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/783#issuecomment-1145687835:422,test,tested,422,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/783#issuecomment-1145687835,2,['test'],['tested']
Testability,"Dear Salmon team,. I am trying to quantify allele specific expression using salmon, so I would like to use the unique counts to estimate confidence itervals of the allele unbalance. However, I get no unique counts in the ambig_info.tsv file, disabling the validateMappings option fixed it. I'm using Salmon v 12 and I do expect unique counts, since I have some reads aligning to variants, as determined by featureCounts on the output sam by this same salmon run. . Is this the expected behavior when one enables validateMappings? ; Can I just go without validating them? I noticed the results are very close when disabling this option. Salmon was run as follows using a default k=31 quasi index.; salmon quant --writeMappings=Z --no-version-check -p10 (--validateMappings) --seqBias --posBias -i X -l IU -1 P.fq.gz -2 Qq.fq.gz -o Test",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/347:830,Test,Test,830,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/347,1,['Test'],['Test']
Testability,"Dear Salmon team,. We have previously been using salmon 0.8.1 for our RNA sequencing analysis pipeline and wanted to upgrade to the latest version (1.3.0). Upon comparing the quant.sf output from salmon 0.8.1 to 1.3.0 (see command below), we noticed that we had far less transcripts with a TPM of unequal 0 in the quant.sf file generated by salmon 1.3.0 compared to the quant.sf output from salmon 0.8.1. . cmd1 = (""{salmon} --no-version-check quant --libType {libType} ""; "" --targets {salmon_ref} --useVBOpt --numBootstraps 50 ""; "" --seqBias --gcBias --geneMap {salmon_gtf}""; "" --sampleOut --sampleUnaligned --threads {threads}""; "" --alignments {input_files[1]} --output {output_dir}/salmon""). I have downsampled the bam file on which we tested the two salmon versions, which can be found here: https://drive.google.com/file/d/1-3ZCXlYkBsu4wyYBgbgQQUbqRwICsyLB/view?usp=sharing . As the error model was not used in salmon 0.8.1, and is now run if the flag –noErrorModel is not set, I furthermore ran salmon 1.3.0 without the error model and performed another run with the error model and range factorization (set to 4 as recommended) enabled. . For this particular downsampled bam file, salmon 0.8.1 got 36.9% of TPM’s unequal 0 but for all three differently configured salmon 1.3.0 runs that number drops to 7.3%. . Is this drastic reduction in detected transcripts in the newer version the result of fewer false positives compared to the old salmon version?",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/562:739,test,tested,739,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/562,1,['test'],['tested']
Testability,"Dear all,. I am trying to analyze direct nanopore RNA sequencing data with salmon.; Now I seem to have problems with getting the command line properly:. I use:; salmon quant -i salmon_index -l r dmso_sham_4.fastq --validateMappings -o transcripts_quant. and get the following; Version Server Response: Not Found; ### salmon (selective-alignment-based) v1.10.3; ### [ program ] => salmon; ### [ command ] => quant; ### [ index ] => { salmon_index }; ### [ libType ] => { r }; ### [ ] => { dmso_sham_4.fastq }; ### [ validateMappings ] => { }; ### [ output ] => { transcripts_quant }; Logs will be written to transcripts_quant/logs; [2024-05-29 11:13:30.128] [jointLog] [info] setting maxHashResizeThreads to 24; Exception : [unknown library format string : R]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting.; [2024-05-29 11:13:30.128] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2024-05-29 11:13:30.128] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2024-05-29 11:13:30.128] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.; [2024-05-29 11:13:30.128] [jointLog] [info] parsing read library format. So, as far I can see, being a bloody beginner, the error: Exception : [unknown library format string : R] somehow suggests that the small letter r in my command line is interpreted as a capital letter???; Or is there anything else wrong with my command?. Help would be appreciated. Thanks and best,; Matthias",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/933:583,Log,Logs,583,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/933,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"Dear all,. I would say that salmon is so fast to report the TPM and read counts for each transcript or gene, and I always use salmon+tximport+edgeR to detect the differentially expressed genes. Because the edgeR can output the normalized read counts and tximport can output TPM for each gene based on the results generated by salmon, I asked the difference between TPM and log2(CPM). From following correlation plot, I found that the samples are clustered by different quantifications, TPM and CPM, but not by samples. Because my RNA-seq experiment contains 7 biological replicates in each of two conditions, I decide to identify differentially expressed genes by using Wilcoxon rank-sum test based on each gene’s TPM or CPM. Also, I can also retain the overlapped differentially expressed genes between edgeR and Wilcoxon rank-sum test. I would like to hear your suggestion. ```; y <- DGEList(counts=data, group=group, genes=genelength) # the genelength is generated by salmon+tximport for each sample ; keep <- filterByExpr(y); y <- y[keep,,keep.lib.sizes=FALSE]; y <- calcNormFactors(y); logcpm <- cpm(y, log=TRUE, prior.count=1); ```; [tpm_cpm_corr-spearman.pdf](https://github.com/COMBINE-lab/salmon/files/10067714/tpm_cpm_corr-spearman.pdf). Thank you in advance. Best regards,; Zheng zhuqing",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/812:688,test,test,688,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/812,4,"['log', 'test']","['log', 'logcpm', 'test']"
Testability,"Dear all. Thank you for your prompt reply. ; @mikelove yes, the CPM is only cross-sample normalisation, but not cross genes. TPM is both cross-sample and cross-gene normalisation. Thus, in my mind, TPM is more suitable for downstream RNA-seq analysis, including clustering analysis, differential expression testing using Wilcoxon rank-sum test. Also, for accurately detecting differentially expressed genes, is it reasonable to overlap the results from different methods, such as edgeR+Wilcoxon rank-sum test?. Best regards,; Zheng zhuqing",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/812#issuecomment-1324468833:307,test,testing,307,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/812#issuecomment-1324468833,3,['test'],"['test', 'testing']"
Testability,"Dear salmon authors,. While I was using **salmon (v0.11.0, downloaded executable, on a Ubuntu Linux** server) to process a **single-end RNA-seq library**, it reported the following error message:. ""**[ERROR] Transcript IDs are not in sorted order; please report this bug on GitHub!**"" . Actually I found it reports this error message for over tens of millions of times through greping the log file. And the command line I applied to invoke salmon was like this:. ""**salmon quant -i mySalmonIndexFile(FMD based/transcriptome) -l A -r myLibrary.fastq -p 8**"". It looks like this is something about single-end reads processing, since I arbitrarily picked up another pair-end library, which works prefectly fine with command line ""-1 PE_library_1.fastq -2 PE_library_2.fastq"", however, when I deliberately provide only one end of the library with ""-r PE_library_1/2.fastq"", exactly the same error was recurred immediately. Curiously, salmon could still accomplish the whole procedure and generate the results file with the aformentioned error reported. But I' m worried about its reliability in this situation. I' m wondering if you have any clues about this issue. With many thanks ahead!",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/265:389,log,log,389,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/265,1,['log'],['log']
Testability,"Dear salmon project. I have a proposal. Right now, the Travis CI test has 1 case for gcc-7.; I thought if we could add and remove test cases easily such as latest version gcc-8, minimal support version gcc-5, clang, and Mac OSX, we would be happy to contribute the source code. Look at the RNA Sequence tool: Trinity's case. [1][2]; The structure of the `.travis.yml` is to add the test cases easily. It has gcc-N and Mac OSX case.; And I prepared it for this salmon project.; I would like to send pull-request soon after now. [1] https://travis-ci.org/trinityrnaseq/trinityrnaseq; [2] https://github.com/trinityrnaseq/trinityrnaseq/blob/master/.travis.yml",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/272:65,test,test,65,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/272,3,['test'],['test']
Testability,"Dear salmon support team,. I firstly assembled MAGs from my metagenome data, then predicted the ORF gene operons using the prodigal software to generate the corresponding prodigal predicted MAG *faa files. Now, I am using each MAG *fna fasta file to map on their corresponding prodigal predicted *faa protein sequences. **But, the TPM values in my quantification files - quant.sf are all as 0.**. So, could you give me some suggestions on this condition?. **Salmon command lines**; #index each MAG faa file; for f in ${quant_sf_dir}*faa; do ; fname=${f##*/}; fbase=${f##*.} ; index_dir=${f%.faa}; #mkdir -p ${index_dir}; #echo ${index_dir}; /services/tools/salmon/1.5.2/bin/salmon index -t ${f} -i ${index_dir}; done. #quantify each MAG fna using each corresponding MAG indexed faa file; for i in ${MAG_PATH}*.fasta; do; iname=${i##*/}; i_dir=${iname%.fasta}; index_dir=${quant_sf_dir}${i_dir}; /services/tools/salmon/1.5.2/bin/salmon quant -i ${index_dir} -l A \; -r ${i} \; **--minAssignedFrags 1 \**; -p 20 -o ${index_dir}_salmon_count > ${index_dir}.salmon.log 2>&1;; done. Best,. Bing",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/792:1061,log,log,1061,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/792,1,['log'],['log']
Testability,"Does it make sense to have '^' and/or '$' around the regex? Having anchors usually speeds up a regex. Otherwise, I am not sure. Have we tested other libraries than boost::regexp?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1013343046:136,test,tested,136,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1013343046,1,['test'],['tested']
Testability,"Due to a current default in the boost library (https://github.com/boostorg/math/issues/1211) in boost::math::digamma, there is a performance hit on aarch64. This happens on v1.10.3 of Salmon, with GNU compiler 13 on Linux aarch64. A 4-thread quantization of one of the Salmon tutorials DRR0* series files spends ~15% of time in this routine (called within CollapsedEMOptimizer). On a larger example, we see 7% performance hit over a run that takes 1300 seconds on 4 cores. On x86 this time is small enough to be lost in the noise. `salmon quant -i athal_index -l A ; -1 DRR016125/DRR016125_1.fastq.gz; -2 DRR016125/DRR016125_2.fastq.gz ; -p $threads --validateMappings -o quants/DRR016125_quant`. There is a simple fix which is to ensure the CMake/Makefiles ensure salmon compiles with: ; `-DBOOST_MATH_NO_LONG_DOUBLE_MATH_FUNCTIONS`; or to add that to any file that brings in boost::math via adding `#define BOOST_MATH_NO_LONG_DOUBLE_MATH_FUNCTIONS` at the start. With that change, a 1300 second runtime drops to 1212 for the larger test case, and for the tutorial case is 48 seconds down to 40 on a 4-core r8g.xlarge (Graviton4). Whilst Boost may fix the issue soon - it's likely that older versions of the library will be found installed for some time. It would be helpful to add this define to cmake settings, or the sources.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/966:1034,test,test,1034,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/966,1,['test'],['test']
Testability,"E info ****; User: lcollado; Job id: 9987283; Job name: step6-salmon_test2.gsk_phaseII; Hostname: compute-060; Task id:; Version Info: ### A newer version of Salmon is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and minor bug fixes; please upgrade at your; earliest convenience.; ###; ### salmon (mapping-based) v0.7.2; ### [ program ] => salmon; ### [ command ] => quant; ### [ index ] => { /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/GENCODE/GRCh38_hg38/transcripts/salmon_index_gencode.v25.transcripts }; ### [ threads ] => { 1 }; ### [ libType ] => { ISR }; ### [ mates1 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10002_C29P7ACXX.fastq.gz }; ### [ mates2 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10002_C29P7ACXX_read2.fastq.gz }; ### [ output ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test2/R10002_C29P7ACXX }; Logs will be written to /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test2/R10002_C29P7ACXX/logs; [2017-03-08 11:53:36.762] [jointLog] [info] parsing read library format; [2017-03-08 11:53:36.763] [jointLog] [info] There is 1 library.; terminate called without an active exception; /cm/local/apps/sge/var/spool/compute-060/job_scripts/9987283: line 31: 1629 Aborted (core dumped) /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Softw; are/Salmon-0.7.2_linux_x86_64/bin/salmon quant -i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/GENCODE/GRCh38_hg38/transcripts/salmon_index_gencode.v25.tr; anscripts -p 1 -l ISR -1 ${FILE1} -2 ${FILE2} -o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test2/${ID}; **** Job ends ****; Wed Mar 8 11:53:40 EST 2017; ```. as well as the `gdb` output for it's core dump file:. ```bash; $ gdb core.1629; GNU gdb (GDB) Red Hat Enterprise Linux (7.2-60.el6_4.1); Copyright (C) 2010 Free Software Foundation, Inc.; License GPLv3+: GNU GPL version 3 or later <http://",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126:29350,Log,Logs,29350,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"EASE_ARM64_T6020; Kernel configured for up to 12 processors.; 12 processors are physically available.; 12 processors are logically available.; Processor type: arm64e (ARM64E); Processors active: 0 1 2 3 4 5 6 7 8 9 10 11; Primary memory available: 64.00 gigabytes; Default processor set: 650 tasks, 3562 threads, 12 processors; Load average: 1.14, Mach factor: 10.84; /bin/machine = unknown; /usr/bin/oslevel = unknown; /bin/universe = unknown. PATH: /Users/jeremybono/miniforge3/bin; PATH: /Users/jeremybono/miniforge3/condabin; PATH: /opt/homebrew/bin; PATH: /opt/homebrew/sbin; PATH: /usr/local/bin; PATH: /System/Cryptexes/App/usr/bin; PATH: /usr/bin; PATH: /bin; PATH: /usr/sbin; PATH: /sbin; PATH: /Users/jeremybono/Downloads/bbmap; PATH: /var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/local/bin; PATH: /var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/bin; PATH: /var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/appleinternal/bin. ## ----------- ##; ## Core tests. ##; ## ----------- ##. configure:2959: checking build system type; configure:2973: result: arm-apple-darwin22.6.0; configure:2993: checking host system type; configure:3006: result: arm-apple-darwin22.6.0; configure:3066: checking if debugging code should be compiled; configure:3082: result: no; configure:3122: checking which encoders to build; configure:3209: result: lzma1 lzma2 delta x86 powerpc ia64 arm armthumb sparc; configure:3213: checking which decoders to build; configure:3305: result: lzma1 lzma2 delta x86 powerpc ia64 arm armthumb sparc; configure:3644: checking which match finders to build; configure:3695: result: hc3 hc4 bt2 bt3 bt4; configure:3713: checking which integrity checks to build; configure:3755: result: crc32 crc64 sha256; configure:3792: checking if assembler optimizations should be used; configure:3816: result: no; configure:3847: checking if small size is preferred over speed; configure:3865: result: no; configure:3881: checking if threading",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/912:2878,test,tests,2878,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/912,1,['test'],['tests']
Testability,"Excellent! Now we should do some internal testing to see if this has any negative performance impact on machines that _do_ have SSE4. Then we can determine if we can just make this the default, or if it's worth cutting a release under 2 configurations.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/500#issuecomment-610602162:42,test,testing,42,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/500#issuecomment-610602162,1,['test'],['testing']
Testability,Exception : [rapidjson internal assertion failure: IsObject()],MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/518:32,assert,assertion,32,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/518,1,['assert'],['assertion']
Testability,"FInally, it took like 25 hours, I am attaching the log. ; [salmon_quant.log](https://github.com/COMBINE-lab/salmon/files/4706992/salmon_quant.log)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/527#issuecomment-636410253:51,log,log,51,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/527#issuecomment-636410253,3,['log'],['log']
Testability,"FYI - for the sample in question, there are **9,974** ""filtered"" barcodes and **737,280** ""raw"" barcodes (from CellRanger). If I take the larger list of ""raw"" barcodes and I remove the ""-1"" from each of them, then that is what I am currently testing for Alevin.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-878607734:242,test,testing,242,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-878607734,1,['test'],['testing']
Testability,"First time trying to use SALMON 1.5.2 (not bioconda) index with decoy.txt on Arabidopsis thaliana. I'm using AtRTD3 Transcriptome ""atRTD3_07082020.fasta"" (https://ics.hutton.ac.uk/atRTD/RTD3/ - username atrtd; password atrtd3-06092021) and the genome ""GWHBDNP00000000.1"" from https://ngdc.cncb.ac.cn/gwh/Assembly/21820/show. I followed the steps from (https://gist.github.com/k3yavi/a486647c35158a8296cec543ed9b526f) using this two files as follow:; ```; grep ""^>"" <(zcat GWHBDNP00000000.1.genome.fasta.gz) | cut -d "" "" -f 1 > decoys.txt; sed -i -e 's/>//g' decoys.txt; cat atRTD3_07082020.fasta GWHBDNP00000000.1.genome.fasta.gz > gentrome.fa.gz; salmon index -t gentrome.fa.gz -d decoys.txt -p 12 -i salmon_index --gencode; ```. The index generation failed, creating a folder with only two files ""pre_indexing.log"" and ""ref_indexing.log""([pre_indexing.log](https://github.com/COMBINE-lab/salmon/files/7515704/pre_indexing.log) and [ref_indexing.log](https://github.com/COMBINE-lab/salmon/files/7515701/ref_indexing.log)) . I recieved this error from the terminal:; ![Screenshot from 2021-11-10 17-24-24](https://user-images.githubusercontent.com/71443183/141187955-4601923f-001f-424a-969a-8ad346f2cf36.png). - OS: Ubuntu Linux; - Version 21.10. Thanks for this great software!!!",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/720:812,log,log,812,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/720,6,['log'],['log']
Testability,"Fixes Dockerfile to be FROM ubuntu:16.04, fixes a checksum in CMakeLists.txt, and makes build_test.sh executable. I tested this by changing the Dockerfile to copy the code into the image rather than pulling the code directly from github so that I could test the changes I made. I then built the image and ran:; ```; $ docker run combinelab/salmon:0.8.2 salmon --version; version : 0.8.2; ```",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/158:116,test,tested,116,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/158,2,['test'],"['test', 'tested']"
Testability,"Following are some weird thing I am noticing in your log:. ```; 2019-11-02T16:23:27.745502492Z [2019-11-02 16:23:27.745] [puff::index::jointLog] [warning] The decoy name JH584303.1 was encountered more than once --- please be sure all decoy names and sequences are unique.; 2019-11-02T16:23:27.745504753Z [2019-11-02 16:23:27.745] [puff::index::jointLog] [warning] The decoy name JH584304.1 was encountered more than once --- please be sure all decoy names and sequences are unique.; 2019-11-02T16:24:33.408457659Z [2019-11-02 16:24:33.408] [puff::index::jointLog] [warning] The decoy file contained the names of 88 decoy sequences, but 66 were matched by sequences in the reference file provided.; ```; Where we expect only 66 decoys (genomic targets) to start with. I think it's the issue with the gencode reference names having blank space as a delimiter in its target name with repeated names. The ipython notebook was right but I missed to update the static website, in the prepare metadata section I have updated the decoy name extracting step to:. ```; grep ""^>"" <(zcat GRCm38.primary_assembly.genome.fa.gz) | cut -d "" "" -f 1 > decoys.txt; ```. That is I splitting the genomic target names by space and taking just the first part as the target name. I working on checking what's happening if I follow the step of using the full gencode names and would update you.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/441#issuecomment-549146224:53,log,log,53,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/441#issuecomment-549146224,1,['log'],['log']
Testability,"For clarification: From memory, using the same cluster, I had the same error at the same stage but only with particular data sets and confirmed this was not an issue of available memory. @k3yavi may remember some more of the details but we never got to the bottom of it. . @Acribbs Testing on another cluster would be a good idea in case this is a very specific cluster configuration issue",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458160685:282,Test,Testing,282,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458160685,1,['Test'],['Testing']
Testability,Forgot the file...; [test.fa.gz](https://github.com/COMBINE-lab/salmon/files/2057739/test.fa.gz),MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/228#issuecomment-393482330:21,test,test,21,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/228#issuecomment-393482330,2,['test'],['test']
Testability,"GAGCACGC_lane-004-chunk-002.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-001-chunk-001.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-002-chunk-000.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-003-chunk-003.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-004-chunk-002.fastq.gz]; Version Info: This is the most recent version of salmon.; [2018-12-06 11:14:56.513] [alevinLog] [info] A custom protocol (END, BC length, UMI length) = (5, 14, 5) is being used. Updating UMI k-mer length accordingly.; Logs will be written to ./fastq/test/logs; [2018-12-06 11:14:56.533] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; ### alevin (dscRNA-seq quantification) v0.12.0; ### [ program ] => salmon ; ### [ command ] => alevin ; ### [ libType ] => { ISR }; ### [ gemcode ] => { }; ### [ index ] => { ./transcripts_index_salmon/ }; ### [ threads ] => { 8 }; ### [ output ] => { ./fastq/test/ }; ### [ tgMap ] => { ./hg_transcriptome/tx2tx.tsv }; ### [ end ] => { 5 }; ### [ umiLength ] => { 5 }; ### [ barcodeLength ] => { 14 }; ### [ dumpCsvCounts ] => { }; ### [ mates1 ] => { /tmp/tmp.p28w2nGvAn/p1.fa }; ### [ mates2 ] => { /tmp/tmp.p28w2nGvAn/p2.fa }; ### [ unmatedReads ] => { ./fastq/fastqs/flowcell1/read-I1_si-ACTTCACT_lane-001-chunk-001.fastq.gz ./fastq/fastqs/flowcell1/read-I1_si-ACTTCACT_lane-002-chunk-000.fastq.gz ./fastq/fastqs/flowcell1/read-I1_si-ACTTCACT_lane-003-chunk-003.fastq.gz ./fastq/fastqs/flowcell1/read-I1_si-ACTTCACT_lane-004-chunk-002.fastq.gz ./fastq/fastqs/flowcell1/read-I1_si-CGAAGTTG_lane-001-chunk-001.fastq.gz ./fastq/fastqs/flowcell1/read-I1_si-CGAAGTTG_lane-002-chunk-000.fastq.gz ./fastq/fastqs/flowcell1/read-I1_si-CGAAGTTG_lane-003-chunk-003.fastq.gz ./fastq/fastqs/flowcell1/read-I1_si-CGAAGTTG_lane-004-chunk-002.fastq.gz ./fastq/fastqs/flowcell1/read-I1_si-GAGCACGC_lane-001-chunk-001.fastq.gz ./fastq/fastqs/flowcell1/read-I1_si-GAGCACGC_lane-002-chu",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-445008548:2588,test,test,2588,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-445008548,1,['test'],['test']
Testability,"Good to hear, I checked the release log but I wasn't able to confirm whether I was using the bugged conda build since we are using docker biocontainers (build v1.9.0--h7e5ed60_1). I'll upgrade our pipeline and close the issue after a new run of the same data if the problem seems to be resolved. Best,; Alex",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/876#issuecomment-1739857661:36,log,log,36,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/876#issuecomment-1739857661,1,['log'],['log']
Testability,"Got it working. The ""short"" form for how to do so in Centos 6.9 is:. ```; 1. install current versions of autoconf, automake, and cmake; 2. install the boost 1.57 set of RPMS if they are not already present; 3. install devtoolset-4 (or higher); 4. download and unpack salmon; 5. modify CMakeLists.txt; #around line 220, remove condition testing, set it to just; set (Boost_USE_STATIC_LIBS OFF); #around line 310; set(Boost_ADDITIONAL_VERSIONS ""1.57.0"" ""1.59.0"" ""1.60.0"" ""1.61.0"" ""1.62"" ""1.63"" ""1.64"" ""1.65"" ""1.66""); find_package(Boost 1.57.0 COMPONENTS iostreams filesystem system thread timer chrono program_options); 6. in top level of salmon do; mkdir build; cd build; nice scl enable devtoolset-4 '~/bin/cmake -DBoost_DEBUG=ON -DCMAKE_VERBOSE_MAKEFILE:BOOL=ON -DBoost_NO_BOOST_CMAKE=BOOL:ON -DBOOST_LIBRARYDIR=/usr/lib64/boost157 -DBOOST_INCLUDEDIR=/usr/include/boost157 ../CMakeLists.txt' >try_cmake2.log 2>&1 &; 7. in top level of salmon do; nice scl enable devtoolset-4 'make' >build_2018_06_13a.log 2>&1 &; There will be lots of warnings but it should run to completion; 8. make install; cp bin/salmon $WHEREVER/bin/salmon; rmdir lib/pkgconfig; cp lib/* $WHEREVER/lib; rm -rf bin; rm -rf lib; export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$WHEREVER/lib; make test; ```. Is it OK to delete the (large) salmon directory at this point, or is the binary hardwired to find things in it?; I know that this does not work:. ```; cd ..; mv salmon not_salmon; cd not_salmon; make test; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-397050436:336,test,testing,336,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-397050436,5,"['log', 'test']","['log', 'test', 'testing']"
Testability,"Got it, thanks for the heads up. I'd probably reach out to the refgenie people about the hg38 specific versions. It makes sense to have the feature of having the gtf at the time of indexing. The only concern I have is that mandating to have the gtf might restrict the overall workflow by a bit. Specifically because a user might not always have the full GTF available for every use case, although we can always make having GTF as an optional requirement for indexing. Adding the support should not be too difficult but it will certainly add a new logic path which would need thorough testing. . We'll certainly keep you updated with the feature as we progress although it can take some time to get back. In terms of your pipeline one option would be to actually save the GTF explicitly in the salmon index folder post indexing. Although it's definitely not a very computer science friendly solution but it will help maintain the consistency while we work on the feature.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/595#issuecomment-738200842:547,log,logic,547,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/595#issuecomment-738200842,2,"['log', 'test']","['logic', 'testing']"
Testability,"Great suggestion, thanks @rob-p and @gmarcais . Somehow, I missed it. I added it in the latest commit. Speed now from 3 runs:; ```; real 1m19.884s 1m15.891s 1m21.462s ; user 8m9.189s 9m1.100s 9m48.764s ; sys 0m5.079s 0m5.170s 0m3.477s; ```; 50% improvement over the past results, i.e., about 33% slower than specific protocol flag now. Although, ideally I should have ran the earlier tests thrice but the sd is small so results should be valid. Nonetheless, I'll do more speed tests with versions in the future. . Let me know what other thoughts you have and what else have I missed. I have some minor improvements in mind too.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1013326966:384,test,tests,384,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1013326966,2,['test'],['tests']
Testability,"Great! One thing I found is that if I `INSTALL` the unitTests like I've been doing, they fail to find the appropriate libraries (again if they were fetched). I pushed a fix for this in develop. Basically, you just have to copy, not install, the unit test executable. That's done with the following incantation:. ```; add_custom_command(TARGET unitTests POST_BUILD; COMMAND ${CMAKE_COMMAND} -E copy $<TARGET_FILE:unitTests> ${GAT_SOURCE_DIR}/tests/$<TARGET_FILE_NAME:unitTests>; COMMENT ""Copying unitTests""; ); ```. I don't know if this is necessary for homebrew or not, since it has no effect on the salmon binary itself.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/70#issuecomment-239632810:250,test,test,250,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/70#issuecomment-239632810,2,['test'],"['test', 'tests']"
Testability,"Great; hopefully I'll be able to repro the issue with the other sample. No rush, as I'll be finishing putting together the final for my class tomorrow morning (and so will be testing the sample between writing exam questions ;P). I just hope this doesn't turn out to be an environment / machine-specific behavior (those are *the worst* bugs to track down and fix).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266948036:175,test,testing,175,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266948036,1,['test'],['testing']
Testability,"Great; this will test against develop, right? Not master. Because 0.7.0 is coming from develop.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/70#issuecomment-239628911:17,test,test,17,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/70#issuecomment-239628911,1,['test'],['test']
Testability,"Great; would you like help testing the pipeline, and integrating it into bcbio? We could help with both :)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/52#issuecomment-255123178:27,test,testing,27,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/52#issuecomment-255123178,1,['test'],['testing']
Testability,"Greetings,. When trying to debug test failure, I ended up with an incomplete error messages which turned out to stem from a typo in the variable name, so I took the liberty to make the whole message a bit more verbose to help with the present and future debugging. I thought you might be interested.; Have a nice day, :); Étienne.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/810:33,test,test,33,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/810,1,['test'],['test']
Testability,"Greetings. Under Centos 6.9, using cmake-3.13.2, gcc 7.3 and 1.68.0, the salmon-1.30 build fails at the make step.; The command make -j8 fails with:. ```; [100%] Linking CXX executable salmon; ../../external/install/lib/libstaden-read.a(libstaden_read_la-open_trace_file.o): In function `find_file_url':; open_trace_file.c:(.text+0xd32): warning: the use of `tempnam' is dangerous, better use `mkstemp'; ../external/pufferfish/src/libpuffer.a(PufferfishIndexer.cpp.o): In function `std::shared_ptr<spdlog::logger> spdlog::details::registry_t<std::mutex>::create<__gnu_cxx::__normal_iterat; or<std::shared_ptr<spdlog::sinks::sink>*, std::vector<std::shared_ptr<spdlog::sinks::sink>, std::allocator<std::shared_ptr<spdlog::sinks::sink> > > > >(std::__cxx11::basic_string<char,; std::char_traits<char>, std::allocator<char> > const&, __gnu_cxx::__normal_iterator<std::shared_ptr<spdlog::sinks::sink>*, std::vector<std::shared_ptr<spdlog::sinks::sink>, std::alloc; ator<std::shared_ptr<spdlog::sinks::sink> > > > const&, __gnu_cxx::__normal_iterator<std::shared_ptr<spdlog::sinks::sink>*, std::vector<std::shared_ptr<spdlog::sinks::sink>, std::alloc; ator<std::shared_ptr<spdlog::sinks::sink> > > > const&)':; PufferfishIndexer.cpp:(.text._ZN6spdlog7details10registry_tISt5mutexE6createIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrINS_5sinks4sinkEESt6vectorISA_SaISA_EEEEEES7_INS_6loggerEERKN; St7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEERKT_SS_[_ZN6spdlog7details10registry_tISt5mutexE6createIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrINS_5sinks4sinkEESt6vectorISA_S; aISA_EEEEEES7_INS_6loggerEERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEERKT_SS_]+0x73): undefined reference to `vtable for std::_Sp_counted_ptr_inplace<spdlog::logger, std::al; locator<spdlog::logger>, (__gnu_cxx::_Lock_policy)2>'; PufferfishIndexer.cpp:(.text._ZN6spdlog7details10registry_tISt5mutexE6createIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrINS_5sinks4sinkEESt6vectorISA_SaISA_EEEEEES7_INS_6loggerEER",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/570:506,log,logger,506,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/570,1,['log'],['logger']
Testability,"HI @gianfilippo ,; I think #245 might help understanding the problem better.; Specifically to answer your questions, I am guessing `737K-august-2016.txt` is all the set of Cellular Barcodes(CB) being whitelisted by 10xGenomics protocol while in Alevin when you are giving external whitelist it assumes that the user is pretty confident about the presence of *all* the given CBs in their experiment. for example if you want to compare Alevin and cellranger apple to apple then you might have to give the `barcodes.tsv`(usually is present along with the `mtx` file) generated by the cellranger. (after removing `-1` from the CB names). ; `[alevinLog] [error] Barcode not found in frequency table`: This error means some of the CB given externally through the whitelist command seems to have no reads at all which violates the above assumption, you can potentially skip this error by using `--debug` flag with alevin (only if have version v0.11.3) but this mode has is yet to be extensively tested.; In case where you don't externally give whitelist CB, Alevin uses knee and KDE based method to identify the cutoff on the knee (and later correct for it) of the CB distribution. Based on your specific dataset it is possible that the method might be overshooting and aggressively identifying less number of clusters. If you can share the log and some part of your data then we can take a look what's going on. Hope this helps.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/284#issuecomment-417964393:988,test,tested,988,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/284#issuecomment-417964393,2,"['log', 'test']","['log', 'tested']"
Testability,"Happy to compare notes! For benchmarking accuracy I'm mostly using data from SEQC. There are four reference samples, each sequenced quite deeply at several different labs. I took 20 lanes from BGI, which is about 100 million reads, which I compare it to TaqMan (~800 genes), PrimePCR on (~18000 genes), and ERCC spike-ins. . On top of that, to get more directly at isoform-level accuracy, I'm simulating data using rlsim, which I've found to be the least awful RNA-Seq simulator. Unlike most simulators, it models some technical effects/bias. I think it underestimates these, but still a lot better than most that assume perfect uniform random sampling, etc. I also have a set of benchmarks designed to get at the question of consistency or stability of estimates, which is one of the main thrusts of the paper I'm working on. The other aspect I've been fretting about a lot the last month has been just what metric to use. You should check out this paper if you haven't seen it, which is pretty eye-opening as to the problems with using correlation on compositional gene expression data. > Lovell, D., Pawlowsky-Glahn, V., Egozcue, J. J., Marguerat, S., & Bähler, J. (2015). Proportionality: a valid alternative to correlation for relative data. PLoS Computational Biology, 11(3), e1004075. http://doi.org/10.1371/journal.pcbi.1004075. Those problems aren't unique to correlation. E.g. the ""median relative difference"" approach taken by the Kallisto paper is very much affected by this, I think even more so than correlation. The method I've adopted is to use the ""proportionality correlation"" they propose on page 9, and add 0.1 TPM to expression values to account for zeros and tiny values. It's not terribly sensitive to the additive constant and gives pretty reliable results in my experience. I have a somewhat horrifying labyrinth of makefiles and julia code that runs all this which I'll probably make public on github in the next few weeks, which may or may not be helpful.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/6#issuecomment-112291922:28,benchmark,benchmarking,28,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/6#issuecomment-112291922,2,['benchmark'],"['benchmarking', 'benchmarks']"
Testability,"Hello @k3yavi and thank you for the pointer,. I obtained the same bug with v.0.12.0 (also Compiled from source). Here's the console log :. ```; ~/software/salmon/scripts/v1_10x/run.sh ~/software/salmon-0.12.0/bin/salmon alevin -l ISR -b ./fastq/fastqs/flowcell1/ --gemcode -i ./transcripts_index_salmon/ -p 8 -o ./fastq/test/ --tgMap ./hg_transcriptome/tx2tx.tsv --end 5 --umiLength 5 --barcodeLength 14 --dumpCsvCounts. TEMPDIR is /tmp/tmp.p28w2nGvAn; Running command [/home/ebecht/software/salmon-0.12.0/bin/salmon alevin -l ISR --gemcode -i ./transcripts_index_salmon/ -p 8 -o ./fastq/test/ --tgMap ./hg_transcriptome/tx2tx.tsv --end 5 --umiLength 5 --barcodeLength 14 --dumpCsvCounts -1 /tmp/tmp.p28w2nGvAn/p1.fa -2 /tmp/tmp.p28w2nGvAn/p2.fa -r ./fastq/fastqs/flowcell1/read-I1_si-ACTTCACT_lane-001-chunk-001.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-ACTTCACT_lane-002-chunk-000.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-ACTTCACT_lane-003-chunk-003.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-ACTTCACT_lane-004-chunk-002.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-CGAAGTTG_lane-001-chunk-001.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-CGAAGTTG_lane-002-chunk-000.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-CGAAGTTG_lane-003-chunk-003.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-CGAAGTTG_lane-004-chunk-002.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-GAGCACGC_lane-001-chunk-001.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-GAGCACGC_lane-002-chunk-000.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-GAGCACGC_lane-003-chunk-003.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-GAGCACGC_lane-004-chunk-002.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-001-chunk-001.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-002-chunk-000.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-003-chunk-003.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-004-chunk-002.fastq.gz]; Version Info: This is the most recent version of salmon.; [2018-12-",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-445008548:132,log,log,132,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-445008548,3,"['log', 'test']","['log', 'test']"
Testability,"Hello @rob-p !. Thanks for developing and maintaining salmon!. When running salmon in [bcbio](https://github.com/bcbio/bcbio-nextgen/) ; we are observing a slight difference in total counts when using automatic strandedness (-l A) and (-l ISF). Everything else is the same: data, STAR versions, STAR alignments (we are using STAR alignment quantification mode). The difference (sum over NumReads column in quant.sf) is 400 counts / 30mln:; - -l A: 29,620,300; - -l ISF: 29,619,900; It affects 628 genes out of 58,735. The maximum difference is 311 counts for a gene. STAR alignment log is the same:; ```; Mapping speed, Million of reads per hour | 157.61 ; Number of input reads | 76133470; Average input read length | 271; UNIQUE READS:; Uniquely mapped reads number | 62201102; Uniquely mapped reads % | 81.70%; Average mapped length | 271.68; Number of splices: Total | 29864202; Number of splices: Annotated (sjdb) | 29762114; Number of splices: GT/AG | 29430057; Number of splices: GC/AG | 286461; Number of splices: AT/AC | 27717; Number of splices: Non-canonical | 119967; Mismatch rate per base, % | 0.34%; Deletion rate per base | 0.03%; Deletion average length | 1.95; Insertion rate per base | 0.02%; Insertion average length | 1.57; MULTI-MAPPING READS:; Number of reads mapped to multiple loci | 5982273; % of reads mapped to multiple loci | 7.86%; Number of reads mapped to too many loci | 138709; % of reads mapped to too many loci | 0.18%; UNMAPPED READS:; % of reads unmapped: too many mismatches | 0.00%; % of reads unmapped: too short | 9.42%; % of reads unmapped: other | 0.63%; CHIMERIC READS:; Number of chimeric reads | 482178; % of chimeric reads | 0.63%; ```. salmon is 1.3.0 in both cases, the command is the same but the libtype:; ```bash; salmon \; quant \; -l ISF \; -p 16 \; -t /path/to/transcriptome/hg38.fa \; -o /path/to/sample; -a /path/to/sample.transcriptome.bam; --numBootstraps 30; ```. salmon logs:; `-l A`; ```; Completed first pass through the alignment file.;",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/669:582,log,log,582,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/669,1,['log'],['log']
Testability,"Hello Avi,. Here is my out put log. Thank you in advance for an help you can provide. [2019-07-29 15:58:39.034] [jointLog] [info] Fragment incompatibility prior; below threshold. Incompatible fragments will be ignored.; [2019-07-29 15:58:39.034] [jointLog] [info] Usage of --validateMappings; implies use of minScoreFraction. Since not explicitly specified, it is; being set to 0.65; [2019-07-29 15:58:39.034] [jointLog] [info] Usage of --validateMappings,; without --hardFilter implies use of range factorization.; rangeFactorizationBins is being set to 4; [2019-07-29 15:58:39.034] [jointLog] [info] Usage of --validateMappings; implies a default consensus slack of 0.2. Setting consensusSlack to 0.2.; [2019-07-29 15:58:39.034] [jointLog] [info] parsing read library format; [2019-07-29 15:58:39.034] [jointLog] [error] Failed to successfully parse; any complete read libraries. Please make sure you provided arguments; properly to -1, -2 (for paired-end libraries) or -r (for single-end; libraries), and that the library format option (-l) *comes before* the read; libraries. Best,. Sara. On Mon, Jul 29, 2019 at 3:25 PM Avi Srivastava <notifications@github.com>; wrote:. > You passed paired-end files; > to salmon, but you passed 12 files to --mates1 and 13 files to --mates2.; > You must pass the same number of files to both flags; >; > Is this true ? Can you share the log ?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/COMBINE-lab/salmon/issues/408?email_source=notifications&email_token=AEHDXAH7HQIR4ZVWMTE2KXLQB5U5LA5CNFSM4IGU4ZTKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD3CF3JY#issuecomment-516185511>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AEHDXAG7WI3B7QBMJOSXTATQB5U5LANCNFSM4IGU4ZTA>; > .; >. -- ; Sara E. Boles, MS; PhD Candidate | Whitehead Lab; Pharmacology and Toxicology Graduate Group; Department of Environmental Toxicology; Univer",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408#issuecomment-516194201:31,log,log,31,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408#issuecomment-516194201,1,['log'],['log']
Testability,"Hello all, . I really wish Salmon was easier to install. . When running: . _cmake -DFETCH_BOOST=TRUE -DCMAKE_INSTALL_PREFIX='/home/.../salmon-master/'_. I get the following message: . _Making Release build; running /home/Documents/apps/salmon-master/scripts/fetchRapMap.sh 2>&1; /home/Documents/apps/salmon-master/scripts/fetchRapMap.sh: line 33: curl: command not found; -- fetch RAPMAP exit code 127. CMake Error at CMakeLists.txt:265 (message):; Could not fetch RapMap source [fetchRapMap.sh returned exit code 127]. -- Configuring incomplete, errors occurred!; See also ""/home/krablab/Documents/apps/salmon-master/CMakeFiles/CMakeOutput.log"".; See also ""/home/krablab/Documents/apps/salmon-master/CMakeFiles/CMakeError.log""._. This seems to be an issue that keeps coming up. What is the proper way to solve it? ; Thanks in advance",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/331:641,log,log,641,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/331,2,['log'],['log']
Testability,"Hello everyone! This is my first time analyzing RNAseq data and I am very much learning as I go while following a YouTube series (https://www.youtube.com/watch?v=butxOf_fxTY&t=217s&ab_channel=SimonCockell). Please excuse if I use wrong terminology in this post, I am very new to all of this and sometimes don't know what the right words are to describe what I am doing or trying to do (lol)!. With the fastq files of reads generated from my RNAseq experiment, I first ran FastQC. The quality of my data seemed to be fine as the per base sequence quality scores were 32+ and most of the other tests passed as well. Next, I built my index for Salmon using the fasta file from Gencode for the human transcriptome. Afterwards, I ran Salmon with the built index and had it automatically detect the library type. When the program was done aligning to the index, I saw that the file had a mapping rate of 40%. I guess what I'm asking is, is this an acceptable mapping rate or should I be concerned?? The reason I ask is because in the data I was working with while learning via the Youtube series, those datasets had mapping rates of nearly 90%. Comparing FastQC reports, my data was of similar/better quality than the data from the Youtube series. In case this is helpful in answering my question, this is the information from the logs for one of my samples:. ```; [2020-09-05 13:51:07.144] [jointLog] [info] setting maxHashResizeThreads to 1; [2020-09-05 13:51:07.144] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2020-09-05 13:51:07.159] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2020-09-05 13:51:07.159] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.35.; [2020-09-05 13:51:07.159] [jointLog] [info] parsing read library format; [2020-09-05 13:51:07.159] [jointLog] [info] Ther",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/571:592,test,tests,592,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/571,1,['test'],['tests']
Testability,"Hello salmon team and @k3yavi,; I would like to have an idea of the sequencing saturation in my samples (10x) based on the alevin UMI deduplication default algorithm (that is, the fraction of duplicated reads from unique transcripts that are sequenced at least 2 times). I use this as a quality metrics to evaluate if the sequencing depth is adequate and the amount of information I could be missing. Also, I would like to play with the different deduplication options in alevin and use it as a comparison point.; I have not been able to find informations in the logs that could help me to compute the seq sat, and I am not sure about the terms used in the output. Could you point me in the right direction?; Best wishes.; (salmon 0.11.1, python 3.6.5 with pip, centOS 7)",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/267:563,log,logs,563,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/267,1,['log'],['logs']
Testability,"Hello to all,. I have a question about salmon and more precisely the alignment part.; I use salmon on BAM files of RNAseq data and the problem is that I don't really know what to use as <LIBTYPE>. I used -l A to get the automatic library but the ""meta_info.json"" it gives me:. ```; ""salmon_version"": ""1.4.0"",; ""samp_type"": ""none"",; ""opt_type"": ""vb"",; ""quant_errors"": [],; ""num_libraries"": 1,; ""library_types"": [; ""MU""; ],. ```. ""MU"" but what puzzles me is that my datas are IlluminaTruSeq Stranded. ""MU"" is used for unstranded then it's a little weird.... I tested every libraries and MU gives me the better percentage with 60% of mapping, the other ISF, IU, ISR give less than 10-20% maximum. Is there a problem to use MU on stranded knowing that it is salmon who chose automatically ? Especially since this is what gives me the best results... Thanks for your . Kisekya",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/676:558,test,tested,558,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/676,1,['test'],['tested']
Testability,"Hello! Thank you for developing these amazing tools.; My laboratory is implementing scCUT&TAG-pro (like CITE-seq but for CUT&TAG rather than RNA-seq) using chromium v2 10X library prep. This means, that we have features (ADTs) with a library prep different than from CITE-seq. . I have seen in your documentation ([https://combine-lab.github.io/alevin-tutorial/2020/alevin-features/](https://combine-lab.github.io/alevin-tutorial/2020/alevin-features/)) that to map features using salmon alevin you need to use the flag `--citeseq` together with `--featureLength `and` --featureStart. ` Does this assume that the barcode is 16bp long and the UMI 12bp long? In my case, I have a cell barcode of 16 and a UMI of 10. . I have also seen that to specify the length I can specify the read geometry (`--bc-geometry 1[1-16] --umi-geometry 1[17-26] --read-geometry 2[1-15]`). However, if I try to use these flags, I would need to specify `--tgMap`, however, I cannot find anywhere in your documentation that specifies how to handle this flag when mapping features. Could you please help me with this?. Finally, I done a first run using the following command:; `salmon alevin -l ISR -iadt_index -1 1.fastq.gz -2 2.fastq.gz -p 20 --citeseq --featureStart 0 --featureLength 15`; And in the log file i got the following warning:; **[2023-09-22 17:09:36.774] [jointLog] [warning] Found 41405334 reads with `N` in the UMI sequence and ignored the reads.; Please report on github if this number is too large** This number means that I am losing 22% of my reads. I have checked and exactly this percentage of the UMI sequences in my reads start with an N, however I do not understand why. Do you have any idea why this could be? . Thank you!; Andrea",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/875:1278,log,log,1278,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/875,1,['log'],['log']
Testability,"Hello!. We are currently using Salmon as part of a very large data processing system. We need to continuously test the end-to-end functionality of our system, which includes a Salmon execution. Unfortunately, this increases our build time from 5 minutes to an hour and a half. It'd be really, really excellent if we could have a way to _simulate_ a Salmon run to verify the correct installation of Salmon and the Salmon-compatible collection of our input data without actually having to do the full Salmon run. Is there any chance you'd consider adding a `--dry-run` argument to run Salmon without actually running the big crunch? Ideally this could also output some dummy results files, but it doesn't have to if you don't like that. Thoughts?. Related: https://github.com/data-refinery/data-refinery/issues/106",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/189:110,test,test,110,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/189,1,['test'],['test']
Testability,"Hello, . while setting ressources for alevin test using: https://combine-lab.github.io/alevin-tutorial/2018/setting-up-resources/. generation of mapping file txp2gene.tsv using given instruction is broken:. ```; c6builder:salmon/1.3.0 > wget -q ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_31/gencode.v31.primary_assembly.annotation.gtf.gz; c6builder:salmon/1.3.0 > bioawk -c gff '$feature==""transcript"" {print $group}' <(gunzip -c gencode.v31.primary_assembly.annotation.gtf.gz) | awk -F ' ' '{print substr($4,2,length($4)-3) ""\t"" substr($2,2,length($2)-3)}' - > txp2gene.tsv; /mount/gensoft2/exe/bioawk/1.0/bin/bioawk: illegal field $(), name ""group""; input record number 7, file /proc/self/fd/14; source line number 1; ```. https://github.com/COMBINE-lab/salmon/issues/336#issuecomment-496251814 point to bioawk modification that allows to generate `txp2gene.tsv`. please update docs !. regards. Eric",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/584:45,test,test,45,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/584,1,['test'],['test']
Testability,"Hello, I am using salmon for an RNAseq experiment but I m getting very low mapping rate (0.03%!) and a strong strand bias (0.96). It never happened before and I can not understand the cause. I have already used FastQC to check the quality and it is good. It happens also with all the other samples (N=6) the service sent to us for the same RNAseq experiment. At the moment I m afraid the service did a mistake or could this problem be related to the library type? . This is the command I ran:; ```; salmon quant -i /somewhere/in/the/server/index/salmon -l A -1 /somewhere/in/the/server/fastq/sample1_1.fq.gz -2 /somewhere/in/the/server/fastq/sample1_2.fq.gz -p 10 --seqBias --gcBias --validateMapping -o /somewhere/in/the/server/salmon; ```. lib_format_counts.json:; ```; {; ""read_files"": [; ""/somewhere/in/the/server/fastq/sample1_1.fq.gz"",; ""/somewhere/in/the/server/fastq/sample1_2.fq.gz""; ],; ""expected_format"": ""IU"",; ""compatible_fragment_ratio"": 1.0,; ""num_compatible_fragments"": 6520,; ""num_assigned_fragments"": 6520,; ""num_frags_with_concordant_consistent_mappings"": 2126,; ""num_frags_with_inconsistent_or_orphan_mappings"": 4704,; ""strand_mapping_bias"": 0.964722483537159,; ""MSF"": 0,; ""OSF"": 0,; ""ISF"": 75,; ""MSR"": 0,; ""OSR"": 0,; ""ISR"": 2051,; ""SF"": 1436,; ""SR"": 3268,; ""MU"": 0,; ""OU"": 0,; ""IU"": 0,; ""U"": 0; }; ```. few lines from salmon_quant.log:; ```; Only 6520 fragments were mapped, but the number of burn-in fragments was set to 5000000.; The effective lengths have been computed using the observed mappings. Mapping rate = 0.0301431%; ```",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/679:1352,log,log,1352,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/679,1,['log'],['log']
Testability,"Hello, I'm trying to install Salmon on my CentOS 7 system, as suggested here:; https://salmon.readthedocs.io/en/latest/building.html#installation. I decided to get the cmake `-DFETCH_BOOST=TRUE` option, in spite of having installed Boost. ; I get this error (here is the full log):. `cmake -DFETCH_BOOST=TRUE`. > Salmon requires g++ 5.2 or greater. https://pastebin.com/UmVJw0Ae. This is particularly odd.; I have installed a recent GCC version and even rebuilt Boost after it... As you can see, if I type . > gcc --version; > g++ --version. By root and user, I always get... > gcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-36); Copyright (C) 2015 Free Software Foundation, Inc.; This is free software; see the source for copying conditions. There is NO warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. and . > g++ (GCC) 4.8.5 20150623 (Red Hat 4.8.5-36); Copyright (C) 2015 Free Software Foundation, Inc.; This is free software; see the source for copying conditions. There is NO; warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. On another tutorial, I found that I should open a bash instead while installing gcc/g++, with the instruction:. `scl enable devtoolset-7 bash`. When I run . > gcc --version; > g++ --version. By root and user, this time the proper version is recognised!. > gcc (GCC) 7.3.1 20180303 (Red Hat 7.3.1-5); Copyright (C) 2017 Free Software Foundation, Inc.; This is free software; see the source for copying conditions. There is NO; warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. and. > g++ (GCC) 7.3.1 20180303 (Red Hat 7.3.1-5); Copyright (C) 2017 Free Software Foundation, Inc.; This is free software; see the source for copying conditions. There is NO; warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. As you can see, this time the latest version is recognised. I'm quite sure the bash was open even when I rebuilt Boost... But even though I re-open the bash before cma",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/388:276,log,log,276,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/388,1,['log'],['log']
Testability,"Hello,. Hoping you can help troubleshoot a salmon quant failure. We're running V0.9.1. BAM files are transcriptome aligned using OSA aligner. The program is calling out a malformed key:pair? The salmon_quant.log is blank. > ./bin/salmon quant -t transcripts.fa -l A -a A549_S1_001.bam -o A549_S1_quant &; [1] 10291; us1salxngst01> Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; # salmon (alignment-based) v0.9.1; # [ program ] => salmon; # [ command ] => quant; # [ targets ] => { transcripts.fa }; # [ libType ] => { A }; # [ alignments ] => { A549_S1_001.bam }; # [ output ] => { A549_S1_quant }; Logs will be written to A549_S1_quant/logs; Malformed key:value pair at line 44017: ""@PG ID:OSA IsCdna:True ; ReferenceLibraryID:Human.B37.3_RefGene20121217 VN:7.2""; ============; Exception : [ERROR: Failed to open file A549_S1.bam, exiting!]; ============; ./bin/salmon alignment-quant was invoked improperly.; For usage information, try ./bin/salmon quant --help-alignments; Exiting.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/222:208,log,log,208,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/222,3,"['Log', 'log']","['Logs', 'log', 'logs']"
Testability,"Hello,. I am doing my best to get the pigx-rnaseq workflow to install locally. Sadly, pigx' test routines bail out with a complaint on a missing sa.bin file as part of the files that are created by `salmon index`. I had tried salmon 1.2 and salmon 1.3 - no sa.bin, also not in your source tree. I placed this as an issue [here](https://github.com/BIMSBbioinfo/pigx_rnaseq/issues/78) and besides grepping through your source tree did some reading also on https://salmon.readthedocs.io . Still, I have no indiation about a missing option or so or if that file was only created in an earlier version. Did I miss this somewhere? Otherwise please kindly consider to explain as part of your documentation what files are to be expected in the index folder. Many thanks and regards,; Steffen",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/553:92,test,test,92,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/553,1,['test'],['test']
Testability,"Hello,. I am having a problem with an inconsistent segmentation fault: 11. Please see below. **Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**; I've only worked in salmon mode. **Describe the bug**; Following the tutorial procedure exactly, I'm experiencing seemingly random segmentation fault: 11 warnings on some alignments but not others. **To Reproduce**; Steps and data to reproduce the behavior:. Specifically, please provide at least the following information:. Salmon was installed yesterday through the getting started tutorial using the conda install method. The sample data downloaded fine using the provided scripts, and the index creation seemed normal. When I went to run the program (with the options given in the tutorial), 10 of the 16 alignments failed with a segmentation fault: 11 warning. Attached is a screen shot of the warning on one of the failed alignments. the quant.sf files of the successful alignments seem normal, and the files do not exist in the faulted samples. . To test repeatability, I deleted all of the quant files, and ran the program again. Again, most samples failed, and the samples that did not we different from the first run. **Expected behavior**; I expected all of the tutorial samples to produce quant.sf files successfully. **Desktop (please complete the following information):**; - OSX 10.13.3. Thank you,; Matt",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/295:1036,test,test,1036,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/295,1,['test'],['test']
Testability,"Hello,. I am using the recent downloaded executable for v1.1.0 and am using salmon (bulk-mode). Noticed one potential bug and have some general questions regarding bootstraps. 1. The potential bug I noticed was when I use `--numGibbsSamples` the logs/salmon_quant.log file is always blank. When I remove this flag and re-run the program the log file is correctly printed out. 2. Regarding Bootstraps:. I've been working with parameters to min/max my predicted estimates to quantified cDNA results that we have. Through this process I was not performing bootstraps and was just using the TPM results that were located within the `quants.sf` file and have been getting some good results, with R-squared values of ~0.98 for actual v. predicted plots. As a note, even after running hundreds of runs with the same parameters, the TPM values in the `quants.sf` file never really fluctuated that much between runs and were generally nearly identical. . However, I thought it would be best to bootstrap `--numBootstraps` each Salmon run and average the bootstraps to get more accurate results. After doing 1,000 bootstraps per sample I noticed that the TPM values I calculated from numbers of mapped reads in the `bootstraps.gz` fluctuated a lot more and overall brought my R-squared values down to ~0.87. (I used your ConvertBootstrapsToTSV.py script to get the read counts from the bootstrap file and then calculated the TPMs using the effective lengths from the `quants.sf` file. As looking through previous issues (#246) I was under the assumption that the bootstrap file only contained new mapped read estimates and the effective lengths should be the same for all bootstrap runs.) . My question is why do the TPM values in the `quants.sf` file not fluctuate as much (even after 100+ runs using the same parameters), while calculated TPM values from bootstraps of the same run are showing greater variance?",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/466:246,log,logs,246,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/466,3,['log'],"['log', 'logs']"
Testability,"Hello,. I have a 10x scRNA-seq dataset I would like to run Alevin on, with bootstrapping. I am working on a cluster and submitting my script (I'll paste it below) with a Slurm scheduler. My issue is that the job runs for a couple of seconds, then gives me this massive “core” output - that is encrypted someway and I can’t read - and then an empty log and an empty alevin.log, so I don’t even have anything to use for troubleshooting. ```; (salmon) [amonaco_m@med0113 1_bootstrappedAlevin]$ ls -al; total 47106; drwxrwxr-x 3 amonaco_m hpc-ag-zinzen 4096 Mar 3 11:00 .; drwxrwxr-x 4 amonaco_m hpc-ag-zinzen 4096 Mar 2 11:47 ..; drwxrwxr-x 2 amonaco_m hpc-ag-zinzen 4096 Mar 3 11:00 alevin; -rw------- 1 amonaco_m hpc-ag-zinzen 36540416 Mar 3 11:00 core.39485; -rw-rw-r-- 1 amonaco_m hpc-ag-zinzen 0 Mar 3 11:00 logs; (salmon) [amonaco_m@med0113 1_bootstrappedAlevin]$ ls -al alevin; total 1; drwxrwxr-x 2 amonaco_m hpc-ag-zinzen 4096 Mar 3 11:00 .; drwxrwxr-x 3 amonaco_m hpc-ag-zinzen 4096 Mar 3 11:00 ..; -rw-rw-r-- 1 amonaco_m hpc-ag-zinzen 0 Mar 3 11:00 alevin.log; ```. I have used Salmon Alevin before on this dataset - without the bootstrap option - while providing the Cell Ranger whitelisted barcodes, and everything has gone smoothly (same script as below, commented out line). I have tried increasing the allotted memory and thread number as well, but with no change in outcome. Have you ever encountered something like this or could address me to where the issue may be (I'm assuming something to do with the bootstrap)?. *****Script I submit:*****; ```; #!/bin/bash; # expected run time ; #SBATCH --time=24:00:00 ; # Combine stderr and stdout log files into the stdout log file.; #SBATCH -o without -e; # Keep current environment variables.; #SBATCH --export=variables; # number of cores; #SBATCH -n 30; # expected memory to be used; #SBATCH —mem=50000; # Specify queue via expected length of job. ; #SBATCH --partition=medium; # Set the log directory.; #SBATCH -o logs. ####declarations; ",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/636:348,log,log,348,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/636,3,['log'],"['log', 'logs']"
Testability,"Hello,. I tried creating a salmon index for bos taurus but was not successful. I created the decoy file using:. grep ""^>"" <(gunzip -c Bos_taurus.ARS-UCD1.2.dna.toplevel.fa.gz) | cut -d "" "" -f 1 > decoys.txt; sed -i.bak -e 's/>//g' decoys.txt. When i try to index using ; salmon index -t bos_taurus_gentrome.fa.gz -d decoys.txt -p 12 -i salmon_index --gencode ; OR; salmon index -t Bos_taurus.ARS-UCD1.2.cdna.all.fa.gz -i bos_taurus_107_index --decoys decoys.txt -k 31. I get an error. The last two lines of the log file are. [puff::index::jointLog] [critical] The decoy file contained the names of 2211 decoy sequences, but 0 were matched by sequences in the reference file provided. To prevent unintentional errors downstream, please ensure that the decoy file exactly matches with the fasta file that is being indexed.; [puff::index::jointLog] [error] The fixFasta phase failed with exit code 1. What is happening and how can i solve this issue?",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/788:511,log,log,511,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/788,1,['log'],['log']
Testability,"Hello,. My lab is in the process of testing out Salmon and potentially switching to it from traditional aligners. With a traditional aligner, we use picard's MarkDuplicates to remove PCR duplicates. Is there a way to remove PCR duplicates with Salmon? I tried using --writeMappings to generate a BAM and feed that into picard, but I just get a SAM validation error: ""Not primary alignment flag should not be set for unmapped read."". Best,; Brian",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/136:36,test,testing,36,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/136,1,['test'],['testing']
Testability,"Hello,. This is the first time I am using Salmon and tried following up all steps but got 0 fragments mapped.. . 1) copied unzip Salmon-0.8.2_linux_x86_64 into folder in server; 2) exported path: export PATH=$PATH:/.../.../Salmon-0.8.2_linux_x86_64/bin/; 3) built index: salmon index -t salmon.index.human.052617.tar -i human_index; 4) now I want to preform quantification on fastq files (only one end of paired end, trimmed for 40 bp): ; salmon quant -i human_index -l U -r Sample1_r1_trimmed.fastq -p 5 -o quants/Sample1_quant. Logs will be written to quants/Sample1_quant/logs; [2017-10-25 10:57:25.879] [jointLog] [info] parsing read library format; [2017-10-25 10:57:25.879] [jointLog] [info] There is 1 library.; [2017-10-25 10:57:26.002] [jointLog] [info] Loading Quasi index; [2017-10-25 10:57:26.002] [jointLog] [info] Loading 32-bit quasi index; [2017-10-25 10:57:26.012] [jointLog] [info] done; [2017-10-25 10:57:26.012] [jointLog] [info] Index contained 28 targets; [2017-10-25 10:57:26.003] [stderrLog] [info] Loading Suffix Array; [2017-10-25 10:57:26.004] [stderrLog] [info] Loading Transcript Info; [2017-10-25 10:57:26.004] [stderrLog] [info] Loading Rank-Select Bit Array; [2017-10-25 10:57:26.005] [stderrLog] [info] There were 28 set bits in the bit array; [2017-10-25 10:57:26.005] [stderrLog] [info] Computing transcript lengths; [2017-10-25 10:57:26.005] [stderrLog] [info] Waiting to finish loading hash; [2017-10-25 10:57:26.012] [stderrLog] [info] Done loading index. processed 81500000 fragments; hits: 0; hits per frag: 0. [2017-10-25 10:58:22.290] [jointLog] [info] Computed 0 rich equivalence classes for further processing; [2017-10-25 10:58:22.290] [jointLog] [info] Counted 0 total reads in the equivalence classes; [2017-10-25 10:58:22.293] [jointLog] [warning] Only 0 fragments were mapped, but the number of burn-in fragments was set to 5000000.; The effective lengths have been computed using the observed mappings. [2017-10-25 10:58:22.293] [jointLog] [info] Mapp",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/167:530,Log,Logs,530,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/167,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"Hello,; I'm trying to compile salmon into arm64 linux system, but I'm getting the error bellow:; ```; ...; Found Jemalloc library --- using this memory allocator; CPACK_SOURCE_IGNORE_FILES = /src/PCA.cpp;/src/PCAUtils.cpp;/build/;/scripts/AggregateToGeneLevel.py;/scripts/ExpressionTools.py;/scripts/GenerateExpressionFiles.sh;/scripts/ParseSoftFile.py;/scripts/PlotCorrelation.py;/scripts/junk;/scripts/sfstrace.log;/scripts/SFPipeline.py;/bin/;/lib/;/sample_data/;PublishREADMEToWebsite.sh;/external/;/src/obsolete/;/include/obsolete/;WebsiteHeader.txt;/experimental_configs/;.git/; TBB_LIBRARIES = /usr/lib/aarch64-linux-gnu/libtbbmalloc_proxy.so;/usr/lib/aarch64-linux-gnu/libtbbmalloc.so;/usr/lib/aarch64-linux-gnu/libtbb.so;/usr/lib/aarch64-linux-gnu/libtbb.so; -- Configuring done; -- Generating done; -- Build files have been written to: /root/salmon-0.14.2/build; [ 34%] Completed 'libtbb'; [ 39%] Built target libtbb; Makefile:162: recipe for target 'all' failed; make: *** [all] Error 2. ```. How to fix this?",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/433:413,log,log,413,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/433,1,['log'],['log']
Testability,"Hello,; salmon 0.11.1, on CentOS 7.; Tested with install from precompiled binaires, and from bioconda/conda 4.5.9. (1) salmon -h is fine, but salmon [command] -h takes lots of time, and ends up with; Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon. It could be related to any bad local proxy settings. Is there any way to skip the upgrade information lookup as a command-line option ?. (2) segmentation error with alevin; ### salmon (single-cell-based) v0.11.1; ### [ program ] => salmon ; ### [ command ] => alevin ; ### [ threads ] => { 10 }; ### [ libType ] => { ISR }; ### [ mates1 ] => { /path/to/sample_S1_L001_R1_001.fastq.gz }; ### [ mates2 ] => { /path/to/sample_S1_L001_R2_001.fastq.gz }; ### [ index ] => { /path/to/salmonIndex }; ### [ output ] => { alevin_output }; ### [ tgMap ] => { tx2gene.tsv }. [2018-08-03 14:31:41.793] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2018-08-03 14:31:41.810] [alevinLog] [info] Processing barcodes files (if Present) ; processed 109 Million barcodes; segmentation error (core dumped). No any other logs available, programs stopped. Best,; juugii.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/264:37,Test,Tested,37,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/264,2,"['Test', 'log']","['Tested', 'logs']"
Testability,"Hello. I am analyzing Drop-Seq data with salmon alevin. I applied the tips given in this discussion (#506). ; However, to me the mapping rates (found in ""salmon_quant.log"") are rather low. On average, the mapping rate is only 23 % with a standard deviation of 9 % when running salmon alevin with default parameters. ; When setting ```--expectCells``` or ```--forceCells```, these numbers change to 23 % (sd: 5%) and 26 % (sd: 6%). Are these mapping rates what you expect for Drop-Seq data? It is my first time analyzing Drop-Seq data, so I have no reference. ; Is this low mapping rate problematic? . Thanks in advance",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/738:167,log,log,167,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/738,1,['log'],['log']
Testability,Here is the duplicate clusters (extension edited for uploading as .txt) and log. ; [quasi_index.log](https://github.com/COMBINE-lab/salmon/files/2474978/quasi_index.log). [duplicate_clusters (copy).txt](https://github.com/COMBINE-lab/salmon/files/2474977/duplicate_clusters.copy.txt),MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/301#issuecomment-429502243:76,log,log,76,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/301#issuecomment-429502243,3,['log'],['log']
Testability,"Here is the part of the log I've left out previously; <img width=""978"" alt=""Screen Shot 2019-11-03 at 8 41 57 PM"" src=""https://user-images.githubusercontent.com/17168657/68090974-860d6200-fe7a-11e9-972f-d529453bbea8.png"">. I've downloaded Linux executables on 11/02/ from the following link: https://github.com/COMBINE-lab/salmon/releases/download/v1.0.0/salmon-1.0.0_linux_x86_64.tar.gz. Decoys and gentrome files seem to be ok since they are working properly with bioconda version of salmon. I am sharing a Dockerfile in case you would like to reproduce the entire environment I was using. [Dockerfile](https://github.com/COMBINE-lab/salmon/files/3802055/Dockerfile)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/441#issuecomment-549171596:24,log,log,24,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/441#issuecomment-549171596,1,['log'],['log']
Testability,Here's a gist of the logs:; https://gist.github.com/sjackman/8b0c2be77efeb9507ca3#file-02-make-L4938,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/46:21,log,logs,21,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/46,1,['log'],['logs']
Testability,"Hey @Gaura - I have a test dataset for us to use. I'm about to set up an alevin run of my own, but wanted to pass it on to you in the meantime. I haven't yet done any testing or exploration of my own yet, though the data comes from a collaborator of ours. The raw (FASTQ) and processed data (UMI counts matrix) is accessible from GEO at [GSE137941](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE137941) and SRA (`fastq-dump --split-files SRR10174292`). These data were generated with the original SPLiT-seq method (your ""v1""). The caveat is that they did NOT combine the oligo-dT and random hexamer barcodes, meaning they are separate cells/columns in their processed data matrix. This means we should be able to run `alevin`/`alevin-fry` directly on these FASTQs, bypassing `splitp` for now, and get something that hopefully matches their processed data matrix. . According to the methods section [of their paper](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7366517/), they used GENCODE v28 annotations, and ultimately kept 6,888 nuclei after filtering. Their processed data matrix seems to have 25,000 columns, so I suppose this is pre-filtering. . Let me know what you think!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-984646381:22,test,test,22,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-984646381,2,['test'],"['test', 'testing']"
Testability,"Hey @alexvpickering ,; I agree, it does makes sense to index the transcript and gene relationship while creating the salmon indexing but I don't see how it solves this problem i.e. if the idea is to ignore the transcripts which doesn't having transcript to gene mapping then it may bias the analysis as we are considering lesser number of transcripts than known; having said that an argument about unknown splice junction can still be made. regarding the link for `gencode_29`, may I ask what version of salmon you are using ? Because I just tried to run alevin with the links you forwarded and it works fine for me. If possible forwarding the log will help too.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/336#issuecomment-496246321:644,log,log,644,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/336#issuecomment-496246321,1,['log'],['log']
Testability,"Hey @jeremymsimon! I checked the protocol and the [pipeline code](https://github.com/yjzhang/split-seq-pipeline/blob/master/split_seq/tools.py). The protocol you described is v1 and the Parsebio is v2. I have implemented v2 in salmon and would be testing it this week. v1 can be similarly implemented. I read the paper and other available resources but I am not clear about the random hexamer usage and it's effects on the barcode. Can you please explain what you meant by BC1s being paired and what's the use of random hexamer, please? Thanks.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-936331597:247,test,testing,247,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-936331597,2,['test'],['testing']
Testability,"Hey @k3yavi . The data is from a public dataset hosted on the 10x genomics website:. [200 Sorted Cells from Human Glioblastoma Multiforme, 3’ LT v3.1](https://support.10xgenomics.com/single-cell-gene-expression/datasets/6.0.0/Brain_Tumor_3p_LT). I downloaded the data and subsampled the FASTQ files to 1,000 reads. It was an arbitary choice, I just needed a small dataset to test a pipeline I was building.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/647#issuecomment-821522673:375,test,test,375,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/647#issuecomment-821522673,1,['test'],['test']
Testability,"Hey @k3yavi, bootstrapping really improved my population studies so I figured I would try it with sc, but I haven't even seen the run get there when I use the multiple files... after `processed X Million barcodes` there are no more logs produced on-screen..",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/329#issuecomment-446185405:232,log,logs,232,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/329#issuecomment-446185405,1,['log'],['logs']
Testability,"Hey @k3yavi,; salmon version is 0.13.1. I don't have the logs at the moment as I am trying the ensembl-based solution suggested by @sarahhcarl using Homo_sapiens.GRCh38.94.chr_patch_hapl_scaff.gtf.gz and equivalent ensembl version for cdna index. After doing so I will reproduce the issue and add the log file here. What about instead of filtering the index based on txp2gene, having some way of padding missing transcripts in txp2gene (e.g. just mapping from the indexes ENST to the same ENST)? I don't understand the algorithm enough to know the best solution - this just seems like an internal detail that the end user should not have to resolve/abandon alevin as a result of. A seperate issue for the [tutorial](https://combine-lab.github.io/alevin-tutorial/2018/setting-up-resources/) that doesn't apply to the accompanying [gist](https://gist.github.com/k3yavi/c501705ed2d29b12b0d10cf78b3ed001): the index is generated using gencode.**v28**.pc_transcripts.fa.gz and the txp2gene.tsv is generated using gencode.**v26**.primary_assembly.annotation.gtf. Perhaps I generated the txp2gene.tsv incorrectly? The bioawk instructions from the tutorial had to be altered (I'm guessing because of version differences). ```bash; bioawk --version; awk version 20110810. # command from tutorial; bioawk -c gff '$feature==""transcript"" {print $group}' <(gunzip -c gencode.v29.annotation.gtf.gz) | awk -F ' ' '{print substr($4,2,length($4)-3) ""\t"" substr($2,2,length($2)-3)}' - > txp2gene.tsv. bioawk: illegal field $(), name ""group""; input record number 7, file /dev/fd/63; source line number 1. # how I modified it; bioawk -c gff '$feature==""transcript"" {print $attribute}' <(gunzip -c gencode.v29.annotation.gtf.gz) | awk -F ' ' '{print substr($4,2,length($4)-3) ""\t"" substr($2,2,length($2)-3)}' - > txp2gene.tsv. cat txp2gene.tsv | head -n 5; ENST00000456328.2 ENSG00000223972.5; ENST00000450305.2 ENSG00000223972.5; ENST00000488147.1 ENSG00000227232.5; ENST00000619216.1 ENSG00000278267.1; ENST00000473358.1",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/336#issuecomment-496251814:57,log,logs,57,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/336#issuecomment-496251814,2,['log'],"['log', 'logs']"
Testability,"Hey @rob-p ,; I know virtually nothing about this, but I've been having somewhat related discussions lately with @mourisl about their method TRUST4 (https://github.com/liulab-dfci/TRUST4). Li seemingly has interest in helping out with this, and coincidentally is the developer of chromap too in case support for ATACseq is also coming soon!. I'll let you both take it from here and looking forward to testing!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/861#issuecomment-1642867731:401,test,testing,401,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/861#issuecomment-1642867731,1,['test'],['testing']
Testability,"Hey @rob-p, you are quite welcome; thanks for the warm response. Being system installed packages most headers and dynamic libraries will be installed using the standard prefixes: /usr/include, /usr/lib/${multiarch-tuple}/, . I've updated the checklist [above](https://github.com/COMBINE-lab/salmon/issues/19#issue-109233280) with links to the file lists so you can see the paths yourself. Interestingly I was able to build, run, and pass all the included tests using the version of BWA in the Debian archive. As for Jellyfish I had to update our package to include 'json.h' which had gotten dropped.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-144914246:455,test,tests,455,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-144914246,1,['test'],['tests']
Testability,"Hey Rob,. I did manage to test v1.3 this evening. Ran much faster. The same sample that took about 6 hours ran in 45mins. Still not great, but I think it might be intrinsic to some of these samples, also I was running it off my laptop and was running Linux off a; flash drive so not an ideal setup. Either way much more reasonable. Do you want me to attach any logs or anything?. Best,. Ryan . Sent from my iPhone. On Jun 16, 2020, at 10:20 AM, Rob Patro <notifications@github.com> wrote:. ﻿. Hi ; @shalercr,; I agree that if each sample runs as quickly as you see here, it's not a big deal to just re-run them all. Note that, while my avoids ~116 times more (eventually-discarded) alignments than did yours, the difference in the number of discarded; fragments (i.e. fragments that had no mapping) is very small — ~7,000, or 0.023% of the fragments. Thus, despite the huge speed-up, I wouldn't expect many differences in the quantifications. However, I couldn't argue against re-quantifying everything; with the new version just for good measure :). When you have a chance, please do let me know if you see this same performance difference using the pre-compiled (linux) binary. here. Of course, once we finalize this release (soon), we will push to bioconda so we will also have OSX binaries available. However, I just want to make sure this fixes things on your end as well before the release.; —; You are receiving this because you were mentioned.; Reply to this email directly, ; view it on GitHub, or ; unsubscribe.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-645119801:26,test,test,26,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-645119801,2,"['log', 'test']","['logs', 'test']"
Testability,"Hey Rob, . Sorry for the delay, here is a link to the quants folder if you guys are still interested. Everything worked well, especially with the additional flag. Any idea on the timeline for the bioconda release?. Best, . Ryan . https://www.dropbox.com/sh/rmy4f6brxx5iczo/AACxbyZFxN0XGcP3YRGjGO-pa?dl=0 . On Jun 18, 2020, at 12:21 AM, Ryan, Shaler <shalercr@mcmaster.ca> wrote:. Thanks for the heads up. I gave it a test this evening and wow, it is wicked fast. I’ll send you those quant files tomorrow when I get a chance, but adding that flag and the new version fixed the problem. . Thank you for all your help. . Best,. Ryan . Sent from my iPhone. On Jun 16, 2020, at 11:36 PM, Rob Patro <notifications@github.com> wrote:. ﻿. P.S. ; @shalercr,; I also note that layering --hitFilterPolicy BOTH on top of the new version cuts down the time by another factor of 2 for me; 2163.65user 12.72system 4:21.57elapsed 832%CPU (0avgtext+0avgdata 1221856maxresident)k. and the number of mappings discarded alignments due to score comes down by another factor of ~6X. It might be worth seeing what you get with that option as well.; —; You are receiving this because you were mentioned.; Reply to this email directly, ; view it on GitHub, or ; unsubscribe.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-647273636:417,test,test,417,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-647273636,1,['test'],['test']
Testability,"Hey Rob. It looks like this was an error in the way I was calling `salmon index`. I've wrapped salmon in a python based pipeline where I manage creation of index files using configuration files. To call `salmon index` I was previously iterating on standard error, capturing your err and logging it after reformatting a bit. It looks like what was happening is:. 1. I opened a subprocess and executed salmon; 2. Salmon worked properly; 3. Salmon stopped producing output on stderr (and sent an EOF marker?) and so my script exited; - killing salmon prematurely; - truncating the salmon index (In a way that salmon found perfectly acceptable during `salmon quant`; - frustrating me quite a bit. I fixed this by doing the right thing and blocking for the process to return an exit code:. ```diff; p = Popen(cmd, stderr=PIPE); - for line in p.stderr:; - line = line.decode(); - if line.endswith('\n'):; - logging.info(line.rstrip()); - else:; - logging.info(line); + _, err = p.communicate(); + logging.info(err); ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/132#issuecomment-303738589:287,log,logging,287,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/132#issuecomment-303738589,4,['log'],['logging']
Testability,"Hey all,. I'm currently attempting to install Salmon from source on a machine running Ubuntu 16.04. I'm following along with the installation instructions (http://salmon.readthedocs.io/en/latest/building.html#installation); however, I am running into errors when running cmake:. michael@thinkpad:/opt/salmon/salmon-0.8.2/build$ cmake -DFETCH_BOOST=TRUE; CMake Error: The source directory ""/opt/salmon/salmon-0.8.2/build"" does not appear to contain CMakeLists.txt.; Specify --help for usage, or press the help button on the CMake GUI. I tried to fix the issue by moving CMakeLists.rxt from the parent directory into the build directory, but I was met with even more errors, I've attached the created CMakeError.log and CMakeOutput.log file. [CMakeOutput.txt](https://github.com/COMBINE-lab/salmon/files/1109023/CMakeOutput.txt); [CMakeError.txt](https://github.com/COMBINE-lab/salmon/files/1109022/CMakeError.txt). I'm thinking that this may be a simple issue that I've overlooked as I'm new to Linux, and installation using CMake is new to me.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/139:710,log,log,710,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/139,2,['log'],['log']
Testability,"Hey, . First, thanks a lot for implementing Alevin for the analysis of scRNA-seq, it is super useful. I would like to open the file ```alevin/quants_tier_mat.gz``` but I am not being able to do it. . When I try to follow the parser instructions [here](https://github.com/k3yavi/vpolo/blob/242b519ea47eae1cce14bb3bafb736a1f3ad7d40/vpolo/alevin/parser.py) I am facing this error when importing sce:; ```; ImportError: cannot import name 'sce' from partially initialized module 'sce' (most likely due to a circular import) (/home/egonie/.local/lib/python3.8/site-packages/sce/__init__.py); ```. I have already imported```vpolo``` which I have installed with: ; ```; pip3 install vpolo; ```. Also I have tested the R library ```fishpond```with the function; ```; fishpond::readEDS(numOfGenes = num.genes, numOfOriginalCells = num.cells, countMatFilename = tier.file, tierImport = T); ```; Which outputs this message:; ```; Error in validObject(x) : ; invalid class ""dgCMatrix"" object: all row indices must be between 0 and nrow-1; ```. Any insight that helps in reading Alevin tiers file would be much appreciated. Thanks in advance and sorry for the inconveniences. Best,. Kike",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/596:700,test,tested,700,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/596,1,['test'],['tested']
Testability,"Hey, I ran into couple of more typos in the --help documentation.; In Salmon Quant Reads mode, the option --writeUnmappedNames says the the file created is named unmapped.txt, while it is actually named unmapped_names.txt; In Salmon Quant Alignment mode, the option --sampleUnaligned says the un-aligned reads are also written to the file ""posSample.bam"", I suppose a 't' is missing there?; Also, when I ran Salmon Quant with Alignment mode, the output auxiliary directory was still named just 'aux' instead of 'aux_info' per the newest change log. ; Sorry if I'm bothering with these pesky details, I though it might help when clearing the documentation a bit.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/81:544,log,log,544,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/81,1,['log'],['log']
Testability,"Hi :). I was already successfully using Salmon before, but unfortunately a storage node of the computing cluster I am using crashed and now I am running into trouble re-installing it. . I downloaded ""salmon-master.zip"", unzipped it and changed into the salmon-master folder. Further, I ran the following command:. > cmake -DCMAKE_INSTALL_PREFIX=/scratch/hpc-prf-ptma2/ptma2001/salmon-master -DFETCH_BOOST=TRUE. The configuration starts, but finally runs into the following error:. > -- Configuring done; > CMake Error: The following variables are used in this project, but they are set to NOTFOUND.; > Please set them or make sure they are set and tested correctly in the CMake files:; > CURL_LIBRARY; > linked by target ""salmon"" in directory /scratch/hpc-prf-ptma2/ptma2001/salmon-master/src; > linked by target ""unitTests"" in directory /scratch/hpc-prf-ptma2/ptma2001/salmon-master/src; > ; > -- Generating done; > CMake Generate step failed. Build files cannot be regenerated correctly. Would you have an idea how I could circumnavigate that issue?. Thanks a lot in advance for your time and help!",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/729:648,test,tested,648,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/729,1,['test'],['tested']
Testability,"Hi :). `wget` war already installed (to download the sources in the first place, so this one works). ; After `wget`ing the source files again re-`cmake`-ing them again `make install` did work, not sure what happened there in the first place. Also the tests are passing now. I will try to figure out what is different between the clean docker version and my system setup and will report back as soon as I know more.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404536671:251,test,tests,251,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404536671,1,['test'],['tests']
Testability,"Hi @ACastanza,. Thanks for reporting both of these. For the first, I think it is just the case that the message needs to be updated. In fact, the `--validateMappings` flag is now deprecated since selective-alignment is used by default (and can't be turned off, except in the single-cell mapping context, with the `--sketchMode` flag, which is currently only in the develop branch). We'll update that message.; Regarding the misplaced newline, the issue is that the other messages are written by the logger, which is asynchronous. So, sometimes it will get to the appropriate place and write a newline before the fragment counter starts, and sometimes it won't. I'll look into if there is a way to better clear the line, even if the update is asynchronous. Thanks!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/587#issuecomment-729044670:499,log,logger,499,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/587#issuecomment-729044670,2,['log'],['logger']
Testability,"Hi @Beatzekatze,. The issue with test 1 seems to be from CMake being unable to find the unit test to execute under certain configurations. I'll consider this a bug in the CMake file, and look into fixing it. The failure of tests 2 and 3 is more interesting, as one would definitely not expect this given that the program compiled without error. Does indexing fail only with `--type fmd`, or also with `--type quasi` (or no `--type` as that is the default)? Would it be possible to run the command under gdb and report the stack trace? That would be something like:. ```; $ gdb --args salmon index -t transcripts.fasta -i sample_salmon_fmd_index --type fmd; ```. and then, when you encounter the segfault issuing the back-trace `bt` command. This would give insight into where, exactly this is showing up. One issue I've seen before is when the resident installation of Boost is _not_ compiled with `--std=c++11` (or 14 or 17), since this leads to an incompatible ABI between salmon and the Boost library. If that's what's going on, it should be evident from the backtrace. Finally, while I'd want to figure out what's going on with this build from source, it would also be useful to know if you encounter the same behavior when installing via bioconda. Thanks for the detailed report!. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404223014:33,test,test,33,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404223014,3,['test'],"['test', 'tests']"
Testability,"Hi @ChelseaCHENX ,. Thanks for raising the issue.; I think if you can share the alevin log (say for 1192 cells ?) we can comment much more about the details. However, if you ask me to guess then I believe the initial whitelisting of alevin seems to be predicting a lot less cells, if you check the alevin log, it would say what % of CB are thrown due to noisy cellular barcodes. If the number is `>20%`, then the chances are indeed ""knee"" estimates are shooting up. The way to get better estimates from there would be to help alevin with a ballpark number of cells (as you are giving to cellranger with --expect-cell 8000, you can provide alevin with --expectCells 8000). Even after that if you get a lot of noisy CB prediction then you can force alevin to use certain number of cells with `--forceCells` option. https://github.com/COMBINE-lab/salmon/issues/362 this issue might help you understand more the details of the pipeline.; Hope it helps !",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/396#issuecomment-510540540:87,log,log,87,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/396#issuecomment-510540540,2,['log'],['log']
Testability,"Hi @Davidwei7,. Thank you for the very detailed bug report! So, I have two initial responses / thoughts about your issue. First, you asked if the issue may be related to a memory allocation error wherein the index didn't build successfully. This is quite possible (and the error you see during quantification is consistent with that). The *full* decoy index is substantially larger than the index on just the transcriptome (after all, it is indexing the entire human genome in addition to the transcriptome). One thing you might try to test this hypothesis, other than requesting to build on a node with more RAM, is to compute a hash (e.g. md5 or sha256 sum) on all of the files in the index, and also record their sizes. Then we can build the index on the same version of the files on our end and compare. Second — and perhaps more importantly for your end goal — the main purpose of the decoy-aware index is to improve specificity rather than sensitivity. That is, the decoys are designed to help avoid _spurious_ mapping of reads to an annotated transcript when a better explanation for the read exists elsewhere in the genome. However, the reads that are mapped to decoys are not otherwise used for quantification. Thus, using the decoy aware transcriptome index is unlikely to improve your mapping rate. I agree that your mapping rate does seem rather low. There are a few potential culprits here, and some diagnostics we can look at to see what might be going wrong. First, you can take a look at the file `aux_info/meta_info.json` in the salmon quantification directories to get a few more details about why reads were not mapped. If you share one of those files here I can describe the relevant fields. Also, I have two more rather common things to consider that might affect the mapping rate. One is to add the sequence for the ribosomal RNAs to your transcriptome before indexing and then quantifying. If your mapping rate increases considerably, this is evidence of rather inefficient depl",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/603#issuecomment-744162850:536,test,test,536,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/603#issuecomment-744162850,1,['test'],['test']
Testability,"Hi @DobbyLikesPenguins,. ### conda idea. So, if you want to try with conda again, I would first recommend that you create a new environment for salmon. ```; conda create --name salmon; ```. which you can then activate with . ```; conda activate salmon; ```. From this environment, you should be able to install the latest version. ```; conda install salmon; ```. or specifying version explicitly like . ```; conda install salmon=1.4.0; ```. ### using the pre-compiled executable. The simplest thing would be to simply add it to your PATH. Assuming you are using bash or a similar shell, you can do something like:. ```; export PATH=<path_to_salmon_directory>/bin:$PATH; ```. to add salmon to your path. It should choose this version when you use `salmon`. However, this will be reset when you logout. To make the change permanent, then you add this command to your bash profile (usually `~/.bash_profile`). It's a little bit different (but very similar) if you are using a different shell. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/483#issuecomment-775273715:793,log,logout,793,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/483#issuecomment-775273715,2,['log'],['logout']
Testability,"Hi @Gaura :; ```shell; ./; ├── alevin_out; │   ├── alevin; │   │   └── alevin.log; │   ├── aux_info; │   │   └── meta_info.json; │   ├── cmd_info.json; │   ├── libParams; │   ├── logs; │   │   └── salmon_quant.log; │   ├── map.rad; │   └── unmapped_bc_count.bin; ├── count; │   ├── alevin; │   │   ├── quants_mat_cols.txt; │   │   ├── quants_mat.mtx; │   │   └── quants_mat_rows.txt; │   ├── featureDump.txt; │   └── quant.json; └── permit_knee_out; ├── all_freq.bin; ├── collate.json; ├── generate_permit_list.json; ├── map.collated.rad; ├── permit_freq.bin; ├── permit_map.bin; └── unmapped_bc_count_collated.bin; ```; I follow the output of the tutorial, it seems that there is no file `alevin_out/alevin/raw_cb_frequency.txt`, it may be that the parameter --dumpFeatures is not added during runtime, I add the --dumpFeatures parameter to try",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/774#issuecomment-1126137203:78,log,log,78,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/774#issuecomment-1126137203,3,['log'],"['log', 'logs']"
Testability,"Hi @Hoohm ,; Thanks for the feature request.; Currently `Alevin` do have a hidden feature, where you can explicitly specify the CB and UMI length. Although we have not yet extensively tested these options but in your settings you might have to specify the following command line argument:; ```; --barcodeLength 7 --umiLength 9 --end 5; ```; Please let us know how it works out for you in these settings, it will help validate these options for `Alevin`. PS: Just a quick question for my understanding, is there a specific reason you chose to use the length of the UMI longer than CB in your experiment ?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/247#issuecomment-402349013:184,test,tested,184,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/247#issuecomment-402349013,1,['test'],['tested']
Testability,"Hi @Kisekya,. So BWA-MEM and BWA-MEM2 are somewhat of a problem to begin with because they perform local alignment, which isn't really ideal for aligning RNA-seq reads to the transcriptome. If you really wish to use an aligner, we've had good experiences with Bowtie2 (when used in the appropriate end-to-end alignment mode) and with STAR (using the alignments projected to the transcriptome with `--quantMode TranscriptomeSAM` flag to output the alignments in transcriptomic coordinates as required by salmon). Apart from the local alignment issue, sorting the BAM file is _absolutely_ a problem for salmon, and is likely why you get the strange library type. When run in alignment mode, just like RSEM, salmon requires the alignments for the the mates of a read pair to appear subsequently in the file, and for all alignments for a given read to appear contiguously in the file. This allows parsing the reads without having to require potentially unbounded memory (holding the record for one end of a fragment in memory while waiting for the record for the other end). In fact, given that you've sorted the alignments here, I'm surprised you're not getting the ""suspicious pair"" warnings in your logs. The ISR library with 40% mapping is likely a more reliable number. The obvious question here is why might the mapping rate be this low? There are a few reasons you might see something like this. One, for example, is poor ribosomal depletion, paired with not having all of the rRNA sequences in your index. In this case, you have many fewer reads coming from the rest of the transcriptome and you get depleted mapping rates like this. . Could you say a bit more about the experimental setup? Is this in a well-annotated organism like human / mouse etc.? Is this a polyA selection or ribosomal depletion prep? Anything else that might be relevant to sample quality?. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/676#issuecomment-873519594:1198,log,logs,1198,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/676#issuecomment-873519594,1,['log'],['logs']
Testability,"Hi @Munfred , ; Thanks again for testing Alevin with your dataset. Extrapolating from the log, It indeed looks like a challenging dataset. In default settings Alevin pipeline starts with finding a knee in the curve (which itself is a non-trivial problem) and then use KDE w/ gaussian correction to adjust for the right probability. In your case it looks like knee is overshooting (if true number of CB is 300 ) but more troubling part for me is gaussian correction is coming out 0. Now based on your motivation for using Alevin, I can propose two solutions:. 1. If the motivation is to get gene-level count without worrying about the whitelisted CB prediction then the easiest way is to use external whitelist. Alevin can use external whitelist using flag `--whitelist` and would generate gene level counts for specified list of CB.; 2. If you need full end-to-end run of Alevin, then I propose using command line flag `--dumpFeatures` along with Alevin default. This flag tells Alevin to dump various features, the important one here would be a file named `frequency.txt`, what this file basically tells you is the frequency of all the observed CB in a order. From there we can manually select a knee in the frequency curve and use that as a whitelist. In terms of improving the task for improving the knee selection in Alevin, if you can share the `frequency.txt` file then I can look into what's causing the issue for gaussian correction or the knee selection itself. Thanks again for your interest !",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/245#issuecomment-402547744:33,test,testing,33,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/245#issuecomment-402547744,2,"['log', 'test']","['log', 'testing']"
Testability,"Hi @OnlyHigh,. Indeed, the _default_ behavior of salmon is to de-duplicate transcripts (to avoid that behavior and allow salmon to index duplicate transcripts, you need to pass the `--keepDuplicates` flag to the indexer). When it does this, it will log the duplicate transcripts in the index. If you look in the directory containing the salmon index, you will find a file called `duplicate_clusters.tsv`. This is a 2 column TSV file with a row for each transcript that was collapsed during indexing. The first column says which retained transcript was identical to the collapsed transcript. We do not write down the specific sequence of these transcripts, but with the original fasta file on which the index was built, you can easily extract this. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/299#issuecomment-428612513:249,log,log,249,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/299#issuecomment-428612513,1,['log'],['log']
Testability,"Hi @PeteHaitch ,; I have just pushed a potentially testable version in Alevin for cel-seq2 ( activated by `--celseq` command line flag ), although to make it work the develop branch has to compiled from source.; A couple of points to note:; * I assumed the the length of both CB and UMI to be 6 as in the original cel-seq2 paper.; * The deduplication algorithm is still same as default and nothing has been changed in the part. Please let us know how it works out for you and if at all it's useful / comparable to the output generated by the traditional cel-seq2 pipeline.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/269#issuecomment-418570247:51,test,testable,51,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/269#issuecomment-418570247,1,['test'],['testable']
Testability,"Hi @PlantDr430,. Thanks for the detailed report. I'll provjde a detailed explanation of the bootstrap variance later when I'm at my computer. However, regarding the gibbs issue with the log file not being properly populated; you still get the appropriate gibbs samples as output, right? The issue is just with writing the log? We'll check into what might be causing this.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/466#issuecomment-568768688:186,log,log,186,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/466#issuecomment-568768688,2,['log'],['log']
Testability,"Hi @Ryan-Zhu ,. Thanks a lot for bringing this to our attention.; We have fixed this in the latest commit of the develop branch https://github.com/COMBINE-lab/salmon/commit/e93d6cee19c46d56d603e75097dbe17ab18e6811 and will merge in the next release . Usually the number of skipped Barcodes due to no mapped reads are relatively few that's why this corner case slipped from our testing. If it's possible for you to compile salmon from source you can use the develop branch to generate the new binary otherwise let us know we can provide a temporary linux binary until the next release.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/374#issuecomment-501943370:377,test,testing,377,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/374#issuecomment-501943370,1,['test'],['testing']
Testability,"Hi @Ryan-Zhu ,; Can you please share the logs ?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/374#issuecomment-501681776:41,log,logs,41,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/374#issuecomment-501681776,1,['log'],['logs']
Testability,"Hi @alexg9010 ,. A apologize profusely for dropping the ball on this. Would it be possible to test with the latest release of salmon? I am still not able to reproduce this behavior on any of our test machines.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/210#issuecomment-395199735:94,test,test,94,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/210#issuecomment-395199735,2,['test'],['test']
Testability,"Hi @alexmascension ,. Thanks for confirming. I'll paste my response, I sent you earlier, here too. In case it's helpful to some other user. > Hi Alex,. >Thanks again for forwarding the data. I think I have the solution for the problems you are facing in alevin. >Your first question was related to alevin quantifying very less number of reads. To answer that,; if you look at the log, at the first few lines, alevin warns about ~91% of the reads being thrown away because; of the noisy CBs. The problem is alevin’s first “knee"" estimation is overshooting in predicting the first boundary. You will find https://github.com/COMBINE-lab/salmon/issues/362 issue to be; very useful in understanding that. As a summary if you look at the plot I attached it has bi-modalities,; which is generally not the case and alevin is greedily finding the threshold at the first ~100 cells. If this; happens the general direction is to help alevin by proving a upper bound, in case of your data; would be ~14000 cells. You can tell alevin with `—expectCells 14000` and alevin start to work; normally and logs ~12% of the data is noisy. >You second question was a little complicated to answer. Seemingly, your salmon index has transcript with; same exact name `ENST00000399966.9`, occurring twice with different sequences. Just by looking at the index,; I am unsure it’s actually present in the reference or its salmon indexing messing up. If I Assume it was actually; present two times in the reference, alevin should report it instead of exiting abruptly in the middle of quantification.; Although, alevin does warns:; ```; [2019-07-04 14:12:32.519] [alevinLog] [warning] Found 1 transcripts with duplicate names; ```; >However, the bug i.e. not being able to distinguish duplicate names of the transcript, has been ; fixed and pushed in the develop branch of salmon. Alevin was reporting the error at the stage of quantification too, ; if you dump the logs in a file, but it was invisible in the console as it was ove",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/386#issuecomment-508754845:380,log,log,380,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/386#issuecomment-508754845,2,['log'],['log']
Testability,"Hi @alexmascension ,. Thanks for raising this.; Quick question thought, the issue header say : ; > Out of Range error for txp to gene Map. But I don't see that error in the log, did you skip copying that ?; Also, I should have raised this in the previous issue too but it should not matter at least in this error case, however, you should use `-lISR` instead of `-lU` with alevin as the reads are expected to come from the reverse strand. It seems a lot of reads `91.1983%` are supposedly getting thrown away, weren't you using the whitelisted CB instead of ""knee"" thresholding ?; If possible, can you share a small set of reads, like these `even some of them fail just when starting the analysis of the cells`, on which I can replicate the issue? it'd help resolve the issue much faster.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/386#issuecomment-504952404:173,log,log,173,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/386#issuecomment-504952404,1,['log'],['log']
Testability,"Hi @alexvpickering ,. Thanks for raising the issue. It seems #377 and #379 are connected .; Alevin is in fact suppose to output whitelist.txt file when provided with the flags you provided.; I think what's happening in your case is since `--keepCBFraction 1`, alevin is using all the CB for quantification and it couldn't find (any or very low) CB from the low confidence region needed for the whitelisting. ; Basically in the above screenshot, alevin never finished. It should have failed more gracefully, I'll make sure of that in the next release. In the meantime you can use the exit code 0 or ""Finished Optimizer"" log for successful finish. Also, try playing with the lower values for the `keepCBFracion` may be around (0.4 / 0.5) and `--freqThreshold` for changing the minimum frequency of a CB to consider, currently set to 10. You can also follow https://github.com/COMBINE-lab/salmon/issues/362 for more details.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/379#issuecomment-502818453:619,log,log,619,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/379#issuecomment-502818453,1,['log'],['log']
Testability,"Hi @apeltzer ,. Thanks for this info. I've fixed the issues related to the bwa files in the develop branch. I tested things out using an Alpine Linux docker image to re-create your environment. Unfortunately, there seems to be a bigger issue for building from source on Alpine Linux that is actually far beyond the scope of Salmon itself. Apparently, Alpine linux uses [musl])(https://www.musl-libc.org/), a non-standard libc replacement that is missing some of the calls used by [Intel's TBB](http://forum.alpinelinux.org/forum/general-discussion/compilation-tbb). I imagine this would affect quite a bit of scientific software on this distribution. I currently haven't found a work-around, but let me know if you're aware of anything. In the mean time, does the pre-compiled binary (or the docker image) work for you?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/162#issuecomment-345752365:110,test,tested,110,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/162#issuecomment-345752365,1,['test'],['tested']
Testability,"Hi @asher1234,. Thanks for the detailed bug report. The detection of the library type as `MU` certainly does raise some flags as that is not something that would be expected. Moreover, in the v0.12.0 log you posted, we see messages like:. ```; Thread saw mini-batch with a maximum of 90.16% zero probability fragments; ```. Which means that e.g. ~90% of the fragments, even though they map, are being assigned a 0 probability under the model (because of e.g. incompatibility with the library type). Would you be able to share one of these samples and the reference transcriptome against which you are quantifying? Also, do things look any different if you force the library type to be something more common (e.g. `-l IU`)?. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/346#issuecomment-469108517:200,log,log,200,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/346#issuecomment-469108517,1,['log'],['log']
Testability,"Hi @asher1234,. Thanks. I'll try and grab the data now. The 0.12.0 log here is quite informative. It looks like the problem is that none of the reads are making through the likelihood filter, which explains why you see the output you do. I'll take a look and see if there is a clear reason why. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/346#issuecomment-469412869:67,log,log,67,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/346#issuecomment-469412869,2,['log'],['log']
Testability,"Hi @astrdhr,. Ok, so the difference between the version you get on the command line, versus the version you get when you actually attempt to run your script to process your data, is certainly a point of concern. In general, the behavior you are seeing during runtime seems like it may be an artifact of not having a compatible index. Is it possible for you to do a ""test run"" outside of the Nextflow script? Since you are getting v1.10.2 locally, and this version should work without segmentation fault, that would at least let us narrow the issue down to different versions of salmon being invoked at different stages of the pipeline. At that point, it may be a Nextflow / nf-core issue, but those folks are *great* and will be able to help in a jiffy!. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/881#issuecomment-1766508995:366,test,test,366,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/881#issuecomment-1766508995,1,['test'],['test']
Testability,"Hi @biobenkj,. Congratulations on publishing your new single-cell technology, and thanks for your interest in adding support to alevin(fry). . After adding the functionality to provide custom geometry for UMI and cellular barcode sequence through command line flags like `--umi-geometry` and `--barcode-geometry,` our general guidelines have been shifted against adding technology-specific command line flags to the alevin codebase. Rob might have more comments on that. Regarding the 0-length cell barcode, I recommend first trying to add the dummy CB before the UMI sequence as a test case. If it helps with your use case, we can discuss adding the ; 0-length cellular barcode functionality to the main codebase. Previously, paired-end read processing was not possible under the alevin framework, but with the publication of alevin-fry, the support for paired-end read (I think) has been added. @DongzeHE and @Gaura might have better thoughts on this.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/805#issuecomment-1282467290:582,test,test,582,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/805#issuecomment-1282467290,2,['test'],['test']
Testability,"Hi @bsipos,. This is caused primarily by salmon's desire to apply an error model (by default) to the CIGAR strings. For secondary alignments, as you note, minmap2 doesn't write the read string, and so when salmon is trying to score the alignments under the error model, it can't find the relevant characters in the read. In general, it's not clear to me if one would actually want to apply the error model (designed primarily for short reads) when quantifying long reads (this is something we are currently testing in the lab). For the time being, I'd probably recommend disabling the error model when quantifying alignments from long reads (`--noErrorModel`). In that case, the errors should hopefully go away. Please let me know, and we'll be sure to keep you updated on best practices for long reads as we figure things out.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/289#issuecomment-420295665:507,test,testing,507,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/289#issuecomment-420295665,2,['test'],['testing']
Testability,"Hi @bzmby ,. I am sure you are aware of this but just wanted to clear that salmon is primarily designed for transcriptome quantification.; Ideally, there should not be a problem with indexing genome, also from the log you shared it looks like a warning. ; Having said that if you will index the genome then at the end of the day you will get quantification of the chromosomes, is that what you wan't ?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/741#issuecomment-1024655023:214,log,log,214,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/741#issuecomment-1024655023,2,['log'],['log']
Testability,"Hi @cfischer1991,. Thanks for the report. There have certainly been _a lot_ of improvements and changes to salmon between v0.8.1 and v1.3.0. The built-in mapping functionality has been largely overhauled. However, I can see that you're not using that here (you're quantifying from alignments). There have been a number of improvements in the alignment-based codepath as well. However, I'd guess that one of the biggest differences in the results you're seeing is due to a changes in the variational Bayes prior that happened between these versions. Specifically, the prior was adjusted to be smaller, and the default was changed from a `per-nucleotide` prior to a `per-transcript` prior. You can try and achieve the newer functionality in 0.8.1 by setting `--perTranscriptPrior` and `--vbPrior 0.01` and seeing, under those settings, how differently things look between 0.8.1 and 1.3.0. *Also*, another important change is in the handling of _incompatible_ alignments — alignments that do not match the prescribed library type. The incompatibility prior used to be set to a small but non-zero value by default `9.9999999999999995e-21`, but has since been changed to `0` by default. Both of these changes in the default have been results of a lot of internal testing suggesting these settings improve quantification results _in general_ (of course, given the complexity in of the quantification problem, there is likely no universal set of parameters that are optimal with respect to every experiment). I'd suggest trying to set these parameters to be the same between versions and to see how much of the variance is controlled by these changes in default values. Then you can determine which settings you believe make more sense in your context, with the understanding that the newer settings have been chosen, in general, to optimize quantification accuracy. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/562#issuecomment-674855490:1258,test,testing,1258,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/562#issuecomment-674855490,1,['test'],['testing']
Testability,"Hi @cliftonlewis, . Sorry for the delay. I tested it on another file and it worked fine. I would like to look at some info from your file. Could you:; 1. Post the `salmon` log of the first run, the one that you did with `--justAlign`; 2. There should be a `map.rad` file in your output directory (`SRR17122012`). Can you run the command: `alevin-fry view --rad map.rad > rad.txt` and share the rad.txt file? . Thanks.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/813#issuecomment-1344650063:43,test,tested,43,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/813#issuecomment-1344650063,2,"['log', 'test']","['log', 'tested']"
Testability,"Hi @cljacobs,. There was at least one unnecessarily large allocation within our pufferfish code, and now Ilia has also massively optimized the intermediate disk space usage behavior of TwoPaCo. An updated binary that incorporates these changes can be obtained [here](https://drive.google.com/open?id=1QHYCT3Vs9bRD7UmJY6JJKjlzmmUE4wRl). If you have a chance, it would be fantastic if you could test this out and see how the resource requirements change for you.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-587082126:393,test,test,393,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-587082126,1,['test'],['test']
Testability,"Hi @dhy2002,. The message at the beginning is just a result of salmon not being able to complete the version check — that is not related to any issues building the index. What is at the end of the log file?. Also, I'll note that we've seen before some issues related to building the index directly on a network file system mounted partition — the tool we use for compacted de Bruijn graph construction, TwoPaCo, can create many small intermediate files that causes issues for NFS. If this is the problem, I might suggest building the index on the local scratch disk of a node, and then copying over the completed index when it's finished. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/755#issuecomment-1050468212:197,log,log,197,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/755#issuecomment-1050468212,1,['log'],['log']
Testability,"Hi @dritoshi ,. Thanks for your request. I'd be happy to add the support for Quartz-seq2 into alevin but it'd be great if you can answer a few questions for us. Is it possible to share some reads/fastq file on which we can test alevin ? Also, please excuse my ignorance, what type of PCR amplification is performed in `Quartz-seq2` protocol, is it CelSeq type IVT (linear) amplification or Drop-Seq type template switching PCR amplification ?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/416#issuecomment-521747003:223,test,test,223,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/416#issuecomment-521747003,1,['test'],['test']
Testability,"Hi @ehiggs, You're right; there's no real reason we shouldn't be able to support ICC. The only issue is that we currently don't have access to a machine with icc, so this prevents us from testing the build ourselves. Is there a (free) resource (similar to Travis) that would allow us to test ICC builds? I'd be willing to add CMake support either way, but it would obviously be better if we could iron out the details ourself rather than wait for users to report issues building with icc.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/9#issuecomment-126348908:188,test,testing,188,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/9#issuecomment-126348908,2,['test'],"['test', 'testing']"
Testability,"Hi @francicco ,. I've dug further, and in addition to these problems with the input file, there was also a specific bug in salmon's processing of the alignments for the error model. Specifically, it was triggered when an alignment ended with a soft-clip of the reference. I have now fixed this issue in the develop branch, and, after some more testing, will push it to a new release.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/231#issuecomment-394859031:344,test,testing,344,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/231#issuecomment-394859031,1,['test'],['testing']
Testability,"Hi @fweghorst,. My guess is that a large fraction of this high number come from `N` bases in the underlying genome assembly (since you are making a gentrome index). To test this hypothesis, you could also build an index with just the cdna (or edna + ncrna) and see what that number is. At the end of the day, of course, it makes sense to use the gentrome index anyway, but this will at least give you an idea of what fraction of nucleotides are being replaced from the decoy (genome) versus the target transcript sequences. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/766#issuecomment-1082558366:168,test,test,168,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/766#issuecomment-1082558366,1,['test'],['test']
Testability,"Hi @gambardella,. Thank you for the detailed bug report. I agree that, though the issue seems to be arising from the input, a seg fault should not happen in any case. Judging from the place in the log from which this is arising, it seems to be happening during the TwoPaCo construction of the compacted de Bruijn graph. We'll dig into this and see if we can figure out how to handle this in a better way.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/521#issuecomment-627508722:197,log,log,197,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/521#issuecomment-627508722,1,['log'],['log']
Testability,"Hi @gianfilippo ,; Thanks for forwarding the logs.; It does look like Alevin knee selection is over-shooting and allowing only ~250 cells as a whitelist.; Although not very frequent but we do have observed this behavior with Alevin knee selection in couple of other experiments and are working on more robust thresholding. I am closing this issue regarding the barcode frequency but will open a new one regarding the aggressive thresholding and would tag you in too, in case you wan't to track.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/284#issuecomment-418813606:45,log,logs,45,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/284#issuecomment-418813606,1,['log'],['logs']
Testability,"Hi @gianfilippo ,; it looks like the logs which you forwarded are for externally given whitelists, can you rerun alevin w/o that?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/284#issuecomment-418130349:37,log,logs,37,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/284#issuecomment-418130349,1,['log'],['logs']
Testability,"Hi @gianfilippo,. Thank you for the report and for including the log File. Can you share one of the problematic samples and the reference against which you are aligning? One big difference is that the alignment rate reported by HISAT2 is to the genome, while for salmon it is with respect to the genome. For certain samples (e.g. if you get a bad sample with poor rRNA depletion etc.) you can have many reads align to the genome, but none of them align to the annotated transcriptome. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/616#issuecomment-764188266:65,log,log,65,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/616#issuecomment-764188266,1,['log'],['log']
Testability,"Hi @grantcramer,. I was able to successfully index and map against the fasta file you link above (on linux). I was also able to index and map against the index on OSX, using the salmon from bioconda (v 0.9.1). So, I'm not _yet_ able to reproduce this. It seems the file you uploaded for your pre-built index is no longer available, so I couldn't try that out. I'd be happy to give it a try if you can put it up on dropbox or some such. Otherwise, I wonder if there could be some sort of binary compatibility issue. Did you build the index on the same machine you're quantifying on? The OSX I tested on is 10.13.1. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/209#issuecomment-375509050:592,test,tested,592,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/209#issuecomment-375509050,1,['test'],['tested']
Testability,"Hi @guidohooiveld, . Regarding your questions:. (1) The motivation behind asking users to use Bioconda to install the binary is to limit the number of variables we may encounter when someone is reporting a bug --- i.e. if there are fewer distribution channels there is less maintenance overhead. Nonetheless, as you can see, I've had to make the binary available anyway, because it was the only way some people could easily get the program. Therefore, I think I'll start attaching binaries to releases again. (2) Yes, though this functionality is not part of Salmon itself. I *highly* recommend the [MultiQC](http://multiqc.info/) tool. MultiQC has a salmon module, which will parse all of the salmon log files in an experiment directory and produce a report. This report will contain the mapping percentages for all of the samples extracted from the salmon logs (and will color them nicely). It will also produce other QC information from the salmon runs. We are currently working on an improved multi-QC module, which will also provide summaries for things like GC / seq bias by analyzing the models that salmon learns, but this module isn't yet complete. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/252#issuecomment-405442271:701,log,log,701,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/252#issuecomment-405442271,4,['log'],"['log', 'logs']"
Testability,"Hi @hliu5259 ,; can you forward the log ?; There can be multiple reasons, did you gave external whitelist ? When you say 9253 samples do you mean 9253 cells ? How did you fix the number of cells ?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/375#issuecomment-501828238:36,log,log,36,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/375#issuecomment-501828238,1,['log'],['log']
Testability,"Hi @jan-g1,. The length of a feature is used during inference to determine the likelihood that multimapping reads should be allocated to different targets. You're describing what is essentially a simplified model where P(f | t) (i.e., the probability of a fragment given a transcript) is independent of length(t). There's currently no option to disable length normalization completely in Salmon, and you can't ""de-normalize"" by simply multiplying by a factor because those weights are considered during each and every round of the EM (or VBEM) algorithm. However, supporting this should actually be very straight-forward. We simply assign a uniform and identical length to all transcripts for the purpose of inference. I can add such a flag in the next release, though it will initially have to be incompatible with bias correction (since it's not clear right now how the biases for which we account interact with this type of sequencing). Also, it would be possible to run salmon with `--dumpEq`, and then to have a little script / tool that simply re-runs the EM, but without different length factors, using the equivalence class file. I might be able to hack something like that together on short notice if you'd be interested in testing it out. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/108#issuecomment-264659889:1233,test,testing,1233,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/108#issuecomment-264659889,2,['test'],['testing']
Testability,"Hi @jckhearn,. The documentation could definitely be more clear, so let me try and clarify here and make a note to clean up the documentation more as well. I'll answer in reverse order:. > Given the above command should I go back to a non-decoy aware transcriptome?. No. What the statement in the documentation means to convey is that if you are using the basic quasi-mapping algorithm (not selective-alignment as enabled by `--validateMappings`, `--mimicBT2` or `--mimicStrictBT2`), then you should not be using a decoy-aware transcriptome. We have not tested the effect of decoys on the basic quasi-mapping approach, and though that may be supported in the future, it is not right now. However, if you are using any flavor of selective-alignment, then please _do_ use the decoy-aware transcriptome. . Regarding ""combining"" `--validateMappings`, `--mimicBT2` and `--mimicStrictBT2`, this is not possible. That is, you should view `--mimicBT2` and `--mimicStrictBT2` as ""meta-flags"" that enable selective-alignment and also set a few other options that are meant to mimic the BT2 behavior more closely. We generally do _not_ recommend `--mimicStrictBT2`, and so the main choice is between simply using `--validateMappings` vs. `--mimicBT2`. The main differences here are that `--mimicBT2` sets slightly more sensitive parameters to find alignments, but is also stricter in what it reports. The biggest differences is that `--validateMappings` will allow orphaned mappings (where one end of a paired-end fragment aligns but the mate doesn't), while `--mimicBT2` will not allow such mappings. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/399#issuecomment-511884297:554,test,tested,554,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/399#issuecomment-511884297,2,['test'],['tested']
Testability,"Hi @jeremymsimon — @Gaura is going to take a look at unfiltered permit listing and will share those results here later. Regarding frameshift errors, I think that's certainly out of scope for the alevin -> fry phase, but that type of thing *could* be in scope for `splitp`. Basically, my logic / reasoning is this: I'd like to avoid further complicating the already immense salmon/alevin codebase with special implementations handling problems outside of their core function (e.g. mapping reads to the reference efficiently and quantifying UMIs/barcode). Since most protocols (and the most common) have quite simple barcode geometry, it makes sense for this code to live there. I'm fully supportive of enabling support for more complex barcode geometries and preprocessing requirements if there are folks whom it would help, but it feels like that essential complexity belongs upstream of alevin / fry, so that by the time the reads get to alevin, it can assume a straightforward geometry. So TLDR : I think we'd be willing to investigate what is required to address potential frameshift errors, and how much of a difference that makes, but I think that analysis and eventual implementation (if we decide it's worth it), belongs in `splitp`.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-988030837:287,log,logic,287,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-988030837,2,['log'],['logic']
Testability,"Hi @jeremymsimon! In order to test and validate the implementation I would need a count matrix generated on samples. Do you have a sample and count matrix from that? The Rosenberg submission of the data has an unclear way of specifying barcodes and I have emailed him about it. If you have count matrix and matching fastqs that we can use to validate, we can wrap it up soon.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-982878463:30,test,test,30,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-982878463,1,['test'],['test']
Testability,"Hi @jeremymsimon,. A few quick thoughts on this.; ; > -Is quantification via alevin-fry (rather than alevin itself) mandatory here? I ask since your run seems successful whereas my full alevin run had a very poor BC detection and mapping rate.; ; I don't think we've been able to successfully obtain the same concordance with alevin yet (as opposed to alevin-fry). There is more sophisticated _internal_ barcode logic going on there, and we may need to pull @k3yavi in to see what is happening outside of the RAD -> fry pipeline.; ; > -I see you specified -l A - can you comment on what the detected/correct library type was here?; ; Unlike `alevin`, when you run with in `--rad` or `--sketch` mode, the library type isn't really relevant. All mappings are passed through to the rad file. Subsequently, in `alevin-fry` there is a `-d` (direction) flag that is used to filter mappings that don't concord with the expected orientation. I'm not sure what @Gaura used in the run above — the default is to keep reads from either orientation.; ; > -I assume all of this will also work in conjunction with --expectCells or --keepCBFraction if those parameters were needed? Your ~7k cells detected is very close to the published number post-filtering, but no similar filtering has been done here yet. My guess is that the proportion of cells that pass these filters will be higher for alevin, but we may still be under-estimating the number of real cells by a little bit here.; ; According to the commands listed, @Gaura used `alevin-fry`'s built-in knee-like filtering. This tries to use a knee on the cumulative read count histogram to determine a good cutoff for ""reliable"" cells versus poor quality cells. Alternatively, one can provide an external permit list with `-u` (unfiltered permit list) to quantify all cells that match any known barcode. This will generally result in *many* more quantified cells, which you will then want to filter post-quantification.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-988011633:412,log,logic,412,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-988011633,1,['log'],['logic']
Testability,"Hi @jeremymsimon,. I've discussed the support for SPLiT-seq/ParseBio with @Gaura in some depth. Honestly, I think the cleanest solution right now is just to have a more streamlined (and streaming) way to match / replace the random hexamers upstream of alevin-fry. By my understanding, if we can simply replace barcode 1 appropriately (as your Perl script currently does), everything should work downstream in alevin/alevin-fry.; ; To that end, I've thrown together a small rust program based on your Perl script. Currently that lives [here](https://github.com/COMBINE-lab/splitp). It reads the same basic parameters as the Perl script, and writes its output to stdout so that it can be used with named pipes. For example, something like:; ; ```; <normal salmon command> -1 read_file_1.fq -2 <(splitp --read-file read_file_2.fq --bc-map bcSharing_example.txt --start 79 --end 86 --one-hamming); ```. which will transform the second fastq file and stream the transformed reads out which can then be read by alevin-fry. One important thing to note is that while *alevin* requires the input reads to be a real file (i.e. you can't stream reads in because it does 2 passes), if you are mapping these reads for processing with *alevin-fry* you can use the process substitution trick above. As you hinted, this program works considerably faster than the Perl script. For example, for the first 10,000,000 reads in `SRR6750042`, the Perl script took 2m 48s to transform the reads and `splitp` took ~6s (if the output wasn't being written to a file on disk it took <4s). This should generally be fast enough to not be a speed bottleneck. So, perhaps the next step is to try to help you walk through this approach with a test dataset (and ideally using alevin-fry) to see if things are turning out as expected?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-961598108:1711,test,test,1711,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-961598108,2,['test'],['test']
Testability,"Hi @jeremymsimon,. So I'm trying to think about what issues _could_ be reasonably dealt with here. . 1) If the length of the sequence in the BAM header and the sequence provided in the FASTA file are different, this seems like a very difficult error to recover from since records can then contain alignments to bases about which we don't know. 2) If the same transcript appears multiple times in the input BAM header, but with different lengths, this also seems a difficult situation to allow. Exact duplicates are one thing, but I'm not sure if sequences ever appear with the same name but different lengths. If so, I'm thinking this would be a hard error. So, I think at least one situation we could reasonably deal with is that the input FASTA file contains multiple entries with the same name (and same length / sequence). In this case, we could retain only one of them, and document / log the fact that multiple identical entries were present in the input. Of course, there would still be an issue if we had a mismatch as with your example STAR input, where STAR concatenated all 3 occurences of an identical transcript. Are there other cases you can think of where it would make sense to somehow deal with the issue in salmon and continue with processing (perhaps with some extra warnings / log info)?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/282#issuecomment-418412904:890,log,log,890,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/282#issuecomment-418412904,2,['log'],['log']
Testability,"Hi @juugii ,. I tried to simulate the coverage/depth bias by subsampling a fraction of the data and then correcting it using a very trivial approach, which seems to be working fine, at least for the dataset I simulated. It would be great if you can also test the same on your dataset too and let us know how it looks for your use case. The gist of the notebook can be found [here](https://gist.github.com/k3yavi/55be0c0c660f1c0034f2d11df31bec00).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/305#issuecomment-433593259:254,test,test,254,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/305#issuecomment-433593259,1,['test'],['test']
Testability,"Hi @k3yavi , ; You are absolutely correct, that the tsv file only had one column, I fixed it above. . But the txdf was my backup... I tried your bioawk script, but I keep getting this error; `bioawk: illegal field $(), name ""group""` . [alevin.log](https://github.com/COMBINE-lab/salmon/files/2639709/alevin.log); [salmon_quant.log](https://github.com/COMBINE-lab/salmon/files/2639710/salmon_quant.log)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/326#issuecomment-443718326:243,log,log,243,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/326#issuecomment-443718326,4,['log'],['log']
Testability,"Hi @k3yavi ,. I'm using alevin to process 10X V3 data and encountered similar problem with this issue. I've tried run the pipeline using default whitelisting by alevin, `--whitelist barcode.txt` which from cellranger v.3.1.0 run (including 7938 barcodes), `--expectCells 10000`, and `--expectCells 30000`. But no matter how I change the parameter, the log shows that there are always about 50% percent reads has been thrown away, and the mapping rate was between 18.7%-19.1%. . the salmon version is `salmon 1.4.0`; the reference genome is sequenced by ourselves, and it's a plant.; my reads layout is paired end 150bp, . > R1: ; @A00582:424:HJYLGDSXY:3:1101:1090:1000 1:N:0:ACCGGCTC; TAACCAGGTCGAGTGAGTATTTAAGGCGCGCGGCGCACCAACGCACTCCCAACAACAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA; > +; FFFFFFFFFFFFFFFFFFFFFFFFFFFF,,:,,FF:,,,::FF,,:F,,,,,,F:,,,:,::FF::::::,FFF:F:FF:FFFFFFF::FF::FF,F:F:FF:F,FFFF,:FF,FFFFF:,FF:::FF:FFF:FF:FF:FFFFFFFFFF:; > R2:; @A00582:424:HJYLGDSXY:3:1101:1090:1000 2:N:0:ACCGGCTC; NCCTAGAAGCAGCCACCCTTGAAAGAGTGCGTAATAGCTCACTGATCGAGCGCTCTTGCGCCGAAGATGAACGGGGCTAAGCGATCTGCCGAAGCTGTGGGATGTAAAAATACATCGGTAGGGGAGCGTTCCGCCTTAGAGAGAAGCCTC; > +; #FF:FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF:FFFFFFFFFFFFFFFFFFFFFFFFFFF:FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF:FFFFFFFFFFFF::FFFFFFFFFF:FFFFFFFFFFFFF:FFFFFF:FFFFFFF:. Here is the logs. ## Default setting ; `salmon alevin -l ISR -1 ../clean/sample_S1_L001_R1_001.fastq -2 ../clean/sample_S1_L001_R2_001.fastq --chromiumV3 -i ../../dna/00.ref_genome/sample/salmon_index_allmRNA -p 40 -o test_alevin_allmRNA --tgMap ../../dna/00.ref_genome/sample/alltxp2gene.tsv`. > [2021-01-25 16:22:09.565] [alevinLog] [info] Found 43030 transcripts(+0 decoys, +0 short and +0 duplicate names in the index); [2021-01-25 16:22:09.615] [alevinLog] [info] Filled with 43030 txp to gene entries; [2021-01-25 16:22:09.620] [alevinLog] [info] Found all transcripts to gene mappings; [2021-01-25 16:22:09.631] [alevinLog] [info",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/340#issuecomment-766311567:352,log,log,352,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/340#issuecomment-766311567,1,['log'],['log']
Testability,"Hi @k3yavi ,; Using the 5238 barcodes that are specific to this experiment, and also removing the quotes from the transcript to gene map file [bcNotFound-2018-07-19b.tar.gz](https://github.com/COMBINE-lab/salmon/files/2214018/bcNotFound-2018-07-19b.tar.gz), this time Alevin finished with no error. However, I did not get a count matrix in csv format. Also, the quants_mat_cols.txt file is missing, and I do not know how to read the binary quants.mat file. `salmon alevin -l ISR -1 SRR6327122_1.fastq.gz -2 SRR6327122_2.fastq.gz --chromium -i index -p 2 -o alevin_output --tgMap transposon_sequence_set.fa.tsv --whitelist barcode_seq_5K.txt --dumpCsvCounts`; Version Info: ### A newer version of Salmon is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; Logs will be written to alevin_output/logs; [2018-07-19 22:53:27.709] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; ### salmon (single-cell-based) v0.10.2; ### [ program ] => salmon ; ### [ command ] => alevin ; ### [ libType ] => { ISR }; ### [ mates1 ] => { SRR6327122_1.fastq.gz }; ### [ mates2 ] => { SRR6327122_2.fastq.gz }; ### [ chromium ] => { }; ### [ index ] => { index }; ### [ threads ] => { 2 }; ### [ output ] => { alevin_output }; ### [ tgMap ] => { transposon_sequence_set.fa.tsv }; ### [ whitelist ] => { barcode_seq_5K.txt }; ### [ dumpCsvCounts ] => { }. [2018-07-19 22:53:27.714] [alevinLog] [info] Processing barcodes files (if Present) . ; processed 87 Million barcodes. [2018-07-19 22:55:37.299] [alevinLog] [info] Done barcode density calculation.; [2018-07-19 22:55:37.299] [alevinLog] [info] # Barcodes Used: 86885223 / 87959276.; [2018-07-19 22:55:37.303] [alevinLog] [info] Done importing white-list Barcodes; [2018-07-19 22:55:37.303] [alevinLog] [info] Total 5238 white-listed Barcodes; [2018-07-1",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/253#issuecomment-406597243:913,Log,Logs,913,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/253#issuecomment-406597243,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"Hi @k3yavi . I have added all the log files I could find of one sample. If you need anything else, please let me know. [salmon_quant.log](https://github.com/COMBINE-lab/salmon/files/7943404/salmon_quant.log); [alevin.log](https://github.com/COMBINE-lab/salmon/files/7943405/alevin.log). Thanks in advance for looking into this.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/739#issuecomment-1022373628:34,log,log,34,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/739#issuecomment-1022373628,5,['log'],['log']
Testability,"Hi @k3yavi, ; My local repository now contains the latest commit, and the run proceeds past the `processed X Million barcodes` however, I have been stuck at `Analyzed 95 cells (100% of all)` for the past few hours.. I am sorry this is giving you guys such issues :( . I also tried this on `cat *R1*.fq.gz` of the files, and had the same issue.; [alevin.log](https://github.com/COMBINE-lab/salmon/files/2672819/alevin.log); [salmon_quant.log](https://github.com/COMBINE-lab/salmon/files/2672821/salmon_quant.log). ```; Logs will be written to path/to/alevin_outputSingleLibrary/quantSC/logs; Check for upgrades manually at https://combine-lab.github.io/salmon; [2018-12-12 15:07:42.022] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; ### alevin (dscRNA-seq quantification) v0.12.1; ### [ program ] => salmon ; ### [ command ] => alevin ; ### [ index ] => { /path/to/gencode_annot/AlevinIndex/ }; ### [ libType ] => { ISR }; ### [ mates1 ] => { 12_CTTGTA_L001_R1_001.fastq.gz 12_CTTGTA_L001_R1_002.fastq.gz 12_CTTGTA_L001_R1_003.fastq.gz 12_CTTGTA_L001_R1_004.fastq.gz 12_CTTGTA_L001_R1_005.fastq.gz 12_CTTGTA_L001_R1_006.fastq.gz 12_CTTGTA_L001_R1_007.fastq.gz 12_CTTGTA_L001_R1_008.fastq.gz 12_CTTGTA_L001_R1_009.fastq.gz 12_CTTGTA_L001_R1_010.fastq.gz 12_CTTGTA_L002_R1_001.fastq.gz 12_CTTGTA_L002_R1_002.fastq.gz 12_CTTGTA_L002_R1_003.fastq.gz 12_CTTGTA_L002_R1_004.fastq.gz 12_CTTGTA_L002_R1_005.fastq.gz 12_CTTGTA_L002_R1_006.fastq.gz 12_CTTGTA_L002_R1_007.fastq.gz 12_CTTGTA_L002_R1_008.fastq.gz 12_CTTGTA_L002_R1_009.fastq.gz 12_CTTGTA_L002_R1_010.fastq.gz }; ### [ mates2 ] => { 12_CTTGTA_L001_R2_001.fastq.gz 12_CTTGTA_L001_R2_002.fastq.gz 12_CTTGTA_L001_R2_003.fastq.gz 12_CTTGTA_L001_R2_004.fastq.gz 12_CTTGTA_L001_R2_005.fastq.gz 12_CTTGTA_L001_R2_006.fastq.gz 12_CTTGTA_L001_R2_007.fastq.gz 12_CTTGTA_L001_R2_008.fastq.gz 12_CTTGTA_L001_R2_009.fastq.gz 12_CTTGTA_L001_R2_010.fastq.gz 12_CTTGTA_L002_R2_001.fastq.gz 12_CTTGTA_L002",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/329#issuecomment-446668422:353,log,log,353,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/329#issuecomment-446668422,6,"['Log', 'log']","['Logs', 'log', 'logs']"
Testability,"Hi @kate-simonova,. While I would certainly recommend updating to the latest version of salmon (which, given the pre 1.0.0 to post 1.0.0 difference would require you to rebuild the index), I don't think that would have a substantial effect on a mapping rate that is this low. If the Fastqscreen report suggests that most of the reads map to the genome (>75%), but you are seeing an 8% mapping rate in salmon, this highly suggests that most of the reads are, for some reason, arising from outside of an annotated gene. I would then have two suggestions to test out:. 1.) Check for mtRNA contamination. Try adding extra mitochondrial RNA to your reference fasta, re-indexing, and re-quantifying. If mtRNA depletion or polyA enrichment failed, then it's possible that you have most of your RNA-seq reads coming from mt genes. I've seen this before a number of times and it results in a situation where most of the reads map back to the genome — but not the annotated transcriptome, which often has an incomplete set of mtRNA sequences. 2.) Try mapping the reads to the genome and see how many reads overlap known genes. This is what you would do with a ""counting-based"" RNA-seq pipeline, so something like STAR+feature-counts or subread+feature-counts. While I would generally not recommend this for quantification, it can be instructive to see the fraction of reads that map to the genome but not to known transcripts. Likewise, you could (with the newest salmon) build an index on the transcriptome with the genome added as a decoy (see about our decoy-aware indexing), then the `meta_info.json` will let you know the fraction of reads that were discarded because they were best matched to a decoy sequence (in this case, the genome, but not some annotated transcript). This should help clarify what's going on, and might suggest some issues with the sample that are preventing a reasonable mapping rate to the annotated transcriptome. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/679#issuecomment-1036524215:555,test,test,555,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/679#issuecomment-1036524215,1,['test'],['test']
Testability,"Hi @keithgmitchell,. Alevin is designed for droplet-based, tagged-end protocols, and in the vast majority of these protocols, transcript-level quantification isn't really reliable enough to be useful. Since most tagged-end protocols sequence information from only the 3' end of the transcripts, there is a highly-biased coverage signal, and discerning UMI assignment at the transcript level is usually not possible. Therefore, I wouldn't generally recommend trying to obtain transcript-level counts from alevin and we haven't tested it in this context. If you have a particular reason you want to look at transcript counts and believe it may be reasonable in your specific use-case, you can alway pass in a gene-to-transcript map that just maps each transcript to itself, which will result in a transcript-level output matrix. However, I anticipate that the resolution problem will become more difficult in this case, and there will be much more uncertainty in the assignments. @k3yavi, please feel free to add anything you think I may have missed. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/588#issuecomment-729974232:526,test,tested,526,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/588#issuecomment-729974232,1,['test'],['tested']
Testability,"Hi @knokknok ,. Thanks for reporting this (and for testing out 0.10.0 so quickly)! Is this read set & reference txome available to try and reproduce this? Also, would it be possible to check if this occurs using the bioconda-packaged release?. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/228#issuecomment-393218241:51,test,testing,51,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/228#issuecomment-393218241,1,['test'],['testing']
Testability,"Hi @knokknok,. Nice catch ! K1 bad k2 are just two bit encoding of the UMI sequences, it passed my unit test because I was testing it with 10x data but you are right it should be dynamic based on the umi length. I'll make the changes to reflect that in the develop branch. Thanks !",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/430#issuecomment-535015422:104,test,test,104,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/430#issuecomment-535015422,2,['test'],"['test', 'testing']"
Testability,"Hi @kzkedzierska,. I'm not sure why the virtual memory usage here is so high, and am also not aware of a great way to predict it. One thing I might ask is if you could test this executable on your system ( [salmon-1.2.0-beta](https://drive.google.com/open?id=1QHYCT3Vs9bRD7UmJY6JJKjlzmmUE4wRl)). This is the near-final beta version of 1.2.0 whose release is imminent. One of the big changes in this version is a considerably more memory-efficient construction. We have been measuring this in terms of resident memory, but it may also apply to virtual memory. Would you mind giving it a try if you have a chance?. Thanks!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/441#issuecomment-605106040:168,test,test,168,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/441#issuecomment-605106040,1,['test'],['test']
Testability,"Hi @litongda007,. Thanks for the updated. I grabbed these and ... basically saw the same thing:. ```; 23R1F : has null = False; 23R2F : has null = False; 23R3F : has null = False; 23R4F : has null = False; R1ST1 : has null = False; R2ST1 : has null = False; R3ST1 : has null = False; R4ST1 : has null = False; ```. I am thinking that perhaps the error is popping up somewhere _downstream_ of salmon. I presume you are using the `salmon` -> `wasabi` -> `sleuth` pipeline, is that correct? If so, I can try and see if I get the same thing importing in R. The tests above were using the python importer from [here](https://github.com/COMBINE-lab/pluribus). **Update**: Ok, that, too, has failed. I converted all of the quantifications to hdf5 files using wasabi, and then checked for nans in the converted files:. ```python; import h5py; import numpy as np; def get_num_nan(x):; nbs = int(x['aux']['num_bootstrap'].value[0]); s = 0; for i in range(nbs):; s += np.isnan(x['bootstrap']['bs{}'.format(i)].value).sum(); return s. samps = ['23R1F', '23R2F', '23R3F', '23R4F', 'R1ST1', 'R2ST1', 'R3ST1', 'R4ST1']; for s in samps:; d = h5py.File('quant/{}/abundance.h5'.format(s)) # abundance.h5 created by wasabi; null_count = get_num_nan(d); print(""{} : null count = {}"".format(s, null_count)); d.close(); ```. The output, as above, is : . ```; 23R1F : null count = 0; 23R2F : null count = 0; 23R3F : null count = 0; 23R4F : null count = 0; R1ST1 : null count = 0; R2ST1 : null count = 0; R3ST1 : null count = 0; R4ST1 : null count = 0; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/529#issuecomment-638553711:557,test,tests,557,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/529#issuecomment-638553711,1,['test'],['tests']
Testability,"Hi @mathog,. > Is it really the case that Salmon cannot use 1.57.0?. It may be able to. We set the minimum required version to the lowest boost version we use in any of our testing machines where we run regression tests. Currently, this is 1.59.0. If you change the relevant `CMakeLists.txt` line, you *really* need to make sure you clear out the CMake cache. You can do this by removing `CMakeCache.txt` in your build directory, as well as the directory `CMakeFiles`. However, it might be easiest just to remove and remake the entire `build` directory. You may also try passing `-DBoost_NO_SYSTEM_PATHS=Bool:ON` to your cmake command. Finally, note that the build system is probably looking for the static libraries --- you can elide that preference by modifying [this line](https://github.com/COMBINE-lab/salmon/blob/master/CMakeLists.txt#L222). Finally, since salmon uses C++11, it's important that whatever boost you link against exposes a C++11 compatible ABI. Unfortunately, `FindBoost.cmake` is the most finicky of the module finding packages I know about 😦. If you use `-DFETCH_BOOST=TRUE`, then CMake will fetch a recent boost and build the libraries it needs and link them statically. I realize you want to avoid this, so hopefully one of the ideas above will help.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-396781869:173,test,testing,173,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-396781869,4,['test'],"['testing', 'tests']"
Testability,"Hi @mdeyssen,. Thanks for reporting this. This is really strange, as the compute note you're using here should be much more than capable of building this index reasonably quickly. Furthermore, stage 0 is the construction of the compacted de Bruijn graph for which we use a modified version of TwoPaCo. One strange thing seems to be that there is no disk read / disk write happening at this point, though TwoPaCo should have written its intermediate files to disk by this point in the algorithm.; ; I'm not sure what the best way to try to debug is at this point. Does the indexing complete correctly when you build it on just the transcriptome (leaving out the decoys)? Can you provide any information about the specific instance type used (and particularly the storage)? We'll see if we can think how to further test what might be going on in this case. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/687#issuecomment-885886146:813,test,test,813,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/687#issuecomment-885886146,1,['test'],['test']
Testability,"Hi @najibveto,. I do not have access to a windows machine, unfortunately, so I can not test this directly. It would seem that somehow the appropriate version of `libstdc++` is not available or is not being found? I would recommend to raise this issue over on the [`bioconda` repository](https://github.com/bioconda/bioconda-recipes/issues) or in their [gitter channel](https://app.gitter.im/#/room/#bioconda_Lobby:gitter.im). Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/864#issuecomment-1660467862:87,test,test,87,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/864#issuecomment-1660467862,1,['test'],['test']
Testability,"Hi @nazeeefa,. In this case, you need to make sure the relevant path is in your library path. Try the following:. ```; LD_LIBRARY_PATH=path/to/salmondir/lib:$LD_LIBRARY_PATH path/to/salmon quant -t fasta_file -l A -a bam_file -o output_dir; ```. If that works you can make the change to the library path automatic at login by putting . ```; ecport LD_LIBRARY_PATH=path/to/salmondir/lib:$LD_LIBRARY_PATH ; ```; In your `.bashrc` file and then opening a new terminal (assuming you are using a bash compatible shell). Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/219#issuecomment-386273154:317,log,login,317,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/219#issuecomment-386273154,1,['log'],['login']
Testability,"Hi @nh13,. This is not something for which we currently have support or something that we currently plan. I'd be open to it, but I'm honestly not sure how to cleanly do it in the current architecture, and doing so would certainly incur a performance hit. Salmon runs 2 phases of inference; and online phase and an offline phase. The online phase has access to _fragment-level_ information that is then summarized away during the offline phase (like the specific locations of each read, the length of each observed fragment, etc.). That information goes away when the reads are summarized into range-factorized equivalence classes. Moreover, some of the model parameters learned during the online phase will depend (in their details) on the order in which observations are made. Ostensibly, observing the same data in the same order **and issuing updates to shared model parameters from worker threads in the same order** should result in identical values, however this has never been tested and was never a design goal. The reason for this is that differences between runs are within the bounds of the inherent inferential uncertainty of the estimated parameters anyway. That is, if one is relying on a specific value at a level of precision such that a different run of salmon would produce a value different enough to change a downstream analysis, then one is imparting more precision on the estimates than they can provide. Other methods that produce identical results between runs for these values may produce the same output, but the accuracy of the output at that level shouldn't be trusted in this case. The uncertainty of the parameter estimates can be evaluated based on the Gibb samples (or bootstrap replicates) that salmon computes. Of course, the small differences between runs rarely lead to differences in downstream analysis (almost certainly at the gene level and also at the transcript level if you use a differential testing method that is aware of inferential uncertainty). On the ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/102#issuecomment-2159300538:984,test,tested,984,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/102#issuecomment-2159300538,2,['test'],['tested']
Testability,"Hi @nskbe,. The issue you're seeing with the mapping file name is related to this note in the release notes:. > Note: In the 0.7.2 release, the file provided to --writeMappings must use a qualified path (e.g. --writeMappings=./out.sam rather than --writeMappings=out.sam), this constraint is already addressed on develop and will be fixed in the next release. . Essentially, the code should internally qualify the filepath before checking if a directory exists, but it doesn't. The fix for this is to pass the file name as a qualified path (i.e. adding `./` before the file name when you want it in the current directory). This is already resolved in develop and the fix for this annoyance will make it into the next release. Regarding the issue with writing the information to `stdout`; actually, all of the logging messages are written to `stderr`. If you don't redirect `stdout`, then you'll see everything, but the intended usage for that mode is something like:. ```; salmon quant -i idx [other options] --writeMappings > out.sam; ```. This will redirect standard out to out.sam. You'll still see the logging messages on the console, since they are written to `stderr`, but all of the mapping contents are redirected to the file. Let me know if this resolves your issue. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/90#issuecomment-247072758:809,log,logging,809,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/90#issuecomment-247072758,2,['log'],['logging']
Testability,"Hi @oligomyeggo,. Thank you for the **incredibly** detailed report :). The problem is the following (derived from your `B13_MeOH_cells_Jurkat_Cas9_EGR1_1_simulated.out.err.txt` log above):. ```; ### [ index ] => { /beevol/home/winklerc/projects/scifi_pipeline/scifi/ref/idx/complete_ref_lens.bin }; ```. So it looks like what your rule is passing to the mapping command is not the path to the index directory, but the path to this specific file, `complete_ref_lens.bin` **within** the index directory. The argument passed to the `-i` flag of `salmon alevin` must be the directory where all of the index files live. I think you just need to have the directory itself stored in a variable upon index creation, and then you can pass it to the mapping rule. Let me know if this helps!. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/713#issuecomment-941839528:177,log,log,177,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/713#issuecomment-941839528,1,['log'],['log']
Testability,"Hi @pinin4fjords ,. Apologies for the delayed response and thanks for your interest in Alevin.; Unfortunately, there is no one straight answer for your question. ; Other people have been using Alevin for various microwell based protocols like (CEL-seq https://github.com/COMBINE-lab/salmon/issues/269 ) but from our side we have not extensively tested alevin on non-droplet based protocols. However, we are open to provide any kind of help you may need to test the microwell-seq protocol and extend the support for alevin. If you happen to have been already testing alevin please let us know of your experience and how we can improve aleivn.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/358#issuecomment-490089165:345,test,tested,345,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/358#issuecomment-490089165,3,['test'],"['test', 'tested', 'testing']"
Testability,"Hi @pinin4fjords,. We have the same use case, trying to automate as much as possible; for some datasets there really isn't anything you can do; if it is super bad both methods are bad. This function does a pretty reasonable job of picking a cutoff based on that histogram:. ```; def guess_depth_cutoff(cb_histogram):; ''' Guesses at an appropriate barcode cutoff; '''; with read_cbhistogram(cb_histogram) as fh:; cb_vals = [int(p.strip().split()[1]) for p in fh]; histo = np.histogram(np.log10(cb_vals), bins=50); vals = histo[0]; edges = histo[1]; mids = np.array([(edges[i] + edges[i+1])/2 for i in range(edges.size - 1)]); wdensity = vals * (10**mids) / sum(vals * (10**mids)); baseline = np.median(wdensity); wdensity = list(wdensity); # find highest density in upper half of barcode distribution; peak = wdensity.index(max(wdensity[len(wdensity)/2:])); cutoff = None; for index, dens in reversed(list(enumerate(wdensity[1:peak]))):; if dens < 2 * baseline:; cutoff = index; break; if not cutoff:; return None; else:; cutoff = 10**mids[cutoff]; logger.info('Setting barcode cutoff to %d' % cutoff); return cutoff; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-490160480:1049,log,logger,1049,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-490160480,1,['log'],['logger']
Testability,"Hi @pophipi ,; Thanks for the interesting question, but unfortunately in the current version of Alevin you can't tweak the mismatch rate option although based on the type of error/noise in the reads you can try reducing the size of the k from default 31 to something smaller and see if it helps. We are working on tweaking the mapping algorithm for Alevin allowing mismatches but it's still in testing phase and has not been integrated yet. We'll let you know as soon as we have version supporting that.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/280#issuecomment-416969420:394,test,testing,394,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/280#issuecomment-416969420,1,['test'],['testing']
Testability,"Hi @rached-97,. First of all, thank you for the _incredibly-detailed_ report. All of the information you provided made it easy to pull down the data and to test what might be going on. I pulled down the first sample, consisting of `SRR9071838_1.fastq` and `SRR9071838_2.fastq`, which was recognized as `IU` for you. . However, since I didn't have access to the annotation you used or the specific scripts you used to extract the transcriptome reference, I instead quantified directly against [gencode v37](ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_37/gencode.v37.transcripts.fa.gz). When I did this, salmon calls the library format type as `ISR`, which is what we would expect. The `lib_format_count.json` is as such:. ```; {; ""read_files"": ""[ SRR9071838_1.fastq.gz, SRR9071838_2.fastq.gz]"",; ""expected_format"": ""ISR"",; ""compatible_fragment_ratio"": 1.0,; ""num_compatible_fragments"": 31944161,; ""num_assigned_fragments"": 31944161,; ""num_frags_with_concordant_consistent_mappings"": 29445487,; ""num_frags_with_inconsistent_or_orphan_mappings"": 2576421,; ""strand_mapping_bias"": 0.000022006283676957945,; ""MSF"": 0,; ""OSF"": 0,; ""ISF"": 648,; ""MSR"": 0,; ""OSR"": 0,; ""ISR"": 29445487,; ""SF"": 1098610,; ""SR"": 1477163,; ""MU"": 0,; ""OU"": 0,; ""IU"": 0,; ""U"": 0; }; ```. As you can see, the strand mapping bias reported is `0.000022006283676957945` (to an insanely higher level of precision than we actually need). This is, of course, drastically different from the value of `0.36810071818291797` that showed up in your table for this sample. While it is true that salmon is quite conservative about calling a library as stranded (i.e. it would rather make the mistake of calling stranded library as unstranded than vice-versa, as the latter would discard reads while the former would not), in this case it looks like the culprit is likely the transcriptome reference being used. When quantified under the standard gencode transcriptome, this sample is inferred as `ISR` with very high confidence ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-825393464:156,test,test,156,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-825393464,1,['test'],['test']
Testability,"Hi @radlinsky,. I've downloaded the read data and am looking into this. In the meantime, I did notice some relevant output from your log. First, when I run with the automatic library type, I get that the most likely library type is `ISF` rather than `ISR`. Second, I note that ~4M fragments are discarded because they produce dovetailing reads. We discard dovetailing reads by default (this was a recent change in default behavior, though it is the same default choice made by e.g. Bowtie2). You can allow these reads to be mapped and quantified by passing salmon the `--allowDovetail` flag during quantification. Does this make any different in the alignments you see for this gene?. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/218#issuecomment-494208884:133,log,log,133,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/218#issuecomment-494208884,1,['log'],['log']
Testability,"Hi @rbenel , I just tested it on a couple of datasets we have, it seems to work fine.; Can you check if you can replicate the issue with two pairs and if possible forward some data to replicate the issue?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/329#issuecomment-446191229:20,test,tested,20,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/329#issuecomment-446191229,1,['test'],['tested']
Testability,"Hi @rbenel ,; Thanks for raising the issue. Just a heads up I am not very experienced in `R` and I may be doing something wrong but can you please forward your `gencode.primary_assemblyv29.tsv` because it seems the file generate after following your R code to generate txp to gene map does not seem to be right. It looks like somehow `as.data.frame(txdf$TXNAME, txdf$GENEID)`is not doing the expected thing i.e. it's dumping only the gene names, at least in my testing. One alternative would be to use bioawk script from [here](https://combine-lab.github.io/alevin-tutorial/2018/setting-up-resources/) or may be use `do.call(rbind, Map(data.frame, A=txdf$TXNAME, B=txdf$GENEID))` in R, I am not sure about the latter though.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/326#issuecomment-443712972:461,test,testing,461,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/326#issuecomment-443712972,1,['test'],['testing']
Testability,"Hi @red-plant,. So, I have some update from our end. @mohsenzakeri dug into the data a bit (specifically `SRR7985407`). What he found is that there are a considerable number of reads (~13%) have long stretches of polyA or polyT that are matching in a hyper-repetitive manner internally within a certain set of transcripts (i.e. these are not matching polyA tails, because those are already trimmed). These matches are, obviously, minimally informative, but we had not special-cased ignoring them yet. Specifically, what seems to be prevalent in these reads are read pairs where one read has polyA, the other has polyT, and the keep matching to the same positions. However, the rest of the reads don't match the transcript, so a bunch of time is wasted on validating (and discarding) these mappings. To test this hypothesis, we made a small change to the mapping algorithm to special case and ignore k-mers that are purely homopolymers. I'll note that in this data, this has no effect on the mapping rate. I get the following performance profile running the trimmed version of this data (having trimmed with `fastp`) using 4 threads, and _without_ the additional `--hitFilterPolicy BOTH` flag. ```; 1306.86user 4.79system 4:42.54elapsed 464%CPU (0avgtext+0avgdata 592704maxresident)k; ```. I was wondering if you might test this altered version out and see if it has a similarly beneficial effect for you as well. Probably, the time will be different, since the processors themselves are, and since I elided all non-essential flags here, but I would hope this version is faster than the current (even with the altered `hitFilterPolicy`). You can find a tarball with the pre-compiled binary [here](https://drive.google.com/file/d/1tPyOPW3Y8l86RS0-zBRLh0wCt3VTpkNw/view?usp=sharing). It should work on any relatively recent linux system.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/527#issuecomment-637568013:802,test,test,802,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/527#issuecomment-637568013,2,['test'],['test']
Testability,"Hi @red-plant,. This is actually an issue that is a result of the range-factorized equivalence classes that are induced by the validate mappings option. We noticed this side-effect of range-factorization in our own testing, and the issue causing it was fixed in 0.13.0. However, it is worth noting that `--validateMappings` will generally map reads in a much more sensitive way than the default quasi-mapping, and so it is likely that if a read maps to one allele, it will also map to the other but with a lower alignment score (which the algorithm accounts for during quantification). If you really only want to consider the best mappings for a read, and not weight read assignments by alignment score, then you can use the `--hardFilter` option that is also introduced in 0.13.0. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/347#issuecomment-469750859:215,test,testing,215,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/347#issuecomment-469750859,1,['test'],['testing']
Testability,"Hi @reganhayward,. Thank you for the detailed report. It's interesting that this happens when running with STAR but not when running with selective alignment. However, salmon will attempt to solve the optimization problem with the alignments it is given, regardless of if those come from STAR or from it's built-in selective alignment. While I would generally expect these to be similar, the alignment algorithms are different; see [e.g. the differences between SA/SAF & STAR here](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-020-02151-8). Nonetheless, it is possible that for a small subset of transcripts, the probabilistic allocations are _so_ ambiguous, that you get large swings in the resulting quantification estimates based on tiny variations in where the optimization starts (which is, itself, stochastic due to the asynchronous nature of salmon's online inference phase). One way we can test this hypothesis is as follows. You can run salmon with `--numGibbsSamples 100` and `-d`. This will tell salmon to perform posterior Gibbs sampling (`--numGibbsSamples 100`) and to dump the range-factorized equivalence classes used for offline quantification (`-d`). The Gibbs sampling files will contain the traces for the transcripts in question over the various iterations of the sampling procedure. Transcripts where there is a tremendous amount of ambiguity will tend to have highly anti-correlated posterior samples, and similarly, if you were to consider the abundance output of these transcripts as a *group*, there would be a large reduction in inferential relative variance. In fact, we [wrote a whole paper on this topic](https://academic.oup.com/bioinformatics/article/36/Supplement_1/i102/5870485). Consider this example from that paper:. ![image](https://user-images.githubusercontent.com/361470/101438021-706d3600-38df-11eb-9ada-a54ea9092d2d.png). The x-axis is samples from the Gibbs chains, and the y-values denote the estimated number of reads assigned to both t",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/600#issuecomment-740363115:917,test,test,917,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/600#issuecomment-740363115,2,['test'],['test']
Testability,"Hi @rfarouni ,. Thanks for the detailed answer.; > I am not sure why the ISF option didn't work, but probably it has something to do with the guide sequences I was provided. At any rate, I have a few other questions I hope you can help me answer. I'm not sure about this, it's possible if the guide sequences were already reverse-complemented then the above behavior would makes sense. I am a little less familiar with the guideRNA based ECCITE-seq data, although the mRNA library should be 5' and the sequence does come from forward strand but do we expect the guide RNA to be on the forward strand as well ? Unclear . I'll ask around at nygc and would let you know. > Why does increasing --maxNumBarcodes to 200000 results in no barcodes getting corrected? (See log for Run 2 below). What is the rationale for the current default of 100000?. That's again a great question. In short single-cell world is expanding rapidly and alevin was initially designed to work with 10x 3' data and some of the restriction are outdated with combinatorial indexing based multiplexed experiments. To be honest, 100k was just a random high enough number that was put down to throw away the obvious junk data. Having said that, you would notice that in both the logs you attached a significant fraction of barcodes are thrown away i.e., `Skipped 82268 barcodes due to No mapped read`, which is like ~82% of the 100k barcodes. Even if you include the 200k almost everything was thrown away, `[warning] Skipped 184123 barcodes due to No mapped read`. Although your point is important one why things are not getting sequence corrected with 200k, unfortunately I might have to do some more testing on that front to give more precise answer but in your case I'd advise keeping the default 100k bound, unless you are doing combinatorially-indexed data . > For the downstream analysis of such data, I usually work with both the read and UMI counts, but quants_mat.gz only contains the UMI counts. Can Alevin a produce a matri",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639048052:764,log,log,764,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639048052,2,['log'],['log']
Testability,"Hi @rmurray2,. Thank you for the report. First, I just want to mention that I don't believe v0.99.0 to be an officially released version number. That is, there was a v0.14.x and a (released in source only v0.15.0), and then the versions moved to 1.0.0 and beyond. However, this behavior certainly isn't related to that. There are 2 things going on that can lead to this effect. The first one, which is relatively easy to test, is that there may be small changes in when the inferred library type starts to be enforced (if it is not `IU`) when auto type detection is used (see [this issue and comments therein](https://github.com/COMBINE-lab/salmon/issues/489)). The second and more fundamental thing going on is that the observed behavior is intended. Even with a single thread of execution provided to salmon for mapping and quantification, there is a separate background thread that simply consumes reads from file and puts them in memory for quantification, and while e.g. pairing information between files is guaranteed to be preserved, exact read order is not. This can lead to differences in the order in which reads are processed and, as a result, differences in the initialization conditions of the optimization. The ultimate result is that for transcripts that have large inferential uncertainty, different numbers of reads can be assigned between runs. We have thought *a lot* about this behavior, what it means, and how the `NumRead` values should best be communicated to users. At the end of the day, the `NumReads` constitute the expected value of latent variables inferred in a _very_ high-dimensional space (# of parameters is at least the number of transcripts). Therefore, there are certain transcripts, whose estimated number of reads simply have _tremendous_ inferential uncertainty — and small perturbations in the initial conditions of the optimization will lead to different estimated values for their abundances. For those transcripts where you observe such fluctuations between",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/613#issuecomment-757989858:421,test,test,421,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/613#issuecomment-757989858,2,['test'],['test']
Testability,"Hi @rob-p ! I try to install Salmon on macOS M1 Max with hombrew (brewsci) ; but I guess the formula is the UNIX one on it. I got :. ```; Benjamin@macbook-pro ~ % brew install salmon ; ==> Downloading https://github.com/COMBINE-lab/salmon/archive/v1.3.0.tar.gz; Already downloaded: /Users/Benjamin/Library/Caches/Homebrew/downloads/b27a343a5c5128c674be4986b6c0bb348bc77d521662866976898bd4768fd8bb--salmon-1.3.0.tar.gz; ==> Installing salmon from brewsci/bio; ==> cmake .; Last 15 lines from /Users/Benjamin/Library/Logs/Homebrew/salmon/01.cmake:; Build system will fetch and use JEMalloc; ==================================================================; CPACK_SOURCE_IGNORE_FILES = /src/PCA.cpp;/src/PCAUtils.cpp;/build/;/scripts/AggregateToGeneLevel.py;/scripts/ExpressionTools.py;/scripts/GenerateExpressionFiles.sh;/scripts/ParseSoftFile.py;/scripts/PlotCorrelation.py;/scripts/junk;/scripts/sfstrace.log;/scripts/SFPipeline.py;/bin/;/lib/;/sample_data/;PublishREADMEToWebsite.sh;/external/;/src/obsolete/;/include/obsolete/;WebsiteHeader.txt;/experimental_configs/;.git/; CC: /opt/homebrew/Library/Homebrew/shims/mac/super/clang; CC version: ; version: 1.0.0; Building basic pufferfish components for salmon; setting -DHAVE_NUMERIC_LIMITS128; -- Could NOT find PkgConfig (missing: PKG_CONFIG_EXECUTABLE) ; -- Could NOT find Jemalloc (missing: JEMALLOC_LIBRARY JEMALLOC_INCLUDE_DIR) ; NO_IPO = FALSE; TBB_LIBRARIES = /tmp/salmon-20220630-57321-j1f2iv/salmon-1.3.0/external/install/lib/libtbb.dylib;/tmp/salmon-20220630-57321-j1f2iv/salmon-1.3.0/external/install/lib/libtbbmalloc.dylib; -- Configuring incomplete, errors occurred!; See also ""/tmp/salmon-20220630-57321-j1f2iv/salmon-1.3.0/CMakeFiles/CMakeOutput.log"".; See also ""/tmp/salmon-20220630-57321-j1f2iv/salmon-1.3.0/CMakeFiles/CMakeError.log"". Do not report this issue to Homebrew/brew or Homebrew/core!. Benjamin@macbook-pro ~ % salmon ; zsh: exec format error: salmon; Benjamin@macbook-pro ~ % ; ```; I try via bioconda but I got a HT",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/787:515,Log,Logs,515,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/787,2,"['Log', 'log']","['Logs', 'log']"
Testability,"Hi @rob-p , @mdshw5 , . I did a local run, it crashed again, but now at least with some more information and a core dump. ; So the process failed with this error:; ```; /bin/bash: line 1: 31345 Aborted (core dumped) /home/agosdsc/pigx/pigx_rnaseq/.guix-profile/bin/salmon quant -i /scratch/AG_Akalin/agosdsc/projects/mrg1_rnaseq/analysis_v2/salmon_index -l A -p 8 -1 /scratch/AG_Akalin/agosdsc/projects/mrg1_rnaseq/analysis_v2/trimmed_reads/N2_1_R1.fastq.gz -2 /scratch/AG_Akalin/agosdsc/projects/mrg1_rnaseq/analysis_v2/trimmed_reads/N2_1_R2.fastq.gz -o /scratch/AG_Akalin/agosdsc/projects/mrg1_rnaseq/analysis_v2/salmon_output/N2_1 --seqBias --gcBias -g /data/akalin/Base/Annotation/ce11/ENSEMBL91/Caenorhabditis_elegans.WBcel235.91.gtf >> /scratch/AG_Akalin/agosdsc/projects/mrg1_rnaseq/analysis_v2/logs/salmon_quant_N2_1.log 2>&1; ```; I uploaded the files and the dump, such that you can try to debug this: ; https://1drv.ms/f/s!AqRdeUKlw8lFjDV7eDqqQbN7cQPa",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/210#issuecomment-377190490:802,log,logs,802,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/210#issuecomment-377190490,2,['log'],"['log', 'logs']"
Testability,"Hi @rob-p , thank you for so quick response. I spent some time organizing my demo data. Here is link for demo: ftp://bioinfo.noble.org/pub/for-github/. Two genes, with transcript name MSAD_157177.t1 and MSAD_200218.t1, get significantly different expression value in two runs, although they are almost identical. . Below are NumReads from Salmon:; ```; runA runB; MSAD_200218.t1 636.8 12201.2; MSAD_157177.t1 9307.1 0.8; ```. I agree with the necessity of allocating mulit-mapping reads. However, our problem is MSAD_157177.t1 received most of mapping reads in runA (9307 vs 636) but lost all of mapping reads in runB (0.8 vs 12201). And MSAD_200218.t1 has totally opposite result. Such different behavior for two genes make downstream Deseq2 reported both genes as significantly DE genes across samples but we know it is false result. Look at histogram.jpg , you will find it is pretty common phenomena over samples in terms of normalized RPKM. . I did a quick test for runB using eXpress, here is eff_counts:; ```; MSAD_200218.t1 5406; MSAD_157177.t1 3990; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/107#issuecomment-263783167:962,test,test,962,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/107#issuecomment-263783167,1,['test'],['test']
Testability,"Hi @rob-p ,. It works! Thank you so much!; I tried all of the k-mer values in your advice (19, 21, 23, 25) for building indices and set the `--minAssignedFrags` parameter rather small to 3 and got a pretty nice mapping rate. And among them `-k` of 19 seemed to have the highest mapping rate. . Please let me know if anything looks abnormal!. Here is the command I used for indexing (same for `-k` = 19, 21, 23, 25):. `salmon index -t gencode.v40.transcripts.fa.gz -k 19 -p 12 -i salmon_index_19 --gencode`. And here is my command for quantification:. `salmon quant -i ../ref/salmon_index_19 -l IU -1 SRR493372_1.fastq SRR493373_1.fastq SRR493374_1.fastq SRR493375_1.fastq SRR493376_1.fastq SRR493377_1.fastq -2 SRR493372_2.fastq SRR493373_2.fastq SRR493374_2.fastq SRR493375_2.fastq SRR493376_2.fastq SRR493377_2.fastq --validateMappings --minAssignedFrags 3 -o transcripts_quant_19`. And the log file for indexing:. > [2022-04-16 11:15:45.756] [jLog] [info] building index ; out : salmon_index_23 ; [2022-04-16 11:15:45.778] [puff::index::jointLog] [info] Running fixFasta [Step 1 of 4] : counting k-mers ; [2022-04-16 11:15:46.377] [puff::index::jointLog] [warning] Entry with header [ENST00000682202.1|ENSG00000243480.8|OTTHUMG00000011023.3|-|AMY2A-204|AMY2A|19|processed_transcript|], had length less than equal to the k-mer length of 23 (perhaps after poly-A clipping) [2022-04-16 11:15:49.574] [puff::index::jointLog] [warning] Entry with header [ENST00000603775.1|ENSG00000271544.1|OTTHUMG00000184300.1|OTTHUMT00000468575.1|ENST00000603775|ENSG00000271544|23|processed_pseudogene|], had length less than equal to the k-mer length of 23 (perhaps after poly-A clipping) [2022-04-16 11:15:52.071] [puff::index::jointLog] [warning] Entry with header [ENST00000632684.1|ENSG00000282431.1|OTTHUMG00000190602.2|OTTHUMT00000485301.2|TRBD1-202|TRBD1|12|TR_D_gene|], had length less than equal to the k-mer length of 23 (perhaps after poly-A clipping) [2022-04-16 11:15:55.682] [puff::index::jointLog] [w",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/768#issuecomment-1100734317:893,log,log,893,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/768#issuecomment-1100734317,1,['log'],['log']
Testability,"Hi @rob-p ,. thank you very much for your quick and detailed answer. I really appreciate that you will include this feature in your next release.; Indeed, I'm interested in testing out your suggested script/tool !. Best,; Jan",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/108#issuecomment-264812173:173,test,testing,173,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/108#issuecomment-264812173,1,['test'],['testing']
Testability,"Hi @rob-p ,; After removing ""-pg"" flag in ""salmon/external/pufferfish/CMakeLists.txt"", it's able to be compiled successfully now using Debug mode. To reproduce (in salmon/build directory):; ISSUE 1: The second test failed, I'm wondering whether this should happen or not.; > /root/cmake-3.13.4-Linux-x86_64/bin/cmake -DFETCH_BOOST=TRUE -DTBB_INSTALL_DIR=/usr/include -DCMAKE_BUILD_TYPE=Debug -DNO_IPO=TRUE -DCMAKE_INSTALL_PREFIX=../stage ..; > make // to get /root/salmon/external/pufferfish/CMakeLists.txt file; > vim /root/salmon/external/pufferfish/CMakeLists.txt // remove the ""-pg"" flag on line 131 ; > make // successfully compiled after removing ""-pg"" flag; > make install ; > make test; ![second_test_failed](https://user-images.githubusercontent.com/24876498/103263448-e4809280-49e2-11eb-9be9-7bbedfa2f1a5.png). (in /mammoth/salmon_data directory):; ISSUE 2: segmentation fault occurs after ""wrote [count] cleaned references"" (the same place as Release mode); > /root/salmon/stage/bin/salmon index -t gentrome.fa.gz -d decoys.txt -p 12 -i salmon_index --gencode (data from your tutorial https://combine-lab.github.io/alevin-tutorial/2019/selective-alignment/); ![image](https://user-images.githubusercontent.com/24876498/103263653-75576e00-49e3-11eb-9661-abd69de73a5e.png). gdb /root/salmon/stage/bin/salmon core.23591; (it seems to crash at cereal::OutputArchive, fixFasta, fixFastaMain, etc.); ![image](https://user-images.githubusercontent.com/24876498/103263925-2100be00-49e4-11eb-8918-01f9adf52d98.png)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/609#issuecomment-751968056:210,test,test,210,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/609#issuecomment-751968056,2,['test'],['test']
Testability,"Hi @rob-p ,; thank you for your help. I got my hands on this kind of data for the first time today and followed the tutorial <https://combine-lab.github.io/alevin-fry-tutorials/2022/split-seq/> to test my data, but following the tutorial I ended up with a matrix file, doesn't seem to generate the file alevin_out/aux_info/alevin_meta_info.json, I actually want to get a report like 10X cellranger summary.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/774#issuecomment-1126090795:197,test,test,197,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/774#issuecomment-1126090795,1,['test'],['test']
Testability,"Hi @rob-p . A question: Can salmon be made available for ARM based arch?. Context: [AWS has recently launched instances with ARM based processors](https://aws.amazon.com/ec2/instance-types/r6/#:~:text=Amazon%20EC2%20R6g%20instances%20are,real%20time%20big%20data%20analytics.) which claim to have better performance. I would like to test/use salmon workflows with ARM based instances. Thanks in advance,",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/556:333,test,test,333,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/556,1,['test'],['test']
Testability,"Hi @rob-p . Before I answer your question and layout my logic, I want to mention that I am **_not_** suggesting fastp is not doing its job, **_neither am I stating that fastp is working incorrectly_**. Now to my answer(s) and logic:; 1. With fastp, I am not sure if adapter trimming happens first and then quality trimming OR vice-versa. I could not find info on this from their README and **_I could be wrong here with my next line_** - [Based on Figure 1 of this paper, it looks to me as though quality trimming is done before adapter trimming](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6129281/figure/bty560-F1/). - [To quote Brian Bushnell (author of BBTools)]( http://seqanswers.com/forums/showpost.php?p=140819&postcount=5), . > It's best to do adapter-trimming first, then quality-trimming, because if you do quality-trimming first, sometimes adapters will be partially trimmed and become too short to be recognized as adapter sequence. When you run BBDuk with both quality-trimming and adapter-trimming in the same run, it will do adapter-trimming first, then quality-trimming. 2. I very well know that the advantage of using fastp is that it can do adapter trimming, etc in a automatic fashion - no need to provide external sequences (example adapter sequences). Yes, I know one can also provide a fasta file of adapters and fatsp will work off it. There are many fatsp issues in GH about adapter detection:. - fail to detect adpaters automatically - (https://github.com/OpenGene/fastp/issues/222 and https://github.com/OpenGene/fastp/issues/205). - [incorrect automatic adapter detection](https://github.com/OpenGene/fastp/issues/240). - [inconsistent behavior with different runs](https://github.com/OpenGene/fastp/issues/231). 3. When I see the above, I am bit skeptical using fastp for qc/adapter trimming. . After lot of trials with bbduk and fastp, I have decided to use bbduk and bbmap for my high throughput analysis. Below, I explain my reasoning behind those choices: . **_```Not",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209:56,log,logic,56,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209,4,['log'],['logic']
Testability,"Hi @rob-p . I have a dataset with about 30 samples or so, in some cases salmon quant (1.2.0) runs fine, with some samples I get the error below. I am using the same command (changing it for different sample names and hence output directories). It works correctly for some samples and errs out with others like below. ```; Command executed:. salmon --no-version-check quant --threads 16 --seqBias --validateMappings; --numBootstraps 100 -l A --writeUnmappedNames -i <my_salmon_index> ; -r sample1.fastq.gz -o salmon_sample1. Command exit status:; 1. Command output:; (empty). Command error:; ### salmon (mapping-based) v1.2.0; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ threads ] => { 16 }; ### [ seqBias ] => { }; ### [ validateMappings ] => { }; ### [ numBootstraps ] => { 100 }; ### [ libType ] => { A }; ### [ writeUnmappedNames ] => { }; ### [ index ] => { my_salmon_index }; ### [ unmatedReads ] => { sample1.fastq.gz }; ### [ output ] => { salmon_sample1 }; Logs will be written to salmon_sample1/logs; [2020-04-22 19:51:56.392] [jointLog] [info] setting maxHashResizeThreads to 16; [2020-04-22 19:51:56.392] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2020-04-22 19:51:56.392] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2020-04-22 19:51:56.392] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.35.; [2020-04-22 19:51:56.392] [jointLog] [info] parsing read library format; [2020-04-22 19:51:56.392] [jointLog] [info] There is 1 library.; -----------------------------------------; | Loading contig table | Time = 72.775 us; -----------------------------------------; [2020-04-22 19:51:56.470] [jointLog] [info] Loading pufferfish index; [2020-04-22 19:51:56.470] [jointLog] [info] Loading dense pufferfish index.; Exception : [Failed to read 8 bytes fr",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/512:982,Log,Logs,982,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/512,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"Hi @rob-p . Sorry, but we couldn't test again the index I used to report the issue. Instead, we used a smaller one with the following characteristics:. ```; counted k-mers for 16040000 transcripts; Elapsed time: 726.738s. Replaced 5730782 non-ATCG nucleotides; Clipped poly-A tails from 530 transcripts; Building rank-select dictionary and saving to disk done; Elapsed time: 13.1116s; Writing sequence data to file . . . done; Elapsed time: 118.505s; [info] Building 64-bit suffix array (length of generalized text is 12671064288 ); Building suffix array . . . success; saving to disk . . . done; Elapsed time: 877.586s; done; Elapsed time: 3607.17s; processed 12671000000 positions; khash had 5905993560 keys; saving hash to disk . . . done; Elapsed time: 1249.59s; [2017-03-22 06:39:06.131] [jLog] [info] done building index; ```. Using this new index and salmon v0.8.2 precompiled binaries we didn't have any problems. Hope this helps. Thanks!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/129#issuecomment-288675236:35,test,test,35,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/129#issuecomment-288675236,1,['test'],['test']
Testability,Hi @rob-p . _**Salmon index command used**_; ```; salmon index -t rnor_gentrome.fa -d decoys.txt -k 17 --keepFixedFasta --keepDuplicates -p 16 -i rnor_ENSEMBL_96_index; ```. **_Directory size after indexing completes_**; ```; du -sh .; 45G; ```. **_Listing of files and their sizes_**; ```; 4.2K ref_indexing.log; 115 pre_indexing.log; 126 versionInfo.json; 944M mphf.bin; 6.0G pos.bin; 1004 info.json; 256K refAccumLengths.bin; 701M refseq.bin; 15G ctable.bin; 2.5G ctg_offsets.bin; 128K reflengths.bin; 2.9G seq.bin; 1.5G rank.bin; 128K complete_ref_lens.bin; 2.8G ref_k17_fixed.fa; 22K duplicate_clusters.tsv; ```,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/505#issuecomment-613224352:309,log,log,309,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/505#issuecomment-613224352,2,['log'],['log']
Testability,"Hi @rob-p ; I did use the pre-compiled binaries and the system I use is ubuntu 14.04.; Hmm.. even with the change you wrote, I seem to be getting similar results.; Does the order of parameters matter? I.e. in my command line, should I put -o first and then --writeMappings?. EDIT: Sorry, actually this might have worked, it's just that my read files were too big, and the run didn't actually even finish because I ran out of memory, and at the time of run cancellation I didn't see the resulting file (but all the other files Salmon output files were present) so I assumed it hasn't even been generated. My command-line window also froze up, so I couldn't see if what the stdout looked like. ; I'll definitely re-test when I find smaller files. . EDIT2: Ok, so I retested with smaller files, the run was successful, but still no resulting file. I'll be rechecking this for any mistakes, if I did something wrong. Here's the logs in case it means anything:. Version Info: This is the most recent version of Salmon.; salmon (mapping-based) v0.7.2; [ program ] => salmon; [ command ] => quant; [ index ] => { ucsc.hg19.transcriptome_salmon_index }; [ libType ] => { A }; [ mates1 ] => { reads.pe_1.fastq }; [ mates2 ] => { reads.pe_2.fastq }; [ output ] => { reads.pe_salmon_quant }; [ threads ] => { 2 }; [ auxDir ] => { aux_info }; [ writeMappings ] => { }; [ ] => { reads.pe.salmon_quant_mapping_info.sam }; Logs will be written to reads.pe_salmon_quant/logs",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/86#issuecomment-244780040:713,test,test,713,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/86#issuecomment-244780040,4,"['Log', 'log', 'test']","['Logs', 'logs', 'test']"
Testability,"Hi @rob-p ; So I tried testing again, running Salmon without any scripts, and again I keep having the same issue. The command line part with the parameter in question is (copy-pasted): ; ""--writeMappings test_output/mappings_info"" ; and the cmd_info.json file looks the same as before, with the """" key. ; Do I need to call that parameter differently, like --writeMappings=file_name, or...? ; If I did made some stupid mistake, sorry then upfront for wasting your time, in the meantime I'll try and test this a couple of more times in the next few days and try and see what's up.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/86#issuecomment-244903765:23,test,testing,23,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/86#issuecomment-244903765,2,['test'],"['test', 'testing']"
Testability,"Hi @rob-p! Thanks for all the great suggestions and comments. I have addressed all of them. I also tested the speed after the changes. The test was done 3 times in the same way as done earlier. . 1. `--sciseq3` ; ```; real 0m58.463s 0m57.884s 0m57.413s; user 7m0.652s 7m1.731s 7m1.278s; sys 0m3.305s 0m3.078s 0m2.665s; ```. 2. `--custom-geo`; ```; real 1m7.411s 1m14.988s 1m3.868s; user 8m8.795s 8m40.302s 7m49.107s; sys 0m4.194s 0m6.412s 0m2.969s; ```. The real time in case 1. was 57.92 ± 0.57s and for case 2. it was 68.75 ± 5.68s, which is about 19% slower.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1023219391:99,test,tested,99,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1023219391,2,['test'],"['test', 'tested']"
Testability,"Hi @rob-p, The version we see the fault on is Red Hat Enterprise Release 6.10 (Scientific linux). I have a version of ubuntu that I can test on but not sure when I can get around to it at the moment.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458145886:136,test,test,136,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458145886,1,['test'],['test']
Testability,"Hi @rob-p, thanks a lot for the detailed info - sounds great. I tried pretty much exactly what you proposed with 10k reads yesterday, and it only took a couple of seconds, so 100k seems like a great compromise to do this as fast and accurate as possible. We'll do some tests for this with different library types in the next couple of weeks (it's not super urgent for us) and we'll get back at you. Perhaps it's a use case of Salmon you would like to document for others as well... :)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/138#issuecomment-585837124:269,test,tests,269,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/138#issuecomment-585837124,1,['test'],['tests']
Testability,"Hi @rob-p,. I was finally able to grab some time to try running the beta version you linked (see attached logs). This certainly helped, although I'm still nowhere near a time-frame of ~30min. Here are my results:. The 31-mer running took a bit over an hour and consumed ~17GB of memory. This is about half the running time as the previous version, but approx. the same amount of memory requirement (more on that below). The 17-mer running, took 4.5hrs to complete and consumed ~64GB of memory. This particular running is again, about twice as fast, although the time really depends on the memory limitations I gave it. Since it appears that this version no longer crashes when given less than about 250GB of memory, I also tested with 32G and 16GB of memory, just to see what impact this would have on the times. Those jobs are still running (it's only been about 4hrs as of this writing, I'll update my post if/when they complete). Current logs are showing that they quickly consume all the available memory, but have not yet crashed. I've also got versions with 128-512GB of memory requested (by powers of 2) for comparison. Some random notes: both the 31-mer index experienced about twice as many soft page reclaims with the new/faster version and experienced a few hard page faults (the previous version saw none of the latter). The 17-mer version experienced fewer page reclaims than any of the 31-mer indices and far fewer than with the prior version. Again, a few page faults crept in, but relatively few by percentage and likely not contributing any significant amount of time overall. [index-qacct-17mer.log](https://github.com/COMBINE-lab/salmon/files/4246516/index-qacct-17mer.log); [index-qacct-31mer.log](https://github.com/COMBINE-lab/salmon/files/4246517/index-qacct-31mer.log). **UPDATE**; The 16GB version finished running. It actually only took a little over 4 hours to run, as well. The troubling thing about this job seems to be that, despite having successfully completed, accordi",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-590516702:106,log,logs,106,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-590516702,3,"['log', 'test']","['logs', 'tested']"
Testability,"Hi @rob-p,. Thank you for your reply.; It's a BWA-mem2 aligment with this command:. ```; ""bwa-mem2 mem -M -t {threads} -v 2 {input.reference} {input.reads} | samtools view -q 20 -F 3844 --threads {threads} -Sb -> {output.inter_bam} && ""; ""samtools sort -@ {threads} -O bam {output.inter_bam} > {output.final_bam} && samtools index -@ {threads} {output.final_bam} && samtools flagstat {output.final_bam} > {output.flag} ""; ```; I don't if it's because I use BWA which is a non-splicing aligner? Or because I sorted my BAM file?; I am developing a pipeline and the first step is to test the data with bwa-mem2 with salmon. Is it really a problem to use the results with the MU lib? The 60% may be wrong and reflect alignments that don't exist and ignore good alignments because of the wrong lib?. ### Edit. I tried to do the mapping and the aligment with salmon:; ```. {; ""read_files"": ""[ ../results/trimmed/3373-1_CCGCGGTT-CTAGCGCT-AHV5HLDSXY_L004_R1_trimmed.fastq.gz, ../results/trimmed/3373-1_CCGCGGTT-CTAGCGCT-AHV5HLDSXY_L004_R2_trimmed.fastq.gz]"",; ""expected_format"": ""ISR"",; ""compatible_fragment_ratio"": 1.0,; ""num_compatible_fragments"": 35843765,; ""num_assigned_fragments"": 35843765,; ""num_frags_with_concordant_consistent_mappings"": 29709658,; ""num_frags_with_inconsistent_or_orphan_mappings"": 6209768,; ""strand_mapping_bias"": 0.000008381042727599249,; ""MSF"": 0,; ""OSF"": 0,; ""ISF"": 249,; ""MSR"": 0,; ""OSR"": 0,; ""ISR"": 29709658,; ""SF"": 2520360,; ""SR"": 3689159,; ""MU"": 0,; ""OU"": 0,; ""IU"": 0,; ""U"": 0; }; ```; It's the ISR library but I have only 40% of mapping , it's really confusing.... Best,; Kisekya",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/676#issuecomment-866187414:580,test,test,580,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/676#issuecomment-866187414,1,['test'],['test']
Testability,"Hi @rob-p,. Thanks for the prompt response. I think I may have realised my mistake. It seems like a silly mistake where I wasn't, in fact, using the same version of salmon for the indexing and quantification. . Also yes they would have been running on different machines. I will try to test this and get back to you.; Thanks again",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/345#issuecomment-466130305:286,test,test,286,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/345#issuecomment-466130305,1,['test'],['test']
Testability,"Hi @rob-p,. Thanks for the speedy reply! There are definitely some strange things going on here. I can confirm that the second run (and the others that timed out) didn't produce any information about mapping. The outdir only contained empty subdirs + an empty log file:. ![image](https://user-images.githubusercontent.com/11418858/220816388-0a6272d4-a0c8-4e26-bf9f-15afda61cc44.png). 1. Thanks for the suggestion, I've now been investigating the potential of an index-related issue. Firstly, I downloaded the pre-built salmon index from refgenie using `refgenie pull hg38/salmon_sa_index`. I then ran `salmon quant` using this index and the singularity image of salmon v1.9.0. What, would you know: it worked in about 11 minutes. ```; <truncated>; [2023-02-23 14:46:31.892] [jointLog] [info] Aggregating expressions to gene level; [2023-02-23 14:46:32.452] [jointLog] [info] done; ```. This pre-built index does appear to be decoy-aware:. ```; [2023-02-23 14:38:21.709] [jointLog] [info] Number of decoys : 195; [2023-02-23 14:38:21.709] [jointLog] [info] First decoy index : 177412 ; ```. Secondly, I created a new transcriptome-only salmon index (`singularity run -B /data $SALMON_SIMG salmon index -t genome.transcripts.fa -i salmon_index -k 31`), then ran `salmon quant` again (as above) but using the new transcriptome-only index. Note: 'genome.transcripts.fa' is the transcripts file created during the `nf-core/rnaseq` pipeline. Again, this analysis completed properly in a reasonable time. Seems like there is something very wrong with the 'gentrome.fa' file that's being created by `nf-core/rnaseq`! It's just so odd that _some_ samples would work and others wouldn't. 2. It's definitely worth noting that I originally opted against using `star_salmon` with the following command:. ```; nextflow run nf-core/rnaseq --max_memory 55.GB --fasta /data/reference_genomes/GRCh38/Homo_sapiens.GRCh38.dna_sm.primary_assembly.fa.gz --gtf /data/reference_genomes/GRCh38/Homo_sapiens.GRCh38.106.gtf.gz -",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/830#issuecomment-1441194948:260,log,log,260,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/830#issuecomment-1441194948,1,['log'],['log']
Testability,"Hi @rob-p,. We ran the tests you requested and the main problem remains. The memory load is lower than before, but for some reason `Salmon` (0.8.2) only works in the SGE cluster we have access to when we increase the memory limits (just like 0.7.2). (Edit: we used 0.8.2 to build a new index). I'll ask the cluster admins as they might have a clue on how to proceed. ## Low memory test. ### bash script. ```bash; #!/bin/bash; #$ -cwd; #$ -l mem_free=14G,h_vmem=15G,h_fsize=100G; #$ -N step6-salmon_test3.gsk_phaseII; #$ -pe local 1; #$ -o ./logs/salmon_test3.$TASK_ID.txt; #$ -e ./logs/salmon_test3.$TASK_ID.txt; #$ -t 1-3; #$ -hold_jid pipeline_setup,step4-featCounts-alzheimer.gsk_phaseII; #$ -m e; echo ""**** Job starts ****""; date. echo ""**** JHPCE info ****""; echo ""User: ${USER}""; echo ""Job id: ${JOB_ID}""; echo ""Job name: ${JOB_NAME}""; echo ""Hostname: ${HOSTNAME}""; echo ""Task id: ${TASK_ID}"". FILE1=$(awk 'BEGIN {FS=""\t""} {print $1}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); if [ TRUE == ""TRUE"" ] ; then; FILE2=$(awk 'BEGIN {FS=""\t""} {print $3}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); fi; ID=$(cat /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk '{print $NF}' | awk ""NR==${SGE_TASK_ID}""). mkdir -p /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test3/${ID}. /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant 	-i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts -p 1 -l ISR 	-1 ${FILE1} -2 ${FILE2} 	-o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test3/${ID}. echo ""**** Job ends ****""; date; ```. ### Example log file. ```; **** Job starts ****; Wed Mar 29 14:51:10 EDT 2017; **** JHPCE info ****; User: lcollado; Job id: 110315; Job name: step6-salmon_test3.gsk_phaseII; Hostname: compute-061; Task id: ; Version Info: This is the most recen",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965:23,test,tests,23,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965,4,"['log', 'test']","['logs', 'test', 'tests']"
Testability,"Hi @rob-p,. i have pasted the three .json file data below. The way i installed was by first installing boost (./bootstrap.sh --prefix=/usr/local), and setting up boost. I did install clang 3.9 too. Then i did use ; cmake -DBOOST_ROOT=/usr/local, make and sudo make install and make test. Then i copied the executable made in bin to /usr/local/bin as sudo. May be it's me using sudo make install which is goofing stuff.. Let me try to reinstall without ""sudo"". I have used salmon 0.8.1, with no problems on another machine. So, on this machine this is a fresh install. I do think there is a script which does fetch Rapmap.. Thanks. Sudeep. #header.json. ""value0"": {; ""IndexType"": 1,; ""IndexVersion"": ""q5"",; ""UsesKmers"": true,; ""KmerLen"": 31,; ""BigSA"": false,; ""PerfectHash"": false,; ""SeqHash"": ""bc7ce7a64f79aeb355818ffc5050bf682f281160738498d11dbc3330b67c4889"",; ""NameHash"": ""3843f236fc87b02e5c477daa29053725d376d8725c10ec23ee2225e8fab6326e""; }; }. #refino.json; {; ""ReferenceFiles"": [; ""Equus_caballus.EquCab2.cds.all.fa""; ]; }. #versioninfo.json. {; ""indexVersion"": 2,; ""hasAuxIndex"": false,; ""auxKmerLength"": 31,; ""indexType"": 1; }",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/135#issuecomment-299885992:282,test,test,282,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/135#issuecomment-299885992,1,['test'],['test']
Testability,"Hi @rob-p,; I am aware of that, but we were off on bwa anyway. I decided to follow your advice and used STAR with this order:. ` ""STAR --runThreadN {threads} --runMode alignReads --genomeDir {input.ref} --readFilesIn {input.fq1} {input.fq2} --readFilesCommand zcat --outSAMtype BAM Unsorted SortedByCoordinate --quantMode TranscriptomeSAM GeneCounts --outFileNamePrefix {output} --outStd Log {log} ""`. I then got this final.out:; ```. Started job on |	Jul 05 07:51:09; Started mapping on |	Jul 05 07:51:13; Finished on |	Jul 05 10:01:38; Mapping speed, Million of reads per hour |	39.36. Number of input reads |	85547657; Average input read length |	298; UNIQUE READS:; Uniquely mapped reads number |	36980651; Uniquely mapped reads % |	43.23%; Average mapped length |	283.47; Number of splices: Total |	943061; Number of splices: Annotated (sjdb) |	0; Number of splices: GT/AG |	411198; Number of splices: GC/AG |	39101; Number of splices: AT/AC |	13983; Number of splices: Non-canonical |	478779; Mismatch rate per base, % |	0.56%; Deletion rate per base |	0.03%; Deletion average length |	4.89; Insertion rate per base |	0.03%; Insertion average length |	4.88; MULTI-MAPPING READS:; Number of reads mapped to multiple loci |	1029261; % of reads mapped to multiple loci |	1.20%; Number of reads mapped to too many loci |	565; % of reads mapped to too many loci |	0.00%; UNMAPPED READS:; Number of reads unmapped: too many mismatches |	0; % of reads unmapped: too many mismatches |	0.00%; Number of reads unmapped: too short |	47533174; % of reads unmapped: too short |	55.56%; Number of reads unmapped: other |	4006; % of reads unmapped: other |	0.00%; CHIMERIC READS:; Number of chimeric reads |	0; % of chimeric reads |	0.00%. ```. I filtered it by samtools -f 2 -F 3840 . and Salmon gave me this result which is still very weak: 24323638 counts. So I decided to reduce the parameters as indicated in this link: https://github.com/alexdobin/STAR/issues/169; Because I trimmed my sequence and some ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/676#issuecomment-874540664:388,Log,Log,388,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/676#issuecomment-874540664,3,"['Log', 'log']","['Log', 'log']"
Testability,"Hi @rob-p. I'm using a SGE-based cluster. The disk I'm writing to is a networked disk that is mounted via NFS on the machines the cluster runs on. I've attached the output of running `qconf -sconf`, which provides details on how the cluster has been configured (I've edited out some lines about the admin e-mails, etc.). I'm not sure how useful much of this information is. A lot of it has to do with scheduling of jobs -- how many jobs/resources users can attempt to claim, that kind of thing. Let me know if there's something else that would be more useful in this context. I've also attached the log that was generated by the indexing run itself (just for the 17mer index), just in case. I can say one thing from having inspected the logs of these things failing a number of times before I finally caved and started giving it insane amounts of memory: by far the longest time and (most likely) the biggest resource hog is between the first and second pass. Even with only 16GB, it manages to complete the first pass (it still takes quite a while, though):. ```; Pass	Filling	Filtering; 1	718	3236	; 2	1839	237; ```. [qconf-sconf.txt](https://github.com/COMBINE-lab/salmon/files/4172585/qconf-sconf.txt); [index_GRCm38_GENCODE_M23_PRI_17mer.log.txt](https://github.com/COMBINE-lab/salmon/files/4172594/index_GRCm38_GENCODE_M23_PRI_17mer.log.txt). EDIT: Oh, I should also probably say, that I'm only seeing this slowdown on index creation. I'm sure that was implied, but I just wanted to be clear that at the moment, I'm happy enough to let the index build for a few hours every once in a while. I'm still saving huge amounts of mapping time, relative to ""full"" aligners.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-583567362:599,log,log,599,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-583567362,8,['log'],"['log', 'logs']"
Testability,"Hi @ryanpe13002,. The bootstrap has no effect on the main `quant.sf` file (that is always the result of the main maximum likelihood estimate). All bootstrap samples are written to the `bootstraps.gz` file. If you load your data with the `fishpond` package in `R`, you can request to load the bootstraps to investigate them. Otherwise, if you use an uncertainty aware tool like [`swish`](https://bioconductor.org/packages/release/bioc/vignettes/fishpond/inst/doc/swish.html) for differential testing, it will make use of the bootstraps automatically to account for inferential uncertainty when performing differential testing. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/818#issuecomment-1354070141:491,test,testing,491,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/818#issuecomment-1354070141,2,['test'],['testing']
Testability,"Hi @s1corley,. Congratulations on your publication! The `--noLengthCorrection` flag has been around for a long time (e.g. where it is suggested in the post to which @tamuanand [links](https://groups.google.com/forum/#!msg/sailfish-users/VIfqBwgF6xQ/fw-rgC_kAwAJ)). However, given our limited access to QuantSeq and our limited (student) bandwidth to do extensive testing on alternative tech, we have kept this flag marked as experimental. As I mention above, it was introduced since, _conceptually_, the QuantSeq protocol should not exhibit a length effect and so the one may not wish to account for the length when determining assignment probabilities during the variational Bayesian optimization. However, the empirical testing of this has been limited. Now that your paper is published, and contains what look to be some _very through_ assessment methodologies, we may be able to look into this and determine if there is anything we can do to, perhaps, optimize salmon even more for accurate quantification from the QuantSeq protocol. We would welcome any suggestions or feedback you may have. Congratulations again on the paper!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565474848:363,test,testing,363,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565474848,4,['test'],['testing']
Testability,"Hi @schelhorn,. Yes; we are _actively_ looking at fusion prediction based on quasi-mapping. The initial results are promising, but we're still working on improving and refining the method. I'll be sure to let you know when we have something that is ready to test :). Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/52#issuecomment-202593692:258,test,test,258,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/52#issuecomment-202593692,1,['test'],['test']
Testability,"Hi @seanken,. Thank you for reporting this. I agree this error message should always show up. My guess is that this is related to the fact that the error is reported through the asynchronous logger, which is notoriously picky about how it must be torn down to avoid dropping messages on atypical (non-zero) program exit. I'll see if I can make this one show up reliably. By the way, do you have a small pair of FASTQ files that will trigger this error?. Thanks,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/736#issuecomment-1018119606:191,log,logger,191,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/736#issuecomment-1018119606,1,['log'],['logger']
Testability,"Hi @shalercr,. Thanks for reporting back! I agree that there are some challenging reads in these samples that are likely at the root of the slightly-longer-than-normal runtime. If you could upload the quant dir for this sample (that contains the logs), that would be useful. We (specifically, my student @mohsenzakeri, who is one of the main developers of the new selective-alignment algorithm) can poke around a bit to see if there is anything strange going on that can be characterized, but it might just be an inherent property of samples with very repetitive reads. Regardless, we'll be happy to take a look. Thanks!. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-645122746:246,log,logs,246,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-645122746,1,['log'],['logs']
Testability,"Hi @sjackman , Thanks for you question. It is indeed a good observation to use salmon for combining separate CB and read-sequence fastq files.; Having said that, we have designed alevin to work with, and tested it on 10x-chromium `cellranger` pipeline which itself has a feature similar to mentioned above by you (enabled by flag `--dumpfq`). This feature takes in two separate files: one with CB+UMI and another with read-sequence, and performs initial whitelisting (knee based , more intelligent whitelisting happens downstream and needs deduplicated UMI counts or one can just optionally provide external whitelist), error corrects the CB, attaches it to the header (although not with tag `BX:Z`) of the read-sequence in the second file, and dumps it to the standard out. I might have to read a bit about `longranger` and its `FASTQ` format, but if you are familiar with the `longranger` pipeline and are sure that it uses 16+10 (CB+UMI) in one file and read-sequence in the second file, then I think you are good to try alevin with `--dumpfq` flag. Let us know how it goes and if you face any problem. . Note: Just put an extra flag `--noQuant` so that alevin knows to stop after dumping the fastq otherwise it will start performing downstream tasks.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/233#issuecomment-395174284:204,test,tested,204,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/233#issuecomment-395174284,1,['test'],['tested']
Testability,"Hi @sudeep71 ,. Can you try `--decoys` I think there is one `-` is missing from the command line argument or just use `-d`. If this doesn't work can you share the logs ?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/389#issuecomment-506494653:163,log,logs,163,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/389#issuecomment-506494653,1,['log'],['logs']
Testability,"Hi @summerrfair,. So, your BAM file looks like a SAM file (which is still OK), *but*, it's missing a header. I'm attaching here a sample SAM file you can use with the test data from the repository. Note, this SAM file is zipped (GitHub made me zip it before attaching it, so unzip it before you process it):. [sample_alignments.sam.zip](https://github.com/COMBINE-lab/salmon/files/4510467/sample_alignments.sam.zip). Once you've unzipped this file, you can run salmon as:. ```~bash; ./bin/salmon quant -l IU -t transcripts.fa -a sample_alignments.sam -o quant_directory; ```. where the `transcripts.fa` is the sample transcriptome distributed with salmon that you can get by unzipping this file : [transcripts.fasta.zip](https://github.com/COMBINE-lab/salmon/files/4510488/transcripts.fasta.zip). When I run this with the latest salmon, I get the following output:. ```; # salmon (alignment-based) v1.2.0; # [ program ] => salmon; # [ command ] => quant; # [ libType ] => { IU }; # [ alignments ] => { sample_alignments.sam }; # [ targets ] => { ../sample_data/transcripts.fasta }; # [ output ] => { sample_aln_quant }; Logs will be written to sample_aln_quant/logs; Library format { type:paired end, relative orientation:inward, strandedness:unstranded }; [2020-04-21 10:11:42.553] [jointLog] [info] setting maxHashResizeThreads to 8; [2020-04-21 10:11:42.553] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2020-04-21 10:11:42.553] [jointLog] [info] numQuantThreads = 4; parseThreads = 4; Checking that provided alignment files have consistent headers . . . done; Populating targets from aln = ""sample_alignments.sam"", fasta = ""../sample_data/transcripts.fasta"" . . .done; [2020-04-21 10:11:43.180] [jointLog] [info] replaced 0 non-ACGT nucleotides with random nucleotides. processed 0 reads in current round; killing thread 3 . . . done. Freeing memory used by read queue . . . 00; Joined parsing thread . . . ""sample_alignments.sam""; Cl",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/511#issuecomment-617206094:167,test,test,167,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/511#issuecomment-617206094,1,['test'],['test']
Testability,"Hi @tamuanand,. Ok, it seems something simple with the preparation of the decoys.txt file. I'm looking into it. If you watch the log, you see the following output before the (intentional exit with status code 1):. ```; [2020-04-14 09:44:12.991] [puff::index::jointLog] [critical] The decoy file contained the names of 955 decoy sequences, but 953 were matched by sequences in the reference file provided. To prevent unintentional errors downstream, please ensure that the decoy file exactly matches with the fasta file that is being indexed.; [2020-04-14 09:44:13.304] [puff::index::jointLog] [error] The fixFasta phase failed with exit code 1; Command exited with non-zero status 1; 56.66user 9.14system 1:04.69elapsed 101%CPU (0avgtext+0avgdata 6902936maxresident)k; 3792inputs+16outputs (30major+3629051minor)pagefaults 0swaps; ```. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/505#issuecomment-613451792:129,log,log,129,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/505#issuecomment-613451792,2,['log'],['log']
Testability,"Hi @tamuanand,. Sure; is there anything specific about bbduk and bbmap for quality / adapter trimming that you think would be provided beyond or in addition to what fastp provides? Also, we have a beta implementation of soft-clipping and are looking for a wide net of testing data. Any suggestions to that end would be welcome!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597344801:268,test,testing,268,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597344801,1,['test'],['testing']
Testability,"Hi @tamuanand,. Thanks again for your detailed questions and thoughts on this issue. Just to follow-up / expand a bit on what @k3yavi has said (and to answer your other question): Yes, one would imagine that, given the details of the QuantSeq protocol, turning off length correction would make the most sense. The main reason this flag is listed as _experimental_, is simply that it was designed based on the expected characteristics of the protocol. Conceptually, the protocol is performing tagged-end sequencing, and so there should be little-to-no length effect. However, since we haven't done extensive internal validation on QuantSeq data, we have left this flag as experimental until it is further tested by ourselves or others. > Also @rob-p , weren't you referring to the RSEM caveat with QuantSeq data analysis wherein one cannot ask RSEM to disable lengthCorrection and hence the count statistics might be misleading?. Correct; as far as we are aware, there is no way to disable the built-in length-dependent assumptions of RSEM. One could use the `--estimate-rspd` flag to allow learning of a non-uniform read distribution (the equivalent of `--posBias` in salmon), though it's unclear / unlikely if this would be as effective as fully disabling the length correction for this type of tagged-end data. If you have any good empirical assessment mechanism for QuantSeq data, and a chance to test out these different salmon options, we'd be happy to get feedback and discuss details further!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565285540:704,test,tested,704,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565285540,4,['test'],"['test', 'tested']"
Testability,"Hi @taylorreiter,. First thing first — this sat for way too long before I got to it, so apologies for that!. So, the reason that they don’t show up in the unmapped.txt file is that is that reads mapped to decoys occupy a sort of “no man’s land” with respect to their mapping status. That is, they *do* map to the index, but just not to a valid target within the index. In other words, if you write a BAM output from `salmon`, the decoy aligned reads will actually show up there, with the information about the decoy to which they are aligned. This is because they are mapped to something in the index, it just happens to be a decoy rather than a “valid target”. However, the output BAM files are big, so I absolutely understand the desire to have them appear in the unmapped names list as well — it's a much smaller and easier thing to go through. I think the right thing to handle this would be to add a specific code/category to the set of unmapped codes used in the `unmapped.txt` file, to designate this is read best mapped to a decoy (rather than that this read is completely unmapped to the index). This shouldn't be too hard to do — I will try to find a few cycles to implement and test it. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/748#issuecomment-1098426758:1189,test,test,1189,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/748#issuecomment-1098426758,1,['test'],['test']
Testability,"Hi @teshomem,. If you want to proceed with transcript-level differential expression, _all transcripts are relevant_. That is, the relevant tools (e.g. DESeq2, limma-voom, Sleuth, etc.) will expect to be provided with _all_ quantified isoforms for each gene. They will then automatically apply their own filtering criteria to determine which transcripts to actually test for DE. . If you want to proceed with DE at the gene level (and hence want to aggregate the quantification information from the level of transcripts to genes), the easiest option is to use the [tximport](http://bioconductor.org/packages/release/bioc/html/tximport.html) package. It can import all of the quantifications from multiple runs of Salmon, aggregate them to the gene level, and produce a count matrix that can then be used with traditional count-based gene-level DE tools. I would recommend the pipeline Salmon => tximport => DESeq2 for gene-level DE analysis. Finally, the best place for questions like this, that don't have to do with a specific bug or feature request for the Salmon software, is the [Google user group](https://groups.google.com/forum/#!forum/sailfish-users). This way, other users will be more likely to provide you with feedback and help answer your questions.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/154#issuecomment-329974141:365,test,test,365,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/154#issuecomment-329974141,2,['test'],['test']
Testability,"Hi @tharvesh — The error suggests that memory allocation failed when trying to build the suffix array. I'm guessing from what I can tell from the log (e.g. the fact that the 64-bit index is being invoked, suggesting the input contains > 2^31 nucleotides), that you actually tried to build an index on the GENCODE **genome** plus a set of extra transcripts. Salmon (unlike Cufflinks, but like RSEM, TIGAR, eXpress, etc.) should be used with the **transcriptome**, not the **genome** of the target organism. That is, if you want to use GENCODE (say, in human), you should be indexing either (ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_24/gencode.v24.transcripts.fa.gz) or (ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_24/gencode.v24.pc_transcripts.fa.gz), not e.g. (ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_24/GRCh38.primary_assembly.genome.fa.gz).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/39#issuecomment-176783177:146,log,log,146,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/39#issuecomment-176783177,1,['log'],['log']
Testability,"Hi @tillea and @nileshpatra, thanks for the report (and ping). Can you point me to a Docker / Singularity container of the relevant Debian build so I can try and reproduce locally? This will make debugging much easier. For example, I am unable to reproduce this issue building the latest release from the `master` branch using the latest [official Debian image](https://hub.docker.com/_/debian). In particular, release 1.10 addresses a rare (but stubborn) segfault that certainly was present in 1.9. However, the fix for this is in the corresponding tagged release of pufferfish, which is pulled in by the build script when salmon is built.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1462538853:446,stub,stubborn,446,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1462538853,1,['stub'],['stubborn']
Testability,"Hi @tillea and @nileshpatra,. Ok, I dug deeper and found out what's going on. The culprit is, in fact, `libcereal`. The problem is that `libcereal` bumped patch versions only since the version corresponding to the headers included in `pufferfish`, but their changes are not, in fact, backwards compatible! This lead to a version mismatch between the headers used in `pufferfish` and the headers found from the installed package, ultimately resulting in an assertion failure in `rapidjson` (which cereal is using) and a segfault. On the plus side, this was relatively easy to fix by bumping the included cereal headers in pufferfish. I also updated the `Findcereal.cmake` module and added a version constraint so that we now require the new version (1.3.2). This is now tagged and released as `salmon 1.10.1`. Please give that a go when you have a chance. I'll note that, before this is added upstream in debian, I'd still advocate for fixing the `libstaden` package to update to the new version. I'd also recommend moving to dependencies like the ones I've included above to remove some really antiquated dependencies that salmon no longer requires but are still being pulled in. Thanks!; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1465096711:456,assert,assertion,456,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1465096711,1,['assert'],['assertion']
Testability,"Hi @tillea,. It seems this is exactly the problem. The build deps here are not quite correct. There are dependencies that salmon no longer has, and some of the dependencies it does have are out of date and can't be used from upstream (e.g. libstaden in the latest version, among others). On the bright side, it's not the dynamic linking alone that is problematic. The following works fine on my end:. ```{bash}; $ docker pull debian:testing; $ docker run -it debian:testing; $ echo ""deb-src http://deb.debian.org/debian unstable main"" > /etc/apt/sources.list.d/10-debsrc.list; $ apt-get update; $ apt-get upgrade; $ apt-get install build-essential git libboost-all-dev liblzma-dev libbz2-dev cmake zlib1g-dev curl unzip wget libcurl4-openssl-dev libtbb-dev libtbb12 liblzma-dev libjemalloc2 pkg-config libgff-dev; $ wget https://github.com/COMBINE-lab/salmon/archive/refs/tags/v1.10.0.tar.gz; $ tar xaf v1.10.0.tar.gz; $ cd salmon-1.10.0; $ mkdir build && cd build; $ cmake -DCMAKE_BUILD_TYPE=Release -DUSE_SHARED_LIBS=TRUE -DBZIP2_LIBRARIES=-lbz2 -DBZIP2_INCLUDE_DIR=/usr/include -DLIBLZMA_INCLUDE_DIR=/usr/include/ -DLIBLZMA_LIBRARY=lzma -DCMAKE_MODULE_PATH=/usr/share/cmake/Modules -DTBB_WILL_RECONFIGURE=FALSE -DBOOST_WILL_RECONFIGURE=FALSE ..; $ make -j8; $ make install; $ make test; ```. This is preferring dynamic linking, and the resulting installed executable runs fine without a segfault. Can you try this on your end? Then the thing to do may be to find what is discordant between the packages I install above and what gets pulled in by `apt build-dep salmon`. Thanks,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464182279:433,test,testing,433,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464182279,3,['test'],"['test', 'testing']"
Testability,"Hi @tillea,. So I went through the list of deps pulled in by `apt build-dep salmon` and the minimal set I gave above. I tried to make the smallest number of changes I could to the `apt build-dep salmon` list while also removing things that are clearly outdated (we no longer use jellyfish, rapmap, etc. and we use the header-only version of spdlog). As a result I came up with this list of dependencies. The offending dependency seems to be `libcereal-dev`. Specifically, I was able to install just this list of dependencies (minus `libcereal-dev`) atop a clean `debian:testing` and get a working version where the only thing downloaded from the internet was the appropriate version of the pufferfish files grabbed by `fetchPufferfish.sh` in the `1.10.0` release. Once I installed `libcereal-dev` with `apt-get install`, and rebuilt, then I got the segfault mentioned at the top of this issue. So, it seems that we either have to let `salmon` build it's own libcereal, or figure out what the problem is with the library upstream. Please let me know if this you observe this same behavior as well (also @nileshpatra may want to try this out). If so, perhaps we can get `libstaden` updated upstream, and then use this as the new dep list for `salmon`. I installed these deps with a simple `xargs apt-get install -y < deps_sorted_updated.txt` (without `libcereal-dev` for the working version, and with it included, as below, for the segfault). Best,; Rob. [deps_sorted_updated.txt](https://github.com/COMBINE-lab/salmon/files/10949233/deps_sorted_updated.txt)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464986376:570,test,testing,570,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464986376,2,['test'],['testing']
Testability,"Hi @tomsing1,. Thanks for following up on this --- I was scratching my head about why multiple libraries might be causing an issue. Both `--seqBias` and `--gcBias` are relatively new features, and have definitely undergone more testing under the ""quasi-mapping"" codepath than the alignment-based codepath (though it's passed our internal regression tests on both). That being said, bias correction is equally valid regardless of whether you're using quasi-mapping or quantifying from a bam file directly. I'd be happy to take a look if you can provide a small example (a subset of the reads in the bam file?) that triggers the behavior. One thought might be that, for some reason, positions in the bam file could disagree with what's provided in the corresponding fasta. However, that's just a guess and I'd have to try and debug the segfault once I can reproduce it. Thanks again for the detailed error report and the update!. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/104#issuecomment-261738431:228,test,testing,228,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/104#issuecomment-261738431,2,['test'],"['testing', 'tests']"
Testability,"Hi @uros-sipetic!. Unfortunately, as you suggest, there really is no good way to infer the fragment length distribution from only single-end reads. Rather, this flag determines how the conditional probability of single-end fragments near the beginning (if in the rc orientation) or end (if in the forward orientation) of the transcript are determined. A single-end read does not have any known fragment length. But we do know that e.g. fragments very close to the end or beginning of the transcript are rather unlikely. In this case, we can integrate (sum) over all possibilities to assign a conditional probability. This is what salmon does. For a single-end read (assume forward orientation for simplicity) at position i on a transcript of length n, we consider the conditional fragment length probability to be given by F_n(n-i), where f_n is the conditional fragment length distribution conditioned on the transcript length (maximum observable length) being n and F_n is the cumulative distribution function of f_n. Intuitively, this means that fragments very close to transcript ends will get a smaller conditional probability, while those farther from the end will get larger conditional probabilities. The `--noSingleFragProb` flag simply turns off this conditional probability all together. It is _not_ recommended to disable the single-end fragment length probability modeling. We have evidence from testing that it improves quantification accuracy. Thus, I would suggest _not_ setting the `--noSingleFragProb` flag. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/575#issuecomment-711061553:1409,test,testing,1409,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/575#issuecomment-711061553,2,['test'],['testing']
Testability,"Hi @uros-sipetic,. Thanks for reporting this. I can't reproduce the issue that, when I pass an argument to `writeMappings`, the SAM data is still written to stdout. Could you tell me if you're using the pre-compiled binary, and if so, what type of system you're running on? However, I can produce a different issue which may be related (and might be an issue with the logic for checking if a directory exists). Can you try the following command in your case and tell me what happens?. `salmon quant -i ucsc.hg19.transcriptome_salmon_index -1 reads.pe_1.fastq -2 reads.pe_2.fastq --writeMappings test_output/mappings_info -o test_output -l A -p 2`. also, you should be able to do `--writeMappings ./mappings_info`. The problem appears to be with the code that checks if the parent path where the mapping info is to be written exists or not:. ``` c++; // get the parent directory; bfs::path qmDir = boost::filesystem::path(sopt.qmFileName).parent_path();; // if it's not already a directory that exists; bool qmDirSuccess = boost::filesystem::is_directory(qmDir);; ```. The issue is that `sopt.qmFileName` need not be a ""canonical"" path, so that the call to parent_path might return the empty string, which results in an exception being thrown (and, at least caught and reported) when boost tries to create the parent directory """". The solution is to canonicalize the path, which I'm doing now. However, if you provide a qualified path (either fully-qualified or even relatively qualified), then it should work. Specifically, if I provide a non-empty argument to `--writeMappings` I don't get any output on stdout.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/86#issuecomment-244773065:368,log,logic,368,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/86#issuecomment-244773065,1,['log'],['logic']
Testability,"Hi @vals,. So there was a very subtle bug in `useFSPD` that would (in a very non-reproducible manner) trigger such a segfault. It was related to some very tricky locking behavior. However, the manner in which `useFSPD` corrected for position specific bias isn't actually compatible with our new sequence-specific and fragment-gc bias models. Thus, I've deprecated `useFSPD`. The replacement is the flag `posBias`. This models the same type of positional bias, but does so in a way that is compatible with our other bias models. It also doesn't rely on the tricky threading behavior, so it should be more stable. Unlike sequence-specific and fragment-gc bias, however, the `posBias` option is still _experimental_ in the 0.7.0 release. However, we have been testing it internally, and I'd be very grateful for your feedback if you have a chance to try it out. Assuming things look good, we can promote it from experimental in the next release.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/64#issuecomment-241234373:757,test,testing,757,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/64#issuecomment-241234373,2,['test'],['testing']
Testability,"Hi @vals,. This is very interesting, as we've been doing quite a bit of testing and (to the contrary) have found v0.4.0 to perform substantially _better_ than v0.3.x. Out of curiosity, could you check how v0.4.0 performs _without_ `--useVBOpt`? Obviously, if you continue to see this regression, I'll be happy to try and dig down deeper, but I might need you to provide some testing data. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/6#issuecomment-111538228:72,test,testing,72,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/6#issuecomment-111538228,2,['test'],['testing']
Testability,"Hi @vals,; I'm still trying to track down this bug and figure out why it occurred in the first place. I've been working on a different way to deal with reclaiming the resources that caused the problem before and was wondering if you'd be willing to test the attached binary to see if it still segfaults on your data. ; Thanks! [SalmonBeta-0.6.1_DebianSqueeze.tar.gz](https://github.com/COMBINE-lab/salmon/files/87914/SalmonBeta-0.6.1_DebianSqueeze.tar.gz)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-171038135:249,test,test,249,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-171038135,1,['test'],['test']
Testability,"Hi @vertesy ,. Thanks for asking the very interesting question.; I'd say the answer might depend on what's your downstream use case. Traditionally, no quantification pipeline, in my knowledge, has used the pre-mRNA counts alone to bump up the gene counts, however, recent method of estimating RNA-velocity does utilizes the intronic counts for extracting the ratio of spliced/unspliced counts. If you are interested in disjoint signals (gene count matrix) for spliced and unspliced molecules you can use the recent scheme of decoy indexing from our latest [preprint](https://www.biorxiv.org/content/10.1101/657874v2). We (mostly @csoneson) have been testing alevin with following scheme for generating spliced and unspliced counts. 1.) Spliced Counts: Index transcriptome w/ pre-mRNA sequence as the decoys.; 2) Unspliced Counts: Index pre-mRNA sequence w/ transcriptome as the decoys. The third case is a little tricky because if you index both pre-mRNA and transcriptome, due to relatively longer length of pre-mRNA sequence compared to transcripts it might end-up biasing the UMI deduplication algorithm towards unspliced counts. To summarize, the best way to have an additive spliced and unspliced counts is still an open area of research.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/450#issuecomment-555136444:650,test,testing,650,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/450#issuecomment-555136444,1,['test'],['testing']
Testability,"Hi @vivekabarath,. The final v0.12.0 has been released and is available via both the release page on github and via bioonda, so I recommend you use the official version. Regarding your specific question, the failure of the unit tests should not be a problem and doesn't affect salmon. However there was previously an issue that could cause the `make test` to fail if `make install` was not run first. This should be resolved in the latest release as well. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/315#issuecomment-444971569:228,test,tests,228,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/315#issuecomment-444971569,2,['test'],"['test', 'tests']"
Testability,"Hi @zhangchipku,. The referenced commit should fix this issue. I've tested `--incompatPrior 0` in alignment and read-based mode with and without VB. The bug was the result of a double-precision floating point comparison close to machine precision returning an unexpected result. The behavior has been fixed (and modified). I'm still planning to do more testing, but feel free to test this out if you can build from source (on the develop branch). --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/78#issuecomment-241225575:68,test,tested,68,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/78#issuecomment-241225575,3,['test'],"['test', 'tested', 'testing']"
Testability,"Hi All,. I downloaded the Salmon index as well as `tgMap` from refgenie for the mm10 genome using the following. ```; ## get index and tgmap from refgenie; wget -O mm10SalmonIndex.gz http://refgenomes.databio.org/v3/assets/archive/0f10d83b1050c08dd53189986f60970b92a315aa7a16a6f1/salmon_sa_index; gunzip mm10SalmonIndex.gz. wget -O mm10tgMap.gz http://refgenomes.databio.org/v3/assets/archive/0f10d83b1050c08dd53189986f60970b92a315aa7a16a6f1/tgMap; gunzip mm10tgMap.gz; ```. The index is surprisingly large, though, as compared to using `salmon index` on just the mm10 transcripts. In addition, when I try using it with `alevin`, it is returning the following error. ```; (base) Koens-MacBook-Pro:data koenvandenberge$ /Applications/salmon/bin/salmon alevin -l ISR \; > -1 SRR1853178_1.fq.gz \; > -2 SRR1853178_2.fq.gz \; > --dropseq \; > -i mm10SalmonIndex \; > -p 1 \; > -o SRR1853178_out \; > --tgMap mm10tgMap; Version Server Response: Not Found; Logs will be written to SRR1853178_out/logs; [2021-11-14 21:21:46.623] [jointLog] [info] setting maxHashResizeThreads to 1; [2021-11-14 21:21:46.623] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2021-11-14 21:21:46.623] [jointLog] [info] The --mimicBT2, --mimicStrictBT2 and --hardFilter flags imply mapping validation (--validateMappings). Enabling mapping validation.; [2021-11-14 21:21:46.623] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2021-11-14 21:21:46.623] [jointLog] [info] The use of range-factorized equivalence classes does not make sense in conjunction with --hardFilter. Disabling range-factorized equivalence classes. ; [2021-11-14 21:21:46.623] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.; [2021-11-14 21:21:46.623] [jointLog] [info] Using default value of 0.87 for minScoreFraction in Alevin; Using default value of 0.6 for consensusSlack ",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/722:951,Log,Logs,951,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/722,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"Hi Andrea,. The bias correction time depends on the number of expressed transcripts. There is a flag to speed it up `--biasSpeedSamp`. It takes a value by which to downsample the fragment length pmf for bias modeling. The larger this number, the faster bias correction will become. The default is 1, and is super conservative (we are probably going to make the default 5 in the next release because it is much faster with no real difference in modeling quality). In fact, values up to at least 10 seem to work quite well with respect to the baseline. So, I'd recommend testing this parameter on a sample until you are happy with the speed, and then using that on all samples. Let me know how it goes, and if my description makes sense. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/201#issuecomment-369766969:569,test,testing,569,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/201#issuecomment-369766969,1,['test'],['testing']
Testability,"Hi Avi,. Here is the salmon log from one of my PE libraries. There are only 12; libraries for each in the directory, which is why I got confused when it; said 13. I will try putting in all of the file names and let you know how; it goes. Thank you for all of your help. Sara. [2019-07-29 15:58:39.034] [jointLog] [info] Fragment incompatibility prior; below threshold. Incompatible fragments will be ignored.; [2019-07-29 15:58:39.034] [jointLog] [info] Usage of --validateMappings; implies use of minScoreFraction. Since not explicitly specified, it is; being set to 0.65; [2019-07-29 15:58:39.034] [jointLog] [info] Usage of --validateMappings,; without --hardFilter implies use of range factorization.; rangeFactorizationBins is being set to 4; [2019-07-29 15:58:39.034] [jointLog] [info] Usage of --validateMappings; implies a default consensus slack of 0.2. Setting consensusSlack to 0.2.; [2019-07-29 15:58:39.034] [jointLog] [info] parsing read library format; [2019-07-29 15:58:39.034] [jointLog] [error] Failed to successfully parse; any complete read libraries. Please make sure you provided arguments; properly to -1, -2 (for paired-end libraries) or -r (for single-end; libraries), and that the library format option (-l) *comes before* the read; libraries. On Mon, Jul 29, 2019 at 4:06 PM Avi Srivastava <notifications@github.com>; wrote:. > Oh Sorry about that what I meant was the salmon.log file or the the; > meta-info.json file created by salmon in the output directory. You can; > check what files salmon is detecting it seems there are 12 files in the; > mate1 and 13 files in the mate2. Can you confirm there are 13 pairs of file; > in that directory and their regex is same as you are using ? Can you also; > try putting the names of the file instead * as regex ?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/COMBINE-lab/salmon/issues/408?email_source=notifications&email_token=AEHDXAA5DH",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408#issuecomment-516514620:28,log,log,28,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408#issuecomment-516514620,1,['log'],['log']
Testability,"Hi Avi,. Thanks for the detailed reply. I was able to run it (see logs below), but I had to use `ISR`, not `ISF` to get it to work. I also had to add these two settings as well; `--freqThreshold 1 --lowRegionMinNumBarcodes 100`. . I am not sure why the `ISF` option didn't work, but probably it has something to do with the guide sequences I was provided. At any rate, I have a few other questions I hope you can help me answer. 1. Why does increasing --maxNumBarcodes to 200000 results in no barcodes getting corrected? (See log for Run 2 below). What is the rationale for the current default of 100000? ; 2. For the downstream analysis of such data, I usually work with both the read and UMI counts, but `quants_mat.gz` only contains the UMI counts. Can Alevin a produce a matrix of read counts as well. It would be a great feature to add. For now, what is easiest way to get the cell x feature matrix of read counts if I use the ` --dumpEq` or `--dumpBfh` flags? Can *tximport* be used for this or do I need to use the Python [parser]([https://github.com/k3yavi/vpolo/blob/master/vpolo/alevin/parser.pyl]) first?. I will be sending you some reads from the experiments for unit testing shortly. Thanks!. Run 1: `salmon alevin -l ISR --citeseq --barcodeLength 16 --umiLength 10 --end 5 --featureStart 19 --featureLength 21 --maxNumBarcodes 100000 --freqThreshold 1 --lowRegionMinNumBarcodes 100`. > 20-06-04 12:24:47.610] [alevinLog] [info] set CITE-seq minScoreFraction parameter to : 0.797619; > [2020-06-04 12:24:47.610] [alevinLog] [info] Found 64 transcripts(+0 decoys, +0 short and +0 duplicate names in the index); > [2020-06-04 12:24:47.610] [alevinLog] [info] Filled with 64 txp to gene entries ; > [2020-06-04 12:24:47.610] [alevinLog] [info] Found all transcripts to gene mappings; > [2020-06-04 12:24:47.616] [alevinLog] [info] Processing barcodes files (if Present) ; > ; > [2020-06-04 12:26:04.322] [alevinLog] [info] Done barcode density calculation.; > [2020-06-04 12:26:04.322] [alev",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638991199:66,log,logs,66,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638991199,4,['log'],"['log', 'logs']"
Testability,"Hi Bill,. One thing I noticed is that your log says :; ```; [2018-10-12 18:13:10.808] [jointLog] [warning] Removed 7582 transcripts that were sequence duplicates of indexed transcripts.; ```. while my run said:. ```; [2018-10-12 17:29:14.651] [jointLog] [warning] Removed 11851 transcripts that were sequence duplicates of indexed transcripts.; ```. that's a non-trivial difference in number. My run was from the fasta file using *this* link (ftp://ftp.ensembl.org/pub/release-94/fasta/homo_sapiens/cdna/Homo_sapiens.GRCh38.cdna.all.fa.gz). Was yours the same? Digging into the _other_ version now to see if I can find anything.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/301#issuecomment-429503523:43,log,log,43,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/301#issuecomment-429503523,1,['log'],['log']
Testability,"Hi Bill,. Strange indeed! Can you share the log salmon made during indexing and the `duplicate_clusters.tsv` file you do get?. Thanks,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/301#issuecomment-429502024:44,log,log,44,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/301#issuecomment-429502024,1,['log'],['log']
Testability,"Hi Brian,. In general, I would argue that one should be cautious with removing PCR duplicates in RNA-seq data (unless you are dealing with reads with UMI tags). This is because reads that align to the same reference position can easily have come from alternative transcripts sharing the same underlying sequence. Hence, the normal tests used to infer PCR duplicates with e.g. DNA-seq reads can yield false-positives in RNA-seq. This is particularly true for highly abundant transcripts (or transcripts from highly-abundant genes). We are currently working on the code that will do duplicate removal when UMI tags are present. That methodology can be extended to remove duplicates even without UMI tags --- though I'd generally caution against that for the reasons mentioned above. However, for the time being, if you have a strong need or desire to filter PCR duplicates, you could use alignment-based Salmon with a BAM file that has duplicates removed. Finally, regarding the error you are getting during SAM validation; this sounds like a different issue. Would you mind providing a piece of that SAM file for me to take a look at? Specifically, I don't believe the quasi-mapping output file should even contain unmapped reads (unless you consider unmapped mates of orphaned reads). --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/136#issuecomment-305317281:331,test,tests,331,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/136#issuecomment-305317281,1,['test'],['tests']
Testability,Hi Hamdi. Bit confused about your logic here - why would you not want to use tximport in R when your next step (DESeq2) is still going to be R? . I am curious to know your reasoning . > I am processing the data on one platform and then transfer to another platform for R/DESeq2 analysis. I would like to be able to generate the output of the first part (salmon) without using an R library.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/437#issuecomment-549185551:34,log,logic,34,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/437#issuecomment-549185551,1,['log'],['logic']
Testability,"Hi James,. Surprisingly, it looks like I don't actually log exactly the version of salmon used in the index. In the index directory, the `header.json` will give you some info. It will tell you the *index* version, but many versions of salmon can correspond to the same *index* version. The info in that file might help to discriminate a little bit. Can you try *indexing* with v0.10.2 (the one you are aligning with)?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/301#issuecomment-429497594:56,log,log,56,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/301#issuecomment-429497594,1,['log'],['log']
Testability,"Hi Jenny,. Thanks for this detailed report. I'd be interested in taking a look at some of the data if it is public or possible to share for the purposes of testing. It is true that if a read is equally explicable by a short and long transcript (and if there is not a lot of other read evidence of the long transcript), the inference algorithm will prefer to assign the read to the shorter isoform, since this will increase the overall likelihood of the observed sequenced fragments. Of course, one could always run salmon's Gibbs sampler `--numGibbsSamples` or bootstrap sampler `--numBootstraps` to determine the variance in these point estimates. I'm on travel for the next couple of days, but will be happy to look into this more deeply when I return. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/133#issuecomment-296703263:156,test,testing,156,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/133#issuecomment-296703263,1,['test'],['testing']
Testability,"Hi Josh,. My best guess is that something is awry with the 64-bit index. That code-path is less well-tested (since I don't really have any transcriptomes in my collection that exceed the size of a 32-bit signed int). If you're able to share the txome and / or the index itself, I'd be happy to try and reproduce and fix this. Actually, I'd be really happy to squash any bugs in the 64-bit code path. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-203627077:101,test,tested,101,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-203627077,1,['test'],['tested']
Testability,"Hi Kivanc,. Indeed, it looks from the logs as if, in the low mapping-rate samples, SAF with decoys is confidently assigning a lot of reads to decoy sequence. For example, out of `11225446` fragments, `6809189` map best to decoys and `3069202` map best to the annotation. This is compared to without decoys where `6166065` reads map to the annotation. Interestingly, you can see that with the decoys, the total number of reads accounted for is considerably higher. I agree that the results of SAF may be closer to that of STAR. One thing I'd be curious to know is how many of those reads aligned by STAR can be confidently assigned to exons. That's the number that you'd want to most-directly compare against the mapping rate of salmon to non-decoy targets. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/479#issuecomment-579314493:38,log,logs,38,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/479#issuecomment-579314493,1,['log'],['logs']
Testability,"Hi Nick,. No problem at all; sorry for not providing a better explanation (I'm planning on writing one up for when this feature is listed in the next official release). In terms of strategy, my recommendation would be to use the default (the `dense hash`) unless indexing memory becomes a problem. The main differences are the following:; - The perfect hash uses an external memory algorithm to construct the hash function, and so requires less memory.; - Because the perfect hash function is built in external memory, **construction** of the hash using this data structure is sower. I don't have longitudinal benchmarks, but it is somewhere between 2 and 5x slower to populate the perfect hash than the dense hash.; - Once constructed, the perfect hash is _considerably_ smaller, and so quantification on an index built using a perfect hash will require only ~50% of the memory that is required when using a dense hash. Obviously if you're quantifying on the same machine that was able to build the index, this isn't a problem. However, if you're shipping the index to smaller memory computers, then this is something to consider.; - The performance difference in terms of mapping speed is very minimal; the minimum perfect hash can be 5-10% slower than the dense hash, but this difference is usually only a matter of seconds. Also, the total runtime difference can be even less since the smaller perfect hash can be read more quickly from disk than the larger dense hash. So, the standard recommendation would be use the default unless you run into memory problems building the index; in that case, try enabling the `--perfectHash` flag.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/53#issuecomment-204069238:610,benchmark,benchmarks,610,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/53#issuecomment-204069238,1,['benchmark'],['benchmarks']
Testability,"Hi Peter,. Obviously, I got tied up with other obligations a bit longer than I thought! Sorry for the delay. Anyway, I've run both of these samples with the newest release, using parameters as close as I can (given that the bias correction flags have changed in 0.7.0). Both samples seem to run cleanly. Would you mind testing with the latest release and seeing if the issue is resolved? Here is the procedure I used:. Index with k=19 (I think this is what you did), using the default `quasi` index. ```; > salmon index -t Canis_familiaris.CanFam3.1.cdna.all.fa.gz -i index -k 19; ```. Run sample `SRR636842`:. ```; > salmon quant -i index -p 16 -l IU -1 SRR636842_1.fastq.gz -2 SRR636842_2.fastq.gz --seqBias -o quant_SRR636842 --useVBOpt; ```. here, the mapping rate was ~78.8%. Run sample `SRR636843`:. ```; >salmon quant -i index -p 16 -l IU -1 SRR636843_1.fastq.gz -2 SRR636843_2.fastq.gz --seqBias -o quant_SRR636843 --useVBOpt; ```. here, the mapping rate was ~79.5%. The mapping rates may differ for you a bit, since I used [this](ftp://ftp.ensembl.org/pub/release-85/fasta/canis_familiaris/cdna/Canis_familiaris.CanFam3.1.cdna.all.fa.gz) Ensembl transcript set directly.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/66#issuecomment-241235054:319,test,testing,319,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/66#issuecomment-241235054,1,['test'],['testing']
Testability,"Hi Rob ; Thanks for your reply, May I just show another exmaple. This is the log.final.out from STAR. Number of input reads | 39258388; Average input read length | 300; UNIQUE READS:; Uniquely mapped reads number | 33103781; Uniquely mapped reads % | 84.32%; Average mapped length | 297.80; Number of splices: Total | 23754767; Number of splices: Annotated (sjdb) | 23730217; Number of splices: GT/AG | 23569617; Number of splices: GC/AG | 108014; Number of splices: AT/AC | 18563; Number of splices: Non-canonical | 58573; Mismatch rate per base, % | 0.26%; Deletion rate per base | 0.03%; Deletion average length | 3.17; Insertion rate per base | 0.01%; Insertion average length | 1.45; MULTI-MAPPING READS:; Number of reads mapped to multiple loci | 2524124; % of reads mapped to multiple loci | 6.43%; Number of reads mapped to too many loci | 518050; % of reads mapped to too many loci | 1.32%; UNMAPPED READS:; Number of reads unmapped: too many mismatches | 0; % of reads unmapped: too many mismatches | 0.00%; Number of reads unmapped: too short | 1717592; % of reads unmapped: too short | 4.38%; Number of reads unmapped: other | 1394841; % of reads unmapped: other | 3.55%; CHIMERIC READS:; Number of chimeric reads | 0; % of chimeric reads | 0.00%; sample6/align_6BE_Log.final.out (END). I run the same sample with salmon index generated as discussed above and got this report ; [2022-05-14 01:26:06.437] [jointLog] [info] Computed 380,631 rich equivalence classes for further processing; [2022-05-14 01:26:06.437] [jointLog] [info] Counted 22,462,069 total reads in the equivalence classes ; [2022-05-14 01:26:06.454] [jointLog] [info] Number of mappings discarded because of alignment score : 236,393,072; [2022-05-14 01:26:06.454] [jointLog] [info] Number of fragments entirely discarded because of alignment score : 3,028,418; [2022-05-14 01:26:06.454] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 0; [2022-05-14 01:26:06.454] [jointLog] [inf",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/775#issuecomment-1126593943:77,log,log,77,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/775#issuecomment-1126593943,1,['log'],['log']
Testability,"Hi Rob, . For example, here is the log output when I try to index the GENCODE Human transcript set v36, using the below code;. salmon index --keepDuplicates -k 35 --gencode -t gencode.v36.transcripts.fa -i Human_v36_Index_k35. Here is where the phrase is found in the log, and is then repeated a lot until the end. Number of ones: 1309432; Number of ones per inventory item: 512; Inventory entries filled: 2558; 1309432; [2021-02-15 04:42:27.548] [puff::index::jointLog] [info] Done wrapping the rank vector with a rank9sel structure.; [2021-02-15 04:42:27.565] [puff::index::jointLog] [info] contig count for validation: 1,309,432; [2021-02-15 04:42:28.338] [puff::index::jointLog] [info] Total # of Contigs : 1,309,432; [2021-02-15 04:42:28.339] [puff::index::jointLog] [info] Total # of numerical Contigs : 1,309,432; [2021-02-15 04:42:28.404] [puff::index::jointLog] [info] Total # of contig vec entries: 7,119,643; [2021-02-15 04:42:28.404] [puff::index::jointLog] [info] bits per offset entry 23; [2021-02-15 04:42:28.590] [puff::index::jointLog] [info] Done constructing the contig vector. 1309433; [2021-02-15 04:42:29.459] [puff::index::jointLog] [info] # segments = 1,309,432; [2021-02-15 04:42:29.459] [puff::index::jointLog] [info] total length = 188,284,293; [2021-02-15 04:42:29.548] [puff::index::jointLog] [info] Reading the reference files ...; [2021-02-15 04:42:31.594] [puff::index::jointLog] [info] positional integer width = 28; [2021-02-15 04:42:31.594] [puff::index::jointLog] [info] seqSize = 188,284,293; [2021-02-15 04:42:31.595] [puff::index::jointLog] [info] rankSize = 188,284,293; [2021-02-15 04:42:31.595] [puff::index::jointLog] [info] edgeVecSize = 0; [2021-02-15 04:42:31.595] [puff::index::jointLog] [info] num keys = 143,763,605; len should not be greater than 64.; ...; ...; ...; len should not be greater than 64.; [2021-02-15 05:07:13.459] [puff::index::jointLog] [info] finished populating pos vector; [2021-02-15 05:07:13.460] [puff::index::jointLog] [info] wr",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/632#issuecomment-779416548:35,log,log,35,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/632#issuecomment-779416548,2,['log'],['log']
Testability,"Hi Rob, . Thank you for the fast reply. I did some tests and ran the suggestions you told me. Everything comes down to the reference i used. The mapping rates are still low (44 - 54 %) but they have increased when I mapped the reads with Salmon allowing for more genes in the reference. Thank you for the useful suggestions though, I will incorporate them in my future evaluations.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/212#issuecomment-379253109:51,test,tests,51,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/212#issuecomment-379253109,1,['test'],['tests']
Testability,"Hi Rob, ; I'd like to ask a follow-up question to this thread:. In your reply above, you said:; > the library type is used as a ""soft"" rather than a ""hard"" filter when determining where a read may originate from (i.e. Orientations other than the expected type have a probability orders of magnitude smaller than the expected type, but still non-zero). Thus, if the only mapping for a read disagrees with the expected type, it will still be used. There is a way to modify this behavior, but since stranded library prep is imperfect, the default behavior is the most reasonable for most situations. I wonder how can I enforce the ""correct"" usage of the strand information by Salmon. I am testing Salmon on some data and there seem to be cases of overlap between two genes (on opposite strands), when the values produced by Salmon seem suspicious. Best, ; Alex",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/67#issuecomment-388851366:686,test,testing,686,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/67#issuecomment-388851366,1,['test'],['testing']
Testability,"Hi Rob,. I took a shot at adding a CONDA_BUILD flag to make it work with conda builds rather than editing the CMakeLists.txt with sed in the build script. I tested it and it seems to work, but it could use a review by someone who has used cmake before. It might be that editing with sed is a cleaner solution, getting the flags in the right place made the CMakeLists.txt file a little ugly. Totally happy to do either solution.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/92:157,test,tested,157,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/92,1,['test'],['tested']
Testability,"Hi Rob,. I would still like to test your branch with selective-alignment if you can provide the linux executable. Tnx!; Klaas",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/196#issuecomment-379190396:31,test,test,31,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/196#issuecomment-379190396,1,['test'],['test']
Testability,"Hi Rob,. I'm testing Salmon 0.6.0 in read-based mode and it seems awesome, fast and accurate. Moreover, it's very well documented, which I really appreciate. My question is about the library type specification. In the libFormatCounts.txt file, library type as well as consistent and inconsistent mappings are correctly reported. However, transcript TPM and NumReads in quant.sf file are the same regardless of the library type specified when playing with different library types combinations. I would expect Salmon to take only into account the consistent mappings for the quantification. I'm specifying the -l parameter before the -1 and -2 parameters. . I'm pretty sure that I'm missing something. I would really appreciate if you could shed light on this issue. Thanks in advance.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/67:13,test,testing,13,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/67,1,['test'],['testing']
Testability,"Hi Rob,. Thanks for the update. I’ll see about setting up a Linux box in the morning and trying the v1.3.1. I expected some reads to be discharged as this is a mixed intestinal sample so there is likely a lot of bacterial rna as we used rRNA depletion not polyA; selection. We were hoping to align to both the mouse genome and one of the bacteria species of interest. . Given the several orders of magnitude difference in discarded alignments between mine on 1.2.1 and your test run on 1.3.1, would you recommend I redo the whole dataset alignment on 1.3.1? If it runs even close to what you saw it shouldn’t take too long; to rerun. . Thanks again,. Ryan. Sent from my iPhone. On Jun 16, 2020, at 12:13 AM, Rob Patro <notifications@github.com> wrote:. ﻿. I processed the data above using the latest salmon from the develop branch; (the release candidate for 1.3.0), and I got the following time (used 8; threads, so timing is not directly comparable). ```; 4604.57user 43.64system 9:24.15elapsed 823%CPU; ```. The whole log is. ```; [2020-06-15 23:51:54.747] [jointLog] [info] setting maxHashResizeThreads to; 8; [2020-06-15 23:51:54.747] [jointLog] [info] Fragment incompatibility prior; below threshold. Incompatible fragments will be ignored.; [2020-06-15 23:51:54.747] [jointLog] [info] Usage of --validateMappings; implies use of minScoreFraction. Since not explicitly specified, it is; being set to 0.65; [2020-06-15 23:51:54.747] [jointLog] [info] Usage of --validateMappings; implies a default consensus slack of 0.2. Setting consensusSlack to 0.35.; [2020-06-15 23:51:54.747] [jointLog] [info] parsing read library format; [2020-06-15 23:51:54.747] [jointLog] [info] There is 1 library.; [2020-06-15 23:51:54.814] [jointLog] [info] Loading pufferfish index; [2020-06-15 23:51:54.814] [jointLog] [info] Loading dense pufferfish index.; [2020-06-15 23:51:55.555] [jointLog] [info] done; [2020-06-15 23:51:55.555] [jointLog] [info] Index contained 116,248 targets; [2020-06-15 23:51:55.588] [jo",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-644527727:474,test,test,474,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-644527727,1,['test'],['test']
Testability,"Hi Rob,. The file that I am building the index on is a cdna.all fasta file from Ensembl, ; exactly this one here : ftp://ftp.ensembl.org/pub/release-91/fasta/caenorhabditis_elegans/cdna/Caenorhabditis_elegans.WBcel235.cdna.all.fa.gz . . It was unzipped and then used with `salmon index`. ; This is the log of the indexing process:; ```; Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; [2018-03-20 17:41:44.417] [jLog] [info] building index; RapMap Indexer. [Step 1 of 4] : counting k-mers; [2018-03-20 17:41:48.639] [jointLog] [warning] Entry with header [W03F8.6d], had length less than the k-mer length of 31 (perhaps after poly-A clipping); Elapsed time: 4.82575s. [2018-03-20 17:41:49.262] [jointLog] [warning] Removed 414 transcripts that were sequence duplicates of indexed transcripts.; [2018-03-20 17:41:49.263] [jointLog] [warning] If you wish to retain duplicate transcripts, please use the `--keepDuplicates` flag; Replaced 0 non-ATCG nucleotides; Clipped poly-A tails from 20 transcripts; Building rank-select dictionary and saving to disk done; Elapsed time: 0.0570225s; Writing sequence data to file . . . done; Elapsed time: 0.286971s; [info] Building 32-bit suffix array (length of generalized text is 56718041); Building suffix array . . . success; saving to disk . . . done; Elapsed time: 0.959095s; done; Elapsed time: 8.1189s; ^M^Mprocessed 0 positions^M^Mprocessed 1000000 positions^M^Mprocessed 2000000 positions^M^Mprocessed 3000000 positions^M^Mprocessed 4000000 positions^M^Mprocessed 5000000 positions^M^Mprocessed 6000000 positions^M^Mprocessed 7000000 positions^M^Mprocessed 8000000 positions^M^Mprocessed 9000000 positions^M^Mprocessed 10000000 positions^M^Mprocessed 11000000 positions^M^Mprocessed 12000000 positions^M^Mprocessed 13000000 positions^M^Mprocessed 14000000 positions^M^Mprocessed 15000000 positions^M^Mprocessed 16000000 positions^M^Mprocessed 17000000 position",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/210#issuecomment-376093497:302,log,log,302,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/210#issuecomment-376093497,1,['log'],['log']
Testability,"Hi Rob,; I haven't got a chance to test whether the suggestions help or not. But I guess it's due to the fact that the read is super short, single-end only as well, thus introduce a huge ambiguity in the quasi-mapping step. Anyway, I will try to test it later.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/120#issuecomment-281555424:35,test,test,35,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/120#issuecomment-281555424,2,['test'],['test']
Testability,"Hi Rob,; That seemed to be the problem. I rebuilt the index on my laptop and salmon worked perfectly on my laptop!; Thanks,; Grant. On Mar 22, 2018, at 6:21 PM, Rob Patro <notifications@github.com<mailto:notifications@github.com>> wrote:. Hi @grantcramer<https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fgrantcramer&data=01%7C01%7Ccramer%40unr.edu%7C54d34feceb114e30a61b08d5905c7a7b%7C523b4bfc0ebd4c03b2b96f6a17fd31d8%7C1&sdata=w1ED%2B5ZBUY6Z8fTiIs62IZJizv0HcvVzw8CtfEdK32E%3D&reserved=0>,. I was able to successfully index and map against the fasta file you link above (on linux). I was also able to index and map against the index on OSX, using the salmon from bioconda (v 0.9.1). So, I'm not yet able to reproduce this. It seems the file you uploaded for your pre-built index is no longer available, so I couldn't try that out. I'd be happy to give it a try if you can put it up on dropbox or some such. Otherwise, I wonder if there could be some sort of binary compatibility issue. Did you build the index on the same machine you're quantifying on? The OSX I tested on is 10.13.1. Best,; Rob. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2FCOMBINE-lab%2Fsalmon%2Fissues%2F209%23issuecomment-375509050&data=01%7C01%7Ccramer%40unr.edu%7C54d34feceb114e30a61b08d5905c7a7b%7C523b4bfc0ebd4c03b2b96f6a17fd31d8%7C1&sdata=5XDT2ix1q1Uz%2B3kTchI%2B5K9Hzu7UuGkyQAz8KB9ko4o%3D&reserved=0>, or mute the thread<https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscribe-auth%2FAj0RizznzcCphH-HJ9Q8uXvndQ4Lsg9Oks5thE43gaJpZM4Sw28q&data=01%7C01%7Ccramer%40unr.edu%7C54d34feceb114e30a61b08d5905c7a7b%7C523b4bfc0ebd4c03b2b96f6a17fd31d8%7C1&sdata=7DLxrFx74WqeN71%2Bs5cfSxEA1NRxj%2F7uqvp9SrGgjck%3D&reserved=0>.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/209#issuecomment-375683475:1092,test,tested,1092,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/209#issuecomment-375683475,1,['test'],['tested']
Testability,"Hi Rob, . Thanks for the quick response. The other computer was OSX, should I try a linux machine? . Here are some dropbox links to two of the files. I believe this is the set for the logs I posted. . https://www.dropbox.com/s/8c3p9hmgmadgj89/31_1.trimmed.fastq.gz?dl=0. https://www.dropbox.com/s/2y9jfvaphe9h21x/31_2.trimmed.fastq.gz?dl=0. Thanks, . Ryan . On Jun 15, 2020, at 9:32 PM, Rob Patro <notifications@github.com> wrote:. Thank you for the report. Can you share one of the samples where you see this issue? Also, out of curiosity, was the other machine you tried on also OSX, or was it a linux machine?; —; You are receiving this because you authored the thread.; Reply to this email directly, ; view it on GitHub, or ; unsubscribe.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-644504783:184,log,logs,184,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-644504783,1,['log'],['logs']
Testability,"Hi Salmon developers,. I wonder if Salmon can handle both paired-end reads, and single-end orphan reads from the same library as inputs. These inputs reads are from trimmomatic outputs, which would generate 4 files: Paired-end reads both pass QC, and 2 of the orphan forward or reverse reads that also passed QC. . In my project, I found that for all of my 49 samples (~25M PE reads/sample), I had about ~70% of reads from each sample are Paired-end both pass QC, and another ~25% are orphan reads (expectedly majority are forwarded reads). 25% seems to be too big for me, so I was thinking to utilize those orphan reads. . Since I wasn't sure if Salmon can handle these inputs in the same run, I initiated 2 runs of salmon, one for PE, one for SE, as follows:; ```; # Mapped PE pass QC; parallel -a data/raw_filenames.txt -j 3 --results logs/salmon_map_PE/ --joblog logs/salmon_map_PE.log \; salmon quant -i data/reference/MmvM27_salmon_ind -l IU \; -1 data/qc/{}_O1_paired.fastq.gz \; -2 data/qc/{}_O2_paired.fastq.gz \; -p 8 \; --validateMappings \; --recoverOrphans \; --allowDovetail \; --useVBOpt \; --seqBias \; -o data/mapped_salmon/{}_quant &. # Mapped SE pass QC; # --fldMean and --fldSD is set based on the PE run results; parallel -a data/raw_filenames.txt -j 3 --results logs/salmon_map_SE/ --joblog logs/salmon_map_SE.log \; salmon quant -i data/reference/MmvM27_salmon_ind -l U \; -r data/qc/{}_O1_unpaired.fastq.gz data/qc/{}_O2_unpaired.fastq.gz \; -p 8 \; --validateMappings \; --fldMean 265 \; --fldSD 105 \; --useVBOpt \; --seqBias \; -o data/mapped_salmon/SE/{}_quant &; ```; But I wasn't sure if the outputs can be directly combined by addition. From TPM definition, I don't think it can be added together for the same transcript of in the same sample. But can I use the NumReads column from the 2 runs, and add them together and then re-generate the combined TPM?. Thank you very much!. Jincheng",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/675:838,log,logs,838,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/675,6,['log'],"['log', 'logs']"
Testability,"Hi Valentine,. Thanks for all of the detailed info to reproduce this; I'll try and take a look at it soon. Since there is _a lot_ of work going on in the develop branch (and good stuff coming in v0.7.0), it actually looks like `--useFSPD` will be replaced with a `--posBias` flag that models both 5' and 3' position specific bias. Of course, we're still working on / testing that feature. In the mean time, I'll see if I can find what's causing this problem. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/64#issuecomment-227424950:367,test,testing,367,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/64#issuecomment-227424950,1,['test'],['testing']
Testability,"Hi Valentine,. That's not good! I suppose that testing the gibbs sampling should be added to our standard set of regression tests. Can you provide me with a data set that reproduces this issue? I'll track it down and figure out why Gibbs is behaving badly. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/58#issuecomment-218878561:47,test,testing,47,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/58#issuecomment-218878561,2,['test'],"['testing', 'tests']"
Testability,"Hi again @GWW,. We have a hotfix for this that we are currently testing, but feel free to try it out if you have a chance. If you download the source from [here](https://github.com/COMBINE-lab/salmon/archive/hash-resize-hotfix.zip), or checkout the branch `hash-resize-hotfix`, you can pass alevin an extra hidden option `--maxHashResizeThreads` that allows you to limit the maximum number of threads used during the hash table resize. If you use `--maxHashResizeThreads 1`, at most one extra thread should be created during hash table resizing. Hopefully, this should fix the issue occurring in your execution environment. If so, please let us know so we can merge the fix back into develop (and then master).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395907924:64,test,testing,64,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395907924,1,['test'],['testing']
Testability,"Hi again,. Together with Mark Miller (JHPCE's admin) we ran more tests. We verified that `Salmon` does indeed use at least 2 threads so now I'm always requesting 2 from SGE. We also noticed that when the jobs fail due to memory (the actual issue in this thread) they fail after the `There is 1 library` message as shown below for one test:. ```; [2017-04-05 14:28:09.021] [jointLog] [info] parsing read library format; [2017-04-05 14:28:09.035] [jointLog] [info] There is 1 library.; terminate called without an active exception; /cm/local/apps/sge/var/spool/compute-064/job_scripts/420662: line 31: 28651 Aborted (core dumped) /dcl01/lieber/ajaffe/Emily/RNAseq-pipelin; e/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant -i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode; .v25.transcripts -p 1 -l ISR -1 ${FILE1} -2 ${FILE2} -o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test7/${ID}; ```. Files that work well, keep on going:. ```; [2017-04-05 14:30:23.757] [jointLog] [info] parsing read library format; [2017-04-05 14:30:23.767] [jointLog] [info] There is 1 library.; [2017-04-05 14:30:24.378] [jointLog] [info] Loading Quasi index; ```. I don't know if that hint makes you suspect anything in `Salmon`. . Now, for some tests only task 2 runs and it turns out that task 2 has a smaller fastq file than the other 2:. ```bash; $ ls -lh merged_fastq/R1000[1-3]*; -rw-r--r-- 1 lcollado lieber_jaffe 6.2G Feb 20 12:39 merged_fastq/R10001_D2B1WACXX.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 6.3G Feb 20 12:40 merged_fastq/R10001_D2B1WACXX_read2.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 4.6G Feb 20 12:42 merged_fastq/R10002_C29P7ACXX.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 4.7G Feb 20 12:44 merged_fastq/R10002_C29P7ACXX_read2.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 7.1G Feb 20 12:47 merged_fastq/R10003_D19KGACXX.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 7.1G Feb 20 12:50 merged_fastq/R10003_D19KGACXX_read2.fastq.g",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:65,test,tests,65,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,2,['test'],"['test', 'tests']"
Testability,"Hi all,. I just wanted to provide this space to start a discussion and get feedback about what people believe to be the most sensible _default_ settings for Salmon (in different modes). We're happy to discuss any suggestions, but can start with some specific questions. Here is the most basic. Right now, Salmon has an ""opt-in"" philosophy. That is, a default run starts with the most basic features, and users opt-in to anything that has non-trivial cost (e.g. gibbs sampling, bias correction, and even things that have close to trivial cost but may not always be useful like dumping the equivalence classes to disk). Perhaps some of these defaults should be re-considered, or perhaps this philosophy makes sense as long as the ""opt-in"" behavior is made clear? It's worth noting that one current benefit of this ""opt-in"" mentality is that defaults are more _consistent_ among data-types. For example, GC-bias modeling for single-end libraries is still a feature in testing (on the develop branch), and so could not reasonably be made default at the current time.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/109:965,test,testing,965,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/109,1,['test'],['testing']
Testability,"Hi all,. I'm just chiming in here to say that we are _definitely_ interested in supporting scRNA-seq data ""out of the box"". At this point, it's really just a matter of deciding what the best approach is. That is, do we have a sufficiently good idea of the appropriate ""model"" for scRNA-seq to implement that, or is a de-duplicated UMI count over transcripts and equivalence classes the best we can do at this point. I'm open to ideas, thoughts, and suggests on how to test this as we start incorporating this feature into Salmon. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/93#issuecomment-259996802:468,test,test,468,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/93#issuecomment-259996802,1,['test'],['test']
Testability,"Hi all. I have been working with the raw fastq files from [this study](https://www.ncbi.nlm.nih.gov/Traces/study/?acc=PRJNA590042&o=acc_s%3Aa), and tried to map them using `Alevin`. following `fastq-dump` I generated the barcode fastq files using `umi-tools`, this is a 3' PE Chromium scRNASeq, so I used; ```; umi_tools extract \; --stdin=GSE140511/fastq_files/SRR10480618_1.fastq.gz \; --stdout GSE140511/fastq_files/SRR10480618_BC_1.fastq.gz \; --read2-in GSE140511/fastq_files/SRR10480618_2.fastq.gz \; --read2-out GSE140511/fastq_files/SRR10480618_BC_2.fastq.gz \; --bc-pattern=CCCCCCCCCCCCCCCCNNNNNNNNNN \; --log=processed_SRR10480618.log; ```. following this step I then ran it on Alevin with ; ```; salmon alevin \; -l ISR \; -1 GSE140511/fastq_files/SRR10480618_BC_1.fastq.gz GSE140511/fastq_files/SRR10480618_BC_2.fastq.gz \; -2 GSE140511/fastq_files/SRR10480618_1.fastq.gz GSE140511/fastq_files/SRR10480618_2.fastq.gz \; --chromium \; -i /data/shared/seb_temp/Mm_index \; -p 32 \; -o /home/seb/shared/seb_temp/GSE140511/salmon_alevin_output/SRR10480618 \; --tgMap /home/seb/shared/seb_temp/txp2gene_SB.tsv; ```. my `txp2gene` file looks like this; ```; ENSMUST00000178537.2 ENSMUSG00000095668.2; ENSMUST00000178862.2 ENSMUSG00000094569.2; ENSMUST00000196221.2 ENSMUSG00000096749.3; ENSMUST00000179664.2 ENSMUSG00000096749.3; ENSMUST00000177564.2 ENSMUSG00000096176.2; ENSMUST00000179520.2 ENSMUSG00000094028.2; ENSMUST00000179883.2 ENSMUSG00000094552.2; ENSMUST00000195858.2 ENSMUSG00000096420.3; ENSMUST00000179932.2 ENSMUSG00000096420.3; ENSMUST00000180001.2 ENSMUSG00000095656.2; ```; and I generated it using the gtf file created by indexing the genome. however, when `salmon alevin` finishes its run, I get a mapping rate of 3% or less, and no errors are generated. I then tried to pass the barcodes that are published in GEO for this sample as `whitelist` adding the following argument; `--whitelist GSM4173504_WT_1_barcodes.tsv`; but here the mapping rate goes down to 0%!!. I am not",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/763:615,log,log,615,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/763,2,['log'],['log']
Testability,"Hi everyone,. I am using the salmon to calculate bins' abundance in metagenomic data. When I used Salmon map the reads to the bins, I only got ~20% mapping rate. And I have mapped the reads back to the bins using bowtie2, I got ~80% mapping rate; Besides, I also used the PE reads as two SE reads and input them into Salmon separately`salmon -i index -r read1`; Both reads could get ~80% mapping rate. I have tested many parameters that may affect the mapping rate, but it still can not be improved. If anyone could pull me out, I would appreciate it. . I index the bins using the default kmer(31), and the length of reads is PE150. And the following is the command I use:; `salmon quant -i assembly_index/ -l A -1 9998_1.fastq.gz -2 9998_2.fastq.gz -p 100 -o 9998.quant --meta`. The log file:; ```{shell}; $cat lib_format_counts.json ; {; ""read_files"": [; ""/share/work/HPC/work_tmp/liangyong/BinningMappingRateLow/9998_1.fastq.gz"",; ""/share/work/HPC/work_tmp/liangyong/BinningMappingRateLow/9998_2.fastq.gz""; ],; ""expected_format"": ""IU"",; ""compatible_fragment_ratio"": 1.0,; ""num_compatible_fragments"": 8925446,; ""num_assigned_fragments"": 8925446,; ""num_frags_with_concordant_consistent_mappings"": 2169449,; ""num_frags_with_inconsistent_or_orphan_mappings"": 10821303,; ""strand_mapping_bias"": 0.5001592570279366,; ""MSF"": 0,; ""OSF"": 0,; ""ISF"": 1084379,; ""MSR"": 0,; ""OSR"": 0,; ""ISR"": 1085070,; ""SF"": 5409839,; ""SR"": 5411464,; ""MU"": 0,; ""OU"": 0,; ""IU"": 0,; ""U"": 0; }. ```. Another log file in the folder of logs:; ```{shell}; $cat salmon_quant.log ; [2023-03-07 06:47:10.266] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2023-03-07 06:47:10.266] [jointLog] [warning] . NOTE: It appears you are running salmon without the `--validateMappings` option.; Mapping validation can generally improve both the sensitivity and specificity of mapping,; with only a moderate increase in use of computational resources. ; Mapping validation is planned to ",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/838:409,test,tested,409,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/838,2,"['log', 'test']","['log', 'tested']"
Testability,"Hi folks,. I'm trying to run DebianSqueeze Salmon v0.4.2 with some issue in the 'quant' step. Here is the skinny:; - ERCC + latest human ensembl transcriptome; - Index builds fine -- no apparent issues; - Quant step fails with the following output:. ``` bash; LD_LIBRARY_PATH=~/software/SalmonBeta-0.4.2_DebianSqueeze/lib; ~/software/SalmonBeta-0.4.2_DebianSqueeze/bin/salmon quant -i index/hs_ens_ercc.sidx --libType IU --output output/salmon -1 reads_1.fastq -2 reads_2.fastq; Version Info: This is the most recent version of Salmon.; # salmon (smem-based) v0.4.2; # [ program ] => salmon; # [ command ] => quant; # [ index ] => { index/hs_ens_ercc.sidx }; # [ libType ] => { IU }; # [ output ] => { output/salmon }; # [ mates1 ] => { reads_1.fastq }; # [ mates2 ] => { reads_2.fastq }; Logs will be written to output/salmon/logs; there is 1 lib; [2015-08-23 21:58:57.438] [jointLog] [info] parsing read library format; [bns_restore_core] Parse error reading index/hs_ens_ercc.sidx/bwaidx.amb; ```. I've provided a reproducible and self-contained Snakefile that only depends on the binaries being dumped in `~/software` and the reads_*fastq below. Let me know if there is anything I can do to help. Thanks a bunch!. Harold. ---. ``` python; ercc_fa = 'index/ERCC.fa'; ens_fa = 'index/Homo_sapiens.GRCh38.cdna.all.fa'; ens_ercc_fa = 'index/hs_ens_ercc.fa'; ens_ercc_sidx = 'index/hs_ens_ercc.sidx'. SALMON_PRE = '~/software/SalmonBeta-0.4.2_DebianSqueeze'; SALMON = 'LD_LIBRARY_PATH={0}/lib; {0}/bin/salmon'.format(SALMON_PRE). rule all:; input:; ens_ercc_fa,; ens_ercc_sidx,; 'output/salmon/quant.sf'. rule download_ens:; output:; ens_fa; params:; dl = 'ftp://ftp.ensembl.org/pub/release-81/fasta/homo_sapiens/cdna/Homo_sapiens.GRCh38.cdna.all.fa.gz'; threads: 1; shell:; 'curl {params.dl} | zcat > {output}'. rule download_ercc:; output:; ercc_fa; params:; dl = 'http://bio.math.berkeley.edu/kallisto/transcriptomes/ERCC.fa.gz'; threads: 1; shell:; 'curl {params.dl} | zcat > {output}'. rule merge_",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/12:789,Log,Logs,789,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/12,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"Hi guys,. I'm certainly open to adding this type of thing if there's sufficient desire for it. I agree with @vals that making umi tags compatible with a data generation model based on expected coverage seems very difficult. Then, the question just becomes what is the best way to support umi-tagged data. I'm open to suggestions, as well as to good datasets against which different approaches may be tested. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/93#issuecomment-251217506:400,test,tested,400,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/93#issuecomment-251217506,1,['test'],['tested']
Testability,"Hi scott,. Thank you for the detailed report. Im trying to reproduce the issue. So far, i have been unable to reproduce the issue on an ubuntu 16.04 or OSX box with either 0.11.1 or 0.9.1. My next test is to try on an ubuntu 14.04 docker container. I'm afraid there may be a system library issue involved. Could you try upgrading via bioconda as well to see if that helps? The latest linux release is available on bioconda.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/271#issuecomment-413855775:197,test,test,197,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/271#issuecomment-413855775,1,['test'],['test']
Testability,"Hi there, . I've being using salmon for a while but have started noticing this sometimes in my outputs, both during indexing and quantification. What does it mean? Is it an issue? It will really bulk out the log. . Thanks,. Dan",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/632:208,log,log,208,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/632,1,['log'],['log']
Testability,"Hi! I'm really sorry for taking so long to get back to you; things have been quite hectic this semester. The reason it's not being show is because it's been placed in a parameter group that is not made visible by default; the `--posBias` option itself is still available. It's definitely still experimental in that it has not been tested nearly as thoroughly as the other bias models. However, it is useable. Once we have performed more testing, it will migrate into the normal options and be better documented. If you gather any useful data while using this flag, we'd love some feedback!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/191#issuecomment-367448963:331,test,tested,331,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/191#issuecomment-367448963,4,['test'],"['tested', 'testing']"
Testability,"Hi!. I'm trying to tidy up some of the strandedness analysis in nf-core/rnaseq, and have gone down the rabbit hole a little bit, hoping you can shortcut things for me. . nf-core/rnaseq's test profile runs Salmon on subsampled FASTQ files and uses Salmon to infer the strandedness, by extracting the `library_types` from a meta_info.json. . In an example run (~50k reads) this is unstranded (`IU`), but I'm having trouble reconciling with what I see in the corresponding `lib_format_counts.json`:. ```; {; ""read_files"": ""[ WT_REP2.subsampled_R1.fastq.gz, WT_REP2.subsampled_R2.fastq.gz]"",; ""expected_format"": ""IU"",; ""compatible_fragment_ratio"": 1.0,; ""num_compatible_fragments"": 39909,; ""num_assigned_fragments"": 39909,; ""num_frags_with_concordant_consistent_mappings"": 41509,; ""num_frags_with_inconsistent_or_orphan_mappings"": 3363,; ""strand_mapping_bias"": 0.11922715555662628,; ""MSF"": 0,; ""OSF"": 0,; ""ISF"": 4949,; ""MSR"": 0,; ""OSR"": 0,; ""ISR"": 36560,; ""SF"": 1754,; ""SR"": 1609,; ""MU"": 0,; ""OU"": 0,; ""IU"": 0,; ""U"": 0; }; ```. Is it possible for me to do my own inference of `IU` from those numbers, or does it happen elsewhere? Is there a minimum number of reads/ mappings required to make this assessment, such that 'IU' is just a default? . I'm hoping to derive my own logic, so that we can harmonise it with the calculations we make from RSeQC's output, for example. I've been poking through [LibraryTypeDetector](https://github.com/COMBINE-lab/salmon/blob/master/include/LibraryTypeDetector.hpp) without much joy, if I replicate that logic in Python I get 'ISR', not 'IU'.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/938:187,test,test,187,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/938,3,"['log', 'test']","['logic', 'test']"
Testability,"Hi!; Thank you for making salmon. Great work!. my command line is ; salmon quant -t /hpc/grid/shared/ngsdb/fasta/gencode.v24.transcripts.no_annotation.fa -l ISR -a RC-140808-00004.tx.bam -p 8 -o salmon_aln --useVBOpt --incompatPrior 0. The end of log file looks like:. 1008 Completed first pass through the alignment file.; 1009 Total # of mapped reads : 53203073; 1010 # of uniquely mapped reads : 14377795; 1011 # ambiguously mapped reads : 38825278; 1012; 1013; 1014; 1015 [2016-08-19 14:45:45.648] [fileLog] [info] quantification processed 53203073 fragments so far; 1016; 1017 [2016-08-19 14:45:45.982] [jointLog] [info] Computed 292761 rich equivalence classes for further processing; 1018 [2016-08-19 14:45:45.982] [jointLog] [info] Counted 53203073 total reads in the equivalence classes; 1019 [2016-08-19 14:45:45.983] [jointLog] [info] starting optimizer; 1020 [2016-08-19 14:45:48.932] [jointLog] [info] Marked 1 weighted equivalence classes as degenerate. I tried dropping the --useVBOpt and it only outputs ""nan"". I also tried --useVBOpt in quasi-mapping base mode.; salmon quant -i /hpc/grid/shared/ngsdb/annotation/gencode/salmon_0.6.1_v24/ -l ISR -1 /hpc/grid/ngsws/btx_clinical/zhanc120/test/longitudinal/fastq/RC-140808-00004_1.fq.gz -2 /hpc/grid/ngsws/btx_clinical/zhanc120/test/longitudinal/fastq/RC-140808-00004_2.fq.gz -p 8 -o salmon --useVBOpt --incompatPrior 0; That worked fine. More on the bam file:; it was generated by STAR with write alignments to transcriptome option. STAR --genomeDir /hpc/grid/shared/ngsdb/STAR/GRCh38_gencode24_100 --readFilesIn /hpc/grid/ngsws/ptx_clinical/zhanc120/test/longitudinal/fastq/RC-140808-00004_1.fq.gz /hpc/grid/ngsws/ptx_clinical/zhanc120/test/longitudinal/fastq/RC-140808-00004_2.fq.gz --readFilesCommand zcat --runThreadN 8 --alignSJDBoverhangMin 1 --outFilterScoreMinOverLread 0.90 --outFilterMatchNminOverLread 0.90 --outFilterMis matchNoverLmax 0.05 --quantMode TranscriptomeSAM --alignEndsType EndToEnd --alignIntronMax 1000000 --o",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/78:247,log,log,247,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/78,1,['log'],['log']
Testability,"Hi!; This is probably not a question for the github, but I wasn't sure where to post; (please redirect me, and I'll happily remove it). I had one small question related to the paper; https://www.biorxiv.org/content/10.1101/657874v1. When performing the benchmarking of all different approaches, the parameters used when testing STAR+Salmon are listed of course. It's mentioned that the parameters of STAR are meant to be kept the same as RSEM uses them in order to get the actual proper comparisons.; All the parameters do look the same, except for one; --sjdbScore; In your paper, this param is not being used, which means that the default value of 2 is active.; RSEM, however, sets this to 1. . I'm not sure if this will affect the results in any major way though, so I just wanted to check if there was maybe a reason behind leaving this value to 2 in the paper. The --sjdbScore value scores alignments with annotated junctions higher over unspliced alignments. ; I'm not even actually sure why RSEM lowers this to 1. ; I was trying to replicate some of your benchmarking, and I was just curious about this one if you have any info that can help out. And again, I probably don't need to mention it anymore, but awesome job with the Salmon! Thanks once more for the awesome software!",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/490:253,benchmark,benchmarking,253,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/490,3,"['benchmark', 'test']","['benchmarking', 'testing']"
Testability,"Hi, . I am using **salmon (v0.13.1)** to quantity RNA-seq data from two biological replicates. After running some exploratory data analyses, I observed a large discrepancy between the two replicates regarding the gene-wise distribution of read counts. The scatterplot below shows the log-read counts from these two biological replicates:. ![salmon v0.13.1 - Scatterplot](https://user-images.githubusercontent.com/26856909/58559326-dcea7d80-81f0-11e9-851a-db28b96b981e.png). After looking at these results, I checked the salmon log output and saw that the number of uniquely mapped reads for the second replicate had several trailing zeros added to it:. <img width=""358"" alt=""salmon v0.13.1 - Output"" src=""https://user-images.githubusercontent.com/26856909/58560225-b1689280-81f2-11e9-9d69-513a93fa47c5.png"">. *I have reproduced this analysis with both versions of salmon v0.12.0 and v0.9.1 and got pretty much the same results*. I would not expect to see such a huge difference between these two biological replicates and the number of uniquely mapped reads being greater than the total number of reads seemed odd to me. I have used the same pipeline to process other RNA-seq data and never had any issues like this so far. Any help would be appreciated.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/368:284,log,log-read,284,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/368,2,['log'],"['log', 'log-read']"
Testability,"Hi, . I'm trying to quantify the expression of some samples derived from mouse. I'm using the latest version of Salmon with the E90 Ensemble reference cDNA with an index built using k=31 (and all default parameters). I map these samples using the following command:. $SALMON quant -i $INDEX -l IU -p 16 --numGibbsSamples 1000 --seqBias --gcBias --posBias --useVBOpt --biasSpeedSamp 5 -1 pair_1.fastq.gz -2 pair_2.fastq.gz -o $PREFIX. When I run this I get mapping rates ranging between 31 - 44 %. I have checked for contamination and this was negative. I have tried different k-mer sizes (reads are ~ 80 nt in length), and the results don't change much. I decided to benchmark this with STAR+RSEM and the same version of the mouse genome from Ensembl as follows:. $RSEM --seed 1786 --star --star-path $STAR --num-threads $CPU --star-gzipped-read-file --paired-end pair_1.fastq.gz pair_2.fastq.gz $INDEX $PREFIX. When I look at the mapping rates with samtools flagstats I get mapping rates between 88 - 94 %. . Do you have any ideas on why I am observing these differences? Am I doing something wrong? . Looking forward to hearing from you.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/212:667,benchmark,benchmark,667,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/212,1,['benchmark'],['benchmark']
Testability,"Hi, . Running much of anything in command line is new to me. I ran the line below without success. . > ./bin/salmon quant -t transcripts.fa -l OSR -a myseq.bam -o salmon_quant. I keep getting the error below and am not sure why. . > [jointLog] [critical] Note: Alignment-free mapping (i.e. mapping without subsequent selective-alignment) has not yet been throughly tested under the pufferfish-based index and using the pufferfish-based mapping strategies. Thus, disabling of selective-alignment is not currently allowed. We may, potentially explore re-enabling this option in future versions of salmon. I am betting this is something really simple. I'd appreciate any help... Thank you!",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/511:365,test,tested,365,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/511,1,['test'],['tested']
Testability,"Hi, . Sorry for not mentioning it previously, can you please also attach/add the error log you are getting.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/549#issuecomment-660248736:87,log,log,87,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/549#issuecomment-660248736,1,['log'],['log']
Testability,"Hi, . Thank you for helping me with my issue. I'm not sure if the mapping rate so low is reasonable in this case: the fastq files (R1 and R2) were generated reservely from the bam files. I tried both Hg38 and Hg19 for this dataset (only bam files available to me, which were aligned by Hg19 genome), and I got similarly low mapping rate. . The salmon log is like this:; ```; [2024-01-27 01:09:31.030] [jointLog] [info] setting maxHashResizeThreads to 20; [2024-01-27 01:09:31.030] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2024-01-27 01:09:31.030] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2024-01-27 01:09:31.030] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.; [2024-01-27 01:09:31.030] [jointLog] [info] parsing read library format; [2024-01-27 01:09:31.030] [jointLog] [info] There is 1 library.; [2024-01-27 01:09:31.032] [jointLog] [info] Loading pufferfish index; [2024-01-27 01:09:31.033] [jointLog] [info] Loading dense pufferfish index.; [2024-01-27 01:09:33.435] [jointLog] [info] done; [2024-01-27 01:09:33.508] [jointLog] [info] Index contained 252,048 targets; [2024-01-27 01:09:36.263] [jointLog] [info] Number of decoys : 0; [2024-01-27 01:09:41.237] [jointLog] [info] Automatically detected most likely library type as IU. [2024-01-27 01:10:28.189] [fileLog] [info] ; At end of round 0; ==================; Observed 3600210 total fragments (3600210 in most recent round). [2024-01-27 01:10:28.188] [jointLog] [info] Computed 179,584 rich equivalence classes for further processing; [2024-01-27 01:10:28.188] [jointLog] [info] Counted 446,871 total reads in the equivalence classes ; [2024-01-27 01:10:28.202] [jointLog] [warning] 0.197488% of fragments were shorter than the k used to build the index.; If this fraction is too large, consider re-building the index with a smaller k.; The m",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/908:351,log,log,351,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/908,1,['log'],['log']
Testability,"Hi, ; I am new to bioinformatics and scRNAseq.; I am working on a scRNAseq dataset i downloaded from GEO. Downloading the SRA file with fastq-dump --split-files resulted in 3 reads, i.e R1, R2, and R3. I understand the R3 reads are the sample index reads. Do I need to use this R3 as input for alevin quantification, since alevin only accepts two read at a time, i.e R1, R2. Additionally, I used R1 and R2 for the alevin quantification using the code;; salmon alevin -l ISR -i Homo_sapiens.GRCh38.transcript_103_salmon_index -1 F379_R1.fastq -2 F379_R2.fastq -o alevin_combinedRun -p 16 --tgMap txp2gene_BM.tsv --chromiumV3 --dumpFeatures . This resulted in 233 cells indicated in the figure below with Mapping rate less than 6%.; <img width=""473"" alt=""Alevin"" src=""https://user-images.githubusercontent.com/38905650/151156881-da620d2e-3e9a-41fc-acce-ef2722788424.PNG"">; log file; 2022-01-26 11:52:30.149] [jointLog] [info] setting maxHashResizeThreads to 16; [2022-01-26 11:52:30.149] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2022-01-26 11:52:30.149] [jointLog] [info] The --mimicBT2, --mimicStrictBT2 and --hardFilter flags imply mapping validation (--validateMappings). Enabling mapping validation.; [2022-01-26 11:52:30.149] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2022-01-26 11:52:30.149] [jointLog] [info] The use of range-factorized equivalence classes does not make sense in conjunction with --hardFilter. Disabling range-factorized equivalence classes. ; [2022-01-26 11:52:30.149] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.; [2022-01-26 11:52:30.149] [jointLog] [info] Using default value of 0.87 for minScoreFraction in Alevin; Using default value of 0.6 for consensusSlack in Alevin. However, when i included the --expectCells 15000 in the command, as shown below i obtained over 20,000 c",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/742:871,log,log,871,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/742,1,['log'],['log']
Testability,"Hi, ; I've been trying to run alevin for single cell data. I've been using test data and the salmon alevin command seems to work right until the end, and then the core is dumped just as counts are in the csv format. I've also tried running it without --dumpCsvCounts and this also results in a segmentation fault. . What I was running:; salmon alevin -l ISR -1 ./hgmm_100_S1_L002_001.fastq.1.gz -2 ./hgmm_100_S1_L002_001.fastq.2.gz --chromium -i geneset.dir/geneset_coding_exons.salmon.index -p 10 -o salmon.dir/hgmm_100_S1_L002_001 --tgMap transcript2geneMap.tsv --dumpCsvCounts. Final part of output:; Analyzed 287 cells (100% of all).; [2019-01-25 11:14:44.509] [alevinLog] [info] Total 46729.00 UMI after deduplicating.; [2019-01-25 11:14:44.509] [alevinLog] [warning] Skipped 63 barcodes due to No mapped read; [2019-01-25 11:14:44.529] [alevinLog] [info] Clearing EqMap; Might take some time.; [2019-01-25 11:14:44.561] [alevinLog] [info] Starting Import of the gene count matrix of size 224x19879.; [2019-01-25 11:14:44.576] [alevinLog] [info] Done initializing the empty matrix.; [2019-01-25 11:14:45.067] [alevinLog] [info] Done Importing gene count matrix for dimension 224x19879; [2019-01-25 11:14:45.770] [alevinLog] [info] Starting dumping cell v gene counts in csv format; Segmentation fault (core dumped) . I am running version 0.12.0 of salmon, installed via bioconda. I have also allocated 30GB of memory for the job, so this isn't a memory issue.; I have seen other users having similar issues using salmon quant having installed salmon through conda and the suggestions have been to install from binaries. This is not an option as salmon needs to be run easily using a conda environment. ; Has any headway been made into fixing the bioconda build?. Thanks,; Anna",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/337:75,test,test,75,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/337,1,['test'],['test']
Testability,"Hi, ; the output from the log is shown below. So apparently, everything went well, except for one minor issue... but my gene counts and my transcript count files are empty??; How is that possible; Cheers; Ashok; ```; [2017-07-18 17:14:11.438] [jointLog] [info] parsing read library format; [2017-07-18 17:14:11.438] [jointLog] [info] There is 1 library.; [2017-07-18 17:14:11.485] [jointLog] [info] Loading Quasi index; [2017-07-18 17:14:11.485] [jointLog] [info] Loading 32-bit quasi index; [2017-07-18 17:14:21.207] [jointLog] [info] done; [2017-07-18 17:14:21.207] [jointLog] [info] Index contained 107368 targets; [2017-07-18 17:14:22.320] [jointLog] [info] Automatically detected most likely library type as SF; [2017-07-18 17:22:52.788] [jointLog] [info] Computed 280679 rich equivalence classes for further processing; [2017-07-18 17:22:52.788] [jointLog] [info] Counted 27517563 total reads in the equivalence classes; [2017-07-18 17:22:52.850] [jointLog] [info] Mapping rate = 37.9965%. [2017-07-18 17:22:52.850] [jointLog] [info] finished quantifyLibrary(); [2017-07-18 17:22:52.853] [jointLog] [info] Starting optimizer; [2017-07-18 17:22:52.789] [fileLog] [info]; At end of round 0; ==================; Observed 72421398 total fragments (72421398 in most recent round). [2017-07-18 17:22:52.981] [jointLog] [info] Marked 1 weighted equivalence classes as degenerate; [2017-07-18 17:22:52.990] [jointLog] [info] iteration = 0 | max rel diff. = 9.36177; [2017-07-18 17:22:53.935] [jointLog] [info] iteration = 100 | max rel diff. = 0.0782409; [2017-07-18 17:22:54.889] [jointLog] [info] iteration = 200 | max rel diff. = 0.0347085; [2017-07-18 17:22:55.784] [jointLog] [info] iteration = 300 | max rel diff. = 0.0249461; [2017-07-18 17:22:56.790] [jointLog] [info] iteration = 400 | max rel diff. = 0.0188653; [2017-07-18 17:22:57.752] [jointLog] [info] iteration = 500 | max rel diff. = 0.0157419; [2017-07-18 17:22:58.688] [jointLog] [info] iteration = 600 | max rel diff. = 0.0128394; [20",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/143:26,log,log,26,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/143,1,['log'],['log']
Testability,"Hi, I had previousl tried using the `--whitelist` option using the 10x barcode whitelist (they're available at `cellranger-2.0.0/cellranger-cs/2.0.0/tenkit/lib/python/tenkit/barcodes/737K-august-2016.txt` and `4M-with-alts-february-2016.txt`). This had the same output as not using them. I just reran alevin with the `--dumpFeatures` flag, attached are the barcodes. I forgot to mention that with cellranger we saw that the knee was very soft, there was no sharp drop, and that might be what's confusing salmon. I had looked at the documentation but did not see a way to manually specify the cutoff. It is also desirable to manually the first few barcodes, because those have abnormally more counts than would be expected. Here's a log-log histogram of the alevin frequency output; ![image](https://user-images.githubusercontent.com/12504176/42296042-b9a944c6-7fa5-11e8-9f33-02a178d249ce.png). [frequency.txt](https://github.com/COMBINE-lab/salmon/files/2164480/frequency.txt)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/245#issuecomment-402569828:732,log,log-log,732,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/245#issuecomment-402569828,1,['log'],['log-log']
Testability,"Hi, I have some kind the same error of (https://github.com/COMBINE-lab/salmon/issues/251#issue-341161248). I download the prebuild index from refgenie and I got exactly the same error message. refgenie pull hg38/salmon_sa_index <- I downloaded the 16Gb of the index files. [2020-05-04 21:30:58.648] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2020-05-04 21:30:58.648] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2020-05-04 21:30:58.648] [jointLog] [info] Usage of --validateMappings, without --hardFilter implies use of range factorization. rangeFactorizationBins is being set to 4; [2020-05-04 21:30:58.648] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.2.; [2020-05-04 21:30:58.648] [jointLog] [info] parsing read library format; [2020-05-04 21:30:58.648] [jointLog] [info] There is 1 library.; [2020-05-04 21:30:58.701] [jointLog] [info] Loading Quasi index; Exception : [rapidjson internal assertion failure: IsObject()]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting. The son files of the index show this;; ls -lrth *json; -rwxrwxrwx 1 usr usr 1007 dic 14 00:41 info.json; -rwxrwxrwx 1 usr usr 96 dic 14 00:44 versionInfo.json. Any idea would be really appreciated,. Kind regards,; Fer",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/518:1121,assert,assertion,1121,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/518,1,['assert'],['assertion']
Testability,"Hi, I have some kind the same error. I download the prebuild index from refgenie and I got exactly the same error message. . refgenie pull hg38/salmon_sa_index <- I downloaded the 16Gb of the index files. [2020-05-04 21:30:58.648] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2020-05-04 21:30:58.648] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2020-05-04 21:30:58.648] [jointLog] [info] Usage of --validateMappings, without --hardFilter implies use of range factorization. rangeFactorizationBins is being set to 4; [2020-05-04 21:30:58.648] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.2.; [2020-05-04 21:30:58.648] [jointLog] [info] parsing read library format; [2020-05-04 21:30:58.648] [jointLog] [info] There is 1 library.; [2020-05-04 21:30:58.701] [jointLog] [info] Loading Quasi index; Exception : [rapidjson internal assertion failure: IsObject()]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting. The son files of the index show this;; ls -lrth *json; -rwxrwxrwx 1 usr usr 1007 dic 14 00:41 info.json; -rwxrwxrwx 1 usr usr 96 dic 14 00:44 versionInfo.json. Any idea would be really appreciated,. Kind regards, ; Fer",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/251#issuecomment-623664770:1053,assert,assertion,1053,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/251#issuecomment-623664770,1,['assert'],['assertion']
Testability,"Hi, I like salmon for RNA-Seq quantification. To better quantify my data, I have some questions.; I compared the number of reads in quant.sf file with the unique counts and ambiguous counts in ambig_info.tsv. Some final estimation are similar to the sum of unique+ambiguous, some closed to unique, and some closed to ambiguous. I want to know how did you estimate the final counts to combine the unique and ambiguous counts?; For the unstranded library, did you use the same algorithm to estimate the final counts as the stranded library? I test some sequences for unstranded library, the estimation for reverse complement sequence is same. Is there a better way to estimate the transcripts anti-overlapping with another one in unstranded library?. Thanks,; Jing",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/492:541,test,test,541,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/492,1,['test'],['test']
Testability,"Hi, I'm trying to use Alevin on a 10X v2 chemistry dataset, and after the preprocessing stpe I get the following error:; ```; Analyzed 1137 cells (11% of all).; ERROR: cell doesn't have any read count; ```; I tried looking at the documentation and previous tickets, but didn't find anything mentioning this issue. Is there any suggestion on how to address it?. The full terminal output is below. Thanks. ```; salmon alevin -lISR -1 cDNA_Small_S1_L001_R1_001.fastq.gz -2 cDNA_Small_S1_L001_R2_001.fastq.gz --chromium -i index -p 20 -o alevin_output9 --tgMap txp2gene.tsv --dumpCsvCounts; Version Info: This is the most recent version of Salmon.; Logs will be written to alevin_output9/logs; ### salmon (single-cell-based) v0.10.2; ### [ program ] => salmon; ### [ command ] => alevin; ### [ libType ] => { ISR }; ### [ mates1 ] => { cDNA_Small_S1_L001_R1_001.fastq.gz }; ### [ mates2 ] => { cDNA_Small_S1_L001_R2_001.fastq.gz }; ### [ chromium ] => { }; ### [ index ] => { index }; ### [ threads ] => { 20 }; ### [ output ] => { alevin_output9 }; ### [ tgMap ] => { txp2gene.tsv }; ### [ dumpCsvCounts ] => { }. [2018-06-30 22:10:28.044] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2018-06-30 22:10:28.048] [alevinLog] [info] Processing barcodes files (if Present). processed 17 Million barcodes. [2018-06-30 22:10:47.141] [alevinLog] [info] Done barcode density calculation.; [2018-06-30 22:10:47.141] [alevinLog] [info] # Barcodes Used: 17712582 / 17712585.; [2018-06-30 22:10:52.008] [alevinLog] [info] Knee found left boundary at 9447; [2018-06-30 22:10:52.498] [alevinLog] [warning] Gauss Prediction 0 Too far from knee prediction skipping it; [2018-06-30 22:10:52.498] [alevinLog] [info] Learned InvCov: 457.073 normfactor: 260.286; [2018-06-30 22:10:52.498] [alevinLog] [info] Total 10434(has 987 low confidence) barcodes; [2018-06-30 22:10:52.530] [alevinLog] [info] Done True Barcode Sampling; [2018-06-30 22:10:53.101] [alevinLo",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/245:645,Log,Logs,645,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/245,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"Hi, I've been using salmon v1.0.0 to quantify bulk transcripts from fastqs using the genocde v32 reference. Ive used it successfully on several cohorts but on my most recent I received the following warning in my log file (I also attached the entire file):. [2021-05-10 20:51:46.936] [jointLog] [warning] NOTE: Read Lib [[ /gcloud-shared/inputR1.gz, /gcloud-shared/inputR2.gz]] :. Detected a *potential* strand bias > 1% in an unstranded protocol check the file: /gcloud-shared/sample/lib_format_counts.json for details. Here is also the lib_formats_count.json:; {; ""read_files"": ""[ /gcloud-shared/inputR1.gz, /gcloud-shared/inputR2.gz]"",; ""expected_format"": ""IU"",; ""compatible_fragment_ratio"": 1.0,; ""num_compatible_fragments"": 43142675,; ""num_assigned_fragments"": 43142675,; ""num_frags_with_concordant_consistent_mappings"": 36380775,; ""num_frags_with_inconsistent_or_orphan_mappings"": 7777480,; ""strand_mapping_bias"": 0.5172763911708863,; ""MSF"": 0,; ""OSF"": 0,; ""ISF"": 18818916,; ""MSR"": 0,; ""OSR"": 0,; ""ISR"": 17561859,; ""SF"": 2219340,; ""SR"": 5558140,; ""MU"": 0,; ""OU"": 0,; ""IU"": 0,; ""U"": 0; }. Here is the salmon command I've been using:. salmon --no-version-check quant -i /gcloud-shared/reference -l A -1 ${FASTQR1} -2 ${FASTQR2} \; --validateMappings --seqBias --gcBias --posBias --threads $(nproc) -o /gcloud-shared/sample. The whole process still produces quants files, but having never received this warning with other sample cohorts I want to be sure it's not affecting the results. Any idea why I might be getting this? Am I using the wrong lib type?. Thanks!. [ukbec_quants_gencode_32_filtered_A653_002_logs_salmon_quant.log](https://github.com/COMBINE-lab/salmon/files/6479118/ukbec_quants_gencode_32_filtered_A653_002_logs_salmon_quant.log)",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/659:213,log,log,213,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/659,3,['log'],['log']
Testability,"Hi, Rob, thanks for the quick reply! By the way, great job on salmon!. Using ./ did fix the issue. About the stdout issue, I'm running:. ~/programs/Salmon-0.7.2_linux_x86_64/bin/salmon quant -i /data/reference/salmon/gencode.grch37.v19/ -r test.fastq --seqBias --gcBias --posBias -p 12 --geneMap /data/reference/salmon/gencode.grch37.v19/geneMap.txt --libType U -o x --writeMappings > out.sam. and not all messages are output to stderr (I'm not using 2> ). The ones starting with ### do, but others end up in out.sam. out.sam starts with:. ESC[1m[2016-09-14 11:37:38.908] [jointLog] [info] parsing read library format; ESC[00mESC[1m[2016-09-14 11:37:38.908] [jointLog] [info] There is 1 library.; ESC[00mESC[1m[2016-09-14 11:37:43.996] [jointLog] [info] Loading Quasi index; ESC[00mESC[1m[2016-09-14 11:37:43.996] [jointLog] [info] Loading 32-bit quasi index; ESC[00mESC[1m[2016-09-14 11:37:43.996] [stderrLog] [info] Loading Suffix Array ; ESC[00mESC[1m[2016-09-14 11:38:06.669] [stderrLog] [info] Loading Transcript Info ; ESC[00mESC[1m[2016-09-14 11:38:12.374] [stderrLog] [info] Loading Rank-Select Bit Array; ESC[00mESC[1m[2016-09-14 11:38:12.444] [stderrLog] [info] There were 95309 set bits in the bit array; ESC[00mESC[1m[2016-09-14 11:38:12.700] [stderrLog] [info] Computing transcript lengths; ESC[00mESC[1m[2016-09-14 11:38:12.700] [stderrLog] [info] Waiting to finish loading hash; ESC[00mESC[1m[2016-09-14 11:39:49.792] [stderrLog] [info] Successfully loaded position hash; ESC[00mESC[1m[2016-09-14 11:39:49.792] [stderrLog] [info] Done loading index; ESC[00mESC[1m[2016-09-14 11:39:49.792] [jointLog] [info] done; ESC[00mESC[1m[2016-09-14 11:39:49.792] [jointLog] [info] Index contained 95309 targets; ESC[00mESC[33mESC[1m[2016-09-14 11:40:18.128] [jointLog] [warning] Fragment GC bias correction is currently only implemented for paired-end libraries. Disabling fragment GC bias correction for this run; ESC[00m@HD VN:1.0 SO:unknown",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/90#issuecomment-247078586:240,test,test,240,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/90#issuecomment-247078586,1,['test'],['test']
Testability,"Hi, Rob. I'm migrating the previous known-good formula from the deprecated Homebrew/science tap to the new Brewsci/bio tap. I usually first migrate the last known-good formula, and then in a second PR bump the version to the most recent version. I'll bump the version know though for the sake of troubleshooting. Here's the build log for 0.9.1: https://circleci.com/gh/brewsci/homebrew-bio/500. ~~By default CircleCI runs with `make -j32`. Is it perhaps an issue with the Makefile not liking parallel?~~; I see that it's already being run with `make -j1` because it's known not to like being run in parallel. > Any idea why this might be happening? Does the CI environment prohibit this for some reason?. I'm not aware of any reason that it wouldn't be run. `curl` is installed.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/181#issuecomment-367734290:330,log,log,330,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/181#issuecomment-367734290,1,['log'],['log']
Testability,"Hi, Rob. I'm seeing this same error `Cannot find source file`; ```; -- Configuring done; CMake Error at src/CMakeLists.txt:113 (add_executable):; Cannot find source file:; /tmp/salmon-20180222-8345-abjxc0/salmon-0.8.2/external/install/src/rapmap/RapMapFileSystem.cpp; Tried extensions .c .C .c++ .cc .cpp .cxx .m .M .mm .h .hh .h++ .hm .hpp; .hxx .in .txx; ```; See the complete build log at https://circleci.com/gh/brewsci/homebrew-bio/491; Any ideas?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/181#issuecomment-367590842:385,log,log,385,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/181#issuecomment-367590842,1,['log'],['log']
Testability,"Hi, is it possible to share the logs and the minimal version of the data on which we can replicate the bug?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/407#issuecomment-514929400:32,log,logs,32,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/407#issuecomment-514929400,1,['log'],['logs']
Testability,"Hi, this got rectified by using ENSEMBL gene ids rather than gene symbol/gene names.; Other issues are : none of my mitochondrial and ribosomal gene lists are able to find in the reference index.; The log file attached:; [alevin.log](https://github.com/COMBINE-lab/salmon/files/3430327/alevin.log); The index reference genome is from gencodeV31.pc.transcripts.fa.gz from gencode human; The txptogene contains list of ENST* -- > ENSG*",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/407#issuecomment-514935938:201,log,log,201,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/407#issuecomment-514935938,3,['log'],['log']
Testability,"Hi, this is following on from our discussion in Bioconductor Slack (channel `#singlecell-queries`) from a few weeks ago. Thanks again for the update to propagate cellular barcode and UMI tags in the alevin generated BAM/SAM (with the `--writeMappings` flag). We have been testing this out, and have been able to access all this information by parsing through the SAM file. However in the end our plan to use this with [Vireo](https://vireosnp.readthedocs.io/en/latest/index.html) and [cellSNP](https://github.com/single-cell-genetics/cellSNP) for genetic demultiplexing of samples didn't really work out, mainly because `alevin` generates a transcriptomic BAM, and `cellSNP` expects a genomic BAM and VCF. I tried a few different options for getting this to work, including (i) attempting to convert to a genomic BAM using [sam-xlate](https://github.com/mozack/ubu/wiki) (which didn't seem to work because `sam-xlate` is designed to convert in the other direction), and (ii) converting the VCF to transcriptomic coordinates, as suggested [here](https://github.com/single-cell-genetics/cellSNP/issues/14) by the `Vireo`/`cellSNP` authors (the VCF conversion seemed to work, but `cellSNP` still didn't match it to the BAM properly). For now, I think we are going to go back to using `Cell Ranger` in our pipeline, since this did work with `Vireo`/`cellSNP`, although was of course much slower than `alevin` and has issues with multi-mapping reads. If you have any other ideas please let me know too. However I also wanted to suggest that if there is any interest on your end in developing some sort of conversion tool (transcriptomic BAM -> genomic BAM) for `alevin` outputs, then I think this would be super useful for people, especially if these genetic demultiplexing tools become more widely used. (We have been getting very good demultiplexing performance with `Cell Ranger` + `Vireo`/`cellSNP`, and are planning to release some of our code as a small `Snakemake` pipeline for others to use, so if ",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/550:272,test,testing,272,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/550,1,['test'],['testing']
Testability,"Hi, this is the log. I give the external whitelist which inculed 9185 barcodes. ; Yeah, I mean the 9253 cells. It comes from the output from the paper. . Bests,; Hongyu. > On Jun 13, 2019, at 2:33 PM, Avi Srivastava <notifications@github.com> wrote:; > ; > Hi @hliu5259 <https://github.com/hliu5259> ,; > can you forward the log ?; > There can be multiple reasons, did you gave external whitelist ? When you say 9253 samples do you mean 9253 cells ? How did you fix the number of cells ?; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/COMBINE-lab/salmon/issues/375?email_source=notifications&email_token=AK7LCF6ALRVM7WPLKREVDT3P2KHI3A5CNFSM4HX4WLH2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODXUUVDQ#issuecomment-501828238>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AK7LCF5HE6PY2FLHJB26QO3P2KHI3ANCNFSM4HX4WLHQ>.; >",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/375#issuecomment-501831515:16,log,log,16,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/375#issuecomment-501831515,2,['log'],['log']
Testability,"Hi, who's concerning,; I was using alevin to run on a PBMC 10xv3 dataset.; Here is my script,; salmon alevin -lISR -1 $fastq1 -2 $fastq2 --chromiumV3 -i $work_p/salmon_index_human -p 12 -o output --tgMap $data_p/test12.tsv --keepCBFraction 1. I kept all CB to make sure I can use emptyDrops. Also, here this index is SAF index followed by your tutorial. Then I got the error message like:; [alevin.log](https://github.com/COMBINE-lab/salmon/files/7035475/alevin.log). Is there any suggestion on how to solve this?; Cheers,; Chloe",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/698:398,log,log,398,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/698,2,['log'],['log']
Testability,"Hi,. I am running salom 0.6.0 on a Ubuntu server. here is my command as well as the STDOUT output:. ```; salmon quant -p 16 --biasCorrect --libType IU -i ~./Salmon/Salmon.index/Homo_sapiens.GRCh38.rel79/ --numBootstraps 100 -o $base <(zcat ${base}_1.fastq.gz ) <(zcat ${base}_2.fastq.gz); Version Info: This is the most recent version of Salmon.; # salmon (mapping-based) v0.6.0 ; # [ program ] => salmon; # [ command ] => quant; # [ threads ] => { 16 }; # [ biasCorrect ] => { }; # [ libType ] => { IU }; # [ index ] => { ./Salmon/Salmon.index/Homo_sapiens.GRCh38.rel79/ }; # [ numBootstraps ] => { 100 }; # [ output ] => { 61LP1AAXX_8 } ; # [ ] => { /dev/fd/63 }; # [ ] => { /dev/fd/62 }; Logs will be written to 61LP1AAXX_8/logs; there is 0[2016-07-11 09:51:45.206] [jointLog] [info] parsing read library format; lib; Loading 32-bit quasi index[2016-07-11 09:51:45.328] [jointLog] [info] Loading Quasi index; [2016-07-11 09:51:45.736] [stderrLog] [info] Loading Suffix Array; [2016-07-11 09:51:45.771] [stderrLog] [info] Loading Position Hash; [2016-07-11 09:52:13.781] [stderrLog] [info] Loading Transcript Info; [2016-07-11 09:52:20.821] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-07-11 09:52:21.877] [stderrLog] [info] There were 173259 set bits in the bit array; [2016-07-11 09:52:22.030] [stderrLog] [info] Computing transcript lengths; [2016-07-11 09:52:22.030] [stderrLog] [info] Waiting to finish loading hash; Index contained 173259 targets; [2016-07-11 09:52:26.970] [jointLog] [info] done; [2016-07-11 09:52:26.970] [stderrLog] [info] Done loading index. [2016-07-11 09:52:27.327] [jointLog] [info] Computed 0 rich equivalence classes for further processing; [2016-07-11 09:52:27.327] [jointLog] [info] Counted 0 total reads in the equivalence classes ; [2016-07-11 09:52:39.858] [jointLog] [warning] Only 0 fragments were mapped, but the number of burn-in fragments was set to 5000000.; The effective lengths have been computed using the observed mappings. **[2016-07-11 09",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/65:691,Log,Logs,691,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/65,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"Hi,. I am running the latest version of Salmon 0.8.2 and I am getting the following error. I did remake the transcript index with the new version of salmon. I get no errors when i compile or run the ""make test"". . Logs will be written to salmon_output_A9039/logs; [2017-05-08 08:59:23.370] [jointLog] [info] parsing read library format; [2017-05-08 08:59:23.370] [jointLog] [info] There is 1 library.; [2017-05-08 08:59:23.395] [stderrLog] [error] Encountered exception [JSON Parsing failed - provided NVP (SeqHash) not found] when loading index.; [2017-05-08 08:59:23.395] [stderrLog] [error] The index was likely build with an older (and incompatible) version of RapMap. Please re-build the index with a compatible version. Using boost 1.64, Clang 3.9, on a linux box. Any help will be appreciated. Thanks",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/135:205,test,test,205,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/135,3,"['Log', 'log', 'test']","['Logs', 'logs', 'test']"
Testability,"Hi,. I am testing Alevin, and would like to compare against Cell Ranger on my data set. While primary mapping statistics indicate more reads mapped, I would like to compare the results in the final analysis, in Seurat. Many steps rely on HGNC Gene symbols as opposed to Ensemble IDs. ### What is the best way to convert ensembl IDs to gene symbol in Alevin?. Alevin (aligned as in this [gist](https://gist.github.com/k3yavi/c501705ed2d29b12b0d10cf78b3ed001#file-alevin-default-ipynb), imported to R in this [tutorial](https://combine-lab.github.io/alevin-tutorial/2018/running-alevin/)) returns ensembl IDs in format like ""ENSG00000215910.7"". ```R; require(""fishpond""); require(""tximport""); ; files <- file.path(""[...]/alevin/quants_mat.gz""); file.exists(files); txi <- tximport(files, type=""alevin"");; rownames( txi$counts); ``` . I am currently converting these using biomart with suboptimal adaptations:. ```R; BiocManager::install(""biomaRt""); require('biomaRt'); mart <- useDataset(""hsapiens_gene_ensembl"", useMart(""ensembl"")); genes <- rownames(txi$counts); df$id <- NA; meta.genes <- getBM(attributes = c(""ensembl_gene_id"",""external_gene_name"", ""description""), ; values = genes, mart = mart ); ```; Manual adaptations:. 1. I trim IDs after dot (""ENSG00000215910.7"" → ""ENSG00000215910”); 2. I remove NA values (not all trimmed gene IDs are found in biomaRt); 3. I add up counts of genes (per ENS.ID) with the same gene symbol, e.g. “Y_RNA” or “HSPA14”. ```R; g.LookUp = meta.genes[,2]; names(g.LookUp) = meta.genes[,1]; ; # 1. Trim; ensembl_ID.simple =str_split_fixed(genes,pattern = '\\.', n=2)[,1]; ; genes.converted = g.LookUp[ensembl_ID.simple]; any.duplicated(genes.converted); ; # ...etc; ```. Is there a better way to convert IDs, possibly implemented in Alevin / Salmon?",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/448:10,test,testing,10,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/448,1,['test'],['testing']
Testability,"Hi,. I am trying to use alevin and alevin-fry to process a mixing experiment with human and mouse cells and generate a plot comparing the amount of UMIs assigned to each species per cell. Since I am using the newer workflow with alevin-fry, I am generating a RAD file with salmon alevin then processing with alevin-fry. For the species-mixed data, I generated a concatenated reference with both mouse and human transcripts to do one alignment on the data. . Starting from ~210m raw reads, I get 139m aligned, and 59m of those are uniquely mapped according to salmon_quant.log. When running alevin-fry, I use the `--resolution trivial` flag to force quantification by uniquely mapped reads alone. However, this procedure does not seem to work, as over 90% of reads map to mouse even though the two species should have been mixed evenly. Do I need to approach this in a different way?",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/715:572,log,log,572,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/715,1,['log'],['log']
Testability,"Hi,. I did refactoring for `.travis.yml`.; This pull-request is for develop branch. * Aligned with 2 spaces indent.; * Removed tailing space.; * Removed old commended out lines on bottom area.; We can check past modification with `git log -p .travis.yml`.; So, I think we can remove the comment lines.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/292:235,log,log,235,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/292,1,['log'],['log']
Testability,"Hi,. I have been running salmon v1.4.0 on 324 samples. In 8 samples I did not get any quantification and the process ended with a warning like "".....salmon was only able to assign 0 fragments to transcripts in the index...."". The command line I used is as follow (I simplified the paths and file names):; salmon quant -p 20 -i Salmon_Index -l A --seqBias --gcBias --biasSpeedSamp -1 $FASTQ1.R1.fastq.gz -2 $FASTQ2.R2.fastq.gz -o $outDIR --validateMappings. These same 8 samples were processed with HISAT2 and the overall alignment rate was above 80%. I attached the log file for one of the 8 runs; [logFile.txt](https://github.com/COMBINE-lab/salmon/files/5846381/logFile.txt). Do you have any suggestions ? do you need more info ?. Thanks",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/616:566,log,log,566,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/616,3,['log'],"['log', 'logFile']"
Testability,"Hi,. I have been trying to run the installed salmon version on our HPC cluster on minimap aligned ONT reads and got the following error:. `processed 0 reads in current round/var/lib/slurm/slurmd/job10333001/slurm_script: line 25: 2153273 Bus error (core dumped)`. My script was as follows:. ```; module load salmon/1.9.0-gcc-10.3.0; cd /scratch/prj/ppn_microglia_mod/targeted/transcriptome/clean/transcriptome. for bc in {01..54}; do. salmon quant --ont -t /scratch/users/k19022845/refgenome/gencode.v44.transcripts.fa -l A -a ""combined_BC""$bc""_aligned.bam"" -o ""BC""$bc""_transcripts_quant"". done; ```; Salmon version was `1.9.0`; Transcriptome ref: Homo Sapiens Gencode v.44. The directories were generated for the barcodes and contain `aux info`, `cmd_info.json`, `libParams` and `logs` but the directories/files are empty. The command was run through `slurm` scheduler on HPC cluster. The output log looks like (repeated for `for` loop):; ```; Version Info: ### PLEASE UPGRADE SALMON ###; ### A newer version of salmon with important bug fixes and improvements is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; Sign up for the salmon mailing list to hear about new versions, features and updates at:; https://oceangenomics.com/subscribe; # salmon (alignment-based) v1.9.0; # [ program ] => salmon ; # [ command ] => quant ; # [ ont ] => { }; # [ targets ] => { /scratch/users/k19022845/refgenome/gencode.v44.transcripts.fa }; # [ libType ] => { A }; # [ alignments ] => { combined_BC01_aligned.bam }; # [ output ] => { BC01_trascripts_quant }; Logs will be written to BC01_trascripts_quant/logs; [2023-11-04 16:49:44.093] [jointLog] [info] setting maxHashResizeThreads to 8; [2023-11-04 16:49:44.093] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; Library format { type:single end",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/898:781,log,logs,781,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/898,2,['log'],"['log', 'logs']"
Testability,"Hi,. I have run a RNAseq sample through Salmon with --l A option (library type); I was told regarding the in-house protocol to generate the library that ""The first read reads off the anti-sense strand, and the second reads off of the sense strand. From what I understand, the first read is reported as the sense strand, and the second read is reported as the anti-sense strand (as the reverse complement)"". i.e. similar to TruSeq (first read comes from anti-sense/reverse strand). That would translate into ISR according to http://salmon.readthedocs.io/en/latest/library_type.html. Yet from the Salmon quant log file = Automatically detected most likely library type as ISF.; If I run the same sample with -l ISF I get the warning:; Greater than 5% of the fragments disagreed with the provided library type; check the file: 2RD_1760_salmon_quant_ISF/lib_format_counts.json for details - ; which shows:; ""expected_format"": ""ISF"",; ""compatible_fragment_ratio"": 0.9281440552329109,; ""num_compatible_fragments"": 8223296,; ""num_assigned_fragments"": 8859935,; ""num_consistent_mappings"": 67110116,; ""num_inconsistent_mappings"": 13842824,; ""MSF"": 0,; ""OSF"": 120231,; ""ISF"": 67110116,; ""MSR"": 0,; ""OSR"": 12968,; ""ISR"": 11405988,; ""SF"": 1926077,; ""SR"": 353507,. I would be very grateful for a possible explanation. Thank you very much!",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/206:608,log,log,608,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/206,1,['log'],['log']
Testability,"Hi,. I have the problem that salmon quant exits with a segfault when more than one BAM file is provided. ; If the BAM files are provided one at a time, no error or segfault happens and salmon wickedly fast quantificates the transcripts. The first used BAM files where shuffled (with samtools bamshuf) as recommended in the docs. To exclude an error on my side I did:; - try unshuffled BAM files --> Segfault; - try older Salmon Version (7.2) --> Segfault; - build Salmon from source --> Segfault; - use different transcriptdata (see below) --> Segfault. The segfault happens after all reads (in all files) are processed:; `processed 48000000 reads in current roundSegmentation fault`. ### Example workflow:. Get the read data from [here](https://trace.ncbi.nlm.nih.gov/Traces/sra/sra.cgi?run=ERR1433122) for example with SRA Toolkit:; `vdb-dump -f fastq --gzip --output-file test.fastq.gz ERR1433122`. Then use STAR:. First build a genome index for the reference transcriptset from [here](https://ics.hutton.ac.uk/atRTD/) and the [TAIR10 genome](https://www.arabidopsis.org/download/index-auto.jsp?dir=%2Fdownload_files%2FGenes%2FTAIR10_genome_release%2FTAIR10_chromosome_files); You probably have to rename the chromosomes either in the .gtf or .fas file, to have consistent names. `STAR --runThreadN 4 --runMode genomeGenerate --genomeDir genome_index/ --genomeFastaFiles TAIR10_chr_all_edited.fas --sjdbGTFfile AtRTD2_19April2016.gtf --sjdbOverhang 100`. Then map:. `STAR --runThreadN 4 --genomeDir genome_index --readFilesCommand zcat --readFilesIn test.fastq.gz --sjdbOverhang 100 --sjdbGTFfile AtRTD2_19April2016.gtf --outFileNamePrefix mapping/ --quantMode TranscriptomeSAM`. and make a .fa file from the genome and the .gtf with:; `gffread -w gff_merged.fa -g TAIR10_chr_all_edited.fas AtRTD2_19April2016.gtf`. Now make a copy of the ""Aligned.toTranscriptome.out.bam"" (for the sake of simplicity) and try; `salmon quant -l A -a Aligned.toTranscriptome.out.bam Aligned.toTranscriptome.out_copy.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/145:875,test,test,875,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/145,1,['test'],['test']
Testability,"Hi,. I recently used STAR and Salmon to quantify RNA expression from FASTQ files. When using Salmon, I was achieving good alignment rates of around 70%, but getting dismal STAR alignment rates of 1%-20% (both using GENCODE v38 references). Further inspection of my STAR log files shows most reads were being unmapped because they were too short. From STAR github issues I discovered that my FASTQ files were scrambled (confirmed with [validatefastq](https://github.com/biopet/validatefastq) tool), and the read headers were not properly sorted. This meant that the reads in the `R1` file did not necessarily correspond to the reads in the `R2` file (this was confirmed by BLASTing some of the reads and seeing they corresponded to different loci). . After discovering my FASTQs were scrambled, I was surprised that Salmon still had such high alignment rates yet STAR did not. I was wondering how exactly Salmon handles input FASTQs with mismatched reads. Is there some fix that Salmon applies to match reads with their corresponding sequence ID, thus explaining the high alignment rate? Are the results from Salmon on my bad input FASTQs complete gibberish and should be discarded, or are they somehow still valid? Is there any defined behavior that Salmon should follow when it encounters improperly sorted input FASTQs?",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/777:270,log,log,270,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/777,1,['log'],['log']
Testability,"Hi,. I think keeping this all in one issue is best. First, i applaud your Herculean effort! I don't have access to a FreeBSD or OpenBSD box, which is partly why we hadn't seen these issues. I can look into this, but testing is hard b/c i don't have the target environment. In the meantime, if you are just trying to use the software, perhaps give the Docker image a try (as i hear Docket can be cajoled to work on FreeBSD).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/162#issuecomment-337396709:216,test,testing,216,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/162#issuecomment-337396709,1,['test'],['testing']
Testability,"Hi,. I try to follow Alevin tutorial on 'How to Use alevin with Seurat' and have an issue with tximport(). I found this step is extremely **slow**. For **quants_mat.gz** file with **4.7M** in size, it took **12** minutes to finish. Is this common for alevin generated single cell data? . Thanks!; Lei. ## Test data: 10x 1k_PMBC_v2; ### Intel(R) Xeon(R) CPU E5-2698 v3 @ 2.30GHz; ## alevin.log; [2019-07-18 14:13:59.692] [alevinLog] [info] Loading Header; [2019-07-18 14:13:59.692] [alevinLog] [info] Loading Transcript Info; [2019-07-18 14:14:00.014] [alevinLog] [info] Found all transcripts to gene mappings; [2019-07-18 14:14:00.023] [alevinLog] [info] Processing barcodes files (if Present); [2019-07-18 14:15:51.124] [alevinLog] [info] Done barcode density calculation.; [2019-07-18 14:15:51.124] [alevinLog] [info] # Barcodes Used: 76866957 76921082.; [2019-07-18 14:15:51.553] [alevinLog] [info] Done importing white-list Barcodes; [2019-07-18 14:15:51.853] [alevinLog] [warning] Skipping 575996 Barcodes as no read was mapped; [2019-07-18 14:15:52.078] [alevinLog] [info] Total 161284 white-listed Barcodes; [2019-07-18 14:15:52.259] [alevinLog] [info] Total 5.95793% reads will be thrown away because of noisy Cellular barcodes.; [2019-07-18 14:15:58.709] [alevinLog] [info] Done populating Z matrix; [2019-07-18 14:15:58.741] [alevinLog] [info] Total 56814 CB got sequence corrected; [2019-07-18 14:15:58.750] [alevinLog] [info] Done indexing Barcodes; [2019-07-18 14:15:58.750] [alevinLog] [info] Total Unique barcodes found: 687531; [2019-07-18 14:15:58.750] [alevinLog] [info] Used Barcodes except Whitelist: 44516; [2019-07-18 14:15:58.973] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify; [2019-07-18 14:15:58.973] [alevinLog] [info] parsing read library format; [2019-07-18 14:24:27.923] [alevinLog] [info] Starting optimizer; [2019-07-18 14:24:28.655] [alevinLog] [warning] 24 mitorna gene(s) does not have transcript in the reference; [2019-07-18 14:24:28.655] [al",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/404:305,Test,Test,305,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/404,2,"['Test', 'log']","['Test', 'log']"
Testability,"Hi,. I'm having issues getting alevin to work on dropseq data after following the tutorial for setting it up. I am using the following command to run it:. salmon alevin -l ISR -1 SRR6054189.sra_1.fastq -2 SRR6054189.sra_2.fastq --dropseq -i ~/Documents/CordBlood/data/index_15 -p 10 -o ~/Documents/CordBlood/data/alevin_out --tgMap ~/Documents/CordBlood/data/txp2gene.tsv --dumpCsvCounts. and eventually get; ""Incorrect call for umi extract"". Here's the full output:. ```; salmon alevin -l ISR -1 SRR6054189.sra_1.fastq -2 SRR6054189.sra_2.fastq --dropseq -i ~/Documents/CordBlood/data/index_15 -p 4 -o ~/Documents/CordBlood/data/alevin4p_out_combined --tgMap ~/Documents/CordBlood/data/txp2gene.tsv --dumpCsvCounts; Version Info: This is the most recent version of Salmon.; Logs will be written to ~/Documents/CordBlood/data/alevin4p_out_combined/logs; ### salmon (single-cell-based) v0.11.0; ### [ program ] => salmon ; ### [ command ] => alevin ; ### [ libType ] => { ISR }; ### [ mates1 ] => { SRR6054189.sra_1.fastq }; ### [ mates2 ] => { SRR6054189.sra_2.fastq }; ### [ dropseq ] => { }; ### [ index ] => {~/Documents/CordBlood/data/index_15 }; ### [ threads ] => { 4 }; ### [ output ] => {~/Documents/CordBlood/data/alevin4p_out_combined }; ### [ tgMap ] => {~/Documents/CordBlood/data/txp2gene.tsv }; ### [ dumpCsvCounts ] => { }. [2018-07-26 11:15:08.510] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2018-07-26 11:15:08.524] [alevinLog] [info] Processing barcodes files (if Present) . ; processed 471 Million barcodes. [2018-07-26 11:25:20.231] [alevinLog] [info] Done barcode density calculation.; [2018-07-26 11:25:20.231] [alevinLog] [info] # Barcodes Used: 470701906 / 471465434.; [2018-07-26 11:25:30.228] [alevinLog] [info] Knee found left boundary at 202 ; [2018-07-26 11:25:31.135] [alevinLog] [info] Gauss Corrected Boundary at 22 ; [2018-07-26 11:25:31.135] [alevinLog] [info] Learned InvCov: 1044.2 normfactor: 295.23",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/258:775,Log,Logs,775,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/258,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"Hi,. I'm running into an issue with quant and hope you could help. Get this error message saying my index/versionInfo.json does not seem to exist (screenshot attached). I have single end reads spread across 5 fastq files per sample. Just trying to run one sample as a test before looping it. . I have tried building an index both with Salmon v 0.8.1 using a conda install as well as salmon v0.9.1 installing directly the binary on a linux computing cluster. . I've attached a screenshot of the indexing process (it boots me out at the end but I cant tell from the outputs if it was cut short, last thing it notes is writing sequence data to the file). I've also attached a screenshot of the generated index folder contents. The index is the most recent Ensembl FASTA cDNA download for mouse. I tried indexing a transcripts FASTA file from Gencode as well and am running into the same issue, so dont think its the specific reference. The reference transcript files are 54 and 56mb respectively, so no issues downloading and transferring to our cluster. . Any thoughts are much appreciated! Thanks!. Paul. ![screen shot 2018-02-12 at 15 37 54](https://user-images.githubusercontent.com/23369975/36214991-d3b453ec-1178-11e8-8331-d641a334c47b.png); ![screen shot 2018-02-12 at 12 41 33](https://user-images.githubusercontent.com/23369975/36214993-d3bf729a-1178-11e8-9c78-38158e423b9b.png); ![screen shot 2018-02-12 at 15 33 53](https://user-images.githubusercontent.com/23369975/36214994-d3cb52cc-1178-11e8-9f74-6cfd554ccb0a.png); ![screen shot 2018-02-12 at 15 35 16](https://user-images.githubusercontent.com/23369975/36214995-d3d50376-1178-11e8-81c3-90de0a347763.png)",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/197:268,test,test,268,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/197,1,['test'],['test']
Testability,"Hi,. My salmon quant program killed itself with the following message. Have no idea what's going on. Maybe because of the memory? I use MacBook pro with 16GB of memory. command =======; conda activate salmon; salmon quant -i salmon_sa_index -l ISR -1 testData/XX_R1.fastq.gz -2 testData/XX_R2.fastq.gz --validateMappings -o XX_2. error message: =======; validateMappings -o XX_2; Version Info: This is the most recent version of salmon.; ### salmon (selective-alignment-based) v1.3.0; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { salmon_sa_index }; ### [ libType ] => { ISR }; ### [ mates1 ] => { testData/XX_R1.fastq.gz }; ### [ mates2 ] => { testData/XX_R2.fastq.gz }; ### [ validateMappings ] => { }; ### [ output ] => { XX_2 }; Logs will be written to XX_2/logs; [2020-08-13 09:35:38.575] [jointLog] [info] setting maxHashResizeThreads to 12; [2020-08-13 09:35:38.576] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2020-08-13 09:35:38.576] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2020-08-13 09:35:38.576] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.35.; [2020-08-13 09:35:38.576] [jointLog] [info] parsing read library format; [2020-08-13 09:35:38.577] [jointLog] [info] There is 1 library.; [2020-08-13 09:35:38.642] [jointLog] [info] Loading pufferfish index; [2020-08-13 09:35:38.642] [jointLog] [info] Loading dense pufferfish index.; -----------------------------------------; | Loading contig table | Time = 11.256 s; -----------------------------------------; size = 36981178; -----------------------------------------; | Loading contig offsets | Time = 127.43 ms; -----------------------------------------; -----------------------------------------; | Loading reference lengths | Time = 3.7792 ms; -------------------------------",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/560:251,test,testData,251,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/560,6,"['Log', 'log', 'test']","['Logs', 'logs', 'testData']"
Testability,"Hi,. We (@emilyburke, @andrewejaffe and me) can successfully run salmon using 1 core in the SGE-managed cluster we have access to. The problem is that for some reason we have to request a lot of memory, thus reducing the number of jobs we can run simultaneously and increasing the overall time it takes to process datasets. . I see in https://github.com/COMBINE-lab/salmon/issues/97 that you suggest using `--perfectHash` and a newer `salmon` version, which we haven't tried and might end up being the solution. Here is the bash script we used to run `salmon` for a 422 sample dataset:. ```bash; #!/bin/bash; #$ -cwd; #$ -l mem_free=80G,h_vmem=90G,h_fsize=100G; #$ -N step6-txQuant-alzheimer.gsk_phaseII; #$ -pe local 1; #$ -o ./logs/txQuant-alzheimer.$TASK_ID.txt; #$ -e ./logs/txQuant-alzheimer.$TASK_ID.txt; #$ -t 1-422; #$ -m a; echo ""**** Job starts ****""; date. echo ""**** JHPCE info ****""; echo ""User: ${USER}""; echo ""Job id: ${JOB_ID}""; echo ""Job name: ${JOB_NAME}""; echo ""Hostname: ${HOSTNAME}""; echo ""Task id: ${TASK_ID}"". FILE1=$(awk 'BEGIN {FS=""\t""} {print $1}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); FILE2=$(awk 'BEGIN {FS=""\t""} {print $3}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); ID=$(cat /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk '{print $NF}' | awk ""NR==${SGE_TASK_ID}""). mkdir -p /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/Salmon_tx/${ID}. /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.7.2_linux_x86_64/bin/salmon quant 	-i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/GENCODE/GRCh38_hg38/transcripts/salmon_index_gencode.v25.transcripts -p 1 -l ISR 	-1 ${FILE1} -2 ${FILE2} 	-o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/Salmon_tx/${ID}. echo ""**** Job ends ****""; date; ```. The important part is that we are requesting 1 single core with 80 GB of free memory and setting the limit at 90 GB. We are also using the `-p 1`",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126:729,log,logs,729,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126,2,['log'],['logs']
Testability,"Hi,. We'll install the latest version of Salmon, make new indexes and run the tests against the new indexes. It'll take us a bit to report back. Best,; Leo",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-289539265:78,test,tests,78,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-289539265,1,['test'],['tests']
Testability,"Hi,. after salmon installation (from source, on Ubuntu 16), 'make test' is failing all 3 tests. So I will go through them one by one. *Test 1*: fails with the `No file or directory` message. ; As I can see from the logs, the executed command `/usr/bin/cmake -DTOPLEVEL_DIR=/usr/local -P /home/rad/packages/salmon-0.10.2/cmake/UnitTests.cmake` sets the toplevel directory to `/usr/local` and fails to find the `tests/UnitTests.cpp` in there. When I set the `-DTOPLEVEL_DIR` to salmons root folder everything works just fine. ; So, is there something missing? If so, how can I fix it?. *Test 2 and 3*: fail with no output but ` Error running ` . When I execute the respective command from the log file ; `salmon index -t transcripts.fasta -i sample_salmon_fmd_index --type fmd`; (and also `salmon index ...` on different data) the error is `Segmentation fault (core dumped)`. Any idea what goes wrong here? . *Aditional info*; * Which version of salmon was used? 0.10.2; * How was salmon installed? Compiled; * Which reference (e.g. transcriptome) was used? samples provided in the sample_data folder ; * Which read files were used? samples provided in the sample_data folder ; * OS: Ubuntu 16 (have to stick to the old version due to group policy) ; * output of `uname -a` : Linux AGRadWS1 4.15.0-24-generic #26~16.04.1-Ubuntu SMP Fri Jun 15 14:35:08 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux; * and `lsb_release -a`: ; No LSB modules are available.; Distributor ID:	Ubuntu; Description:	Ubuntu 16.04.4 LTS; Release:	16.04; Codename:	xenial",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/250:66,test,test,66,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/250,7,"['Test', 'log', 'test']","['Test', 'log', 'logs', 'test', 'tests']"
Testability,"Hi,. sorry about it. Here they are. [alevin.log](https://github.com/COMBINE-lab/salmon/files/2346583/alevin.log); [salmon_quant.log](https://github.com/COMBINE-lab/salmon/files/2346584/salmon_quant.log)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/284#issuecomment-418196261:44,log,log,44,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/284#issuecomment-418196261,4,['log'],['log']
Testability,"Hi,. thanks for the prompt reply and suggestions. I rerun it as you suggested, using the cellranger generated barcode file and it looks much better now. I am attaching the log files. How much of the FASTQ files would you need ?. Thanks; [salmon_quant.log.txt](https://github.com/COMBINE-lab/salmon/files/2343857/salmon_quant.log.txt); [alevin.log.txt](https://github.com/COMBINE-lab/salmon/files/2343858/alevin.log.txt)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/284#issuecomment-417970098:172,log,log,172,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/284#issuecomment-417970098,5,['log'],['log']
Testability,"Hi,. thanks for the prompt reply. you are right, I went back to the FASTQ qc and noticed that this set of; samples all have a very low total number of reads and I would discard them.; I guess, it makes sense that the salmon did not assign fragments to any; transcripts. I should have caught it. Sorry. Thanks for your help. On Wed, Jan 20, 2021 at 9:22 PM Rob Patro <notifications@github.com> wrote:. > Hi @gianfilippo <https://github.com/gianfilippo>,; >; > Thank you for the report and for including the log File. Can you share one; > of the problematic samples and the reference against which you are; > aligning? One big difference is that the alignment rate reported by HISAT2; > is to the genome, while for salmon it is with respect to the genome. For; > certain samples (e.g. if you get a bad sample with poor rRNA depletion; > etc.) you can have many reads align to the genome, but none of them align; > to the annotated transcriptome.; >; > --Rob; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/COMBINE-lab/salmon/issues/616#issuecomment-764188266>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ACPSFVD3TOPU3IYXVD6ZWKDS26FXVANCNFSM4WL6CV6A>; > .; >",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/616#issuecomment-764205368:506,log,log,506,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/616#issuecomment-764205368,1,['log'],['log']
Testability,"Hi,; I am having trouble with salmon on linux, I downloaded salmon through bioconda and was following your ""GETTING STARTED"" tutorial, followed the code exactly and it all worked fine except I am not getting the quant.sf file for any of the samples. I also tried it on my own mRNA fastq files and the same thing happened. I am able to get all the other files like the log in its own directory. The log files are empty though so I was not able to get any information as to what is wrong. I am not getting any errors either so I don't really know where to start looking.; Any help you can give would be much appreciated.; Thank you,; Tj.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/239:368,log,log,368,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/239,2,['log'],['log']
Testability,"Hi,; I am processing canine data (replicates SRR636842 and SRR636843) and Salmon segfaults with no (?) useful information in the log that would help me to identify the problem. Other data from the same study are processed fine (mouse, cow and pig; all 51nt reads). ```; # salmon (mapping-based) v0.6.0; # [ program ] => salmon ; # [ command ] => quant ; # [ index ] => { /[...path...]/genemodel/cfa_canFam3_ensembl_vN.pctr_norm.k19.idx }; # [ threads ] => { 16 }; # [ libType ] => { IU }; # [ mates1 ] => { /dev/fd/63 }; # [ mates2 ] => { /dev/fd/62 }; # [ biasCorrect ] => { }; # [ output ] => { /[...path...]/tmp/SRX211583 }; # [ forgettingFactor ] => { 0.8 }; # [ useVBOpt ] => { }; # [ sensitive ] => { }; # [ geneMap ] => { /[...path...]/genemodel/cfa_canFam3_ensembl_vN.pctr_map.tsv }; Logs will be written to /[...path...]/tmp/SRX211583/logs; there is 1 lib; [2016-07-19 09:35:23.827] [jointLog] [info] parsing read library format; Loading 32-bit quasi index[2016-07-19 09:35:23.895] [jointLog] [info] Loading Quasi index; [2016-07-19 09:35:23.898] [stderrLog] [info] Loading Suffix Array ; [2016-07-19 09:35:23.899] [stderrLog] [info] Loading Position Hash; [2016-07-19 09:35:29.545] [stderrLog] [info] Loading Transcript Info ; [2016-07-19 09:35:30.913] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-07-19 09:35:31.452] [stderrLog] [info] There were 24526 set bits in the bit array; [2016-07-19 09:35:31.737] [stderrLog] [info] Computing transcript lengths; [2016-07-19 09:35:31.737] [stderrLog] [info] Waiting to finish loading hash; Index contained 24526 targets; [2016-07-19 09:36:30.462] [jointLog] [info] done; [2016-07-19 09:36:30.462] [stderrLog] [info] Done loading index; ```. All data are processed in the same pipeline, so I guess there is something particular about this dataset - but given this information, I have no clue where to start looking.; I have seen ticket #64, but I am not using the `--useFSPD` parameter, so I assume it's a different problem. +Peter",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/66:129,log,log,129,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/66,3,"['Log', 'log']","['Logs', 'log', 'logs']"
Testability,"Hi,; I don't want to report a bug, but rather have 2 (unrelated) questions:; Because we don't generate that many RNA-seq data sets, I am using Salmon every now and then. I really like the program (speed!) and the obtained results. - Since I don't use Salmon on a daily basis, I usually have (would like) to update Salmon to its latest release. For these the binaries you (used to) provide are very convenient. I noticed that these are not explicitly linked to anymore on the page `https://github.com/COMBINE-lab/salmon/releases`, although these still are available through [this link](https://github.com/COMBINE-lab/salmon/files/2099291/salmon-latest_linux_x86_64.tar.gz) that is regularly posted on this Github 'forum'. Please note that I learned you favor the Bioconda route for keeping Salmon up to date. Nevertheless, provided it doesn't take too much effort, I would appreciate it very much if you could still make the binaries available. - My 2nd question has to do with some basic QC-ing: I am currently analyzing a set of 96 mouse samples. While running Salmon, I noticed most samples do have a nice percentage of mapped reads (>80%), but I also noticed that for samples this percentage was much lower (<50%).; Q: Is there an easy way of obtaining these numbers (""percent_mapped"") for all samples that were mapped in a Salmon run (without manually reviewing all 96 samples the 'meta_info.json' file)? In other words, how to obtain an 'overall log file'?. Thanks,; Guido",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/252:1451,log,log,1451,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/252,1,['log'],['log']
Testability,"Hi,; I get this error:. salmon: /drone/src/github.com/COMBINE-lab/salmon/include/eigen3/Eigen/src/Core/DenseCoeffsBase.h:378: Eigen::DenseCoeffsBase<Derived, 1>::Scalar& Eigen::DenseCoeffsBase<Derived, 1>::operator[](Eigen::DenseCoeffsBase<Derived, 1>::Index) [with Derived = Eigen::Matrix<double, -1, 1>; Eigen::DenseCoeffsBase<Derived, 1>::Scalar = double; Eigen::DenseCoeffsBase<Derived, 1>::Index = long int]: Assertion `index >= 0 && index < size()' failed.; /home/ngs/scripts/sc-rna/sc-s-salmon-quant.sh: line 40: 10170 Aborted (core dumped) . when I run. ```bash; salmon quant \; -i ""$path_dr_salmonindex_transcriptome_ercc"" \; -o ""$newfilename-salmon-quant"" \; -g ""$path_dr_gtf"" \; -l ""U"" \; -p 1 \; --fldMax 50 \; --fldMean 43 \; --seqBias \; --numBootstraps 10 \; -r <(zcat $1); ```. <details>; <summary>Std out</summary>. ```; Logs will be written to 142-salmon-quant/logs; [2017-08-02 14:41:28.018] [jointLog] [info] parsing read library format; [2017-08-02 14:41:28.018] [jointLog] [info] There is 1 library.; [2017-08-02 14:41:28.190] [jointLog] [info] Loading Quasi index; [2017-08-02 14:41:28.254] [jointLog] [info] Loading 32-bit quasi index; [2017-08-02 14:41:28.286] [stderrLog] [info] Loading Suffix Array; [2017-08-02 14:41:36.196] [stderrLog] [info] Loading Transcript Info; [2017-08-02 14:41:38.296] [stderrLog] [info] Loading Rank-Select Bit Array; [2017-08-02 14:41:38.631] [stderrLog] [info] There were 51378 set bits in the bit array; [2017-08-02 14:41:38.676] [stderrLog] [info] Computing transcript lengths; [2017-08-02 14:41:38.676] [stderrLog] [info] Waiting to finish loading hash; [2017-08-02 14:41:42.951] [stderrLog] [info] Done loading index. [2017-08-02 14:41:42.951] [jointLog] [info] done; [2017-08-02 14:41:42.951] [jointLog] [info] Index contained 51378 targets. [2017-08-02 14:41:46.428] [jointLog] [info] Computed 10524 rich equivalence classes for further processing; [2017-08-02 14:41:46.428] [jointLog] [info] Counted 98301 total reads in the equivalence ",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/144:414,Assert,Assertion,414,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/144,3,"['Assert', 'Log', 'log']","['Assertion', 'Logs', 'logs']"
Testability,"Hi,; I just installed salmon using conda. I tried to execute the sample test that comes on the main page: https://combine-lab.github.io/salmon/getting_started/. When I try to run the quantification code; #!/bin/bash; for fn in data/DRR0161{25..40};; do; samp=`basename ${fn}`; echo ""Processing sample ${samp}""; salmon quant -i athal_index -l A \; -1 ${fn}/${samp}_1.fastq.gz \; -2 ${fn}/${samp}_2.fastq.gz \; -p 8 --validateMappings -o quants/${samp}_quant; done ; even though the files are there, in the data directory, the tool seems to not recognize the fastq files and pops the following error for every DRR0161xx_x.fastq.gz file:; ERROR: file [DRR016140_2.fastq.gz] does not appear to exist!. ]; salmon quant was invoked improperly. Is this some common error or is it a new bug?; Thanks in advance for any response/suggestion on how to proceed here",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/963:72,test,test,72,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/963,1,['test'],['test']
Testability,"Hi,; I seem to be having problems with installing Salmon on my mac.; I've tried doing this using ; **1. brew install salmon:**; brew install salmon; Updating Homebrew...; ==> Auto-updated Homebrew!; Updated 2 taps (homebrew/core, homebrew/science).; ==> Updated Formulae; homebrew/science/seqan. ==> Installing salmon from homebrew/science; ==> Downloading https://github.com/COMBINE-lab/salmon/archive/v0.7.2.tar.gz; Already downloaded: /Users/sangrim/Library/Caches/Homebrew/salmon-0.7.2.tar.gz; ==> cmake . -DCMAKE_C_FLAGS_RELEASE=-DNDEBUG -DCMAKE_CXX_FLAGS_RELEASE=-DNDEBUG -DCMAKE_INSTALL_PREFIX=/usr/local/Cellar/salmon/0.7.2 -DCMA; ==> make install; 🍺 /usr/local/Cellar/salmon/0.7.2: 6 files, 8.5M, built in 7 minutes 8 seconds; sangrim@C02Q7CT1G8WN:~/bin$> salmon; **salmon(2034,0x7fffbc21a3c0) malloc: *** malloc_zone_unregister() failed for 0x7fffbc210000**. and also,; **2. compiling from the osx tarball; the installation seemingly succeeds,**; Install the project...; /usr/local/Cellar/cmake/3.7.1/bin/cmake -P cmake_install.cmake; -- Install configuration: """"; -- Up-to-date: /Users/../bin/salmon-0.7.2/lib; -- Up-to-date: /Users/../bin/salmon-0.7.2/lib/pkgconfig; -- Installing: /Users/../bin/salmon-0.7.2/bin/salmon; -- Installing: /Users/../bin/salmon-0.7.2/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly. Please add /Users/../bin/salmon-0.7.2/bin to your PATH; Please add /Users/../bin/salmon-0.7.2/lib to your DYLD_FALLBACK_LIBRARY_PATH. ...and then make test, hangs...; Running tests...; /usr/local/Cellar/cmake/3.7.1/bin/ctest --force-new-ctest-process ; Test project /Users/maheshsangrithi/bin/salmon-0.7.2/build; Start 1: unit_tests; ........Ctrl+C to cancel...; then if ./salmon is run, I get the same error...; salmon(2034,0x7fffbc21a3c0) malloc: *** malloc_zone_unregister() failed for 0x7fffbc210000. Thanks in advance for your help.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/112:1523,test,test,1523,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/112,3,"['Test', 'test']","['Test', 'test', 'tests']"
Testability,"Hi,; I was skimming through some of the code and other open issues on support for other library (cell barcode/umi) designs. It looks like there is code for supporting inDrop libraries, but I wasn't sure which parameters I'd need to set. I have inDrop v2 libraries that I'd like to process and am just trying to figure out if we'll need to write our own extensions or if there is already code in place that we can test. Related to some of the comments about the best model for UMI correction in #269 ; The inDrop (at least the v2 protocol) is based on the CEL-Seq like chemistry -- which uses (in vitro transcription) IVT for the initial amplification rather than PCR. From what I've seen so far, the 2 main flavors of single cell RNA-Seq library construction chemistry are; 1. CelSeq/inDrop; polyA capture -> Reverse transcription (RT) for 1st strand cDNA synthesis -> 2nd strand synthesis -> IVT (linear) amplification -> fragmentation -> RT again to convert back to cDNA -> final PCR to amplify library and add Illumina adapters. 2. DropSeq/10X; polyA capture -> RT with template switching -> PCR amplification of cDNA -> fragmentation followed by variable library construction (either transposon/Nextera based or more traditional --frag, end repair, a-tail and adapter ligation) -> final PCR to amplify library and add Illumina adapters. Thanks so much!; Julie",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/339:413,test,test,413,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/339,1,['test'],['test']
Testability,"Hi,; I'm coming back to salmon after a ""long"" time not using it. I'm a little bit confused with an error message from the last version (0.14.1) when trying to create an index.; The message complains about a non existing file, but the file does exists; and in fact, with old versions of salmon (0.7.2), it does build an index with the exact same command:. ```; [curis@info124 __Index]$ ls; génome.rat_084.fa.gz@ génôme_rat.v_6-0__Ensemble_084/ test/ test.fa. [curis@info124 __Index]$ salmon_0.14.1 index -t test.fa -i test; Version Info: This is the most recent version of salmon.; The file [test.fa] provided for the transcriptome does not appear to exist.[curis@info124 __Index]$ . [curis@info124 __Index]$ salmon_0.9.1 index -t test.fa -i test; Version Info: ### PLEASE UPGRADE SALMON ###; [...]; The file [test.fa] provided for the transcriptome does not appear to exist.[curis@info124 __Index]$ . [curis@info124 __Index]$ salmon_0.7.2 index -t test.fa -i test; Version Info: ### A newer version of Salmon is available. ####; [...]; [2019-08-22 18:11:33.022] [jLog] [info] building index; RapMap Indexer. [Step 1 of 4] : counting k-mers; ```; I guess I'm missing something obvious, due to some change in a previous version of salmon (around 0.9.1 ?), but I do not understand why salmon does not find the file when it is present...; Thanks in advance for any help",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/420:443,test,test,443,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/420,10,['test'],['test']
Testability,"Hi,; I'm having a similar issue with specification of library type. I'm quantifying a single-end library of type SF with salmon 1.3.0. ; The two commands being compared are:. auto detect:. salmon --no-version-check quant --writeMappings -i target --incompatPrior 0.0 --validateMappings -l A -r d218056_dedup.fastq -p 4 -o d218056_A.quant > d218056_A.sam. specify SF:. salmon --no-version-check quant --writeMappings -i target --incompatPrior 0.0 --validateMappings -l SF -r d218056_dedup.fastq -p 4 -o d218056_SF.quant > d218056_SF.sam. The log files indicate that salmon correctly identifies the library as SF in the auto case. I noticed the issue when examining a pair of genes with overlapping 3'UTRs. The forward strand gene (GQ67_03478) is expressed at a much lower level than the reverse strand gene (GQ67_03479). The sam files contain the same number of reads mapped to each transcript without regard to how the libtype is specified:. egrep -v '^@' d218056_A.sam|grep -c GQ67_03478 ; 382; egrep -v '^@' d218056_A.sam|grep -c GQ67_03479; 399; egrep -v '^@' d218056_SF.sam|grep -c GQ67_03478 ; 382; egrep -v '^@' d218056_SF.sam|grep -c GQ67_03479; 399. The quantitation is very different with 120 counts assigned to the forward strand gene in the A case and a much more accurate (based on examination of the sam file) 10 counts in the SF case:. grep GQ67_03478 d218056_A.quant/quant.sf ; GQ67_03478T0 2914 2664.000 202.831978 119.926. grep GQ67_03478 d218056_SF.quant/quant.sf ; GQ67_03478T0 2914 2664.000 17.066270 10.000. For the reverse strand gene, the auto case undercounts due to reads being assigned to the forward strand gene. grep GQ67_03479 d218056_A.quant/quant.sf ; GQ67_03479T0 1383 1133.000 1245.013842 313.074. grep GQ67_03479 d218056_SF.quant/quant.sf ; GQ67_03479T0 1383 1133.000 1589.051981 396.000. I've been using salmon with -l A thinking that if the software correctly recognizes the libtype, the results would be nearly identical to explicitly specifying the libtype but th",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/489#issuecomment-738804437:541,log,log,541,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/489#issuecomment-738804437,1,['log'],['log']
Testability,"Hi,; I've ran Alevin and generated an alevinQC report. The initial whitelist contains 5261 cells and the final whitelist contains 4340 cells. ; filtered_cb_frequency.txt contains 5261 cells and whitelist.txt contains 4240 cells.; AlevinQC states that ""Once the initial set of whitelisted cell barcodes is defined, Alevin goes through the remaining cell barcodes. If a cell barcode is similar enough to a whitelisted cell barcode, it will be corrected and the reads will be added to those of the whitelisted one.""; However my final counts matrix contains 5621 cells, the number from the initial whitelist. ; Shouldn't my final counts matrix contain 4340 cells after the correction has taken place?; I'm running:; ```; salmon alevin -l ISR -1 test.fastq.1.gz -2 test.fastq.2.gz --chromium -i geneset.dir/geneset_all.salmon.index -p 16 -o salmon.dir/test; --tgMap t2gmap.tsv --dumpFeatures --dumpUmiGraph; ```. Thanks,; Anna",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/428:741,test,test,741,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/428,3,['test'],['test']
Testability,"Hi,; Sorry for reviving this old thread, but could you confirm that this option was indeed implemented and tested, and let me know which version of Salmon it was implemented on?; Thanks",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/83#issuecomment-291810537:107,test,tested,107,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/83#issuecomment-291810537,1,['test'],['tested']
Testability,"Hi,; i met a problem when installing the index for salmon. The feedback suggests that ""server did not respond before timeout"". This problem is shown in the following picture.; I've already given it enough space for running, while it seems that it was stuck in the first step. And the index file only contains ""pre_indexing.log ref_indexing.log""; So could you please help me to solve this problem?; Thanks; ![image](https://user-images.githubusercontent.com/100278952/155299114-10a7e3b7-bf08-49aa-824d-48dcbaa1fd71.png)",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/755:323,log,log,323,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/755,2,['log'],['log']
Testability,"Hi,; it goes literally in panic: . ```; panic: runtime error: slice bounds out of range. goroutine 1 [running]:; github.com/sylabs/singularity/internal/pkg/util/uri.Split(0x7ffd422b2b65, 0x1f, 0xc00003c195, 0xc0004852f0, 0xc0004e5c78, 0x929217); 	/tools/others_tools/Go/go-1.11.2/src/github.com/sylabs/singularity/internal/pkg/util/uri/uri.go:104 +0x13e; github.com/sylabs/singularity/cmd/singularity/cli.replaceURIWithImage(0x19d2a60, 0xc0000b8900, 0x11, 0x12); 	/tools/others_tools/Go/go-1.11.2/src/github.com/sylabs/singularity/cmd/singularity/cli/actions.go:189 +0x5d; github.com/sylabs/singularity/vendor/github.com/spf13/cobra.(*Command).execute(0x19d2a60, 0xc000030160, 0x12, 0x12, 0x19d2a60, 0xc000030160); 	/tools/others_tools/Go/go-1.11.2/src/github.com/sylabs/singularity/vendor/github.com/spf13/cobra/command.go:755 +0x4ed; github.com/sylabs/singularity/vendor/github.com/spf13/cobra.(*Command).ExecuteC(0x19d65c0, 0x0, 0xf6, 0xfc0b01); 	/tools/others_tools/Go/go-1.11.2/src/github.com/sylabs/singularity/vendor/github.com/spf13/cobra/command.go:852 +0x2fd; github.com/sylabs/singularity/vendor/github.com/spf13/cobra.(*Command).Execute(0x19d65c0, 0x4, 0x1133611); 	/tools/others_tools/Go/go-1.11.2/src/github.com/sylabs/singularity/vendor/github.com/spf13/cobra/command.go:800 +0x2b; github.com/sylabs/singularity/cmd/singularity/cli.ExecuteSingularity(); 	/tools/others_tools/Go/go-1.11.2/src/github.com/sylabs/singularity/cmd/singularity/cli/singularity.go:114 +0x110; main.main(); 	/tools/others_tools/Go/go-1.11.2/src/github.com/sylabs/singularity/cmd/singularity/cli.go:16 +0x20; ```; with -e you clean environment before running container.; I haven't found how to add the environmental variable, but logging in as shell and exporting the variable, it works ( or at least, I discover that I have to rebuild the index since it was built with the old verision in RapMap). I'll see if there is another way to import the variable or I'll build an image with the env; Thanks ; Claudio",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/447#issuecomment-553005722:1719,log,logging,1719,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/447#issuecomment-553005722,1,['log'],['logging']
Testability,"Hi,; it seems that --writeUnmappedNames option doesn't work for `salmon alevin` (both R1 and R2 reads were used), while `salmon quant` with the same dataset (only R2 reads were used since R1 contains barcodes) reports unmapped read names correctly. The `alevin` reports all the reads in the dataset as unmapped, while `quant` gets only the fraction of them (the size of that fraction the same as reported in log). `salmon version: 1.1.0`",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/501:408,log,log,408,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/501,1,['log'],['log']
Testability,"Hi. I just did:. ```; salmon index -t /no_backup/indexes/salmon/gencode_mm10/gentrome.fa \; -i /no_backup/indexes/salmon/gencode_mm10 \; -d /no_backup/indexes/salmon/gencode_mm10/decoys.txt \; -k 29 --threads 8; ````. And the log file says:. ```; Version Info: This is the most recent version of salmon.; [2021-12-30 00:46:18.878] [jLog] [info] building index; out : /no_backup/indexes/salmon/gencode_mm10; [2021-12-30 00:46:18.881] [puff::index::jointLog] [info] Running fixFasta. [Step 1 of 4] : counting k-mers; [2021-12-30 00:46:18.914] [puff::index::jointLog] [warning] It appears that this may be a GENCODE transcriptome (from analyzing the separators in the FASTA header). However, you have not set '|' as a header separator. If this is a GENCODE transcriptome, consider passing --gencode to the pufferfish index command. [2021-12-30 00:46:19.915] [puff::index::jointLog] [warning] Entry with header [ENSMUST00000229312.1|ENSMUSG00000056486.18|OTTMUSG00000013428.7|OTTMUST00000171565.1|Chn1-211|Chn1|20|processed_transcript|], had length less than equal to the k-mer length of 29 (perhaps after poly-A clipping). # [omissis]. [2021-12-30 00:46:27.227] [puff::index::jointLog] [warning] Entry with header [ENSMUST00000226172.1|ENSMUSG00000002249.21|OTTMUSG00000024245.6|OTTMUST00000167695.2|Tead3-208|Tead3|11|processed_transcript|], had length less than equal to the k-mer length of 29 (perhaps after poly-A clipping); [2021-12-30 00:46:28.327] [puff::index::jointLog] [warning] Removed 1612 transcripts that were sequence duplicates of indexed transcripts.; [2021-12-30 00:46:28.327] [puff::index::jointLog] [warning] If you wish to retain duplicate transcripts, please use the `--keepDuplicates` flag; [2021-12-30 00:46:28.327] [puff::index::jointLog] [critical] The decoy file contained the names of 55 decoy sequences, but 0 were matched by sequences in the reference file provided. To prevent unintentional errors downstream, please ensure that the decoy file exactly matches with the fast",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/731#issuecomment-1002817868:226,log,log,226,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/731#issuecomment-1002817868,1,['log'],['log']
Testability,Hi. I'm having a similar issue. When I run the Salmon exec I get:. `MacBook-Pro-31:~ alex$ /Users/alex/Desktop/Code/Salmon-v0.8.0_macOS_10.12/bin/salmon ; exit;; dyld: Library not loaded: /usr/local/opt/tbb/lib/libtbbmalloc_proxy.dylib; Referenced from: /Users/alex/Desktop/Code/Salmon-v0.8.0_macOS_10.12/bin/salmon; Reason: image not found; Abort trap: 6; logout; `. I'm running Sierra 10.12.2. Can you advise? What do I specifically need to do to get Salmon to work?. Thanks.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/117#issuecomment-279257362:357,log,logout,357,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/117#issuecomment-279257362,1,['log'],['logout']
Testability,"Hmm, something's up. I just deleted my previous transcripts_quan directory, replaced salmon with this newer version, and ran the same command. It finishes almost immediately with a return value of 1. ```; $ /home/jorvis/salmon/bin/salmon quant -p 24 -i transcripts_index -l IU -1 R1.trimmed.PE.fastq -2 R2.trimmed.PE.fastq -o transcripts_quan; Version Info: This is the most recent version of Salmon.; # salmon (mapping-based) v0.6.0; # [ program ] => salmon ; # [ command ] => quant ; # [ threads ] => { 24 }; # [ index ] => { transcripts_index }; # [ libType ] => { IU }; # [ mates1 ] => { R1.trimmed.PE.fastq }; # [ mates2 ] => { R2.trimmed.PE.fastq }; # [ output ] => { transcripts_quan }; Logs will be written to transcripts_quan/logs; there is [2016-03-31 12:30:21.714] [jointLog] [info] parsing read library format; 1 lib; [jorvis@grid-1-3-4 salmon]$ echo $?; 1; [jorvis@grid-1-3-4 salmon]$ ls transcripts_quan; logs; [jorvis@grid-1-3-4 salmon]$ ls transcripts_quan/logs/; salmon_quant.log; [jorvis@grid-1-3-4 salmon]$ cat transcripts_quan/logs/salmon_quant.log ; [2016-03-31 12:30:21.714] [jointLog] [info] parsing read library format; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-204011075:694,Log,Logs,694,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-204011075,7,"['Log', 'log']","['Logs', 'log', 'logs']"
Testability,"Hrmm, I seem to be able to load and map against that index (though I'm testing with the latest develop version). Is there anything specific about the machines / vms where this is failing versus succeeding?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/321#issuecomment-442557809:71,test,testing,71,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/321#issuecomment-442557809,1,['test'],['testing']
Testability,"Hrmm, it doesn't seem so. I am able to do cmake with exactly these options and it still runs the `fetchRapMap.sh` script. I tried this under both 0.8.2 and 0.9.1. Let me look more through the logs. Also, parallel builds *should* work in newer releases (our internal build does parallel make on our CI).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/181#issuecomment-367755018:192,log,logs,192,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/181#issuecomment-367755018,1,['log'],['logs']
Testability,"Hrmm, that shouldn't happen (i.e. that's why the log is called `stderrLog`). So something is strange there. I'll take a look. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/90#issuecomment-247079124:49,log,log,49,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/90#issuecomment-247079124,1,['log'],['log']
Testability,"I actually didn't test it :). I'll confirm the current behavior tomorrow. Thanks for following up on this!. > On Jan 3, 2016, at 8:37 PM, Rob Patro notifications@github.com wrote:; > ; > Actually, @mdshw5 --- it's not quite clear to me why the parser isn't doing the right thing in this case. If you take a look at how the paired-end sequence parser is actually populating the internal buffer (e.g. here), it is reading one entry from stream1 and then one entry from stream2. I'm guessing there may be some issue with having two different handles open to the same fifo? However, that doesn't seem like it should be a problem. Given the way the code is actually reading from the different streams, it's not clear to me why it's not currently working as expected. I'll try and take a deeper look.; > ; > —; > Reply to this email directly or view it on GitHub.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-168566647:18,test,test,18,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-168566647,2,['test'],['test']
Testability,"I agree – I wasn’t aware of that one. I’ve tested that and it has the same effect as the other flag, performance looks good.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/966#issuecomment-2416748677:43,test,tested,43,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/966#issuecomment-2416748677,1,['test'],['tested']
Testability,"I already attach the file. Can you see it right now?. Bests. > On Jun 13, 2019, at 3:07 PM, Avi Srivastava <notifications@github.com> wrote:; > ; > I think you forgot to attach the log file ?; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub <https://github.com/COMBINE-lab/salmon/issues/375?email_source=notifications&email_token=AK7LCF6HIQSMM4UTPONU37TP2KLH5A5CNFSM4HX4WLH2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODXUXQJA#issuecomment-501839908>, or mute the thread <https://github.com/notifications/unsubscribe-auth/AK7LCFZKFOYIZEGYU5YOIX3P2KLH5ANCNFSM4HX4WLHQ>.; >",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/375#issuecomment-501845900:181,log,log,181,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/375#issuecomment-501845900,1,['log'],['log']
Testability,"I also have had to submit indexing jobs with much larger resources and times since the switch to the new indexing method with whole genome decoys. Prior to this I could built and index asking for only 16GB of ram in minutes. Now, I have to request ~256GB of memory and it runs for 7-10 hours. These are just ""standard"" mouse transcriptomes (GENCODE M23). I should note that using 17-mers as my kmer length dramatically increased these requirements. I re-ran using 31-mers, and the time reduces to a couple of hours and only used ~20GB of memory. I've attached two files that have summaries of the resources used in the jobs I ran in the above. Everything about these jobs is the same, except for the k-mer lengths. I requested the same amount of resources for each, but you can see that the one labeled 31mer has drastically less ""ru_maxrss"", which is the maximum amount of memory used by the process (it's in KB, although it's not labeled in the log). I also noted that there weren't any hard page faults for either of the jobs (""ru_majflt""). The longer job did have more soft page faults/page reclaims (""ru_minflt""). I don't know if that's useful information or not. [qacct-17mer.log](https://github.com/COMBINE-lab/salmon/files/4172209/qacct-17mer.log); [qacct-31mer.log](https://github.com/COMBINE-lab/salmon/files/4172210/qacct-31mer.log)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-583526416:947,log,log,947,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-583526416,5,['log'],['log']
Testability,"I also tried on the `testing` image. For more detail, here are the steps performed (perhaps taking a look at the installed packages will highlight a difference, as I did this from a clean testing Docker image, so my environment had nothing else in it). ### Attempt to reproduce segfault on Debian:testing. ```{bash}; $ docker pull debian:testing. $ docker run -it debian:testing. $ apt-get update. $ apt-get install build-essential git libboost-all-dev liblzma-dev libbz2-dev cmake zlib1g-dev curl unzip wget libcurl4-openssl-dev. $ git clone https://github.com/COMBINE-lab/salmon.git; $ cd salmon; $ mkdir build && cd build; $ cmake -DNO_IPO=TRUE .. # GCC still doesn't handle LTO robustly; $ make -j8; $ make install; $ make test; ```. which leads to the output. ```; root@fd877e359439:/salmon/build# make install; [ 7%] Built target libcereal; [ 13%] Built target libtbb; [ 16%] Built target ntcard; [ 19%] Built target graphdump; [ 27%] Built target twopaco; [ 29%] Built target ksw2pp_sse2; [ 32%] Built target ksw2pp_sse4; [ 37%] Built target ksw2pp_basic; [ 38%] Built target ksw2pp; [ 59%] Built target puffer; [ 73%] Built target salmon_core; [ 76%] Built target alevin_core; [ 77%] Built target UnitTestsMain; [ 81%] Built target unitTests; [100%] Built target salmon; Install the project...; -- Install configuration: ""Release""; -- Installing: /salmon/lib/libntcard.a; -- Installing: /salmon/lib/ntcard/ntcard-targets.cmake; -- Installing: /salmon/lib/ntcard/ntcard-targets-release.cmake; -- Installing: /salmon/lib/libgraphdump.a; -- Installing: /salmon/lib/graphdump/graphdump-targets.cmake; -- Installing: /salmon/lib/graphdump/graphdump-targets-release.cmake; -- Installing: /salmon/lib/libtwopaco.a; -- Installing: /salmon/lib/twopaco/twopaco-targets.cmake; -- Installing: /salmon/lib/twopaco/twopaco-targets-release.cmake; -- Installing: /salmon/lib/libtbb.so; -- Installing: /salmon/lib/libtbb.so.12; -- Installing: /salmon/lib/libtbb.so.12.5; -- Installing: /salmon/lib/libtbbmalloc",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554:21,test,testing,21,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554,6,['test'],"['test', 'testing']"
Testability,"I am analyzing single cell RNAseq with10x chemistry.; I have my own transcriptome from long read sequencing and followed all the steps, prepare metadata, make the gentrome.fasta, indexing, using bioawk for the transcript to gene table.; Getting this error consistently:; ```; salmon alevin -l ISR -1 Novogene/fastq/Alin_neg/Alin_neg_S2_L008_R1_001.fastq.gz -2 Novogene/fastq/Alin_neg/Alin_neg_S2_L008_R2_001.fastq.gz --chromiumV3 -i salmon_alevin/Alin_neg_salmon_index -p 15 -o Alin_neg_alevin_output --tgMap PacBio/single_cell_pipeline/sqanti3_output/Alin_neg_txp2gene.tsv. Version Info: This is the most recent version of salmon.; Logs will be written to Alin_neg_alevin_output/logs; [2020-06-22 22:51:19.065] [jointLog] [info] setting maxHashResizeThreads to 15; [2020-06-22 22:51:19.065] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2020-06-22 22:51:19.065] [jointLog] [info] The --mimicBT2, --mimicStrictBT2 and --hardFilter flags imply mapping validation (--validateMappings). Enabling mapping validation.; [2020-06-22 22:51:19.065] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2020-06-22 22:51:19.065] [jointLog] [info] The use of range-factorized equivalence classes does not make sense in conjunction with --hardFilter. Disabling range-factorized equivalence classes.; [2020-06-22 22:51:19.066] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.35.; [2020-06-22 22:51:19.066] [jointLog] [info] Using default value of 0.87 for minScoreFraction in Alevin; Using default value of 0.6 for consensusSlack in Alevin; [2020-06-22 22:51:19.250] [alevinLog] [info] Found 88744 transcripts(+455 decoys, +0 short and +0 duplicate names in the index); [2020-06-22 22:51:19.323] [alevinLog] [info] Filled with 36098 txp to gene entries; [2020-06-22 22:51:19.323] [alevinLog] [error] E",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/540:633,Log,Logs,633,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/540,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"I am assuming you gave the `--chromium` to `pbmc_4k` data too and it's throwing error, since the above log doesn't seems to have it. I am puzzled because it should have complained much before starting reading the fastq. Can you please try the following command: ; ```; salmon alevin -p 10 -lISR --chromium --no-version-check -1 /path/to/downloads/10xPBMC/pbmc4k_S1_L001_R1_001.fastq.gz -2 /path/to/downloads/10xPBMC/pbmc4k_S1_L001_R2_001.fastq.gz -i /path/to/salmonIndex -o alevin_output --tgMap tx2gene.tsv; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/264#issuecomment-410328801:103,log,log,103,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/264#issuecomment-410328801,1,['log'],['log']
Testability,"I am encountering two issues when I follow the instructions for installing salmon 1.10.1:https://salmon.readthedocs.io/en/latest/building.html#installation; I am installing on a mac studio (M2 max) running Ventura. . The first issue I run into is that my understanding of the instructions suggests that I should be in the ""build"" directory when I run cmake. However, if I do that it returns an error about CMakeLists.txt not being in that location. I noticed that is in the salmon directory so I ran cmake from there and it seemed to work fine. But, I'm not sure if that is leading to the problems I am having downstream. . The second issue is when I run make I get an error associated with configuring liblzma (error 77). I have pasted the console log below. I appreciate any suggestions and apologize if I missed something obvious. . This file contains any messages produced by compilers while; running configure, to aid debugging if configure makes a mistake. It was created by XZ Utils configure 5.2.2, which was; generated by GNU Autoconf 2.69. Invocation command line was. $ /Users/jeremybono/Downloads/salmon-1.10.1/external/xz-5.2.2/configure --prefix=/Users/jeremybono/Downloads/salmon-1.10.1/external/install CC=/Library/Developer/CommandLineTools/usr/bin/cc CXX=/Library/Developer/CommandLineTools/usr/bin/c++ CFLAGS= CPPFLAGS= LDFLAGS=. ## --------- ##; ## Platform. ##; ## --------- ##. hostname = Jeremys-Mac-Studio.local; uname -m = arm64; uname -r = 22.6.0; uname -s = Darwin; uname -v = Darwin Kernel Version 22.6.0: Wed Jul 5 22:21:53 PDT 2023; root:xnu-8796.141.3~6/RELEASE_ARM64_T6020. /usr/bin/uname -p = arm; /bin/uname -X = unknown. /bin/arch = unknown; /usr/bin/arch -k = unknown; /usr/convex/getsysinfo = unknown; /usr/bin/hostinfo = Mach kernel version:; 	 Darwin Kernel Version 22.6.0: Wed Jul 5 22:21:53 PDT 2023; root:xnu-8796.141.3~6/RELEASE_ARM64_T6020; Kernel configured for up to 12 processors.; 12 processors are physically available.; 12 processors are logically ava",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/912:749,log,log,749,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/912,1,['log'],['log']
Testability,"I am running `salmon v1.4.0` on my total RNA samples to get isoform expressions. The library consists of mRNA + lncRNA.; The **mapping rate** is extremely lower than expected: **6%** and as a result TPM values are either 0 or very low for most of the transcripts:. `salmon quant --no-version-check -p 20 -i /library/salmon_mm10 -l A --seqBias --gcBias -1 Mice_A_batch2_1.fq.gz -2 Mice_A_batch2_2.fq.gz -o salmon_out`. ```; ### salmon (selective-alignment-based) v1.4.0; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ threads ] => { 20 }; ### [ index ] => { /library/salmon_mm10 }; ### [ libType ] => { A }; ### [ seqBias ] => { }; ### [ gcBias ] => { }; ### [ mates1 ] => { /upload/uploads/files/public/1/Mice_A_batch2_1.fq.gz }; ### [ mates2 ] => { /upload/uploads/files/public/1/Mice_A_batch2_2.fq.gz }; ### [ output ] => { /results/RNA-Seq/Mice_A_batch2/salmon_out }; Logs will be written to /results/RNA-Seq/Mice_A_batch2/salmon_out/logs; [2021-05-20 10:53:54.759] [jointLog] [info] setting maxHashResizeThreads to 20; [2021-05-20 10:53:54.760] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2021-05-20 10:53:54.760] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2021-05-20 10:53:54.760] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.; [2021-05-20 10:53:54.760] [jointLog] [info] parsing read library format; [2021-05-20 10:53:54.760] [jointLog] [info] There is 1 library.; [2021-05-20 10:53:54.892] [jointLog] [info] Loading pufferfish index; [2021-05-20 10:53:54.901] [jointLog] [warning] The index did not record if the `--keepDuplicates` flag was used. Please consider re-indexing with a newer version of salmon that will propagate this information.; [2021-05-20 10:53:54.901] [jointLog] [info] Loading dense pufferfish index.; -----------------------------------------; | Loading contig table",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/661:885,Log,Logs,885,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/661,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"I am running salmon and I am getting this error. . ### salmon (mapping-based) v0.13.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ threads ] => { 5 }; ### [ index ] => { ~/CellNet/CellNetLocal/ref/salmon.index.mouse.052617.tgz }; ### [ libType ] => { U }; ### [ unmatedReads ] => { subset_SRR2070946_trimmed.fq }; ### [ output ] => { salmonRes_SRR2070946 }; Logs will be written to salmonRes_SRR2070946/logs; [2024-02-28 02:07:19.419] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2024-02-28 02:07:19.419] [jointLog] [warning] . NOTE: It appears you are running salmon without the `--validateMappings` option.; Mapping validation can generally improve both the sensitivity and specificity of mapping,; with only a moderate increase in use of computational resources. ; Mapping validation is planned to become a default option (i.e. turned on by default) in; the next release of salmon.; Unless there is a specific reason to do this (e.g. testing on clean simulated data),; `--validateMappings` is generally recommended. [2024-02-28 02:07:19.419] [jointLog] [info] parsing read library format; [2024-02-28 02:07:19.419] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file ~/CellNet/CellNetLocal/ref/salmon.index.mouse.052617.tgz/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; ~/anaconda3/envs/salmon/bin/salmon quant was invoked improperly.; For usage information, try ~/anaconda3/envs/salmon/bin/salmon quant --help; Exiting.; ./salmonRes_SRR2070926/quant.sf ; Error in file(file, ""rt"") : cannot open the connection; In addition: Warning message:; In file(file, ""rt"") :; cannot open file './salmonRes_SRR2070926/quant.sf': No such file or directory. I can see versionInfo.json in the salmon.index.mouse.052617.tgz. I am not sure why it can not see it.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/914:375,Log,Logs,375,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/914,3,"['Log', 'log', 'test']","['Logs', 'logs', 'testing']"
Testability,"I am trying to quantify my reads with salmon quant (v. 1.8.0) and I'm getting an error saying ""SAM file says target Vcev1_p0.Chr07.17417.mRNA has length 2346, but the FASTA file contains a sequence of length [2348 or 2347]"". Do you know what is the issue?. `./salmon-1.8.0_linux_x86_64/bin/salmon quant -l A -a ./STARaligned_Rev5-2_Aligned.toTranscriptome.out.bam -t ./vcae1.4.cds.fa -o ./Rev5-2.quant`. Version Info: This is the most recent version of salmon.; salmon (alignment-based) v1.8.0; [ program ] => salmon; [ command ] => quant; [ libType ] => { A }; [ alignments ] => { ./STARaligned_Rev5-2_Aligned.toTranscriptome.out.bam }; [ targets ] => {./vcae1.4.cds.fa }; [ output ] => { ./Rev5-2.quant }; Logs will be written to /h./Rev5-2.quant/logs; [2022-06-21 22:56:14.963] [jointLog] [info] setting maxHashResizeThreads to 8; [2022-06-21 22:56:14.963] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; Library format { type:paired end, relative orientation:inward, strandedness:unstranded }; [2022-06-21 22:56:15.015] [jointLog] [info] numQuantThreads = 4; parseThreads = 4; Checking that provided alignment files have consistent headers . . . done; Populating targets from aln = ""./STARaligned_Rev5-2_Aligned.toTranscriptome.out.bam"", fasta = ""./vcae1.4.cds.fa"" . . . **SAM file says target Vcev1_p0.Chr07.17417.mRNA has length 2346, but the FASTA file contains a sequence of length [2348 or 2347]**",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/785:708,Log,Logs,708,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/785,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"I am trying to quantify some rna sequences with Salmon. Instead of creating my own index, I downloaded a pre-build version from here: [http://refgenomes.databio.org/v3/genomes/splash/2230c535660fb4774114bfa966a62f823fdb6d21acf138d4](url) suggested in the salmon doc. I downloaded the file: `salmon_partial_sa_index:default` which is under my scope of research. Then, I just run the following command: `salmon quant -i default -l A -1 P10_1.fq.gz -2 P10_2.fq.gz --validateMappings -o transcripts_quant`, where `default` is the name of the folder resulting after the decompression of the salmon pre-build index, and `P10_1.fq.gz -2 P10_2.fq.gz` are paired reads of rna. I get this error: **rapidjson internal assertion failure: IsObject()**. I read a thread where a user performed a re-build. But since I am new to this filed I don't know what FASTA file I could use to do it. It's worth mentioning that I am working on a remote server and I downloaded the pre-build index directly on it, using `wget`. Some screenshot of what the `default` folder contains:. <img width=""806"" alt=""Schermata 2023-07-27 alle 14 42 59"" src=""https://github.com/COMBINE-lab/salmon/assets/81829336/e0bda06a-f344-4836-9e27-8e2de6a10265"">",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/862:707,assert,assertion,707,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/862,1,['assert'],['assertion']
Testability,"I am trying to test salmon ver 0.7.2 using commandline:. salmon index -t test-data/transcripts.fasta -i output --type quasi -k 31 --threads 4 --sasamp 1; salmon quant -l IU -index output -1 test-data/reads_1.fastq -2 test-data/reads_2.fastq -o output_quant. the .sf file is not reproducible, any clue???",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/102:15,test,test,15,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/102,4,['test'],"['test', 'test-data']"
Testability,"I am trying to use Salmon and am being returned the following error. Any help here? . Version Server Response: Not Found; ### salmon (selective-alignment-based) v1.5.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ threads ] => { 5 }; ### [ index ] => { ref//salmon.index.human.122116 }; ### [ libType ] => { U }; ### [ unmatedReads ] => { subset_SRR1501367_1_trimmed.fq }; ### [ output ] => { salmonRes_SRR1501367 }; Logs will be written to salmonRes_SRR1501367/logs; [2021-07-16 11:47:01.372] [jointLog] [info] setting maxHashResizeThreads to 5; [2021-07-16 11:47:01.372] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2021-07-16 11:47:01.372] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2021-07-16 11:47:01.372] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.; [2021-07-16 11:47:01.372] [jointLog] [info] parsing read library format; [2021-07-16 11:47:01.372] [jointLog] [info] There is 1 library.; Exception : [Error: This version of salmon does not support indexing using the RapMap index.]; /Users/jcm161/anaconda3/envs/salmon/bin/salmon quant was invoked improperly.; For usage information, try /Users/jcm161/anaconda3/envs/salmon/bin/salmon quant --help; Exiting.; Version Server Response: Not Found; ### salmon (selective-alignment-based) v1.5.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ threads ] => { 5 }; ### [ index ] => { ref//salmon.index.human.122116 }; ### [ libType ] => { U }; ### [ unmatedReads ] => { subset_SRR1501368_1_trimmed.fq }; ### [ output ] => { salmonRes_SRR1501368 }; Logs will be written to salmonRes_SRR1501368/logs; [2021-07-16 11:47:01.380] [jointLog] [info] setting maxHashResizeThreads to 5; [2021-07-16 11:47:01.380] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2021-07-16 11:4",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/685:433,Log,Logs,433,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/685,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"I am unsure what qualifies as many but on an input of 20M reads and an unsorted BAM file, I get around 600 lines of error in the log file, some of the reads have many alignments so the errors are redundant to some extent. The no. of unique reads' alignments that cause an error is perhaps 300.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/701#issuecomment-1427049939:129,log,log,129,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/701#issuecomment-1427049939,1,['log'],['log']
Testability,"I am using salmon v1.0.0 that was compiled using bioconda. I downloaded fastq files from GEO, built an index using salmon index, but am getting 0 mappings. . #Downloading data; wget -o test.fastq.gz s3://sra-pub-src-5/SRR*******/test.fastq.gz. #building the salmon index from gencode [using vM22 for consistency]; salmon index -t gencode.vM22.transcripts.fa.gz -i gencode.vM22.transcripts --gencode. #running salmon quant; salmon quant -l A -i gencode.vM22.transcripts -r test.fastq.gz -o ~/Test1/ --gcBias --validateMappings --numGibbsSamples 20. The output .sf files have 0 TPMs and 0 fragment reads for all outputs and I am attaching a screenshot of the log file. . The reference genome and sequencing file is from the same organism. . ![Screen Shot 2022-10-06 at 3 53 32 PM](https://user-images.githubusercontent.com/108241225/194406132-61d5a5ce-a429-4b04-9fab-e4586dea9020.png)",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/804:185,test,test,185,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/804,4,"['log', 'test']","['log', 'test']"
Testability,"I assumed it was latter :) I can re-run it in a few days with more memory and actually benchmark (time, max memory, etc) it if that's helpful!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-575858246:87,benchmark,benchmark,87,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-575858246,1,['benchmark'],['benchmark']
Testability,"I believe this is because unlike the `salmon` target, the unitTests that run when `make test` is executed aren't installed via the `install` command [see e.g.](https://github.com/COMBINE-lab/salmon/blob/master/src/CMakeLists.txt#L312). This is due, I presume, to my naive usage of CMake as it relates to the testing target. I've yet to find a solid resource that explains the ""right way"" to handle this using (modern) CMake. That, of course, goes to your point of the pain of CMake.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-397080244:88,test,test,88,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-397080244,2,['test'],"['test', 'testing']"
Testability,"I built salmon 0.7.2 on OSX 10.13.3, then ran 'make test'. Test #1 fails, other two succeed. Looking at file Testing/Temporary/LastTest.log, it says:. ```; ""unit_tests"" start time: Mar 03 20:31 PST; Output:; ----------------------------------------------------------; CMake Error at /Users/tedtoal/src/salmon-0.7.2/cmake/UnitTests.cmake:7 (message):; Error running No such file or directory. ```. I looked in the tests directory and find program ""unitTests"", and when I run it, it succeeds:. ```; ===============================================================================; All tests passed (158 assertions in 4 test cases). ```. leading me to believe that actually, test1 succeeds, but something is wrong with the test system and it doesn't see that it succeeded.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/204:52,test,test,52,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/204,9,"['Test', 'assert', 'log', 'test']","['Test', 'Testing', 'assertions', 'log', 'test', 'tests']"
Testability,"I can confirm that the problem in the log is not creating the exception error raised by this issue and the indexing procedure took care of the potential duplicates due to repeated names. There is something else going on. I used the binary from github and indexed, it seems to work on our end. @rob-p thoughts ?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/441#issuecomment-549155511:38,log,log,38,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/441#issuecomment-549155511,1,['log'],['log']
Testability,"I can try '^' and '$' after lunch. I didn't test any other library, since boost was already a pre-requisite for salmon and my focus was on getting it to work first. But now that it is done, other libraries can be tried. However, at this moment, I'm not clear about the effort and speed-up ratio.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1013348732:44,test,test,44,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1013348732,2,['test'],['test']
Testability,"I did not previously test that, but I am currently running the analysis with the extra `--expectCells 10000` parameter. I will post an update. If all goes well, I will then close the ticket. Thank you again for your help!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-883784536:21,test,test,21,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-883784536,1,['test'],['test']
Testability,"I did not see any output. That's the reason why the test stopped with the timeout.; Ref: https://travis-ci.org/COMBINE-lab/salmon/builds/419012959. Here is my commit on this PR. You can do cherry-pick to check it.; https://github.com/junaruga/salmon/commits/hotfix/develop-unrecognized-cxx-std-14_3. If you add `--verbose` or `--debug` to the `ctest`, you might see something?. ```; /usr/local/cmake-3.9.2/bin/ctest --force-new-ctest-process --verbose --debug; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/276#issuecomment-416155226:52,test,test,52,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/276#issuecomment-416155226,1,['test'],['test']
Testability,"I didn't do more full testing, but it looks like the latter problem is indeed coming from `alevin-fry quant` (and this is a temporary but expected behavior). https://github.com/COMBINE-lab/alevin-fry/blob/967f5cbb404fb86a71291d88a73afa071570b575/libradicl/src/quant.rs#L1622-L1651. I'm not familiar enough with rust to know whether this will result in overwriting `cmd_info.json` and `meta_info.json` files that exist, but it does seem to me a good behavior would be to merge the info from `salmon alevin` and `alevin-fry`, particularly for the `meta_info.json` file, where both tools add useful information.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/688#issuecomment-883468182:22,test,testing,22,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/688#issuecomment-883468182,1,['test'],['testing']
Testability,"I didn't realize the resolver was so screwed up. And yeah, I get it that it's not your responsibility to fix it! In retrospect, as we're always specify versions in Snakemake profiles, the problem should be a non-issue. I was just doing some local testing when I encountered the ""issue"". Thx,; Adam",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/895#issuecomment-1784111111:247,test,testing,247,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/895#issuecomment-1784111111,1,['test'],['testing']
Testability,"I don't see any files named `*CMakeLog*`. Which file exactly do you need? I see…; ```; CMakeFiles/CMakeError.log CMakeFiles/CMakeRuleHashes.txt; CMakeFiles/CMakeOutput.log CMakeFiles/TargetDirectories.txt; ```; Here's a gist: https://gist.github.com/sjackman/6e15b7dfebaaad99b9476aa5ce269fda; This error is reproducible like so:; ```sh; docker run -it linuxbrew/linuxbrew brew install -sdv https://raw.githubusercontent.com/sjackman/homebrew-bio/dab661f902c5841e0d498eb338975c47080a1118/Formula/salmon.rb; ```. Ignore `FormulaUnavailableError: No available formula with the name ""xorg""`; and select `5. shell` to get a shell prompt",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/181#issuecomment-367793075:109,log,log,109,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/181#issuecomment-367793075,2,['log'],['log']
Testability,"I edited in the results of my 16GB test to the post above. There's something a bit weird going on with that job in particular. However, I can say that despite the (relatively) severe memory limitation, it appears that everything worked out just fine in ~4hrs. Not the fastest time overall, but factoring the times that I was stuck waiting for resources on those huge jobs, this is definitely an improvement.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-590592852:35,test,test,35,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-590592852,1,['test'],['test']
Testability,"I explicitly preallocate the output array/vector for pcre and re2. Boost regex doesn't seem to offer that (at least, I don't know). Regarding xpressive: yeah, what a disappointment. And I don't actually save the capture with xpressive. I thought the automaton was entirely generated and optimize at compile time. Apparently creating an automaton with C++ template system must be really hard because the generated code is garbage. Or I am using it wrong. In any case, xpressive as I use it is entirely static (I haven't tested the dynamic version). So it is not useful in our case. I was just curious if it could match hand crafted code. What was I thinking!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1024206420:519,test,tested,519,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1024206420,1,['test'],['tested']
Testability,"I guess there can be many things and it's hard to say without the logs, can you share the alevin and the salmon logs ?; Like @rob-p mentioned you can try changing ISR to ISF and/or using alevin-fry and check if that makes a difference, although if it's about mapping then probably it won't matter. I did notice one strange thing in the `umi extract` command though, please recheck this through the UMI tools package but you used `--stdout GSE140511/fastq_files/SRR10480618_BC_1.fastq.gz` and `--read2-out GSE140511/fastq_files/SRR10480618_BC_2.fastq.gz` in the umi tools command, which are the two files that probably should be provided as `-1` and `-2` flags to alevin. I am not sure why you are using `GSE140511/fastq_files/SRR10480618_1.fastq.gz` as the `-2` flag, which looks wrong to me, may be that will solve the issue. . Hope it helps.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/763#issuecomment-1073009028:66,log,logs,66,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/763#issuecomment-1073009028,2,['log'],['logs']
Testability,"I had a fasta file with an space at the end of a sequence line. This caused salmon to fail, somewhat quietly (no output files are produced). It would be nice to report the specific problem with the input or position of the failing line, ... log:. <pre>; Logs will be written to output_dir/logs; there is 1 lib; [2015-10-09 15:47:13.170] [jointLog] [info] parsing read library format; [bns_restore_core] Parse error reading ./current_index/bwaidx.amb; </pre>",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/22:241,log,log,241,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/22,3,"['Log', 'log']","['Logs', 'log', 'logs']"
Testability,"I have a pretty wide array of benchmarks and I haven't seen any regression with the VB option on 0.4.1, including ERCC spike-ins on the SEQC data, where it does very well. But I haven't tested 0.4.0. @vals your data looks really compelling, I wonder if you'd humor me and try something, if it's not too much trouble: Could you try recomputing these correlations excluding ERCC-00074 and ERCC-00130? I've seen some data suggesting these might be misannotated by the vendor, which can cause these two to have a large effect on something like Pearson correlation, especially with methods like salmon and cufflinks that do bias correction. In benchmarks I've done, excluding them leads to more reliable results. I'm really curious if doing the same in your data changes anything.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/6#issuecomment-111743583:30,benchmark,benchmarks,30,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/6#issuecomment-111743583,3,"['benchmark', 'test']","['benchmarks', 'tested']"
Testability,"I have a salmon index which fails silently when used:. ```; Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; # salmon (mapping-based) v0.5.1; # [ program ] => salmon; # [ command ] => quant; # [ index ] => { ... }; # [ libType ] => { IU }; # [ mates1 ] => { ... }; # [ mates2 ] => { ... }; # [ output ] => { ... }; # [ threads ] => { 16 }; Logs will be written to ...; [2016-01-22 16:54:55.564] [jointLog] [info] parsing read library format; there is 1 lib; Loading 32-bit quasi index; [2016-01-22 16:54:56.303] [jointLog] [info] Loading Quasi index; [2016-01-22 16:54:56.320] [stderrLog] [info] Loading Suffix Array; [2016-01-22 16:54:56.321] [stderrLog] [info] Loading Position Hash; [2016-01-22 16:56:17.595] [stderrLog] [info] Loading Transcript Info; [2016-01-22 16:56:36.767] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-01-22 16:56:40.858] [stderrLog] [info] There were 552702 set bits in the bit array; [2016-01-22 16:56:41.758] [stderrLog] [info] Computing transcript lengths; [2016-01-22 16:56:41.761] [stderrLog] [info] Waiting to finish loading hash; Index contained 552702 targets; [2016-01-22 17:00:40.648] [stderrLog] [info] Done loading index; [2016-01-22 17:00:40.648] [jointLog] [info] done; ```. Then the process exits and nothing but the `cmd_info.json` and log file are written to disk. The sequencing library is not an issue, as I can use several other index files successfully. This is reproducible with ~600 sequencing libraries as well. I believe this also occurs using v0.6.0, but will confirm. Since there is no core dump, is there any way for me to debug this?",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/37:434,Log,Logs,434,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/37,2,"['Log', 'log']","['Logs', 'log']"
Testability,I have attached a small subset of the bam for testing. ; [in.bam.zip](https://github.com/COMBINE-lab/salmon/files/3337430/in.bam.zip),MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/387#issuecomment-506585956:46,test,testing,46,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/387#issuecomment-506585956,1,['test'],['testing']
Testability,"I have been trying to use the salmon docker container available on docker hub. When I run salmon quant I am able to load all of the files and start the program, but I get a killed message while loading hash. I get an empty log file and empty folders created after the container is killed. **To Reproduce**; I run the following command to run the container:; `docker run -v /Users/caz3so/workspaces/salmon_docker:/temp -w /temp -ti combinelab/salmon`. The following is the output:; <img width=""1389"" alt=""screenshot 2018-06-27 11 15 56"" src=""https://user-images.githubusercontent.com/31480706/41983246-8296bb76-79fb-11e8-9710-c38ec051b7e7.png"">. **Expected behavior**; I have salmon installed on my machine and was able to run these files with no problem. It is only when I am using the docker container, so it could be a docker related problem. . **Desktop (please complete the following information):**; I am using a 2017 Macbook pro with 16 GB 2133 MHz LPDDR3 memory and a 2.8 GHz Intel Core i7 processor.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/243:223,log,log,223,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/243,1,['log'],['log']
Testability,"I have mapped Oxford Nanopore Reads to transcriptome using Graphmap. When I tried to run salmon quant on the BAM file, it shows that error below:. ```; salmon quant -t GRCh37.67.cdna.all.fa -l A -a in.bam -o out.count -p 15 --incompatPrior 1 --noErrorModel; # salmon (alignment-based) v0.11.3; # [ program ] => salmon; # [ command ] => quant; # [ targets ] => { /mnt/projects/kokep/kokep/reference/GRCh37.67.cdna.all.fa }; # [ libType ] => { A }; # [ alignments ] => { in.bam }; # [ output ] => { out.count }; # [ threads ] => { 15 }; # [ incompatPrior ] => { 1 }; # [ noErrorModel ] => { }; Version Info: ### PLEASE UPGRADE SALMON ###; ### A newer version of salmon with important bug fixes and improvements is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; Sign up for the salmon mailing list to hear about new versions, features and updates at:; https://oceangenomics.com/subscribe; ###; Logs will be written to out.count/logs; Malformed key:value pair at line 1: ""@HD VN:1.0 SO:coordinate ""; ============; Exception : [ERROR: Failed to open file in.bam, exiting!; ]; ============; /mnt/projects/kokep/kokep/devel/miniconda3/envs/salmon/bin/salmon alignment-quant was invoked improperly.; For usage information, try /mnt/projects/kokep/kokep/devel/miniconda3/envs/salmon/bin/salmon quant --help-alignments; Exiting. ```; How do I fix the error? Thanks in advance.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/387:1051,Log,Logs,1051,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/387,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"I have tried running Alevin with a few samples and everytime the program reaches 6M reads it crashes. I have tried this with a number of samples that have worked with Cell Ranger. I recompiled the program with `-DCMAKE_BUILD_TYPE=Debug` and have attached the output and gdb backtrace. There is roughly 8M reads in the single fastq file I am testing with. I can see a whole bunch of threads being created despite limiting the number of processes to two. Thanks!. ```; (gdb) run alevin -l ISR --chromium -p 1 -o 85948/alevin -1 <(gunzip -c ./85948/run1/85948_S18_L001_R1_001.fastq.gz) -2 <(gunzip -c ./85948/run1/85948_S18_L001_R2_001.fastq.gz) -i ./salmon/transcripts_index --tgMap tx2gene.txt; Starting program: ./salmon/build-debug/src/salmon alevin -l ISR --chromium -p 1 -o 85948/alevin -1 <(gunzip -c ./85948/run1/85948_S18_L001_R1_001.fastq.gz) -2 <(gunzip -c ./85948/run1/85948_S18_L001_R2_001.fastq.gz) -i ./salmon/transcripts_index --tgMap tx2gene.txt; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".; For more information about this security protection see the; ""Auto-loading safe path"" section in the GDB manual. E.g., run from the shell:; info ""(gdb)Auto-loading safe path""; [New Thread 0x7fff7e0f4700 (LWP 27861)]; [Thread 0x7fff7e0f4700 (LWP 27861) exited]; Version Info: ### A newer version of Salmon is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; [New Thread 0x7fff7d273700 (LWP 27862)]; Logs will be written to 85948/alevin/logs; [New Thread 0x7ffefc3f1700 (LWP 27865)]; [New Thread 0x7ffe7b56f700 (LWP 27866)]; [New Thread 0x7ffdfa6ed700 (LWP 27867)]; ### salmon (single-cell-based) v0.10.1; ### [ program ] => salmon; ### [ command ] => alevin; ### [ libType ] => { ISR }; ### [ chromium ] => { }; ### [ threads ] => { 1 }; ### [ output ] => { 85",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234:341,test,testing,341,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234,1,['test'],['testing']
Testability,"I have tried to dichotomise my transcript db. The 2nd transcript in the attached file, crashes with the 2x12 paired-end fastq I have tried (ISR or IU). index was generated with:; salmon index -t test.fa --gencode -k 31 -i index. quantification with:; salmon quant -i index -l A -1 /tmp/r1.fastq.gz -2 /tmp/r2.fastq.gz --validateMappings -o test",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/228#issuecomment-393482153:195,test,test,195,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/228#issuecomment-393482153,2,['test'],['test']
Testability,"I haven't done too much testing with the quality of inferring the fragment start position distribution with few samples. 5 million is probably overkill, as it's a fairly low-dimensional model --- you could try setting the number of burnin fragments to a lower number.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/33#issuecomment-168354132:24,test,testing,24,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/33#issuecomment-168354132,1,['test'],['testing']
Testability,"I increased ram to 24G. Segmentation fault happens even faster. I have fiddled with swap memory, to no avail, but I am not a good swap fiddler.; libs with malloc in their name, installed in directory /salmon-latest_linux_x86_64/ib adjacent to /salmon-latest_linux_x86_64/bin, are the same as elsewhere already on my system. conda and bioconda are not available for FreeBSD. What OS would work?; I have looked through the published papers and find no mention of which OS should work. My attempted command for compiling the sources from unzipped directory salmon-0.14.1 is: cmake -S src -B build; Many errors result, starting with:; TBB_LIBRARIES = ; Setting libdivsufsort = /external/install/lib/libdivsufsort.a; Setting libdivsufsort64 = /external/install/lib/libdivsufsort64.a; -- Configuring done; CMake Error at CMakeLists.txt:196 (add_executable):; Cannot find source file:. /tests/UnitTests.cpp. Tried extensions .c .C .c++ .cc .cpp .cxx .cu .m .M .mm .h .hh .h++ .hm; .hpp .hxx .in .txx. CMake Error at CMakeLists.txt:196 (add_executable):; Target ""unitTests"" links to target ""Threads::Threads"" but the target was; not found. Perhaps a find_package() call is missing for an IMPORTED; target, or an ALIAS target is missing?. CMake Error at CMakeLists.txt:162 (add_library):; Cannot find source file:. /src/jellyfish/mer_dna.cc. Tried extensions .c .C .c++ .cc .cpp .cxx .cu .m .M .mm .h .hh .h++ .hm; .hpp .hxx .in .txx. Apparently the so-called sources do not include many files ending in .cpp, for instance. Please, I repeat, what linux OS should be able to install salmon? ; And/Or what command could compile salmon?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/419#issuecomment-522626638:880,test,tests,880,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/419#issuecomment-522626638,1,['test'],['tests']
Testability,"I just now installed Salmon 0.12.0-alpha by compiling it on Ubuntu 18.04 successfully and ran the make and make install commands. While running the make test command I get the following output...; ----------------------------------------------------------------------------------------; Running tests...; Test project /scratch/Programes/salmon-0.12.0-alpha; Start 1: unit_tests; 1/2 Test #1: unit_tests .......................***Failed 0.01 sec; Start 2: salmon_read_test_quasi; 2/2 Test #2: salmon_read_test_quasi ........... Passed 1.06 sec. 50% tests passed, 1 tests failed out of 2. Total Test time (real) = 1.07 sec. The following tests FAILED:; 	 1 - unit_tests (Failed); Errors while running CTest; Makefile:151: recipe for target 'test' failed; make: *** [test] Error 8; ----------------------------------------------------------------------------------------; Why is this test failing?; It is OK.; I am new to Salmon. with best regards,; Baradwaj",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/315:153,test,test,153,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/315,12,"['Test', 'test']","['Test', 'test', 'tests']"
Testability,"I just tried the /dev/fd/0 approach. First I ran. ```; salmon quant -i /nfs/research2/teichmann/reference/mus-musculus/salmon/quasi/mouse_cdna_38.p3.78_repbase_ercc.fa -l IU -1 reads_1.fastq -2 reads_2.fastq -o normal_salmon_out; ```. In this case the following is the content of the `salmon_quant.log`. ```; [2016-01-03 00:33:37.001] [jointLog] [info] parsing read library format; [2016-01-03 00:33:37.510] [jointLog] [info] Loading Quasi index; [2016-01-03 00:33:53.646] [jointLog] [info] done; [2016-01-03 00:34:14.501] [jointLog] [info] Computed 13742 rich equivalence classes for further processing; [2016-01-03 00:34:14.501] [jointLog] [info] Counted 335230 total reads in the equivalence classes; [2016-01-03 00:34:14.501] [fileLog] [info]; At end of round 0; ==================; Observed 3835342 total fragments (3835342 in most recent round). [2016-01-03 00:34:20.992] [jointLog] [warning] Only 335230 fragments were mapped, but the number of burn-in fragments was set to 5000000.; The effective lengths have been computed using the observed mappings. [2016-01-03 00:34:20.992] [jointLog] [info] Mapping rate = 8.74055%. [2016-01-03 00:34:20.992] [jointLog] [info] finished quantifyLibrary(); [2016-01-03 00:34:20.992] [jointLog] [info] Starting optimizer; [2016-01-03 00:34:21.028] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate; [2016-01-03 00:34:21.030] [jointLog] [info] iteration = 0 | max rel diff. = 23.4889; [2016-01-03 00:34:21.167] [jointLog] [info] iteration = 100 | max rel diff. = 0.150549; [2016-01-03 00:34:21.304] [jointLog] [info] iteration = 200 | max rel diff. = 0.0517672; [2016-01-03 00:34:21.447] [jointLog] [info] iteration = 300 | max rel diff. = 0.0368208; [2016-01-03 00:34:21.578] [jointLog] [info] iteration = 400 | max rel diff. = 0.0237254; [2016-01-03 00:34:21.705] [jointLog] [info] iteration = 500 | max rel diff. = 0.0147784; [2016-01-03 00:34:21.834] [jointLog] [info] iteration = 600 | max rel diff. = 0.0131134; [2016-01-03 00:34:21",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-168447784:298,log,log,298,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-168447784,1,['log'],['log']
Testability,I just tried to index the GRCh38 transcriptome with decoys on a local machine (macOS Catalina 16GB) and it seemed to be doing ok for a while but after ~3hrs it got stuck (see log attached). I waited a good long while before killing it. Any suggestions?; These are the files I'm using:; ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_33/gencode.v33.transcripts.fa.gz; ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_33/GRCh38.primary_assembly.genome.fa.gz. [ref_indexing.log](https://github.com/COMBINE-lab/salmon/files/4377206/ref_indexing.log). EDIT: works fine without using decoys.; EDIT2: do you recommend using the indexes you link to here: http://bit.ly/30yn3FJ ? Or is there someway you could link to updated versions for the latest Salmon? ; thanks!,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-603455186:175,log,log,175,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-603455186,3,['log'],['log']
Testability,I made myself a plot to illustrate @roryk 's approach (hopefully got it right)- just leaving it here in case others are interested. ![compare_droplet_threshold](https://user-images.githubusercontent.com/5775915/57373557-9032fa00-7190-11e9-9cec-15b0a32f88aa.png). Code here: https://github.com/ebi-gene-expression-group/jon-sandbox/tree/master/droplet_cutoffs.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-490391990:323,sandbox,sandbox,323,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-490391990,1,['sandbox'],['sandbox']
Testability,"I might add that the progress display is pretty, but having an option to exclude it from the stderr logging, or even have no status updates, would be helpful for log file analysis.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/55#issuecomment-209989267:100,log,logging,100,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/55#issuecomment-209989267,2,['log'],"['log', 'logging']"
Testability,"I processed the data above using the latest salmon from the develop branch; (the release candidate for 1.3.0), and I got the following time (used 8; threads, so timing is not directly comparable). ```; 4604.57user 43.64system 9:24.15elapsed 823%CPU; ```. The whole log is. ```; [2020-06-15 23:51:54.747] [jointLog] [info] setting maxHashResizeThreads to; 8; [2020-06-15 23:51:54.747] [jointLog] [info] Fragment incompatibility prior; below threshold. Incompatible fragments will be ignored.; [2020-06-15 23:51:54.747] [jointLog] [info] Usage of --validateMappings; implies use of minScoreFraction. Since not explicitly specified, it is; being set to 0.65; [2020-06-15 23:51:54.747] [jointLog] [info] Usage of --validateMappings; implies a default consensus slack of 0.2. Setting consensusSlack to 0.35.; [2020-06-15 23:51:54.747] [jointLog] [info] parsing read library format; [2020-06-15 23:51:54.747] [jointLog] [info] There is 1 library.; [2020-06-15 23:51:54.814] [jointLog] [info] Loading pufferfish index; [2020-06-15 23:51:54.814] [jointLog] [info] Loading dense pufferfish index.; [2020-06-15 23:51:55.555] [jointLog] [info] done; [2020-06-15 23:51:55.555] [jointLog] [info] Index contained 116,248 targets; [2020-06-15 23:51:55.588] [jointLog] [info] Number of decoys : 0; [2020-06-16 00:00:59.666] [jointLog] [info] Computed 344,764 rich; equivalence classes for further processing; [2020-06-16 00:00:59.666] [jointLog] [info] Counted 12,956,134 total reads; in the equivalence classes; [2020-06-16 00:00:59.673] [jointLog] [warning] 0.0736383% of fragments were; shorter than the k used to build the index.; If this fraction is too large, consider re-building the index with a; smaller k.; The minimum read size found was 1. [2020-06-16 00:00:59.673] [jointLog] [info] Number of mappings discarded; because of alignment score : 134,091,887; [2020-06-16 00:00:59.673] [jointLog] [info] Number of fragments entirely; discarded because of alignment score : 2,429,390; [2020-06-16 00:00:59.673]",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-644520228:265,log,log,265,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-644520228,1,['log'],['log']
Testability,"I ran salmon alevin 0.14.0 with a custom transcriptome reference and the following options: --chromium --dumpFeatures --dumpMtx --whitelist mylist.txt. Everything ran through OK. However, when I tried to load the .mtx file with readMM() in R, I got the error: ; ` Error: readMM(): column values 'j' are not in 1:nc `. When I tried to read directly the binary file into a matrix, there's a warning:; ```; counts <- readBin(quants_mat.gz, what = 'numeric', n = length(genes)*length(cells)); close.connection(quants_mat.gz); Warning message:; In matrix(data = counts, nrow = length(cells), ncol = length(genes), :; data length [391335] is not a sub-multiple or multiple of the number of rows [4942]; ```; It seems like there's issue with the dimensions; [out.zip](https://github.com/COMBINE-lab/salmon/files/3296080/out.zip); of the output matrix. I've attached my log file as well as my output files (both .mtx and binary). Thank you.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/380:862,log,log,862,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/380,1,['log'],['log']
Testability,"I realized that most of these unassigned reads are probably paired-end reads that didn't match the specified the libType, which was ""IU"", or inward, not stranded. So I ran `samtools stats` on my BAM file to verify that.; ```; SN inward oriented pairs: 6191674; SN outward oriented pairs: 13515; ```; The inward pairs 6191674 is close to the pairs Salmon assigned, which was 6192944, but not the same. That's OK, considering Salmon and samtools probably have different ways of defining inward, outward read pairs.; I think it's helpful if Salmon can say in the log how many reads were excluded, for what reason. Thanks.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/952#issuecomment-2292317033:560,log,log,560,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/952#issuecomment-2292317033,1,['log'],['log']
Testability,"I really hope it doesn't 😟 , but the testing I've been doing is on 64-bit 14.10. I have a 16.04 box I can try it on as well. running on the 16.10 machine now to see if I can repro.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266936224:37,test,testing,37,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266936224,1,['test'],['testing']
Testability,"I recently ran Salmon by quasi-mapping-based mode and when I checked the salmon_quant.log file, saw that mapping rate was around ~%65-68 for all of the samples. Do you have any suggestions to improve the mapping rate? I used ""--libType A"" to to infer the library type info and got a warning that ""Greater than 5% of the fragments disagreed with the provided library typ"", but I guess this is not an issue. This is an example for one of the ""lib_format_counts.json"" files: . ```; {; ""read_files"": ""( /mnt/dznehomes/homes/simonj/RNAseq_pipeline/frontal_data/samples/Trimmed_FASTQ_files/00116_GFM_R1_trimmed.fastq.gz, /mnt/dznehomes/homes/simonj/RNAseq_pipeline/frontal_data/samples/Trimmed_FASTQ_files/00116_GFM_R2_trimmed.fastq.gz )"",; ""expected_format"": ""ISR"",; ""compatible_fragment_ratio"": 0.9241470144855659,; ""num_compatible_fragments"": 34584460,; ""num_assigned_fragments"": 37423115,; ""num_consistent_mappings"": 334748580,; ""num_inconsistent_mappings"": 28046150,; ""MSF"": 0,; ""OSF"": 32448,; ""ISF"": 20518131,; ""MSR"": 0,; ""OSR"": 487250,; ""ISR"": 334748580,; ""SF"": 1833525,; ""SR"": 5088606,; ""MU"": 0,; ""OU"": 0,; ""IU"": 0,; ""U"": 0; }; ```",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/160:86,log,log,86,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/160,1,['log'],['log']
Testability,"I see, we might have to tweak a bit based on the use case for `longranger basic`.; In `v0.10`, alevin should still be able to do CB correction, and attach the corrected CBs to the header of the second file, although the remaining template sequence (128 bases) from the first file might get loss, since `cellranger` was using template sequencing in only one file. Like @rob-p was saying we can work on making this step more generalized, once we confirm that the error-correction model for `cellranger` and `longranger` can be used interchangeably. In theory we can still concatenate the remaining 128 bases into an interleaved format since alevin has hidden options to provide the lengths explicitly but we have not tested this feature extensively. We will keep this at the top of our feature-request list and would inform you as soon as we have a stable version with this feature. Thanks again for the interest !!. re: *interleaved format* -- indeed an interleave format does makes sense and should be the default dumping format, but I believe since the default mode of 10x's `mkfastq` is to dump separate `FASTQ`, we should not use resources to create an interim interleaved format and then consume it downstream (since`FASTQ` itself is not very efficient), instead, in alevin we just consume the two separate `FASTQ` into our own interim data-structure to perform the downstream analysis.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/233#issuecomment-395195411:715,test,tested,715,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/233#issuecomment-395195411,1,['test'],['tested']
Testability,I seem to be having this same problem attempting to compile salmon 0.7.2 using GCC 5.3 (linuxbrew) on our server cluster. Works fine on my Mac though. Any ideas? I can post the log.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/46#issuecomment-247394237:177,log,log,177,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/46#issuecomment-247394237,1,['log'],['log']
Testability,"I tend to benchmark new versions of software mostly to check how much better things get over time at solving our problems. My strategy for benchmarking is to look at correlation between spike-ins at known abundances and estimated expression by software. The latest version of Salmon (0.4.0) performs markedly worse than all the previous versions of Salmon on the same data. ![salmong-performance](https://cloud.githubusercontent.com/assets/668803/8134113/8ff1a4ae-1124-11e5-80d5-10022530ba99.png). For running parameters, here is the top part of one of the `quant.sf` files. ```; # salmon (smem-based) v0.4.0; # [ program ] => salmon ; # [ command ] => quant ; # [ index ] => { /nfs/research2/teichmann/reference/homo-sapiens/salmon/Homo_sapiens.GRCh38.78.cdna_ERCC }; # [ libType ] => { IU }; # [ threads ] => { 4 }; # [ mates1 ] => { /nfs/research2/teichmann/valentine/detection-comparison/salmon-comparison/human/SRP030617_HCT116_86_1.fastq }; # [ mates2 ] => { /nfs/research2/teichmann/valentine/detection-comparison/salmon-comparison/human/SRP030617_HCT116_86_2.fastq }; # [ output ] => { /tmp/SRP030617_HCT116_86_salmon_out }; # [ geneMap ] => { /nfs/research2/teichmann/reference/homo-sapiens/Homo_sapiens.GRCh38.78.cdna_ERCC.gene_map.txt }; # [ useVBOpt ] => { }; # [ mapping rate ] => { 48.8199% }; ```",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/6:10,benchmark,benchmark,10,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/6,2,['benchmark'],"['benchmark', 'benchmarking']"
Testability,I tested against the released 0.6.0 tarball.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/70#issuecomment-239631165:2,test,tested,2,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/70#issuecomment-239631165,1,['test'],['tested']
Testability,"I tested changing the parameters, and I am still getting the same error message:. ```; [2021-07-08 16:05:50.979] [alevinLog] [info] Done importing white-list Barcodes; [2021-07-08 16:05:50.979] [alevinLog] [error] Wrong whitelist provided; Please check https://salmon.readthedocs.io/en/develop/alevin.html#whitelist; ```. However, I will look into the other information and see if I can understand what is happening. I can also test not using a white list and see if that changes the number to be something like an order of magnitude different that what I would expect from the other sample. So, I will post an update when I can run alevin without an error message, and try to give some sense of the results that are quantified.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-877303669:2,test,tested,2,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-877303669,2,['test'],"['test', 'tested']"
Testability,"I think I see the issue, and we might not actually need the data.; The issue being the list of CBs in `whitelist.txt` is too many. It seems the data is very noisy and `knee` finding algorithm is failing. I'd suggest to use `--dumpFeatures` flag with alevin (you can also do `--noQuant` to stop alevin before mapping). This flag will generate `raw_cb_frequency.txt` file i.e. the frequency of all the observed CB and making the histogram will help visually find if there is possible knee in the data, generally it is in a real experiment. re: the mapping rate, in the alevin log you'll observe there were 50% of the CB which were thrown away if you use `forceCells 3000` w/o whitelist, basically alevin is taking top `3000` cells into consideration and throwing everything away. While the rise in mapping rate when externally provided with whitelist is actually by allowing more CB to go through. The two options `forceCells` and `whitelist` wan't intended to be use simultaneously because if provided with external whitelist alevin assumes the user is confident with the set of CBs, in your case this list is huge (~700k). Are you using the 10x whitelist from their website? If yes, then it's not what alevin expect with `--whitelist` option. One work around here would be to look at the CB frequency histogram and making a file with only the CB sequences which you thing are above knee. Providing that file as the `--whitelist` is the intended use case for alevin. Hope this makes sense.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/340#issuecomment-458718943:574,log,log,574,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/340#issuecomment-458718943,1,['log'],['log']
Testability,I think logging non-error output to stderr is OK.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/55#issuecomment-237040761:8,log,logging,8,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/55#issuecomment-237040761,1,['log'],['logging']
Testability,"I think we should sort out this issue step by step. If you say `libstaden` has an important bugfix we should upgrade to the latest version in any case. Do you have a link to this bug? I admit this update simply slipped through - we should have upgraded this in the beginning of this year. Usually we try to follow upstream closely (which we failed for salmon blatantly for several reasons - one is the close connection to pufferfish).; Regarding `pufferfish`: We tried hard to get `pufferfish` packaged but failed (due to the use of other versions of `spdlog`, `cereal`, and `fmt`) However, since we can't run `fetchPufferfish.sh` *inside the build process* I was running it separately and added the downloaded source in [debian/external/pufferfish](https://salsa.debian.org/med-team/salmon/-/tree/master/debian/external/pufferfish) So I think the requirement of salmon should be fulfilled. I confirm your feeling that pufferfish is important for the current issue.; However, in the test I did when opening this bug report I did not do that pre-downloading of pufferfish since I was building right in the downloaded source tarball. `libpufferfish-dev` was not installed by `apt build-dep salmon` since this package does not exist.; Kind regards, Andreas.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464878371:983,test,test,983,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464878371,2,['test'],['test']
Testability,I think you forgot to attach the log file ?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/375#issuecomment-501839908:33,log,log,33,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/375#issuecomment-501839908,1,['log'],['log']
Testability,"I think you're right wrt conda. I was able to install 1.10.2 with mamba fairly easily. We've been moving away from conda (towards mamba) but this didn't cross my mind when I was playing in my sandbox. Might be some cluster latency issues combined with conda's snail's pace causing the problem on our end. Thx for the quick replies!. Adam H. Freedman, PhD; Data Scientist; Faculty of Arts & Sciences Informatics Group; Harvard University; 38 Oxford St; Cambridge, MA 02138; phone: +001 310 415 7145; ________________________________; From: Rob Patro ***@***.***>; Sent: Sunday, October 29, 2023 11:01 AM; To: COMBINE-lab/salmon ***@***.***>; Cc: Freedman, Adam ***@***.***>; Mention ***@***.***>; Subject: Re: [COMBINE-lab/salmon] anaconda version of salmon outdated, missing decoys option (Issue #895). Hi @adamfreedman<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_adamfreedman&d=DwMCaQ&c=WO-RGvefibhHBZq3fL85hQ&r=MITI_LEJgyr1a24IMFAlSaZIPxMpOUT21T7L3fg4CjA&m=40O3raH84f_BIZ3HF7nqTYSO2FehGrGHL9b7sqT7LIpWZjFmA3BLxNDTHoz420jp&s=kxY9gCLGWZJp-dp7l31S6M5u2RuUTeWXVrKmaydpo5o&e=>,. I think this is just conda being very very very slow (and potentially broken). The following works fine for me (and finishes in ~1 minute):. mamba create -n salmon -c conda-forge -c bioconda salmon=1.10.2. Can you use the mamba resolver in your environment? Conda has become hardly usable over the years, but mamba works quite well as a fast replacement. I'll also note that I swapped the order of conda-forge and bioconda as the docs specify that bioconda should preferably come last in the list of channels. --Rob. —; Reply to this email directly, view it on GitHub<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_COMBINE-2Dlab_salmon_issues_895-23issuecomment-2D1784137337&d=DwMCaQ&c=WO-RGvefibhHBZq3fL85hQ&r=MITI_LEJgyr1a24IMFAlSaZIPxMpOUT21T7L3fg4CjA&m=40O3raH84f_BIZ3HF7nqTYSO2FehGrGHL9b7sqT7LIpWZjFmA3BLxNDTHoz420jp&s=GNiCXqUbJLM16QBJ5PNAqv-rsgDdpCpcvezPXO_riWk&e=>, or unsubscribe<",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/895#issuecomment-1784196835:192,sandbox,sandbox,192,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/895#issuecomment-1784196835,2,['sandbox'],['sandbox']
Testability,"I tried using Homo_sapiens.GRCh38.94.chr_patch_hapl_scaff.gtf.gz for the annotation file and ftp://ftp.ensembl.org/pub/release-94/fasta/homo_sapiens/cdna/Homo_sapiens.GRCh38.cdna.all.fa.gz to build the index but got a similar error. Here are the logs (I modified the salmon log a bit because it didn't have the error message that printed to stdout). [alevin.log](https://github.com/COMBINE-lab/salmon/files/3224429/alevin.log); [salmon_quant.log](https://github.com/COMBINE-lab/salmon/files/3224440/salmon_quant.log). One curious thing that I noticed:. ```; Index contained 175,775 targets; ...; ERROR: Txp to Gene Map not found for 175775 transcripts; ```; It seems to not be finding any of the transcripts? This was also the case for the gencode attempt that I made previously.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/336#issuecomment-496258062:246,log,logs,246,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/336#issuecomment-496258062,6,['log'],"['log', 'logs']"
Testability,"I tried wrapping the code around alphaSum but it didn't work.; I also set digammaMin to 1e-9 but no change.; What I find weird is that the following code works... ```cpp; #include <boost/math/special_functions/digamma.hpp>. int main() {; double logNorm = boost::math::digamma(1e-50);; printf(""%f\n"", logNorm);; return logNorm;; }; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393598770:245,log,logNorm,245,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393598770,3,['log'],['logNorm']
Testability,"I used salmon 0.9.1 successfully a few weeks ago. I am using the latest update according to miniconda. Now after typing in this script in the command line in my Terminal on my Mac, I get the following error message. I have tried to trouble shoot but I have not been able to solve the problem. . salmon quant -i cs_index -l A -r fastqtrimd/BOD19_5R1trimd.fastq.gz -o quant/BOD19_5R1_quant —seqBias --gcBias --writeUnmappedNames. Here is the error message in the command line:. Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; ### salmon (mapping-based) v0.9.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { cs_index }; ### [ libType ] => { A }; ### [ unmatedReads ] => { BOD19_5R1trimd.fastq.gz }; ### [ output ] => { BOD19_5R1_quant }; ### [ seqBias ] => { }; ### [ gcBias ] => { }; ### [ writeUnmappedNames ] => { }; Logs will be written to BOD19_5R1_quant/logs; [2018-03-19 12:13:21.295] [jointLog] [info] parsing read library format; [2018-03-19 12:13:21.295] [jointLog] [info] There is 1 library.; [2018-03-19 12:13:21.402] [jointLog] [info] Loading Quasi index; [2018-03-19 12:13:21.403] [jointLog] [info] Loading 32-bit quasi index; Exception : [Failed to read 8 bytes from input stream! Read 0]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting.; [2018-03-19 12:13:21.403] [stderrLog] [info] Loading Suffix Array . Does anyone have any ideas what is wrong? Sorry I am a novice!",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/209:940,Log,Logs,940,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/209,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"I was attempting to create an index for mapping of transcripts using the full chicken (Gallus gallus) genome from Ensembl. No errors appeared, but the ref_indexing.log stated ""Replaced 9,788,221 non-ATCG nucleotides"" which seems rather high compared to some of the numbers I've seen from gencode-derived indices. This is my first time making an index, so I don't know where to begin troubleshooting. What ""non-ATCG nucleotides"" are being replaced here, and what are they being replaced with? Could Salmon be reading metadata in transcript headers as nucleotide sequences? Why would it do that? Am I just being paranoid?. Here's my code. Note that chicken does not have a ""transcriptome"" file, so I concatenated the cdna and ncrna files ahead of the full genome. I've also attached the ref_indexing.log file.; ```. SALMON_BIN=/data/homezvol1/fweghors/chickscripts/salmon-1.8.0_linux_x86_64/bin/salmon; grep ""^>"" <(gunzip -c Gallus_gallus.GRCg6a.dna.toplevel.fa.gz) | cut -d "" "" -f 1 > decoys.txt; sed -i.bak -e 's/>//g' decoys.txt. cat Gallus_gallus.GRCg6a.cdna.all.fa.gz Gallus_gallus.GRCg6a.ncrna.fa.gz Gallus_gallus.GRCg6a.dna.toplevel.fa.gz > gentrome.fa.gz. gunzip gentrome.fa.gz. $SALMON_BIN index -t gentrome.fa -d decoys.txt -p 13 -i salmon_index; ```. [ref_indexing.log](https://github.com/COMBINE-lab/salmon/files/8375551/ref_indexing.log)",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/766:164,log,log,164,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/766,4,['log'],['log']
Testability,"I wonder if the max 1-edit distance restriction is too stringent for 21 length barcodes. One important flag to play with is the `--minScoreFraction`. The basic rule to set that is define [here](https://github.com/COMBINE-lab/salmon/blob/91091fc3650a3220f657a9f31616916513f0ad02/src/SalmonUtils.cpp#L3242-L3253). The gist being say if we wan't max k-edit we allow all the reads above the following threshold score (as in the log ):. ```; [2020-06-04 17:55:11.700] [alevinLog] [info] set CITE-seq minScoreFraction parameter to : 0.797619; ```; i.e. we use the equation `(max_score + edit_cost) - 0.5) / max_score`; where `max_score` = 2 * length of barcode = 2 * 21 = 42,; and `edit_cost`= `min( k * (mismatch - match), k * (go + ge - match)`;; `mismatch` penalty = -4; `match` = 2; `go` gap open penalty = -4; `ge` gap extend penalty = -2. For k=1, we had `edit_cost = 8` leading to automatic setting of `minScoreFraction` of 0.797619.; we have looked at 15 length barcodes, but it's possible longer barcodes might have more sequencing error. Let's try allowing more edits i.e. k=2, by setting `--minScoreFraction 0.607` and see if it improves the mapping rate.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639235133:424,log,log,424,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639235133,1,['log'],['log']
Testability,I wonder if there is any output from the `unit_tests` that are hanging. Does the travis log provide anything?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/276#issuecomment-416087043:88,log,log,88,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/276#issuecomment-416087043,1,['log'],['log']
Testability,"I would think the best way to test it would be as Mike says: run Salmon on a paired-end library with bias-correction enabled, and then re-run it on only read 1 of the same library, only read 2, and on all the reads but treating it as single-end, and see how close it comes in each case. I would say it's also important to test whether the bias estimation is robust against modest misspecification of the mean fragment size, since that is often not known very accurately.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/83#issuecomment-246164791:30,test,test,30,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/83#issuecomment-246164791,2,['test'],['test']
Testability,"I'm also at a loss for exactly what could bre going on here. Specifically, this bit confused me:. > It looks like the log points to a sample that completed successfully at 19:45:18.487 before the sample at the top of the post started 19:51:56.392. So, unless the clock is messed up, it seems the successful completion (which, obviously required loading the complete index for alignment) happens *before* the exception. Further, the output you printed around the exception happens at the start of program execution, so I don't understand the timeline of events here for a single run / execution.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/512#issuecomment-618093803:118,log,log,118,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/512#issuecomment-618093803,1,['log'],['log']
Testability,"I'm going to cc @dpryan79 on this — does it just not finish? It seems to work within our GitHub CI, where we have to grab the prebuilt salmon to test `simpleaf`.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/895#issuecomment-1784122719:145,test,test,145,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/895#issuecomment-1784122719,2,['test'],['test']
Testability,"I'm running salmon v.4 (downloaded and compiled today) on gencode v22 and got the following error:. Performing PCA decomposition; salmon: /home/merkija1/software/salmon-0.4.0/include/eigen3/Eigen/src/Core/Redux.h:202: static Eigen::internal::redux_impl<Func, Derived, 3, 0>::Scalar Eigen::internal::redux_impl<Func, Derived, 3, 0>::run(const Derived&, const Func&) [with Func = Eigen::internal::scalar_sum_op<double>; Derived = Eigen::Block<const Eigen::Matrix<double, -1, -1>, -1, 1, true>; Eigen::internal::redux_impl<Func, Derived, 3, 0>::Scalar = double]: Assertion `size && ""you are using an empty matrix""' failed.; Aborted. The command I ran is:; salmon-0.4.0/src/salmon quant --index gencode.v22.index_0.4.0/ --mates1 <(gunzip -c r1_fq1.gz r1_fq2.gz --mates2 <(gunzip -c r2_fq1.gz r2_fq2.gz ) --output $OUTPUT_DIR --biasCorrect --threads 4 --geneMap gencode.v22.annotation.nochr.gtf --libType ""ISF"". If I remove the --biasCorrect flag, it runs without error.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/5:560,Assert,Assertion,560,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/5,1,['Assert'],['Assertion']
Testability,I'm still experiencing this `cmake` error:. ```; -- extracting... [tar xfz]; CMake Error: Problem with archive_write_finish_entry(): Can't restore time; CMake Error: Problem extracting tar: /var/tmp/sjackman/salmon20160307-4399-1vksuoo/salmon-0.6.0/external/libdivsufsort.zip; -- extracting... [error clean up]; CMake Error at /var/tmp/sjackman/salmon20160307-4399-1vksuoo/salmon-0.6.0/libdivsufsort-prefix/src/libdivsufsort-stamp/extract-libdivsufsort.cmake:33 (message):; error: extract of; '/var/tmp/sjackman/salmon20160307-4399-1vksuoo/salmon-0.6.0/external/libdivsufsort.zip'; failed; ```. Here's a gist of the logs:; https://gist.github.com/sjackman/2bbfcf212c555fb20505#file-02-make-L397-L404,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/10#issuecomment-193515060:616,log,logs,616,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/10#issuecomment-193515060,1,['log'],['logs']
Testability,"I'm testing it now. ``` sh; brew edit salmon; ```. Then add. ``` ruby; patch do; url ""https://github.com/COMBINE-lab/salmon/pull/70.patch""; sha256 ""7129eac8591ad954cca30576519071b1f5ea2a36206f973a1aef0bc1eb5d20da""; end; ```. Then. ``` sh; brew install salmon --build-bottle; brew bottle salmon --json -v; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/70#issuecomment-239628714:4,test,testing,4,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/70#issuecomment-239628714,1,['test'],['testing']
Testability,I'm testing now whether `develop` bd7096e0fa055e0a71ab03a52d99977bcb61c905 is relocatable.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/70#issuecomment-239634152:4,test,testing,4,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/70#issuecomment-239634152,1,['test'],['testing']
Testability,"I'm trying to process the 10X 1.3 Million Brain Cells from E18 Mice dataset using Alevin with compiled salmon version 0.12.0 using the gencode.vM19.pc_transcripts.fa.gz as reference (https://support.10xgenomics.com/single-cell-gene-expression/datasets/1.3.0/1M_neurons). The chemistry used is the 10x-v2. I have divided the fastqs into the 133 libraries and I'm trying to run Alevin per library fastqs (~140 r1 fastqs per library). The dataset has been processed with the longranger demux program, which outputs one fastq with both the UMI+barcode and read-sequence. I have divided the fastqs so that it corresponds to the input of Alevin (i.e. the UMI+barcode in one fastq and the read-sequence in the other). However it seems that Alevin gets stuck on processing the barcodes, no error code is produced it just doesn't seem to do anything anymore with just ""processed X Million barcodes"" printed on the screen. Are you aware of such a problem with many fastq files or is there something that I'm not taking into account? Is there a limit how many files can be used as an input? I tested Alevin with 60 fastqs (120 in total r1+r2 fastqs) and it ran through but with more than 60 fastqs it seems to get stuck on processing the barcodes. If it is not possible to run all the library related fastqs, do you recommend running them in smaller batches and then combining the resulting count matrices?. Command used: salmon alevin -l ISR -1 R1_fastqs -2 R2_fastqs --chromium -i index -p 20 -o alevin_output --tgMap txp2gene_mouse.tsv --dumpCsvCounts --whitelist barcode_whitelist.txt --minScoreFraction 0.7. The barcode whitelist was gotten from the HDF5 file which has the original data in a filtered matrix format (it has been run through the cellranger).",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/333:1082,test,tested,1082,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/333,1,['test'],['tested']
Testability,"I'm trying to use salmon v1.0.0 to merge a bunch of bulk quant files successfully also run with salmon. However, salmon can't seem to find the quant files, even though farther down in the log it lists the quant file within the same directory in memory:. [critical] The sample directory /gcloud-shared/quants/A653_388/quant.sf either doesn't exist, or doesn't contain a quant.sf file; ...yet... /gcloud-shared/quants/A653_388:; total 9.9M; drwxr-xr-x 2 root root 4.0K May 20 16:11 aux_info; -rw-r--r-- 1 root root 349 May 20 16:11 cmd_info.json; drwxr-xr-x 2 root root 4.0K May 20 16:11 libParams; -rw-r--r-- 1 root root 588 May 20 16:11 lib_format_counts.json; drwxr-xr-x 2 root root 4.0K May 20 16:11 logs; -rw-r--r-- 1 root root 9.8M May 20 16:11 quant.sf. Here's a shorter version of my command :; salmon --no-version-check quantmerge --quants /gcloud-shared/quants/A653_388 /gcloud-shared/quants/A653_242 --names sample1 sample2 --column numreads --genes -o /gcloud-shared/merge/ukbec_gene_numreads.sf. Any idea what might be happening? I'll also attach the logs and quant file from the sample in case thats helpful. [ukbec_logs_salmon_quantmerge5.txt](https://github.com/COMBINE-lab/salmon/files/6517777/ukbec_logs_salmon_quantmerge5.txt). [ukbec_quants_gencode_32_filtered_A653_388_quant.txt](https://github.com/COMBINE-lab/salmon/files/6517782/ukbec_quants_gencode_32_filtered_A653_388_quant.txt); [ukbec_quants_gencode_32_filtered_A653_388_logs_salmon_quant.log](https://github.com/COMBINE-lab/salmon/files/6517784/ukbec_quants_gencode_32_filtered_A653_388_logs_salmon_quant.log)",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/662:188,log,log,188,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/662,5,['log'],"['log', 'logs']"
Testability,"I've addressed this in a recent [commit](https://github.com/COMBINE-lab/salmon/commit/05859ef8412687be14de5084f3b1e0e688fb3e76). Now, `version`, `help`, `cite` and `swim` will print to stdout, while other normal logging messages will print to stderr. Basically, if it was specifically requested by the user, send it to stdout; otherwise send it to stderr.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/148#issuecomment-378405708:212,log,logging,212,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/148#issuecomment-378405708,1,['log'],['logging']
Testability,I've been trying to understand this readout as mine seems abnormally low.; I want to understand it well enough to be sure that the low readout is indicative of and how I can test hypotheses.; Currently my hits per frag is 0.0170477 using mapping-based mode against the human transcripts from https://www.gencodegenes.org/human/. The sample was expected to have a high amount of human RNA and if I'm interpereting this correctly this means that a small minority of reads were mappable to that transcriptome. I'm sorry to open a thread about this but I didn't see it explained in the Docs or any other discussions.,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/558:174,test,test,174,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/558,1,['test'],['test']
Testability,"I've been using 0.7.1 without problems until today.; I'm trying to index the transcriptome (made with gffread) of human GRCh37 from archived Ensembl 60. The process has been running for hours, with no messages beyond this:. ```; Version Info: ### A newer version of Salmon is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases ; contains some new features and minor bug fixes; please upgrade at your; earliest convenience.; ###; [2016-11-04 13:45:38.583] [jLog] [info] building index; RapMap Indexer. [Step 1 of 4] : counting k-mers. ```. This is all there is in the index.log. `[2016-11-04 13:45:38.583] [jLog] [info] building index`. None of me previous indexes have taken so long, especially not in total silence. So I'm guessing it gets stuck somewhere, but where? Why?. I know there is a newer version, but getting our busy sysadmin to install things takes time and I didn;t see anything critical for my usage case listed in the release notes.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/100:624,log,log,624,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/100,1,['log'],['log']
Testability,"I've installed Salmon and made the index, but once I run the analysis, I've got this error:. (salmon) andrea@Precision-7920-Tower:/hdd_a/andrea/Salmon$ sudo salmon quant -i GRCh38_salmon_index/ -l A -r /hdd_a/andrea/Salmon/Fastq/1_vehicle_R1.fastq.gz --validateMappings -o /Output/; ### salmon (mapping-based) v0.12.0; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { GRCh38_salmon_index/ }; ### [ libType ] => { A }; ### [ unmatedReads ] => { /hdd_a/andrea/Salmon/Fastq/1_vehicle_R1.fastq.gz }; ### [ validateMappings ] => { }; ### [ output ] => { /Output/ }; Logs will be written to /Output/logs; [2024-02-21 09:49:04.094] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2024-02-21 09:49:04.094] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2024-02-21 09:49:04.094] [jointLog] [info] Usage of --validateMappings implies use of range factorization. rangeFactorizationBins is being set to 4; [2024-02-21 09:49:04.094] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 1. Setting consensusSlack to 1.; [2024-02-21 09:49:04.094] [jointLog] [info] parsing read library format; [2024-02-21 09:49:04.094] [jointLog] [info] There is 1 library.; [2024-02-21 09:49:04.207] [jointLog] [info] Loading Quasi index; Exception : [rapidjson internal assertion failure: IsObject()]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting. Any suggestion? ; Thank you",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/913:586,Log,Logs,586,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/913,3,"['Log', 'assert', 'log']","['Logs', 'assertion', 'logs']"
Testability,"I've just been testing Salmon using Illumina TruSeq stranded (dUTP) libraries. Using either `ISF` (correct libType) or `ISR` I get a **ton** of messages like this:. ```; expected = Library format { type: }; paired end, relative orientation:inwardexpected = Library format { type:paired end, relative orientation:Library format { type:paired end, relative orientation:inwardpaired endinward, strandedness:, relative orientation:inward, strandedness:(sense, antisense) }; observed = Library format { type:paired end, relative orientation:inward, strandedness:(antisense, sense) }; (sense, antisense)expected = , strandedness:(sense, antisense), strandedness:(sense, antisense) }; observed = }; Library format { type:paired end, relative orientation:inward, strandedness:(sense, antisense) }; observed = Library format { type:paired end, relative orientation:inward, strandedness:(antisense, sense) }; expected = Library format { type:observed = Library format { type: }; paired endLibrary format { type:paired end, relative orientation:, relative orientation:inward, strandedness:(sense, antisense) }; observed = Library format { type:paired end, relative orientation:inward, strandedness:observed = inward, strandedness:(antisense, sense) }; (antisense, sense) }paired end, relative orientation:inward, strandedness:(antisense, sense) }; expected = Library format { type:paired end, relative orientation:inward, strandedness:(sense, antisense)expected = Library format { type:Library format { type:; }paired endpaired endexpected = Library format { type:paired end, relative orientation:; , relative orientation:inwardinward, strandedness:(sense, antisense)observed = , strandedness:(antisense, sense) }; }; observed = Library format { type:paired end, relative orientation:inward, strandedness:(antisense, sense) }expected = Library format { type:, relative orientation:Library format { type:paired end; ```. and so on... It seems that the [`LibraryFormat` class](https://github.com/COMBINE-lab/salmon",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/16:15,test,testing,15,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/16,1,['test'],['testing']
Testability,"I've run into this as well, but's proving tricky to track down. I'm by no mean a expert on build chains (or a C/C++ for that matter), but as far as I can figure, this issue seems specific to RedHat systems. I get exactly the same linking error on RH6 and RH7 using any GCC compiler I have access to on those systems (4.8.5, 5.2.0, 7.2.0). Compiling on an Arch system with GCC 9.2.0 (glibc 2.30) sees no issue. Unfortunately I don't have easy access to the same compiler versions on both systems. I'm compiling GCC 5.2.0 (with glibc2.28) on the Arch system to test this now, but it's going to be a little while before I even know if I have a working toolchain that can use it.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/455#issuecomment-558714532:559,test,test,559,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/455#issuecomment-558714532,1,['test'],['test']
Testability,"I've switched to using precompiled binaries, version 0.6.0. Now working on a new server running CentOS Linux release 7.1.1503. I was able to successfully generate my index, then started running the quantification step. Here is my command:. `$ /home/jorvis/salmon/bin/salmon quant -p 24 -i transcripts_index -l IU -1 R1.trimmed.PE.fastq -2 R2.trimmed.PE.fastq -o transcripts_quan`. This host has 48 cores and 128GB RAM. . And here is the STDOUT. ```; Version Info: This is the most recent version of Salmon.; # salmon (mapping-based) v0.6.0; # [ program ] => salmon; # [ command ] => quant; # [ threads ] => { 24 }; # [ index ] => { transcripts_index }; # [ libType ] => { IU }; # [ mates1 ] => { R1.trimmed.PE.fastq }; # [ mates2 ] => { R2.trimmed.PE.fastq }; # [ output ] => { transcripts_quan }; Logs will be written to transcripts_quan/logs; [2016-03-30 15:50:48.489] [jointLog] [info] parsing read library format; there is 1 lib; Loading 64-bit quasi index[2016-03-30 15:50:48.543] [jointLog] [info] Loading Quasi index; [2016-03-30 15:50:48.544] [stderrLog] [info] Loading Suffix Array; [2016-03-30 15:50:48.544] [stderrLog] [info] Loading Position Hash; [2016-03-30 15:50:58.359] [stderrLog] [info] Loading Transcript Info; [2016-03-30 15:50:59.932] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-03-30 15:51:00.610] [stderrLog] [info] There were 2027284 set bits in the bit array; [2016-03-30 15:51:00.917] [stderrLog] [info] Computing transcript lengths; [2016-03-30 15:51:00.925] [stderrLog] [info] Waiting to finish loading hash; Index contained 2027284 targets; [2016-03-30 15:51:08.499] [jointLog] [info] done; [2016-03-30 15:51:08.499] [stderrLog] [info] Done loading index. Segmentation fault; ```. The only log file I see is this one: transcripts_quan/logs/salmon_quant.log. $ cat salmon_quant.log ; [2016-03-30 15:50:48.489] [jointLog] [info] parsing read library format; [2016-03-30 15:50:48.543] [jointLog] [info] Loading Quasi index; [2016-03-30 15:51:08.499] [jointLog] [i",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/54:798,Log,Logs,798,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/54,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"I've tried to reproduce the issue in docker by using the Build-Depends that are used in Debian:. $ docker pull debian:testing; $ docker run -it debian:testing; $ echo ""deb-src http://deb.debian.org/debian unstable main"" > /etc/apt/sources.list.d/10-debsrc.list; $ apt update; $ apt upgrade; $ apt build-dep salmon; $ wget https://github.com/COMBINE-lab/salmon/archive/refs/tags/v1.10.0.tar.gz; $ tar xaf v1.10.0.tar.gz; $ cd salmon-1.10.0; $ mkdir build && cd build; $ cmake -DNO_IPO=TRUE ..; $ make -j8; make -j8; [ 3%] Built target ksw2pp_sse4; [ 6%] Built target ntcard; [ 15%] Built target twopaco; [ 18%] Built target graphdump; [ 21%] Built target ksw2pp_sse2; [ 27%] Built target ksw2pp_basic; [ 43%] Built target salmon_core; [ 67%] Built target puffer; [ 68%] Built target ksw2pp; [ 69%] Built target UnitTestsMain; [ 73%] Built target alevin_core; [ 74%] Linking CXX executable unitTests; /usr/bin/ld: /usr/lib/x86_64-linux-gnu/libcurl.a(libcurl_gnutls_la-psl.o): in function `Curl_psl_destroy':; (.text+0x21): undefined reference to `psl_free'; /usr/bin/ld: /usr/lib/x86_64-linux-gnu/libcurl.a(libcurl_gnutls_la-psl.o): in function `Curl_psl_use':; (.text+0xbc): undefined reference to `psl_latest'; /usr/bin/ld: (.text+0x157): undefined reference to `psl_builtin'; /usr/bin/ld: /usr/lib/x86_64-linux-gnu/libcurl.a(libcurl_gnutls_la-version.o): in function `curl_version':; (.text+0x129): undefined reference to `BrotliDecoderVersion'; /usr/bin/ld: (.text+0x16f): undefined reference to `ZSTD_versionNumber'; /usr/bin/ld: (.text+0x1e3): undefined reference to `idn2_check_version'; /usr/bin/ld: (.text+0x20e): undefined reference to `psl_get_version'; /usr/bin/ld: /usr/lib/x86_64-linux-gnu/libcurl.a(libcurl_gnutls_la-version.o): in function `curl_version_info':; (.text+0x386): undefined reference to `idn2_check_version'; /usr/bin/ld: (.text+0x3ad): undefined reference to `BrotliDecoderVersion'; /usr/bin/ld: (.text+0x3b8): undefined reference to `BrotliDecoderVersion'; /usr/bin/ld: (.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463708855:118,test,testing,118,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463708855,2,['test'],['testing']
Testability,"If i use the smaller set of barcodes, then I progress further. However, I still receive an error message (and there no **quants_mat_rows.txt** file):. ```; [2021-07-13 13:59:07.109] [alevinLog] [info] Total 0.00 UMI after deduplicating.; [2021-07-13 13:59:07.109] [alevinLog] [info] Total 0 BiDirected Edges.; [2021-07-13 13:59:07.109] [alevinLog] [info] Total 0 UniDirected Edges.; [2021-07-13 13:59:07.134] [alevinLog] [info] Finished optimizer; /var/spool/slurmd/job3050767/slurm_script: line 23: 10494 Floating point exception../../Ref_Generation/salmon-1.5.1_linux_x86_64/bin/salmon alevin -l ISF --chromium -1 $R1 -2 $R2 -i $REF -p 4 -o $ID --tgMap $MAP --whitelist $CBWL. ```. If the barcode is on the opposite read, then I am not sure if I should really be using the reverse or reverse complement (possibly even for the full barcode list)?. However, for the sake of this discussion, I will now test not providing any white list. If that works, then I will close the ticket again. **Update (7/14/2021)**: I have added the full log file here: [cluster_log.log](https://github.com/COMBINE-lab/salmon/files/6819402/cluster_log.log)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-879497561:902,test,test,902,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-879497561,4,"['log', 'test']","['log', 'test']"
Testability,If salmon would just read stdin using a symbolic `-` then you should be able to do something like:. ``` bash; interleaved_fastq_emitter | salmon --mates1 - --mates2 - ; ```. ...as long as the fastq reading logic is operating on 4-lines at a time. This way there's no new arguments added to salmon.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-163361739:206,log,logic,206,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-163361739,1,['log'],['logic']
Testability,If you need testers for this I'm glad to help.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/37#issuecomment-188285598:12,test,testers,12,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/37#issuecomment-188285598,1,['test'],['testers']
Testability,"If you'd like to commit the equivalent of this PR into develop, I can test it for you. Give me the PR or commit SHA1, and I'll test it.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/70#issuecomment-239632730:70,test,test,70,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/70#issuecomment-239632730,2,['test'],['test']
Testability,"In CMakeLists.txt, `check_cxx_compiler_flag(-stdlib=libc++ HAVE_LIBCPP)` is used to determine whether to use LLVM's C++ stdlib - libc++, or the system's own GNU one (libstdc++). Unfortunately, those distros do not ship with that library (per the clip below) - and yet the test succeeds - yielding failure later in the build process due to lots of missing header files.; ```; [rocky@ip-10-11-36-33 ~]$ cat >test.cpp; #include <iostream>. int main() {; std::cout << ""Helloworld"";; }; [rocky@ip-10-11-36-33 ~]$ clang++ -stdlib=libc++ test.cpp ; test.cpp:1:10: fatal error: 'iostream' file not found; 1 | #include <iostream>; | ^~~~~~~~~~; 1 error generated.; ```. The cause is that CMake's `check_cxx_compiler_flag(-stdlib=libc++ HAVE_LIBCPP)` test which is used in Salmon only tests if the compiler accepts the flag (the test code it uses doesn't have any includes - just `main() {return 0;}`) rather than if it works. I don't know the whys behind the missing library - the library is available on OS/X for example - however it seems this behaviour should be changed for now on Linux platforms.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/969:272,test,test,272,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/969,7,['test'],"['test', 'tests']"
Testability,"In terms of an intermediate update:. **Setting 1**:. _Command 1_:; `/path/to/salmon alevin -l ISF --chromium -1 $R1 -2 $R2 -i $REF -p 4 -o $ID --tgMap $MAP`; _End of Log 1_:; ```; [2021-07-13 20:12:34.651] [alevinLog] [info] Starting white listing of 814 cells; [2021-07-13 20:12:34.651] [alevinLog] [info] Starting to make feature Matrix; [2021-07-13 20:12:34.654] [alevinLog] [info] Done making feature Matrix; [2021-07-13 20:12:35.447] [alevinLog] [info] Finished white listing; [2021-07-13 20:12:36.158] [alevinLog] [info] Finished optimizer; 0.0408521	8.9925e-05	0.000114595	636780	18682.9	; 0.0290163	6.61624e-05	0.000111685	230922	8010.3	; ```; _Size of quants_mat_rows.txt 1_: 814 lines/barcodes. **Setting 2:**:; _Command 1_:; `/path/to/salmon alevin -l ISR --chromium -1 $R1 -2 $R2 -i $REF -p 4 -o $ID --tgMap $MAP`; _End of Log 1_:; ```; [2021-07-14 09:51:38.564] [alevinLog] [info] Starting white listing of 814 cells; [2021-07-14 09:51:38.564] [alevinLog] [info] Starting to make feature Matrix; [2021-07-14 09:51:38.566] [alevinLog] [info] Done making feature Matrix; [2021-07-14 09:51:39.347] [alevinLog] [info] Finished white listing; [2021-07-14 09:51:39.541] [alevinLog] [info] Finished optimizer; [2021-07-14 09:51:39.564] [jointLog] [warning] NOTE: Read Lib [[ ../Reads/5309-CT-2_S01_L005_R1_001.fastq.gz, ../Reads/5309-CT-2_S01_L005_R2_001.fastq.gz]] :. Greater than 5% of the fragments disagreed with the provided library type; check the file: 5309-CT-2/lib_format_counts.json for details. 0.0408521	8.9925e-05	0.000114595	636780	18682.9	; 0.0290163	6.61624e-05	0.000111685	230922	8010.3	; ```; _Size of quants_mat_rows.txt 1_: 814 lines/barcodes. Technically, this means that the program ran without generating an error message, but this seems strange to me. So, I think I would prefer to keep the issue open a little bit longer.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-880273749:166,Log,Log,166,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-880273749,2,['Log'],['Log']
Testability,"Internal testing suggests that these errors are gone, but feel free to report back here (and reopen this) if you still encounter it.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/50#issuecomment-303617599:9,test,testing,9,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/50#issuecomment-303617599,1,['test'],['testing']
Testability,"Is it possible for you to share the alevin log, then I can explain better the numbers ?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/379#issuecomment-503319334:43,log,log,43,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/379#issuecomment-503319334,1,['log'],['log']
Testability,"Is there a way to compile Salmon to a 32-bit architecture by any chance? I ask because I'd like to have single-cell tutorials on sandbox.bio v2 that use Salmon. But to power the platform, I'm running a 32-bit/i686 Debian OS in the browser 😬. When I try to compile it in a [i386/debian:bookworm-20230904-slim](https://hub.docker.com/r/i386/debian/) Docker container, this is the error I get:. ```; 1075.0 -- Build files have been written to: /root/build/salmon/external/oneTBB-2021.5.0; 1075.2 [ 14%] Performing build step for 'libtbb'; 1075.7 [ 2%] Building CXX object src/tbb/CMakeFiles/tbb.dir/address_waiter.cpp.o; 1079.6 [ 5%] Building CXX object src/tbb/CMakeFiles/tbb.dir/allocator.cpp.o; 1083.2 [ 7%] Building CXX object src/tbb/CMakeFiles/tbb.dir/arena.cpp.o; 1087.7 In file included from /usr/lib/gcc/i686-linux-gnu/12/include/x86gprintrin.h:89,; 1087.7 from /usr/lib/gcc/i686-linux-gnu/12/include/immintrin.h:27,; 1087.7 from /root/build/salmon/external/oneTBB-2021.5.0/src/tbb/../../include/oneapi/tbb/detail/_machine.h:42,; 1087.7 from /root/build/salmon/external/oneTBB-2021.5.0/src/tbb/../../include/oneapi/tbb/detail/_utils.h:26,; 1087.7 from /root/build/salmon/external/oneTBB-2021.5.0/src/tbb/task_dispatcher.h:20,; 1087.7 from /root/build/salmon/external/oneTBB-2021.5.0/src/tbb/arena.cpp:17:; 1087.7 /usr/lib/gcc/i686-linux-gnu/12/include/waitpkgintrin.h: In function 'tbb::detail::r1::prolonged_pause()':; 1087.7 /usr/lib/gcc/i686-linux-gnu/12/include/waitpkgintrin.h:53:1: error: inlining failed in call to 'always_inline' '_tpause(unsigned int, unsigned long long)': target specific option mismatch; 1087.7 53 | _tpause (unsigned int __A, unsigned long long __B); 1087.7 | ^~~~~~~; 1087.7 compilation terminated due to -Wfatal-errors.; 1087.8 make[5]: *** [src/tbb/CMakeFiles/tbb.dir/build.make:104: src/tbb/CMakeFiles/tbb.dir/arena.cpp.o] Error 1; 1087.8 make[4]: *** [CMakeFiles/Makefile2:170: src/tbb/CMakeFiles/tbb.dir/all] Error 2; 1087.8 make[3]: *** [Makefile:156: all] Er",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/872:129,sandbox,sandbox,129,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/872,1,['sandbox'],['sandbox']
Testability,Is there any output to the terminal when salmon is running that would suggest it couldn't interpret the GTF properly? Can you share the salmon log file?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/569#issuecomment-709325079:143,log,log,143,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/569#issuecomment-709325079,1,['log'],['log']
Testability,"It appears that you're trying to index the entire mm9 genome using salmon. Both salmon and rapmap are designed to work with a smaller sequence space such as what you would find in a transcriptome. Your log file shows that salmon processes 615,000,000 bases from the genome and then aborts. Depending on how many transcripts are in your feature file, a human transcriptome [might be 5-10X smaller](http://seqanswers.com/forums/showthread.php?t=5298).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/49#issuecomment-197862096:202,log,log,202,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/49#issuecomment-197862096,1,['log'],['log']
Testability,It does seem that this option is implemented on the latest release (0.8.2). With single-end data with the --gcBias flag there is a warning about the implementation being experimental. Have you had a chance to test the results? Would be very interested to hear,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/83#issuecomment-320479168:209,test,test,209,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/83#issuecomment-320479168,1,['test'],['test']
Testability,"It looks like the first several runs crashed with:. ```; ...; [2016-12-18 12:10:47.956] [jointLog] [info] iteration = 519 | max rel diff. = 0.00832947; [2016-12-18 12:10:47.962] [jointLog] [info] Finished optimizer; [2016-12-18 12:10:47.962] [jointLog] [info] writing output. salmon: /usr/include/boost/random/gamma_distribution.hpp:117: boost::random::gamma_distribution<RealType>::gamma_distribution(const result_type&, const result_type&) [with RealType; = double; boost::random::gamma_distribution<RealType>::result_type = double]: Assertion `_alpha > result_type(0)' failed.; ```. And then a run finally hung with:. ```; [2016-12-18 13:31:06.283] [jointLog] [info] iteration = 517 | max rel diff. = 0.00871129; [2016-12-18 13:31:06.289] [jointLog] [info] Finished optimizer; [2016-12-18 13:31:06.289] [jointLog] [info] writing output. [2016-12-18 13:31:06.703] [jointLog] [info] Starting Gibbs Sampler; 0% [> ] ETA > 1 week; ```. Here's another batch of 100 backtraces: [salmon-gdb-bt.zip](https://github.com/COMBINE-lab/salmon/files/659757/salmon-gdb-bt.zip)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267855087:536,Assert,Assertion,536,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267855087,1,['Assert'],['Assertion']
Testability,"It must be a different `unitTest` executable that is running, since `make test` is just using CMake to run the same executable in `./src/unitTests`. I'm happy to help debug this further, but I'm currently most interested in how a transcript gets an infinite count after round 0.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393692302:74,test,test,74,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393692302,1,['test'],['test']
Testability,"It took ~1.5H for V1.2.1 with ```--hitFilterPolicy BOTH```. Attaching log and fastp report, which shows normal tetramer over-representation. By the insert size determined by fastp I suspect there's quite a bit of dovetailing, I did had extremely slow performance with dovetailed libraries (for example SRR7945268, which is insert size 100, and its a PE 150 [not my data]) even allowing dovetails, to the point I ended up mapping them as single end and not using one of the pairs. Even then it took its time. Edit: allowing dovetails only increased the mapping rate by 0.0277%. As an additional note, not ```--minAlnProb 0.1``` nor ```--hardFilter``` help. . [fastp.pdf](https://github.com/COMBINE-lab/salmon/files/4711278/fastp.pdf); [salmon_quant.log](https://github.com/COMBINE-lab/salmon/files/4711259/salmon_quant.log)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/527#issuecomment-636837126:70,log,log,70,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/527#issuecomment-636837126,3,['log'],['log']
Testability,"It's possible this is [related to the other issue](https://github.com/COMBINE-lab/salmon/issues/321), since I'm also seeing:. ```; 2018-11-28 18:01:19,745 i-05ef169a0611966c7 data_refinery_workers.processors.utils ERROR [pipeline_applied: SALMON] [failure_reason: Shell call to salmon failed because: ### salmon (; ### [ program ] => salmon; ### [ command ] => quant; ### [ libType ] => { A }; ### [ biasSpeedSamp ] => { 5 }; ### [ index ] => { /home/user/data_store/TRANSCRIPTOME_INDEX/HOMO_SAPIENS/long }; ### [ mates1 ] => { /home/user/data_store/processor_job_405995/SRR2963482_1.fastq }; ### [ mates2 ] => { /home/user/data_store/processor_job_405995/SRR2963482_2.fastq }; ### [ threads ] => { 16 }; ### [ output ] => { /home/user/data_store/processor_job_405995/SRR2963482_output/ }; ### [ seqBias ] => { }; ### [ gcBias ] => { }; ### [ dumpEq ] => { }; ### [ writeUnmappedNames ] => { }; Logs will be written to /home/user/data_store/processor_job_405995/SRR2963482_output/logs; [2018-11-28 18:01:15.711] [jointLog] [info] parsing read library format; [2018-11-28 18:01:15.711] [jointLog] [info] There is 1 library.; [2018-11-28 18:01:15.761] [stderrLog] [info] Loading Suffix Array; [2018-11-28 18:01:15.761] [jointLog] [info] Loading Quasi index; [2018-11-28 18:01:15.761] [jointLog] [info] Loading 32-bit quasi index; Exception : [Failed to read 1176099240 bytes from input stream! Read 872415224]; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/322#issuecomment-442548280:895,Log,Logs,895,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/322#issuecomment-442548280,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"Just a bit more information:. I installed through conda salmon=0.11.3 and executed command on two different fastq files. The first one was on a single lane of the data and the second was on a concatenated file across 4 lanes. I managed to run the single lane file but got a seg dump error for the ""big""er file. Both times it seems to output the correct files. . Single lane:; ```; salmon alevin -l ISR -1 hgmm_100_S1_L001_001.fastq.1.gz -2 hgmm_100_S1_L001_001.fastq.2.gz --chromium -i geneset.dir/geneset_coding_exons.salmon.index/ -o salmon.dir/ --tgMap transcript2geneMap.tsv --dumpCsvCounts; Version Info: ### PLEASE UPGRADE SALMON ###; ### A newer version of Salmon with important bug fixes and improvements is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; Logs will be written to salmon.dir/logs; ### alevin (dscRNA-seq quantification) v0.11.3; ### [ program ] => salmon ; ### [ command ] => alevin ; ### [ libType ] => { ISR }; ### [ mates1 ] => { hgmm_100_S1_L001_001.fastq.1.gz }; ### [ mates2 ] => { hgmm_100_S1_L001_001.fastq.2.gz }; ### [ chromium ] => { }; ### [ index ] => { geneset.dir/geneset_coding_exons.salmon.index/ }; ### [ output ] => { salmon.dir/ }; ### [ tgMap ] => { transcript2geneMap.tsv }; ### [ dumpCsvCounts ] => { }. [2019-01-29 09:54:57.898] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-01-29 09:54:57.916] [alevinLog] [info] Processing barcodes files (if Present) . ; processed 0 Million barcodes. [2019-01-29 09:54:59.693] [alevinLog] [info] Done barcode density calculation.; [2019-01-29 09:54:59.693] [alevinLog] [info] # Barcodes Used: 902561 / 912145.; [2019-01-29 09:55:04.490] [alevinLog] [info] Knee found left boundary at 391 ; [2019-01-29 09:55:04.817] [alevinLog] [info] Gauss Corrected Boundary at 99 ; [2019-01-29 09:55:04.81",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722:923,Log,Logs,923,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"Just wanted to put an opinion in. I am currently using Salmon v1.1.0 and noticed that `--posBias` wasn't listed in the help messages, but I found it in your read the docs. I tested it out and it made a significant improvement in my calculations. I know it is considered ""experimental"", but it helped in my research and will publish that I used it when we get the manuscript out. Also, do you think you could give a brief explanation on what `--forgettingFactor` is doing and how it could be affecting quantification calculations?",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/474:174,test,tested,174,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/474,1,['test'],['tested']
Testability,"LE1=$(awk 'BEGIN {FS=""\t""} {print $1}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); FILE2=$(awk 'BEGIN {FS=""\t""} {print $3}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); ID=$(cat /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk '{print $NF}' | awk ""NR==${SGE_TASK_ID}""). mkdir -p /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/Salmon_tx/${ID}. /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.7.2_linux_x86_64/bin/salmon quant 	-i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/GENCODE/GRCh38_hg38/transcripts/salmon_index_gencode.v25.transcripts -p 1 -l ISR 	-1 ${FILE1} -2 ${FILE2} 	-o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/Salmon_tx/${ID}. echo ""**** Job ends ****""; date; ```. The important part is that we are requesting 1 single core with 80 GB of free memory and setting the limit at 90 GB. We are also using the `-p 1` option. . Here is the log file for one of them (task 3):. ```; **** Job starts ****; Mon Mar 6 23:19:13 EST 2017; **** JHPCE info ****; User: lcollado; Job id: 9958683; Job name: step6-txQuant-alzheimer.gsk_phaseII; Hostname: compute-068; Task id: ; Version Info: ### A newer version of Salmon is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases ; contains new features, improvements, and minor bug fixes; please upgrade at your; earliest convenience.; ###; ### salmon (mapping-based) v0.7.2; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/GENCODE/GRCh38_hg38/transcripts/salmon_index_gencode.v25.transcripts }; ### [ threads ] => { 1 }; ### [ libType ] => { ISR }; ### [ mates1 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10003_D19KGACXX.fastq.gz }; ### [ mates2 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10003_D19KGACXX_read2.fastq.gz }; ### [ outpu",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126:2024,log,log,2024,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126,1,['log'],['log']
Testability,Make test failed,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/315:5,test,test,5,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/315,1,['test'],['test']
Testability,Make test fails on Ubuntu 16,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/250:5,test,test,5,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/250,1,['test'],['test']
Testability,"Mar 2 11:47 ..; drwxrwxr-x 2 amonaco_m hpc-ag-zinzen 4096 Mar 3 11:00 alevin; -rw------- 1 amonaco_m hpc-ag-zinzen 36540416 Mar 3 11:00 core.39485; -rw-rw-r-- 1 amonaco_m hpc-ag-zinzen 0 Mar 3 11:00 logs; (salmon) [amonaco_m@med0113 1_bootstrappedAlevin]$ ls -al alevin; total 1; drwxrwxr-x 2 amonaco_m hpc-ag-zinzen 4096 Mar 3 11:00 .; drwxrwxr-x 3 amonaco_m hpc-ag-zinzen 4096 Mar 3 11:00 ..; -rw-rw-r-- 1 amonaco_m hpc-ag-zinzen 0 Mar 3 11:00 alevin.log; ```. I have used Salmon Alevin before on this dataset - without the bootstrap option - while providing the Cell Ranger whitelisted barcodes, and everything has gone smoothly (same script as below, commented out line). I have tried increasing the allotted memory and thread number as well, but with no change in outcome. Have you ever encountered something like this or could address me to where the issue may be (I'm assuming something to do with the bootstrap)?. *****Script I submit:*****; ```; #!/bin/bash; # expected run time ; #SBATCH --time=24:00:00 ; # Combine stderr and stdout log files into the stdout log file.; #SBATCH -o without -e; # Keep current environment variables.; #SBATCH --export=variables; # number of cores; #SBATCH -n 30; # expected memory to be used; #SBATCH —mem=50000; # Specify queue via expected length of job. ; #SBATCH --partition=medium; # Set the log directory.; #SBATCH -o logs. ####declarations; conda activate salmon. Read1=$1 # fastq file - CB+UMI; Read2=$2 # fastq file - insert read; index=$3 # directory from salmon index; outDir=$4 # output directory; tsv=$5 # tsv containing txp-gene-id pairs; whitelist=$6 # cell ranger output barcodes. salmon alevin -lISR -1 $Read1 -2 $Read2 --chromiumV3 -i $index -p 8 -o $outDir --tgMap $tsv --whitelist $whitelist --numCellBootstraps 20 --dumpFeatures. #salmon alevin -lISR -1 $Read1 -2 $Read2 --chromiumV3 -i $index -p 8 -o $outDir --tgMap $tsv --whitelist $whitelist. ```. Thank you in advance!; Anna. -------------------------; Additional FYI:; ```; (salmon",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/636:1655,log,log,1655,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/636,2,['log'],['log']
Testability,May as well post `brew gist-logs salmon` for the record.; I'll build a precompiled binary bottle for salmon 0.7.2.; https://github.com/Linuxbrew/homebrew-science/pull/282,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/46#issuecomment-247475711:28,log,logs,28,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/46#issuecomment-247475711,1,['log'],['logs']
Testability,"My apologies for the late reply, somehow I missed the reply.; I am glad to hear that and thanks for testing alevin with BD Rhapsody.; Let us know if you need help with anything else, we'd be happy to help. Closing this issue but feel free to reopen.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/445#issuecomment-565298381:100,test,testing,100,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/445#issuecomment-565298381,1,['test'],['testing']
Testability,"My little testing: https://github.com/OceanGenomics/RegexBench. Some results on matching 1 million short strings with ~90% positive match and ~10% random strings:; ```; time-manual:	Elapsed (wall clock) time (h:mm:ss or m:ss): 0:00.06; time-boostregex:	Elapsed (wall clock) time (h:mm:ss or m:ss): 0:00.28; time-pcre2:	Elapsed (wall clock) time (h:mm:ss or m:ss): 0:00.23; time-retwo:	Elapsed (wall clock) time (h:mm:ss or m:ss): 0:00.63; time-boostxpressive:	Elapsed (wall clock) time (h:mm:ss or m:ss): 0:05.76; time-grep:	Elapsed (wall clock) time (h:mm:ss or m:ss): 0:00.17; ```. retwo is RE2. It is surprisingly highly affected by the number of captures. With 4 captures as above, it is the slowest. Without any it is as fast as grep. And xpressive is very slow, while I expected it to be the fastest!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1024181953:10,test,testing,10,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1024181953,1,['test'],['testing']
Testability,"NCODEv29/combined_index -l IU ; -1 /home/RnaSeq/fastq/DM_4a_H_1.fq.gz /home/RnaSeq/fastq/DM_4b_H_1.fq.gz /home/RnaSeq/fastq/DM_4c_H_1.fq.gz ; -2 /home/RnaSeq/fastq/DM_4a_H_2.fq.gz /home/RnaSeq/fastq/DM_4b_H_2.fq.gz /home/RnaSeq/fastq/DM_4c_H_2.fq.gz ; -o /home/RnaSeq/salmon_output_files/out/DM4h; Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /home/RnaSeq/transcriptome_gencode_v29/human_GENCODEv29/combined_index }; ### [ libType ] => { IU }; ### [ mates1 ] => { /home/RnaSeq/fastq/DM_4a_H_1.fq.gz /home/RnaSeq/fastq/DM_4b_H_1.fq.gz /home/RnaSeq/fastq/DM_4c_H_1.fq.gz }; ### [ mates2 ] => { /home/RnaSeq/fastq/DM_4a_H_2.fq.gz /home/RnaSeq/fastq/DM_4b_H_2.fq.gz /home/RnaSeq/fastq/DM_4c_H_2.fq.gz }; ### [ validateMappings ] => { }; ### [ output ] => { /home/RnaSeq/salmon_output_files/out/DM4h }; Logs will be written to /home/RnaSeq/salmon_output_files/out/DM4h/logs; [2019-07-01 12:51:42.856] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-07-01 12:51:42.856] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2019-07-01 12:51:42.856] [jointLog] [info] Usage of --validateMappings, without --hardFilter implies use of range factorization. rangeFactorizationBins is being set to 4; [2019-07-01 12:51:42.856] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.2.; [2019-07-01 12:51:42.856] [jointLog] [info] parsing read library format; [2019-07-01 12:51:42.856] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file /home/RnaSeq/transcriptome_gencode_v29/human_GENCODEv29/combined_index/versionInfo.json doesn't seem to exist. Please try re-buil",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/389#issuecomment-507253562:2945,Log,Logs,2945,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/389#issuecomment-507253562,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"No additional ideas from me. I didn't cover single-end when coding up alpine, but I would go about it just as you describe. re: ""under the naive implementation in the single-end case"", I guess the _super-naive_ implementation is to just use the FLD mean to compute the observed GC model (ignore the distribution for this estimation task). It might get close enough. I guess one could test by comparing the GC bias estimates from running paired with read 1 & 2 vs running single end with just 1 or 2.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/83#issuecomment-243845991:384,test,test,384,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/83#issuecomment-243845991,1,['test'],['test']
Testability,"No, that shouldn't cause a problem. When I ran your command (including the `ISF` and placing the `--libType` after the set of reads), my run still completed successfully (and didn't produce any warnings during Gibbs sampling). Salmon's behavior when running in unstranded mode on stranded data is simply to map the reads in the orientation they match, and to report on the console (and in the log) that there was a mapping bias (i.e. that the data look stranded). Specifically, here is what I get when I run (a close approximation of) your command. ```; $salmon quant --index Salmon_index_hg38.analysisSet_knownGene --unmatedReads SRR2454059.fq.gz --libType ISF --useVBOpt --output test_quant --; numGibbsSamples 100 --threads 16; Version Info: This is the most recent **development version** of Salmon.; ### salmon (mapping-based) v0.7.3; ### [ program ] => salmon; ### [ command ] => quant; ### [ index ] => { Salmon_index_hg38.analysisSet_knownGene }; ### [ unmatedReads ] => { SRR2454059.fq.gz }; ### [ libType ] => { ISF }; ### [ useVBOpt ] => { }; ### [ output ] => { test_quant }; ### [ numGibbsSamples ] => { 100 }; ### [ threads ] => { 16 }; Logs will be written to test_quant/logs; [2016-12-13 22:38:54.413] [jointLog] [info] parsing read library format; [2016-12-13 22:38:54.413] [jointLog] [info] There is 1 library.; [2016-12-13 22:38:56.240] [stderrLog] [info] Loading Suffix Array; [2016-12-13 22:38:56.240] [jointLog] [info] Loading Quasi index; [2016-12-13 22:38:56.240] [jointLog] [info] Loading 32-bit quasi index; [2016-12-13 22:39:01.268] [stderrLog] [info] Loading Transcript Info; [2016-12-13 22:39:02.630] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-12-13 22:39:03.041] [stderrLog] [info] There were 182608 set bits in the bit array; [2016-12-13 22:39:03.159] [stderrLog] [info] Computing transcript lengths; [2016-12-13 22:39:03.160] [stderrLog] [info] Waiting to finish loading hash; [2016-12-13 22:39:07.653] [stderrLog] [info] Done loading index; [2016-12-13 22",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266934878:393,log,log,393,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266934878,2,['log'],['log']
Testability,"Nominally, you can use `info locals` and `p x` (where x is a specific variable name) to look at the value of variables in the stack. However, without debug flags, the ability to peek at such values is questionable. Alternatively we could log the values that gamma is being called with before each call . . . but that's going to lead to some crazy logs until the hang occurs.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267842038:238,log,log,238,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267842038,2,['log'],"['log', 'logs']"
Testability,"OK --- very strange. I've been testing it out on different data and have been unable to reproduce the segfault. I'll try on your dataset when it's ready to see if the problem pops up. I actually hope it does, because it will be a very tricky bug to fix if it only happens on certain hosts!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168424793:31,test,testing,31,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168424793,1,['test'],['testing']
Testability,"OK, could you send me a private e-mail address so I don't post links for; the data publicly?. On Wed, Mar 30, 2016 at 3:42 PM, Rob Patro notifications@github.com wrote:. > Hi Josh,; > ; > My best guess is that something is awry with the 64-bit index. That; > code-path is less well-tested (since I don't really have any transcriptomes; > in my collection that exceed the size of a 32-bit signed int). If you're; > able to share the txome and / or the index itself, I'd be happy to try and; > reproduce and fix this. Actually, I'd be really happy to squash any bugs in; > the 64-bit code path.; > ; > --Rob; > ; > —; > You are receiving this because you authored the thread.; > Reply to this email directly or view it on GitHub; > https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-203627077",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-203633436:282,test,tested,282,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-203633436,1,['test'],['tested']
Testability,"OK, so it seems like adding the UMI <-> eq class counting should be pretty straightforward. @vals, so when you say effective length should be kept constant, you mean we shouldn't adjust for bias, or that we don't expect a transcript length effect at all? Also, is there a basic primer I can read up on regarding the details of the data format (e.g. where in each read I should look for the tag, how long the tag is expected to be, etc.)? I'll be relying on you guys to test stuff out and point me at relevant data sets as I go forward with implementing this.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/108#issuecomment-269069945:469,test,test,469,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/108#issuecomment-269069945,1,['test'],['test']
Testability,"OS: ubuntu 16.04; Salmon was installed using conda. Version Info: This is the most recent version of Salmon.; ### salmon (mapping-based) v0.10.2; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /work/yu_liu/resource/salmon_gencodev28_index/ }; ### [ libType ] => { U }; ### [ unmatedReads ] => { /work/yu_liu/NEPC_david/data_source/Output.Fastqs/HS_1-1_S1_R1_001.fastq.gz }; ### [ threads ] => { 8 }; ### [ output ] => { /scratch/yu_liu/HS_1-1_quant }; Logs will be written to /scratch/yu_liu/HS_1-1_quant/logs; [2018-07-13 20:04:48.086] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2018-07-13 20:04:48.086] [jointLog] [info] parsing read library format; [2018-07-13 20:04:48.086] [jointLog] [info] There is 1 library.; Exception : [rapidjson internal assertion failure: IsObject()]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/251:479,Log,Logs,479,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/251,3,"['Log', 'assert', 'log']","['Logs', 'assertion', 'logs']"
Testability,Oh Sorry about that what I meant was the salmon.log file or the the meta-info.json file created by salmon in the output directory. You can check what files salmon is detecting it seems there are 12 files in the mate1 and 13 files in the mate2. Can you confirm there are 13 pairs of file in that directory and their regex is same as you are using ? Can you also try putting the names of the file instead `*` as regex ?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408#issuecomment-516195181:48,log,log,48,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408#issuecomment-516195181,1,['log'],['log']
Testability,"Oh one more thing, is it possible to share a few hundred reads for your experiment, just for some unit testing on my side?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638388616:103,test,testing,103,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638388616,1,['test'],['testing']
Testability,"Oh wow 14k v 126k is indeed a big difference, is it possible to share the Alevin log for your run ? From the logs you attached it's not clear what's the mapping rate. May I also ask to look at another log file inside the logs folder, called salmon_quant.log. that would have more information regarding the mapping rate.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639161938:81,log,log,81,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639161938,10,['log'],"['log', 'logs']"
Testability,"Oh, so multiple things can go wrong based on how you sampled the read like CB frequency not being aligning with the expected experiment. I'd say if you have to try a small experiment, may be sample all the reads from say ~10 Cellular barcode and specify them to alevin using `--whitelist` flag. I just tested the data it seems to work with the following log.; ```; [2021-04-16 15:57:26.183] [jointLog] [info] Mapping rate = 48.8769%. [2021-04-16 15:57:26.183] [jointLog] [info] finished quantifyLibrary(); [2021-04-16 15:57:26.360] [alevinLog] [info] Starting optimizer; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/647#issuecomment-821529523:302,test,tested,302,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/647#issuecomment-821529523,2,"['log', 'test']","['log', 'tested']"
Testability,"Ok ... so, now it's hanging in single-threaded code, and it does so in a call to std::gamma_distribution. I'm running out of logical possibilities here. Either (1) undefined behavior somewhere else is affecting the hanging here or (2) `std::gamma_distribution` is in an infinite loop. I'll note that `gamma_distribution` does contain a while loop, but I'd be immensely surprised if the standard libraries distribution sampler had an undiscovered infinite loop.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267840129:125,log,logical,125,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267840129,1,['log'],['logical']
Testability,"Ok @DarwinAwardWinner, I think it's fixed for real this time. The issue was stemming from an uninitialized prior value in the Gibbs sampler under VBOpt mode (the initialization code was updated on the develop branch, which is where the bug was introduced). This, in turn, was leading to `nan` being passed as the alpha parameter of `std::gamma_distribution`. With the `-Ofast` optimization flags, at least, this leads `std::gamma_distribution()` to hang forever in an infinite loop. Clearly, `nan` should not be passed to `std::gamma_distribution()`, but I'd argue the behavior of looping forever here is not great. Anyway, I fixed the initialization bug, so that this nan should never pop up. Just to be safe, I also changed the default optimization flag to `-O3` so that at least `nan` and `inf` can be properly tested. Since the TBB code and the parallel sampling weren't causing the issue, I've added them back in. Could you please test the latest push (40584e62859fb65463188b50d132c1eb622b21f0) and verify that this resolves the issue for you (*hopefully*!)?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267877253:814,test,tested,814,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267877253,2,['test'],"['test', 'tested']"
Testability,"Ok, I have an strace file from a hung run. I couldn't attach with gdb because the default system security settings prohibit it. I'll change the settings and try to get a gdb backtrace, but in the meantime, here's the strace log. Note that it was hung for about 2 hours before I was able to collect the log. https://www.dropbox.com/s/zn7qzo55wtcrbyg/salmon-strace.log.gz?dl=0",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267413760:224,log,log,224,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267413760,3,['log'],['log']
Testability,"Ok, I realized that the Segmentation fault was not caused by passing multiple bam files, but by including either the `--seqBias` or `--gcBias` arguments. . The following command generates the segmentation fault:. ```; salmon quant -t transcripts.fasta -g gene_annotations.gtf -l IU -p 8 -o quantitation -a Aligned.toTranscriptome.bam --seqBias --gcBias; ```. and returns the following output before exiting:. ```; # salmon (alignment-based) v0.7.2; # [ program ] => salmon; # [ command ] => quant; # [ targets ] => { transcripts.fasta }; # [ geneMap ] => { gene_annotations.gtf }; # [ libType ] => { IU }; # [ threads ] => { 8 }; # [ output ] => { quantitation }; # [ alignments ] => {Aligned.toTranscriptome.bam }; # [ seqBias ] => { }; # [ gcBias ] => { }; Library format { type:paired end, relative orientation:inward, strandedness:unstranded }; Logs will be written to quantitation/logs; numQuantThreads = 4; parseThreads = 4; Checking that provided alignment files have consistent headers . . . done; Populating targets from aln = ""Aligned.toTranscriptome.bam"", fasta = ""transcripts.fasta"" . . .WARNING: Transcript ENSMUST00000185127 appears in the reference but did not appear in the BAM; WARNING: Transcript ENSMUST00000180893 appears in the reference but did not appear in the BAM; WARNING: Transcript ENSMUST00000206884 appears in the reference but did not appear in the BAM; WARNING: Transcript ENSMUST00000181916 appears in the reference but did not appear in the BAM; WARNING: Transcript ENSMUST00000202657 appears in the reference but did not appear in the BAM; [truncated]. replaced 3 non-ACGT nucleotides with random nucleotides; done. processed 0 reads in current round; ```. follow by the segmentation fold. The same command without the `--seqBias --gcBias` arguments succeeds. Perhas bias correction is not supported (or even necessary) when quantifying from a bam file?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/104#issuecomment-261738122:849,Log,Logs,849,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/104#issuecomment-261738122,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"Ok, I'll give it a try with the --expectCells flag. I'm working on implementing Salmon and Alevin (along with support for full and partial decoy indexing and preprocessing to add intron flanking sequences for velocity) in GenePattern so I needed to test that flag anyway.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/625#issuecomment-776212333:249,test,test,249,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/625#issuecomment-776212333,1,['test'],['test']
Testability,"Ok, I'm tagging @k3yavi since I believe he tested the hot fix with the data you shared. Hey may have some more insight on what's going on here. By the way, the command you quote above still contains the `--citeseq` flag, but I assume that's just a typo.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/670#issuecomment-860925409:43,test,tested,43,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/670#issuecomment-860925409,1,['test'],['tested']
Testability,"Ok, new plan:. ```sh; while true; do; strace -s 99 -f -o salmon-strace.log \; salmon quant \; --index /home/ryan/references/hg38/Salmon_index_$REF \; --libType SR --unmatedReads fastq_files/$SAMPLE.fq.gz\; --threads 8 --seqBias --gcBias --useVBOpt --dumpEq --dumpEqWeights \; --geneMap /home/ryan/references/hg38/Salmon_index_$REF/genemap.txt \; --output salmon_temp/REF/$SAMPLE \; --auxDir aux_info \; --numGibbsSamples 100; done; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267357651:71,log,log,71,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267357651,1,['log'],['log']
Testability,"Ok, pushed to [bioconda](https://github.com/bioconda/bioconda-recipes/pull/17922/checks?check_run_id=248588035), should be available in a couple of hours. Once it's available I'll make the official release too on the github. It'd be great if you can quickly test the new release for the bug once it's available. Thanks again !",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/431#issuecomment-538581395:258,test,test,258,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/431#issuecomment-538581395,1,['test'],['test']
Testability,"Ok, salmon V1.0.0 finished in 5H 15 min, so about 5 times faster, the exact same library and parameters, and achieved almost the same mapping rate (85.1058% with V1.2.0 vs 84.6341% with V1.0.0) attaching log. I must add I did not trim this library for adapters nor quality, nor did anything to it. Just mapped as is. But fastQC showed excellent levels of quality even at the ends and no or minimal adapter content. ; Also no changes have been done one my OS other than regular updates, but still Ubuntu 18.04. I don't remember any specific changes I've done to it. ; Pearson's correlation in transcript abundance (isoform lelvel) is 0.9984013. Spearman's is 0.9899048. ; Also, I did checked that salmon was actually using 4 threads in both cases, and it was fully using those.; [salmon_quant.log](https://github.com/COMBINE-lab/salmon/files/4707443/salmon_quant.log)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/527#issuecomment-636447127:204,log,log,204,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/527#issuecomment-636447127,3,['log'],['log']
Testability,"Ok, the assertion is useful. That argument shouldn't be 0. But it's also the case that if Boost validates the arguments appropriately, it shouldn't *hang*.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267856046:8,assert,assertion,8,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267856046,1,['assert'],['assertion']
Testability,"Ok, when I attempt the build the way you say above, I get the following error during CMake:. ```; -- fetch PUFFERFISH exit code 127; CMake Error at CMakeLists.txt:317 (message):; Could not fetch pufferfish source [fetchPufferfish.sh returned exit code; 127]. -- Configuring incomplete, errors occurred!; See also ""/salmon-1.10.0/build/CMakeFiles/CMakeOutput.log"".; ```. It seems `wget`, `curl` and `unzip` were missing, and I had to install them. After that, I was able to build and install. At that point, I was able to reproduce the issue! So, it seems to me the underlying problem is coming from one of the upstream dependencies (i.e. libraries being linked to). I will try see if I can find the offender. In general, we like to statically link salmon for exactly this reason. Outside of package systems with which I am familiar (e.g. conda), we don't have a lot of experience in specifying dependent package version constrains, which I believe to be at fault here.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463973824:358,log,log,358,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463973824,1,['log'],['log']
Testability,Ok; that is _super_ strange since (obviously) it cannot both complete successfully and throw an exception. It looks like the log points to a sample that completed successfully at `19:45:18.487` before the sample at the top of the post started `19:51:56.392`. Is this the quant directory for the same sample?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/512#issuecomment-618029055:125,log,log,125,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/512#issuecomment-618029055,1,['log'],['log']
Testability,"Oki, so I have updated a couple of things in the latest commit on the develop branch, which should make the things more streamlined. . * `maxNumBarcodes`: As you have initially used `maxNumBarcodes` which is by default set to 100k it means. by default alevin quantifies 100k CBs which includes both the low and high confidence CB count. You can change this number accordingly to set the universe of the top CB to quantify.; * `KeepCBFraction` : It defines what fraction of `maxNumBarcodes` to be used as the high confidence barcodes and should definitely generate the quants for. If set to 1 then everything is high confidence and the whitelisting cannot be performed. Thanks to this issue, alevin will not fail without error when there is no low confidence CB is found instead it checks if the number of low confidence CB is less than `lowRegionMinBarcodes` (default to 200), alevin will warn and not perform the whitelisting.; * `freqThreshold`: This is used to filter out most obvious cases to filter out CB with frequency less than set by the parameter (default to 10). Hope this help ! I am also testing on my end for any other potential bug. Please let me know if you get a chance to check the develop branch .",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/379#issuecomment-503396823:1101,test,testing,1101,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/379#issuecomment-503396823,1,['test'],['testing']
Testability,"Our lab makes heavy use of Salmon. Its a great tool we use it almost daily. **Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**; Salmon. **Describe the bug**; While digging through the log files to try and figure out why some of our biologic samples have low mapping rates I discovered a warning. . [2021-06-22 12:39:41.282] [jointLog] [warning] Only 1920342 fragments were mapped, but the number of burn-in fragments was set to 5000000.; The effective lengths have been computed using the observed mappings. [2021-06-22 12:39:41.282] [jointLog] [info] Mapping rate = 55.5444%. about half of our samples have over 90% mapping rates. . Any idea what this warning means?. **To Reproduce**; Steps and data to reproduce the behavior:. salmon 1.4.0 ; Linux mustard 3.10.0-862.6.3.el7.x86_64 #1 SMP Tue Jun 26 16:32:21 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux. $ cat /etc/redhat-release; CentOS Linux release 7.5.1804 (Core) . I think when I installed salmon I could not install the 1.5.x version. I forgot why; ```; function runSalmon() {; # runs salmon on one sample and outputs to that directory ; salmonIndexDir=""$1""; rightReads=""$2""; leftReads=""$3""; outputDir=""$4"". #set -x # turn debug on ; # set +x # turn debug off . if [[ ! -f ""$outputDir""/quant.sf ]]; then. 	mkdir -p ""$outputDir"". # printf ""##############\n"" ; # printf ""warning --minAssignedFrags is set to $minNumFrags to enable test data set\n"" ; # minNumFrags=1 ; # --minAssignedFrags=$minNumFrags \ ; # printf ""##############\n"" . #if [[ -f ""$inputDir""/output_single_end.fq.gz ]]; then . numThr=12; salmon quant \; -i $salmonIndexDir \; --libType A \; -1 ""${rightReads}"" \; -2 ""${leftReads}"" \; -p $numThr \; --recoverOrphans \; --validateMappings \; --gcBias \; --seqBias \; --rangeFactorizationBins 4 \; --writeUnmappedNames \; --output ${outputDir}. salmonRet=$?; if [ $salmonRet -ne 0 ]; then; echo ERROR salmon ""$rightReads"" returned exit status ""$exitStatus""; continue; fi. #fi ; else; echo ""[INFO] skip",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/677:218,log,log,218,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/677,1,['log'],['log']
Testability,"PCE info ****; User: lcollado; Job id: 9987275; Job name: step6-salmon_test.gsk_phaseII; Hostname: compute-051; Task id:; Version Info: ### A newer version of Salmon is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and minor bug fixes; please upgrade at your; earliest convenience.; ###; ### salmon (mapping-based) v0.7.2; ### [ program ] => salmon; ### [ command ] => quant; ### [ index ] => { /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/GENCODE/GRCh38_hg38/transcripts/salmon_index_gencode.v25.transcripts }; ### [ threads ] => { 1 }; ### [ libType ] => { ISR }; ### [ mates1 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10003_D19KGACXX.fastq.gz }; ### [ mates2 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10003_D19KGACXX_read2.fastq.gz }; ### [ output ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test/R10003_D19KGACXX }; Logs will be written to /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test/R10003_D19KGACXX/logs; [2017-03-08 11:37:32.888] [jointLog] [info] parsing read library format; [2017-03-08 11:37:32.893] [jointLog] [info] There is 1 library.; terminate called without an active exception; /cm/local/apps/sge/var/spool/compute-051/job_scripts/9987275: line 31: 41232 Aborted (core dumped) /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Softw; are/Salmon-0.7.2_linux_x86_64/bin/salmon quant -i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/GENCODE/GRCh38_hg38/transcripts/salmon_index_gencode.v25.tr; anscripts -p 1 -l ISR -1 ${FILE1} -2 ${FILE2} -o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test/${ID}; **** Job ends ****; Wed Mar 8 11:37:36 EST 2017; ```. and the core dump file shows that the program was terminated:. ```bash; $ gdb core.41232; GNU gdb (GDB) Red Hat Enterprise Linux (7.2-60.el6_4.1); Copyright (C) 2010 Free Software Foundation, Inc.; License GPLv3+: GNU GPL version 3 or later",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126:23615,Log,Logs,23615,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"RIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = -1 ENOMEM (Cannot allocate memory); futex(0x7fffbf4c3350, FUTEX_WAKE_PRIVATE, 2147483647) = 0; write(2, ""terminate called without an acti""..., 45terminate called without an active exception; ) = 45; rt_sigprocmask(SIG_UNBLOCK, [ABRT], NULL, 8) = 0; write(3, ""[2017-04-05 16:24:38.504] [joint""..., 136) = 136; tgkill(10693, 10693, SIGABRT) = 0; --- SIGABRT (Aborted) @ 0 (0) ---; +++ killed by SIGABRT (core dumped) +++; ```. (371 lines for task 1, 368 for task 2). Basically, both fail at a point where `mmap()` cannot allocate memory. So it definitely looks like a memory issue and I don't know if these information gives you any hints. . ## Bumping memory. Bumping the memory request to 28/30GB. This is a scenario where task 2 seems to work ok but tasks 1 and 3 fail. ```bash; #!/bin/bash; #$ -cwd; #$ -pe local 2; #$ -l mem_free=14G,h_vmem=15G,h_fsize=100G; #$ -N step6-salmon_test12.gsk_phaseII; #$ -o ./logs/salmon_test12.$TASK_ID.txt; #$ -e ./logs/salmon_test12.$TASK_ID.txt; #$ -t 1-3; #$ -hold_jid pipeline_setup,step4-featCounts-alzheimer.gsk_phaseII; #$ -m e; echo ""**** Job starts ****""; date. echo ""**** JHPCE info ****""; echo ""User: ${USER}""; echo ""Job id: ${JOB_ID}""; echo ""Job name: ${JOB_NAME}""; echo ""Hostname: ${HOSTNAME}""; echo ""Task id: ${TASK_ID}"". FILE1=$(awk 'BEGIN {FS=""\t""} {print $1}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); if [ TRUE == ""TRUE"" ] ; then; FILE2=$(awk 'BEGIN {FS=""\t""} {print $3}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); fi; ID=$(cat /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk '{print $NF}' | awk ""NR==${SGE_TASK_ID}""). mkdir -p /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/${ID}. strace /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant 	-i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:77886,log,logs,77886,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['log'],['logs']
Testability,"RP057125_SRS936134_2.fastq \; > -o SRP057125_SRS936134_salmon_out \; > -g /nfs/research2/teichmann/reference/mus-musculus/salmon/mouse_cdna38.78_repbase_ercc_index_gene_map.txt \; > --biasCorrect \; > --useFSPD; Version Info: This is the most recent version of Salmon.; # salmon (mapping-based) v0.6.0; # [ program ] => salmon; # [ command ] => quant; # [ index ] => { /nfs/research2/teichmann/reference/mus-musculus/salmon/quasi/mouse_cdna_38.p3.78_repbase_ercc.fa }; # [ libType ] => { IU }; # [ mates1 ] => { /nfs/research2/teichmann/valentine/detection-comparison/salmon0.4.2-comparison/mouse/SRP057125_SRS936134_1.fastq }; # [ mates2 ] => { /nfs/research2/teichmann/valentine/detection-comparison/salmon0.4.2-comparison/mouse/SRP057125_SRS936134_2.fastq }; # [ output ] => { SRP057125_SRS936134_salmon_out }; # [ geneMap ] => { /nfs/research2/teichmann/reference/mus-musculus/salmon/mouse_cdna38.78_repbase_ercc_index_gene_map.txt }; # [ biasCorrect ] => { }; # [ useFSPD ] => { }; Logs will be written to SRP057125_SRS936134_salmon_out/logs; [2016-01-02 20:22:59.800] [jointLog] [info] parsing read library format; there is 1 lib; Loading 32-bit quasi index[2016-01-02 20:23:00.830] [stderrLog] [info] Loading Suffix Array; [2016-01-02 20:23:00.830] [stderrLog] [info] Loading Position Hash; [2016-01-02 20:23:00.829] [jointLog] [info] Loading Quasi index; [2016-01-02 20:23:03.751] [stderrLog] [info] Loading Transcript Info; [2016-01-02 20:23:04.776] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-01-02 20:23:05.009] [stderrLog] [info] There were 104534 set bits in the bit array; [2016-01-02 20:23:05.325] [stderrLog] [info] Computing transcript lengths; [2016-01-02 20:23:05.325] [stderrLog] [info] Waiting to finish loading hash; Index contained 104534 targets; [2016-01-02 20:23:16.571] [stderrLog] [info] Done loading index; [2016-01-02 20:23:16.571] [jointLog] [info] done. processed 12000001 fragments; hits: 24367128, hits per frag: 2.04044. [2016-01-02 20:23:49.850] [jointL",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741:7454,Log,Logs,7454,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168426741,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"Ran with only --validateMappings and -p 4 options. Wow, it took less than 15 minutes! Thanks a lot to you and your team for looking into this.; Best,; Jose; [salmon_quant.log](https://github.com/COMBINE-lab/salmon/files/4717767/salmon_quant.log)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/527#issuecomment-637581730:171,log,log,171,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/527#issuecomment-637581730,2,['log'],['log']
Testability,RapidJSON Logs Error,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/322:10,Log,Logs,10,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/322,1,['Log'],['Logs']
Testability,Realized I haven't run the gene quantification yet and its looking for quant.genes.sf not quant.sf like the log says?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/662#issuecomment-845350603:108,log,log,108,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/662#issuecomment-845350603,1,['log'],['log']
Testability,"Right --- such classes should be removed (specifically because they can cause such underflow issues). I suspect that I just need to make the bound for evaluation more conservative. I chose the smallest value that worked on my testing machine, but I imagine that when underflow occurs could be slightly different on different machines. I should just find / choose a stricter bound.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393580320:226,test,testing,226,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393580320,1,['test'],['testing']
Testability,"Right, that might explain it. So first of all I indeed used the `--dumpFeature` option to get the `MappedUMI.txt`, sorry for that. I will check the file once again and rerun the analysis, which I did on my machine at home. It might be that the 17M I told from the top of my head is actually incorrect. Unfortunately, the 10x crashes with a memory error on our clusters (I tested 2 different machines), for which I will open a separate thread (I think I saw someone else reporting a similar issue; will look that up). Celseq2 runs fine. I will check the analysis and the `mappedUMI.txt` a.s.a.p. I fear this issue will soon be resolved where both of us have a memory problem to deal with ;-). Cheers,; Wout",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/361#issuecomment-490115088:372,test,tested,372,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/361#issuecomment-490115088,1,['test'],['tested']
Testability,"Rob,. Thanks for the --no-version-check option, I did not see it. regarding issue (2). I have been able to process these files without any problem with other; tools.; I have the same problem with the 10x pbmc4k fastq files:. salmon --no-version-check alevin -p 10 -lISR -1; /path/to/downloads/10xPBMC/pbmc4k_S1_L001_R1_001.fastq.gz -2; /path/to/downloads/10xPBMC/pbmc4k_S1_L001_R2_001.fastq.gz -i; /path/to/salmonIndex -o alevin_output --tgMap tx2gene.tsv; Logs will be written to alevin_output/logs; ### salmon (single-cell-based) v0.11.1; ### [ program ] => salmon; ### [ command ] => alevin; ### [ threads ] => { 10 }; ### [ libType ] => { ISR }; ### [ mates1 ] => {; /path/to/downloads/10xPBMC/pbmc4k_S1_L001_R1_001.fastq.gz }; ### [ mates2 ] => {; /path/to/downloads/10xPBMC/pbmc4k_S1_L001_R2_001.fastq.gz }; ### [ index ] => { /path/to/salmonIndex }; ### [ output ] => { alevin_output }; ### [ tgMap ] => { tx2gene.tsv }. [2018-08-03 19:20:57.848] [jointLog] [info] Fragment incompatibility; prior below threshold. Incompatible fragments will be ignored.; [2018-08-03 19:20:57.867] [alevinLog] [info] Processing barcodes files; (if Present). processed 189 Million barcodes. Segmentation error (core dumped). Avi,. You are right, I did miss the --chromium option. However, I just tried; again with the above command with --chromium and I still get the; segmentation error.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/264#issuecomment-410325090:457,Log,Logs,457,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/264#issuecomment-410325090,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"Running Salmon-0.7.2_linux_x86_64 with --writeMappings=map.out and it crashes with:. Exception : [boost::filesystem::create_directory: No such file or directory]. When I run without a file name, it outputs to stdout, but it also outputs messages such as:; ESC[1m[2016-09-14 11:06:07.550] [jointLog] [info] parsing read library format; ESC[00mESC[1m[2016-09-14 11:06:07.550] [jointLog] [info] There is 1 library.; ESC[00mESC[1m[2016-09-14 11:06:08.300] [jointLog] [info] Loading Quasi index; ESC[00mESC[1m[2016-09-14 11:06:08.300] [jointLog] [info] Loading 32-bit quasi index; So the output is not a clean .sam file. ~/programs/Salmon-0.7.2_linux_x86_64/bin/salmon quant -i /data/reference/salmon/gencode.grch37.v19/ -r test.fastq --seqBias --gcBias --posBias -p 12 --writeMappings=map.out --geneMap /data/reference/salmon/gencode.grch37.v19/geneMap.txt --libType U -o x",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/90:719,test,test,719,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/90,1,['test'],['test']
Testability,"Salmon 0.9.1. ```; 2018-11-28 17:07:26,833 i-0656458112d739fa6 data_refinery_workers.processors.utils ERROR [failure_reason: Shell call to salmon failed because: ### salmon (mapping-based) v0.9.1; ### [ program ] => salmon; ### [ command ] => quant; ### [ libType ] => { A }; ### [ biasSpeedSamp ] => { 5 }; ### [ index ] => { /home/user/data_store/TRANSCRIPTOME_INDEX/HOMO_SAPIENS/long }; ### [ mates1 ] => { /home/user/data_store/processor_job_408895/SRR4051017_1.fastq }; ### [ mates2 ] => { /home/user/data_store/processor_job_408895/SRR4051017_2.fastq }; ### [ threads ] => { 16 }; ### [ output ] => { /home/user/data_store/processor_job_408895/SRR4051017_output/ }; ### [ seqBias ] => { }; ### [ gcBias ] => { }; ### [ dumpEq ] => { }; ### [ writeUnmappedNames ] => { }; Logs will be written to /home/user/data_store/processor_job_408895/SRR4051017_output/logs; Exception : [rapidjson internal assertion failure: IsObject()]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting.; ```. Is this a ""working"" sample that just fails because of a problem with the logger?",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/322:777,Log,Logs,777,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/322,4,"['Log', 'assert', 'log']","['Logs', 'assertion', 'logger', 'logs']"
Testability,"Salmon version: 0.13.1 (installed via pre-compiled binary). I used salmon to quantify some samples and wanted to use the `quantmerge` command to produce a combined table. However, the merged table I got as output only contained 17 lines (of 52228 in the quant.genes.sf files). I was able to identify that the problem was related somehow to the ""Name"" column itself, although I didn't find any obvious pattern for failure. For example, if I rename all the genes to simply ""1"", ""2"", ... and then `quantmerge`, I get a properly combined table with all samples/genes. Looking back at the ""original"" data with the gene names, I find that the truncated merged table consistently/always truncates immediately *after* processing some gene names. For example, the 16th gene name in my ""quant.genes.sf"" table happens to be ""Erdr1"". If this line is moved to the top of that file, then the merged table will truncate at 2 (the header counting for one of those, obviously). Unfortunately, it's not just ""Erdr1"". If that line is moved to the end of the file, or deleted entirely, there is another failure at gene ""Gm28674"", which happens to be the 19th gene. And so on for a very large number of names (I gave up after removing ~30 one at a time). I've now tested with a few different samples and with a number of randomly selected subsets of the original quant files and the behavior is consistent. I can't figure out what the pattern is, but ""Erdr1"", ""Gm28674"", and all the other genes I discovered with my ad-hoc process above, always cause `quantmerge` to truncate the output.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/356:1243,test,tested,1243,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/356,1,['test'],['tested']
Testability,Salmon: rapidjson internal assertion failure: IsObject(),MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/862:27,assert,assertion,27,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/862,1,['assert'],['assertion']
Testability,"Seeing lots of these - any ideas? v0.9.1. ```; ERROR [processor_job: 399381] [pipeline_applied: SALMON] [no_retry: False] [failure_reason: Shell call to salmon failed because: ### salmon (; ### [ program ] => salmon; ### [ command ] => quant; ### [ libType ] => { A }; ### [ biasSpeedSamp ] => { 5 }; ### [ index ] => { /home/user/data_store/TRANSCRIPTOME_INDEX/MUS_MUSCULUS/short }; ### [ mates1 ] => { /home/user/data_store/processor_job_399381/ERR1680104_1.fastq }; ### [ mates2 ] => { /home/user/data_store/processor_job_399381/ERR1680104_2.fastq }; ### [ threads ] => { 16 }; ### [ output ] => { /home/user/data_store/processor_job_399381/ERR1680104_output/ }; ### [ seqBias ] => { }; ### [ gcBias ] => { }; ### [ dumpEq ] => { }; ### [ writeUnmappedNames ] => { }; Logs will be written to /home/user/data_store/processor_job_399381/ERR1680104_output/logs; [2018-11-28 17:08:09.121] [jointLog] [info] parsing read library format; [2018-11-28 17:08:09.121] [jointLog] [info] There is 1 library.; [2018-11-28 17:08:09.165] [stderrLog] [info] Loading Suffix Array; [2018-11-28 17:08:09.165] [jointLog] [info] Loading Quasi index; [2018-11-28 17:08:09.165] [jointLog] [info] Loading 32-bit quasi index; Exception : [Failed to read 879238456 bytes from input stream! Read 851443704]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting.]: Processor job failed!; ```",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/321:771,Log,Logs,771,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/321,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"Seems to work on some of the test at my end, let me know if its still a problem. The command to use would be; ```; salmon alevin -l ISR --citeseq --barcodeLength 16 --umiLength 10 --end 5 --featureStart 19 --featureLength 21; ```. One thing to note, since it's a 5' protocol, you might have to change `-lISR` to `-lISF` since the 5` protocol expects the single-cell reads from the forward strand, unlike 3' where we expect the reads from reverse. It should not be a problem for the guide/feature barcodes though.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638444905:29,test,test,29,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638444905,2,['test'],['test']
Testability,"Slack to 1.; [2019-01-28 21:02:08.487] [jointLog] [info] Using default value of 0.8 for minScoreFraction in Alevin; [2019-01-28 21:09:02.560] [jointLog] [info] There is 1 library.; [2019-01-28 21:09:04.049] [jointLog] [info] Loading Quasi index; [2019-01-28 21:09:04.286] [jointLog] [info] Loading 32-bit quasi index; [2019-01-28 21:09:43.870] [jointLog] [info] done; [2019-01-28 21:09:43.870] [jointLog] [info] Index contained 58,086 targets; [2019-01-28 21:40:30.445] [jointLog] [info] Computed 64,654 rich equivalence classes for further processing; [2019-01-28 21:40:30.445] [jointLog] [info] Counted 107,408,832 total reads in the equivalence classes; [2019-01-28 21:40:30.446] [jointLog] [warning] Found 39484 reads with `N` in the UMI sequence and ignored the reads.; Please report on github if this number is too large; [2019-01-28 21:40:30.446] [jointLog] [info] Mapping rate = 37.2969%. [2019-01-28 21:40:30.446] [jointLog] [info] finished quantifyLibrary(). cat alevin/alevin.log; [2019-01-28 21:02:08.496] [alevinLog] [info] Processing barcodes files (if Present). [2019-01-28 21:07:56.106] [alevinLog] [info] Done barcode density calculation.; [2019-01-28 21:07:56.106] [alevinLog] [info] # Barcodes Used: 287883370 / 287983348.; [2019-01-28 21:07:57.808] [alevinLog] [info] Done importing white-list Barcodes; [2019-01-28 21:07:58.273] [alevinLog] [warning] Skipping 290359 Barcodes with 0 reads; Assuming this is the required behavior.; [2019-01-28 21:07:58.517] [alevinLog] [info] Total 446921 white-listed Barcodes; [2019-01-28 21:09:02.029] [alevinLog] [info] Done populating Z matrix; [2019-01-28 21:09:02.331] [alevinLog] [info] Done indexing Barcodes; [2019-01-28 21:09:02.331] [alevinLog] [info] Total Unique barcodes found: 3214859; [2019-01-28 21:09:02.331] [alevinLog] [info] Used Barcodes except Whitelist: 168781; [2019-01-28 21:09:02.559] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2019-01-28 21:09:02.559] [alevinLog] [info] parsing read librar",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/340:6892,log,log,6892,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/340,1,['log'],['log']
Testability,"So, it took ~30 min (impressively fast) for V1.0.0 with ```--hitFilterPolicy BOTH```, it seems that you are right. Attaching the log and running again in V1.2.1. Thanks again; José ; [salmon_quant.log](https://github.com/COMBINE-lab/salmon/files/4710898/salmon_quant.log)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/527#issuecomment-636790517:129,log,log,129,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/527#issuecomment-636790517,3,['log'],['log']
Testability,"Solved with ; `-DFETCH_STADEN=TRUE`. to recap, installing on an Ubuntu 20.04: ; ```; git clone --depth=1 https://github.com/COMBINE-lab/salmon.git; cd salmon; git checkout tags/v1.5.2. apt-get build-dep -y salmon; cmake -DFETCH_BOOST=FALSE --log-level=VERBOSE -DCMAKE_INSTALL_PREFIX=/directory_to_place/salmon/1.5.2 -DFETCH_STADEN=TRUE -DNO_IPO=TRUE && make && make install; ```. Please note you can't mkdir build and cd build as the cmake files are bundled under the git's root dir. You'll need to move the files (but i'm not familiar with cmake so i just run it from the git root). Compilation is required as the distributed binaries use the older libc (GLIBC_2.29)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/425#issuecomment-962540229:242,log,log-level,242,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/425#issuecomment-962540229,1,['log'],['log-level']
Testability,"Some progress. Found a src rpm for cereal, rebuilt that into an RPM and installed. Then this (ROOT_* env variables come from the respective module load commands):. ```; cmake \; -DCMAKE_INSTALL_PREFIX=$TOPDIR \; -DSTADEN_ROOT=$ROOT_IO_LIB \; -DGFF_ROOT=$ROOT_LIBGFF \; -DTBB_ROOT=$ROOT_LIBTBB \; -DCMAKE_VERBOSE_MAKEFILE:BOOL=ON \; -DBOOST_LIBRARYDIR=/usr/lib64/boost169 \; -DBOOST_INCLUDEDIR=/usr/include/boost169 \; -DBoost_NO_SYSTEM_PATHS=ON \; .. 2>&1 | tee cmake_2020_06_09.log; ```; found everything. The ""make"" went along pretty well until here:; ```; [100%] Linking CXX executable salmon; cd /usr/common/src/salmon-1.2.1/build/src && /usr/common/src/cmake-3.17.1/bin/cmake -E cmake_link_script CMakeFiles/salmon.dir/link.txt --verbose=1; /usr/lib64/ccache/c++ -O3 -DNDEBUG -flto -fno-fat-lto-objects CMakeFiles/salmon.dir/EMUtils.cpp.o CMakeFiles/salmon.dir/CollapsedEMOptimizer.cpp.o CMakeFiles/salmon.dir/CollapsedCellOptimizer.cpp.o CMakeFiles/salmon.dir/CollapsedGibbsSampler.cpp.o CMakeFiles/salmon.dir/Salmon.cpp.o CMakeFiles/salmon.dir/BuildSalmonIndex.cpp.o CMakeFiles/salmon.dir/Graph.cpp.o CMakeFiles/salmon.dir/DedupUMI.cpp.o CMakeFiles/salmon.dir/Alevin.cpp.o CMakeFiles/salmon.dir/AlevinHash.cpp.o CMakeFiles/salmon.dir/SalmonAlevin.cpp.o CMakeFiles/salmon.dir/WhiteList.cpp.o CMakeFiles/salmon.dir/SalmonQuantify.cpp.o CMakeFiles/salmon.dir/FragmentLengthDistribution.cpp.o CMakeFiles/salmon.dir/FragmentStartPositionDistribution.cpp.o CMakeFiles/salmon.dir/GZipWriter.cpp.o CMakeFiles/salmon.dir/SalmonQuantMerge.cpp.o CMakeFiles/salmon.dir/ProgramOptionsGenerator.cpp.o CMakeFiles/salmon.dir/FASTAParser.cpp.o CMakeFiles/salmon.dir/AlignmentModel.cpp.o CMakeFiles/salmon.dir/SalmonQuantifyAlignments.cpp.o CMakeFiles/salmon.dir/BAMUtils.cpp.o -o salmon -L/usr/common/src/salmon-1.2.1/lib -L/usr/common/src/salmon-1.2.1/external/install/lib -Wl,-rpath,""\$ORIGIN/../lib:\$ORIGIN/../../lib:\$ORIGIN/:\$ORIGIN/../../external/install/lib"" ../external/pufferfish/src/libpuffer.a libs",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641531162:479,log,log,479,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641531162,1,['log'],['log']
Testability,"Sorry :// Another issue... . Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v1.2.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /media/usr/Hybrid_02/Unidad_Bioinf/FER_Scripts/Index/hg38/salmon_sa_index/default }; ### [ libType ] => { A }; ### [ gcBias ] => { }; ### [ validateMappings ] => { }; ### [ mates1 ] => { /media/usr/trimmed_fastq_files/PAIRED_trimmed_fastq_files/APSa16_1P.fq.gz }; ### [ mates2 ] => { /media/usr/trimmed_fastq_files/PAIRED_trimmed_fastq_files/APSa16_2P.fq.gz }; ### [ threads ] => { 7 }; ### [ output ] => { /media/usr/quantification/APSa16.fq.gz_quant }; Logs will be written to /media/usr/quantification/APSa16.fq.gz_quant/logs; [2020-05-05 09:19:06.171] [jointLog] [info] setting maxHashResizeThreads to 7; [2020-05-05 09:19:06.171] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2020-05-05 09:19:06.171] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2020-05-05 09:19:06.171] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.35.; [2020-05-05 09:19:06.171] [jointLog] [info] parsing read library format; [2020-05-05 09:19:06.171] [jointLog] [info] There is 1 library.; [2020-05-05 09:19:06.278] [jointLog] [info] Loading pufferfish index; [2020-05-05 09:19:06.278] [jointLog] [warning] The index did not record if the `--keepDuplicates` flag was used. Please consider re-indexing with a newer version of salmon that will propagate this information.; [2020-05-05 09:19:06.278] [jointLog] [info] Loading dense pufferfish index.; -----------------------------------------; | Loading contig table | Time = 30.609 s; -----------------------------------------; size = 36981178; -----------------------------------------; | Loading contig offsets | Time = 1.3312 s; --------------------------",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/518#issuecomment-623910021:651,Log,Logs,651,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/518#issuecomment-623910021,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"Sorry for the confusion, what I meant was the alevin log, it should be inside the alevin folder of your output subdirectory with the name `alevin.log`.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/396#issuecomment-510545906:53,log,log,53,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/396#issuecomment-510545906,2,['log'],['log']
Testability,"Sorry for the inconvenience. I completely missed this point. My test set was too small and none were doubles. I was in the process of writting a bug fix... Anyway, thanks for the correction.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/356#issuecomment-486109301:64,test,test,64,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/356#issuecomment-486109301,1,['test'],['test']
Testability,"Sorry if I wasn't clear. I did try with and without the --chromium; option, with the same error. I just have try the exact command you provided (including the --chromium; flag), with option in the same order. The command log is then:; ### salmon (single-cell-based) v0.11.1; ### [ program ] => salmon; ### [ command ] => alevin; ### [ threads ] => { 10 }; ### [ libType ] => { ISR }; ### [ chromium ] => { }; ### [ mates1 ] => {; /path/to/downloads/10xPBMC/pbmc4k_S1_L001_R1_001.fastq.gz }; ### [ mates2 ] => {; /path/to/downloads/10xPBMC/pbmc4k_S1_L001_R2_001.fastq.gz }; ### [ index ] => { /path/to/salmonIndex }; ### [ output ] => { alevin_output }; ### [ tgMap ] => { tx2gene.tsv }. Now it seems to work. I'll tell you if the whole alignment is; successfull when it will end. Note that when I use the --chromium flag earlier in the command, ie:. salmon --no-version-check --chromium alevin -p 10 -lISR -1 [...]. The log contains:; ### salmon (single-cell-based) v0.11.1; ### [ program ] => salmon; ### [ command ] => alevin; ### [ ] => { alevin }; ### [ threads ] => { 10 }; ### [ libType ] => { ISR }",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/264#issuecomment-410331030:221,log,log,221,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/264#issuecomment-410331030,4,['log'],['log']
Testability,"Sorry, I shouldn't have used that sample as an example. That's just the first of many, and there was some issue causing a super low mapping rate. Here is another example:. ```; Processing sample RHM5942; Version Info: This is the most recent version of Salmon.; ### salmon (mapping-based) v0.11.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /data2/csijcs/hg38/hg38.transcriptome.index }; ### [ libType ] => { A }; ### [ mates1 ] => { /data2/csijcs/AML/RNA_seq/AML_total_MNC/total_MNCs/Fresh_samples/RHM5942/RHM5942_R1_001.fastq.gz }; ### [ mates2 ] => { /data2/csijcs/AML/RNA_seq/AML_total_MNC/total_MNCs/Fresh_samples/RHM5942/RHM5942_R2_001.fastq.gz }; ### [ threads ] => { 32 }; ### [ output ] => { /data2/csijcs/AML/RNA_seq/AML_total_MNC/total_MNCs/Fresh_samples/salmon_quants/RHM5942 }; Logs will be written to /data2/csijcs/AML/RNA_seq/AML_total_MNC/total_MNCs/Fresh_samples/salmon_quants/RHM5942/logs; [2018-07-27 16:24:55.658] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2018-07-27 16:24:55.658] [jointLog] [info] parsing read library format; [2018-07-27 16:24:55.658] [jointLog] [info] There is 1 library.; [2018-07-27 16:25:01.242] [jointLog] [info] Loading Quasi index; [2018-07-27 16:25:01.242] [jointLog] [info] Loading 32-bit quasi index; [2018-07-27 16:25:01.243] [stderrLog] [info] Loading Suffix Array ; [2018-07-27 16:25:42.630] [stderrLog] [info] Loading Transcript Info ; [2018-07-27 16:25:45.683] [stderrLog] [info] Loading Rank-Select Bit Array; [2018-07-27 16:25:47.834] [stderrLog] [info] There were 203027 set bits in the bit array; [2018-07-27 16:25:48.128] [stderrLog] [info] Computing transcript lengths; [2018-07-27 16:25:48.200] [stderrLog] [info] Waiting to finish loading hash; [2018-07-27 16:25:48.331] [stderrLog] [info] Done loading index; [2018-07-27 16:25:48.331] [jointLog] [info] done; [2018-07-27 16:25:48.331] [jointLog] [info] Index contained 203027 targets. proces",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/261#issuecomment-409427898:822,Log,Logs,822,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/261#issuecomment-409427898,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"Sorry, me (#228) again...; While most of my samples seem to work on linux, I got an exception for one of them:. Version Info: This is the most recent version of Salmon.; \#\#\# salmon (mapping-based) v0.10.0; \#\#\# [ program ] => salmon; \#\#\# [ command ] => quant; \#\#\# [ index ] => { salmon010.index.all_combined }; \#\#\# [ libType ] => { A }; \#\#\# [ mates1 ] => { R1.fastq.gz }; \#\#\# [ mates2 ] => { R2.fastq.gz }; \#\#\# [ posBias ] => { }; \#\#\# [ gcBias ] => { }; \#\#\# [ seqBias ] => { }; \#\#\# [ useVBOpt ] => { }; \#\#\# [ validateMappings ] => { }; \#\#\# [ output ] => { processed_salmon0100_k31_allcombined/R }; Logs will be written to processed_salmon0100_k31_allcombined/R/logs; [2018-05-31 16:54:42.310] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2018-05-31 16:54:42.310] [jointLog] [info] Usage of --validateMappings implies use of range factorization. rangeFactorizationBins is being set to 4; [2018-05-31 16:54:42.310] [jointLog] [info] parsing read library format; [2018-05-31 16:54:42.310] [jointLog] [info] There is 1 library.; [2018-05-31 16:54:42.480] [jointLog] [info] Loading Quasi index; [2018-05-31 16:54:42.501] [jointLog] [info] Loading 32-bit quasi index; [2018-05-31 16:54:42.501] [stderrLog] [info] Loading Suffix Array; [2018-05-31 16:55:01.293] [stderrLog] [info] Loading Transcript Info; [2018-05-31 16:55:06.428] [stderrLog] [info] Loading Rank-Select Bit Array; [2018-05-31 16:55:07.107] [stderrLog] [info] There were 310732 set bits in the bit array; [2018-05-31 16:55:07.158] [stderrLog] [info] Computing transcript lengths; [2018-05-31 16:55:07.159] [stderrLog] [info] Waiting to finish loading hash; [2018-05-31 16:55:25.973] [jointLog] [info] done; [2018-05-31 16:55:25.973] [jointLog] [info] Index contained 310732 targets; [2018-05-31 16:55:25.973] [stderrLog] [info] Done loading index. processed 67500000 fragmentsointLog] [info] Automatically detected most likely library type ",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/229:636,Log,Logs,636,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/229,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"Sorry,. > Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; # salmon (alignment-based) v0.9.1; # [ program ] => salmon; # [ command ] => quant; # [ targets ] => { transcripts.fa }; # [ libType ] => { A }; # [ alignments ] => { A549_S1_001.bam }; # [ output ] => { A549_S1_quant }; Logs will be written to A549_S1_quant/logs; Malformed key:value pair at line 44017: ""@PG ID:OSA IsCdna:True ReferenceLibraryID:Human.B37.3_RefGene20121217 VN:7.2""; ============; Exception : [ERROR: Failed to open file A549_S1_001.bam, exiting!]; ============; ./bin/salmon alignment-quant was invoked improperly.; For usage information, try ./bin/salmon quant --help-alignments; Exiting.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/222#issuecomment-387497883:374,Log,Logs,374,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/222#issuecomment-387497883,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"Still looking, but this is very strange! It happens when the program is exiting, during the destruction of some objects. Strangely, it doesn't happen on the test data (also it's strange that it doesn't happen in the version compiled from source).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168357540:157,test,test,157,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/34#issuecomment-168357540,1,['test'],['test']
Testability,"Strangely enough - with the above error message of mine. when I go to the logs directory and look up salmon_quant.log, it has correct info (last line below); ```; [2020-04-22 19:45:18.487] [jointLog] [info] Finished Bootstrapping; ```. And the output directory has a `quant.sf` file and it has all the records I want -- however, salmon is exiting with the above error message",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/512#issuecomment-618027626:74,log,logs,74,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/512#issuecomment-618027626,2,['log'],"['log', 'logs']"
Testability,"Strictly speaking, barcodes.tsv**.gz** files are provided. I was viewing the uncompressed file in Notepad++, so I think that number (from the line numbers on the left) should be correct. I will double-check the next time that I am on my work computer. I will test using the smaller number of barcodes. However, unlike the larger file, I think this would be different for every sample. If part of the reason that I wanted to run Alevin is that I wanted an independent quantification (which takes less time), then that may be a notable limitation. However, for whatever reason, this seems to only be an issue with the v2 sample (the v3 sample worked fine). So, I will test that, and I will at least confirm if I see the same error message or not.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-878693769:259,test,test,259,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-878693769,2,['test'],['test']
Testability,"Sure thing. Here's a small quants file. It's just the top 2500 lines of one of the files I was testing with. I double checked and this one gets cut at 17 lines (it has ""Erdr1""). [quant.genes.sf.txt](https://github.com/COMBINE-lab/salmon/files/3066421/quant.genes.sf.txt). And here is the mapping I was using:. [map.tsv.gz](https://github.com/COMBINE-lab/salmon/files/3066425/map.tsv.gz). If you need anything else, I'm happy to oblige.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/356#issuecomment-481924188:95,test,testing,95,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/356#issuecomment-481924188,1,['test'],['testing']
Testability,"Sure, thanks for pointing this out, we have updated the document now !; We are gonna do testing at our end too, but let us know if you have any other issue.; Happy Weekend !",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395912965:88,test,testing,88,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395912965,1,['test'],['testing']
Testability,"TCACT_lane-001-chunk-001.fastq.gz; read-I1_si-ACTTCACT_lane-002-chunk-000.fastq.gz; read-I1_si-ACTTCACT_lane-003-chunk-003.fastq.gz; read-I1_si-ACTTCACT_lane-004-chunk-002.fastq.gz; read-I1_si-CGAAGTTG_lane-001-chunk-001.fastq.gz; read-I1_si-CGAAGTTG_lane-002-chunk-000.fastq.gz; read-I1_si-CGAAGTTG_lane-003-chunk-003.fastq.gz; read-I1_si-CGAAGTTG_lane-004-chunk-002.fastq.gz; read-I1_si-GAGCACGC_lane-001-chunk-001.fastq.gz; read-I1_si-GAGCACGC_lane-002-chunk-000.fastq.gz; read-I1_si-GAGCACGC_lane-003-chunk-003.fastq.gz; read-I1_si-GAGCACGC_lane-004-chunk-002.fastq.gz; read-I1_si-TTCGTGAA_lane-001-chunk-001.fastq.gz; read-I1_si-TTCGTGAA_lane-002-chunk-000.fastq.gz; read-I1_si-TTCGTGAA_lane-003-chunk-003.fastq.gz; read-I1_si-TTCGTGAA_lane-004-chunk-002.fastq.gz]; Version Info: This is the most recent version of Salmon.; [2018-09-11 16:28:53.145] [alevinLog] [info] A custom protocol (END, BC length, UMI length) = (5, 14, 5) is being used. Updating UMI k-mer length accordingly.; Logs will be written to ../../alevin_15_pc/logs; ### salmon (single-cell-based) v0.11.2; ### [ program ] => salmon ; ### [ command ] => alevin ; ### [ libType ] => { ISR }; ### [ mates1 ] => { read-I1_si-ACTTCACT_lane-001-chunk-001.fastq.gz read-I1_si-ACTTCACT_lane-002-chunk-000.fastq.gz read-I1_si-ACTTCACT_lane-003-chunk-003.fastq.gz read-I1_si-ACTTCACT_lane-004-chunk-002.fastq.gz read-I1_si-CGAAGTTG_lane-001-chunk-001.fastq.gz read-I1_si-CGAAGTTG_lane-002-chunk-000.fastq.gz read-I1_si-CGAAGTTG_lane-003-chunk-003.fastq.gz read-I1_si-CGAAGTTG_lane-004-chunk-002.fastq.gz read-I1_si-GAGCACGC_lane-001-chunk-001.fastq.gz read-I1_si-GAGCACGC_lane-002-chunk-000.fastq.gz read-I1_si-GAGCACGC_lane-003-chunk-003.fastq.gz read-I1_si-GAGCACGC_lane-004-chunk-002.fastq.gz read-I1_si-TTCGTGAA_lane-001-chunk-001.fastq.gz read-I1_si-TTCGTGAA_lane-002-chunk-000.fastq.gz read-I1_si-TTCGTGAA_lane-003-chunk-003.fastq.gz read-I1_si-TTCGTGAA_lane-004-chunk-002.fastq.gz }; ### [ mates2 ] => { read-RA_si-ACTTCACT_lane-001",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/294:5594,Log,Logs,5594,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/294,1,['Log'],['Logs']
Testability,"TGAAGAAAGG; +D00585:41:CB64LANXX:1:1202:13646:88674; BBBBBFFFFFFFFFFFF<FFFBF//<; @D00585:40:CB7FUANXX:1:2113:18626:8045; TGGGCGTTCTTGCATTCCTGGAACCT; +D00585:40:CB7FUANXX:1:2113:18626:8045; BBBBBFFFFFFFFFFFF<FBFFFFFF; ``` . And an extract of the reads fastq:; ```; @D00585:41:CB64LANXX:1:1202:13646:88674; TCTGTTCATGTGTATTTGCTGTCTCTTAGCCCAGACTTCCCGTGTCCTTTCCACCGGGCCTTTGAGAGGTCACAGGGTCTTGATGCTGTGGTCTTCAT; +D00585:41:CB64LANXX:1:1202:13646:88674; BFFF<FFFBFFB<FFFB<FFFBF//FFFFB<FFFF<F///FFFB/BF<//F<7//FBFBB/F<BF</F<FFFFFFFF<</<FFBFBFFBFF<FBBBBB; @D00585:40:CB7FUANXX:1:2113:18626:8045; ATGTGTATTTGCTGTCTCTTAGCCCAGACTTCCCGTGTCCTTTCCACCGGGCCTTTGAGAGGTCACAGGGTCTTGATGCTGTGGTCTTCATCTGCAGG; +D00585:40:CB7FUANXX:1:2113:18626:8045; FFFFFBFFFFFFFFFFFB/FBFFFFBFFFFFFFBBFFFFFFFFFFFFFFFFFFFFFFFFFFFFFBFFFBFFFFFFFFFFFFFFFFFF<FFBFFBBBBB; ``` . This is the log of the analysis:; ```; Version Info: This is the most recent version of salmon.; Logs will be written to /mnt/beegfs/alexmascension/Projects/Single-cell_skin_analysis//Data/Cheng-2018//Alevin/sample/logs; [2019-06-23 18:08:01.732] [alevinLog] [info] A custom protocol (END, BC length, UMI length) = (5, 16, 10) is being used. Updating UMI k-mer length accordingly.; [2019-06-23 18:08:01.803] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-06-23 18:08:01.804] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2019-06-23 18:08:01.804] [jointLog] [info] Usage of --validateMappings, without --hardFilter implies use of range factorization. rangeFactorizationBins is being set to 4; [2019-06-23 18:08:01.804] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.2.; [2019-06-23 18:08:01.804] [jointLog] [info] Using default value of 0.87 for minScoreFraction in Alevin; Using default value of 0.6 for consensusSlack in Alevin; [2019-06-23 1",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/386:1476,Log,Logs,1476,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/386,2,"['Log', 'log']","['Logs', 'logs']"
Testability,Testing problem: test 1 fails,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/204:0,Test,Testing,0,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/204,2,"['Test', 'test']","['Testing', 'test']"
Testability,"Thank you in advance for developing this amazing thing. . I have some little suggestions. I have little background on algorithm used in salmon, and need to give a quick test on the data. I read through the documents, and it's very difficult for me to understand the rational running behind for some options without reading series of original algorithm papers. I guess some import details are missed in the document, for example, what's the difference of quasi-mapping model and light-weight alignment based model, and how salmon deal with pair end reads that not concordantly aligned. To be honest, it's not very friendly to end-user of this tool, and prevents some of us using it extensively. obenno",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/248#issuecomment-402909186:169,test,test,169,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/248#issuecomment-402909186,1,['test'],['test']
Testability,"Thank you very much, @k3yavi ! The references to the other discussion is very helpful. I am testing what happens if I use `-lISF` (instead of `-lISR`). Thanks again!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-876797474:92,test,testing,92,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-876797474,1,['test'],['testing']
Testability,"Thank you very much, @k3yavi !. There was a different 10x white list that worked for a different sample (with a different 10x design), and there is a 3rd dataset that is a BD Rhapsody experiment (where I can't use CellRanger). However, for this particular sample, I also have the CellRanger results. So, I can test as you have described, and close the ticket. If I have additional questions about the different cell counts from the different methods, then I will open a different ticket for that separate topic. Thanks again!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-877526812:310,test,test,310,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-877526812,1,['test'],['test']
Testability,"Thanks @Ryan-Zhu ,. A couple of thoughts.; To me the data seem a little noisy as a lot of CB/reads are thrown away due to ""knee"" thresholding.; Check https://github.com/COMBINE-lab/salmon/issues/362 if you wanna play with how to customize alevin for user-define whitelisting. Having said that this is how you can parse the data from alevin.; Alevin use 1277 CB after its knee thresholding + 638 low confidence Barcode for downstream whitelisting = total 1915 CBs.; If you check the warning in the log it says :. ```; [2019-06-12 15:07:08.152] [alevinLog] [warning] Skipped 313 barcodes due to No mapped read; ```; Basically it means out of 1915, 313 didn't had any read mapped to them, so alevin doesn't report them in the output matrix. Alevin reports 1915 - 313 = 1602 CBs both in `.mtx` and `quants_mat.gz` file. You can check the order of the CB in the `quants_mat_rows.txt` file, which has 1602 rows/CBs. If you don't provide alevin with external whitelist alevin tries to do post whitelisting of it's own. Basically out of the 1277 high confidence CBs alevin initially find out through knee it assigns 647 CBs as final whitelisted CB as found in the `whitelist.txt` file. If you wan't to subsample these CBs you have to extract the information from the `.mtx` or `quants_mat.gz` file. You can check a simple python parse of the `quants_mat.gz` file [here](https://github.com/k3yavi/vpolo/blob/master/vpolo/alevin/parser.py#L187-L230).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/374#issuecomment-501846672:497,log,log,497,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/374#issuecomment-501846672,2,['log'],['log']
Testability,Thanks @dritoshi for the data and info. Let me play a bit with the data over the weekend. It should be very straightforward to add but I might have to check some unit test. I'll keep you updated.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/416#issuecomment-521863053:167,test,test,167,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/416#issuecomment-521863053,1,['test'],['test']
Testability,Thanks @k3yavi - I think those options would really help us use Alevin in production- look forward to the next release. . I'll do some more testing in the meantime.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-490859077:140,test,testing,140,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-490859077,1,['test'],['testing']
Testability,Thanks @k3yavi . [alevin.log](https://github.com/COMBINE-lab/salmon/files/3303575/alevin.log); [salmon_quant.log](https://github.com/COMBINE-lab/salmon/files/3303576/salmon_quant.log),MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/379#issuecomment-503326828:25,log,log,25,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/379#issuecomment-503326828,4,['log'],['log']
Testability,Thanks @k3yavi! I'm not aware of the issues with previous version. I tested it with the [test data](https://github.com/indrops/indrops/tree/master/test/seq_runs/run_v2_single_file) and the data I mentioned earlier and it worked fine. Let me know how the review goes and if I have missed something.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/703#issuecomment-920995572:69,test,tested,69,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/703#issuecomment-920995572,3,['test'],"['test', 'tested']"
Testability,"Thanks @rfarouni ! A small dataset with few thousand reads would be great to have, the one I currently had was too few to test things on.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639622262:122,test,test,122,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639622262,1,['test'],['test']
Testability,"Thanks @rfarouni for the updates. > With --minScoreFraction 0.607 I get a way much better mapping rate. I wonder if there is way to determine the optimal value empirically?. Glad to hear that, may I ask what percent of the reads are mapping now ? It's not clear from the alevin logs you shared but I think the total number of deduplicated UMIs are similar to your baseline experiment. I think defining an optimal empirical threshold is a great idea but the issue is that 21 length barcodes are kind of in the middle i.e. a tad longer than the regular barcodes and somewhat smaller than a full read. The full read alignment process indeed allows more erroneous reads to map but 21 is a bit too short to work with. @rob-p might have more thoughts on this one. > But now there are a lot of barcodes that are not in the whitelist. Thanks again for checking this, it is indeed concerning. However, as I was mentioning earlier in a regular single-cell experiment we end up throwing away almost all of these very low frequency count cellular barcodes. I'd say even 45 reads CBs are most probably a noise and will be filtered away, because only a fraction of the reads will map and after deduplication it'll result in significantly low count in 1 cellular barcode. > Also with the default setting of --freqThreshold, no CB correction gets done. I can check why is this happening, let me know once you have a toy dataset to play with.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-640093397:278,log,logs,278,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-640093397,2,['log'],['logs']
Testability,"Thanks @rob-p,. Your explanations are helpful, and I think it may my concern may just be more associated with your general thought as I've tested this with multiple parameters. The one I represented here was just an example, but I also can see how the parameters can be affecting these results. It was just strange to see such a huge shift with the addition/removal of one gene, which makes me think it more associated with how the inference of the variables are conditioned. . As for providing the meta_info.json files, I currently have thousands of them as I am running triplicates of ~150 parameter combinations for multiple tissue types and stages. In the end I don't think it will be necessary as we will likely be changing our approach a bit, which should be fine with the system I have in place. . Also, as for `--scoreExp` our main goal is to try and use Salmon to get quantification of individual genes (primary versus spliced forms). From my analysis, it appears that some genes perform better with scores > 0, however, some genes do perform better with a `--scoreExp` of 0. Although, this could be a factor in running Salmon with such a narrow view (i.e. two transcripts and some housekeeping genes) and might not be the case as more genes are added to the run.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/523#issuecomment-633062608:139,test,tested,139,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/523#issuecomment-633062608,1,['test'],['tested']
Testability,"Thanks @roryk and @k3yavi . The issue we have is that we're trying to run a pipeline in a fairly high-throughput manner to get a sensible 'enough' matrix without too much manual intervention. So I'm trying to avoid anything that requires an eyeballing step, accepting that the matrix we get will be less optimal than one you'd get from manual optimisation. Where possible, our curators are extracting the expected cell numbers from publications, so sometimes I have at least a general idea of where to look for an elbow/ feature. @roryk - have you used your alternate view on the data to automatically derive cutoffs? Does it work well?. @k3yavi:. As I say, first point is that this is for cases where I have a rough idea of the target cell number- we're generally working with pre-published data (though cell numbers per run are not always available). . From https://github.com/COMBINE-lab/salmon/issues/340 I'd inferred that --expectCells gives Alevin ballpark to look for a knee within, while --forceCells is a strict cuttoff. Is that correct? . That being the case, my thought was to try --expectCells first, and failing that --forceCells. The problem is that I need to parse the STDOUT/ERR to detect the boundary error from --expectCells, which is not a very robust way of doing things. If you returned informative error codes (anything but 1) on this and other errors, I could detect the error and implement the logic I describe.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-490157428:1418,log,logic,1418,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-490157428,1,['log'],['logic']
Testability,"Thanks @shalercr,. I'll grab those files once they are finished uploading. I don't know if all samples show similar behavior, but these are called `31_1` and `31_2`, while in your logs you had `13_1` and `13_2`. Regarding OSX vs. linux, it should not really matter, obviously (salmon should work well under both, but I'm just curious since this is obviously atypical and unexpected behavior). --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-644505526:180,log,logs,180,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-644505526,1,['log'],['logs']
Testability,"Thanks Jeremy! Yes, that's what I was hinting at with different v1/v2 protocols. From their code, you can see differences in amplicon sequences:; - For v1: 'NNNNNNNNNNIIIIIIIIGTGGCCGATGTTTCGCATCGGCGTACGACTIIIIIIIIATCCACGTGCTTGAGAGGCCAGAGCATTCGIIIIIIII'; - For v2: 'NNNNNNNNNNIIIIIIIIGTGGCCGATGTTTCGCATCGGCGTACGACTIIIIIIIIATCCACGTGCTTGAGACTGTGGIIIIIIII'; where the `IIIIIIII` sequence corresponds to barcode. This is from the pipeline code I mentioned earlier used for [this paper](https://www.nature.com/articles/s41593-021-00872-y). Do you have a the pairing file for the BC1 barcodes? Is it the Supp Table S12 in the Rosenberg paper? It is needed for development and testing.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-951080577:669,test,testing,669,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-951080577,1,['test'],['testing']
Testability,"Thanks Matt for the response and fix, unfortunately the error persists;; Might need to re-align using a different pipeline?. > Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; # salmon (alignment-based) v0.9.1; # [ program ] => salmon; # [ command ] => quant; # [ targets ] => { transcripts.fa }; # [ libType ] => { A }; # [ alignments ] => { A549_S1_001.bam }; # [ output ] => { A549_S1_quant }; Logs will be written to A549_S1_quant/logs; Malformed key:value pair at line 44017: ""@PG ID:OSA IsCdna:True ReferenceLibraryID:Human.B37.3_RefGene20121217 VN:7.2""; ============; Exception : [ERROR: Failed to open file A549_S1_001.bam, exiting!]; ============; ./bin/salmon alignment-quant was invoked improperly.; For usage information, try ./bin/salmon quant --help-alignments; Exiting.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/222#issuecomment-387497579:491,Log,Logs,491,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/222#issuecomment-387497579,2,"['Log', 'log']","['Logs', 'logs']"
Testability,Thanks for helping to look into this @hiraksarkar ; That seems like a logical outcome re the higher number of connected transcripts - interesting. As requested - I've added in the bootstrap folder - here are the new links:; [Selective alignment](https://drive.google.com/file/d/11TfZXuBZqMbtCL6BwZwI7ms3gzPNipav/view?usp=sharingl); [Alignment based - STAR](https://drive.google.com/file/d/12piPEagYNuDcPC861CKHYjQ1AVDu8QYP/view?usp=sharing),MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/600#issuecomment-757553955:70,log,logical,70,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/600#issuecomment-757553955,1,['log'],['logical']
Testability,"Thanks for making these available! I'm looking through. Though it's not directly related to the `fetchRapMap.sh` script, I do find [this](https://gist.github.com/sjackman/6e15b7dfebaaad99b9476aa5ce269fda#file-cmakeerror-log-L47) disconcerting. Any idea what's up there?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/181#issuecomment-367795756:220,log,log-,220,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/181#issuecomment-367795756,1,['log'],['log-']
Testability,"Thanks for reporting back (with the nice plots!). This is interesting, because, at least in our other testing, the VB seems to be performing slightly _better_ than the EM. One guess I have is that the VB Opt tends to produce slightly sparser solutions than the EM opt. Usually, this is a ""good thing"". However, if you're dealing with such small datasets (n ~50), then dropping a few points could make a significant difference. Since you can reproduce the previous behavior when dropping the VB option, there's no rush. However, if you are able to share some of the data at some point, I'd be interested in digging in and figuring out exactly what's happening here. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/6#issuecomment-111604379:102,test,testing,102,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/6#issuecomment-111604379,1,['test'],['testing']
Testability,Thanks for reporting it @cliftonlewis. I have tested the fix and it works both with and without rad mode (`--justAlign`). The solution is in pr #817.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/813#issuecomment-1344736974:46,test,tested,46,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/813#issuecomment-1344736974,1,['test'],['tested']
Testability,"Thanks for testing that out. In this case, I'll try an dig more deeply into why you're having issues compiling from source. In the mean time, I hope the pre-compiled binary will work for you. edit: I wonder if the error might be related to the fact that the build system things TBB was compiled with GCC 4.4? From the log:. > /usr/local/packages/intel-tbb.4.4.3.181/compilers_and_libraries_2016.2.181/linux/tbb/lib/intel64_lin/**gcc4.4**/libtbb.so.2",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/51#issuecomment-201332198:11,test,testing,11,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/51#issuecomment-201332198,2,"['log', 'test']","['log', 'testing']"
Testability,"Thanks for the heads up. I gave it a test this evening and wow, it is wicked fast. I’ll send you those quant files tomorrow when I get a chance, but adding that flag and the new version fixed the problem. . Thank you for all your help. . Best,. Ryan . Sent from my iPhone. On Jun 16, 2020, at 11:36 PM, Rob Patro <notifications@github.com> wrote:. ﻿. P.S. ; @shalercr,; I also note that layering --hitFilterPolicy BOTH on top of the new version cuts down the time by another factor of 2 for me; 2163.65user 12.72system 4:21.57elapsed 832%CPU (0avgtext+0avgdata 1221856maxresident)k. and the number of mappings discarded alignments due to score comes down by another factor of ~6X. It might be worth seeing what you get with that option as well.; —; You are receiving this because you were mentioned.; Reply to this email directly, ; view it on GitHub, or ; unsubscribe.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-645762627:37,test,test,37,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-645762627,1,['test'],['test']
Testability,"Thanks for the quick answer!; Here is the log file:. [2020-04-22 12:53:21.437] [jointLog] [info] setting maxHashResizeThreads to 8; [2020-04-22 12:53:21.437] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2020-04-22 12:53:21.437] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2020-04-22 12:53:21.437] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.35.; [2020-04-22 12:53:21.437] [jointLog] [info] parsing read library format; [2020-04-22 12:53:21.437] [jointLog] [info] There is 1 library.; [2020-04-22 12:53:21.501] [jointLog] [info] Loading pufferfish index; [2020-04-22 12:53:21.503] [jointLog] [info] Loading dense pufferfish index.; [2020-04-22 12:54:13.540] [jointLog] [info] done; [2020-04-22 12:54:13.713] [jointLog] [info] Index contained 228,799 targets; [2020-04-22 12:54:29.422] [jointLog] [info] Number of decoys : 84; [2020-04-22 12:54:29.466] [jointLog] [info] First decoy index : 228,673 ; [2020-04-22 13:00:24.946] [jointLog] [info] Automatically detected most likely library type as ISR; [2020-04-23 00:06:31.287] [jointLog] [info] Thread saw mini-batch with a maximum of 1.06% zero probability fragments; [2020-04-23 00:06:41.198] [jointLog] [info] Thread saw mini-batch with a maximum of 1.08% zero probability fragments; [2020-04-23 00:06:50.741] [jointLog] [info] Thread saw mini-batch with a maximum of 1.02% zero probability fragments; [2020-04-23 00:06:56.260] [jointLog] [info] Thread saw mini-batch with a maximum of 1.08% zero probability fragments; [2020-04-23 00:06:56.781] [jointLog] [info] Thread saw mini-batch with a maximum of 1.04% zero probability fragments; [2020-04-23 00:07:03.636] [jointLog] [info] Thread saw mini-batch with a maximum of 1.04% zero probability fragments; [2020-04-23 00:07:03.759] [jointLog] [info] Thread saw mini-batch ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/516#issuecomment-621872756:42,log,log,42,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/516#issuecomment-621872756,1,['log'],['log']
Testability,Thanks for the report @bernt-matthias. It's interesting that the exception propagation ends up at this place in the code. Would it be possible to also provide the log file for the indexing at the point you catch the indexing in this state? That will help us figure out which allocation could be going awry and why it is propagating to this location rather than causing the program to exit more abruptly.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/484#issuecomment-588455026:163,log,log,163,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/484#issuecomment-588455026,1,['log'],['log']
Testability,Thanks for this bug report @gringer! I have pushed a change to develop that should address this. Would you need me to produce an executable to test this out?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/806#issuecomment-1293938189:143,test,test,143,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/806#issuecomment-1293938189,1,['test'],['test']
Testability,"Thanks for your help. @TomSmithCGAT suggested that it could be our cluster, as he had issues he could resolve with the same cluster. I have a second cluster I can test on. I will do testing on this first and see if I can come to the bottom of it and will get back to you.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458159405:163,test,test,163,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458159405,2,['test'],"['test', 'testing']"
Testability,"Thanks for your input sir. On Sat, Nov 23, 2019 at 3:07 AM Rob Patro <notifications@github.com> wrote:. > @cljacobs <https://github.com/cljacobs> : yes; great point. This has been fixed; > in develop; > <https://github.com/COMBINE-lab/salmon/blob/develop/CMakeLists.txt#L1>.; > It was an oversight due to our testing infrastructure already having a; > newer version of CMake that didn't run into this problem.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/COMBINE-lab/salmon/issues/453?email_source=notifications&email_token=AN2V7HXRZ7T5IT4HH7XJX2DQVBGLJA5CNFSM4JP7NHKKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEE66GMI#issuecomment-557703985>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AN2V7HTSAKLGW4THGPC2QSDQVBGLJANCNFSM4JP7NHKA>; > .; >. -- ; *Shanmugavadivel, P. S.*; *Scientist (Agricultural Biotechnology),*. *#216, Block A,*; *ICAR-Indian Institute of Pulses Research,*. *Min. of Agriculture & Farmers Welfare,*. *Govt. of India,Kanpur - 208 024.*; *email: shanmugavadivel.ps@icar.gov.in <shanmugavadivel.ps@icar.gov.in>*; *www.iipr.res.in <http://www.iipr.res.in>*",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/453#issuecomment-557774500:309,test,testing,309,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/453#issuecomment-557774500,1,['test'],['testing']
Testability,"Thanks for your quickly reply! It really worked @k3yavi; Then I run the command line ; `salmon alevin -l ISR /home/lailab/disk/gjw/Ascite-1_R1.fq.gz -2 /home/lailab/disk/gjw/Ascite-1_R2.fq.gz --chromium --index /home/lailab/disk/gjw/default/ -p 10 -o /home/lailab/disk/gjw/alevin_out --tgMap /home/lailab/disk/gjw/txp2gene.tsv`. ```; Version Server Response: Not Found; Logs will be written to /home/lailab/disk/gjw/alevin_out/logs; [2021-05-27 14:31:00.318] [jointLog] [info] setting maxHashResizeThreads to 10; [2021-05-27 14:31:00.318] [jointLog] [info] The --mimicBT2, --mimicStrictBT2 and --hardFilter flags imply mapping validation (--validateMappings). Enabling mapping validation.; [2021-05-27 14:31:00.318] [jointLog] [error] You passed paired-end files to salmon, but you passed 0 files to --mates1 and 1 files to --mates2. You must pass the same number of files to both flags; [2021-05-27 14:31:00.318] [jointLog] [info] Using default value of 0.87 for minScoreFraction in Alevin; Using default value of 0.6 for consensusSlack in Alevin; [2021-05-27 14:31:00.318] [alevinLog] [error] Could not properly process salmon-level options!; ```; Is it the problem with my data?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/663#issuecomment-850151665:370,Log,Logs,370,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/663#issuecomment-850151665,2,"['Log', 'log']","['Logs', 'logs']"
Testability,Thanks so much @k3yavi! We will take a look and see about adding a small function to add a synthetic cell barcode in front of the UMI on read 2. I do think there is value in adding in 0-length cell barcode functionality for a variety of plate-based single cell approaches as well as allow for UMI containing bulk RNA-seq. We will follow up after @jamorrison and I discuss and test. @DongzeHE and @Gaura I'd love to hear your thoughts on this too. Thanks again!,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/805#issuecomment-1282574837:376,test,test,376,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/805#issuecomment-1282574837,1,['test'],['test']
Testability,"Thanks! I don't have a CentOS 5 setup anywhere where I could test, but if it should be fixed then I'll go ahead and update the formula and bug you about it if anyone runs into problems.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/89#issuecomment-245930320:61,test,test,61,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/89#issuecomment-245930320,1,['test'],['test']
Testability,"Thanks! Worked with a Mapping rate = 73.4157%. See log below. However, I only get half the number of mapped reads per cell-feature. I still need to examine the existing alignment to understand why. ![image](https://user-images.githubusercontent.com/9895004/84175848-8c863c80-aa4e-11ea-8d36-986e7d6f04b5.png). > [2020-06-09 12:31:05.494] [alevinLog] [info] Found 64 transcripts(+0 decoys, +0 short and +0 duplicate names in the index); > [2020-06-09 12:31:05.494] [alevinLog] [info] Filled with 64 txp to gene entries ; > [2020-06-09 12:31:05.494] [alevinLog] [info] Found all transcripts to gene mappings; > [2020-06-09 12:31:05.499] [alevinLog] [info] Processing barcodes files (if Present) ; > ; > ; > [2020-06-09 12:32:20.000] [alevinLog] [info] Done barcode density calculation.; > [2020-06-09 12:32:20.000] [alevinLog] [info] # Barcodes Used: [32m52200250[0m / [31m52200250[0m.; > [2020-06-09 12:32:20.285] [alevinLog] [info] Done importing white-list Barcodes; > [2020-06-09 12:32:20.423] [alevinLog] [warning] Skipping 672237 Barcodes as no read was mapped; > [2020-06-09 12:32:20.578] [alevinLog] [info] Total 65042 white-listed Barcodes; > [2020-06-09 12:32:20.578] [alevinLog] [info] Sorting and dumping raw barcodes; > [2020-06-09 12:32:21.060] [alevinLog] [info] Total 5.06742% reads will be thrown away because of noisy Cellular barcodes.; > [2020-06-09 12:32:23.856] [alevinLog] [info] Done populating Z matrix; > [2020-06-09 12:32:23.882] [alevinLog] [info] Total 79207 CB got sequence corrected. > [2020-06-09 12:32:23.893] [alevinLog] [info] Done indexing Barcodes; > [2020-06-09 12:32:23.893] [alevinLog] [info] Total Unique barcodes found: 604589; > [2020-06-09 12:32:23.893] [alevinLog] [info] Used Barcodes except Whitelist: 71340; > [2020-06-09 12:32:24.004] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify; > ; > [2020-06-09 12:32:24.004] [alevinLog] [info] parsing read library format; > [2020-06-09 12:33:33.719] [alevinLog] [info] Starting optimizer; ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-641426690:51,log,log,51,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-641426690,1,['log'],['log']
Testability,"Thanks, I usually do not trim reads. I am surprised to see such a difference from version 0.8.3. Do you have a recommendation for --minScoreFraction if I do not trim reads? Or maybe I should go back to NOT using --validateMappings?; For testing purposes, I will try trimming the reads for this sample. Will report back.; Oh, and this sample was prepared by ultra-low RNA input protocol, so the issues of adapter contamination could be present.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-586475673:237,test,testing,237,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-586475673,1,['test'],['testing']
Testability,"Thanks, for the response and I'll wait for the detail explanation. . As for the Gibbs, yes I get the appropriate gibbs sample outputs, it's just appears that the log file is not being written.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/466#issuecomment-568769945:162,log,log,162,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/466#issuecomment-568769945,1,['log'],['log']
Testability,"Thanks. I noticed that you forked BWA. I'm guessing my substitution of mainline BWA for your forked version is behind the last error. If we get int64_t defined, that might resolve it. I'd be happy to test, and can submit some patches for my other edits to CMakefiles.txt . I will try the Docker image. I was hesitant to use it because it relies on ZFS, and I'm not sure how ZFS will interact with my jail. Probably the easier path right now though.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/162#issuecomment-337616760:200,test,test,200,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/162#issuecomment-337616760,1,['test'],['test']
Testability,"That is . . . strange! Salmon _literally_ uses the RapMap index (and the RapMap functions) directly to obtain the quasi-mappings. One thing I noticed is that you seem to be using `pseudoindex` which is our independent re-implementation of pseudo-alignment. However, Salmon (and Sailfish) use quasi-mapping (RapMap's `quasiindex` and `quasimap` commands, as [we found this to be more accurate](http://biorxiv.org/content/biorxiv/early/2016/01/16/029652.full.pdf)). I presume that if you used the quasi-mapping functionality, you might observe the bug. If you don't (i.e. if RapMap performs quasi-mapping properly), then this is a real thinker (and I'd be happy to take a look myself if you can share the file). P.S. The same caveat I mentioned above may apply. That is, it is possible that a polyA transcript that is completely removed from the input could cause a problem unless we check for it in the quasi-index, but may not affect the pseudo-index. This is because the quasi-index relies on a packed representation of the transcriptome and an associated sparse bit-vector to perform the mapping, and it assumes that all of the transcripts will have a non-zero length (if this is the culprit, it is, of course, easy to fix with an explicit check). You could also test this hypothesis by generating the quasi-index with the `--noClip` option, which will disable poly-A clipping when building the index.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/37#issuecomment-175088841:1265,test,test,1265,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/37#issuecomment-175088841,1,['test'],['test']
Testability,"That is totally unexpected. There is nothing obvious from the output above. Could you share the output directory itself? It will also contain a log file with time stamps so we can see where the time went. Regarding the mapping rate; that is a bit on the low end, but not catastrophically so (May be worth trimming to see if that changes things at all). The number of decoy fragments is also quite high, meaning a good number of reads arising outside of annotated transcripts.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/516#issuecomment-621834194:144,log,log,144,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/516#issuecomment-621834194,1,['log'],['log']
Testability,"That's very strange in that it doesn't even seem to be trying to load the index! I obviously don't have the same set of reads you do, but here is what I get when using this pre-compiled binary on the 64-bit index (this is a small read set from single-cell data, which is why the total # of reads is so small). ```; rob@feynman:/mnt/scratch3/rob/JoshTest$ ~/SoftwareStaging/salmon/scripts/SalmonBeta-0.6.5-pre_CentOS5/bin/salmon quant -p 15 -i salmon_index -l IU -1 ../strange_peak/19232_1_1.fastq -2 ../strange_peak/19232_1_2.fastq -o quant_binary; Version Info: This is the most recent version of Salmon.; # salmon (mapping-based) v0.6.0; # [ program ] => salmon; # [ command ] => quant; # [ threads ] => { 15 }; # [ index ] => { salmon_index }; # [ libType ] => { IU }; # [ mates1 ] => { ../strange_peak/19232_1_1.fastq }; # [ mates2 ] => { ../strange_peak/19232_1_2.fastq }; # [ output ] => { quant_binary }; Logs will be written to quant_binary/logs; there is 1[2016-03-31 14:05:14.184] [jointLog] [info] parsing read library format; lib; Loading 64-bit quasi index[2016-03-31 14:05:14.266] [stderrLog] [info] Loading Suffix Array; [2016-03-31 14:05:14.266] [jointLog] [info] Loading Quasi index. [2016-03-31 14:07:58.647] [stderrLog] [info] Loading Transcript Info; [2016-03-31 14:08:59.703] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-03-31 14:09:06.744] [stderrLog] [info] There were 2027284 set bits in the bit array; [2016-03-31 14:09:08.123] [stderrLog] [info] Computing transcript lengths; [2016-03-31 14:09:08.240] [stderrLog] [info] Waiting to finish loading hash; Index contained 2027284 targets; [2016-03-31 14:09:15.789] [jointLog] [info] done; [2016-03-31 14:09:15.786] [stderrLog] [info] Successfully loaded position hash; [2016-03-31 14:09:15.789] [stderrLog] [info] Done loading index. [2016-03-31 14:09:36.623] [jointLog] [info] Computed 8083 rich equivalence classes for further processing; [2016-03-31 14:09:36.623] [jointLog] [info] Counted 159824 total reads in th",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-204066023:912,Log,Logs,912,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-204066023,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"The ability to guess RNAseq library format is very useful when quantifying numerous heterogeneous data sets. I tested Salmon's ability to guess library format using a public SRA dataset (PRJNA543304; PMID: 31216476). This dataset was generated using a paired-end stranded protocol (TruSeq Stranded Total RNA Library Prep Kit, Illumina, Cat. 20020597). Based on my understanding, the library format using Salmon's notation would be ISR. Briefly, with the help of several R packages (GenomicRanges, Biostrings, and rtracklayer) I generated my own FASTA file using the human genome sequence and exon annotations both from Ensembl. I extracted the sequences of both mature transcripts and their premature precursors. I was sure to get the reverse complement sequences of genes on the minus strand. I generated an index from this FASTA file without decoys (salmon index -k 31) and quantified the FASTQ files using the following sample code:. ```; # Shuffle FASTQ files; paste <(cat SRR9071838_1.fastq) <(cat SRR9071838_2.fastq) | paste - - - - | shuf --random-source=SRR9071838_1.fastq | \; awk -F '\t' -v std=""$SLURM_TMPDIR"" '{ OFS=""\n""; print $1,$3,$5,$7 > (std ""/SRR9071838_1.fastq""); print $2,$4,$6,$8 > (std ""/SRR9071838_2.fastq"") }'. # Quantify; ./software/salmon-1.4.0_linux_x86_64/bin/salmon quant -i ./shared_data/annotations/Salmon/noDecoys \; -o ./Salmon_out_final_shuf_a_noDecoys/SRR9071838 -l A -p 8 \; -1 $SLURM_TMPDIR/SRR9071838_1.fastq -2 $SLURM_TMPDIR/SRR9071838_2.fastq; ```; I then briefed over the resulting lib_format_counts.json files and noticed that in all but one case, Salmon inferred that the library format is IU, not the expected ISR. Here is a summary:. ```; > salmon.guess.auto; read_files expected_format compatible_fragment_ratio num_compatible_fragments num_assigned_fragments num_frags_with_concordant_consistent_mappings; 1: [SRR9071838_1.fastq, SRR9071838_2.fastq] IU 1.0 46378505 46378505 55523877; 2: [SRR9071839_1.fastq, SRR9071839_2.fastq] ISR 1.0 50070023 50070023",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/655:111,test,tested,111,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/655,1,['test'],['tested']
Testability,"The bash script looks good to me, and I am not aware of any hard limit on the number of files as input. However, I just did tested on 24 files as an input and it seems to work. Hard to tell what's wrong, without being able to replicate the issue.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/329#issuecomment-446208541:124,test,tested,124,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/329#issuecomment-446208541,1,['test'],['tested']
Testability,"The current behavior, which I think is the most reasonable for now, is to keep logging messages to stderr, even if they are not errors. This lets us use stdout for output which may need to be redirected to other programs (e.g. mapping results).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/55#issuecomment-245804636:79,log,logging,79,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/55#issuecomment-245804636,1,['log'],['logging']
Testability,"The documentation states. >If your alignments for the sample you want to quantify appear in multiple .bam/.sam files, then you can simply provide the Salmon -a parameter with a (space-separated) list of these files. But I somehow can't get that to work. I have two bam files, each of them with (different) STAR alignments to the same reference. When I pass either one of them, salmon works just fine, e.g. with the following commands:. ```; salmon quant -t transcripts.fasta -l IU -p 2 -o quantitation/quant.sf -a run1/Aligned.toTranscriptome.out.bam; # or; salmon quant -t transcripts.fasta -l IU -p 2 -o quantitation/quant.sf -a run2/Aligned.toTranscriptome.out.bam; ```; But when I try to pass both of them, I get the following error:. ```; salmon quant -t transcripts.fasta -l IU -p 2 -o quantitation/quant.sf) -a run1/Aligned.toTranscriptome.out.bam run2/Aligned.toTranscriptome.out.bam. Version Info: This is the most recent version of Salmon.; # salmon (alignment-based) v0.7.2; # [ program ] => salmon; # [ command ] => quant; # [ targets ] => { transcripts.fasta }; # [ libType ] => { IU }; # [ threads ] => { 2 }; # [ output ] => { sample1/quantitation }; # [ alignments ] => { run1/Aligned.toTranscriptome.out.bam run2/Aligned.toTranscriptome.out.bam }; Library format { type:paired end, relative orientation:inward, strandedness:unstranded }; Logs will be written to quantitation/logs; numQuantThreads = 2; parseThreads = 2; Checking that provided alignment files have consistent headers . . . done; Populating targets from aln = ""run1/Aligned.toTranscriptome.out.bam"", fasta = ""transcripts.fasta"" . . .replaced 0 non-ACGT nucleotides with random nucleotides; done. processed 0 reads in current roundSegmentation fault (core dumped); ```. The `Checking that provided alignment files have consistent headers . . . done` line seems to indicate that both bam files were recognized and that the headers matched. . Any hints on what might be going on?",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/104:1355,Log,Logs,1355,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/104,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"The following bash code will detect and parse either format of gtf into an appropriately versioned two column tx2gene file. test=$(zless -S $gtf | grep -v ""#"" | awk '$3==""transcript""' | head -n 1| cut -f9 | tr -s "";"" "" "" | awk '{print$3}' | sort | uniq | sed 's/\""//g'); if [[ $test == ""transcript_id"" ]]; then; zless -S $gtf | grep -v ""#"" | awk '$3==""transcript""' | cut -f9 | tr -s "";"" "" "" | awk '{print$4""\t""$2}' | sort | uniq | sed 's/\""//g' > txp2gene.tsv; elif [[ $test == ""gene_version"" ]]; then; echo ""Separate version field (ensembl, non-gencode transcriptome, eg. rat, etc)""; zless -S $gtf | grep -v ""#"" | awk '$3==""transcript""' | cut -f9 | tr -s "";"" "" "" | awk '{print$6 ""."" $8""\t""$2 ""."" $4}' | sort | uniq | sed 's/\""//g' > txp2gene.tsv; fi",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/598#issuecomment-737617544:124,test,test,124,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/598#issuecomment-737617544,3,['test'],['test']
Testability,"The implementation to output mapping information from within salmon (not yet full alignments) is almost complete. The feature needs some testing, but it will definitely make it into the next release.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/38#issuecomment-242924562:137,test,testing,137,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/38#issuecomment-242924562,1,['test'],['testing']
Testability,"The indexing log shows nothing out of the ordinary:. ```; [2016-01-22 15:11:57.283] [jointLog] [info] building index; [2016-01-22 15:40:12.318] [jointLog] [info] done building index; ```. There was actually a blank line at the very end of the transcriptome FASTA which I though might be related to #22, so I removed this line, re-indexed and have the same behavior. I'll check on the nucleotide size of the transcriptome now. cc @jmerkin",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/37#issuecomment-174533495:13,log,log,13,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/37#issuecomment-174533495,1,['log'],['log']
Testability,"The last patch display the error with `std::cerr << ...`, because `log->critical(...)` does not seem to work. Not sure how to fix it.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/617#issuecomment-835404939:67,log,log,67,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/617#issuecomment-835404939,1,['log'],['log']
Testability,"The latest recommended way is through [tximport](https://github.com/mikelove/tximport). In case you need to check more benchmarks comparing different output format, please check [EDS](https://github.com/COMBINE-lab/EDS/blob/master/README.md). Closing this issue but feel free to reopen in case you still have problems.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/354#issuecomment-548616000:119,benchmark,benchmarks,119,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/354#issuecomment-548616000,1,['benchmark'],['benchmarks']
Testability,"The relevant parts of the log are here:; ```; [2019-10-04 10:37:22.243] [ff::console] [warning] Removed 89618 transcripts that were sequence duplicates of indexed transcripts.; [2019-10-04 10:37:22.243] [ff::console] [warning] If you wish to retain duplicate transcripts, please use the `--keepDuplicates` flag; [2019-10-04 10:37:22.318] [ff::console] [info] Replaced 1,775,734,603 non-ATCG nucleotides; [2019-10-04 10:37:22.318] [ff::console] [info] Clipped poly-A tails from 422 transcripts; wrote 593292 cleaned references; seqHash 256 : bd425816a78195ed31cf17ce9df99c2bf56bff98f0df5ace1e958b263d805390; seqHash 512 : 845b625de6f8f018796e464f7c49f6596d2b31b28a58771d56ece24b3d9cad98b8189572ff43d6a3eb8ef24b5d3bc5ac0f89845a57e3682498a56a1bc920e7b7; nameHash 256 : 3bd11eac1e6b05e93689676ca056c165e7c26723c4b137fd284bb8b40ef5df62; nameHash 512 : e68449cfd99f5968182735275b00779b8a396e413a3629beef933e51bd18902c821c26e2a5461c687d023ef85168e58d76bacd5fe1f0a3111bfccc34af9c4035; [2019-10-04 10:37:37.931] [console] [info] Filter size not provided; estimating from number of distinct k-mers; [2019-10-04 10:38:33.012] [console] [info] ntHll estimated 2765935300 distinct k-mers, setting filter size to 2^36; Threads = 8; Vertex length = 31; Hash functions = 5; Filter size = 68719476736; Capacity = 2; Files:; test_pufferfish_index/ref_k31_fixed.fa; --------------------------------------------------------------------------------; Round 0, 0:68719476736; Pass Filling Filtering; 1 385 3124; 2 1258 2; True junctions count = 5437144; False junctions count = 4410615; Hash table size = 9847759; Candidate marks count = 26276463; --------------------------------------------------------------------------------; Reallocating bifurcations time: 6; True marks count: 20290262; Edges construction time: 5004; --------------------------------------------------------------------------------; Distinct junctions = 5437144. approximateContigTotalLength: 1543877663; counters:; 49076 936 921 40; Exception : [std:",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/432#issuecomment-538547108:26,log,log,26,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/432#issuecomment-538547108,1,['log'],['log']
Testability,The script was running `cmake && make install` with no `make`. Could that be it? I've added `make` before `make install`. I'll get that log file for you.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/181#issuecomment-367756380:136,log,log,136,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/181#issuecomment-367756380,1,['log'],['log']
Testability,"The specific error message seems to be coming from [the serialization library we use](https://github.com/USCiLab/cereal/blob/master/include/cereal/archives/portable_binary.hpp#L245). This was upgraded recently, so I'm hoping that they didn't introduce a new bug upstream. As soon as I can reproduce this, I can test if rolling back the version of the serialization library fixes the issue (which I don't believe occurred in 0.7.2).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/129#issuecomment-287255919:311,test,test,311,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/129#issuecomment-287255919,1,['test'],['test']
Testability,"There are quant.sf files in each one of folders. But i get the error saying ""doesn't contain quant.sf "". aux_info cmd_info.json lib_format_counts.json libParams logs quant.sf",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/179#issuecomment-543271953:161,log,logs,161,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/179#issuecomment-543271953,1,['log'],['logs']
Testability,"There is a long literature about why we use counts or CPM (in either case, optionally with an effective transcript length offset) instead of raw TPM for statistical modeling. Using TPM throws out information about the sampling variation. It can be recovered in large sample datasets, but in small sample datasets, it's too much information loss. With respect to Wilcoxon, again, it's good to incorporate the inherent sampling variation of counts into the test statistic even with nonparametric schemes. This occurs in SAMseq (2013). https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4605138/. ...and also in our method Swish (2019), which is based on SAMseq but designed specifically for output of methods like Salmon. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6765120/. Note that Swish is both 1) nonparametric 2) takes into account the multinomial-based sampling nature of sequencing data 3) also takes into account inferential uncertainty from multimapping reads (across isoforms, alleles, or genes).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/812#issuecomment-1325134215:455,test,test,455,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/812#issuecomment-1325134215,1,['test'],['test']
Testability,"They should be unnecessary to diagnose, but if you want to extract the first 100k reads or so, we can try and use them for test quantification.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/561#issuecomment-674423103:123,test,test,123,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/561#issuecomment-674423103,1,['test'],['test']
Testability,"Thinking more about the another problem can be the salmon index i.e. since it's gencode and if not already specified, you might wanna add `--gencode` as the command line flag while creating the index. The problem is the _full_ name in the reference fasta and the GTF does not align, only a prefix from the fasta does. Another thing I noticed in the logs you forwarded is that the number of CB detected by our knee heuristic seems to be undershooting. I might have to look into the data to tell more about it but the alternatives would be to explicitly specify the true/expected CB through a tsv file using flag `--whitelist` or you can force Alevin to use top X highly expressed CB with flag `--forceCells X`. Hope this helps.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/326#issuecomment-443715231:349,log,logs,349,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/326#issuecomment-443715231,1,['log'],['logs']
Testability,"This 'bug' is related to the funcionality. When attempting to quantify reads using the form, salmon quant -i contig_index -l A -1 R1.fastq -2 R2.fastq -o SalmQuant_out, I get the error from the title of this post (screenshot below). * Salmon v 1.5.1 (downloaded executable) used to quantify transcriptome from two fastq files, R1 and R2, containing the same number of sequences. Executed as follows:; * salmon quant -i contig_index -l A -1 R1.fastq -2 R2.fastq -o SalmQuant_out. **Expected behavior**; I expected a quant.sf file. Instead I; ![Screen Shot 2021-09-07 at 3 25 26 PM](https://user-images.githubusercontent.com/50889111/132418472-1bca6641-008e-4a9e-aae5-e0b61f771fd4.png); got the error in the title, and in the salmon_quant.log file. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. **Desktop (please complete the following information):**; - OS: Ubuntu Linux; - Version: 18.04.1 . Any insight and help getting that quantification file is greatly appreciated.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/700:737,log,log,737,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/700,1,['log'],['log']
Testability,"This PR addresses issue #699. To use the protocol, pass the `--splitseqV2` or `--splitseqV1` flag. To test the implementation correlation analysis was done on [data](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE137941) submitted with the [article](https://www.sciencedirect.com/science/article/pii/S1934590920300552). Thanks @jeremymsimon for pointing to the data. Here are the results of correlation b/w the alevin output and published counts. This test run was done as mentioned in [here](https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-988185505). ![image](https://user-images.githubusercontent.com/12998572/145128352-6efe899a-ea06-49bf-9223-24ad4ba70223.png). ```; > summary(cr); Min. 1st Qu. Median Mean 3rd Qu. Max. ; 0.2966 0.7128 0.8690 0.8163 0.9448 0.9963 ; ```",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/726:102,test,test,102,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/726,2,['test'],['test']
Testability,"This PR introduces a new feature that will allow users to specify custom single cell protocols and use with alevin. Custom Geometry (--custom-geo) should be used when:; 1. Barcode or umi have variable lengths; 2. There is known fixed sequence in the reads; 3. There is some sequence to be excluded; From the input peglib spec it creates a regex. Boost regex library is used to parse the reads. Apart from small tests on multiple outlier cases, it was tested on a sci-RNA-seq3 sample SRR7827207 for speed. For this the spec is `--custom-geo 1{b[9-10]f[CAGAGC]u[8]b[10]}2{r}`. It says:; - Read 1 starts with barcode of variable length 9-10 bp, followed by; - A fixed sequence CAGAGC, then; - A umi of length 8, and lastly; - barcode of length 10.; - The second read is all biological. The barcodes are concatenated in the output and a padding sequence is added to make the length as max length + 1. The extra base is added so that we don't introduce spurious matches in barcode. For example, if the barcodes have length 3-4 bp and the two barcodes are `ATG` and `ATGA`, after padding they will be `ATGAC` and `ATGAA` resp. Adding just `A` to shorter barcode would result in a spurious match. . Since `--custom-geo` uses regex, it is slower than protocol specific flag. The time with 8 threads on a large Ubuntu 20 machine:. 1. Using `--sciseq3`:; ```; real 1m0.425s; user 7m21.501s; sys 0m2.964s; ```; 2. Using `--custom-geo`; ```; real 1m39.887s; user 11m55.602s; sys 0m6.839s; ```; Notably, it is about 66% slower. However, it allows support for almost all current and future protocols. . There will be a tutorial shortly on how and when to use this and how is it different from other flags such as `--umi-geometry`, `--read-geometry` and `--bc-geomtery`. There is scope of speed improvement in the future along with integration of all custom geometry processing protocols.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/734:411,test,tests,411,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/734,2,['test'],"['tested', 'tests']"
Testability,"This came up in #336. When building a gencode-based index with `salmon index` without the `--gencode` flag, the index that is generated won't work when subsequently running e.g. `salmon alevin`. This can be a pain to figure out the mistake (missing `--gencode` flag). Perhaps some sort of quick grep of the index file name for `'gencode'` or within the file for multiple `'|'`s (used for gencode field separator but not ensembl) should be done to check if it's gencode followed by a warning/error if the --gencode flag is missing? Another possibility could be to just auto-detect if the index is gencode using the above tests, removing the need for the `--gencode` flag. Thank you",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/366:620,test,tests,620,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/366,1,['test'],['tests']
Testability,"This happens when there was no read in the same length bin during training period (the first so many reads are used for training) as the read under consideration. So Salmon can't assigned a valid log likelihood and an error is reported. The 3 errors are really the same one. The error log likelihood of 3 models are added (based on position of first mismatch/indel, length of clipping at each end of the read). If the length bin is empty for 1 model, it is likely empty for the other 2 models, and 3 warnings are printed when 1 would have been enough. This read gets a error likelihood of 1 and is mostly ignored by Salmon after that. Such reads should be rare by definition (unless the input BAM was not randomized, or there is bug) and this warning should be rare as well. So unless you see many such warnings, you can safely ignore it.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/701#issuecomment-1421264240:196,log,log,196,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/701#issuecomment-1421264240,2,['log'],['log']
Testability,"This is a question related to a strange message in the log out file after Salmon indexing on a very small genome with my own generated transcriptome and decoy. I'm running Salmon v1.0.0 index on the transcriptome of Candida parapsilosis which has a small genome of 26mbp. I created the transcriptome using Cufflinks gffread on my reference genome fasta and gff3. I created the decoy by concatenating the whole genome to the transcriptome [as it was described in the manual](https://salmon.readthedocs.io/en/latest/salmon.html#preparing-transcriptome-indices-mapping-based-mode). . I am running using the following options:. `salmon index -t gentrome.fa.gz -d decoys.txt -p 12 -i cpar_salmon_index -k 31; `. After indexing using a kmer size threshold of -k 31, I see the following message in the log out file ""filter size not provided. ntHll estimated 12754610 distinct k-mers, setting filter size to 2^28."" . 2^28 seems very high compared to 31 bp set using -k 31. I'm also curious why, after setting a k size, it printed the message ""filter size not provided."". I've pasted a more complete snippet of the log out file text below. Does everything look like it's run successfully? I'm concerned since I am running on a small genome and with my own generated decoy and transcriptome. Does it look like this running as it should, or is there a bug that I should provide more details about?. > [puff::index::jointLog] [info] Filter size not provided; ; > estimating from number of distinct k-mers; > [puff::index::jointLog] [info] ntHll estimated 1275461; > 0 distinct k-mers, setting filter size to 2^28; > Threads = 12; > Vertex length = 31; > Hash functions = 5; > Filter size = 268435456; > Capacity = 2; > Files: ; > cpar_salmon_index/ref_k31_fixed.fa; > --------------------------------------------------------------------------------; > Round 0, 0:268435456; > Pass	Filling	Filtering; > 1	0	8	; > 2	4	0; > True junctions count = 18712; > False junctions count = 40617; > Hash table size = 59329; > ",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/510:55,log,log,55,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/510,2,['log'],['log']
Testability,"This is an installation problem. I am getting a link-time error building Salmon 1.0.0 with GCC 7.3.0 and CMake 3.12.1. The error occurs immediately after ""[100%] Linking CXX executable salmon"". The OS is RHEL6. Here's the output:. ```; /software/Core/GCCcore/7.3.0/include/c++/7.3.0/bits/shared_ptr_base.h:522: error: undefined reference to 'vtable for std::_Sp_counted_ptr_inplace<spdlog::logger, std::allocator<spdlog::logger>, (__gnu_cxx::_Lock_policy)2>'; /software/Compiler/GCCcore/7.3.0/binutils/2.30/bin/ld.gold: the vtable symbol may be undefined because the class is missing its key function; /software/Compiler/GCCcore/7.3.0/binutils/2.30/bin/ld.gold: the symbol should have been defined by a plugin; /software/Core/GCCcore/7.3.0/include/c++/7.3.0/bits/shared_ptr_base.h:522: error: undefined reference to 'vtable for std::_Sp_counted_ptr_inplace<spdlog::async_logger, std::allocator<spdlog::async_logger>, (__gnu_cxx::_Lock_policy)2>'; /software/Compiler/GCCcore/7.3.0/binutils/2.30/bin/ld.gold: the vtable symbol may be undefined because the class is missing its key function; /software/Compiler/GCCcore/7.3.0/binutils/2.30/bin/ld.gold: the symbol should have been defined by a plugin; ```. Googling this error implies an issue with the code, not a missing library.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/455:390,log,logger,390,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/455,2,['log'],['logger']
Testability,"This is failing on our local drone CI during runtime. The log output is :. ```; + echo ""[Testing quant]""; [Testing quant]; + ./.drone/test_quant.sh; Holy build box activated; Prefix: /hbb_exe; CFLAGS: -g -O2 -fvisibility=hidden -I/hbb_exe/include ; LDFLAGS: -L/hbb_exe/lib -static-libstdc++; STATICLIB_CFLAGS: -g -O2 -fvisibility=hidden -I/hbb_exe/include ; SHLIB_CFLAGS: -g -O2 -fvisibility=hidden -I/hbb_exe/include ; SHLIB_LDFLAGS: -L/hbb_exe/lib -static-libstdc++; [Drone test] current path : /drone/src/github.com/COMBINE-lab/salmon; [Drone test] making quant test directory; [Drone test] run nextflow pipeline; N E X T F L O W ~ version 0.29.1; Launching `tests/test_quant.nf` [curious_gilbert] - revision: 4f25b30301; [warm up] executor > local; [91/922fac] Submitted process > buildIndex; ERROR ~ Error executing process > 'buildIndex'; Caused by:; Process `buildIndex` terminated with an error exit status (127); Command executed:; /drone/src/github.com/COMBINE-lab/salmon/bin/salmon index -t Homo_sapiens.GRCh37.75.cdna.pc.fa -i nfindex; Command exit status:; 127; Command output:; (empty); Command error:; /drone/src/github.com/COMBINE-lab/salmon/bin/salmon: error while loading shared libraries: libjemalloc.so.2: cannot open shared object file: No such file or directory; Work dir:; /drone/src/github.com/COMBINE-lab/salmon/work/91/922facec25da43edd4a2ce82f2289d; Tip: when you have fixed the problem you can continue the execution appending to the nextflow command line the option `-resume`; -- Check '.nextflow.log' file for detail; ```. So, it seems to be due to failure to find the dynamic shared library for jemalloc. Any idea why that might be?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/348#issuecomment-472495264:58,log,log,58,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/348#issuecomment-472495264,16,"['Test', 'log', 'test']","['Testing', 'log', 'test', 'tests']"
Testability,"This is not a bug but more of a question. I've run Salmon in alignment mode with transcriptome BAM file generated by STAR. The BAM file contains no unaligned reads. My question is there are often a small number of reads that were not assigned to any rich equivalence class. I am trying to understand what these reads are. I notice that this only happens when the input is paired-end reads. I suspect maybe the unassigned reads are dovetail paired end reads, but I don't know. The `--allowDovetail` option is not available in alignment mode. Here is an excerpt of the log:; ```; Completed first pass through the alignment file.; Total # of mapped reads : 6205189; # of uniquely mapped reads : 1718004; # ambiguously mapped reads : 4487185. [2024-08-14 18:21:52.491] [jointLog] [info] Computed 350358 rich equivalence classes for further processing; [2024-08-14 18:21:52.491] [jointLog] [info] Counted 6192944 total reads in the equivalence classes; ```; As you can see 6192944 out of 6205189 reads were assigned to rich equivalence classes.; It would be nice to know what the excluded reads are, and/or if there are options to rescue these reads, similar to `--allowDovetail`.; This is Salmon version 1.10.3, but I also ran older version, which generated same results.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/952:567,log,log,567,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/952,1,['log'],['log']
Testability,"This is related to https://github.com/COMBINE-lab/salmon/issues/272. * Now there are 2 test cases on Travis CI, adding one case.; * Added code for speed up such as `git - depth: 1`, `make -j 4`.; * Refactoring. Removed tailing spaces. Notes:; * I added `gcc-5`'s case as maybe it is minimal support version of gcc for this project.; * I want to replace current case `gcc-7` to latest version `gcc-8` if you like.; * Total running time (""Ran for"" on the Travis page.) becomes faster than current situation. In my repository, total running time is ""15 min 11 sec"", seeing current master branch's test is around 17 min+. See [1]; * Removed `travis_wait`. Without the command, the default behavior is ""when a long running command or compile step regularly takes longer than 10 minutes without producing any output"". [2] I have not faced the situation when I did debug. ; * There are commented out area at the bottom of `.travis.yml`. However as we can run `git log -p .travis.yml` to check past modification, shall we remove the commented out ""whitelist"" area?. [1] https://travis-ci.org/junaruga/salmon/builds/417976633; [2] https://docs.travis-ci.com/user/common-build-problems/#build-times-out-because-no-output-was-received",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/273:87,test,test,87,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/273,3,"['log', 'test']","['log', 'test']"
Testability,"This is the initial output log, where it reports an inccorrect gene annotation:. ---; Version Info: This is the most recent version of salmon.; -----------------------------------------; | Loading contig table | Time = 13.512 s; -----------------------------------------; size = 16145665; -----------------------------------------; | Loading contig offsets | Time = 382.03 ms; -----------------------------------------; -----------------------------------------; | Loading reference lengths | Time = 9.4861 ms; -----------------------------------------; -----------------------------------------; | Loading mphf table | Time = 2.4236 s; -----------------------------------------; size = 1057188904; Number of ones: 16145664; Number of ones per inventory item: 512; Inventory entries filled: 31535; -----------------------------------------; | Loading contig boundaries | Time = 4.031 s; -----------------------------------------; size = 1057188904; -----------------------------------------; | Loading sequence | Time = 1.983 s; -----------------------------------------; size = 572818984; -----------------------------------------; | Loading positions | Time = 14.658 s; -----------------------------------------; size = 942318702; -----------------------------------------; | Loading reference sequence | Time = 1.4932 s; -----------------------------------------; -----------------------------------------; | Loading reference accumulative lengths | Time = 10.959 ms; -----------------------------------------; Error: invalid feature coordinates (end<start!) at line:; NC_029855.1	RefSeq	gene	406748	107842	.	+	.	gene_id ""A5N79_gp28""; db_xref ""GeneID:27215502""; exception ""trans-splicing""; gbkey ""Gene""; gene ""nad2""; gene_biotype ""protein_coding""; locus_tag ""A5N79_gp28""; ; --- . After I remove the erroneous entry, there is no more complaint:. ---; Version Info: This is the most recent version of salmon.; -----------------------------------------; | Loading contig table | Time = 14.648 s; -----",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/569#issuecomment-709699746:27,log,log,27,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/569#issuecomment-709699746,1,['log'],['log']
Testability,"This pull-request is for develop branch.; This fixes https://github.com/COMBINE-lab/salmon/issues/275 . The reason of the build error was because b2 was always built with ""gcc"".; I added something like below code. ```; echo ""using gcc : ${CC_VERSION} : ${CMAKE_CXX_COMPILER} ;"" > ${CMAKE_CURRENT_SOURCE_DIR}/external/boost_1_66_0/tools/build/src/user-config.jam. /path/to/b2 .. toolset=${CC} ...; ```; ; There are still challenges to fix it. 1. The `make test` was finished with timeout. When setting `travis_wait 30 make test`, still failed with the timeout. Maybe we need to change the unit test logic to output something (log or progress bar) regularly to `stdout` during the test process or change the test logic itself. It is freezing at the below point. ```; /usr/local/cmake-3.9.2/bin/ctest --force-new-ctest-process ; Test project /home/travis/build/junaruga/salmon/build; Start 1: unit_tests; ```. 2. The `b2` parameter string `toolset=gcc-7 cxxflags=-std=c++14` is duplicated like this. Maybe we can change the logic in `CMakeLists.txt`. ```; CC=/usr/bin/gcc-7 CXX=/usr/bin/g++-7 /home/travis/build/junaruga/salmon/external/boost_1_66_0/b2 -d0 -j2 --with-iostreams --with-atomic --with-chrono --with-container --with-date_time --with-exception --with-filesystem --with-graph --with-graph_parallel --with-math --with-program_options --with-system --with-locale --with-timer toolset=gcc-7 toolset=gcc-7 cxxflags=-std=c++14 ""cxxflags= -std=c++14 -I/home/travis/build/junaruga/salmon/external/install/include -L/home/travis/build/junaruga/salmon/external/install/lib"" link=static install; ```. 3. `CMakeLists.txt` and `cmake/*.cmake` have a mixture of the different code formatting style. Aligning for formatting those make us read the files easier. I found the useful information for that. [1][2][3][4].; * 2 or 4 space indent?; * ""Tab"" indent is unintentionally used maybe.; * `set(...)` or `set (...)`.; * `set or SET`. [1] the KDE cmake coding style: https://community.kde.org/Policies/CMake",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/276:455,test,test,455,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/276,9,"['Test', 'log', 'test']","['Test', 'log', 'logic', 'test']"
Testability,"This seems to be a separate issue than the other (and a more informative exception). Once I've resolved the other issue, I would probably try to bug you for a sample that causes this --- though I have a reasonable idea about how to fix it. It would be nice to have the fix for both issues in the same hotfix. To be more specific : this is, as the exception says, a numeric underflow issue when evaluating the digamma function. The solution here is just to bump up the value that is required before evaluating this function. This should be straightforward, but I suspect the issue is also related to this log message:. > [2018-05-31 17:08:11.488] [jointLog] [info] Marked 1 weighted equivalence classes as degenerate",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393571565:604,log,log,604,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393571565,1,['log'],['log']
Testability,"Time = 3.3385 ms; -----------------------------------------. Segmentation fault (core dumped); ```. Output when the flag is off and the process finishes without the seg fault:; ```; Version Info: ### PLEASE UPGRADE SALMON ###; ### A newer version of salmon with important bug fixes and improvements is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; Sign up for the salmon mailing list to hear about new versions, features and updates at:; https://oceangenomics.com/subscribe; ### salmon (selective-alignment-based) v1.9.0; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /share/genomes/human/hg38/gencode_v43/primary_comprehensive/SalmonIndex }; ### [ libType ] => { A }; ### [ mates1 ] => { GSM7099349.R1.fastq }; ### [ mates2 ] => { GSM7099349.R2.fastq }; ### [ output ] => { salmon_out }; ### [ threads ] => { 1 }; Logs will be written to salmon_out/logs; [2023-11-30 09:36:58.680] [jointLog] [info] setting maxHashResizeThreads to 1; [2023-11-30 09:36:58.680] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2023-11-30 09:36:58.680] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2023-11-30 09:36:58.680] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.; [2023-11-30 09:36:58.680] [jointLog] [info] parsing read library format; [2023-11-30 09:36:58.680] [jointLog] [info] There is 1 library.; [2023-11-30 09:36:58.681] [jointLog] [info] Loading pufferfish index; [2023-11-30 09:36:58.681] [jointLog] [info] Loading dense pufferfish index.; -----------------------------------------; | Loading contig table | Time = 17.497 s; -----------------------------------------; size = 37303070; -----------------------------------------; |",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/902:5488,Log,Logs,5488,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/902,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"Type A ; -1 $read1 \; -2 $read2 \; -p 16 \; --validateMappings \; --gcBias \; --seqBias \; --recoverOrphans \; --rangeFactorizationBins 4 \; --output $outdir. **Expected behavior**; A clear and concise description of what you expected to happen.; Salmon quant to produce quant.sf file. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem.; ```shell; Version Info Exception: server did not respond before timeout; ### salmon (selective-alignment-based) v1.10.2; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /share/references/gencode/salmon_index }; ### [ libType ] => { A }; ### [ mates1 ] => { RNA_1.fastq.gz }; ### [ mates2 ] => { RNA_2.fastq.gz }; ### [ threads ] => { 16 }; ### [ validateMappings ] => { }; ### [ gcBias ] => { }; ### [ seqBias ] => { }; ### [ recoverOrphans ] => { }; ### [ rangeFactorizationBins ] => { 4 }; ### [ output ] => { salmon.standard/sample }; Logs will be written to salmon.standard/sample/logs; [2024-11-01 05:13:59.563] [jointLog] [info] setting maxHashResizeThreads to 16; [2024-11-01 05:13:59.563] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2024-11-01 05:13:59.563] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2024-11-01 05:13:59.563] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.; [2024-11-01 05:13:59.563] [jointLog] [info] parsing read library format; [2024-11-01 05:13:59.563] [jointLog] [info] There is 1 library.; [2024-11-01 05:13:59.563] [jointLog] [info] Loading pufferfish index; [2024-11-01 05:13:59.563] [jointLog] [info] Loading dense pufferfish index.; -----------------------------------------; | Loading contig table | Time = 10.554 s; -----------------------------------------; size = 37302779; -----------------------------------------; | Loading contig offsets | Time = 91.707 ms;",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/971:2029,log,logs,2029,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/971,1,['log'],['logs']
Testability,"UPDATE: On @rob-p 's suggestion, I removed the `--recoverOrphans` option and then all 60 samples did finished without segfaulting. Perhaps there were too many orphans to handle - alignments rates were a dismal 0.5-23%. These were heavily degraded samples that the sequencing center recommended not to sequence but the PI wanted to try it anyway. If you want a pair of fastq files (full or cutdown to ~5 M reads) to test this weird edge case, I can see about getting them to you. Thanks!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/668#issuecomment-862525216:415,test,test,415,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/668#issuecomment-862525216,1,['test'],['test']
Testability,"URE=FALSE -DBOOST_WILL_RECONFIGURE=FALSE; $ make; $ tar xaf sample_data.tgz; $ src/salmon index -t sample_data/transcripts.fasta -i sample_salmon_quasi_index; Version Info: This is the most recent version of salmon.; [2023-03-08 17:30:38.873] [jLog] [warning] The salmon index is being built without any decoy sequences. It is recommended that decoy sequence (either computed auxiliary decoy sequence or the genome of the organism) be provided during indexing. Further details can be found at https://salmon.readthedocs.io/en/latest/salmon.html#preparing-transcriptome-indices-mapping-based-mode.; [2023-03-08 17:30:38.873] [jLog] [info] building index; out : sample_salmon_quasi_index; [2023-03-08 17:30:38.873] [puff::index::jointLog] [info] Running fixFasta; ; [Step 1 of 4] : counting k-mers; ; [2023-03-08 17:30:38.879] [puff::index::jointLog] [info] Replaced 0 non-ATCG nucleotides; [2023-03-08 17:30:38.879] [puff::index::jointLog] [info] Clipped poly-A tails from 0 transcripts; wrote 15 cleaned references; Segmentation fault. * Version 1.9.0 as well as version 1.10.0 are affected. Unfortunately we did not managed to package version 1.7.0 and 1.8.0 but I confirm that version 1.6.0 was not affected by the described problem.; * Salmon was build as Debian package as well as built from source (see above); * The reference was taken from the `sample_data` shipped with the release tarball. **Expected behavior**; Clean processing without SEGFAULT. **Desktop (please complete the following information):**; - OS: Debian (testing or unstable). **Additional context**; * You can find some debug logs inside the [Debian bug log](https://bugs.debian.org/1028713). ; * There is a build log which includes the said salmon call above as [build time test](https://salsa.debian.org/med-team/salmon/-/jobs/4031000); * When ignoring the package build time test the [Continuous Integration log](https://salsa.debian.org/med-team/salmon/-/jobs/3980059) might be interesting as well. Kind regards, Andreas.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835:2410,test,testing,2410,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835,7,"['log', 'test']","['log', 'logs', 'test', 'testing']"
Testability,"Uh, why then does ""make test"" fail if the root directory name is changed? That was using the binary/libraries in $WHEREVER, after bin and lib below the root directory were removed. Typically that sort of operation doesn't care what the top level is named. For some future release, perhaps the run time dynamic loading of libraries could look up the path to libtbb.so.2 and try that first, before falling back to LD_LIBRARY_PATH? On my system ldd of salmon shows a link to libtbb.so.2, no LD_LIBRARY_PATH needed. ldd does not show any links to libtbb.malloc*. The program will do at least ""salmon --help' that way without any errors or warnings. That isn't sufficient to pass ""make test"" though (even when the directory has not been renamed). It seems that libtbb.malloc* libraries are used during that test, and that use requires LD_LIBRARY_PATH. Only when they are found that way does ""make test"" work.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-397063656:24,test,test,24,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-397063656,4,['test'],['test']
Testability,"Unfortunately, I don't necessarily have a great data set to test on, since my motivation for requesting this feature was that I'm working on a single-end dataset.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/83#issuecomment-246164908:60,test,test,60,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/83#issuecomment-246164908,1,['test'],['test']
Testability,Unit tests with `make test` not finding `libtbb.so.12`,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/845:5,test,tests,5,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/845,2,['test'],"['test', 'tests']"
Testability,Update .travis.yml to add test case easily.,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/273:26,test,test,26,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/273,1,['test'],['test']
Testability,"Version 0.7.1 seems to refer to ""SF"" libtype as just ""F"". Maybe this is an abbreviation done on purpose since ""F"" alone necessarily implies ""stranded"" but I think that can be confusing. Moreover, in lib_format_counts.json file, both ""F"" and ""SF"" are listed, but only ""F"" gets counts whereas ""SF"" is 0. ""F"" is not recognized as a valid library type for the parameter `-l`, only ""SF"" is (as expected). I haven't tested it but the same probably happens with ""R"" and ""SR"".",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/82:410,test,tested,410,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/82,1,['test'],['tested']
Testability,Version 1.5.2 downloaded binary for linux system from GitHub. Judging but the length of the log output I do not think this applies to all alignments but certainly some alignments give the example output:. ```; [2021-09-08 15:37:54.395] [jointLog] [warning] read 88:4979|5fc1333a-4512-4baf-bc46-07f3b1a3ca5d (length 4891 - align length 4731) has no trained error model; [2021-09-08 15:37:54.395] [jointLog] [warning] read 88:4979|5fc1333a-4512-4baf-bc46-07f3b1a3ca5d (length 4891) has no trained clipping model; [2021-09-08 15:37:54.395] [jointLog] [warning] read 88:4979|5fc1333a-4512-4baf-bc46-07f3b1a3ca5d (length 4891) has no trained clipping model; ```. Code to run salmon quant mode:; ```; salmon-1.5.2_linux_x86_64/bin/salmon quant -p 4 --ont -t Genome_files/gencode.v37.transcripts.fa -l SF -a /analysisdata/rawseq/fastq/SHARED/000081/Interactome_project_ONT-CAGE/iPSC_rep1/run1/alignment/Fantom6_iPSC_rep1_run1_pass_transcriptome.bam -o /analysisdata/rawseq/fastq/SHARED/000081/Interactome_project_ONT-CAGE/iPSC_rep1/run1/salmon_quant; ```. Was wondering if I can ignore these errors?,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/701:92,log,log,92,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/701,1,['log'],['log']
Testability,"Version Info Exception: server did not respond before timeout; Logs will be written to /public/home/name/workspace/scRNA_APA/labratsc/output/tissues/dedup_Microvascular_endothelial_cells_of_adipose_tissue_2/logs; [2023-06-19 16:31:27.810] [jointLog] [info] setting maxHashResizeThreads to 12; [2023-06-19 16:31:27.811] [jointLog] [info] The --mimicBT2, --mimicStrictBT2 and --hardFilter flags imply mapping validation (--validateMappings). Enabling mapping validation.; [2023-06-19 16:31:27.814] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2023-06-19 16:31:27.814] [jointLog] [info] The use of range-factorized equivalence classes does not make sense in conjunction with --hardFilter. Disabling range-factorized equivalence classes. ; [2023-06-19 16:31:27.814] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.; [2023-06-19 16:31:27.816] [jointLog] [info] Using default value of 0.87 for minScoreFraction in Alevin; Using default value of 0.6 for consensusSlack in Alevin; [2023-06-19 16:31:27.888] [alevinLog] [info] Found 39363 transcripts(+0 decoys, +0 short and +0 duplicate names in the index); ### alevin (dscRNA-seq quantification) v1.10.1; ### [ program ] => salmon ; ### [ command ] => alevin ; ### [ libType ] => { ISR }; ### [ mates1 ] => { /public/home/name/workspace/data/tissues/dedup_fastq/dedup_Microvascular_endothelial_cells_of_adipose_tissue_2_R1.fastq.gz }; ### [ mates2 ] => { /public/home/name/workspace/data/tissues/dedup_fastq/dedup_Microvascular_endothelial_cells_of_adipose_tissue_2_R2.fastq.gz }; ### [ chromiumV3 ] => { }; ### [ index ] => { /public/home/name/workspace/scRNA_APA/labratsc/output/tissues/txfasta.idx }; ### [ threads ] => { 12 }; ### [ output ] => { /public/home/name/workspace/scRNA_APA/labratsc/output/tissues/dedup_Microvascular_endothelial_cells_of_adipose_tissue_2 }; ### [ tgMap ] => { /public/home/name/workspace/scRNA_APA/lab",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/853:63,Log,Logs,63,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/853,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"Very strange, I'd like to start with first apologizing for relatively poor documentation for all these meta files (`MappedUMI`) and I think that's the point of confusion. The expected behavior is as follows:; * `--dumpFeature` dumps various meta files like `filtered_cb_frequency.txt` which gives number of reads in each CB after sequence correction and `MappedUMI,txt` which is a subset of reads from the `filtered_cb_frequency.txt` which are mapped by alevin and should be reflective of the mapping rate.; * `--dumpUmiGraph` dumps the internal graphical structure used by alevin for deduplication. Having said that, I was curious that the sum of count in the `MappedUMI.txt` is coming out to be 17M. I tested the same at my end and it's coming out to be ~200M . I am puzzled why the counts are so low for your run, can you please double check if alevin has finished ? It seems the behavior you are observing in the CEL-seq data is the right one. For counting the number of mapped reads use the file `MappedUMI.txt` and for counting number of deduplicated reads use `quants_mat.gz`.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/361#issuecomment-490105924:704,test,tested,704,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/361#issuecomment-490105924,1,['test'],['tested']
Testability,"We do no have access to BSD-based systems (apart from the extent to which OSX can be said to be BSD-based) on which to test during development. Bioconda works on many linux distributions; though I do not have a comprehensive list. For example, we regularly run on Ubuntu, CentOS, RedHat and Debian. If you have the facilities to use Docker on this machine, you can also pull down a docker image of the latest release from https://hub.docker.com/r/combinelab/salmon.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/419#issuecomment-522628674:119,test,test,119,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/419#issuecomment-522628674,1,['test'],['test']
Testability,"We have a partly assembled genome with some almost identical gene modes which can be either allele or paralogs. Usually there are only a few nuclear tide differences between them. We expected Salmon return similar expression levels for these similar genes. However, it came out one gene had normal counts(in my case it was roughly 12,000 mapping reads) and another gene got zero in mapping read counts. I guess Salmon re-assigned read counts between highly similarly genes based on estimated mapping quality. In addition, the same gene model would get significantly different counts across runs due to the re-assignment, which made thing worse. I also tested RSEM and found the similar problem. I noticed the RSEM set the column #5 (mapping quality) in BAM from upstream mapping pipeline which might be reason for this issue. The third software I tried is eXpress which assigns mapping counts evenly between similar genes. . My suggestion is to allow users to switch off the re-assignment between similar genes.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/107:652,test,tested,652,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/107,1,['test'],['tested']
Testability,"We might have to go through the paper and the dropseq guidelines to check what really changed.; You might wanna check https://github.com/COMBINE-lab/salmon/issues/247, we actually have a hidden option to do customized umi/CB length options, however this goes into a little more unexplored territory and requires a bit more testing. We'd appreciate your feedback if you happen to run this mode.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/258#issuecomment-408191888:323,test,testing,323,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/258#issuecomment-408191888,2,['test'],['testing']
Testability,"We shy away from using `native` arch anywhere, and instead try to be explicit about the instruction sets used. My current best guess is that we assume SSE4 (at least [here](https://github.com/COMBINE-lab/pufferfish/blob/master/CMakeLists.txt#L77)). I believe this processor does not fully support SSE4.0. I can try and see if there are any other places we make this assumption, and then perhaps make a test pre-compiled binary without it.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/500#issuecomment-610580721:402,test,test,402,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/500#issuecomment-610580721,1,['test'],['test']
Testability,"We use Salmon a lot in my lab. It's a great tool. **Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**; I am running salmon quant using dockerImg ""quay.io/biocontainers/salmon:1.4.0--hf69c8f4_0"", i.e. salmon (selective-alignment-based) v1.4.0. **Describe the bug**; When I run salmon I exits with an error code of 137. any idea what this means? I also noticed that the output directory is not created. **To Reproduce**; I am running the container on app.terra.bio, unfortunately, I can not share the workspace because the data is from identifiable human subjects. Bellow, I include the log file showing how I ran salmon. I think the bug may have something to do with the run time environment. Know what salmon exit codes mean would really help me figure out where my bug is. Specifically, please provide at least the following information:. * Which version of salmon was used?; 1.4.0; * How was salmon installed (compiled, downloaded executable, through bioconda)?; dockerImg ""quay.io/biocontainers/salmon:1.4.0--hf69c8f4_0"",; * Which reference (e.g. transcriptome) was used?; we have a custom reference based on g35. ; * Which read files were used?; * Which which program options were used?; * . **Expected behavior**; A clear and concise description of what you expected to happen. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX]; - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux the output of `uname -a` and `lsb_release -a`]. **Additional context**; Add any other context about the problem here. ```; + mkdir -p salmon.out; + salmon quant -i sel.align.gencode.v35.ucsc.rmsk.salmon.v1.3.0.sidx --libType A -1 /cromwell_root/fc-secure-519db2bc-049f-43a0-ab75-a2eb9c2cb059/6a6c9b92-3026-47d3-8944-60f0842c566e/samToFastqTest/5f578d2f-7e74-4402-955a-4d4623b83ead/call-samToFastq/GTEX-111CU-0526-SM-5EGHK.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/641:618,log,log,618,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/641,1,['log'],['log']
Testability,"We were given some test data - ~400,000 150 PE on two samples from a MiSeq run on a mosquito. They wanted to know recommended sequencing depth and whether they needed 150 PE or if they could get away with 100 SE. There is a decent-ish genome and transcriptome for the species (https://www.ncbi.nlm.nih.gov/genome/?term=aedes+albopictus), so we ran the 150 PE and artificially created 100 SE from R1 through our pipeline, which includes STAR plus Salmon. The STAR results were expected: 100 SE had ~40% mulitmapping / ~48% unique in genes and 150 BP improved to ~30% multimapping / ~57% unique in genes. Surprisingly, Salmon showed the opposite: 100 SE had a ~70% mapping rate while 150 PE has only a ~57% mapping rate. . We thought at first that Salmon maybe wasn't counting fragments if both ends didn't map but the answer in issue #31 says Salmon should be counting single-end mapped towards quantification. The first line in the salmon_quant.log file says ""Fragment incompatibility prior below threshold. Incompatible fragments will be ignored."" I couldn't find much in salmon quant --help-reads about fragment priors and then I found it was in pretty much all salmon_quant.logs we have, so that may not be the problem. We also thought the trouble may have something to do with the small number of fragments, so we ran through some mouse 150 PE + artificial 100 SE, that had 40M reads and also subsampled to 400K reads, but the salmon mapping rates were pretty much the same (~75%) regardless of type/length of reads or sequencing depth. So what do you think could be going on? I am worried that Salmon's ""better"" mapping percentage of 100 SE is not accurately measuring expression. We didn't test 150 SE because that is not a sequencing option with NovaSeq, but we could try it if you think it would help to figure out what is going on. Thanks,; Jenny",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/349:19,test,test,19,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/349,4,"['log', 'test']","['log', 'logs', 'test']"
Testability,"Well, it doesn't matter how long the log is, since we only need the last line, right?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267842175:37,log,log,37,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267842175,1,['log'],['log']
Testability,Well... `./src/unitTests` seems to always pass and `make test` to always fail...,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393689032:57,test,test,57,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393689032,1,['test'],['test']
Testability,"When I do with proxy I got : . ```; Last login: Thu Jun 30 15:10:26 on ttys001; Benjamin@u932-ulm-2-57030119-6834 ~ % all_proxy= url:port conda install salmon; Collecting package metadata (current_repodata.json): failed. # >>>>>>>>>>>>>>>>>>>>>> ERROR REPORT <<<<<<<<<<<<<<<<<<<<<<. Traceback (most recent call last):; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/exceptions.py"", line 1082, in __call__; return func(*args, **kwargs); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/cli/main.py"", line 87, in _main; exit_code = do_call(args, p); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/cli/conda_argparse.py"", line 84, in do_call; return getattr(module, func_name)(args, parser); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/cli/main_install.py"", line 20, in execute; install(args, parser, 'install'); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/cli/install.py"", line 260, in install; unlink_link_transaction = solver.solve_for_transaction(; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/solve.py"", line 152, in solve_for_transaction; unlink_precs, link_precs = self.solve_for_diff(update_modifier, deps_modifier,; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/solve.py"", line 195, in solve_for_diff; final_precs = self.solve_final_state(update_modifier, deps_modifier, prune, ignore_pinned,; File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/solve.py"", line 300, in solve_final_state; ssc = self._collect_all_metadata(ssc); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/common/io.py"", line 88, in decorated; return f(*args, **kwds); File ""/usr/local/Caskroom/miniforge/base/lib/python3.9/site-packages/conda/core/solve.py"", line 463, in _collect_all_metadata; index, r = self._prepare(prepared_specs); File ""/usr/local/Ca",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515:41,log,login,41,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171208515,1,['log'],['login']
Testability,"When using the -z option to obtain a SAM file and using that same SAM file as an input for a quantification, the following error is thrown:. ```; Version Info: This is the most recent version of salmon.; # salmon (alignment-based) v1.1.0; # [ program ] => salmon ; # [ command ] => quant ; # [ targets ] => { ../../gencode.v32.transcripts.fa }; # [ libType ] => { A }; # [ alignments ] => { sal.bam }; # [ output ] => { salsal }; Logs will be written to salsal/logs; [2019-12-20 16:29:27.435] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; Library format { type:paired end, relative orientation:inward, strandedness:unstranded }; parseThreads = 4; [2019-12-20 16:29:27.723] [jointLog] [info] numQuantThreads = 4; Checking that provided alignment files have consistent headers . . . done; Populating targets from aln = ""sal.bam"", fasta = ""../../gencode.v32.transcripts.fa"" . . . SAM file says target ENST00000481276.1|ENSG00000189339.12|OTTHUMG00000078639.4|OTTHUMT00000171590.1|SLC35E2B-202|SLC35E2B|2199|retained_intron| has length 2184, but the FASTA file contains a sequence of length [2200 or 2199]; ```. For this transcript the correct length is indeed 2199. The same error occurs when using a RapMap-produced SAM. OS is Ubuntu 18.04, salmon version 1.1.0",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/465:430,Log,Logs,430,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/465,2,"['Log', 'log']","['Logs', 'logs']"
Testability,While Bioconda is working on resolving the issue for osx deployment of salmon (>v10.2). the following binary can be used for osx based testing of Salmon/Alevin. Note: The code has been compiled on Osx High Sierra (v 10.13.2) and can potentially create problem with other versions of osx.,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/260:135,test,testing,135,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/260,1,['test'],['testing']
Testability,"Whoaa! Ok. This is something. It's hanging in a place where we have no client (i.e., Salmon) threading code. It's inside an Intel TBB for loop. But, according to gdb, the TBB libraries that are executing at this point are system ones (/usr/lib/x86_64-linux-gnu/libtbb.so.2). Also interesting is that the full backtrace is into a call to the logarithm function, which shouldn't block. Could you spin up another Salmon process but with Salmon's copy of TBB in the LD_LIBRARY_PATH before the system one, just to make sure that's not the issue? It's likely not, but it's worth being sure. Whatever ends up causing this, I have a feeling it will be something very strange.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267491370:341,log,logarithm,341,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267491370,1,['log'],['logarithm']
Testability,"Yea, so Drop-seq data tends to be a bit more noisier than 10x, at least in my experience. ; I had a quick look at the logs and it seems the ""knee"" method is under estimating a bit. I highly recommend playing with the alevin flags from the discussion I forwarded, I think it should work fine with `--expectCells 3000` or `--forceCells 3000`. You can check and process the featureDump file from the alevin if you use `--dumpFeatures` flag to choose the number of barcodes to provide in the expectCells or forceCells command.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/625#issuecomment-776205702:118,log,logs,118,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/625#issuecomment-776205702,1,['log'],['logs']
Testability,"Yeah, I haven't heard back yet. Any test case is fine where the data is publicly accessible. Thanks.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-983999718:36,test,test,36,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-983999718,1,['test'],['test']
Testability,"Yep that sounds reasonable to me.; In case you wan't to avoid multiple round of alevin runs, the idea in the develop branch is to use `--freqThreshold 0 --maxNumBarcodes 4294967295 --keepCBFraction 0.95` i.e. maxNumBarcodes is almost infinity which will force alevin to consider all CB for processing while keeping 95% of the CB as high confidence and hopefully the last 5% would be `>200` CBs which will make alevin run whitelisting. Thanks again for testing alevin and its features !",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/379#issuecomment-503624687:452,test,testing,452,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/379#issuecomment-503624687,1,['test'],['testing']
Testability,"Yep, check this line in the log:; > Total 41.2673% reads will be thrown away because of noisy Cellular barcodes. I think the CB frequency is most probably a bimodal distribution, I'd suggest you to try `--expectCells 8000` command line flag along with the regular command you are using above and check if the numbers in the log comes down to `~15%`.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/396#issuecomment-510549172:28,log,log,28,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/396#issuecomment-510549172,2,['log'],['log']
Testability,"Yes ! it's other error that I can't find . but I try : . ```; Last login: Thu Jun 30 15:14:51 on ttys002; Benjamin@u932-ulm-2-57030119-6834 ~ % conda config --add channels defaults; conda config --add channels bioconda; conda config --add channels conda-forge; Warning: 'conda-forge' already in 'channels' list, moving to the top; Benjamin@u932-ulm-2-57030119-6834 ~ % conda install salmon; Collecting package metadata (current_repodata.json): failed. CondaHTTPError: HTTP 000 CONNECTION FAILED for url <https://conda.anaconda.org/conda-forge/osx-arm64/current_repodata.json>; Elapsed: -. An HTTP error occurred when trying to retrieve this URL.; HTTP errors are often intermittent, and a simple retry will get you on your way.; 'https://conda.anaconda.org/conda-forge/osx-arm64'; ```. ```; Benjamin@u932-ulm-2-57030119-6834 ~ % conda config --show channels ; channels:; - conda-forge; - bioconda; - defaults; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171223414:67,log,login,67,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171223414,2,['log'],['login']
Testability,"Yes, @rob-p! It's an improvement from ~33% to ~19% slower (I'm not sure why sd is high for custom testing though). Yeah, I'm eager to hear your views too, @gmarcais.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1023351185:98,test,testing,98,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1023351185,1,['test'],['testing']
Testability,"Yes, all have entry in the *.fa file but are missing from *.gtf file. > grep ""ENST00000615101"" Homo_sapiens.GRCh38.87.cdna.ncrna.fa; >ENST00000615101 ncrna chromosome:GRCh38:CHR_HSCHR15_4_CTG8:30951585:30951821:1 gene:ENSG00000276152 gene_biotype:misc_RNA transcript_biotype:misc_RNA gene_symbol:Metazoa_SRP description:Metazoan signal recognition particle RNA [Source:RFAM;Acc:RF00017]. >grep ""ENST00000615101"" Homo_sapiens.GRCh38.87.gtf; > NA. Did you ever test salmon using ENSEMBL build?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/122#issuecomment-283461979:459,test,test,459,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/122#issuecomment-283461979,1,['test'],['test']
Testability,"Yes, this is a set of transcripts assembled using a few different Trinity and Velvet/Oases protocols, merged together. I'm testing reduction with different tools along with relative abundance estimation.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-204098008:123,test,testing,123,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/54#issuecomment-204098008,1,['test'],['testing']
Testability,"You can pull from this commit sha on develop to test the equivalent changes on that branch `bd7096e0fa055e0a71ab03a52d99977bcb61c905`. If this works, I think I'm pretty much good to go for the release. Just doing some last minute clean up and finishing up the release notes.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/70#issuecomment-239632891:48,test,test,48,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/70#issuecomment-239632891,1,['test'],['test']
Testability,You can see the added cmake file lint test case as allowed failures on Travis here.; It's good to see how the `cmakelint` works.; https://travis-ci.org/COMBINE-lab/salmon/builds/427929967,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/293#issuecomment-421432387:38,test,test,38,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/293#issuecomment-421432387,1,['test'],['test']
Testability,"You do not need a different transcriptome for each readset. Your general workflow should be... 1. prepare a transcriptome in fasta format; 2. For each sample, align that sample to the transcriptome to create a bam file using hisat2 and samtools; 3. For each bam file, run salmon quant using that bam file and the transcriptome as input; 4. merge output using salmon quantmerge; . ...I'm curious why you are using hisat2 though. Every benchmark I've seen suggests that just using salmons psuedo-mapper works just as well.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/740#issuecomment-1139144572:434,benchmark,benchmark,434,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/740#issuecomment-1139144572,1,['benchmark'],['benchmark']
Testability,"Yup, but I'm just trying to work backward. That is, first figure out what's going on with the `minEqWeight` error, and then figure out if that's related to what was causing it to hang. The issue right now is just that I can't seem to easily repro either Gibbs error. I just ran using the binary you compiled with the following command, and got this output:. ```; $LD_LIBRARY_PATH=~/SoftwareStaging/salmon/lib:$LD_LIBRARY_PATH ./salmon quant --index Salmon_index_hg38.analysisSet_knownGene --unmatedReads SRR2454059.fq.gz --libType ISF --us; eVBOpt --output test_quant --numGibbsSamples 100 --threads 16; Version Info: This is the most recent **development version** of Salmon.; ### salmon (mapping-based) v0.7.3; ### [ program ] => salmon; ### [ command ] => quant; ### [ index ] => { Salmon_index_hg38.analysisSet_knownGene }; ### [ unmatedReads ] => { SRR2454059.fq.gz }; ### [ libType ] => { ISF }; ### [ useVBOpt ] => { }; ### [ output ] => { test_quant }; ### [ numGibbsSamples ] => { 100 }; ### [ threads ] => { 16 }; Logs will be written to test_quant/logs; [2016-12-13 22:44:07.409] [jointLog] [info] parsing read library format; [2016-12-13 22:44:07.409] [jointLog] [info] There is 1 library.; [2016-12-13 22:44:09.318] [jointLog] [info] Loading Quasi index; [2016-12-13 22:44:09.318] [jointLog] [info] Loading 32-bit quasi index; [2016-12-13 22:44:09.318] [stderrLog] [info] Loading Suffix Array; [2016-12-13 22:44:15.002] [stderrLog] [info] Loading Transcript Info; [2016-12-13 22:44:16.278] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-12-13 22:44:16.625] [stderrLog] [info] There were 182608 set bits in the bit array; [2016-12-13 22:44:16.680] [stderrLog] [info] Computing transcript lengths; [2016-12-13 22:44:16.681] [stderrLog] [info] Waiting to finish loading hash; [2016-12-13 22:44:20.485] [stderrLog] [info] Done loading index; [2016-12-13 22:44:20.485] [jointLog] [info] done; [2016-12-13 22:44:20.485] [jointLog] [info] Index contained 182608 targets. processed 19000",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266935584:1024,Log,Logs,1024,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266935584,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"[ output ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX }; ) = 594; stat(""/etc/localtime"", {st_mode=S_IFREG|0644, st_size=3519, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX/logs"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX/logs"", 0x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, ...}) = 0; mkdir(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX/logs"", 0777) = 0; write(2, ""Logs will be written to "", 24Logs will be written to ) = 24; write(2, ""/dcl01/lieber/ajaffe/lab/libd_al""..., 81/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX/logs) = 81; write(2, ""\n"", 1; ) = 1; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX/libParams"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX/libParams"", 0x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, ...}) = 0; mkdir(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX/libParams"", 0777) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX/aux_info"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test1",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:67506,log,logs,67506,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"[ output ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX }; ) = 594; stat(""/etc/localtime"", {st_mode=S_IFREG|0644, st_size=3519, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX/logs"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX/logs"", 0x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, ...}) = 0; mkdir(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX/logs"", 0777) = 0; write(2, ""Logs will be written to "", 24Logs will be written to ) = 24; write(2, ""/dcl01/lieber/ajaffe/lab/libd_al""..., 81/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX/logs) = 81; write(2, ""\n"", 1; ) = 1; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX/libParams"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX/libParams"", 0x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, ...}) = 0; mkdir(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX/libParams"", 0777) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX/aux_info"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test1",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:106088,log,logs,106088,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"[BWTIncConstructFromPacked] 40 iterations done. 293988548 characters processed.; [BWTIncConstructFromPacked] 50 iterations done. 348084948 characters processed.; [BWTIncConstructFromPacked] 60 iterations done. 396161956 characters processed.; [BWTIncConstructFromPacked] 70 iterations done. 438888868 characters processed.; [BWTIncConstructFromPacked] 80 iterations done. 476860644 characters processed.; [BWTIncConstructFromPacked] 90 iterations done. 510606036 characters processed.; [BWTIncConstructFromPacked] 100 iterations done. 540594980 characters processed.; [BWTIncConstructFromPacked] 110 iterations done. 567245236 characters processed.; [BWTIncConstructFromPacked] 120 iterations done. 590928020 characters processed.; [bwa_index] 279.06 seconds elapse.; [bwa_index] Update BWT... 1.72 sec; [bwa_index] Pack forward-only FASTA... 1.90 sec; [bwa_index] Construct SA from BWT and Occ... 59.56 sec; [2018-06-25 19:34:53.084] [jLog] [info] done building index; ```. Doh, something unexpected from the logs, isn't it?. ```; $ ls -latr ftp.ensembl.org/pub/release-92/fasta/homo_sapiens/cdna/Homo_sapiens.GRCh38.cdna.all; total 8374704; drwx------. 3 mmokrejs mmokrejs 4096 Jun 25 19:25 ..; -rw-r--r--. 1 mmokrejs mmokrejs 36158409 Jun 25 19:26 rsd.bin; -rw-r--r--. 1 mmokrejs mmokrejs 423777 Jun 25 19:26 duplicate_clusters.tsv; -rw-r--r--. 1 mmokrejs mmokrejs 294997212 Jun 25 19:26 txpInfo.bin; -rw-r--r--. 1 mmokrejs mmokrejs 1157068836 Jun 25 19:26 sa.bin; -rw-r--r--. 1 mmokrejs mmokrejs 1779709484 Jun 25 19:29 hash.bin; -rw-r--r--. 1 mmokrejs mmokrejs 75 Jun 25 19:29 refInfo.json; -rw-r--r--. 1 mmokrejs mmokrejs 9816 Jun 25 19:29 quasi_index.log; -rw-r--r--. 1 mmokrejs mmokrejs 666 Jun 25 19:29 header.json; -rw-r--r--. 1 mmokrejs mmokrejs 304768324 Jun 25 19:33 bwaidx.bwt; -rw-r--r--. 1 mmokrejs mmokrejs 76192062 Jun 25 19:33 bwaidx.pac; -rw-r--r--. 1 mmokrejs mmokrejs 50007825 Jun 25 19:33 bwaidx.ann; -rw-r--r--. 1 mmokrejs mmokrejs 89 Jun 25 19:33 bwaidx.amb; drwxr-xr-x. 2 mm",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/242:15321,log,logs,15321,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/242,1,['log'],['logs']
Testability,[Proposal] Travis CI to add test case easily,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/272:28,test,test,28,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/272,1,['test'],['test']
Testability,"[SRR3212847.24133171] : proper-pair; mapped; matemapped; > ; > [2021-01-08 12:42:10.700] [jointLog] [warning] ; > ; > WARNING: Detected suspicious pair --- ; > The names are different:; > read1 : SRR3212847.33911054; > read2 : SRR3212847.30781941; > ; > Segmentation fault (core dumped); > ```; > ; > ### 3. Sorting with `samtools sort -n`; > ```; > samtools sort \; > -@ 40 \; > -n \; > -o SRR3212847.Aligned.SortedByName.bam \; > SRR3212847.Aligned.SortedByCoord.bam; > ; > salmon quant \; > -t mRNA.fasta \; > -p 20 \; > -l A \; > -a SRR3212847.Aligned.SortedByName.bam \; > -o SRR3212847.Aligned.SortedByName; > ```; > ; > ```; > Version Info: This is the most recent version of salmon.; > # salmon (alignment-based) v1.4.0; > # [ program ] => salmon ; > # [ command ] => quant ; > # [ targets ] => { mRNA.fasta }; > # [ threads ] => { 20 }; > # [ libType ] => { A }; > # [ alignments ] => { SRR3212847.Aligned.SortedByName.bam }; > # [ output ] => { SRR3212847.Aligned.SortedByName }; > Logs will be written to SRR3212847.Aligned.SortedByName/logs; > [2021-01-08 13:02:04.845] [jointLog] [info] setting maxHashResizeThreads to 20; > [2021-01-08 13:02:04.845] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; > Library format { type:paired end, relative orientation:inward, strandedness:unstranded }; > [2021-01-08 13:02:04.878] [jointLog] [info] numQuantThreads = 14; > parseThreads = 6; > Checking that provided alignment files have consistent headers . . . done; > Populating targets from aln = ""SRR3212847.Aligned.SortedByName.bam"", fasta = ""mRNA.fasta"" . . .done; > ; > processed 0 reads in current roundSegmentation fault (core dumped); > ```; > ; > (Which is the same as the 1st error. Actually, each time I re-run those two errors switched.); > ; > I tried running Salmon on the sorted-by-coordinates bam, and it didn't fail:; > ; > ```; > nohup salmon quant \; > -t mRNA.fasta \; > -p 20 \; > -l A \; > -a SRR3212847.Aligned.Sorte",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/582#issuecomment-1343749456:3811,Log,Logs,3811,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/582#issuecomment-1343749456,1,['Log'],['Logs']
Testability,"[info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2021-07-16 11:47:01.372] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.; [2021-07-16 11:47:01.372] [jointLog] [info] parsing read library format; [2021-07-16 11:47:01.372] [jointLog] [info] There is 1 library.; Exception : [Error: This version of salmon does not support indexing using the RapMap index.]; /Users/jcm161/anaconda3/envs/salmon/bin/salmon quant was invoked improperly.; For usage information, try /Users/jcm161/anaconda3/envs/salmon/bin/salmon quant --help; Exiting.; Version Server Response: Not Found; ### salmon (selective-alignment-based) v1.5.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ threads ] => { 5 }; ### [ index ] => { ref//salmon.index.human.122116 }; ### [ libType ] => { U }; ### [ unmatedReads ] => { subset_SRR1501368_1_trimmed.fq }; ### [ output ] => { salmonRes_SRR1501368 }; Logs will be written to salmonRes_SRR1501368/logs; [2021-07-16 11:47:01.380] [jointLog] [info] setting maxHashResizeThreads to 5; [2021-07-16 11:47:01.380] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2021-07-16 11:47:01.380] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2021-07-16 11:47:01.380] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.; [2021-07-16 11:47:01.380] [jointLog] [info] parsing read library format; [2021-07-16 11:47:01.380] [jointLog] [info] There is 1 library.; Exception : [Error: This version of salmon does not support indexing using the RapMap index.]; /Users/jcm161/anaconda3/envs/salmon/bin/salmon quant was invoked improperly.; For usage information, try /Users/jcm161/anaconda3/envs/salmon/bin/salmon quant --help; Exiting.; Version Server Response: Not Found; ### salmon (selective-alignment-b",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/685:1722,Log,Logs,1722,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/685,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"[info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2021-07-16 11:47:01.380] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.; [2021-07-16 11:47:01.380] [jointLog] [info] parsing read library format; [2021-07-16 11:47:01.380] [jointLog] [info] There is 1 library.; Exception : [Error: This version of salmon does not support indexing using the RapMap index.]; /Users/jcm161/anaconda3/envs/salmon/bin/salmon quant was invoked improperly.; For usage information, try /Users/jcm161/anaconda3/envs/salmon/bin/salmon quant --help; Exiting.; Version Server Response: Not Found; ### salmon (selective-alignment-based) v1.5.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ threads ] => { 5 }; ### [ index ] => { ref//salmon.index.human.122116 }; ### [ libType ] => { U }; ### [ unmatedReads ] => { subset_SRR1501370_1_trimmed.fq }; ### [ output ] => { salmonRes_SRR1501370 }; Logs will be written to salmonRes_SRR1501370/logs; [2021-07-16 11:47:01.393] [jointLog] [info] setting maxHashResizeThreads to 5; [2021-07-16 11:47:01.393] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2021-07-16 11:47:01.393] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2021-07-16 11:47:01.393] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.; [2021-07-16 11:47:01.393] [jointLog] [info] parsing read library format; [2021-07-16 11:47:01.393] [jointLog] [info] There is 1 library.; Exception : [Error: This version of salmon does not support indexing using the RapMap index.]; /Users/jcm161/anaconda3/envs/salmon/bin/salmon quant was invoked improperly.; For usage information, try /Users/jcm161/anaconda3/envs/salmon/bin/salmon quant --help; Exiting.; Version Server Response: Not Found; ### salmon (selective-alignment-b",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/685:3011,Log,Logs,3011,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/685,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"[info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2021-07-16 11:47:01.387] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.; [2021-07-16 11:47:01.387] [jointLog] [info] parsing read library format; [2021-07-16 11:47:01.387] [jointLog] [info] There is 1 library.; Exception : [Error: This version of salmon does not support indexing using the RapMap index.]; /Users/jcm161/anaconda3/envs/salmon/bin/salmon quant was invoked improperly.; For usage information, try /Users/jcm161/anaconda3/envs/salmon/bin/salmon quant --help; Exiting.; Version Server Response: Not Found; ### salmon (selective-alignment-based) v1.5.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ threads ] => { 5 }; ### [ index ] => { ref//salmon.index.human.122116 }; ### [ libType ] => { U }; ### [ unmatedReads ] => { subset_SRR1501372_1_trimmed.fq }; ### [ output ] => { salmonRes_SRR1501372 }; Logs will be written to salmonRes_SRR1501372/logs; [2021-07-16 11:47:01.614] [jointLog] [info] setting maxHashResizeThreads to 5; [2021-07-16 11:47:01.614] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2021-07-16 11:47:01.614] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2021-07-16 11:47:01.614] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.; [2021-07-16 11:47:01.614] [jointLog] [info] parsing read library format; [2021-07-16 11:47:01.614] [jointLog] [info] There is 1 library.; Exception : [Error: This version of salmon does not support indexing using the RapMap index.]; /Users/jcm161/anaconda3/envs/salmon/bin/salmon quant was invoked improperly.; For usage information, try /Users/jcm161/anaconda3/envs/salmon/bin/salmon quant --help; Exiting.; Version Server Response: Not Found; ### salmon (selective-alignment-b",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/685:5589,Log,Logs,5589,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/685,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"[info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2021-07-16 11:47:01.393] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.; [2021-07-16 11:47:01.393] [jointLog] [info] parsing read library format; [2021-07-16 11:47:01.393] [jointLog] [info] There is 1 library.; Exception : [Error: This version of salmon does not support indexing using the RapMap index.]; /Users/jcm161/anaconda3/envs/salmon/bin/salmon quant was invoked improperly.; For usage information, try /Users/jcm161/anaconda3/envs/salmon/bin/salmon quant --help; Exiting.; Version Server Response: Not Found; ### salmon (selective-alignment-based) v1.5.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ threads ] => { 5 }; ### [ index ] => { ref//salmon.index.human.122116 }; ### [ libType ] => { U }; ### [ unmatedReads ] => { subset_SRR1501369_1_trimmed.fq }; ### [ output ] => { salmonRes_SRR1501369 }; Logs will be written to salmonRes_SRR1501369/logs; [2021-07-16 11:47:01.387] [jointLog] [info] setting maxHashResizeThreads to 5; [2021-07-16 11:47:01.387] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2021-07-16 11:47:01.387] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2021-07-16 11:47:01.387] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.; [2021-07-16 11:47:01.387] [jointLog] [info] parsing read library format; [2021-07-16 11:47:01.387] [jointLog] [info] There is 1 library.; Exception : [Error: This version of salmon does not support indexing using the RapMap index.]; /Users/jcm161/anaconda3/envs/salmon/bin/salmon quant was invoked improperly.; For usage information, try /Users/jcm161/anaconda3/envs/salmon/bin/salmon quant --help; Exiting.; Version Server Response: Not Found; ### salmon (selective-alignment-b",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/685:4300,Log,Logs,4300,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/685,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"[info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2021-07-16 11:47:01.610] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.; [2021-07-16 11:47:01.610] [jointLog] [info] parsing read library format; [2021-07-16 11:47:01.610] [jointLog] [info] There is 1 library.; Exception : [Error: This version of salmon does not support indexing using the RapMap index.]; /Users/jcm161/anaconda3/envs/salmon/bin/salmon quant was invoked improperly.; For usage information, try /Users/jcm161/anaconda3/envs/salmon/bin/salmon quant --help; Exiting.; Version Server Response: Not Found; ### salmon (selective-alignment-based) v1.5.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ threads ] => { 5 }; ### [ index ] => { ref//salmon.index.human.122116 }; ### [ libType ] => { U }; ### [ unmatedReads ] => { subset_SRR1501373_1_trimmed.fq }; ### [ output ] => { salmonRes_SRR1501373 }; Logs will be written to salmonRes_SRR1501373/logs; [2021-07-16 11:47:01.638] [jointLog] [info] setting maxHashResizeThreads to 5; [2021-07-16 11:47:01.638] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2021-07-16 11:47:01.638] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2021-07-16 11:47:01.638] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.; [2021-07-16 11:47:01.638] [jointLog] [info] parsing read library format; [2021-07-16 11:47:01.638] [jointLog] [info] There is 1 library.; Exception : [Error: This version of salmon does not support indexing using the RapMap index.]; /Users/jcm161/anaconda3/envs/salmon/bin/salmon quant was invoked improperly.; For usage information, try /Users/jcm161/anaconda3/envs/salmon/bin/salmon quant --help; Exiting.; Version Server Response: Not Found; ### salmon (selective-alignment-b",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/685:8167,Log,Logs,8167,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/685,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"[info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2021-07-16 11:47:01.614] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.; [2021-07-16 11:47:01.614] [jointLog] [info] parsing read library format; [2021-07-16 11:47:01.614] [jointLog] [info] There is 1 library.; Exception : [Error: This version of salmon does not support indexing using the RapMap index.]; /Users/jcm161/anaconda3/envs/salmon/bin/salmon quant was invoked improperly.; For usage information, try /Users/jcm161/anaconda3/envs/salmon/bin/salmon quant --help; Exiting.; Version Server Response: Not Found; ### salmon (selective-alignment-based) v1.5.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ threads ] => { 5 }; ### [ index ] => { ref//salmon.index.human.122116 }; ### [ libType ] => { U }; ### [ unmatedReads ] => { subset_SRR1501371_1_trimmed.fq }; ### [ output ] => { salmonRes_SRR1501371 }; Logs will be written to salmonRes_SRR1501371/logs; [2021-07-16 11:47:01.610] [jointLog] [info] setting maxHashResizeThreads to 5; [2021-07-16 11:47:01.610] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2021-07-16 11:47:01.610] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2021-07-16 11:47:01.610] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.; [2021-07-16 11:47:01.610] [jointLog] [info] parsing read library format; [2021-07-16 11:47:01.610] [jointLog] [info] There is 1 library.; Exception : [Error: This version of salmon does not support indexing using the RapMap index.]; /Users/jcm161/anaconda3/envs/salmon/bin/salmon quant was invoked improperly.; For usage information, try /Users/jcm161/anaconda3/envs/salmon/bin/salmon quant --help; Exiting.; Version Server Response: Not Found; ### salmon (selective-alignment-b",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/685:6878,Log,Logs,6878,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/685,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"[info] Using default value of 0.87 for minScoreFraction in Alevin; Using default value of 0.6 for consensusSlack in Alevin; [2021-04-09 12:16:37.649] [alevinLog] [info] Found 45374 transcripts(+1 decoys, +0 short and +0 duplicate names in the index); [2021-04-09 12:16:37.702] [alevinLog] [info] Filled with 45374 txp to gene entries; ### alevin (dscRNA-seq quantification) v1.4.0; ### [ program ] => salmon; ### [ command ] => alevin; ### [ libType ] => { ISR }; ### [ index ] => { results/salmon/index/GRCh38.p13 }; ### [ mates1 ] => { /Users/james/GitHub/scrnaseq/.tests/fastq/S1_L001_R1_001.fastq.gz /Users/james/GitHub/scrnaseq/.tests/fastq/S1_L002_R1_001.fastq.gz /Users/james/GitHub/scrnaseq/.tests/fastq/S1_L003_R1_001.fastq.gz /Users/james/GitHub/scrnaseq/.tests/fastq/S1_L004_R1_001.fastq.gz }; ### [ mates2 ] => { /Users/james/GitHub/scrnaseq/.tests/fastq/S1_L001_R2_001.fastq.gz /Users/james/GitHub/scrnaseq/.tests/fastq/S1_L002_R2_001.fastq.gz /Users/james/GitHub/scrnaseq/.tests/fastq/S1_L003_R2_001.fastq.gz /Users/james/GitHub/scrnaseq/.tests/fastq/S1_L004_R2_001.fastq.gz }; ### [ output ] => { results/salmon/alevin/S1 }; ### [ threads ] => { 1 }; ### [ tgMap ] => { results/eisar/GRCh38.p13/GRCh38.p13.tx2gene.tsv }; ### [ chromiumV3 ] => { }; ### [ mrna ] => { results/gffread/GRCh38.p13/GRCh38.p13.mrna.txt }; ### [ rrna ] => { results/gffread/GRCh38.p13/GRCh38.p13.rrna.txt }. [2021-04-09 12:16:37.708] [alevinLog] [info] Found all transcripts to gene mappings; [2021-04-09 12:16:37.722] [alevinLog] [info] Processing barcodes files (if Present). [2021-04-09 12:16:37.728] [alevinLog] [info] Done barcode density calculation.; [2021-04-09 12:16:37.728] [alevinLog] [info] # Barcodes Used: 4000 / 4000.; [2021-04-09 12:16:37.729] [alevinLog] [info] Knee found left boundary at 102; [2021-04-09 12:16:37.862] [alevinLog] [info] Gauss Corrected Boundary at 52; [2021-04-09 12:16:37.862] [alevinLog] [info] Learned InvCov: 419.096 normfactor: 100.648; [2021-04-09 12:16:37.862] [alev",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/647:2175,test,tests,2175,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/647,1,['test'],['tests']
Testability,"\; -1 /path/to/""{fastq_1}"" \; -2 /path/to/""{fastq_2}""\; --writeUnmappedNames \; --validateMappings \; --recoverOrphans\; --gcBias \; --seqBias \; --recoverOrphans\; -o /path/to/output/{Samples} \; --threads 2' :::: /path/to/sheet_with_sample_and_fastq_names.csv; ```; Specifically, please provide at least the following information:. * Which version of salmon was used?; Both 1.10.2 and 1.10.3 were tested. ; * How was salmon installed (compiled, downloaded executable, through bioconda)?; Used bioconda; * Which reference (e.g. transcriptome) was used?; GRCh38 ; * Which read files were used?; Illumina NovaSeq. Merged fastq based on direction (fastq split across lanes and had to add top off data) with zcat, used cutadapt for adapter trimming. . * Which which program options were used?; Ribodetector was used to get rid of rRNA contamination. Used output of non rRNA files with Salmon quant. **Expected behavior**; A clear and concise description of what you expected to happen.; Salmon Quant outputting of .sf files. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem.; From SLURM generated error file. **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX]; - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux the output of `uname -a` and `lsb_release -a`]; HPCS: Red Hat Server 7.9. **Additional context**; Add any other context about the problem here.; Removal of --recoverOrphans leads to jobs finishing to completion. . Oddly enough, with --recoverOrphans dropped, I start seeing output into .err files I set in SLURM rather than in the .log file with each folder. .err files typically terminate after reporting hits for frags are finished unlike with salmon_output.log files without --recoverOrphans. As an aside, when googling ""recover orphans salmon crash"" this was the top result: https://ksltv.com/635908/tens-of-thousands-of-live-salmon-fell-off-a-truck-in-oregon-and-into-a-creek/",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/961:2754,log,log,2754,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/961,2,['log'],['log']
Testability,"] [info] Computed 185,593 rich equivalence classes for further processing; [2018-12-05 15:45:46.198] [jointLog] [info] Counted 163,106,139 total reads in the equivalence classes ; [2018-12-05 15:45:46.199] [jointLog] [warning] Found 115077 reads with `N` in the UMI sequence and ignored the reads.; Please report on github if this number is too large; [2018-12-05 15:45:46.199] [jointLog] [info] Mapping rate = 60.9633%. [2018-12-05 15:45:46.199] [jointLog] [info] finished quantifyLibrary(); [2018-12-05 15:45:47.617] [alevinLog] [info] Starting optimizer. Analyzed 5344 cells (100% of all).; [2018-12-05 15:47:14.597] [alevinLog] [info] Total 1870793 UMI after deduplicating.; [2018-12-05 15:47:14.693] [alevinLog] [info] Clearing EqMap; Might take some time.; [2018-12-05 15:47:18.921] [alevinLog] [info] Starting Import of the gene count matrix.; Exception : [std::bad_alloc]; alevin was invoked improperly.; For usage information, try alevin --help; Exiting.; ```. PBMC 3k shell log:; ```; ~/software/salmon/scripts/v1_10x/run.sh salmon alevin -lISR -b pbmc3k_fastqs/ --gemcode -i ../transcripts_index_salmon/ -p 8 -o alevin_output --tgMap ../hg_transcriptome/tx2gene.tsv. TEMPDIR is /tmp/tmp.WnzMm7GQBO; Running command [salmon alevin -lISR --gemcode -i ../transcripts_index_salmon/ -p 8 -o alevin_output --tgMap ../hg_transcriptome/tx2gene.tsv -1 /tmp/tmp.WnzMm7GQBO/p1.fa -2 /tmp/tmp.WnzMm7GQBO/p2.fa -r pbmc3k_fastqs/read-I1_si-ACGCGGAA_lane-001-chunk-001.fastq.gz; pbmc3k_fastqs/read-I1_si-ACGCGGAA_lane-002-chunk-000.fastq.gz; pbmc3k_fastqs/read-I1_si-CGCTATCC_lane-001-chunk-001.fastq.gz; pbmc3k_fastqs/read-I1_si-CGCTATCC_lane-002-chunk-000.fastq.gz; pbmc3k_fastqs/read-I1_si-GTTGCATG_lane-001-chunk-001.fastq.gz; pbmc3k_fastqs/read-I1_si-GTTGCATG_lane-002-chunk-000.fastq.gz; pbmc3k_fastqs/read-I1_si-TAAATCGT_lane-001-chunk-001.fastq.gz; pbmc3k_fastqs/read-I1_si-TAAATCGT_lane-002-chunk-000.fastq.gz]; Version Info: Could not resolve upgrade information in the alotted time.; Check for ",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/328:8878,log,log,8878,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/328,1,['log'],['log']
Testability,"] [info] Finished optimizer; [2020-06-16 00:01:17.131] [jointLog] [info] writing output. ```. So, you can note that the number of mappings discarded because of alignment; score is still quite big (134M) and, indeed, this took longer than I would; normally expect for; a sample with ~30M reads. However, it is _massively_ smaller (~116 times); than the 15.6B in your run. Thus, it may have been the same issue as in; the other GitHub issue. You can try the pre-compiled linux binary I linked; there if you have access to a linux machine to test on. By the way, the; issue there was a bunch of reads plagued by super-repetitive homopolymer; segments, I haven't looked at these reads yet for evidence of that though. On Mon, Jun 15, 2020 at 11:09 PM shalercr <notifications@github.com> wrote:. >; >; >; >; >; > Hi Rob,; >; >; > Thanks for the quick response. The other computer was OSX, should I try a; > linux machine?; >; >; > Here are some dropbox links to two of the files. I believe this is the set; > for the logs I posted.; >; >; > https://www.dropbox.com/s/8c3p9hmgmadgj89/31_1.trimmed.fastq.gz?dl=0; >; >; > https://www.dropbox.com/s/2y9jfvaphe9h21x/31_2.trimmed.fastq.gz?dl=0; >; >; >; >; > Thanks,; >; >; > Ryan; >; >; >; >; >; > On Jun 15, 2020, at 9:32 PM, Rob Patro <notifications@github.com> wrote:; >; >; >; >; > Thank you for the report. Can you share one of the samples where you see; > this issue? Also, out of curiosity, was the other machine you tried on also; > OSX, or was it a linux machine?; > —; > You are receiving this because you authored the thread.; > Reply to this email directly,; > view it on GitHub, or; > unsubscribe.; >; > —; > You are receiving this because you commented.; > Reply to this email directly, view it on GitHub; > <https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-644504783>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AACYH7UHOYB7KYKDASFB5RDRW3O7HANCNFSM4N7EOYSQ>; > .; >; —; You are receiving this because yo",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-644527727:5482,log,logs,5482,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-644527727,1,['log'],['logs']
Testability,"] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2021-07-16 11:47:01.638] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.; [2021-07-16 11:47:01.638] [jointLog] [info] parsing read library format; [2021-07-16 11:47:01.638] [jointLog] [info] There is 1 library.; Exception : [Error: This version of salmon does not support indexing using the RapMap index.]; /Users/jcm161/anaconda3/envs/salmon/bin/salmon quant was invoked improperly.; For usage information, try /Users/jcm161/anaconda3/envs/salmon/bin/salmon quant --help; Exiting.; Version Server Response: Not Found; ### salmon (selective-alignment-based) v1.5.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ threads ] => { 5 }; ### [ index ] => { ref//salmon.index.human.122116 }; ### [ libType ] => { U }; ### [ unmatedReads ] => { subset_SRR2173891_trimmed.fq }; ### [ output ] => { salmonRes_SRR2173891 }; Logs will be written to salmonRes_SRR2173891/logs; [2021-07-16 11:47:01.649] [jointLog] [info] setting maxHashResizeThreads to 5; [2021-07-16 11:47:01.649] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2021-07-16 11:47:01.649] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2021-07-16 11:47:01.649] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.; [2021-07-16 11:47:01.649] [jointLog] [info] parsing read library format; [2021-07-16 11:47:01.649] [jointLog] [info] There is 1 library.; Exception : [Error: This version of salmon does not support indexing using the RapMap index.]; /Users/jcm161/anaconda3/envs/salmon/bin/salmon quant was invoked improperly.; For usage information, try /Users/jcm161/anaconda3/envs/salmon/bin/salmon quant --help; Exiting.; Version Server Response: Not Found; ### salmon (selective-alignment-b",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/685:9454,Log,Logs,9454,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/685,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2021-07-16 11:47:01.649] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.; [2021-07-16 11:47:01.649] [jointLog] [info] parsing read library format; [2021-07-16 11:47:01.649] [jointLog] [info] There is 1 library.; Exception : [Error: This version of salmon does not support indexing using the RapMap index.]; /Users/jcm161/anaconda3/envs/salmon/bin/salmon quant was invoked improperly.; For usage information, try /Users/jcm161/anaconda3/envs/salmon/bin/salmon quant --help; Exiting.; Version Server Response: Not Found; ### salmon (selective-alignment-based) v1.5.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ threads ] => { 5 }; ### [ index ] => { ref//salmon.index.human.122116 }; ### [ libType ] => { U }; ### [ unmatedReads ] => { subset_SRR2173892_trimmed.fq }; ### [ output ] => { salmonRes_SRR2173892 }; Logs will be written to salmonRes_SRR2173892/logs; [2021-07-16 11:47:01.807] [jointLog] [info] setting maxHashResizeThreads to 5; [2021-07-16 11:47:01.807] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2021-07-16 11:47:01.807] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2021-07-16 11:47:01.807] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.; [2021-07-16 11:47:01.807] [jointLog] [info] parsing read library format; [2021-07-16 11:47:01.807] [jointLog] [info] There is 1 library.; Exception : [Error: This version of salmon does not support indexing using the RapMap index.]; /Users/jcm161/anaconda3/envs/salmon/bin/salmon quant was invoked improperly.; For usage information, try /Users/jcm161/anaconda3/envs/salmon/bin/salmon quant --help; Exiting.; ./salmonRes_SRR1501367/quant.sf ; Error in file(file, ""rt"") : cannot ",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/685:10741,Log,Logs,10741,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/685,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2022-01-20 13:56:19.915] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.; [2022-01-20 13:56:19.915] [jointLog] [info] parsing read library format; ```. But no errors/no other outputs after that. I reran many times with slightly different settings, including different set of reads and a different reference with the same results, but only got an error when I ran: . ```; salmon quant -p 1 -i $index -1 $read1 -2 $read2 –o res_new -l OSR; ```. Which returned the error:. ```; [2022-01-20 14:39:44.578] [jointLog] [error] Failed to successfully parse any complete read libraries. Please make sure you provided arguments properly to -1, -2 (for paired-end libraries) or -r (for single-end libraries), and that the library format option (-l) *comes before* the read libraries.; ```. This error allowed me to fix the original command (running now, yay!) but I only got that error after changing up the arguments I used (for whatever reason the original arguments did not allow for the error to be reported correctly to the user) and updating the name of the output I used (ran the exact same command that gave me the error with the old output name (res) and it did not give an error. Note I did not delete the output between tests). Not a huge issue, but figured it could affect others in the future as well (took me quite a while to figure out the issue due to the lack of error message) so should report it. ## Expected behavior. When -l comes before -1/-2, the error message:. ```; [2022-01-20 14:39:44.578] [jointLog] [error] Failed to successfully parse any complete read libraries. Please make sure you provided arguments properly to -1, -2 (for paired-end libraries) or -r (for single-end libraries), and that the library format option (-l) *comes before* the read libraries.; ```. should be reported regardless of other arguments given.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/736:2367,test,tests,2367,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/736,1,['test'],['tests']
Testability,"_URL=https://api.github.com/repos/COMBINE-lab/salmon/releases/latest; VERSION=$(curl -s $GITHUB_URL | \; grep '""tag_name"":' | \; cut -d : -f 2,3 | \; tr -d \"",v | \; xargs); LATEST_RELEASE=$(curl -s $GITHUB_URL | \; grep '""tarball_url""' | \; cut -d : -f 2,3 | \; tr -d \"", | \; xargs); module load gcc/7.4.0 cmake/3.15.1 boost/1.70.0-gcc libiconv/1.16; export CC=`which gcc`; export CXX=`which c++`. cd $MODULE_HOME; mkdir -p source/$PACKAGE_NAME/$VERSION; INSTALL_DIR=$MODULE_HOME/modules/$PACKAGE_NAME/$VERSION; mkdir -p $INSTALL_DIR; mkdir -p modfiles/$PACKAGE_NAME. cd source/$PACKAGE_NAME/$VERSION; wget $LATEST_RELEASE -O - | tar -xz --strip-components 1; cmake -DBOOST_ROOT=/global/software/sl-7.x86_64/modules/gcc/7.4.0/boost/1.70.0-gcc -DCMAKE_INSTALL_PREFIX=$INSTALL_DIR; make; ```; And the tail of the output from make:. ```; creating: /clusterfs/vector/home/groups/software/sl-7.x86_64/source/salmon/1.5.1/scripts/../external/pufferfish-salmon-v1.5.1/tests/compile_tests/; inflating: /clusterfs/vector/home/groups/software/sl-7.x86_64/source/salmon/1.5.1/scripts/../external/pufferfish-salmon-v1.5.1/tests/compile_tests/int128_numeric_limits.cpp ; -- fetch PUFFERFISH exit code 0; -- Found ZLIB: /usr/lib64/libz.so (found version ""1.2.11"") ; -- Performing Test Iconv_IS_BUILT_IN; -- Performing Test Iconv_IS_BUILT_IN - Failed; CMake Error at /global/home/groups/consultsw/sl-7.x86_64/modules/cmake/3.15.1/share/cmake-3.15/Modules/FindPackageHandleStandardArgs.cmake:137 (message):; Could NOT find Iconv (missing: Iconv_LIBRARY); Call Stack (most recent call first):; /global/home/groups/consultsw/sl-7.x86_64/modules/cmake/3.15.1/share/cmake-3.15/Modules/FindPackageHandleStandardArgs.cmake:378 (_FPHSA_FAILURE_MESSAGE); /global/home/groups/consultsw/sl-7.x86_64/modules/cmake/3.15.1/share/cmake-3.15/Modules/FindIconv.cmake:120 (find_package_handle_standard_args); CMakeLists.txt:362 (find_package). -- Configuring incomplete, errors occurred!; See also ""/clusterfs/vector/home/groups/sof",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/453#issuecomment-862737315:1474,test,tests,1474,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/453#issuecomment-862737315,2,['test'],['tests']
Testability,"_lane-002-chunk-000.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-CGAAGTTG_lane-003-chunk-003.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-CGAAGTTG_lane-004-chunk-002.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-GAGCACGC_lane-001-chunk-001.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-GAGCACGC_lane-002-chunk-000.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-GAGCACGC_lane-003-chunk-003.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-GAGCACGC_lane-004-chunk-002.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-001-chunk-001.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-002-chunk-000.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-003-chunk-003.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-004-chunk-002.fastq.gz]; Version Info: This is the most recent version of salmon.; [2018-12-06 11:14:56.513] [alevinLog] [info] A custom protocol (END, BC length, UMI length) = (5, 14, 5) is being used. Updating UMI k-mer length accordingly.; Logs will be written to ./fastq/test/logs; [2018-12-06 11:14:56.533] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; ### alevin (dscRNA-seq quantification) v0.12.0; ### [ program ] => salmon ; ### [ command ] => alevin ; ### [ libType ] => { ISR }; ### [ gemcode ] => { }; ### [ index ] => { ./transcripts_index_salmon/ }; ### [ threads ] => { 8 }; ### [ output ] => { ./fastq/test/ }; ### [ tgMap ] => { ./hg_transcriptome/tx2tx.tsv }; ### [ end ] => { 5 }; ### [ umiLength ] => { 5 }; ### [ barcodeLength ] => { 14 }; ### [ dumpCsvCounts ] => { }; ### [ mates1 ] => { /tmp/tmp.p28w2nGvAn/p1.fa }; ### [ mates2 ] => { /tmp/tmp.p28w2nGvAn/p2.fa }; ### [ unmatedReads ] => { ./fastq/fastqs/flowcell1/read-I1_si-ACTTCACT_lane-001-chunk-001.fastq.gz ./fastq/fastqs/flowcell1/read-I1_si-ACTTCACT_lane-002-chunk-000.fastq.gz ./fastq/fastqs/flowcell1/read-I1_si-ACTTCACT_lane-003-chunk-003.fastq.gz ./fastq/fastqs/flowcell1/read-I1_si-ACTTCACT_lane-004-chunk-",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-445008548:2152,Log,Logs,2152,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-445008548,1,['Log'],['Logs']
Testability,"` flag the option `--dumpCsvCounts` does not seem to work. **To Reproduce**; Salmon version 0.13.1 from Bioconda. `salmon alevin -l ISR -i ../salmon/index/ -1 R1_file -2 R2_file -o out_dir/ --tgMap ../salmon/txp2gene.tsv -p 20 --chromium --whitelist whitelist.txt --dumpFeatures --dumpCsvCounts`. I have a very problematic sample where the knee autodetection fails (way too high cell number). So I created a whitelist of the 5000 most frequent entries of the filtered_cb_frequency.txt. It seems to work as expected, but the quants_mat.csv is not created, which I need for further downstream analysis (Seurat). The quant_mat.gz is created though, is there a way to manually create a .csv from this file (it seems to be binary).; Thanks. P.S.: The alevin logs seem to contain some non-standard characters when the number of ""Barcodes used"" should be printed (maybe because of the colour highlighting?). **Expected behavior**; quants_mat.csv of the whitelisted cells should be created. **Logs**; ```; [2019-05-17 07:28:11.279] [alevinLog] [info] Processing barcodes files (if Present) . ; [2019-05-17 07:39:15.712] [alevinLog] [info] Done barcode density calculation.; [2019-05-17 07:39:15.712] [alevinLog] [info] # Barcodes Used: [32m346967519[0m / [31m347069857[0m.; [2019-05-17 07:39:15.731] [alevinLog] [info] Done importing white-list Barcodes; [2019-05-17 07:39:15.732] [alevinLog] [info] Total 4000 white-listed Barcodes; [2019-05-17 07:39:16.050] [alevinLog] [info] Done populating Z matrix; [2019-05-17 07:39:16.112] [alevinLog] [info] Done indexing Barcodes; [2019-05-17 07:39:16.112] [alevinLog] [info] Total Unique barcodes found: 3968995; [2019-05-17 07:39:16.112] [alevinLog] [info] Used Barcodes except Whitelist: 80709; [2019-05-17 07:39:16.858] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2019-05-17 07:39:16.868] [alevinLog] [info] parsing read library format; [2019-05-17 08:05:24.319] [alevinLog] [info] Starting optimizer. [2019-05-17 08:06:06.627] [ale",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/363:1128,Log,Logs,1128,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/363,1,['Log'],['Logs']
Testability,"```; /usr/bin/ld: cannot find -lpthreads; ```; That's normal. Cmake is probing to determine the name of the pthreads library on this system, and it's named `-lpthread` not `-lpthreads`, so this test fails, and is expected to fail.; ```; ❯❯❯ ls /usr/lib/x86_64-linux-gnu/libpthread.so; /usr/lib/x86_64-linux-gnu/libpthread.so; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/181#issuecomment-367796621:194,test,test,194,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/181#issuecomment-367796621,1,['test'],['test']
Testability,"```; > ; > ```; > Version Info: This is the most recent version of salmon.; > # salmon (alignment-based) v1.4.0; > # [ program ] => salmon ; > # [ command ] => quant ; > # [ targets ] => { mRNA.fasta }; > # [ threads ] => { 20 }; > # [ libType ] => { A }; > # [ alignments ] => { SRR3212847.Aligned.SortedByName.bam }; > # [ output ] => { SRR3212847.Aligned.SortedByName }; > Logs will be written to SRR3212847.Aligned.SortedByName/logs; > [2021-01-08 13:02:04.845] [jointLog] [info] setting maxHashResizeThreads to 20; > [2021-01-08 13:02:04.845] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; > Library format { type:paired end, relative orientation:inward, strandedness:unstranded }; > [2021-01-08 13:02:04.878] [jointLog] [info] numQuantThreads = 14; > parseThreads = 6; > Checking that provided alignment files have consistent headers . . . done; > Populating targets from aln = ""SRR3212847.Aligned.SortedByName.bam"", fasta = ""mRNA.fasta"" . . .done; > ; > processed 0 reads in current roundSegmentation fault (core dumped); > ```; > ; > (Which is the same as the 1st error. Actually, each time I re-run those two errors switched.); > ; > I tried running Salmon on the sorted-by-coordinates bam, and it didn't fail:; > ; > ```; > nohup salmon quant \; > -t mRNA.fasta \; > -p 20 \; > -l A \; > -a SRR3212847.Aligned.SortedByCoord.bam \; > -o SRR3212847.Aligned.SortedByCoord \; > > SRR3212847.Aligned.SortedByCoord.out &; > ```; > ; > Even so, `SRR3212847.Aligned.SortedByCoord.out` contained ~3.5GB worth of the warnings above.; > ; > Any help would be much appreciated. Thanks!. hello,i have the same problem,thanks for your answer. Your SRR3212847.Aligned.SortedByCoord.out contained ~3.5GB worth of the warnings above, What is the warning message? And in my log file,the warning as follow:. ![image](https://user-images.githubusercontent.com/45484925/206608510-b5cc88bd-18ac-42eb-bfa1-a5be862b0873.png); Can i ignore these warnings?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/582#issuecomment-1343749456:5261,log,log,5261,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/582#issuecomment-1343749456,1,['log'],['log']
Testability,"```; You passed paired-end files; to salmon, but you passed 12 files to --mates1 and 13 files to --mates2.; You must pass the same number of files to both flags; ```. Is this true ? Can you share the log ?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408#issuecomment-516185511:200,log,log,200,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408#issuecomment-516185511,1,['log'],['log']
Testability,"```bash; $ qacct -j 9958683 -t 3; ==============================================================; qname shared.q; hostname compute-068.cm.cluster; group lieber_jaffe; owner lcollado; project NONE; department defaultdepartment; jobname step6-txQuant-alzheimer.gsk_phaseII; jobnumber 9958683; taskid 3; account sge; priority 0; qsub_time Mon Mar 6 23:18:58 2017; start_time Mon Mar 6 23:19:12 2017; end_time Tue Mar 7 17:27:45 2017; granted_pe local; slots 1; failed 0; exit_status 0; ru_wallclock 65313; ru_utime 25600.565; ru_stime 29552.966; ru_maxrss 6548296; ru_ixrss 0; ru_ismrss 0; ru_idrss 0; ru_isrss 0; ru_minflt 1662027; ru_majflt 369; ru_nswap 0; ru_inblock 0; ru_oublock 56256; ru_msgsnd 0; ru_msgrcv 0; ru_nsignals 0; ru_nvcsw 801190; ru_nivcsw 2880329; cpu 55153.531; mem 403295.295; io 17.447; iow 0.000; maxvmem 9.065G; arid undefined; ```. For task 1 the maxvmem was 9.072G and for task 2 9.061G. I then ran a test requesting a minimum of 10 GB of free RAM and a max of 11 GB, which in theory should work unless `salmon` uses variable amounts of memory with the same data. ```bash; #!/bin/bash; #$ -cwd; #$ -l mem_free=10G,h_vmem=11G,h_fsize=100G; #$ -N step6-salmon_test.gsk_phaseII; #$ -pe local 1; #$ -o ./logs/salmon_test.$TASK_ID.txt; #$ -e ./logs/salmon_test.$TASK_ID.txt; #$ -m a; echo ""**** Job starts ****""; date. echo ""**** JHPCE info ****""; echo ""User: ${USER}""; echo ""Job id: ${JOB_ID}""; echo ""Job name: ${JOB_NAME}""; echo ""Hostname: ${HOSTNAME}""; echo ""Task id: ${TASK_ID}"". FILE1=$(awk 'BEGIN {FS=""\t""} {print $1}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); FILE2=$(awk 'BEGIN {FS=""\t""} {print $3}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); ID=$(cat /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk '{print $NF}' | awk ""NR==${SGE_TASK_ID}""). mkdir -p /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test/${ID}. /dcl01/lieber/ajaffe/Emily/RNAseq-p",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126:21081,test,test,21081,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126,1,['test'],['test']
Testability,"a from the repository. Note, this SAM file is zipped (GitHub made me zip it before attaching it, so unzip it before you process it):. [sample_alignments.sam.zip](https://github.com/COMBINE-lab/salmon/files/4510467/sample_alignments.sam.zip). Once you've unzipped this file, you can run salmon as:. ```~bash; ./bin/salmon quant -l IU -t transcripts.fa -a sample_alignments.sam -o quant_directory; ```. where the `transcripts.fa` is the sample transcriptome distributed with salmon that you can get by unzipping this file : [transcripts.fasta.zip](https://github.com/COMBINE-lab/salmon/files/4510488/transcripts.fasta.zip). When I run this with the latest salmon, I get the following output:. ```; # salmon (alignment-based) v1.2.0; # [ program ] => salmon; # [ command ] => quant; # [ libType ] => { IU }; # [ alignments ] => { sample_alignments.sam }; # [ targets ] => { ../sample_data/transcripts.fasta }; # [ output ] => { sample_aln_quant }; Logs will be written to sample_aln_quant/logs; Library format { type:paired end, relative orientation:inward, strandedness:unstranded }; [2020-04-21 10:11:42.553] [jointLog] [info] setting maxHashResizeThreads to 8; [2020-04-21 10:11:42.553] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2020-04-21 10:11:42.553] [jointLog] [info] numQuantThreads = 4; parseThreads = 4; Checking that provided alignment files have consistent headers . . . done; Populating targets from aln = ""sample_alignments.sam"", fasta = ""../sample_data/transcripts.fasta"" . . .done; [2020-04-21 10:11:43.180] [jointLog] [info] replaced 0 non-ACGT nucleotides with random nucleotides. processed 0 reads in current round; killing thread 3 . . . done. Freeing memory used by read queue . . . 00; Joined parsing thread . . . ""sample_alignments.sam""; Closed all files . . .; Emptied frag queue. . . [2020-04-21 10:11:43.477] [jointLog] [info]. Completed first pass through the alignment file.; Total # of mapped reads : 10000; #",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/511#issuecomment-617206094:1120,Log,Logs,1120,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/511#issuecomment-617206094,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"a)?; downloaded executable; * Which reference (e.g. transcriptome) was used?; Araport 11, from A. thaliana; * Which read files were used?; regular fastq.gz ( SRR7985407); * Which which program options were used?; --validateMappings; -p 4; --seqBias; --gcBias ; --posBias. **Expected behavior**; Much faster alignment, it is Salmon !!; **Screenshots**; this is the run info so far:. Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v1.2.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /home/jaimealaniz/Documents/indexes/salmon/ara11/ }; ### [ libType ] => { A }; ### [ mates1 ] => { SRR7985407_1.fq.gz }; ### [ mates2 ] => { SRR7985407_2.fq.gz }; ### [ validateMappings ] => { }; ### [ threads ] => { 4 }; ### [ seqBias ] => { }; ### [ gcBias ] => { }; ### [ posBias ] => { }; ### [ output ] => { /home/jaimealaniz/Documents/salmon.embryo/SRR7985407/ }; Logs will be written to /home/jaimealaniz/Documents/salmon.embryo/SRR7985407/logs; [2020-05-29 20:14:24.283] [jointLog] [info] setting maxHashResizeThreads to 4; [2020-05-29 20:14:24.283] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2020-05-29 20:14:24.283] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2020-05-29 20:14:24.283] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.35.; [2020-05-29 20:14:24.283] [jointLog] [info] parsing read library format; [2020-05-29 20:14:24.283] [jointLog] [info] There is 1 library.; [2020-05-29 20:14:24.341] [jointLog] [info] Loading pufferfish index; [2020-05-29 20:14:24.342] [jointLog] [info] Loading dense pufferfish index.; -----------------------------------------; | Loading contig table | Time = 41.693 ms; -----------------------------------------; size = 357712; -----------------------------------------; | Load",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/527:2020,log,logs,2020,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/527,1,['log'],['logs']
Testability,"able | Time = 755.36 ms; -----------------------------------------; size = 3783918493; Number of ones: 37280288; Number of ones per inventory item: 512; Inventory entries filled: 72814; -----------------------------------------; | Loading contig boundaries | Time = 4.2405 s; -----------------------------------------; size = 3783918493; -----------------------------------------; | Loading sequence | Time = 387.95 ms; -----------------------------------------; size = 2665509853; -----------------------------------------; | Loading positions | Time = 4.3613 s; -----------------------------------------; size = 3516045923; -----------------------------------------; | Loading reference sequence | Time = 360.88 ms; -----------------------------------------; -----------------------------------------; | Loading reference accumulative lengths | Time = 985.04 us; -----------------------------------------; [2023-02-23 09:40:13.935] [jointLog] [info] done; ```; (taken from the terminal as the logfile is empty, and the current time is 12:54 pm = >3 hr run time so far). **To Reproduce**; I ran the following command:. ```; salmon quant \; --geneMap Homo_sapiens.GRCh38.106.gtf \; --threads 6 \; --libType=ISR \; --index salmon_index \; -1 ACV_REP2_1_val_1.fq.gz -2 CV_REP2_2_val_2.fq.gz \; --seqBias --gcBias --posBias \; -o ACV_REP2; ```; * Which version of salmon was used? v1.9.0; * How was salmon installed (compiled, downloaded executable, through bioconda)? `nf-core/rnaseq`: via singularity; while running manually to troubleshoot: conda.; * Which reference (e.g. transcriptome) was used? Homo_sapiens.GRCh38 transcriptome + genome as a 'gentrome'; * Which read files were used? newly sequenced bulk RNAseq reads. **Expected behavior**; All samples with similar numbers of reads using the same index to finish in roughly the same amount of time. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. **Desktop (please complete the following informa",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/830:10769,log,logfile,10769,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/830,1,['log'],['logfile']
Testability,"aco/twopaco-targets.cmake; -- Installing: /salmon/lib/twopaco/twopaco-targets-release.cmake; -- Installing: /salmon/lib/libtbb.so; -- Installing: /salmon/lib/libtbb.so.12; -- Installing: /salmon/lib/libtbb.so.12.5; -- Installing: /salmon/lib/libtbbmalloc.so; -- Installing: /salmon/lib/libtbbmalloc.so.2; -- Installing: /salmon/lib/libtbbmalloc.so.2.5; -- Installing: /salmon/lib/libtbbmalloc_proxy.so; -- Installing: /salmon/lib/libtbbmalloc_proxy.so.2; -- Installing: /salmon/lib/libtbbmalloc_proxy.so.2.5; -- Installing: /salmon/bin/salmon; -- Installing: /salmon/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly.; ==========================================================================; Please add /salmon/bin to your PATH; Please add /salmon/lib to your LD_LIBRARY_PATH; ==========================================================================; root@fd877e359439:/salmon/build# make test; Running tests...; Test project /salmon/build; Start 1: unit_tests; 1/2 Test #1: unit_tests ....................... Passed 0.37 sec; Start 2: salmon_read_test_quasi; 2/2 Test #2: salmon_read_test_quasi ........... Passed 1.80 sec. 100% tests passed, 0 tests failed out of 2. Total Test time (real) = 2.17 sec; ```. The `make test` command itself runs the test the builds the index and maps the reads against it. Either way, I can do that explicitly too (from within build):. ```; $ ./src/salmon index -t ../sample_data/transcripts.fasta -i sample_idx; ```. returns succesfully with a built index. ```; ...; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Done wrapping the rank vector with a rank9sel structure.; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] contig count for validation: 23; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Total # of Contigs : 23; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Total # of numerical Contigs : 23; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Total # of c",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554:2711,Test,Test,2711,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554,2,['Test'],['Test']
Testability,"aded executable, through bioconda)?. From our dockerfile:; ```; # Install Salmon; ENV SALMON_VERSION 0.9.1; RUN wget https://github.com/COMBINE-lab/salmon/releases/download/v${SALMON_VERSION}/Salmon-${SALMON_VERSION}_linux_x86_64.tar.gz; RUN tar -xzf Salmon-${SALMON_VERSION}_linux_x86_64.tar.gz; # Create soft link `/usr/local/bin/salmon` that points to the actual program; RUN ln -sf `pwd`/Salmon-latest_linux_x86_64/bin/salmon /usr/local/bin/; RUN rm -f Salmon-${SALMON_VERSION}_linux_x86_64.tar.gz; # End Salmon installation.; ```. * Which reference (e.g. transcriptome) was used?. One we prepared. We got the raw transcriptome from ensembl, then prepared it with:; https://github.com/AlexsLemonade/refinebio/blob/dev/workers/data_refinery_workers/processors/transcriptome_index.py. Which produced:; https://s3.amazonaws.com/data-refinery-test-assets/Caenorhabditis_elegans_short_1527089586.tar.gz. * Which read files were used?. Two read files out of:; https://s3.amazonaws.com/data-refinery-test-assets/salmon_tests.tar.gz. found within that archive at:; `test_experiment/raw/reads_1.fastq`; and ; `test_experiment/raw/reads_2.fastq`. Unfortunately I am not entirely sure where these were found. * Which which program options were used?. The exact invocation of salmon was:; ```; salmon --no-version-check quant -l A --biasSpeedSamp 5 -i /home/user/data_store/processed/TEST/TRANSCRIPTOME_INDEX/index -1 /home/user/data_store/salmon_tests/test_experiment/raw/reads_1.fastq -2 /home/user/data_store/salmon_tests/test_experiment/raw/reads_2.fastq -p 20 -o /home/user/data_store/TEST/test_sample/processed/ --seqBias --gcBias --dumpEq --writeUnmappedNames; ```. **Expected behavior**; This happened while I was modifying the tests for running salmon. I'm guessing that my code isn't quite right yet so something going wrong isn't quite unexpected. However I would have expected an error to come out of Salmon rather than producing JSON which is invalid. **Desktop (please complete the following inf",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/279:1450,test,test-assets,1450,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/279,1,['test'],['test-assets']
Testability,"ads:. `minimap2 -ax splice:hq -uf ref.fa reads.fq > aln.sam`. This approach seems to employ a splicing aware algorithm against a genomic reference, using canonical splicing signals to help map the transcripts. However, this method doesn't seem to be applicable to Salmon given the requirement that the reads are aligned directly to the transcriptome (hence the need to account for splicing with '_-ac splice_' is lost). An alternative approach I've seen (i.e., the one used in ONT's own DGE [pipeline](https://github.com/nanoporetech/pipeline-transcriptome-de)) is to use minimap2 to align to the transcriptome reference but to retain a large number of secondary mappings (-N 100 in minimap2):. `minimap2 -ax map-ont -N 100 transcriptome.fa reads.fq`. This makes more sense in terms of the _-ax_ preset used, but I guess I'm just wondering then what the optimal input for Salmon would be in order to get the most accurate count data? I know secondary mappings are important for the algorithm to calculate uncertainty / maximum likelihood, but is there an recommend number of these to retain? The logic behind allowing for a high number of secondary alignments when using a transcriptome reference is to account for the high similarity among isoforms. From a high-level view I could see how this might be problematic though, depending on how Salmon actually uses the alternate mappings (i.e., is it just for the statistics or does it affect the counts as well?). . I've also seen groups toying with adjusting the _-p_ setting in minimap2 which sets the minimal ratio of the secondary to primary alignment score that is allowed in order to report the secondary mapping. Surveying the forums and discussion boards, values of _-N_ ranging from the default of 5 to 100 and of _-p_ ranging from 0 to 1, (i.e., anything) seem to be acceptable. Given this ambiguity, I figured going to the 'source' and asking the creators what Salmon actually wants might be beneficial, so if yall have done any testing or ha",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/790:1765,log,logic,1765,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/790,1,['log'],['logic']
Testability,"al # of Contigs : 23; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Total # of numerical Contigs : 23; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Total # of contig vec entries: 36; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] bits per offset entry 6; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Done constructing the contig vector. 24; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] # segments = 23; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] total length = 19592; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Reading the reference files ...; [2023-03-10 05:51:33.750] [puff::index::jointLog] [info] positional integer width = 15; [2023-03-10 05:51:33.750] [puff::index::jointLog] [info] seqSize = 19592; [2023-03-10 05:51:33.750] [puff::index::jointLog] [info] rankSize = 19592; [2023-03-10 05:51:33.750] [puff::index::jointLog] [info] edgeVecSize = 0; [2023-03-10 05:51:33.750] [puff::index::jointLog] [info] num keys = 18902; for info, total work write each : 2.331 total work inram from level 3 : 4.322 total work raw : 25.000; [Building BooPHF] 100 % elapsed: 0 min 0 sec remaining: 0 min 0 sec; Bitarray 105024 bits (100.00 %) (array + ranks ); final hash 0 bits (0.00 %) (nb in final hash 0); [2023-03-10 05:51:33.781] [puff::index::jointLog] [info] mphf size = 0.0125198 MB; [2023-03-10 05:51:33.781] [puff::index::jointLog] [info] chunk size = 9796; [2023-03-10 05:51:33.781] [puff::index::jointLog] [info] chunk 0 = [0, 9796); [2023-03-10 05:51:33.781] [puff::index::jointLog] [info] chunk 1 = [9796, 19562); [2023-03-10 05:51:33.784] [puff::index::jointLog] [info] finished populating pos vector; [2023-03-10 05:51:33.784] [puff::index::jointLog] [info] writing index components; [2023-03-10 05:51:33.784] [puff::index::jointLog] [info] finished writing dense pufferfish index; [2023-03-10 05:51:33.784] [jLog] [info] done building index; ```. So on `testing` at least, I can't yet reproduce this issue.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554:5512,test,testing,5512,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554,1,['test'],['testing']
Testability,"alevin (single-cell mode). **Describe the bug**; Getting error "" Size of the feature file doesn't match"" in the log file while starting to make feature Matrix. Latest version of Salmon was used",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/407:112,log,log,112,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/407,1,['log'],['log']
Testability,"alevin (single-cell mode). **Describe the bug**; I receive the following ERROR: Txp to Gene Map not found for 102926 transcripts. **To Reproduce**; /usr/local/bin/salmon alevin -lISR -1 cells_CTTGTA_L001_R1_001.fastq.gz -2 cells_CTTGTA_L001_R2_001.fastq.gz --celseq2 -i AlevinIndex/ -p 8 -o alevin_output --tgMap gencode.primary_assembly.tsv. Specifically, please provide at least the following information:. * v0.12.0, compiled ; * FASTA file labeled ""Transcript sequences"" from https://www.gencodegenes.org/human/ ; * GTF file labeled ""Comprehensive gene annotation - PRI"" from https://www.gencodegenes.org/human/. **Expected behavior**; To receive the following files in the output dir; quants_mat.gz – Compressed count matrix.; quants_mat_cols.txt – Column Header (Gene-ids) of the matrix.; quants_mat_rows.txt – Row Index (CB-ids) of the matrix. [alevin.log](https://github.com/COMBINE-lab/salmon/files/2638932/alevin.log); [salmon_quant.log](https://github.com/COMBINE-lab/salmon/files/2638934/salmon_quant.log). The tgMap was created using `tximport` in R; ```; library(tximport); gtf <- paste0(local_path, ""/gencode.v29.annotation.gtf""); txdb <- makeTxDbFromGFF(gtf); txdf <- select(txdb, keys(txdb, ""GENEID""), ""TXNAME"", ""GENEID"") . txdf_switch <- data.frame(txdf$TXNAME, txdf$GENEID) #in order to switch the order TXNAME and GENEID apppear. write_tsv(txdf_switch, paste0(local_path, ""/gencode_annot/gencode.primary_assembly.v29.tsv""), col_names = FALSE). ```",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/326:859,log,log,859,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/326,4,['log'],['log']
Testability,"alevin (single-cell mode). I am trying to run alevin using a space separated list of (20) files as input. The fastq files we received from sequencing, were separated arbitrarily to keep them at about ~200 MB a file, but they are all the same sample and I wish to treat them as one library. There is no error produced, but it has been running for ~15 hours, and the log files are blank. As a side note, running each ""pair"" works just fine. . v0.12.1; compiled from source ; OS - Ubuntu Linux, x86_64 x86_64 x86_64 GNU/Linux. Alevin is supposed to be able to run with multiple read files, as specified here: https://github.com/COMBINE-lab/salmon/blob/master/doc/source/salmon.rst#providing-multiple-read-files-to-salmon. ```; Logs will be written to /alevin_outputSingleLibrary/quantSC/logs; ### alevin (dscRNA-seq quantification) v0.12.1; ### [ program ] => salmon ; ### [ command ] => alevin ; ### [ index ] => { AlevinIndex/ }; ### [ libType ] => { ISR }; ### [ mates1 ] => { 12_CTTGTA_L001_R1_001.fastq.gz 12_CTTGTA_L001_R1_002.fastq.gz 12_CTTGTA_L001_R1_003.fastq.gz 12_CTTGTA_L001_R1_004.fastq.gz 12_CTTGTA_L001_R1_005.fastq.gz 12_CTTGTA_L001_R1_006.fastq.gz 12_CTTGTA_L001_R1_007.fastq.gz 12_CTTGTA_L001_R1_008.fastq.gz 12_CTTGTA_L001_R1_009.fastq.gz 12_CTTGTA_L001_R1_010.fastq.gz 12_CTTGTA_L002_R1_001.fastq.gz 12_CTTGTA_L002_R1_002.fastq.gz 12_CTTGTA_L002_R1_003.fastq.gz 12_CTTGTA_L002_R1_004.fastq.gz 12_CTTGTA_L002_R1_005.fastq.gz 12_CTTGTA_L002_R1_006.fastq.gz 12_CTTGTA_L002_R1_007.fastq.gz 12_CTTGTA_L002_R1_008.fastq.gz 12_CTTGTA_L002_R1_009.fastq.gz 12_CTTGTA_L002_R1_010.fastq.gz }; ### [ mates2 ] => { 12_CTTGTA_L001_R2_001.fastq.gz 12_CTTGTA_L001_R2_002.fastq.gz 12_CTTGTA_L001_R2_003.fastq.gz 12_CTTGTA_L001_R2_004.fastq.gz 12_CTTGTA_L001_R2_005.fastq.gz 12_CTTGTA_L001_R2_006.fastq.gz 12_CTTGTA_L001_R2_007.fastq.gz 12_CTTGTA_L001_R2_008.fastq.gz 12_CTTGTA_L001_R2_009.fastq.gz 12_CTTGTA_L001_R2_010.fastq.gz 12_CTTGTA_L002_R2_001.fastq.gz 12_CTTGTA_L002_R2_002.fastq.gz 12_CTTGTA",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/329:365,log,log,365,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/329,3,"['Log', 'log']","['Logs', 'log', 'logs']"
Testability,"alevinLog] [info] parsing read library format; > [2020-06-04 17:57:36.339] [alevinLog] [info] Starting optimizer; > ; > ; > [2020-06-04 17:57:37.051] [alevinLog] [warning] mrna file not provided; using is 1 less feature for whitelisting; > [2020-06-04 17:57:37.051] [alevinLog] [warning] rrna file not provided; using is 1 less feature for whitelisting; > [2020-06-04 17:57:37.338] [alevinLog] [info] Total 23937.00 UMI after deduplicating.; > [2020-06-04 17:57:37.338] [alevinLog] [info] Total 91 BiDirected Edges.; > [2020-06-04 17:57:37.338] [alevinLog] [info] Total 82 UniDirected Edges.; > [2020-06-04 17:57:37.338] [alevinLog] [warning] Skipped 82268 barcodes due to No mapped read; > [2020-06-04 17:57:37.341] [alevinLog] [info] Clearing EqMap; Might take some time.; > [2020-06-04 17:57:37.348] [alevinLog] [warning] Num Low confidence barcodes too less 1 < 10.Can't performing whitelisting; Skipping; > [2020-06-04 17:57:37.348] [alevinLog] [info] Finished optimizer; > ; > . salmon_quant.log. > [2020-06-04 17:55:11.700] [jointLog] [info] setting maxHashResizeThreads to 7; > [2020-06-04 17:55:11.700] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; > [2020-06-04 17:55:11.700] [jointLog] [info] The --mimicBT2, --mimicStrictBT2 and --hardFilter flags imply mapping validation (--validateMappings). Enabling mapping validation.; > [2020-06-04 17:55:11.700] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; > [2020-06-04 17:55:11.700] [jointLog] [info] The use of range-factorized equivalence classes does not make sense in conjunction with --hardFilter. Disabling range-factorized equivalence classes. ; > [2020-06-04 17:55:11.700] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.35.; > [2020-06-04 17:55:11.700] [jointLog] [info] Using default value of 0.797619 for minScoreF",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639196415:2691,log,log,2691,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639196415,1,['log'],['log']
Testability,"alevinLog] [info] parsing read library format; [2019-06-06 19:24:55.716] [jointLog] [info] There is 1 library.; [2019-06-06 19:24:55.889] [jointLog] [info] Loading Quasi index; [2019-06-06 19:24:55.889] [jointLog] [info] Loading 32-bit quasi index; [2019-06-06 19:24:55.890] [stderrLog] [info] Loading Suffix Array ; [2019-06-06 19:24:56.791] [stderrLog] [info] Loading Transcript Info ; [2019-06-06 19:24:57.025] [stderrLog] [info] Loading Rank-Select Bit Array; [2019-06-06 19:24:57.061] [stderrLog] [info] There were 136,011 set bits in the bit array; [2019-06-06 19:24:57.084] [stderrLog] [info] Computing transcript lengths; [2019-06-06 19:24:57.084] [stderrLog] [info] Waiting to finish loading hash; [2019-06-06 19:25:06.552] [jointLog] [info] done; [2019-06-06 19:25:06.552] [jointLog] [info] Index contained 136,011 targets; [2019-06-06 19:25:06.552] [stderrLog] [info] Done loading index; [2019-06-06 19:25:06.728] [alevinLog] [error] Barcode not found in frequency table; ```. Salmon Quant log is this. ```; [2019-06-06 19:23:29.519] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-06-06 19:23:29.519] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2019-06-06 19:23:29.520] [jointLog] [info] Usage of --validateMappings, without --hardFilter implies use of range factorization. rangeFactorizationBins is being set to 4; [2019-06-06 19:23:29.520] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.2.; [2019-06-06 19:23:29.520] [jointLog] [info] Using default value of 0.87 for minScoreFraction in Alevin; Using default value of 0.6 for consensusSlack in Alevin; [2019-06-06 19:24:55.716] [jointLog] [info] There is 1 library.; [2019-06-06 19:24:55.889] [jointLog] [info] Loading Quasi index; [2019-06-06 19:24:55.889] [jointLog] [info] Loading 32-bit quasi index; [2019",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/369#issuecomment-499592790:2145,log,log,2145,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/369#issuecomment-499592790,1,['log'],['log']
Testability,"alloc tbbmalloc_proxy; TBB_LIBRARIES = /apps/gentoo/usr/lib/libtbbmalloc_proxy.so;/apps/gentoo/usr/lib/libtbbmalloc.so;/apps/gentoo/usr/lib/libtbb.so; Build system will compile libgff; ==================================================================; ==================================================================; Build system will compile Staden IOLib; ==================================================================; Build system will fetch SPDLOG; ==================================================================; -- Found PkgConfig: /apps/gentoo/usr/bin/pkg-config (found version ""0.29.2""); -- Found Jemalloc: /apps/gentoo/usr/lib/libjemalloc.so (found version """"); Found Jemalloc library --- using this memory allocator; CPACK_SOURCE_IGNORE_FILES = /src/PCA.cpp;/src/PCAUtils.cpp;/build/;/scripts/AggregateToGeneLevel.py;/scripts/ExpressionTools.py;/scripts/GenerateExpressionFiles.sh;/scripts/ParseSoftFile.py;/scripts/PlotCorrelation.py;/scripts/junk;/scripts/sfstrace.log;/scripts/SFPipeline.py;/bin/;/lib/;/sample_data/;PublishREADMEToWebsite.sh;/external/;/src/obsolete/;/include/obsolete/;WebsiteHeader.txt;/experimental_configs/;.git/; TBB_LIBRARIES = /apps/gentoo/usr/lib/libtbbmalloc_proxy.so;/apps/gentoo/usr/lib/libtbbmalloc.so;/apps/gentoo/usr/lib/libtbb.so; -- Configuring done; CMake Error at src/CMakeLists.txt:158 (add_executable):; Cannot find source file:. $blah/salmon-0.10.2/external/install/src/rapmap/RapMapFileSystem.cpp. Tried extensions .c .C .c++ .cc .cpp .cxx .cu .m .M .mm .h .hh .h++ .hm; .hpp .hxx .in .txx. CMake Error at src/CMakeLists.txt:160 (add_executable):; Cannot find source file:. $blah/salmon-0.10.2/external/install/src/rapmap/rank9b.cpp. Tried extensions .c .C .c++ .cc .cpp .cxx .cu .m .M .mm .h .hh .h++ .hm; .hpp .hxx .in .txx. CMake Error at src/CMakeLists.txt:158 (add_executable):; No SOURCES given to target: salmon. CMake Error at src/CMakeLists.txt:160 (add_executable):; No SOURCES given to target: unitTests. -- Build files have ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-399775387:4606,log,log,4606,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-399775387,1,['log'],['log']
Testability,"almon index -t {input.seqs} -i {params.index_dir} --decoys {input.decoys} -k 31; '''; ```. I've attached my reference transcriptome and my file of decoy names at the bottom of this issue. Details -- . * Which version of salmon was used?: 1.6.0; * How was salmon installed (compiled, downloaded executable, through bioconda)?: Miniconda; * Which reference (e.g. transcriptome) was used?: Self-generated; * Which read files were used?: ERX4307280, SRX10245671, SRX3847835; * Which which program options were used?. ```; salmon quant -i {params.index_dir} -l A -r {input.reads} -o {params.out_dir} --validateMappings --writeUnmappedNames; ```. **Expected behavior**; I expected the reads that were counted in the log file as ""discarded because they are best-mapped to decoys"" to be labelled in the `aux_info/unmapped_names.txt` file with `d`, but all reads were marked as `u`. **Screenshots**; ```; $grep ""Number of fragments discarded because they are best-mapped to decoys"" */logs/*. ERX4307280_quant/logs/salmon_quant.log:[2022-02-02 15:51:25.854] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 948,850; SRX10245671_quant/logs/salmon_quant.log:[2022-02-02 15:57:10.321] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 961,758; SRX3847835_quant/logs/salmon_quant.log:[2022-02-02 15:33:54.185] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 220,351; ```. **Desktop (please complete the following information):**; - OS: Linux; - Version: ; ```; Linux farm.cse.ucdavis.edu 4.15.0-159-generic #167-Ubuntu SMP Tue Sep 21 08:55:05 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux; ```; ```; No LSB modules are available.; Distributor ID:	Ubuntu; Description:	Ubuntu 18.04.6 LTS; Release:	18.04; Codename:	bionic; ```; **Additional context**; I intentionally mapped all three libraries as SE, even though two are PE. Because of the presence of polycistronic transcripts in microbes, many pair",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/748:4309,log,logs,4309,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/748,1,['log'],['logs']
Testability,"almon-0.13.1/build && /usr/local/Cellar/cmake/3.13.4/bin/cmake -E cmake_depends ""Unix Makefiles"" /Users/gabriel/Projects/salmon-0.13.1 /Users/gabriel/Projects/salmon-0.13.1 /Users/gabriel/Projects/salmon-0.13.1/build /Users/gabriel/Projects/salmon-0.13.1/build /Users/gabriel/Projects/salmon-0.13.1/build/CMakeFiles/libstadenio.dir/DependInfo.cmake --color=; /Applications/Xcode.app/Contents/Developer/usr/bin/make -f CMakeFiles/libstadenio.dir/build.make CMakeFiles/libstadenio.dir/build; [ 9%] Performing configure step for 'libstadenio'; cd /Users/gabriel/Projects/salmon-0.13.1/external/staden-io_lib && ./configure --enable-shared=no --without-libcurl --prefix=/Users/gabriel/Projects/salmon-0.13.1/external/install LDFLAGS= CFLAGS= CC=/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/cc CXX=/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/c++; checking for a BSD-compatible install... /usr/local/bin/ginstall -c; checking whether build environment is sane... yes; checking for a thread-safe mkdir -p... /usr/local/bin/gmkdir -p; checking for gawk... gawk; checking whether make sets $(MAKE)... yes; checking whether make supports nested variables... yes; checking whether to enable maintainer-specific portions of Makefiles... no; checking for gcc... /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/cc; checking whether the C compiler works... yes; checking for C compiler default output file name... a.out; checking for suffix of executables...; checking whether we are cross compiling... configure: error: in `/Users/gabriel/Projects/salmon-0.13.1/external/staden-io_lib':; configure: error: cannot run C compiled programs.; If you meant to cross compile, use `--host'.; See `config.log' for more details; make[2]: *** [libstadenio-prefix/src/libstadenio-stamp/libstadenio-configure] Error 1; make[1]: *** [CMakeFiles/libstadenio.dir/all] Error 2; make: *** [all] Error 2; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/348#issuecomment-472500713:3253,log,log,3253,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/348#issuecomment-472500713,1,['log'],['log']
Testability,"and for the detailed report! This is an interesting observation. The most likely reason you are seeing this behavior is that the fast mapping algorithms are, in a sense, quite greedy in how they attempt to map reads. This can lead them to suffer with compared to more traditional alignment algorithms like Bowtie2 and BWA-MEM with respect to both sensitivity and specificity. Here, you are likely seeing a manifestation of the former. Specifically, greedy behavior can lead to spurious matches. Many of these spurious matches are filtered out when applying a consensus mechanism to the series of matches produced by a read; however, this can result in the read going unmapped. We have noticed this behavior where spurious matches can ""mask"" better overall mappings, and we have developed an algorithm to overcome these limitations (called selective-alignment). This is currently implemented in [this branch](https://github.com/COMBINE-lab/salmon/tree/rescue-orphan) of the Salmon repo (if you want to test it out and have trouble building, we can build you a linux executable). This algorithm explores more potential mappings and then applies a fast algorithm for filtering potentially poor ones. In our benchmarks, it exhibits sensitivity and specificity very close to Bowtie2 (which is among the best of the alignment-based methods we considered). Also, I will note that, though the speed and statistical optimization procedures used in fast transcript abundance estimation tools make them a potentially desirable choice for microbiomic / metagenomic abundance estimation, their indices are typically optimized for speed and not size. For small numbers of bacterial species this can be okay, but if one wishes to index large collections of species, the memory usage can become a problem. To this end, we have developed a new indexing scheme (software [here](https://github.com/COMBINE-lab/pufferfish), slightly out-of-date pre-print [here](https://www.biorxiv.org/content/early/2017/09/21/191874)).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/196#issuecomment-365337297:1041,test,test,1041,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/196#issuecomment-365337297,1,['test'],['test']
Testability,"ap to a decoy, and is not used for the purposes of quantification. Consistent with the behavior I hypothesized above for STAR, if you have many softclipped bases at the end of the read that nonetheless match what is in the genome downstream of the end of the annotated transcript, you'll likely see these reads assigned as decoys. To check this, you can look at salmon's `meta_info.json` output file to see how many reads were mapped best to decoys. * Why do I see much higher counts for this gene with FeatureCounts?. * It depends on the specific behavior you invoke. However, my guess is that FeatureCounts is being run with flags such that reads that only somewhat overlap a feature are nonetheless assigned to it. This suggests that while no good alignment may actually exist to the annotated transcript, FeatureCounts is still assigning the read to that feature because it overlaps it to some degree and matches the corresponding location on the genome. Again, you can test this by changing the required overlap fraction of FeatureCounts. * Why does running salmon outside of nf-core produce much higher counts?. * Since you are indexing *just* the transcriptome, and not including the genome as decoy sequence (as is done in nf-core), then the only thing that will prevent reads from being assigned to the gene in question is if so much of the read overhangs off the end of the annotated transcript that no mapping matches the minimum required alignment score. This is likely to be a much more liberal threshold than what STAR allows, so it also explains why you see higher counts than when alignment mode is used. * Other thoughts / suggestions?. * So, there are several things that you might consider doing if you believe the correct behavior in your case is to assign these reads to such genes. First, when run in mapping mode, salmon has a `--softclipOverhangs` flag that will further reduce the penalty for reads overhanging the annotated end of a transcript. This will allow more reads to ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/798#issuecomment-1237133883:2627,test,test,2627,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/798#issuecomment-1237133883,1,['test'],['test']
Testability,"apping,; with only a moderate increase in use of computational resources. ; Mapping validation is planned to become a default option (i.e. turned on by default) in; the next release of salmon.; Unless there is a specific reason to do this (e.g. testing on clean simulated data),; `--validateMappings` is generally recommended. [2019-07-24 13:33:30.080] [jointLog] [info] parsing read library format; [2019-07-24 13:33:30.080] [jointLog] [info] There is 1 library.; /var/spool/slurmd/job12930414/slurm_script: line 14: --validateMappings: command not found; basename: extra operand ‘lightreceptor-1_S114_L005_R1_001.qc.fq.gz’; Try 'basename --help' for more information.; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { abalone_index }; ### [ libType ] => { A }; ### [ mates1 ] => { .R1_001.qc.fq.gz }; ### [ mates2 ] => { .R2_001.qc.fq.gz }; ### [ output ] => { .quant }; Logs will be written to .quant/logs; [2019-07-24 13:33:30.175] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-07-24 13:33:30.175] [jointLog] [warning] . NOTE: It appears you are running salmon without the `--validateMappings` option.; Mapping validation can generally improve both the sensitivity and specificity of mapping,; with only a moderate increase in use of computational resources. ; Mapping validation is planned to become a default option (i.e. turned on by default) in; the next release of salmon.; Unless there is a specific reason to do this (e.g. testing on clean simulated data),; `--validateMappings` is generally recommended. [2019-07-24 13:33:30.175] [jointLog] [info] parsing read library format; [2019-07-24 13:33:30.175] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file abalone_index/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was inv",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408:15592,Log,Logs,15592,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408,1,['Log'],['Logs']
Testability,"appings that result when one considers only the transcriptome as a source of mapping. There are a number of ways to proceed on this front, but this is a good place to first check for discrepancy (and the paper gives a good overview of the relative tradeoffs and merits of different alignment approaches). * Salmon and RSEM use related but distinct optimization algorithms by default. RSEM uses the EM algorithm, and salmon uses the variational Bayesian EM algorithm. The latter tends to induce more sparse solutions. This is simply because they are optimizing slightly different objectives. It is very difficult to say in general if one is ""better"" than the other in a blanket way, but [there is previous literature to support that the VBEM may be more accurate](https://academic.oup.com/bioinformatics/article/29/18/2292/239795). However, while RSEM only implements the EM algorithm, salmon actually implements and provides a switch to use either. So, if you want to test the effect of this difference, you can run salmon with the `--useEM` algorithm. This will tell salmon to use the ""classic"" EM algorithm and will eliminate this source of variation. * As with the other question you asked, there may be a _small_ discrepancy depending on when enforcement of a stranded library kicks in under salmon's `A` library type. You can eliminate that variable by simply providing `-l SF` to match the library type being used with RSEM. * Coming back to the `IndelSoftclipSingleend` parameter I mentioned in the first point; RSEM disallows indels in the alignments that it quantifies. This means that to produce RSEM-compatible input, STAR must not align reads that contain indels. While this won't generally have a big effect for many transcripts, it can certainly affect the abundance estimates for transcripts in your sample where the sample you are quantifying has (indel) variation with respect to the reference annotation. We touch upon that a bit as well in the [paper I mentioned above](https://gen",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/612#issuecomment-758004590:3282,test,test,3282,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/612#issuecomment-758004590,2,['test'],['test']
Testability,"are always about 50% percent reads has been thrown away, and the mapping rate was between 18.7%-19.1%. . the salmon version is `salmon 1.4.0`; the reference genome is sequenced by ourselves, and it's a plant.; my reads layout is paired end 150bp, . > R1: ; @A00582:424:HJYLGDSXY:3:1101:1090:1000 1:N:0:ACCGGCTC; TAACCAGGTCGAGTGAGTATTTAAGGCGCGCGGCGCACCAACGCACTCCCAACAACAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA; > +; FFFFFFFFFFFFFFFFFFFFFFFFFFFF,,:,,FF:,,,::FF,,:F,,,,,,F:,,,:,::FF::::::,FFF:F:FF:FFFFFFF::FF::FF,F:F:FF:F,FFFF,:FF,FFFFF:,FF:::FF:FFF:FF:FF:FFFFFFFFFF:; > R2:; @A00582:424:HJYLGDSXY:3:1101:1090:1000 2:N:0:ACCGGCTC; NCCTAGAAGCAGCCACCCTTGAAAGAGTGCGTAATAGCTCACTGATCGAGCGCTCTTGCGCCGAAGATGAACGGGGCTAAGCGATCTGCCGAAGCTGTGGGATGTAAAAATACATCGGTAGGGGAGCGTTCCGCCTTAGAGAGAAGCCTC; > +; #FF:FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF:FFFFFFFFFFFFFFFFFFFFFFFFFFF:FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF:FFFFFFFFFFFF::FFFFFFFFFF:FFFFFFFFFFFFF:FFFFFF:FFFFFFF:. Here is the logs. ## Default setting ; `salmon alevin -l ISR -1 ../clean/sample_S1_L001_R1_001.fastq -2 ../clean/sample_S1_L001_R2_001.fastq --chromiumV3 -i ../../dna/00.ref_genome/sample/salmon_index_allmRNA -p 40 -o test_alevin_allmRNA --tgMap ../../dna/00.ref_genome/sample/alltxp2gene.tsv`. > [2021-01-25 16:22:09.565] [alevinLog] [info] Found 43030 transcripts(+0 decoys, +0 short and +0 duplicate names in the index); [2021-01-25 16:22:09.615] [alevinLog] [info] Filled with 43030 txp to gene entries; [2021-01-25 16:22:09.620] [alevinLog] [info] Found all transcripts to gene mappings; [2021-01-25 16:22:09.631] [alevinLog] [info] Processing barcodes files (if Present); [2021-01-25 16:26:35.067] [alevinLog] [info] Done barcode density calculation.; [2021-01-25 16:26:35.067] [alevinLog] [info] # Barcodes Used: 188934609 / 188934609.; [2021-01-25 16:26:42.979] [alevinLog] [info] Knee found left boundary at 21; [2021-01-25 16:27:05.707] [alevinLog] [warning] Gauss Prediction 4969 Too far from knee",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/340#issuecomment-766311567:1377,log,logs,1377,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/340#issuecomment-766311567,1,['log'],['logs']
Testability,"arget salmon_core; [ 77%] Built target unitTests; [100%] Built target salmon; Install the project...; -- Install configuration: ""Release""; -- Installing: /salmon-0.10.2/lib; -- Installing: /salmon-0.10.2/lib/libtbb.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc_proxy.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc.so.2; -- Installing: /salmon-0.10.2/lib/libtbb.so.2; -- Installing: /salmon-0.10.2/lib/pkgconfig; -- Installing: /salmon-0.10.2/lib/libtbbmalloc_proxy.so.2; -- Installing: /salmon-0.10.2/bin/salmon; -- Installing: /salmon-0.10.2/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly.; ==========================================================================; Please add /salmon-0.10.2/bin to your PATH; Please add /salmon-0.10.2/lib to your LD_LIBRARY_PATH; ==========================================================================; root@e08cc9670e4a:/salmon-0.10.2/build# make test; Running tests...; Test project /salmon-0.10.2/build; Start 1: unit_tests; 1/3 Test #1: unit_tests ....................... Passed 0.17 sec; Start 2: salmon_read_test_fmd; 2/3 Test #2: salmon_read_test_fmd ............. Passed 1.78 sec; Start 3: salmon_read_test_quasi; 3/3 Test #3: salmon_read_test_quasi ........... Passed 1.59 sec. 100% tests passed, 0 tests failed out of 3. Total Test time (real) = 3.54 sec; root@e08cc9670e4a:/salmon-0.10.2/build# lsb_release -a; LSB Version: core-9.20160110ubuntu0.2-amd64:core-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-amd64:security-9.20160110ubuntu0.2-noarch; Distributor ID: Ubuntu; Description: Ubuntu 16.04.4 LTS; Release: 16.04; Codename: xenial; ```. I built with:. `$ cmake -DFETCH_BOOST=TRUE .. && make install && make test`. I can also install the boost via apt and see if that makes a difference (though I expect not since it looked like TBB was the issue, and I let cmake install that). We can also check our compiler versions, per",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268:1863,test,test,1863,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268,2,['test'],"['test', 'tests']"
Testability,"aseII; #$ -m e; echo ""**** Job starts ****""; date. echo ""**** JHPCE info ****""; echo ""User: ${USER}""; echo ""Job id: ${JOB_ID}""; echo ""Job name: ${JOB_NAME}""; echo ""Hostname: ${HOSTNAME}""; echo ""Task id: ${TASK_ID}"". FILE1=$(awk 'BEGIN {FS=""\t""} {print $1}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); if [ TRUE == ""TRUE"" ] ; then; FILE2=$(awk 'BEGIN {FS=""\t""} {print $3}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); fi; ID=$(cat /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk '{print $NF}' | awk ""NR==${SGE_TASK_ID}""). mkdir -p /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/${ID}. strace /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant 	-i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts -p 1 -l ISR 	-1 ${FILE1} -2 ${FILE2} 	-o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/${ID} 2> logs/strace_test12_${SGE_TASK_ID}.txt. echo ""**** Job ends ****""; date; ```. Again, here is the `strace` output for task 1 (411 lines):. ```; execve(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", [""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""quant"", ""-i"", ""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""-p"", ""1"", ""-l"", ""ISR"", ""-1"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-2"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-o"", ""/dcl01/lieber/ajaffe/lab/libd_al""...], [/* 107 vars */]) = 0; brk(0) = 0xc2c000; mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbfffd000; readlink(""/proc/self/exe"", ""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", 4096) = 88; access(""/etc/ld.so.preload"", R_OK) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/../lib/tls/x86_64/libpthread.so.0",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:79035,log,logs,79035,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['log'],['logs']
Testability,"ash; $ qacct -j 9987275 -t 3; ==============================================================; qname shared.q; hostname compute-051.cm.cluster; group lieber_jaffe; owner lcollado; project NONE; department defaultdepartment; jobname step6-salmon_test.gsk_phaseII; jobnumber 9987275; taskid 3; account sge; priority 0; qsub_time Wed Mar 8 11:37:17 2017; start_time Wed Mar 8 11:37:31 2017; end_time Wed Mar 8 11:37:36 2017; granted_pe local; slots 1; failed 0; exit_status 0; ru_wallclock 5; ru_utime 0.368; ru_stime 3.680; ru_maxrss 537668; ru_ixrss 0; ru_ismrss 0; ru_idrss 0; ru_isrss 0; ru_minflt 21951; ru_majflt 282; ru_nswap 0; ru_inblock 56; ru_oublock 1066296; ru_msgsnd 0; ru_msgrcv 0; ru_nsignals 0; ru_nvcsw 1230; ru_nivcsw 53; cpu 4.048; mem 27.889; io 0.002; iow 0.000; maxvmem 10.736G; arid undefined; ```. I'm sure that the job got terminated because the memory reached the limit of 11 GB. . I previously did several tests where for a file the max memory reported was about 9 GB when requesting about 100G of RAM, and the same job kept failing even if I requested 10G, 20G, 30G, 40G... I didn't save the info then to report the problem. . Back on these tests, I then increased the memory requested a bit more (and used the `-m e` SGE option to get an email with the max vmem, which matches the `qacct` output). Here is the bash script:. ```bash; #!/bin/bash; #$ -cwd; #$ -l mem_free=14G,h_vmem=15G,h_fsize=100G; #$ -N step6-salmon_test2.gsk_phaseII; #$ -pe local 1; #$ -o ./logs/salmon_test2.$TASK_ID.txt; #$ -e ./logs/salmon_test2.$TASK_ID.txt; #$ -m e; echo ""**** Job starts ****""; date. echo ""**** JHPCE info ****""; echo ""User: ${USER}""; echo ""Job id: ${JOB_ID}""; echo ""Job name: ${JOB_NAME}""; echo ""Hostname: ${HOSTNAME}""; echo ""Task id: ${TASK_ID}"". FILE1=$(awk 'BEGIN {FS=""\t""} {print $1}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); FILE2=$(awk 'BEGIN {FS=""\t""} {print $3}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.mani",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126:26563,test,tests,26563,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126,1,['test'],['tests']
Testability,"astq/R10001_D2B1WACXX.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 6.3G Feb 20 12:40 merged_fastq/R10001_D2B1WACXX_read2.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 4.6G Feb 20 12:42 merged_fastq/R10002_C29P7ACXX.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 4.7G Feb 20 12:44 merged_fastq/R10002_C29P7ACXX_read2.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 7.1G Feb 20 12:47 merged_fastq/R10003_D19KGACXX.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 7.1G Feb 20 12:50 merged_fastq/R10003_D19KGACXX_read2.fastq.gz; ```. where R10001* is task 1, R10002* is task 2, R10003* is task 3. So it looks like at some point Salmon is asking for some memory based on the input data. ## Strace test with low memory (but above reported usage when requesting 90GB). Mark taught me about `strace` and we ran the following test:. ```bash; #!/bin/bash; #$ -cwd; #$ -pe local 2; #$ -l mem_free=7G,h_vmem=8G,h_fsize=100G; #$ -N step6-salmon_test11.gsk_phaseII; #$ -o ./logs/salmon_test11.$TASK_ID.txt; #$ -e ./logs/salmon_test11.$TASK_ID.txt; #$ -t 1-3; #$ -hold_jid pipeline_setup,step4-featCounts-alzheimer.gsk_phaseII; #$ -m e; echo ""**** Job starts ****""; date. echo ""**** JHPCE info ****""; echo ""User: ${USER}""; echo ""Job id: ${JOB_ID}""; echo ""Job name: ${JOB_NAME}""; echo ""Hostname: ${HOSTNAME}""; echo ""Task id: ${TASK_ID}"". FILE1=$(awk 'BEGIN {FS=""\t""} {print $1}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); if [ TRUE == ""TRUE"" ] ; then; FILE2=$(awk 'BEGIN {FS=""\t""} {print $3}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); fi; ID=$(cat /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk '{print $NF}' | awk ""NR==${SGE_TASK_ID}""). mkdir -p /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/${ID}. strace /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant 	-i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:2480,log,logs,2480,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['log'],['logs']
Testability,"astq/fastqs/flowcell1/read-I1_si-CGAAGTTG_lane-003-chunk-003.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-CGAAGTTG_lane-004-chunk-002.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-GAGCACGC_lane-001-chunk-001.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-GAGCACGC_lane-002-chunk-000.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-GAGCACGC_lane-003-chunk-003.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-GAGCACGC_lane-004-chunk-002.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-001-chunk-001.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-002-chunk-000.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-003-chunk-003.fastq.gz; ./fastq/fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-004-chunk-002.fastq.gz]; Version Info: This is the most recent version of salmon.; [2018-12-06 11:14:56.513] [alevinLog] [info] A custom protocol (END, BC length, UMI length) = (5, 14, 5) is being used. Updating UMI k-mer length accordingly.; Logs will be written to ./fastq/test/logs; [2018-12-06 11:14:56.533] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; ### alevin (dscRNA-seq quantification) v0.12.0; ### [ program ] => salmon ; ### [ command ] => alevin ; ### [ libType ] => { ISR }; ### [ gemcode ] => { }; ### [ index ] => { ./transcripts_index_salmon/ }; ### [ threads ] => { 8 }; ### [ output ] => { ./fastq/test/ }; ### [ tgMap ] => { ./hg_transcriptome/tx2tx.tsv }; ### [ end ] => { 5 }; ### [ umiLength ] => { 5 }; ### [ barcodeLength ] => { 14 }; ### [ dumpCsvCounts ] => { }; ### [ mates1 ] => { /tmp/tmp.p28w2nGvAn/p1.fa }; ### [ mates2 ] => { /tmp/tmp.p28w2nGvAn/p2.fa }; ### [ unmatedReads ] => { ./fastq/fastqs/flowcell1/read-I1_si-ACTTCACT_lane-001-chunk-001.fastq.gz ./fastq/fastqs/flowcell1/read-I1_si-ACTTCACT_lane-002-chunk-000.fastq.gz ./fastq/fastqs/flowcell1/read-I1_si-ACTTCACT_lane-003-chunk-003.fastq.gz ./fastq/fastqs/flowcell1/read-I1_si-ACTTCACT_lane-004-chunk-002.fastq.gz ./fastq/fastqs/flowc",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-445008548:2184,test,test,2184,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-445008548,2,"['log', 'test']","['logs', 'test']"
Testability,"b/libtbb.so.12.5; -- Installing: /salmon/lib/libtbbmalloc.so; -- Installing: /salmon/lib/libtbbmalloc.so.2; -- Installing: /salmon/lib/libtbbmalloc.so.2.5; -- Installing: /salmon/lib/libtbbmalloc_proxy.so; -- Installing: /salmon/lib/libtbbmalloc_proxy.so.2; -- Installing: /salmon/lib/libtbbmalloc_proxy.so.2.5; -- Installing: /salmon/bin/salmon; -- Installing: /salmon/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly.; ==========================================================================; Please add /salmon/bin to your PATH; Please add /salmon/lib to your LD_LIBRARY_PATH; ==========================================================================; root@fd877e359439:/salmon/build# make test; Running tests...; Test project /salmon/build; Start 1: unit_tests; 1/2 Test #1: unit_tests ....................... Passed 0.37 sec; Start 2: salmon_read_test_quasi; 2/2 Test #2: salmon_read_test_quasi ........... Passed 1.80 sec. 100% tests passed, 0 tests failed out of 2. Total Test time (real) = 2.17 sec; ```. The `make test` command itself runs the test the builds the index and maps the reads against it. Either way, I can do that explicitly too (from within build):. ```; $ ./src/salmon index -t ../sample_data/transcripts.fasta -i sample_idx; ```. returns succesfully with a built index. ```; ...; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Done wrapping the rank vector with a rank9sel structure.; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] contig count for validation: 23; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Total # of Contigs : 23; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Total # of numerical Contigs : 23; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Total # of contig vec entries: 36; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] bits per offset entry 6; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Done constructing the contig vector",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554:2928,test,tests,2928,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554,2,['test'],['tests']
Testability,"b; -- Installing: /salmon-0.10.2/lib/libtbb.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc_proxy.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc.so.2; -- Installing: /salmon-0.10.2/lib/libtbb.so.2; -- Installing: /salmon-0.10.2/lib/pkgconfig; -- Installing: /salmon-0.10.2/lib/libtbbmalloc_proxy.so.2; -- Installing: /salmon-0.10.2/bin/salmon; -- Installing: /salmon-0.10.2/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly.; ==========================================================================; Please add /salmon-0.10.2/bin to your PATH; Please add /salmon-0.10.2/lib to your LD_LIBRARY_PATH; ==========================================================================; root@e08cc9670e4a:/salmon-0.10.2/build# make test; Running tests...; Test project /salmon-0.10.2/build; Start 1: unit_tests; 1/3 Test #1: unit_tests ....................... Passed 0.17 sec; Start 2: salmon_read_test_fmd; 2/3 Test #2: salmon_read_test_fmd ............. Passed 1.78 sec; Start 3: salmon_read_test_quasi; 3/3 Test #3: salmon_read_test_quasi ........... Passed 1.59 sec. 100% tests passed, 0 tests failed out of 3. Total Test time (real) = 3.54 sec; root@e08cc9670e4a:/salmon-0.10.2/build# lsb_release -a; LSB Version: core-9.20160110ubuntu0.2-amd64:core-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-amd64:security-9.20160110ubuntu0.2-noarch; Distributor ID: Ubuntu; Description: Ubuntu 16.04.4 LTS; Release: 16.04; Codename: xenial; ```. I built with:. `$ cmake -DFETCH_BOOST=TRUE .. && make install && make test`. I can also install the boost via apt and see if that makes a difference (though I expect not since it looked like TBB was the issue, and I let cmake install that). We can also check our compiler versions, perhaps. I have : . ```; root@e08cc9670e4a:/salmon-0.10.2/build# g++ --version; g++ (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609; Copyright (C) 2015 Free Software Foundati",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268:2043,Test,Test,2043,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268,1,['Test'],['Test']
Testability,"bb/2020.5-CentOS-vanilla/lib/libtbb.so -lgomp /usr/lib64/libjemalloc.so -lrt ../external/pufferfish/src/libksw2pp.a libalevin_core.a -ldl -pthread ; /tmp/cc91ASWS.ltrans1.ltrans.o: In function `boost::iostreams::basic_gzip_compressor<std::allocator<char> >::basic_gzip_compressor(boost::iostreams::gzip_params const&, long) [clone .constprop.783]':; <artificial>:(.text+0xdca4): undefined reference to `boost::iostreams::detail::zlib_base::zlib_base()'; <artificial>:(.text+0xdcbc): undefined reference to `boost::iostreams::detail::zlib_base::do_init(boost::iostreams::zlib_params const&, bool, void* (*)(void*, unsigned int, unsigned int), void (*)(void*, void*), void*)'; <artificial>:(.text+0xddc8): undefined reference to `boost::iostreams::zlib::best_compression'; <artificial>:(.text+0xddd4): undefined reference to `boost::iostreams::zlib::best_speed'; /tmp/cc91ASWS.ltrans1.ltrans.o: In function `GZipWriter::writeMtx(std::shared_ptr<spdlog::logger>&, boost::filesystem::path&, unsigned long, unsigned long, unsigned long) [clone .constprop.780]':; <artificial>:(.text+0xe056): undefined reference to `boost::iostreams::zlib::default_strategy'; <artificial>:(.text+0xe05d): undefined reference to `boost::iostreams::zlib::deflated'; <artificial>:(.text+0xe2d1): undefined reference to `boost::filesystem::detail::status(boost::filesystem::path const&, boost::system::error_code*)'; ...; ```. The boost related errors go on forever. There is nothing about ""boost"" in that command line, so apparently the relevant pieces never made it into the makefile. Running that very long command line with this added on the end:. ```; -L/usr/lib64/boost169 -lboost_filesystem -lboost_system -lboost_program_options -lboost_iostreams; ```; ; let Salmon link (with no other warnings). The resulting binary will do; ""salmon -h"" correctly but has so far not been tested further. So, in short CMakeLists.txt's handling of boost is still badly broken on CentOS, 8 this time, but it was terrible on 7 and 6 too.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641531162:4467,test,tested,4467,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641531162,1,['test'],['tested']
Testability,"be computationally challenging (at least for existing methods). zUMIs, for example, does an automatic barcode detection based on fixed barcode positions like we're doing here with alevin, so it would mis-detect cells like the shifted ones you pasted above. For SPLiT-seq, we do know exactly which barcodes go into the wells, however, so it is technically possible to restrict based on all possible known combinations of barcodes instead and be more positionally flexible. But deciding how many indel bases are allowable, and presumably doing multiple passes through the data to establish an include-list could be time-consuming. Further, the zUMIs developer rightly mentions [in this thread](https://github.com/sdparekh/zUMIs/issues/63) that there are likely going to be _many_ unused barcode combinations this way, so lots of time could be spent looking for ""cells"" that don't actually exist in the data. The authors of the paper from which our test dataset was derived describe in their methods using a Drop-seq computational framework, so I'm not sure which approach theirs is more similar to. . The simplest approach here is certainly the automatic detection, but it will come at the cost of losing meaningful reads to frameshift errors. . My guess is this falls well out of the scope of alevin, but if you're interested in improving on that, there may be a middle ground between the two approaches above, one that I'm not sure if your group or others have attempted for other methods: we could essentially do a 2-pass barcode detection. The first pass would restrict based on positions like we're already doing, and establish an include-list of possible barcodes seen in the data. Then we could pass through the barcode sequences a second time, looking only for those sequence combinations, but allowing 1-2bp flexibility in the positions they occur, potentially rescuing some of the ones missed during the first pass. This would get around the issue of searching for thousands (or more) barcodes",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-985554883:1019,test,test,1019,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-985554883,2,['test'],['test']
Testability,"big_info.tsv; │   ├── bootstrap; │   │   ├── bootstraps.gz; │   │   └── names.tsv.gz; │   ├── exp3_pos.gz; │   ├── exp3_seq.gz; │   ├── exp5_pos.gz; │   ├── exp5_seq.gz; │   ├── expected_bias.gz; │   ├── exp_gc.gz; │   ├── fld.gz; │   ├── meta_info.json; │   ├── obs3_pos.gz; │   ├── obs3_seq.gz; │   ├── obs5_pos.gz; │   ├── obs5_seq.gz; │   ├── observed_bias_3p.gz; │   ├── observed_bias.gz; │   └── obs_gc.gz; ├── cmd_info.json; ├── lib_format_counts.json; ├── libParams; │   └── flenDist.txt; ├── logs; │   └── salmon_quant.log; └── quant.sf. 5 directories, 23 files; ```. Not working:. ./salmon/bin/salmon quant -p 64 --index reference/salmon_index -l ISR -1 merged/1791-${id}_1P.fastq.gz -2 merged/1791-${id}_2P.fastq.gz --validateMappings --seqBias --gcBias --posBias --softclip --allowDovetail --recoverOrphans --numBootstraps 10 -o mapped/salmon_${id}. Not working produced the following file structure:. ```; salmon_03_withRecover; ├── aux_info; ├── libParams; └── logs; └── salmon_quant.log. 4 directories, 1 file; ```. The file `mapped/salmon_03_withRecover/logs/salmon_quant.log` has nothing inside it. **Expected behavior**. Properly-mapped reads, as demonstrated by the following metadata:. ```; {; ""salmon_version"": ""1.10.0"",; ""samp_type"": ""bootstrap"",; ""opt_type"": ""vb"",; ""quant_errors"": [],; ""num_libraries"": 1,; ""library_types"": [; ""ISR""; ],; ""frag_dist_length"": 1001,; ""frag_length_mean"": 158.48833607498765,; ""frag_length_sd"": 54.34014977759742,; ""seq_bias_correct"": true,; ""gc_bias_correct"": true,; ""num_bias_bins"": 4096,; ""mapping_type"": ""mapping"",; ""keep_duplicates"": false,; ""num_valid_targets"": 147493,; ""num_decoy_targets"": 61,; ""num_eq_classes"": 179681,; ""serialized_eq_classes"": false,; ""eq_class_properties"": [; ""range_factorized"",; ""gzipped""; ],; ""length_classes"": [; 496,; 768,; 1403,; 2707,; 100404; ],; ""index_seq_hash"": ""c0bf1b46db288bdf947208ef6410a0ced47fa770ab5284a1b231d958b283728b"",; ""index_name_hash"": ""db38822bce0fbc9a64cfb0b230f58119448d1c82706f1c515f210ccc",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/929:2436,log,log,2436,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/929,1,['log'],['log']
Testability,"biomart, and also generated a ENSMUST to ENSMUSG biomart.csv mapping file. Log is below. Since this is our first attempt at dropseq I also pulled out the first R1 and R2 sequences, in case these are somehow informative:. R1:; CAGGAGTGGATTTAGTCCTT; CGCGGAAGATGAGCATTATG; TTTCGTGCCGCCCTCCCTCG; ACAGCGACAAGGCTACCTCA; AATAGGGTCAACGATTAGAG; CGGATGGTTCCCAGCTGCCT; ACATTTCCGCGGTAGGGGGG; GTGGCAAGATTTAATATCCG. R2:; GAATANNNNNNNNNNNNNNNNNNNNAAGGATAACAGTTTCCAGTAC; GGACATTGGTCANCNNGCAGACACGGGTCAATGCGGCAAAAAACAA; GCAACNNNNNNNNNNNNNNNNNNNNGACNAGCGGGCTCACCATAAT; GNGTGNNNNNNNNNNNNNNNNNNNNCGANGTGATTTCTGCCCAGTG; CCCGACTGTNCTNNNNAAGGTCAGCAGTTCAAATCCCAGCAACCAC no hits found; GAGTGNNNNNNNNNNNNNNNCNNNGGCGGTTAGTGCTGAGAGTGCG; GCATACTGGTTGNCNNGCTGAAGTTTAAGGGCCTGGTTTTTTGAAA Cdv3 or Ncoa; GCACCCNANNNCNNNNCCGNAGNTCTGAAGATCAAATCACAGCAAA. ============================; ============================; ============================. Version Info: This is the most recent version of Salmon.; Logs will be written to mSpT3/logs; ### salmon (single-cell-based) v0.11.2; ### [ program ] => salmon ; ### [ command ] => alevin ; ### [ libType ] => { A }; ### [ mates1 ] => { data/mSpT3_S2_L001_R1_001.fastq data/mSpT3_S2_L002_R1_001.fastq }; ### [ mates2 ] => { data/mSpT3_S2_L001_R2_001.fastq data/mSpT3_S2_L002_R2_001.fastq }; ### [ dropseq ] => { }; ### [ threads ] => { 10 }; ### [ output ] => { mSpT3 }; ### [ index ] => { mouse_cdna }; ### [ tgMap ] => { biomart.csv }. [2018-08-29 11:26:45.317] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2018-08-29 11:26:45.325] [alevinLog] [info] Processing barcodes files (if Present) . ; processed 18 Million barcodes. [2018-08-29 11:28:11.683] [alevinLog] [info] Done barcode density calculation.; [2018-08-29 11:28:11.683] [alevinLog] [info] # Barcodes Used: 18693290 / 18712858.; [2018-08-29 11:28:17.405] [alevinLog] [info] Knee found left boundary at 2385 ; [2018-08-29 11:28:19.290] [alevinLog] [warning] Gauss Predi",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/281:1372,Log,Logs,1372,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/281,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"ble difference is because (1) the reads are assumed to arrive in a random order (2) this is only a very small fraction of the total data and (3) if the unoriented reads map to a target in the ""wrong"" direction, they will also align to the proper target in the ""right"" direction and, once the orientation filter is applied for future reads, the weight of evidence should turn the probability of assignment of these unoriented reads toward the proper target. However, I'm guessing there is an edge case you're seeing here where the conditions don't induce this behavior. So, there are 2 immediate solutions to the problem. First, if you know the library type explicitly, you can use that. Second (and some other folks have discussed this here for other reasons), you can do a ""throw-away"" run of salmon on a small prefix of the read file (e.g. `salmon quant ... -lA --skipQuant -r <(gunzip -c reads.fq.gz | head -n 400000)`) to get the output of the automatic library type determination, and then run the full dataset with that library type. Finally, moving forward, I'm happy to consider working on modifying this default behavior. That is, we could (though it would be a little bit of work) modify the default behavior. The idea here is to basically run as we do now for the first 10,000 aligned reads to get the library type and then ""reset"" the whole quantification pipeline. The main challenge here is that salmon is designed to work with streaming FASTQ input, and we don't want to break that. So we can't do something as easy as ""reset the file pointer"". I think the best option is to make a copy of the first X reads in memory, detection the library type with them, and then start quantifying them and continue with the rest of the file. That complicates the logic a bit, because now the input source for reads changes dynamically during quantification --- but I think it could be done. Please let me know if you both have interest in this feature and it's worth putting on the list. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/489#issuecomment-738830213:3066,log,logic,3066,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/489#issuecomment-738830213,1,['log'],['logic']
Testability,"c duplicate_clusters.tsv; c3ec09a30adc9d47bc95839157cb2ff66530353106a4fd8e75b167ac5db67820 info.json; 430be78bae99a4592fcedc5c800a42313f2b1252e3953f89f347779056c1ee5b mphf.bin; 2fb0b5151f9f2544c06a9f95d03075f7af0494d0fe31745504a5a7da43edc1b1 pos.bin; 15d3bb6a16bcd8c1a6814852bd3dcfa439b60ec84c706f868ee7ec2d5a90581d pre_indexing.log; 8e665e5fdee5af6fcedabc69fd04eda6e66055ef811ebde6de6f86a66521198a rank.bin; 793c79f5fd6046dfea07bbc9587d2835088e54c78197d652d1b1f205c6b16983 refAccumLengths.bin; c5ea8eccca3fdc299ad7c9d2f07a4ed14c8c830940e83c315e7eaad6905a40aa ref_indexing.log; b580b9c6257254a018a9ae22291a64892c1a3715c69272637f5c504fc5545a70 reflengths.bin; 89679603ac0b28042275e5ff04b222bad3fd431cab573f0c2b61e7455aec43e7 refseq.bin; 46bf28001e00d491b68bf8758b99c1f304523c79bd94a97d7797888856594e84 seq.bin; 4c7e56ba28383774e786826099ef412761326fe18ce69f29033ad2886542985d versionInfo.json; `; Following are different.; `ctable.bin; info.json; mphf.bin; pos.bin; pre_indexing.log; ref_indexing.log; seq.bin; versionInfo.json`. I will try creating the vM25 index with increased memory. Wonder if its not building. Just FYI, my sha256sum on vM23 index is:; `9788716f4ce42b049fe7e865108f45392bb8a5847cfcd47369512783dc918239 complete_ref_lens.bin; 9c2453a47ce1808f54733f049b8c4cf38634c9116eb55ed725b73219caa101c5 ctable.bin; 928ba619dc5388ccab6d5c4f8ce162e07a5b5c79028be4aee4d838f43a3b9d92 ctg_offsets.bin; 0814d0e7dd8a4b126709c42728816995aefdf5a5bb6337c2d3c048cb0f56094d duplicate_clusters.tsv; dcbf8e140627b3c99d4dbcdaa585447a691fddb620f137811b669e73800f9b3b info.json; 5959abf5969a26481c6aa20fecbdddf19fa558e949cfbda5760205f38bb907b9 mphf.bin; 28460131b85c74ffb7627761a291614757e72b4e3b82971dcc048a50cc8d9e7f pos.bin; b5eb5e3fb0d03509d9fc90f6b5461c6aecc44423068f3303553cc07fffc7c1b9 pre_indexing.log; eca518136526233f3dc28d9684926793cb84327242d54c1a8a20c66aa1928fad rank.bin; a990247ba2b351fd0921de6470bf0c3505472d8f463e6f8b9ec7c221b6b56af8 refAccumLengths.bin; 436199afbb35045a70fdc7b9e542ef805b5717",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/561#issuecomment-674527480:1692,log,log,1692,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/561#issuecomment-674527480,1,['log'],['log']
Testability,"c-ag-zinzen 4096 Mar 3 11:00 ..; -rw-rw-r-- 1 amonaco_m hpc-ag-zinzen 0 Mar 3 11:00 alevin.log; ```. I have used Salmon Alevin before on this dataset - without the bootstrap option - while providing the Cell Ranger whitelisted barcodes, and everything has gone smoothly (same script as below, commented out line). I have tried increasing the allotted memory and thread number as well, but with no change in outcome. Have you ever encountered something like this or could address me to where the issue may be (I'm assuming something to do with the bootstrap)?. *****Script I submit:*****; ```; #!/bin/bash; # expected run time ; #SBATCH --time=24:00:00 ; # Combine stderr and stdout log files into the stdout log file.; #SBATCH -o without -e; # Keep current environment variables.; #SBATCH --export=variables; # number of cores; #SBATCH -n 30; # expected memory to be used; #SBATCH —mem=50000; # Specify queue via expected length of job. ; #SBATCH --partition=medium; # Set the log directory.; #SBATCH -o logs. ####declarations; conda activate salmon. Read1=$1 # fastq file - CB+UMI; Read2=$2 # fastq file - insert read; index=$3 # directory from salmon index; outDir=$4 # output directory; tsv=$5 # tsv containing txp-gene-id pairs; whitelist=$6 # cell ranger output barcodes. salmon alevin -lISR -1 $Read1 -2 $Read2 --chromiumV3 -i $index -p 8 -o $outDir --tgMap $tsv --whitelist $whitelist --numCellBootstraps 20 --dumpFeatures. #salmon alevin -lISR -1 $Read1 -2 $Read2 --chromiumV3 -i $index -p 8 -o $outDir --tgMap $tsv --whitelist $whitelist. ```. Thank you in advance!; Anna. -------------------------; Additional FYI:; ```; (salmon) [amonaco_m@med0113 1_bootstrappedAlevin]$ salmon version; Version Info: This is the most recent version of salmon.; salmon v1.4.0. Usage: salmon -h|--help or ; salmon -v|--version or ; salmon -c|--cite or ; salmon [--no-version-check] <COMMAND> [-h | options]. Commands:; index : create a salmon index; quant : quantify a sample; alevin : single cell analysis;",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/636:1977,log,logs,1977,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/636,1,['log'],['logs']
Testability,can you try `make install` before `make test`?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393690468:40,test,test,40,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393690468,1,['test'],['test']
Testability,cat Testing/Temporary/LastTestsFailed.log; 1:unit_tests,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393679453:4,Test,Testing,4,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393679453,2,"['Test', 'log']","['Testing', 'log']"
Testability,"ce sequence | Time = 240.84 ms; -----------------------------------------; -----------------------------------------; | Loading reference accumulative lengths | Time = 3.9587 ms; -----------------------------------------; [2021-04-09 12:16:41.658] [jointLog] [info] done; [2021-04-09 12:16:41.658] [jointLog] [info] Index contained 45,375 targets; [2021-04-09 12:16:41.673] [jointLog] [info] Number of decoys : 1; [2021-04-09 12:16:41.673] [jointLog] [info] First decoy index : 45,374. [2021-04-09 12:16:42.811] [alevinLog] [info] Starting optimizer. [2021-04-09 12:16:42.800] [jointLog] [info] Computed 84 rich equivalence classes for further processing; [2021-04-09 12:16:42.800] [jointLog] [info] Counted 135 total reads in the equivalence classes; [2021-04-09 12:16:42.801] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 26; [2021-04-09 12:16:42.803] [jointLog] [info] Mapping rate = 3.375%. Analyzed 184 cells (95% of all).Log] [info] finished quantifyLibrary(); [2021-04-09 12:16:43.532] [alevinLog] [warning] 37 mitorna gene(s) does not have transcript in the reference; [2021-04-09 12:16:43.532] [alevinLog] [info] Total 0 usable mRna genes; [2021-04-09 12:16:43.533] [alevinLog] [warning] 529 ribosomal rna gene(s) does not have transcript in the reference; [2021-04-09 12:16:43.533] [alevinLog] [info] Total 22 usable rRna genes; [2021-04-09 12:16:43.582] [alevinLog] [info] Total 135.00 UMI after deduplicating.; [2021-04-09 12:16:43.582] [alevinLog] [info] Total 0 BiDirected Edges.; [2021-04-09 12:16:43.582] [alevinLog] [info] Total 0 UniDirected Edges.; [2021-04-09 12:16:43.582] [alevinLog] [warning] Skipped 113 barcodes due to No mapped read; [2021-04-09 12:16:43.584] [alevinLog] [info] Clearing EqMap; Might take some time.; [2021-04-09 12:16:43.589] [alevinLog] [info] Starting white listing of 81 cells; [2021-04-09 12:16:43.589] [alevinLog] [info] Starting to make feature Matrix; [2021-04-09 12:16:43.589] [alevinLog] [info] Done makin",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/647:6318,Log,Log,6318,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/647,1,['Log'],['Log']
Testability,"cell mode)?**; salmon; **Describe the bug**; A clear and concise description of what the bug is.; salmon quant is leading to segmentation fault when `--skipQuant` flag is set. The behavior may be annotation dependent.; **To Reproduce**; Steps and data to reproduce the behavior:. Specifically, please provide at least the following information:. * Which version of salmon was used? :; * v1.9.0; * How was salmon installed (compiled, downloaded executable, through bioconda)? ; * bioconda; * Which reference (e.g. transcriptome) was used?; * human hg38 [gencode v43 comprehensive](https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_43/gencode.v43.primary_assembly.annotation.gtf.gz) produces the error; * human hg38 [gencode v43 basic](https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_43/gencode.v43.basic.annotation.gtf.gz) works fine.; * Which read files were used?; * The issue is reproducible with multiple independent read files. Logs attached are from reads subsampled from [GSM7099349](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSM7099349); * Which which program options were used?; * --skipQuant -l A. **Expected behavior**; A clear and concise description of what you expected to happen.; salmon quant finishes without seg fault with `--skipQuant`; **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem.; Terminal output when `--skipQuant` is on:; ```; Version Info: ### PLEASE UPGRADE SALMON ###; ### A newer version of salmon with important bug fixes and improvements is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; Sign up for the salmon mailing list to hear about new versions, features and updates at:; https://oceangenomics.com/subscribe; ### salmon (selective-alignment-based) v1.9.0; ### [ program ] => salmon ; ### [ command ] => quant ; #",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/902:1037,Log,Logs,1037,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/902,1,['Log'],['Logs']
Testability,"cession SRP034543. For some it works fine, but some there is segmentation fault when using the `--useFSPD`. For an example run where it fails, have a look at accession SRR2048254. Here is the command I ran along with output. ```; $ salmon quant \; > -i /nfs/research2/teichmann/reference/mus-musculus/salmon/mouse_cdna_38.p4.83_repbase20.11_ercc_SIRV.fa \; > -l IU \; > -1 <(zcat /nfs/research2/teichmann/valentine/data/SRP034543/SRR2048254_1.fastq.gz) \; > -2 <(zcat /nfs/research2/teichmann/valentine/data/SRP034543/SRR2048254_2.fastq.gz) \; > -o /tmp/SRR2048254_salmon_out \; > --biasCorrect \; > --useFSPD; Version Info: This is the most recent version of Salmon.; # salmon (mapping-based) v0.6.0; # [ program ] => salmon; # [ command ] => quant; # [ index ] => { /nfs/research2/teichmann/reference/mus-musculus/salmon/mouse_cdna_38.p4.83_repbase20.11_ercc_SIRV.fa }; # [ libType ] => { IU }; # [ mates1 ] => { /dev/fd/63 }; # [ mates2 ] => { /dev/fd/62 }; # [ output ] => { /tmp/SRR2048254_salmon_out }; # [ biasCorrect ] => { }; # [ useFSPD ] => { }; Logs will be written to /tmp/SRR2048254_salmon_out/logs; [2016-06-21 10:04:29.524] [jointLog] [info] parsing read library format; there is 1 lib; Loading 32-bit quasi indextcmalloc: large alloc 4294967296 bytes == 0x4d084000 @; [2016-06-21 10:04:30.159] [stderrLog] [info] Loading Suffix Array; [2016-06-21 10:04:30.159] [stderrLog] [info] Loading Position Hash; [2016-06-21 10:04:30.158] [jointLog] [info] Loading Quasi index; [2016-06-21 10:04:32.681] [stderrLog] [info] Loading Transcript Info; [2016-06-21 10:04:33.686] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-06-21 10:04:34.050] [stderrLog] [info] There were 115426 set bits in the bit array; [2016-06-21 10:04:34.376] [stderrLog] [info] Computing transcript lengths; [2016-06-21 10:04:34.377] [stderrLog] [info] Waiting to finish loading hash; Index contained 115426 targets; [2016-06-21 10:04:47.033] [jointLog] [info] done; [2016-06-21 10:04:47.033] [stderrLog] [info] D",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/64:1102,Log,Logs,1102,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/64,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"cho ""User: ${USER}""; echo ""Job id: ${JOB_ID}""; echo ""Job name: ${JOB_NAME}""; echo ""Hostname: ${HOSTNAME}""; echo ""Task id: ${TASK_ID}"". FILE1=$(awk 'BEGIN {FS=""\t""} {print $1}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); if [ TRUE == ""TRUE"" ] ; then; FILE2=$(awk 'BEGIN {FS=""\t""} {print $3}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); fi; ID=$(cat /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk '{print $NF}' | awk ""NR==${SGE_TASK_ID}""). mkdir -p /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test3/${ID}. /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant 	-i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts -p 1 -l ISR 	-1 ${FILE1} -2 ${FILE2} 	-o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test3/${ID}. echo ""**** Job ends ****""; date; ```. ### Example log file. ```; **** Job starts ****; Wed Mar 29 14:51:10 EDT 2017; **** JHPCE info ****; User: lcollado; Job id: 110315; Job name: step6-salmon_test3.gsk_phaseII; Hostname: compute-061; Task id: ; Version Info: This is the most recent version of Salmon.; ### salmon (mapping-based) v0.8.2; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts }; ### [ threads ] => { 1 }; ### [ libType ] => { ISR }; ### [ mates1 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX.fastq.gz }; ### [ mates2 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX_read2.fastq.gz }; ### [ output ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test3/R10001_D2B1WACXX }; Logs will be written to /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test3/R10001_D2B1WACXX/logs; [1m[2017-03-29 14:51:11.533] [join",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965:1768,log,log,1768,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965,1,['log'],['log']
Testability,"cho ""User: ${USER}""; echo ""Job id: ${JOB_ID}""; echo ""Job name: ${JOB_NAME}""; echo ""Hostname: ${HOSTNAME}""; echo ""Task id: ${TASK_ID}"". FILE1=$(awk 'BEGIN {FS=""\t""} {print $1}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); if [ TRUE == ""TRUE"" ] ; then; FILE2=$(awk 'BEGIN {FS=""\t""} {print $3}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); fi; ID=$(cat /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk '{print $NF}' | awk ""NR==${SGE_TASK_ID}""). mkdir -p /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test5/${ID}. /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant 	-i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts -p 1 -l ISR 	-1 ${FILE1} -2 ${FILE2} 	-o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test5/${ID}. echo ""**** Job ends ****""; date; ```. ### Example log file. ```; **** Job starts ****; Wed Mar 29 23:27:11 EDT 2017; **** JHPCE info ****; User: lcollado; Job id: 110632; Job name: step6-salmon_test5.gsk_phaseII; Hostname: compute-066; Task id: ; Version Info: This is the most recent version of Salmon.; ### salmon (mapping-based) v0.8.2; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts }; ### [ threads ] => { 1 }; ### [ libType ] => { ISR }; ### [ mates1 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX.fastq.gz }; ### [ mates2 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX_read2.fastq.gz }; ### [ output ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test5/R10001_D2B1WACXX }; Logs will be written to /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test5/R10001_D2B1WACXX/logs; [1m[2017-03-29 23:59:18.699] [join",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965:8683,log,log,8683,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965,1,['log'],['log']
Testability,"cluding `versionInfo.json`. My pipeline crashes during the next step, where I am attempting to map reads. Again, I followed the code as outlined by the alevin-fry tutorial (tweaked slightly) and my snakemake rule is as follows (apologies that I am still using the deprecated --end, --barcodeLength and --umiLength options; my intention was to update those once I had my pipeline working, but I've gotten stuck on the index build):. ```; rule map_reads: ; # map reads and generate a RAD (Reduced Alignment Data) file; input:; R1 = ""{out_data}/preprocessed_fastqs/{sample}_R1.fastq.gz"",; R2 = ""{out_data}/preprocessed_fastqs/{sample}_R2.fastq.gz"",; idx = rules.build_idx.output,; tgmap = ""{out_data}/ref/transcriptome/transcriptome_splici_fl86_t2g.tsv""; output:; ""{out_data}/{sample}/map/alevin/alevin.log"",; ""{out_data}/{sample}/map/aux_info/meta_info.json"",; ""{out_data}/{sample}/map/cmd_info.json"",; ""{out_data}/{sample}/map/libParams"",; ""{out_data}/{sample}/map/logs/salmon_quant.log"",; ""{out_data}/{sample}/map/map.rad"",; ""{out_data}/{sample}/map/unmapped_bc_count.bin"",; params:; job_name = ""map_reads"",; memory = ""select[mem>64] rusage[mem=64]"",; library_type = ""ISR"",; end = 5,; barcodeLength = 16,; umiLength = 8,; out_dir = ""{out_data}/{sample}/map""; log:; ""logs/map_reads/{sample}.out""; threads:; 16; shell:; """"""; salmon alevin \; -l {params.library_type} \; -1 {input.R1} \; -2 {input.R2} \; -i {input.idx} \; -p {threads} \; -o {params.out_dir} \; --tgMap {input.tgmap} \; --end {params.end} \; --barcodeLength {params.barcodeLength} \; --umiLength {params.umiLength} \; --keepCBFraction 1 \; --sketch; """"""; ```. Specifically, please provide at least the following information:. * Which version of salmon was used? v1.5.2; * How was salmon installed (compiled, downloaded executable, through bioconda)? Downloaded [this](https://github.com/COMBINE-lab/salmon/releases/tag/v1.5.2) binary; * Which reference (e.g. transcriptome) was used? Human reference (GRCh38) (from the alevin-fry tutori",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/713:3879,log,log,3879,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/713,1,['log'],['log']
Testability,cmake/TestSalmonQuasi.cmake: more verbose test failure messages.,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/810:6,Test,TestSalmonQuasi,6,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/810,2,"['Test', 'test']","['TestSalmonQuasi', 'test']"
Testability,"conda create never seems to even get out of the gate ... a little bit of testing strongly suggests that version of salmon can't be found :. conda create -n owlVsunicorn -c bioconda owlVsunicorn; Collecting package metadata (current_repodata.json): done; Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): / Killed. this is the first time I've encountered an issue where something that is ""supposed"" to be there can't be found. Adam H. Freedman, PhD; Data Scientist; Faculty of Arts & Sciences Informatics Group; Harvard University; 38 Oxford St; Cambridge, MA 02138; phone: +001 310 415 7145; ________________________________; From: Rob Patro ***@***.***>; Sent: Sunday, October 29, 2023 10:01 AM; To: COMBINE-lab/salmon ***@***.***>; Cc: Freedman, Adam ***@***.***>; State change ***@***.***>; Subject: Re: [COMBINE-lab/salmon] anaconda version of salmon outdated, missing decoys option (Issue #895). I'm going to cc @dpryan79<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_dpryan79&d=DwMFaQ&c=WO-RGvefibhHBZq3fL85hQ&r=MITI_LEJgyr1a24IMFAlSaZIPxMpOUT21T7L3fg4CjA&m=mSC4skssR3kpqIDO5fXv00Vk9PrFQeVf0OH62EOgXZ9hbM31qjkaQra0z60JiEA_&s=hPsmfTmSAfiwDhS2JFQyD0EUHl5m5sbj_n46DYj6tdM&e=> on this — does it just not finish? It seems to work within our GitHub CI, where we have to grab the prebuilt salmon to test simpleaf. —; Reply to this email directly, view it on GitHub<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_COMBINE-2Dlab_salmon_issues_895-23issuecomment-2D1784122719&d=DwMFaQ&c=WO-RGvefibhHBZq3fL85hQ&r=MITI_LEJgyr1a24IMFAlSaZIPxMpOUT21T7L3fg4CjA&m=mSC4skssR3kpqIDO5fXv00Vk9PrFQeVf0OH62EOgXZ9hbM31qjkaQra0z60JiEA_&s=6Y-rQOzzAA-t9QV8NyfcMVeySD2an4xeN1HsDqa6VpQ&e=>, or unsubscribe<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_notifications_unsubscribe-2Dauth_ADBMMUDFRQIHN4AMNBHWCN3YBZOUTAVCNFSM6AAAAAA6UYYPGOVHI2DSMVQWIX3LMV43OSLTON2WKQ3PN",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/895#issuecomment-1784126021:73,test,testing,73,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/895#issuecomment-1784126021,2,['test'],['testing']
Testability,"cript. 3. I loaded the reference genome fasta acquired from Ensembl using the Biostrings package. GRanges and Biostrings are tightly integrated, allowing me to subset sequences from a Biostrings object using the GRanges object. **I believe the problem lies here.** It appears that when subsetting the mature exonic sequences from Biostrings using GRanges, the strand field in the GRanges object **was not** utilized. I.e., I needed to get the reverse complement of the extracted sequences for transcripts on the minus strand. I had done that and assumed that this behaviour would be consistent. However, for reasons I have not been able to pinpoint (potentially a bug), the strand information **was accounted for** when I used GRanges to subset the premature sequences. I **did not** need to get the reverse complement of the premature sequences on the minus strand as I had to do for the mature sequences. Yet, I did that anyway. I initially did test my protocol to ensure it produced identical transcript sequences to Gencode, but I only did this for mature sequences. All seemed fine for both + and - strand transcripts. After your feedback, I compared the premature sequences in my transcript fasta against the transcript fasta from Gencode. As you can see in the smoothed dot plots below, the premature sequences of transcripts on the minus strand are in the wrong orientation and have the wrong complementarity!. ![Screenshot from 2021-04-24 00-35-05](https://user-images.githubusercontent.com/10429333/115947355-0d96c880-a495-11eb-92a6-d8d2233c8d2b.png). I included my R code below for this test case for anyone who might stumble upon this issue. Under the code headers “Mature transcript sequences” and “Premature transcript sequences”, you can observe that I used identical protocols for sequence subsetting, yet in the mature case the strand information in the GRanges seems to be disregarded when subsetting from Biostrings, but in the premature case the strand information is used. Of cou",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191:2328,test,test,2328,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191,2,['test'],['test']
Testability,"criptome using BWA-mem and then sorted them by coordinates (as a regular procedure). I know Salmon assumes the alignments are not sorted, so I shuffled these bam files, and then run `salmon quant`.; Here are the errors I got in a number of trials:. ### Fresh installation of Salmon; ```; conda create --name salmon -c bioconda salmon; conda activate salmon; ```. ### 1. Shuffling a bam file with `samtools collate`; ```; samtools collate \; -@ 40 \; -o SRR3212847.Aligned.Shuffled.bam \; SRR3212847.Aligned.SortedByCoord.bam. salmon quant \; -t mRNA.fasta \; -p 20 \; -l A \; -a SRR3212847.Aligned.Shuffled.bam \; -o SRR3212847.Aligned.Shuffled ; ```. ```; Version Info: This is the most recent version of salmon.; # salmon (alignment-based) v1.4.0; # [ program ] => salmon ; # [ command ] => quant ; # [ targets ] => { mRNA.fasta }; # [ threads ] => { 20 }; # [ libType ] => { A }; # [ alignments ] => { SRR3212847.Aligned.Shuffled.bam }; # [ output ] => { SRR3212847.Aligned.Shuffled }; Logs will be written to SRR3212847.Aligned.Shuffled/logs; [2021-01-08 12:43:44.680] [jointLog] [info] setting maxHashResizeThreads to 20; [2021-01-08 12:43:44.680] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; Library format { type:paired end, relative orientation:inward, strandedness:unstranded }; [2021-01-08 12:43:44.711] [jointLog] [info] numQuantThreads = 14; parseThreads = 6; Checking that provided alignment files have consistent headers . . . done; Populating targets from aln = ""SRR3212847.Aligned.Shuffled.bam"", fasta = ""mRNA.fasta"" . . .done. processed 0 reads in current roundSegmentation fault (core dumped); ```. ### 2. Shuffling a headless bam file with `samtools collate`; (I think I saw something about the bam's header in another thread dealing with this issue); ```; samtools view \; -b \; -@ 40 \; -o SRR3212847.Aligned.SortedByCoord.NoHeader.bam \; SRR3212847.Aligned.SortedByCoord.bam. samtools collate \; -@ 40 \; -o SRR321284",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/582#issuecomment-756727212:1070,Log,Logs,1070,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/582#issuecomment-756727212,1,['Log'],['Logs']
Testability,"ctFromPacked] 70 iterations done. 438888868 characters processed.; [BWTIncConstructFromPacked] 80 iterations done. 476860644 characters processed.; [BWTIncConstructFromPacked] 90 iterations done. 510606036 characters processed.; [BWTIncConstructFromPacked] 100 iterations done. 540594980 characters processed.; [BWTIncConstructFromPacked] 110 iterations done. 567245236 characters processed.; [BWTIncConstructFromPacked] 120 iterations done. 590928020 characters processed.; [bwa_index] 279.06 seconds elapse.; [bwa_index] Update BWT... 1.72 sec; [bwa_index] Pack forward-only FASTA... 1.90 sec; [bwa_index] Construct SA from BWT and Occ... 59.56 sec; [2018-06-25 19:34:53.084] [jLog] [info] done building index; ```. Doh, something unexpected from the logs, isn't it?. ```; $ ls -latr ftp.ensembl.org/pub/release-92/fasta/homo_sapiens/cdna/Homo_sapiens.GRCh38.cdna.all; total 8374704; drwx------. 3 mmokrejs mmokrejs 4096 Jun 25 19:25 ..; -rw-r--r--. 1 mmokrejs mmokrejs 36158409 Jun 25 19:26 rsd.bin; -rw-r--r--. 1 mmokrejs mmokrejs 423777 Jun 25 19:26 duplicate_clusters.tsv; -rw-r--r--. 1 mmokrejs mmokrejs 294997212 Jun 25 19:26 txpInfo.bin; -rw-r--r--. 1 mmokrejs mmokrejs 1157068836 Jun 25 19:26 sa.bin; -rw-r--r--. 1 mmokrejs mmokrejs 1779709484 Jun 25 19:29 hash.bin; -rw-r--r--. 1 mmokrejs mmokrejs 75 Jun 25 19:29 refInfo.json; -rw-r--r--. 1 mmokrejs mmokrejs 9816 Jun 25 19:29 quasi_index.log; -rw-r--r--. 1 mmokrejs mmokrejs 666 Jun 25 19:29 header.json; -rw-r--r--. 1 mmokrejs mmokrejs 304768324 Jun 25 19:33 bwaidx.bwt; -rw-r--r--. 1 mmokrejs mmokrejs 76192062 Jun 25 19:33 bwaidx.pac; -rw-r--r--. 1 mmokrejs mmokrejs 50007825 Jun 25 19:33 bwaidx.ann; -rw-r--r--. 1 mmokrejs mmokrejs 89 Jun 25 19:33 bwaidx.amb; drwxr-xr-x. 2 mmokrejs mmokrejs 4096 Jun 25 19:34 .; -rw-r--r--. 1 mmokrejs mmokrejs 95 Jun 25 19:34 versionInfo.json; -rw-r--r--. 1 mmokrejs mmokrejs 115 Jun 25 19:34 indexing.log; -rw-r--r--. 1 mmokrejs mmokrejs 4876291928 Jun 25 19:34 bwaidx.sa; $; ```. Hope this helps.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/242:15969,log,log,15969,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/242,2,['log'],['log']
Testability,"d 254gb. lsb_release -a; ```; LSB Version:	:base-4.0-amd64:base-4.0-noarch:core-4.0-amd64:core-4.0-noarch:graphics-4.0-amd64:graphics-4.0-noarch:printing-4.0-amd64:printing-4.0-noarch; Distributor ID:	Scientific; Description:	Scientific Linux release 6.4 (Carbon); Release:	6.4; Codename:	Carbon; ```. Do you have any idea what can be the causing the error?. Thanks. We are using the precompiled salmon bin and running it with:. `salmon quant -i $index -1 $f1 -2 $f2 -o $output_folder --meta --incompatPrior 0.0 --libType A -p 8 --gcBias --seqBias --numBootstraps 30`. ```; Version Info: This is the most recent version of Salmon.; ### salmon (mapping-based) v0.8.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { ./storage/tmm.idx }; ### [ mates1 ] => { DNA_1.fastq.gz }; ### [ mates2 ] => {DNA_2.fastq.gz }; ### [ output ] => { /DNA_tmm }; ### [ meta ] => { }; ### [ incompatPrior ] => { 0.0 }; ### [ libType ] => { A }; ### [ threads ] => { 8 }; ### [ gcBias ] => { }; ### [ seqBias ] => { }; ### [ numBootstraps ] => { 30 }; Logs will be written to ./storage/logs; [2017-03-15 11:53:20.568] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2017-03-15 11:53:20.568] [jointLog] [info] parsing read library format; [2017-03-15 11:53:20.568] [jointLog] [info] There is 1 library.; [2017-03-15 11:53:20.653] [jointLog] [info] Loading Quasi index; [2017-03-15 11:53:20.683] [jointLog] [info] Loading 64-bit quasi index; [2017-03-15 11:53:20.684] [stderrLog] [info] Loading Suffix Array ; [2017-03-15 12:19:05.982] [stderrLog] [info] Loading Transcript Info ; Exception : [Failed to read 130159192 bytes from input stream! Read 65079596]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting.; ```. Index building log:. ```; Version Info: This is the most recent version of Salmon.; index ["" ./storage/tmm.idx""] did not previously exist . . . creating it; [2017-03-14 12:10:34",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/129:1516,Log,Logs,1516,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/129,1,['Log'],['Logs']
Testability,"d concise description of what you expected to happen.; Salmon quant to generate quant.sf file. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem.; ```; Version Info: ### PLEASE UPGRADE SALMON ###; ### A newer version of salmon with bug fixes is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; Sign up for the salmon mailing list to hear about new versions, features and updates at:; https://oceangenomics.com/subscribe; ###; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ validateMappings ] => { }; ### [ threads ] => { 1 }; ### [ libType ] => { A }; ### [ index ] => { transcriptome-index }; ### [ mates1 ] => { sample1_R1_001.trimmed.fastq.gz }; ### [ mates2 ] => { sample1_R2_001.trimmed.fastq.gz }; ### [ output ] => { sample1 }; Logs will be written to sample1/logs; [2023-10-11 16:03:44.489] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2023-10-11 16:03:44.490] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2023-10-11 16:03:44.490] [jointLog] [info] Usage of --validateMappings, without --hardFilter implies use of range factorization. rangeFactorizationBins is being set to 4; [2023-10-11 16:03:44.490] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.2.; [2023-10-11 16:03:44.490] [jointLog] [info] parsing read library format; [2023-10-11 16:03:44.491] [jointLog] [info] There is 1 library.; [2023-10-11 16:03:45.109] [jointLog] [info] Loading Quasi index; [2023-10-11 16:03:45.111] [jointLog] [info] Loading 32-bit quasi index; [2023-10-11 16:03:45.173] [stderrLog] [info] Loading Suffix Array ; [2023-10-11 16:03",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/881:2179,Log,Logs,2179,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/881,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"d exactly 1 time; 54959922 (72.59%) aligned >1 times; 86.42% overall alignment rate; ```. The output of Single-End reads(just read1):; ```{shell}; salmon quant -i assembly_index -l A -r 9998_1.fastq.gz --meta -p 100 -o 9998.quant_se2; Version Info: ### PLEASE UPGRADE SALMON ###; ### A newer version of salmon with bug fixes is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; Sign up for the salmon mailing list to hear about new versions, features and updates at:; https://oceangenomics.com/subscribe; ###; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { assembly_index }; ### [ libType ] => { A }; ### [ unmatedReads ] => { 9998_1.fastq.gz }; ### [ meta ] => { }; ### [ threads ] => { 100 }; ### [ output ] => { 9998.quant_se2 }; Logs will be written to 9998.quant_se2/logs; [2023-03-17 07:40:15.733] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2023-03-17 07:40:15.733] [jointLog] [warning] . NOTE: It appears you are running salmon without the `--validateMappings` option.; Mapping validation can generally improve both the sensitivity and specificity of mapping,; with only a moderate increase in use of computational resources. ; Mapping validation is planned to become a default option (i.e. turned on by default) in; the next release of salmon.; Unless there is a specific reason to do this (e.g. testing on clean simulated data),; `--validateMappings` is generally recommended. [2023-03-17 07:40:15.733] [jointLog] [info] parsing read library format; [2023-03-17 07:40:15.733] [jointLog] [info] There is 1 library.; [2023-03-17 07:40:15.882] [jointLog] [info] Loading Quasi index; [2023-03-17 07:40:15.882] [jointLog] [info] Loading 64-bit quasi index; [2023-03-17 07:40:15.882] [stderrLog] [info] Loading Su",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/838:6641,log,logs,6641,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/838,1,['log'],['logs']
Testability,"d slightly) and my snakemake rule is as follows (apologies that I am still using the deprecated --end, --barcodeLength and --umiLength options; my intention was to update those once I had my pipeline working, but I've gotten stuck on the index build):. ```; rule map_reads: ; # map reads and generate a RAD (Reduced Alignment Data) file; input:; R1 = ""{out_data}/preprocessed_fastqs/{sample}_R1.fastq.gz"",; R2 = ""{out_data}/preprocessed_fastqs/{sample}_R2.fastq.gz"",; idx = rules.build_idx.output,; tgmap = ""{out_data}/ref/transcriptome/transcriptome_splici_fl86_t2g.tsv""; output:; ""{out_data}/{sample}/map/alevin/alevin.log"",; ""{out_data}/{sample}/map/aux_info/meta_info.json"",; ""{out_data}/{sample}/map/cmd_info.json"",; ""{out_data}/{sample}/map/libParams"",; ""{out_data}/{sample}/map/logs/salmon_quant.log"",; ""{out_data}/{sample}/map/map.rad"",; ""{out_data}/{sample}/map/unmapped_bc_count.bin"",; params:; job_name = ""map_reads"",; memory = ""select[mem>64] rusage[mem=64]"",; library_type = ""ISR"",; end = 5,; barcodeLength = 16,; umiLength = 8,; out_dir = ""{out_data}/{sample}/map""; log:; ""logs/map_reads/{sample}.out""; threads:; 16; shell:; """"""; salmon alevin \; -l {params.library_type} \; -1 {input.R1} \; -2 {input.R2} \; -i {input.idx} \; -p {threads} \; -o {params.out_dir} \; --tgMap {input.tgmap} \; --end {params.end} \; --barcodeLength {params.barcodeLength} \; --umiLength {params.umiLength} \; --keepCBFraction 1 \; --sketch; """"""; ```. Specifically, please provide at least the following information:. * Which version of salmon was used? v1.5.2; * How was salmon installed (compiled, downloaded executable, through bioconda)? Downloaded [this](https://github.com/COMBINE-lab/salmon/releases/tag/v1.5.2) binary; * Which reference (e.g. transcriptome) was used? Human reference (GRCh38) (from the alevin-fry tutorial [here](https://cf.10xgenomics.com/supp/cell-exp/refdata-gex-GRCh38-2020-A.tar.gz)); * Which read files were used? See attached subsampled sub_R1.fastq.gz and sub_R2.fastq.gz fr",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/713:4156,log,log,4156,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/713,2,['log'],"['log', 'logs']"
Testability,d14_monocytes/cd14_monocytes_fastqs.tar) or the [PBMC 3k from the same paper](http://cf.10xgenomics.com/samples/cell-exp/1.0.0/pbmc3k/pbmc3k_fastqs.tar); * Which program options were used?; I ran the following command for the CD14 Monocytes dataset:; `~/software/salmon/scripts/v1_10x/run.sh ~/software/salmon/bin/salmon salmon alevin -l ISR -b ./fastq/fastqs/flowcell1/ --gemcode -i ./transcripts_index_salmon/ -p 8 -o ./fastq/test/ --tgMap ./hg_transcriptome/tx2tx.tsv --end 5 --umiLength 5 --barcodeLength 14 --dumpCsvCounts; `; and the following one for the PBMC_3K dataset:; `~/software/salmon/scripts/v1_10x/run.sh ~/software/salmon/bin/salmon alevin -l ISR -b pbmc3k_fastqs/ --gemcode -i ../transcripts_index_salmon/ -p 8 -o alevin_output --tgMap ../hg_transcriptome/tx2gene.tsv --dumpCsvCounts; `. **Screenshots**; CD14+ Monocytes shell log:; ```~/software/salmon/scripts/v1_10x/run.sh salmon alevin -l ISR -b ./fastqs/flowcell1/ --gemcode -i ../transcripts_index_salmon/ -p 8 -o ./fastq/test/ --tgMap ../hg_transcriptome/tx2tx.tsv --end 5 --umiLength 5 --barcodeLength 14 --dumpCsvCounts --dumpFeatures. TEMPDIR is /tmp/tmp.lLLibfwH4G; Running command [salmon alevin -l ISR --gemcode -i ../transcripts_index_salmon/ -p 8 -o ./fastq/test/ --tgMap ../hg_transcriptome/tx2tx.tsv --end 5 --umiLength 5 --barcodeLength 14 --dumpCsvCounts --dumpFeatures -1 /tmp/tmp.lLLibfwH4G/p1.fa -2 /tmp/tmp.lLLibfwH4G/p2.fa -r ./fastqs/flowcell1/read-I1_si-ACTTCACT_lane-001-chunk-001.fastq.gz; ./fastqs/flowcell1/read-I1_si-ACTTCACT_lane-002-chunk-000.fastq.gz; ./fastqs/flowcell1/read-I1_si-ACTTCACT_lane-003-chunk-003.fastq.gz; ./fastqs/flowcell1/read-I1_si-ACTTCACT_lane-004-chunk-002.fastq.gz; ./fastqs/flowcell1/read-I1_si-CGAAGTTG_lane-001-chunk-001.fastq.gz; ./fastqs/flowcell1/read-I1_si-CGAAGTTG_lane-002-chunk-000.fastq.gz; ./fastqs/flowcell1/read-I1_si-CGAAGTTG_lane-003-chunk-003.fastq.gz; ./fastqs/flowcell1/read-I1_si-CGAAGTTG_lane-004-chunk-002.fastq.gz; ./fastqs/flowcell1/read-I1_si-GAGCACGC,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/328:1909,test,test,1909,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/328,1,['test'],['test']
Testability,"e 31: 54922 Aborted (core dumped) /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant -i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts -p 1 -l ISR -1 ${FILE1} -2 ${FILE2} -o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test3/${ID}; **** Job ends ****; Wed Mar 29 14:51:13 EDT 2017; ```. ### SGE email info example. ```; Job-array task 110315.1 (step6-salmon_test3.gsk_phaseII) Complete; User = lcollado; Queue = shared.q@compute-061.cm.cluster; Host = compute-061.cm.cluster; Start Time = 03/29/2017 14:51:09; End Time = 03/29/2017 14:51:13; User Time = 00:00:00; System Time = 00:00:02; Wallclock Time = 00:00:04; CPU = 00:00:02; Max vmem = 14.820G; Exit Status = 0; ```. ## 16 cores. ### Bash. ```bash; #!/bin/bash; #$ -cwd; #$ -l mem_free=2G,h_vmem=3G,h_fsize=100G; #$ -N step6-salmon_test4.gsk_phaseII; #$ -pe local 16; #$ -o ./logs/salmon_test4.$TASK_ID.txt; #$ -e ./logs/salmon_test4.$TASK_ID.txt; #$ -t 1-3; #$ -hold_jid pipeline_setup,step4-featCounts-alzheimer.gsk_phaseII; #$ -m e; echo ""**** Job starts ****""; date. echo ""**** JHPCE info ****""; echo ""User: ${USER}""; echo ""Job id: ${JOB_ID}""; echo ""Job name: ${JOB_NAME}""; echo ""Hostname: ${HOSTNAME}""; echo ""Task id: ${TASK_ID}"". FILE1=$(awk 'BEGIN {FS=""\t""} {print $1}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); if [ TRUE == ""TRUE"" ] ; then; FILE2=$(awk 'BEGIN {FS=""\t""} {print $3}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); fi; ID=$(cat /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk '{print $NF}' | awk ""NR==${SGE_TASK_ID}""). mkdir -p /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test4/${ID}. /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant 	-i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gen",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965:3989,log,logs,3989,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965,1,['log'],['logs']
Testability,"e conda evironment) is going differently ! Skip to Try 2. below for success; Try 1.; Index seemed to go the same as before, using the command [from a script]; salmon index -t decoys/gentrome.fa -d decoys/decoys.txt -i salmonIndexDecoyMouse; but then command; salmon quant -p 3 -i salmonIndexDecoyMouse -l A -1 SRR1818187_2.fastq.gz -2 SRR1818187_1.fastq.gz --validateMappings -o Salmontranscripts_quant; Fails as follows, saying it cannot find a .json file(s); ---------------------------------------------------------------------; (salmon) wayne@Ubuntu19:~/rnaseq$ sh salmonQuantDecoy.sh ; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ threads ] => { 3 }; ### [ index ] => { salmonIndexDecoyMouse }; ### [ libType ] => { A }; ### [ mates1 ] => { SRR1818187_2.fastq.gz }; ### [ mates2 ] => { SRR1818187_1.fastq.gz }; ### [ validateMappings ] => { }; ### [ output ] => { Salmontranscripts_quant }; Logs will be written to Salmontranscripts_quant/logs; [2019-08-25 11:40:44.518] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-08-25 11:40:44.518] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2019-08-25 11:40:44.518] [jointLog] [info] Usage of --validateMappings, without --hardFilter implies use of range factorization. rangeFactorizationBins is being set to 4; [2019-08-25 11:40:44.518] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.2.; [2019-08-25 11:40:44.518] [jointLog] [info] parsing read library format; [2019-08-25 11:40:44.518] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file salmonIndexDecoyMouse/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was invoked improperly.; For ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/419#issuecomment-524651435:1138,Log,Logs,1138,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/419#issuecomment-524651435,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"e got the raw transcriptome from ensembl, then prepared it with:; https://github.com/AlexsLemonade/refinebio/blob/dev/workers/data_refinery_workers/processors/transcriptome_index.py. Which produced:; https://s3.amazonaws.com/data-refinery-test-assets/Caenorhabditis_elegans_short_1527089586.tar.gz. * Which read files were used?. Two read files out of:; https://s3.amazonaws.com/data-refinery-test-assets/salmon_tests.tar.gz. found within that archive at:; `test_experiment/raw/reads_1.fastq`; and ; `test_experiment/raw/reads_2.fastq`. Unfortunately I am not entirely sure where these were found. * Which which program options were used?. The exact invocation of salmon was:; ```; salmon --no-version-check quant -l A --biasSpeedSamp 5 -i /home/user/data_store/processed/TEST/TRANSCRIPTOME_INDEX/index -1 /home/user/data_store/salmon_tests/test_experiment/raw/reads_1.fastq -2 /home/user/data_store/salmon_tests/test_experiment/raw/reads_2.fastq -p 20 -o /home/user/data_store/TEST/test_sample/processed/ --seqBias --gcBias --dumpEq --writeUnmappedNames; ```. **Expected behavior**; This happened while I was modifying the tests for running salmon. I'm guessing that my code isn't quite right yet so something going wrong isn't quite unexpected. However I would have expected an error to come out of Salmon rather than producing JSON which is invalid. **Desktop (please complete the following information):**. Our exact environment for running this is described here:; https://github.com/AlexsLemonade/refinebio/blob/dev/workers/dockerfiles/Dockerfile.salmon. The base image is `ubuntu:16.04`. **Additional context**; Here is the contents of `lib_format_counts.json` file (github won't let me upload it):; ```; {; ""read_files"": ""( /home/user/data_store/salmon_tests/test_experiment/raw/reads_1.fastq, /home/user/data_store/salmon_tests/test_experiment/raw/reads_2.fastq )"",; ""expected_format"": ""IU"",; ""compatible_fragment_ratio"": 1.0,; ""num_compatible_fragments"": 184,; ""num_assigned_fragments"": 184,",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/279:2035,TEST,TEST,2035,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/279,1,['TEST'],['TEST']
Testability,"e it appears that this version no longer crashes when given less than about 250GB of memory, I also tested with 32G and 16GB of memory, just to see what impact this would have on the times. Those jobs are still running (it's only been about 4hrs as of this writing, I'll update my post if/when they complete). Current logs are showing that they quickly consume all the available memory, but have not yet crashed. I've also got versions with 128-512GB of memory requested (by powers of 2) for comparison. Some random notes: both the 31-mer index experienced about twice as many soft page reclaims with the new/faster version and experienced a few hard page faults (the previous version saw none of the latter). The 17-mer version experienced fewer page reclaims than any of the 31-mer indices and far fewer than with the prior version. Again, a few page faults crept in, but relatively few by percentage and likely not contributing any significant amount of time overall. [index-qacct-17mer.log](https://github.com/COMBINE-lab/salmon/files/4246516/index-qacct-17mer.log); [index-qacct-31mer.log](https://github.com/COMBINE-lab/salmon/files/4246517/index-qacct-31mer.log). **UPDATE**; The 16GB version finished running. It actually only took a little over 4 hours to run, as well. The troubling thing about this job seems to be that, despite having successfully completed, according to the accounting log it used over 20GB of memory... which should be impossible to do. Our resident experts suspect there's a race condition occurring at the tail end of the job and that all of that extra memory is being allocated before the scheduler can kill it for exceeding the limit. Whatever the case, though, this throws into question some of those numbers that I've been grabbing from the accounting logs --- it's either being misreported, or the memory gobbling is happening so rapidly that it may not, in fact, be being properly recorded. I tested the index anyway. It *appears* to be working just fine. Nothi",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-590516702:1613,log,log,1613,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-590516702,1,['log'],['log']
Testability,"e not sorted, so I shuffled these bam files, and then run `salmon quant`. Here are the errors I got in a number of trials:; > ; > ### Fresh installation of Salmon; > ```; > conda create --name salmon -c bioconda salmon; > conda activate salmon; > ```; > ; > ### 1. Shuffling a bam file with `samtools collate`; > ```; > samtools collate \; > -@ 40 \; > -o SRR3212847.Aligned.Shuffled.bam \; > SRR3212847.Aligned.SortedByCoord.bam; > ; > salmon quant \; > -t mRNA.fasta \; > -p 20 \; > -l A \; > -a SRR3212847.Aligned.Shuffled.bam \; > -o SRR3212847.Aligned.Shuffled ; > ```; > ; > ```; > Version Info: This is the most recent version of salmon.; > # salmon (alignment-based) v1.4.0; > # [ program ] => salmon ; > # [ command ] => quant ; > # [ targets ] => { mRNA.fasta }; > # [ threads ] => { 20 }; > # [ libType ] => { A }; > # [ alignments ] => { SRR3212847.Aligned.Shuffled.bam }; > # [ output ] => { SRR3212847.Aligned.Shuffled }; > Logs will be written to SRR3212847.Aligned.Shuffled/logs; > [2021-01-08 12:43:44.680] [jointLog] [info] setting maxHashResizeThreads to 20; > [2021-01-08 12:43:44.680] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; > Library format { type:paired end, relative orientation:inward, strandedness:unstranded }; > [2021-01-08 12:43:44.711] [jointLog] [info] numQuantThreads = 14; > parseThreads = 6; > Checking that provided alignment files have consistent headers . . . done; > Populating targets from aln = ""SRR3212847.Aligned.Shuffled.bam"", fasta = ""mRNA.fasta"" . . .done; > ; > processed 0 reads in current roundSegmentation fault (core dumped); > ```; > ; > ### 2. Shuffling a headless bam file with `samtools collate`; > (I think I saw something about the bam's header in another thread dealing with this issue); > ; > ```; > samtools view \; > -b \; > -@ 40 \; > -o SRR3212847.Aligned.SortedByCoord.NoHeader.bam \; > SRR3212847.Aligned.SortedByCoord.bam; > ; > samtools collate \; > -@ 40 \; > -o SRR",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/582#issuecomment-1343749456:1204,log,logs,1204,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/582#issuecomment-1343749456,1,['log'],['logs']
Testability,"e of --validateMappings; > implies use of minScoreFraction. Since not explicitly specified, it is; > being set to 0.65; > [2019-07-29 15:58:39.034] [jointLog] [info] Usage of --validateMappings,; > without --hardFilter implies use of range factorization.; > rangeFactorizationBins is being set to 4; > [2019-07-29 15:58:39.034] [jointLog] [info] Usage of --validateMappings; > implies a default consensus slack of 0.2. Setting consensusSlack to 0.2.; > [2019-07-29 15:58:39.034] [jointLog] [info] parsing read library format; > [2019-07-29 15:58:39.034] [jointLog] [error] Failed to successfully parse; > any complete read libraries. Please make sure you provided arguments; > properly to -1, -2 (for paired-end libraries) or -r (for single-end; > libraries), and that the library format option (-l) *comes before* the read; > libraries.; >; > On Mon, Jul 29, 2019 at 4:06 PM Avi Srivastava <notifications@github.com>; > wrote:; >; >> Oh Sorry about that what I meant was the salmon.log file or the the; >> meta-info.json file created by salmon in the output directory. You can; >> check what files salmon is detecting it seems there are 12 files in the; >> mate1 and 13 files in the mate2. Can you confirm there are 13 pairs of file; >> in that directory and their regex is same as you are using ? Can you also; >> try putting the names of the file instead * as regex ?; >>; >> —; >> You are receiving this because you were mentioned.; >> Reply to this email directly, view it on GitHub; >> <https://github.com/COMBINE-lab/salmon/issues/408?email_source=notifications&email_token=AEHDXAA5DHKAZKVCZY5N7ULQB5ZXXA5CNFSM4IGU4ZTKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD3CIG3I#issuecomment-516195181>,; >> or mute the thread; >> <https://github.com/notifications/unsubscribe-auth/AEHDXAHE56TJTIQFQDFDGMDQB5ZXXANCNFSM4IGU4ZTA>; >> .; >>; >; >; > --; > Sara E. Boles, MS; > PhD Candidate | Whitehead Lab; > Pharmacology and Toxicology Graduate Group; > Department of Environmental Toxic",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408#issuecomment-516521791:3393,log,log,3393,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408#issuecomment-516521791,1,['log'],['log']
Testability,"e seg fault on each one. However the number that appears immediately before ""Segmentation fault"" (914 below) varies from one invocation to the next, even on the same data file. . I appreciate any help you can offer and I apologize in advance if there's something obvious I should have read or known about. (it seems like the lines below that are preceded by ### are coming out in fold face. They are not meant to.). (salmon) MacBook-Pro-2:salmon-tutorial brent$ bash quant_tut_samples.sh; Processing sample DRR016125; Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; ### salmon (mapping-based) v0.11.3; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { athal_index }; ### [ libType ] => { A }; ### [ mates1 ] => { data/DRR016125/DRR016125_1.fastq.gz }; ### [ mates2 ] => { data/DRR016125/DRR016125_2.fastq.gz }; ### [ threads ] => { 8 }; ### [ output ] => { quants/DRR016125_quant }; Logs will be written to quants/DRR016125_quant/logs; [2018-11-24 15:08:09.785] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2018-11-24 15:08:09.785] [jointLog] [info] parsing read library format; [2018-11-24 15:08:09.785] [jointLog] [info] There is 1 library.; [2018-11-24 15:08:09.877] [jointLog] [info] Loading Quasi index; [2018-11-24 15:08:09.877] [jointLog] [info] Loading 32-bit quasi index; [2018-11-24 15:08:09.877] [stderrLog] [info] Loading Suffix Array ; [2018-11-24 15:08:10.319] [stderrLog] [info] Loading Transcript Info ; [2018-11-24 15:08:10.423] [stderrLog] [info] Loading Rank-Select Bit Array; [2018-11-24 15:08:10.432] [stderrLog] [info] There were 40,812 set bits in the bit array; [2018-11-24 15:08:10.435] [stderrLog] [info] Computing transcript lengths; [2018-11-24 15:08:10.435] [stderrLog] [info] Waiting to finish loading hash. quant_tut_samples.sh: line 2: 914 Segmentation fault: 11 salmon quant -i athal_i",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/317#issuecomment-441396828:1303,Log,Logs,1303,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/317#issuecomment-441396828,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"e step6-txQuant-alzheimer.gsk_phaseII; jobnumber 9958683; taskid 3; account sge; priority 0; qsub_time Mon Mar 6 23:18:58 2017; start_time Mon Mar 6 23:19:12 2017; end_time Tue Mar 7 17:27:45 2017; granted_pe local; slots 1; failed 0; exit_status 0; ru_wallclock 65313; ru_utime 25600.565; ru_stime 29552.966; ru_maxrss 6548296; ru_ixrss 0; ru_ismrss 0; ru_idrss 0; ru_isrss 0; ru_minflt 1662027; ru_majflt 369; ru_nswap 0; ru_inblock 0; ru_oublock 56256; ru_msgsnd 0; ru_msgrcv 0; ru_nsignals 0; ru_nvcsw 801190; ru_nivcsw 2880329; cpu 55153.531; mem 403295.295; io 17.447; iow 0.000; maxvmem 9.065G; arid undefined; ```. For task 1 the maxvmem was 9.072G and for task 2 9.061G. I then ran a test requesting a minimum of 10 GB of free RAM and a max of 11 GB, which in theory should work unless `salmon` uses variable amounts of memory with the same data. ```bash; #!/bin/bash; #$ -cwd; #$ -l mem_free=10G,h_vmem=11G,h_fsize=100G; #$ -N step6-salmon_test.gsk_phaseII; #$ -pe local 1; #$ -o ./logs/salmon_test.$TASK_ID.txt; #$ -e ./logs/salmon_test.$TASK_ID.txt; #$ -m a; echo ""**** Job starts ****""; date. echo ""**** JHPCE info ****""; echo ""User: ${USER}""; echo ""Job id: ${JOB_ID}""; echo ""Job name: ${JOB_NAME}""; echo ""Hostname: ${HOSTNAME}""; echo ""Task id: ${TASK_ID}"". FILE1=$(awk 'BEGIN {FS=""\t""} {print $1}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); FILE2=$(awk 'BEGIN {FS=""\t""} {print $3}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); ID=$(cat /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk '{print $NF}' | awk ""NR==${SGE_TASK_ID}""). mkdir -p /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test/${ID}. /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.7.2_linux_x86_64/bin/salmon quant 	-i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/GENCODE/GRCh38_hg38/transcripts/salmon_index_gencode.v25.transcripts -p 1 -l ISR 	-1 ${FILE1} -2 ${FILE2} 	-o /dcl0",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126:21380,log,logs,21380,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126,1,['log'],['logs']
Testability,"eads.fq > aln.sam`. This approach seems to employ a splicing aware algorithm against a genomic reference, using canonical splicing signals to help map the transcripts. However, this method doesn't seem to be applicable to Salmon given the requirement that the reads are aligned directly to the transcriptome (hence the need to account for splicing with '_-ac splice_' is lost). An alternative approach I've seen (i.e., the one used in ONT's own DGE [pipeline](https://github.com/nanoporetech/pipeline-transcriptome-de)) is to use minimap2 to align to the transcriptome reference but to retain a large number of secondary mappings (-N 100 in minimap2):. `minimap2 -ax map-ont -N 100 transcriptome.fa reads.fq`. This makes more sense in terms of the _-ax_ preset used, but I guess I'm just wondering then what the optimal input for Salmon would be in order to get the most accurate count data? I know secondary mappings are important for the algorithm to calculate uncertainty / maximum likelihood, but is there an recommend number of these to retain? The logic behind allowing for a high number of secondary alignments when using a transcriptome reference is to account for the high similarity among isoforms. From a high-level view I could see how this might be problematic though, depending on how Salmon actually uses the alternate mappings (i.e., is it just for the statistics or does it affect the counts as well?). . I've also seen groups toying with adjusting the _-p_ setting in minimap2 which sets the minimal ratio of the secondary to primary alignment score that is allowed in order to report the secondary mapping. Surveying the forums and discussion boards, values of _-N_ ranging from the default of 5 to 100 and of _-p_ ranging from 0 to 1, (i.e., anything) seem to be acceptable. Given this ambiguity, I figured going to the 'source' and asking the creators what Salmon actually wants might be beneficial, so if yall have done any testing or have recommendations I'd very appreciative.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/790:2657,test,testing,2657,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/790,1,['test'],['testing']
Testability,"ebio/blob/dev/workers/data_refinery_workers/processors/transcriptome_index.py. Which produced:; https://s3.amazonaws.com/data-refinery-test-assets/Caenorhabditis_elegans_short_1527089586.tar.gz. * Which read files were used?. Two read files out of:; https://s3.amazonaws.com/data-refinery-test-assets/salmon_tests.tar.gz. found within that archive at:; `test_experiment/raw/reads_1.fastq`; and ; `test_experiment/raw/reads_2.fastq`. Unfortunately I am not entirely sure where these were found. * Which which program options were used?. The exact invocation of salmon was:; ```; salmon --no-version-check quant -l A --biasSpeedSamp 5 -i /home/user/data_store/processed/TEST/TRANSCRIPTOME_INDEX/index -1 /home/user/data_store/salmon_tests/test_experiment/raw/reads_1.fastq -2 /home/user/data_store/salmon_tests/test_experiment/raw/reads_2.fastq -p 20 -o /home/user/data_store/TEST/test_sample/processed/ --seqBias --gcBias --dumpEq --writeUnmappedNames; ```. **Expected behavior**; This happened while I was modifying the tests for running salmon. I'm guessing that my code isn't quite right yet so something going wrong isn't quite unexpected. However I would have expected an error to come out of Salmon rather than producing JSON which is invalid. **Desktop (please complete the following information):**. Our exact environment for running this is described here:; https://github.com/AlexsLemonade/refinebio/blob/dev/workers/dockerfiles/Dockerfile.salmon. The base image is `ubuntu:16.04`. **Additional context**; Here is the contents of `lib_format_counts.json` file (github won't let me upload it):; ```; {; ""read_files"": ""( /home/user/data_store/salmon_tests/test_experiment/raw/reads_1.fastq, /home/user/data_store/salmon_tests/test_experiment/raw/reads_2.fastq )"",; ""expected_format"": ""IU"",; ""compatible_fragment_ratio"": 1.0,; ""num_compatible_fragments"": 184,; ""num_assigned_fragments"": 184,; ""num_consistent_mappings"": 0,; ""num_inconsistent_mappings"": 255,; ""strand_mapping_bias"": NaN,; ""MSF"": ",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/279:2181,test,tests,2181,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/279,1,['test'],['tests']
Testability,"echo ""User: ${USER}""; echo ""Job id: ${JOB_ID}""; echo ""Job name: ${JOB_NAME}""; echo ""Hostname: ${HOSTNAME}""; echo ""Task id: ${TASK_ID}"". FILE1=$(awk 'BEGIN {FS=""\t""} {print $1}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); FILE2=$(awk 'BEGIN {FS=""\t""} {print $3}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); ID=$(cat /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk '{print $NF}' | awk ""NR==${SGE_TASK_ID}""). mkdir -p /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test/${ID}. /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.7.2_linux_x86_64/bin/salmon quant 	-i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/GENCODE/GRCh38_hg38/transcripts/salmon_index_gencode.v25.transcripts -p 1 -l ISR 	-1 ${FILE1} -2 ${FILE2} 	-o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test/${ID}. echo ""**** Job ends ****""; date; ```. The log file for the same file (task 3) now shows that there was a problem:. ```; **** Job starts ****; Wed Mar 8 11:37:31 EST 2017; **** JHPCE info ****; User: lcollado; Job id: 9987275; Job name: step6-salmon_test.gsk_phaseII; Hostname: compute-051; Task id:; Version Info: ### A newer version of Salmon is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and minor bug fixes; please upgrade at your; earliest convenience.; ###; ### salmon (mapping-based) v0.7.2; ### [ program ] => salmon; ### [ command ] => quant; ### [ index ] => { /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/GENCODE/GRCh38_hg38/transcripts/salmon_index_gencode.v25.transcripts }; ### [ threads ] => { 1 }; ### [ libType ] => { ISR }; ### [ mates1 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10003_D19KGACXX.fastq.gz }; ### [ mates2 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10003_D19KGACXX_read2.fastq.gz }; ### [ o",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126:22490,log,log,22490,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126,1,['log'],['log']
Testability,"ed by your `auto-load safe-path' set to ""$debugdir:$datadir/auto-load"".; To enable execution of this file add; add-auto-load-safe-path /u/user/local/lib64/libstdc++.so.6.0.21-gdb.py; line to your configuration file ""/u/user/.gdbinit"".; To completely disable this security protection add; set auto-load safe-path /; line to your configuration file ""/u/user/.gdbinit"".; For more information about this security protection see the; ""Auto-loading safe path"" section in the GDB manual. E.g., run from the shell:; info ""(gdb)Auto-loading safe path""; [New Thread 0x7fff7e0f4700 (LWP 14274)]; Version Info: ### A newer version of Salmon is available. ####; [Thread 0x7fff7e0f4700 (LWP 14274) exited]; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; [New Thread 0x7fff7d273700 (LWP 14275)]; Logs will be written to pbmc4k/alevin/logs; [New Thread 0x7ffefc3f1700 (LWP 14276)]; [New Thread 0x7ffe7b56f700 (LWP 14277)]; [New Thread 0x7ffdfa6ed700 (LWP 14278)]; ### salmon (single-cell-based) v0.10.1; ### [ program ] => salmon; ### [ command ] => alevin; ### [ libType ] => { ISR }; ### [ chromium ] => { }; ### [ threads ] => { 8 }; ### [ output ] => { pbmc4k/alevin }; ### [ mates1 ] => { /dev/fd/63 }; ### [ mates2 ] => { /dev/fd/62 }; ### [ index ] => { /u/user/ref/cellranger/salmon/transcripts_index }; ### [ tgMap ] => { tx2gene.txt }. [2018-06-08 13:37:41.409] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [New Thread 0x7ffd795e7700 (LWP 14279)]; [New Thread 0x7ffcf95e6700 (LWP 14280)]; [New Thread 0x7ffc795e5700 (LWP 14281)]; [2018-06-08 13:37:41.419] [alevinLog] [info] Processing barcodes files (if Present). processed 6 Million barcodes[New Thread 0x7ffbf7063700 (LWP 14333)]; [New Thread 0x7ffb77062700 (LWP 14334)]; [New Thread 0x7ffaf7061700 (LWP 14335)]; [New Thread 0x7ffa77060700 (LWP 1433",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395836214:3098,Log,Logs,3098,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395836214,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"ed data),; `--validateMappings` is generally recommended. [2019-07-24 13:33:29.347] [jointLog] [info] parsing read library format; [2019-07-24 13:33:29.347] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file abalone_index/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting.; /var/spool/slurmd/job12930414/slurm_script: line 14: --validateMappings: command not found; basename: extra operand ‘lightreceptor-1_S114_L005_R1_001.qc.fq.gz’; Try 'basename --help' for more information.; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { abalone_index }; ### [ libType ] => { A }; ### [ mates1 ] => { .R1_001.qc.fq.gz }; ### [ mates2 ] => { .R2_001.qc.fq.gz }; ### [ output ] => { .quant }; Logs will be written to .quant/logs; [2019-07-24 13:33:29.441] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-07-24 13:33:29.441] [jointLog] [warning] . NOTE: It appears you are running salmon without the `--validateMappings` option.; Mapping validation can generally improve both the sensitivity and specificity of mapping,; with only a moderate increase in use of computational resources. ; Mapping validation is planned to become a default option (i.e. turned on by default) in; the next release of salmon.; Unless there is a specific reason to do this (e.g. testing on clean simulated data),; `--validateMappings` is generally recommended. [2019-07-24 13:33:29.441] [jointLog] [info] parsing read library format; [2019-07-24 13:33:29.441] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file abalone_index/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was invoked improperly.; For usage inform",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408:2736,log,logs,2736,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408,1,['log'],['logs']
Testability,"ed data),; `--validateMappings` is generally recommended. [2019-07-24 13:33:29.441] [jointLog] [info] parsing read library format; [2019-07-24 13:33:29.441] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file abalone_index/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting.; /var/spool/slurmd/job12930414/slurm_script: line 14: --validateMappings: command not found; basename: extra operand ‘lightreceptor-1_S114_L005_R1_001.qc.fq.gz’; Try 'basename --help' for more information.; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { abalone_index }; ### [ libType ] => { A }; ### [ mates1 ] => { .R1_001.qc.fq.gz }; ### [ mates2 ] => { .R2_001.qc.fq.gz }; ### [ output ] => { .quant }; Logs will be written to .quant/logs; [2019-07-24 13:33:29.532] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-07-24 13:33:29.532] [jointLog] [warning] . NOTE: It appears you are running salmon without the `--validateMappings` option.; Mapping validation can generally improve both the sensitivity and specificity of mapping,; with only a moderate increase in use of computational resources. ; Mapping validation is planned to become a default option (i.e. turned on by default) in; the next release of salmon.; Unless there is a specific reason to do this (e.g. testing on clean simulated data),; `--validateMappings` is generally recommended. [2019-07-24 13:33:29.532] [jointLog] [info] parsing read library format; Exception : [Error: The index version file abalone_index/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was invoked improperly.; For usage information, try salmon[2019-07-24 13:33:29.532] [jointLog] [info] Ther",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408:4347,log,logs,4347,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408,1,['log'],['logs']
Testability,"ed data),; `--validateMappings` is generally recommended. [2019-07-24 13:33:29.626] [jointLog] [info] parsing read library format; [2019-07-24 13:33:29.626] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file abalone_index/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting.; /var/spool/slurmd/job12930414/slurm_script: line 14: --validateMappings: command not found; basename: extra operand ‘lightreceptor-1_S114_L005_R1_001.qc.fq.gz’; Try 'basename --help' for more information.; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { abalone_index }; ### [ libType ] => { A }; ### [ mates1 ] => { .R1_001.qc.fq.gz }; ### [ mates2 ] => { .R2_001.qc.fq.gz }; ### [ output ] => { .quant }; Logs will be written to .quant/logs; [2019-07-24 13:33:29.720] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-07-24 13:33:29.720] [jointLog] [warning] . NOTE: It appears you are running salmon without the `--validateMappings` option.; Mapping validation can generally improve both the sensitivity and specificity of mapping,; with only a moderate increase in use of computational resources. ; Mapping validation is planned to become a default option (i.e. turned on by default) in; the next release of salmon.; Unless there is a specific reason to do this (e.g. testing on clean simulated data),; `--validateMappings` is generally recommended. [2019-07-24 13:33:29.720] [jointLog] [info] parsing read library format; [2019-07-24 13:33:29.720] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file abalone_index/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was invoked improperly.; For usage inform",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408:7568,log,logs,7568,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408,1,['log'],['logs']
Testability,"ed data),; `--validateMappings` is generally recommended. [2019-07-24 13:33:29.720] [jointLog] [info] parsing read library format; [2019-07-24 13:33:29.720] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file abalone_index/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting.; /var/spool/slurmd/job12930414/slurm_script: line 14: --validateMappings: command not found; basename: extra operand ‘lightreceptor-1_S114_L005_R1_001.qc.fq.gz’; Try 'basename --help' for more information.; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { abalone_index }; ### [ libType ] => { A }; ### [ mates1 ] => { .R1_001.qc.fq.gz }; ### [ mates2 ] => { .R2_001.qc.fq.gz }; ### [ output ] => { .quant }; Logs will be written to .quant/logs; [2019-07-24 13:33:29.808] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-07-24 13:33:29.808] [jointLog] [warning] . NOTE: It appears you are running salmon without the `--validateMappings` option.; Mapping validation can generally improve both the sensitivity and specificity of mapping,; with only a moderate increase in use of computational resources. ; Mapping validation is planned to become a default option (i.e. turned on by default) in; the next release of salmon.; Unless there is a specific reason to do this (e.g. testing on clean simulated data),; `--validateMappings` is generally recommended. [2019-07-24 13:33:29.808] [jointLog] [info] parsing read library format; [2019-07-24 13:33:29.808] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file abalone_index/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was invoked improperly.; For usage inform",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408:9179,log,logs,9179,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408,1,['log'],['logs']
Testability,"ed data),; `--validateMappings` is generally recommended. [2019-07-24 13:33:29.808] [jointLog] [info] parsing read library format; [2019-07-24 13:33:29.808] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file abalone_index/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting.; /var/spool/slurmd/job12930414/slurm_script: line 14: --validateMappings: command not found; basename: extra operand ‘lightreceptor-1_S114_L005_R1_001.qc.fq.gz’; Try 'basename --help' for more information.; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { abalone_index }; ### [ libType ] => { A }; ### [ mates1 ] => { .R1_001.qc.fq.gz }; ### [ mates2 ] => { .R2_001.qc.fq.gz }; ### [ output ] => { .quant }; Logs will be written to .quant/logs; [2019-07-24 13:33:29.899] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-07-24 13:33:29.899] [jointLog] [warning] . NOTE: It appears you are running salmon without the `--validateMappings` option.; Mapping validation can generally improve both the sensitivity and specificity of mapping,; with only a moderate increase in use of computational resources. ; Mapping validation is planned to become a default option (i.e. turned on by default) in; the next release of salmon.; Unless there is a specific reason to do this (e.g. testing on clean simulated data),; `--validateMappings` is generally recommended. [2019-07-24 13:33:29.899] [jointLog] [info] parsing read library format; [2019-07-24 13:33:29.899] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file abalone_index/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was invoked improperly.; For usage inform",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408:10790,log,logs,10790,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408,1,['log'],['logs']
Testability,"ed data),; `--validateMappings` is generally recommended. [2019-07-24 13:33:29.899] [jointLog] [info] parsing read library format; [2019-07-24 13:33:29.899] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file abalone_index/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting.; /var/spool/slurmd/job12930414/slurm_script: line 14: --validateMappings: command not found; basename: extra operand ‘lightreceptor-1_S114_L005_R1_001.qc.fq.gz’; Try 'basename --help' for more information.; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { abalone_index }; ### [ libType ] => { A }; ### [ mates1 ] => { .R1_001.qc.fq.gz }; ### [ mates2 ] => { .R2_001.qc.fq.gz }; ### [ output ] => { .quant }; Logs will be written to .quant/logs; [2019-07-24 13:33:29.990] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-07-24 13:33:29.990] [jointLog] [warning] . NOTE: It appears you are running salmon without the `--validateMappings` option.; Mapping validation can generally improve both the sensitivity and specificity of mapping,; with only a moderate increase in use of computational resources. ; Mapping validation is planned to become a default option (i.e. turned on by default) in; the next release of salmon.; Unless there is a specific reason to do this (e.g. testing on clean simulated data),; `--validateMappings` is generally recommended. [2019-07-24 13:33:29.990] [jointLog] [info] parsing read library format; [2019-07-24 13:33:29.990] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file abalone_index/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was invoked improperly.; For usage inform",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408:12401,log,logs,12401,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408,1,['log'],['logs']
Testability,"ed data),; `--validateMappings` is generally recommended. [2019-07-24 13:33:29.990] [jointLog] [info] parsing read library format; [2019-07-24 13:33:29.990] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file abalone_index/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting.; /var/spool/slurmd/job12930414/slurm_script: line 14: --validateMappings: command not found; basename: extra operand ‘lightreceptor-1_S114_L005_R1_001.qc.fq.gz’; Try 'basename --help' for more information.; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { abalone_index }; ### [ libType ] => { A }; ### [ mates1 ] => { .R1_001.qc.fq.gz }; ### [ mates2 ] => { .R2_001.qc.fq.gz }; ### [ output ] => { .quant }; Logs will be written to .quant/logs; [2019-07-24 13:33:30.080] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; Exception : [Error: The index version file abalone_index/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting.; [2019-07-24 13:33:30.080] [jointLog] [warning] . NOTE: It appears you are running salmon without the `--validateMappings` option.; Mapping validation can generally improve both the sensitivity and specificity of mapping,; with only a moderate increase in use of computational resources. ; Mapping validation is planned to become a default option (i.e. turned on by default) in; the next release of salmon.; Unless there is a specific reason to do this (e.g. testing on clean simulated data),; `--validateMappings` is generally recommended. [2019-07-24 13:33:30.080] [jointLog] [info] parsing read library format; [2019-07-24 13:33:30.08",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408:14012,log,logs,14012,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408,1,['log'],['logs']
Testability,"ed data),; `--validateMappings` is generally recommended. [2019-07-24 13:33:30.175] [jointLog] [info] parsing read library format; [2019-07-24 13:33:30.175] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file abalone_index/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting.; /var/spool/slurmd/job12930414/slurm_script: line 14: --validateMappings: command not found; basename: extra operand ‘lightreceptor-1_S114_L005_R1_001.qc.fq.gz’; Try 'basename --help' for more information.; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { abalone_index }; ### [ libType ] => { A }; ### [ mates1 ] => { .R1_001.qc.fq.gz }; ### [ mates2 ] => { .R2_001.qc.fq.gz }; ### [ output ] => { .quant }; Logs will be written to .quant/logs; [2019-07-24 13:33:30.269] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-07-24 13:33:30.269] [jointLog] [warning] . NOTE: It appears you are running salmon without the `--validateMappings` option.; Mapping validation can generally improve both the sensitivity and specificity of mapping,; with only a moderate increase in use of computational resources. ; Mapping validation is planned to become a default option (i.e. turned on by default) in; the next release of salmon.; Unless there is a specific reason to do this (e.g. testing on clean simulated data),; `--validateMappings` is generally recommended. Exception : [Error: The index version file abalone_index/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting.; [2019-07-24 13:33:30.269] [jointLog] [info] parsing read library format; [2019-07-24 13:33:30.26",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408:17234,log,logs,17234,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408,1,['log'],['logs']
Testability,"ed, it is being set to 0.65; [2019-01-29 15:45:58.012] [jointLog] [info] Usage of --validateMappings implies use of range factorization. rangeFactorizationBins is being set to 4; [2019-01-29 15:45:58.012] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 1. Setting consensusSlack to 1.; [2019-01-29 15:45:58.012] [jointLog] [info] Using default value of 0.8 for minScoreFraction in Alevin; [2019-01-29 15:45:58.021] [alevinLog] [info] Processing barcodes files (if Present). processed 287 Million barcodes. [2019-01-29 15:51:37.144] [alevinLog] [info] Done barcode density calculation.; [2019-01-29 15:51:37.144] [alevinLog] [info] # Barcodes Used: 287883370 / 287983348.; [2019-01-29 15:51:38.549] [alevinLog] [error] Can't find right Boundary.; Please Report this issue on github.; ```. ### whitelist forceCells 3000. The mapping rate was boost to 37%, but now the forceCells and expectCells seems not work, alevin still processed over 400,000 cells.; ```; cat logs/salmon_quant.log; [2019-01-28 21:02:08.487] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-01-28 21:02:08.487] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2019-01-28 21:02:08.487] [jointLog] [info] Usage of --validateMappings implies use of range factorization. rangeFactorizationBins is being set to 4; [2019-01-28 21:02:08.487] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 1. Setting consensusSlack to 1.; [2019-01-28 21:02:08.487] [jointLog] [info] Using default value of 0.8 for minScoreFraction in Alevin; [2019-01-28 21:09:02.560] [jointLog] [info] There is 1 library.; [2019-01-28 21:09:04.049] [jointLog] [info] Loading Quasi index; [2019-01-28 21:09:04.286] [jointLog] [info] Loading 32-bit quasi index; [2019-01-28 21:09:43.870] [jointLog] [info] done; [2019-01-28 21:09:43.870] [jointLog] [i",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/340:5308,log,logs,5308,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/340,1,['log'],['logs']
Testability,"een struggling with this for a few days and would be very grateful for any advice on how to move forward. Thank you in advance. Here is my command:; ```; #!/bin/bash -l ; #SBATCH -J male_salmon_map; #SBATCH -t 700:00:00; #SBATCH -p high; #SBATCH --cpus-per-task=24; source ~/.bashrc; source activate salmon; cd /home/seboles/abaloneraw/salmon_quantification/salmon_male/abalone_orfs/; ./bin/salmon -i salmon_index -p 8 -l --libType A -1 *R1_001.qc.fq.gz -2 R2_001.qc.fq.gz --validateMappings -o transcripts_quant; ```; # And here is my error message:. ```; basename: extra operand ‘lightreceptor-1_S114_L005_R1_001.qc.fq.gz’; Try 'basename --help' for more information.; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { abalone_index }; ### [ libType ] => { A }; ### [ mates1 ] => { .R1_001.qc.fq.gz }; ### [ mates2 ] => { .R2_001.qc.fq.gz }; ### [ output ] => { .quant }; Logs will be written to .quant/logs; [2019-07-24 13:33:29.347] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-07-24 13:33:29.347] [jointLog] [warning] . NOTE: It appears you are running salmon without the `--validateMappings` option.; Mapping validation can generally improve both the sensitivity and specificity of mapping,; with only a moderate increase in use of computational resources. ; Mapping validation is planned to become a default option (i.e. turned on by default) in; the next release of salmon.; Unless there is a specific reason to do this (e.g. testing on clean simulated data),; `--validateMappings` is generally recommended. [2019-07-24 13:33:29.347] [jointLog] [info] parsing read library format; [2019-07-24 13:33:29.347] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file abalone_index/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was inv",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408:1094,Log,Logs,1094,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408,1,['Log'],['Logs']
Testability,"en I build this index on one of our machines. Perhaps we could see if these match: . ```; $:salmon_index [j1] (develop ?) $ sha256sum *; 306e9d98b3460859f579059bf876aa3b6e264c8f38c04cde332b03632edc6dfb complete_ref_lens.bin; 28519aac34b84b4d0570c97340815e719511c204e04a240dd43e365d2872eed3 ctable.bin; 1c7501deaa4524f4700152713228cb03949775dce481384eac67bb45458508be ctg_offsets.bin; dbc575fed0d589b4671c26bd8cbcb4b3d52ef41c299a90de978ab940abb751fc duplicate_clusters.tsv; 987050914456cf247a24136429d8faaa293cf5617bfd57166c64976b2778d95b info.json; 0b7e8cb4ebed78513900831c047f0d66589068921c33bb15c49b3567c84e2edc mphf.bin; 117369928fde1bff4ca278246c331e079cc0860c3b415e34cd4b08f588063abc pos.bin; 297492e67d274b2ff8f026d2fbc8045f96e17793a58dd74c19b5ab1b7156df8a pre_indexing.log; 8e665e5fdee5af6fcedabc69fd04eda6e66055ef811ebde6de6f86a66521198a rank.bin; 793c79f5fd6046dfea07bbc9587d2835088e54c78197d652d1b1f205c6b16983 refAccumLengths.bin; 92acf575c90c6954ff75be1ea791f822eee05e486c6e86c52943d8bc1a0849ca ref_indexing.log; b580b9c6257254a018a9ae22291a64892c1a3715c69272637f5c504fc5545a70 reflengths.bin; 89679603ac0b28042275e5ff04b222bad3fd431cab573f0c2b61e7455aec43e7 refseq.bin; 94cb79a2f4acd811d2164f2926c96869a8103b9118170d0688f57b46e695cd5c seq.bin; 89d56bb135f32c7b5fa337bc3c45814b80c2886a3cccc31ff0533c6324ca11fd versionInfo.json; ```. I'm also including a link [here](https://drive.google.com/file/d/1uxGUy8gaQ20dpEi7-D3ookFF4JYawsIR/view?usp=sharing) to a tarball containing the index I built. Could you see if you can perform quantification with this index? Finally, it might be worth checking that nothing strange / unexpected is going on with how libraries are being resolved in the linker path when you are running salmon. Could you share the output of running `ldd salmon`? If none of those point at anything obvious, I might also suggest seeing if it runs as expected inside a Docker container. You can grab a dockerfile for salmon [here](https://hub.docker.com/r/combinelab/salmon).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/561#issuecomment-674454751:1345,log,log,1345,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/561#issuecomment-674454751,1,['log'],['log']
Testability,"environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): / Killed. this is the first time I've encountered an issue where something that is ""supposed"" to be there can't be found. Adam H. Freedman, PhD; Data Scientist; Faculty of Arts & Sciences Informatics Group; Harvard University; 38 Oxford St; Cambridge, MA 02138; phone: +001 310 415 7145; ________________________________; From: Rob Patro ***@***.***>; Sent: Sunday, October 29, 2023 10:01 AM; To: COMBINE-lab/salmon ***@***.***>; Cc: Freedman, Adam ***@***.***>; State change ***@***.***>; Subject: Re: [COMBINE-lab/salmon] anaconda version of salmon outdated, missing decoys option (Issue #895). I'm going to cc @dpryan79<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_dpryan79&d=DwMFaQ&c=WO-RGvefibhHBZq3fL85hQ&r=MITI_LEJgyr1a24IMFAlSaZIPxMpOUT21T7L3fg4CjA&m=mSC4skssR3kpqIDO5fXv00Vk9PrFQeVf0OH62EOgXZ9hbM31qjkaQra0z60JiEA_&s=hPsmfTmSAfiwDhS2JFQyD0EUHl5m5sbj_n46DYj6tdM&e=> on this — does it just not finish? It seems to work within our GitHub CI, where we have to grab the prebuilt salmon to test simpleaf. —; Reply to this email directly, view it on GitHub<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_COMBINE-2Dlab_salmon_issues_895-23issuecomment-2D1784122719&d=DwMFaQ&c=WO-RGvefibhHBZq3fL85hQ&r=MITI_LEJgyr1a24IMFAlSaZIPxMpOUT21T7L3fg4CjA&m=mSC4skssR3kpqIDO5fXv00Vk9PrFQeVf0OH62EOgXZ9hbM31qjkaQra0z60JiEA_&s=6Y-rQOzzAA-t9QV8NyfcMVeySD2an4xeN1HsDqa6VpQ&e=>, or unsubscribe<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_notifications_unsubscribe-2Dauth_ADBMMUDFRQIHN4AMNBHWCN3YBZOUTAVCNFSM6AAAAAA6UYYPGOVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTOOBUGEZDENZRHE&d=DwMFaQ&c=WO-RGvefibhHBZq3fL85hQ&r=MITI_LEJgyr1a24IMFAlSaZIPxMpOUT21T7L3fg4CjA&m=mSC4skssR3kpqIDO5fXv00Vk9PrFQeVf0OH62EOgXZ9hbM31qjkaQra0z60JiEA_&s=ckSFRx1FekMV-wL0KtdZFPdtgCB1DiAziHIsdrF0cKQ&e=>.; You are receiving this because you mo",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/895#issuecomment-1784126021:1420,test,test,1420,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/895#issuecomment-1784126021,2,['test'],['test']
Testability,"ep1_S42_R1_001Aligned.out.bam leaf_infe_t2_rep3_S66_R1_001Aligned.out.bam leaf_infe_t3_rep1_S43_R1_001Aligned.out.bam leaf_infe_t3_rep3_S67_R1_001Aligned.out.bam leaf_infe_t4_rep1_S44_R1_001Aligned.out.bam leaf_infe_t4_rep3_S68_R1_001Aligned.out.bam leaf_infe_t5_rep1_S45_R1_001Aligned.out.bam leaf_infe_t5_rep3_S69_R1_001Aligned.out.bam leaf_infe_t6_rep1_S46_R1_001Aligned.out.bam leaf_infe_t6_rep3_S70_R1_001Aligned.out.bam leaf_mock_t1_rep1_S35_R1_001Aligned.out.bam leaf_mock_t1_rep3_S59_R1_001Aligned.out.bam leaf_mock_t2_rep1_S36_R1_001Aligned.out.bam leaf_mock_t2_rep3_S60_R1_001Aligned.out.bam leaf_mock_t3_rep1_S37_R1_001Aligned.out.bam leaf_mock_t3_rep3_S61_R1_001Aligned.out.bam leaf_mock_t4_rep1_S38_R1_001Aligned.out.bam leaf_mock_t4_rep3_S62_R1_001Aligned.out.bam leaf_mock_t5_rep1_S39_R1_001Aligned.out.bam leaf_mock_t5_rep3_S63_R1_001Aligned.out.bam leaf_mock_t6_rep1_S40_R1_001Aligned.out.bam leaf_mock_t6_rep3_S64_R1_001Aligned.out.bam }; # [ output ] => { ../SalmonQuantFiles }; Logs will be written to ../SalmonQuantFiles/logs; [2023-01-29 16:06:31.513] [jointLog] [info] setting maxHashResizeThreads to 8; [2023-01-29 16:06:31.513] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; Library format { type:single end, relative orientation:none, strandedness:unstranded }; [2023-01-29 16:06:31.580] [jointLog] [info] numQuantThreads = 4; parseThreads = 4; Checking that provided alignment files have consistent headers . . . done; Populating targets from aln = ""apex_infe_t1_rep1_S29_R1_001Aligned.out.bam"", fasta = ""/rsstu/users/c/cjdohert/NSF_Tomato/AT_RefGenomeFiles/TAIR10_chr_all.fas"" . . .done. processed 0 reads in current round[2023-01-29 16:06:34.583] [jointLog] [info] replaced 186,207 non-ACGT nucleotides with random nucleotides; processed 2000000 reads in current round[2023-01-29 16:06:35.068] [jointLog] [info] Automatically detected most likely library type as U. [2023-01-29 16:06:35.443] [jointLog] [info] .",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/825:6718,Log,Logs,6718,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/825,1,['Log'],['Logs']
Testability,eproduce**. * Salmon version: Release v0.11.3; * Installed from: Compiled. I also followed the instructions from the [alevin tutorial](https://combine-lab.github.io/alevin-tutorial/2018/running-alevin/) to compile the `scripts/v1_10x/wrapper.cpp` file; * Reference transcriptome: [Homo_sapiens.GRCh37.cdna.all.fa](ftp://ftp.ensembl.org/pub/grch37/release-83/fasta/homo_sapiens/cdna/Homo_sapiens.GRCh37.cdna.all.fa.gz); * Which read files were used? Either the [CD14+ Monocytes from the 10x v1 paper](http://s3-us-west-2.amazonaws.com/10x.files/samples/cell-exp/1.1.0/cd14_monocytes/cd14_monocytes_fastqs.tar) or the [PBMC 3k from the same paper](http://cf.10xgenomics.com/samples/cell-exp/1.0.0/pbmc3k/pbmc3k_fastqs.tar); * Which program options were used?; I ran the following command for the CD14 Monocytes dataset:; `~/software/salmon/scripts/v1_10x/run.sh ~/software/salmon/bin/salmon salmon alevin -l ISR -b ./fastq/fastqs/flowcell1/ --gemcode -i ./transcripts_index_salmon/ -p 8 -o ./fastq/test/ --tgMap ./hg_transcriptome/tx2tx.tsv --end 5 --umiLength 5 --barcodeLength 14 --dumpCsvCounts; `; and the following one for the PBMC_3K dataset:; `~/software/salmon/scripts/v1_10x/run.sh ~/software/salmon/bin/salmon alevin -l ISR -b pbmc3k_fastqs/ --gemcode -i ../transcripts_index_salmon/ -p 8 -o alevin_output --tgMap ../hg_transcriptome/tx2gene.tsv --dumpCsvCounts; `. **Screenshots**; CD14+ Monocytes shell log:; ```~/software/salmon/scripts/v1_10x/run.sh salmon alevin -l ISR -b ./fastqs/flowcell1/ --gemcode -i ../transcripts_index_salmon/ -p 8 -o ./fastq/test/ --tgMap ../hg_transcriptome/tx2tx.tsv --end 5 --umiLength 5 --barcodeLength 14 --dumpCsvCounts --dumpFeatures. TEMPDIR is /tmp/tmp.lLLibfwH4G; Running command [salmon alevin -l ISR --gemcode -i ../transcripts_index_salmon/ -p 8 -o ./fastq/test/ --tgMap ../hg_transcriptome/tx2tx.tsv --end 5 --umiLength 5 --barcodeLength 14 --dumpCsvCounts --dumpFeatures -1 /tmp/tmp.lLLibfwH4G/p1.fa -2 /tmp/tmp.lLLibfwH4G/p2.fa -r ./fastqs/flowc,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/328:1341,test,test,1341,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/328,1,['test'],['test']
Testability,"eq"": true,; > ""have_edge_vec"": false,; > ""SeqHash"": ""34c8b30e5d42a0d4459fb24e44ecef46af39893984bf9613001e925a7b1308b7"",; > ""NameHash"": ""b503f6a369add974e996e5f42942882b50c2bf1419400420255d32a88fb61a18"",; > ""SeqHash512"": ""4b94376c390dd8e917d39dfbaed1092d9a661dbdb67635863f9a14b129948f1244929faf60f5b7c1d6fae142d87fb2c66455f49d0d3663f7498b275efad4ed93"",; > ""NameHash512"": ""46c31c9178b3290b2f57e9b682ea8eebe885ba9037e48cb6b385a0c70ce13e2b259400bc9bda4aca912c3b857edde7de41d11b1a7b9ccbe8b24df77808c22e59"",; > ""DecoySeqHash"": ""e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855"",; > ""DecoyNameHash"": ""e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855"",; > ""num_decoys"": 0,; > ""first_decoy_index"": 18446744073709551607,; > ""keep_duplicates"": false; > }. And the command I used:. `/home/bayegy/pipelines/metagenome/softwares/salmon-latest_linux_x86_64/bin/salmon quant --validateMappings -i /media/bayegy/disk1/Projects/qianquan-zhangke/result/Assembly_out//salmon_index -l A -p 90 --meta -1 /media/bayegy/disk1/Projects/qianquan-zhangke/result/kneaddata_out//YGSC11_R1_kneaddata_paired_1.fastq.gz -2 /media/bayegy/disk1/Projects/qianquan-zhangke/result/kneaddata_out//YGSC11_R1_kneaddata_paired_2.fastq.gz -o /media/bayegy/disk1/Projects/qianquan-zhangke/result/salmon_out//YGSC11.quant`. Sometimes, salmon would stay at the step of ""Starting optimizer"" for hours(10 hours at least). The CPU utilization is 100%, but the procedure never move forward. > [2020-06-04 12:06:12.254] [jointLog] [info] Mapping rate = 91.8009%; > ; > [2020-06-04 12:06:12.254] [jointLog] [info] finished quantifyLibrary(); > [2020-06-04 12:06:12.254] [jointLog] [info] Starting optimizer. The funny thing is that salmon would pass this step in no time if I restart the procedure with same command. It is annoying that I have to check the log time to time to restart salmon when it get blocked. I wonder what is the possible reason for this and how can i stop this from happening again. . Many thanks.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/532:2294,log,log,2294,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/532,1,['log'],['log']
Testability,"es where the data come from and how I invoked salmon. * Which read files were used?. See above. * Which which program options were used?. I used the bash script from ; https://combine-lab.github.io/salmon/getting_started/. **Expected behavior**. I expected an output indicating successful quantification. **Screenshots**. I couldn't figure out how to insert a picture, but here is the text from ""terminal"" window.; `(salmon) MacBook-Pro-2:salmon-tutorial brent$ bash quant_tut_samples.sh; Processing sample DRR016125; Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; ### salmon (mapping-based) v0.11.3; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { athal_index }; ### [ libType ] => { A }; ### [ mates1 ] => { data/DRR016125/DRR016125_1.fastq.gz }; ### [ mates2 ] => { data/DRR016125/DRR016125_2.fastq.gz }; ### [ threads ] => { 8 }; ### [ output ] => { quants/DRR016125_quant }; Logs will be written to quants/DRR016125_quant/logs; [2018-11-24 15:08:09.785] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2018-11-24 15:08:09.785] [jointLog] [info] parsing read library format; [2018-11-24 15:08:09.785] [jointLog] [info] There is 1 library.; [2018-11-24 15:08:09.877] [jointLog] [info] Loading Quasi index; [2018-11-24 15:08:09.877] [jointLog] [info] Loading 32-bit quasi index; [2018-11-24 15:08:09.877] [stderrLog] [info] Loading Suffix Array ; [2018-11-24 15:08:10.319] [stderrLog] [info] Loading Transcript Info ; [2018-11-24 15:08:10.423] [stderrLog] [info] Loading Rank-Select Bit Array; [2018-11-24 15:08:10.432] [stderrLog] [info] There were 40,812 set bits in the bit array; [2018-11-24 15:08:10.435] [stderrLog] [info] Computing transcript lengths; [2018-11-24 15:08:10.435] [stderrLog] [info] Waiting to finish loading hash. quant_tut_samples.sh: line 2: 914 Segmentation fault: 11 salmon quant -i athal_i",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/317:1648,Log,Logs,1648,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/317,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"es. Those jobs are still running (it's only been about 4hrs as of this writing, I'll update my post if/when they complete). Current logs are showing that they quickly consume all the available memory, but have not yet crashed. I've also got versions with 128-512GB of memory requested (by powers of 2) for comparison. Some random notes: both the 31-mer index experienced about twice as many soft page reclaims with the new/faster version and experienced a few hard page faults (the previous version saw none of the latter). The 17-mer version experienced fewer page reclaims than any of the 31-mer indices and far fewer than with the prior version. Again, a few page faults crept in, but relatively few by percentage and likely not contributing any significant amount of time overall. [index-qacct-17mer.log](https://github.com/COMBINE-lab/salmon/files/4246516/index-qacct-17mer.log); [index-qacct-31mer.log](https://github.com/COMBINE-lab/salmon/files/4246517/index-qacct-31mer.log). **UPDATE**; The 16GB version finished running. It actually only took a little over 4 hours to run, as well. The troubling thing about this job seems to be that, despite having successfully completed, according to the accounting log it used over 20GB of memory... which should be impossible to do. Our resident experts suspect there's a race condition occurring at the tail end of the job and that all of that extra memory is being allocated before the scheduler can kill it for exceeding the limit. Whatever the case, though, this throws into question some of those numbers that I've been grabbing from the accounting logs --- it's either being misreported, or the memory gobbling is happening so rapidly that it may not, in fact, be being properly recorded. I tested the index anyway. It *appears* to be working just fine. Nothing faulted or crashed when I attempted to quantify some reads against it. [index-qacct-17mer-16gigs.log](https://github.com/COMBINE-lab/salmon/files/4247214/index-qacct-17mer-16gigs.log)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-590516702:2022,log,log,2022,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-590516702,5,"['log', 'test']","['log', 'logs', 'tested']"
Testability,"essImpl<cereal::NameValuePair<bool&>, (this=0x00007fffffff4990, t=0x00007fffffff44f8)0>(cereal::NameValuePair<bool&> const&) at cereal.hpp:505:9; frame #10: 0x00000000004e0e49 salmon`void cereal::OutputArchive<cereal::JSONOutputArchive, 0u>::process<cereal::NameValuePair<bool&> >(this=0x00007fffffff4990, head=0x00007fffffff44f8) at cereal.hpp:417:15; frame #11: 0x0000000000483895 salmon`cereal::JSONOutputArchive& cereal::OutputArchive<cereal::JSONOutputArchive, 0u>::operator(this=0x00007fffffff4990, args=0x00007fffffff44f8)<cereal::NameValuePair<bool&> >(cereal::NameValuePair<bool&>&&) at cereal.hpp:311:15; frame #12: 0x0000000000569d2b salmon`fixFasta(parser=0x00000008018dd000, decoyNames=0x00007fffffff66c8, keepDuplicates=false, k=31, sepStr="" \t"", expect_transcriptome=true, iomutex=0x00007fffffff5f80, log=<unavailable>, outFile=<unavailable>, refIdExtensions=size=40811, shortRefs=size=1) at FixFasta.cpp:456:5; frame #13: 0x000000000056d58f salmon`fixFastaMain(args=size=7, refIdExtension=size=40811, shortRefs=size=1, log=<unavailable>, hasFeatures=false) at FixFasta.cpp:684:16 ; frame #14: 0x0000000000471f33 salmon`pufferfishIndex(indexOpts=0x00007fffffffdcd8) at PufferfishIndexer.cpp:429:17; frame #15: 0x0000000000983a5c salmon`salmonIndex(int, char const**, std::__1::unique_ptr<SalmonIndex, std::__1::default_delete<SalmonIndex> >&) [inlined] SalmonIndex::buildPuffIndex_(this=<unavailable>, indexDir=(m_pathname = ""athal_index""), idxOpt=<unavailable>) at SalmonIndex.hpp:111:15; frame #16: 0x0000000000983a32 salmon`salmonIndex(int, char const**, std::__1::unique_ptr<SalmonIndex, std::__1::default_delete<SalmonIndex> >&) [inlined] SalmonIndex::build(this=<unavailable>, indexDir=(m_pathname = ""athal_index""), idxOpt=<unavailable>) at SalmonIndex.hpp:76; frame #17: 0x00000000009839c3 salmon`salmonIndex(argc=<unavailable>, argv=<unavailable>, (null)=<unavailable>) at BuildSalmonIndex.cpp:236; frame #18: 0x000000000097a673 salmon`main [inlined] std::__1::__function::__val",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/725:4858,log,log,4858,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/725,1,['log'],['log']
Testability,"essor; Department of Biochemistry and Molecular Biology, Howard Building Room 205, Mail Stop 330; University of Nevada, Reno; Reno, NV 89557; (775) 784-4204; cramer@unr.edu<mailto:cramer@unr.edu>; http://www.ag.unr.edu/cramer/. On Mar 22, 2018, at 6:21 PM, Rob Patro <notifications@github.com<mailto:notifications@github.com>> wrote:. Hi @grantcramer<https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fgrantcramer&data=01%7C01%7Ccramer%40unr.edu%7C54d34feceb114e30a61b08d5905c7a7b%7C523b4bfc0ebd4c03b2b96f6a17fd31d8%7C1&sdata=w1ED%2B5ZBUY6Z8fTiIs62IZJizv0HcvVzw8CtfEdK32E%3D&reserved=0>,. I was able to successfully index and map against the fasta file you link above (on linux). I was also able to index and map against the index on OSX, using the salmon from bioconda (v 0.9.1). So, I'm not yet able to reproduce this. It seems the file you uploaded for your pre-built index is no longer available, so I couldn't try that out. I'd be happy to give it a try if you can put it up on dropbox or some such. Otherwise, I wonder if there could be some sort of binary compatibility issue. Did you build the index on the same machine you're quantifying on? The OSX I tested on is 10.13.1. Best,; Rob. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2FCOMBINE-lab%2Fsalmon%2Fissues%2F209%23issuecomment-375509050&data=01%7C01%7Ccramer%40unr.edu%7C54d34feceb114e30a61b08d5905c7a7b%7C523b4bfc0ebd4c03b2b96f6a17fd31d8%7C1&sdata=5XDT2ix1q1Uz%2B3kTchI%2B5K9Hzu7UuGkyQAz8KB9ko4o%3D&reserved=0>, or mute the thread<https://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscribe-auth%2FAj0RizznzcCphH-HJ9Q8uXvndQ4Lsg9Oks5thE43gaJpZM4Sw28q&data=01%7C01%7Ccramer%40unr.edu%7C54d34feceb114e30a61b08d5905c7a7b%7C523b4bfc0ebd4c03b2b96f6a17fd31d8%7C1&sdata=7DLxrFx74WqeN71%2Bs5cfSxEA1NRxj%2F7uqvp9SrGgjck%3D&reserved=0>.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/209#issuecomment-375513800:1574,test,tested,1574,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/209#issuecomment-375513800,1,['test'],['tested']
Testability,"ext+0x475): undefined reference to `nghttp2_version'; /usr/bin/ld: /usr/lib/x86_64-linux-gnu/libcurl.a(libcurl_gnutls_la-libssh2.o): in function `ssh_attach':; (.text+0x3e1): undefined reference to `libssh2_session_abstract'; /usr/bin/ld: /usr/lib/x86_64-linux-gnu/libcurl.a(libcurl_gnutls_la-libssh2.o): in function `ssh_statemach_act':; (.text+0x4b1): undefined reference to `libssh2_session_set_blocking'; /usr/bin/ld: (.text+0x4fb): undefined reference to `libssh2_session_handshake'; /usr/bin/ld: (.text+0x58d): undefined reference to `libssh2_hostkey_hash'; /usr/bin/ld: (.text+0x6a0): undefined reference to `libssh2_hostkey_hash'; /usr/bin/ld: (.text+0x75d): undefined reference to `libssh2_knownhost_free'; ... So somehow this does not build - but I have the impression that the linker issues are caused by some missing CMAKE options (as well as using the build directory). Thus I used the cmake command line as its used in the Debian packaging:. $ docker pull debian:testing; $ docker run -it debian:testing; $ echo ""deb-src http://deb.debian.org/debian unstable main"" > /etc/apt/sources.list.d/10-debsrc.list; $ apt update; $ apt upgrade; $ apt build-dep salmon; $ wget https://github.com/COMBINE-lab/salmon/archive/refs/tags/v1.10.0.tar.gz; $ tar xaf v1.10.0.tar.gz; $ cd salmon-1.10.0; $ cmake -DCMAKE_BUILD_TYPE=Release -DUSE_SHARED_LIBS=TRUE -DBZIP2_LIBRARIES=-lbz2 -DBZIP2_INCLUDE_DIR=/usr/include -DLIBLZMA_INCLUDE_DIR=/usr/include/ -DLIBLZMA_LIBRARY=lzma -DCMAKE_MODULE_PATH=/usr/share/cmake/Modules -DTBB_WILL_RECONFIGURE=FALSE -DBOOST_WILL_RECONFIGURE=FALSE; $ make; $ tar xaf sample_data.tgz; # src/salmon index -t sample_data/transcripts.fasta -i sample_salmon_quasi_index; Version Info: This is the most recent version of salmon.; index [""sample_salmon_quasi_index""] did not previously exist . . . creating it; [2023-03-10 11:56:01.434] [jLog] [warning] The salmon index is being built without any decoy sequences. It is recommended that decoy sequence (either computed auxiliar",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463708855:3125,test,testing,3125,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463708855,2,['test'],['testing']
Testability,"f range-factorized equivalence classes does not make sense in conjunction with --hardFilter. Disabling range-factorized equivalence classes.; [2021-04-09 12:16:37.619] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.; [2021-04-09 12:16:37.619] [jointLog] [info] Using default value of 0.87 for minScoreFraction in Alevin; Using default value of 0.6 for consensusSlack in Alevin; [2021-04-09 12:16:37.649] [alevinLog] [info] Found 45374 transcripts(+1 decoys, +0 short and +0 duplicate names in the index); [2021-04-09 12:16:37.702] [alevinLog] [info] Filled with 45374 txp to gene entries; ### alevin (dscRNA-seq quantification) v1.4.0; ### [ program ] => salmon; ### [ command ] => alevin; ### [ libType ] => { ISR }; ### [ index ] => { results/salmon/index/GRCh38.p13 }; ### [ mates1 ] => { /Users/james/GitHub/scrnaseq/.tests/fastq/S1_L001_R1_001.fastq.gz /Users/james/GitHub/scrnaseq/.tests/fastq/S1_L002_R1_001.fastq.gz /Users/james/GitHub/scrnaseq/.tests/fastq/S1_L003_R1_001.fastq.gz /Users/james/GitHub/scrnaseq/.tests/fastq/S1_L004_R1_001.fastq.gz }; ### [ mates2 ] => { /Users/james/GitHub/scrnaseq/.tests/fastq/S1_L001_R2_001.fastq.gz /Users/james/GitHub/scrnaseq/.tests/fastq/S1_L002_R2_001.fastq.gz /Users/james/GitHub/scrnaseq/.tests/fastq/S1_L003_R2_001.fastq.gz /Users/james/GitHub/scrnaseq/.tests/fastq/S1_L004_R2_001.fastq.gz }; ### [ output ] => { results/salmon/alevin/S1 }; ### [ threads ] => { 1 }; ### [ tgMap ] => { results/eisar/GRCh38.p13/GRCh38.p13.tx2gene.tsv }; ### [ chromiumV3 ] => { }; ### [ mrna ] => { results/gffread/GRCh38.p13/GRCh38.p13.mrna.txt }; ### [ rrna ] => { results/gffread/GRCh38.p13/GRCh38.p13.rrna.txt }. [2021-04-09 12:16:37.708] [alevinLog] [info] Found all transcripts to gene mappings; [2021-04-09 12:16:37.722] [alevinLog] [info] Processing barcodes files (if Present). [2021-04-09 12:16:37.728] [alevinLog] [info] Done barcode density calculation.; [2021-04-09 12:16:37.728] [alevinLog] [info] # Barcodes Used: 400",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/647:1888,test,tests,1888,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/647,1,['test'],['tests']
Testability,"fasta file, I get the following output and error message:. Version Info: This is the most recent version of salmon.; # salmon (alignment-based) v1.4.0; # [ program ] => salmon; # [ command ] => quant; # [ targets ] => { all_transcripts.fa }; # [ libType ] => { A }; # [ threads ] => { 10 }; # [ alignments ] => { /groups/inah/test_Salmon/4010760_5_mono_S58_L001_R1_001.fastq_AT_QT.fastq.gz.STAR_aligned.toTranscriptome.bam /groups/inah/test_Sal; mon/4010760_5_mono_S58_L002_R1_001.fastq_AT_QT.fastq.gz.STAR_aligned.toTranscriptome.bam /groups/inah/test_Salmon/4010760_5_mono_S58_L003_R1_001.fastq_AT; _QT.fastq.gz.STAR_aligned.toTranscriptome.bam /groups/inah/test_Salmon/4010760_5_mono_S58_L004_R1_001.fastq_AT_QT.fastq.gz.STAR_aligned.toTranscriptome.b; am }; # [ output ] => { 4010760_5_mono_S58_R1_001.fastq_AT_QT.fastq.gz.STAR_aligned.toTranscriptome.bam.salmon_quant }; Logs will be written to 4010760_5_mono_S58_R1_001.fastq_AT_QT.fastq.gz.STAR_aligned.toTranscriptome.bam.salmon_quant/logs; [2021-03-05 18:20:21.015] [jointLog] [info] setting maxHashResizeThreads to 10; [2021-03-05 18:20:21.015] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; Library format { type:paired end, relative orientation:inward, strandedness:unstranded }; parseThreads = 5; [2021-03-05 18:20:21.314] [jointLog] [info] numQuantThreads = 5; Checking that provided alignment files have consistent headers . . . done; Populating targets from aln = ""/groups/inah/test_Salmon/4010760_5_mono_S58_L001_R1_001.fastq_AT_QT.fastq.gz.STAR_aligned.toTranscriptome.bam"", fasta = ""a; ll_transcripts.fa"" . . .done; [2021-03-05 18:20:24.846] [jointLog] [info] replaced 1216 non-ACGT nucleotides with random nucleotides; processed 0 reads in current round[2021-03-05 18:20:25.180] [jointLog] [info] Automatically detected most likely library type as ISR; processed 3000000 reads in current round[2021-03-05 18:20:39.705] [jointLog] [info]; The alignment group queue pool h",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/638:1490,log,logs,1490,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/638,1,['log'],['logs']
Testability,"fferent RNAseq experiments). So to make it quick I am only passing two transcripts to Salmon (T - 1, and T - 2) for version 1 and 2 of the transcript, where version 2 has the 2nd exon (of 4 total exons) removed. . Now I know Salmon was created to map reads to a large number of transcripts across the whole genome, but I believe it still should be possible to narrow down the view to only 1 gene with 2 versions. I believe I just need to set the parameters right, but I also want to set the parameters in a general way so that my script can work across different species with different input RNAseq data. The other problem is that we currently do not have an idea of what proportion of these two versions of the gene should actually exist in the RNAseq data I have (which we didn't perform but just grabbed a random sample from GenBank to test with). My adviser wants to first try and test it computationally first and then verify it in the lab (which is somewhat backwards in my mind, as it's really just a shot in the dark and from my preliminary analysis of Salmon, different parameters can drastically change the proportions of the two versions). . As you can see below, I have tried some parameter settings that I thought would be helpful (particularly ```--quasiCoverage```). But again I could be wrong and would like to know your opinions in the matter. . These runs were all performed with this 'default' run: ; ```; salmon quant -i index -l A -1 reads_1.fq -2 reads_2.fq --validateMappings -p 20 --numPreAuxModelSamples 250 --numAuxModelSamples 1000 -o output ; ```; I changes the ```AuxModelSamples``` to low values as I was generally only mapping 6000 reads to the two transcripts in total, so I didn't think they were working at the default settings. Below is also a small chart of some of my runs (which included quasi-mapping and selective-alignment), but what you can get is that there is a large variance between parameters. Particularly ```--seqBias``` showed a dramatic drop in pred",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/401:1815,test,test,1815,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/401,1,['test'],['test']
Testability,"g reference sequence | Time = 2.4349 s; -----------------------------------------; -----------------------------------------; | Loading reference accumulative lengths | Time = 5.1367 ms; -----------------------------------------; [2021-09-20 16:31:04.631] [jointLog] [info] done; [2021-09-20 16:31:04.632] [jointLog] [info] Index contained 116,612 targets; Killed. ```. However, if I run it only with --validateMappings, it works fine and generates the output quant.sf file. ```; $ salmon quant -l A -i /mnt/hgfs/Data/reference_data/mm10/default -r /mnt/hgfs/Data/raw_data/S01_S1_R1_001.fastq.gz -o out -p 6 --validateMappings; Version Server Response: Not Found; ### salmon (selective-alignment-based) v1.5.2; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ libType ] => { A }; ### [ index ] => { /mnt/hgfs/Data/reference_data/mm10/default }; ### [ unmatedReads ] => { /mnt/hgfs/Data/raw_data/S01_S1_R1_001.fastq.gz }; ### [ output ] => { out }; ### [ threads ] => { 6 }; ### [ validateMappings ] => { }; Logs will be written to out/logs; [2021-09-20 16:20:48.240] [jointLog] [info] setting maxHashResizeThreads to 6; [2021-09-20 16:20:48.240] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2021-09-20 16:20:48.240] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2021-09-20 16:20:48.240] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.; [2021-09-20 16:20:48.240] [jointLog] [info] parsing read library format; [2021-09-20 16:20:48.240] [jointLog] [info] There is 1 library.; [2021-09-20 16:20:48.328] [jointLog] [info] Loading pufferfish index; [2021-09-20 16:20:48.331] [jointLog] [info] Loading dense pufferfish index.; -----------------------------------------; | Loading contig table | Time = 22.244 s; -----------------------------------------; size = 24942314; ------------------------------------",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/708:3697,Log,Logs,3697,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/708,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"g] [info] Computing transcript lengths; [2017-08-02 14:41:38.676] [stderrLog] [info] Waiting to finish loading hash; [2017-08-02 14:41:42.951] [stderrLog] [info] Done loading index. [2017-08-02 14:41:42.951] [jointLog] [info] done; [2017-08-02 14:41:42.951] [jointLog] [info] Index contained 51378 targets. [2017-08-02 14:41:46.428] [jointLog] [info] Computed 10524 rich equivalence classes for further processing; [2017-08-02 14:41:46.428] [jointLog] [info] Counted 98301 total reads in the equivalence classes; [2017-08-02 14:41:46.432] [jointLog] [warning] Only 98301 fragments were mapped, but the number of burn-in fragments was set to 5000000.; The effective lengths have been computed using the observed mappings. [2017-08-02 14:41:46.432] [jointLog] [info] Mapping rate = 42.6252%. [2017-08-02 14:41:46.432] [jointLog] [info] finished quantifyLibrary(); [2017-08-02 14:41:46.446] [jointLog] [info] Starting optimizer; [2017-08-02 14:41:46.508] [jointLog] [info] Marked 0 weighted equivalence classes as degenerate; [2017-08-02 14:41:46.510] [jointLog] [info] iteration = 0 | max rel diff. = 2.50175; [2017-08-02 14:41:46.521] [jointLog] [info] iteration 11, adjusting effective lengths to account for biases; salmon: /drone/src/github.com/COMBINE-lab/salmon/include/eigen3/Eigen/src/Core/DenseCoeffsBase.h:378: Eigen::DenseCoeffsBase<Derived, 1>::Scalar& Eigen::DenseCoeffsBase<Derived, 1>::operator[](Eigen::DenseCoeffsBase<Derived, 1>::Index) [with Derived = Eigen::Matrix<double, -1, 1>; Eigen::DenseCoeffsBase<Derived, 1>::Scalar = double; Eigen::DenseCoeffsBase<Derived, 1>::Index = long int]: Assertion `index >= 0 && index < size()' failed.; /home/ngs/scripts/sc-rna/sc-s-salmon-quant.sh: line 40: 10170 Aborted (core dumped) /home/ngs/programs/salmon/Salmon-0.8.2_linux_x86_64/bin/salmon quant -i ""$path_dr_salmonindex_transcriptome_ercc"" -o ""$newfilename-salmon-quant"" -g ""$path_dr_gtf"" -l ""U"" -p 1 --fldMax 50 --fldMean 43 --seqBias --numBootstraps 10 -r <(zcat $1). ```; </details>",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/144:3104,Assert,Assertion,3104,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/144,1,['Assert'],['Assertion']
Testability,"gcBias --seqBias --rangeFactorizationBins 4 --output salmon.out; Version Info: This is the most recent version of salmon.; ### salmon (selective-alignment-based) v1.4.0; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { sel.align.gencode.v35.ucsc.rmsk.salmon.v1.3.0.sidx }; ### [ libType ] => { A }; ### [ mates1 ] => { /cromwell_root/fc-secure-519db2bc-049f-43a0-ab75-a2eb9c2cb059/6a6c9b92-3026-47d3-8944-60f0842c566e/samToFastqTest/5f578d2f-7e74-4402-955a-4d4623b83ead/call-samToFastq/GTEX-111CU-0526-SM-5EGHK.2.fastq.gz }; ### [ mates2 ] => { /cromwell_root/fc-secure-519db2bc-049f-43a0-ab75-a2eb9c2cb059/6a6c9b92-3026-47d3-8944-60f0842c566e/samToFastqTest/5f578d2f-7e74-4402-955a-4d4623b83ead/call-samToFastq/GTEX-111CU-0526-SM-5EGHK.1.fastq.gz }; ### [ threads ] => { 8 }; ### [ recoverOrphans ] => { }; ### [ validateMappings ] => { }; ### [ gcBias ] => { }; ### [ seqBias ] => { }; ### [ rangeFactorizationBins ] => { 4 }; ### [ output ] => { salmon.out }; Logs will be written to salmon.out/logs; [2021-03-29 16:21:11.395] [jointLog] [info] setting maxHashResizeThreads to 8; [2021-03-29 16:21:11.395] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2021-03-29 16:21:11.395] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2021-03-29 16:21:11.395] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.; [2021-03-29 16:21:11.395] [jointLog] [info] parsing read library format; [2021-03-29 16:21:11.399] [jointLog] [info] There is 1 library.; [2021-03-29 16:21:11.496] [jointLog] [info] Loading pufferfish index; [2021-03-29 16:21:11.509] [jointLog] [info] Loading dense pufferfish index.; -----------------------------------------; | Loading contig table | Time = 553.34 s; -----------------------------------------; size = 45242875; -----------------------------------------; | Loading contig",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/641:3249,Log,Logs,3249,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/641,1,['Log'],['Logs']
Testability,"github.io/salmon/getting_started/. This describes where the data come from and how I invoked salmon. Which read files were used?; See above. Which which program options were used?; I used the bash script from; https://combine-lab.github.io/salmon/getting_started/. Expected behavior. I expected an output indicating successful quantification. Screenshots. I couldn't figure out how to insert a picture, but here is the text from ""terminal"" window.; `(salmon) MacBook-Pro-2:salmon-tutorial brent$ bash quant_tut_samples.sh; Processing sample DRR016125; Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon. salmon (mapping-based) v0.11.3; [ program ] => salmon; [ command ] => quant; [ index ] => { athal_index }; [ libType ] => { A }; [ mates1 ] => { data/DRR016125/DRR016125_1.fastq.gz }; [ mates2 ] => { data/DRR016125/DRR016125_2.fastq.gz }; [ threads ] => { 8 }; [ output ] => { quants/DRR016125_quant }; Logs will be written to quants/DRR016125_quant/logs; [2018-11-24 15:08:09.785] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2018-11-24 15:08:09.785] [jointLog] [info] parsing read library format; [2018-11-24 15:08:09.785] [jointLog] [info] There is 1 library.; [2018-11-24 15:08:09.877] [jointLog] [info] Loading Quasi index; [2018-11-24 15:08:09.877] [jointLog] [info] Loading 32-bit quasi index; [2018-11-24 15:08:09.877] [stderrLog] [info] Loading Suffix Array; [2018-11-24 15:08:10.319] [stderrLog] [info] Loading Transcript Info; [2018-11-24 15:08:10.423] [stderrLog] [info] Loading Rank-Select Bit Array; [2018-11-24 15:08:10.432] [stderrLog] [info] There were 40,812 set bits in the bit array; [2018-11-24 15:08:10.435] [stderrLog] [info] Computing transcript lengths; [2018-11-24 15:08:10.435] [stderrLog] [info] Waiting to finish loading hash. quant_tut_samples.sh: line 2: 914 Segmentation fault: 11 salmon quant -i athal_index -",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/318:1654,Log,Logs,1654,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/318,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"gz; Already downloaded: /Users/Benjamin/Library/Caches/Homebrew/downloads/b27a343a5c5128c674be4986b6c0bb348bc77d521662866976898bd4768fd8bb--salmon-1.3.0.tar.gz; ==> Installing salmon from brewsci/bio; ==> cmake .; Last 15 lines from /Users/Benjamin/Library/Logs/Homebrew/salmon/01.cmake:; Build system will fetch and use JEMalloc; ==================================================================; CPACK_SOURCE_IGNORE_FILES = /src/PCA.cpp;/src/PCAUtils.cpp;/build/;/scripts/AggregateToGeneLevel.py;/scripts/ExpressionTools.py;/scripts/GenerateExpressionFiles.sh;/scripts/ParseSoftFile.py;/scripts/PlotCorrelation.py;/scripts/junk;/scripts/sfstrace.log;/scripts/SFPipeline.py;/bin/;/lib/;/sample_data/;PublishREADMEToWebsite.sh;/external/;/src/obsolete/;/include/obsolete/;WebsiteHeader.txt;/experimental_configs/;.git/; CC: /opt/homebrew/Library/Homebrew/shims/mac/super/clang; CC version: ; version: 1.0.0; Building basic pufferfish components for salmon; setting -DHAVE_NUMERIC_LIMITS128; -- Could NOT find PkgConfig (missing: PKG_CONFIG_EXECUTABLE) ; -- Could NOT find Jemalloc (missing: JEMALLOC_LIBRARY JEMALLOC_INCLUDE_DIR) ; NO_IPO = FALSE; TBB_LIBRARIES = /tmp/salmon-20220630-57321-j1f2iv/salmon-1.3.0/external/install/lib/libtbb.dylib;/tmp/salmon-20220630-57321-j1f2iv/salmon-1.3.0/external/install/lib/libtbbmalloc.dylib; -- Configuring incomplete, errors occurred!; See also ""/tmp/salmon-20220630-57321-j1f2iv/salmon-1.3.0/CMakeFiles/CMakeOutput.log"".; See also ""/tmp/salmon-20220630-57321-j1f2iv/salmon-1.3.0/CMakeFiles/CMakeError.log"". Do not report this issue to Homebrew/brew or Homebrew/core!. Benjamin@macbook-pro ~ % salmon ; zsh: exec format error: salmon; Benjamin@macbook-pro ~ % ; ```; I try via bioconda but I got a HTTPerror . and by building from source and I don't understand how to do it from the website . How can I do it on macOS Monterey M1 Max chip ? . thanks a lot for you help in advance . Since it's the v 1.3.0 is it possible to update the brew formula to 1.9.0 ?",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/787:1717,log,log,1717,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/787,2,['log'],['log']
Testability,"h a cryptic error message, maybe you can help me sort this out.; ```; Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; ### salmon (mapping-based) v0.9.1; ### [ program ] => salmon; ### [ command ] => quant; ### [ index ] => { /scratch/AG_Akalin/agosdsc/projects/mrg1_rnaseq/analysis_v2/salmon_index }; ### [ libType ] => { A }; ### [ threads ] => { 8 }; ### [ mates1 ] => { /scratch/AG_Akalin/agosdsc/projects/mrg1_rnaseq/analysis_v2/trimmed_reads/rluc_2_R1.fastq.gz }; ### [ mates2 ] => { /scratch/AG_Akalin/agosdsc/projects/mrg1_rnaseq/analysis_v2/trimmed_reads/rluc_2_R2.fastq.gz }; ### [ output ] => { /scratch/AG_Akalin/agosdsc/projects/mrg1_rnaseq/analysis_v2/salmon_output/rluc_2 }; ### [ seqBias ] => { }; ### [ gcBias ] => { }; ### [ geneMap ] => { /data/akalin/Base/Annotation/ce11/ENSEMBL91/Caenorhabditis_elegans.WBcel235.91.gtf }; Logs will be written to /scratch/AG_Akalin/agosdsc/projects/mrg1_rnaseq/analysis_v2/salmon_output/rluc_2/logs; [2018-03-21 10:00:03.272] [jointLog] [info] parsing read library format; [2018-03-21 10:00:03.272] [jointLog] [info] There is 1 library.; [2018-03-21 10:00:03.517] [stderrLog] [info] Loading Suffix Array; [2018-03-21 10:00:03.501] [jointLog] [info] Loading Quasi index; [2018-03-21 10:00:03.506] [jointLog] [info] Loading 32-bit quasi index; [2018-03-21 10:00:03.846] [stderrLog] [info] Loading Transcript Info; [2018-03-21 10:00:03.980] [stderrLog] [info] Loading Rank-Select Bit Array; [2018-03-21 10:00:03.995] [stderrLog] [info] There were 35448 set bits in the bit array; [2018-03-21 10:00:04.001] [stderrLog] [info] Computing transcript lengths; [2018-03-21 10:00:04.001] [stderrLog] [info] Waiting to finish loading hash; [2018-03-21 10:00:40.560] [stderrLog] [info] Done loading index; [2018-03-21 10:00:40.560] [jointLog] [info] done; [2018-03-21 10:00:40.560] [jointLog] [info] Index contained 35448 targets. terminate called after throwing a",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/210:1035,Log,Logs,1035,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/210,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"h read files were used?; * Illumina HiSeq, trimmed using Trimmomatic ; * Which which program options were used?. Working:. ./salmon/bin/salmon quant -p 64 --index reference/salmon_index -l ISR -1 merged/1791-${id}_1P.fastq.gz -2 merged/1791-${id}_2P.fastq.gz --validateMappings --seqBias --gcBias --posBias --softclip --allowDovetail --numBootstraps 10 -o mapped/salmon_${id}. Working produced the following file structure:. ```; salmon_03; ├── aux_info; │   ├── ambig_info.tsv; │   ├── bootstrap; │   │   ├── bootstraps.gz; │   │   └── names.tsv.gz; │   ├── exp3_pos.gz; │   ├── exp3_seq.gz; │   ├── exp5_pos.gz; │   ├── exp5_seq.gz; │   ├── expected_bias.gz; │   ├── exp_gc.gz; │   ├── fld.gz; │   ├── meta_info.json; │   ├── obs3_pos.gz; │   ├── obs3_seq.gz; │   ├── obs5_pos.gz; │   ├── obs5_seq.gz; │   ├── observed_bias_3p.gz; │   ├── observed_bias.gz; │   └── obs_gc.gz; ├── cmd_info.json; ├── lib_format_counts.json; ├── libParams; │   └── flenDist.txt; ├── logs; │   └── salmon_quant.log; └── quant.sf. 5 directories, 23 files; ```. Not working:. ./salmon/bin/salmon quant -p 64 --index reference/salmon_index -l ISR -1 merged/1791-${id}_1P.fastq.gz -2 merged/1791-${id}_2P.fastq.gz --validateMappings --seqBias --gcBias --posBias --softclip --allowDovetail --recoverOrphans --numBootstraps 10 -o mapped/salmon_${id}. Not working produced the following file structure:. ```; salmon_03_withRecover; ├── aux_info; ├── libParams; └── logs; └── salmon_quant.log. 4 directories, 1 file; ```. The file `mapped/salmon_03_withRecover/logs/salmon_quant.log` has nothing inside it. **Expected behavior**. Properly-mapped reads, as demonstrated by the following metadata:. ```; {; ""salmon_version"": ""1.10.0"",; ""samp_type"": ""bootstrap"",; ""opt_type"": ""vb"",; ""quant_errors"": [],; ""num_libraries"": 1,; ""library_types"": [; ""ISR""; ],; ""frag_dist_length"": 1001,; ""frag_length_mean"": 158.48833607498765,; ""frag_length_sd"": 54.34014977759742,; ""seq_bias_correct"": true,; ""gc_bias_correct"": true,; ""num_bias_bins""",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/929:1966,log,log,1966,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/929,1,['log'],['log']
Testability,"h read, the length of each observed fragment, etc.). That information goes away when the reads are summarized into range-factorized equivalence classes. Moreover, some of the model parameters learned during the online phase will depend (in their details) on the order in which observations are made. Ostensibly, observing the same data in the same order **and issuing updates to shared model parameters from worker threads in the same order** should result in identical values, however this has never been tested and was never a design goal. The reason for this is that differences between runs are within the bounds of the inherent inferential uncertainty of the estimated parameters anyway. That is, if one is relying on a specific value at a level of precision such that a different run of salmon would produce a value different enough to change a downstream analysis, then one is imparting more precision on the estimates than they can provide. Other methods that produce identical results between runs for these values may produce the same output, but the accuracy of the output at that level shouldn't be trusted in this case. The uncertainty of the parameter estimates can be evaluated based on the Gibb samples (or bootstrap replicates) that salmon computes. Of course, the small differences between runs rarely lead to differences in downstream analysis (almost certainly at the gene level and also at the transcript level if you use a differential testing method that is aware of inferential uncertainty). On the other hand, if you are in need of something that produces identical output between runs (but that still also lets you assess uncertainty), then you can give [piscem](https://github.com/COMBINE-lab/piscem) => [piscem-infer](https://github.com/COMBINE-lab/piscem-infer) a try. That tool already works well, but it is in active development and we'd certainly be happy to help build features that you and others might find useful, and would be happy to chat about that if you like.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/102#issuecomment-2159300538:1936,test,testing,1936,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/102#issuecomment-2159300538,2,['test'],['testing']
Testability,ha ... that log isn't particularly interesting --- what happens if you run `./src/unitTests` from the build directory?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393687065:12,log,log,12,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393687065,1,['log'],['log']
Testability,"have a public 10xV2 sample that I am reprocessing ([SRR13313130](https://trace.ncbi.nlm.nih.gov/Traces/sra/?run=SRR13313130)). More specifically, I believe that the sample should be **10X Genomics 5' v1**. I am using the following command:. ```; ID=5309-CT-2; R1=../Reads/5309-CT-2_S01_L005_R1_001.fastq.gz; R2=../Reads/5309-CT-2_S01_L005_R2_001.fastq.gz. TYPE=10xV2; #for MAP, download from UCSC Table Browser, and remove 1st line (and then manually add SARS-COV-2 genes); MAP=/path/to/SARS_COV_2-hg38_RefSeq_2column.txt; REF=/path/to/SARS_COV_2-hg38_salmon; CBWL=/path/to/737K-august-2016.txt. salmon alevin -l ISR --chromium -1 $R1 -2 $R2 -i $REF -p 4 -o $ID --tgMap $MAP --whitelist $CBWL; ```. If I use the V3 barcode list, then I _don't_ get an error message. However, I got more discordant cell counts between CellRanger and STARsolo. The Kallisto cell barcode recovery rate was also low (<10%). So, I thought there error was that different cell barcodes should be used for this sample. I think that matches, what I saw on this FAQ page from 10x Genomics:. https://kb.10xgenomics.com/hc/en-us/articles/115004506263-What-is-a-barcode-whitelist-. So, I downloaded the [737k-august-2016.txt](https://github.com/10XGenomics/cellranger/blob/master/lib/python/cellranger/barcodes/737K-august-2016.txt) file from 10x, and I am testing using that. However, I am now receiving the following error message:. ```; [2021-07-07 17:07:44.192] [alevinLog] [info] Done importing white-list Barcodes; [2021-07-07 17:07:44.192] [alevinLog] [error] Wrong whitelist provided; Please check https://salmon.readthedocs.io/en/develop/alevin.html#whitelist; ```. On the [website linked](https://salmon.readthedocs.io/en/develop/alevin.html#whitelist), I see a note saying ""**Not 10x 724k whitelist**"". However, I apologize that I don't think I understand this note (and the exact file name is different). Should I be doing some differently when running Alevin for this sample?. Thank you very much. Sincerely,; Charles",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/682:1334,test,testing,1334,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/682,1,['test'],['testing']
Testability,"he transcripts. The first used BAM files where shuffled (with samtools bamshuf) as recommended in the docs. To exclude an error on my side I did:; - try unshuffled BAM files --> Segfault; - try older Salmon Version (7.2) --> Segfault; - build Salmon from source --> Segfault; - use different transcriptdata (see below) --> Segfault. The segfault happens after all reads (in all files) are processed:; `processed 48000000 reads in current roundSegmentation fault`. ### Example workflow:. Get the read data from [here](https://trace.ncbi.nlm.nih.gov/Traces/sra/sra.cgi?run=ERR1433122) for example with SRA Toolkit:; `vdb-dump -f fastq --gzip --output-file test.fastq.gz ERR1433122`. Then use STAR:. First build a genome index for the reference transcriptset from [here](https://ics.hutton.ac.uk/atRTD/) and the [TAIR10 genome](https://www.arabidopsis.org/download/index-auto.jsp?dir=%2Fdownload_files%2FGenes%2FTAIR10_genome_release%2FTAIR10_chromosome_files); You probably have to rename the chromosomes either in the .gtf or .fas file, to have consistent names. `STAR --runThreadN 4 --runMode genomeGenerate --genomeDir genome_index/ --genomeFastaFiles TAIR10_chr_all_edited.fas --sjdbGTFfile AtRTD2_19April2016.gtf --sjdbOverhang 100`. Then map:. `STAR --runThreadN 4 --genomeDir genome_index --readFilesCommand zcat --readFilesIn test.fastq.gz --sjdbOverhang 100 --sjdbGTFfile AtRTD2_19April2016.gtf --outFileNamePrefix mapping/ --quantMode TranscriptomeSAM`. and make a .fa file from the genome and the .gtf with:; `gffread -w gff_merged.fa -g TAIR10_chr_all_edited.fas AtRTD2_19April2016.gtf`. Now make a copy of the ""Aligned.toTranscriptome.out.bam"" (for the sake of simplicity) and try; `salmon quant -l A -a Aligned.toTranscriptome.out.bam Aligned.toTranscriptome.out_copy.bam -t gff_merged.fa -o ./out/`. Then the above mentioned segfault happens. The only workaround I found is to merge the BAM files of the replicates with ""samtools merge"". Any idea why the segfault appears?. Cheers,; Tobi",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/145:1553,test,test,1553,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/145,1,['test'],['test']
Testability,"hed to using precompiled binaries, version 0.6.0. Now working on a new server running CentOS Linux release 7.1.1503. I was able to successfully generate my index, then started running the quantification step. Here is my command:. `$ /home/jorvis/salmon/bin/salmon quant -p 24 -i transcripts_index -l IU -1 R1.trimmed.PE.fastq -2 R2.trimmed.PE.fastq -o transcripts_quan`. This host has 48 cores and 128GB RAM. . And here is the STDOUT. ```; Version Info: This is the most recent version of Salmon.; # salmon (mapping-based) v0.6.0; # [ program ] => salmon; # [ command ] => quant; # [ threads ] => { 24 }; # [ index ] => { transcripts_index }; # [ libType ] => { IU }; # [ mates1 ] => { R1.trimmed.PE.fastq }; # [ mates2 ] => { R2.trimmed.PE.fastq }; # [ output ] => { transcripts_quan }; Logs will be written to transcripts_quan/logs; [2016-03-30 15:50:48.489] [jointLog] [info] parsing read library format; there is 1 lib; Loading 64-bit quasi index[2016-03-30 15:50:48.543] [jointLog] [info] Loading Quasi index; [2016-03-30 15:50:48.544] [stderrLog] [info] Loading Suffix Array; [2016-03-30 15:50:48.544] [stderrLog] [info] Loading Position Hash; [2016-03-30 15:50:58.359] [stderrLog] [info] Loading Transcript Info; [2016-03-30 15:50:59.932] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-03-30 15:51:00.610] [stderrLog] [info] There were 2027284 set bits in the bit array; [2016-03-30 15:51:00.917] [stderrLog] [info] Computing transcript lengths; [2016-03-30 15:51:00.925] [stderrLog] [info] Waiting to finish loading hash; Index contained 2027284 targets; [2016-03-30 15:51:08.499] [jointLog] [info] done; [2016-03-30 15:51:08.499] [stderrLog] [info] Done loading index. Segmentation fault; ```. The only log file I see is this one: transcripts_quan/logs/salmon_quant.log. $ cat salmon_quant.log ; [2016-03-30 15:50:48.489] [jointLog] [info] parsing read library format; [2016-03-30 15:50:48.543] [jointLog] [info] Loading Quasi index; [2016-03-30 15:51:08.499] [jointLog] [info] done",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/54:1731,log,log,1731,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/54,4,['log'],"['log', 'logs']"
Testability,"hello! have you by any chance figured it out? I have quite similiar problem. . I am running salmon v.1.1.0 on my ubuntu machine with 128GB of RAM. I set the limit for vitrual memory at ~75GB to not overload the system:. ```bash; ○ → ulimit -a; core file size (blocks, -c) 0; data seg size (kbytes, -d) unlimited; scheduling priority (-e) 0; file size (blocks, -f) unlimited; pending signals (-i) 514510; max locked memory (kbytes, -l) 65536; max memory size (kbytes, -m) unlimited; open files (-n) 1024; pipe size (512 bytes, -p) 8; POSIX message queues (bytes, -q) 819200; real-time priority (-r) 0; stack size (kbytes, -s) 8192; cpu time (seconds, -t) unlimited; max user processes (-u) 514510; virtual memory (kbytes, -v) 75331648; file locks (-x) unlimited; ```. I am building the index with the following command:. ```bash; salmon index \; -t /mnt/rescomp/ref/hg38/gentrome.fa.gz \; -i /mnt/rescomp/ref/hg38/salmon_index -k 31 \; --decoys /mnt/rescomp/ref/hg38/decoys.txt \; --threads 16 \; --gencode |& tee logs/salmon_index.log; ```. gentrome is created based on the gencode transcriptome (v33) and genome primary algnment sequence (GRCh38.p13). [salmon_index.log](https://github.com/COMBINE-lab/salmon/files/4392725/salmon_index.log). The output directory:; ```; ○ → ll /mnt/rescomp/ref/hg38/salmon_index; total 7.9G; drwxr-sr-x 1 37304 723 4.0K Mar 27 01:36 ./; drwxr-sr-x 1 37304 723 4.0K Mar 26 22:13 ../; -rw-r--r-- 1 37304 723 888K Mar 27 00:32 complete_ref_lens.bin; -rw-r--r-- 1 37304 723 31K Mar 27 00:27 duplicate_clusters.tsv; -rw-r--r-- 1 37304 723 674M Mar 27 01:46 path.bin; -rw-r--r-- 1 37304 723 55 Mar 27 01:46 pre_indexing.log; -rw-r--r-- 1 37304 723 40K Mar 27 01:46 ref_indexing.log; -rw-r--r-- 1 37304 723 3.3G Mar 27 00:32 ref_k31_fixed.fa; -rw-r--r-- 1 37304 723 703 Mar 27 00:32 ref_sigs.json; -rw-r--r-- 1 37304 723 4.1G Mar 27 01:36 tmp_dbg.bin; ```; I know for a fact that the memory usage did not go over 16GB. Any hints how to proceed?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/441#issuecomment-604919589:1013,log,logs,1013,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/441#issuecomment-604919589,6,['log'],"['log', 'logs']"
Testability,"hi @jma1991 ,. Thanks for reaching out. You may have already noticed it but may I ask do you expect such a low number of read mapping ? Alevin is logging only 3% of the reads as mapped.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/647#issuecomment-821477730:146,log,logging,146,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/647#issuecomment-821477730,1,['log'],['logging']
Testability,"hi, I am running Salmon-1.2.1 on my MacBook with Sierra 10.13.6. I try to run Salmon binary with terminal, and I get this error. How'd do solve this problem? . Last login: Sat May 2 23:14:08 on ttys007; /Users/maysonlin/Downloads/salmon-1.2.1-h2072146_0\ 2/bin/salmon ; exit;; Maysons-MacBook-Air:~ maysonlin$ /Users/maysonlin/Downloads/salmon-1.2.1-h2072146_0\ 2/bin/salmon ; exit;; dyld: Library not loaded: @rpath/libtbbmalloc.dylib; Referenced from: /Users/maysonlin/Downloads/salmon-1.2.1-h2072146_0 2/bin/salmon; Reason: image not found; Abort trap: 6; logout; Saving session...; ...copying shared history...; ...saving history...truncating history files...; ...completed. [Process completed]",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/517:165,log,login,165,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/517,2,['log'],"['login', 'logout']"
Testability,"his (e.g. testing on clean simulated data),; `--validateMappings` is generally recommended. [2019-07-24 13:33:29.532] [jointLog] [info] parsing read library format; Exception : [Error: The index version file abalone_index/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was invoked improperly.; For usage information, try salmon[2019-07-24 13:33:29.532] [jointLog] [info] There is 1 library.; quant --help; Exiting.; /var/spool/slurmd/job12930414/slurm_script: line 14: --validateMappings: command not found; basename: extra operand ‘lightreceptor-1_S114_L005_R1_001.qc.fq.gz’; Try 'basename --help' for more information.; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { abalone_index }; ### [ libType ] => { A }; ### [ mates1 ] => { .R1_001.qc.fq.gz }; ### [ mates2 ] => { .R2_001.qc.fq.gz }; ### [ output ] => { .quant }; Logs will be written to .quant/logs; [2019-07-24 13:33:29.626] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-07-24 13:33:29.626] [jointLog] [warning] . NOTE: It appears you are running salmon without the `--validateMappings` option.; Mapping validation can generally improve both the sensitivity and specificity of mapping,; with only a moderate increase in use of computational resources. ; Mapping validation is planned to become a default option (i.e. turned on by default) in; the next release of salmon.; Unless there is a specific reason to do this (e.g. testing on clean simulated data),; `--validateMappings` is generally recommended. [2019-07-24 13:33:29.626] [jointLog] [info] parsing read library format; [2019-07-24 13:33:29.626] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file abalone_index/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was inv",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408:5926,Log,Logs,5926,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408,1,['Log'],['Logs']
Testability,"ho ""User: ${USER}""; echo ""Job id: ${JOB_ID}""; echo ""Job name: ${JOB_NAME}""; echo ""Hostname: ${HOSTNAME}""; echo ""Task id: ${TASK_ID}"". FILE1=$(awk 'BEGIN {FS=""\t""} {print $1}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); if [ TRUE == ""TRUE"" ] ; then; FILE2=$(awk 'BEGIN {FS=""\t""} {print $3}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); fi; ID=$(cat /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk '{print $NF}' | awk ""NR==${SGE_TASK_ID}""). mkdir -p /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test4/${ID}. /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant 	-i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts -p 16 -l ISR 	-1 ${FILE1} -2 ${FILE2} 	-o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test4/${ID}. echo ""**** Job ends ****""; date; ```. ### Example log file. ```; **** Job starts ****; Wed Mar 29 14:53:43 EDT 2017; **** JHPCE info ****; User: lcollado; Job id: 110316; Job name: step6-salmon_test4.gsk_phaseII; Hostname: compute-067; Task id: ; Version Info: This is the most recent version of Salmon.; ### salmon (mapping-based) v0.8.2; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts }; ### [ threads ] => { 16 }; ### [ libType ] => { ISR }; ### [ mates1 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX.fastq.gz }; ### [ mates2 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX_read2.fastq.gz }; ### [ output ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test4/R10001_D2B1WACXX }; Logs will be written to /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test4/R10001_D2B1WACXX/logs; [1m[2017-03-29 14:56:39.675] [joi",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965:5177,log,log,5177,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965,1,['log'],['log']
Testability,https://travis-ci.org/Homebrew/homebrew-science/jobs/114404533#L1110-L1115. ```; /bin/sh ../libtool --tag=CC --mode=compile /usr/local/Library/ENV/4.3/clang -DHAVE_CONFIG_H -I. -I.. -I.. -I/usr/local/include -L/usr/local/lib -MT libstaden_read_la-cram_io.lo -MD -MP -MF .deps/libstaden_read_la-cram_io.Tpo -c -o libstaden_read_la-cram_io.lo `test -f 'cram_io.c' || echo './'`cram_io.c; libtool: compile: /usr/local/Library/ENV/4.3/clang -DHAVE_CONFIG_H -I. -I.. -I.. -I/usr/local/include -L/usr/local/lib -MT libstaden_read_la-cram_io.lo -MD -MP -MF .deps/libstaden_read_la-cram_io.Tpo -c cram_io.c -o libstaden_read_la-cram_io.o; cram_io.c:66:10: fatal error: 'lzma.h' file not found; #include <lzma.h>; ^; 1 error generated.; make[5]: *** [libstaden_read_la-cram_io.lo] Error 1; make[4]: *** [all-recursive] Error 1; make[3]: *** [all] Error 2; make[2]: *** [libstadenio-prefix/src/libstadenio-stamp/libstadenio-build] Error 2; make[1]: *** [CMakeFiles/libstadenio.dir/all] Error 2; make: *** [all] Error 2; ```,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/45:342,test,test,342,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/45,1,['test'],['test']
Testability,"ily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant -i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts -p 16 -l ISR -1 ${FILE1} -2 ${FILE2} -o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test4/${ID}; **** Job ends ****; Wed Mar 29 14:58:05 EDT 2017. ```. ### SGE email example info. ```; Job-array task 110316.1 (step6-salmon_test4.gsk_phaseII) Complete; User = lcollado; Queue = shared.q@compute-067.cm.cluster; Host = compute-067.cm.cluster; Start Time = 03/29/2017 14:53:42; End Time = 03/29/2017 14:58:05; User Time = 00:00:00; System Time = 00:05:39; Wallclock Time = 00:04:23; CPU = 00:05:39; Max vmem = 24.202G; Exit Status = 0; ```. Note that in this case, it didn't read the maximum memory requested (16 * 3 = 48 GB). ## Large memory, p 1. ### Bash. ```bash; #!/bin/bash; #$ -cwd; #$ -l mem_free=80G,h_vmem=90G,h_fsize=100G; #$ -N step6-salmon_test5.gsk_phaseII; #$ -pe local 1; #$ -o ./logs/salmon_test5.$TASK_ID.txt; #$ -e ./logs/salmon_test5.$TASK_ID.txt; #$ -t 1-3; #$ -hold_jid pipeline_setup,step4-featCounts-alzheimer.gsk_phaseII; #$ -m e; echo ""**** Job starts ****""; date. echo ""**** JHPCE info ****""; echo ""User: ${USER}""; echo ""Job id: ${JOB_ID}""; echo ""Job name: ${JOB_NAME}""; echo ""Hostname: ${HOSTNAME}""; echo ""Task id: ${TASK_ID}"". FILE1=$(awk 'BEGIN {FS=""\t""} {print $1}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); if [ TRUE == ""TRUE"" ] ; then; FILE2=$(awk 'BEGIN {FS=""\t""} {print $3}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); fi; ID=$(cat /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk '{print $NF}' | awk ""NR==${SGE_TASK_ID}""). mkdir -p /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test5/${ID}. /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant 	-i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965:7456,log,logs,7456,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965,1,['log'],['logs']
Testability,"immed.PE.fastq IL100038709.R2.trimmed.PE.fastq IL100044635.R2.trimmed.PE.fastq IL100054706.R2.trimmed.PE.fastq IL100062514.R2.trimmed.PE.fastq --validateMappings -p 12 --output salmon_out`. But here's the output:. ```; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon; ### [ command ] => quant; ### [ index ] => { transcripts_index }; ### [ libType ] => { IU }; ### [ mates1 ] => { IL100038432.R1.trimmed.PE.fastq IL100038433.R1.trimmed.PE.fastq IL100038708.R1.trimmed.PE.fastq IL100038709.R1.trimmed.PE.fastq IL100044635.R1.trimmed.PE.fastq IL100054706.R1.trimmed.PE.fastq IL100062514.R1.trimmed.PE.fastq }; ### [ mates2 ] => { IL100038432.R2.trimmed.PE.fastq IL100038433.R2.trimmed.PE.fastq IL100038708.R2.trimmed.PE.fastq IL100038709.R2.trimmed.PE.fastq IL100044635.R2.trimmed.PE.fastq IL100054706.R2.trimmed.PE.fastq IL100062514.R2.trimmed.PE.fastq }; ### [ validateMappings ] => { }; ### [ threads ] => { 12 }; ### [ output ] => { salmon_out }; Logs will be written to salmon_out/logs; [2019-08-27 11:44:12.350] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-08-27 11:44:12.350] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2019-08-27 11:44:12.350] [jointLog] [info] Usage of --validateMappings, without --hardFilter implies use of range factorization. rangeFactorizationBins is being set to 4; [2019-08-27 11:44:12.350] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.2.; [2019-08-27 11:44:12.350] [jointLog] [info] parsing read library format; [2019-08-27 11:44:12.350] [jointLog] [info] There is 1 library.; [2019-08-27 11:44:12.396] [stderrLog] [info] Loading Suffix Array; [2019-08-27 11:44:12.395] [jointLog] [info] Loading Quasi index; [2019-08-27 11:44:12.395] [jointLog] [info] Loading 32-b",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/426:1859,Log,Logs,1859,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/426,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"ion of salmon with important bug fixes and improvements is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; Sign up for the salmon mailing list to hear about new versions, features and updates at:; https://oceangenomics.com/subscribe; ### salmon (selective-alignment-based) v1.9.0; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { references/salmon/sel.align.gencode.v39.ucsc.rmsk.salmon.v1.9.0.sidx/ }; ### [ libType ] => { A }; ### [ mates1 ] => { SRR14506785_output_forward_paired.fq.gz }; ### [ mates2 ] => { SRR14506785_output_reverse_paired.fq.gz }; ### [ threads ] => { 8 }; ### [ validateMappings ] => { }; ### [ gcBias ] => { }; ### [ seqBias ] => { }; ### [ recoverOrphans ] => { }; ### [ rangeFactorizationBins ] => { 4 }; ### [ output ] => { SRR14506785.salmon.rmsk.out }; ### [ writeUnmappedNames ] => { }; Logs will be written to SRR14506785.salmon.rmsk.out/logs; [2023-09-28 04:51:02.450] [jointLog] [info] setting maxHashResizeThreads to 8; [2023-09-28 04:51:02.450] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2023-09-28 04:51:02.450] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2023-09-28 04:51:02.450] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.; [2023-09-28 04:51:02.450] [jointLog] [info] parsing read library format; [2023-09-28 04:51:02.450] [jointLog] [info] There is 1 library.; [2023-09-28 04:51:02.450] [jointLog] [info] Loading pufferfish index; [2023-09-28 04:51:02.451] [jointLog] [info] Loading dense pufferfish index.; -----------------------------------------; | Loading contig table | Time = 31.648 s; -----------------------------------------; size = 45110164; ---------------------------",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/876:2204,Log,Logs,2204,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/876,1,['Log'],['Logs']
Testability,"ion"": ""1.1.0"",; ""index"": ""results/salmon/index"",; ""libType"": ""A"",; ""mates1"": ""results/trimmed/ILWN_RNAseq_G002_ATCACG_Arachis_hypogaea_I801_L1_R1_val_1.fq.gz"",; ""mates2"": ""results/trimmed/ILWN_RNAseq_G002_ATCACG_Arachis_hypogaea_I801_L1_R2_val_2.fq.gz"",; ""output"": ""results/salmon/quant/ILWN_RNAseq_G002_ATCACG_Arachis_hypogaea_I801_L1_salmon_quant"",; """": ""results/salmon/quant/ILWN_RNAseq_G002_ATCACG_Arachis_hypogaea_I801_L1_salmon_quant/ILWN_RNAseq_G002_ATCACG_Arachis_hypogaea_I801_L1_salmon_mappings"",; ""validateMappings"": [],; ""gcBias"": [],; ""seqBias"": [],; ""writeUnmappedNames"": [],; ""writeMappings"": ""results/salmon/quant/ILWN_RNAseq_G002_ATCACG_Arachis_hypogaea_I801_L1_salmon_quant/ILWN_RNAseq_G002_ATCACG_Arachis_hypogaea_I801_L1_salmon_mappings"",; ""threads"": ""20"",; ""numBootstraps"": ""100"",; ""auxDir"": ""aux_info""; }; ```. </p>; </details>. <details><summary>Salmon run w/ quasi mapping method</summary>; <p>. ```python; rule salmon_index_test:; input:; tcp = TRANSCRIPTS; output:; directory(""results/salmon_test/index""); priority:1; log:; ""results/salmon_test/logs/index.log""; conda:; ""../envs/salmon.yaml""; threads:30; shell:; """"""; salmon index -p {threads} -t {input.tcp} -i {output}; """""". rule salmon_quant_test:; input:; r1=""results/trimmed/{smp}_R1_val_1.fq.gz"",; r2=""results/trimmed/{smp}_R2_val_2.fq.gz"",; index = ""results/salmon_test/index""; output:; directory(""results/salmon_test/quant/{smp}_salmon_test_quant""),; log:; ""results/salmon_test/logs/{smp}.salmon_test.log""; conda:; ""../envs/salmon.yaml""; threads:30; shell:; """"""; salmon quant -i {input.index} -l A -1 {input.r1} -2 {input.r2} -o {output} --validateMappings --gcBias --seqBias --writeUnmappedNames -p {threads} --numBootstraps 100; """"""; ```. </p>; </details>. <details><summary>Mapping rates w/ quasi mapping method</summary>; <p>. ![image](https://user-images.githubusercontent.com/42179487/73189014-b8350580-40f1-11ea-8f6a-9d7d39867a89.png). </p>; </details>. <details><summary>cmd_info.json (quasi)</summary>; <p>. ",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/479:3487,log,log,3487,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/479,2,['log'],"['log', 'logs']"
Testability,"ionBins 4 --output salmon.out; Version Info: This is the most recent version of salmon.; ### salmon (selective-alignment-based) v1.4.0; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { sel.align.gencode.v35.ucsc.rmsk.salmon.v1.3.0.sidx }; ### [ libType ] => { A }; ### [ mates1 ] => { /cromwell_root/fc-secure-519db2bc-049f-43a0-ab75-a2eb9c2cb059/6a6c9b92-3026-47d3-8944-60f0842c566e/samToFastqTest/5f578d2f-7e74-4402-955a-4d4623b83ead/call-samToFastq/GTEX-111CU-0526-SM-5EGHK.2.fastq.gz }; ### [ mates2 ] => { /cromwell_root/fc-secure-519db2bc-049f-43a0-ab75-a2eb9c2cb059/6a6c9b92-3026-47d3-8944-60f0842c566e/samToFastqTest/5f578d2f-7e74-4402-955a-4d4623b83ead/call-samToFastq/GTEX-111CU-0526-SM-5EGHK.1.fastq.gz }; ### [ threads ] => { 8 }; ### [ recoverOrphans ] => { }; ### [ validateMappings ] => { }; ### [ gcBias ] => { }; ### [ seqBias ] => { }; ### [ rangeFactorizationBins ] => { 4 }; ### [ output ] => { salmon.out }; Logs will be written to salmon.out/logs; [2021-03-29 16:21:11.395] [jointLog] [info] setting maxHashResizeThreads to 8; [2021-03-29 16:21:11.395] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2021-03-29 16:21:11.395] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2021-03-29 16:21:11.395] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.; [2021-03-29 16:21:11.395] [jointLog] [info] parsing read library format; [2021-03-29 16:21:11.399] [jointLog] [info] There is 1 library.; [2021-03-29 16:21:11.496] [jointLog] [info] Loading pufferfish index; [2021-03-29 16:21:11.509] [jointLog] [info] Loading dense pufferfish index.; -----------------------------------------; | Loading contig table | Time = 553.34 s; -----------------------------------------; size = 45242875; -----------------------------------------; | Loading contig offsets | Time = 14.76 s; --------",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/641:3284,log,logs,3284,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/641,1,['log'],['logs']
Testability,"ipQuant`; **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem.; Terminal output when `--skipQuant` is on:; ```; Version Info: ### PLEASE UPGRADE SALMON ###; ### A newer version of salmon with important bug fixes and improvements is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; Sign up for the salmon mailing list to hear about new versions, features and updates at:; https://oceangenomics.com/subscribe; ### salmon (selective-alignment-based) v1.9.0; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /share/genomes/human/hg38/gencode_v43/primary_comprehensive/SalmonIndex }; ### [ skipQuant ] => { }; ### [ libType ] => { A }; ### [ mates1 ] => { GSM7099349.R1.fastq }; ### [ mates2 ] => { GSM7099349.R2.fastq }; ### [ output ] => { salmon_out }; ### [ threads ] => { 1 }; Logs will be written to salmon_out/logs; [2023-11-30 09:40:21.543] [jointLog] [info] setting maxHashResizeThreads to 1; [2023-11-30 09:40:21.543] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2023-11-30 09:40:21.543] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2023-11-30 09:40:21.543] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.; [2023-11-30 09:40:21.543] [jointLog] [info] parsing read library format; [2023-11-30 09:40:21.543] [jointLog] [info] There is 1 library.; [2023-11-30 09:40:21.544] [jointLog] [info] Loading pufferfish index; [2023-11-30 09:40:21.545] [jointLog] [info] Loading dense pufferfish index.; -----------------------------------------; | Loading contig table | Time = 17.538 s; -----------------------------------------; size = 37303070; -----------------------------------------; |",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/902:2363,Log,Logs,2363,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/902,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"iple loci |	1.20%; Number of reads mapped to too many loci |	565; % of reads mapped to too many loci |	0.00%; UNMAPPED READS:; Number of reads unmapped: too many mismatches |	0; % of reads unmapped: too many mismatches |	0.00%; Number of reads unmapped: too short |	47533174; % of reads unmapped: too short |	55.56%; Number of reads unmapped: other |	4006; % of reads unmapped: other |	0.00%; CHIMERIC READS:; Number of chimeric reads |	0; % of chimeric reads |	0.00%. ```. I filtered it by samtools -f 2 -F 3840 . and Salmon gave me this result which is still very weak: 24323638 counts. So I decided to reduce the parameters as indicated in this link: https://github.com/alexdobin/STAR/issues/169; Because I trimmed my sequence and some can have a size between 100pb -150pb. ` ""STAR --runThreadN {threads} --runMode alignReads --genomeDir {input.ref} --readFilesIn {input.fq1} {input.fq2} --readFilesCommand zcat --outSAMtype BAM Unsorted SortedByCoordinate --outFilterScoreMinOverLread 0 --outFilterMatchNminOverLread 0 --quantMode TranscriptomeSAM GeneCounts --outFileNamePrefix {output} --outStd Log {log} ""`. I got this final.out:; ```; Started job on |	Jul 05 14:25:19; Started mapping on |	Jul 05 14:25:23; Finished on |	Jul 05 16:37:44; Mapping speed, Million of reads per hour |	38.78. Number of input reads |	85547657; Average input read length |	298; UNIQUE READS:; Uniquely mapped reads number |	70090369; Uniquely mapped reads % |	81.93%; Average mapped length |	191.51; Number of splices: Total |	1068826; Number of splices: Annotated (sjdb) |	0; Number of splices: GT/AG |	470490; Number of splices: GC/AG |	43525; Number of splices: AT/AC |	15865; Number of splices: Non-canonical |	538946; Mismatch rate per base, % |	1.29%; Deletion rate per base |	0.03%; Deletion average length |	4.76; Insertion rate per base |	0.03%; Insertion average length |	5.23; MULTI-MAPPING READS:; Number of reads mapped to multiple loci |	15205492; % of reads mapped to multiple loci |	17.77%; Number o",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/676#issuecomment-874540664:2363,Log,Log,2363,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/676#issuecomment-874540664,3,"['Log', 'log']","['Log', 'log']"
Testability,"is (e.g. testing on clean simulated data),; `--validateMappings` is generally recommended. [2019-07-24 13:33:29.347] [jointLog] [info] parsing read library format; [2019-07-24 13:33:29.347] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file abalone_index/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting.; /var/spool/slurmd/job12930414/slurm_script: line 14: --validateMappings: command not found; basename: extra operand ‘lightreceptor-1_S114_L005_R1_001.qc.fq.gz’; Try 'basename --help' for more information.; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { abalone_index }; ### [ libType ] => { A }; ### [ mates1 ] => { .R1_001.qc.fq.gz }; ### [ mates2 ] => { .R2_001.qc.fq.gz }; ### [ output ] => { .quant }; Logs will be written to .quant/logs; [2019-07-24 13:33:29.441] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-07-24 13:33:29.441] [jointLog] [warning] . NOTE: It appears you are running salmon without the `--validateMappings` option.; Mapping validation can generally improve both the sensitivity and specificity of mapping,; with only a moderate increase in use of computational resources. ; Mapping validation is planned to become a default option (i.e. turned on by default) in; the next release of salmon.; Unless there is a specific reason to do this (e.g. testing on clean simulated data),; `--validateMappings` is generally recommended. [2019-07-24 13:33:29.441] [jointLog] [info] parsing read library format; [2019-07-24 13:33:29.441] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file abalone_index/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was inv",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408:2705,Log,Logs,2705,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408,1,['Log'],['Logs']
Testability,"is (e.g. testing on clean simulated data),; `--validateMappings` is generally recommended. [2019-07-24 13:33:29.441] [jointLog] [info] parsing read library format; [2019-07-24 13:33:29.441] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file abalone_index/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting.; /var/spool/slurmd/job12930414/slurm_script: line 14: --validateMappings: command not found; basename: extra operand ‘lightreceptor-1_S114_L005_R1_001.qc.fq.gz’; Try 'basename --help' for more information.; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { abalone_index }; ### [ libType ] => { A }; ### [ mates1 ] => { .R1_001.qc.fq.gz }; ### [ mates2 ] => { .R2_001.qc.fq.gz }; ### [ output ] => { .quant }; Logs will be written to .quant/logs; [2019-07-24 13:33:29.532] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-07-24 13:33:29.532] [jointLog] [warning] . NOTE: It appears you are running salmon without the `--validateMappings` option.; Mapping validation can generally improve both the sensitivity and specificity of mapping,; with only a moderate increase in use of computational resources. ; Mapping validation is planned to become a default option (i.e. turned on by default) in; the next release of salmon.; Unless there is a specific reason to do this (e.g. testing on clean simulated data),; `--validateMappings` is generally recommended. [2019-07-24 13:33:29.532] [jointLog] [info] parsing read library format; Exception : [Error: The index version file abalone_index/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was invoked improperly.; For usage information, try salmon[2019-07-24 13",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408:4316,Log,Logs,4316,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408,1,['Log'],['Logs']
Testability,"is (e.g. testing on clean simulated data),; `--validateMappings` is generally recommended. [2019-07-24 13:33:29.626] [jointLog] [info] parsing read library format; [2019-07-24 13:33:29.626] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file abalone_index/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting.; /var/spool/slurmd/job12930414/slurm_script: line 14: --validateMappings: command not found; basename: extra operand ‘lightreceptor-1_S114_L005_R1_001.qc.fq.gz’; Try 'basename --help' for more information.; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { abalone_index }; ### [ libType ] => { A }; ### [ mates1 ] => { .R1_001.qc.fq.gz }; ### [ mates2 ] => { .R2_001.qc.fq.gz }; ### [ output ] => { .quant }; Logs will be written to .quant/logs; [2019-07-24 13:33:29.720] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-07-24 13:33:29.720] [jointLog] [warning] . NOTE: It appears you are running salmon without the `--validateMappings` option.; Mapping validation can generally improve both the sensitivity and specificity of mapping,; with only a moderate increase in use of computational resources. ; Mapping validation is planned to become a default option (i.e. turned on by default) in; the next release of salmon.; Unless there is a specific reason to do this (e.g. testing on clean simulated data),; `--validateMappings` is generally recommended. [2019-07-24 13:33:29.720] [jointLog] [info] parsing read library format; [2019-07-24 13:33:29.720] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file abalone_index/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was inv",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408:7537,Log,Logs,7537,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408,1,['Log'],['Logs']
Testability,"is (e.g. testing on clean simulated data),; `--validateMappings` is generally recommended. [2019-07-24 13:33:29.720] [jointLog] [info] parsing read library format; [2019-07-24 13:33:29.720] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file abalone_index/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting.; /var/spool/slurmd/job12930414/slurm_script: line 14: --validateMappings: command not found; basename: extra operand ‘lightreceptor-1_S114_L005_R1_001.qc.fq.gz’; Try 'basename --help' for more information.; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { abalone_index }; ### [ libType ] => { A }; ### [ mates1 ] => { .R1_001.qc.fq.gz }; ### [ mates2 ] => { .R2_001.qc.fq.gz }; ### [ output ] => { .quant }; Logs will be written to .quant/logs; [2019-07-24 13:33:29.808] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-07-24 13:33:29.808] [jointLog] [warning] . NOTE: It appears you are running salmon without the `--validateMappings` option.; Mapping validation can generally improve both the sensitivity and specificity of mapping,; with only a moderate increase in use of computational resources. ; Mapping validation is planned to become a default option (i.e. turned on by default) in; the next release of salmon.; Unless there is a specific reason to do this (e.g. testing on clean simulated data),; `--validateMappings` is generally recommended. [2019-07-24 13:33:29.808] [jointLog] [info] parsing read library format; [2019-07-24 13:33:29.808] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file abalone_index/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was inv",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408:9148,Log,Logs,9148,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408,1,['Log'],['Logs']
Testability,"is (e.g. testing on clean simulated data),; `--validateMappings` is generally recommended. [2019-07-24 13:33:29.808] [jointLog] [info] parsing read library format; [2019-07-24 13:33:29.808] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file abalone_index/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting.; /var/spool/slurmd/job12930414/slurm_script: line 14: --validateMappings: command not found; basename: extra operand ‘lightreceptor-1_S114_L005_R1_001.qc.fq.gz’; Try 'basename --help' for more information.; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { abalone_index }; ### [ libType ] => { A }; ### [ mates1 ] => { .R1_001.qc.fq.gz }; ### [ mates2 ] => { .R2_001.qc.fq.gz }; ### [ output ] => { .quant }; Logs will be written to .quant/logs; [2019-07-24 13:33:29.899] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-07-24 13:33:29.899] [jointLog] [warning] . NOTE: It appears you are running salmon without the `--validateMappings` option.; Mapping validation can generally improve both the sensitivity and specificity of mapping,; with only a moderate increase in use of computational resources. ; Mapping validation is planned to become a default option (i.e. turned on by default) in; the next release of salmon.; Unless there is a specific reason to do this (e.g. testing on clean simulated data),; `--validateMappings` is generally recommended. [2019-07-24 13:33:29.899] [jointLog] [info] parsing read library format; [2019-07-24 13:33:29.899] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file abalone_index/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was inv",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408:10759,Log,Logs,10759,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408,1,['Log'],['Logs']
Testability,"is (e.g. testing on clean simulated data),; `--validateMappings` is generally recommended. [2019-07-24 13:33:29.899] [jointLog] [info] parsing read library format; [2019-07-24 13:33:29.899] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file abalone_index/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting.; /var/spool/slurmd/job12930414/slurm_script: line 14: --validateMappings: command not found; basename: extra operand ‘lightreceptor-1_S114_L005_R1_001.qc.fq.gz’; Try 'basename --help' for more information.; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { abalone_index }; ### [ libType ] => { A }; ### [ mates1 ] => { .R1_001.qc.fq.gz }; ### [ mates2 ] => { .R2_001.qc.fq.gz }; ### [ output ] => { .quant }; Logs will be written to .quant/logs; [2019-07-24 13:33:29.990] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-07-24 13:33:29.990] [jointLog] [warning] . NOTE: It appears you are running salmon without the `--validateMappings` option.; Mapping validation can generally improve both the sensitivity and specificity of mapping,; with only a moderate increase in use of computational resources. ; Mapping validation is planned to become a default option (i.e. turned on by default) in; the next release of salmon.; Unless there is a specific reason to do this (e.g. testing on clean simulated data),; `--validateMappings` is generally recommended. [2019-07-24 13:33:29.990] [jointLog] [info] parsing read library format; [2019-07-24 13:33:29.990] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file abalone_index/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was inv",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408:12370,Log,Logs,12370,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408,1,['Log'],['Logs']
Testability,"is (e.g. testing on clean simulated data),; `--validateMappings` is generally recommended. [2019-07-24 13:33:29.990] [jointLog] [info] parsing read library format; [2019-07-24 13:33:29.990] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file abalone_index/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting.; /var/spool/slurmd/job12930414/slurm_script: line 14: --validateMappings: command not found; basename: extra operand ‘lightreceptor-1_S114_L005_R1_001.qc.fq.gz’; Try 'basename --help' for more information.; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { abalone_index }; ### [ libType ] => { A }; ### [ mates1 ] => { .R1_001.qc.fq.gz }; ### [ mates2 ] => { .R2_001.qc.fq.gz }; ### [ output ] => { .quant }; Logs will be written to .quant/logs; [2019-07-24 13:33:30.080] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; Exception : [Error: The index version file abalone_index/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting.; [2019-07-24 13:33:30.080] [jointLog] [warning] . NOTE: It appears you are running salmon without the `--validateMappings` option.; Mapping validation can generally improve both the sensitivity and specificity of mapping,; with only a moderate increase in use of computational resources. ; Mapping validation is planned to become a default option (i.e. turned on by default) in; the next release of salmon.; Unless there is a specific reason to do this (e.g. testing on clean simulated data),; `--validateMappings` is generally recommended. [2019-07-24 13:33:30.080] [jointLog] [info] parsing read libra",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408:13981,Log,Logs,13981,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408,1,['Log'],['Logs']
Testability,"is (e.g. testing on clean simulated data),; `--validateMappings` is generally recommended. [2019-07-24 13:33:30.175] [jointLog] [info] parsing read library format; [2019-07-24 13:33:30.175] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file abalone_index/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting.; /var/spool/slurmd/job12930414/slurm_script: line 14: --validateMappings: command not found; basename: extra operand ‘lightreceptor-1_S114_L005_R1_001.qc.fq.gz’; Try 'basename --help' for more information.; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { abalone_index }; ### [ libType ] => { A }; ### [ mates1 ] => { .R1_001.qc.fq.gz }; ### [ mates2 ] => { .R2_001.qc.fq.gz }; ### [ output ] => { .quant }; Logs will be written to .quant/logs; [2019-07-24 13:33:30.269] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-07-24 13:33:30.269] [jointLog] [warning] . NOTE: It appears you are running salmon without the `--validateMappings` option.; Mapping validation can generally improve both the sensitivity and specificity of mapping,; with only a moderate increase in use of computational resources. ; Mapping validation is planned to become a default option (i.e. turned on by default) in; the next release of salmon.; Unless there is a specific reason to do this (e.g. testing on clean simulated data),; `--validateMappings` is generally recommended. Exception : [Error: The index version file abalone_index/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting.; [2019-07-24 13:33:30.269] [jointLog] [info] parsing read libra",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408:17203,Log,Logs,17203,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408,1,['Log'],['Logs']
Testability,"isabling range-factorized equivalence classes. ; [2021-05-19 18:46:25.303] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.; [2021-05-19 18:46:25.303] [jointLog] [info] parsing read library format; [2021-05-19 18:46:25.303] [jointLog] [info] There is 1 library.; [2021-05-19 18:46:25.429] [jointLog] [info] Loading pufferfish index; [2021-05-19 18:46:25.429] [jointLog] [info] Loading dense pufferfish index.; [2021-05-19 18:46:27.087] [jointLog] [info] done; [2021-05-19 18:46:27.087] [jointLog] [info] Index contained 141,069 targets; [2021-05-19 18:46:32.618] [jointLog] [info] Number of decoys : 0; [2021-05-19 18:46:33.428] [jointLog] [info] Automatically detected most likely library type as IU. [2021-05-19 18:49:27.444] [jointLog] [error] . [2021-05-19 18:49:27.506] [jointLog] [error] Processing reads : Error reading from the FASTA/Q stream. Minimum return code for left and right read was (-2). Make sure the file is valid. ```; For rabbitQC's log; ```; Detecting adapter sequence for read1...; CCCAGCCATAACACAGTATCAAACTCCACTATTTGTCTGATCCGTACTTATTACAGCCGT. Detecting adapter sequence for read2...; CCAACTTGGTCTACAAGACGCCACATCCCCTATTATAGAAGAGCTAATAAATTTCCATGA. Read1 before filtering:; total reads: 44178187; total bases: 2140649565; Q20 bases: 1899503304(88.7349%); Q30 bases: 1839878933(85.9496%). Read1 after filtering:; total reads: 34172299; total bases: 1775386278; Q20 bases: 1762557969(99.2774%); Q30 bases: 1737891531(97.8881%). Read2 before filtering:; total reads: 44178187; total bases: 2233386484; Q20 bases: 2180294210(97.6228%); Q30 bases: 2141791820(95.8988%). Read2 aftering filtering:; total reads: 34172299; total bases: 1749324083; Q20 bases: 1731172028(98.9623%); Q30 bases: 1700577336(97.2134%). Filtering result:; reads passed filter: 68344598; reads failed due to low quality: 11353966; reads failed due to too many N: 40048; reads failed due to too short: 8617762; reads with adapter trimmed: 382600; bases trimmed due to adapters: 6",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/660:2487,log,log,2487,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/660,1,['log'],['log']
Testability,"itional alignment algorithms like Bowtie2 and BWA-MEM with respect to both sensitivity and specificity. Here, you are likely seeing a manifestation of the former. Specifically, greedy behavior can lead to spurious matches. Many of these spurious matches are filtered out when applying a consensus mechanism to the series of matches produced by a read; however, this can result in the read going unmapped. We have noticed this behavior where spurious matches can ""mask"" better overall mappings, and we have developed an algorithm to overcome these limitations (called selective-alignment). This is currently implemented in [this branch](https://github.com/COMBINE-lab/salmon/tree/rescue-orphan) of the Salmon repo (if you want to test it out and have trouble building, we can build you a linux executable). This algorithm explores more potential mappings and then applies a fast algorithm for filtering potentially poor ones. In our benchmarks, it exhibits sensitivity and specificity very close to Bowtie2 (which is among the best of the alignment-based methods we considered). Also, I will note that, though the speed and statistical optimization procedures used in fast transcript abundance estimation tools make them a potentially desirable choice for microbiomic / metagenomic abundance estimation, their indices are typically optimized for speed and not size. For small numbers of bacterial species this can be okay, but if one wishes to index large collections of species, the memory usage can become a problem. To this end, we have developed a new indexing scheme (software [here](https://github.com/COMBINE-lab/pufferfish), slightly out-of-date pre-print [here](https://www.biorxiv.org/content/early/2017/09/21/191874)). That code already implements a tool for taxonomic read assignment (a la the excellent [Kraken](https://github.com/DerrickWood/kraken)), but not yet abundance estimation (that is coming soon). So, depending on how much you want to scale up, you might want to keep an eye on",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/196#issuecomment-365337297:1244,benchmark,benchmarks,1244,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/196#issuecomment-365337297,1,['benchmark'],['benchmarks']
Testability,"jobnumber 9958683; taskid 3; account sge; priority 0; qsub_time Mon Mar 6 23:18:58 2017; start_time Mon Mar 6 23:19:12 2017; end_time Tue Mar 7 17:27:45 2017; granted_pe local; slots 1; failed 0; exit_status 0; ru_wallclock 65313; ru_utime 25600.565; ru_stime 29552.966; ru_maxrss 6548296; ru_ixrss 0; ru_ismrss 0; ru_idrss 0; ru_isrss 0; ru_minflt 1662027; ru_majflt 369; ru_nswap 0; ru_inblock 0; ru_oublock 56256; ru_msgsnd 0; ru_msgrcv 0; ru_nsignals 0; ru_nvcsw 801190; ru_nivcsw 2880329; cpu 55153.531; mem 403295.295; io 17.447; iow 0.000; maxvmem 9.065G; arid undefined; ```. For task 1 the maxvmem was 9.072G and for task 2 9.061G. I then ran a test requesting a minimum of 10 GB of free RAM and a max of 11 GB, which in theory should work unless `salmon` uses variable amounts of memory with the same data. ```bash; #!/bin/bash; #$ -cwd; #$ -l mem_free=10G,h_vmem=11G,h_fsize=100G; #$ -N step6-salmon_test.gsk_phaseII; #$ -pe local 1; #$ -o ./logs/salmon_test.$TASK_ID.txt; #$ -e ./logs/salmon_test.$TASK_ID.txt; #$ -m a; echo ""**** Job starts ****""; date. echo ""**** JHPCE info ****""; echo ""User: ${USER}""; echo ""Job id: ${JOB_ID}""; echo ""Job name: ${JOB_NAME}""; echo ""Hostname: ${HOSTNAME}""; echo ""Task id: ${TASK_ID}"". FILE1=$(awk 'BEGIN {FS=""\t""} {print $1}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); FILE2=$(awk 'BEGIN {FS=""\t""} {print $3}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); ID=$(cat /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk '{print $NF}' | awk ""NR==${SGE_TASK_ID}""). mkdir -p /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test/${ID}. /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.7.2_linux_x86_64/bin/salmon quant 	-i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/GENCODE/GRCh38_hg38/transcripts/salmon_index_gencode.v25.transcripts -p 1 -l ISR 	-1 ${FILE1} -2 ${FILE2} 	-o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg3",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126:21419,log,logs,21419,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126,1,['log'],['logs']
Testability,"k_phaseII; #$ -m e; echo ""**** Job starts ****""; date. echo ""**** JHPCE info ****""; echo ""User: ${USER}""; echo ""Job id: ${JOB_ID}""; echo ""Job name: ${JOB_NAME}""; echo ""Hostname: ${HOSTNAME}""; echo ""Task id: ${TASK_ID}"". FILE1=$(awk 'BEGIN {FS=""\t""} {print $1}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); if [ TRUE == ""TRUE"" ] ; then; FILE2=$(awk 'BEGIN {FS=""\t""} {print $3}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); fi; ID=$(cat /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk '{print $NF}' | awk ""NR==${SGE_TASK_ID}""). mkdir -p /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/${ID}. strace /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant 	-i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts -p 1 -l ISR 	-1 ${FILE1} -2 ${FILE2} 	-o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/${ID} 2> logs/strace_${SGE_TASK_ID}.txt. echo ""**** Job ends ****""; date; ```. This requests SGE 2 cores with a total free memory of 2 * 7 = 14 GB and a maximum memory of 16 GB. This is the `strace` output for task 1:. ```; execve(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", [""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""quant"", ""-i"", ""/dcl01/lieber/ajaffe/Emily/RNAse""..., ""-p"", ""1"", ""-l"", ""ISR"", ""-1"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-2"", ""/dcl01/lieber/ajaffe/lab/libd_al""..., ""-o"", ""/dcl01/lieber/ajaffe/lab/libd_al""...], [/* 107 vars */]) = 0; brk(0) = 0xc2c000; mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbfffd000; readlink(""/proc/self/exe"", ""/dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon"", 4096) = 88; access(""/etc/ld.so.preload"", R_OK) = -1 ENOENT (No such file or directory); open(""/dcl01/lieber/ajaffe/Emily/RNAseq-pipel",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:3629,log,logs,3629,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['log'],['logs']
Testability,"l -c bioconda salmon; Arabidopsis Thaliana reference genome was used - TAIR10_chr_all.fas - from here: https://www.arabidopsis.org/download/index-auto.jsp?dir=%2Fdownload_files%2FGenes%2FTAIR10_genome_release%2FTAIR10_chromosome_files. 3.; Alignment was done using STAR. 4.; See command below for options used. 5.; Linux login01 3.10.0-1160.el7.x86_64 #1 SMP Mon Oct 19 16:18:59 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux. 6. Output, for success case, one file only. ```; salmon quant -t /rsstu/users/c/cjdohert/NSF_Tomato/AT_RefGenomeFiles/TAIR10_chr_all.fas -l A -a leaf_mock_t6_rep3_S64_R1_001Aligned.out.bam -o salmonquant; Version Info: This is the most recent version of salmon.; # salmon (alignment-based) v1.9.0; # [ program ] => salmon ; # [ command ] => quant ; # [ targets ] => { /rsstu/users/c/cjdohert/NSF_Tomato/AT_RefGenomeFiles/TAIR10_chr_all.fas }; # [ libType ] => { A }; # [ alignments ] => { leaf_mock_t6_rep3_S64_R1_001Aligned.out.bam }; # [ output ] => { salmonquant }; Logs will be written to salmonquant/logs; [2023-01-29 16:02:11.267] [jointLog] [info] setting maxHashResizeThreads to 8; [2023-01-29 16:02:11.267] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; Library format { type:single end, relative orientation:none, strandedness:unstranded }; [2023-01-29 16:02:11.308] [jointLog] [info] numQuantThreads = 4; parseThreads = 4; Checking that provided alignment files have consistent headers . . . done; Populating targets from aln = ""leaf_mock_t6_rep3_S64_R1_001Aligned.out.bam"", fasta = ""/rsstu/users/c/cjdohert/NSF_Tomato/AT_RefGenomeFiles/TAIR10_chr_all.fas"" . . .done. processed 0 reads in current round[2023-01-29 16:02:12.216] [jointLog] [info] replaced 186,207 non-ACGT nucleotides with random nucleotides; [2023-01-29 16:02:12.668] [jointLog] [info] Automatically detected most likely library type as U. processed 2000000 reads in current round[2023-01-29 16:02:13.116] [jointLog] [info] . The alignment gro",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/825:1753,Log,Logs,1753,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/825,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"lane-003-chunk-003.fastq.gz; ./fastqs/flowcell1/read-I1_si-CGAAGTTG_lane-004-chunk-002.fastq.gz; ./fastqs/flowcell1/read-I1_si-GAGCACGC_lane-001-chunk-001.fastq.gz; ./fastqs/flowcell1/read-I1_si-GAGCACGC_lane-002-chunk-000.fastq.gz; ./fastqs/flowcell1/read-I1_si-GAGCACGC_lane-003-chunk-003.fastq.gz; ./fastqs/flowcell1/read-I1_si-GAGCACGC_lane-004-chunk-002.fastq.gz; ./fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-001-chunk-001.fastq.gz; ./fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-002-chunk-000.fastq.gz; ./fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-003-chunk-003.fastq.gz; ./fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-004-chunk-002.fastq.gz]; Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; [2018-12-05 15:10:07.252] [alevinLog] [info] A custom protocol (END, BC length, UMI length) = (5, 14, 5) is being used. Updating UMI k-mer length accordingly.; Logs will be written to ./fastq/test/logs; ### alevin (dscRNA-seq quantification) v0.11.3; ### [ program ] => salmon ; ### [ command ] => alevin ; ### [ libType ] => { ISR }; ### [ gemcode ] => { }; ### [ index ] => { ../transcripts_index_salmon/ }; ### [ threads ] => { 8 }; ### [ output ] => { ./fastq/test/ }; ### [ tgMap ] => { ../hg_transcriptome/tx2tx.tsv }; ### [ end ] => { 5 }; ### [ umiLength ] => { 5 }; ### [ barcodeLength ] => { 14 }; ### [ dumpCsvCounts ] => { }; ### [ dumpFeatures ] => { }; ### [ mates1 ] => { /tmp/tmp.lLLibfwH4G/p1.fa }; ### [ mates2 ] => { /tmp/tmp.lLLibfwH4G/p2.fa }; ### [ unmatedReads ] => { ./fastqs/flowcell1/read-I1_si-ACTTCACT_lane-001-chunk-001.fastq.gz ./fastqs/flowcell1/read-I1_si-ACTTCACT_lane-002-chunk-000.fastq.gz ./fastqs/flowcell1/read-I1_si-ACTTCACT_lane-003-chunk-003.fastq.gz ./fastqs/flowcell1/read-I1_si-ACTTCACT_lane-004-chunk-002.fastq.gz ./fastqs/flowcell1/read-I1_si-CGAAGTTG_lane-001-chunk-001.fastq.gz ./fastqs/flowcell1/read-I1_si-CGAAGTTG_lane-002-chunk-000.fastq.gz ./fastqs/flowcell1/rea",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/328:3755,test,test,3755,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/328,2,"['log', 'test']","['logs', 'test']"
Testability,"le. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; Sign up for the salmon mailing list to hear about new versions, features and updates at:; https://oceangenomics.com/subscribe; ### salmon (selective-alignment-based) v1.9.0; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { references/salmon/sel.align.gencode.v39.ucsc.rmsk.salmon.v1.9.0.sidx/ }; ### [ libType ] => { A }; ### [ mates1 ] => { SRR14506785_output_forward_paired.fq.gz }; ### [ mates2 ] => { SRR14506785_output_reverse_paired.fq.gz }; ### [ threads ] => { 8 }; ### [ validateMappings ] => { }; ### [ gcBias ] => { }; ### [ seqBias ] => { }; ### [ recoverOrphans ] => { }; ### [ rangeFactorizationBins ] => { 4 }; ### [ output ] => { SRR14506785.salmon.rmsk.out }; ### [ writeUnmappedNames ] => { }; Logs will be written to SRR14506785.salmon.rmsk.out/logs; [2023-09-28 04:51:02.450] [jointLog] [info] setting maxHashResizeThreads to 8; [2023-09-28 04:51:02.450] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2023-09-28 04:51:02.450] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2023-09-28 04:51:02.450] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.; [2023-09-28 04:51:02.450] [jointLog] [info] parsing read library format; [2023-09-28 04:51:02.450] [jointLog] [info] There is 1 library.; [2023-09-28 04:51:02.450] [jointLog] [info] Loading pufferfish index; [2023-09-28 04:51:02.451] [jointLog] [info] Loading dense pufferfish index.; -----------------------------------------; | Loading contig table | Time = 31.648 s; -----------------------------------------; size = 45110164; -----------------------------------------; | Loading contig offsets | Time = 96.211 ms; ------",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/876:2256,log,logs,2256,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/876,1,['log'],['logs']
Testability,"lib/libtbbmalloc.so.2; -- Installing: /salmon-0.10.2/lib/libtbb.so.2; -- Installing: /salmon-0.10.2/lib/pkgconfig; -- Installing: /salmon-0.10.2/lib/libtbbmalloc_proxy.so.2; -- Installing: /salmon-0.10.2/bin/salmon; -- Installing: /salmon-0.10.2/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly.; ==========================================================================; Please add /salmon-0.10.2/bin to your PATH; Please add /salmon-0.10.2/lib to your LD_LIBRARY_PATH; ==========================================================================; root@e08cc9670e4a:/salmon-0.10.2/build# make test; Running tests...; Test project /salmon-0.10.2/build; Start 1: unit_tests; 1/3 Test #1: unit_tests ....................... Passed 0.17 sec; Start 2: salmon_read_test_fmd; 2/3 Test #2: salmon_read_test_fmd ............. Passed 1.78 sec; Start 3: salmon_read_test_quasi; 3/3 Test #3: salmon_read_test_quasi ........... Passed 1.59 sec. 100% tests passed, 0 tests failed out of 3. Total Test time (real) = 3.54 sec; root@e08cc9670e4a:/salmon-0.10.2/build# lsb_release -a; LSB Version: core-9.20160110ubuntu0.2-amd64:core-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-amd64:security-9.20160110ubuntu0.2-noarch; Distributor ID: Ubuntu; Description: Ubuntu 16.04.4 LTS; Release: 16.04; Codename: xenial; ```. I built with:. `$ cmake -DFETCH_BOOST=TRUE .. && make install && make test`. I can also install the boost via apt and see if that makes a difference (though I expect not since it looked like TBB was the issue, and I let cmake install that). We can also check our compiler versions, perhaps. I have : . ```; root@e08cc9670e4a:/salmon-0.10.2/build# g++ --version; g++ (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609; Copyright (C) 2015 Free Software Foundation, Inc.; This is free software; see the source for copying conditions. There is NO; warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. root@e08cc9670e4a:/salmon",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268:2207,test,tests,2207,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268,2,['test'],['tests']
Testability,"libthread_db.so.1"".; warning: File ""/u/user/local/lib64/libstdc++.so.6.0.21-gdb.py"" auto-loading has been declined by your `auto-load safe; -path' set to ""$debugdir:$datadir/auto-load"".; To enable execution of this file add; add-auto-load-safe-path /u/user/local/lib64/libstdc++.so.6.0.21-gdb.py; line to your configuration file ""/u/user/.gdbinit"".; To completely disable this security protection add; set auto-load safe-path /; line to your configuration file ""/u/user/.gdbinit"".; For more information about this security protection see the; ""Auto-loading safe path"" section in the GDB manual. E.g., run from the shell:; info ""(gdb)Auto-loading safe path""; [New Thread 0x7fff7dbff700 (LWP 21437)]; [Thread 0x7fff7dbff700 (LWP 21437) exited]; Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; [New Thread 0x7ffefcfff700 (LWP 21653)]; Logs will be written to BM_1/alevin/logs; [New Thread 0x7ffe7cffe700 (LWP 21654)]; [New Thread 0x7ffdfcffd700 (LWP 21655)]; [New Thread 0x7ffd7cffc700 (LWP 21656)]; ### salmon (single-cell-based) v0.10.3; ### [ program ] => salmon; ### [ command ] => alevin; ### [ libType ] => { ISR }; ### [ chromium ] => { }; ### [ threads ] => { 4 }; ### [ output ] => { BM_1/alevin }; ### [ mates1 ] => { ./BM_1/run1/bm_S10_L001_R1_001.fastq.gz }; ### [ mates2 ] => { ./BM_1/run1/bm_S10_L001_R2_001.fastq.gz }; ### [ maxHashResizeThreads ] => { 2 }; ### [ index ] => { /u/user/ref/cellranger/salmon/transcripts_index }; ### [ tgMap ] => { tx2gene.txt }. [2018-06-10 16:07:09.798] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [New Thread 0x7ffcfcffb700 (LWP 21657)]; [Thread 0x7ffcfcffb700 (LWP 21657) exited]; [New Thread 0x7ffc7cffa700 (LWP 21658)]; [New Thread 0x7ffbfcff9700 (LWP 21659)]o[Thread 0x7ffc7cffa700 (LWP 21658) exited]; [Thread 0x7ffbfcff9700 (LWP 21659) exited]; [New Thread 0x7ffb7cff8700 (LWP 21660)]; [Thr",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396078627:2556,Log,Logs,2556,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396078627,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"ligned 0 times; 9748641 (12.88%) aligned exactly 1 time; 54959922 (72.59%) aligned >1 times; 86.42% overall alignment rate; ```. The output of Single-End reads(just read1):; ```{shell}; salmon quant -i assembly_index -l A -r 9998_1.fastq.gz --meta -p 100 -o 9998.quant_se2; Version Info: ### PLEASE UPGRADE SALMON ###; ### A newer version of salmon with bug fixes is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; Sign up for the salmon mailing list to hear about new versions, features and updates at:; https://oceangenomics.com/subscribe; ###; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { assembly_index }; ### [ libType ] => { A }; ### [ unmatedReads ] => { 9998_1.fastq.gz }; ### [ meta ] => { }; ### [ threads ] => { 100 }; ### [ output ] => { 9998.quant_se2 }; Logs will be written to 9998.quant_se2/logs; [2023-03-17 07:40:15.733] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2023-03-17 07:40:15.733] [jointLog] [warning] . NOTE: It appears you are running salmon without the `--validateMappings` option.; Mapping validation can generally improve both the sensitivity and specificity of mapping,; with only a moderate increase in use of computational resources. ; Mapping validation is planned to become a default option (i.e. turned on by default) in; the next release of salmon.; Unless there is a specific reason to do this (e.g. testing on clean simulated data),; `--validateMappings` is generally recommended. [2023-03-17 07:40:15.733] [jointLog] [info] parsing read library format; [2023-03-17 07:40:15.733] [jointLog] [info] There is 1 library.; [2023-03-17 07:40:15.882] [jointLog] [info] Loading Quasi index; [2023-03-17 07:40:15.882] [jointLog] [info] Loading 64-bit quasi index; [2023-03-17 07:",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/838:6602,Log,Logs,6602,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/838,1,['Log'],['Logs']
Testability,"lmon/build-debug/src/salmon alevin -l ISR --chromium -p 1 -o 85948/alevin -1 <(gunzip -c ./85948/run1/85948_S18_L001_R1_001.fastq.gz) -2 <(gunzip -c ./85948/run1/85948_S18_L001_R2_001.fastq.gz) -i ./salmon/transcripts_index --tgMap tx2gene.txt; [Thread debugging using libthread_db enabled]; Using host libthread_db library ""/lib/x86_64-linux-gnu/libthread_db.so.1"".; For more information about this security protection see the; ""Auto-loading safe path"" section in the GDB manual. E.g., run from the shell:; info ""(gdb)Auto-loading safe path""; [New Thread 0x7fff7e0f4700 (LWP 27861)]; [Thread 0x7fff7e0f4700 (LWP 27861) exited]; Version Info: ### A newer version of Salmon is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; [New Thread 0x7fff7d273700 (LWP 27862)]; Logs will be written to 85948/alevin/logs; [New Thread 0x7ffefc3f1700 (LWP 27865)]; [New Thread 0x7ffe7b56f700 (LWP 27866)]; [New Thread 0x7ffdfa6ed700 (LWP 27867)]; ### salmon (single-cell-based) v0.10.1; ### [ program ] => salmon; ### [ command ] => alevin; ### [ libType ] => { ISR }; ### [ chromium ] => { }; ### [ threads ] => { 1 }; ### [ output ] => { 85948/alevin }; ### [ mates1 ] => { /dev/fd/63 }; ### [ mates2 ] => { /dev/fd/62 }; ### [ index ] => { ./salmon/transcripts_index }; ### [ tgMap ] => { tx2gene.txt }. [2018-06-08 11:55:47.378] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [New Thread 0x7ffd797e8700 (LWP 27869)]; [New Thread 0x7ffcf97e7700 (LWP 27870)]; [2018-06-08 11:55:47.387] [alevinLog] [info] Processing barcodes files (if Present). processed 6 Million barcodes[New Thread 0x7ffc77265700 (LWP 27920)]; [New Thread 0x7ffbf7264700 (LWP 27921)]; [New Thread 0x7ffb77263700 (LWP 27922)]; [New Thread 0x7ffaf7262700 (LWP 27923)]; [New Thread 0x7ffa77261700 (LWP 27924)]; [New Thread 0x7ff",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234:1640,Log,Logs,1640,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"lmon/lib/libtbbmalloc.so; -- Installing: /salmon/lib/libtbbmalloc.so.2; -- Installing: /salmon/lib/libtbbmalloc.so.2.5; -- Installing: /salmon/lib/libtbbmalloc_proxy.so; -- Installing: /salmon/lib/libtbbmalloc_proxy.so.2; -- Installing: /salmon/lib/libtbbmalloc_proxy.so.2.5; -- Installing: /salmon/bin/salmon; -- Installing: /salmon/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly.; ==========================================================================; Please add /salmon/bin to your PATH; Please add /salmon/lib to your LD_LIBRARY_PATH; ==========================================================================; root@fd877e359439:/salmon/build# make test; Running tests...; Test project /salmon/build; Start 1: unit_tests; 1/2 Test #1: unit_tests ....................... Passed 0.37 sec; Start 2: salmon_read_test_quasi; 2/2 Test #2: salmon_read_test_quasi ........... Passed 1.80 sec. 100% tests passed, 0 tests failed out of 2. Total Test time (real) = 2.17 sec; ```. The `make test` command itself runs the test the builds the index and maps the reads against it. Either way, I can do that explicitly too (from within build):. ```; $ ./src/salmon index -t ../sample_data/transcripts.fasta -i sample_idx; ```. returns succesfully with a built index. ```; ...; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Done wrapping the rank vector with a rank9sel structure.; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] contig count for validation: 23; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Total # of Contigs : 23; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Total # of numerical Contigs : 23; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Total # of contig vec entries: 36; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] bits per offset entry 6; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Done constructing the contig vector. 24; [2023-03-10 05:51:33.748] [puf",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554:2973,Test,Test,2973,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554,1,['Test'],['Test']
Testability,"lmonQuantifyAlignments.cpp:39:; /usr/local/salmon-0.10.2/include/eigen3/Eigen/src/Core/AssignEvaluator.h:90:50: warning: enum constant in boolean context [-Wint-in-bool-context]; MaySliceVectorize = bool(MightVectorize) && bool(DstHasDirectAccess); ^~~~~~~~~~~~~~~~~~~~~~~~; At global scope:; cc1plus: warning: unrecognized command line option ‘-Wno-unused-local-typedef’; cc1plus: warning: unrecognized command line option ‘-Wno-unused-local-typedef’; make[2]: *** [src/CMakeFiles/salmon.dir/SalmonQuantifyAlignments.cpp.o] Error 1; make[1]: *** [src/CMakeFiles/salmon.dir/all] Error 2; make: *** [all] Error 2; ```. I also tried installing it through bioconda. Apparently, it installs it correctly, but when I try to use Trinity (I'm installing Salmon as a Trinity requirement) this is what happens: . ```; salmon: /opt/conda/conda-bld/salmon_1528409373758/work/salmon-0.10.2/include/eigen3/Eigen/src/Core/util/Memory.h:161: void* Eigen::internal::aligned_malloc(std::size_t): Assertion `(size<16 || (std::size_t(result)%16)==0) && ""System's malloc returned an unaligned pointer. Compile with EIGEN_MALLOC_ALREADY_ALIGNED=0 to fallback to handmade alignd memory allocator.""' failed.; Error, cmd:; salmon --no-version-check quant -i /home/federicoplazzi/test_Trinity_Assembly/trinity_out_dir/read_partitions/Fb_0/CBin_0/c30.trinity.reads.fa.out/Trinity.fasta.tmp.salmon.idx -l U -r /home/federicoplazzi/test_Trinity_Assembly/trinity_out_dir/read_partitions/Fb_0/CBin_0/c30.trinity.reads.fa.out/single.fa -o salmon_outdir -p 1 --minAssignedFrags 1; died with ret (6) at /usr/local/trinityrnaseq-Trinity-v2.6.6/util/support_scripts/../../PerlLib/Process_cmd.pm line 19.; Process_cmd::process_cmd(""salmon --no-version-check quant -i /home/federicoplazzi/test_""...) called at /usr/local/trinityrnaseq-Trinity-v2.6.6/util/support_scripts/salmon_runner.pl line 26; Trinity run failed. Must investigate error above.; warning, cmd: /usr/local/trinityrnaseq-Trinity-v2.6.6/util/support_scripts/../../Trinity -",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/235#issuecomment-398081403:1499,Assert,Assertion,1499,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/235#issuecomment-398081403,1,['Assert'],['Assertion']
Testability,"loaded executable, through bioconda)?; Bioconda; * Which reference (e.g. transcriptome) was used?; gencode.v27.transcripts.fa; * Which read files were used?; fastq; * Which which program options were used?; -l A, single end . **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. ```; salmon quant -i ~/Reference_indexes/humangencodev27_transcripts_index_20181023 -l A -r ~/Downloads/ENCFF600FYP.fastq.gz -o ./salmon_test/ENCFF600FYP_quant; Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; ### salmon (mapping-based) v0.11.3; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { ~/Reference_indexes/humangencodev27_transcripts_index_20181023 }; ### [ libType ] => { A }; ### [ unmatedReads ] => { ~/Downloads/ENCFF600FYP.fastq.gz }; ### [ output ] => { ./salmon_test/ENCFF600FYP_quant }; Logs will be written to ./salmon_test/ENCFF600FYP_quant/logs; [2018-10-23 20:11:13.424] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2018-10-23 20:11:13.425] [jointLog] [info] parsing read library format; [2018-10-23 20:11:13.425] [jointLog] [info] There is 1 library.; [2018-10-23 20:11:13.513] [stderrLog] [info] Loading Suffix Array ; [2018-10-23 20:11:13.513] [jointLog] [info] Loading Quasi index; [2018-10-23 20:11:13.513] [jointLog] [info] Loading 32-bit quasi index; [2018-10-23 20:11:14.645] [stderrLog] [info] Loading Transcript Info ; [2018-10-23 20:11:14.975] [stderrLog] [info] Loading Rank-Select Bit Array; [2018-10-23 20:11:15.031] [stderrLog] [info] There were 199,612 set bits in the bit array; [2018-10-23 20:11:15.042] [stderrLog] [info] Computing transcript lengths; [2018-10-23 20:11:15.042] [stderrLog] [info] Waiting to finish loading hash; [2018-10-23 20:11:20.618] [stderrLog] [info] Done loading index; [2018-10-23 20:11:20.618] [jointLog] [info] done; [2018-10-23",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/303:1745,log,logs,1745,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/303,1,['log'],['logs']
Testability,log(CPM) and TPM are so different,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/812:0,log,log,0,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/812,1,['log'],['log']
Testability,ls -l /work/yu_liu/resource/salmon_gencodev28_index/; total 2234181; -rw-r--r-- 1 yu_liu data-sci 179889 Jul 13 19:43 duplicate_clusters.tsv; -rw-r--r-- 1 yu_liu data-sci 673607680 Jul 13 19:47 hash.bin; -rw-r--r-- 1 yu_liu data-sci 0 Jul 13 19:47 header.json; -rw-r--r-- 1 yu_liu data-sci 0 Jul 13 19:47 indexing.log; -rw-r--r-- 1 yu_liu data-sci 8192 Jul 13 19:47 quasi_index.log; -rw-r--r-- 1 yu_liu data-sci 0 Jul 13 19:47 refInfo.json; -rw-r--r-- 1 yu_liu data-sci 38621520 Jul 13 19:43 rsd.bin; -rw-r--r-- 1 yu_liu data-sci 1235888364 Jul 13 19:44 sa.bin; -rw-r--r-- 1 yu_liu data-sci 336807483 Jul 13 19:43 txpInfo.bin; -rw-r--r-- 1 yu_liu data-sci 0 Jul 13 19:47 versionInfo.json,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/251#issuecomment-404957888:314,log,log,314,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/251#issuecomment-404957888,2,['log'],['log']
Testability,"lt still segfaults. It still needed an edit of the CMakeLists.txt file. Still, for future reference:. ```; pversion=1.2.1; package=salmon; TOPDIR=/usr/common/modules/el8/x86_64/software/${package}/${pversion}-CentOS-vanilla; wget https://github.com/COMBINE-lab/salmon/archive/v1.2.1.tar.gz; gunzip -c v1.2.1.tar.gz | tar -xf -; /bin/rm v1.2.1.tar.gz; cd ${package}-${pversion}; mv CMakeLists.txt CMakeLists.txt.dist; cat >mypatch <<'EOD'; --- CMakeLists.txt.dist	2020-04-21 22:31:07.000000000 -0700; +++ CMakeLists.txt	2020-06-09 14:55:02.733885772 -0700; @@ -419,6 +419,10 @@; find_package(Boost 1.59.0 COMPONENTS iostreams filesystem system timer chrono program_options); message(""BOOST_INCLUDEDIR = ${BOOST_INCLUDEDIR}""); message(""BOOST_LIBRARYDIR = ${BOOST_LIBRARYDIR}""); +message(""Forcing Boost_FOUND to TRUE""); +set(Boost_FOUND TRUE); +set(Boost_LIBRARY_DIRS ""/usr/lib64/boost169""); +set(Boost_LIBRARIES -lboost_iostreams -lboost_filesystem -lboost_system -lboost_timer -lboost_chrono -lboost_program_options); message(""Boost_FOUND = ${Boost_FOUND}""); endif(); ; EOD; patch -p0 <mypatch; module load cmake; module load io_lib; module load libgff; module load libtbb; mkdir build; cd build; export CFLAGS=""-g -O0""; export CXXFLAGS=""-g -O0""; cmake \; -DCMAKE_INSTALL_PREFIX=$TOPDIR \; -DSTADEN_ROOT=$ROOT_IO_LIB \; -DGFF_ROOT=$ROOT_LIBGFF \; -DTBB_ROOT=$ROOT_LIBTBB \; -DCMAKE_VERBOSE_MAKEFILE:BOOL=ON \; -DBOOST_LIBRARYDIR=/usr/lib64/boost169 \; -DBOOST_INCLUDEDIR=/usr/include/boost169 \; -DBoost_NO_SYSTEM_PATHS=ON \; .. 2>&1 | tee cmake_2020_06_09.log; make -j 4 2>&1 | tee build_2020_06_09.log. ```. Since it was compiled ""-g -O0"" this time it was easier to step through it. Well, somewhat. In Salmon.cpp line 195 is the last place a break point works. If one is set for 197 it segfaults before reaching it. Line 195 is:. `	 po::store(parsed, vm);; `; I tried briefly to trace inward from there but couldn't make heads or tails of the path it was taking through an endless series of headers.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641612831:1604,log,log,1604,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641612831,2,['log'],['log']
Testability,"mary>Salmon run w/ SFA method</summary>; <p>. ```python; rule salmon_meta:; input:; ref= REFERENCE,; tcp= TRANSCRIPTS; output:; gent= ""results/salmon/decoy/gentrome.fa"",; decoy= ""results/salmon/decoy/decoys.txt"",; bak=""results/salmon/decoy/decoys.txt.bak""; conda:; ""../envs/salmon.yaml""; shell:; """"""; grep ""^>"" {input.ref} | cut -d "" "" -f 1 > {output.decoy}; sed -i.bak -e 's/>//g' {output.decoy}; cat {input.tcp} {input.ref} > {output.gent}; """""". rule salmon_index:; input:; gent= ""results/salmon/decoy/gentrome.fa"",; decoy= ""results/salmon/decoy/decoys.txt"",; output:; directory(""results/salmon/index""); conda:; ""../envs/salmon.yaml""; threads:20; shell:; """"""; salmon index -p {threads} -t {input.gent} -d {input.decoy} -i {output}; """""". if config[""salmon""][""mapping_mode""]:; rule salmon_quant_mapping:; input:; r1=""results/trimmed/{smp}_R1_val_1.fq.gz"",; r2=""results/trimmed/{smp}_R2_val_2.fq.gz"",; index = ""results/salmon/index""; output:; directory(""results/salmon/quant/{smp}_salmon_quant""),; mappings=""results/salmon/quant/{smp}_salmon_quant/{smp}_salmon_mappings""; log:; 		""results/salmon/logs/{smp}.salmon.log""; conda:; ""../envs/salmon.yaml""; threads:20; shell:; """"""; salmon quant -i {input.index} -l A -1 {input.r1} -2 {input.r2} -o {output} --validateMappings --gcBias --seqBias --writeUnmappedNames --writeMappings={output.mappings} -p {threads} --numBootstraps 100; """"""; ```. </p>; </details>. <details><summary>Mapping rates w/ SFA method</summary>; <p>. ![image](https://user-images.githubusercontent.com/42179487/73188783-62605d80-40f1-11ea-87ef-e16050f94e60.png). </p>; </details>. <details><summary>cmd_info.json (SFA)</summary>; <p>. ```json; {; ""salmon_version"": ""1.1.0"",; ""index"": ""results/salmon/index"",; ""libType"": ""A"",; ""mates1"": ""results/trimmed/ILWN_RNAseq_G002_ATCACG_Arachis_hypogaea_I801_L1_R1_val_1.fq.gz"",; ""mates2"": ""results/trimmed/ILWN_RNAseq_G002_ATCACG_Arachis_hypogaea_I801_L1_R2_val_2.fq.gz"",; ""output"": ""results/salmon/quant/ILWN_RNAseq_G002_ATCACG_Arachis_hypogae",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/479:1839,log,log,1839,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/479,2,['log'],"['log', 'logs']"
Testability,"me 0.368; ru_stime 3.680; ru_maxrss 537668; ru_ixrss 0; ru_ismrss 0; ru_idrss 0; ru_isrss 0; ru_minflt 21951; ru_majflt 282; ru_nswap 0; ru_inblock 56; ru_oublock 1066296; ru_msgsnd 0; ru_msgrcv 0; ru_nsignals 0; ru_nvcsw 1230; ru_nivcsw 53; cpu 4.048; mem 27.889; io 0.002; iow 0.000; maxvmem 10.736G; arid undefined; ```. I'm sure that the job got terminated because the memory reached the limit of 11 GB. . I previously did several tests where for a file the max memory reported was about 9 GB when requesting about 100G of RAM, and the same job kept failing even if I requested 10G, 20G, 30G, 40G... I didn't save the info then to report the problem. . Back on these tests, I then increased the memory requested a bit more (and used the `-m e` SGE option to get an email with the max vmem, which matches the `qacct` output). Here is the bash script:. ```bash; #!/bin/bash; #$ -cwd; #$ -l mem_free=14G,h_vmem=15G,h_fsize=100G; #$ -N step6-salmon_test2.gsk_phaseII; #$ -pe local 1; #$ -o ./logs/salmon_test2.$TASK_ID.txt; #$ -e ./logs/salmon_test2.$TASK_ID.txt; #$ -m e; echo ""**** Job starts ****""; date. echo ""**** JHPCE info ****""; echo ""User: ${USER}""; echo ""Job id: ${JOB_ID}""; echo ""Job name: ${JOB_NAME}""; echo ""Hostname: ${HOSTNAME}""; echo ""Task id: ${TASK_ID}"". FILE1=$(awk 'BEGIN {FS=""\t""} {print $1}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); FILE2=$(awk 'BEGIN {FS=""\t""} {print $3}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); ID=$(cat /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk '{print $NF}' | awk ""NR==${SGE_TASK_ID}""). mkdir -p /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test2/${ID}. /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.7.2_linux_x86_64/bin/salmon quant 	-i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/GENCODE/GRCh38_hg38/transcripts/salmon_index_gencode.v25.transcripts -p 1 -l ISR 	-1 ${FILE1} -2 ${FILE2} 	-o /dc",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126:27120,log,logs,27120,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126,1,['log'],['logs']
Testability,"med/ILWN_RNAseq_G002_ATCACG_Arachis_hypogaea_I801_L1_R1_val_1.fq.gz"",; ""mates2"": ""results/trimmed/ILWN_RNAseq_G002_ATCACG_Arachis_hypogaea_I801_L1_R2_val_2.fq.gz"",; ""output"": ""results/salmon/quant/ILWN_RNAseq_G002_ATCACG_Arachis_hypogaea_I801_L1_salmon_quant"",; """": ""results/salmon/quant/ILWN_RNAseq_G002_ATCACG_Arachis_hypogaea_I801_L1_salmon_quant/ILWN_RNAseq_G002_ATCACG_Arachis_hypogaea_I801_L1_salmon_mappings"",; ""validateMappings"": [],; ""gcBias"": [],; ""seqBias"": [],; ""writeUnmappedNames"": [],; ""writeMappings"": ""results/salmon/quant/ILWN_RNAseq_G002_ATCACG_Arachis_hypogaea_I801_L1_salmon_quant/ILWN_RNAseq_G002_ATCACG_Arachis_hypogaea_I801_L1_salmon_mappings"",; ""threads"": ""20"",; ""numBootstraps"": ""100"",; ""auxDir"": ""aux_info""; }; ```. </p>; </details>. <details><summary>Salmon run w/ quasi mapping method</summary>; <p>. ```python; rule salmon_index_test:; input:; tcp = TRANSCRIPTS; output:; directory(""results/salmon_test/index""); priority:1; log:; ""results/salmon_test/logs/index.log""; conda:; ""../envs/salmon.yaml""; threads:30; shell:; """"""; salmon index -p {threads} -t {input.tcp} -i {output}; """""". rule salmon_quant_test:; input:; r1=""results/trimmed/{smp}_R1_val_1.fq.gz"",; r2=""results/trimmed/{smp}_R2_val_2.fq.gz"",; index = ""results/salmon_test/index""; output:; directory(""results/salmon_test/quant/{smp}_salmon_test_quant""),; log:; ""results/salmon_test/logs/{smp}.salmon_test.log""; conda:; ""../envs/salmon.yaml""; threads:30; shell:; """"""; salmon quant -i {input.index} -l A -1 {input.r1} -2 {input.r2} -o {output} --validateMappings --gcBias --seqBias --writeUnmappedNames -p {threads} --numBootstraps 100; """"""; ```. </p>; </details>. <details><summary>Mapping rates w/ quasi mapping method</summary>; <p>. ![image](https://user-images.githubusercontent.com/42179487/73189014-b8350580-40f1-11ea-8f6a-9d7d39867a89.png). </p>; </details>. <details><summary>cmd_info.json (quasi)</summary>; <p>. ```json; {; ""salmon_version"": ""1.1.0"",; ""index"": ""results/salmon_test/index"",; ""libType"":",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/479:3525,log,log,3525,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/479,1,['log'],['log']
Testability,"med/Sample_8-15/8-15_221020_L002_R2.fastq.gz; /nobackup/qkdf72/Trinity/Reads/All-H.m-reads/Trimmed/Sample_23-31/23-31_221020_L002_R2.fastq.gz; /nobackup/qkdf72/Trinity/Reads/All-H.m-reads/Trimmed/P3_43-52_221020_L002_R2.fastq.gz; /nobackup/qkdf72/Trinity/Reads/All-H.m-reads/Trimmed/P2-45-54_221020_L002_R2.fastq.gz; /nobackup/qkdf72/Trinity/Reads/All-H.m-reads/Trimmed/P3_39-47_221020_L002_R2.fastq.gz; /nobackup/qkdf72/Trinity/Reads/All-H.m-reads/Trimmed/Sample_22-30/22-30_221020_L002_R2.fastq.gz; /nobackup/qkdf72/Trinity/Reads/All-H.m-reads/Trimmed/Sample_27-35/27-35_221020_L002_R2.fastq.gz; /nobackup/qkdf72/Trinity/Reads/All-H.m-reads/Trimmed/Sample_25-33/25-33_221020_L002_R2.fastq.gz; /nobackup/qkdf72/Trinity/Reads/All-H.m-reads/Trimmed/P2-5-11_221020_L002_R2.fastq.gz }; ### [ threads ] => { 100 }; ### [ validateMappings ] => { }; ### [ output ] => { salmon_out/P2-45-54_221020_L002_R1.fastq.gz_quant }; Logs will be written to salmon_out/P2-45-54_221020_L002_R1.fastq.gz_quant/logs; [2023-08-27 19:59:26.866] [jointLog] [info] setting maxHashResizeThreads to 100; [2023-08-27 19:59:26.866] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2023-08-27 19:59:26.866] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2023-08-27 19:59:26.866] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.; [2023-08-27 19:59:26.866] [jointLog] [info] parsing read library format; [2023-08-27 19:59:26.866] [jointLog] [info] There is 1 library.; [2023-08-27 19:59:26.867] [jointLog] [info] Loading pufferfish index; [2023-08-27 19:59:26.867] [jointLog] [info] Loading dense pufferfish index.; -----------------------------------------; | Loading contig table | Time = 3.5071 s; -----------------------------------------; size = 23930024; -----------------------------------------; | Loading contig offsets | Time = 66.098 ms; -",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/870:9382,log,logs,9382,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/870,1,['log'],['logs']
Testability,"metimes don't know what the right words are to describe what I am doing or trying to do (lol)!. With the fastq files of reads generated from my RNAseq experiment, I first ran FastQC. The quality of my data seemed to be fine as the per base sequence quality scores were 32+ and most of the other tests passed as well. Next, I built my index for Salmon using the fasta file from Gencode for the human transcriptome. Afterwards, I ran Salmon with the built index and had it automatically detect the library type. When the program was done aligning to the index, I saw that the file had a mapping rate of 40%. I guess what I'm asking is, is this an acceptable mapping rate or should I be concerned?? The reason I ask is because in the data I was working with while learning via the Youtube series, those datasets had mapping rates of nearly 90%. Comparing FastQC reports, my data was of similar/better quality than the data from the Youtube series. In case this is helpful in answering my question, this is the information from the logs for one of my samples:. ```; [2020-09-05 13:51:07.144] [jointLog] [info] setting maxHashResizeThreads to 1; [2020-09-05 13:51:07.144] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2020-09-05 13:51:07.159] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2020-09-05 13:51:07.159] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.35.; [2020-09-05 13:51:07.159] [jointLog] [info] parsing read library format; [2020-09-05 13:51:07.159] [jointLog] [info] There is 1 library.; [2020-09-05 13:51:07.828] [jointLog] [info] Loading pufferfish index; [2020-09-05 13:51:07.876] [jointLog] [info] Loading dense pufferfish index.; [2020-09-05 13:51:49.487] [jointLog] [info] done; [2020-09-05 13:51:49.551] [jointLog] [info] Index contained 228,754 targets; [2020",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/571:1325,log,logs,1325,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/571,1,['log'],['logs']
Testability,"ml""; benchmark:""benchmarks/salmon_index_{gtdb_species}.txt""; shell:'''; salmon index -t {input.seqs} -i {params.index_dir} --decoys {input.decoys} -k 31; '''; ```. I've attached my reference transcriptome and my file of decoy names at the bottom of this issue. Details -- . * Which version of salmon was used?: 1.6.0; * How was salmon installed (compiled, downloaded executable, through bioconda)?: Miniconda; * Which reference (e.g. transcriptome) was used?: Self-generated; * Which read files were used?: ERX4307280, SRX10245671, SRX3847835; * Which which program options were used?. ```; salmon quant -i {params.index_dir} -l A -r {input.reads} -o {params.out_dir} --validateMappings --writeUnmappedNames; ```. **Expected behavior**; I expected the reads that were counted in the log file as ""discarded because they are best-mapped to decoys"" to be labelled in the `aux_info/unmapped_names.txt` file with `d`, but all reads were marked as `u`. **Screenshots**; ```; $grep ""Number of fragments discarded because they are best-mapped to decoys"" */logs/*. ERX4307280_quant/logs/salmon_quant.log:[2022-02-02 15:51:25.854] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 948,850; SRX10245671_quant/logs/salmon_quant.log:[2022-02-02 15:57:10.321] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 961,758; SRX3847835_quant/logs/salmon_quant.log:[2022-02-02 15:33:54.185] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 220,351; ```. **Desktop (please complete the following information):**; - OS: Linux; - Version: ; ```; Linux farm.cse.ucdavis.edu 4.15.0-159-generic #167-Ubuntu SMP Tue Sep 21 08:55:05 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux; ```; ```; No LSB modules are available.; Distributor ID:	Ubuntu; Description:	Ubuntu 18.04.6 LTS; Release:	18.04; Codename:	bionic; ```; **Additional context**; I intentionally mapped all three libraries as SE, even though two are PE. Bec",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/748:4284,log,logs,4284,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/748,1,['log'],['logs']
Testability,"mon installed (compiled, downloaded executable, through bioconda)?; downloaded executable; * Which reference (e.g. transcriptome) was used?; Araport 11, from A. thaliana; * Which read files were used?; regular fastq.gz ( SRR7985407); * Which which program options were used?; --validateMappings; -p 4; --seqBias; --gcBias ; --posBias. **Expected behavior**; Much faster alignment, it is Salmon !!; **Screenshots**; this is the run info so far:. Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v1.2.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /home/jaimealaniz/Documents/indexes/salmon/ara11/ }; ### [ libType ] => { A }; ### [ mates1 ] => { SRR7985407_1.fq.gz }; ### [ mates2 ] => { SRR7985407_2.fq.gz }; ### [ validateMappings ] => { }; ### [ threads ] => { 4 }; ### [ seqBias ] => { }; ### [ gcBias ] => { }; ### [ posBias ] => { }; ### [ output ] => { /home/jaimealaniz/Documents/salmon.embryo/SRR7985407/ }; Logs will be written to /home/jaimealaniz/Documents/salmon.embryo/SRR7985407/logs; [2020-05-29 20:14:24.283] [jointLog] [info] setting maxHashResizeThreads to 4; [2020-05-29 20:14:24.283] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2020-05-29 20:14:24.283] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2020-05-29 20:14:24.283] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.35.; [2020-05-29 20:14:24.283] [jointLog] [info] parsing read library format; [2020-05-29 20:14:24.283] [jointLog] [info] There is 1 library.; [2020-05-29 20:14:24.341] [jointLog] [info] Loading pufferfish index; [2020-05-29 20:14:24.342] [jointLog] [info] Loading dense pufferfish index.; -----------------------------------------; | Loading contig table | Time = 41.693 ms; -----------------------------------------; s",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/527:1943,Log,Logs,1943,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/527,1,['Log'],['Logs']
Testability,"n installed (compiled, downloaded executable, through bioconda)?; Installed with bioconda; * Which reference (e.g. transcriptome) was used? ; This transcriptome: https://drive.google.com/open?id=1XcsFUxJM6XaYEKh9BYdUoAyJSlWJLIiW. ; It's a mouse transcriptome with 3 additional transcripts at the end; * Which read files were used?; * Which which program options were used?; `salmon alevin -lISR -1 ./H2_S5_L003_R1_001.fastq.gz -2 H2_S5_L003_R2_001.fastq.gz --chromium -i salmon_index -p 8 -o alevin_output --tgMap txp2gene.tsv`. **Desktop (please complete the following information):**; - OS: CentOS; - Version:; Linux login1 3.10.0-514.2.2.el7.x86_64 #1 SMP Tue Dec 6 23:06:41 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux; LSB Version: :core-4.1-amd64:core-4.1-noarch; Distributor ID: CentOS; Description: CentOS Linux release 7.3.1611 (Core); Release: 7.3.1611; Codename: Core. **Additional context**; ```; Version Info: This is the most recent version of Salmon.; Logs will be written to alevin_output/logs; ### salmon (single-cell-based) v0.10.2; ### [ program ] => salmon ; ### [ command ] => alevin ; ### [ libType ] => { ISR }; ### [ mates1 ] => { ./H2_S5_L003_R1_001.fastq.gz }; ### [ mates2 ] => { H2_S5_L003_R2_001.fastq.gz }; ### [ chromium ] => { }; ### [ index ] => { salmon_index }; ### [ threads ] => { 8 }; ### [ output ] => { alevin_output }; ### [ tgMap ] => { txp2gene.tsv }. [2018-06-12 21:01:31.327] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2018-06-12 21:01:31.330] [alevinLog] [info] Processing barcodes files (if Present) . ; processed 141 Million barcodes. [2018-06-12 21:08:38.126] [alevinLog] [info] Done barcode density calculation.; [2018-06-12 21:08:38.126] [alevinLog] [info] # Barcodes Used: 140111660 / 141062078.; [2018-06-12 21:08:42.014] [alevinLog] [info] Knee found left boundary at 127 ; [2018-06-12 21:08:55.712] [alevinLog] [warning] Gauss Prediction 12274 Too far from knee prediction skipping it;",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/237:1526,Log,Logs,1526,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/237,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"n, my reading is that the command does not include anything to link boost libraries. So telling cmake where the libraries are, where the include files are, and that boost was found was not sufficient. There must be some other set of symbols which need to be defined. `/opt/rh/devtoolset-4/root/usr/bin/c++ -pthread -ftree-vectorize -funroll-loops -fPIC -fomit-frame-pointer -O3 -DRAPMAP_SALMON_SUPPORT -DHAVE_ANSI_TERM -DHAVE_SSTREAM -Wall -Wno-unknown-pragmas -Wno-reorder -Wno-unused-variable -std=c++11 -Wreturn-type -Werror=return-type -Wno-unused-function -Wno-unused-local-typedef -static-libstdc++ -Wno-unused-local-typedefs -pthread -ftree-vectorize -funroll-loops -fPIC -fomit-frame-pointer -O3 -DRAPMAP_SALMON_SUPPORT -DHAVE_ANSI_TERM -DHAVE_SSTREAM -Wall -Wno-unknown-pragmas -Wno-reorder -Wno-unused-variable -std=c++11 -Wreturn-type -Werror=return-type -Wno-unused-function -Wno-unused-local-typedef -static-libstdc++ -Wno-unused-local-typedefs -rdynamic CMakeFiles/unitTests.dir/__/tests/UnitTests.cpp.o CMakeFiles/unitTests.dir/FragmentLengthDistribution.cpp.o CMakeFiles/unitTests.dir/__/external/install/src/rapmap/rank9b.cpp.o CMakeFiles/unitTests.dir/__/external/install/src/rapmap/bit_array.c.o -o unitTests -L/home/mathog/src/salmon/lib -L/home/mathog/src/salmon/external/install/lib -Wl,-rpath,""\$ORIGIN/../lib:\$ORIGIN/../../lib:\$ORIGIN/:\$ORIGIN/../../external/install/lib"" libsalmon_core.a libalevin_core.a -lgff -lpthread ../external/install/lib/libstaden-read.a -lz ../external/install/lib/libdivsufsort.a ../external/install/lib/libdivsufsort64.a ../external/install/lib/libbwa.a -lm -llzma -lbz2 -ltbb -lgomp -lrt ../external/install/lib/libjemalloc.a -lrt -ldl ../external/install/lib/libjemalloc.a -ldl`. Oh, I also had to update automake and autoconf because the 2 year old versions on this system were not new enough. Is there a static binary version of salmon available for download, Linux 64 bit? It looks like the default links are that way anyway, and that would ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-397025719:2673,test,tests,2673,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-397025719,1,['test'],['tests']
Testability,"nad-1_S120_L006_R2_001.qc.fq.gz; lightreceptor-2_S115_L006_R2_001.qc.fq.gz; mgonad-2_S121_L005_R2_001.qc.fq.gz mgonad-1_S120_L005_R2_001.qc.fq.gz; lightreceptor-2_S115_L005_R2_001.qc.fq.gz; lightreceptor-1_S114_L005_R2_001.qc.fq.gz; mgonad-2_S121_L004_R2_001.qc.fq.gz mgonad-1_S120_L004_R2_001.qc.fq.gz; lightreceptor-2_S115_L004_R2_001.qc.fq.gz; lightreceptor-1_S114_L004_R2_001.qc.fq.gz ${i} -o ${i}_quant --seqBias; --gcBias --validateMappings; done```. And here is my output from salmon.log. [2019-07-30 10:40:14.624] [jointLog] [info] Fragment incompatibility prior; below threshold. Incompatible fragments will be ignored.; [2019-07-30 10:40:14.624] [jointLog] [error] You passed paired-end files to; salmon, but you passed 12 files to --mates1 and 13 files to --mates2. You; must pass the same number of files to both flags. Thank you in advance for any tips you may have for me. Sara. On Tue, Jul 30, 2019 at 10:30 AM Sara Boles <seboles@ucdavis.edu> wrote:. > Hi Avi,; >; > Here is the salmon log from one of my PE libraries. There are only 12; > libraries for each in the directory, which is why I got confused when it; > said 13. I will try putting in all of the file names and let you know how; > it goes. Thank you for all of your help.; >; > Sara; >; > [2019-07-29 15:58:39.034] [jointLog] [info] Fragment incompatibility prior; > below threshold. Incompatible fragments will be ignored.; > [2019-07-29 15:58:39.034] [jointLog] [info] Usage of --validateMappings; > implies use of minScoreFraction. Since not explicitly specified, it is; > being set to 0.65; > [2019-07-29 15:58:39.034] [jointLog] [info] Usage of --validateMappings,; > without --hardFilter implies use of range factorization.; > rangeFactorizationBins is being set to 4; > [2019-07-29 15:58:39.034] [jointLog] [info] Usage of --validateMappings; > implies a default consensus slack of 0.2. Setting consensusSlack to 0.2.; > [2019-07-29 15:58:39.034] [jointLog] [info] parsing read library format; > [2019-07-29 15:58:3",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408#issuecomment-516521791:1959,log,log,1959,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408#issuecomment-516521791,1,['log'],['log']
Testability,"ncluded quasi-mapping and selective-alignment), but what you can get is that there is a large variance between parameters. Particularly ```--seqBias``` showed a dramatic drop in predicted T - 2 transcripts. ![image](https://user-images.githubusercontent.com/29610303/61421680-5899aa00-a8c5-11e9-8349-bd708316599d.png). Any suggestions onto parameters settings to help me with this narrow question?. Now onto some questions regarding some outputs. 1. I run into a segmentation fault (core dumped) when I try to run the experimental ```--posBias```. I am new to RNAseq, but I thought this might help with this particular RNAseq set as it was a PolyA tail selection and when mapping to the full genome there is an observed heavy mapping to exon 1 with decreased mapping over exon 2, 3 and 4. . 2. During my runs I have been using ```-l A``` as I will be using this method in my script so that Salmon can just select the best libtype based on the given sequence to help make my script less complex. However, I found something strange when I used ```-l A``` on my test sequence. I got a warning of >1% strand bias on the command line and in the lib_format_counts.json I see that Salmon selected ""IU"" which I believe to be the correct libtype as well, but got this:; ```; {; ""read_files"": [; ""/data/wyka/vamsi/SRR1174205_1_paired.fastq"",; ""/data/wyka/vamsi/SRR1174205_2_paired.fastq""; ],; ""expected_format"": ""IU"",; ""compatible_fragment_ratio"": 1.0,; ""num_compatible_fragments"": 5549,; ""num_assigned_fragments"": 5549,; ""num_frags_with_concordant_consistent_mappings"": 4190,; ""num_frags_with_inconsistent_or_orphan_mappings"": 1359,; ""strand_mapping_bias"": 0.45441527446300719,; ""MSF"": 0,; ""OSF"": 0,; ""ISF"": 2286,; ""MSR"": 0,; ""OSR"": 0,; ""ISR"": 1904,; ""SF"": 547,; ""SR"": 812,; ""MU"": 0,; ""OU"": 0,; ""IU"": 0,; ""U"": 0; }; ```; When my strand mapping was 0.45 (which to be honest I am not sure how bad that actually is), but I noticed that my reads were mapped with the ISF, ISR, SF, and SR libtypes. Is that normal?",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/401:3807,test,test,3807,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/401,1,['test'],['test']
Testability,"ncreasing --maxNumBarcodes to 200000 results in no barcodes getting corrected? (See log for Run 2 below). What is the rationale for the current default of 100000?. That's again a great question. In short single-cell world is expanding rapidly and alevin was initially designed to work with 10x 3' data and some of the restriction are outdated with combinatorial indexing based multiplexed experiments. To be honest, 100k was just a random high enough number that was put down to throw away the obvious junk data. Having said that, you would notice that in both the logs you attached a significant fraction of barcodes are thrown away i.e., `Skipped 82268 barcodes due to No mapped read`, which is like ~82% of the 100k barcodes. Even if you include the 200k almost everything was thrown away, `[warning] Skipped 184123 barcodes due to No mapped read`. Although your point is important one why things are not getting sequence corrected with 200k, unfortunately I might have to do some more testing on that front to give more precise answer but in your case I'd advise keeping the default 100k bound, unless you are doing combinatorially-indexed data . > For the downstream analysis of such data, I usually work with both the read and UMI counts, but quants_mat.gz only contains the UMI counts. Can Alevin a produce a matrix of read counts as well. It would be a great feature to add. For now, what is easiest way to get the cell x feature matrix of read counts if I use the --dumpEq or --dumpBfh flags? Can tximport be used for this or do I need to use the Python parser first?. Congratulations on the awesome paper :). We were actually discussing yesterday about your paper and potentially modifying alevin to include model for correcting index-hoping, although it's still in discussion phase. To answer your question, thanks for the feature request, I can add that feature on the weekend if it's urgent. However, you can also generate that with the current version using the `--dumpBfh` flag and `bfh",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639048052:1669,test,testing,1669,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639048052,2,['test'],['testing']
Testability,"nd tried setting --minAssignedFrags to 5, 3, 1 but always got the same warning and results. And here is my command for quantification (but I changed --minAssignedFrags parameter several times):. `salmon quant -i ../ref/salmon_index -l IU -1 SRR493372_1.fastq SRR493373_1.fastq SRR493374_1.fastq SRR493375_1.fastq SRR493376_1.fastq SRR493377_1.fastq -2 SRR493372_2.fastq SRR493373_2.fastq SRR493374_2.fastq SRR493375_2.fastq SRR493376_2.fastq SRR493377_2.fastq --validateMappings --minAssignedFrags 1 -o transcripts_quant`. I then tried different transcriptome files for building indices. I built the index using the following transcriptome respectively: (1) another decoy-aware transcriptome with GRCh38.p13.genome.fa.gz and gencode.v40.transcripts.fa.gz from Gencode using the same tutorial above (2) gencode.v40.transcripts.fa.gz from Gencode only (3) Homo_sapiens.GRCh38.cdna.all.fa.gz from Ensembl ; But I still received the same warning and 0 fragments mapped results. Below is one of the log file (they all look similar):. > [2022-04-15 23:47:55.696] [jointLog] [info] setting maxHashResizeThreads to 48 ; [2022-04-15 23:47:55.696] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored. ; [2022-04-15 23:47:55.696] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65 ; [2022-04-15 23:47:55.696] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35. ; [2022-04-15 23:47:55.696] [jointLog] [info] parsing read library format ; [2022-04-15 23:47:55.696] [jointLog] [info] There is 1 library. ; [2022-04-15 23:47:55.833] [jointLog] [info] Loading pufferfish index ; [2022-04-15 23:47:55.833] [jointLog] [info] Loading dense pufferfish index. ; [2022-04-15 23:49:52.320] [jointLog] [info] done ; [2022-04-15 23:49:52.320] [jointLog] [info] Index contained 245,900 targets ; [2022-04-15 23:49:52.424] [jointLog] [info] Number of decoys : 63",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/768:2085,log,log,2085,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/768,1,['log'],['log']
Testability,"ndex_test/salmon_0.8.2_index_gencode.v25.transcripts }; ### [ threads ] => { 1 }; ### [ libType ] => { ISR }; ### [ mates1 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX.fastq.gz }; ### [ mates2 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX_read2.fastq.gz }; ### [ output ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX }; ) = 594; stat(""/etc/localtime"", {st_mode=S_IFREG|0644, st_size=3519, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=512, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=512, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX/logs"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX/logs"", 0x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=512, ...}) = 0; mkdir(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX/logs"", 0777) = 0; write(2, ""Logs will be written to "", 24Logs will be written to ) = 24; write(2, ""/dcl01/lieber/ajaffe/lab/libd_al""..., 81/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX/logs) = 81; write(2, ""\n"", 1; ) = 1; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX/libParams"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX/libParams"", 0x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10001_D2B1WACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=512, ...}",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:30299,log,logs,30299,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,2,['log'],['logs']
Testability,"ndex_test/salmon_0.8.2_index_gencode.v25.transcripts }; ### [ threads ] => { 1 }; ### [ libType ] => { ISR }; ### [ mates1 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10002_C29P7ACXX.fastq.gz }; ### [ mates2 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10002_C29P7ACXX_read2.fastq.gz }; ### [ output ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX }; ) = 594; stat(""/etc/localtime"", {st_mode=S_IFREG|0644, st_size=3519, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=512, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=512, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX/logs"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX/logs"", 0x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=512, ...}) = 0; mkdir(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX/logs"", 0777) = 0; write(2, ""Logs will be written to "", 24Logs will be written to ) = 24; write(2, ""/dcl01/lieber/ajaffe/lab/libd_al""..., 81/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX/logs) = 81; write(2, ""\n"", 1; ) = 1; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX/libParams"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX/libParams"", 0x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10002_C29P7ACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=512, ...}",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:147976,log,logs,147976,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,2,['log'],['logs']
Testability,"ne is split into two version by exon skipping and is not alternatively spliced. I also want to make this process fast as the idea would be to look for differences in the proportions of gene versions that are created based on a large databases of RNAseq data (easily 200+ different RNAseq experiments). So to make it quick I am only passing two transcripts to Salmon (T - 1, and T - 2) for version 1 and 2 of the transcript, where version 2 has the 2nd exon (of 4 total exons) removed. . Now I know Salmon was created to map reads to a large number of transcripts across the whole genome, but I believe it still should be possible to narrow down the view to only 1 gene with 2 versions. I believe I just need to set the parameters right, but I also want to set the parameters in a general way so that my script can work across different species with different input RNAseq data. The other problem is that we currently do not have an idea of what proportion of these two versions of the gene should actually exist in the RNAseq data I have (which we didn't perform but just grabbed a random sample from GenBank to test with). My adviser wants to first try and test it computationally first and then verify it in the lab (which is somewhat backwards in my mind, as it's really just a shot in the dark and from my preliminary analysis of Salmon, different parameters can drastically change the proportions of the two versions). . As you can see below, I have tried some parameter settings that I thought would be helpful (particularly ```--quasiCoverage```). But again I could be wrong and would like to know your opinions in the matter. . These runs were all performed with this 'default' run: ; ```; salmon quant -i index -l A -1 reads_1.fq -2 reads_2.fq --validateMappings -p 20 --numPreAuxModelSamples 250 --numAuxModelSamples 1000 -o output ; ```; I changes the ```AuxModelSamples``` to low values as I was generally only mapping 6000 reads to the two transcripts in total, so I didn't think they we",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/401:1769,test,test,1769,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/401,1,['test'],['test']
Testability,"ned_BC""$bc""_aligned.bam"" -o ""BC""$bc""_transcripts_quant"". done; ```; Salmon version was `1.9.0`; Transcriptome ref: Homo Sapiens Gencode v.44. The directories were generated for the barcodes and contain `aux info`, `cmd_info.json`, `libParams` and `logs` but the directories/files are empty. The command was run through `slurm` scheduler on HPC cluster. The output log looks like (repeated for `for` loop):; ```; Version Info: ### PLEASE UPGRADE SALMON ###; ### A newer version of salmon with important bug fixes and improvements is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; Sign up for the salmon mailing list to hear about new versions, features and updates at:; https://oceangenomics.com/subscribe; # salmon (alignment-based) v1.9.0; # [ program ] => salmon ; # [ command ] => quant ; # [ ont ] => { }; # [ targets ] => { /scratch/users/k19022845/refgenome/gencode.v44.transcripts.fa }; # [ libType ] => { A }; # [ alignments ] => { combined_BC01_aligned.bam }; # [ output ] => { BC01_trascripts_quant }; Logs will be written to BC01_trascripts_quant/logs; [2023-11-04 16:49:44.093] [jointLog] [info] setting maxHashResizeThreads to 8; [2023-11-04 16:49:44.093] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; Library format { type:single end, relative orientation:none, strandedness:unstranded }; [2023-11-04 16:49:44.699] [jointLog] [info] numQuantThreads = 4; parseThreads = 4; Checking that provided alignment files have consistent headers . . . done; Populating targets from aln = ""combined_BC01_aligned.bam"", fasta = ""/scratch/users/k19022845/refgenome/gencode.v44.transcripts.fa"" . . .done. processed 0 reads in current round/var/lib/slurm/slurmd/job10333001/slurm_script: line 25: 2152693 Bus error (core dumped); ```. Any advice on this would be highly appreciated!",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/898:1705,Log,Logs,1705,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/898,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"nfo] Building 64-bit suffix array (length of generalized text is 2654911539 ); Building suffix array . . . success; saving to disk . . . done; Elapsed time: 126.003s; done; Elapsed time: 883.472s; processed 615000000 positionssalmon: /home/vagrant/salmon/external/install/include/sparsehash/internal/densehashtable.h:782: void google::dense_hashtable<Value, Key, HashFcn, ExtractKey, SetKey, EqualKey, Alloc>::clear_to_size(google::dense_hashtable<Value, Key, HashFcn, ExtractKey, SetKey, EqualKey, Alloc>::size_type) [with Value = std::pair<const long unsigned int, rapmap::utils::SAInterval<long int> >; Key = long unsigned int; HashFcn = rapmap::utils::KmerKeyHasher; ExtractKey = google::dense_hash_map<long unsigned int, rapmap::utils::SAInterval<long int>, rapmap::utils::KmerKeyHasher, std::equal_to<long unsigned int>, google::libc_allocator_with_realloc<std::pair<const long unsigned int, rapmap::utils::SAInterval<long int> > > >::SelectKey; SetKey = google::dense_hash_map<long unsigned int, rapmap::utils::SAInterval<long int>, rapmap::utils::KmerKeyHasher, std::equal_to<long unsigned int>, google::libc_allocator_with_realloc<std::pair<const long unsigned int, rapmap::utils::SAInterval<long int> > > >::SetKey; EqualKey = std::equal_to<long unsigned int>; Alloc = google::libc_allocator_with_realloc<std::pair<const long unsigned int, rapmap::utils::SAInterval<long int> > >; google::dense_hashtable<Value, Key, HashFcn, ExtractKey, SetKey, EqualKey, Alloc>::size_type = long unsigned int]: Assertion table' failed.; Aborted; ```. I also checked the log file and it shows nothing except. ```; more indexing.log; [2016-03-17 10:41:34.655] [jointLog] [info] building index; ```. output:. ```; -rw-r--r-- 1 vdas DPT 59 Mar 17 10:41 indexing.log; -rw-r--r-- 1 vdas DPT 331863951 Mar 17 10:42 rsd.bin; -rw-r--r-- 1 vdas DPT 2654912013 Mar 17 10:43 txpInfo.bin; -rw-r--r-- 1 vdas DPT 21239292320 Mar 17 10:59 sa.bin; ```. So can you give me a workaround or inputs to solve this issue? Thanks",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/49:2912,log,log,2912,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/49,3,['log'],['log']
Testability,ng-based) v0.11.1 and was installed through bioconda.; The command being run is:. ```; salmon quant -i /data2/csijcs/hg38/hg38.transcriptome.index -l A \; -1 ${dir}/${samp}/${samp}_R1_001.fastq.gz \; -2 ${dir}/${samp}/${samp}_R2_001.fastq.gz \; -p 16 -o ${dir}/salmon_quants/${samp}; ```. The output is:; ```; Processing sample PBMC_AML_BM_001; Version Info: This is the most recent version of Salmon.; ### salmon (mapping-based) v0.11.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /data2/csijcs/hg38/hg38.transcriptome.index }; ### [ libType ] => { A }; ### [ mates1 ] => { /data2/csijcs/AML/RNA_seq/AML_total_MNC/total_MNCs/Fresh_samples/PBMC_AML_BM_001/PBMC_AML_BM_001_R1_001.fastq.gz }; ### [ mates2 ] => { /data2/csijcs/AML/RNA_seq/AML_total_MNC/total_MNCs/Fresh_samples/PBMC_AML_BM_001/PBMC_AML_BM_001_R2_001.fastq.gz }; ### [ threads ] => { 16 }; ### [ output ] => { /data2/csijcs/AML/RNA_seq/AML_total_MNC/total_MNCs/Fresh_samples/salmon_quants/PBMC_AML_BM_001 }; Logs will be written to /data2/csijcs/AML/RNA_seq/AML_total_MNC/total_MNCs/Fresh_samples/salmon_quants/PBMC_AML_BM_001/logs; [2018-07-30 15:41:42.232] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2018-07-30 15:41:42.232] [jointLog] [info] parsing read library format; [2018-07-30 15:41:42.232] [jointLog] [info] There is 1 library.; [2018-07-30 15:41:45.840] [jointLog] [info] Loading Quasi index; [2018-07-30 15:41:45.840] [jointLog] [info] Loading 32-bit quasi index; [2018-07-30 15:41:45.840] [stderrLog] [info] Loading Suffix Array ; [2018-07-30 15:42:39.168] [stderrLog] [info] Loading Transcript Info ; [2018-07-30 15:42:53.599] [stderrLog] [info] Loading Rank-Select Bit Array; [2018-07-30 15:42:56.236] [stderrLog] [info] There were 203027 set bits in the bit array; [2018-07-30 15:42:56.328] [stderrLog] [info] Computing transcript lengths; [2018-07-30 15:42:56.329] [stderrLog] [info] Waiting to finish loading hash; [2018-07,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/261:1447,Log,Logs,1447,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/261,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"ng. **To Reproduce**; Steps and data to reproduce the behavior:. I followed the alevin-fry tutorial to generate a splici transcriptome, using the same [Human reference (GRCh38) dataset](https://cf.10xgenomics.com/supp/cell-exp/refdata-gex-GRCh38-2020-A.tar.gz) provided by the tutorial. My snakemake rule to build the index uses the same commands outlined in the alevin-fry tutorial, and looks like this:. ```; rule build_idx: ; # build a splici (spliced + intron) index for alevin-fry; input:; fasta = ""{out_data}/ref/transcriptome/transcriptome_splici_fl86.fa""; output:; ""{out_data}/ref/idx/complete_ref_lens.bin"",; ""{out_data}/ref/idx/ctable.bin"",; ""{out_data}/ref/idx/ctg_offsets.bin"",; ""{out_data}/ref/idx/duplicate_clusters.tsv"",; ""{out_data}/ref/idx/info.json"",; ""{out_data}/ref/idx/mphf.bin"",; ""{out_data}/ref/idx/pos.bin"",; ""{out_data}/ref/idx/pre_indexing.log"",; ""{out_data}/ref/idx/rank.bin"",; ""{out_data}/ref/idx/refAccumLengths.bin"",; ""{out_data}/ref/idx/ref_indexing.log"",; ""{out_data}/ref/idx/reflengths.bin"",; ""{out_data}/ref/idx/refseq.bin"",; ""{out_data}/ref/idx/seq.bin"",; ""{out_data}/ref/idx/versionInfo.json""; params:; job_name = ""build_idx"",; memory = ""select[mem>64] rusage[mem=64]"",; out_dir = ""{out_data}/ref/idx""; log:; ""logs/build_idx.out""; threads:; 16; shell:; """"""; salmon index \; -t {input.fasta} \; -i {params.out_dir} \; -p {threads}; """"""; ```. Running this rule does generate all the expected output files, including `versionInfo.json`. My pipeline crashes during the next step, where I am attempting to map reads. Again, I followed the code as outlined by the alevin-fry tutorial (tweaked slightly) and my snakemake rule is as follows (apologies that I am still using the deprecated --end, --barcodeLength and --umiLength options; my intention was to update those once I had my pipeline working, but I've gotten stuck on the index build):. ```; rule map_reads: ; # map reads and generate a RAD (Reduced Alignment Data) file; input:; R1 = ""{out_data}/preprocessed_fas",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/713:2436,log,log,2436,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/713,1,['log'],['log']
Testability,"ng] If you wish to retain duplicate transcripts, please use the `--keepDuplicates` flag; [2019-10-04 10:37:22.318] [ff::console] [info] Replaced 1,775,734,603 non-ATCG nucleotides; [2019-10-04 10:37:22.318] [ff::console] [info] Clipped poly-A tails from 422 transcripts; wrote 593292 cleaned references; seqHash 256 : bd425816a78195ed31cf17ce9df99c2bf56bff98f0df5ace1e958b263d805390; seqHash 512 : 845b625de6f8f018796e464f7c49f6596d2b31b28a58771d56ece24b3d9cad98b8189572ff43d6a3eb8ef24b5d3bc5ac0f89845a57e3682498a56a1bc920e7b7; nameHash 256 : 3bd11eac1e6b05e93689676ca056c165e7c26723c4b137fd284bb8b40ef5df62; nameHash 512 : e68449cfd99f5968182735275b00779b8a396e413a3629beef933e51bd18902c821c26e2a5461c687d023ef85168e58d76bacd5fe1f0a3111bfccc34af9c4035; [2019-10-04 10:37:37.931] [console] [info] Filter size not provided; estimating from number of distinct k-mers; [2019-10-04 10:38:33.012] [console] [info] ntHll estimated 2765935300 distinct k-mers, setting filter size to 2^36; Threads = 8; Vertex length = 31; Hash functions = 5; Filter size = 68719476736; Capacity = 2; Files:; test_pufferfish_index/ref_k31_fixed.fa; --------------------------------------------------------------------------------; Round 0, 0:68719476736; Pass Filling Filtering; 1 385 3124; 2 1258 2; True junctions count = 5437144; False junctions count = 4410615; Hash table size = 9847759; Candidate marks count = 26276463; --------------------------------------------------------------------------------; Reallocating bifurcations time: 6; True marks count: 20290262; Edges construction time: 5004; --------------------------------------------------------------------------------; Distinct junctions = 5437144. approximateContigTotalLength: 1543877663; counters:; 49076 936 921 40; Exception : [std::bad_alloc]; ./testing/src/novartis-pisces/pisces/redist/salmon/bin/salmon index was invoked improperly.; For usage information, try ./testing/src/novartis-pisces/pisces/redist/salmon/bin/salmon index --help; Exiting.; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/432#issuecomment-538547108:2016,test,testing,2016,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/432#issuecomment-538547108,2,['test'],['testing']
Testability,"nning this rule does generate all the expected output files, including `versionInfo.json`. My pipeline crashes during the next step, where I am attempting to map reads. Again, I followed the code as outlined by the alevin-fry tutorial (tweaked slightly) and my snakemake rule is as follows (apologies that I am still using the deprecated --end, --barcodeLength and --umiLength options; my intention was to update those once I had my pipeline working, but I've gotten stuck on the index build):. ```; rule map_reads: ; # map reads and generate a RAD (Reduced Alignment Data) file; input:; R1 = ""{out_data}/preprocessed_fastqs/{sample}_R1.fastq.gz"",; R2 = ""{out_data}/preprocessed_fastqs/{sample}_R2.fastq.gz"",; idx = rules.build_idx.output,; tgmap = ""{out_data}/ref/transcriptome/transcriptome_splici_fl86_t2g.tsv""; output:; ""{out_data}/{sample}/map/alevin/alevin.log"",; ""{out_data}/{sample}/map/aux_info/meta_info.json"",; ""{out_data}/{sample}/map/cmd_info.json"",; ""{out_data}/{sample}/map/libParams"",; ""{out_data}/{sample}/map/logs/salmon_quant.log"",; ""{out_data}/{sample}/map/map.rad"",; ""{out_data}/{sample}/map/unmapped_bc_count.bin"",; params:; job_name = ""map_reads"",; memory = ""select[mem>64] rusage[mem=64]"",; library_type = ""ISR"",; end = 5,; barcodeLength = 16,; umiLength = 8,; out_dir = ""{out_data}/{sample}/map""; log:; ""logs/map_reads/{sample}.out""; threads:; 16; shell:; """"""; salmon alevin \; -l {params.library_type} \; -1 {input.R1} \; -2 {input.R2} \; -i {input.idx} \; -p {threads} \; -o {params.out_dir} \; --tgMap {input.tgmap} \; --end {params.end} \; --barcodeLength {params.barcodeLength} \; --umiLength {params.umiLength} \; --keepCBFraction 1 \; --sketch; """"""; ```. Specifically, please provide at least the following information:. * Which version of salmon was used? v1.5.2; * How was salmon installed (compiled, downloaded executable, through bioconda)? Downloaded [this](https://github.com/COMBINE-lab/salmon/releases/tag/v1.5.2) binary; * Which reference (e.g. transcriptome) ",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/713:3861,log,logs,3861,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/713,1,['log'],['logs']
Testability,"noarch:graphics-4.0-amd64:graphics-4.0-noarch:printing-4.0-amd64:printing-4.0-noarch; Distributor ID:	Scientific; Description:	Scientific Linux release 6.4 (Carbon); Release:	6.4; Codename:	Carbon; ```. Do you have any idea what can be the causing the error?. Thanks. We are using the precompiled salmon bin and running it with:. `salmon quant -i $index -1 $f1 -2 $f2 -o $output_folder --meta --incompatPrior 0.0 --libType A -p 8 --gcBias --seqBias --numBootstraps 30`. ```; Version Info: This is the most recent version of Salmon.; ### salmon (mapping-based) v0.8.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { ./storage/tmm.idx }; ### [ mates1 ] => { DNA_1.fastq.gz }; ### [ mates2 ] => {DNA_2.fastq.gz }; ### [ output ] => { /DNA_tmm }; ### [ meta ] => { }; ### [ incompatPrior ] => { 0.0 }; ### [ libType ] => { A }; ### [ threads ] => { 8 }; ### [ gcBias ] => { }; ### [ seqBias ] => { }; ### [ numBootstraps ] => { 30 }; Logs will be written to ./storage/logs; [2017-03-15 11:53:20.568] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2017-03-15 11:53:20.568] [jointLog] [info] parsing read library format; [2017-03-15 11:53:20.568] [jointLog] [info] There is 1 library.; [2017-03-15 11:53:20.653] [jointLog] [info] Loading Quasi index; [2017-03-15 11:53:20.683] [jointLog] [info] Loading 64-bit quasi index; [2017-03-15 11:53:20.684] [stderrLog] [info] Loading Suffix Array ; [2017-03-15 12:19:05.982] [stderrLog] [info] Loading Transcript Info ; Exception : [Failed to read 130159192 bytes from input stream! Read 65079596]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting.; ```. Index building log:. ```; Version Info: This is the most recent version of Salmon.; index ["" ./storage/tmm.idx""] did not previously exist . . . creating it; [2017-03-14 12:10:34.791] [jLog] [info] building index; RapMap Indexer. [Step 1 of 4] : counting k-mers; counted k-mers",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/129:1550,log,logs,1550,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/129,1,['log'],['logs']
Testability,not sure what's the best way to share the 34G fastqs for your test.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/340#issuecomment-458713282:62,test,test,62,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/340#issuecomment-458713282,1,['test'],['test']
Testability,"nt:; read1 [SRR3212847.24133171] : no proper-pair; not mapped; matenot mapped. read2 : [SRR3212847.24133171] : proper-pair; mapped; matemapped. [2021-01-08 12:42:10.700] [jointLog] [warning] . WARNING: Detected suspicious pair --- ; The names are different:; read1 : SRR3212847.33911054; read2 : SRR3212847.30781941. Segmentation fault (core dumped); ```. ### 3. Sorting with `samtools sort -n`; ```; samtools sort \; -@ 40 \; -n \; -o SRR3212847.Aligned.SortedByName.bam \; SRR3212847.Aligned.SortedByCoord.bam. salmon quant \; -t mRNA.fasta \; -p 20 \; -l A \; -a SRR3212847.Aligned.SortedByName.bam \; -o SRR3212847.Aligned.SortedByName; ```. ```; Version Info: This is the most recent version of salmon.; # salmon (alignment-based) v1.4.0; # [ program ] => salmon ; # [ command ] => quant ; # [ targets ] => { mRNA.fasta }; # [ threads ] => { 20 }; # [ libType ] => { A }; # [ alignments ] => { SRR3212847.Aligned.SortedByName.bam }; # [ output ] => { SRR3212847.Aligned.SortedByName }; Logs will be written to SRR3212847.Aligned.SortedByName/logs; [2021-01-08 13:02:04.845] [jointLog] [info] setting maxHashResizeThreads to 20; [2021-01-08 13:02:04.845] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; Library format { type:paired end, relative orientation:inward, strandedness:unstranded }; [2021-01-08 13:02:04.878] [jointLog] [info] numQuantThreads = 14; parseThreads = 6; Checking that provided alignment files have consistent headers . . . done; Populating targets from aln = ""SRR3212847.Aligned.SortedByName.bam"", fasta = ""mRNA.fasta"" . . .done. processed 0 reads in current roundSegmentation fault (core dumped); ```; (Which is the same as the 1st error. Actually, each time I re-run those two errors switched.). I tried running Salmon on the sorted-by-coordinates bam, and it didn't fail:; ```; nohup salmon quant \; -t mRNA.fasta \; -p 20 \; -l A \; -a SRR3212847.Aligned.SortedByCoord.bam \; -o SRR3212847.Aligned.SortedByCoord",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/582#issuecomment-756727212:3520,Log,Logs,3520,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/582#issuecomment-756727212,1,['Log'],['Logs']
Testability,"nyone could pull me out, I would appreciate it. . I index the bins using the default kmer(31), and the length of reads is PE150. And the following is the command I use:; `salmon quant -i assembly_index/ -l A -1 9998_1.fastq.gz -2 9998_2.fastq.gz -p 100 -o 9998.quant --meta`. The log file:; ```{shell}; $cat lib_format_counts.json ; {; ""read_files"": [; ""/share/work/HPC/work_tmp/liangyong/BinningMappingRateLow/9998_1.fastq.gz"",; ""/share/work/HPC/work_tmp/liangyong/BinningMappingRateLow/9998_2.fastq.gz""; ],; ""expected_format"": ""IU"",; ""compatible_fragment_ratio"": 1.0,; ""num_compatible_fragments"": 8925446,; ""num_assigned_fragments"": 8925446,; ""num_frags_with_concordant_consistent_mappings"": 2169449,; ""num_frags_with_inconsistent_or_orphan_mappings"": 10821303,; ""strand_mapping_bias"": 0.5001592570279366,; ""MSF"": 0,; ""OSF"": 0,; ""ISF"": 1084379,; ""MSR"": 0,; ""OSR"": 0,; ""ISR"": 1085070,; ""SF"": 5409839,; ""SR"": 5411464,; ""MU"": 0,; ""OU"": 0,; ""IU"": 0,; ""U"": 0; }. ```. Another log file in the folder of logs:; ```{shell}; $cat salmon_quant.log ; [2023-03-07 06:47:10.266] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2023-03-07 06:47:10.266] [jointLog] [warning] . NOTE: It appears you are running salmon without the `--validateMappings` option.; Mapping validation can generally improve both the sensitivity and specificity of mapping,; with only a moderate increase in use of computational resources. ; Mapping validation is planned to become a default option (i.e. turned on by default) in; the next release of salmon.; Unless there is a specific reason to do this (e.g. testing on clean simulated data),; `--validateMappings` is generally recommended. [2023-03-07 06:47:10.266] [jointLog] [info] parsing read library format; [2023-03-07 06:47:10.266] [jointLog] [info] There is 1 library.; [2023-03-07 06:47:10.412] [jointLog] [info] Loading Quasi index; [2023-03-07 06:47:10.412] [jointLog] [info] Loading 64-bit quasi index; [2023-03-0",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/838:1477,log,log,1477,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/838,2,['log'],"['log', 'logs']"
Testability,"o lieber_jaffe 6.2G Feb 20 12:39 merged_fastq/R10001_D2B1WACXX.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 6.3G Feb 20 12:40 merged_fastq/R10001_D2B1WACXX_read2.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 4.6G Feb 20 12:42 merged_fastq/R10002_C29P7ACXX.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 4.7G Feb 20 12:44 merged_fastq/R10002_C29P7ACXX_read2.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 7.1G Feb 20 12:47 merged_fastq/R10003_D19KGACXX.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 7.1G Feb 20 12:50 merged_fastq/R10003_D19KGACXX_read2.fastq.gz; ```. where R10001* is task 1, R10002* is task 2, R10003* is task 3. So it looks like at some point Salmon is asking for some memory based on the input data. ## Strace test with low memory (but above reported usage when requesting 90GB). Mark taught me about `strace` and we ran the following test:. ```bash; #!/bin/bash; #$ -cwd; #$ -pe local 2; #$ -l mem_free=7G,h_vmem=8G,h_fsize=100G; #$ -N step6-salmon_test11.gsk_phaseII; #$ -o ./logs/salmon_test11.$TASK_ID.txt; #$ -e ./logs/salmon_test11.$TASK_ID.txt; #$ -t 1-3; #$ -hold_jid pipeline_setup,step4-featCounts-alzheimer.gsk_phaseII; #$ -m e; echo ""**** Job starts ****""; date. echo ""**** JHPCE info ****""; echo ""User: ${USER}""; echo ""Job id: ${JOB_ID}""; echo ""Job name: ${JOB_NAME}""; echo ""Hostname: ${HOSTNAME}""; echo ""Task id: ${TASK_ID}"". FILE1=$(awk 'BEGIN {FS=""\t""} {print $1}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); if [ TRUE == ""TRUE"" ] ; then; FILE2=$(awk 'BEGIN {FS=""\t""} {print $3}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); fi; ID=$(cat /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk '{print $NF}' | awk ""NR==${SGE_TASK_ID}""). mkdir -p /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/${ID}. strace /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant 	-i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/A",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:2439,log,logs,2439,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['log'],['logs']
Testability,"ode M34 (GRCm39) ; * Which read files were used?; * Illumina HiSeq, trimmed using Trimmomatic ; * Which which program options were used?. Working:. ./salmon/bin/salmon quant -p 64 --index reference/salmon_index -l ISR -1 merged/1791-${id}_1P.fastq.gz -2 merged/1791-${id}_2P.fastq.gz --validateMappings --seqBias --gcBias --posBias --softclip --allowDovetail --numBootstraps 10 -o mapped/salmon_${id}. Working produced the following file structure:. ```; salmon_03; ├── aux_info; │   ├── ambig_info.tsv; │   ├── bootstrap; │   │   ├── bootstraps.gz; │   │   └── names.tsv.gz; │   ├── exp3_pos.gz; │   ├── exp3_seq.gz; │   ├── exp5_pos.gz; │   ├── exp5_seq.gz; │   ├── expected_bias.gz; │   ├── exp_gc.gz; │   ├── fld.gz; │   ├── meta_info.json; │   ├── obs3_pos.gz; │   ├── obs3_seq.gz; │   ├── obs5_pos.gz; │   ├── obs5_seq.gz; │   ├── observed_bias_3p.gz; │   ├── observed_bias.gz; │   └── obs_gc.gz; ├── cmd_info.json; ├── lib_format_counts.json; ├── libParams; │   └── flenDist.txt; ├── logs; │   └── salmon_quant.log; └── quant.sf. 5 directories, 23 files; ```. Not working:. ./salmon/bin/salmon quant -p 64 --index reference/salmon_index -l ISR -1 merged/1791-${id}_1P.fastq.gz -2 merged/1791-${id}_2P.fastq.gz --validateMappings --seqBias --gcBias --posBias --softclip --allowDovetail --recoverOrphans --numBootstraps 10 -o mapped/salmon_${id}. Not working produced the following file structure:. ```; salmon_03_withRecover; ├── aux_info; ├── libParams; └── logs; └── salmon_quant.log. 4 directories, 1 file; ```. The file `mapped/salmon_03_withRecover/logs/salmon_quant.log` has nothing inside it. **Expected behavior**. Properly-mapped reads, as demonstrated by the following metadata:. ```; {; ""salmon_version"": ""1.10.0"",; ""samp_type"": ""bootstrap"",; ""opt_type"": ""vb"",; ""quant_errors"": [],; ""num_libraries"": 1,; ""library_types"": [; ""ISR""; ],; ""frag_dist_length"": 1001,; ""frag_length_mean"": 158.48833607498765,; ""frag_length_sd"": 54.34014977759742,; ""seq_bias_correct"": true,; ""gc_bias_correc",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/929:1939,log,logs,1939,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/929,1,['log'],['logs']
Testability,"odel for data generated from any technology and that's what we have been trying to do with salmon for years, piece by piece. Having said that, we don't mean to discourage people from trying salmon, that's one of the way we learn how can we improve the model even further. Now, coming back to your original question about using QuantSeq with salmon and how the paper above approach to solve it. I have a couple of thoughts:; 1.) Like you said, from the reading of their command line argument they didn't use the `nolengthcorrection` and I am surprised about the results myself. Since you have experience with the technology, you are best person to explore the difference in using and not using the length correction with salmon, that's why I shared.; 2.) Salmon models the transcript lengths in its quantification model. The basic intuition being longer length transcripts have higher probability of a read being sampled from them and has to be corrected for when using relative count metrices (like TPM) to avoid length bias. The logic behind `noLengthCorrection` is to _not_ correct for length for 3' protocol since we expect all the reads from one end of the transcript and if we do length correction, I hypothesize, we might end up biasing the estimates on the opposite direction; however the effect size of this hypothesis is still an open question and seemingly from the results from the paper it has minor effect. On the flip side may be it does have effect but their baseline estimates were not great and any improvement is good, for that again since you have experience with the data it's good to know / test what's going on.; 3.) A little experimental thought, although `noLengthCorrection` flag can generate decent estimates, it's actually fully disabling the length effect, which in my opinion we can do better as you look at Figure 1B of the paper it shows some length based affect but again we don't know how much difference it can create in generating the estimates. . I Hope it helps .",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565256512:2013,log,logic,2013,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565256512,4,"['log', 'test']","['logic', 'test']"
Testability,"og] [info] chunk 5 = [185,776,605, 222,931,953); [2021-12-31 11:28:47.220] [puff::index::jointLog] [info] chunk 6 = [222,931,953, 260,087,274); [2021-12-31 11:28:47.220] [puff::index::jointLog] [info] chunk 7 = [260,087,274, 297,242,536); [2021-12-31 11:28:57.275] [puff::index::jointLog] [info] finished populating pos vector; [2021-12-31 11:28:57.275] [puff::index::jointLog] [info] writing index components; [2021-12-31 11:28:59.670] [puff::index::jointLog] [info] finished writing dense pufferfish index; [2021-12-31 11:28:59.944] [jLog] [info] done building index; Threads = 8; Vertex length = 29; Hash functions = 5; Filter size = 4294967296; Capacity = 2; Files: ; /no_backup/indexes/salmon/mm10_gencode/ref_k29_fixed.fa; --------------------------------------------------------------------------------; Round 0, 0:4294967296; Pass	Filling	Filtering; 1	22	34	; 2	9	0; True junctions count = 1275494; False junctions count = 1606379; Hash table size = 2881873; Candidate marks count = 14783512; --------------------------------------------------------------------------------; Reallocating bifurcations time: 0; True marks count: 12564712; Edges construction time: 10; --------------------------------------------------------------------------------; Distinct junctions = 1275494. for info, total work write each : 2.331 total work inram from level 3 : 4.322 total work raw : 25.000 ; Bitarray 1252655360 bits (100.00 %) (array + ranks ); final hash 0 bits (0.00 %) (nb in final hash 0); ```. And these files are present in the index folder:; ```; ls -1 /no_backup/indexes/salmon/mm10_gencode; complete_ref_lens.bin; ctable.bin; ctg_offsets.bin; duplicate_clusters.tsv; info.json; mphf.bin; pos.bin; pre_indexing.log; rank.bin; refAccumLengths.bin; ref_indexing.log; reflengths.bin; refseq.bin; seq.bin; versionInfo.json; ```. So the problem was that the transcript file I provided to the `generateDecoyTranscriptome.sh` was gzipped and failed with `cat`.... 🤦‍♂️. Thanks a lot the help!; Nicco",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/731#issuecomment-1003342883:6582,log,log,6582,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/731#issuecomment-1003342883,2,['log'],['log']
Testability,"ogram_options); message(""BOOST_INCLUDEDIR = ${BOOST_INCLUDEDIR}""); message(""BOOST_LIBRARYDIR = ${BOOST_LIBRARYDIR}""); message(""Boost_FOUND 1.57.0 = ${Boost_FOUND}""); set(Boost_FOUND ""1""); message(""Boost_FOUND FORCED = ${Boost_FOUND}""); include(ExternalProject); ```; This emits:; ```. -- Could NOT find Boost; Boost_FOUND 1.57 = 0; -- Could NOT find Boost; BOOST_INCLUDEDIR = /usr/include/boost157; BOOST_LIBRARYDIR = /usr/lib64; Boost_FOUND 1.57.0 = 0; Boost_FOUND FORCED = 1; BOOST INCLUDE DIR = /usr/include/boost157; BOOST INCLUDE DIRS = /usr/include/boost157; BOOST LIB DIR = /usr/lib64; BOOST LIBRARIES = ; ```; That at least allowed cmake to complete when it was run with:. `nice scl enable devtoolset-4 '~/bin/cmake -DCMAKE_VERBOSE_MAKEFILE:BOOL=ON -DBoost_NO_BOOST_CMAKE=BOOL:ON -DBOOST_LIBRARYDIR=/usr/lib64 -DBOOST_INCLUDEDIR=/usr/include/boost157 ../CMakeLists.txt' >try_cmake.log 2>&1 &; `. Then tried to build it. ```; cd ..; nice scl enable devtoolset-4 'make' >build_2018_06_13d.log 2>&1 &. ```. It failed at this command because of missing boost symbols in a link operation, my reading is that the command does not include anything to link boost libraries. So telling cmake where the libraries are, where the include files are, and that boost was found was not sufficient. There must be some other set of symbols which need to be defined. `/opt/rh/devtoolset-4/root/usr/bin/c++ -pthread -ftree-vectorize -funroll-loops -fPIC -fomit-frame-pointer -O3 -DRAPMAP_SALMON_SUPPORT -DHAVE_ANSI_TERM -DHAVE_SSTREAM -Wall -Wno-unknown-pragmas -Wno-reorder -Wno-unused-variable -std=c++11 -Wreturn-type -Werror=return-type -Wno-unused-function -Wno-unused-local-typedef -static-libstdc++ -Wno-unused-local-typedefs -pthread -ftree-vectorize -funroll-loops -fPIC -fomit-frame-pointer -O3 -DRAPMAP_SALMON_SUPPORT -DHAVE_ANSI_TERM -DHAVE_SSTREAM -Wall -Wno-unknown-pragmas -Wno-reorder -Wno-unused-variable -std=c++11 -Wreturn-type -Werror=return-type -Wno-unused-function -Wno-unused-local-typedef",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-397025719:1583,log,log,1583,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-397025719,1,['log'],['log']
Testability,"oh, Then can I rm duplicate identical reads in my bam file? Will this affect my results?; because i got the warning in log file: ; ![image](https://user-images.githubusercontent.com/45484925/211450308-2c13c0c6-7a63-4a08-9658-d991c4bf285a.png); and i check the bam file, actually, there are indeed three identical reads, its not paired,so got the warnings.(may be another read was filtered).; ![image](https://user-images.githubusercontent.com/45484925/211451982-e5c9dc34-b9f9-4120-82b0-4827aa4ffd92.png). So I wonder if duplicate reads can be deleted?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/822#issuecomment-1376654942:119,log,log,119,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/822#issuecomment-1376654942,1,['log'],['log']
Testability,"okies, I think I see the issue. So look at the following lines in the log:; ```; [2019-06-17 21:21:44.518] [alevinLog] [info] Total 824863; [2019-06-17 21:22:47.680] [alevinLog] [info] Total Unique barcodes found: 3474567; ```; What it means is alevin found total: `3,474,567` unique CB in the whole sample and keeps `824,863` CB for further processing which is ~23% of the CB. So all the `keepCBFraction` values above 0.23 would have no effect. If you wan't to generate the `whitelist.txt`, alevin has to have some low confidence CB to learn from, so I am guessing in your case any value from 0.15-0.20 should ideally work. Having said that, I am still exploring why even setting `freqThreshold` to 0, alevin not considers all `3M` CB for processing, I guess there is some kind of filter which is coming into the picture but I might need a bit more time to explore that. I will update here once I figure it out. Thanks again for raising the issue and investing your time in improving alevin.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/379#issuecomment-503344686:70,log,log,70,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/379#issuecomment-503344686,2,['log'],['log']
Testability,"omatic adapter detection](https://github.com/OpenGene/fastp/issues/240). - [inconsistent behavior with different runs](https://github.com/OpenGene/fastp/issues/231). 3. When I see the above, I am bit skeptical using fastp for qc/adapter trimming. . After lot of trials with bbduk and fastp, I have decided to use bbduk and bbmap for my high throughput analysis. Below, I explain my reasoning behind those choices: . **_```Note - edited this on 02-Apr-2020 to have the correct order of operations ```_** . 1. **_STEP 1 - run bbmap.sh on raw fatsq file to remove contaminants as appropriate (rRNA, mitochondrial, chloroplast)_**; - You have alluded to the importance of removing contaminants [in this post](https://github.com/COMBINE-lab/salmon/issues/160#issuecomment-334762498); >However, the other thing to try is simply to align one of these samples to the genome with a tool like STAR or HISAT2 and look at their mapping rate to known features. If it's similar, then the other reads could be accounted for by e.g. intron retention or even contamination. Finally, [@vals has an excellent series of blog posts on investigating and addressing low mapping rates](http://www.nxn.se/valent/2017/9/18/low-mapping-rate-5-human-dna-contamination); - bbmap Command ([based of this biostars post](https://www.biostars.org/p/143019/#210890)):; `bbmap.sh in=read_1.fq.gz ref=rRNA_Chlor_Mito.fa maxindel=1 minid=0.95 outu=clean_read_1.fq.gz nodisk`; - Strategy:; `use the rRNA+Mito+Chloroplast file and map the reads using bbmap, then collect the unmapped reads (clean_read_1.fq.gz) for my downstream analysis`. 2. **_STEP 2 - run bbduk.sh on the outu files from bbmap step -- the outu stands for output unmapped - as stated in the logic above, anything that is unmapped to the rRNA_Chlor_Mito.fa is a clean read for downstream analysis_**. I use bbduk with adapter trimming and quality trimming in same command line - also, the adapters.fa file that ships with BBTools can be used in all runs. Hope that helps.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209:3297,log,logic,3297,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209,2,['log'],['logic']
Testability,"on for the problems you are facing in alevin. >Your first question was related to alevin quantifying very less number of reads. To answer that,; if you look at the log, at the first few lines, alevin warns about ~91% of the reads being thrown away because; of the noisy CBs. The problem is alevin’s first “knee"" estimation is overshooting in predicting the first boundary. You will find https://github.com/COMBINE-lab/salmon/issues/362 issue to be; very useful in understanding that. As a summary if you look at the plot I attached it has bi-modalities,; which is generally not the case and alevin is greedily finding the threshold at the first ~100 cells. If this; happens the general direction is to help alevin by proving a upper bound, in case of your data; would be ~14000 cells. You can tell alevin with `—expectCells 14000` and alevin start to work; normally and logs ~12% of the data is noisy. >You second question was a little complicated to answer. Seemingly, your salmon index has transcript with; same exact name `ENST00000399966.9`, occurring twice with different sequences. Just by looking at the index,; I am unsure it’s actually present in the reference or its salmon indexing messing up. If I Assume it was actually; present two times in the reference, alevin should report it instead of exiting abruptly in the middle of quantification.; Although, alevin does warns:; ```; [2019-07-04 14:12:32.519] [alevinLog] [warning] Found 1 transcripts with duplicate names; ```; >However, the bug i.e. not being able to distinguish duplicate names of the transcript, has been ; fixed and pushed in the develop branch of salmon. Alevin was reporting the error at the stage of quantification too, ; if you dump the logs in a file, but it was invisible in the console as it was over written my complex progress bar. . >Once I process it through the modified pipeline, alevin finished normally and I am attaching the quants generated; by alevin. >Thanks again for forwarding the data.; Best,; —Avi",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/386#issuecomment-508754845:1936,log,logs,1936,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/386#issuecomment-508754845,2,['log'],['logs']
Testability,"on linux, binary download of salmon: salmon-0.11.2-linux_x86_64. Trying to process some Drop-seq data. Command:. ./salmon-0.11.2-linux_x86_64/bin/salmon alevin -l A -1 data/mSpT3_S2_L001_R1_001.fastq data/mSpT3_S2_L002_R1_001.fastq -2 data/mSpT3_S2_L001_R2_001.fastq data/mSpT3_S2_L002_R2_001.fastq --dropseq -p 10 -o mSpT3 -i mouse_cdna --tgMap biomart.csv. Where I have downloaded the cdna as FASTA from biomart, and also generated a ENSMUST to ENSMUSG biomart.csv mapping file. Log is below. Since this is our first attempt at dropseq I also pulled out the first R1 and R2 sequences, in case these are somehow informative:. R1:; CAGGAGTGGATTTAGTCCTT; CGCGGAAGATGAGCATTATG; TTTCGTGCCGCCCTCCCTCG; ACAGCGACAAGGCTACCTCA; AATAGGGTCAACGATTAGAG; CGGATGGTTCCCAGCTGCCT; ACATTTCCGCGGTAGGGGGG; GTGGCAAGATTTAATATCCG. R2:; GAATANNNNNNNNNNNNNNNNNNNNAAGGATAACAGTTTCCAGTAC; GGACATTGGTCANCNNGCAGACACGGGTCAATGCGGCAAAAAACAA; GCAACNNNNNNNNNNNNNNNNNNNNGACNAGCGGGCTCACCATAAT; GNGTGNNNNNNNNNNNNNNNNNNNNCGANGTGATTTCTGCCCAGTG; CCCGACTGTNCTNNNNAAGGTCAGCAGTTCAAATCCCAGCAACCAC no hits found; GAGTGNNNNNNNNNNNNNNNCNNNGGCGGTTAGTGCTGAGAGTGCG; GCATACTGGTTGNCNNGCTGAAGTTTAAGGGCCTGGTTTTTTGAAA Cdv3 or Ncoa; GCACCCNANNNCNNNNCCGNAGNTCTGAAGATCAAATCACAGCAAA. ============================; ============================; ============================. Version Info: This is the most recent version of Salmon.; Logs will be written to mSpT3/logs; ### salmon (single-cell-based) v0.11.2; ### [ program ] => salmon ; ### [ command ] => alevin ; ### [ libType ] => { A }; ### [ mates1 ] => { data/mSpT3_S2_L001_R1_001.fastq data/mSpT3_S2_L002_R1_001.fastq }; ### [ mates2 ] => { data/mSpT3_S2_L001_R2_001.fastq data/mSpT3_S2_L002_R2_001.fastq }; ### [ dropseq ] => { }; ### [ threads ] => { 10 }; ### [ output ] => { mSpT3 }; ### [ index ] => { mouse_cdna }; ### [ tgMap ] => { biomart.csv }. [2018-08-29 11:26:45.317] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2018-08-29 11:26",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/281:481,Log,Log,481,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/281,1,['Log'],['Log']
Testability,"on/modules/el8/x86_64/software/libtbb/2020.5-CentOS-vanilla/lib/libtbb.so -lgomp /usr/lib64/libjemalloc.so -lrt ../external/pufferfish/src/libksw2pp.a libalevin_core.a -ldl -pthread ; /tmp/cc91ASWS.ltrans1.ltrans.o: In function `boost::iostreams::basic_gzip_compressor<std::allocator<char> >::basic_gzip_compressor(boost::iostreams::gzip_params const&, long) [clone .constprop.783]':; <artificial>:(.text+0xdca4): undefined reference to `boost::iostreams::detail::zlib_base::zlib_base()'; <artificial>:(.text+0xdcbc): undefined reference to `boost::iostreams::detail::zlib_base::do_init(boost::iostreams::zlib_params const&, bool, void* (*)(void*, unsigned int, unsigned int), void (*)(void*, void*), void*)'; <artificial>:(.text+0xddc8): undefined reference to `boost::iostreams::zlib::best_compression'; <artificial>:(.text+0xddd4): undefined reference to `boost::iostreams::zlib::best_speed'; /tmp/cc91ASWS.ltrans1.ltrans.o: In function `GZipWriter::writeMtx(std::shared_ptr<spdlog::logger>&, boost::filesystem::path&, unsigned long, unsigned long, unsigned long) [clone .constprop.780]':; <artificial>:(.text+0xe056): undefined reference to `boost::iostreams::zlib::default_strategy'; <artificial>:(.text+0xe05d): undefined reference to `boost::iostreams::zlib::deflated'; <artificial>:(.text+0xe2d1): undefined reference to `boost::filesystem::detail::status(boost::filesystem::path const&, boost::system::error_code*)'; ...; ```. The boost related errors go on forever. There is nothing about ""boost"" in that command line, so apparently the relevant pieces never made it into the makefile. Running that very long command line with this added on the end:. ```; -L/usr/lib64/boost169 -lboost_filesystem -lboost_system -lboost_program_options -lboost_iostreams; ```; ; let Salmon link (with no other warnings). The resulting binary will do; ""salmon -h"" correctly but has so far not been tested further. So, in short CMakeLists.txt's handling of boost is still badly broken on CentOS, 8 this time, ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641531162:3563,log,logger,3563,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/460#issuecomment-641531162,1,['log'],['logger']
Testability,"on; Install the project...; -- Install configuration: ""Release""; -- Installing: /salmon-0.10.2/lib; -- Installing: /salmon-0.10.2/lib/libtbb.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc_proxy.so; -- Installing: /salmon-0.10.2/lib/libtbbmalloc.so.2; -- Installing: /salmon-0.10.2/lib/libtbb.so.2; -- Installing: /salmon-0.10.2/lib/pkgconfig; -- Installing: /salmon-0.10.2/lib/libtbbmalloc_proxy.so.2; -- Installing: /salmon-0.10.2/bin/salmon; -- Installing: /salmon-0.10.2/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly.; ==========================================================================; Please add /salmon-0.10.2/bin to your PATH; Please add /salmon-0.10.2/lib to your LD_LIBRARY_PATH; ==========================================================================; root@e08cc9670e4a:/salmon-0.10.2/build# make test; Running tests...; Test project /salmon-0.10.2/build; Start 1: unit_tests; 1/3 Test #1: unit_tests ....................... Passed 0.17 sec; Start 2: salmon_read_test_fmd; 2/3 Test #2: salmon_read_test_fmd ............. Passed 1.78 sec; Start 3: salmon_read_test_quasi; 3/3 Test #3: salmon_read_test_quasi ........... Passed 1.59 sec. 100% tests passed, 0 tests failed out of 3. Total Test time (real) = 3.54 sec; root@e08cc9670e4a:/salmon-0.10.2/build# lsb_release -a; LSB Version: core-9.20160110ubuntu0.2-amd64:core-9.20160110ubuntu0.2-noarch:security-9.20160110ubuntu0.2-amd64:security-9.20160110ubuntu0.2-noarch; Distributor ID: Ubuntu; Description: Ubuntu 16.04.4 LTS; Release: 16.04; Codename: xenial; ```. I built with:. `$ cmake -DFETCH_BOOST=TRUE .. && make install && make test`. I can also install the boost via apt and see if that makes a difference (though I expect not since it looked like TBB was the issue, and I let cmake install that). We can also check our compiler versions, perhaps. I have : . ```; root@e08cc9670e4a:/salmon-0.10.2/build# g++ --version",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268:1947,Test,Test,1947,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/250#issuecomment-404306268,1,['Test'],['Test']
Testability,"on_mappings"",; ""validateMappings"": [],; ""gcBias"": [],; ""seqBias"": [],; ""writeUnmappedNames"": [],; ""writeMappings"": ""results/salmon/quant/ILWN_RNAseq_G002_ATCACG_Arachis_hypogaea_I801_L1_salmon_quant/ILWN_RNAseq_G002_ATCACG_Arachis_hypogaea_I801_L1_salmon_mappings"",; ""threads"": ""20"",; ""numBootstraps"": ""100"",; ""auxDir"": ""aux_info""; }; ```. </p>; </details>. <details><summary>Salmon run w/ quasi mapping method</summary>; <p>. ```python; rule salmon_index_test:; input:; tcp = TRANSCRIPTS; output:; directory(""results/salmon_test/index""); priority:1; log:; ""results/salmon_test/logs/index.log""; conda:; ""../envs/salmon.yaml""; threads:30; shell:; """"""; salmon index -p {threads} -t {input.tcp} -i {output}; """""". rule salmon_quant_test:; input:; r1=""results/trimmed/{smp}_R1_val_1.fq.gz"",; r2=""results/trimmed/{smp}_R2_val_2.fq.gz"",; index = ""results/salmon_test/index""; output:; directory(""results/salmon_test/quant/{smp}_salmon_test_quant""),; log:; ""results/salmon_test/logs/{smp}.salmon_test.log""; conda:; ""../envs/salmon.yaml""; threads:30; shell:; """"""; salmon quant -i {input.index} -l A -1 {input.r1} -2 {input.r2} -o {output} --validateMappings --gcBias --seqBias --writeUnmappedNames -p {threads} --numBootstraps 100; """"""; ```. </p>; </details>. <details><summary>Mapping rates w/ quasi mapping method</summary>; <p>. ![image](https://user-images.githubusercontent.com/42179487/73189014-b8350580-40f1-11ea-8f6a-9d7d39867a89.png). </p>; </details>. <details><summary>cmd_info.json (quasi)</summary>; <p>. ```json; {; ""salmon_version"": ""1.1.0"",; ""index"": ""results/salmon_test/index"",; ""libType"": ""A"",; ""mates1"": ""results/trimmed/ILWN_RNAseq_G002_ATCACG_Arachis_hypogaea_I801_L1_R1_val_1.fq.gz"",; ""mates2"": ""results/trimmed/ILWN_RNAseq_G002_ATCACG_Arachis_hypogaea_I801_L1_R2_val_2.fq.gz"",; ""output"": ""results/salmon_test/quant/ILWN_RNAseq_G002_ATCACG_Arachis_hypogaea_I801_L1_salmon_test_quant"",; ""validateMappings"": [],; ""gcBias"": [],; ""seqBias"": [],; ""writeUnmappedNames"": [],; ""threads"": ""30"",; ",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/479:3928,log,log,3928,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/479,1,['log'],['log']
Testability,"onsistent_mappings"": 2169449,; ""num_frags_with_inconsistent_or_orphan_mappings"": 10821303,; ""strand_mapping_bias"": 0.5001592570279366,; ""MSF"": 0,; ""OSF"": 0,; ""ISF"": 1084379,; ""MSR"": 0,; ""OSR"": 0,; ""ISR"": 1085070,; ""SF"": 5409839,; ""SR"": 5411464,; ""MU"": 0,; ""OU"": 0,; ""IU"": 0,; ""U"": 0; }. ```. Another log file in the folder of logs:; ```{shell}; $cat salmon_quant.log ; [2023-03-07 06:47:10.266] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2023-03-07 06:47:10.266] [jointLog] [warning] . NOTE: It appears you are running salmon without the `--validateMappings` option.; Mapping validation can generally improve both the sensitivity and specificity of mapping,; with only a moderate increase in use of computational resources. ; Mapping validation is planned to become a default option (i.e. turned on by default) in; the next release of salmon.; Unless there is a specific reason to do this (e.g. testing on clean simulated data),; `--validateMappings` is generally recommended. [2023-03-07 06:47:10.266] [jointLog] [info] parsing read library format; [2023-03-07 06:47:10.266] [jointLog] [info] There is 1 library.; [2023-03-07 06:47:10.412] [jointLog] [info] Loading Quasi index; [2023-03-07 06:47:10.412] [jointLog] [info] Loading 64-bit quasi index; [2023-03-07 06:51:59.707] [jointLog] [info] done; [2023-03-07 06:51:59.707] [jointLog] [info] Index contained 777288 targets; [2023-03-07 06:52:10.338] [jointLog] [info] Automatically detected most likely library type as IU; [2023-03-07 06:54:46.142] [fileLog] [info] ; At end of round 0; ==================; Observed 40535435 total fragments (40535435 in most recent round). [2023-03-07 06:54:46.141] [jointLog] [info] Computed 1249282 rich equivalence classes for further processing; [2023-03-07 06:54:46.141] [jointLog] [info] Counted 8925446 total reads in the equivalence classes ; [2023-03-07 06:54:46.282] [jointLog] [warning] 0.0015986% of fragments were shorter than the k u",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/838:2137,test,testing,2137,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/838,1,['test'],['testing']
Testability,"or**; I expected the project to build and produce a binary I could use to test my changes. **Desktop (please complete the following information):**; - OS: Ubuntu 18.04; - Version:. ```; lsb_release -a; No LSB modules are available.; Distributor ID:	Ubuntu; Description:	Ubuntu 18.04.2 LTS; Release:	18.04; Codename:	bionic; kurt@kurtputer:~/Development/refinebio-collab$ uname -a; Linux kurtputer 4.15.0-51-generic #55-Ubuntu SMP Wed May 15 14:27:21 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux; ```. **Additional context**; I was able to fix the following errors with these resolutions:; ```; ERROR:; CMake Error: The following variables are used in this project, but they are set to NOTFOUND.; Please set them or make sure they are set and tested correctly in the CMake files:; CURL_LIBRARY; linked by target ""salmon"" in directory /home/kurt/Development/salmon/src; linked by target ""unitTests"" in directory /home/kurt/Development/salmon/src; RESOLUTION:; sudo apt-get install libcurl4-openssl-dev; ----------------------------------; ERROR:; Performing download step for 'libbz2'; % Total % Received % Xferd Average Speed Time Time Time Current; Dload Upload Total Spent Left Speed; 100 227 100 227 0 0 1013 0 --:--:-- --:--:-- --:--:-- 1013; 100 16207 0 16207 0 0 34336 0 --:--:-- --:--:-- --:--:-- 166k; bzip2-1.0.6.tar.gz: FAILED; sha256sum: WARNING: 1 computed checksum did NOT match; bzip2-1.0.6.tar.gz did not match expected SHA256! Exiting.; CMakeFiles/libbz2.dir/build.make:89: recipe for target 'libbz2-prefix/src/libbz2-stamp/libbz2-download' failed; make[2]: *** [libbz2-prefix/src/libbz2-stamp/libbz2-download] Error 1; CMakeFiles/Makefile2:183: recipe for target 'CMakeFiles/libbz2.dir/all' failed; make[1]: *** [CMakeFiles/libbz2.dir/all] Error 2; Makefile:162: recipe for target 'all' failed; make: *** [all] Error 2; RESOLUTION:; modifying build.make to pull from sourceforge instead of bzip.org; -----------------------------------------------------------; ERROR:; libtool: compile: /us",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/383:3295,test,tested,3295,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/383,1,['test'],['tested']
Testability,"ormation.; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { abalone_index }; ### [ libType ] => { A }; ### [ mates1 ] => { .R1_001.qc.fq.gz }; ### [ mates2 ] => { .R2_001.qc.fq.gz }; ### [ output ] => { .quant }; Logs will be written to .quant/logs; [2019-07-24 13:33:29.347] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-07-24 13:33:29.347] [jointLog] [warning] . NOTE: It appears you are running salmon without the `--validateMappings` option.; Mapping validation can generally improve both the sensitivity and specificity of mapping,; with only a moderate increase in use of computational resources. ; Mapping validation is planned to become a default option (i.e. turned on by default) in; the next release of salmon.; Unless there is a specific reason to do this (e.g. testing on clean simulated data),; `--validateMappings` is generally recommended. [2019-07-24 13:33:29.347] [jointLog] [info] parsing read library format; [2019-07-24 13:33:29.347] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file abalone_index/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting.; /var/spool/slurmd/job12930414/slurm_script: line 14: --validateMappings: command not found; basename: extra operand ‘lightreceptor-1_S114_L005_R1_001.qc.fq.gz’; Try 'basename --help' for more information.; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { abalone_index }; ### [ libType ] => { A }; ### [ mates1 ] => { .R1_001.qc.fq.gz }; ### [ mates2 ] => { .R2_001.qc.fq.gz }; ### [ output ] => { .quant }; Logs will be written to .quant/logs; [2019-07-24 13:33:29",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408:1722,test,testing,1722,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408,1,['test'],['testing']
Testability,"ormation.; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { abalone_index }; ### [ libType ] => { A }; ### [ mates1 ] => { .R1_001.qc.fq.gz }; ### [ mates2 ] => { .R2_001.qc.fq.gz }; ### [ output ] => { .quant }; Logs will be written to .quant/logs; [2019-07-24 13:33:29.441] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-07-24 13:33:29.441] [jointLog] [warning] . NOTE: It appears you are running salmon without the `--validateMappings` option.; Mapping validation can generally improve both the sensitivity and specificity of mapping,; with only a moderate increase in use of computational resources. ; Mapping validation is planned to become a default option (i.e. turned on by default) in; the next release of salmon.; Unless there is a specific reason to do this (e.g. testing on clean simulated data),; `--validateMappings` is generally recommended. [2019-07-24 13:33:29.441] [jointLog] [info] parsing read library format; [2019-07-24 13:33:29.441] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file abalone_index/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting.; /var/spool/slurmd/job12930414/slurm_script: line 14: --validateMappings: command not found; basename: extra operand ‘lightreceptor-1_S114_L005_R1_001.qc.fq.gz’; Try 'basename --help' for more information.; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { abalone_index }; ### [ libType ] => { A }; ### [ mates1 ] => { .R1_001.qc.fq.gz }; ### [ mates2 ] => { .R2_001.qc.fq.gz }; ### [ output ] => { .quant }; Logs will be written to .quant/logs; [2019-07-24 13:33:29",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408:3333,test,testing,3333,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408,1,['test'],['testing']
Testability,"ormation.; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { abalone_index }; ### [ libType ] => { A }; ### [ mates1 ] => { .R1_001.qc.fq.gz }; ### [ mates2 ] => { .R2_001.qc.fq.gz }; ### [ output ] => { .quant }; Logs will be written to .quant/logs; [2019-07-24 13:33:29.532] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-07-24 13:33:29.532] [jointLog] [warning] . NOTE: It appears you are running salmon without the `--validateMappings` option.; Mapping validation can generally improve both the sensitivity and specificity of mapping,; with only a moderate increase in use of computational resources. ; Mapping validation is planned to become a default option (i.e. turned on by default) in; the next release of salmon.; Unless there is a specific reason to do this (e.g. testing on clean simulated data),; `--validateMappings` is generally recommended. [2019-07-24 13:33:29.532] [jointLog] [info] parsing read library format; Exception : [Error: The index version file abalone_index/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was invoked improperly.; For usage information, try salmon[2019-07-24 13:33:29.532] [jointLog] [info] There is 1 library.; quant --help; Exiting.; /var/spool/slurmd/job12930414/slurm_script: line 14: --validateMappings: command not found; basename: extra operand ‘lightreceptor-1_S114_L005_R1_001.qc.fq.gz’; Try 'basename --help' for more information.; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { abalone_index }; ### [ libType ] => { A }; ### [ mates1 ] => { .R1_001.qc.fq.gz }; ### [ mates2 ] => { .R2_001.qc.fq.gz }; ### [ output ] => { .quant }; Logs will be written to .quant/logs; [2019-07-24 13:33:29.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408:4944,test,testing,4944,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408,1,['test'],['testing']
Testability,"ormation.; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { abalone_index }; ### [ libType ] => { A }; ### [ mates1 ] => { .R1_001.qc.fq.gz }; ### [ mates2 ] => { .R2_001.qc.fq.gz }; ### [ output ] => { .quant }; Logs will be written to .quant/logs; [2019-07-24 13:33:29.626] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-07-24 13:33:29.626] [jointLog] [warning] . NOTE: It appears you are running salmon without the `--validateMappings` option.; Mapping validation can generally improve both the sensitivity and specificity of mapping,; with only a moderate increase in use of computational resources. ; Mapping validation is planned to become a default option (i.e. turned on by default) in; the next release of salmon.; Unless there is a specific reason to do this (e.g. testing on clean simulated data),; `--validateMappings` is generally recommended. [2019-07-24 13:33:29.626] [jointLog] [info] parsing read library format; [2019-07-24 13:33:29.626] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file abalone_index/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting.; /var/spool/slurmd/job12930414/slurm_script: line 14: --validateMappings: command not found; basename: extra operand ‘lightreceptor-1_S114_L005_R1_001.qc.fq.gz’; Try 'basename --help' for more information.; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { abalone_index }; ### [ libType ] => { A }; ### [ mates1 ] => { .R1_001.qc.fq.gz }; ### [ mates2 ] => { .R2_001.qc.fq.gz }; ### [ output ] => { .quant }; Logs will be written to .quant/logs; [2019-07-24 13:33:29",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408:6554,test,testing,6554,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408,1,['test'],['testing']
Testability,"ormation.; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { abalone_index }; ### [ libType ] => { A }; ### [ mates1 ] => { .R1_001.qc.fq.gz }; ### [ mates2 ] => { .R2_001.qc.fq.gz }; ### [ output ] => { .quant }; Logs will be written to .quant/logs; [2019-07-24 13:33:29.720] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-07-24 13:33:29.720] [jointLog] [warning] . NOTE: It appears you are running salmon without the `--validateMappings` option.; Mapping validation can generally improve both the sensitivity and specificity of mapping,; with only a moderate increase in use of computational resources. ; Mapping validation is planned to become a default option (i.e. turned on by default) in; the next release of salmon.; Unless there is a specific reason to do this (e.g. testing on clean simulated data),; `--validateMappings` is generally recommended. [2019-07-24 13:33:29.720] [jointLog] [info] parsing read library format; [2019-07-24 13:33:29.720] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file abalone_index/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting.; /var/spool/slurmd/job12930414/slurm_script: line 14: --validateMappings: command not found; basename: extra operand ‘lightreceptor-1_S114_L005_R1_001.qc.fq.gz’; Try 'basename --help' for more information.; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { abalone_index }; ### [ libType ] => { A }; ### [ mates1 ] => { .R1_001.qc.fq.gz }; ### [ mates2 ] => { .R2_001.qc.fq.gz }; ### [ output ] => { .quant }; Logs will be written to .quant/logs; [2019-07-24 13:33:29",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408:8165,test,testing,8165,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408,1,['test'],['testing']
Testability,"ormation.; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { abalone_index }; ### [ libType ] => { A }; ### [ mates1 ] => { .R1_001.qc.fq.gz }; ### [ mates2 ] => { .R2_001.qc.fq.gz }; ### [ output ] => { .quant }; Logs will be written to .quant/logs; [2019-07-24 13:33:29.808] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-07-24 13:33:29.808] [jointLog] [warning] . NOTE: It appears you are running salmon without the `--validateMappings` option.; Mapping validation can generally improve both the sensitivity and specificity of mapping,; with only a moderate increase in use of computational resources. ; Mapping validation is planned to become a default option (i.e. turned on by default) in; the next release of salmon.; Unless there is a specific reason to do this (e.g. testing on clean simulated data),; `--validateMappings` is generally recommended. [2019-07-24 13:33:29.808] [jointLog] [info] parsing read library format; [2019-07-24 13:33:29.808] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file abalone_index/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting.; /var/spool/slurmd/job12930414/slurm_script: line 14: --validateMappings: command not found; basename: extra operand ‘lightreceptor-1_S114_L005_R1_001.qc.fq.gz’; Try 'basename --help' for more information.; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { abalone_index }; ### [ libType ] => { A }; ### [ mates1 ] => { .R1_001.qc.fq.gz }; ### [ mates2 ] => { .R2_001.qc.fq.gz }; ### [ output ] => { .quant }; Logs will be written to .quant/logs; [2019-07-24 13:33:29",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408:9776,test,testing,9776,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408,1,['test'],['testing']
Testability,"ormation.; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { abalone_index }; ### [ libType ] => { A }; ### [ mates1 ] => { .R1_001.qc.fq.gz }; ### [ mates2 ] => { .R2_001.qc.fq.gz }; ### [ output ] => { .quant }; Logs will be written to .quant/logs; [2019-07-24 13:33:29.899] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-07-24 13:33:29.899] [jointLog] [warning] . NOTE: It appears you are running salmon without the `--validateMappings` option.; Mapping validation can generally improve both the sensitivity and specificity of mapping,; with only a moderate increase in use of computational resources. ; Mapping validation is planned to become a default option (i.e. turned on by default) in; the next release of salmon.; Unless there is a specific reason to do this (e.g. testing on clean simulated data),; `--validateMappings` is generally recommended. [2019-07-24 13:33:29.899] [jointLog] [info] parsing read library format; [2019-07-24 13:33:29.899] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file abalone_index/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting.; /var/spool/slurmd/job12930414/slurm_script: line 14: --validateMappings: command not found; basename: extra operand ‘lightreceptor-1_S114_L005_R1_001.qc.fq.gz’; Try 'basename --help' for more information.; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { abalone_index }; ### [ libType ] => { A }; ### [ mates1 ] => { .R1_001.qc.fq.gz }; ### [ mates2 ] => { .R2_001.qc.fq.gz }; ### [ output ] => { .quant }; Logs will be written to .quant/logs; [2019-07-24 13:33:29",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408:11387,test,testing,11387,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408,1,['test'],['testing']
Testability,"ormation.; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { abalone_index }; ### [ libType ] => { A }; ### [ mates1 ] => { .R1_001.qc.fq.gz }; ### [ mates2 ] => { .R2_001.qc.fq.gz }; ### [ output ] => { .quant }; Logs will be written to .quant/logs; [2019-07-24 13:33:29.990] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-07-24 13:33:29.990] [jointLog] [warning] . NOTE: It appears you are running salmon without the `--validateMappings` option.; Mapping validation can generally improve both the sensitivity and specificity of mapping,; with only a moderate increase in use of computational resources. ; Mapping validation is planned to become a default option (i.e. turned on by default) in; the next release of salmon.; Unless there is a specific reason to do this (e.g. testing on clean simulated data),; `--validateMappings` is generally recommended. [2019-07-24 13:33:29.990] [jointLog] [info] parsing read library format; [2019-07-24 13:33:29.990] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file abalone_index/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting.; /var/spool/slurmd/job12930414/slurm_script: line 14: --validateMappings: command not found; basename: extra operand ‘lightreceptor-1_S114_L005_R1_001.qc.fq.gz’; Try 'basename --help' for more information.; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { abalone_index }; ### [ libType ] => { A }; ### [ mates1 ] => { .R1_001.qc.fq.gz }; ### [ mates2 ] => { .R2_001.qc.fq.gz }; ### [ output ] => { .quant }; Logs will be written to .quant/logs; [2019-07-24 13:33:30",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408:12998,test,testing,12998,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408,1,['test'],['testing']
Testability,"ormation.; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { abalone_index }; ### [ libType ] => { A }; ### [ mates1 ] => { .R1_001.qc.fq.gz }; ### [ mates2 ] => { .R2_001.qc.fq.gz }; ### [ output ] => { .quant }; Logs will be written to .quant/logs; [2019-07-24 13:33:30.175] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-07-24 13:33:30.175] [jointLog] [warning] . NOTE: It appears you are running salmon without the `--validateMappings` option.; Mapping validation can generally improve both the sensitivity and specificity of mapping,; with only a moderate increase in use of computational resources. ; Mapping validation is planned to become a default option (i.e. turned on by default) in; the next release of salmon.; Unless there is a specific reason to do this (e.g. testing on clean simulated data),; `--validateMappings` is generally recommended. [2019-07-24 13:33:30.175] [jointLog] [info] parsing read library format; [2019-07-24 13:33:30.175] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file abalone_index/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting.; /var/spool/slurmd/job12930414/slurm_script: line 14: --validateMappings: command not found; basename: extra operand ‘lightreceptor-1_S114_L005_R1_001.qc.fq.gz’; Try 'basename --help' for more information.; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { abalone_index }; ### [ libType ] => { A }; ### [ mates1 ] => { .R1_001.qc.fq.gz }; ### [ mates2 ] => { .R2_001.qc.fq.gz }; ### [ output ] => { .quant }; Logs will be written to .quant/logs; [2019-07-24 13:33:30",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408:16220,test,testing,16220,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408,1,['test'],['testing']
Testability,"over the TBX21 region, I get back >4000 paired reads. The majority of the TBX21 reads have flags 99 or 147:; (# of reads) | (flag); 4431 | 147; 12 | 355; 14 | 403; 2 | 419; 4432 | 99. I also confirmed that many of these reads are indeed from the TBX21 spliced transcripts (cross splice junctions). I am running Salmon in mapping-based mode on the unaligned fastqs, and it is picking up exactly 0 reads in these transcripts. salmon index -t hg38_salmon_transcriptome.fa -i salmon_hg38_index --type quasi -k 31; salmon quant -i salmon_hg38_index -l ISR -p 8 -1 SRR1615172_1_val_1.fq.gz -2 SRR1615172_2_val_2.fq.gz -o salmon_quant_SRR1615172. The genome-wide distribution of insert size ranges for this sample are unusual (bi-modal), and this is partly why STAR only mapped 65% of the reads. The other issue with the sample is STAR reports 19% multi-mapped reads, but even so, there are still at least 4000 reads uniquely mapping to TBX21. Attached are:; ### Output from Salmon; [salmon_quant.log](https://github.com/COMBINE-lab/salmon/files/3199053/salmon_quant.log); [lib_format_counts.json.zip](https://github.com/COMBINE-lab/salmon/files/3199074/lib_format_counts.json.zip); ### Output from STAR; [SRR1615173.Log.final.out.STAR.txt](https://github.com/COMBINE-lab/salmon/files/3199078/SRR1615173.Log.final.out.STAR.txt); ### Output from samtools view over the TBX21 gene start and end (hg38 17:47733244-47746119); [TBX21_reads.txt](https://github.com/COMBINE-lab/salmon/files/3199054/TBX21_reads.txt); ### FastQC reports of the two fastqs; [SRR1615173_1_val_1.fq_fastqc.zip](https://github.com/COMBINE-lab/salmon/files/3199049/SRR1615173_1_val_1.fq_fastqc.zip); [SRR1615173_2_val_2.fq_fastqc.zip](https://github.com/COMBINE-lab/salmon/files/3199050/SRR1615173_2_val_2.fq_fastqc.zip); ### Output from CollectInsertSizeMetrics; [insert_size_histogram.pdf](https://github.com/COMBINE-lab/salmon/files/3199051/insert_size_histogram.pdf); [insert_size_metrics.txt](https://github.com/COMBINE-lab/salmon/f",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/218#issuecomment-494079306:1494,log,log,1494,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/218#issuecomment-494079306,1,['log'],['log']
Testability,"ovided; using is 1 less feature for whitelisting; [2019-01-29 09:55:59.107] [alevinLog] [info] Starting to make feature Matrix; [2019-01-29 09:55:59.115] [alevinLog] [info] Done making regular featues; [2019-01-29 09:55:59.115] [alevinLog] [info] Done making feature Matrix; [2019-01-29 09:55:59.123] [alevinLog] [info] Finished white listing; [2019-01-29 09:55:59.126] [alevinLog] [info] Finished optimizer; ``` . Concat fastq:; ```; salmon alevin -l ISR -1 big.fastq.1.gz -2 big.fastq.2.gz --chromium -i geneset.dir/geneset_coding_exons.salmon.index/ -o salmon.dir/ --tgMap transcript2geneMap.tsv --dumpCsvCounts; Version Info: ### PLEASE UPGRADE SALMON ###; ### A newer version of Salmon with important bug fixes and improvements is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; Logs will be written to salmon.dir/logs; ### alevin (dscRNA-seq quantification) v0.11.3; ### [ program ] => salmon ; ### [ command ] => alevin ; ### [ libType ] => { ISR }; ### [ mates1 ] => { big.fastq.1.gz }; ### [ mates2 ] => { big.fastq.2.gz }; ### [ chromium ] => { }; ### [ index ] => { geneset.dir/geneset_coding_exons.salmon.index/ }; ### [ output ] => { salmon.dir/ }; ### [ tgMap ] => { transcript2geneMap.tsv }; ### [ dumpCsvCounts ] => { }. [2019-01-29 09:56:37.731] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-01-29 09:56:37.749] [alevinLog] [info] Processing barcodes files (if Present) . ; processed 2 Million barcodes. [2019-01-29 09:56:43.029] [alevinLog] [info] Done barcode density calculation.; [2019-01-29 09:56:43.029] [alevinLog] [info] # Barcodes Used: 2695632 / 2712324.; [2019-01-29 09:56:52.900] [alevinLog] [info] Knee found left boundary at 692 ; [2019-01-29 09:56:53.219] [alevinLog] [info] Gauss Corrected Boundary at 100 ; [2019-01-29 09:56:53.219] [alevin",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722:6386,log,logs,6386,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722,1,['log'],['logs']
Testability,"p:256:32: error: ‘class RapMapSAIndex<long int, spp::sparse_hash_map<long unsigned int, rapmap::utils::SAInterval<long int>, rapmap::utils::KmerKeyHasher, std::equal_to<long unsigned int>, spp::libc_allocator<std::pair<const long unsigned int, rapmap::utils::SAInterval<long int> > > > >’ has no member named ‘isDecoy’; decoy = quasiIndex64_->isDecoy(tid);; .../salmon/include/SalmonIndex.hpp:260:43: error: ‘class RapMapSAIndex<int, FrugalBooMap<long unsigned int, rapmap::utils::SAInterval<int> > >’ has no member named ‘isDecoy’; decoy = quasiIndexPerfectHash32_->isDecoy(tid);; .../salmon/include/SalmonIndex.hpp:262:32: error: ‘class RapMapSAIndex<int, spp::sparse_hash_map<long unsigned int, rapmap::utils::SAInterval<int>, rapmap::utils::KmerKeyHasher, std::equal_to<long unsigned int>, spp::libc_allocator<std::pair<const long unsigned int, rapmap::utils::SAInterval<int> > > > >’ has no member named ‘isDecoy’; decoy = quasiIndex32_->isDecoy(tid);; ```. In investigating this further, it appears that the version of RapMap being downloaded and compiled (release salmon-v0.14.1, according to scripts/fetchRapMap.sh) is missing the commit that introduced the isDecoy() function for the RapMapSAIndex class (what appears to be commit COMBINE-lab/RapMap@152ed9026005f4a823988c4893386079aa663a53, with changes in COMBINE-lab/RapMap@55ef430ec8c3b130666c8f3855073a79c6236fb4 on the develop-salmon branch). (Also, was it intentional that two releases of RapMap were made on the same commit? Both salmon-v0.14.0 and salmon-v0.14.1 releases appear to have been made on commit COMBINE-lab/RapMap@89dbe45481dac12ac8cffd6d5d924699c5ad7e04.). Adjusting the fetchRapMap.sh script to use the SVER and EXPECTED_SHA256SUM variables back to their values in commit COMBINE-lab/salmon@cf07385f2164698eda5b9869dd4865fec747840d, then re-running the script, and recompiling produces no errors, and the tests all run. Hope that helps, and thanks for all your work in developing Salmon!. Best regards,; Patrick Reilly",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/418:2282,test,tests,2282,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/418,1,['test'],['tests']
Testability,"piled, downloaded executable, through bioconda)?: Miniconda; * Which reference (e.g. transcriptome) was used?: Self-generated; * Which read files were used?: ERX4307280, SRX10245671, SRX3847835; * Which which program options were used?. ```; salmon quant -i {params.index_dir} -l A -r {input.reads} -o {params.out_dir} --validateMappings --writeUnmappedNames; ```. **Expected behavior**; I expected the reads that were counted in the log file as ""discarded because they are best-mapped to decoys"" to be labelled in the `aux_info/unmapped_names.txt` file with `d`, but all reads were marked as `u`. **Screenshots**; ```; $grep ""Number of fragments discarded because they are best-mapped to decoys"" */logs/*. ERX4307280_quant/logs/salmon_quant.log:[2022-02-02 15:51:25.854] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 948,850; SRX10245671_quant/logs/salmon_quant.log:[2022-02-02 15:57:10.321] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 961,758; SRX3847835_quant/logs/salmon_quant.log:[2022-02-02 15:33:54.185] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 220,351; ```. **Desktop (please complete the following information):**; - OS: Linux; - Version: ; ```; Linux farm.cse.ucdavis.edu 4.15.0-159-generic #167-Ubuntu SMP Tue Sep 21 08:55:05 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux; ```; ```; No LSB modules are available.; Distributor ID:	Ubuntu; Description:	Ubuntu 18.04.6 LTS; Release:	18.04; Codename:	bionic; ```; **Additional context**; I intentionally mapped all three libraries as SE, even though two are PE. Because of the presence of polycistronic transcripts in microbes, many paired-end reads would be discordant, which causes counts to look very...odd. See [this preprint](https://www.biorxiv.org/content/10.1101/2022.01.24.477642v1) for more details on that phenomenon. I'm trying to use the decoys as a first step in identifying reads that map to interg",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/748:4636,log,logs,4636,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/748,1,['log'],['logs']
Testability,"please provide at least the following information:. * Which version of salmon was used?. 0.9.1. * How was salmon installed (compiled, downloaded executable, through bioconda)?. From our dockerfile:; ```; # Install Salmon; ENV SALMON_VERSION 0.9.1; RUN wget https://github.com/COMBINE-lab/salmon/releases/download/v${SALMON_VERSION}/Salmon-${SALMON_VERSION}_linux_x86_64.tar.gz; RUN tar -xzf Salmon-${SALMON_VERSION}_linux_x86_64.tar.gz; # Create soft link `/usr/local/bin/salmon` that points to the actual program; RUN ln -sf `pwd`/Salmon-latest_linux_x86_64/bin/salmon /usr/local/bin/; RUN rm -f Salmon-${SALMON_VERSION}_linux_x86_64.tar.gz; # End Salmon installation.; ```. * Which reference (e.g. transcriptome) was used?. One we prepared. We got the raw transcriptome from ensembl, then prepared it with:; https://github.com/AlexsLemonade/refinebio/blob/dev/workers/data_refinery_workers/processors/transcriptome_index.py. Which produced:; https://s3.amazonaws.com/data-refinery-test-assets/Caenorhabditis_elegans_short_1527089586.tar.gz. * Which read files were used?. Two read files out of:; https://s3.amazonaws.com/data-refinery-test-assets/salmon_tests.tar.gz. found within that archive at:; `test_experiment/raw/reads_1.fastq`; and ; `test_experiment/raw/reads_2.fastq`. Unfortunately I am not entirely sure where these were found. * Which which program options were used?. The exact invocation of salmon was:; ```; salmon --no-version-check quant -l A --biasSpeedSamp 5 -i /home/user/data_store/processed/TEST/TRANSCRIPTOME_INDEX/index -1 /home/user/data_store/salmon_tests/test_experiment/raw/reads_1.fastq -2 /home/user/data_store/salmon_tests/test_experiment/raw/reads_2.fastq -p 20 -o /home/user/data_store/TEST/test_sample/processed/ --seqBias --gcBias --dumpEq --writeUnmappedNames; ```. **Expected behavior**; This happened while I was modifying the tests for running salmon. I'm guessing that my code isn't quite right yet so something going wrong isn't quite unexpected. However I",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/279:1296,test,test-assets,1296,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/279,1,['test'],['test-assets']
Testability,"poly-A tails from 0 transcripts; [2020-04-07 21:12:14.599] [jointLog] [info] Building rank-select dictionary and saving to disk; [2020-04-07 21:12:14.599] [jointLog] [info] done; Elapsed time: 5.7764e-05s; [2020-04-07 21:12:14.606] [jointLog] [info] Writing sequence data to file . . . ; [2020-04-07 21:12:14.607] [jointLog] [info] done; Elapsed time: 0.000590993s; [2020-04-07 21:12:14.614] [jointLog] [info] Building 32-bit suffix array (length of generalized text is 28,577); [2020-04-07 21:12:14.616] [jointLog] [info] Building suffix array . . . ; success; saving to disk . . . done; Elapsed time: 0.000716831s; done; Elapsed time: 0.0107059s; ```; Specifically, please provide at least the following information:. * Which version of salmon was used? 1.1.0, 1.0.0 and 0.14.1; * How was salmon installed (compiled, downloaded executable, through bioconda)? GitHub binary; * Which reference (e.g. transcriptome) was used? sample data from GitHub release; * Which read files were used? none; * Which which program options were used? -k 31 -i index -t sample_data/transcripts.fasta. **Expected behavior**; A clear and concise description of what you expected to happen.; I expected salmon 1.1.0 to run without a core-dump and produce similar results to 0.14.1. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX] Ubuntu 18.04.4 LTS; - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux the output of `uname -a` and `lsb_release -a`]; Linux firefly 5.3.0-40-generic #32~18.04.1-Ubuntu SMP Mon Feb 3 14:05:59 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux. **Additional context**; Using ""bcbio-nextgen"", with ""salmon 1.1.0"" installed by Anaconda: Removed this version because of core-dumps and installed the binary releases of ""salmon"" 1.1.0 then 0.41.1 from GitHub in /usr/local. Did stand-alone tests with sample data from the GitHub binary release.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/500:3519,test,tests,3519,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/500,1,['test'],['tests']
Testability,"pool/compute-061/job_scripts/110315: line 31: 54922 Aborted (core dumped) /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant -i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode.v25.transcripts -p 1 -l ISR -1 ${FILE1} -2 ${FILE2} -o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test3/${ID}; **** Job ends ****; Wed Mar 29 14:51:13 EDT 2017; ```. ### SGE email info example. ```; Job-array task 110315.1 (step6-salmon_test3.gsk_phaseII) Complete; User = lcollado; Queue = shared.q@compute-061.cm.cluster; Host = compute-061.cm.cluster; Start Time = 03/29/2017 14:51:09; End Time = 03/29/2017 14:51:13; User Time = 00:00:00; System Time = 00:00:02; Wallclock Time = 00:00:04; CPU = 00:00:02; Max vmem = 14.820G; Exit Status = 0; ```. ## 16 cores. ### Bash. ```bash; #!/bin/bash; #$ -cwd; #$ -l mem_free=2G,h_vmem=3G,h_fsize=100G; #$ -N step6-salmon_test4.gsk_phaseII; #$ -pe local 16; #$ -o ./logs/salmon_test4.$TASK_ID.txt; #$ -e ./logs/salmon_test4.$TASK_ID.txt; #$ -t 1-3; #$ -hold_jid pipeline_setup,step4-featCounts-alzheimer.gsk_phaseII; #$ -m e; echo ""**** Job starts ****""; date. echo ""**** JHPCE info ****""; echo ""User: ${USER}""; echo ""Job id: ${JOB_ID}""; echo ""Job name: ${JOB_NAME}""; echo ""Hostname: ${HOSTNAME}""; echo ""Task id: ${TASK_ID}"". FILE1=$(awk 'BEGIN {FS=""\t""} {print $1}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); if [ TRUE == ""TRUE"" ] ; then; FILE2=$(awk 'BEGIN {FS=""\t""} {print $3}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); fi; ID=$(cat /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk '{print $NF}' | awk ""NR==${SGE_TASK_ID}""). mkdir -p /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test4/${ID}. /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant 	-i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965:3949,log,logs,3949,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-290516965,1,['log'],['logs']
Testability,"probably unrelated, but also unexpected. Make test on my linux and osx box looks like:. ```; $ make test; Running tests...; Test project /Users/rob/salmon/build; Start 1: unit_tests; 1/3 Test #1: unit_tests ....................... Passed 0.13 sec; Start 2: salmon_read_test_fmd; 2/3 Test #2: salmon_read_test_fmd ............. Passed 0.87 sec; Start 3: salmon_read_test_quasi; 3/3 Test #3: salmon_read_test_quasi ........... Passed 0.39 sec. 100% tests passed, 0 tests failed out of 3. Total Test time (real) = 1.41 sec; ```. It looks the same on the continuous integration server : . ```; Running tests...; /usr/local/cmake-3.9.2/bin/ctest --force-new-ctest-process ; Test project /home/travis/build/COMBINE-lab/salmon/build; Start 1: unit_tests; 1/3 Test #1: unit_tests ....................... Passed 0.13 sec; Start 2: salmon_read_test_fmd; 2/3 Test #2: salmon_read_test_fmd ............. Passed 2.55 sec; Start 3: salmon_read_test_quasi; 3/3 Test #3: salmon_read_test_quasi ........... Passed 1.72 sec; 100% tests passed, 0 tests failed out of 3; Total Test time (real) = 4.41 sec; ```. Also, you can look, in the build directory, in the subdirectory `Testing/Temporary/LastTestsFailed.log` which will give details of which specific test failed.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393676260:46,test,test,46,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/229#issuecomment-393676260,21,"['Test', 'log', 'test']","['Test', 'Testing', 'log', 'test', 'tests']"
Testability,"processed 26000000 reads in current roundSegmentation fault (core dumped); ```. Output for failure case - four files. ```; salmon quant -t /rsstu/users/c/cjdohert/NSF_Tomato/AT_RefGenomeFiles/TAIR10_chr_all.fas -l A -a leaf_mock_t6_rep3_S64_R1_001Aligned.out.bam leaf_mock_t6_rep1_S40_R1_001Aligned.out.bam leaf_mock_t5_rep3_S63_R1_001Aligned.out.bam leaf_mock_t5_rep1_S39_R1_001Aligned.out.bam -p 8 -o ../SalmonQuantFiles; Version Info: This is the most recent version of salmon.; # salmon (alignment-based) v1.9.0; # [ program ] => salmon ; # [ command ] => quant ; # [ targets ] => { /rsstu/users/c/cjdohert/NSF_Tomato/AT_RefGenomeFiles/TAIR10_chr_all.fas }; # [ libType ] => { A }; # [ alignments ] => { leaf_mock_t6_rep3_S64_R1_001Aligned.out.bam leaf_mock_t6_rep1_S40_R1_001Aligned.out.bam leaf_mock_t5_rep3_S63_R1_001Aligned.out.bam leaf_mock_t5_rep1_S39_R1_001Aligned.out.bam }; # [ threads ] => { 8 }; # [ output ] => { ../SalmonQuantFiles }; Logs will be written to ../SalmonQuantFiles/logs; [2023-01-29 16:52:41.666] [jointLog] [info] setting maxHashResizeThreads to 8; [2023-01-29 16:52:41.666] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; Library format { type:single end, relative orientation:none, strandedness:unstranded }; [2023-01-29 16:52:41.668] [jointLog] [info] numQuantThreads = 4; parseThreads = 4; Checking that provided alignment files have consistent headers . . . done; Populating targets from aln = ""leaf_mock_t6_rep3_S64_R1_001Aligned.out.bam"", fasta = ""/rsstu/users/c/cjdohert/NSF_Tomato/AT_RefGenomeFiles/TAIR10_chr_all.fas"" . . .done. processed 0 reads in current round[2023-01-29 16:52:42.565] [jointLog] [info] replaced 186,207 non-ACGT nucleotides with random nucleotides; processed 2000000 reads in current round[2023-01-29 16:52:43.137] [jointLog] [info] Automatically detected most likely library type as U. [2023-01-29 16:52:43.276] [jointLog] [info] . The alignment group queue pool has been exhaus",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/825:8874,log,logs,8874,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/825,1,['log'],['logs']
Testability,pts_index_salmon/ -p 8 -o alevin_output --tgMap ../hg_transcriptome/tx2gene.tsv. TEMPDIR is /tmp/tmp.WnzMm7GQBO; Running command [salmon alevin -lISR --gemcode -i ../transcripts_index_salmon/ -p 8 -o alevin_output --tgMap ../hg_transcriptome/tx2gene.tsv -1 /tmp/tmp.WnzMm7GQBO/p1.fa -2 /tmp/tmp.WnzMm7GQBO/p2.fa -r pbmc3k_fastqs/read-I1_si-ACGCGGAA_lane-001-chunk-001.fastq.gz; pbmc3k_fastqs/read-I1_si-ACGCGGAA_lane-002-chunk-000.fastq.gz; pbmc3k_fastqs/read-I1_si-CGCTATCC_lane-001-chunk-001.fastq.gz; pbmc3k_fastqs/read-I1_si-CGCTATCC_lane-002-chunk-000.fastq.gz; pbmc3k_fastqs/read-I1_si-GTTGCATG_lane-001-chunk-001.fastq.gz; pbmc3k_fastqs/read-I1_si-GTTGCATG_lane-002-chunk-000.fastq.gz; pbmc3k_fastqs/read-I1_si-TAAATCGT_lane-001-chunk-001.fastq.gz; pbmc3k_fastqs/read-I1_si-TAAATCGT_lane-002-chunk-000.fastq.gz]; Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; Logs will be written to alevin_output/logs; ### alevin (dscRNA-seq quantification) v0.11.3; ### [ program ] => salmon ; ### [ command ] => alevin ; ### [ libType ] => { ISR }; ### [ gemcode ] => { }; ### [ index ] => { ../transcripts_index_salmon/ }; ### [ threads ] => { 8 }; ### [ output ] => { alevin_output }; ### [ tgMap ] => { ../hg_transcriptome/tx2gene.tsv }; ### [ mates1 ] => { /tmp/tmp.WnzMm7GQBO/p1.fa }; ### [ mates2 ] => { /tmp/tmp.WnzMm7GQBO/p2.fa }; ### [ unmatedReads ] => { pbmc3k_fastqs/read-I1_si-ACGCGGAA_lane-001-chunk-001.fastq.gz pbmc3k_fastqs/read-I1_si-ACGCGGAA_lane-002-chunk-000.fastq.gz pbmc3k_fastqs/read-I1_si-CGCTATCC_lane-001-chunk-001.fastq.gz pbmc3k_fastqs/read-I1_si-CGCTATCC_lane-002-chunk-000.fastq.gz pbmc3k_fastqs/read-I1_si-GTTGCATG_lane-001-chunk-001.fastq.gz pbmc3k_fastqs/read-I1_si-GTTGCATG_lane-002-chunk-000.fastq.gz pbmc3k_fastqs/read-I1_si-TAAATCGT_lane-001-chunk-001.fastq.gz pbmc3k_fastqs/read-I1_si-TAAATCGT_lane-002-chunk-000.fastq.gz }. [2018-12-05 16:30:15.406] [jointLog] [info] Fra,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/328:9954,Log,Logs,9954,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/328,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"q) (in perl because I'm old-school) that does this and allows for mismatches within 1 hamming distance. I'm sure someone could port this to python, rust, or C/C++ and speed this step up substantially, but it seems to work fine. The next step is to run alevin. I've done so using salmon v1.5.2 with the following parameters (for a ParseBio run), reversing R1/R2 as per Avi's suggestion:; ```; salmon alevin -l ISR \; --expectCells 9000 \; --read-geometry 2[1-end] \; --umi-geometry 1[1-10] \; --bc-geometry 1[11-18,49-56,79-86] \; -2 R1.fastq.gz \; -1 R2_corrected.fastq.gz \; -i gencode_v36_transcripts_idx \; -p 8 \; -o SplitBio_SL2_alevin \; --tgMap gencode.v36.txt; ``` . I know that these libraries are stranded, but I doubt `ISR` is the correct architecture, especially given it's not true PE sequencing. Notably, running alevin this way gets me only a 4% mapping rate, and most of my cells get filtered out downstream due to having really low depth. . Below is my `salmon_quant.log`:; ```; [2021-08-20 12:29:32.343] [jointLog] [info] setting maxHashResizeThreads to 8; [2021-08-20 12:29:32.343] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2021-08-20 12:29:32.343] [jointLog] [info] The --mimicBT2, --mimicStrictBT2 and --hardFilter flags imply mapping validation (--validateMappings). Enabling mapping validation.; [2021-08-20 12:29:32.343] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2021-08-20 12:29:32.343] [jointLog] [info] The use of range-factorized equivalence classes does not make sense in conjunction with --hardFilter. Disabling range-factorized equivalence classes. ; [2021-08-20 12:29:32.343] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.; [2021-08-20 12:29:32.343] [jointLog] [info] Using default value of 0.87 for minScoreFraction in Alevin; Using default value of 0.6 for consensusSlack ",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699:2943,log,log,2943,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699,1,['log'],['log']
Testability,q_files/SRR2454059.fq.gz --threads 8 --libType ISF --seqBias --gcBias --useVBOpt --dumpEq --dumpEqWeights --geneMap /home/ryan/references/hg38/Salmon_index_hg38.analysisSet_knownGene/genemap.txt --output salmon_quant/hg38.analysisSet_knownGene/SRR2454059 --auxDir aux_info --numGibbsSamples 100; Version Info: This is the most recent **development version** of Salmon.; ### salmon (mapping-based) v0.7.3; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /home/ryan/references/hg38/Salmon_index_hg38.analysisSet_knownGene }; ### [ unmatedReads ] => { fastq_files/SRR2454059.fq.gz }; ### [ threads ] => { 8 }; ### [ libType ] => { ISF }; ### [ seqBias ] => { }; ### [ gcBias ] => { }; ### [ useVBOpt ] => { }; ### [ dumpEq ] => { }; ### [ dumpEqWeights ] => { }; ### [ geneMap ] => { /home/ryan/references/hg38/Salmon_index_hg38.analysisSet_knownGene/genemap.txt }; ### [ output ] => { salmon_quant/hg38.analysisSet_knownGene/SRR2454059 }; ### [ auxDir ] => { aux_info }; ### [ numGibbsSamples ] => { 100 }; Logs will be written to salmon_quant/hg38.analysisSet_knownGene/SRR2454059/logs; [2016-12-13 12:44:39.271] [jointLog] [info] parsing read library format; [2016-12-13 12:44:39.271] [jointLog] [info] There is 1 library.; [2016-12-13 12:44:39.836] [jointLog] [info] Loading Quasi index; [2016-12-13 12:44:39.836] [jointLog] [info] Loading 32-bit quasi index; [2016-12-13 12:44:39.836] [stderrLog] [info] Loading Suffix Array ; [2016-12-13 12:44:43.439] [stderrLog] [info] Loading Transcript Info ; [2016-12-13 12:44:44.355] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-12-13 12:44:44.613] [stderrLog] [info] There were 182608 set bits in the bit array; [2016-12-13 12:44:44.629] [stderrLog] [info] Computing transcript lengths; [2016-12-13 12:44:44.629] [stderrLog] [info] Waiting to finish loading hash; [2016-12-13 12:44:44.629] [stderrLog] [info] Done loading index; [2016-12-13 12:44:44.629] [jointLog] [info] done; [2016-12-13 12:44:44.629] [jointLog] [inf,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111:1220,Log,Logs,1220,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111,1,['Log'],['Logs']
Testability,"r -xz --strip-components 1; cmake -DBOOST_ROOT=/global/software/sl-7.x86_64/modules/gcc/7.4.0/boost/1.70.0-gcc -DCMAKE_INSTALL_PREFIX=$INSTALL_DIR; make; ```; And the tail of the output from make:. ```; creating: /clusterfs/vector/home/groups/software/sl-7.x86_64/source/salmon/1.5.1/scripts/../external/pufferfish-salmon-v1.5.1/tests/compile_tests/; inflating: /clusterfs/vector/home/groups/software/sl-7.x86_64/source/salmon/1.5.1/scripts/../external/pufferfish-salmon-v1.5.1/tests/compile_tests/int128_numeric_limits.cpp ; -- fetch PUFFERFISH exit code 0; -- Found ZLIB: /usr/lib64/libz.so (found version ""1.2.11"") ; -- Performing Test Iconv_IS_BUILT_IN; -- Performing Test Iconv_IS_BUILT_IN - Failed; CMake Error at /global/home/groups/consultsw/sl-7.x86_64/modules/cmake/3.15.1/share/cmake-3.15/Modules/FindPackageHandleStandardArgs.cmake:137 (message):; Could NOT find Iconv (missing: Iconv_LIBRARY); Call Stack (most recent call first):; /global/home/groups/consultsw/sl-7.x86_64/modules/cmake/3.15.1/share/cmake-3.15/Modules/FindPackageHandleStandardArgs.cmake:378 (_FPHSA_FAILURE_MESSAGE); /global/home/groups/consultsw/sl-7.x86_64/modules/cmake/3.15.1/share/cmake-3.15/Modules/FindIconv.cmake:120 (find_package_handle_standard_args); CMakeLists.txt:362 (find_package). -- Configuring incomplete, errors occurred!; See also ""/clusterfs/vector/home/groups/software/sl-7.x86_64/source/salmon/1.5.1/CMakeFiles/CMakeOutput.log"".; See also ""/clusterfs/vector/home/groups/software/sl-7.x86_64/source/salmon/1.5.1/CMakeFiles/CMakeError.log"".; ```; I'm also attaching the full CMake logs. This is right at the edge of my knowledge, so I'm not 100% sure I got libiconv installed correctly. Compilation completed without error, and I added the bin, include, and lib directories to PATH, CPATH, and LD_LIBRARY_PATH, respectively. [CMakeError.log](https://github.com/COMBINE-lab/salmon/files/6665942/CMakeError.log); [CMakeOutput.log](https://github.com/COMBINE-lab/salmon/files/6665943/CMakeOutput.log)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/453#issuecomment-862737315:2573,log,log,2573,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/453#issuecomment-862737315,14,['log'],"['log', 'logs']"
Testability,"r 1; Makefile:478: recipe for target 'all' failed; make[3]: *** [all] Error 2; CMakeFiles/libstadenio.dir/build.make:111: recipe for target 'libstadenio-prefix/src/libstadenio-stamp/libstadenio-build' failed; make[2]: *** [libstadenio-prefix/src/libstadenio-stamp/libstadenio-build] Error 2; CMakeFiles/Makefile2:257: recipe for target 'CMakeFiles/libstadenio.dir/all' failed; make[1]: *** [CMakeFiles/libstadenio.dir/all] Error 2; Makefile:162: recipe for target 'all' failed; make: *** [all] Error 2; ```. The internet tells me it's probably an issue with the order that the libraries are specified to gcc in or that gcc needs a `-lz` flag. However I don't even know where that gcc command is coming from. **To Reproduce**. This is difficult, because I would assume that the errors I'm seeing are specific to my machine. However I can say that I ran; ```; ./cmake-3.14.5-Linux-x86_64/bin/cmake -DFETCH_BOOST=TRUE; ```. and then. ```; make; ```. **Expected behavior**; I expected the project to build and produce a binary I could use to test my changes. **Desktop (please complete the following information):**; - OS: Ubuntu 18.04; - Version:. ```; lsb_release -a; No LSB modules are available.; Distributor ID:	Ubuntu; Description:	Ubuntu 18.04.2 LTS; Release:	18.04; Codename:	bionic; kurt@kurtputer:~/Development/refinebio-collab$ uname -a; Linux kurtputer 4.15.0-51-generic #55-Ubuntu SMP Wed May 15 14:27:21 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux; ```. **Additional context**; I was able to fix the following errors with these resolutions:; ```; ERROR:; CMake Error: The following variables are used in this project, but they are set to NOTFOUND.; Please set them or make sure they are set and tested correctly in the CMake files:; CURL_LIBRARY; linked by target ""salmon"" in directory /home/kurt/Development/salmon/src; linked by target ""unitTests"" in directory /home/kurt/Development/salmon/src; RESOLUTION:; sudo apt-get install libcurl4-openssl-dev; ----------------------------------; ERRO",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/383:2632,test,test,2632,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/383,1,['test'],['test']
Testability,"r one test:. ```; [2017-04-05 14:28:09.021] [jointLog] [info] parsing read library format; [2017-04-05 14:28:09.035] [jointLog] [info] There is 1 library.; terminate called without an active exception; /cm/local/apps/sge/var/spool/compute-064/job_scripts/420662: line 31: 28651 Aborted (core dumped) /dcl01/lieber/ajaffe/Emily/RNAseq-pipelin; e/Software/Salmon-0.8.2_linux_x86_64/bin/salmon quant -i /dcl01/lieber/ajaffe/Emily/RNAseq-pipeline/Annotation/Salmon_index_test/salmon_0.8.2_index_gencode; .v25.transcripts -p 1 -l ISR -1 ${FILE1} -2 ${FILE2} -o /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test7/${ID}; ```. Files that work well, keep on going:. ```; [2017-04-05 14:30:23.757] [jointLog] [info] parsing read library format; [2017-04-05 14:30:23.767] [jointLog] [info] There is 1 library.; [2017-04-05 14:30:24.378] [jointLog] [info] Loading Quasi index; ```. I don't know if that hint makes you suspect anything in `Salmon`. . Now, for some tests only task 2 runs and it turns out that task 2 has a smaller fastq file than the other 2:. ```bash; $ ls -lh merged_fastq/R1000[1-3]*; -rw-r--r-- 1 lcollado lieber_jaffe 6.2G Feb 20 12:39 merged_fastq/R10001_D2B1WACXX.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 6.3G Feb 20 12:40 merged_fastq/R10001_D2B1WACXX_read2.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 4.6G Feb 20 12:42 merged_fastq/R10002_C29P7ACXX.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 4.7G Feb 20 12:44 merged_fastq/R10002_C29P7ACXX_read2.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 7.1G Feb 20 12:47 merged_fastq/R10003_D19KGACXX.fastq.gz; -rw-r--r-- 1 lcollado lieber_jaffe 7.1G Feb 20 12:50 merged_fastq/R10003_D19KGACXX_read2.fastq.gz; ```. where R10001* is task 1, R10002* is task 2, R10003* is task 3. So it looks like at some point Salmon is asking for some memory based on the input data. ## Strace test with low memory (but above reported usage when requesting 90GB). Mark taught me about `strace` and we ran the following test:. ```bash; #!/bin/bash; #$ ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:1288,test,tests,1288,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['test'],['tests']
Testability,"ragment incompatibility prior; below threshold. Incompatible fragments will be ignored.; [2019-07-29 15:58:39.034] [jointLog] [info] Usage of --validateMappings; implies use of minScoreFraction. Since not explicitly specified, it is; being set to 0.65; [2019-07-29 15:58:39.034] [jointLog] [info] Usage of --validateMappings,; without --hardFilter implies use of range factorization.; rangeFactorizationBins is being set to 4; [2019-07-29 15:58:39.034] [jointLog] [info] Usage of --validateMappings; implies a default consensus slack of 0.2. Setting consensusSlack to 0.2.; [2019-07-29 15:58:39.034] [jointLog] [info] parsing read library format; [2019-07-29 15:58:39.034] [jointLog] [error] Failed to successfully parse; any complete read libraries. Please make sure you provided arguments; properly to -1, -2 (for paired-end libraries) or -r (for single-end; libraries), and that the library format option (-l) *comes before* the read; libraries. Best,. Sara. On Mon, Jul 29, 2019 at 3:25 PM Avi Srivastava <notifications@github.com>; wrote:. > You passed paired-end files; > to salmon, but you passed 12 files to --mates1 and 13 files to --mates2.; > You must pass the same number of files to both flags; >; > Is this true ? Can you share the log ?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/COMBINE-lab/salmon/issues/408?email_source=notifications&email_token=AEHDXAH7HQIR4ZVWMTE2KXLQB5U5LA5CNFSM4IGU4ZTKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD3CF3JY#issuecomment-516185511>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AEHDXAG7WI3B7QBMJOSXTATQB5U5LANCNFSM4IGU4ZTA>; > .; >. -- ; Sara E. Boles, MS; PhD Candidate | Whitehead Lab; Pharmacology and Toxicology Graduate Group; Department of Environmental Toxicology; University of California, Davis, CA 95616; http://whiteheadresearch.wordpress.com/; https://sites.google.com/a/ucdavis.edu/sara-e-boles/",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408#issuecomment-516194201:1377,log,log,1377,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408#issuecomment-516194201,1,['log'],['log']
Testability,rapidjson internal assertion failure: IsObject(),MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/251:19,assert,assertion,19,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/251,2,['assert'],['assertion']
Testability,"rdinates (as a regular procedure). I know Salmon assumes the alignments are not sorted, so I shuffled these bam files, and then run `salmon quant`.; Here are the errors I got in a number of trials:. ### Fresh installation of Salmon; ```; conda create --name salmon -c bioconda salmon; conda activate salmon; ```. ### 1. Shuffling a bam file with `samtools collate`; ```; samtools collate \; -@ 40 \; -o SRR3212847.Aligned.Shuffled.bam \; SRR3212847.Aligned.SortedByCoord.bam. salmon quant \; -t mRNA.fasta \; -p 20 \; -l A \; -a SRR3212847.Aligned.Shuffled.bam \; -o SRR3212847.Aligned.Shuffled ; ```. ```; Version Info: This is the most recent version of salmon.; # salmon (alignment-based) v1.4.0; # [ program ] => salmon ; # [ command ] => quant ; # [ targets ] => { mRNA.fasta }; # [ threads ] => { 20 }; # [ libType ] => { A }; # [ alignments ] => { SRR3212847.Aligned.Shuffled.bam }; # [ output ] => { SRR3212847.Aligned.Shuffled }; Logs will be written to SRR3212847.Aligned.Shuffled/logs; [2021-01-08 12:43:44.680] [jointLog] [info] setting maxHashResizeThreads to 20; [2021-01-08 12:43:44.680] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; Library format { type:paired end, relative orientation:inward, strandedness:unstranded }; [2021-01-08 12:43:44.711] [jointLog] [info] numQuantThreads = 14; parseThreads = 6; Checking that provided alignment files have consistent headers . . . done; Populating targets from aln = ""SRR3212847.Aligned.Shuffled.bam"", fasta = ""mRNA.fasta"" . . .done. processed 0 reads in current roundSegmentation fault (core dumped); ```. ### 2. Shuffling a headless bam file with `samtools collate`; (I think I saw something about the bam's header in another thread dealing with this issue); ```; samtools view \; -b \; -@ 40 \; -o SRR3212847.Aligned.SortedByCoord.NoHeader.bam \; SRR3212847.Aligned.SortedByCoord.bam. samtools collate \; -@ 40 \; -o SRR3212847.Aligned.Shuffled.NoHeader.bam \; SRR3212847.Ali",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/582#issuecomment-756727212:1122,log,logs,1122,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/582#issuecomment-756727212,1,['log'],['logs']
Testability,"re:. ```; salmon_03; ├── aux_info; │   ├── ambig_info.tsv; │   ├── bootstrap; │   │   ├── bootstraps.gz; │   │   └── names.tsv.gz; │   ├── exp3_pos.gz; │   ├── exp3_seq.gz; │   ├── exp5_pos.gz; │   ├── exp5_seq.gz; │   ├── expected_bias.gz; │   ├── exp_gc.gz; │   ├── fld.gz; │   ├── meta_info.json; │   ├── obs3_pos.gz; │   ├── obs3_seq.gz; │   ├── obs5_pos.gz; │   ├── obs5_seq.gz; │   ├── observed_bias_3p.gz; │   ├── observed_bias.gz; │   └── obs_gc.gz; ├── cmd_info.json; ├── lib_format_counts.json; ├── libParams; │   └── flenDist.txt; ├── logs; │   └── salmon_quant.log; └── quant.sf. 5 directories, 23 files; ```. Not working:. ./salmon/bin/salmon quant -p 64 --index reference/salmon_index -l ISR -1 merged/1791-${id}_1P.fastq.gz -2 merged/1791-${id}_2P.fastq.gz --validateMappings --seqBias --gcBias --posBias --softclip --allowDovetail --recoverOrphans --numBootstraps 10 -o mapped/salmon_${id}. Not working produced the following file structure:. ```; salmon_03_withRecover; ├── aux_info; ├── libParams; └── logs; └── salmon_quant.log. 4 directories, 1 file; ```. The file `mapped/salmon_03_withRecover/logs/salmon_quant.log` has nothing inside it. **Expected behavior**. Properly-mapped reads, as demonstrated by the following metadata:. ```; {; ""salmon_version"": ""1.10.0"",; ""samp_type"": ""bootstrap"",; ""opt_type"": ""vb"",; ""quant_errors"": [],; ""num_libraries"": 1,; ""library_types"": [; ""ISR""; ],; ""frag_dist_length"": 1001,; ""frag_length_mean"": 158.48833607498765,; ""frag_length_sd"": 54.34014977759742,; ""seq_bias_correct"": true,; ""gc_bias_correct"": true,; ""num_bias_bins"": 4096,; ""mapping_type"": ""mapping"",; ""keep_duplicates"": false,; ""num_valid_targets"": 147493,; ""num_decoy_targets"": 61,; ""num_eq_classes"": 179681,; ""serialized_eq_classes"": false,; ""eq_class_properties"": [; ""range_factorized"",; ""gzipped""; ],; ""length_classes"": [; 496,; 768,; 1403,; 2707,; 100404; ],; ""index_seq_hash"": ""c0bf1b46db288bdf947208ef6410a0ced47fa770ab5284a1b231d958b283728b"",; ""index_name_hash"": ""db38822bce0f",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/929:2413,log,logs,2413,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/929,1,['log'],['logs']
Testability,"rease in use of computational resources. ; Mapping validation is planned to become a default option (i.e. turned on by default) in; the next release of salmon.; Unless there is a specific reason to do this (e.g. testing on clean simulated data),; `--validateMappings` is generally recommended. [2019-07-24 13:33:30.080] [jointLog] [info] parsing read library format; [2019-07-24 13:33:30.080] [jointLog] [info] There is 1 library.; /var/spool/slurmd/job12930414/slurm_script: line 14: --validateMappings: command not found; basename: extra operand ‘lightreceptor-1_S114_L005_R1_001.qc.fq.gz’; Try 'basename --help' for more information.; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { abalone_index }; ### [ libType ] => { A }; ### [ mates1 ] => { .R1_001.qc.fq.gz }; ### [ mates2 ] => { .R2_001.qc.fq.gz }; ### [ output ] => { .quant }; Logs will be written to .quant/logs; [2019-07-24 13:33:30.175] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-07-24 13:33:30.175] [jointLog] [warning] . NOTE: It appears you are running salmon without the `--validateMappings` option.; Mapping validation can generally improve both the sensitivity and specificity of mapping,; with only a moderate increase in use of computational resources. ; Mapping validation is planned to become a default option (i.e. turned on by default) in; the next release of salmon.; Unless there is a specific reason to do this (e.g. testing on clean simulated data),; `--validateMappings` is generally recommended. [2019-07-24 13:33:30.175] [jointLog] [info] parsing read library format; [2019-07-24 13:33:30.175] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file abalone_index/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was invoked improperly.; For usage inform",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408:15623,log,logs,15623,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408,1,['log'],['logs']
Testability,"rence transcriptome and my file of decoy names at the bottom of this issue. Details -- . * Which version of salmon was used?: 1.6.0; * How was salmon installed (compiled, downloaded executable, through bioconda)?: Miniconda; * Which reference (e.g. transcriptome) was used?: Self-generated; * Which read files were used?: ERX4307280, SRX10245671, SRX3847835; * Which which program options were used?. ```; salmon quant -i {params.index_dir} -l A -r {input.reads} -o {params.out_dir} --validateMappings --writeUnmappedNames; ```. **Expected behavior**; I expected the reads that were counted in the log file as ""discarded because they are best-mapped to decoys"" to be labelled in the `aux_info/unmapped_names.txt` file with `d`, but all reads were marked as `u`. **Screenshots**; ```; $grep ""Number of fragments discarded because they are best-mapped to decoys"" */logs/*. ERX4307280_quant/logs/salmon_quant.log:[2022-02-02 15:51:25.854] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 948,850; SRX10245671_quant/logs/salmon_quant.log:[2022-02-02 15:57:10.321] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 961,758; SRX3847835_quant/logs/salmon_quant.log:[2022-02-02 15:33:54.185] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 220,351; ```. **Desktop (please complete the following information):**; - OS: Linux; - Version: ; ```; Linux farm.cse.ucdavis.edu 4.15.0-159-generic #167-Ubuntu SMP Tue Sep 21 08:55:05 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux; ```; ```; No LSB modules are available.; Distributor ID:	Ubuntu; Description:	Ubuntu 18.04.6 LTS; Release:	18.04; Codename:	bionic; ```; **Additional context**; I intentionally mapped all three libraries as SE, even though two are PE. Because of the presence of polycistronic transcripts in microbes, many paired-end reads would be discordant, which causes counts to look very...odd. See [this preprint](https://www.biorxiv",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/748:4473,log,logs,4473,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/748,1,['log'],['logs']
Testability,"revious (successful) index build, so I am not sure why I am getting an error that the `versionInfo.json` file is missing. **To Reproduce**; Steps and data to reproduce the behavior:. I followed the alevin-fry tutorial to generate a splici transcriptome, using the same [Human reference (GRCh38) dataset](https://cf.10xgenomics.com/supp/cell-exp/refdata-gex-GRCh38-2020-A.tar.gz) provided by the tutorial. My snakemake rule to build the index uses the same commands outlined in the alevin-fry tutorial, and looks like this:. ```; rule build_idx: ; # build a splici (spliced + intron) index for alevin-fry; input:; fasta = ""{out_data}/ref/transcriptome/transcriptome_splici_fl86.fa""; output:; ""{out_data}/ref/idx/complete_ref_lens.bin"",; ""{out_data}/ref/idx/ctable.bin"",; ""{out_data}/ref/idx/ctg_offsets.bin"",; ""{out_data}/ref/idx/duplicate_clusters.tsv"",; ""{out_data}/ref/idx/info.json"",; ""{out_data}/ref/idx/mphf.bin"",; ""{out_data}/ref/idx/pos.bin"",; ""{out_data}/ref/idx/pre_indexing.log"",; ""{out_data}/ref/idx/rank.bin"",; ""{out_data}/ref/idx/refAccumLengths.bin"",; ""{out_data}/ref/idx/ref_indexing.log"",; ""{out_data}/ref/idx/reflengths.bin"",; ""{out_data}/ref/idx/refseq.bin"",; ""{out_data}/ref/idx/seq.bin"",; ""{out_data}/ref/idx/versionInfo.json""; params:; job_name = ""build_idx"",; memory = ""select[mem>64] rusage[mem=64]"",; out_dir = ""{out_data}/ref/idx""; log:; ""logs/build_idx.out""; threads:; 16; shell:; """"""; salmon index \; -t {input.fasta} \; -i {params.out_dir} \; -p {threads}; """"""; ```. Running this rule does generate all the expected output files, including `versionInfo.json`. My pipeline crashes during the next step, where I am attempting to map reads. Again, I followed the code as outlined by the alevin-fry tutorial (tweaked slightly) and my snakemake rule is as follows (apologies that I am still using the deprecated --end, --barcodeLength and --umiLength options; my intention was to update those once I had my pipeline working, but I've gotten stuck on the index build):. ```; rul",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/713:2321,log,log,2321,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/713,1,['log'],['log']
Testability,"ring aggregation.; [2023-02-22 16:45:42.113] [jointLog] [info] Aggregating expressions to gene level; [2023-02-22 16:45:42.215] [jointLog] [info] done; ```. - Unsuccessful log:. ```; Version Info: This is the most recent version of salmon.; ### salmon (selective-alignment-based) v1.9.0; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ geneMap ] => { /home/cfos/Documents/Collaboration/Ece/2023_Bulk/work/5d/a1220b107b2450d88e8e92fa0f3c06/Homo_sapiens.GRCh38.106.gtf }; ### [ threads ] => { 6 }; ### [ libType ] => { ISR }; ### [ index ] => { /home/cfos/Documents/Collaboration/Ece/2023_Bulk/work/5d/a1220b107b2450d88e8e92fa0f3c06/salmon }; ### [ mates1 ] => { /home/cfos/Documents/Collaboration/Ece/2023_Bulk/work/5d/a1220b107b2450d88e8e92fa0f3c06/ACV_REP2_1_val_1.fq.gz }; ### [ mates2 ] => { /home/cfos/Documents/Collaboration/Ece/2023_Bulk/work/5d/a1220b107b2450d88e8e92fa0f3c06/ACV_REP2_2_val_2.fq.gz }; ### [ seqBias ] => { }; ### [ gcBias ] => { }; ### [ posBias ] => { }; ### [ output ] => { ACV_REP2 }; Logs will be written to ACV_REP2/logs; [2023-02-23 09:39:48.709] [jointLog] [info] setting maxHashResizeThreads to 6; [2023-02-23 09:39:48.709] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2023-02-23 09:39:48.709] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2023-02-23 09:39:48.709] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.; [2023-02-23 09:39:48.709] [jointLog] [info] parsing read library format; [2023-02-23 09:39:48.709] [jointLog] [info] There is 1 library.; [2023-02-23 09:39:48.709] [jointLog] [info] Loading pufferfish index; [2023-02-23 09:39:48.709] [jointLog] [info] Loading dense pufferfish index.; -----------------------------------------; | Loading contig table | Time = 15.056 s; -----------------------------------------; size = 37280289; -------------------------",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/830:8499,Log,Logs,8499,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/830,2,"['Log', 'log']","['Logs', 'logs']"
Testability,"rom untrimmed files:; ```; wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/ERR436/001/ERR4363141/ERR4363141.fastq.gz; ```. I generated the transcriptome by annotating all publicly available genomes for my species (*Faecalibacterium prausnitzii_C*). Using these annotations, I cut out coding domain sequences and nc/r/tRNAs and clustered the sequences at 95% identity. Then, I took the complement of these sequences (all the left over intergenic stuff) and designated these as decoys. . I indexed the transcriptome with:; ```; rule index_transcriptome:; input:; seqs=ancient(""outputs/gtdb_genomes_salmon_ref/{gtdb_species}.fa""),; decoys=ancient(""outputs/gtdb_genomes_intergenic_comb/{gtdb_species}_clustered_intergenic_seq_names.txt""); output: ""outputs/gtdb_genomes_salmon_index/{gtdb_species}/info.json""; threads: 1; params: index_dir = lambda wildcards: ""outputs/gtdb_genomes_salmon_index/"" + wildcards.gtdb_species; resources:; mem_mb=16000,; tmpdir=TMPDIR; conda: ""envs/salmon.yml""; benchmark:""benchmarks/salmon_index_{gtdb_species}.txt""; shell:'''; salmon index -t {input.seqs} -i {params.index_dir} --decoys {input.decoys} -k 31; '''; ```. I've attached my reference transcriptome and my file of decoy names at the bottom of this issue. Details -- . * Which version of salmon was used?: 1.6.0; * How was salmon installed (compiled, downloaded executable, through bioconda)?: Miniconda; * Which reference (e.g. transcriptome) was used?: Self-generated; * Which read files were used?: ERX4307280, SRX10245671, SRX3847835; * Which which program options were used?. ```; salmon quant -i {params.index_dir} -l A -r {input.reads} -o {params.out_dir} --validateMappings --writeUnmappedNames; ```. **Expected behavior**; I expected the reads that were counted in the log file as ""discarded because they are best-mapped to decoys"" to be labelled in the `aux_info/unmapped_names.txt` file with `d`, but all reads were marked as `u`. **Screenshots**; ```; $grep ""Number of fragments discarded because they are best",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/748:3241,benchmark,benchmark,3241,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/748,2,['benchmark'],"['benchmark', 'benchmarks']"
Testability,"rt_scripts/ExitTester.jar 0; Error: dl failure on line 893; Error: failed /path/to/java/8u131/x86_64/jre/lib/amd64/server/libjvm.so, because /path/to/bin/salmon/0.11.3/x86_64/lib/libm.so.6: symbol __get_cpu_features, version GLIBC_PRIVATE not defined in file libc.so.6 with link time reference; Error, cmd: java -Xmx64m -XX:ParallelGCThreads=2 -jar /path/to/trinity/2.6.6/x86_64/util/support_scripts/ExitTester.jar 0 died with ret 1536 at /path/to/bin/core/../..//trinity/2.6.6/x86_64/bin/Trinity line 2581.; 	main::process_cmd('java -Xmx64m -XX:ParallelGCThreads=2 -jar /path/to...') called at /path/to/bin/core/../..//trinity/2.6.6/x86_64/bin/Trinity line 2666; 	eval {...} called at /path/to/bin/core/../..//trinity/2.6.6/x86_64/bin/Trinity line 2665; 	main::test_java_failure_capture() called at /path/to/bin/core/../..//trinity/2.6.6/x86_64/bin/Trinity line 1159. I get similar error while just checking for java version; $ java -version. Error: dl failure on line 893; Error: failed /tsl/software/testing/java/8u131/x86_64/jre/lib/amd64/server/libjvm.so, because /tsl/software/testing/bin/core/../..//salmon/0.11.3/x86_64/lib/libm.so.6: symbol __get_cpu_features, version GLIBC_PRIVATE not defined in file libc.so.6 with link time reference. **To Reproduce**; Steps and data to reproduce the behavior:. Specifically, please provide at least the following information:. * Which version of salmon was used? 0.11.3; * How was salmon installed (compiled, downloaded executable, through bioconda)? downloaded executables; * Which reference (e.g. transcriptome) was used? no reference; * Which read files were used? fastq; * Which program options were used? Trinity options. **Expected behavior**; A clear and concise description of what you expected to happen. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX] CentOS; - Version [ If you are on OSX, the output of",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/290:1662,test,testing,1662,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/290,1,['test'],['testing']
Testability,"s -- . * Which version of salmon was used?: 1.6.0; * How was salmon installed (compiled, downloaded executable, through bioconda)?: Miniconda; * Which reference (e.g. transcriptome) was used?: Self-generated; * Which read files were used?: ERX4307280, SRX10245671, SRX3847835; * Which which program options were used?. ```; salmon quant -i {params.index_dir} -l A -r {input.reads} -o {params.out_dir} --validateMappings --writeUnmappedNames; ```. **Expected behavior**; I expected the reads that were counted in the log file as ""discarded because they are best-mapped to decoys"" to be labelled in the `aux_info/unmapped_names.txt` file with `d`, but all reads were marked as `u`. **Screenshots**; ```; $grep ""Number of fragments discarded because they are best-mapped to decoys"" */logs/*. ERX4307280_quant/logs/salmon_quant.log:[2022-02-02 15:51:25.854] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 948,850; SRX10245671_quant/logs/salmon_quant.log:[2022-02-02 15:57:10.321] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 961,758; SRX3847835_quant/logs/salmon_quant.log:[2022-02-02 15:33:54.185] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 220,351; ```. **Desktop (please complete the following information):**; - OS: Linux; - Version: ; ```; Linux farm.cse.ucdavis.edu 4.15.0-159-generic #167-Ubuntu SMP Tue Sep 21 08:55:05 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux; ```; ```; No LSB modules are available.; Distributor ID:	Ubuntu; Description:	Ubuntu 18.04.6 LTS; Release:	18.04; Codename:	bionic; ```; **Additional context**; I intentionally mapped all three libraries as SE, even though two are PE. Because of the presence of polycistronic transcripts in microbes, many paired-end reads would be discordant, which causes counts to look very...odd. See [this preprint](https://www.biorxiv.org/content/10.1101/2022.01.24.477642v1) for more details on that phenomenon. I'm",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/748:4491,log,log,4491,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/748,1,['log'],['log']
Testability,"s configure 5.2.2, which was; generated by GNU Autoconf 2.69. Invocation command line was. $ /Users/jeremybono/Downloads/salmon-1.10.1/external/xz-5.2.2/configure --prefix=/Users/jeremybono/Downloads/salmon-1.10.1/external/install CC=/Library/Developer/CommandLineTools/usr/bin/cc CXX=/Library/Developer/CommandLineTools/usr/bin/c++ CFLAGS= CPPFLAGS= LDFLAGS=. ## --------- ##; ## Platform. ##; ## --------- ##. hostname = Jeremys-Mac-Studio.local; uname -m = arm64; uname -r = 22.6.0; uname -s = Darwin; uname -v = Darwin Kernel Version 22.6.0: Wed Jul 5 22:21:53 PDT 2023; root:xnu-8796.141.3~6/RELEASE_ARM64_T6020. /usr/bin/uname -p = arm; /bin/uname -X = unknown. /bin/arch = unknown; /usr/bin/arch -k = unknown; /usr/convex/getsysinfo = unknown; /usr/bin/hostinfo = Mach kernel version:; 	 Darwin Kernel Version 22.6.0: Wed Jul 5 22:21:53 PDT 2023; root:xnu-8796.141.3~6/RELEASE_ARM64_T6020; Kernel configured for up to 12 processors.; 12 processors are physically available.; 12 processors are logically available.; Processor type: arm64e (ARM64E); Processors active: 0 1 2 3 4 5 6 7 8 9 10 11; Primary memory available: 64.00 gigabytes; Default processor set: 650 tasks, 3562 threads, 12 processors; Load average: 1.14, Mach factor: 10.84; /bin/machine = unknown; /usr/bin/oslevel = unknown; /bin/universe = unknown. PATH: /Users/jeremybono/miniforge3/bin; PATH: /Users/jeremybono/miniforge3/condabin; PATH: /opt/homebrew/bin; PATH: /opt/homebrew/sbin; PATH: /usr/local/bin; PATH: /System/Cryptexes/App/usr/bin; PATH: /usr/bin; PATH: /bin; PATH: /usr/sbin; PATH: /sbin; PATH: /Users/jeremybono/Downloads/bbmap; PATH: /var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/local/bin; PATH: /var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/bin; PATH: /var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/appleinternal/bin. ## ----------- ##; ## Core tests. ##; ## ----------- ##. configure:2959: checking build system type; configure:2973: result: arm-apple-da",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/912:1988,log,logically,1988,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/912,1,['log'],['logically']
Testability,"s for develop branch.; This fixes https://github.com/COMBINE-lab/salmon/issues/275 . The reason of the build error was because b2 was always built with ""gcc"".; I added something like below code. ```; echo ""using gcc : ${CC_VERSION} : ${CMAKE_CXX_COMPILER} ;"" > ${CMAKE_CURRENT_SOURCE_DIR}/external/boost_1_66_0/tools/build/src/user-config.jam. /path/to/b2 .. toolset=${CC} ...; ```; ; There are still challenges to fix it. 1. The `make test` was finished with timeout. When setting `travis_wait 30 make test`, still failed with the timeout. Maybe we need to change the unit test logic to output something (log or progress bar) regularly to `stdout` during the test process or change the test logic itself. It is freezing at the below point. ```; /usr/local/cmake-3.9.2/bin/ctest --force-new-ctest-process ; Test project /home/travis/build/junaruga/salmon/build; Start 1: unit_tests; ```. 2. The `b2` parameter string `toolset=gcc-7 cxxflags=-std=c++14` is duplicated like this. Maybe we can change the logic in `CMakeLists.txt`. ```; CC=/usr/bin/gcc-7 CXX=/usr/bin/g++-7 /home/travis/build/junaruga/salmon/external/boost_1_66_0/b2 -d0 -j2 --with-iostreams --with-atomic --with-chrono --with-container --with-date_time --with-exception --with-filesystem --with-graph --with-graph_parallel --with-math --with-program_options --with-system --with-locale --with-timer toolset=gcc-7 toolset=gcc-7 cxxflags=-std=c++14 ""cxxflags= -std=c++14 -I/home/travis/build/junaruga/salmon/external/install/include -L/home/travis/build/junaruga/salmon/external/install/lib"" link=static install; ```. 3. `CMakeLists.txt` and `cmake/*.cmake` have a mixture of the different code formatting style. Aligning for formatting those make us read the files easier. I found the useful information for that. [1][2][3][4].; * 2 or 4 space indent?; * ""Tab"" indent is unintentionally used maybe.; * `set(...)` or `set (...)`.; * `set or SET`. [1] the KDE cmake coding style: https://community.kde.org/Policies/CMake_Coding_Style; [2]",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/276:1021,log,logic,1021,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/276,1,['log'],['logic']
Testability,"s to be mapped and a RAD file to be generated. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX] Linux (university cluster); - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux the output of `uname -a` and `lsb_release -a`]; ; Output of `uname -a`:; ```; Linux amc-bodhi 3.10.0-514.21.1.el7.x86_64 #1 SMP Thu May 25 17:04:51 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux; ```. Output of `lsb_release -a`:; ```; LSB Version:	:core-4.1-amd64:core-4.1-noarch:cxx-4.1-amd64:cxx-4.1-noarch:desktop-4.1-amd64:desktop-4.1-noarch:languages-4.1-amd64:languages-4.1-noarch:printing-4.1-amd64:printing-4.1-noarch; Distributor ID:	CentOS; Description:	CentOS Linux release 7.4.1708 (Core) ; Release:	7.4.1708; Codename:	Core; ```. **Additional context**; Add any other context about the problem here. I have attached subsampled fastq files for one of my samples as an example:; [sub_R1.fastq.gz](https://github.com/COMBINE-lab/salmon/files/7331798/sub_R1.fastq.gz); [sub_R2.fastq.gz](https://github.com/COMBINE-lab/salmon/files/7331799/sub_R2.fastq.gz). This is the error log after attempting to run the map reads step, which indicates an issue with the index build:; [B13_MeOH_cells_Jurkat_Cas9_EGR1_1_stimulated.out.err.txt](https://github.com/COMBINE-lab/salmon/files/7331816/B13_MeOH_cells_Jurkat_Cas9_EGR1_1_stimulated.out.err.txt). This is the error log after building the index, which seems to have run successfully (though maybe I am missing something):; [build_idx.out.err.txt](https://github.com/COMBINE-lab/salmon/files/7331817/build_idx.out.err.txt). This is the versionInfo.json file that is successfully generated after building the index, but that can't be found when mapping reads:; [versionInfo.txt](https://github.com/COMBINE-lab/salmon/files/7331818/versionInfo.txt). Thank you so much for any help/insight you might have! I appreciate it.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/713:6593,log,log,6593,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/713,2,['log'],['log']
Testability,"s used?; 0.11.3; * How was salmon installed (compiled, downloaded executable, through bioconda)?; Bioconda; * Which reference (e.g. transcriptome) was used?; gencode.v27.transcripts.fa; * Which read files were used?; fastq; * Which which program options were used?; -l A, single end . **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. ```; salmon quant -i ~/Reference_indexes/humangencodev27_transcripts_index_20181023 -l A -r ~/Downloads/ENCFF600FYP.fastq.gz -o ./salmon_test/ENCFF600FYP_quant; Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; ### salmon (mapping-based) v0.11.3; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { ~/Reference_indexes/humangencodev27_transcripts_index_20181023 }; ### [ libType ] => { A }; ### [ unmatedReads ] => { ~/Downloads/ENCFF600FYP.fastq.gz }; ### [ output ] => { ./salmon_test/ENCFF600FYP_quant }; Logs will be written to ./salmon_test/ENCFF600FYP_quant/logs; [2018-10-23 20:11:13.424] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2018-10-23 20:11:13.425] [jointLog] [info] parsing read library format; [2018-10-23 20:11:13.425] [jointLog] [info] There is 1 library.; [2018-10-23 20:11:13.513] [stderrLog] [info] Loading Suffix Array ; [2018-10-23 20:11:13.513] [jointLog] [info] Loading Quasi index; [2018-10-23 20:11:13.513] [jointLog] [info] Loading 32-bit quasi index; [2018-10-23 20:11:14.645] [stderrLog] [info] Loading Transcript Info ; [2018-10-23 20:11:14.975] [stderrLog] [info] Loading Rank-Select Bit Array; [2018-10-23 20:11:15.031] [stderrLog] [info] There were 199,612 set bits in the bit array; [2018-10-23 20:11:15.042] [stderrLog] [info] Computing transcript lengths; [2018-10-23 20:11:15.042] [stderrLog] [info] Waiting to finish loading hash; [2018-10-23 20:11:20.618] [stderrLog] [info] Done loading index; [20",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/303:1689,Log,Logs,1689,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/303,1,['Log'],['Logs']
Testability,"s.gz; │   ├── exp3_seq.gz; │   ├── exp5_pos.gz; │   ├── exp5_seq.gz; │   ├── expected_bias.gz; │   ├── exp_gc.gz; │   ├── fld.gz; │   ├── meta_info.json; │   ├── obs3_pos.gz; │   ├── obs3_seq.gz; │   ├── obs5_pos.gz; │   ├── obs5_seq.gz; │   ├── observed_bias_3p.gz; │   ├── observed_bias.gz; │   └── obs_gc.gz; ├── cmd_info.json; ├── lib_format_counts.json; ├── libParams; │   └── flenDist.txt; ├── logs; │   └── salmon_quant.log; └── quant.sf. 5 directories, 23 files; ```. Not working:. ./salmon/bin/salmon quant -p 64 --index reference/salmon_index -l ISR -1 merged/1791-${id}_1P.fastq.gz -2 merged/1791-${id}_2P.fastq.gz --validateMappings --seqBias --gcBias --posBias --softclip --allowDovetail --recoverOrphans --numBootstraps 10 -o mapped/salmon_${id}. Not working produced the following file structure:. ```; salmon_03_withRecover; ├── aux_info; ├── libParams; └── logs; └── salmon_quant.log. 4 directories, 1 file; ```. The file `mapped/salmon_03_withRecover/logs/salmon_quant.log` has nothing inside it. **Expected behavior**. Properly-mapped reads, as demonstrated by the following metadata:. ```; {; ""salmon_version"": ""1.10.0"",; ""samp_type"": ""bootstrap"",; ""opt_type"": ""vb"",; ""quant_errors"": [],; ""num_libraries"": 1,; ""library_types"": [; ""ISR""; ],; ""frag_dist_length"": 1001,; ""frag_length_mean"": 158.48833607498765,; ""frag_length_sd"": 54.34014977759742,; ""seq_bias_correct"": true,; ""gc_bias_correct"": true,; ""num_bias_bins"": 4096,; ""mapping_type"": ""mapping"",; ""keep_duplicates"": false,; ""num_valid_targets"": 147493,; ""num_decoy_targets"": 61,; ""num_eq_classes"": 179681,; ""serialized_eq_classes"": false,; ""eq_class_properties"": [; ""range_factorized"",; ""gzipped""; ],; ""length_classes"": [; 496,; 768,; 1403,; 2707,; 100404; ],; ""index_seq_hash"": ""c0bf1b46db288bdf947208ef6410a0ced47fa770ab5284a1b231d958b283728b"",; ""index_name_hash"": ""db38822bce0fbc9a64cfb0b230f58119448d1c82706f1c515f210cccaf4fdf7d"",; ""index_seq_hash512"": ""d683c5132cae8695500566a25eb95c0349427afe1664ac571160337850aa269b634a",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/929:2526,log,log,2526,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/929,1,['log'],['log']
Testability,"s://oceangenomics.com/subscribe; ###; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { assembly_index }; ### [ libType ] => { A }; ### [ unmatedReads ] => { 9998_1.fastq.gz }; ### [ meta ] => { }; ### [ threads ] => { 100 }; ### [ output ] => { 9998.quant_se2 }; Logs will be written to 9998.quant_se2/logs; [2023-03-17 07:40:15.733] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2023-03-17 07:40:15.733] [jointLog] [warning] . NOTE: It appears you are running salmon without the `--validateMappings` option.; Mapping validation can generally improve both the sensitivity and specificity of mapping,; with only a moderate increase in use of computational resources. ; Mapping validation is planned to become a default option (i.e. turned on by default) in; the next release of salmon.; Unless there is a specific reason to do this (e.g. testing on clean simulated data),; `--validateMappings` is generally recommended. [2023-03-17 07:40:15.733] [jointLog] [info] parsing read library format; [2023-03-17 07:40:15.733] [jointLog] [info] There is 1 library.; [2023-03-17 07:40:15.882] [jointLog] [info] Loading Quasi index; [2023-03-17 07:40:15.882] [jointLog] [info] Loading 64-bit quasi index; [2023-03-17 07:40:15.882] [stderrLog] [info] Loading Suffix Array ; [2023-03-17 07:42:06.971] [stderrLog] [info] Loading Transcript Info ; [2023-03-17 07:42:17.580] [stderrLog] [info] Loading Rank-Select Bit Array; [2023-03-17 07:42:20.101] [stderrLog] [info] There were 777288 set bits in the bit array; [2023-03-17 07:42:20.887] [stderrLog] [info] Computing transcript lengths; [2023-03-17 07:42:20.892] [stderrLog] [info] Waiting to finish loading hash; [2023-03-17 07:44:44.131] [stderrLog] [info] Done loading index; [2023-03-17 07:44:44.131] [jointLog] [info] done; [2023-03-17 07:44:44.131] [jointLog] [info] Index contained 777288 targets. processed 40500000 fragmentsointLog",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/838:7238,test,testing,7238,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/838,1,['test'],['testing']
Testability,"salmon version 1.5.1; Running with the following keystrokes:; salmon quant -i contig_index -l A -1 R1.fastq -2 R2.fastq -o salmonoutput (screenshot attached as ""command""). It keeps throwing the attached error message (as log).; Ive verified the R1 and R2 have the same number of entries using grep to count the number of ""@"" symbols. These match. The lines of each file are the same as well. (screenshot also attached as ""size""); ![Command](https://user-images.githubusercontent.com/50889111/134416661-77de22d1-5fc4-4b89-a21d-940948fdc4b8.png); ![Size](https://user-images.githubusercontent.com/50889111/134416664-21c6373f-57be-4c8d-b917-68aa16262f57.png); <img width=""1314"" alt=""Log"" src=""https://user-images.githubusercontent.com/50889111/134416666-5dcf3843-ef06-45b1-bb77-6c2dbae9e6e4.png"">. I'm not sure what to do from here; Please help.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/709:221,log,log,221,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/709,2,"['Log', 'log']","['Log', 'log']"
Testability,"salmon/lib/libtbb.so; -- Installing: /salmon/lib/libtbb.so.12; -- Installing: /salmon/lib/libtbb.so.12.5; -- Installing: /salmon/lib/libtbbmalloc.so; -- Installing: /salmon/lib/libtbbmalloc.so.2; -- Installing: /salmon/lib/libtbbmalloc.so.2.5; -- Installing: /salmon/lib/libtbbmalloc_proxy.so; -- Installing: /salmon/lib/libtbbmalloc_proxy.so.2; -- Installing: /salmon/lib/libtbbmalloc_proxy.so.2.5; -- Installing: /salmon/bin/salmon; -- Installing: /salmon/lib/libsalmon_core.a. Installation complete. Please ensure the following paths are set properly.; ==========================================================================; Please add /salmon/bin to your PATH; Please add /salmon/lib to your LD_LIBRARY_PATH; ==========================================================================; root@fd877e359439:/salmon/build# make test; Running tests...; Test project /salmon/build; Start 1: unit_tests; 1/2 Test #1: unit_tests ....................... Passed 0.37 sec; Start 2: salmon_read_test_quasi; 2/2 Test #2: salmon_read_test_quasi ........... Passed 1.80 sec. 100% tests passed, 0 tests failed out of 2. Total Test time (real) = 2.17 sec; ```. The `make test` command itself runs the test the builds the index and maps the reads against it. Either way, I can do that explicitly too (from within build):. ```; $ ./src/salmon index -t ../sample_data/transcripts.fasta -i sample_idx; ```. returns succesfully with a built index. ```; ...; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Done wrapping the rank vector with a rank9sel structure.; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] contig count for validation: 23; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Total # of Contigs : 23; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Total # of numerical Contigs : 23; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] Total # of contig vec entries: 36; [2023-03-10 05:51:33.748] [puff::index::jointLog] [info] bits per offset entry 6; [202",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554:2862,Test,Test,2862,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1463312554,1,['Test'],['Test']
Testability,"salmon_test.gsk_phaseII; jobnumber 9987275; taskid 3; account sge; priority 0; qsub_time Wed Mar 8 11:37:17 2017; start_time Wed Mar 8 11:37:31 2017; end_time Wed Mar 8 11:37:36 2017; granted_pe local; slots 1; failed 0; exit_status 0; ru_wallclock 5; ru_utime 0.368; ru_stime 3.680; ru_maxrss 537668; ru_ixrss 0; ru_ismrss 0; ru_idrss 0; ru_isrss 0; ru_minflt 21951; ru_majflt 282; ru_nswap 0; ru_inblock 56; ru_oublock 1066296; ru_msgsnd 0; ru_msgrcv 0; ru_nsignals 0; ru_nvcsw 1230; ru_nivcsw 53; cpu 4.048; mem 27.889; io 0.002; iow 0.000; maxvmem 10.736G; arid undefined; ```. I'm sure that the job got terminated because the memory reached the limit of 11 GB. . I previously did several tests where for a file the max memory reported was about 9 GB when requesting about 100G of RAM, and the same job kept failing even if I requested 10G, 20G, 30G, 40G... I didn't save the info then to report the problem. . Back on these tests, I then increased the memory requested a bit more (and used the `-m e` SGE option to get an email with the max vmem, which matches the `qacct` output). Here is the bash script:. ```bash; #!/bin/bash; #$ -cwd; #$ -l mem_free=14G,h_vmem=15G,h_fsize=100G; #$ -N step6-salmon_test2.gsk_phaseII; #$ -pe local 1; #$ -o ./logs/salmon_test2.$TASK_ID.txt; #$ -e ./logs/salmon_test2.$TASK_ID.txt; #$ -m e; echo ""**** Job starts ****""; date. echo ""**** JHPCE info ****""; echo ""User: ${USER}""; echo ""Job id: ${JOB_ID}""; echo ""Job name: ${JOB_NAME}""; echo ""Hostname: ${HOSTNAME}""; echo ""Task id: ${TASK_ID}"". FILE1=$(awk 'BEGIN {FS=""\t""} {print $1}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); FILE2=$(awk 'BEGIN {FS=""\t""} {print $3}' /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk ""NR==${SGE_TASK_ID}""); ID=$(cat /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/samples.manifest | awk '{print $NF}' | awk ""NR==${SGE_TASK_ID}""). mkdir -p /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test2/${ID}. /dcl01/",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126:26799,test,tests,26799,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126,1,['test'],['tests']
Testability,"set to 0.65; [2021-04-09 12:16:37.619] [jointLog] [info] The use of range-factorized equivalence classes does not make sense in conjunction with --hardFilter. Disabling range-factorized equivalence classes.; [2021-04-09 12:16:37.619] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.; [2021-04-09 12:16:37.619] [jointLog] [info] Using default value of 0.87 for minScoreFraction in Alevin; Using default value of 0.6 for consensusSlack in Alevin; [2021-04-09 12:16:37.649] [alevinLog] [info] Found 45374 transcripts(+1 decoys, +0 short and +0 duplicate names in the index); [2021-04-09 12:16:37.702] [alevinLog] [info] Filled with 45374 txp to gene entries; ### alevin (dscRNA-seq quantification) v1.4.0; ### [ program ] => salmon; ### [ command ] => alevin; ### [ libType ] => { ISR }; ### [ index ] => { results/salmon/index/GRCh38.p13 }; ### [ mates1 ] => { /Users/james/GitHub/scrnaseq/.tests/fastq/S1_L001_R1_001.fastq.gz /Users/james/GitHub/scrnaseq/.tests/fastq/S1_L002_R1_001.fastq.gz /Users/james/GitHub/scrnaseq/.tests/fastq/S1_L003_R1_001.fastq.gz /Users/james/GitHub/scrnaseq/.tests/fastq/S1_L004_R1_001.fastq.gz }; ### [ mates2 ] => { /Users/james/GitHub/scrnaseq/.tests/fastq/S1_L001_R2_001.fastq.gz /Users/james/GitHub/scrnaseq/.tests/fastq/S1_L002_R2_001.fastq.gz /Users/james/GitHub/scrnaseq/.tests/fastq/S1_L003_R2_001.fastq.gz /Users/james/GitHub/scrnaseq/.tests/fastq/S1_L004_R2_001.fastq.gz }; ### [ output ] => { results/salmon/alevin/S1 }; ### [ threads ] => { 1 }; ### [ tgMap ] => { results/eisar/GRCh38.p13/GRCh38.p13.tx2gene.tsv }; ### [ chromiumV3 ] => { }; ### [ mrna ] => { results/gffread/GRCh38.p13/GRCh38.p13.mrna.txt }; ### [ rrna ] => { results/gffread/GRCh38.p13/GRCh38.p13.rrna.txt }. [2021-04-09 12:16:37.708] [alevinLog] [info] Found all transcripts to gene mappings; [2021-04-09 12:16:37.722] [alevinLog] [info] Processing barcodes files (if Present). [2021-04-09 12:16:37.728] [alevinLog] [info] Done barcode density calculation.;",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/647:1822,test,tests,1822,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/647,1,['test'],['tests']
Testability,set:; `~/software/salmon/scripts/v1_10x/run.sh ~/software/salmon/bin/salmon salmon alevin -l ISR -b ./fastq/fastqs/flowcell1/ --gemcode -i ./transcripts_index_salmon/ -p 8 -o ./fastq/test/ --tgMap ./hg_transcriptome/tx2tx.tsv --end 5 --umiLength 5 --barcodeLength 14 --dumpCsvCounts; `; and the following one for the PBMC_3K dataset:; `~/software/salmon/scripts/v1_10x/run.sh ~/software/salmon/bin/salmon alevin -l ISR -b pbmc3k_fastqs/ --gemcode -i ../transcripts_index_salmon/ -p 8 -o alevin_output --tgMap ../hg_transcriptome/tx2gene.tsv --dumpCsvCounts; `. **Screenshots**; CD14+ Monocytes shell log:; ```~/software/salmon/scripts/v1_10x/run.sh salmon alevin -l ISR -b ./fastqs/flowcell1/ --gemcode -i ../transcripts_index_salmon/ -p 8 -o ./fastq/test/ --tgMap ../hg_transcriptome/tx2tx.tsv --end 5 --umiLength 5 --barcodeLength 14 --dumpCsvCounts --dumpFeatures. TEMPDIR is /tmp/tmp.lLLibfwH4G; Running command [salmon alevin -l ISR --gemcode -i ../transcripts_index_salmon/ -p 8 -o ./fastq/test/ --tgMap ../hg_transcriptome/tx2tx.tsv --end 5 --umiLength 5 --barcodeLength 14 --dumpCsvCounts --dumpFeatures -1 /tmp/tmp.lLLibfwH4G/p1.fa -2 /tmp/tmp.lLLibfwH4G/p2.fa -r ./fastqs/flowcell1/read-I1_si-ACTTCACT_lane-001-chunk-001.fastq.gz; ./fastqs/flowcell1/read-I1_si-ACTTCACT_lane-002-chunk-000.fastq.gz; ./fastqs/flowcell1/read-I1_si-ACTTCACT_lane-003-chunk-003.fastq.gz; ./fastqs/flowcell1/read-I1_si-ACTTCACT_lane-004-chunk-002.fastq.gz; ./fastqs/flowcell1/read-I1_si-CGAAGTTG_lane-001-chunk-001.fastq.gz; ./fastqs/flowcell1/read-I1_si-CGAAGTTG_lane-002-chunk-000.fastq.gz; ./fastqs/flowcell1/read-I1_si-CGAAGTTG_lane-003-chunk-003.fastq.gz; ./fastqs/flowcell1/read-I1_si-CGAAGTTG_lane-004-chunk-002.fastq.gz; ./fastqs/flowcell1/read-I1_si-GAGCACGC_lane-001-chunk-001.fastq.gz; ./fastqs/flowcell1/read-I1_si-GAGCACGC_lane-002-chunk-000.fastq.gz; ./fastqs/flowcell1/read-I1_si-GAGCACGC_lane-003-chunk-003.fastq.gz; ./fastqs/flowcell1/read-I1_si-GAGCACGC_lane-004-chunk-002.fastq.gz; ./fastqs/fl,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/328:2154,test,test,2154,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/328,1,['test'],['test']
Testability,"sh had 109134690 keys; saving hash to disk . . . done; Elapsed time: 12.6069s; [2018-06-25 19:29:02.297] [jLog] [info] done building index; ```. It would be more interesting to see what filename is used for the index. Showing the ""basename"" of the index file is not very helpful. I would prefer to see the filename(s) on the beginning and end lines:. ```; index [""Homo_sapiens.GRCh38.cdna.all""] did not previously exist . . . creating it; [2018-06-25 19:25:57.122] [jLog] [info] building index; ...; [2018-06-25 19:29:02.297] [jLog] [info] done building index; ```. 5. The duplicates have same sequence or ID or both? The message should be clearer. I wonder what are these duplicates in a human cdna predicted, as available from `ftp://ftp.ensembl.org/pub/release-92/fasta/homo_sapiens/cdna`; :. ```; [2018-06-25 19:26:07.480] [jointLog] [warning] Removed 11768 transcripts that were sequence duplicates of indexed transcripts.; ```. 6. For the bwa-based index again, the logs are too verbose on one hand and on the second, they do not say what files were created. I doubt any file with *prefix* `Homo_sapiens.GRCh38.cdna.all/bwaidx` was created. ```; + salmon index -t Homo_sapiens.GRCh38.cdna.all.fa -i Homo_sapiens.GRCh38.cdna.all --type fmd; outputPrefix = ""Homo_sapiens.GRCh38.cdna.all/bwaidx""; [2018-06-25 19:29:02.497] [jLog] [info] building index; [bwa_index] Pack FASTA... 2.87 sec; [bwa_index] Construct BWT for the packed sequence...; [BWTIncCreate] textLength=609536484, availableWord=54888760; [BWTIncConstructFromPacked] 10 iterations done. 87569268 characters processed.; [BWTIncConstructFromPacked] 20 iterations done. 164630980 characters processed.; [BWTIncConstructFromPacked] 30 iterations done. 233119636 characters processed.; [BWTIncConstructFromPacked] 40 iterations done. 293988548 characters processed.; [BWTIncConstructFromPacked] 50 iterations done. 348084948 characters processed.; [BWTIncConstructFromPacked] 60 iterations done. 396161956 characters processed.; [BWTIncC",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/242:13534,log,logs,13534,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/242,1,['log'],['logs']
Testability,"si-GAGCACGC_lane-003-chunk-003.fastq.gz; ./fastqs/flowcell1/read-I1_si-GAGCACGC_lane-004-chunk-002.fastq.gz; ./fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-001-chunk-001.fastq.gz; ./fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-002-chunk-000.fastq.gz; ./fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-003-chunk-003.fastq.gz; ./fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-004-chunk-002.fastq.gz]; Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; [2018-12-05 15:10:07.252] [alevinLog] [info] A custom protocol (END, BC length, UMI length) = (5, 14, 5) is being used. Updating UMI k-mer length accordingly.; Logs will be written to ./fastq/test/logs; ### alevin (dscRNA-seq quantification) v0.11.3; ### [ program ] => salmon ; ### [ command ] => alevin ; ### [ libType ] => { ISR }; ### [ gemcode ] => { }; ### [ index ] => { ../transcripts_index_salmon/ }; ### [ threads ] => { 8 }; ### [ output ] => { ./fastq/test/ }; ### [ tgMap ] => { ../hg_transcriptome/tx2tx.tsv }; ### [ end ] => { 5 }; ### [ umiLength ] => { 5 }; ### [ barcodeLength ] => { 14 }; ### [ dumpCsvCounts ] => { }; ### [ dumpFeatures ] => { }; ### [ mates1 ] => { /tmp/tmp.lLLibfwH4G/p1.fa }; ### [ mates2 ] => { /tmp/tmp.lLLibfwH4G/p2.fa }; ### [ unmatedReads ] => { ./fastqs/flowcell1/read-I1_si-ACTTCACT_lane-001-chunk-001.fastq.gz ./fastqs/flowcell1/read-I1_si-ACTTCACT_lane-002-chunk-000.fastq.gz ./fastqs/flowcell1/read-I1_si-ACTTCACT_lane-003-chunk-003.fastq.gz ./fastqs/flowcell1/read-I1_si-ACTTCACT_lane-004-chunk-002.fastq.gz ./fastqs/flowcell1/read-I1_si-CGAAGTTG_lane-001-chunk-001.fastq.gz ./fastqs/flowcell1/read-I1_si-CGAAGTTG_lane-002-chunk-000.fastq.gz ./fastqs/flowcell1/read-I1_si-CGAAGTTG_lane-003-chunk-003.fastq.gz ./fastqs/flowcell1/read-I1_si-CGAAGTTG_lane-004-chunk-002.fastq.gz ./fastqs/flowcell1/read-I1_si-GAGCACGC_lane-001-chunk-001.fastq.gz ./fastqs/flowcell1/read-I1_si-GAGCACGC_lane-002-chunk-000.fastq.gz ./fastqs/flowc",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/328:4027,test,test,4027,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/328,1,['test'],['test']
Testability,"so, I did fix the `umi_tools` commands as; ```; umi_tools whitelist \; -I /home/GSE140511/fastq_files/SRR10480618_1.fastq.gz \; --bc-pattern=CCCCCCCCCCCCCCCCNNNNNNNNNNNN \; --log=/home/GSE140511/SRR10480618_fq/SRR10480618_log_whitelist.log \; --log2stderr > /home/GSE140511/SRR10480618_fq/SRR10480618_whitelist.txt. umi_tools extract \; --bc-pattern=CCCCCCCCCCCCCCCCNNNNNNNNNNNN \; --stdin /home/GSE140511/fastq_files/SRR10480618_1.fastq.gz \; --stdout /home/GSE140511/SRR10480618_fq/SRR10480618_BC_1.fastq.gz \; --read2-in /home/GSE140511/fastq_files/SRR10480618_2.fastq.gz \; --read2-out=/home/GSE140511/SRR10480618_fq/SRR10480618_BC_2.fastq.gz \; --whitelist=/home/GSE140511/SRR10480618_fq/SRR10480618_whitelist.txt; ```. I swapped the reads as:; ```; /salmon-1.8.0_linux_x86_64/bin/salmon alevin \; -l ISR \; -2 /home/GSE140511/SRR10480618_fq/SRR10480618_BC_trimmed_1.fastq.gz \; -1 /home/GSE140511/SRR10480618_fq/SRR10480618_BC_trimmed_2.fastq.gz \; --chromiumV3 \; -i /data/ref_genomes/Mmus_GrCm39 \; -p 32 \; -o /home/GSE140511/salmon_alevin_output/SRR10480618_rev2 \; --expectCells 3000 --forceCells 3000 \; --tgMap /home/txp2gene_SB.tsv; ```; I tried both `ISR` and `ISF` (just in case)...mapping rate ranged from zero point something to one point something.; I also tried with and without `--expectCells 3000 --forceCells 3000` looking at a few suggestions [here](https://github.com/COMBINE-lab/salmon/discussions/506) but it didn't really make any difference. `Alevin.log` from the last run is:; ````; [2022-03-27 05:24:09.430] [alevinLog] [info] Found 116716 transcripts(+0 decoys, +39 short and +0 duplicate names in the index); [2022-03-27 05:24:09.478] [alevinLog] [info] Filled with 116755 txp to gene entries ; [2022-03-27 05:24:09.484] [alevinLog] [info] Found all transcripts to gene mappings; [2022-03-27 05:24:09.495] [alevinLog] [info] Processing barcodes files (if Present) . ; [2022-03-27 05:33:37.411] [alevinLog] [info] Done barcode density calculation.; [2022-03-27 05:33:37",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/763#issuecomment-1082597942:175,log,log,175,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/763#issuecomment-1082597942,2,['log'],['log']
Testability,"species}/info.json""; threads: 1; params: index_dir = lambda wildcards: ""outputs/gtdb_genomes_salmon_index/"" + wildcards.gtdb_species; resources:; mem_mb=16000,; tmpdir=TMPDIR; conda: ""envs/salmon.yml""; benchmark:""benchmarks/salmon_index_{gtdb_species}.txt""; shell:'''; salmon index -t {input.seqs} -i {params.index_dir} --decoys {input.decoys} -k 31; '''; ```. I've attached my reference transcriptome and my file of decoy names at the bottom of this issue. Details -- . * Which version of salmon was used?: 1.6.0; * How was salmon installed (compiled, downloaded executable, through bioconda)?: Miniconda; * Which reference (e.g. transcriptome) was used?: Self-generated; * Which read files were used?: ERX4307280, SRX10245671, SRX3847835; * Which which program options were used?. ```; salmon quant -i {params.index_dir} -l A -r {input.reads} -o {params.out_dir} --validateMappings --writeUnmappedNames; ```. **Expected behavior**; I expected the reads that were counted in the log file as ""discarded because they are best-mapped to decoys"" to be labelled in the `aux_info/unmapped_names.txt` file with `d`, but all reads were marked as `u`. **Screenshots**; ```; $grep ""Number of fragments discarded because they are best-mapped to decoys"" */logs/*. ERX4307280_quant/logs/salmon_quant.log:[2022-02-02 15:51:25.854] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 948,850; SRX10245671_quant/logs/salmon_quant.log:[2022-02-02 15:57:10.321] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 961,758; SRX3847835_quant/logs/salmon_quant.log:[2022-02-02 15:33:54.185] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 220,351; ```. **Desktop (please complete the following information):**; - OS: Linux; - Version: ; ```; Linux farm.cse.ucdavis.edu 4.15.0-159-generic #167-Ubuntu SMP Tue Sep 21 08:55:05 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux; ```; ```; No LSB modules are available.;",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/748:4019,log,log,4019,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/748,1,['log'],['log']
Testability,"ted data),; `--validateMappings` is generally recommended. [2019-07-24 13:33:29.532] [jointLog] [info] parsing read library format; Exception : [Error: The index version file abalone_index/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was invoked improperly.; For usage information, try salmon[2019-07-24 13:33:29.532] [jointLog] [info] There is 1 library.; quant --help; Exiting.; /var/spool/slurmd/job12930414/slurm_script: line 14: --validateMappings: command not found; basename: extra operand ‘lightreceptor-1_S114_L005_R1_001.qc.fq.gz’; Try 'basename --help' for more information.; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { abalone_index }; ### [ libType ] => { A }; ### [ mates1 ] => { .R1_001.qc.fq.gz }; ### [ mates2 ] => { .R2_001.qc.fq.gz }; ### [ output ] => { .quant }; Logs will be written to .quant/logs; [2019-07-24 13:33:29.626] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-07-24 13:33:29.626] [jointLog] [warning] . NOTE: It appears you are running salmon without the `--validateMappings` option.; Mapping validation can generally improve both the sensitivity and specificity of mapping,; with only a moderate increase in use of computational resources. ; Mapping validation is planned to become a default option (i.e. turned on by default) in; the next release of salmon.; Unless there is a specific reason to do this (e.g. testing on clean simulated data),; `--validateMappings` is generally recommended. [2019-07-24 13:33:29.626] [jointLog] [info] parsing read library format; [2019-07-24 13:33:29.626] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file abalone_index/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was invoked improperly.; For usage inform",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408:5957,log,logs,5957,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408,1,['log'],['logs']
Testability,"tem system timer chrono program_options); message(""BOOST_INCLUDEDIR = ${BOOST_INCLUDEDIR}""); message(""BOOST_LIBRARYDIR = ${BOOST_LIBRARYDIR}""); +message(""Forcing Boost_FOUND to TRUE""); +set(Boost_FOUND TRUE); +set(Boost_LIBRARY_DIRS ""/usr/lib64/boost169""); +set(Boost_LIBRARIES -lboost_iostreams -lboost_filesystem -lboost_system -lboost_timer -lboost_chrono -lboost_program_options); message(""Boost_FOUND = ${Boost_FOUND}""); endif(); ; EOD; patch -p0 <mypatch; module load cmake; module load io_lib; module load libgff; module load libtbb; # module load pufferfish #ignored even if set; mkdir build; cd build; cmake \; -DCMAKE_INSTALL_PREFIX=$TOPDIR \; -DSTADEN_ROOT=$ROOT_IO_LIB \; -DGFF_ROOT=$ROOT_LIBGFF \; -DTBB_ROOT=$ROOT_LIBTBB \; -DCMAKE_VERBOSE_MAKEFILE:BOOL=ON \; -DBOOST_LIBRARYDIR=/usr/lib64/boost169 \; -DBOOST_INCLUDEDIR=/usr/include/boost169 \; -DBoost_NO_SYSTEM_PATHS=ON \; .. 2>&1 | tee cmake_2020_06_23.log; make -j 4 2>&1 | tee build_2020_06_23.log; make test # both passed; make install 2>&1 | tee install_2020_06_23.log; cd ..; cp sample_data.tgz $TOPDIR; module_generate_from_directory.sh \; $package \; $pversion \; CentOS/vanilla \; $TOPDIR \; ""Fast highly-accurate, transcript-level quantification estimates from RNA-seq data."" \; ""https://github.com/COMBINE-lab/salmon""; ```. When the following commands are run in an XFCE4 terminal or an uxterm (black text, white background) using the sample data provided in the distribution:. ```; gunzip -c sample_data.tgz | (cd /tmp; tar -xf -); module load salmon; cd /tmp/sample_data; salmon index -t transcripts.fasta -i sample_salmon_fmd_index --type puff; salmon quant -i sample_salmon_fmd_index \; -l IU \; -1 reads_1.fastq -2 reads_2.fastq \; -o sample_salmon_fmd_quant. ```; the output line:. ```; [2020-06-23 13:58:50.657] [jointLog] [warning] Only 10000 fragments were mapped, but the number of burn-in fragments was set to 5000000.; The effective lengths have been computed using the observed mappings.; ```. is emitted in ye",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/541:1645,log,log,1645,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/541,2,"['log', 'test']","['log', 'test']"
Testability,"test/salmon_0.8.2_index_gencode.v25.transcripts }; ### [ threads ] => { 1 }; ### [ libType ] => { ISR }; ### [ mates1 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX.fastq.gz }; ### [ mates2 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10001_D2B1WACXX_read2.fastq.gz }; ### [ output ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX }; ) = 594; stat(""/etc/localtime"", {st_mode=S_IFREG|0644, st_size=3519, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX/logs"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX/logs"", 0x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, ...}) = 0; mkdir(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX/logs"", 0777) = 0; write(2, ""Logs will be written to "", 24Logs will be written to ) = 24; write(2, ""/dcl01/lieber/ajaffe/lab/libd_al""..., 81/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX/logs) = 81; write(2, ""\n"", 1; ) = 1; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX/libParams"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX/libParams"", 0x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, .",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:105651,log,logs,105651,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,2,['log'],['logs']
Testability,"test/salmon_0.8.2_index_gencode.v25.transcripts }; ### [ threads ] => { 1 }; ### [ libType ] => { ISR }; ### [ mates1 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10002_C29P7ACXX.fastq.gz }; ### [ mates2 ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/merged_fastq/R10002_C29P7ACXX_read2.fastq.gz }; ### [ output ] => { /dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX }; ) = 594; stat(""/etc/localtime"", {st_mode=S_IFREG|0644, st_size=3519, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, ...}) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX/logs"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX/logs"", 0x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, ...}) = 0; mkdir(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX/logs"", 0777) = 0; write(2, ""Logs will be written to "", 24Logs will be written to ) = 24; write(2, ""/dcl01/lieber/ajaffe/lab/libd_al""..., 81/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX/logs) = 81; write(2, ""\n"", 1; ) = 1; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX/libParams"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX/libParams"", 0x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, .",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:67069,log,logs,67069,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,2,['log'],['logs']
Testability,"tested with 32G and 16GB of memory, just to see what impact this would have on the times. Those jobs are still running (it's only been about 4hrs as of this writing, I'll update my post if/when they complete). Current logs are showing that they quickly consume all the available memory, but have not yet crashed. I've also got versions with 128-512GB of memory requested (by powers of 2) for comparison. Some random notes: both the 31-mer index experienced about twice as many soft page reclaims with the new/faster version and experienced a few hard page faults (the previous version saw none of the latter). The 17-mer version experienced fewer page reclaims than any of the 31-mer indices and far fewer than with the prior version. Again, a few page faults crept in, but relatively few by percentage and likely not contributing any significant amount of time overall. [index-qacct-17mer.log](https://github.com/COMBINE-lab/salmon/files/4246516/index-qacct-17mer.log); [index-qacct-31mer.log](https://github.com/COMBINE-lab/salmon/files/4246517/index-qacct-31mer.log). **UPDATE**; The 16GB version finished running. It actually only took a little over 4 hours to run, as well. The troubling thing about this job seems to be that, despite having successfully completed, according to the accounting log it used over 20GB of memory... which should be impossible to do. Our resident experts suspect there's a race condition occurring at the tail end of the job and that all of that extra memory is being allocated before the scheduler can kill it for exceeding the limit. Whatever the case, though, this throws into question some of those numbers that I've been grabbing from the accounting logs --- it's either being misreported, or the memory gobbling is happening so rapidly that it may not, in fact, be being properly recorded. I tested the index anyway. It *appears* to be working just fine. Nothing faulted or crashed when I attempted to quantify some reads against it. [index-qacct-17mer-16gigs.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-590516702:1713,log,log,1713,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-590516702,1,['log'],['log']
Testability,"the number of burn-in fragments was set to 5000000.; The effective lengths have been computed using the observed mappings. [2021-06-22 12:39:41.282] [jointLog] [info] Mapping rate = 55.5444%. about half of our samples have over 90% mapping rates. . Any idea what this warning means?. **To Reproduce**; Steps and data to reproduce the behavior:. salmon 1.4.0 ; Linux mustard 3.10.0-862.6.3.el7.x86_64 #1 SMP Tue Jun 26 16:32:21 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux. $ cat /etc/redhat-release; CentOS Linux release 7.5.1804 (Core) . I think when I installed salmon I could not install the 1.5.x version. I forgot why; ```; function runSalmon() {; # runs salmon on one sample and outputs to that directory ; salmonIndexDir=""$1""; rightReads=""$2""; leftReads=""$3""; outputDir=""$4"". #set -x # turn debug on ; # set +x # turn debug off . if [[ ! -f ""$outputDir""/quant.sf ]]; then. 	mkdir -p ""$outputDir"". # printf ""##############\n"" ; # printf ""warning --minAssignedFrags is set to $minNumFrags to enable test data set\n"" ; # minNumFrags=1 ; # --minAssignedFrags=$minNumFrags \ ; # printf ""##############\n"" . #if [[ -f ""$inputDir""/output_single_end.fq.gz ]]; then . numThr=12; salmon quant \; -i $salmonIndexDir \; --libType A \; -1 ""${rightReads}"" \; -2 ""${leftReads}"" \; -p $numThr \; --recoverOrphans \; --validateMappings \; --gcBias \; --seqBias \; --rangeFactorizationBins 4 \; --writeUnmappedNames \; --output ${outputDir}. salmonRet=$?; if [ $salmonRet -ne 0 ]; then; echo ERROR salmon ""$rightReads"" returned exit status ""$exitStatus""; continue; fi. #fi ; else; echo ""[INFO] skipping ${outputDir}/quant.sf it already exists""; fi; }; ```. Specifically, please provide at least the following information:. * Which version of salmon was used?; * salmon 1.4.0 . * How was salmon installed (compiled, downloaded executable, through bioconda)?; * compiled locally salmon-1.4.0_linux_x86_64.tar.gz; * ; * Which reference (e.g. transcriptome) was used?; * we have custom human ref with additional annotatio",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/677:1418,test,test,1418,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/677,1,['test'],['test']
Testability,"the pool. No new fragments will be allocated. processed 26000000 reads in current roundSegmentation fault (core dumped); ```. Output for failure case - four files. ```; salmon quant -t /rsstu/users/c/cjdohert/NSF_Tomato/AT_RefGenomeFiles/TAIR10_chr_all.fas -l A -a leaf_mock_t6_rep3_S64_R1_001Aligned.out.bam leaf_mock_t6_rep1_S40_R1_001Aligned.out.bam leaf_mock_t5_rep3_S63_R1_001Aligned.out.bam leaf_mock_t5_rep1_S39_R1_001Aligned.out.bam -p 8 -o ../SalmonQuantFiles; Version Info: This is the most recent version of salmon.; # salmon (alignment-based) v1.9.0; # [ program ] => salmon ; # [ command ] => quant ; # [ targets ] => { /rsstu/users/c/cjdohert/NSF_Tomato/AT_RefGenomeFiles/TAIR10_chr_all.fas }; # [ libType ] => { A }; # [ alignments ] => { leaf_mock_t6_rep3_S64_R1_001Aligned.out.bam leaf_mock_t6_rep1_S40_R1_001Aligned.out.bam leaf_mock_t5_rep3_S63_R1_001Aligned.out.bam leaf_mock_t5_rep1_S39_R1_001Aligned.out.bam }; # [ threads ] => { 8 }; # [ output ] => { ../SalmonQuantFiles }; Logs will be written to ../SalmonQuantFiles/logs; [2023-01-29 16:52:41.666] [jointLog] [info] setting maxHashResizeThreads to 8; [2023-01-29 16:52:41.666] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; Library format { type:single end, relative orientation:none, strandedness:unstranded }; [2023-01-29 16:52:41.668] [jointLog] [info] numQuantThreads = 4; parseThreads = 4; Checking that provided alignment files have consistent headers . . . done; Populating targets from aln = ""leaf_mock_t6_rep3_S64_R1_001Aligned.out.bam"", fasta = ""/rsstu/users/c/cjdohert/NSF_Tomato/AT_RefGenomeFiles/TAIR10_chr_all.fas"" . . .done. processed 0 reads in current round[2023-01-29 16:52:42.565] [jointLog] [info] replaced 186,207 non-ACGT nucleotides with random nucleotides; processed 2000000 reads in current round[2023-01-29 16:52:43.137] [jointLog] [info] Automatically detected most likely library type as U. [2023-01-29 16:52:43.276] [jointLog] [info] .",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/825:8830,Log,Logs,8830,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/825,1,['Log'],['Logs']
Testability,"threads:; 16; shell:; """"""; salmon index \; -t {input.fasta} \; -i {params.out_dir} \; -p {threads}; """"""; ```. Running this rule does generate all the expected output files, including `versionInfo.json`. My pipeline crashes during the next step, where I am attempting to map reads. Again, I followed the code as outlined by the alevin-fry tutorial (tweaked slightly) and my snakemake rule is as follows (apologies that I am still using the deprecated --end, --barcodeLength and --umiLength options; my intention was to update those once I had my pipeline working, but I've gotten stuck on the index build):. ```; rule map_reads: ; # map reads and generate a RAD (Reduced Alignment Data) file; input:; R1 = ""{out_data}/preprocessed_fastqs/{sample}_R1.fastq.gz"",; R2 = ""{out_data}/preprocessed_fastqs/{sample}_R2.fastq.gz"",; idx = rules.build_idx.output,; tgmap = ""{out_data}/ref/transcriptome/transcriptome_splici_fl86_t2g.tsv""; output:; ""{out_data}/{sample}/map/alevin/alevin.log"",; ""{out_data}/{sample}/map/aux_info/meta_info.json"",; ""{out_data}/{sample}/map/cmd_info.json"",; ""{out_data}/{sample}/map/libParams"",; ""{out_data}/{sample}/map/logs/salmon_quant.log"",; ""{out_data}/{sample}/map/map.rad"",; ""{out_data}/{sample}/map/unmapped_bc_count.bin"",; params:; job_name = ""map_reads"",; memory = ""select[mem>64] rusage[mem=64]"",; library_type = ""ISR"",; end = 5,; barcodeLength = 16,; umiLength = 8,; out_dir = ""{out_data}/{sample}/map""; log:; ""logs/map_reads/{sample}.out""; threads:; 16; shell:; """"""; salmon alevin \; -l {params.library_type} \; -1 {input.R1} \; -2 {input.R2} \; -i {input.idx} \; -p {threads} \; -o {params.out_dir} \; --tgMap {input.tgmap} \; --end {params.end} \; --barcodeLength {params.barcodeLength} \; --umiLength {params.umiLength} \; --keepCBFraction 1 \; --sketch; """"""; ```. Specifically, please provide at least the following information:. * Which version of salmon was used? v1.5.2; * How was salmon installed (compiled, downloaded executable, through bioconda)? Downloaded [",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/713:3697,log,log,3697,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/713,1,['log'],['log']
Testability,"tion = 400 | max rel diff. = 0.0247299; [2023-03-07 06:55:05.539] [jointLog] [info] iteration = 500 | max rel diff. = 0.0189304; [2023-03-07 06:55:09.278] [jointLog] [info] iteration = 600 | max rel diff. = 0.017332; [2023-03-07 06:55:13.044] [jointLog] [info] iteration = 700 | max rel diff. = 0.013562; [2023-03-07 06:55:16.780] [jointLog] [info] iteration = 800 | max rel diff. = 0.0118759; [2023-03-07 06:55:20.542] [jointLog] [info] iteration = 900 | max rel diff. = 0.0114777; [2023-03-07 06:55:24.213] [jointLog] [info] iteration = 1000 | max rel diff. = 0.0100626; [2023-03-07 06:55:24.977] [jointLog] [info] iteration = 1022 | max rel diff. = 0.00967998; [2023-03-07 06:55:25.088] [jointLog] [info] Finished optimizer; [2023-03-07 06:55:25.088] [jointLog] [info] writing output ; ```; And the quality control report by `fastp` ; [fastp_report.pdf](https://github.com/COMBINE-lab/salmon/files/10999908/fastp_report.pdf). The log of `bowtie2`:; ```{shell}; $cat bowtie2.log ; 40535435 reads; of these:; 40535435 (100.00%) were paired; of these:; 38666766 (95.39%) aligned concordantly 0 times; 313581 (0.77%) aligned concordantly exactly 1 time; 1555088 (3.84%) aligned concordantly >1 times; ----; 38666766 pairs aligned concordantly 0 times; of these:; 808295 (2.09%) aligned discordantly 1 time; ----; 37858471 pairs aligned 0 times concordantly or discordantly; of these:; 75716942 mates make up the pairs; of these:; 11008379 (14.54%) aligned 0 times; 9748641 (12.88%) aligned exactly 1 time; 54959922 (72.59%) aligned >1 times; 86.42% overall alignment rate; ```. The output of Single-End reads(just read1):; ```{shell}; salmon quant -i assembly_index -l A -r 9998_1.fastq.gz --meta -p 100 -o 9998.quant_se2; Version Info: ### PLEASE UPGRADE SALMON ###; ### A newer version of salmon with bug fixes is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earlies",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/838:5139,log,log,5139,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/838,1,['log'],['log']
Testability,"tput:; gent= ""results/salmon/decoy/gentrome.fa"",; decoy= ""results/salmon/decoy/decoys.txt"",; bak=""results/salmon/decoy/decoys.txt.bak""; conda:; ""../envs/salmon.yaml""; shell:; """"""; grep ""^>"" {input.ref} | cut -d "" "" -f 1 > {output.decoy}; sed -i.bak -e 's/>//g' {output.decoy}; cat {input.tcp} {input.ref} > {output.gent}; """""". rule salmon_index:; input:; gent= ""results/salmon/decoy/gentrome.fa"",; decoy= ""results/salmon/decoy/decoys.txt"",; output:; directory(""results/salmon/index""); conda:; ""../envs/salmon.yaml""; threads:20; shell:; """"""; salmon index -p {threads} -t {input.gent} -d {input.decoy} -i {output}; """""". if config[""salmon""][""mapping_mode""]:; rule salmon_quant_mapping:; input:; r1=""results/trimmed/{smp}_R1_val_1.fq.gz"",; r2=""results/trimmed/{smp}_R2_val_2.fq.gz"",; index = ""results/salmon/index""; output:; directory(""results/salmon/quant/{smp}_salmon_quant""),; mappings=""results/salmon/quant/{smp}_salmon_quant/{smp}_salmon_mappings""; log:; 		""results/salmon/logs/{smp}.salmon.log""; conda:; ""../envs/salmon.yaml""; threads:20; shell:; """"""; salmon quant -i {input.index} -l A -1 {input.r1} -2 {input.r2} -o {output} --validateMappings --gcBias --seqBias --writeUnmappedNames --writeMappings={output.mappings} -p {threads} --numBootstraps 100; """"""; ```. </p>; </details>. <details><summary>Mapping rates w/ SFA method</summary>; <p>. ![image](https://user-images.githubusercontent.com/42179487/73188783-62605d80-40f1-11ea-87ef-e16050f94e60.png). </p>; </details>. <details><summary>cmd_info.json (SFA)</summary>; <p>. ```json; {; ""salmon_version"": ""1.1.0"",; ""index"": ""results/salmon/index"",; ""libType"": ""A"",; ""mates1"": ""results/trimmed/ILWN_RNAseq_G002_ATCACG_Arachis_hypogaea_I801_L1_R1_val_1.fq.gz"",; ""mates2"": ""results/trimmed/ILWN_RNAseq_G002_ATCACG_Arachis_hypogaea_I801_L1_R2_val_2.fq.gz"",; ""output"": ""results/salmon/quant/ILWN_RNAseq_G002_ATCACG_Arachis_hypogaea_I801_L1_salmon_quant"",; """": ""results/salmon/quant/ILWN_RNAseq_G002_ATCACG_Arachis_hypogaea_I801_L1_salmon_quant/ILWN_R",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/479:1881,log,log,1881,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/479,1,['log'],['log']
Testability,"transcript_gene.tsv`. Here is an extract of CB+UMI fastq:; ```; @D00585:41:CB64LANXX:1:1202:13646:88674; ACATCAGTCCCTCAGTTGAAGAAAGG; +D00585:41:CB64LANXX:1:1202:13646:88674; BBBBBFFFFFFFFFFFF<FFFBF//<; @D00585:40:CB7FUANXX:1:2113:18626:8045; TGGGCGTTCTTGCATTCCTGGAACCT; +D00585:40:CB7FUANXX:1:2113:18626:8045; BBBBBFFFFFFFFFFFF<FBFFFFFF; ``` . And an extract of the reads fastq:; ```; @D00585:41:CB64LANXX:1:1202:13646:88674; TCTGTTCATGTGTATTTGCTGTCTCTTAGCCCAGACTTCCCGTGTCCTTTCCACCGGGCCTTTGAGAGGTCACAGGGTCTTGATGCTGTGGTCTTCAT; +D00585:41:CB64LANXX:1:1202:13646:88674; BFFF<FFFBFFB<FFFB<FFFBF//FFFFB<FFFF<F///FFFB/BF<//F<7//FBFBB/F<BF</F<FFFFFFFF<</<FFBFBFFBFF<FBBBBB; @D00585:40:CB7FUANXX:1:2113:18626:8045; ATGTGTATTTGCTGTCTCTTAGCCCAGACTTCCCGTGTCCTTTCCACCGGGCCTTTGAGAGGTCACAGGGTCTTGATGCTGTGGTCTTCATCTGCAGG; +D00585:40:CB7FUANXX:1:2113:18626:8045; FFFFFBFFFFFFFFFFFB/FBFFFFBFFFFFFFBBFFFFFFFFFFFFFFFFFFFFFFFFFFFFFBFFFBFFFFFFFFFFFFFFFFFF<FFBFFBBBBB; ``` . This is the log of the analysis:; ```; Version Info: This is the most recent version of salmon.; Logs will be written to /mnt/beegfs/alexmascension/Projects/Single-cell_skin_analysis//Data/Cheng-2018//Alevin/sample/logs; [2019-06-23 18:08:01.732] [alevinLog] [info] A custom protocol (END, BC length, UMI length) = (5, 16, 10) is being used. Updating UMI k-mer length accordingly.; [2019-06-23 18:08:01.803] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-06-23 18:08:01.804] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2019-06-23 18:08:01.804] [jointLog] [info] Usage of --validateMappings, without --hardFilter implies use of range factorization. rangeFactorizationBins is being set to 4; [2019-06-23 18:08:01.804] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.2.; [2019-06-23 18:08:01.804] [jointLog] [info] Using de",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/386:1391,log,log,1391,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/386,1,['log'],['log']
Testability,"try_t<std::mutex>::create<__gnu_cxx::__normal_iterat; or<std::shared_ptr<spdlog::sinks::sink>*, std::vector<std::shared_ptr<spdlog::sinks::sink>, std::allocator<std::shared_ptr<spdlog::sinks::sink> > > > >(std::__cxx11::basic_string<char,; std::char_traits<char>, std::allocator<char> > const&, __gnu_cxx::__normal_iterator<std::shared_ptr<spdlog::sinks::sink>*, std::vector<std::shared_ptr<spdlog::sinks::sink>, std::alloc; ator<std::shared_ptr<spdlog::sinks::sink> > > > const&, __gnu_cxx::__normal_iterator<std::shared_ptr<spdlog::sinks::sink>*, std::vector<std::shared_ptr<spdlog::sinks::sink>, std::alloc; ator<std::shared_ptr<spdlog::sinks::sink> > > > const&)':; PufferfishIndexer.cpp:(.text._ZN6spdlog7details10registry_tISt5mutexE6createIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrINS_5sinks4sinkEESt6vectorISA_SaISA_EEEEEES7_INS_6loggerEERKN; St7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEERKT_SS_[_ZN6spdlog7details10registry_tISt5mutexE6createIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrINS_5sinks4sinkEESt6vectorISA_S; aISA_EEEEEES7_INS_6loggerEERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEERKT_SS_]+0x73): undefined reference to `vtable for std::_Sp_counted_ptr_inplace<spdlog::logger, std::al; locator<spdlog::logger>, (__gnu_cxx::_Lock_policy)2>'; PufferfishIndexer.cpp:(.text._ZN6spdlog7details10registry_tISt5mutexE6createIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrINS_5sinks4sinkEESt6vectorISA_SaISA_EEEEEES7_INS_6loggerEERKN; St7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEERKT_SS_[_ZN6spdlog7details10registry_tISt5mutexE6createIN9__gnu_cxx17__normal_iteratorIPSt10shared_ptrINS_5sinks4sinkEESt6vectorISA_S; aISA_EEEEEES7_INS_6loggerEERKNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEERKT_SS_]+0x24e): undefined reference to `vtable for std::_Sp_counted_ptr_inplace<spdlog::async_logger,; std::allocator<spdlog::async_logger>, (__gnu_cxx::_Lock_policy)2>'; collect2: error: ld returned 1 exit status; make[2]: *** [src/salmon] Error 1; make[1]: *** ",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/570:1747,log,logger,1747,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/570,2,['log'],['logger']
Testability,ts --geneMap /home/ryan/references/hg38/Salmon_index_hg38.analysisSet_knownGene/genemap.txt --output salmon_quant/hg38.analysisSet_knownGene/SRR2454059 --auxDir aux_info --numGibbsSamples 100; Version Info: This is the most recent **development version** of Salmon.; ### salmon (mapping-based) v0.7.3; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /home/ryan/references/hg38/Salmon_index_hg38.analysisSet_knownGene }; ### [ unmatedReads ] => { fastq_files/SRR2454059.fq.gz }; ### [ threads ] => { 8 }; ### [ libType ] => { ISF }; ### [ seqBias ] => { }; ### [ gcBias ] => { }; ### [ useVBOpt ] => { }; ### [ dumpEq ] => { }; ### [ dumpEqWeights ] => { }; ### [ geneMap ] => { /home/ryan/references/hg38/Salmon_index_hg38.analysisSet_knownGene/genemap.txt }; ### [ output ] => { salmon_quant/hg38.analysisSet_knownGene/SRR2454059 }; ### [ auxDir ] => { aux_info }; ### [ numGibbsSamples ] => { 100 }; Logs will be written to salmon_quant/hg38.analysisSet_knownGene/SRR2454059/logs; [2016-12-13 12:44:39.271] [jointLog] [info] parsing read library format; [2016-12-13 12:44:39.271] [jointLog] [info] There is 1 library.; [2016-12-13 12:44:39.836] [jointLog] [info] Loading Quasi index; [2016-12-13 12:44:39.836] [jointLog] [info] Loading 32-bit quasi index; [2016-12-13 12:44:39.836] [stderrLog] [info] Loading Suffix Array ; [2016-12-13 12:44:43.439] [stderrLog] [info] Loading Transcript Info ; [2016-12-13 12:44:44.355] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-12-13 12:44:44.613] [stderrLog] [info] There were 182608 set bits in the bit array; [2016-12-13 12:44:44.629] [stderrLog] [info] Computing transcript lengths; [2016-12-13 12:44:44.629] [stderrLog] [info] Waiting to finish loading hash; [2016-12-13 12:44:44.629] [stderrLog] [info] Done loading index; [2016-12-13 12:44:44.629] [jointLog] [info] done; [2016-12-13 12:44:44.629] [jointLog] [info] Index contained 182608 targets; [2016-12-13 12:44:49.583] [jointLog] [warning] Fragment GC bias corr,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111:1295,log,logs,1295,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111,1,['log'],['logs']
Testability,"two settings as well; `--freqThreshold 1 --lowRegionMinNumBarcodes 100`. . I am not sure why the `ISF` option didn't work, but probably it has something to do with the guide sequences I was provided. At any rate, I have a few other questions I hope you can help me answer. 1. Why does increasing --maxNumBarcodes to 200000 results in no barcodes getting corrected? (See log for Run 2 below). What is the rationale for the current default of 100000? ; 2. For the downstream analysis of such data, I usually work with both the read and UMI counts, but `quants_mat.gz` only contains the UMI counts. Can Alevin a produce a matrix of read counts as well. It would be a great feature to add. For now, what is easiest way to get the cell x feature matrix of read counts if I use the ` --dumpEq` or `--dumpBfh` flags? Can *tximport* be used for this or do I need to use the Python [parser]([https://github.com/k3yavi/vpolo/blob/master/vpolo/alevin/parser.pyl]) first?. I will be sending you some reads from the experiments for unit testing shortly. Thanks!. Run 1: `salmon alevin -l ISR --citeseq --barcodeLength 16 --umiLength 10 --end 5 --featureStart 19 --featureLength 21 --maxNumBarcodes 100000 --freqThreshold 1 --lowRegionMinNumBarcodes 100`. > 20-06-04 12:24:47.610] [alevinLog] [info] set CITE-seq minScoreFraction parameter to : 0.797619; > [2020-06-04 12:24:47.610] [alevinLog] [info] Found 64 transcripts(+0 decoys, +0 short and +0 duplicate names in the index); > [2020-06-04 12:24:47.610] [alevinLog] [info] Filled with 64 txp to gene entries ; > [2020-06-04 12:24:47.610] [alevinLog] [info] Found all transcripts to gene mappings; > [2020-06-04 12:24:47.616] [alevinLog] [info] Processing barcodes files (if Present) ; > ; > [2020-06-04 12:26:04.322] [alevinLog] [info] Done barcode density calculation.; > [2020-06-04 12:26:04.322] [alevinLog] [info] # Barcodes Used: [32m52200250[0m / [31m52200250[0m.; > [2020-06-04 12:26:04.435] [alevinLog] [info] Forcing to use 100000 cells; > [2020-",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638991199:1180,test,testing,1180,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638991199,2,['test'],['testing']
Testability,"uld have on the times. Those jobs are still running (it's only been about 4hrs as of this writing, I'll update my post if/when they complete). Current logs are showing that they quickly consume all the available memory, but have not yet crashed. I've also got versions with 128-512GB of memory requested (by powers of 2) for comparison. Some random notes: both the 31-mer index experienced about twice as many soft page reclaims with the new/faster version and experienced a few hard page faults (the previous version saw none of the latter). The 17-mer version experienced fewer page reclaims than any of the 31-mer indices and far fewer than with the prior version. Again, a few page faults crept in, but relatively few by percentage and likely not contributing any significant amount of time overall. [index-qacct-17mer.log](https://github.com/COMBINE-lab/salmon/files/4246516/index-qacct-17mer.log); [index-qacct-31mer.log](https://github.com/COMBINE-lab/salmon/files/4246517/index-qacct-31mer.log). **UPDATE**; The 16GB version finished running. It actually only took a little over 4 hours to run, as well. The troubling thing about this job seems to be that, despite having successfully completed, according to the accounting log it used over 20GB of memory... which should be impossible to do. Our resident experts suspect there's a race condition occurring at the tail end of the job and that all of that extra memory is being allocated before the scheduler can kill it for exceeding the limit. Whatever the case, though, this throws into question some of those numbers that I've been grabbing from the accounting logs --- it's either being misreported, or the memory gobbling is happening so rapidly that it may not, in fact, be being properly recorded. I tested the index anyway. It *appears* to be working just fine. Nothing faulted or crashed when I attempted to quantify some reads against it. [index-qacct-17mer-16gigs.log](https://github.com/COMBINE-lab/salmon/files/4247214/index-qacct",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-590516702:1788,log,log,1788,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-590516702,1,['log'],['log']
Testability,"unction with --hardFilter. Disabling range-factorized equivalence classes.; [2021-04-09 12:16:37.619] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.; [2021-04-09 12:16:37.619] [jointLog] [info] Using default value of 0.87 for minScoreFraction in Alevin; Using default value of 0.6 for consensusSlack in Alevin; [2021-04-09 12:16:37.649] [alevinLog] [info] Found 45374 transcripts(+1 decoys, +0 short and +0 duplicate names in the index); [2021-04-09 12:16:37.702] [alevinLog] [info] Filled with 45374 txp to gene entries; ### alevin (dscRNA-seq quantification) v1.4.0; ### [ program ] => salmon; ### [ command ] => alevin; ### [ libType ] => { ISR }; ### [ index ] => { results/salmon/index/GRCh38.p13 }; ### [ mates1 ] => { /Users/james/GitHub/scrnaseq/.tests/fastq/S1_L001_R1_001.fastq.gz /Users/james/GitHub/scrnaseq/.tests/fastq/S1_L002_R1_001.fastq.gz /Users/james/GitHub/scrnaseq/.tests/fastq/S1_L003_R1_001.fastq.gz /Users/james/GitHub/scrnaseq/.tests/fastq/S1_L004_R1_001.fastq.gz }; ### [ mates2 ] => { /Users/james/GitHub/scrnaseq/.tests/fastq/S1_L001_R2_001.fastq.gz /Users/james/GitHub/scrnaseq/.tests/fastq/S1_L002_R2_001.fastq.gz /Users/james/GitHub/scrnaseq/.tests/fastq/S1_L003_R2_001.fastq.gz /Users/james/GitHub/scrnaseq/.tests/fastq/S1_L004_R2_001.fastq.gz }; ### [ output ] => { results/salmon/alevin/S1 }; ### [ threads ] => { 1 }; ### [ tgMap ] => { results/eisar/GRCh38.p13/GRCh38.p13.tx2gene.tsv }; ### [ chromiumV3 ] => { }; ### [ mrna ] => { results/gffread/GRCh38.p13/GRCh38.p13.mrna.txt }; ### [ rrna ] => { results/gffread/GRCh38.p13/GRCh38.p13.rrna.txt }. [2021-04-09 12:16:37.708] [alevinLog] [info] Found all transcripts to gene mappings; [2021-04-09 12:16:37.722] [alevinLog] [info] Processing barcodes files (if Present). [2021-04-09 12:16:37.728] [alevinLog] [info] Done barcode density calculation.; [2021-04-09 12:16:37.728] [alevinLog] [info] # Barcodes Used: 4000 / 4000.; [2021-04-09 12:16:37.729] [alevinLog] [info] Knee found",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/647:1954,test,tests,1954,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/647,1,['test'],['tests']
Testability,"vided; using is 1 less feature for whitelisting; [2022-03-27 05:46:42.064] [alevinLog] [warning] rrna file not provided; using is 1 less feature for whitelisting; [2022-03-27 05:49:49.761] [alevinLog] [info] Total 535438.00 UMI after deduplicating.; [2022-03-27 05:49:49.761] [alevinLog] [info] Total 2317116 BiDirected Edges.; [2022-03-27 05:49:49.761] [alevinLog] [info] Total 867878 UniDirected Edges.; [2022-03-27 05:49:49.761] [alevinLog] [warning] Skipped 955 barcodes due to No mapped read; [2022-03-27 05:49:49.766] [alevinLog] [info] Clearing EqMap; Might take some time.; [2022-03-27 05:49:50.011] [alevinLog] [info] Starting white listing of 3044 cells; [2022-03-27 05:49:50.011] [alevinLog] [info] Starting to make feature Matrix; [2022-03-27 05:49:50.014] [alevinLog] [info] Done making feature Matrix; [2022-03-27 05:49:50.717] [alevinLog] [info] Finished white listing; [2022-03-27 05:49:51.422] [alevinLog] [info] Finished optimizer; ````. and the `salmon_quant.log` looks like:; ```; [2022-03-27 05:24:09.395] [jointLog] [info] setting maxHashResizeThreads to 32; [2022-03-27 05:24:09.395] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2022-03-27 05:24:09.395] [jointLog] [info] The --mimicBT2, --mimicStrictBT2 and --hardFilter flags imply mapping validation (--validateMappings). Enabling mapping validation.; [2022-03-27 05:24:09.395] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2022-03-27 05:24:09.395] [jointLog] [info] The use of range-factorized equivalence classes does not make sense in conjunction with --hardFilter. Disabling range-factorized equivalence classes. ; [2022-03-27 05:24:09.395] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.; [2022-03-27 05:24:09.395] [jointLog] [info] Using default value of 0.87 for minScoreFraction in Alevin; Using default value of 0.6 for consensu",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/763#issuecomment-1082597942:4136,log,log,4136,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/763#issuecomment-1082597942,1,['log'],['log']
Testability,"w days and would be very grateful for any advice on how to move forward. Thank you in advance. Here is my command:; ```; #!/bin/bash -l ; #SBATCH -J male_salmon_map; #SBATCH -t 700:00:00; #SBATCH -p high; #SBATCH --cpus-per-task=24; source ~/.bashrc; source activate salmon; cd /home/seboles/abaloneraw/salmon_quantification/salmon_male/abalone_orfs/; ./bin/salmon -i salmon_index -p 8 -l --libType A -1 *R1_001.qc.fq.gz -2 R2_001.qc.fq.gz --validateMappings -o transcripts_quant; ```; # And here is my error message:. ```; basename: extra operand ‘lightreceptor-1_S114_L005_R1_001.qc.fq.gz’; Try 'basename --help' for more information.; Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { abalone_index }; ### [ libType ] => { A }; ### [ mates1 ] => { .R1_001.qc.fq.gz }; ### [ mates2 ] => { .R2_001.qc.fq.gz }; ### [ output ] => { .quant }; Logs will be written to .quant/logs; [2019-07-24 13:33:29.347] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-07-24 13:33:29.347] [jointLog] [warning] . NOTE: It appears you are running salmon without the `--validateMappings` option.; Mapping validation can generally improve both the sensitivity and specificity of mapping,; with only a moderate increase in use of computational resources. ; Mapping validation is planned to become a default option (i.e. turned on by default) in; the next release of salmon.; Unless there is a specific reason to do this (e.g. testing on clean simulated data),; `--validateMappings` is generally recommended. [2019-07-24 13:33:29.347] [jointLog] [info] parsing read library format; [2019-07-24 13:33:29.347] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file abalone_index/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; salmon quant was invoked improperly.; For usage inform",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/408:1125,log,logs,1125,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/408,1,['log'],['logs']
Testability,"warnings in the form of '[warning] len : *, but txp.RefLenght : *' appeared in the running log.; How did this occurred? Will this affect the quantification?; salmon version : v1.0.0; reference genome: ensembl GRCh38 release 96; ****gentrome and decoy generating command:****; grep ""^>"" $home/Ensembl_human_v96/Homo_sapiens.GRCh38.dna.primary_assembly.fa | cut -d "" "" -f 1 > decoys_new.txt; sed -i.bak -e 's/>//g' decoys_new.txt; cat $home/Ensembl_human_v96/Homo_sapiens.GRCh38_v96.cdna.all.fa $home/Ensembl_human_v96/Homo_sapiens.GRCh38.dna.primary_assembly.fa > $home/Ensembl_human_v96/gentrome.fa.gz; ; ****salmon index command:****; salmon index -t $home/Ensembl_human_v96/gentrome.fa.gz -d ; $home/Ensembl_human_v96/decoys.txt -p 12 -i ${home}/NGS/salmon_index_human_v96. ****salmon quant command:****; 	salmon quant -i ${home_path}/NGS/salmon_index_human_v96 -l A \; 	-1 ${fastq1} -2 ${fastq2} --validateMappings -p 12 --gcBias \; 	-o $count_path/${sample_name} ; ![image](https://user-images.githubusercontent.com/51859749/69779623-8f70bc80-11e3-11ea-9c94-6be4b9819d28.png)",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/457:91,log,log,91,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/457,1,['log'],['log']
Testability,"when I run cmake I get: . Cannot find source file:; [...]salmon-0.9.1/external/install/src/rapmap/RapMapFileSystem.cpp; Tried extensions .c .C .c++ .cc .cpp .cxx .m .M .mm .h .hh .h++ .hm .hpp .hxx .in .txx; CMake Error at src/CMakeLists.txt:120 (add_executable):; Cannot find source file:; [...]/salmon-0.9.1/external/install/src/rapmap/rank9b.cpp; Tried extensions .c .C .c++ .cc .cpp .cxx .m .M .mm .h .hh .h++ .hm .hpp .hxx .in .txx. Apart from that the build tries to download libgff, although libgf-dev is installed - it fails because it requires curl, which is not installed - i.e. that should also be tested for. System: Debian GNU/Linux (unstable), amd64 . Best, ; Gert",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/181:609,test,tested,609,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/181,1,['test'],['tested']
Testability,"which we are making the inference are actually changing. It is possible e.g. that some uniquely mapped reads may not be chosen in some bootstrap sample (since we are re-sampling the observed read count, but doing so _with replacement_), and so the estimates of sets of related isoforms will change in those samples. Thus, since the observations themselves are changing, we expect the estimates to display greater variance. In fact, this is the main goal of performing the bootstrapping (or Gibbs sampling) — to estimate the uncertainty due to inference if we had observed many reads coming from the same underlying ""population"" as the ones we have in our specific sample, but subject to the random sampling effect induced by sequencing and all of the subsequent downstream effects it has on our estimator (i.e. salmon's computational procedure for estimating transcript abundance via the variational Bayesian optimization algorithm). From the practical perspective, one would not necessarily expect taking the average of the bootstrap estimates to produce a more accurate point estimate than taking the normal point estimate produced by salmon. The main purpose of performing the Gibbs sampling or bootstrapping is to allow accurate assessment of the _posterior variance_ of the point estimates (to build things like credible intervals). The mean of the bootstrap estimates should be highly-correlated with the normal point estimates, but I wouldn't expect it to be identical. Also, you might try seeing what you get with a different summary statistic, like the median. However, the main point of producing this information is to allow you to assess the posterior variance, and also to pass these samples to uncertainty-aware differential analysis tools, like [swish](https://academic.oup.com/nar/article/47/18/e105/5542870), downstream of salmon. . Anyway, thanks again for the detailed report! We'll look into the logging issue, and please let me know if my description above answers your question.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/466#issuecomment-568828362:3308,log,logging,3308,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/466#issuecomment-568828362,2,['log'],['logging']
Testability,"x rel diff.; = 0.229724; [2020-06-16 00:01:10.426] [jointLog] [info] iteration = 600 | max rel diff.; = 0.242741; [2020-06-16 00:01:12.163] [jointLog] [info] iteration = 700 | max rel diff.; = 0.196958; [2020-06-16 00:01:14.015] [jointLog] [info] iteration = 800 | max rel diff.; = 0.239461; [2020-06-16 00:01:15.803] [jointLog] [info] iteration = 900 | max rel diff.; = 0.197651; [2020-06-16 00:01:17.095] [jointLog] [info] iteration = 969 | max rel diff.; = 0.00714824; [2020-06-16 00:01:17.131] [jointLog] [info] Finished optimizer; [2020-06-16 00:01:17.131] [jointLog] [info] writing output. ```. So, you can note that the number of mappings discarded because of alignment; score is still quite big (134M) and, indeed, this took longer than I would; normally expect for; a sample with ~30M reads. However, it is _massively_ smaller (~116 times); than the 15.6B in your run. Thus, it may have been the same issue as in; the other GitHub issue. You can try the pre-compiled linux binary I linked; there if you have access to a linux machine to test on. By the way, the; issue there was a bunch of reads plagued by super-repetitive homopolymer; segments, I haven't looked at these reads yet for evidence of that though. On Mon, Jun 15, 2020 at 11:09 PM shalercr <notifications@github.com> wrote:. >; >; >; >; >; > Hi Rob,; >; >; > Thanks for the quick response. The other computer was OSX, should I try a; > linux machine?; >; >; > Here are some dropbox links to two of the files. I believe this is the set; > for the logs I posted.; >; >; > https://www.dropbox.com/s/8c3p9hmgmadgj89/31_1.trimmed.fastq.gz?dl=0; >; >; > https://www.dropbox.com/s/2y9jfvaphe9h21x/31_2.trimmed.fastq.gz?dl=0; >; >; >; >; > Thanks,; >; >; > Ryan; >; >; >; >; >; > On Jun 15, 2020, at 9:32 PM, Rob Patro <notifications@github.com> wrote:; >; >; >; >; > Thank you for the report. Can you share one of the samples where you see; > this issue? Also, out of curiosity, was the other machine you tried on also; > OSX, or was ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-644527727:5009,test,test,5009,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-644527727,1,['test'],['test']
Testability,"x rel diff.; = 0.229724; [2020-06-16 00:01:10.426] [jointLog] [info] iteration = 600 | max rel diff.; = 0.242741; [2020-06-16 00:01:12.163] [jointLog] [info] iteration = 700 | max rel diff.; = 0.196958; [2020-06-16 00:01:14.015] [jointLog] [info] iteration = 800 | max rel diff.; = 0.239461; [2020-06-16 00:01:15.803] [jointLog] [info] iteration = 900 | max rel diff.; = 0.197651; [2020-06-16 00:01:17.095] [jointLog] [info] iteration = 969 | max rel diff.; = 0.00714824; [2020-06-16 00:01:17.131] [jointLog] [info] Finished optimizer; [2020-06-16 00:01:17.131] [jointLog] [info] writing output; ```. So, you can note that the number of mappings discarded because of alignment; score is still quite big (134M) and, indeed, this took longer than I would; normally expect for; a sample with ~30M reads. However, it is _massively_ smaller (~116 times); than the 15.6B in your run. Thus, it may have been the same issue as in; the other GitHub issue. You can try the pre-compiled linux binary I linked; there if you have access to a linux machine to test on. By the way, the; issue there was a bunch of reads plagued by super-repetitive homopolymer; segments, I haven't looked at these reads yet for evidence of that though. On Mon, Jun 15, 2020 at 11:09 PM shalercr <notifications@github.com> wrote:. >; >; >; >; >; > Hi Rob,; >; >; > Thanks for the quick response. The other computer was OSX, should I try a; > linux machine?; >; >; > Here are some dropbox links to two of the files. I believe this is the set; > for the logs I posted.; >; >; > https://www.dropbox.com/s/8c3p9hmgmadgj89/31_1.trimmed.fastq.gz?dl=0; >; >; > https://www.dropbox.com/s/2y9jfvaphe9h21x/31_2.trimmed.fastq.gz?dl=0; >; >; >; >; > Thanks,; >; >; > Ryan; >; >; >; >; >; > On Jun 15, 2020, at 9:32 PM, Rob Patro <notifications@github.com> wrote:; >; >; >; >; > Thank you for the report. Can you share one of the samples where you see; > this issue? Also, out of curiosity, was the other machine you tried on also; > OSX, or was ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-644520228:4253,test,test,4253,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/537#issuecomment-644520228,1,['test'],['test']
Testability,"x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX/libParams"", 0x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, ...}) = 0; mkdir(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX/libParams"", 0777) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX/aux_info"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX/aux_info"", 0x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, ...}) = 0; mkdir(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX/aux_info"", 0777) = 0; open(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX/logs/salmon_quant.log"", O_WRONLY|O_CREAT|O_APPEND, 0666) = 3; fstat(3, {st_mode=S_IFREG|0644, st_size=0, ...}) = 0; mmap(NULL, 4194304, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbea00000; fstat(3, {st_mode=S_IFREG|0644, st_size=0, ...}) = 0; lseek(3, 0, SEEK_SET) = 0; mmap(NULL, 8388608, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7fffbe200000; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7fff3e5eb000; mprotect(0x7fff3e5eb000, 4096, PROT_NONE) = 0; clone(child_stack=0x7fff7e5eaed0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7fff7e5eb9d0, tls=0x7fff7e5eb700, child_tidptr=0x7fff7e5eb9d0) = 10740; mmap(NULL, 8388608, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7fffbda000",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:68945,log,logs,68945,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['log'],['logs']
Testability,"x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX/libParams"", 0x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, ...}) = 0; mkdir(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX/libParams"", 0777) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX/aux_info"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX/aux_info"", 0x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, ...}) = 0; mkdir(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX/aux_info"", 0777) = 0; open(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX/logs/salmon_quant.log"", O_WRONLY|O_CREAT|O_APPEND, 0666) = 3; fstat(3, {st_mode=S_IFREG|0644, st_size=0, ...}) = 0; mmap(NULL, 4194304, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbea00000; fstat(3, {st_mode=S_IFREG|0644, st_size=0, ...}) = 0; lseek(3, 0, SEEK_SET) = 0; mmap(NULL, 8388608, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7fffbe200000; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7fff3e5eb000; mprotect(0x7fff3e5eb000, 4096, PROT_NONE) = 0; clone(child_stack=0x7fff7e5eaed0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7fff7e5eb9d0, tls=0x7fff7e5eb700, child_tidptr=0x7fff7e5eb9d0) = 51998; mmap(NULL, 8388608, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7fffbda000",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:107527,log,logs,107527,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['log'],['logs']
Testability,"x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, ...}) = 0; mkdir(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX/libParams"", 0777) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX/aux_info"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX/aux_info"", 0x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, ...}) = 0; mkdir(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX/aux_info"", 0777) = 0; open(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test11/R10002_C29P7ACXX/logs/salmon_quant.log"", O_WRONLY|O_CREAT|O_APPEND, 0666) = 3; fstat(3, {st_mode=S_IFREG|0644, st_size=0, ...}) = 0; mmap(NULL, 4194304, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbea00000; fstat(3, {st_mode=S_IFREG|0644, st_size=0, ...}) = 0; lseek(3, 0, SEEK_SET) = 0; mmap(NULL, 8388608, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7fffbe200000; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7fff3e5eb000; mprotect(0x7fff3e5eb000, 4096, PROT_NONE) = 0; clone(child_stack=0x7fff7e5eaed0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7fff7e5eb9d0, tls=0x7fff7e5eb700, child_tidptr=0x7fff7e5eb9d0) = 10740; mmap(NULL, 8388608, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7fffbda00000; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7ffefe5ea000; mprotect(0x7ffefe5ea000, 4096, PROT_NONE",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:68963,log,log,68963,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['log'],['log']
Testability,"x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, ...}) = 0; mkdir(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX/libParams"", 0777) = 0; stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX/aux_info"", 0x7fffffff1e50) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX/aux_info"", 0x7fffffff1e60) = -1 ENOENT (No such file or directory); stat(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX"", {st_mode=S_IFDIR|S_ISGID|0755, st_size=33280, ...}) = 0; mkdir(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX/aux_info"", 0777) = 0; open(""/dcl01/lieber/ajaffe/lab/libd_alzheimers/hg38/salmon_test12/R10001_D2B1WACXX/logs/salmon_quant.log"", O_WRONLY|O_CREAT|O_APPEND, 0666) = 3; fstat(3, {st_mode=S_IFREG|0644, st_size=0, ...}) = 0; mmap(NULL, 4194304, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7fffbea00000; fstat(3, {st_mode=S_IFREG|0644, st_size=0, ...}) = 0; lseek(3, 0, SEEK_SET) = 0; mmap(NULL, 8388608, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7fffbe200000; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7fff3e5eb000; mprotect(0x7fff3e5eb000, 4096, PROT_NONE) = 0; clone(child_stack=0x7fff7e5eaed0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7fff7e5eb9d0, tls=0x7fff7e5eb700, child_tidptr=0x7fff7e5eb9d0) = 51998; mmap(NULL, 8388608, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_NORESERVE, -1, 0) = 0x7fffbda00000; mmap(NULL, 1073745920, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS|MAP_STACK, -1, 0) = 0x7ffefe5ea000; mprotect(0x7ffefe5ea000, 4096, PROT_NONE",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888:107545,log,log,107545,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/126#issuecomment-291994888,1,['log'],['log']
Testability,"yes `--no-version-check` does the trick, but among all the users of the cluster I'm pretty sure some of them will forgot ;-). on our local installation I disabled the getVersionMessage even if salmon handle the no network cleanly. (I tested using `unshare -n salmon whatever you want`); NB debian maintainer also disabled the phone home call in their packages. sorry if it it may sound harsh",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/486#issuecomment-617310271:234,test,tested,234,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/486#issuecomment-617310271,1,['test'],['tested']
Testability,"ype` after the set of reads), my run still completed successfully (and didn't produce any warnings during Gibbs sampling). Salmon's behavior when running in unstranded mode on stranded data is simply to map the reads in the orientation they match, and to report on the console (and in the log) that there was a mapping bias (i.e. that the data look stranded). Specifically, here is what I get when I run (a close approximation of) your command. ```; $salmon quant --index Salmon_index_hg38.analysisSet_knownGene --unmatedReads SRR2454059.fq.gz --libType ISF --useVBOpt --output test_quant --; numGibbsSamples 100 --threads 16; Version Info: This is the most recent **development version** of Salmon.; ### salmon (mapping-based) v0.7.3; ### [ program ] => salmon; ### [ command ] => quant; ### [ index ] => { Salmon_index_hg38.analysisSet_knownGene }; ### [ unmatedReads ] => { SRR2454059.fq.gz }; ### [ libType ] => { ISF }; ### [ useVBOpt ] => { }; ### [ output ] => { test_quant }; ### [ numGibbsSamples ] => { 100 }; ### [ threads ] => { 16 }; Logs will be written to test_quant/logs; [2016-12-13 22:38:54.413] [jointLog] [info] parsing read library format; [2016-12-13 22:38:54.413] [jointLog] [info] There is 1 library.; [2016-12-13 22:38:56.240] [stderrLog] [info] Loading Suffix Array; [2016-12-13 22:38:56.240] [jointLog] [info] Loading Quasi index; [2016-12-13 22:38:56.240] [jointLog] [info] Loading 32-bit quasi index; [2016-12-13 22:39:01.268] [stderrLog] [info] Loading Transcript Info; [2016-12-13 22:39:02.630] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-12-13 22:39:03.041] [stderrLog] [info] There were 182608 set bits in the bit array; [2016-12-13 22:39:03.159] [stderrLog] [info] Computing transcript lengths; [2016-12-13 22:39:03.160] [stderrLog] [info] Waiting to finish loading hash; [2016-12-13 22:39:07.653] [stderrLog] [info] Done loading index; [2016-12-13 22:39:07.653] [jointLog] [info] done; [2016-12-13 22:39:07.653] [jointLog] [info] Index contained 182608 ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266934878:1151,Log,Logs,1151,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266934878,3,"['Log', 'log']","['Logs', 'logs']"
Testability,"z }; ### [ output ] => { /DNA_tmm }; ### [ meta ] => { }; ### [ incompatPrior ] => { 0.0 }; ### [ libType ] => { A }; ### [ threads ] => { 8 }; ### [ gcBias ] => { }; ### [ seqBias ] => { }; ### [ numBootstraps ] => { 30 }; Logs will be written to ./storage/logs; [2017-03-15 11:53:20.568] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2017-03-15 11:53:20.568] [jointLog] [info] parsing read library format; [2017-03-15 11:53:20.568] [jointLog] [info] There is 1 library.; [2017-03-15 11:53:20.653] [jointLog] [info] Loading Quasi index; [2017-03-15 11:53:20.683] [jointLog] [info] Loading 64-bit quasi index; [2017-03-15 11:53:20.684] [stderrLog] [info] Loading Suffix Array ; [2017-03-15 12:19:05.982] [stderrLog] [info] Loading Transcript Info ; Exception : [Failed to read 130159192 bytes from input stream! Read 65079596]; salmon quant was invoked improperly.; For usage information, try salmon quant --help; Exiting.; ```. Index building log:. ```; Version Info: This is the most recent version of Salmon.; index ["" ./storage/tmm.idx""] did not previously exist . . . creating it; [2017-03-14 12:10:34.791] [jLog] [info] building index; RapMap Indexer. [Step 1 of 4] : counting k-mers; counted k-mers for 30000 transcripts[2017-03-14 12:10:36.701] [jointLog] [warning] Entry with header [734bf21190b56e1ed4c8d7093c340df1fc6266bd80ed60ebc0ae0f4e9343c3a4], had length less than the k-mer length of 31 (perhaps after poly-A clipping); counted k-mers for 420000 transcripts[2017-03-14 12:10:56.697] [jointLog] [warning] Entry with header [0c9d699aa70741734115dadd8175a44a013ad4122a3af7952e3b38e9593da047], had length less than the k-mer length of 31 (perhaps after poly-A clipping); counted k-mers for 11130000 transcripts[2017-03-14 12:20:15.975] [jointLog] [warning] Entry with header [9067b76fbcadd65a043ddff42dccfbd201e1b7ab5307ce7712d6301e32923ff1], had length less than the k-mer length of 31 (perhaps after poly-A clipping); [2017-",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/129:2298,log,log,2298,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/129,1,['log'],['log']
Testability,"{Boost_FOUND}""); find_package(Boost 1.57.0 COMPONENTS iostreams filesystem system thread timer chrono program_options); message(""BOOST_INCLUDEDIR = ${BOOST_INCLUDEDIR}""); message(""BOOST_LIBRARYDIR = ${BOOST_LIBRARYDIR}""); message(""Boost_FOUND 1.57.0 = ${Boost_FOUND}""); set(Boost_FOUND ""1""); message(""Boost_FOUND FORCED = ${Boost_FOUND}""); include(ExternalProject); ```; This emits:; ```. -- Could NOT find Boost; Boost_FOUND 1.57 = 0; -- Could NOT find Boost; BOOST_INCLUDEDIR = /usr/include/boost157; BOOST_LIBRARYDIR = /usr/lib64; Boost_FOUND 1.57.0 = 0; Boost_FOUND FORCED = 1; BOOST INCLUDE DIR = /usr/include/boost157; BOOST INCLUDE DIRS = /usr/include/boost157; BOOST LIB DIR = /usr/lib64; BOOST LIBRARIES = ; ```; That at least allowed cmake to complete when it was run with:. `nice scl enable devtoolset-4 '~/bin/cmake -DCMAKE_VERBOSE_MAKEFILE:BOOL=ON -DBoost_NO_BOOST_CMAKE=BOOL:ON -DBOOST_LIBRARYDIR=/usr/lib64 -DBOOST_INCLUDEDIR=/usr/include/boost157 ../CMakeLists.txt' >try_cmake.log 2>&1 &; `. Then tried to build it. ```; cd ..; nice scl enable devtoolset-4 'make' >build_2018_06_13d.log 2>&1 &. ```. It failed at this command because of missing boost symbols in a link operation, my reading is that the command does not include anything to link boost libraries. So telling cmake where the libraries are, where the include files are, and that boost was found was not sufficient. There must be some other set of symbols which need to be defined. `/opt/rh/devtoolset-4/root/usr/bin/c++ -pthread -ftree-vectorize -funroll-loops -fPIC -fomit-frame-pointer -O3 -DRAPMAP_SALMON_SUPPORT -DHAVE_ANSI_TERM -DHAVE_SSTREAM -Wall -Wno-unknown-pragmas -Wno-reorder -Wno-unused-variable -std=c++11 -Wreturn-type -Werror=return-type -Wno-unused-function -Wno-unused-local-typedef -static-libstdc++ -Wno-unused-local-typedefs -pthread -ftree-vectorize -funroll-loops -fPIC -fomit-frame-pointer -O3 -DRAPMAP_SALMON_SUPPORT -DHAVE_ANSI_TERM -DHAVE_SSTREAM -Wall -Wno-unknown-pragmas -Wno-reorder -Wno-un",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-397025719:1477,log,log,1477,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-397025719,1,['log'],['log']
Usability," ! -f ""$outputDir""/quant.sf ]]; then. 	mkdir -p ""$outputDir"". # printf ""##############\n"" ; # printf ""warning --minAssignedFrags is set to $minNumFrags to enable test data set\n"" ; # minNumFrags=1 ; # --minAssignedFrags=$minNumFrags \ ; # printf ""##############\n"" . #if [[ -f ""$inputDir""/output_single_end.fq.gz ]]; then . numThr=12; salmon quant \; -i $salmonIndexDir \; --libType A \; -1 ""${rightReads}"" \; -2 ""${leftReads}"" \; -p $numThr \; --recoverOrphans \; --validateMappings \; --gcBias \; --seqBias \; --rangeFactorizationBins 4 \; --writeUnmappedNames \; --output ${outputDir}. salmonRet=$?; if [ $salmonRet -ne 0 ]; then; echo ERROR salmon ""$rightReads"" returned exit status ""$exitStatus""; continue; fi. #fi ; else; echo ""[INFO] skipping ${outputDir}/quant.sf it already exists""; fi; }; ```. Specifically, please provide at least the following information:. * Which version of salmon was used?; * salmon 1.4.0 . * How was salmon installed (compiled, downloaded executable, through bioconda)?; * compiled locally salmon-1.4.0_linux_x86_64.tar.gz; * ; * Which reference (e.g. transcriptome) was used?; * we have custom human ref with additional annotations; * ; * Which read files were used?; paired reads. * Which which program options were used?; * see above. **Expected behavior**; A clear and concise description of what you expected to happen. I think this is a potential documentation issue?. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX]; - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux the output of `uname -a` and `lsb_release -a`]; - $ lsb_release -a; bash: lsb_release: command not found...; (base) [aedavids@mustard bin]$ uname -a ; Linux mustard 3.10.0-862.6.3.el7.x86_64 #1 SMP Tue Jun 26 16:32:21 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux. **Additional context**; Add any other context about the problem here.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/677:2553,clear,clear,2553,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/677,1,['clear'],['clear']
Usability," -p {threads} \; -o {params.out_dir} \; --tgMap {input.tgmap} \; --end {params.end} \; --barcodeLength {params.barcodeLength} \; --umiLength {params.umiLength} \; --keepCBFraction 1 \; --sketch; """"""; ```. Specifically, please provide at least the following information:. * Which version of salmon was used? v1.5.2; * How was salmon installed (compiled, downloaded executable, through bioconda)? Downloaded [this](https://github.com/COMBINE-lab/salmon/releases/tag/v1.5.2) binary; * Which reference (e.g. transcriptome) was used? Human reference (GRCh38) (from the alevin-fry tutorial [here](https://cf.10xgenomics.com/supp/cell-exp/refdata-gex-GRCh38-2020-A.tar.gz)); * Which read files were used? See attached subsampled sub_R1.fastq.gz and sub_R2.fastq.gz from one sample as representative reads.; * Which which program options were used? See above snakemake rule code for program options, which closely follow the options used in the alevin-fry tutorial. **Expected behavior**; A clear and concise description of what you expected to happen. I expected my reads to be mapped and a RAD file to be generated. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX] Linux (university cluster); - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux the output of `uname -a` and `lsb_release -a`]; ; Output of `uname -a`:; ```; Linux amc-bodhi 3.10.0-514.21.1.el7.x86_64 #1 SMP Thu May 25 17:04:51 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux; ```. Output of `lsb_release -a`:; ```; LSB Version:	:core-4.1-amd64:core-4.1-noarch:cxx-4.1-amd64:cxx-4.1-noarch:desktop-4.1-amd64:desktop-4.1-noarch:languages-4.1-amd64:languages-4.1-noarch:printing-4.1-amd64:printing-4.1-noarch; Distributor ID:	CentOS; Description:	CentOS Linux release 7.4.1708 (Core) ; Release:	7.4.1708; Codename:	Core; ```. **Additional context**; Add any other context about the problem h",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/713:5299,clear,clear,5299,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/713,1,['clear'],['clear']
Usability," > salmon index -t gentrome.fa.gz -d decoys.txt -p 12 -i salmon_index --gencode. ===========Then I get segmentation fault; ![image](https://user-images.githubusercontent.com/24876498/103153659-191b0100-47cd-11eb-942e-fcd99b3cf2e2.png). 6. gdb salmon <corefile>; It seemed to crash at these functions: fixFasta(), fixFastaMain() ; ![image](https://user-images.githubusercontent.com/24876498/103153694-554e6180-47cd-11eb-9e4e-dc4bfdf7f731.png). Specifically, please provide at least the following information:. * Which version of salmon was used? v1.4.0; * How was salmon installed (compiled, downloaded executable, through bioconda)? compiled; * Which reference (e.g. transcriptome) was used? gencode.vM23.transcripts.fa.gz GRCm38.primary_assembly.genome.fa.gz; * Which read files were used? not quantifying yet, I'm at the indexing step.; * Which which program options were used? salmon index -t gentrome.fa.gz -d decoys.txt -p 12 -i salmon_index --gencode. **Expected behavior**; A clear and concise description of what you expected to happen.; Producing directory that contains indexed files to be applied to ""salmon quant"" command. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem.; 2 pictures: a segmentation fault screenshot and a gdb backtrack screenshot in ""**To Reproduce**"" section. **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX] : CentOS7; - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux the output of `uname -a` and `lsb_release -a`]; - ""uname -a""; Linux 3.10.0-1062.18.1.el7.x86_64 #1 SMP Tue Mar 17 23:49:17 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux; - ""lsb_release -a""; LSB Version: :core-4.1-amd64:core-4.1-noarch:cxx-4.1-amd64:cxx-4.1-noarch:desktop-4.1-amd64:desktop-4.1-noarch:languages-4.1-amd64:languages-4.1-noarch:printing-4.1-amd64:printing-4.1-noarch; Distributor ID: CentOS; Description: CentOS Linux release 7.7.1908 (Core); Release: 7.7.1908; Codename: Core; ",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/609:2942,clear,clear,2942,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/609,1,['clear'],['clear']
Usability," >when you say cellranger subsampling, do you mean the cellranger aggregate pipeline?. Yes, sorry for not clearly stating it. I did use the cellranger aggregate function indeed, which by default subsample the expression matrices with high sequencing depth depending on amount of mapped reads, if I understand well. >Use Alevin w/o any modification to the fastq on both of your sample to generate the gene count matrices. I already did that, in downstream analyses I have a batch effect issue related to the sequencing depth. >that's why we recommend using the Seurat package downstream of the Alevin quantified matrices. I have some experience with downstream analyses with Seurat, Pagoda, Scater, scanpy and a few other tools, and I am aware of batch correction methods like CCA or MNN. But that is not what I am looking for here. I did both CCA and MNN but I loose some important information in the resulting eigenspaces or corrected matrix. I believe the proper way to correct my batch effect is to simply fix the difference between my two libraries, ie. the sequencing depth in this case. As I explained in my first message, cellranger aggregate (subsampling based on the amount of mapped reads) works very well in my case, correct the effect without any loss or modification of important genes in our scientific question. Not CCA or MNN. I would like to be able to do the same from the alevin quantifications. So I am looking for a proper way to apply a correction before/during/after the alevin quantification, in a way similar to what cellranger do with STAR. Alternatively, could a subsampling covariate be added to the probalistic quantification model of alevin (if I understand it well), in sort that such a discrepency bewteen samples would be corrected?. I did look at the mappedUMI file:. ![image](https://user-images.githubusercontent.com/34892073/47551835-85ef9380-d903-11e8-893f-2a684576437b.png). So an option you would recommend is to simply compute the subsampling coefficient for ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/305#issuecomment-433319913:1611,simpl,simply,1611,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/305#issuecomment-433319913,2,['simpl'],['simply']
Usability," BAM Unsorted --quantMode TranscriptomeSAM --outSAMattributes NH HI AS NM MD --quantTranscriptomeBan IndelSoftclipSingleend`; note that last parameter that I will come back to later. Also, the paper referenced above also describes a new capability present in recent versions of salmon that allow it to index the entire genome (as well as the transcriptome) to have the former act as a decoy. This allows avoiding what might otherwise be spurious mappings that result when one considers only the transcriptome as a source of mapping. There are a number of ways to proceed on this front, but this is a good place to first check for discrepancy (and the paper gives a good overview of the relative tradeoffs and merits of different alignment approaches). * Salmon and RSEM use related but distinct optimization algorithms by default. RSEM uses the EM algorithm, and salmon uses the variational Bayesian EM algorithm. The latter tends to induce more sparse solutions. This is simply because they are optimizing slightly different objectives. It is very difficult to say in general if one is ""better"" than the other in a blanket way, but [there is previous literature to support that the VBEM may be more accurate](https://academic.oup.com/bioinformatics/article/29/18/2292/239795). However, while RSEM only implements the EM algorithm, salmon actually implements and provides a switch to use either. So, if you want to test the effect of this difference, you can run salmon with the `--useEM` algorithm. This will tell salmon to use the ""classic"" EM algorithm and will eliminate this source of variation. * As with the other question you asked, there may be a _small_ discrepancy depending on when enforcement of a stranded library kicks in under salmon's `A` library type. You can eliminate that variable by simply providing `-l SF` to match the library type being used with RSEM. * Coming back to the `IndelSoftclipSingleend` parameter I mentioned in the first point; RSEM disallows indels in the align",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/612#issuecomment-758004590:2839,simpl,simply,2839,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/612#issuecomment-758004590,2,['simpl'],['simply']
Usability," anot.pre$premature_group <- sapply(; split(; names(anot.pre),; paste(anot.pre$gene_id, anot.pre$transcript_range, sep = '_'); ),; paste, collapse = ';'; )[; paste(anot.pre$gene_id, anot.pre$transcript_range, sep = '_'); ]. # ... need to convert GR to data.table before unique because unique method for GR class ignores metadata and rownames; anot.pre <- as.data.table(anot.pre) %>% unique %>% makeGRangesFromDataFrame(., keep.extra.columns = T); names(anot.pre) <- anot.pre$premature_group. ### Read human genome sequence ####; message('Loading genome sequence...'). dna <- readDNAStringSet(filepath = genome.fasta). # simplify chromosome names; names(dna) <- sapply(strsplit(names(dna), ' '), '[', 1). dna <- dna[chromosomes] # subset chrom 1-22, X, Y, MT. ### Read Gencode transcript sequences ####; gencode <- readDNAStringSet(gencode.tx.fasta); names(gencode) <- gsub(; pattern = '\\|.*', replacement = '',; x = names(gencode); ). ### Sample transcripts on + and - strand (and avoid premature transcripts with multiple mature counterparts for simplicity); anot.pre <- anot.pre[order(width(anot.pre), decreasing = F), ]. chosenOnesP <- anot.pre[; strand(anot.pre) == '+' & !grepl(';', anot.pre$premature_group) & anot.pre$premature_group %in% names(gencode) & !duplicated(anot.pre$premature_group) &; anot.pre$premature_group %in% anot[anot$transcript_source == 'ensembl_havana']$transcript_id; ]$premature_group[1]. chosenOnesM <- anot.pre[; strand(anot.pre) == '-' & !grepl(';', anot.pre$premature_group) & anot.pre$premature_group %in% names(gencode) & !duplicated(anot.pre$premature_group) &; anot.pre$premature_group %in% anot[anot$transcript_source == 'ensembl_havana']$transcript_id; ]$premature_group[1]. chosenOnes <- c(chosenOnesP, chosenOnesM). # subset chosed ones; anot.ori <- anot; anot.pre.ori <- anot.pre. anot <- anot[anot$transcript_id %in% chosenOnes, ]; anot.pre <- anot.pre[anot.pre$premature_group %in% chosenOnes, ]. # sanity check (make sure strand information is the same ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191:6211,simpl,simplicity,6211,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191,2,['simpl'],['simplicity']
Usability," be annotation dependent.; **To Reproduce**; Steps and data to reproduce the behavior:. Specifically, please provide at least the following information:. * Which version of salmon was used? :; * v1.9.0; * How was salmon installed (compiled, downloaded executable, through bioconda)? ; * bioconda; * Which reference (e.g. transcriptome) was used?; * human hg38 [gencode v43 comprehensive](https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_43/gencode.v43.primary_assembly.annotation.gtf.gz) produces the error; * human hg38 [gencode v43 basic](https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_43/gencode.v43.basic.annotation.gtf.gz) works fine.; * Which read files were used?; * The issue is reproducible with multiple independent read files. Logs attached are from reads subsampled from [GSM7099349](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSM7099349); * Which which program options were used?; * --skipQuant -l A. **Expected behavior**; A clear and concise description of what you expected to happen.; salmon quant finishes without seg fault with `--skipQuant`; **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem.; Terminal output when `--skipQuant` is on:; ```; Version Info: ### PLEASE UPGRADE SALMON ###; ### A newer version of salmon with important bug fixes and improvements is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; Sign up for the salmon mailing list to hear about new versions, features and updates at:; https://oceangenomics.com/subscribe; ### salmon (selective-alignment-based) v1.9.0; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /share/genomes/human/hg38/gencode_v43/primary_comprehensive/SalmonIndex }; ### [ skipQuant ] => { }; ### [ libType ] => { A }; ### [ mates1 ] => { GSM7099349.R1.fastq }; ### ",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/902:1246,clear,clear,1246,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/902,1,['clear'],['clear']
Usability," corrected; [2021-01-25 16:27:07.414] [alevinLog] [info] Done indexing Barcodes; [2021-01-25 16:27:07.414] [alevinLog] [info] Total Unique barcodes found: 3896665; [2021-01-25 16:27:07.414] [alevinLog] [info] Used Barcodes except Whitelist: 3667; [2021-01-25 16:27:07.498] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify; [2021-01-25 16:27:07.498] [alevinLog] [info] parsing read library format; [2021-01-25 16:30:54.542] [alevinLog] [info] Starting optimizer; [2021-01-25 16:30:54.782] [alevinLog] [warning] mrna file not provided; using is 1 less feature for whitelisting; [2021-01-25 16:30:54.782] [alevinLog] [warning] rrna file not provided; using is 1 less feature for whitelisting; [2021-01-25 16:30:55.950] [alevinLog] [info] Total 1350278.00 UMI after deduplicating.; [2021-01-25 16:30:55.950] [alevinLog] [info] Total 30909 BiDirected Edges.; [2021-01-25 16:30:55.950] [alevinLog] [info] Total 8817 UniDirected Edges.; [2021-01-25 16:30:55.969] [alevinLog] [info] Clearing EqMap; Might take some time.; [2021-01-25 16:30:56.294] [alevinLog] [warning] Num High confidence barcodes too less 20 < 90.Can't performing whitelisting; Skipping; [2021-01-25 16:30:56.297] [alevinLog] [info] Finished optimizer. ## with `--exceptCells 7000`; > [2021-01-21 09:24:45.891] [alevinLog] [info] Found 43030 transcripts(+0 decoys, +0 short and +0 duplicate names in the index); [2021-01-21 09:24:45.942] [alevinLog] [info] Filled with 43030 txp to gene entries; [2021-01-21 09:24:45.947] [alevinLog] [info] Found all transcripts to gene mappings; [2021-01-21 09:24:45.967] [alevinLog] [info] Processing barcodes files (if Present); [2021-01-21 09:33:35.885] [alevinLog] [info] Done barcode density calculation.; [2021-01-21 09:33:35.885] [alevinLog] [info] # Barcodes Used: 188934609 / 188934609.; [2021-01-21 09:33:37.337] [alevinLog] [info] Total 10016(has 1000 low confidence) barcodes; [2021-01-21 09:33:38.202] [alevinLog] [info] Done True Barcode Sampling; [2021-01-21 09:33:39.137",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/340#issuecomment-766311567:3916,Clear,Clearing,3916,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/340#issuecomment-766311567,1,['Clear'],['Clearing']
Usability," corrected; [2021-01-25 16:27:07.414] [alevinLog] [info] Done indexing Barcodes; [2021-01-25 16:27:07.414] [alevinLog] [info] Total Unique barcodes found: 3896665; [2021-01-25 16:27:07.414] [alevinLog] [info] Used Barcodes except Whitelist: 3667; [2021-01-25 16:27:07.498] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify; [2021-01-25 16:27:07.498] [alevinLog] [info] parsing read library format; [2021-01-25 16:30:54.542] [alevinLog] [info] Starting optimizer; [2021-01-25 16:30:54.782] [alevinLog] [warning] mrna file not provided; using is 1 less feature for whitelisting; [2021-01-25 16:30:54.782] [alevinLog] [warning] rrna file not provided; using is 1 less feature for whitelisting; [2021-01-25 16:30:55.950] [alevinLog] [info] Total 1350278.00 UMI after deduplicating.; [2021-01-25 16:30:55.950] [alevinLog] [info] Total 30909 BiDirected Edges.; [2021-01-25 16:30:55.950] [alevinLog] [info] Total 8817 UniDirected Edges.; [2021-01-25 16:30:55.969] [alevinLog] [info] Clearing EqMap; Might take some time.; [2021-01-25 16:30:56.294] [alevinLog] [warning] Num High confidence barcodes too less 20 < 90.Can't performing whitelisting; Skipping; [2021-01-25 16:30:56.297] [alevinLog] [info] Finished optimizer. ### with `--exceptCells 7000`; > [2021-01-21 09:24:45.891] [alevinLog] [info] Found 43030 transcripts(+0 decoys, +0 short and +0 duplicate names in the index); [2021-01-21 09:24:45.942] [alevinLog] [info] Filled with 43030 txp to gene entries; [2021-01-21 09:24:45.947] [alevinLog] [info] Found all transcripts to gene mappings; [2021-01-21 09:24:45.967] [alevinLog] [info] Processing barcodes files (if Present); [2021-01-21 09:33:35.885] [alevinLog] [info] Done barcode density calculation.; [2021-01-21 09:33:35.885] [alevinLog] [info] # Barcodes Used: 188934609 / 188934609.; [2021-01-21 09:33:37.337] [alevinLog] [info] Total 10016(has 1000 low confidence) barcodes; [2021-01-21 09:33:38.202] [alevinLog] [info] Done True Barcode Sampling; [2021-01-21 09:33:39.13",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/620:4848,Clear,Clearing,4848,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/620,1,['Clear'],['Clearing']
Usability," error when running salmon quant. **To Reproduce**; Steps and data to reproduce the behavior:; Inconsistent behaviour, sometimes quant.sf files are generated, sometimes not. Specifically, please provide at least the following information:. * Which version of salmon was used? 1.10.2 (also occurred using 1.10.1 and 0.14).; * How was salmon installed (compiled, downloaded executable, through bioconda)? installed through bioconda (defined in conda environment).; * Which reference (e.g. transcriptome) was used? BY4742 transcriptome generated using gffread (command used: ""gffread -g BY4742.fa -o wt-syn-transcriptome.gff -w wt-syn-transcriptome.fa -v -C BY4742.gff"").; * Which read files were used? Paired end fastq files (trimmed by fastp).; * Which which program options were used? ""--validateMappings --threads 1 --libType A --index transcriptome-index --mates1 sample1_R1_001.trimmed.fastq.gz --mates2 sample1_R2_001.trimmed.fastq.gz --output sample1"". **Expected behavior**; A clear and concise description of what you expected to happen.; Salmon quant to generate quant.sf file. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem.; ```; Version Info: ### PLEASE UPGRADE SALMON ###; ### A newer version of salmon with bug fixes is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; Sign up for the salmon mailing list to hear about new versions, features and updates at:; https://oceangenomics.com/subscribe; ###; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ validateMappings ] => { }; ### [ threads ] => { 1 }; ### [ libType ] => { A }; ### [ index ] => { transcriptome-index }; ### [ mates1 ] => { sample1_R1_001.trimmed.fastq.gz }; ### [ mates2 ] => { sample1_R2_001.trimmed.fastq.gz }; ### [ output ] => { sample1 }; Logs will be written ",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/881:1182,clear,clear,1182,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/881,1,['clear'],['clear']
Usability," exact read order is not. This can lead to differences in the order in which reads are processed and, as a result, differences in the initialization conditions of the optimization. The ultimate result is that for transcripts that have large inferential uncertainty, different numbers of reads can be assigned between runs. We have thought *a lot* about this behavior, what it means, and how the `NumRead` values should best be communicated to users. At the end of the day, the `NumReads` constitute the expected value of latent variables inferred in a _very_ high-dimensional space (# of parameters is at least the number of transcripts). Therefore, there are certain transcripts, whose estimated number of reads simply have _tremendous_ inferential uncertainty — and small perturbations in the initial conditions of the optimization will lead to different estimated values for their abundances. For those transcripts where you observe such fluctuations between runs, this is simply evidence that the precision that can be confidently placed on those estimates is below the degree of variation you observe. Treating these transcripts in downstream analysis as more certain can easily lead to spurious inferences regarding things like differential transcript expression or usage. . One can make an argument for trying to provide a way to enforce removal of this variation (which, granted, would be a challenge). However, the reason we decided against even attempting this is because it doesn't properly address any issue with respect to an actual biological analysis. That is, even if you could fix, precisely, the update order and initialization conditions for a specific sample to eliminate any variation between runs, almost all experiments consist of multiple samples. In other samples, the same transcript fractions could give rise to a slightly different set of observed fragments that induce exactly the same type of variation under uncertainty; and since that uncertainty is baked into the samp",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/613#issuecomment-757989858:2016,simpl,simply,2016,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/613#issuecomment-757989858,2,['simpl'],['simply']
Usability," here with alevin, so it would mis-detect cells like the shifted ones you pasted above. For SPLiT-seq, we do know exactly which barcodes go into the wells, however, so it is technically possible to restrict based on all possible known combinations of barcodes instead and be more positionally flexible. But deciding how many indel bases are allowable, and presumably doing multiple passes through the data to establish an include-list could be time-consuming. Further, the zUMIs developer rightly mentions [in this thread](https://github.com/sdparekh/zUMIs/issues/63) that there are likely going to be _many_ unused barcode combinations this way, so lots of time could be spent looking for ""cells"" that don't actually exist in the data. The authors of the paper from which our test dataset was derived describe in their methods using a Drop-seq computational framework, so I'm not sure which approach theirs is more similar to. . The simplest approach here is certainly the automatic detection, but it will come at the cost of losing meaningful reads to frameshift errors. . My guess is this falls well out of the scope of alevin, but if you're interested in improving on that, there may be a middle ground between the two approaches above, one that I'm not sure if your group or others have attempted for other methods: we could essentially do a 2-pass barcode detection. The first pass would restrict based on positions like we're already doing, and establish an include-list of possible barcodes seen in the data. Then we could pass through the barcode sequences a second time, looking only for those sequence combinations, but allowing 1-2bp flexibility in the positions they occur, potentially rescuing some of the ones missed during the first pass. This would get around the issue of searching for thousands (or more) barcodes that never exist. . However, for your above sequences in red, we would still need to somehow collapse the barcodes `GATAGACA`, `ATAGACAT`, and `ATAGACAG`, but perhaps t",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-985554883:1176,simpl,simplest,1176,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-985554883,2,['simpl'],['simplest']
Usability," in a way how the reference transcriptome is interpreted. I did this by using bulk ATAC data from both species, calling peaks with MACS2, and then using this peak set (BED format) to extract strain- and species-corrected sequences (fasta) to use as a reference. _**My questions/issues**_:; Considering the basic Alevin invocation:; `salmon alevin -l ISR -1 cb.fastq.gz -2 reads.fastq.gz --chromiumV3 -i salmon_index_directory [--whitelist barcodes.tsv] -p 10 -o alevin_output`; ; `-1 cb.fastq.gz` —> these should be CB+UMI reads, but in 10X ATAC there are no UMIs, so this would only be a 16bp CB. I'm afraid this would be a major issue considering how Alevin relies on UMI whitelisting. Would it help if I already provide a list of filtered whitelisted CB, as provided by Cell Ranger? I have this from a quality control alignment to only one parental species. `--chromiumV3 `—> If I understand correctly, this tells the program to search for the first X bases of cb.fastq.gz as CB, and the first Y bases of it as UMI (as per [this ](https://github.com/COMBINE-lab/salmon/issues/369) thread). So technically one could swap --chromiumV3 for --end 5 --barcodeLength X --umiLength Y and set this manually? But again, what if I only have CBs?. `-2 reads.fastq.gz` —> I understand this is meant for 10X scRNA-seq - which only has insert information on read2, but in 10X scATAC both insert read1 and read2 contain information on open chromatin. I reckon this is the major head scratcher for me, whether it is possible to use Alevin on scATAC at all. Should I merge the fastq read files into a single “reads.fastq.gz”? Or should I treat them as independent (but with the same CBs) and run something along the lines of: `salmon alevin -l ISR -1 cb.fastq.gz cb.fastq.gz -2 read1.fastq.gz read2.fastq.gz` (…etc)? Or maybe there is a way I am not aware of that Alevin can handle paired-end data?. Thank you in advance and I hope I have been detailed and clear enough. Please ask for more details where needed :)",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/611:2621,clear,clear,2621,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/611,1,['clear'],['clear']
Usability," is my first time analyzing RNAseq data and I am very much learning as I go while following a YouTube series (https://www.youtube.com/watch?v=butxOf_fxTY&t=217s&ab_channel=SimonCockell). Please excuse if I use wrong terminology in this post, I am very new to all of this and sometimes don't know what the right words are to describe what I am doing or trying to do (lol)!. With the fastq files of reads generated from my RNAseq experiment, I first ran FastQC. The quality of my data seemed to be fine as the per base sequence quality scores were 32+ and most of the other tests passed as well. Next, I built my index for Salmon using the fasta file from Gencode for the human transcriptome. Afterwards, I ran Salmon with the built index and had it automatically detect the library type. When the program was done aligning to the index, I saw that the file had a mapping rate of 40%. I guess what I'm asking is, is this an acceptable mapping rate or should I be concerned?? The reason I ask is because in the data I was working with while learning via the Youtube series, those datasets had mapping rates of nearly 90%. Comparing FastQC reports, my data was of similar/better quality than the data from the Youtube series. In case this is helpful in answering my question, this is the information from the logs for one of my samples:. ```; [2020-09-05 13:51:07.144] [jointLog] [info] setting maxHashResizeThreads to 1; [2020-09-05 13:51:07.144] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2020-09-05 13:51:07.159] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2020-09-05 13:51:07.159] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.35.; [2020-09-05 13:51:07.159] [jointLog] [info] parsing read library format; [2020-09-05 13:51:07.159] [jointLog] [info] There is 1 library.; [2",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/571:1058,learn,learning,1058,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/571,1,['learn'],['learning']
Usability," not able to attach them here because of the size. Specifically, please provide at least the following information:. * Which version of salmon was used?; salmon 1.3.0. * How was salmon installed (compiled, downloaded executable, through bioconda)?; wget https://github.com/COMBINE-lab/salmon/releases/download/v1.3.0/salmon-1.3.0_linux_x86_64.tar.gz; tar xzvf salmon-1.3.0_linux_x86_64.tar.gz; Directory was relabeled as salmon. * Which reference (e.g. transcriptome) was used?; Mouse Gencode vM25; wget http://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M25/gencode.vM25.transcripts.fa.gz; wget http://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M25/GRCm38.primary_assembly.genome.fa.gz. * Which read files were used?; Files used for salmon quant are attached (*fq.gz). * Which which program options were used?; None specifically was invoked to run salmon.; I am running salmon on a cluster (Linux 3.10.0-957.el7.x86_64 x86_64). **Expected behavior**; A clear and concise description of what you expected to happen. I expect the salmon quant to align and quantify the reads. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem.; 1) Attaching the screenshot in the zipped folder.; 2) Attaching the screenshot of the contents in the folder containing the indexed file. The versionInfo.json file is present in that folder. **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX]; Linux 3.10.0-957.el7.x86_64 x86_64; - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux the output of `uname -a` and `lsb_release -a`]; Linux compute-106.cm.cluster 3.10.0-957.el7.x86_64 #1 SMP Thu Nov 8 23:39:32 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux. lsb-release:. LSB Version: :core-4.1-amd64:core-4.1-noarch:cxx-4.1-amd64:cxx-4.1-noarch:desktop-4.1-amd64:desktop-4.1-noarch:languages-4.1-amd64:languages-4.1-noarch:printing-4.1-amd64:printing-4.1-noarch; Distributor ID: CentOS; Descriptio",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/561:2420,clear,clear,2420,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/561,1,['clear'],['clear']
Usability," read apportionment, such that as the vbPrior increased the two transcripts became increasingly similar in their final expression (presumably they would eventually hit 50/50). It's good to know how that settings affects my data, but this is not quite what I was hoping for... . Ideally, the short transcript would get nearly *all* of the reads, rather than splitting the reads 50/50 or, with the default settings, giving nearly all the reads to the longer transcript. I realized that, as a human, the reason the short transcript is obviously the dominant one is how the reads pileup in the alignment. There are hundreds of reads mapping to both transcripts, but NO reads map to the 5' of the long transcript. As I understand the selective alignment, the alignment scores are passed to the quantification step, but the *position* of the reads is not used downstream. In order to pass my human intuition along here, the software would need to pay attention to the coverage bias of the reads mapping to the transcripts and assign a penalty when two otherwise identical transcripts have a different coverage variance across the transcript. This sounds like what the --posBias flag should incorporate into the effective lengths, but it doesn't have much effect on these transcripts for me (FYI, I am getting a segfault when I run only --posBias in the current salmon version, but if I run all the models together like --gcBias --seqBias --posBias, it completes fine). . Also, my intuition for these transcripts is not really a coverage ""bias"" as much as the read depth absolutely plummeting at the 5' end of the long transcript. It would be neat if Salmon could detect these kinds of dramatic dropoffs and add a warning or something... even if not incorporating the information into the quants... it could even be a good QC step to identify large deletions/insertions over a gene body. As far as I know, there are NO rnaseq quant programs that would handle this, because even something like a STAR -> RSEM",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623043651:1049,intuit,intuition,1049,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623043651,2,['intuit'],['intuition']
Usability," the premature sequences in my transcript fasta against the transcript fasta from Gencode. As you can see in the smoothed dot plots below, the premature sequences of transcripts on the minus strand are in the wrong orientation and have the wrong complementarity!. ![Screenshot from 2021-04-24 00-35-05](https://user-images.githubusercontent.com/10429333/115947355-0d96c880-a495-11eb-92a6-d8d2233c8d2b.png). I included my R code below for this test case for anyone who might stumble upon this issue. Under the code headers “Mature transcript sequences” and “Premature transcript sequences”, you can observe that I used identical protocols for sequence subsetting, yet in the mature case the strand information in the GRanges seems to be disregarded when subsetting from Biostrings, but in the premature case the strand information is used. Of course, this problem is out of the scope of this forum so it will be okay to close this issue. I will reach out to the developers of GenomicRanges and Biostrings to point out this potential problem and seek their guidance. Thank you again for all your help. Rached. ```; # setwd('wd'). options(scipen = 9999). libraries <- lapply(; X = c('data.table', 'magrittr', 'rtracklayer', 'Biostrings', 'reshape2', 'ggplot2'),; FUN = library, character.only = TRUE; ). ### Inputs ####; anot.gtf <- '../../shared_data/annotations/Ensembl/Homo_sapiens.GRCh38.101.gtf.gz' # Ensembl GTF; genome.fasta <- '../../shared_data/annotations/Ensembl/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz' # Genome fasta from Ensembl; gencode.tx.fasta <- '../../shared_data/annotations/Gencode/gencode.v35.transcripts.fa.gz' # Gencode transcript FASTA. dotPlot.fname <- '../ouput/dotPlots.pdf'. ### Read exon annotations ####; message('Loading Ensembl exon annotation (1-22, X, Y, MT)...'). chromosomes <- c(1:22, 'X', 'Y', 'MT'). anot <- import(anot.gtf, feature = 'exon') %>% sort; anot <- anot[seqnames(anot) %in% chromosomes, ]. # append gene and transcript version numbers to IDs; a",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191:3591,guid,guidance,3591,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191,2,['guid'],['guidance']
Usability," the right end of the transcript which is inconsistent with the coverage profile and, as hoped, salmon did not assign any reads to that variant. So, in these two scenarios the default options produce nice results in line with our human intuition. 2. **Failure scenario with default options:** ; ![PDI1_example](https://user-images.githubusercontent.com/10292386/86509895-3df36600-bda0-11ea-8f0b-df0de4fefa31.png); <img width=""383"" alt=""PDI1_table"" src=""https://user-images.githubusercontent.com/10292386/86509897-40ee5680-bda0-11ea-9566-9f2bdab464f0.png"">. In this example there are four genes (oriented in the same direction) with wildly different expression levels. I added a ""PDI1_SuperTranscript"" which stretches from the 5' end of PDI1 to the 3' end of POF1 (so, all reads from all 4 genes would multimap to the super transcript). This is a contrived example to illustrate the technical details, but you could imagine similar biological scenarios, especially regarding splicing isoforms. With the default options, you get the counterintuitive result that all of the reads from just MGR1 and POF1 (the two lowest abundance transcripts) are assigned to the super transcript. EMC1 loses ~50% of its reads to the super transcript, and PDI1 only loses ~10%. I'm not showing it, but if you remove the default PDI1 transcript from the index (so it's just the super transcript + the 3 genes MGR1/EMC1/POF1), all three of them lose all of their reads to the super transcript... meaning that whether or not EMC1 gets assigned any reads depends entirely on the presence of a non-overlapping gene, PDI1, in the salmon index. This is definitely at odds with our intuition from looking at the coverage plots, but makes sense when you break all the transcripts down to a simple reads per kb equation. As before, if you turn off length modeling then all of the reads get assigned to the super transcript. I hope this was insightful and cleared up the issue a bit. Feel free to e-mail or reply here. Best,; Jason",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-653747847:6540,intuit,intuition,6540,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-653747847,6,"['clear', 'intuit', 'simpl']","['cleared', 'intuition', 'simple']"
Usability," transcripts). Similarly, if you can provide the quantification directory, we can help examine this too. If this is the case, that the posterior distributions are highly anti-correlated, it is likely that the ambiguity you are seeing is simply inherent given the alignments salmon is being provided. If you have the quantification folder resulting from the same sample using selective alignment, we could compare and contrast the two. At that point, there are a few options depending on how deeply you want to dive. You could try to see how STAR and selective alignment are mapping differently to these transcripts. One potential difference is that STAR is _a lot_ more happy to softclip reads, which selective alignment won't do by default (you can test the effect with the `--softclipOverhangs` to allow selective alignment to softclip reads that hang off the transcript end or `--softclip` to allow softclips anywhere). Note that selective alignment may _still_ be a bit more conservative than STAR about softclips simply because of the nature of the scoring function it uses. This might give you a sense if one of these alignment methodologies is more consistent with your expectations in this case. Another option is to consider doing a grouping with `terminus`. This will reduce the set of ""genes"" that you can call as DE, because it will be happy to group together transcripts from different genes. However, it should help considerably in eliminating DE from highly-uncertain point estimates. Finally, you might consider performing DE with swish (cc @mikelove as he might have some input here) rather than DESeq2 (though we've typically been using swish at the transcript level rather than the gene level). Unlike DESeq2, swish will explicitly take into account the inferential uncertainty in the abundance estimates, using the Gibbs samples produced by salmon. This will allow it to avoid spurious DE calls that might otherwise occur when you have highly uncertain transcripts that, by chance,",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/600#issuecomment-740363115:3867,simpl,simply,3867,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/600#issuecomment-740363115,2,['simpl'],['simply']
Usability," worst warnings. Salmon writes most of the messages to `STDERR`. 1. `Version Info: This is the most recent version of Salmon.` is output to `STDOUT`. I find it useless. If salmon run some network connection to figure out its version it is `a)` prone to errors, `b)` I would expect a fat warning in the documentation a `phone home` feature is builtin, `c)` it is likely to fail on more network-restricted installations. Or, `d)`, the message is incorrect. I suggest drop the message altogether. 2. `salmon quant` writes a lot of normal messages to `STDERR`. Please use `STDOUT` instead. If a program exits with a non-zero exit code it is common to read its `STDERR` output to learn what was the cause for the error. It is awkward to realize there is lots of unrelated text. Please follow common rules on Unix. 3. The docs at http://salmon.readthedocs.io/en/latest/salmon.html did not mention the `fmd` index is just a plain index from `bwa`. Why don't you instruct users to use `bwa index` instead? It would be clearer (if that is the type of index you employ). 4. `salmon index` behavior. ```; salmon index -t Homo_sapiens.GRCh38.cdna.all.fa -i Homo_sapiens.GRCh38.cdna.all --type quasi -k 31; index [""Homo_sapiens.GRCh38.cdna.all""] did not previously exist . . . creating it; [2018-06-25 19:25:57.122] [jLog] [info] building index; RapMap Indexer. [Step 1 of 4] : counting k-mers; [2018-06-25 19:25:57.176] [jointLog] [warning] Entry with header [ENST00000434970.2], had length less than the k-mer length of 31 (perhaps after poly-A clipping); [2018-06-25 19:25:57.176] [jointLog] [warning] Entry with header [ENST00000448914.1], had length less than the k-mer length of 31 (perhaps after poly-A clipping); ...; [2018-06-25 19:26:07.297] [jointLog] [warning] Entry with header [ENST00000579054.1], had length less than the k-mer length of 31 (perhaps after poly-A clipping); [2018-06-25 19:26:07.451] [jointLog] [warning] Entry with header [ENST00000634174.1], had length less than the k-mer length ",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/242:1200,clear,clearer,1200,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/242,1,['clear'],['clearer']
Usability,"# tl;dr; - `salmon alevin` returns an error if the cell barcode length is > 31 base pairs; - This blocks me from using `salmon alevin` for a novel scRNA-seq chemistry that has a 34 base pair cell barcode.; - Previously the `salmon alevin` maximum cell barcode length was increased from 20 base pairs to 31 base pairs. https://github.com/COMBINE-lab/salmon/discussions/629; - Could you please increase the maximum cell barcode length again?; - Or provide guidance on how I should do this in my own fork of salmon?. # Summary. This bug primarily related to alevin (single-cell mode). **Describe the bug**. **To Reproduce**; ```; salmon alevin; -i /path/to/salmon_index ; -p 16 ; -l ISR; --read-geometry 2[1-100] ; --bc-geometry 1[1-34] ; --umi-geometry 1[35-44] ; --sketch ; -1 /path/to/r1.fastq ; -2 /path/to/r2.fastqs; -o /output/path ; --tgMap /path/to/t2g.tsv; ```. Steps and data to reproduce the behavior:. Specifically, please provide at least the following information:. * Salmon version`v1.10.1`; * How was salmon installed? -> Compiled; * Encountered this error when running a feature barcoding analysis following this tutorial https://combine-lab.github.io/alevin-fry-tutorials/2021/af-feature-bc/. **Expected behavior**; Salmon alevin does not error out when the cell barcode length is 34 base pairs. **Screenshots**; Error log; `[2024-06-17 22:00:25.466] [alevinLog] [error] Barcode length (34) was not in the required length range [1, 31].`. **Desktop (please complete the following information):**; - OS: Ubuntu 22.04",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/943:454,guid,guidance,454,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/943,1,['guid'],['guidance']
Usability,"**Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**. **Describe the bug**; A clear and concise description of what the bug is. **To Reproduce**; Steps and data to reproduce the behavior:. Specifically, please provide at least the following information:. * Which version of salmon was used?; * How was salmon installed (compiled, downloaded executable, through bioconda)?; * Which reference (e.g. transcriptome) was used?; * Which read files were used?; * Which which program options were used?. **Expected behavior**; A clear and concise description of what you expected to happen. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX]; - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux the output of `uname -a` and `lsb_release -a`]. **Additional context**; Add any other context about the problem here.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/320:110,clear,clear,110,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/320,6,['clear'],['clear']
Usability,"**Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**. **Describe the bug**; A clear and concise description of what the bug is. **To Reproduce**; Steps and data to reproduce the behavior:. Specifically, please provide at least the following information:. * Which version of salmon was used?; Salmon 1.4; * How was salmon installed (compiled, downloaded executable, through bioconda)?; downloaded executable; * Which reference (e.g. transcriptome) was used?; ensembl releases 103 and 87; * Which read files were used?; fastq files; * Which which program options were used?; quant --validateMappings --numBootstraps 50 --gcBias --seqBias. **Expected behavior**; A clear and concise description of what you expected to happen.; We expected to get the similar TPMs for a recalculation of a cohort of RNAseq data with a newer ensembl fasta release, but they were far off. **Desktop (please complete the following information):**; - RHEL7. **Additional context**; We also attempted to create our own fasta files using stringtie and scallop, but ran into the same issue as stated above.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/653:110,clear,clear,110,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/653,2,['clear'],['clear']
Usability,"**Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**. **Describe the bug**; I am getting this error : Two references with the same name but different sequences: XR_001465382.2_LOC4; 21118_-. We require that all input records have a unique name up to the first whitespace character. But when I try to create a histogram of that reference it only shows 1 sequence with that name: ; grep 'XR_001465383.2_LOC421108' galGal6.gene+cluster+repBase+tRNA.fa.nodup | sort | uniq -c | awk '{printf(""%s\t%s\n"", $1, $2)}'; 1 >XR_001465383.2_LOC421108_-. **To Reproduce**; This is the code I used ; salmon index -t galGal6.gene+cluster+repBase+tRNA.fa.nodup -i SalmonIndexNodup -k 31. Specifically, please provide at least the following information:. * Which version of salmon was used?; I used v1.5.1; * How was salmon installed (compiled, downloaded executable, through bioconda)?; Yes; * Which reference (e.g. transcriptome) was used?; Mouse (mm10); * Which read files were used?; * Which which program options were used?. **Expected behavior**; A clear and concise description of what you expected to happen. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX]; - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux the output of `uname -a` and `lsb_release -a`]. **Additional context**; Add any other context about the problem here.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/683:1069,clear,clear,1069,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/683,1,['clear'],['clear']
Usability,"**Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**. **Describe the bug**; I can't run ""Quantifying in mapping-based mode"" in Salmon 1.8.0 for reads single-end.; Im not sure if the ""--libType"" (-l) argument is right...; The menssage that appear is ""Segmentation fault"" and the run finish. (following Screenshots). **To Reproduce**; Im executing the following command: salmon quant -i index -l A -r ../fastq_zip/SRR16620521.fastq.gz -o ../salmon_quant/. The ""index"" is my directory with my transciptome data and ""SRR16620521.fastq.gz"" is my file single-end. Specifically, please provide at least the following information:. * Which version of salmon was used? 1.8.0; * How was salmon installed (compiled, downloaded executable, through bioconda)? conda install salmon=1.8.0; * Which reference (e.g. transcriptome) was used? Sviridis_500_v2.1.transcript_primaryTranscriptOnly.fa.gz (Setaria viridis transciptome from Phytozome); * Which read files were used? SRR16620521.fastq.gz; * Which which program options were used? . **Expected behavior**; A clear and concise description of what you expected to happen. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem.; ![image](https://user-images.githubusercontent.com/87829929/236075390-07846634-fa21-4146-8a21-673947510a84.png). **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX]; - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux the output of `uname -a` and `lsb_release -a`]. **Additional context**; Add any other context about the problem here.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/847:1080,clear,clear,1080,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/847,1,['clear'],['clear']
Usability,"**Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**. **Describe the bug**; I installed latest version of salmon through git clone for trinityrnaseq. When i run trinity using a command ""perl Trinity --seqType fq --left reads_1.fq --right reads_2.fq --CPU 6 --max_memory 20G' I am getting a message to install salmon. kindly give me a solution for this. **To Reproduce**; Trinity Trinity-v2.8.5 requires salmon to be installed. Get it here: https://combine-lab.github.io/salmon/ at Trinity line 3870. Specifically, please provide at least the following information:. * Which version of salmon was used?; * How was salmon installed (compiled, downloaded executable, through bioconda)?; **Expected behavior**; A clear and concise description of what you expected to happen. **Screenshots**; iipr@iipr-ubuntu:~/trinityrnaseq-Trinity-v2.8.5$ perl Trinity --seqType fq --left reads_1.fq --right reads_2.fq --CPU 6 --max_memory 20G. ______ ____ ____ ____ ____ ______ __ __; | || \ | || \ | || || | |; | || D ) | | | _ | | | | || | |; |_| |_|| / | | | | | | | |_| |_|| ~ |; | | | \ | | | | | | | | | |___, |; | | | . \ | | | | | | | | | | |; |__| |__|\_||____||__|__||____| |__| |____/. Trinity-v2.8.5. Left read files: $VAR1 = [; 'reads_1.fq'; ];; Right read files: $VAR1 = [; 'reads_2.fq'; ];; Trinity version: Trinity-v2.8.5; ** NOTE: Latest version of Trinity is v2.8.6, and can be obtained at:; 	https://github.com/trinityrnaseq/trinityrnaseq/releases. Trinity Trinity-v2.8.5 requires salmon to be installed. Get it here: https://combine-lab.github.io/salmon/ at Trinity line 3870.; iipr@iipr-ubuntu:~/trinityrnaseq-Trinity-v2.8.5$ ^C. **Desktop (please complete the following information):**; - OS: Ubuntu; - Version18.04. **Additional context**; Add any other context about the problem here.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/452:741,clear,clear,741,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/452,1,['clear'],['clear']
Usability,"**Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**. **Describe the bug**; I installed salmon using cmake command. i.e mkdir build/.. cd build... cmake and i encountered these; **To Reproduce**; Steps and data to reproduce the behavior:. Specifically, please provide at least the following information:. * latest version 1.0. **Expected behavior**; A clear and concise description of what you expected to happen. **Screenshots**; -- fetch PUFFERFISH exit code 0; -- Found ZLIB: /usr/lib/x86_64-linux-gnu/libz.a (found version ""1.2.11""); CMake Error at CMakeLists.txt:319 (find_package):; By not providing ""FindIconv.cmake"" in CMAKE_MODULE_PATH this project has; asked CMake to find a package configuration file provided by ""Iconv"", but; CMake did not find one. Could not find a package configuration file provided by ""Iconv"" with any of; the following names:. IconvConfig.cmake; iconv-config.cmake. Add the installation prefix of ""Iconv"" to CMAKE_PREFIX_PATH or set; ""Iconv_DIR"" to a directory containing one of the above files. If ""Iconv""; provides a separate development package or SDK, be sure it has been; installed. -- Configuring incomplete, errors occurred!; See also ""/home/iipr/trinityrnaseq-Trinity-v2.8.5/salmon/build/CMakeFiles/CMakeOutput.log"".; See also ""/home/iipr/trinityrnaseq-Trinity-v2.8.5/salmon/build/CMakeFiles/CMakeError.log""; **Desktop (please complete the following information):**; - OS: Ubuntu; - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux the output of `uname -a` and `lsb_release -a`]. **Additional context**; Add any other context about the problem here.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/453:384,clear,clear,384,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/453,1,['clear'],['clear']
Usability,"**Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**. The bug is primarily related to salmon, but I am using salmon to build an index for use with alevin-fry per the [alevin-fry tutorial](https://combine-lab.github.io/alevin-fry-tutorials/2021/improving-txome-specificity/). . **Describe the bug**; A clear and concise description of what the bug is. I have previously followed the steps outlined in the alevin-fry tutorial for a single sample and everything worked as expected. Now I am following the same steps but wrapped in a snakemake pipeline to process several samples and am running into issues building the index. Specifically, I am receiving the following error when my pipeline moves on the mapping reads step:. ```; Exception : [Error: The index version file /beevol/home/winklerc/projects/scifi_pipeline/scifi/ref/idx/complete_ref_lens.bin/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; alevin (sc-align) was invoked improperly.; ```. I have tried re-building the index, and have also tried reusing the index that I had previously built for the single sample run that previously worked. However, neither of those approaches fixed the above error. When I build the index I am able to generate all of the expected files and the file sizes match those of my previous (successful) index build, so I am not sure why I am getting an error that the `versionInfo.json` file is missing. **To Reproduce**; Steps and data to reproduce the behavior:. I followed the alevin-fry tutorial to generate a splici transcriptome, using the same [Human reference (GRCh38) dataset](https://cf.10xgenomics.com/supp/cell-exp/refdata-gex-GRCh38-2020-A.tar.gz) provided by the tutorial. My snakemake rule to build the index uses the same commands outlined in the alevin-fry tutorial, and looks like this:. ```; rule build_idx: ; # build a splici (spliced + intron) index for alevin-fry; input:; fasta = ""{out_data}/ref/transcriptome/transcriptome",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/713:333,clear,clear,333,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/713,1,['clear'],['clear']
Usability,"**Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**. salmon (bulk mode) latest binary (1.8.0) from github. **Describe the bug**; A clear and concise description of what the bug is. core dumped crash on building index process. **To Reproduce**; Steps and data to reproduce the behavior:. wget http://ftp.ensembl.org/pub/current_fasta/mus_musculus/cdna/Mus_musculus.GRCm39.cdna.all.fa.gz ; wget http://ftp.ensembl.org/pub/current_fasta/mus_musculus/dna/Mus_musculus.GRCm39.dna.primary_assembly.fa.gz; wget https://github.com/COMBINE-lab/salmon/releases/download/v1.8.0/salmon-1.8.0_linux_x86_64.tar.gz; grep ""^>"" <(gunzip -c Mus_musculus.GRCm39.dna.primary_assembly.fa.gz) | cut -d "" "" -f 1 > decoys.txt; sed -i.bak -e 's/>//g' decoys.txt; cat Mus_musculus.GRCm39.cdna.all.fa.gz Mus_musculus.GRCm39.dna.primary_assembly.fa.gz > gentrome.fa.gz; salmon index -t gentrome.fa.gz -d decoys.txt -p 60 -i Mus_musculus.GRCm39_v1.8.0_decoy.index. Specifically, please provide at least the following information:. * Which version of salmon was used?; 1.8.0. * How was salmon installed (compiled, downloaded executable, through bioconda)?; downloaded executable. * Which reference (e.g. transcriptome) was used?; downloaded executable; . **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. salmon-1.8.0_linux_x86_64/bin/salmon index -t gentrome.fa.gz -d decoys.txt -p 60 -i Mus_musculus.GRCm39_v1.8.0_decoy.index; Version Info: This is the most recent version of salmon.; index [""Mus_musculus.GRCm39_v1.8.0_decoy.index""] did not previously exist . . . creating it; [2022-06-01 18:13:38.986] [jLog] [info] building index; out : Mus_musculus.GRCm39_v1.8.0_decoy.index; [2022-06-01 18:13:38.986] [puff::index::jointLog] [info] Running fixFasta. [Step 1 of 4] : counting k-mers; [2022-06-01 18:13:38.994] [puff::index::jointLog] [warning] Entry with header [ENSMUST00000178537.2], had length less than equal to the k-mer length of 31 (perha",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/783:164,clear,clear,164,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/783,1,['clear'],['clear']
Usability,"**Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**. salmon. **Describe the bug**; A clear and concise description of what the bug is. Running `salmon index` on a HPC cluster (called from a trinity perl script). After a while salmon is only idling. In the stderr I see:. ```; Encountered FastxParser destructor while parser was still marked active (or while parsing threads were still active). Be sure to call stop() before letting FastxParser leave scope!; ```. The problem seems to be the available memory. On HPC systems one usually needs to specify a max amount of memory which is enforced (e.g. with ulimit). . If I give more memory to the job salmon finishes. . **To Reproduce**; Steps and data to reproduce the behavior:. Specifically, please provide at least the following information:. * Which version of salmon was used?; * How was salmon installed (compiled, downloaded executable, through bioconda)?; * Which reference (e.g. transcriptome) was used?; * Which read files were used?; * Which which program options were used?. Salmon 1.1 installed through conda. I guess any data will do to reproduce as long as the memory limitations ar small enough. **Expected behavior**; A clear and concise description of what you expected to happen. Would be good if salmon would exit with a better error message and a non-zero exit code in such a case. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX]; - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux the output of `uname -a` and `lsb_release -a`]. CentOS 7. **Additional context**; Add any other context about the problem here.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/484:118,clear,clear,118,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/484,2,['clear'],['clear']
Usability,"**Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**; Alevin-fry. **Describe the bug**; A clear and concise description of what the bug is.; The new updates to the `cmd_info.json` file result in an extra `:` at the end of `""salmon_version:""` inside the quotes. This results in the json file being read in with the header of that entry being `salmon_version:` when it should be `salmon_version`. . Note that this was found when running `salmon alevin` in the `--rad` or `--justAlign` mode and we have not tested if this is also the case when running only `salmon alevin`. . **To Reproduce**; Steps and data to reproduce the behavior:; We ran alevin-fry v0.4.1 starting with `salmon alevin` using `--rad` on single-cell data in the salmon biocontainer and that led to the `cmd_info.json` file being output with the extra `:` on salmon_version. . The biocontainer that we used was: quay.io/biocontainers/salmon:1.5.2--h84f40af_0 . Specifically, please provide at least the following information:. * Which version of salmon was used?; 1.5.2; * How was salmon installed (compiled, downloaded executable, through bioconda)?; used the biocontainer ; * Which reference (e.g. transcriptome) was used?; used the splici index following the alevin-fry tutorial ; * Which read files were used?; * Which which program options were used?; ```; salmon alevin -l ISR --chromiumV3 --dumpFeatures --rad; ```. **Expected behavior**; A clear and concise description of what you expected to happen.; We would expect that the extra `:` would not be included to be consistent with previous versions of salmon. ; <img width=""325"" alt=""Screen Shot 2021-07-29 at 12 35 38 PM"" src=""https://user-images.githubusercontent.com/54039191/127538599-206d5e71-cb7a-4a82-8064-4e92e12ee892.png"">. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX]; - Version [ If you are ",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/691:122,clear,clear,122,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/691,1,['clear'],['clear']
Usability,"**Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**; Alevin; **Describe the bug**; A clear and concise description of what the bug is.; Reanalyzing published Drop-Seq data the alevin analysis results in drastically fewer barcodes accepted than the published dataset. Published dataset contains 3000 CBs for the specific sample (authors report that 70% of [these] putative cells from WT mice met QC criteria), alevin result contains 459 CBs.; A similar highly abbreviated CB result was obtained with reanalysis of SRR8889412. **To Reproduce**; Steps and data to reproduce the behavior:. Data used from Sample: https://www.ebi.ac.uk/ena/browser/view/SRR8889411; Publication: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6925218/#; Specific Sample: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSM3720936. Alevin was run using no special parameters with the --dropseq flags. The only significant protocol deviation was in index construction (see below). Specifically, please provide at least the following information:. * Which version of salmon was used?; v1.4.0; * How was salmon installed (compiled, downloaded executable, through bioconda)?; Salmon was run in stock docker container; * Which reference (e.g. transcriptome) was used?; Full decoy Index generated on Gencode M25 per Alevin Velocity tutorial with a k=17 (dataset has 50bp R2 Reads); Introns were extracted with 49bp flanking sequence. ; ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M25/gencode.vM25.annotation.gtf.gz. * Which read files were used?; Data used from Sample: https://www.ebi.ac.uk/ena/browser/view/SRR8889411; * Which which program options were used?; --dropseq -l ISR. **Expected behavior**; A clear and concise description of what you expected to happen.; Cell calls should be ballpark similar to published result (3000 original vs. 459 alevin). **Tar of Alevin Output directory**; [WT01_P7_WT_Cerebellum_alevin.output.tar.gz](https://github.com/COMBINE-lab/salmon",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/625:118,clear,clear,118,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/625,1,['clear'],['clear']
Usability,"**Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**; Both. **Describe the bug**; When viewing http://salmon.readthedocs.io/en/latest/index.html, the page header described Salmon 0.8.1. Is the documentation out of date, or is that simply not an updated version number?. **To Reproduce**; View http://salmon.readthedocs.io/en/latest/index.html. **Expected behavior**; Salmon 0.11.0 is the latest release, thus I expected the latest version of the documentation to reflect that.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/259:263,simpl,simply,263,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/259,1,['simpl'],['simply']
Usability,"**Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**; Bulk. **Describe the bug**; A clear and concise description of what the bug is.; After building an index of the most recent build of the ensemble mouse genome (39) with salmon, running quant failed immediately. The output from the failed salmon quant is: . Version Server Response: Not Found; ### salmon (selective-alignment-based) v1.5.2; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { mnt/home/oconn341/salmon/indexs/alt_long_index }; ### [ libType ] => { A }; ### [ mates1 ] => { preprocs_fastq/ERAP1_EAE_2270_S4/ERAP1_EAE_2270_S4_R1_001.fastq.gz }; ### [ mates2 ] => { preprocs_fastq/ERAP1_EAE_2270_S4/ERAP1_EAE_2270_S4_R2_001.fastq.gz }; ### [ output ] => { preprocs_fastq/ERAP1_EAE_2270_S4 }; ### [ validateMappings ] => { }; ### [ rangeFactorizationBins ] => { 4 }; ### [ gcBias ] => { }; ### [ seqBias ] => { }; Logs will be written to preprocs_fastq/ERAP1_EAE_2270_S4/logs; [2021-08-20 18:19:52.590] [jointLog] [info] setting maxHashResizeThreads to 40; [2021-08-20 18:19:52.590] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2021-08-20 18:19:52.590] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2021-08-20 18:19:52.590] [jointLog] [info] Setting consensusSlack to selective-alignment default of 0.35.; [2021-08-20 18:19:52.590] [jointLog] [info] parsing read library format; [2021-08-20 18:19:52.590] [jointLog] [info] There is 1 library.; Exception : [Error: The index version file mnt/home/oconn341/salmon/indexs/alt_long_index/versionInfo.json doesn't seem to exist. Please try re-building the salmon index.]; /mnt/home/oconn341/salmon/bin/salmon quant was invoked improperly.; For usage information, try /mnt/home/oconn341/salmon/bin/salmon quant --help; Exiting. However, the versionInfo.json file is in my index folder",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/696:116,clear,clear,116,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/696,1,['clear'],['clear']
Usability,"**Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**; Related to Salmon. **Describe the bug**; my transcript file has a total of 119032 records:. [gao@bio reference]$ grep -c "">"" GRCm38.vM11.transcripts.ercc.Tg.fa; 119032. However, my salmon output has 117509 records:; [gao@bio KM25_salmon_quant.originalData.k21]$ wc -l quant.sf; 117509 quant.sf. How should I explain this?; **To Reproduce**; Steps and data to reproduce the behavior:. Specifically, please provide at least the following information:. * Which version of salmon was used? ; I used salmon 0.13.0; * How was salmon installed (compiled, downloaded executable, through bioconda)?; Installed on HPC; * Which reference (e.g. transcriptome) was used?; Mouse transcriptome; * Which read files were used?; RNAseq files; * Which which program options were used?; command line:. salmon quant -p 8 -i /data/Re-analysis/SalmonRun/reference/GRCm38.vM11.transcripts.ercc.Tg.fa.k21.index -g /data/Re-analysis/Salmon-Run/reference/tx2gene.gencode.v27.tabbed.csv --seqBias --gcBias -l A -1 read1.fastq.gz -2 read2.fastq.gz -o /data/Re-analysis/Salmon-Run/quant-output-co; rrected/KM25_salmon_quant.originalData.k21. **Expected behavior**; A clear and concise description of what you expected to happen. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX]; HPC computing cluster; - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux the output of `uname -a` and `lsb_release -a`]. **Additional context**; Add any other context about the problem here.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/378:1223,clear,clear,1223,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/378,1,['clear'],['clear']
Usability,"**Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**; Running make inside build after doing ""cmake"" against the source directory. . **Describe the bug**; A clear and concise description of what the bug is.; Unable to compile this file with gcc-4.9.2 and cmake 3.11.1; **To Reproduce**; Steps and data to reproduce the behavior:; Following steps as specified in guide. Assigning prefix to point to different installation directory and have tried passing in boost location and telling cmake to fetch boost but both result with the same error. . Specifically, please provide at least the following information:; `[ 91%] Building CXX object src/CMakeFiles/salmon.dir/SalmonQuantify.cpp.o; /nfs/sw/src/rescomp-6993/salmon/src/SalmonQuantify.cpp: In function ‘void processReadLibrary(ReadExperimentT&, ReadLibrary&, SalmonIndex*, std::vector<Transcript>&, ClusterForest&, std::atomic<long unsigned int>&, std::atomic<long unsigned int>&, std::atomic<long unsigned int>&, bool, std::atomic<bool>&, ForgettingMassCalculator&, FragmentLengthDistribution&, SalmonOpts&, double, bool, std::mutex&, size_t, std::vector<std::vector<AlignmentGroup<AlnT> > >&, volatile bool&)’:; /nfs/sw/src/rescomp-6993/salmon/src/SalmonQuantify.cpp:1964:47: error: parameter declared ‘auto’; auto parserPtrDeleter = [&salmonOpts](auto* p) -> void {; ^; /nfs/sw/src/rescomp-6993/salmon/src/SalmonQuantify.cpp: In lambda function:; /nfs/sw/src/rescomp-6993/salmon/src/SalmonQuantify.cpp:1966:7: error: ‘p’ was not declared in this scope; p->stop();; ^; /nfs/sw/src/rescomp-6993/salmon/src/SalmonQuantify.cpp:1974:12: error: ‘p’ was not declared in this scope; delete p;; ^; /nfs/sw/src/rescomp-6993/salmon/src/SalmonQuantify.cpp: In function ‘void processReadLibrary(ReadExperimentT&, ReadLibrary&, SalmonIndex*, std::vector<Transcript>&, ClusterForest&, std::atomic<long unsigned int>&, std::atomic<long unsigned int>&, std::atomic<long unsigned int>&, bool, std::atomic<bool>&, ForgettingMassCalcul",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/296:188,clear,clear,188,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/296,2,"['clear', 'guid']","['clear', 'guide']"
Usability,"**Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**; Salmon (build mode). **Describe the bug**; A clear and concise description of what the bug is. From salmon output: ""validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.35"". When passing the --validateMappings flag without an explicit consensus slack, the program says that a 0.2 value is implied for the consensus salck, but then proceeds to set a different value. **To Reproduce**; Steps and data to reproduce the behavior:; Pass --validateMappigngs without explicit consensusSlack; Specifically, please provide at least the following information:. * Which version of salmon was used? - 1.3.0; * How was salmon installed (compiled, downloaded executable, through bioconda)? bioconda; * Which reference (e.g. transcriptome) was used? Mouse gencode M25; * Which read files were used? Internal experiment; * Which which program options were used?. salmon quant \; --index=$index \; --threads=12 \; --validateMappings \; --gcBias \; --posBias \; --seqBias \; --libType=A \ (ISR was detected, which is correct); -1 ""${R1[$i]}"" \; -2 ""${R2[$i]}"" \; --numBootstraps=30 \; --output=$outdir ;. **Expected behavior**; A clear and concise description of what you expected to happen. The default consensusSlack and the value that is set when it is not explicitly provided should be the same value. **Desktop (please complete the following information):**; ProductName:	Mac OS X; ProductVersion:	10.15.7; BuildVersion:	19H2",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/587:131,clear,clear,131,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/587,2,['clear'],['clear']
Usability,"**Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**; Salmon (bulk mode); **Describe the bug**; A clear and concise description of what the bug is.; Salmon fails without warning when using --recoverOrphans as part of quasi mapping. Dropping --recoverOrphans allows for job to be completed. Salmon exits with a nonzero exit code: 9 otherwise (shows as 9:0 with squeue). This also may be related to #929 . **To Reproduce**; Steps and data to reproduce the behavior:; https://combine-lab.github.io/alevin-tutorial/2019/selective-alignment/; to generate our index . SLURM script; ```bash; #!/bin/bash; #SBATCH --chdir=/path/to/working/dir/; #SBATCH --partition=short; #SBATCH --job-name=Salmon; #SBATCH --error=/path/to/logs/%x_%j.err; #SBATCH --output=/path/to/logs/%x_%j.out; #SBATCH --ntasks=6; #SBATCH --time=02:00:00; #SBATCH --cpus-per-task=2; #SBATCH --mem-per-cpu=30G; module load parallel # parallel/20150822-GCC-4.9.2; module load Anaconda3/2022.05; conda activate Salmon. parallel --jobs 6 --header : --colsep ',' \; 'salmon quant -I /path/to/index/folder/ \; -l A\; -1 /path/to/""{fastq_1}"" \; -2 /path/to/""{fastq_2}""\; --writeUnmappedNames \; --validateMappings \; --recoverOrphans\; --gcBias \; --seqBias \; --recoverOrphans\; -o /path/to/output/{Samples} \; --threads 2' :::: /path/to/sheet_with_sample_and_fastq_names.csv; ```; Specifically, please provide at least the following information:. * Which version of salmon was used?; Both 1.10.2 and 1.10.3 were tested. ; * How was salmon installed (compiled, downloaded executable, through bioconda)?; Used bioconda; * Which reference (e.g. transcriptome) was used?; GRCh38 ; * Which read files were used?; Illumina NovaSeq. Merged fastq based on direction (fastq split across lanes and had to add top off data) with zcat, used cutadapt for adapter trimming. . * Which which program options were used?; Ribodetector was used to get rid of rRNA contamination. Used output of non rRNA files with Salmon quant. **",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/961:130,clear,clear,130,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/961,1,['clear'],['clear']
Usability,"**Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**; alevin; **Describe the bug**; A clear and concise description of what the bug is.; I am running the following command on some sci-rna-seq3 samples and it seems to not work as expected. ; `salmon alevin -i af_splici/dm6_splici_idx/ -l ISR -1 data/SRR17122012_1.fastq -2 data/SRR17122012_2.fastq -o SRR17122012 --tgMap transcriptome_splici_fl52/transcriptome_splici_fl52_t2g.tsv -p 28 --sciseq3 --justAlign`; I then took the output into alevin-fry to create a generate-permit-list and it gives me the error that salmon hasn't added the extra bps to account for the chemistry; ""thread 'main' panicked at 'assertion failed: `(left == right)`; left: `20`,; right: `19`: found barcodes of different lenghts 20 and 19', src/cellfilter.rs:203:13; note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace""; Thus I re-ran salmon alevin without the --justAlign flag and it seems to hit a different error; ""### alevin (dscRNA-seq quantification) v1.9.0; ### [ program ] => salmon ; ### [ command ] => alevin ; ### [ index ] => { af_splici/dm6_splici_idx/ }; ### [ libType ] => { ISR }; ### [ mates1 ] => { data/SRR17122012_1.fastq }; ### [ mates2 ] => { data/SRR17122012_2.fastq }; ### [ output ] => { SRR17122012 }; ### [ tgMap ] => { transcriptome_splici_fl52/transcriptome_splici_fl52_t2g.tsv }; ### [ threads ] => { 28 }; ### [ sciseq3 ] => { }. [2022-11-28 21:13:57.772] [alevinLog] [info] Found all transcripts to gene mappings; [2022-11-28 21:13:57.781] [alevinLog] [info] Processing barcodes files (if Present) . ; processed 10 Million barcodes. [2022-11-28 21:14:01.454] [alevinLog] [info] Done barcode density calculation.; [2022-11-28 21:14:01.454] [alevinLog] [info] # Barcodes Used: 1 / 10285890.; [2022-11-28 21:14:01.455] [alevinLog] [error] Can't find left Boundary.; Please Report this issue on github."". Specifically, please provide at least the following information:. * Which version of",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/813:118,clear,clear,118,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/813,1,['clear'],['clear']
Usability,"**Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**; alevin; **Describe the bug**; I got reasonable cell barcode when I worked with 10X cellranger, I just got very few cell barcode when I use alevin. I don't have problem with 10X V3 data when I use alevin. **To Reproduce**; Steps and data to reproduce the behavior:. Specifically, please provide at least the following information:. * Which version of salmon was used?; * How was salmon installed (compiled, downloaded executable, through bioconda)?; * Which reference (e.g. transcriptome) was used?; * Which read files were used?; * Which which program options were used?. **Expected behavior**; A clear and concise description of what you expected to happen. **Screenshots**; ![image](https://github.com/user-attachments/assets/287e4955-ca55-4767-99a8-299c100b667f). **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX]; - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux the output of `uname -a` and `lsb_release -a`]. **Additional context**; Add any other context about the problem here.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/949:683,clear,clear,683,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/949,1,['clear'],['clear']
Usability,"**Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**; bulk mode. **Describe the bug**; A clear and concise description of what the bug is.; Running salmon quant in 276 samples on HPC, most of them run smoothly while 7 samples end with ""Segmentation fault (core dumped)"". **To Reproduce**; Steps and data to reproduce the behavior:; run salmon quant in 276 samples on HPC, 7 failed with ""Segmentation fault (core dumped)"". But by changing the p from 16 to 64, 2 of them won't be stopped by this error. Specifically, please provide at least the following information:. * Which version of salmon was used? v1.10.2; * How was salmon installed (compiled, downloaded executable, through bioconda)? bioconda ; * Which reference (e.g. transcriptome) was used? GRCh38 transcripts from gencode v44; * Which read files were used? paired-end bulk RNA seq file in fastq.gz format; * Which which program options were used? ; …/miniconda3/envs/salmon1/bin/salmon quant -i …/share/references/gencode/salmon_index --libType A ; -1 $read1 \; -2 $read2 \; -p 16 \; --validateMappings \; --gcBias \; --seqBias \; --recoverOrphans \; --rangeFactorizationBins 4 \; --output $outdir. **Expected behavior**; A clear and concise description of what you expected to happen.; Salmon quant to produce quant.sf file. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem.; ```shell; Version Info Exception: server did not respond before timeout; ### salmon (selective-alignment-based) v1.10.2; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /share/references/gencode/salmon_index }; ### [ libType ] => { A }; ### [ mates1 ] => { RNA_1.fastq.gz }; ### [ mates2 ] => { RNA_2.fastq.gz }; ### [ threads ] => { 16 }; ### [ validateMappings ] => { }; ### [ gcBias ] => { }; ### [ seqBias ] => { }; ### [ recoverOrphans ] => { }; ### [ rangeFactorizationBins ] => { 4 }; ### [ output ] => { salmon.standard/sample }; Logs will be writte",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/971:121,clear,clear,121,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/971,1,['clear'],['clear']
Usability,"**Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**; bulk; **Describe the bug**; A clear and concise description of what the bug is.; Version Info: This is the most recent version of salmon.; [2022-08-22 15:07:03.859] [jLog] [warning] The salmon index is being built witho ut any decoy sequences. It is recommended that decoy sequence (either computed auxiliary decoy sequence or the genome of the organism) be provided during index ing. Further details can be found at https://salmon.readthedocs.io/en/latest/sal mon.html#preparing-transcriptome-indices-mapping-based-mode.; [2022-08-22 15:07:03.860] [jLog] [info] building index; out : transcripts_index; [2022-08-22 15:07:03.860] [puff::index::jointLog] [info] Running fixFasta. [Step 1 of 4] : counting k-mers. [2022-08-22 15:07:03.865] [puff::index::jointLog] [info] Replaced 0 non-ATCG nuc leotides; [2022-08-22 15:07:03.865] [puff::index::jointLog] [info] Clipped poly-A tails fr om 0 transcripts; wrote 0 cleaned references; [2022-08-22 15:07:03.865] [puff::index::jointLog] [info] Filter size not provide d; estimating from number of distinct k-mers; [2022-08-22 15:07:03.866] [puff::index::jointLog] [info] ntHll estimated 47270 d istinct k-mers, setting filter size to 2^20; Threads = 2; Vertex length = 31; Hash functions = 5; Filter size = 1048576; Capacity = 2; Files:; transcripts_index/ref_k31_fixed.fa; --------------------------------------------------------------------------------; Round 0, 0:1048576; Pass Filling Filtering; terminate called without an active exception; Aborted (core dumped). **To Reproduce**; Steps and data to reproduce the behavior:; salmon index -t contigs_for_salmon -i transcripts_index -k 31; my reads are paired end RNA-reads (rRNA REMOVED); My transcriptome is a 90 contigs resulted from reads assembly; Specifically, please provide at least the following information:. * Which version of salmon was used?; * ; * How was salmon installed (compiled, downloaded executable",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/795:116,clear,clear,116,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/795,1,['clear'],['clear']
Usability,"**Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**; salmon (buik mode). **Describe the bug**; A clear and concise description of what the bug is.; I compiled the code (salmon v1.4.0) and produced the executable. Then when I try to ""salmon index -t gentrome.fa.gz -d decoys.txt -p 12 -i salmon_index --gencode"" (transcriptome and genome from your tutorial: https://combine-lab.github.io/alevin-tutorial/2019/selective-alignment/), a segmentation fault occurs. (gdb backtrack is provided below.). **To Reproduce**; Steps and data to reproduce the behavior:. 1. run a docker container using ubuntu:18.04 as image. 2. (packages I installed); apt-get install -y gcc g++ make wget git curl libtbb2-dbg libtbb-dev unzip zlib1g-dev libcurl4-openssl-dev liblzma-dev libbz2-dev libcereal-dev libgff-dev libpkgconfig-perl libjemalloc-dev; /*; gcc (Ubuntu 7.5.0-3ubuntu118.04) 7.5.0; g++ (Ubuntu 7.5.0-3ubuntu118.04) 7.5.0; GNU Make 4.1; */; wget https://github.com/Kitware/CMake/releases/download/v3.13.4/cmake-3.13.4-Linux-x86_64.sh /cmake version 3.13.4/. 3. git clone https://github.com/COMBINE-lab/salmon.git; I'm at the top commit: commit 0813a0a (HEAD -> master, tag: v1.4.0, origin/master, origin/HEAD). 4. In directory salmon/build, I type; > cmake -DFETCH_BOOST=TRUE -DTBB_INSTALL_DIR=/usr/include -DCMAKE_BUILD_TYPE=Release -DCMAKE_INSTALL_PREFIX=../stage ..; > make; > make install. 5. following your tutorial https://combine-lab.github.io/alevin-tutorial/2019/selective-alignment/; > wget ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M23/gencode.vM23.transcripts.fa.gz; > wget ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M23/GRCm38.primary_assembly.genome.fa.gz; > grep ""^>"" <(gunzip -c GRCm38.primary_assembly.genome.fa.gz) | cut -d "" "" -f 1 > decoys.txt; > sed -i.bak -e 's/>//g' decoys.txt; > cat gencode.vM23.transcripts.fa.gz GRCm38.primary_assembly.genome.fa.gz > gentrome.fa.gz; > salmon index -t gentrome.fa.gz -d decoy",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/609:130,clear,clear,130,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/609,1,['clear'],['clear']
Usability,"**Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**; salmon (bulk mode). **Describe the bug**; A clear and concise description of what the bug is.; Segmentation fault error when running salmon quant. **To Reproduce**; Steps and data to reproduce the behavior:; Inconsistent behaviour, sometimes quant.sf files are generated, sometimes not. Specifically, please provide at least the following information:. * Which version of salmon was used? 1.10.2 (also occurred using 1.10.1 and 0.14).; * How was salmon installed (compiled, downloaded executable, through bioconda)? installed through bioconda (defined in conda environment).; * Which reference (e.g. transcriptome) was used? BY4742 transcriptome generated using gffread (command used: ""gffread -g BY4742.fa -o wt-syn-transcriptome.gff -w wt-syn-transcriptome.fa -v -C BY4742.gff"").; * Which read files were used? Paired end fastq files (trimmed by fastp).; * Which which program options were used? ""--validateMappings --threads 1 --libType A --index transcriptome-index --mates1 sample1_R1_001.trimmed.fastq.gz --mates2 sample1_R2_001.trimmed.fastq.gz --output sample1"". **Expected behavior**; A clear and concise description of what you expected to happen.; Salmon quant to generate quant.sf file. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem.; ```; Version Info: ### PLEASE UPGRADE SALMON ###; ### A newer version of salmon with bug fixes is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; Sign up for the salmon mailing list to hear about new versions, features and updates at:; https://oceangenomics.com/subscribe; ###; ### salmon (mapping-based) v0.14.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ validateMappings ] => { }; ### [ threads ] => { 1 }; ### [ libType ] => { A }; ### [",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/881:130,clear,clear,130,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/881,1,['clear'],['clear']
Usability,"**Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**; salmon(bulk mode). **Describe the bug**; A clear and concise description of what the bug is.; While setting -DCMAKE_BUILD_TYPE=Debug, ; ""make"" command failed at ; [ 86%] Building CXX object src/CMakeFiles/salmon.dir/EMUtils.cpp.o; c++: error: -pg and -fomit-frame-pointer are incompatible; src/CMakeFiles/salmon.dir/build.make:62: recipe for target 'src/CMakeFiles/salmon.dir/EMUtils.cpp.o' failed; make[2]: *** [src/CMakeFiles/salmon.dir/EMUtils.cpp.o] Error 1; CMakeFiles/Makefile2:790: recipe for target 'src/CMakeFiles/salmon.dir/all' failed; make[1]: *** [src/CMakeFiles/salmon.dir/all] Error 2; Makefile:162: recipe for target 'all' failed; make: *** [all] Error 2. **To Reproduce**; Steps and data to reproduce the behavior:; 1. run a docker container using ubuntu:18.04 as image. 2. (packages I installed); apt-get install -y gcc g++ make wget git curl libtbb2-dbg libtbb-dev unzip zlib1g-dev libcurl4-openssl-dev liblzma-dev libbz2-dev libcereal-dev libgff-dev libpkgconfig-perl libjemalloc-dev; /*; gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0; g++ (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0; GNU Make 4.1; */; wget https://github.com/Kitware/CMake/releases/download/v3.13.4/cmake-3.13.4-Linux-x86_64.sh /*cmake version 3.13.4*/. 3. git clone https://github.com/COMBINE-lab/salmon.git; I'm at the top commit: commit 0813a0a287c2bd80071511830befe5d786a59ad1 (HEAD -> master, tag: v1.4.0, origin/master, origin/HEAD). 4. In directory salmon/build, I type; cmake -DFETCH_BOOST=TRUE -DTBB_INSTALL_DIR=/usr/include -DCMAKE_BUILD_TYPE=Debug -DCMAKE_INSTALL_PREFIX=../stage .. =============At last, getting these:; -- Configuring done; -- Generating done; -- Build files have been written to: /root/salmon/build. 5. In directory salmon/build, I type; make. ===========Then crashed here; [ 86%] Built target unitTests; Scanning dependencies of target salmon; [ 86%] Building CXX object src/CMakeFiles/salmon.dir/EMUtils.cpp.o",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/608:129,clear,clear,129,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/608,1,['clear'],['clear']
Usability,"**Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**; salmon. **Describe the bug**; A clear and concise description of what the bug is. I had an older version of salmon that works (v0.8.2) that I believe was not compiled with Bioconda. I am now trying to get the latest version through Bioconda and with the same ""salmon quant"" command (See below) that works on the old version, I get a ""segmentation fault 11"" error and it never actually quantifies any reads. Do you know why this would happen?. **To Reproduce**; Steps and data to reproduce the behavior:. Specifically, please provide at least the following information:. * Which version of salmon was used?; 0.11.3; * How was salmon installed (compiled, downloaded executable, through bioconda)?; Bioconda; * Which reference (e.g. transcriptome) was used?; gencode.v27.transcripts.fa; * Which read files were used?; fastq; * Which which program options were used?; -l A, single end . **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. ```; salmon quant -i ~/Reference_indexes/humangencodev27_transcripts_index_20181023 -l A -r ~/Downloads/ENCFF600FYP.fastq.gz -o ./salmon_test/ENCFF600FYP_quant; Version Info: Could not resolve upgrade information in the alotted time.; Check for upgrades manually at https://combine-lab.github.io/salmon; ### salmon (mapping-based) v0.11.3; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { ~/Reference_indexes/humangencodev27_transcripts_index_20181023 }; ### [ libType ] => { A }; ### [ unmatedReads ] => { ~/Downloads/ENCFF600FYP.fastq.gz }; ### [ output ] => { ./salmon_test/ENCFF600FYP_quant }; Logs will be written to ./salmon_test/ENCFF600FYP_quant/logs; [2018-10-23 20:11:13.424] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2018-10-23 20:11:13.425] [jointLog] [info] parsing read library format; [2018-10-23 20:11:13.425] [jointLog] [info] ",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/303:118,clear,clear,118,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/303,1,['clear'],['clear']
Usability,"**Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**; salmon; **Describe the bug**; A clear and concise description of what the bug is.; It appears that when I run the quant command it gets up to the ""loading dense pufferfish index"" but stop after loading positions. So I think that it isn't even getting to the quantification step because it doesn't finish loading the index. **To Reproduce**; Steps and data to reproduce the behavior:. Specifically, please provide at least the following information:. * Which version of salmon was used?; *v.1.5.0; * How was salmon installed (compiled, downloaded executable, through bioconda)?; * through bioconda; * Which reference (e.g. transcriptome) was used?; * ; * Which read files were used?; * Which which program options were used?. **Expected behavior**; A clear and concise description of what you expected to happen.; I would expect it to continue to ""loading reference sequence"" etc., then display done and continue with the quantification; **Screenshots**; ![image](https://user-images.githubusercontent.com/85455566/120937098-82d2fb80-c6d9-11eb-9aea-a2935ccc1e50.png). **Desktop (please complete the following information):**; Ubuntu Linux; - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux the output of `uname -a` and `lsb_release -a`]. **Additional context**; I'm pretty new to linux and salmono it is likely that my problem is due to some simple misunderstanding of how the program works, but any help would be appreciated.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/667:118,clear,clear,118,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/667,3,"['clear', 'simpl']","['clear', 'simple']"
Usability,"**Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**; salmon; **Describe the bug**; A clear and concise description of what the bug is.; The cDNA fasta file contains 176241 ENSTs,but the result file only contains 166667 ENSTs.; **To Reproduce**; Steps and data to reproduce the behavior:; The steps and data are as follows. ; Specifically, please provide at least the following information:. * Which version of salmon was used? v0.9.1; * How was salmon installed (compiled, downloaded executable, through bioconda)?; downloaded executable; * Which reference (e.g. transcriptome) was used? ; Homo_sapiens.GRCh38.cdna.all.fa obtained from Ensembl release 83; * Which read files were used? ; GSE41009; * Which which program options were used? ; Building index: salmon index -t filepath/Homo_sapiens.GRCh38.cdna.all.fa -i V83-homo_index --type quasi -k 31; Quantification: salmon quant -p 50 -i filepath/V83-homo_index -l IU -1 ESC-SRR574820_1.fastq ESC-SRR574821_1.fastq -2 ESC-SRR574820_2.fastq ESC-SRR574821_2.fastq -o ESC-quantification. **Expected behavior**; A clear and concise description of what you expected to happen.; The result file should contain all the ENSTs existed in cDNA fasta file.; **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX]; - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux the output of `uname -a` and `lsb_release -a`]; uname -a; Linux mn1 2.6.32-431.29.2.2.ky3.1.x86_64 #1 SMP Thu Sep 25 10:15:09 CST 2014 x86_64 x86_64 x86_64 GNU/Linux. lsb_release -a; LSB Version:	:base-4.0-amd64:base-4.0-noarch:core-4.0-amd64:core-4.0-noarch:graphics-4.0-amd64:graphics-4.0-noarch:printing-4.0-amd64:printing-4.0-noarch; Distributor ID:	NeoKylin; Description:	NeoKylin release 3.2 (Carambola); Release:	3.2; Codename:	Carambola; **Additional context**; Add any other context about the prob",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/255:118,clear,clear,118,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/255,1,['clear'],['clear']
Usability,"**Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**; salmon; **Describe the bug**; A clear and concise description of what the bug is.; salmon 1.1.0 and 1.0.0 core-dump when attempting to build an index under Ubuntu 18.04 LTS; **To Reproduce**; Steps and data to reproduce the behavior:; ```; root@firefly:/usr/local/src/salmon# salmon-1.1.0_linux_x86_6/bin/salmon index -k 31 -i index -t sample_data/transcripts.fasta; Version Info: This is the most recent version of salmon.; [2020-04-07 21:11:41.237] [jLog] [info] building index; out : index; [2020-04-07 21:11:41.240] [puff::index::jointLog] [info] Running fixFasta. [Step 1 of 4] : counting k-mers; Illegal instruction (core dumped). root@firefly:/usr/local/src/salmon# salmon-0.14.1_linux_x86_64/bin/salmon index -k 31 -i index -t sample_data/transcripts.fasta; Version Info: ### PLEASE UPGRADE SALMON ###; ### A newer version of salmon with bug fixes is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; Sign up for the salmon mailing list to hear about new versions, features and updates at:; https://oceangenomics.com/subscribe; ###; [2020-04-07 21:12:14.575] [jLog] [info] building index; [2020-04-07 21:12:14.580] [jointLog] [info] [Step 1 of 4] : counting k-mers; Elapsed time: 0.00677775s. [2020-04-07 21:12:14.596] [jointLog] [info] Replaced 0 non-ATCG nucleotides; [2020-04-07 21:12:14.596] [jointLog] [info] Clipped poly-A tails from 0 transcripts; [2020-04-07 21:12:14.599] [jointLog] [info] Building rank-select dictionary and saving to disk; [2020-04-07 21:12:14.599] [jointLog] [info] done; Elapsed time: 5.7764e-05s; [2020-04-07 21:12:14.606] [jointLog] [info] Writing sequence data to file . . . ; [2020-04-07 21:12:14.607] [jointLog] [info] done; Elapsed time: 0.000590993s; [2020-04-07 21:12:14.614] [jointLog] [info] Building 32-bit su",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/500:118,clear,clear,118,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/500,1,['clear'],['clear']
Usability,"**Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**; salmon; **Describe the bug**; A clear and concise description of what the bug is.; salmon quant is leading to segmentation fault when `--skipQuant` flag is set. The behavior may be annotation dependent.; **To Reproduce**; Steps and data to reproduce the behavior:. Specifically, please provide at least the following information:. * Which version of salmon was used? :; * v1.9.0; * How was salmon installed (compiled, downloaded executable, through bioconda)? ; * bioconda; * Which reference (e.g. transcriptome) was used?; * human hg38 [gencode v43 comprehensive](https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_43/gencode.v43.primary_assembly.annotation.gtf.gz) produces the error; * human hg38 [gencode v43 basic](https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_43/gencode.v43.basic.annotation.gtf.gz) works fine.; * Which read files were used?; * The issue is reproducible with multiple independent read files. Logs attached are from reads subsampled from [GSM7099349](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSM7099349); * Which which program options were used?; * --skipQuant -l A. **Expected behavior**; A clear and concise description of what you expected to happen.; salmon quant finishes without seg fault with `--skipQuant`; **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem.; Terminal output when `--skipQuant` is on:; ```; Version Info: ### PLEASE UPGRADE SALMON ###; ### A newer version of salmon with important bug fixes and improvements is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; Sign up for the salmon mailing list to hear about new versions, features and updates at:; https://oceangenomics.com/subscribe; ### salmon (selective-alignment-",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/902:118,clear,clear,118,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/902,1,['clear'],['clear']
Usability,"**Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**; salmon; **Describe the bug**; I was trying to do salmon quant on multiple bam files together but got the error.; <img width=""1209"" alt=""image"" src=""https://github.com/COMBINE-lab/salmon/assets/30546732/45cad092-de37-4e00-a873-6ea46254efbd"">. **To Reproduce**; Steps and data to reproduce the behavior:; `salmon quant -t /Reference/GRCm39_Gencode/GRCm39.fa --libType A --ont -a ./bamfiles/*.bam -o ./salmon_bulk`; Specifically, please provide at least the following information:. * Which version of salmon was used?; ; * How was salmon installed (compiled, downloaded executable, through bioconda)?; * Which reference (e.g. transcriptome) was used?; * Which read files were used?; * Which which program options were used?. **Expected behavior**; A clear and concise description of what you expected to happen. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX]; - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux the output of `uname -a` and `lsb_release -a`]. **Additional context**; Add any other context about the problem here.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/920:833,clear,clear,833,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/920,1,['clear'],['clear']
Usability,"**Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**; salmon; **Describe the bug**; is been running like an order of magnitude slower than when I last used it ; **A clear and concise description of what the bug is.**; So I am aligning reads against Arabidopsis Thaliana, using Araport 11 annotation. I usually had 20 M reads aligned within an hour or 2. I am aligning a 46M reads library and it has been running for 20 hours using 4 threads of my humble i5-3210M and is barely on 38.5M, after 20 hours! Index was constructed with default kmer size and no decoys. I have had this problem with other libraries since upgraded from V1.0.0, . **To Reproduce**; I guess just try to align stuff against araport11, this particular problem comes with any fq.gz. It will take hours and hours and hours to align. **Specifically, please provide at least the following information:**. * Which version of salmon was used?; 1.2.1; * How was salmon installed (compiled, downloaded executable, through bioconda)?; downloaded executable; * Which reference (e.g. transcriptome) was used?; Araport 11, from A. thaliana; * Which read files were used?; regular fastq.gz ( SRR7985407); * Which which program options were used?; --validateMappings; -p 4; --seqBias; --gcBias ; --posBias. **Expected behavior**; Much faster alignment, it is Salmon !!; **Screenshots**; this is the run info so far:. Version Info: This is the most recent version of salmon.; ### salmon (mapping-based) v1.2.1; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /home/jaimealaniz/Documents/indexes/salmon/ara11/ }; ### [ libType ] => { A }; ### [ mates1 ] => { SRR7985407_1.fq.gz }; ### [ mates2 ] => { SRR7985407_2.fq.gz }; ### [ validateMappings ] => { }; ### [ threads ] => { 4 }; ### [ seqBias ] => { }; ### [ gcBias ] => { }; ### [ posBias ] => { }; ### [ output ] => { /home/jaimealaniz/Documents/salmon.embryo/SRR7985407/ }; Logs will be written to /home/jaimealaniz/Documents/salmon",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/527:197,clear,clear,197,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/527,1,['clear'],['clear']
Usability,"**Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**; yes; **Describe the bug**; A clear and concise description of what the bug is.; I was going though the tutorial https://combine-lab.github.io/alevin-tutorial/2020/alevin-velocity/; using Alevin and scVelo. The filtering with ; scv.pp.filter_genes(adata, min_shared_counts = 30). gives the error bellow. Any advice?; **Error**; R[write to console]: Error in (function (object, connection, ascii = FALSE, xdr = TRUE, version = NULL, : ; unimplemented type 'char' in 'eval'. R[write to console]: In addition: ; R[write to console]: Warning message:. R[write to console]: call dbDisconnect() when finished working with a connection . ---------------------------------------------------------------------------; RRuntimeError Traceback (most recent call last); /primary/projects/mnp/tools/anaconda3/envs/alevin_env/lib/python3.7/copy.py in deepcopy(x, memo, _nil); 168 if reductor:; --> 169 rv = reductor(4); 170 else:. /primary/projects/mnp/tools/anaconda3/envs/alevin_env/lib/python3.7/site-packages/rpy2/rinterface_lib/sexp.py in __getstate__(self); 123 self.__sexp__._cdata,; --> 124 globalenv.__sexp__._cdata); 125 ). /primary/projects/mnp/tools/anaconda3/envs/alevin_env/lib/python3.7/site-packages/rpy2/rinterface_lib/_rinterface_capi.py in serialize(cdata, cdata_env); 412 if error_occured[0]:; --> 413 raise embedded.RRuntimeError(_geterrmessage()); 414 return res. RRuntimeError: Error in (function (object, connection, ascii = FALSE, xdr = TRUE, version = NULL, : ; unimplemented type 'char' in 'eval'. The above exception was the direct cause of the following exception:. SystemError Traceback (most recent call last); /primary/projects/mnp/tools/anaconda3/envs/alevin_env/lib/python3.7/copy.py in deepcopy(x, memo, _nil); 140 ; --> 141 d = id(x); 142 y = memo.get(d, _nil). SystemError: <built-in function id> returned a result with an error set. The above exception was the direct cause of the following ex",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/526:115,clear,clear,115,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/526,1,['clear'],['clear']
Usability,"**salmon (bulk mode)**. **Describe the bug**; During salmon quant call, there is a segmentation fault . **To Reproduce**; Steps and data to reproduce the behavior:; * I am hardly able to recreate it myself, I ran 230 samples and 3 seg faulted. Specifically, please provide at least the following information:; * Which version of salmon was used?: 1.9.0; * How was salmon installed (compiled, downloaded executable, through bioconda)?: quay.io docker container; * Which reference (e.g. transcriptome) was used?: A combination of the GRCh38.p13 transcripts and the repeatmasker annotation from UCSC, with the GRCh38.p13 primary assembly as decoys.; * Which read files were used?: Paired forward and reverse reads (trimmed by Trimmomatic); * Which which program options were used?:; - [--libType A, --validateMappings, --seqBias, --gcBias, --recoverOrphans, --writeUnmappedNames, -p 8, --rangeFactorizationBins 4]. **Expected behavior**; A clear and concise description of what you expected to happen. Salmon quant to produce quant.sf file. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. ```; Version Info: ### PLEASE UPGRADE SALMON ###; ### A newer version of salmon with important bug fixes and improvements is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; Sign up for the salmon mailing list to hear about new versions, features and updates at:; https://oceangenomics.com/subscribe; ### salmon (selective-alignment-based) v1.9.0; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { references/salmon/sel.align.gencode.v39.ucsc.rmsk.salmon.v1.9.0.sidx/ }; ### [ libType ] => { A }; ### [ mates1 ] => { SRR14506785_output_forward_paired.fq.gz }; ### [ mates2 ] => { SRR14506785_output_reverse_paired.fq.gz }; ### [ threads ] => { 8 }; ### [ validateMappings ] => { }; ##",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/876:937,clear,clear,937,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/876,1,['clear'],['clear']
Usability,"**tl;dr**: 3-tag sequencing methods for bulk RNA samples contain known sample indices and UMIs and thus resembles sc-RNA-seq read formats. Do you have a recommendation on how to use Salmon and / or Alevin to quantify gene expression for this data type?. Congratulations on the recent [alevin preprint](https://www.biorxiv.org/content/early/2018/10/24/335000)! The new algorithm to deduplicate UMIs looks awesome. I am wondering if you had a recommendation on how to leverage it for 3' tag sequencing of bulk samples. There are a number of protocols that focus on the 3' ends of transcripts to allow for cheap quantification of gene expression, e.g. - [BRB-seq](https://www.biorxiv.org/content/early/2018/01/30/256594); - [Drug-seq](https://www.nature.com/articles/s41467-018-06500-x); - [Quant-seq](https://www.lexogen.com/quantseq-3mrna-sequencing/). These methods combine conventional (known) sample-indices to label samples (or wells) with unique molecular identifiers (UMIs). (I found [one question on this topic](https://github.com/COMBINE-lab/salmon/issues/108) in the salmon issue tracker from back in 2016). Here is the Drug-seq approach, for example:. ![Drug-seq](https://media.springernature.com/lw900/springer-static/image/art%3A10.1038%2Fs41467-018-06500-x/MediaObjects/41467_2018_6500_Fig1_HTML.png). The resulting read data resembles that of single-cell approaches and requires deduplication of UMIs and quantification based on reads with a strong 3' bias. It seems analysis of this data could benefit a lot from the algorithms implemented in Alevin. Can this data be analyzed with Salmon and / or Alevin? Are there any pitfalls that I should be aware off?. Many thanks for any feedback - and thanks again for making these great tools available to the community.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/306:1692,feedback,feedback,1692,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/306,1,['feedback'],['feedback']
Usability,"--unmatedReads ] arg List of files containing unmated reads ; of (e.g. single-end reads); -1 [ --mates1 ] arg File containing the #1 mates; -2 [ --mates2 ] arg File containing the #2 mates. alevin-specific Options:; --noDedup Stops the pipeline after CB sequence ; correction and quasi-mapping reads.; --dropseq Use DropSeq Single Cell protocol for ; the library; --chromium Use 10x chromium v2 Single Cell ; protocol for the library.; --gemcode Use 10x gemcode v1 Single Cell protocol; for the library.; --whitelist arg File containing white-list barcodes; --noQuant Don't run downstream barcode-salmon ; model.; --naive Run Gene level naive deduplication; --noSoftMap Don't use soft-assignment for quant ; instead do hard-assignment.; --mrna arg path to a file containing mito-RNA ; gene, one per line; --rrna arg path to a file containing ribosomal ; RNA, one per line; --useCorrelation Use pair-wise pearson correlation with ; True barcodes as a feature for ; white-list creation.; --dumpfq Dump barcode modified fastq file for ; downstream analysis by using coin toss ; for multi-mapping.; --debug Enabling this mode mode will try to ; ignore segfaults based on no whitelist ; mapping or no whitelist deduplicated ; count; --dumpBfh dump the big hash with all the barcodes; and the UMI sequence.; --dumpFeatures Dump features for whitelist and ; downstream analysis.; --dumpCsvCounts Dump cell v transcripts count matrix in; csv format.; --lowRegionMinNumBarcodes arg (=200) Minimum Number of CB to use for ; learning Low confidence region ; (Default: 200).; --maxNumBarcodes arg (=100000) Maximum allowable limit to process the ; cell barcodes. (Default: 100000); --tgMap arg transcript to gene map tsv file; ```; 2) `salmon alevin -lISR -1 cells_CTTGTA_L001_R1_001.fastq.gz -2 cells_CTTGTA_L001_R2_001.fastq.gz --celseq2 -i AlevinIndex_develop/ -p 8 -o alevin_output --tgMap gencode.primary_assembly.tsv`. **The tsv I created myself (with tximport), but I don't think that is the issue here...",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/325#issuecomment-443517536:1865,learn,learning,1865,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/325#issuecomment-443517536,2,['learn'],['learning']
Usability,"-0.7.12.3/bwamem.c; bwa-0.7.12.3/bwamem.h; bwa-0.7.12.3/bwamem_extra.c; bwa-0.7.12.3/bwamem_pair.c; bwa-0.7.12.3/bwape.c; bwa-0.7.12.3/bwase.c; bwa-0.7.12.3/bwase.h; bwa-0.7.12.3/bwaseqio.c; bwa-0.7.12.3/bwashm.c; bwa-0.7.12.3/bwt.c; bwa-0.7.12.3/bwt.h; bwa-0.7.12.3/bwt_gen.c; bwa-0.7.12.3/bwt_lite.c; bwa-0.7.12.3/bwt_lite.h; bwa-0.7.12.3/bwtaln.c; bwa-0.7.12.3/bwtaln.h; bwa-0.7.12.3/bwtgap.c; bwa-0.7.12.3/bwtgap.h; bwa-0.7.12.3/bwtindex.c; bwa-0.7.12.3/bwtsw2.h; bwa-0.7.12.3/bwtsw2_aux.c; bwa-0.7.12.3/bwtsw2_chain.c; bwa-0.7.12.3/bwtsw2_core.c; bwa-0.7.12.3/bwtsw2_main.c; bwa-0.7.12.3/bwtsw2_pair.c; bwa-0.7.12.3/example.c; bwa-0.7.12.3/fastmap.c; bwa-0.7.12.3/is.c; bwa-0.7.12.3/kbtree.h; bwa-0.7.12.3/khash.h; bwa-0.7.12.3/kopen.c; bwa-0.7.12.3/kseq.h; bwa-0.7.12.3/ksort.h; bwa-0.7.12.3/kstring.c; bwa-0.7.12.3/kstring.h; bwa-0.7.12.3/ksw.c; bwa-0.7.12.3/ksw.h; bwa-0.7.12.3/kthread.c; bwa-0.7.12.3/kvec.h; bwa-0.7.12.3/main.c; bwa-0.7.12.3/malloc_wrap.c; bwa-0.7.12.3/malloc_wrap.h; bwa-0.7.12.3/maxk.c; bwa-0.7.12.3/pemerge.c; bwa-0.7.12.3/qualfa2fq.pl; bwa-0.7.12.3/utils.c; bwa-0.7.12.3/utils.h; bwa-0.7.12.3/xa2multi.pl; [ 50%] No patch step for 'libbwa'; [ 50%] No update step for 'libbwa'; [ 51%] No configure step for 'libbwa'; [ 51%] Performing build step for 'libbwa'; /bin/ld: cannot find -lz; collect2: error: ld returned 1 exit status; make[3]: *** [bwa] Error 1; make[2]: *** [libbwa-prefix/src/libbwa-stamp/libbwa-build] Error 2; make[1]: *** [CMakeFiles/libbwa.dir/all] Error 2; make: *** [all] Error 2. So as you said I'd say its having issued finding the zlibs library. Similar to how I used 'DZLIB_LIBRARY=/users/work/jake/bin/zlib-1.2.11/zlib.h' to specify the zlib library for 'cmake', is there a way to do it for the 'make' command? I've tried using the following but haven't had success:; make -I /users/work/jake/bin/zlib-1.2.11/zlib.h; make --include-dir=/users/work/jake/bin/zlib-1.2.11/zlib.h. Sorry for the very basic questions.... I'm kind of learning as I go.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/141#issuecomment-314451873:4138,learn,learning,4138,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/141#issuecomment-314451873,2,['learn'],['learning']
Usability,"-colsep ',' \; 'salmon quant -I /path/to/index/folder/ \; -l A\; -1 /path/to/""{fastq_1}"" \; -2 /path/to/""{fastq_2}""\; --writeUnmappedNames \; --validateMappings \; --recoverOrphans\; --gcBias \; --seqBias \; --recoverOrphans\; -o /path/to/output/{Samples} \; --threads 2' :::: /path/to/sheet_with_sample_and_fastq_names.csv; ```; Specifically, please provide at least the following information:. * Which version of salmon was used?; Both 1.10.2 and 1.10.3 were tested. ; * How was salmon installed (compiled, downloaded executable, through bioconda)?; Used bioconda; * Which reference (e.g. transcriptome) was used?; GRCh38 ; * Which read files were used?; Illumina NovaSeq. Merged fastq based on direction (fastq split across lanes and had to add top off data) with zcat, used cutadapt for adapter trimming. . * Which which program options were used?; Ribodetector was used to get rid of rRNA contamination. Used output of non rRNA files with Salmon quant. **Expected behavior**; A clear and concise description of what you expected to happen.; Salmon Quant outputting of .sf files. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem.; From SLURM generated error file. **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX]; - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux the output of `uname -a` and `lsb_release -a`]; HPCS: Red Hat Server 7.9. **Additional context**; Add any other context about the problem here.; Removal of --recoverOrphans leads to jobs finishing to completion. . Oddly enough, with --recoverOrphans dropped, I start seeing output into .err files I set in SLURM rather than in the .log file with each folder. .err files typically terminate after reporting hits for frags are finished unlike with salmon_output.log files without --recoverOrphans. As an aside, when googling ""recover orphans salmon crash"" this was the top result: https://ksltv.com/635908/tens-of-thousand",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/961:2024,clear,clear,2024,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/961,1,['clear'],['clear']
Usability,". For this to work I need to break out the big guns and use --forceCells, yes? What I would really like is to try --expectCells first to allow Alevin to be a little bit intelligent, and if that fails to use --forceCells. Is that a sensible approach?. If so, could we a) have an informative error code on the boundary error above such that I can easily detect that error and re-submit with --forceCells, or b) if this is generically useful have a flag in Alevin to do it directly?. **To Reproduce**; Steps and data to reproduce the behavior:. - cDNA reads in ftp://ftp.ebi.ac.uk/pub/databases/microarray/data/experiment/MTAB/E-MTAB-7142/Control_6_R2.fastq.gz; - barcode reads in ftp://ftp.ebi.ac.uk/pub/databases/microarray/data/experiment/MTAB/E-MTAB-7142/Control_6_R1.fastq.gz; - transcript/ gene mapping as: [transcript_to_gene.txt](https://github.com/COMBINE-lab/salmon/files/3153221/transcript_to_gene.txt); - Run Alevin in drop-seq mode, salmon 0.13.1. **Expected behavior**; A clear and concise description of what you expected to happen. **Screenshots**. ```; ### alevin (dscRNA-seq quantification) v0.13.1; ### [ program ] => salmon ; ### [ command ] => alevin ; ### [ libType ] => { ISR }; ### [ mates1 ] => { barcodes.fastq.gz }; ### [ mates2 ] => { cdna.fastq.gz }; ### [ dropseq ] => { }; ### [ index ] => { salmon_index }; ### [ threads ] => { 12 }; ### [ output ] => { ERR2744256_tmp }; ### [ tgMap ] => { transcript_to_gene.txt }; ### [ dumpFeatures ] => { }; ### [ expectCells ] => { 278 }. [2019-05-07 14:40:36.500] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2019-05-07 14:40:36.500] [jointLog] [info] Usage of --validateMappings, without --hardFilter implies use of range factorization. rangeFactorizationBins is being set to 4; [2019-05-07 14:40:36.500] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.2.; [2019-05-07 14",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/362:1682,clear,clear,1682,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/362,1,['clear'],['clear']
Usability,".1 1 length=36; CTGATCCTCGAGAGCACTCACAGAGTTTTTTGTTTT; +SRR6327122.1 1 length=36; AAFFFJJJJJJJJJJJJJJJJJJJJJ7-----A<-<; And; `$ zcat SRR6327122_2.fastq.gz |head -n 4`; @SRR6327122.1 1 length=88; CGGCCACAAGATCGCCTTTTTATCCCTCGCCCAGAGCACCCCCCGACCCCACATCCCCTGCTTCACGGCCCCCCTCGCGGCCTACCCG; +SRR6327122.1 1 length=88; --7-<7----7---77----77A-7--7-A7-7---7-A-A7<F-777-77-A---A<A----77--77------------7------. * Which which program options were used?; One can download the data and results tarball; [bcNotFound-2018-07-19.tar.gz](https://github.com/COMBINE-lab/salmon/files/2211985/bcNotFound-2018-07-19.tar.gz).; First, I indexed the reference using:; `salmon index -k 31 -t transposon_sequence_set.fa -i index`; Then, I ran Alevin using the following command:; `salmon alevin -l ISR -1 SRR6327122_1.fastq.gz -2 SRR6327122_2.fastq.gz --chromium -i index -p 2 -o alevin_output --tgMap transposon_sequence_set.fa.tsv --whitelist cell_barcode_seq.txt --dumpCsvCounts`. **Expected behavior**; A clear and concise description of what you expected to happen.; The count matrix be saved when Alevin is done. **Screenshots**; The full output messages are:; Version Info: ### A newer version of Salmon is available. ####; ###; The newest version, available at https://github.com/COMBINE-lab/salmon/releases; contains new features, improvements, and bug fixes; please upgrade at your; earliest convenience.; ###; Logs will be written to alevin_output/logs; ### salmon (single-cell-based) v0.10.2; ### [ program ] => salmon ; ### [ command ] => alevin ; ### [ libType ] => { ISR }; ### [ mates1 ] => { SRR6327122_1.fastq.gz }; ### [ mates2 ] => { SRR6327122_2.fastq.gz }; ### [ chromium ] => { }; ### [ index ] => { index }; ### [ threads ] => { 2 }; ### [ output ] => { alevin_output }; ### [ tgMap ] => { transposon_sequence_set.fa.tsv }; ### [ whitelist ] => { cell_barcode_seq.txt }; ### [ dumpCsvCounts ] => { }. [2018-07-19 18:24:03.053] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatib",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/253:3067,clear,clear,3067,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/253,1,['clear'],['clear']
Usability,".1',; 'ENST00000493496.5',; 'ENST00000460361.1',; 'ENST00000441953.6',; 'ENST00000431735.6',; 'ENST00000462670.1',; 'ENST00000491795.5',; 'ENST00000468378.1',; 'ENST00000383214.8',; 'ENST00000383213.8',; 'ENST00000486373.5',; 'ENST00000491702.1',; 'ENST00000478834.1',; 'ENST00000444757.5',; 'ENST00000429042.5',; 'ENST00000454420.5',; 'ENST00000425069.5',; 'ENST00000414757.5',; 'ENST00000414916.5']; ```; and, the other transcript is connected to ; ```; ['ENST00000376621.7',; 'ENST00000487166.1',; 'ENST00000383450.3',; 'ENST00000497332.1',; 'ENST00000441604.5',; 'ENST00000481420.1',; 'ENST00000487687.1',; 'ENST00000454829.5',; 'ENST00000490227.1',; 'ENST00000437917.5',; 'ENST00000481380.1',; 'ENST00000383596.6',; 'ENST00000488456.1',; 'ENST00000417834.5',; 'ENST00000486264.1',; 'ENST00000462708.1',; 'ENST00000478748.1',; 'ENST00000465483.1',; 'ENST00000478986.1',; 'ENST00000480572.1',; 'ENST00000497917.1',; 'ENST00000469494.1',; 'ENST00000489631.1',; 'ENST00000433809.1',; 'ENST00000456550.1',; 'ENST00000450423.1',; 'ENST00000435788.1',; 'ENST00000416639.1',; 'ENST00000443235.1',; 'ENST00000458592.1',; 'ENST00000430236.1',; 'ENST00000464231.1',; 'ENST00000496960.1',; 'ENST00000492408.1',; 'ENST00000479883.1',; 'ENST00000467241.1',; 'ENST00000483987.1',; 'ENST00000495838.1',; 'ENST00000467550.1']; ```; Clearly, in the alignment-based is connected to a lot of other transcripts connected, so their different behaviors is expected. ; I think this makes the solution so unstable that EM assigns all the reads to one rather than distributing them to other members. We need to look at the actual bootstrap/gibbs to have more insight. . I would also like to add, as @rob-p suggested previously, this is a classic example where EM algorithm is not that reliable, b/c of uncertainty and `terminus` might be the best answer. . Here is the [script](https://gist.github.com/hiraksarkar/30d8ce2d52035181e00be1479be50a57) for constructing the graph from the equivalence class file. . Best; Hirak",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/600#issuecomment-757504634:2329,Clear,Clearly,2329,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/600#issuecomment-757504634,1,['Clear'],['Clearly']
Usability,"/bin/salmon/0.11.3/x86_64/lib/libm.so.6: symbol __get_cpu_features, version GLIBC_PRIVATE not defined in file libc.so.6 with link time reference; Error, cmd: java -Xmx64m -XX:ParallelGCThreads=2 -jar /path/to/trinity/2.6.6/x86_64/util/support_scripts/ExitTester.jar 0 died with ret 1536 at /path/to/bin/core/../..//trinity/2.6.6/x86_64/bin/Trinity line 2581.; 	main::process_cmd('java -Xmx64m -XX:ParallelGCThreads=2 -jar /path/to...') called at /path/to/bin/core/../..//trinity/2.6.6/x86_64/bin/Trinity line 2666; 	eval {...} called at /path/to/bin/core/../..//trinity/2.6.6/x86_64/bin/Trinity line 2665; 	main::test_java_failure_capture() called at /path/to/bin/core/../..//trinity/2.6.6/x86_64/bin/Trinity line 1159. I get similar error while just checking for java version; $ java -version. Error: dl failure on line 893; Error: failed /tsl/software/testing/java/8u131/x86_64/jre/lib/amd64/server/libjvm.so, because /tsl/software/testing/bin/core/../..//salmon/0.11.3/x86_64/lib/libm.so.6: symbol __get_cpu_features, version GLIBC_PRIVATE not defined in file libc.so.6 with link time reference. **To Reproduce**; Steps and data to reproduce the behavior:. Specifically, please provide at least the following information:. * Which version of salmon was used? 0.11.3; * How was salmon installed (compiled, downloaded executable, through bioconda)? downloaded executables; * Which reference (e.g. transcriptome) was used? no reference; * Which read files were used? fastq; * Which program options were used? Trinity options. **Expected behavior**; A clear and concise description of what you expected to happen. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX] CentOS; - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux the output of `uname -a` and `lsb_release -a`]. **Additional context**; Add any other context about the problem here.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/290:2359,clear,clear,2359,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/290,1,['clear'],['clear']
Usability,/read-I1_si-TTCGTGAA_lane-002-chunk-000.fastq.gz ./fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-003-chunk-003.fastq.gz ./fastqs/flowcell1/read-I1_si-TTCGTGAA_lane-004-chunk-002.fastq.gz }. [2018-12-05 15:10:07.288] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2018-12-05 15:10:07.288] [jointLog] [warning] You seem to have passed in both un-paired reads and paired-end reads. It is not currently possible to quantify hybrid library types in salmon.; [2018-12-05 15:10:07.298] [alevinLog] [info] Processing barcodes files (if Present) . ; processed 267 Million barcodes. [2018-12-05 15:12:18.914] [alevinLog] [info] Done barcode density calculation.; [2018-12-05 15:12:18.914] [alevinLog] [info] # Barcodes Used: 267451749 / 267548197.; [2018-12-05 15:12:25.126] [alevinLog] [info] Knee found left boundary at 11954 ; [2018-12-05 15:12:27.371] [alevinLog] [info] Gauss Corrected Boundary at 4345 ; [2018-12-05 15:12:27.371] [alevinLog] [info] Learned InvCov: 713.683 normfactor: 1183.93; [2018-12-05 15:12:27.371] [alevinLog] [info] Total 5344(has 999 low confidence) barcodes; [2018-12-05 15:12:27.494] [alevinLog] [info] Done True Barcode Sampling; [2018-12-05 15:12:27.880] [alevinLog] [info] Done populating Z matrix; [2018-12-05 15:12:27.952] [alevinLog] [info] Done indexing Barcodes; [2018-12-05 15:12:27.952] [alevinLog] [info] Total Unique barcodes found: 4180559; [2018-12-05 15:12:27.952] [alevinLog] [info] Used Barcodes except Whitelist: 134856; [2018-12-05 15:12:29.321] [stderrLog] [info] Loading Suffix Array ; [2018-12-05 15:12:29.216] [jointLog] [info] There are 2 libraries.; [2018-12-05 15:12:29.318] [jointLog] [info] Loading Quasi index; [2018-12-05 15:12:29.319] [jointLog] [info] Loading 32-bit quasi index; [2018-12-05 15:12:29.216] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2018-12-05 15:12:29.216] [alevinLog] [info] parsing read library format; [2018-12-05 15:12:29.949] [stderrLog] [i,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/328:6245,Learn,Learned,6245,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/328,1,['Learn'],['Learned']
Usability,"021-04-09 12:16:42.801] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 26; [2021-04-09 12:16:42.803] [jointLog] [info] Mapping rate = 3.375%. Analyzed 184 cells (95% of all).Log] [info] finished quantifyLibrary(); [2021-04-09 12:16:43.532] [alevinLog] [warning] 37 mitorna gene(s) does not have transcript in the reference; [2021-04-09 12:16:43.532] [alevinLog] [info] Total 0 usable mRna genes; [2021-04-09 12:16:43.533] [alevinLog] [warning] 529 ribosomal rna gene(s) does not have transcript in the reference; [2021-04-09 12:16:43.533] [alevinLog] [info] Total 22 usable rRna genes; [2021-04-09 12:16:43.582] [alevinLog] [info] Total 135.00 UMI after deduplicating.; [2021-04-09 12:16:43.582] [alevinLog] [info] Total 0 BiDirected Edges.; [2021-04-09 12:16:43.582] [alevinLog] [info] Total 0 UniDirected Edges.; [2021-04-09 12:16:43.582] [alevinLog] [warning] Skipped 113 barcodes due to No mapped read; [2021-04-09 12:16:43.584] [alevinLog] [info] Clearing EqMap; Might take some time.; [2021-04-09 12:16:43.589] [alevinLog] [info] Starting white listing of 81 cells; [2021-04-09 12:16:43.589] [alevinLog] [info] Starting to make feature Matrix; [2021-04-09 12:16:43.589] [alevinLog] [info] Done making feature Matrix; Exception : [vector]; alevin was invoked improperly.; For usage information, try alevin --help; Exiting.; ```. **To Reproduce**. I have uploaded the files used and a script to run a reproducible example:. https://www.dropbox.com/sh/ksn45n73bazp0rc/AABlsbkG-SLyKJN4DBO7zQ-va?dl=0. * Which version of salmon was used? 1.4.0; * How was salmon installed? bioconda. **Expected behavior**. Alevin should run to completion, with no errors. **Desktop :**; - OS: OSX; - Version: ProductName=Mac OS X, ProductVersion=10.15.7, BuildVersion=19H524. **Additional context**. The files are from a small test dataset - the reads have been subsampled and the genome reference sequence and annotation was filtered for the X chromosome. The index file was",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/647:7096,Clear,Clearing,7096,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/647,1,['Clear'],['Clearing']
Usability,"09-20 22:30:12.334] [alevinLog] [info] Total Unique barcodes found: 675135; [2021-09-20 22:30:12.334] [alevinLog] [info] Used Barcodes except Whitelist: 7515; [2021-09-20 22:30:13.043] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2021-09-20 22:30:13.044] [alevinLog] [info] parsing read library format; [2021-09-20 22:33:09.346] [alevinLog] [info] Starting optimizer. [2021-09-20 22:33:09.516] [alevinLog] [warning] mrna file not provided; using is 1 less feature for whitelisting; [2021-09-20 22:33:09.516] [alevinLog] [warning] rrna file not provided; using is 1 less feature for whitelisting; [2021-09-20 22:33:09.576] [alevinLog] [info] Total 46357.00 UMI after deduplicating.; [2021-09-20 22:33:09.576] [alevinLog] [info] Total 2930 BiDirected Edges.; [2021-09-20 22:33:09.576] [alevinLog] [info] Total 3804 UniDirected Edges.; [2021-09-20 22:33:09.576] [alevinLog] [warning] Skipped 21 barcodes due to No mapped read; [2021-09-20 22:33:09.579] [alevinLog] [info] Clearing EqMap; Might take some time.; [2021-09-20 22:33:09.590] [alevinLog] [warning] Num Low confidence barcodes too less 186 < 200.Can't performing whitelisting; Skipping; [2021-09-20 22:33:09.591] [alevinLog] [info] Finished optimizer. ```; Then I tried setting `--keepCBFraction 1`. This does decrease the total number of reads being thrown away. However, mapping percentage is still low as compared to what I was getting from CellRanger (27%). I thought that since Alevin takes into consideration the multi mapping reads, the mapping percentage will likely increase because when we ran STAR on this data we found a lot of multi mapping reads. ```bash; nohup ./salmon alevin -l ISR -1 S1_L003_R1_001.fastq.gz -2 S1_L003_R2_001.fastq.gz --chromiumV3 -i ~/salmon_selective/salmon_index/ -p 20 -o ~/salmon_selective/9NT_keepCBfraction --keepCBFraction 1 --tgMap ~/salmon_selective/txgene_p3d7.txt &. [2021-09-21 00:11:13.532] [alevinLog] [info] Total 1.97665% reads will be thrown away because of noisy Ce",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/706:4568,Clear,Clearing,4568,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/706,1,['Clear'],['Clearing']
Usability,"1/3 loss in performance seems significant, given that presumably the code does something else than just parsing UMIs. I am looking at Boost own comparison and benchmarks, and on long inputs (20MB) it is competitive with PCRE2. But with short inputs (20-30 characters) PCRE2 is consistently faster (by about 30% :thinking: ). And if PCRE2 is feature full, not sure it is the fastest either, especially for simple regexp.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1023320721:405,simpl,simple,405,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1023320721,2,['simpl'],['simple']
Usability,"10x Genomics Chromium genomic DNA sequencing selects roughly one million barcodes at random with replacement from a possible pool of four million barcodes. Most errors likely result from DNA oligo synthesis rather than sequencing errors (intuition but unconfirmed). There's on other open source tool that does this task `ema preproc`: https://github.com/arshajii/ema#usage. The authors of `ema` have reported that correcting off-by-one errors is sufficient. Their tool corrects off-by-one errors by default, and can optionally correct off-by-two errors. Long Ranger Basic corrects off-by-two errors. The uncorrected barcode may be stored in the `RX:Z` tag. The corrected barcode is stored in the `BX:Z` tag. Thanks for considering this feature request!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/233#issuecomment-395182521:238,intuit,intuition,238,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/233#issuecomment-395182521,2,['intuit'],['intuition']
Usability,200250[0m / [31m52200250[0m.; > [2020-06-04 12:42:01.300] [alevinLog] [info] Forcing to use 200000 cells; > [2020-06-04 12:42:02.037] [alevinLog] [info] Throwing 0 barcodes with < 1 reads; > [2020-06-04 12:42:02.738] [alevinLog] [info] Total [32m197328[0m(has [32m101[0m low confidence) barcodes; > [2020-06-04 12:42:03.656] [alevinLog] [info] Done True Barcode Sampling; > [2020-06-04 12:42:03.830] [alevinLog] [info] Total 0.780192% reads will be thrown away because of noisy Cellular barcodes.; > [2020-06-04 12:42:13.353] [alevinLog] [info] Done populating Z matrix; > [2020-06-04 12:42:13.353] [alevinLog] [info] Total 0 CB got sequence corrected; > [2020-06-04 12:42:13.353] [alevinLog] [info] Done indexing Barcodes; > [2020-06-04 12:42:13.353] [alevinLog] [info] Total Unique barcodes found: 604589; > [2020-06-04 12:42:13.353] [alevinLog] [info] Used Barcodes except Whitelist: 0; > [2020-06-04 12:42:13.555] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify; > ; > [2020-06-04 12:42:13.556] [alevinLog] [info] parsing read library format; > [2020-06-04 12:43:22.789] [alevinLog] [info] Starting optimizer; > ; > [2020-06-04 12:43:23.499] [alevinLog] [warning] mrna file not provided; using is 1 less feature for whitelisting; > [2020-06-04 12:43:23.499] [alevinLog] [warning] rrna file not provided; using is 1 less feature for whitelisting; > [2020-06-04 12:43:23.835] [alevinLog] [info] Total 24009.00 UMI after deduplicating.; > [2020-06-04 12:43:23.835] [alevinLog] [info] Total 89 BiDirected Edges.; > [2020-06-04 12:43:23.835] [alevinLog] [info] Total 82 UniDirected Edges.; > [2020-06-04 12:43:23.835] [alevinLog] [warning] Skipped 184123 barcodes due to No mapped read; > [2020-06-04 12:43:23.840] [alevinLog] [info] Clearing EqMap; Might take some time.; > [2020-06-04 12:43:23.846] [alevinLog] [warning] Num Low confidence barcodes too less 1 < 100.Can't performing whitelisting; Skipping; > [2020-06-04 12:43:23.846] [alevinLog] [info] Finished optimizer,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638991199:6642,Clear,Clearing,6642,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638991199,1,['Clear'],['Clearing']
Usability,31m52200250[0m.; > [2020-06-05 13:09:43.576] [alevinLog] [info] Forcing to use 100000 cells; > [2020-06-05 13:09:43.653] [alevinLog] [info] Throwing 0 barcodes with < 1 reads; > [2020-06-05 13:09:43.673] [alevinLog] [info] Total [32m95377[0m(has [32m11[0m low confidence) barcodes; > [2020-06-05 13:09:43.875] [alevinLog] [info] Done True Barcode Sampling; > [2020-06-05 13:09:44.027] [alevinLog] [info] Total 1.2299% reads will be thrown away because of noisy Cellular barcodes.; > [2020-06-05 13:09:48.338] [alevinLog] [info] Done populating Z matrix; > [2020-06-05 13:09:48.376] [alevinLog] [info] Total 118774 CB got sequence corrected; > [2020-06-05 13:09:48.389] [alevinLog] [info] Done indexing Barcodes; > [2020-06-05 13:09:48.389] [alevinLog] [info] Total Unique barcodes found: 604589; > [2020-06-05 13:09:48.389] [alevinLog] [info] Used Barcodes except Whitelist: 88156; > [2020-06-05 13:09:49.130] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify; > ; > [2020-06-05 13:09:49.132] [alevinLog] [info] parsing read library format; > [2020-06-05 13:11:01.670] [alevinLog] [info] Starting optimizer; > ; > ; > [2020-06-05 13:11:02.377] [alevinLog] [warning] mrna file not provided; using is 1 less feature for whitelisting; > [2020-06-05 13:11:02.377] [alevinLog] [warning] rrna file not provided; using is 1 less feature for whitelisting; > [2020-06-05 13:11:04.408] [alevinLog] [info] Total 322945.00 UMI after deduplicating.; > [2020-06-05 13:11:04.408] [alevinLog] [info] Total 15972 BiDirected Edges.; > [2020-06-05 13:11:04.408] [alevinLog] [info] Total 176951 UniDirected Edges.; > [2020-06-05 13:11:04.408] [alevinLog] [warning] Skipped 12046 barcodes due to No mapped read; > [2020-06-05 13:11:04.415] [alevinLog] [info] Clearing EqMap; Might take some time.; > [2020-06-05 13:11:04.455] [alevinLog] [warning] Num Low confidence barcodes too less 8 < 10.Can't performing whitelisting; Skipping; > [2020-06-05 13:11:04.455] [alevinLog] [info] Finished optimizer,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639642373:2461,Clear,Clearing,2461,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639642373,1,['Clear'],['Clearing']
Usability,31m52200250[0m.; > [2020-06-05 13:39:18.623] [alevinLog] [info] Forcing to use 100000 cells; > [2020-06-05 13:39:19.364] [alevinLog] [info] Throwing 49909 barcodes with < 10 reads; > [2020-06-05 13:39:20.065] [alevinLog] [info] Total [32m50092[0m(has [32m201[0m low confidence) barcodes; > [2020-06-05 13:39:20.928] [alevinLog] [info] Done True Barcode Sampling; > [2020-06-05 13:39:21.057] [alevinLog] [info] Total 1.70493% reads will be thrown away because of noisy Cellular barcodes.; > [2020-06-05 13:39:23.175] [alevinLog] [info] Done populating Z matrix; > [2020-06-05 13:39:23.175] [alevinLog] [info] Total 0 CB got sequence corrected; > [2020-06-05 13:39:23.175] [alevinLog] [info] Done indexing Barcodes; > [2020-06-05 13:39:23.175] [alevinLog] [info] Total Unique barcodes found: 604589; > [2020-06-05 13:39:23.175] [alevinLog] [info] Used Barcodes except Whitelist: 0; > [2020-06-05 13:39:23.278] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify; > ; > [2020-06-05 13:39:23.278] [alevinLog] [info] parsing read library format; > [2020-06-05 13:40:35.769] [alevinLog] [info] Starting optimizer; > ; > ; > [2020-06-05 13:40:36.476] [alevinLog] [warning] mrna file not provided; using is 1 less feature for whitelisting; > [2020-06-05 13:40:36.476] [alevinLog] [warning] rrna file not provided; using is 1 less feature for whitelisting; > [2020-06-05 13:40:37.933] [alevinLog] [info] Total 227279.00 UMI after deduplicating.; > [2020-06-05 13:40:37.933] [alevinLog] [info] Total 14712 BiDirected Edges.; > [2020-06-05 13:40:37.933] [alevinLog] [info] Total 173086 UniDirected Edges.; > [2020-06-05 13:40:37.933] [alevinLog] [warning] Skipped 5326 barcodes due to No mapped read; > [2020-06-05 13:40:37.936] [alevinLog] [info] Clearing EqMap; Might take some time.; > [2020-06-05 13:40:37.962] [alevinLog] [warning] Num Low confidence barcodes too less 165 < 200.Can't performing whitelisting; Skipping; > [2020-06-05 13:40:37.962] [alevinLog] [info] Finished optimizer,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639663002:2575,Clear,Clearing,2575,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639663002,1,['Clear'],['Clearing']
Usability,"33:39.994] [alevinLog] [info] Total Unique barcodes found: 3896665; [2021-01-21 09:33:39.994] [alevinLog] [info] Used Barcodes except Whitelist: 34503; [2021-01-21 09:33:40.718] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify; [2021-01-21 09:33:40.718] [alevinLog] [info] parsing read library format; [2021-01-21 09:48:11.430] [alevinLog] [info] Starting optimizer; [2021-01-21 09:48:12.160] [alevinLog] [warning] mrna file not provided; using is 1 less feature for whitelisting; [2021-01-21 09:48:12.160] [alevinLog] [warning] rrna file not provided; using is 1 less feature for whitelisting; [2021-01-21 09:48:36.288] [alevinLog] [info] Total 19031525.00 UMI after deduplicating.; [2021-01-21 09:48:36.288] [alevinLog] [info] Total 454402 BiDirected Edges.; [2021-01-21 09:48:36.288] [alevinLog] [info] Total 113688 UniDirected Edges.; [2021-01-21 09:48:36.288] [alevinLog] [warning] Skipped 44 barcodes due to No mapped read; [2021-01-21 09:48:36.307] [alevinLog] [info] Clearing EqMap; Might take some time.; [2021-01-21 09:48:41.314] [alevinLog] [info] Starting white listing of 9971 cells; [2021-01-21 09:48:41.314] [alevinLog] [info] Starting to make feature Matrix; [2021-01-21 09:48:41.337] [alevinLog] [info] Done making feature Matrix; [2021-01-21 09:48:41.557] [alevinLog] [info] Finished white listing; [2021-01-21 09:48:41.580] [alevinLog] [info] Finished optimizer. > {; ""total_reads"": 188934609,; ""reads_with_N"": 0,; ""noisy_cb_reads"": 98310747,; ""noisy_umi_reads"": 16600,; ""used_reads"": 90607262,; ""mapping_rate"": 18.89108045842464,; ""reads_in_eqclasses"": 35691789,; ""total_cbs"": 3896665,; ""used_cbs"": 44518,; ""initial_whitelist"": 9015,; ""low_conf_cbs"": 1000,; ""num_features"": 5,; ""no_read_mapping_cbs"": 44,; ""final_num_cbs"": 6765,; ""deduplicated_umis"": 19031525,; ""mean_umis_per_cell"": 2813,; ""mean_genes_per_cell"": 1315; }. ## My best result with `--exceptCells 30000`; > ...; [2021-01-23 11:07:52.910] [alevinLog] [info] Done barcode density calculation.; [2021-",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/340#issuecomment-766311567:6262,Clear,Clearing,6262,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/340#issuecomment-766311567,1,['Clear'],['Clearing']
Usability,"33:39.994] [alevinLog] [info] Total Unique barcodes found: 3896665; [2021-01-21 09:33:39.994] [alevinLog] [info] Used Barcodes except Whitelist: 34503; [2021-01-21 09:33:40.718] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify; [2021-01-21 09:33:40.718] [alevinLog] [info] parsing read library format; [2021-01-21 09:48:11.430] [alevinLog] [info] Starting optimizer; [2021-01-21 09:48:12.160] [alevinLog] [warning] mrna file not provided; using is 1 less feature for whitelisting; [2021-01-21 09:48:12.160] [alevinLog] [warning] rrna file not provided; using is 1 less feature for whitelisting; [2021-01-21 09:48:36.288] [alevinLog] [info] Total 19031525.00 UMI after deduplicating.; [2021-01-21 09:48:36.288] [alevinLog] [info] Total 454402 BiDirected Edges.; [2021-01-21 09:48:36.288] [alevinLog] [info] Total 113688 UniDirected Edges.; [2021-01-21 09:48:36.288] [alevinLog] [warning] Skipped 44 barcodes due to No mapped read; [2021-01-21 09:48:36.307] [alevinLog] [info] Clearing EqMap; Might take some time.; [2021-01-21 09:48:41.314] [alevinLog] [info] Starting white listing of 9971 cells; [2021-01-21 09:48:41.314] [alevinLog] [info] Starting to make feature Matrix; [2021-01-21 09:48:41.337] [alevinLog] [info] Done making feature Matrix; [2021-01-21 09:48:41.557] [alevinLog] [info] Finished white listing; [2021-01-21 09:48:41.580] [alevinLog] [info] Finished optimizer. > {; ""total_reads"": 188934609,; ""reads_with_N"": 0,; ""noisy_cb_reads"": 98310747,; ""noisy_umi_reads"": 16600,; ""used_reads"": 90607262,; ""mapping_rate"": 18.89108045842464,; ""reads_in_eqclasses"": 35691789,; ""total_cbs"": 3896665,; ""used_cbs"": 44518,; ""initial_whitelist"": 9015,; ""low_conf_cbs"": 1000,; ""num_features"": 5,; ""no_read_mapping_cbs"": 44,; ""final_num_cbs"": 6765,; ""deduplicated_umis"": 19031525,; ""mean_umis_per_cell"": 2813,; ""mean_genes_per_cell"": 1315; }. ### My best result with `--exceptCells 30000`; > ...; [2021-01-23 11:07:52.910] [alevinLog] [info] Done barcode density calculation.; [2021",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/620:7195,Clear,Clearing,7195,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/620,1,['Clear'],['Clearing']
Usability,"4.0. **Describe the bug**; When I run salmon I exits with an error code of 137. any idea what this means? I also noticed that the output directory is not created. **To Reproduce**; I am running the container on app.terra.bio, unfortunately, I can not share the workspace because the data is from identifiable human subjects. Bellow, I include the log file showing how I ran salmon. I think the bug may have something to do with the run time environment. Know what salmon exit codes mean would really help me figure out where my bug is. Specifically, please provide at least the following information:. * Which version of salmon was used?; 1.4.0; * How was salmon installed (compiled, downloaded executable, through bioconda)?; dockerImg ""quay.io/biocontainers/salmon:1.4.0--hf69c8f4_0"",; * Which reference (e.g. transcriptome) was used?; we have a custom reference based on g35. ; * Which read files were used?; * Which which program options were used?; * . **Expected behavior**; A clear and concise description of what you expected to happen. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX]; - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux the output of `uname -a` and `lsb_release -a`]. **Additional context**; Add any other context about the problem here. ```; + mkdir -p salmon.out; + salmon quant -i sel.align.gencode.v35.ucsc.rmsk.salmon.v1.3.0.sidx --libType A -1 /cromwell_root/fc-secure-519db2bc-049f-43a0-ab75-a2eb9c2cb059/6a6c9b92-3026-47d3-8944-60f0842c566e/samToFastqTest/5f578d2f-7e74-4402-955a-4d4623b83ead/call-samToFastq/GTEX-111CU-0526-SM-5EGHK.2.fastq.gz -2 /cromwell_root/fc-secure-519db2bc-049f-43a0-ab75-a2eb9c2cb059/6a6c9b92-3026-47d3-8944-60f0842c566e/samToFastqTest/5f578d2f-7e74-4402-955a-4d4623b83ead/call-samToFastq/GTEX-111CU-0526-SM-5EGHK.1.fastq.gz -p 8 --recoverOrphans --validateMappings --gcBias --se",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/641:1254,clear,clear,1254,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/641,1,['clear'],['clear']
Usability,"40] [alevinLog] [info] Finished optimizer; > `. I also tried . `salmon alevin -l ISR --chromium --featureStart 19 --featureLength 21 --tgMap guide_to_gene.tsv`. But I get the following output. > `; > [2020-06-03 13:47:17.330] [alevinLog] [info] Found 64 transcripts(+0 decoys, +0 short and +0 duplicate names in the index); > [2020-06-03 13:47:17.330] [alevinLog] [info] Filled with 64 txp to gene entries ; > [2020-06-03 13:47:17.330] [alevinLog] [info] Found all transcripts to gene mappings; > [2020-06-03 13:47:17.336] [alevinLog] [info] Processing barcodes files (if Present) ; > ; > processed 52 Million barcodes; > ; > [2020-06-03 13:48:30.047] [alevinLog] [info] Done barcode density calculation.; > [2020-06-03 13:48:30.047] [alevinLog] [info] # Barcodes Used: 52200250 / 52200250.; > [2020-06-03 13:48:33.285] [alevinLog] [info] Knee found left boundary at 1174 ; > [2020-06-03 13:48:34.501] [alevinLog] [info] Gauss Corrected Boundary at 148 ; > [2020-06-03 13:48:34.501] [alevinLog] [info] Learned InvCov: 985.935 normfactor: 763.254; > [2020-06-03 13:48:34.501] [alevinLog] [info] Total 349(has 201 low confidence) barcodes; > [2020-06-03 13:48:35.369] [alevinLog] [info] Done True Barcode Sampling; > [2020-06-03 13:48:35.441] [alevinLog] [warning] Total 73.3629% reads will be thrown away because of noisy Cellular barcodes.; > [2020-06-03 13:48:35.454] [alevinLog] [info] Done populating Z matrix; > [2020-06-03 13:48:35.455] [alevinLog] [info] Total 4286 CB got sequence corrected; > [2020-06-03 13:48:35.455] [alevinLog] [info] Done indexing Barcodes; > [2020-06-03 13:48:35.455] [alevinLog] [info] Total Unique barcodes found: 604589; > [2020-06-03 13:48:35.455] [alevinLog] [info] Used Barcodes except Whitelist: 4282; > [2020-06-03 13:48:35.558] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify; > ...; > processed 52 Million fragments; > hits: 0, hits per frag: 0; > ; > [2020-06-03 13:49:37.892] [jointLog] [info] Computed 0 rich equivalence classes for furt",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531:4731,Learn,Learned,4731,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531,1,['Learn'],['Learned']
Usability,"41.673] [jointLog] [info] Number of decoys : 1; [2021-04-09 12:16:41.673] [jointLog] [info] First decoy index : 45,374. [2021-04-09 12:16:42.811] [alevinLog] [info] Starting optimizer. [2021-04-09 12:16:42.800] [jointLog] [info] Computed 84 rich equivalence classes for further processing; [2021-04-09 12:16:42.800] [jointLog] [info] Counted 135 total reads in the equivalence classes; [2021-04-09 12:16:42.801] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 26; [2021-04-09 12:16:42.803] [jointLog] [info] Mapping rate = 3.375%. Analyzed 184 cells (95% of all).Log] [info] finished quantifyLibrary(); [2021-04-09 12:16:43.532] [alevinLog] [warning] 37 mitorna gene(s) does not have transcript in the reference; [2021-04-09 12:16:43.532] [alevinLog] [info] Total 0 usable mRna genes; [2021-04-09 12:16:43.533] [alevinLog] [warning] 529 ribosomal rna gene(s) does not have transcript in the reference; [2021-04-09 12:16:43.533] [alevinLog] [info] Total 22 usable rRna genes; [2021-04-09 12:16:43.582] [alevinLog] [info] Total 135.00 UMI after deduplicating.; [2021-04-09 12:16:43.582] [alevinLog] [info] Total 0 BiDirected Edges.; [2021-04-09 12:16:43.582] [alevinLog] [info] Total 0 UniDirected Edges.; [2021-04-09 12:16:43.582] [alevinLog] [warning] Skipped 113 barcodes due to No mapped read; [2021-04-09 12:16:43.584] [alevinLog] [info] Clearing EqMap; Might take some time.; [2021-04-09 12:16:43.589] [alevinLog] [info] Starting white listing of 81 cells; [2021-04-09 12:16:43.589] [alevinLog] [info] Starting to make feature Matrix; [2021-04-09 12:16:43.589] [alevinLog] [info] Done making feature Matrix; Exception : [vector]; alevin was invoked improperly.; For usage information, try alevin --help; Exiting.; ```. **To Reproduce**. I have uploaded the files used and a script to run a reproducible example:. https://www.dropbox.com/sh/ksn45n73bazp0rc/AABlsbkG-SLyKJN4DBO7zQ-va?dl=0. * Which version of salmon was used? 1.4.0; * How was salmon installe",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/647:6711,usab,usable,6711,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/647,1,['usab'],['usable']
Usability,"8dd90e917d; seqHash 512 : 87b7752997ca977ff56d02f69857a32f13b3c39a0a084c72feaa2c97e698b9b04d80a88c6755b97aede5604b89fdf66789a14f7976a89597a7832760a47e8919; nameHash 256 : 54e47ff5eb21b38ef24c8ffa3fc2a192ee5d9c0541bc6ee2da9414ecbd0f8c59; nameHash 512 : 163b337219cfd19b0c4c99cece12c2c2b760b3bf7e4686dbe633259c78552a56f2f015f18740a33c18e0f14c5f362997395c3168590f3ad80704071cabfab13a; [2019-11-20 19:50:26.273] [puff::index::jointLog] [info] Filter size not provided; estimating from number of distinct k-mers; [2019-11-20 19:50:27.059] [puff::index::jointLog] [info] ntHll estimated 34379504 distinct k-mers, setting filter size to 2^30; Threads = 2; Vertex length = 31; Hash functions = 5; Filter size = 1073741824; Capacity = 2; Files: ; utr_library/ref_k31_fixed.fa; --------------------------------------------------------------------------------; Round 0, 0:1073741824; Pass	Filling	Filtering; 1	17	42	; 2	2	0; True junctions count = 102593; False junctions count = 122933; Hash table size = 225526; Candidate marks count = 1387640; --------------------------------------------------------------------------------; Reallocating bifurcations time: 0; True marks count: 1100523; Edges construction time: 13; --------------------------------------------------------------------------------; Distinct junctions = 102593. approximateContigTotalLength: 29519449; counters:; 13519 5 4 5; ERROR!! DOESN'T SUPPORT STRING LENGTH LONGER THAN 255. String length: 317; ```. And the `output_sequences.fa` is from `qapa fasta -f genome/hg38/hg38.fa /qapa/qapa_3utrs.gencode_V31.hg38.bed output_sequences.fa`. The bed file is the pre-compiled annotation file from QAPA. **To Reproduce**; Steps and data to reproduce the behavior:. **Expected behavior**; A clear and concise description of what you expected to happen. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. **Desktop (please complete the following information):**; - OS: Ubuntu Linux; - Ubuntu 18.04.2 LTS",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/451:2756,clear,clear,2756,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/451,1,['clear'],['clear']
Usability,":26.234] [alevinLog] [info] Total Unique barcodes found: 127233006; [2022-03-27 05:34:26.234] [alevinLog] [info] Used Barcodes except Whitelist: 50131; [2022-03-27 05:34:26.966] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2022-03-27 05:34:26.966] [alevinLog] [info] parsing read library format; [2022-03-27 05:46:41.876] [alevinLog] [info] Starting optimizer. [2022-03-27 05:46:42.064] [alevinLog] [warning] mrna file not provided; using is 1 less feature for whitelisting; [2022-03-27 05:46:42.064] [alevinLog] [warning] rrna file not provided; using is 1 less feature for whitelisting; [2022-03-27 05:49:49.761] [alevinLog] [info] Total 535438.00 UMI after deduplicating.; [2022-03-27 05:49:49.761] [alevinLog] [info] Total 2317116 BiDirected Edges.; [2022-03-27 05:49:49.761] [alevinLog] [info] Total 867878 UniDirected Edges.; [2022-03-27 05:49:49.761] [alevinLog] [warning] Skipped 955 barcodes due to No mapped read; [2022-03-27 05:49:49.766] [alevinLog] [info] Clearing EqMap; Might take some time.; [2022-03-27 05:49:50.011] [alevinLog] [info] Starting white listing of 3044 cells; [2022-03-27 05:49:50.011] [alevinLog] [info] Starting to make feature Matrix; [2022-03-27 05:49:50.014] [alevinLog] [info] Done making feature Matrix; [2022-03-27 05:49:50.717] [alevinLog] [info] Finished white listing; [2022-03-27 05:49:51.422] [alevinLog] [info] Finished optimizer; ````. and the `salmon_quant.log` looks like:; ```; [2022-03-27 05:24:09.395] [jointLog] [info] setting maxHashResizeThreads to 32; [2022-03-27 05:24:09.395] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2022-03-27 05:24:09.395] [jointLog] [info] The --mimicBT2, --mimicStrictBT2 and --hardFilter flags imply mapping validation (--validateMappings). Enabling mapping validation.; [2022-03-27 05:24:09.395] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.6",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/763#issuecomment-1082597942:3701,Clear,Clearing,3701,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/763#issuecomment-1082597942,1,['Clear'],['Clearing']
Usability,":35.455] [alevinLog] [info] Total Unique barcodes found: 604589; > [2020-06-03 13:48:35.455] [alevinLog] [info] Used Barcodes except Whitelist: 4282; > [2020-06-03 13:48:35.558] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify; > ...; > processed 52 Million fragments; > hits: 0, hits per frag: 0; > ; > [2020-06-03 13:49:37.892] [jointLog] [info] Computed 0 rich equivalence classes for further processing; > [2020-06-03 13:49:37.892] [jointLog] [info] Counted 0 total reads in the equivalence classes ; > [2020-06-03 13:49:37.893] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 0; > [2020-06-03 13:49:37.893] [jointLog] [warning] Found 370 reads with `N` in the UMI sequence and ignored the reads.; > Please report on github if this number is too large; > [2020-06-03 13:49:37.893] [jointLog] [info] Mapping rate = 0%; > ; > [2020-06-03 13:49:37.893] [jointLog] [info] finished quantifyLibrary(); > [2020-06-03 13:49:37.899] [alevinLog] [info] Starting optimizer; > ; > [2020-06-03 13:49:38.613] [alevinLog] [warning] mrna file not provided; using is 1 less feature for whitelisting; > [2020-06-03 13:49:38.613] [alevinLog] [warning] rrna file not provided; using is 1 less feature for whitelisting; > [2020-06-03 13:49:38.614] [alevinLog] [info] Total 0.00 UMI after deduplicating.; > [2020-06-03 13:49:38.614] [alevinLog] [info] Total 0 BiDirected Edges.; > [2020-06-03 13:49:38.614] [alevinLog] [info] Total 0 UniDirected Edges.; > [2020-06-03 13:49:38.614] [alevinLog] [warning] Skipped 348 barcodes due to No mapped read; > [2020-06-03 13:49:38.614] [alevinLog] [info] Clearing EqMap; Might take some time.; > [2020-06-03 13:49:38.620] [alevinLog] [warning] Num Low confidence barcodes too less 1 < 200.Can't performing whitelisting; Skipping; > [2020-06-03 13:49:38.620] [alevinLog] [info] Finished optimizer; > Floating point exception (core dumped); > `. Any suggestions on how to get this working are highly appreciated!. Thanks",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531:6955,Clear,Clearing,6955,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531,1,['Clear'],['Clearing']
Usability,":41.122] [stderrLog] [info] Done loading index. processed 0 Million fragments; hits: 161433, hits per frag: 0.32698. [2019-01-29 09:55:54.788] [alevinLog] [info] Starting optimizer; [2019-01-29 09:55:54.742] [jointLog] [info] Computed 6,346 rich equivalence classes for further processing; [2019-01-29 09:55:54.742] [jointLog] [info] Counted 80,300 total reads in the equivalence classes ; [2019-01-29 09:55:54.754] [jointLog] [warning] Only 80300 fragments were mapped, but the number of burn-in fragments was set to 5000000.; The effective lengths have been computed using the observed mappings. [2019-01-29 09:55:54.754] [jointLog] [info] Mapping rate = 8.80342%. [2019-01-29 09:55:54.754] [jointLog] [info] finished quantifyLibrary(). Analyzed 289 cells (100% of all).; [2019-01-29 09:55:56.858] [alevinLog] [info] Total 72037 UMI after deduplicating.; [2019-01-29 09:55:56.858] [alevinLog] [warning] Skipped 151 barcodes due to No mapped read; [2019-01-29 09:55:56.876] [alevinLog] [info] Clearing EqMap; Might take some time.; [2019-01-29 09:55:56.917] [alevinLog] [info] Starting Import of the gene count matrix.; [2019-01-29 09:55:57.130] [alevinLog] [info] Done Importing gene count matrix for dimension 138x19879; [2019-01-29 09:55:57.130] [alevinLog] [info] Starting dumping cell v gene counts in csv format; 0.00215799	7.4911e-08	0.000194712	11697.8	; 0.00705206	1.19109e-07	30039.7	29692.8	; [2019-01-29 09:55:59.105] [alevinLog] [info] Finished dumping csv counts; [2019-01-29 09:55:59.106] [alevinLog] [info] Starting white listing; [2019-01-29 09:55:59.107] [alevinLog] [info] Done importing order of barcodes ""quants_mat_rows.txt"" file.; [2019-01-29 09:55:59.107] [alevinLog] [info] Total 138 barcodes found; [2019-01-29 09:55:59.107] [alevinLog] [warning] mrna file not provided; using is 1 less feature for whitelisting; [2019-01-29 09:55:59.107] [alevinLog] [warning] rrna file not provided; using is 1 less feature for whitelisting; [2019-01-29 09:55:59.107] [alevinLog] [info] St",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722:4498,Clear,Clearing,4498,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722,1,['Clear'],['Clearing']
Usability,; ### [ command ] => alevin; ### [ libType ] => { ISR }; ### [ mates1 ] => { cDNA_Small_S1_L001_R1_001.fastq.gz }; ### [ mates2 ] => { cDNA_Small_S1_L001_R2_001.fastq.gz }; ### [ chromium ] => { }; ### [ index ] => { index }; ### [ threads ] => { 20 }; ### [ output ] => { alevin_output9 }; ### [ tgMap ] => { txp2gene.tsv }; ### [ dumpCsvCounts ] => { }. [2018-06-30 22:10:28.044] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2018-06-30 22:10:28.048] [alevinLog] [info] Processing barcodes files (if Present). processed 17 Million barcodes. [2018-06-30 22:10:47.141] [alevinLog] [info] Done barcode density calculation.; [2018-06-30 22:10:47.141] [alevinLog] [info] # Barcodes Used: 17712582 / 17712585.; [2018-06-30 22:10:52.008] [alevinLog] [info] Knee found left boundary at 9447; [2018-06-30 22:10:52.498] [alevinLog] [warning] Gauss Prediction 0 Too far from knee prediction skipping it; [2018-06-30 22:10:52.498] [alevinLog] [info] Learned InvCov: 457.073 normfactor: 260.286; [2018-06-30 22:10:52.498] [alevinLog] [info] Total 10434(has 987 low confidence) barcodes; [2018-06-30 22:10:52.530] [alevinLog] [info] Done True Barcode Sampling; [2018-06-30 22:10:53.101] [alevinLog] [info] Done populating Z matrix; [2018-06-30 22:10:53.103] [alevinLog] [info] Done indexing Barcodes; [2018-06-30 22:10:53.104] [alevinLog] [info] Total Unique barcodes found: 263650; [2018-06-30 22:10:53.104] [alevinLog] [info] Used Barcodes except Whitelist: 5556; [2018-06-30 22:10:53.248] [jointLog] [info] There is 1 library.; [2018-06-30 22:10:53.248] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2018-06-30 22:10:53.248] [alevinLog] [info] parsing read library format; [2018-06-30 22:10:53.308] [jointLog] [info] Loading Quasi index; [2018-06-30 22:10:53.308] [jointLog] [info] Loading 32-bit quasi index; [2018-06-30 22:10:53.308] [stderrLog] [info] Loading Suffix Array; [2018-06-30 22:10:53.375] [stderrLog] [info] L,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/245:1757,Learn,Learned,1757,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/245,1,['Learn'],['Learned']
Usability,; ### [ program ] => salmon ; ### [ command ] => alevin ; ### [ libType ] => { ISR }; ### [ mates1 ] => { ./H2_S5_L003_R1_001.fastq.gz }; ### [ mates2 ] => { H2_S5_L003_R2_001.fastq.gz }; ### [ chromium ] => { }; ### [ index ] => { salmon_index }; ### [ threads ] => { 8 }; ### [ output ] => { alevin_output }; ### [ tgMap ] => { txp2gene.tsv }. [2018-06-12 21:01:31.327] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2018-06-12 21:01:31.330] [alevinLog] [info] Processing barcodes files (if Present) . ; processed 141 Million barcodes. [2018-06-12 21:08:38.126] [alevinLog] [info] Done barcode density calculation.; [2018-06-12 21:08:38.126] [alevinLog] [info] # Barcodes Used: 140111660 / 141062078.; [2018-06-12 21:08:42.014] [alevinLog] [info] Knee found left boundary at 127 ; [2018-06-12 21:08:55.712] [alevinLog] [warning] Gauss Prediction 12274 Too far from knee prediction skipping it; [2018-06-12 21:08:55.712] [alevinLog] [info] Learned InvCov: 255.229 normfactor: 12656.9; [2018-06-12 21:08:55.712] [alevinLog] [info] Total 327(has 200 low confidence) barcodes; [2018-06-12 21:08:55.895] [alevinLog] [info] Done True Barcode Sampling; [2018-06-12 21:08:56.092] [alevinLog] [info] Done populating Z matrix; [2018-06-12 21:08:56.093] [alevinLog] [info] Done indexing Barcodes; [2018-06-12 21:08:56.094] [alevinLog] [info] Total Unique barcodes found: 1530568; [2018-06-12 21:08:56.094] [alevinLog] [info] Used Barcodes except Whitelist: 4828; [2018-06-12 21:08:56.124] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2018-06-12 21:08:56.124] [alevinLog] [info] parsing read library format; [2018-06-12 21:08:56.124] [jointLog] [info] There is 1 library.; [2018-06-12 21:08:56.183] [jointLog] [info] Loading Quasi index; [2018-06-12 21:08:56.184] [jointLog] [info] Loading 32-bit quasi index; [2018-06-12 21:08:56.184] [stderrLog] [info] Loading Suffix Array ; [2018-06-12 21:08:56.530] [stderrLog] [info] L,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/237:2610,Learn,Learned,2610,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/237,1,['Learn'],['Learned']
Usability,"; -----------------------------------------; [2021-04-09 12:16:41.658] [jointLog] [info] done; [2021-04-09 12:16:41.658] [jointLog] [info] Index contained 45,375 targets; [2021-04-09 12:16:41.673] [jointLog] [info] Number of decoys : 1; [2021-04-09 12:16:41.673] [jointLog] [info] First decoy index : 45,374. [2021-04-09 12:16:42.811] [alevinLog] [info] Starting optimizer. [2021-04-09 12:16:42.800] [jointLog] [info] Computed 84 rich equivalence classes for further processing; [2021-04-09 12:16:42.800] [jointLog] [info] Counted 135 total reads in the equivalence classes; [2021-04-09 12:16:42.801] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 26; [2021-04-09 12:16:42.803] [jointLog] [info] Mapping rate = 3.375%. Analyzed 184 cells (95% of all).Log] [info] finished quantifyLibrary(); [2021-04-09 12:16:43.532] [alevinLog] [warning] 37 mitorna gene(s) does not have transcript in the reference; [2021-04-09 12:16:43.532] [alevinLog] [info] Total 0 usable mRna genes; [2021-04-09 12:16:43.533] [alevinLog] [warning] 529 ribosomal rna gene(s) does not have transcript in the reference; [2021-04-09 12:16:43.533] [alevinLog] [info] Total 22 usable rRna genes; [2021-04-09 12:16:43.582] [alevinLog] [info] Total 135.00 UMI after deduplicating.; [2021-04-09 12:16:43.582] [alevinLog] [info] Total 0 BiDirected Edges.; [2021-04-09 12:16:43.582] [alevinLog] [info] Total 0 UniDirected Edges.; [2021-04-09 12:16:43.582] [alevinLog] [warning] Skipped 113 barcodes due to No mapped read; [2021-04-09 12:16:43.584] [alevinLog] [info] Clearing EqMap; Might take some time.; [2021-04-09 12:16:43.589] [alevinLog] [info] Starting white listing of 81 cells; [2021-04-09 12:16:43.589] [alevinLog] [info] Starting to make feature Matrix; [2021-04-09 12:16:43.589] [alevinLog] [info] Done making feature Matrix; Exception : [vector]; alevin was invoked improperly.; For usage information, try alevin --help; Exiting.; ```. **To Reproduce**. I have uploaded the files use",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/647:6521,usab,usable,6521,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/647,1,['usab'],['usable']
Usability,"; The new updates to the `cmd_info.json` file result in an extra `:` at the end of `""salmon_version:""` inside the quotes. This results in the json file being read in with the header of that entry being `salmon_version:` when it should be `salmon_version`. . Note that this was found when running `salmon alevin` in the `--rad` or `--justAlign` mode and we have not tested if this is also the case when running only `salmon alevin`. . **To Reproduce**; Steps and data to reproduce the behavior:; We ran alevin-fry v0.4.1 starting with `salmon alevin` using `--rad` on single-cell data in the salmon biocontainer and that led to the `cmd_info.json` file being output with the extra `:` on salmon_version. . The biocontainer that we used was: quay.io/biocontainers/salmon:1.5.2--h84f40af_0 . Specifically, please provide at least the following information:. * Which version of salmon was used?; 1.5.2; * How was salmon installed (compiled, downloaded executable, through bioconda)?; used the biocontainer ; * Which reference (e.g. transcriptome) was used?; used the splici index following the alevin-fry tutorial ; * Which read files were used?; * Which which program options were used?; ```; salmon alevin -l ISR --chromiumV3 --dumpFeatures --rad; ```. **Expected behavior**; A clear and concise description of what you expected to happen.; We would expect that the extra `:` would not be included to be consistent with previous versions of salmon. ; <img width=""325"" alt=""Screen Shot 2021-07-29 at 12 35 38 PM"" src=""https://user-images.githubusercontent.com/54039191/127538599-206d5e71-cb7a-4a82-8064-4e92e12ee892.png"">. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX]; - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux the output of `uname -a` and `lsb_release -a`]. **Additional context**; Add any other context about the problem here.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/691:1447,clear,clear,1447,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/691,1,['clear'],['clear']
Usability,"> Default RPATH settings; > By default if you don't change any RPATH related settings, CMake will link the executables and shared libraries with full RPATH to all used libraries in the build tree. When installing, it will clear the RPATH of these targets so they are installed with an empty RPATH. https://cmake.org/Wiki/CMake_RPATH_handling#Default_RPATH_settings. We want this default `RPATH` behaviour from `cmake`. I'm unsure why we're getting non-default behaviour.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/70#issuecomment-239534893:222,clear,clear,222,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/70#issuecomment-239534893,2,['clear'],['clear']
Usability,"> Yep use --end 5 --umiLength 8 --barcodeLength 18. Thanks again, I forgot, however, to specify that the sequence is composed first of BC and then of UMI (BC + UMI) (I'm not sure if it was clear in the issue).; Does the command remain the same?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/494#issuecomment-601087573:189,clear,clear,189,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/494#issuecomment-601087573,2,['clear'],['clear']
Usability,"@Hoohm , I believe the custom length options looks good from our end. Feel free to reopen the issue if you face any problem while using alevin in this mode. Re: More customizable options like a regex for extracting CB and UMI is still in development and has been raised in issue #233 and will keep that issue open until we have more generic extraction. . Thanks again for the feedback and useful comments.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/247#issuecomment-412352707:376,feedback,feedback,376,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/247#issuecomment-412352707,2,['feedback'],['feedback']
Usability,"@apeltzer ,. I tried to use the pre-compiled binary myself under alpine within Docker. Initially, it suffers from the same issue (lack of a compliant libc). However, by installing the glibc compatibility layer (which was simply a few commands as laid out [here](https://github.com/sgerrand/alpine-pkg-glibc)), I was able to get the pre-compiled binary to work without issue. Actually, this layer may also fix building from source, but I have not checked yet.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/162#issuecomment-345761296:221,simpl,simply,221,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/162#issuecomment-345761296,2,['simpl'],['simply']
Usability,"@ctb — One thing that would be required for this (apart from some engineering of the command-line parsing / validation code) is a trustworthy, efficient, _multithreaded_ `FAST(A/Q)` parser for interleaved format reads. Right now, Salmon (& Sailfish, &RapMap, & most of the other HTS-centric methods we're developing) use the Jellyfish 2 read parser. I've made this choice since it's fairly simple to use, yet provides nice parallel performance and, most importantly, is fairly well-tested and trust-worthy. Can you suggest a reliable, well-tested, concurrency-enabled library for parsing reads in interleaved format?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-152827801:390,simpl,simple,390,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-152827801,2,['simpl'],['simple']
Usability,"@demis001 salmon currently makes exact matches between the fasta headers and transcript annotations in the GTF, so no - it doesn't work. Since gene level summarization is pretty simple you could just use something like https://github.com/daler/gffutils to read your GTF, drop the version numbers from the GTF entries, then drop the version numbers from the salmon quant.sf file, and join the two yourself. The summarization from tx->gene is just summing each gene's transcripts' TPM values. @rob-p: I do think this is a common enough issue that salmon could handle dropping accession.version numbers with an extra option.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/122#issuecomment-282048231:178,simpl,simple,178,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/122#issuecomment-282048231,2,['simpl'],['simple']
Usability,@hariiyer16 I have not! The index works in an older version of salmon but not the newer one even though it was built in a way that should be usable by the newer Salmon version.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/559#issuecomment-674765288:141,usab,usable,141,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/559#issuecomment-674765288,2,['usab'],['usable']
Usability,"@ialbert,. Thanks again for the detailed bug report and reproducible example for this. We (@mohsenzakeri and I) have pushed experimental support for soft-clipping to the develop branch. You can enable this feature by passing `--softclip` flag to the `quant` command. We have also made a pre-compiled binary that includes this feature [here](https://drive.google.com/open?id=1Si1BqGXLievhol-e3RWjhxzajvVHY2mS). If you have a chance to test this on some of your data to see if the soft-clipping is working as expected in IGV on a larger scale (we tested on the data you provided), we'd be happy to have any feedback. In a future version, we will likely provide the ability to write the full CIGAR string (with mismatches, indels, etc.) out, but that requires the merging and testing of two branches of pufferfish upstream, and so will probably be reserved for a future release.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/475#issuecomment-596774053:605,feedback,feedback,605,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/475#issuecomment-596774053,2,['feedback'],['feedback']
Usability,"@k3yavi — might it be worthwhile exploring the effect of changing the min score fraction here, or enabling softclipping? I do recall that this seems in the ballpark of drop-seq data mapping to the annotated (spliced) transcriptome, but is it clear _why_ the mapping rates for this technology are so low?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/738#issuecomment-1019515038:242,clear,clear,242,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/738#issuecomment-1019515038,2,['clear'],['clear']
Usability,"@k3yavi,. The backtrace seems to suggest the issue is arising from [here](https://github.com/COMBINE-lab/salmon/blob/master/src/Alevin.cpp#L648), and functions called within. Any idea how something untoward could happen with the number of threads being spawned? Also, it looks like here we are simply spawning and joining threads manually --- so we can't blame that on tbb ;P.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395869990:294,simpl,simply,294,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395869990,2,['simpl'],['simply']
Usability,"@mdshw5 — I certainly think that this information could be useful (and bias terms are taken into effect when computing the effective length, when bias modeling is enabled). The problem is that the position-specific start distribution is learned globally (well, conditioned on a few different length classes), rather than being transcript specific. So, it's not exactly clear how it would help too much in Shaun's case, since this is a particular transcript, where a splicing variation is causing a huge portion of the transcript to have no mapped reads. Unless this happens in many transcripts (globally), this particular transcript's contribution to the global position-specific start distribution will likely be rather small.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/8#issuecomment-237931240:237,learn,learned,237,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/8#issuecomment-237931240,4,"['clear', 'learn']","['clear', 'learned']"
Usability,"@mdshw5, the best option I've found so far is actually [rsem-prepare-reference](http://deweylab.biostat.wisc.edu/rsem/rsem-prepare-reference.html). It's a bit slower than gtf-to-fasta, but, so far, seems to do a better job producing a usable transcriptome in the general case.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/15#issuecomment-144478110:235,usab,usable,235,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/15#issuecomment-144478110,2,['usab'],['usable']
Usability,"@mohsenzakeri — if you have any insight here, I'd be interested to know your thoughts. Check out the following test from the ksw2 cli program (modified to output the contents of the `ksw_extz_t` structure:. *with extz*. ```; ./ksw2-test -s -t extz AGCAGAAGCGGGTATTGAGGAGCGTAAATTGTAGTTA TCGGGCATTACCGGATC; first second -48 max:0 max_t:-1 max_q:-1 mqe:-18 mte:-48 mqe_t:13 mte_q:16; ```. *with extz2sse*. ```; ./ksw2-test -s -t extz2_sse AGCAGAAGCGGGTATTGAGGAGCGTAAATTGTAGTTA TCGGGCATTACCGGATC; first second -48 max:0 max_t:-1 max_q:-1 mqe:-18 mte:-48 mqe_t:13 mte_q:3; ```. note, specifically, the differences in the `mte_q` field. Presumably, using the sse instructions should simply speed things up, not change the results! The strings here are taken from the actual strings for the test read. The first `AGCAGAAGCGGGTATTGAGGAGCGTAAATTGTAGTTA` is the buffer of the reference and the second `TCGGGCATTACCGGATC` is the bit of the read before the first MEM.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/475#issuecomment-574491993:677,simpl,simply,677,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/475#issuecomment-574491993,2,['simpl'],['simply']
Usability,"@mousepixels Apologies for slow reply, I found myself circling back to this same issue with another project and thought I'd update the thread. Seems like there was some guidance all along regarding dealing with ONT data. See this [link ](https://combine-lab.github.io/salmon-tutorials/2021/ont-long-read-quantification/). . To summarize, looks like they advise _-N 100 -p 1.0_ for minimap2, which coincidently is what I have been doing as well. Hope that's helpful if you haven't already come up with a strategy.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/790#issuecomment-2028185516:169,guid,guidance,169,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/790#issuecomment-2028185516,2,['guid'],['guidance']
Usability,"@rob-p . I did notice that the header was missing so I am looking into getting the original. I downloaded/unzipped the files you sent and seem to still have the same issue, though. ; ```; $ conda activate salmon; $ cd ~/opt/anaconda2/envs/salmon; $ ./bin/salmon quant -l IU -t transcripts.fa -a sample_alignments.sam -o quant_directory; Version Info: This is the most recent version of salmon.; # salmon (alignment-based) v1.2.0; # [ program ] => salmon ; # [ command ] => quant ; # [ libType ] => { IU }; # [ targets ] => { transcripts.fa }; # [ alignments ] => { sample_alignments.sam }; # [ output ] => { quant_directory }; Logs will be written to quant_directory/logs; [2020-04-21 11:46:41.365] [jointLog] [critical] Note: Alignment-free mapping (i.e. mapping without subsequent selective-alignment) has not yet been throughly tested under the pufferfish-based index and using the pufferfish-based mapping strategies. Thus, disabling of selective-alignment is not currently allowed. We may, potentially explore re-enabling this option in future versions of salmon. ```. To set up Salmon, I entered the following per the Getting Started Guide:; `$ conda config --add channels conda-forge`; `$ conda config --add channels bioconda`; `$ conda create -n salmon salmon`. Then, set the wd to `~opt/anaconda2/envs/salmon`. To run, I dropped the `transcripts.fa` and `seq.bam`/`seq.sam` file into the ~opt/anaconda2/envs/salmon and ran it. I noticed that if I moved the files to an entirely separate directory or deleted them all together and ran `./bin/salmon quant -l IU -t transcripts.fa -a sample_alignments.sam -o quant_directory`, the same error came up. Is it possible that there is an issue with Salmon reading the files?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/511#issuecomment-617263834:1140,Guid,Guide,1140,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/511#issuecomment-617263834,1,['Guid'],['Guide']
Usability,@rob-p Thank you very much for the clear explanation. That answers my question.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/510#issuecomment-617275380:35,clear,clear,35,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/510#issuecomment-617275380,2,['clear'],['clear']
Usability,"@rob-p can you elaborate on this a bit more: . > The effect of --minScoreFraction depends, to some extent, on how you set the match/mismatch/gap parameters. With the default parameters, 0.9 is actually higher than 90% sequence identity, because the default mismatch penalty is twice the match score. If you assume only matches and mismatches, then the --minScoreFraction you want to set is the one such that x * (match_score * read_length) <= (match_score * read_length) - (m * read_length * match_score) + (m * read_length * mismatch_penalty), where m is the mismatch fraction (0.1 in your case). So, for example, if the match_score is 2 and mismatch penalty is -4, and the read length is 100, you want to set it so that: x * 200 = 200 - (0.1 * 100 * 2) + (0.1 * 100 * -4) = 200 - 20 - 40 = 140 so, the appropriate x would be ~0.7. Of course, if you want to make the calculation simple, you can set the match score to 1 and mismatch penalty to 0, and then the interpretation (modulo gaps) is straightforward (and 0.9 means what you want). Would the two parameter sets mentioned above have the same effect assuming read length 100?. Also, it says Alevin has a default minScoreFraction of 0.87. Would it be safe to assume differentiating between isoforms with Alevin is a similar problem to differentiating between orthologous genes in metagenomics/transcriptomics?. Which parameters would be relevant to control for this?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/330#issuecomment-2249029869:880,simpl,simple,880,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/330#issuecomment-2249029869,2,['simpl'],['simple']
Usability,"@roryk I don't think an R package is the right answer :) . My real motivation is to load into Degust: http://www.vicbioinformatics.com/degust/. It can be done with simple Unix cut/paste or with a python script too. But I don't want to depend on R for the pipeline, or even littler. @vals I'll take a look at your script, but still be better if part of Salmon.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/77#issuecomment-240556885:164,simpl,simple,164,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/77#issuecomment-240556885,2,['simpl'],['simple']
Usability,"@tamuanand,. Right now, I added the code to dump the _salmon_ version into versionInfo.json. Which is a standard json file that goes in the index directory. Actually, that file already contains an index version key, which is simply a number that is incremented every time there is a change made that alters the binary representation of the index on disk. That is particularly useful because not every salmon version requires re-building the index. Regarding the feature I've added. It's fairly standard practice for us to put information that is meant to be read by both humans and machines (scripts, R packages downstream, etc.) into a JSON file. This makes it easy to access it simply from many languages, and to have _some_ (but not too much) structure to this data. There are even slick command line tools for pulling info out of JSON files (like [jq](https://stedolan.github.io/jq/)). If there is a strong reason that you need the _salmon_ version in its own text file, I'm willing to oblige and duplicate the information there. Just let me know.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/498#issuecomment-605694474:225,simpl,simply,225,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/498#issuecomment-605694474,4,['simpl'],['simply']
Usability,"@tamuanand,. Thank you for pointing out the relevant literature, and I definitely appreciate your clarity on this issue. Also, I completely agree with your suggested re-wordings in the manuscript, as they correct the mistaken terminology and make the overall intent even more clear. We will be sure to address this when we revise the pre-print. Thanks again!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/365#issuecomment-499544736:276,clear,clear,276,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/365#issuecomment-499544736,2,['clear'],['clear']
Usability,"@tdsone I _think_ this is the right logic: https://github.com/COMBINE-lab/salmon/blob/master/include/LibraryTypeDetector.hpp. . The main source of my confusion on this post was that I think Salmon just chucks back 'IU' for read numbers below 50k. It confused me less on realistic read numbers. I've simplified [quite a bit](https://github.com/nf-core/rnaseq/blob/bc6189f09954c0d00a71ac43b2ccf69ef22bbd82/subworkflows/local/utils_nfcore_rnaseq_pipeline/main.nf#L587) to just work with the strandedness component, using the numbers from lib_format_counts.json. It seems to produce results broadly as expected, but might be a bit naive, for example the numbers are mappings rather than fragments which could throw things off a bit.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/938#issuecomment-2175817517:299,simpl,simplified,299,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/938#issuecomment-2175817517,2,['simpl'],['simplified']
Usability,"@vals, it shouldn't be a coverage issue, at least as compared to previous versions of Salmon. Hopefully we'll have a chance to look at this soon and see if we can figure out what might be causing the performance ""regression"" when `--useVBOpt` is enabled. As @dcjones suggests, we haven't really seen any performance degradation with the VB option in our other testing, so I suspect something characteristic of this dataset. @dcjones; it's great to see you drop by! I'm actually looking for a reasonable collection of datasets to do (automated) regression testing on new releases of salmon --- something to replace my fairly simple and manual existing regression tests. I'd greatly appreciate any suggestions or advice you may have about this! Such tests will become even more useful as we're experimenting with a few inference approaches and it would be great to have a reasonable spread of data to see the effects of different strategies.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/6#issuecomment-112224408:624,simpl,simple,624,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/6#issuecomment-112224408,2,['simpl'],['simple']
Usability,"@zhangchipku,. The default value of `--minScoreFraction` is quite reasonable, I think. It depends on the read length, but for a 100-bp read, it corresponds to 8 mismatches under the default scoring parameters. So the read pair could have up to 16 mismatches before being discarded. I understand that the recommendation to trim reads is a new one, but I think it is a standard best-practice anyway. However, we are looking at the possibility of allowing read-end soft-clipping in future releases, which could mitigate this need in the most common case. It is worth noting that, if you *don't* want to use selective alignment, then the last version of salmon that you can use is the one tagged as `0.15.0`. As of version 1.0.0, the index structure and default mapping algorithm changed, so that selective alignment is ""always on"". This is discussed in some detail in the release notes for version 1.0.0. Generally, we think that the benefits offered by selective-alignment are important, and, unless there is a very strong reason not to, one should generally ensure that reads sharing some exact matches with the reference also produce reasonable quality alignments at the implied loci. However, we also try to be very receptive and responsive to our users' workflows and desiderata, so if the soft-clipping feature is something that would make your experience much smoother, we will certainly consider prioritizing that feature for a future release.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-586478704:1231,responsiv,responsive,1231,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-586478704,2,['responsiv'],['responsive']
Usability,A PR noting the differences in my approach to #269.; The one that I think needs addressing is in `writeFastq` (https://github.com/COMBINE-lab/salmon/compare/develop...PeteHaitch:develop?expand=1#diff-bf2f37cd9ea77a5c454a5bd860a924ee); without some change to this the `UMI` and `CB` are incorrectly extracted for CEL-Seq2. ; I simply commented out the original lines and modified it as needed for CEL-Seq2 in order to test my modified version.; I guess some sort of protocol-specific conditional is needed here. The remainder are minor/cosmetic choices of variable names (please feel free to ignore!).,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/285:326,simpl,simply,326,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/285,1,['simpl'],['simply']
Usability,"A follow up on this (with a lot of help from @raungar; thanks!) led to the conclusion that the problem was that insufficient memory was allocated to the cluster job during indexing (indexing this transcriptome takes ~4.3G). Allocating more memory to the job resolves the issue. The strange thing is that the cluster manager seemed to kill the job rather than refuse to allocate the memory (which would have resulted in a `bad_alloc` exception that would have made the problem clear). So, if you're indexing with salmon on a cluster and see this behavior, be aware of the memory allocation and that the cluster software may surreptitiously kill the process rather than simply fail to allocate the memory!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/197#issuecomment-467720836:476,clear,clear,476,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/197#issuecomment-467720836,4,"['clear', 'simpl']","['clear', 'simply']"
Usability,A simple question about strand bias,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/762:2,simpl,simple,2,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/762,2,['simpl'],['simple']
Usability,"Actually, @mdshw5 --- it's not quite clear to me why the parser isn't doing the right thing in this case. If you take a look at how the paired-end sequence parser is actually populating the internal buffer (e.g. [here](https://github.com/COMBINE-lab/salmon/blob/master/include/PairSequenceParser.hpp#L182)), it is reading one entry from stream1 and then one entry from stream2. I'm guessing there may be some issue with having two different handles open to the same fifo? However, that doesn't seem like it should be a problem. Given the way the code is actually reading from the different streams, it's not clear to me why it's not currently working as expected. I'll try and take a deeper look.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-168563402:37,clear,clear,37,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-168563402,4,['clear'],['clear']
Usability,"Actually, I was only checking the package for building it on Debian, I don't use it personally. ; From that point of view of packaging the software for Debian it would be desirable to be able to build the software without any downloads during the build process. The reason for this is that building packages on the Debian build servers does not allow downloads for the very simple reason that this would bypass the QA checks for proper licensing of all files required to build some software (The same is true for Ubuntu and Linux distributions based on Debian). . Best, ; Gert",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/181#issuecomment-357167540:374,simpl,simple,374,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/181#issuecomment-357167540,2,['simpl'],['simple']
Usability,"Alright, I'll have a go at the simple model. @mikelove, once I have it implemented we can figure out a reasonable test. Actually, enabling the feature was _way_ easier than I thought. The actual bias application code (via re-estimation of effective lengths) can remain the same. I now have code-paths to build GC bias models treating single-end reads as equal to the _conditional_ mean fragment length (given the transcript). Let me know what you think would be a good way to test it.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/83#issuecomment-245366321:31,simpl,simple,31,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/83#issuecomment-245366321,2,['simpl'],['simple']
Usability,"Also - the problem does not happen for Danio rerio indexes, which were created on the same machine. We have also had successes with Homo sap. _short_, but not Homo sap. _long_. Is it possible that some of the indexes were simply corrupted during creation? Although you're able to map to the index I provided above. I have no idea.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/321#issuecomment-442610783:222,simpl,simply,222,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/321#issuecomment-442610783,2,['simpl'],['simply']
Usability,"As suggested by Nick Schurch, we should be writing non-error output (including simple logging and informative messages) to stdout rather than stderr.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/55:79,simpl,simple,79,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/55,1,['simpl'],['simple']
Usability,"Asked from a colleague claiming it was better to use ""correct"" values (ie, given by the RNASeq platform) for fragment length distribution, I tried to use this option. However, I did not understood a few thing about them in the documentation, and could not figure out the answer from the code...; The documentation states that these options give the mean and standard deviation of a truncated normal variable used to model the distribution. However, it is not clear if they correspond of the (µ, sigma) parameters of the Gaussian that _will_ be truncated (as is usually given) or _after_ truncation, as is easy to estimate by sample mean and sample standard deviation. These values may be quite different, I guess, if truncation is indeed important.; From the code, I found that the values are stored in the fragLenDistMean and fragLenDistPriorSD slots of the SalmonOpts, and that their default values are 200 and 80. However, I could not find any place where these slots were used again (a grep on all .cpp files in src did not found any result except the lines in SalmonQuantify.cpp and SalmonQuantifyAlignments.cpp that seem to parse the command line options:; ` (; ""fldMean"",; po::value<size_t>(&(sopt.fragLenDistPriorMean))->default_value(200),; ""The mean used in the fragment length distribution prior""); (; ""fldSD"",; po::value<size_t>(&(sopt.fragLenDistPriorSD))->default_value(80),; ""The standard deviation used in the fragment length distribution ""; ""prior""); `; However, I do not use C++ so I may have missed something in the role of the `po` namespace.; Could you give any hint of where these values are used, so I can understand what is there exact meaning?; Thanks in advance",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/127:459,clear,clear,459,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/127,1,['clear'],['clear']
Usability,"Biostrings object using the GRanges object. **I believe the problem lies here.** It appears that when subsetting the mature exonic sequences from Biostrings using GRanges, the strand field in the GRanges object **was not** utilized. I.e., I needed to get the reverse complement of the extracted sequences for transcripts on the minus strand. I had done that and assumed that this behaviour would be consistent. However, for reasons I have not been able to pinpoint (potentially a bug), the strand information **was accounted for** when I used GRanges to subset the premature sequences. I **did not** need to get the reverse complement of the premature sequences on the minus strand as I had to do for the mature sequences. Yet, I did that anyway. I initially did test my protocol to ensure it produced identical transcript sequences to Gencode, but I only did this for mature sequences. All seemed fine for both + and - strand transcripts. After your feedback, I compared the premature sequences in my transcript fasta against the transcript fasta from Gencode. As you can see in the smoothed dot plots below, the premature sequences of transcripts on the minus strand are in the wrong orientation and have the wrong complementarity!. ![Screenshot from 2021-04-24 00-35-05](https://user-images.githubusercontent.com/10429333/115947355-0d96c880-a495-11eb-92a6-d8d2233c8d2b.png). I included my R code below for this test case for anyone who might stumble upon this issue. Under the code headers “Mature transcript sequences” and “Premature transcript sequences”, you can observe that I used identical protocols for sequence subsetting, yet in the mature case the strand information in the GRanges seems to be disregarded when subsetting from Biostrings, but in the premature case the strand information is used. Of course, this problem is out of the scope of this forum so it will be okay to close this issue. I will reach out to the developers of GenomicRanges and Biostrings to point out this potenti",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191:2516,feedback,feedback,2516,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191,2,['feedback'],['feedback']
Usability,Broken linked files cause salmon indexing to pause (indefinitely) without throwing an error,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/134:45,pause,pause,45,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/134,2,['pause'],['pause']
Usability,"Can we use genome as a reference instead of using transcriptome, and can you please tell me how can we use Salmon output to check alternative splicing events. Your feedback will be highly appreciated.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/161:164,feedback,feedback,164,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/161,1,['feedback'],['feedback']
Usability,"Choosing the top 500 barcodes from the `frequency.txt` list worked! Thanks for bringing my attention to that, I had not realized how do the cuttoff manually. You might want to expand a bit more about the `--dumpFeatures` flag in the documentation (https://salmon.readthedocs.io/en/latest/alevin.html) and possibly mention it in the tutorial (https://combine-lab.github.io/alevin-tutorial/2018/running-alevin/). I think using the `features.txt` to pick barcodes should be more clearly advertised, since it's not straightforward with cell ranger and many people will find it useful. . Thanks!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/245#issuecomment-402627049:476,clear,clearly,476,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/245#issuecomment-402627049,2,['clear'],['clearly']
Usability,"Currently the indexer has a --gencode flag to handle the composite fasta headers in GENCODE transcript fasta files and `split the transcript name at the first '|' character`. However, the alignment-based mode doesn't use an index, and the current behavior is to read the fasta headers from -t verbatim. So, if I run the STAR aligner with the standard workflow using GENCODE files as index, the Aligned.toTranscriptome.out.bam output would already be aligned to the transcriptome, with the RNAME fields set in the same way `salmon index --gencode`, for example:. `ST-J00106:110:H5NY5BBXX:3:2211:22495:7240 99 ENSMUST00000195335.1 799 60 76M = 945 222 CTCAGTAGGAAGATTATAACTAATACTCCCCCATCAAACAGTTTTAAGGACAGAAGAGAACAAAGCATGTAAAGTG <AFFFJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJJFJJJJJJJJJJJJJJJJFFJA<AFJJFFA NH:i:1 HI:i:1 RG:Z:160212_ST-J00106_0110.3`. As a result, Salmon won't quantify anything if I run Salmon in the Alignment-based mode with the official GENCODE transcripts.fa, for example, `salmon quant -l IU -a Aligned.toTranscriptome.out.bam -o $OUTPUT_DIR -t gencode.vM9.pc_transcripts.fa -g gencode.vM9.annotation.gtf` since the RNAME and the FASTA headers don't match, causing a large number of messages like `WARNING: Transcript ENSMUST00000082421.1|ENSMUSG00000064370.1|-|-|mt-Cytb-201|mt-Cytb|1144|CDS:1-1144| appears in the reference but did not appear in the BAM`. Similarly, the gene quantification mode won't work either, since the names in -t and -g will never match. While for the immediate need I can just trim the fasta headers from the GENCODE transctipts.fa using a simple script, it must be an oversight that the same functionality is provided in quasi-alignment mode only.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/95:1587,simpl,simple,1587,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/95,1,['simpl'],['simple']
Usability,"Currently, the default (and only) behavior of Salmon when aggregating from the transcript to gene level is to return transcripts with no corresponding gene in the `GTF` or 2-column format file as their own gene. In some cases, it would be desirable, instead, to simply filter out or ""drop"" such transcripts from the gene-level output. We should add a flag to optionally enable this behavior. Feature requested by @demis001.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/124:262,simpl,simply,262,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/124,1,['simpl'],['simply']
Usability,"Dear @callumparr,. Thank you for bringing this up. So you are correct that the `--noLengthCorrection` flag should be passed to salmon when quantifying data that does not have a ""fragmentation effect"", that is, where the number of fragments we expect to draw from a transcript is not dependent upon the length of that transcript. In the ONT protocols, it is usually the case that we get 1 read -> 1 transcript, even if we don't read the whole thing. We have tested the effect of this in ONT data with spike ins, and have verified that using `--noLengthCorrection` does generally lead to improved accuracy with respect to quantification estimates. We have informed ONT of this, and I would guess they may optimize the flags that are used soon (we have also developed an error model that works correctly for these long reads, and that should make it into the next release of salmon). Regarding the effect this has on the `NumReads` values reported by salmon, it's not as simple as with the `TPM` estimates. The length affects the assigned reads through the probabilistic model on which inference is done. With the length effect we have that P(f | t_i) ∝ P( position | f, t_i ) * P( alignment | f, t_i) --- forgetting the alignment term for the time being, we have that with length correction P( position | f, t_i ) ∝ 1 / l_i and without length correction the l_i term goes away. In other words, the probability of allocating reads has a term that depends on the effective length when the `--noLengthCorrection` flag is not passed, but that term goes away when it is passed. This is not quite as drastic as with TPM where the normalization includes the length directly in the normalization (note, however, that when the `--noLengthCorrection` flag is passed, this adjusts the TPM as well). Further, the `NumReads` is still better than TPM in this regard because it still encodes the effect size (i.e. `NumReads` will sum to the total number of aligned reads). Anyway TLDR: Passing the `--noLengthCorrectio",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/651#issuecomment-821995147:968,simpl,simple,968,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/651#issuecomment-821995147,2,['simpl'],['simple']
Usability,"Dear @juugii,. Thanks for reporting these. Regarding . (1) : Yes, it is possible to skip the version check. Simply place `--no-version-check` before any command. For example:. ```; salmon --no-version-check index <... parameters for indexing>; ```. and . ```; salmon --no-version-check quant <... parameters for quantification>; ```; This will let you avoid the network timeout. Regarding issue (2), it's difficult to say what's happening without seeing the data. I'm looping in @k3yavi to help take a look into this.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/264#issuecomment-410255823:108,Simpl,Simply,108,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/264#issuecomment-410255823,1,['Simpl'],['Simply']
Usability,"Dear Dr. Patro,. First of all, my apologies as I want to make it clear that I have just posted this same question on Bioconductor community as well in a hope to get a quick reply. . I have put great amount of effort to find out answer to this question on internet. Couldn't find it anywhere (bioconductor, biostars, seqanswers, github etc.). I have 3 replicates for each sample and one of the replicates from each sample is single-end and other two are paired-end as SE and PE were processed at different facilities (I know I have to do batch correction in downstream analysis). Now I want to use transcript level abundance from quant.sf file which I derived for each replicates using Salmon's quasi-mapping pipeline (used appropriate flags for SE and PE reads). All these (SE & PE) reads are strand specific. . My question is, can I use quant.sf directly from these replicates for downstream DE analysis using tximport or do SE or PE requires separate kind of processing before I can use them together as replicates for downstream analysis. I am planning to use limma-voom for my DE analysis. Thank you so much for your time and apologies if the question was answered already.; Sandip Darji",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/156:65,clear,clear,65,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/156,1,['clear'],['clear']
Usability,"Dear Rob,. Thank you so much for your guidance. I appreciate you taking the time to help me. I was able to run salmon, no problem. All the best,; Craig",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/520#issuecomment-625604855:38,guid,guidance,38,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/520#issuecomment-625604855,2,['guid'],['guidance']
Usability,"Dear Rob,; a brief update:; 1) with the flag -DNO_IPO=TRUE the compilation worked perfectly. thank you . 2)following a guide found at stackoverlow ([Find which assembly instruction caused an Illegal Instruction error without debugging], I discover that the illegal instruction is **vfmsubsd**. ; I am not an expert at all in the field, but googling it seems to be a standard SSE instruction.; I am surprised indeed.; cpus tested: ; Intel Xeon Gold 5220 (72) ; Intel Xeon Gold 5317 (48); Intel i7-10750H (12). Best and thanks again; Silvano. Program terminated with signal SIGILL, Illegal instruction.; #0 0x00007fa222c47396 in __ieee754_pow_fma4 () from /dataraw/mouse/salmon-1.8.0_linux_x86_64/bin/../lib/libm.so.6. 0x7fa222c47396 <__ieee754_pow_fma4+182> vfmsubsd %xmm3,%xmm6,%xmm3,%xmm7",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/783#issuecomment-1145687835:119,guid,guide,119,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/783#issuecomment-1145687835,2,['guid'],['guide']
Usability,"Dear `salmon` developers,. We are using salmon at ONT for quantifying transcripts from alignments of cDNA reads to transcriptomes on a regular basis and in [some](https://github.com/nanoporetech/pipeline-transcriptome-de) of our pipelines.; Transcriptomic aligments of long reads generate less multimapping reads than short reads (depeneding on the structure of the transcriptome), however we would prefer not to ignore them during quantification in order to make maximal use of the data.; However, since the error model was built for short reads, until now we have used the tool with the error model turned off (`--noErrorModel`), which is not optimal. Would it be possible to add a simple error model suitable for long read alignments? We propose something like the following for calculating the likelihood of an alignment:. - The likelihood of the aligment would be calculated based on the empirical distributions (or a normal fit) of edit distances conditioned on the length of the alignment. We could provide you with this information if needed.; - The likelihood of left and right soft or hard clipped sequences would be calculated as a function of their length (such as (1/x)^z, where the parameter z can be tuned based on real datasets). A more complicated model could be build taking into account the error profile of the long reads. It might be overkill though. I had a look at the source code and it seems to me that it might not be hard to implement it, however I am lacking the intimate knowledge of the codebase to do it easily.; Let me know if you would be interested in adding this feature. If yes, we could evaluate the change in the quality of estimates on real datasets. Best regards,; Botond Sipos",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/519:684,simpl,simple,684,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/519,1,['simpl'],['simple']
Usability,"Dear salmon team and @k3yavi,. I am an happy user of alevin on scRNAseq data (10x). In some circumstances, I have to compare samples from very uneven sequencing depth (less than 100k reads per cell vs 1M reads per cell,), which naturally produces a huge ""batch effect"", some transcripts being impossible to detect at a lower sequencing depth. For 10x datasets, cellranger offers to compensate this kind of difference across datasets by subsampling, and I should tell it works very well. I tried this strategy before running alevin, by the use of python scripts subsampling the fastq files prior any alevin quasi-mapping. However, all my attempts failed, as all downstream analyses shown that this strategy didn't correct the batch effect at all with alevin (visualization on dimension reduction/UMAP show a huge difference between batches, while the cellranger subsampling method clearly corrects it). An important point is by default, the cellranger method corrects according to the amount of mapped reads between samples. So ideally, I should have to evaluate the difference in term of mapped reads to compute a subsampling coefficient (fraction of reads to keep). What correct alevin metrics should I use to estimate such a coefficient?. Considering the probalistic approach of alevin's transcript quantification, I am wondering if it could be any better way to normalize the samples to account for this kind of issue? Also, any option to subsample the reads (take a read into account under a certain probability) during alevin quantification would be of great help in my case. Thank you for your work and your time,; Best,; juugii",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/305:880,clear,clearly,880,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/305,1,['clear'],['clearly']
Usability,Done the required work. Sorry for bothering everyone. Downloaded the refGene.gtf file from UCSC for mm9 having transcript information and then used `gffread` to build the transcript.fa for the mm9. Finally ran salmon indexes and to my surprise it finished in matter of few minutes < 3'. Thanks for all the suggestions. This is something which I always like getting to learn something new every day. Closing the issue.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/49#issuecomment-197975002:368,learn,learn,368,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/49#issuecomment-197975002,2,['learn'],['learn']
Usability,"Due to a current default in the boost library (https://github.com/boostorg/math/issues/1211) in boost::math::digamma, there is a performance hit on aarch64. This happens on v1.10.3 of Salmon, with GNU compiler 13 on Linux aarch64. A 4-thread quantization of one of the Salmon tutorials DRR0* series files spends ~15% of time in this routine (called within CollapsedEMOptimizer). On a larger example, we see 7% performance hit over a run that takes 1300 seconds on 4 cores. On x86 this time is small enough to be lost in the noise. `salmon quant -i athal_index -l A ; -1 DRR016125/DRR016125_1.fastq.gz; -2 DRR016125/DRR016125_2.fastq.gz ; -p $threads --validateMappings -o quants/DRR016125_quant`. There is a simple fix which is to ensure the CMake/Makefiles ensure salmon compiles with: ; `-DBOOST_MATH_NO_LONG_DOUBLE_MATH_FUNCTIONS`; or to add that to any file that brings in boost::math via adding `#define BOOST_MATH_NO_LONG_DOUBLE_MATH_FUNCTIONS` at the start. With that change, a 1300 second runtime drops to 1212 for the larger test case, and for the tutorial case is 48 seconds down to 40 on a 4-core r8g.xlarge (Graviton4). Whilst Boost may fix the issue soon - it's likely that older versions of the library will be found installed for some time. It would be helpful to add this define to cmake settings, or the sources.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/966:708,simpl,simple,708,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/966,1,['simpl'],['simple']
Usability,"Even I am not sure how to add the flags in the make command explicitly.; But, I'd suggest you can try couple of things:; Like I said before installing zlib to apt-get/brew would be the easiest.; If not can you try `-DZLIB_LIBRARY=/users/work/jake/bin/zlib-1.2.11/` i.e. remove `zlib.h`.; As you can see I am learning on the go too 😜",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/141#issuecomment-314454908:308,learn,learning,308,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/141#issuecomment-314454908,2,['learn'],['learning']
Usability,"FYI, miniconda works fine on FreeBSD. It's not too difficult to configure manually, but to make it even easier:. As root:. ```; pkg install auto-admin linux-miniconda-installer; auto-install-linux_base; ```; As a non-root user:. ```; miniconda-installer; conda-shell; conda config --add channels conda-forge; conda config --add channels bioconda; conda create -n salmon salmon; ```; Note: Just running `conda install salmon` instead of `conda create -n salmon salmon` will install a very old version rather than the latest. This utilizes the Linux compatibility module, which simply adds Linux system calls to the FreeBSD kernel. Unlike a virtual machine, there's no performance penalty and memory overhead is trivial. In fact, Linux binaries sometimes run slightly faster on FreeBSD than they do on Linux. Average speed is about the same. I'd only use conda as a stop-gap, though. There's a large and growing selection of bioinformatics software in FreeBSD ports that can be more easily installed and used, e.g. 'pkg install samtools bwa'. Also I'm working on a native FreeBSD port for salmon:. https://github.com/COMBINE-lab/salmon/issues/162. Best,. Jason",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/419#issuecomment-917648051:576,simpl,simply,576,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/419#issuecomment-917648051,2,['simpl'],['simply']
Usability,"From my somewhat superficial understanding, I have feeling that it is the only the soft clipping (deletion at either end) that causes the problem (and not INDELs in general). I think it might be better if the CIGAR string contained the soft clipping operations (the POS would still need to be shifted) of course. Right now when one visualizes the BAM file various distracting artifacts manifest themselves with both salmon and kallisto even when the POS field is correct. See the image below:. ![Alignments](https://www.ialbert.me/static/down/pseudo_alignments/pseudo_aln.png). (Top Kallisto, second Salmon, bottom Hisat. ). The soft clipped sequences are not marked as such, therefore lead to ugly misalignment at the ends, that in turn dominate the visualization. . Ideally, the pseudo-bam should look a little more like Hisat, I don't know how feasible that is though, perhaps knowing that only the ends need to be fixed makes for a simpler solution.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/475#issuecomment-574738566:936,simpl,simpler,936,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/475#issuecomment-574738566,2,['simpl'],['simpler']
Usability,"From the `alevin-fry` repo (by @fransua). ```; Hi,; I cannot find clear help on read_geometry. There are a couple of examples but they do not seem to work for me and I am struggling to change them.; Specifically I have several questions:. what does the ""read_geometry"" refers to? I saw that it is usually set to ""2[1-end]"", but why only read 2, and when does the whole read is not a read?. what is the pattern of inclusion exclusion? 1-10 starts at the first nucleotide but includes the ninth or the tenth too?. How does alevin-fry deals with unexact position, for instance in my case the cell tag can start anywhere between position 85 and 115 because of a variable polyA before. thanks. ```",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/816:66,clear,clear,66,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/816,1,['clear'],['clear']
Usability,Full length cDNA distribution as a guide to abundances?,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/56:35,guid,guide,35,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/56,2,['guid'],['guide']
Usability,Get it - here it is:; ```; [2019-07-09 09:07:39.162] [alevinLog] [info] Processing barcodes files (if Present) . ; [2019-07-09 09:16:59.454] [alevinLog] [info] Done barcode density calculation.; [2019-07-09 09:16:59.454] [alevinLog] [info] # Barcodes Used: [32m877102495[0m / [31m877935734[0m.; [2019-07-09 09:17:06.234] [alevinLog] [info] Knee found left boundary at [32m 4375 [0m; [2019-07-09 09:17:07.572] [alevinLog] [info] Gauss Corrected Boundary at [32m 795 [0m; [2019-07-09 09:17:07.572] [alevinLog] [info] Learned InvCov: 173.265 normfactor: 1097.45; [2019-07-09 09:17:07.597] [alevinLog] [info] Total 41.2673% reads will be thrown away because of noisy Cellular barcodes.; [2019-07-09 09:17:07.597] [alevinLog] [info] Total [32m1192[0m(has [32m397[0m low confidence) barcodes; [2019-07-09 09:17:07.765] [alevinLog] [info] Done True Barcode Sampling; [2019-07-09 09:17:08.039] [alevinLog] [info] Done populating Z matrix; [2019-07-09 09:17:08.067] [alevinLog] [info] Done indexing Barcodes; [2019-07-09 09:17:08.067] [alevinLog] [info] Total Unique barcodes found: 7881525; [2019-07-09 09:17:08.067] [alevinLog] [info] Used Barcodes except Whitelist: 84951; [2019-07-09 09:17:08.128] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2019-07-09 09:17:08.128] [alevinLog] [info] parsing read library format; [2019-07-09 10:02:26.992] [alevinLog] [info] Starting optimizer. [2019-07-09 10:13:56.661] [alevinLog] [info] Total 99488568.00 UMI after deduplicating.; [2019-07-09 10:13:56.701] [alevinLog] [info] Clearing EqMap; Might take some time.; [2019-07-09 10:14:11.020] [alevinLog] [info] Starting Import of the gene count matrix of size 1192x60053.; [2019-07-09 10:14:11.286] [alevinLog] [info] Done initializing the empty matrix.; [2019-07-09 10:14:13.421] [alevinLog] [info] Done Importing gene count matrix for dimension 1192x60053; [2019-07-09 10:14:13.622] [alevinLog] [info] Starting white listing; [2019-07-09 10:14:13.627] [alevinLog] [info] Done imp,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/396#issuecomment-510547693:523,Learn,Learned,523,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/396#issuecomment-510547693,1,['Learn'],['Learned']
Usability,"Glad to hear that it worked for you. Thanks for the suggestions, we will surely update the document soon and be more clear about the manual cutoff.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/245#issuecomment-402759530:117,clear,clear,117,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/245#issuecomment-402759530,2,['clear'],['clear']
Usability,"Glad to hear that, let us know if you need any other help or have suggestions / feedbacks to improve Alevin.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/258#issuecomment-415102037:80,feedback,feedbacks,80,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/258#issuecomment-415102037,2,['feedback'],['feedbacks']
Usability,"Good Afternoon,. I hope this message finds you well. . I am having a hard time running salmon version 0.14.1 downloaded via bioconda. I am trying to count my reads using alignment-based mode. Whenever I run the program, I get similar error messages to [issue 104](https://github.com/COMBINE-lab/salmon/issues/104). Here is the command I am running:. salmon quant -t trimmed_fasta/SRR1810204_1.trim.fastq -l A -a results/bam_files/SRR1810204_1.trim.fastq.bam -o salmon_test. trimmed_fasta/SRR1810204_1.trim.fastq is a fastq sample that I've obtained following trimmomatic and contains the forward strands of the data. . results/bam_files/SRR1810204_1.trim.fastq.bam is the bam file following bwa alignment of the fastq file here and its reverse strand to a reference database. . Could the issue be that I am not using both forward and reverse strands in the target argument for salmon since they were both used to generate the alignment file? I tried to look at the docs for guidance on the best course of action, and I had a hard time finding info. All help would be very much appreciated. All the best,; Craig",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/520:974,guid,guidance,974,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/520,1,['guid'],['guidance']
Usability,Great to learn that. Let us know if you have any other issue. :),MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/774#issuecomment-1185670648:9,learn,learn,9,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/774#issuecomment-1185670648,2,['learn'],['learn']
Usability,"Great; thanks for reporting this and helping us track it down. Please let us know if you run into anything else, or if you have other general feedback / suggestions regarding alevin!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396325784:142,feedback,feedback,142,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-396325784,2,['feedback'],['feedback']
Usability,Guidance on Minimap2 Settings for Quantification of ONT Reads in Alignment Mode,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/790:0,Guid,Guidance,0,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/790,1,['Guid'],['Guidance']
Usability,"HI @jamesrhowe ,; A couple of things, we have made major upgrades into Alevin with the release `v0.12.0` and would be releasing soon and it would take care of the problems you are facing.; We are still working on improving the tutorials and guide for using Alevin but for 10xV3 we added a new flag into `0.12.0` since the UMI length has increased; with the command line flag `--chromiumV3`. You might have to swap `--chromium` with `--chromiumV3`. I'd let you know once we release the latest version otherwise if you can compile from source, compiling `develop` should do the job for you.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/324#issuecomment-443218599:241,guid,guide,241,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/324#issuecomment-443218599,2,['guid'],['guide']
Usability,"HI @mfansler ,; Thanks for asking the very important question.; Alevin is primarily (till current release) designed to work with 3'-tagged end, droplet based sequencing where the primary assumption is that most of the reads would ideally be sequenced from the 3'-end of the molecule. Although, Salmon is a transcript quantification tool for *bulk* RNA-seq but we believe in singe-cell (3'-tagged) sequencing, generating quantification at transcript level is fundamentally hard problem to solve. Specifically, one of the reason is, a lot of transcripts share the terminal exon, and the features like length effect which are used in bulk RNA-seq to resolve ambiguity is not directly usable in single-cell for resolving the transcript ambiguity making the problem hard.; It's possible in the future that assays are designed to help incorporate more information e.g. sequencing from both 5' or 3' end sequencing or use SMART-seq2 which sequence the full molecule. In latter case people have been using Salmon as-is for generating the transcript level quantification. . _In summary_: We believe it's a trade-off based on your use case i.e. if you wan't to generate transcript level counts then most-likely single cell protocols which sequence from the full length of the molecules like smart-seq2 is better suited but if the motivation is to get higher number of cell coverage w/ decent gene-level molecule counts that's where 3'-end tagged end sequencing protocols shines most. _One Liner_; Alevin generates only gene-level counts for droplet based sequencing (til latest release v0.11.2).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/287#issuecomment-420627713:681,usab,usable,681,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/287#issuecomment-420627713,2,['usab'],['usable']
Usability,"HI, ; Maybe this is not the best place to ask this, I am aware. But as the minds behind Salmon I guess is going to be the best possible answer. ; I realised the quantification using salmon with genecode transcriptome on 94 paired-end fastq patient samples. ; I get the gene-sumarised TPM using Tximeta. ; I used then EdgeR to normalice these TPM (stored as gse) with . ```; y <- makeDGEList(gse); y <- calcNormFactors(y); norm.counts.TMM <- cpm(y); ```. My question is, is TPM already ""ready-to-use"" for comparison between samples (gene1 across the 94 samples) ? or the TPM values are only comparables between the same sample (i.e. gene 1 vs gen 10 in sample 1). is the way `(makeDGElist, calcNormFactors, cpm)` the way to normalise salmon output? . I try for several weeks to found it in different forums, (even I read some of the Rob answers to this kind of questions...) but still not clear about the right procedure. Kindest regards!",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/557:888,clear,clear,888,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/557,1,['clear'],['clear']
Usability,"Hello @Starahoush, greetings from Brazil! I'm an undergraduate student in Biomedical Informatics at the Federal University of Paraná, currently involved in a scientific initiation project in an immunology lab. I'm working extensively with FASTQ files from samples sequenced on the BD Rhapsody V1 platform and I've been facing a challenge: a significant portion of the reads are being discarded due to ""noisy cellular barcodes"", with around 50% of the reads affected. Could you please share if you've encountered a similar situation in your experiment or provide some guidance on how to address this issue? I appreciate your attention and assistance!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/850#issuecomment-2052164298:567,guid,guidance,567,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/850#issuecomment-2052164298,2,['guid'],['guidance']
Usability,"Hello dear Salmon developers,; First of all - thank you very much for your effort in supporting Oxford Nanopore reads! I've been Salmon for quantification of ONT sequencing experiments, and recently I decided to dive deeper into how it produces counts for ONT data. The release with initial ONT support (v1.5.1) states that counts should be 100 for all transcripts because at that time it was not clear how EffectiveLength should be computed. However, now (when using release v1.10.1) Salmon produces some meaningful count estimates. I tried to figure out the algorithm by looking at the code, but failed... ; Is there a place where you have the said algorithm documented, or if not, could you please explain how is it implemented?; Thank you in advance!",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/924:397,clear,clear,397,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/924,1,['clear'],['clear']
Usability,"Hello everyone! This is my first time analyzing RNAseq data and I am very much learning as I go while following a YouTube series (https://www.youtube.com/watch?v=butxOf_fxTY&t=217s&ab_channel=SimonCockell). Please excuse if I use wrong terminology in this post, I am very new to all of this and sometimes don't know what the right words are to describe what I am doing or trying to do (lol)!. With the fastq files of reads generated from my RNAseq experiment, I first ran FastQC. The quality of my data seemed to be fine as the per base sequence quality scores were 32+ and most of the other tests passed as well. Next, I built my index for Salmon using the fasta file from Gencode for the human transcriptome. Afterwards, I ran Salmon with the built index and had it automatically detect the library type. When the program was done aligning to the index, I saw that the file had a mapping rate of 40%. I guess what I'm asking is, is this an acceptable mapping rate or should I be concerned?? The reason I ask is because in the data I was working with while learning via the Youtube series, those datasets had mapping rates of nearly 90%. Comparing FastQC reports, my data was of similar/better quality than the data from the Youtube series. In case this is helpful in answering my question, this is the information from the logs for one of my samples:. ```; [2020-09-05 13:51:07.144] [jointLog] [info] setting maxHashResizeThreads to 1; [2020-09-05 13:51:07.144] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2020-09-05 13:51:07.159] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2020-09-05 13:51:07.159] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 0.2. Setting consensusSlack to 0.35.; [2020-09-05 13:51:07.159] [jointLog] [info] parsing read library format; [2020-09-05 13:51:07.159] [jointLog] [info] Ther",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/571:79,learn,learning,79,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/571,1,['learn'],['learning']
Usability,"Hello there,. first off thank you so much for this program: I've been using salmon for roughly a year now and surely won't go back to any other quantification method.; However, I have questions regarding one of my current analyses (sorry if this is the wrong place to ask!). . How well would salmon cope with quantification when using a _de novo_ transcriptome of a polyploid non-model species as reference?. The goal is to find candidate genes via differential gene expression analyses. Since our non-model species is closely related to a model species, we'd simply like to:. - use salmon for quantification; - annotate using the closely related model proteome; - aggregate counts using tximport ; - find DEGs with DESeq2. . So far, the results seem plausible. But I would love to hear an opinion on this: are there things to watch out for with this approach?. Best wishes and stay healthy,. Lukas",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/618:560,simpl,simply,560,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/618,1,['simpl'],['simply']
Usability,"Hello! I did some work with the oxford nanopore error model last summer. There's a blog post about the ONT long read quantification here: https://combine-lab.github.io/salmon-tutorials/2021/ont-long-read-quantification/ . In terms of length correction, the --ont flag basically turns off length correction (since it doesn't really apply to long reads). The error model that the current version of salmon uses for the --ont flag (found in src/ONTAlignmentModel.cpp) basically bins reads by length (into 4 bins by default, I believe). Then for each bin it learns a binomial/geometric distribution for the number of errors (mismatches or indels) in the alignment of the reads in the bin, as well as distributions for the number of bases softclipped at the beginning and end of the read. It then uses these models to penalize reads that have an amount of errors/softclips that is very different from the center of the learned distribution, only if the number of errors/softclips is larger than what we expect for that bin (since a smaller than expected number of errors in the alignment is generally a good, not a bad sign for how likely the read is to map to this transcript). I'm not the original author/creator of this model, so I don't have all the details on specifics of how it works/the design decisions that went into it, but let me know if you have any other questions I can answer!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/924#issuecomment-2148242254:554,learn,learns,554,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/924#issuecomment-2148242254,4,['learn'],"['learned', 'learns']"
Usability,"Hello, . I have RNA-seq data for 3 runs under the same condition, and the data for each run was generated as single-end libraries using 3 lanes (100bp, 100bp and 50bp). After mapping using Salmon against the transcriptome and normalizing the counts using DESeq2, I found out that a control gene had a much higher level of deviation between runs. One of them was reported to have zero counts. . I ran Salmon for each library in that run and got the following results for that gene. Lib1 (50bp): GeneA 1859 1610.000 0.058387 6.313500; Lib2 (100bp): GeneA 1859 1610.000 0.086646 11.991785; Lib3 (100bp): GeneA 1859 1610.000 0.000000 0.000000; Lib1+Lib2+Lib3: GeneA 1859 1610.000 0.000000 0.000011. So I expected that Lib3 would have a problem. But when I ran bowite2 against the transcriptome, the raw counts for GeneA was 39 for Lib1, 21 for Lib2 and 24 for lib3, which looked normal. The number of reads was almost the same in each library, but the size of the library was 1/2 in Lib1 (50bp). . It was not clear to me why Samlon failed to detect GeneA in Lib3 even though the same parameters were used and also why in the combined library, the TPM and number of reads became 0 despite the counts of this gene in Lib1 and Lib2. How would I be able to improve the sensitivity (on the report, only 0.3% was reported to be smaller than K). for indexing and mapping, I used the default parameters: . salmon index -t Nbv5.1_TrPrm_NtCorrect.fasta Nbv5.1_TrPrm_NtCorrect_index; salmon quant -i ../../Database/Nbv5.1_TrPrm_NtCorrect_index -l U -r ../1-Transcriptome_Trimmed_Reads/QTCR002A_S5_L00T_R1_001_trimmed.fq.gz -p 12 -o QTCR002A_S5_L00T_R1_001_trimmed.against.Nbv5.1_TrPrm.out. Thanks,",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/218:1005,clear,clear,1005,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/218,1,['clear'],['clear']
Usability,"Hello, . While running the quantifications of my samples while quasi-mapping, the resulting created quant folders remain empty following the shell script is done running. An example of this would be from the ""Getting Started"" tab: . #!/bin/bash; for fn in data/DRR0161{25..40};; do; samp=`basename ${fn}`; echo ""Processing sample ${samp}""; salmon quant -i athal_index -l A \; -1 ${fn}/${samp}_1.fastq.gz \; -2 ${fn}/${samp}_2.fastq.gz \; -p 8 -o quants/${samp}_quant; done . Once this is done, the created folders are empty, whereas I would expect them to continue to quant files. Of note, I do sometimes get complete quantification of one or two samples (again, referring to the A.thaliana example used in the ""Getting Started"" tab. My, albeit limited, experience might suggest that my case might be a matter of number of threads used/made available. I would appreciate any feed back/confirmation on this. As a reference, I was initially running this on a quad core (3.1 GHz Intel Core i7) MacBook Pro. Thank you for taking the time to consider this, most likely, simple issue",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/302:1065,simpl,simple,1065,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/302,1,['simpl'],['simple']
Usability,"Hello, @rob-p and first of all big thanks from me (and the community in general!) for being so reactive and helpful, and that's not even mentioning the tool you and your colleagues provided, which is very cool!. > do transcript assembly in these samples (using e.g. scallop or StringTie2) and then re-quantify using salmon under the expanded annotation. Could you please point me (and others who might be reading this topic) to a guide on how to convert this purported _de novo_ transcriptome to common gene/transcriptome names already known for the organism?? I am not even sure how that would work since many of us use well-known model organisms like mice or fruit flies, for which both the genome and transcriptome are well-described... What kind of genes/transcripts will I be looking at, exactly, after assembling this particular _de novo_ transcriptome which in theory came from mus musculus but in practice is only applicable to this particular single experiment???. Best regards,; Emile",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/533#issuecomment-1453502593:430,guid,guide,430,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/533#issuecomment-1453502593,2,['guid'],['guide']
Usability,"Hello, I'm debugging a salmon install problem with conda. I don't have time to double check, but it looks something like:. * if you install salmon 1.1.0, you get a version of tbb, 2021.1.1, from conda-forge ; * if you then try to upgrade to salmon 1.4.0, you actually want to get a different version of tbb from defaults, but the version pinning doesn't require it so it sticks with conda-forge; * if you force `tbb==2020.3` for salmon 1.4.0, things work; * if you don't, you get `salmon: error while loading shared libraries: libtbb.so.2: cannot open shared object file: No such file or directory`. The error shows up with:; `tbb 2021.1.1 h4bd325d_0 conda-forge`. and the functioning version of tbb seems to be:; `tbb 2020.3 hfd86e86_0 defaults`. I don't have time to chase this down further at the moment, but hopefully this will be sufficiently clear for me to figure it out later :)",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/637:848,clear,clear,848,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/637,1,['clear'],['clear']
Usability,"Hello,. I have some questions about functions within the software and mainly I am seeking some advice on parameter setting as I believe the developers might have a better idea of how to tackle this problem I am working with. To start, I am helping my adviser with this as a side project so I have limited knowledge on the topic and I also have limited knowledge on RNAseq as I mostly deal with full genomes. Lastly, I also do know that this research question is very narrow and I believe the concept can be done by Salmon, but this is where I would need your feedback. . The idea is to look for the number of reads that map to two versions of a gene. The gene is split into two version by exon skipping and is not alternatively spliced. I also want to make this process fast as the idea would be to look for differences in the proportions of gene versions that are created based on a large databases of RNAseq data (easily 200+ different RNAseq experiments). So to make it quick I am only passing two transcripts to Salmon (T - 1, and T - 2) for version 1 and 2 of the transcript, where version 2 has the 2nd exon (of 4 total exons) removed. . Now I know Salmon was created to map reads to a large number of transcripts across the whole genome, but I believe it still should be possible to narrow down the view to only 1 gene with 2 versions. I believe I just need to set the parameters right, but I also want to set the parameters in a general way so that my script can work across different species with different input RNAseq data. The other problem is that we currently do not have an idea of what proportion of these two versions of the gene should actually exist in the RNAseq data I have (which we didn't perform but just grabbed a random sample from GenBank to test with). My adviser wants to first try and test it computationally first and then verify it in the lab (which is somewhat backwards in my mind, as it's really just a shot in the dark and from my preliminary analysis of Salmon, di",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/401:559,feedback,feedback,559,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/401,1,['feedback'],['feedback']
Usability,"Hello,. I'm trying to create an index file with salmon (version 1.4.0) according to this tutorial here: https://combine-lab.github.io/alevin-tutorial/2019/selective-alignment/ (because I would like to find isoforms using isoformSwitchAnalyseR and the salmon files I already have didn't seem to work, and this tutorial was recommended in the documentation (https://salmon.readthedocs.io/en/latest/salmon.html ) for preparing transcriptome indices (mapping-based mode) ). Since my samples are from humans, I replaced the mouse-files with the (still) current Gencode files for human (v37), and everything seemed to work well until the last step:. salmon index -t gentrome.fa.gz -d decoys.txt -p 12 -i salmon_index --gencode. I left my machine alone for almost 8 h (no other programs, nothing to disturb it). When I finally had a look at it, the terminal was still in Round0, the system monitor still showed some action, and the system was still responsive (no freeze or anything). When I had a look at the index directory, there were no changes in any files after the sub-directory ""twopaco_tmp"" was created, and this directory only contains a file called bifurcations.bin, which was 0 byes (after 8h of computing time). Therefore, I rebooted my system (if there went anything wrong that I couldn't see) and tried changing the parameters. . 1. I changed the number of threads to -p 6 since my machine is rather old, and maybe -p 12 was too much. 2. Since someone seemed to have a similar problem and would have tried changing the filter size next, I tried to change the filter size by adding --filterSize 2^39 (at the same time, I also added --keepDuplicates because I want to use the data to find differentially expressed isoforms later on). salmon index -t gentrome.fa.gz -d decoys.txt -p 6 --keepDuplicates --filterSize 2^39 -i salmon_index --gencode. However, this didn't work and got killed. . I thought it might be due to the --filterSize argument and changed it to 39 (because maybe the 2^ is assu",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/643:942,responsiv,responsive,942,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/643,1,['responsiv'],['responsive']
Usability,"Hello,; Thank you for your guidance on this question. However, I encountered the same error despite using the latest versions of Trinityrnaseq and salmon. I ran Trinity version 2.15.1 to generate Fasta files. I attempted to use Salmon version 1.10.1 for indexing, but I encountered this exception. Upon checking the Docker link provided in the comment, I found that the salmon version listed is 1.5.0. So, I tried using Salmon 1.5.0 and encountered the same error. Could you please advise me on how to resolve this issue? Thank you. ```; $./trinityrnaseq-v2.15.1/Trinity --seqType fq --max_memory 6 --samples_file sample.txt --min_kmer_cov 2 --no_parallel_norm_stats --output trinity_test_0210_1019 --CPU 6. ... $ ~/tools/salmon-latest_linux_x86_64/bin/salmon index --index quasi --type quasi --transcripts ~/first_try_Gall/trinity_test_0210_1019.Trinity.fasta ; Version Info: This is the most recent version of salmon.; Exception : [Error: RapMap-based indexing is not supported in this version of salmon.]; /home/ubuntu/tools/salmon-latest_linux_x86_64/bin/salmon index was invoked improperly.; For usage information, try /home/ubuntu/tools/salmon-latest_linux_x86_64/bin/salmon index --help; Exiting.; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/832#issuecomment-1990328443:27,guid,guidance,27,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/832#issuecomment-1990328443,2,['guid'],['guidance']
Usability,"Hey @jeremymsimon! I checked the protocol and the [pipeline code](https://github.com/yjzhang/split-seq-pipeline/blob/master/split_seq/tools.py). The protocol you described is v1 and the Parsebio is v2. I have implemented v2 in salmon and would be testing it this week. v1 can be similarly implemented. I read the paper and other available resources but I am not clear about the random hexamer usage and it's effects on the barcode. Can you please explain what you meant by BC1s being paired and what's the use of random hexamer, please? Thanks.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-936331597:362,clear,clear,362,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-936331597,2,['clear'],['clear']
Usability,"Hey Rob, not sure if I understood your answer. ; During cDNA synthesis, we use random 9-mer (not 6-mer). My impression from the documentation is that -seqbias can only be used if cDNA synthesis was done using 6-mer. This point is not clear in your answer for me. ; Could you please clarify?; Many thanks",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/880#issuecomment-1757735883:234,clear,clear,234,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/880#issuecomment-1757735883,2,['clear'],['clear']
Usability,"Hey all,. I'm currently attempting to install Salmon from source on a machine running Ubuntu 16.04. I'm following along with the installation instructions (http://salmon.readthedocs.io/en/latest/building.html#installation); however, I am running into errors when running cmake:. michael@thinkpad:/opt/salmon/salmon-0.8.2/build$ cmake -DFETCH_BOOST=TRUE; CMake Error: The source directory ""/opt/salmon/salmon-0.8.2/build"" does not appear to contain CMakeLists.txt.; Specify --help for usage, or press the help button on the CMake GUI. I tried to fix the issue by moving CMakeLists.rxt from the parent directory into the build directory, but I was met with even more errors, I've attached the created CMakeError.log and CMakeOutput.log file. [CMakeOutput.txt](https://github.com/COMBINE-lab/salmon/files/1109023/CMakeOutput.txt); [CMakeError.txt](https://github.com/COMBINE-lab/salmon/files/1109022/CMakeError.txt). I'm thinking that this may be a simple issue that I've overlooked as I'm new to Linux, and installation using CMake is new to me.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/139:946,simpl,simple,946,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/139,1,['simpl'],['simple']
Usability,"Hey, I ran into couple of more typos in the --help documentation.; In Salmon Quant Reads mode, the option --writeUnmappedNames says the the file created is named unmapped.txt, while it is actually named unmapped_names.txt; In Salmon Quant Alignment mode, the option --sampleUnaligned says the un-aligned reads are also written to the file ""posSample.bam"", I suppose a 't' is missing there?; Also, when I ran Salmon Quant with Alignment mode, the output auxiliary directory was still named just 'aux' instead of 'aux_info' per the newest change log. ; Sorry if I'm bothering with these pesky details, I though it might help when clearing the documentation a bit.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/81:628,clear,clearing,628,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/81,1,['clear'],['clearing']
Usability,"Hey,. I'm pretty new to RNA-seq so hope this question is formatted okay! . I've carried out my RNA-seq analysis using STAR into feature counts but wanted to redo the analysis using Salmon as everything I'm reading says its the way forward! I've tried to create a genome index using the following files. ``; wget http://ftp.ensembl.org/pub/release-103/fasta/cricetulus_griseus_picr/cdna/Cricetulus_griseus_picr.CriGri-PICR.cdna.all.fa.gz; wget http://ftp.ensembl.org/pub/release-103/fasta/cricetulus_griseus_picr/dna/Cricetulus_griseus_picr.CriGri-PICR.dna.nonchromosomal.fa.gz; ``; Then I created the decoy file and the combined file them using the following. ; `; grep ""^>"" <(zcat Cricetulus_griseus_picr.CriGri-PICR.dna.nonchromosomal.fa.gz) | cut -d "" "" -f 1 > decoys.txt; cat Cricetulus_griseus_picr.CriGri-PICR.cdna.all.fa.gz Cricetulus_griseus_picr.CriGri-PICR.dna.nonchromosomal.fa.gz > gentrome.fa.gz; `; And finally ran the index using ; `./salmon index -t /data/fcr18ab/Refrence/New_Refrence_Files/gentrome.fa.gz -d /data/fcr18ab/Refrence/New_Refrence_Files/decoys.txt -p 1 -i /fastdata/fcr18ab/Adrian_salmon_index/salmon_index `. The error I get is shown below in the file. It says it can't find any of the decoy sequences in the combined file, but I have searched through them and they are there?. [Super_Low.txt](https://github.com/COMBINE-lab/salmon/files/6254711/Super_Low.txt). Sorry if this is a super simple issue. The cell line is a cancer cell which has not got defined chromosomes. I'm sure its me messing up somewhere but I can't figure out where!",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/644:1419,simpl,simple,1419,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/644,1,['simpl'],['simple']
Usability,"Heya, we had the same problem with unclear knee-plots like this. We make an alternative plot that looks like these. The first is on high quality data from Allon's K562 data from the original inDrop paper; a knee plot works well on this dataset. ![image](https://user-images.githubusercontent.com/414586/57312464-9e631680-70bb-11e9-961d-5bf2c3ede38a.png). and this is from blood in the Zebrafish, the data is of less good quality. The knee plot for this data wasn't clear enough to draw a reasonable cutoff but this alternative plot makes it easier to pick the cutoff:. ![image](https://user-images.githubusercontent.com/414586/57312538-c3578980-70bb-11e9-910c-84017a5dbcde.png). These plots are made like this:. ```; barcode_plot = function(bcs, sample) {; bcs_hist = hist(log10(bcs$count), plot=FALSE, n=50); fLog = bcs_hist$count; xLog = bcs_hist$mids; y = fLog * (10^xLog) / sum(fLog * (10^xLog)); print(qplot(xLog, y) + geom_point() + theme_bw() + ggtitle(sample)); return(data.frame(x=xLog, y=y, sample=sample)); }; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-490143007:465,clear,clear,465,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-490143007,2,['clear'],['clear']
Usability,"Hi @ACastanza,. Thanks for reporting both of these. For the first, I think it is just the case that the message needs to be updated. In fact, the `--validateMappings` flag is now deprecated since selective-alignment is used by default (and can't be turned off, except in the single-cell mapping context, with the `--sketchMode` flag, which is currently only in the develop branch). We'll update that message.; Regarding the misplaced newline, the issue is that the other messages are written by the logger, which is asynchronous. So, sometimes it will get to the appropriate place and write a newline before the fragment counter starts, and sometimes it won't. I'll look into if there is a way to better clear the line, even if the update is asynchronous. Thanks!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/587#issuecomment-729044670:704,clear,clear,704,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/587#issuecomment-729044670,2,['clear'],['clear']
Usability,"Hi @Alecrim24,. It looks like the list of r1 files are being interpreted as a single, long, filename. Same with the list of r2 files. Any idea why that's the case? They should be a space-separated list (of course, there *are* a ton of them here, but the error clearly suggests they are being interpreted as a single, long, filename). --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/870#issuecomment-1694754832:260,clear,clearly,260,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/870#issuecomment-1694754832,2,['clear'],['clearly']
Usability,"Hi @Anto007,. Sounds like an interesting experiment! A couple of questions: (1) are you quantifying the meta-transcriptome or the metagenomes? What I mean is, are your target sequences the specific genes from the microbes, or the entire microbial genomes? Is the sequencing data RNA-seq from sequencing the mixture of expressed gene transcripts, or DNA-seq of the microbes? This will have an effect on how you expect reads to be generated. The effect of `--minScoreFraction` depends, to some extent, on how you set the match/mismatch/gap parameters. With the default parameters, `0.9` is actually higher than 90% sequence identity, because the default mismatch penalty is twice the match score. If you assume only matches and mismatches, then the `--minScoreFraction` you want to set is the one such that ; x * (match_score * read_length) <= (match_score * read_length) - (m * read_length * match_score) + (m * read_length * mismatch_penalty), where m is the mismatch fraction (0.1 in your case). So, for example, if the match_score is 2 and mismatch penalty is -4, and the read length is 100, you want to set it so that:. x * 200 = 200 - (0.1 * 100 * 2) + (0.1 * 100 * -4) = 200 - 20 - 40 = 140 . so, the appropriate x would be ~0.7. Of course, if you want to make the calculation simple, you can set the match score to 1 and mismatch penalty to 0, and then the interpretation (modulo gaps) is straightforward (and 0.9 means what you want). Finally, I'd typically avoid using `--mimicStrictBT2`, since those are pretty harsh parameters. Of course, you could try mapping both with and without that flag and see how it affects your mapping rate.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/330#issuecomment-447589060:1282,simpl,simple,1282,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/330#issuecomment-447589060,2,['simpl'],['simple']
Usability,"Hi @BenLangmead!. Thanks for the formal feature request. This is, indeed, a great idea, and something I've been interested in for quite a while. As far as I can tell, the main impediment to this is the hash table (https://github.com/greg7mdp/sparsepp) used in the index. The suffix array used by the mapping algorithm (by virtue of simply being a flat array of either 32 or 64-bit integers) is trivial to load via shared memory, as is the flat representation of the concatenated text itself. The bitvector and rank data structure that separate individual transcript sequences might be a bit trickier, but is also small enough to exist per-process. However, it's unclear to me if there is an easy or straightforward way to have the hash table reside in shared memory, and this is usually the single largest element of the index. As I mentioned, this is a feature that I've thought would be very useful for quite a while, and I'm interested in seeing it implemented. If you have any suggestions on what might be the best approach, I'm all 👂s.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/335#issuecomment-455905666:332,simpl,simply,332,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/335#issuecomment-455905666,2,['simpl'],['simply']
Usability,"Hi @ChelseaCHENX ,. Thanks for confirming the counts of the number of predicted cells.; As much as I'd love to give you an exact answers, but in realty w/ current settings it requires a little more exploratory analysis. Whitelisting traditionally is done by making some greedy choices and generally can results in different number of predicted cells, and having an exact answer is difficult to have. For example, if you run alevin with `--dumpFeatures` and plot the frequency of CB, as dumped in the `raw_cb_frequency.txt`, you will observe a monotonically non-increasing function. Different tools try to get the ""knee"" in the distribution, so as alevin, as the first round of whitelisting. For cellranger, at least in my understanding, they try to take the top X% (I think it's 10) of the value suggested through `expectCells` command as high confidence and use all the CB which has the frequency greater than the lowest frequency of the high confidence barcodes for quantification. To counter the greediness of the CB calling, we in our suggested method for alevin, proposed a naive bayes based approach by learning features from not only CB frequency but various other features. There had been other methods like ""emptyDrops"" which you can try for more fine-grained whitelisting post quantification using alevin quants. Having said that, if you use expectCells with bigger value, alevin will start to include more and more cells. However as the frequency of the new CB which gets included as high confidence with each new iteration drops exponentially, and even though the new CB gets merged to a high confidence barcode its chance of affecting the quantification also drops. In summary, if you are sure about your experiment to have more cells then it's ideal to increase the value otherwise, I think, with the increased expectCells value the quants can potentially be effected but most probably not by a lot. Hope it helps !",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/396#issuecomment-510628771:1109,learn,learning,1109,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/396#issuecomment-510628771,2,['learn'],['learning']
Usability,"Hi @Cold7,. Thanks for the report. So, could you provide the full output that you get on the terminal when you run this? Your command line looks fine to me. Since version 1.0.0, `--validateMappings` has become the default behavior and so this flag technically has no effect (it is marked as ""deprecated""). However, the argument parser should _absolutely_ accept it, and it's not clear to me why it might be giving you this error. The full output from the terminal may help to diagnose this.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/563#issuecomment-680250718:379,clear,clear,379,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/563#issuecomment-680250718,2,['clear'],['clear']
Usability,"Hi @DawnEve,. Thanks for your feedback, and I'm sorry this caused you such a headache. You're right that it would be a good idea to link to the most common transcriptomes for model organisms (e.g. human and mouse) directly in the documentation. I'll add this in the future. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/186#issuecomment-359218368:30,feedback,feedback,30,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/186#issuecomment-359218368,2,['feedback'],['feedback']
Usability,"Hi @DobbyLikesPenguins,. ### conda idea. So, if you want to try with conda again, I would first recommend that you create a new environment for salmon. ```; conda create --name salmon; ```. which you can then activate with . ```; conda activate salmon; ```. From this environment, you should be able to install the latest version. ```; conda install salmon; ```. or specifying version explicitly like . ```; conda install salmon=1.4.0; ```. ### using the pre-compiled executable. The simplest thing would be to simply add it to your PATH. Assuming you are using bash or a similar shell, you can do something like:. ```; export PATH=<path_to_salmon_directory>/bin:$PATH; ```. to add salmon to your path. It should choose this version when you use `salmon`. However, this will be reset when you logout. To make the change permanent, then you add this command to your bash profile (usually `~/.bash_profile`). It's a little bit different (but very similar) if you are using a different shell. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/483#issuecomment-775273715:484,simpl,simplest,484,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/483#issuecomment-775273715,4,['simpl'],"['simplest', 'simply']"
Usability,"Hi @ECuris,. Yes, the values you give are used to form a normal distribution, which is then truncated on the left at 0. So, the parameters you provide are the mean and standard deviation of the distribution *prior* to truncation. However, I'll note that the values are such that 0 is usually sufficiently far (in terms of standard deviations from the mean) that the mean and standard deviation of the fragment length distribution are very similar before and after the 0 truncation. Finally, I'll mention that, if you have paired-end reads, Salmon will *always* learn the empirical fragment length distribution (since the experiment, itself, is the best estimator of the true distribution), but the `--fldMean` and `--fldSD` parameters define the prior distribution that is updated with observed fragment lengths.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/127#issuecomment-285686442:561,learn,learn,561,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/127#issuecomment-285686442,2,['learn'],['learn']
Usability,"Hi @EPunzi,. I'm glad you were able to get this to work. Thanks for the detailed feedback. This is, indeed, interesting to us. Though, it looks like it's a bug in the Boost build. Could you let me know what OS (& version), and compiler you're using? I can report this upstream to Boost. Thanks again!; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/235#issuecomment-398454333:81,feedback,feedback,81,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/235#issuecomment-398454333,2,['feedback'],['feedback']
Usability,"Hi @GWW,. Thanks for the link. We'll look into this. In the meantime, I also noticed something that gave me pause. Specifically, in your output, you have:. ```; ### [ mates1 ] => { /dev/fd/63 }; ### [ mates2 ] => { /dev/fd/62 }; ```. Which makes me think that you are using pipe / process substitution to feed the reads to alevin. While this works fine with normal salmon, it's not currently possible with alevin. This is because alevin goes through the barcode file once by itself, and then goes through both the barcode and read files in unison to assign reads to cells using the initial barcode mapping. Thus, the pipe can't be reset to read from the beginning again, which is a problem. Are you, in fact, using process substitution here? Alevin can read directly from gzipped fastq files, so that's not necessary. Could you see if you encounter the issue if you remove the process substitution (if you're using it)?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395843922:108,pause,pause,108,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/234#issuecomment-395843922,2,['pause'],['pause']
Usability,"Hi @HamletShaoE --- what version of Salmon are you using? If you are using the latest version, in addition to the `quant.sf` file, there is a file in the output directory called `stats.tsv`. The format of this file is a list of key-value pairs. The first key-value pair lists the total number of observed fragments in the input (and can be ignored for your purposes). Each subsequent line lists a transcript id followed by that transcript's computed effective length. You can simply take these values and join them (in the database / data frame sense) with the main quantification results. I should note that the next version of Salmon (v0.6.0), which should be out shortly, in addition to including a number of improvements and new features, will make these effective length values easier to get at --- they will appear in the main `quant.sf` file (versions compiled from the develop branch will already do this). For the time being, however, the `stats.tsv` file is the place to get this info. Finally, I'd mention that, though I don't know your use case, I'd be cautious of using FPKM any place that TPM might be used instead. Within a sample, they are proportional (thus the equation you provide), but between samples, FPKM values have un-necessary variation based on the average lengths of the expressed transcripts in the samples; an arbitrary variation for which TPM corrects.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/32#issuecomment-166890654:476,simpl,simply,476,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/32#issuecomment-166890654,2,['simpl'],['simply']
Usability,"Hi @Jensen416,. Thank you for reporting this. Certain versions of the GCC compiler are not capable of performing full program link time optimization (`lto`) for this codebase. This is a known issue — and there are other programs that exhibit this same behavior. This is something that GCC must fix upstream — an internal compiler error is something that really shouldn't happen. Luckily, the solution is simple; just don't use whole program inter procedural optimization. Try using this `cmake` invocation (after clearing out your build directory):. ```; cmake -DNO_IPO=TRUE -DFETCH_BOOST=TRUE -DTBB_INSTALL_DIR= ~/anaconda3/pkgs/tbb-2021.5.0-hd09550d_0/ -DCMAKE_INSTALL_PREFIX= ~/salmon/; ```. The `-DNO_IPO` tells `cmake` to invoke the compiler without inter procedural optimization (i.e. `lto`). Let me know if this works for you. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/778#issuecomment-1134776478:404,simpl,simple,404,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/778#issuecomment-1134776478,4,"['clear', 'simpl']","['clearing', 'simple']"
Usability,"Hi @Liripo - if I'm understanding correctly, your UMI/barcodes are on R2 but `alevin` is incorrectly extracting them from the R1 file? If so, you should be able to simply reverse your inputs, e.g.:. ```; salmon alevin -i ../../GRch38_splici_idx \; -l A \; -1 2.fq.gz \; -2 1.fq.gz \; -p 32 \; --splitseqV1 \; -o alevin_out \; --tgMap ../../transcriptome_splici_fl86/transcriptome_splici_fl86_t2g.tsv \; --dumpFeatures --whitelist ../white_barcode.txt; ```; I've needed to do this for my own projects sometimes, since our cDNA/barcode reads are opposite that of the original Rosenberg paper, and it works fine. Can you give that a try and see if it solves your issue? Or if I'm misunderstanding, can you elaborate more on what you expected the output to look like?. And seconding @rob-p's suggestion above - you should be using `alevin` -> `alevin-fry`",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/774#issuecomment-1127073879:164,simpl,simply,164,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/774#issuecomment-1127073879,2,['simpl'],['simply']
Usability,"Hi @Melkaz,; These options have been added as of commit c207d0f28e5782f9a16747a72ac6f06c277fd4ed. There are some new options, all of which have reasonable defaults (the ones that were hard coded before). The relevant options here are: `--fldMean` which you can use to specify the expected mean length of the fragment distribution and `--fldSD` which you can use to specify the expected standard deviation of the fragment length distribution. These values are used to set the _prior_ on the fragment length distribution. This means that if you're using paired-end reads, the observations will overwhelm this prior quickly and we'll learn the empirical distribution. If you're using single-end data, then the prior won't really be updated and the values you specify above are what will be used in practice (e.g. to compute effective transcript lengths). Please let us know if you run into any trouble using this new feature. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/2#issuecomment-103974922:631,learn,learn,631,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/2#issuecomment-103974922,2,['learn'],['learn']
Usability,"Hi @Miserlou,. I'm not necessarily opposed to this. What exactly would the dry-run do? For example, would it simply check if the input files exist, try to load the index, etc.? This seems like it could be useful functionality, though, in my experience `--dry-run` commands usually aren't effectful (i.e. they usually don't create directories or output files). --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/189#issuecomment-362155044:109,simpl,simply,109,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/189#issuecomment-362155044,2,['simpl'],['simply']
Usability,"Hi @Munfred , thanks for all the useful comments and glad to hear that you were able to run alevin successfully. ; I agree, in the next release we can work on adding the flag for ignoring the reads below a certain length.; Regarding the Transcript to gene Mapping file, all `bioawk` script does it to generate a `tsv` file with the first column as transcript name (as present in the reference) and the second column is the relevant gene id to the transcript. We have described the format [here](http://salmon.readthedocs.io/en/latest/alevin.html) but we can also update the tutorial to reflect the same more clearly. I agree with your last point too, we are working on writing a python parser, to parse the binary format and would update the tutorial soon with the relevant code. Thanks again for using our tool and let us know if you have any other feedback / suggestion regarding improving the alevin pipeline.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/237#issuecomment-400439678:608,clear,clearly,608,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/237#issuecomment-400439678,4,"['clear', 'feedback']","['clearly', 'feedback']"
Usability,"Hi @Munfred ,. Apologies for the delayed response.; Thanks for your very important question. We are aware of the problem and are extensively working on improving the downstream processing of the alevin output. Unfortunately, in current form there is no other direct way of loading alevin output matrix. We are thinking of alternative options like using `loompy` but it's a work in progress. We will definitely inform here once we have a simpler working version.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/354#issuecomment-490091075:437,simpl,simpler,437,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/354#issuecomment-490091075,2,['simpl'],['simpler']
Usability,"Hi @PeteHaitch ,; Thanks for your interest in *Alevin*.; Although in current Alevin we have concentrated mainly on learning more about Droplet based 3'-tagged single cell protocols, especially 10x; we are very much interested in extending it towards other protocols like CEL-seq.; However, there are couple of challenges/difference which should be considered before incorporating it into the Alevin pipeline. Currently Alevin relies on the fact that the droplet based protocols use PCR amplification of the library and the UMI deduplication phase of Alevin assumes an exponential model, I am not sure how true is this with CEL-seq? Another issue is that CEL-seq is a Fluidigm based system while the current application for Alevin is for microfluidics based. In general we have observed that the 10x cell isolation step is pretty robust in reporting the Cellular Barcodes(CB) and although we have a probabilisitic model to handle the CB based uncertainty but the ambiguous case like that are very less frequent, (although not true for Drop-Seq). Having said that, we might have to do some analysis to actually figure out the right model for Barcode correction in Fluidigm based system. Also, please do let us know of your experience in using the solution proposed in #247 . Looking forward to hearing back from you.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/269#issuecomment-414162302:115,learn,learning,115,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/269#issuecomment-414162302,2,['learn'],['learning']
Usability,"Hi @PeteHaitch! I agree with @PeteHaitch here --- I think we should provide an easy way to specify custom cb & umi parameters paired with a particular protocol. For 10x v2, since it's a very standard commercial protocol, I think simply having a `--chromium` flag is probably OK. But we should make it easy for ppl to tweak their CB & UMI lengths.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/269#issuecomment-418580112:229,simpl,simply,229,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/269#issuecomment-418580112,2,['simpl'],['simply']
Usability,"Hi @PlantDr430,. Thanks for the context! As always, we'd be interested in learning anything interesting you find about the general behavior of salmon in different contexts and with different parameter settings etc. Out of curiosity, when you mention that genes perform ""better"" with one or another `--scoreExp`, is it the case that this is data where you have some sort of ground truth expectation for the abundance of the primary vs. spliced forms? If so, super interesting!. One other thought I had about this. While it is true, as I mentioned in my original post, that the conditioning on the transcripts is _fundamental_ in the case of salmon and other transcript expression tools that don't, themselves, try to assemble new transcripts, it's not necessarily true that there is no evidence in the quantifications that something my be awry. Specifically, I noticed that you are using posterior confidence estimation (bootstrapping). We actually have a [recent paper](https://www.biorxiv.org/content/10.1101/2020.04.07.029967v1.full) that discusses how to use the uncertainty estimates from salmon (though we rely on the Gibbs sampler rather than bootstrapping) to group together transcripts whose abundances cannot be individually estimated with confidence (with evidenced provided by the posterior samples). It might be useful to identify such cases in your analysis. Let me know if there's any other way I can help!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/523#issuecomment-633091638:74,learn,learning,74,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/523#issuecomment-633091638,2,['learn'],['learning']
Usability,"Hi @SeBaBInf,. Thanks for reporting this. I'm pinging @k3yavi for his thoughts here. Two quick thoughts though -- the first is that the abstract for this paper mentions 5' tagged end sequencing, thus it might be necessary to swap the reads so that the biological and technical reads are in the expected order. Second, it's likely also worth seeing if and how the data look different if you process with alevin-fry rather than alevin. I'll let @k3yavi provide more detailed guidance here. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/763#issuecomment-1073004001:473,guid,guidance,473,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/763#issuecomment-1073004001,2,['guid'],['guidance']
Usability,"Hi @TSL-RamKrishna,. Thanks for the report. However, it's not exactly clear to me how this is related specifically to salmon. Generally, if the libm you have is _newer_ than the one salmon was built with, you should be OK. So, one option would be to simply remove the `libm.so.6` from the salmon `lib` directory and see what happens.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/290#issuecomment-424523688:70,clear,clear,70,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/290#issuecomment-424523688,4,"['clear', 'simpl']","['clear', 'simply']"
Usability,"Hi @Tima-Ze,. This should not cause any trouble with downstream analysis. The indexing procedure is simply informing you that these transcripts (about which you are being warned) are shorter than the seed length used for alignment. This means that it simply won't be possible for fragments to align to these transcripts, and so they will always have a 0 abundance in the resulting `quant.sf` files. This isn't a problem, as these transcripts are too short to be measured via RNA-seq anyway. The indexing messages just let you know this in advance. You can safely ignore these warnings for your downstream analysis.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/214#issuecomment-751366278:100,simpl,simply,100,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/214#issuecomment-751366278,4,['simpl'],['simply']
Usability,"Hi @Tima-Ze,. Yes, salmon can be used to quantify these reads, but the results will depend (somewhat) on the `--fldMean` and `--fldSD` flags that are used. It's important to note that this is not a unique characteristic of salmon, and any transcript-level quantification tool using a probabilistic model (e.g. RSEM, eXpress, BitSeq, etc.) have the same requirement. That is, the fragment length distribution should be known so that _effective_ transcript lengths can be estimated, which have an effect on fragment assignment probabilities. If the wrong fragment length distribution is specified, then the _effective_ transcript lengths will be off and this can affect the assignment of some fragments. This is only a requirement with single-end reads, since with paired-end reads the fragment length distribution is learned from the data. Further, the inference procedure is somewhat robust to these choices (small changes in fld mean and sd don't generally lead to drastically different results). If you have access to the BioAnalyzer results for the sequencing run, those can give information about the fragment length distribution (even in a single end experiment). If not, you can proceed with the default values. Even if they don't exactly match the true distribution in the single-end sample, at least the same values will be applied in all samples and so, ideally, most results of misspecification will wash out in subsequent differential analysis. . Finally, it's worth noting that the same restriction holds in both alignment-based and mapping-based modes. This is because in neither mode do single-end fragments provide sufficient information to estimate the fragment length distribution from the data. We only know where one end of a fragment mapped and cannot infer where the other end would be. This is not an alignment versus mapping (versus selective-alignment) issue, but rather is fundamental to having only observed one side of the entire fragment generated during fragmentation and ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/127#issuecomment-750920243:816,learn,learned,816,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/127#issuecomment-750920243,2,['learn'],['learned']
Usability,"Hi @Vivianstats ,. Thanks for reaching out. You can certainly dump the CB and UMI tagged Bam file, however, the problem is we can't mark a subset of reads as deduplicated. Alevin's algorithm does not deduplicate UMI at the read level instead we deduplicate at the level of an arboreacence. Basically, the problems is it's not clear which alignment / read should be marked as primary because of following reasons:. 1.) Alevin does fractional assignment of ambiguous reads.; 2.) If there are multiple equally good alignment of a read which alignment should be marked primary for the deduplication ? ; 3.) Even in the UMI tools world, a UMI from a single gene can come from a range of genomic loci, because of the random process of sequence fragmentation. I am not quite sure what UMI tools does, I can check with the developers, but I feel randomly marking one among multiple equally good choice can hide the full picture. Hope it helps. @rob-p feel free to add if I missed something.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/574#issuecomment-710738799:326,clear,clear,326,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/574#issuecomment-710738799,2,['clear'],['clear']
Usability,"Hi @Zhuxitong, . You can easily change the k-mer length used for indexing by passing the desired value to the `-k` option of the `index` command. So, that part isn't technically a problem. The bigger issue is that Ribo-seq data doesn't follow the same basic model as RNA-seq data. That is, the coverage variation in RNA-seq is more often an issue to be corrected (e.g. evidence of bias during library prep / sequencing), whereas it is integral to the interpretation of Ribo-seq data (i.e. the peaks are primary features of interest). Therefore, it's not clear to me that using any RNA-seq abundance estimation software on Ribo-seq data ""off-the-shelf"" is conceptually the right thing to do, though you are welcome to experiment with it. However, there is some interesting work on combining transcript abundance profiles with Ribo-seq data to infer isoform-level information in the Ribo-seq data. For example, [this recent pre-print](https://www.biorxiv.org/content/10.1101/582031v3) provides a pipeline for this.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/454#issuecomment-557558554:554,clear,clear,554,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/454#issuecomment-557558554,2,['clear'],['clear']
Usability,"Hi @adamfreedman,. I think this is just conda being very very very slow. For me, the below command, replacing `mamba` with `conda` (but keeping the switched channel order) eventually did work, but took several minutes to ""collect package metadata"". However, the following works fine for me (and finishes in ~1 minute):. ```; mamba create -n salmon -c conda-forge -c bioconda salmon=1.10.2; ```. Can you use the `mamba` resolver in your environment? Conda has become hardly usable over the years, but `mamba` works quite well as a fast replacement. I'll also note that I swapped the order of `conda-forge` and `bioconda` as the docs specify that `bioconda` should preferably come last in the list of channels. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/895#issuecomment-1784137337:473,usab,usable,473,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/895#issuecomment-1784137337,2,['usab'],['usable']
Usability,"Hi @aedavids,. Thanks for catching that this is undocumented! This means that the mapping type was determined as mapping to a _decoy_ sequence. When we added this output into the code, the documentation wasn't updated accordingly. We'll update the documentation. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/657#issuecomment-833857753:48,undo,undocumented,48,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/657#issuecomment-833857753,2,['undo'],['undocumented']
Usability,"Hi @afkoeppel,. Thanks for reporting this. While I completely understand that this is not the desired behavior, it is the expected behavior. That is, when collapsing duplicates during indexing, the invariant that is maintained is that all sequence-identical transcripts will be ""collapsed"" and a single representative maintained. In practice (i.e. in implementation), the transcript that is maintained is the first one encountered. In the short-term, your suggested solution is the best. That is you can simply remove the non-canonical transcripts from the input fasta file. Alternatively, you could re-order the entries in the file so that the canonical transcript occurs first. In the longer term, I'd be happy to implement a de-duplication procedure that is more aware of the semantics of the transcript names. However, I'd want to figure out how to do this that is agnostic to where the transcripts are coming from (i.e. that doesn't work only for Gencode, human etc., and that does something sensible when the transcripts are e.g. _de novo_ assembled contigs). On that front, I'm completely open to suggestions. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/249#issuecomment-404220623:504,simpl,simply,504,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/249#issuecomment-404220623,2,['simpl'],['simply']
Usability,"Hi @amaer ,. Yes, exactly. The input is a simple TSV where the first column is transcript names and the second column is the gene names (note, that the keys in column 1 are unique, but that many transcripts can map to the same gene). This is the same type of input accepted by tximport to do the transcript => gene mapping. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/198#issuecomment-366005924:42,simpl,simple,42,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/198#issuecomment-366005924,2,['simpl'],['simple']
Usability,"Hi @amitpande74 ,. May be you are already aware of this but just to make it clear, the idea behind decoy indexing is to ""exclude"" those sequences from the transcriptome quantification and that's why you don't see the indexed transposon sequence in the salmon output. The motivation behind such indexing is to remove false mapping reads i.e. exclude RNA-seq reads from the quantification pipelines which maps better to the decoy sequences compared to the provided transcriptome. . I hope that clarifies your doubt and if you wan't to quantify GFP sequences then you have to concatenate them with the transcriptome sequence ""not"" the decoy sequence, although I just wanted to give you heads up that this analysis goes into an unexplored territory as we personally have not explored such use cases. Unless Rob have more thoughts on it.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/737#issuecomment-1024668469:76,clear,clear,76,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/737#issuecomment-1024668469,2,['clear'],['clear']
Usability,"Hi @apredeus,. In short, what you explain in the first paragraph is right and is the expected behavior. However, to simplify the parsing algorithm (i.e. to ensure that BAM input can be parsed in bounded memory), both `salmon` and `RSEM` require that all of the alignments for a given read are adjacent within the input BAM file. If this is violated, they will be treated as different reads. In other words, if you have something like:. ```; read1:aln1; read1:aln2; read1:aln3; read2:aln1; read2:aln2; read2:aln3; ```. then in total, 2 ""reads"" worth of mass will be assigned (probabilistically across the targets). However, if you have. ```; read1:aln1; read1:aln2; read2:aln1; read1:aln3; read2:aln2; read2:aln3; ```. Then there will be *4* total reads assigned. Each time the query name (read name modulo 1/2 of a paired-end read) changes in the BAM stream, it is assumed to be a new read, and its alignments are dealt with separately. Both Bowtie2 and STAR (when projecting genomic alignments to the transcriptome) will follow this convention by default, but I'm not certain the same is true for other aligners. Again, this restriction is present in both `RSEM` and `salmon`, and it's an optimization that is made because otherwise there can be unbounded distance in the worst case between the different alignments for a read and so the parser would either have to hold all alignments in memory (which is very bad), or make many passes over the input BAM (which is also very bad) to perform quantification. Let me know if you think this may be the issue in your case. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/844#issuecomment-1518485720:116,simpl,simplify,116,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/844#issuecomment-1518485720,2,['simpl'],['simplify']
Usability,"Hi @asher1234,. Thanks. I'll try and grab the data now. The 0.12.0 log here is quite informative. It looks like the problem is that none of the reads are making through the likelihood filter, which explains why you see the output you do. I'll take a look and see if there is a clear reason why. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/346#issuecomment-469412869:277,clear,clear,277,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/346#issuecomment-469412869,2,['clear'],['clear']
Usability,"Hi @atasub,. It's hard to say exactly if this mapping rate is much lower than expected or not. Many RNA-seq experiments do end up with a mapping rate of 65-70%. One thing that might contribute to a lower mapping rate would be short reads relative to the minimum required exact match length (default of 31). If your reads are relatively short (after trimming, which it looks like you are doing here) --- say ~50bp, then one might try lowering the k value with which the index is built. This will allow more sensitive mapping. However, the other thing to try is simply to align one of these samples to the genome with a tool like STAR or HISAT2 and look at their mapping rate _to known features_. If it's similar, then the other reads could be accounted for by e.g. intron retention or even contamination. Finally, @vals has an [*excellent* series of blog posts](http://www.nxn.se/valent/2017/9/18/low-mapping-rate-5-human-dna-contamination) on investigating and addressing low mapping rates (albeit in single-cell data) that you might find useful. Let me know what you find.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/160#issuecomment-334762498:560,simpl,simply,560,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/160#issuecomment-334762498,2,['simpl'],['simply']
Usability,"Hi @biobenkj,. Congratulations on publishing your new single-cell technology, and thanks for your interest in adding support to alevin(fry). . After adding the functionality to provide custom geometry for UMI and cellular barcode sequence through command line flags like `--umi-geometry` and `--barcode-geometry,` our general guidelines have been shifted against adding technology-specific command line flags to the alevin codebase. Rob might have more comments on that. Regarding the 0-length cell barcode, I recommend first trying to add the dummy CB before the UMI sequence as a test case. If it helps with your use case, we can discuss adding the ; 0-length cellular barcode functionality to the main codebase. Previously, paired-end read processing was not possible under the alevin framework, but with the publication of alevin-fry, the support for paired-end read (I think) has been added. @DongzeHE and @Gaura might have better thoughts on this.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/805#issuecomment-1282467290:326,guid,guidelines,326,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/805#issuecomment-1282467290,2,['guid'],['guidelines']
Usability,"Hi @bsipos,. This is caused primarily by salmon's desire to apply an error model (by default) to the CIGAR strings. For secondary alignments, as you note, minmap2 doesn't write the read string, and so when salmon is trying to score the alignments under the error model, it can't find the relevant characters in the read. In general, it's not clear to me if one would actually want to apply the error model (designed primarily for short reads) when quantifying long reads (this is something we are currently testing in the lab). For the time being, I'd probably recommend disabling the error model when quantifying alignments from long reads (`--noErrorModel`). In that case, the errors should hopefully go away. Please let me know, and we'll be sure to keep you updated on best practices for long reads as we figure things out.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/289#issuecomment-420295665:342,clear,clear,342,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/289#issuecomment-420295665,2,['clear'],['clear']
Usability,"Hi @bzmby ,. I am sure you are aware of this but just wanted to clear that salmon is primarily designed for transcriptome quantification.; Ideally, there should not be a problem with indexing genome, also from the log you shared it looks like a warning. ; Having said that if you will index the genome then at the end of the day you will get quantification of the chromosomes, is that what you wan't ?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/741#issuecomment-1024655023:64,clear,clear,64,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/741#issuecomment-1024655023,2,['clear'],['clear']
Usability,"Hi @citron96,. The patch is quite simple and i have verified it and it works for salmon-1.1.0 version that i compiled. Here is the patch content:. --- salmon-1.1.0/CMakeLists.txt.orig 2020-03-24 08:50:22.681000000 -0700; +++ salmon-1.1.0/CMakeLists.txt 2020-03-24 08:51:41.786000000 -0700; @@ -596,7 +596,7 @@; message(""Build system will fetch and build Intel Threading Building Blocks""); message(""==================================================================""); # These are useful for the custom install step we'll do later; -set(TBB_SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/tbb-2019_U8); +set(TBB_SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/oneTBB-2019_U8); set(TBB_INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install). if(""${TBB_COMPILER}"" STREQUAL ""gcc""); @@ -610,9 +610,9 @@; externalproject_add(libtbb; DOWNLOAD_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external; DOWNLOAD_COMMAND curl -k -L https://github.com/intel/tbb/archive/2019_U8.tar.gz -o tbb-2019_U8.tgz &&; - ${SHASUM} 7b1fd8caea14be72ae4175896510bf99c809cd7031306a1917565e6de7382fba tbb-2019_U8.tgz &&; + ${SHASUM} 6b540118cbc79f9cbc06a35033c18156c21b84ab7b6cf56d773b168ad2b68566 tbb-2019_U8.tgz &&; tar -xzvf tbb-2019_U8.tgz; - SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/tbb-2019_U8; + SOURCE_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/oneTBB-2019_U8; INSTALL_DIR ${CMAKE_CURRENT_SOURCE_DIR}/external/install; PATCH_COMMAND ""${TBB_PATCH_STEP}""; CONFIGURE_COMMAND """". Rob, ; I understand that you don't want to push changes to older releases but perhaps one; can issue a README/NOTE for all prior releases that are affected by this. The explanation of; what changed will allow people to create their own patches for their specific releases. Regards,; Nadya",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/497#issuecomment-603916394:34,simpl,simple,34,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/497#issuecomment-603916394,2,['simpl'],['simple']
Usability,"Hi @come-raczy,. Thanks for reporting this, it is addressed now in commit efe26b1ca2ced305256357e3b2e95f0e51e3376d. While the function that returns this value is called in two places `normalizeAlphas()` and `writeAbundances()`, the latter of these is actually deprecated and so is not used (we should clean up that code). So, while this value should clearly be initialized, the only potential effect here is through `normalizeAlphas()`, is called before the optimization, and which modifies the alphas that will be used for setting the _initial conditions_ of the VBEM. Therefore, the effect is likely to be limited since, even if the value of `totalCount_` was incorrectly initialized, it should only affect the initialization condition of the optimization. Thank you again for the detailed bug report, and the patch! This is now fixed in develop and will be in the next release.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/355#issuecomment-480004146:350,clear,clearly,350,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/355#issuecomment-480004146,2,['clear'],['clearly']
Usability,"Hi @curtisd0886,. So, issues relevant to processing this data should be resolved in the new release (v1.5.1). However, for technical reasons in the way different modes are handled internally, we had to simplify the mixing and matching of certain different options. Specifically, one can no longer use the `--citeseq` flag in conjunction with the custom geometry flags. So, if you have non-standard `--citeseq` geometry, the recommendation is to just use the new barcode specification format (e.g. `--umi-geometry`, `--bc-geometry` and `--read-geometry`), along with a couple of other flags. Specifically, you should explicitly provide `--keepCBFraction 1.0` and a tgMap file (even if it is just a trivial one mapping each feature to itself). @k3yavi can elaborate further if I've overlooked anything. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/670#issuecomment-860704025:202,simpl,simplify,202,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/670#issuecomment-860704025,2,['simpl'],['simplify']
Usability,"Hi @danphillips28,. Oh ok! Now I see what's going on. We really should be more stringent about catching the issue here. . The problem is that using k > 32 is not permitted in the current implementation. This is because we use a 64-bit machine word to encode k-mers, and you can only fit up to 32 nucleotides in a word. In reality, anything > 31 is not allowed, since the k-mer should be odd so that the orientation can be inferred from the canonical (lexicographically smaller) version. There is nothing fundamentally problematic about using a larger k, it's just that it would require some modifications throughout the codebase we've not yet made. Further, we've not really found cases where having such large k really help. Specifically, the larger k, the fewer errors you need to render a read unmappable (if there is an error in every k-mer, you can't map the read). On the other hand, selective alignment will do a good job of filtering out poor matches where there is insufficient similarity between the read and reference. Thus, we set a default value of k=31. You can go lower (with any odd value), but it's not currently possible to go higher. I hope this clears things up, and thanks for bringing this to our attention. I think the indexer should bail with an error in this case, until (and unless) this feature is supported. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/632#issuecomment-779418628:1165,clear,clears,1165,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/632#issuecomment-779418628,2,['clear'],['clears']
Usability,"Hi @davidaknowles,. Assuming that the total size of all cell barcodes doesn't exceed 32 nucleotides, then it should be possible to simply specify them using a custom geometry string. Of course for that to work, we need to know where the 4th barcode is located, so that we can generate the correct custom geometry string to extract it. I'll ping @DongzeHE and @k3yavi here to see if either of them are familiar with this chemistry already. As always, I'd also suggest running this through `alevin-fry` (or using the `simpleaf` wrapper). While we continue to support `alevin`, `alevin-fry` (largely interfaced by `simpleaf`) is where most of our development effort is currently going, and hopefully we can make the user experience there as smooth and easy as possible!. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/874#issuecomment-1732428996:131,simpl,simply,131,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/874#issuecomment-1732428996,8,"['simpl', 'user experience']","['simpleaf', 'simply', 'user experience']"
Usability,"Hi @davidaknowles,. Indeed — the barcode extraction will happen either in `salmon alevin` or, if you are using the new `piscem` module for mapping prior to quantification (both are exposed in the `simpleaf` wrapper tool to simplify single-cell processing with `alevin-fry`), then it will happen there. We have a new very general and much more capable module in the works that will be able to handle all manners of single-cell geometry, but nothing about the Parse library seems beyond the capabilities of the current geometry processing code. If you share some reads, we can also try and take a look and figure out where the last BC resides. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/874#issuecomment-1733872331:197,simpl,simpleaf,197,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/874#issuecomment-1733872331,4,['simpl'],"['simpleaf', 'simplify']"
Usability,"Hi @davidnboone and @mcfwoodruff,. So, I should have mentioned that if you want to use the pre-compiled binary I provide, you have to put the `lib` folder in your path. One way to accomplish this is to run salmon as follows:. ```; DYLD_FALLBACK_LIBRARY_PATH=<path_to_salmon_folder>/lib <path_to_salmon_folder>/bin/salmon ; ```; Where `<path_to_salmon_folder>` is simply the top-level directory where you decompressed salmon. You can, of course, make a little wrapper script to make launching it less ugly.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/295#issuecomment-421417111:363,simpl,simply,363,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/295#issuecomment-421417111,2,['simpl'],['simply']
Usability,"Hi @deevdevil88,. The challenges I faced with this issue made me switch over to `kallisto` which has some nice advantages as far as speed. I didn't see any obvious affects on quality for my samples although I did have to re-implement some of the auto-detection that `alevin` and `salmon` do for you. . I personally observed some strange behaviour with Soupx - visually apparent differences in gene expression between samples that at the time I felt were artefactual of the adjustment by Soupx. I eventually rolled-my-own strategy where I omitted ambient outlier genes from differential expression. Ambient outliers were defined by taking droplets with UMI counts <10 with using a boxplot in R to define outliers. The osca.bioconductor.org [recommendations](https://osca.bioconductor.org/multi-sample-comparisons.html#ambient-problems) ended up being very similar. They also describe some of the pitfalls of adjusting counts. Best of luck! Always appreciative of all the great work and responsiveness of @k3yavi and the team!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/538#issuecomment-646058370:985,responsiv,responsiveness,985,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/538#issuecomment-646058370,2,['responsiv'],['responsiveness']
Usability,"Hi @demis001,. I see. There is only one behavior built in (i.e., report the transcript as it's own gene). You can easily filter the gene -level quantification file to get rid of transcripts like this though. The easiest way would be something like:. ```; > cat <(head -1 quant.genes.sf) <(grep ""ENSG*"" quant.genes.sf) > quant.genes.filtered.sf; ```; That is, simply filter the `quant.genes.sf` file for any line that matches `ENSG`, leaving the rest behind (and adding the header line). --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/122#issuecomment-283477075:359,simpl,simply,359,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/122#issuecomment-283477075,2,['simpl'],['simply']
Usability,"Hi @evofish,. Unless you have a particular reason to build from source, it is much easier to install salmon via bioconda, or to simply download our pre-compiled executable from the releases page. Nonetheless, your error stems from not having the `curl` program installed, which is used by the build system to automatically fetch all dependencies.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/331#issuecomment-447689917:128,simpl,simply,128,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/331#issuecomment-447689917,2,['simpl'],['simply']
Usability,"Hi @francicco ,. Thanks for sharing the data. I'm able to re-create the problem and am trying to debug it now. The reason you see this behavior in 0.10.1 but not in 0.8.1 is because in 0.10.1 the error model is enabled by default, while it is not in 0.8.1. If you run the newest salmon with `--noErrorModel` (the default in 0.8.1), your sample runs to completion. However, using the error model helps (which is why I made it the default), so I'm trying to debug what's happening there. I'll keep you posted. One more point worth mentioning. I noticed you are passing a coordinate sorted BAM file. For quantification with salmon, you really should not be passing a coordinate sorted BAM. This is because Salmon expects the alignments to appear in a random order, which is important for how the streaming stochastic variational algorithm learns the auxiliary parameters. Sorting by coordinates biases the models towards the isoforms that appear earliest in the BAM file.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/231#issuecomment-394764686:836,learn,learns,836,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/231#issuecomment-394764686,2,['learn'],['learns']
Usability,"Hi @francicco,. It looks like the problem is that the compiler being used is newer than the linker being used to link bzip2 here (see e.g. [this](https://stackoverflow.com/questions/46058050/unable-to-compile-unrecognized-relocation)). You should try and make sure the appropriate (newer) linker is present in your path before the older one. Another option, of course, would be to simply install salmon through Bioconda, which will take care of such issues for you. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/231#issuecomment-394164828:381,simpl,simply,381,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/231#issuecomment-394164828,2,['simpl'],['simply']
Usability,"Hi @gresteban ,. Thanks for the kind words. I'm working on improving the documentation even more for v0.7.0, which should land soon. Regarding your question, what you're seeing is expected behavior. That is, for the vast majority of transcripts, Salmon will simply do the ""right thing"" regardless of the library type. This is because the library type is used as a ""soft"" rather than a ""hard"" filter when determining where a read may originate from (i.e. Orientations other than the expected type have a probability orders of magnitude smaller than the expected type, but still non-zero). Thus, if the only mapping for a read disagrees with the expected type, it will still be used. There is a way to modify this behavior, but since stranded library prep is imperfect, the default behavior is the most reasonable for most situations. The reason that you'll see consistency in most cases, regardless of the library type, is as follows. Imagine that I have a read that maps to transcript 1 in the forward orientation and transcript 2 in the reverse orientation. Further, imagine I have a stranded library, and I expect all reads to map in the reverse orientation. If the mapping to transcript 1 is ""spurious"", there are unlikely to be many othe reads mapping to that transcript in this manner, while we would expect other reads to map to transcript 2 in the prescribed manner. Since Salmon considers all of the reads in its probabilistic model when deciding how each read should be allocated, the fact that many reads map to transcript 2 will increase its abundance and, likewise, increase the probability that we assign this read to transcript 2 --- that is, the other mappings will help us make the right choice, regardless of the fact that we neglected to assign a stranded library type. That said, there are situations where the library type makes a difference. This is most often for a few transcripts that are very sequence similar (e.g. Paralogs that happen to be on opposite strands). In this cas",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/67#issuecomment-238090033:258,simpl,simply,258,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/67#issuecomment-238090033,2,['simpl'],['simply']
Usability,"Hi @gringer,. Yes, we can add a section for this in the docs. It will replace the old way for specifying geometry soon, as its just easier and more flexible. We talk about it in the 1.4.0 release notes. I copy the relevant info below (@k3yavi pulled for the 1-based indexing and won out ... this time):. generic barcode / umi / read geometry syntax : Alevin learned to support a generic syntax to specify the read sequence that should be used for barcodes, UMIs and the read sequence. The syntax allows one to specify how the pattern corresponding to the barcode, UMI, and read sequence should be pieced together, and the syntax is meant to be intuitive and general. For example, one can specify the 10Xv2 geometry in the following manner using the generic syntax:. --read-geometry 2[1-end] --bc-geometry 1[1-16] --umi-geometry 1[17-26]. This specifies that the ""sequence"" read (the biological sequence to be aligned) comes from read 2, and it spans from the first index 1 (this syntax used 1-based indexing) until the end of the read. Likewise, the barcode derives from read 1 and occupies positions 1-16, and the UMI comes from read 1 and occupies positions 17-26. The syntax can specify multiple ranges, and they will simply be concatenated together to produce the string. For example, one could specify --bc-geometry 1[1-8,16-23] to designate that the barcode should be taken from the substring in positions 1-8 of read 1 followed by the substring in positions 16-23 of read 1. It is even possible to have the string pieced together across both reads, but that functionality is only available if you are running with --rad or --sketch and preparing a RAD file for alevin-fry. If you are running classic alevin, the barcode must reside on a single read. The robust parsing of the flexible geometry syntax is made possible by the cpp-peglib project.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/445#issuecomment-777884823:358,learn,learned,358,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/445#issuecomment-777884823,6,"['intuit', 'learn', 'simpl']","['intuitive', 'learned', 'simply']"
Usability,"Hi @guidohooiveld, . Regarding your questions:. (1) The motivation behind asking users to use Bioconda to install the binary is to limit the number of variables we may encounter when someone is reporting a bug --- i.e. if there are fewer distribution channels there is less maintenance overhead. Nonetheless, as you can see, I've had to make the binary available anyway, because it was the only way some people could easily get the program. Therefore, I think I'll start attaching binaries to releases again. (2) Yes, though this functionality is not part of Salmon itself. I *highly* recommend the [MultiQC](http://multiqc.info/) tool. MultiQC has a salmon module, which will parse all of the salmon log files in an experiment directory and produce a report. This report will contain the mapping percentages for all of the samples extracted from the salmon logs (and will color them nicely). It will also produce other QC information from the salmon runs. We are currently working on an improved multi-QC module, which will also provide summaries for things like GC / seq bias by analyzing the models that salmon learns, but this module isn't yet complete. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/252#issuecomment-405442271:4,guid,guidohooiveld,4,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/252#issuecomment-405442271,4,"['guid', 'learn']","['guidohooiveld', 'learns']"
Usability,"Hi @guidohooiveld,. Yes, the original cutoff was set to accomodate TITIN, which, at the time, was the longest human transcript. Note, this warning doesn't prevent the transcript from being indexed, it just notifies the user its exceptionally long. I think updating the warning threshold makes sense so that gencode indexes cleanly in this regard. We'll update this. Thanks for the report!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/591#issuecomment-733736492:4,guid,guidohooiveld,4,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/591#issuecomment-733736492,2,['guid'],['guidohooiveld']
Usability,"Hi @jan-g1,. The length of a feature is used during inference to determine the likelihood that multimapping reads should be allocated to different targets. You're describing what is essentially a simplified model where P(f | t) (i.e., the probability of a fragment given a transcript) is independent of length(t). There's currently no option to disable length normalization completely in Salmon, and you can't ""de-normalize"" by simply multiplying by a factor because those weights are considered during each and every round of the EM (or VBEM) algorithm. However, supporting this should actually be very straight-forward. We simply assign a uniform and identical length to all transcripts for the purpose of inference. I can add such a flag in the next release, though it will initially have to be incompatible with bias correction (since it's not clear right now how the biases for which we account interact with this type of sequencing). Also, it would be possible to run salmon with `--dumpEq`, and then to have a little script / tool that simply re-runs the EM, but without different length factors, using the equivalence class file. I might be able to hack something like that together on short notice if you'd be interested in testing it out. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/108#issuecomment-264659889:196,simpl,simplified,196,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/108#issuecomment-264659889,10,"['clear', 'simpl']","['clear', 'simplified', 'simply']"
Usability,"Hi @jashapiro,. So there are definitely a few things going on here. The first is that you correctly diagnosed the missing cmd_info.json information when `alevin` is run in RAD mode. That was simply an oversight, and there is no reason that file shouldn't have been written. Second, there is also useful information that belongs in `meta_info.json` in the `aux_info` directory (like the SHA hash of the reference sequences); that was also missing but has now been added.; ; In addition to salmon's `alevin` command, each step of `alevin-fry` also writes some useful metadata when it executes. For example, there is a json file written by the `generate-permit-list` step, one written by the `collate` step, and one written by the `quant` step. We've never run into the problem of the output of `alevin-fry` overwriting the output of `alevin` because we use a directory structure where the output quantifications reside in a separate directory from the input RAD file. However, I can now see that if you're writing the quants in the same place as the input, then there will be a conflict in the file names, and the existing files will be overwritten with the new ones. I agree that both tools output useful information. I'm a *bit* ambivalent about assuming the salmon-generated files exist, and merging them into one output file, as I think there might be cases where those files aren't present and `alevin-fry` should still run properly since it doesn't require them to perform it's processing. One option would be to rename the `alevin-fry` output files to prefix/postfix them so they don't collide with the salmon files even if they live in the same directory. Then, one could (now or later) write a small command to merge the relevant json files into a unified output if that would be more convenient downstream. Let me know your thoughts. Thanks!; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/688#issuecomment-883497669:191,simpl,simply,191,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/688#issuecomment-883497669,2,['simpl'],['simply']
Usability,"Hi @jasonvrogers,. First of all thank you so much for sharing this thorough analysis with us, it was very clear and helpful for understanding the details of the problem you are referring to. Secondly, I apologize for the long time it took me to get back at you. I would like you to know that we have been and are still working on possible solutions for addressing this problem, and here I would like to share some updates with you. . About the success cases, it was nice to know that the current model of Salmon with length correction works pretty well in recovering the right estimates for those ""easier"" cases where one transcript is fully contained in another one. Turning off the length correction, tells the Salmon model not to consider the effective length of each transcript for computing the conditional probabilities of originating a fragment from a transcript. So, for the RNA-seq data there is no reason to turn off this term of the model, and we highly recommend not to use that flag for the bulk RNA-seq abundance estimation with Salmon. Looking more carefully at the 2nd case you have posted as the failure case, it is interesting to see that there is a very nice visual evidence on the super transcript that the long transcript might not be expressed at all. I am referring to the zero coverage regions on the Super Transcript between the regions corresponding to the smaller transcripts, e. g., between POF1 and EMC1. So, we tried a solution that inspects the coverage profile of all transcripts and calculates the probability of observing a zero coverage region on each transcript. If this probability is too low, this would be counted as an evidence for a transcript not being expressed at all. This approach seems to be working fine on this example that you have shared here. however, one problem was that there were considerable number of reads in the sample that were uniquely mapping only to the Super Transcript and turning of the expression of that transcript would result in t",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-666512703:106,clear,clear,106,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-666512703,2,['clear'],['clear']
Usability,"Hi @jckhearn,. The documentation could definitely be more clear, so let me try and clarify here and make a note to clean up the documentation more as well. I'll answer in reverse order:. > Given the above command should I go back to a non-decoy aware transcriptome?. No. What the statement in the documentation means to convey is that if you are using the basic quasi-mapping algorithm (not selective-alignment as enabled by `--validateMappings`, `--mimicBT2` or `--mimicStrictBT2`), then you should not be using a decoy-aware transcriptome. We have not tested the effect of decoys on the basic quasi-mapping approach, and though that may be supported in the future, it is not right now. However, if you are using any flavor of selective-alignment, then please _do_ use the decoy-aware transcriptome. . Regarding ""combining"" `--validateMappings`, `--mimicBT2` and `--mimicStrictBT2`, this is not possible. That is, you should view `--mimicBT2` and `--mimicStrictBT2` as ""meta-flags"" that enable selective-alignment and also set a few other options that are meant to mimic the BT2 behavior more closely. We generally do _not_ recommend `--mimicStrictBT2`, and so the main choice is between simply using `--validateMappings` vs. `--mimicBT2`. The main differences here are that `--mimicBT2` sets slightly more sensitive parameters to find alignments, but is also stricter in what it reports. The biggest differences is that `--validateMappings` will allow orphaned mappings (where one end of a paired-end fragment aligns but the mate doesn't), while `--mimicBT2` will not allow such mappings. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/399#issuecomment-511884297:58,clear,clear,58,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/399#issuecomment-511884297,4,"['clear', 'simpl']","['clear', 'simply']"
Usability,"Hi @jeremymsimon — @Gaura is going to take a look at unfiltered permit listing and will share those results here later. Regarding frameshift errors, I think that's certainly out of scope for the alevin -> fry phase, but that type of thing *could* be in scope for `splitp`. Basically, my logic / reasoning is this: I'd like to avoid further complicating the already immense salmon/alevin codebase with special implementations handling problems outside of their core function (e.g. mapping reads to the reference efficiently and quantifying UMIs/barcode). Since most protocols (and the most common) have quite simple barcode geometry, it makes sense for this code to live there. I'm fully supportive of enabling support for more complex barcode geometries and preprocessing requirements if there are folks whom it would help, but it feels like that essential complexity belongs upstream of alevin / fry, so that by the time the reads get to alevin, it can assume a straightforward geometry. So TLDR : I think we'd be willing to investigate what is required to address potential frameshift errors, and how much of a difference that makes, but I think that analysis and eventual implementation (if we decide it's worth it), belongs in `splitp`.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-988030837:608,simpl,simple,608,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-988030837,2,['simpl'],['simple']
Usability,"Hi @jeremymsimon,. I've discussed the support for SPLiT-seq/ParseBio with @Gaura in some depth. Honestly, I think the cleanest solution right now is just to have a more streamlined (and streaming) way to match / replace the random hexamers upstream of alevin-fry. By my understanding, if we can simply replace barcode 1 appropriately (as your Perl script currently does), everything should work downstream in alevin/alevin-fry.; ; To that end, I've thrown together a small rust program based on your Perl script. Currently that lives [here](https://github.com/COMBINE-lab/splitp). It reads the same basic parameters as the Perl script, and writes its output to stdout so that it can be used with named pipes. For example, something like:; ; ```; <normal salmon command> -1 read_file_1.fq -2 <(splitp --read-file read_file_2.fq --bc-map bcSharing_example.txt --start 79 --end 86 --one-hamming); ```. which will transform the second fastq file and stream the transformed reads out which can then be read by alevin-fry. One important thing to note is that while *alevin* requires the input reads to be a real file (i.e. you can't stream reads in because it does 2 passes), if you are mapping these reads for processing with *alevin-fry* you can use the process substitution trick above. As you hinted, this program works considerably faster than the Perl script. For example, for the first 10,000,000 reads in `SRR6750042`, the Perl script took 2m 48s to transform the reads and `splitp` took ~6s (if the output wasn't being written to a file on disk it took <4s). This should generally be fast enough to not be a speed bottleneck. So, perhaps the next step is to try to help you walk through this approach with a test dataset (and ideally using alevin-fry) to see if things are turning out as expected?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-961598108:295,simpl,simply,295,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-961598108,2,['simpl'],['simply']
Usability,"Hi @jonahcullen,. No need to apologize! We should better document these numbers. Basically, the elements you point out : `num_decoy_fragments`, `num_dovetail_fragments` and `num_fragments_filtered_vm` are the fragments where alignment was *attempted* but subsequently failed. In these cases because (1) the read best mapped to a decoy, (2) the best alignment was dovetailed or (3) no alignment passed the alignment score threshold. In addition to this, fragments can fail to align when no sufficiently good seed is found such that alignment is not even attempted. This can happen e.g. if no 31-mer from the read matches the transcriptome/genome, or if the only matching 31-mers are degenerate in terms of their frequency (appear thousands of times and are therefore not useful for alignment). So, the most likely occurrence here is that these ~1M fragments simply had no alignment attempted. Let me know if this answers your question. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/782#issuecomment-1142131363:857,simpl,simply,857,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/782#issuecomment-1142131363,2,['simpl'],['simply']
Usability,"Hi @junaruga --- so, I cherry picked your changes into develop (thanks again!) and did some more exploring. It looks like `jemalloc` is to blame for the unitTests hanging on the travis server. I modified `unitTests` to not link against `jemalloc` (but still linked salmon against it), and everything passes. I did see some potentially related issues on the `jemalloc` github issues, but it's not clear _exactly_ what is causing this behavior.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/276#issuecomment-416348427:396,clear,clear,396,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/276#issuecomment-416348427,2,['clear'],['clear']
Usability,"Hi @juugii ,; Thanks a lot for starting an interesting discussion related to Alevin. It does sound really interesting. If I may, I'd like to ask a couple of questions before going deeper into your questions. ; * When you say you try subsampling the `Fastq`, did you sample randomly across the full `Fastq` or chose the top X reads. One can imagine that if you simply, sample just the top X reads and the `Fastq` has not been generated in random order then a certain subset of CB will get all the reads and you'd still observe the coverage bias in them. I'd suggest can you please try subsampling randomly across the full `Fastq` if you haven't tried that already.; * `re: subsampling coefficient:` If you are looking for per-CB level mapping rate for your sample that would be very easy to calculate, although getting one number for the full sample might be little tricky since the mapping rate might have large variance across the sample, but it would be an interesting plot to generate, do let us know how it looks in your case.; If you run Alevin with `--dumpFeatures` flag, alevin will generate a file `featureDump.txt`, whose first column will be the per CB level mapping rate i.e. `#mapped reads/#raw reads`. If you wan't absolute values for per-CB reads and mapped reads, it should be in the file `filtered_cb_frequency.txt` and `mappedUMI.txt` respectively.; * `re: cellranger subsampling:` Correct me if I am wrong, when you say cellranger subsampling, do you mean the `cellranger aggregate` pipeline? It's possible you are talking about some other step which I am not aware of but if it's `aggregate` then I think it happens downstream of all the quantification. Indeed coverage bias correction is an important part of the aggregation step but in general it's not the only one and that's why we recommend using the `Seurat` package downstream of the Alevin quantified matrices. We will be more than happy to write a tutorial on, ""how to perform batch correction downstream of Alevin"" but in ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/305#issuecomment-433169468:360,simpl,simply,360,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/305#issuecomment-433169468,2,['simpl'],['simply']
Usability,"Hi @k3yavi - thanks for the response. We have been looking at using Alevin to support our wider pipelines in the gene expression group at the EBI, as a generic way of quantifying droplet experiments. It has worked well for the 10X v2 studies I've tried, but I'm experiencing some trouble with the drop-seq studies I've tried thus far due to noisy barcodes. May just be bad data, but I'll post an issue or two when I'm clearer.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/358#issuecomment-490095148:418,clear,clearer,418,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/358#issuecomment-490095148,2,['clear'],['clearer']
Usability,"Hi @k3yavi . Thank you for linking me to your script to parse the bfh file from alevin. I think I could figure out the structure of the bfh file. I will write it down underneath with the help of an example. Could you confirm it is correct? . Everything up and until the listing of the barcodes is clear. I will start with a line from after the barcodes. ; ""7	90480	90486	107507	107990	108641	109149	112915	1	1	105	1	TGGGATTT	1"". I think that each such line corresponds to an equivalence class (EC). The first entry on each row is the number of transcripts in the EC. This is followed by the transcripts (more correctly, indices you can use to obtain the transcripts). Then you have the number of reads with in the EC, followed by the number of barcodes (~cells). For each barcode, you have an index that can be used to retrieve the identity of the barcode, followed by the number of UMIs within that barcode, the sequence of the UMI and lastly the number of reads associated with that UMI. . My goal is create a expression matrix where the ECs are the rows and the columns are the cells. If I want the UMI counts, do I need to count the number of reads associated with each UMI or just the number of UMIs per cell? . Thanks in advance.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/728#issuecomment-1028272923:297,clear,clear,297,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/728#issuecomment-1028272923,2,['clear'],['clear']
Usability,"Hi @k3yavi . Thank you very much for the answer. . I am interested in the equivalence class counts (ECC) per cell and the transcripts that belong to each equivalence class. I think bfh.txt is file that contains that information, but I couldn't figure out how the file is structured. I looked at the function you linked to, but the schema hasn't become totally clear. Could you provide some more information? . Thanks in advance.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/728#issuecomment-1022365298:360,clear,clear,360,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/728#issuecomment-1022365298,2,['clear'],['clear']
Usability,"Hi @k3yavi, ; So there is no issue when I manually add 2 pairs. Is there a max amount of input files? ; Below is the simple bash script to organize the data and find the correct files; ```; #!/bin/bash; #this script calls alevin for multiple library pairs of files . #where salmon located; salmon=""/usr/local/bin/salmon"". index=""path/to/gencode_annot/AlevinIndex/""; echo ${index}. #output folder path; output_folder=""path/to/alevin_outputTest""; echo ${output_folder}. #where the raw files are; samples_folder=""path/to/Raw_data/Sample_cells/"". cd ${samples_folder}. sample1=$(ls *R1*.fastq.gz -p | grep -v / | tr '\n' ' ') #this gives us a space seperated list of all the R1 files; #this is from the alevin tutorial ""Often, a single library may be split into multiple FASTA/Q files. Also, sometimes one may wish to quantify multiple; #replicates or samples together, treating them as if they are one library""; echo ""Value of sample1:""; echo ${sample1}. echo ""Value of sample2:""; sample2=${sample1//R1/R2} #switch the R1 with R2 to find the second pair for ALL (//) occurances; echo ${sample2}. tgMap=""path/to/gencode.primary_assembly.v29.tsv""; #this is a transcript --> gene map tsv file. Can create this using tximport. whitelist=""path/to/my_barcode.tsv""; #a list of true barcodes; salmonCommand=""${salmon} alevin -i $index -lISR -1 ${sample1} -2 ${sample2} -p 8 --celseq2 --dumpCsvCounts -o ${output_folder}/quantSC --tgMap ${tgMap} --whitelist ${whitelist}""; #--numCellBootstraps 100; #numCellBootstraps args -- generate a mean and varience for cell x; #dumpCSVcounts - dumps cell v. transcripts count matrix in csv format; echo ${salmonCommand}; if ${salmonCommand}; then; touch ${output_folder}/qauntSC_complete.txt; else; touch ${output_folder}/quantSC_failed_to_complete.txt; fi; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/329#issuecomment-446199327:117,simpl,simple,117,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/329#issuecomment-446199327,2,['simpl'],['simple']
Usability,"Hi @k3yavi,; Many thanks for you prompt answer, once again. >When you say you try subsampling the Fastq, did you sample randomly across the full Fastq or chose the top X reads. Yes, I did perform a random subsampling, ie. taking a read with a p probability while reading the fastq files, p being the subsampling coefficient I did mention (pE[0;1]). An implementation of this approach as an option during the transcript quantification would be great. I can provide you with the simple python script I use for the subsampling, but I am not sure if it is the proper way to subsample during alevin quantification. >when you say cellranger subsampling, do you mean the cellranger aggregate pipeline?. Yes, sorry for not clearly stating it. I did use the cellranger aggregate function indeed, which by default subsample the expression matrices with high sequencing depth depending on amount of mapped reads, if I understand well. >Use Alevin w/o any modification to the fastq on both of your sample to generate the gene count matrices. I already did that, in downstream analyses I have a batch effect issue related to the sequencing depth. >that's why we recommend using the Seurat package downstream of the Alevin quantified matrices. I have some experience with downstream analyses with Seurat, Pagoda, Scater, scanpy and a few other tools, and I am aware of batch correction methods like CCA or MNN. But that is not what I am looking for here. I did both CCA and MNN but I loose some important information in the resulting eigenspaces or corrected matrix. I believe the proper way to correct my batch effect is to simply fix the difference between my two libraries, ie. the sequencing depth in this case. As I explained in my first message, cellranger aggregate (subsampling based on the amount of mapped reads) works very well in my case, correct the effect without any loss or modification of important genes in our scientific question. Not CCA or MNN. I would like to be able to do the same from the a",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/305#issuecomment-433319913:477,simpl,simple,477,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/305#issuecomment-433319913,4,"['clear', 'simpl']","['clearly', 'simple']"
Usability,"Hi @kvittingseerup,. No need to apologize, I think it was I who was not clear. What I am saying is that this is *already* the way that Salmon handles such a case. That is, if you have a paired-end read, and one of the reads maps but the other doesn't (due to e.g., adapter contamination or just very low quality), then Salmon will consider the remaining (mapping) end of the read as representative of an entire fragment, and will resolve the fragment origin accordingly during optimization. Generally, not having both ends of a paired-end read leads to increased ambiguity, but this isn't a particularly big problem if it only happens to a generally small fraction of the reads. Further, since you cannot reliably infer the implied fragment length on a transcript from only a single-end read, such mappings will not contribute to the bias model. Again, however, as long as this doesn't happen to the vast majority of fragments, it should have only a negligible effect on quantification and bias correction. Please let me know if this description makes sense. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/150#issuecomment-355881997:72,clear,clear,72,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/150#issuecomment-355881997,2,['clear'],['clear']
Usability,"Hi @kvittingseerup,. Sorry for letting this sit for so long without responding. Currently, Salmon does not support mixed paired-end and single-end library types, so this is presumably what is causing the error (granted, the error message here could be considerably better). Practically, I'd be curious what the difference is between allowing this and simply running Salmon with the _non-quality-trimmed_ paired-end reads. Specifically, if Salmon is not able to map a pair concordantly, but it can map one of the ends of the read, then it will already do so. . However, in the case that there's a really compelling reason to want to quality trim the reads prior to quantification (and to include the reads such that the mate has been completely quality-trimmed away), we would be able to support this. It will require a bit of modification to allow different library types to be processed back to back and to contribute to the same quantification estimates. In this case, I imagine what we would want to do for the orphans is essentially what Salmon would do internally if it can't map the mate. That is, we would learn essentially all of the parameters and biases from the pairs that do map concordantly, and then just include the orphaned reads as indicating an entire fragment but of unknown length. Let me know if you have any thoughts about the above, and sorry again for the delay!. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/150#issuecomment-353196630:351,simpl,simply,351,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/150#issuecomment-353196630,4,"['learn', 'simpl']","['learn', 'simply']"
Usability,"Hi @lauraht,. So I decided to explore just one of these to see if I could figure out what might be going on. The below is with respect to `SRR9007475`. So first, even though I processed the data with the latest version of the develop branch (which will become 1.2.0), I got basically identical results to what you reported. Simply aligning the data against an index built on a human Gencode v26 transcriptome (with no decoys) gives me a mapping rate of `0.00378202832148367%`. The first thing I did was to quality and adapter trim the data (using `fastp -i SRR9007475.fastq.gz -o SRR9007475_trimmed.fastq.gz -q 10 -w 8`) and ... whoa. This is the fastp html report [fastp.html.zip](https://github.com/COMBINE-lab/salmon/files/4176345/fastp.html.zip). So the first astounding statistic, the mean read length before trimming is 51bp (these are relatively short single-end reads). The mean read length after trimming is 21bp! So, the average read length is, in fact, less than the k-mer length used for indexing (default is k=31). On the trimmed data, the mapping rate goes up to `2.3545475882931305%`, still very low, but now there's somewhat of an explanation, the average read is shorter than a single k-mer. So, the next thing I tried was indexing with a smaller k; a _really_ small one in this case,`k=15`. Then, I re-ran on the _trimmed_ reads (the fact that the trimming took us from 51-21bp suggests that the reads had a lot of low quality bases, adapter contamination, or both). Under this setting, I still get a very low mapping rate, but it was _much_ higher — `16.766993524863488%`. The final thing I tried was seeing how the mapping rate changed as I altered `--minScoreFraction`, which is the salmon parameter that determines the alignment score that a read must achieve in order to be mapped validly. The default is 0.65. This means that the read cannot have a score < 0.65 * the maximum achievable score for the read given it's length. In the case of a 21bp read, the best score would be ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/482#issuecomment-583799668:324,Simpl,Simply,324,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/482#issuecomment-583799668,1,['Simpl'],['Simply']
Usability,"Hi @mathog,. > Is it really the case that Salmon cannot use 1.57.0?. It may be able to. We set the minimum required version to the lowest boost version we use in any of our testing machines where we run regression tests. Currently, this is 1.59.0. If you change the relevant `CMakeLists.txt` line, you *really* need to make sure you clear out the CMake cache. You can do this by removing `CMakeCache.txt` in your build directory, as well as the directory `CMakeFiles`. However, it might be easiest just to remove and remake the entire `build` directory. You may also try passing `-DBoost_NO_SYSTEM_PATHS=Bool:ON` to your cmake command. Finally, note that the build system is probably looking for the static libraries --- you can elide that preference by modifying [this line](https://github.com/COMBINE-lab/salmon/blob/master/CMakeLists.txt#L222). Finally, since salmon uses C++11, it's important that whatever boost you link against exposes a C++11 compatible ABI. Unfortunately, `FindBoost.cmake` is the most finicky of the module finding packages I know about 😦. If you use `-DFETCH_BOOST=TRUE`, then CMake will fetch a recent boost and build the libraries it needs and link them statically. I realize you want to avoid this, so hopefully one of the ideas above will help.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-396781869:333,clear,clear,333,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/236#issuecomment-396781869,2,['clear'],['clear']
Usability,"Hi @mdshw5,. @k3yavi was originally developing the barcode algorithm in a separate repo, but all of this work has been merged into the salmon repo now. The new `alevin` command runs the single-cell method, which handles barcode identification and correction, mapping and UMI deduplication, and which is described in this [bioRxiv preprint](https://www.biorxiv.org/content/early/2018/06/01/335000) that just landed. We're still actively developing and improving the method and very much welcome any feedback!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/93#issuecomment-394000666:498,feedback,feedback,498,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/93#issuecomment-394000666,2,['feedback'],['feedback']
Usability,"Hi @mej54,. First, thanks for using salmon and for providing detailed feedback! There are two main points I'd like to make in response to the points you raise. . First, v0.9.1 is _very_ old, and there have been a large number of bug fixes and substantial improvements to salmon since that version (though it's much better than people who are still using 0.8.2 from, like, 3 years ago!). Specifically, I'd highly recommend upgrading to the latest version (1.1.0, with 1.2.0 coming out shortly). We've added (and made standard) selective-alignment, which is a procedure that provides alignment scoring for the assigned reads to avoid spurious mappings that arise with fast lightweight mapping procedures. Second, the observation of mismatching bases at the provided alignment location is the expected behavior with the mappings written by salmon with the `--writeMappings` option. Specifically, while newer versions of salmon (0.15.0 and greater) will do alignment scoring and removal of low score alignments by default, salmon still does not compute or write out a full CIGAR string for its alignments. Instead, it uses a _score-only_ dynamic program to compute the optimal alignment score at the given location, but it ""spoofs"" the CIGAR string. Thus, if there is e.g. a small indel in the read, this will show up in an IGV visualization as a large number of mismatches after that indeed location. I'm not sure that is what is happening in the screenshot you show above, and, in fact, may of these mappings may disappear with selective-alignment. However, it will definitely still be possible to see a cigar string showing full matches, where there are mismatches in IGV. This is intended behavior due to score-only alignment. However, it's also true that newer versions of salmon will report the alignment score in an `AS` tag, so that you can see how high the alignment quality was at the particular location.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/491#issuecomment-597349699:70,feedback,feedback,70,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/491#issuecomment-597349699,2,['feedback'],['feedback']
Usability,"Hi @mmokrejs ,. I have written [a script](https://github.com/COMBINE-lab/salmon/blob/master/scripts/runner.sh) for users with this need (i.e., running with interleaved FASTQ files). It simply splits the interleaved file into two streams, however, and so won't deal with unsynchronized streams where not all reads are properly paired. Because this solutions is sort of piecemeal, I've not added it to the official documentation. However, full support for interleaved FASTQ files is something I'd be interested in if we can peel off the time to write up proper support. P.S. Thanks for the suggestions on the documentation, I'll go ahead and make the suggested changes.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/240#issuecomment-399944991:185,simpl,simply,185,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/240#issuecomment-399944991,2,['simpl'],['simply']
Usability,"Hi @mmokrejs,. Thanks again for all the feedback, we'll work on these. I'll mention that (2) is not quite simple as it seems. Specifically, if you write mappings (`--writeMappings, -z`), the implicit file is STDOUT. I believe this has been discussed with @tseemann in the past. This is intentional so that one can immediately pipe that output to e.g. samtools to convert the SAM format to a BAM format. I am open to cleaner solutions that (ideally) don't involve having to write the BAM files directly.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/242#issuecomment-400056707:40,feedback,feedback,40,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/242#issuecomment-400056707,4,"['feedback', 'simpl']","['feedback', 'simple']"
Usability,"Hi @mojakab ,; Thanks for your interest in Alevin. Currently most of our research efforts have gone into developing Alevin for droplet based 3' tag sequencing like 10x chromium and DropSeq. Although similar but Cel-Seq2 relies on a different cell isolation step which can potentially create assay specific bias between the experiments. Basically Alevin is designed to work with single-cell protocols which follows the following criteria:; * Droplet based cell isolation.; * 3' tag sequencing.; * Fragmentation post Amplification. We have similar such request in https://github.com/COMBINE-lab/salmon/issues/269, where the user was able to use Alevin with Cel-Seq2 but currently we have not explored the full potential of Alevin with Cel-Seq2 and might require more careful consideration. If you happen to use Alevin on Cel-Seq2 data we'd appreciate your feedback based on your experience.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/311#issuecomment-439527284:854,feedback,feedback,854,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/311#issuecomment-439527284,2,['feedback'],['feedback']
Usability,"Hi @mugpeng,. This is because it is covered by the custom geometry specification (as laid out in the docs). I agree it's nice to have a specific flag for each geometry, rather than to have to e.g. specify the custom geometry each time. We are working on good solutions to that at a higher level (e.g. in our `simpleaf` tool where users can register their own custom geometry specifications and refer to them by name). However, in `salmon`/`alevin` right now, the named geometries are hard-coded, and so to have a specific `--indropV2` flag, that would have to be added to the argument parser and then mapped to the specific underlying geometry in the code. This isn't hard, but as the number of different chemistries proliferates, it's not ultimately a scalable solution. So, the current recommendation would be to use the custom geometry flags as specified in the documentation, or adopt a wrapper like `simpleaf` and add `indropV2` to your custom geometry specification library. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/878#issuecomment-1758171139:309,simpl,simpleaf,309,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/878#issuecomment-1758171139,4,['simpl'],['simpleaf']
Usability,"Hi @nh13,. This is not something for which we currently have support or something that we currently plan. I'd be open to it, but I'm honestly not sure how to cleanly do it in the current architecture, and doing so would certainly incur a performance hit. Salmon runs 2 phases of inference; and online phase and an offline phase. The online phase has access to _fragment-level_ information that is then summarized away during the offline phase (like the specific locations of each read, the length of each observed fragment, etc.). That information goes away when the reads are summarized into range-factorized equivalence classes. Moreover, some of the model parameters learned during the online phase will depend (in their details) on the order in which observations are made. Ostensibly, observing the same data in the same order **and issuing updates to shared model parameters from worker threads in the same order** should result in identical values, however this has never been tested and was never a design goal. The reason for this is that differences between runs are within the bounds of the inherent inferential uncertainty of the estimated parameters anyway. That is, if one is relying on a specific value at a level of precision such that a different run of salmon would produce a value different enough to change a downstream analysis, then one is imparting more precision on the estimates than they can provide. Other methods that produce identical results between runs for these values may produce the same output, but the accuracy of the output at that level shouldn't be trusted in this case. The uncertainty of the parameter estimates can be evaluated based on the Gibb samples (or bootstrap replicates) that salmon computes. Of course, the small differences between runs rarely lead to differences in downstream analysis (almost certainly at the gene level and also at the transcript level if you use a differential testing method that is aware of inferential uncertainty). On the ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/102#issuecomment-2159300538:670,learn,learned,670,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/102#issuecomment-2159300538,2,['learn'],['learned']
Usability,"Hi @nicolasstransky --- thanks for reporting this. Now the question is, how should this be handled? I see at least 2 obvious possibilities :; 1. Assume that the transcript name should be split at the first whitespace character **or** `|`. Currently,; it is only split at the first whitespace.; 2. If a gtf is provided for gene-level quantification, ensure that some non-trivial number of genes (e.g.; more than half?) have at least 1 transcript in the index corresponding to them. If not, then complain. Of course, there are also potentially other, better solutions; so I'm open to suggestions. The problem with 1 is that _de-novo_ assemblers may have transcript names that are not unique up to the first `|`, so that the whole name needs to be taken into account. The problem with 2 is that it alerts the user of this potential issue, but doesn't resolve it. In the latter case, the user could provide the transcript-to-gene mapping using the provided transcript names in the ""simple"" format — i.e. > a simple tab-delimited format where each line contains the name of a transcript and the gene to which it belongs separated by a tab. which is also accepted by the `--geneMap` option. I sort of lean toward 2, but, as I said, am happy to consider other suggestions.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/15#issuecomment-144471362:978,simpl,simple,978,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/15#issuecomment-144471362,4,['simpl'],['simple']
Usability,"Hi @nskbe,. I apologize for the slow reply. Things have been super-busy over the ""break"" trying to get things done before the semester starts here. Let me see if I can answer your question satisfactorily. In retrospect, I think that the raw `lib_format_counts.json` file can be quite confusing, and I should definitely provide a more thorough description of it in the documentation (or include a tool to generate a more digestible report from it). Basically, the report records the number of each type of _mapping_ observed. By _mapping_, I mean the particular correspondence between a read and a transcript. A given read can have many mappings, and so can contribute multiple times to the entries of the `lib_format_counts.json` file. The reason changing the library type doesn't change the results of this file is because this file records how fragments _mapped_ to the reference, not necessarily how they were _assigned_ during quantification. So, for example, a read map map in both the forward `SF` and reverse complement `SR` orientations. If you pass the library type `-l SR` to Salmon, then the reverse complement mapping will be strongly preferred for assignment of the read to the forward mapping. However, before the read was probabilistically assigned to a transcript, both types of mappings were observed. From the report you have provided, you quite clearly have a `SR` library type. One other thing that I should note. As I mention above, Salmon will assign a higher probability to the preferred library type, but not, by default, a probability of 1. If you want to force Salmon to only assign reads that arise from mappings in the prescribed orientation, you should pass the flag `--incompatPrior 0.0`. This will tell Salmon that it should assign a probability of 0 to any read that maps to a transcript in a way that disagrees with the provided library type. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/183#issuecomment-359218185:1364,clear,clearly,1364,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/183#issuecomment-359218185,2,['clear'],['clearly']
Usability,"Hi @pinin4fjords ,; Thanks for raising an important question and running alevin for the training.; I think there is a confusion regarding the `quantmerge` command. That command works only with bulk RNA-seq quants not with alevin output. To answer your question of running multiple alevin instance for multiple file pair, might depend on what are the separate files from, are they from separate lanes or are they separated based on cellular barcode ? The basic intuition is after initial barcode assignment, alevin works on each cell disjointly meaning as long as you are confident that each file pair is cell disjoint then at the end you can just cat the output of the alevin quants. Also, depending on what's the training about you can think of multiple workarounds like you can use very small 100 cell (7 million reads) datasets from 10x and combine it all together in one file if size and multiple files is a problem.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/434#issuecomment-540033932:460,intuit,intuition,460,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/434#issuecomment-540033932,2,['intuit'],['intuition']
Usability,"Hi @pophipi ,; Thanks for reporting the issue.; It looks like a bug has creeped in while merging the `drop-seq` pipeline to alevin [here](https://github.com/COMBINE-lab/salmon/blob/ad4f74a4e3d7424bcd0ec0c1ec2af300dcbffc44/src/AlevinUtils.cpp#L47-L48).; If it's an urgent requirement you can swap the above two lines by: . ```; umi = read.substr(pt.barcodeLength, pt.umiLength);; return true;; ```. If it's too much trouble to compile from source, we will release a version w/ the hot-fix by today/tomorrow and would update you soon.; Thanks again !. P.S: I was curious how did the `chromium` pipeline went through, since the length requirement of 10x based pipeline is longer and it should break much earlier. The experiment you forwarded above seems to have 25 length bases for CB+UMI sequences. I wonder has any of the Drop-seq guideline changed? I was in the impression it was 12 base CB and 8 base UMI if not, then `--dropseq` flag would not be ideal thing to use since it will just use 20 bases out of 25 present in the fastq files.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/258#issuecomment-408168390:830,guid,guideline,830,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/258#issuecomment-408168390,2,['guid'],['guideline']
Usability,"Hi @rfarouni ,. Is it possible to visualize the above two plots on the same scale ? ; Regarding the few cells not from 10x whitelist, I should have been more clear last time. ; Basically, what I meant earlier when I said that 10x data is clean is that we do observe some cells from the non whitelist file _but_ they have very few UMI and we discard them anyway. I am guessing here your motivation is a bit different i.e. considering very low confidence (even with 1 UMI) barcodes, while generally we discard anything below 10 as noise. Thanks a lot for offering to help with index-hopping idea. I agree, it'd be great to include the model in the alevin framework. Currently I just got the gist of your paper, let us go through the paper in a bit more detail and we'll get back to you as soon as we have some free cycles for the integration.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639137897:158,clear,clear,158,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639137897,2,['clear'],['clear']
Usability,"Hi @rfarouni ,. Please use [this](https://drive.google.com/file/d/11lav7dOQkn5VuSNZwC2CZUgx_eeXpBmx/view?usp=sharing) link to download a linux compatible binary, the fix will be available by default with the next release . > Also, does Alevin use 10x cell barcode whitelist internally to correct barcodes?. In our experiments, we find that, in expectation, the 10x generated experiments are clean enough that we don't need the 10x whitelisted barcode to be explicitly specified or used. > And do you recommend using the `--naiveEqclass` only 64 guide sequences as features ?. That's a very good question. Basically the answer lies in how complicated the UMI graph network is. Experiment with the antibody derived barcodes (ADT) with 20 protein panel, generally, doesn't need the `--naiveEqclass` mode UMI deduplication, unless the experiment is super deeply sequenced. However, for super low diversity like 4-8 barcodes e.g. for HTO like sample barcodes, the graphical network becomes exponentially hard to solve and significantly increases the running time for alevin. . In general, I'd recommend if you expect very low diversity in the number of barcodes in your experiment, use `--naiveEqclass` otherwise prefer avoiding it. Generally, the experiment with low diversity barcodes results in such a highly dense count matrix that a few error in UMI deduplication won't matter and you can tradeoff extra long running time with reasonable under/over UMI deduplicated counts. . _In short_, 64 guide sequences are relatively high diversity and I'd advise skipping `--naiveEqclass` in your command line argument. Hope it helps !",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638576983:545,guid,guide,545,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638576983,4,['guid'],['guide']
Usability,"Hi @rfarouni ,. Thanks for the detailed answer.; > I am not sure why the ISF option didn't work, but probably it has something to do with the guide sequences I was provided. At any rate, I have a few other questions I hope you can help me answer. I'm not sure about this, it's possible if the guide sequences were already reverse-complemented then the above behavior would makes sense. I am a little less familiar with the guideRNA based ECCITE-seq data, although the mRNA library should be 5' and the sequence does come from forward strand but do we expect the guide RNA to be on the forward strand as well ? Unclear . I'll ask around at nygc and would let you know. > Why does increasing --maxNumBarcodes to 200000 results in no barcodes getting corrected? (See log for Run 2 below). What is the rationale for the current default of 100000?. That's again a great question. In short single-cell world is expanding rapidly and alevin was initially designed to work with 10x 3' data and some of the restriction are outdated with combinatorial indexing based multiplexed experiments. To be honest, 100k was just a random high enough number that was put down to throw away the obvious junk data. Having said that, you would notice that in both the logs you attached a significant fraction of barcodes are thrown away i.e., `Skipped 82268 barcodes due to No mapped read`, which is like ~82% of the 100k barcodes. Even if you include the 200k almost everything was thrown away, `[warning] Skipped 184123 barcodes due to No mapped read`. Although your point is important one why things are not getting sequence corrected with 200k, unfortunately I might have to do some more testing on that front to give more precise answer but in your case I'd advise keeping the default 100k bound, unless you are doing combinatorially-indexed data . > For the downstream analysis of such data, I usually work with both the read and UMI counts, but quants_mat.gz only contains the UMI counts. Can Alevin a produce a matri",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639048052:142,guid,guide,142,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639048052,8,['guid'],"['guide', 'guideRNA']"
Usability,"Hi @rmurray2,. Thank you for the report. First, I just want to mention that I don't believe v0.99.0 to be an officially released version number. That is, there was a v0.14.x and a (released in source only v0.15.0), and then the versions moved to 1.0.0 and beyond. However, this behavior certainly isn't related to that. There are 2 things going on that can lead to this effect. The first one, which is relatively easy to test, is that there may be small changes in when the inferred library type starts to be enforced (if it is not `IU`) when auto type detection is used (see [this issue and comments therein](https://github.com/COMBINE-lab/salmon/issues/489)). The second and more fundamental thing going on is that the observed behavior is intended. Even with a single thread of execution provided to salmon for mapping and quantification, there is a separate background thread that simply consumes reads from file and puts them in memory for quantification, and while e.g. pairing information between files is guaranteed to be preserved, exact read order is not. This can lead to differences in the order in which reads are processed and, as a result, differences in the initialization conditions of the optimization. The ultimate result is that for transcripts that have large inferential uncertainty, different numbers of reads can be assigned between runs. We have thought *a lot* about this behavior, what it means, and how the `NumRead` values should best be communicated to users. At the end of the day, the `NumReads` constitute the expected value of latent variables inferred in a _very_ high-dimensional space (# of parameters is at least the number of transcripts). Therefore, there are certain transcripts, whose estimated number of reads simply have _tremendous_ inferential uncertainty — and small perturbations in the initial conditions of the optimization will lead to different estimated values for their abundances. For those transcripts where you observe such fluctuations between",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/613#issuecomment-757989858:885,simpl,simply,885,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/613#issuecomment-757989858,2,['simpl'],['simply']
Usability,"Hi @rob-p ,. Thank you for your explanation, that is very clear and helpful. Yes, the transcriptome annotation was not originally from my RNA-seq data and I may try using stringtie to discover new isoforms, probably that would cover more of my reads.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/533#issuecomment-638961902:58,clear,clear,58,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/533#issuecomment-638961902,2,['clear'],['clear']
Usability,"Hi @rob-p . I have a question on the ""right"" way of tximport/DESeq2 after salmon quant. . Why I ask ""right way"" - is because I am a bit confused with the tximport vignette. 1 - https://bioconductor.org/packages/devel/bioc/vignettes/tximport/inst/doc/tximport.html#Downstream_DGE_in_Bioconductor. ```; Do not manually pass the original gene-level counts to downstream methods without an offset. ; The only case where this would make sense is if there is no length bias to the counts, as happens in 3’ tagged RNA-seq data (see section below). ; The original gene-level counts are in txi$counts when tximport was run with countsFromAbundance=""no"". ; This is simply passing the summed estimated transcript counts, and does not correct for potential differential isoform usage (the offset), which is the point of the tximport methods (Soneson, Love, and Robinson 2015) for gene-level analysis. ; Passing uncorrected gene-level counts without an offset is not recommended by the tximport package authors. ; The two methods we provide here are: “original counts and offset” or “bias corrected counts without an offset”. ; Passing txi to DESeqDataSetFromTximport as outlined below is correct: the function creates the appropriate offset for you to perform gene-level differential expression.; ```. 2 - https://bioconductor.org/packages/devel/bioc/vignettes/tximport/inst/doc/tximport.html#Salmon. ```; files <- file.path(dir, ""salmon"", samples$run, ""quant.sf.gz""); names(files) <- paste0(""sample"", 1:6); txi.salmon <- tximport(files, type = ""salmon"", tx2gene = tx2gene); head(txi.salmon$counts). ```; Why the confusion - https://bioconductor.org/packages/devel/bioc/vignettes/tximport/inst/doc/tximport.html#Downstream_DGE_in_Bioconductor - states ; - The two methods we provide here are: “original counts and offset” or “bias corrected counts without an offset”. Passing txi to DESeqDataSetFromTximport as outlined below is correct: the function creates the appropriate offset for you to perform gene-level d",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/581:655,simpl,simply,655,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/581,1,['simpl'],['simply']
Usability,"Hi @rob-p . I wanted to know if you (or anyone else in your team) has looked into **_how the[ 'seal' program from BBTools](https://jgi.doe.gov/data-and-tools/bbtools/bb-tools-user-guide/seal-guide/) compares with Salmon_**. I ask this for couple of reasons based on comments on Biostars postings (in fact you have also posted in 1 of the threads):. 1. https://www.biostars.org/p/130451/#209851 - This is the post by Brian Bushnell (the developer of all the tools in BBTools) in Biostars about 4 years back (and **_you have also posted there_** https://www.biostars.org/p/130451/#130507). . This is what Brian wrote then:; ```; BBMap and Seal can be used for expression analysis, ; but not differential-expression analysis, without an additional program. ; However, they do the hard work of the actual mapping. ; Maybe I should write something for DE analysis; ```. 2. **_This is the more important posting of Brian from 4 years back_** - https://www.biostars.org/p/175454/#175625 - and I want to draw your attention to ; ```; If all you want to know is whether gene A or B is more upregulated ; in your experiment, then mapping to a transcriptome using any aligner is fine... ; but you could accomplish the same thing ; faster and probably more accurately using a kmer-matching tool like Seal; ```. Couple of questions/suggestions:. 1. Have you considered comparing salmon with seal and how the two compare . 2. Probably, it would/could be a good idea to combine the best of both the tools ```seal and salmon``` for the benefit of the research community in general by collaborating with Brian?. Thanks,",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/499:180,guid,guide,180,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/499,2,['guid'],['guide']
Usability,"Hi @rob-p, ; Thank you for getting back to me so quickly and thank you for the explanation. ; I found this info about the `--eqclasses ` parameter in the Salmon quant help manual for alignment-based mode:; <img width=""626"" alt=""Screenshot 2023-10-03 at 11 40 56"" src=""https://github.com/COMBINE-lab/salmon/assets/76558077/dc98c406-759f-4543-8cdd-5299d24775eb"">; Everything else I tried was a guess.; I wasn’t sure how to get the right file, so I thought it might be the **eq_classes.txt.gz** file, made using the `--dumpEq` option. I read about [—dumpEq option ](https://salmon.readthedocs.io/en/latest/salmon.html#dumpeq) and I found some explanation of [equivalence class file](https://salmon.readthedocs.io/en/latest/file_formats.html#equivalence-class-file). So, I made this file using the `--dumpEq` option and then used it with `--eqclasses` option, but I made mistake by also providing a BAM file with `-a` option. When I got the error, i thought maybe this file was supposed to be used instead of the alignment BAM file, not together with, and now i understand.; I'm still not clear: is this file only used when I want to analyze the same sample multiple times, with different options?; Also, I noticed the `--eqclasses` parameter isn’t in the help manual for salmon quant in mapping-based mode because it’s not there when I run `salmon quant --help-reads`.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/877#issuecomment-1744787632:1085,clear,clear,1085,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/877#issuecomment-1744787632,2,['clear'],['clear']
Usability,"Hi @rob-p,. Ah, I hadn't looked carefully at the outputs, so I was overlooking the fact that the `meta_info.json` for `salmon alevin` is in the `aux_info` subdirectory, while the one for `alevin-fry quant` is in the output directory, so I don't _think_ there will be a conflict. (We have been using the same directory in our pipeline for simplicity.) However, I do think having them named the same thing is a potential source of confusion. Is there a reason not to name the file produced by `alevin-fry quant` something more like `quant.json` or `quant_info.json` to be more in parallel with the `collate.json` and `generate_permit_list.json` files generated at those steps? Either way, I agree that merging the files within `alevin-fry` is probably _not_ the best solution. . The `cmd_info.json` file, seems a special case: I am not sure what the ultimate goal for that file is; it seems now to be included ""for R compatibility"" though I am not fully clear on what that means (with `.mtx` input we don't need it, but `tximeta`/`tximport` may be looking for it?). If the final quant output directory does need the file, it would seem to make sense to copy it along somehow from the `salmon alevin --rad` output directory (with a stop along the way in the `collate` output I guess?). Presumably the `aux_info` would also be desired for `tximeta` if/when `alevin-fry` support is implemented there?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/688#issuecomment-883524316:338,simpl,simplicity,338,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/688#issuecomment-883524316,4,"['clear', 'simpl']","['clear', 'simplicity']"
Usability,"Hi @rob-p,. I am also seeking guidance on the use of Salmon for metatranscriptomes. Similar to this issue and issue #350 I am using the predicted genes from a metagenome assembly as the 'reference transcriptome' and would like to quantify gene expression from the corresponding metatranscriptome data. My metaT data is unstranded. What flags are most appropriate for this purpose? `--meta`? Something else? Are there any assumptions within Salmon that make it unsuitable for metagenomic/metatranscriptomic data (for example, the probability of observing a fragment when organisms are present at different abudances)?. Rachael",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/195#issuecomment-598522020:30,guid,guidance,30,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/195#issuecomment-598522020,2,['guid'],['guidance']
Usability,"Hi @rob-p,; thanks a lot for your investigation. Could you please be more verbose on those incorrect Build-Depends? What dependencies can be removed (if not used they should not really harm, thought but you are correct that it makes sense to remove these) and more importantly which can not be used. For instance if we can't use libstaden as packaged we have a problem. All preconditions for a Debian package have to be packaged first. Fetching something from network is not permitted at package build time.; Thus I simply tried changing the cmake options to. ```; $ cmake -DCMAKE_BUILD_TYPE=Release -DUSE_SHARED_LIBS=TRUE -DBZIP2_LIBRARIES=-lbz2 -DBZIP2_INCLUDE_DIR=/usr/include -DLIBLZMA_INCLUDE_DIR=/usr/include/ -DLIBLZMA_LIBRARY=lzma -DCMAKE_MODULE_PATH=/usr/share/cmake/Modules -DTBB_WILL_RECONFIGURE=FALSE -DBOOST_WILL_RECONFIGURE=FALSE ..; ```. which does not change the SEGFAULT problem. If the issue belongs to something we need to download from somewhere please let me know what looks suspicious to you. This would be helpful since we could either add it to the Debian package source in debian/missing-sources ... or rather fix the predependency that would break salmon.; Kind regards, Andreas.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464471988:516,simpl,simply,516,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464471988,2,['simpl'],['simply']
Usability,"Hi @rob-p. I'm using a SGE-based cluster. The disk I'm writing to is a networked disk that is mounted via NFS on the machines the cluster runs on. I've attached the output of running `qconf -sconf`, which provides details on how the cluster has been configured (I've edited out some lines about the admin e-mails, etc.). I'm not sure how useful much of this information is. A lot of it has to do with scheduling of jobs -- how many jobs/resources users can attempt to claim, that kind of thing. Let me know if there's something else that would be more useful in this context. I've also attached the log that was generated by the indexing run itself (just for the 17mer index), just in case. I can say one thing from having inspected the logs of these things failing a number of times before I finally caved and started giving it insane amounts of memory: by far the longest time and (most likely) the biggest resource hog is between the first and second pass. Even with only 16GB, it manages to complete the first pass (it still takes quite a while, though):. ```; Pass	Filling	Filtering; 1	718	3236	; 2	1839	237; ```. [qconf-sconf.txt](https://github.com/COMBINE-lab/salmon/files/4172585/qconf-sconf.txt); [index_GRCm38_GENCODE_M23_PRI_17mer.log.txt](https://github.com/COMBINE-lab/salmon/files/4172594/index_GRCm38_GENCODE_M23_PRI_17mer.log.txt). EDIT: Oh, I should also probably say, that I'm only seeing this slowdown on index creation. I'm sure that was implied, but I just wanted to be clear that at the moment, I'm happy enough to let the index build for a few hours every once in a while. I'm still saving huge amounts of mapping time, relative to ""full"" aligners.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-583567362:1492,clear,clear,1492,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/476#issuecomment-583567362,2,['clear'],['clear']
Usability,"Hi @roryk ; I know about tximport but is there any way to generate the input data for DESeq2 without using R? I am processing the data on one platform and then transfer to another platform for R/DESeq2 analysis. I would like to be able to generate the output of the first part (salmon) without using an R library. . If it is not possible and I have run R to get the count matrix for DEseq2, I can figure out a way to do it. DESeq2 input file is a simple matrix of counts and ""salmon quantmerge"" already generates this, can you please explain to me why an external library is required ? Is there something I am missing that tximport package is doing to the data? Does tximport takes into account gene lengths or library size to generate the output? . Thanks; Best Regards; Hamdi",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/437#issuecomment-545201602:447,simpl,simple,447,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/437#issuecomment-545201602,2,['simpl'],['simple']
Usability,"Hi @roryk,. Salmon doesn't currently have the ability to output a pseudobam, but that is definitely possible (and not too difficult). We have a related feature planned; perhaps you could tell me if it suits your use case. However, first, I should mention that if you'd simply like a pseudobam for _all_ the mapping locations of the reads, you can use [RapMap](https://github.com/COMBINE-lab/RapMap). RapMap implements the quasi-mapping algorithm upon which Salmon and Sailfish are based (and RapMap is used as a library in the Salmon and Sailfish codebases). Given an index and set of reads, RapMap will report all of the multi-mapping locations that Salmon and Sailfish would consider during quantification. The other feature we have in the works is to have Salmon optionally output a `.bam` file (with actual alignments) post-quantification. It turns out that, given the quasi-mapping information and the quantification results, taking the extra step from quasi-mapping to an actual _alignment_ can be done fairly efficiently. In this mode, Salmon would make one more pass over the reads and, considering the estimated abundances, sample a single alignment for each multi-mapping read proportional to the relative abundance of the different multi-mapping targets (i.e. it would perform a sampling over the multi-mapping locations that would, in expectation, give the same abundances as the _soft_ assignments computed by the optimization algorithm). This feature will be very useful for [transrate](https://github.com/Blahah/transrate). However, given that your goal is to use outside information to perform the filtering yourself, this option may not be ideal for you.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/38#issuecomment-175092553:269,simpl,simply,269,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/38#issuecomment-175092553,2,['simpl'],['simply']
Usability,"Hi @s1corley,. Congratulations on your publication! The `--noLengthCorrection` flag has been around for a long time (e.g. where it is suggested in the post to which @tamuanand [links](https://groups.google.com/forum/#!msg/sailfish-users/VIfqBwgF6xQ/fw-rgC_kAwAJ)). However, given our limited access to QuantSeq and our limited (student) bandwidth to do extensive testing on alternative tech, we have kept this flag marked as experimental. As I mention above, it was introduced since, _conceptually_, the QuantSeq protocol should not exhibit a length effect and so the one may not wish to account for the length when determining assignment probabilities during the variational Bayesian optimization. However, the empirical testing of this has been limited. Now that your paper is published, and contains what look to be some _very through_ assessment methodologies, we may be able to look into this and determine if there is anything we can do to, perhaps, optimize salmon even more for accurate quantification from the QuantSeq protocol. We would welcome any suggestions or feedback you may have. Congratulations again on the paper!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565474848:1074,feedback,feedback,1074,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565474848,2,['feedback'],['feedback']
Usability,"Hi @saipra003,. Thank you for posting the issue, and also following up with the resolution. It’s not immediately clear why there would have been an issue with 1.2.1, but we’ll be sure to make not of this for anyone else who runs into such an issue with older releases. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/690#issuecomment-886279790:113,clear,clear,113,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/690#issuecomment-886279790,2,['clear'],['clear']
Usability,"Hi @satta,. Thanks for bringing this to my attention. I am of two minds on this proposal. On one hand, I agree that it is cleaner, in theory, to have a RapMap shared library to which Salmon could simply link. Currently, Salmon pulls in the relevant portions of the RapMap code to call what is essentially an ill-defined public API for mapping. On the other hand, I have two concerns about separating the code at this point, one is major the other minor. The major concern is that both Salmon and RapMap are still very much under active development, core code and even the interfaces are undergoing reasonably rapid changes (thus the versioning < 1.0). This allows me to easily add features that may potentially benefit Salmon to the RapMap codebase, and then to synchronize Salmon releases with particular commits (tags) in the RapMap codebase. The current build system makes it very easy to pull in the appropriately versioned RapMap code. On the other hand, I have very little experience in properly versioning shared libraries so I would have to understand that better and how this could be done without complicating the build process. My _minor_ concern is that I don't know what effect, if any, separating the code into a separate shared library might have on compiler optimizations. Right now, since the relevant RapMap code is compiled alongside Salmon and they are linked together into the same module, certain optimizations may be possible that would not be so when linking to a shared library. My educated guess is that the effect of such optimizations would be negligible, but it's something that may be worth some exploration first. Overall, I'm very open to this idea, but I think I need to do some homework on it before we can commit and undertake the change.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/87#issuecomment-246027704:196,simpl,simply,196,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/87#issuecomment-246027704,2,['simpl'],['simply']
Usability,"Hi @schelhorn,. Sorry for the uncharacteristically slow response on this. We're going full steam ahead for the RECOMB deadline, so I've been less responsive than usual. Anyway, I've invited you to the repository for the fusion project (it's currently private). Feel free to poke around, but it's probably not useful until we can send you a short writeup describing the current pipeline (since things are still very ""alpha""). Regarding calling fusions from the sam output of Salmon, one can't do this directly because there are, by default, no encompassing reads (i.e. individual reads split between transcripts) and, to improve abundance estimation, salmon is conservative with it's use of spanning reads. However, we can get at this information from quasi-mapping, so I can definitely consider adding some flags to provide this info (this is the type of thing we output in the fusion pipeline currently, and then we have to postprocess it).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/52#issuecomment-256045452:146,responsiv,responsive,146,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/52#issuecomment-256045452,2,['responsiv'],['responsive']
Usability,"Hi @summerrfair ,. I can't see anything obviously wrong with the command line. Do you have a small example of the transcripts.fa and myseq.bam file you could share? The message indicates that salmon thinks its running in mapping-based mode (with input fastq files), but you are clearly running in alignment based mode. Is the behavior any different if you put the -a argument first?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/511#issuecomment-616870047:278,clear,clearly,278,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/511#issuecomment-616870047,2,['clear'],['clearly']
Usability,"Hi @tamuanand and @uros-sipetic,. Thanks for the feedback on this! I just cut v1.2.1 which ""fixes"" the behavior. It will simply discard any duplicate _decoy_ sequences, which resolves this problem without requiring manual intervention.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/505#issuecomment-617830355:49,feedback,feedback,49,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/505#issuecomment-617830355,4,"['feedback', 'simpl']","['feedback', 'simply']"
Usability,"Hi @tamuanand,. Nope; these values are right. The `indexVersion` is a global identifier with respect to previous versions of salmon. It is a global number that is incremented each time (a) a backward-incompatible change to the index is introduced or (b) a fundamentally new piece of information is contained in the index. This field took a value of `1` way back when we started versioning the salmon index a number of years ago, and version `1` was based on the RapMap index (rather than pufferfish like the current one). This is simply a global identifier that we can use internally to determine whether the version of salmon reading this index can be expected to make use of it. The other field `indexType` corresponds to the value from an internal enumeration used in the salmon code. Over the years (since it was first released in 2014), salmon has used a number of different data structures for its underlying index. First, it used a modified version of the FMD index that BWA is based upon, then, it used the RapMap index (based upon a sparse hash map and an uncompressed suffix array), and now it uses the pufferfish index. This `indexType` filed just records the type of this index. In modern (post 1.0.0) versions of salmon, the pufferfish index (`2`) is the only valid version. There's a lot of history to these values, but they all make sense internally within salmon, which is how the contents of this file are primarily used (i.e. to make sure there is compatibility between the version of salmon being run and the index we are trying to consume). Hopefully, this description clears things up a bit. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/504#issuecomment-613217080:530,simpl,simply,530,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/504#issuecomment-613217080,4,"['clear', 'simpl']","['clears', 'simply']"
Usability,"Hi @tamuanand,. Ok, it seems something simple with the preparation of the decoys.txt file. I'm looking into it. If you watch the log, you see the following output before the (intentional exit with status code 1):. ```; [2020-04-14 09:44:12.991] [puff::index::jointLog] [critical] The decoy file contained the names of 955 decoy sequences, but 953 were matched by sequences in the reference file provided. To prevent unintentional errors downstream, please ensure that the decoy file exactly matches with the fasta file that is being indexed.; [2020-04-14 09:44:13.304] [puff::index::jointLog] [error] The fixFasta phase failed with exit code 1; Command exited with non-zero status 1; 56.66user 9.14system 1:04.69elapsed 101%CPU (0avgtext+0avgdata 6902936maxresident)k; 3792inputs+16outputs (30major+3629051minor)pagefaults 0swaps; ```. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/505#issuecomment-613451792:39,simpl,simple,39,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/505#issuecomment-613451792,2,['simpl'],['simple']
Usability,"Hi @tamuanand,. Thanks again for your detailed questions and thoughts on this issue. Just to follow-up / expand a bit on what @k3yavi has said (and to answer your other question): Yes, one would imagine that, given the details of the QuantSeq protocol, turning off length correction would make the most sense. The main reason this flag is listed as _experimental_, is simply that it was designed based on the expected characteristics of the protocol. Conceptually, the protocol is performing tagged-end sequencing, and so there should be little-to-no length effect. However, since we haven't done extensive internal validation on QuantSeq data, we have left this flag as experimental until it is further tested by ourselves or others. > Also @rob-p , weren't you referring to the RSEM caveat with QuantSeq data analysis wherein one cannot ask RSEM to disable lengthCorrection and hence the count statistics might be misleading?. Correct; as far as we are aware, there is no way to disable the built-in length-dependent assumptions of RSEM. One could use the `--estimate-rspd` flag to allow learning of a non-uniform read distribution (the equivalent of `--posBias` in salmon), though it's unclear / unlikely if this would be as effective as fully disabling the length correction for this type of tagged-end data. If you have any good empirical assessment mechanism for QuantSeq data, and a chance to test out these different salmon options, we'd be happy to get feedback and discuss details further!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565285540:368,simpl,simply,368,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565285540,6,"['feedback', 'learn', 'simpl']","['feedback', 'learning', 'simply']"
Usability,"Hi @tamuanand,. Thanks for the suggestion. You're right, of course, and we should change the wording in that readme. The cause of the sequence similarity is not always known, and frankly, not important for our particular application. We adopted this term as shorthand given it's common use and also because the version of MashMap used to compute these sequence-similar regions was introduced in the paper [A fast adaptive algorithm for computing whole-genome homology maps](https://academic.oup.com/bioinformatics/article/34/17/i748/5093242). In the preprint itself, we're generally careful to simply refer to these as sequence-similar regions ;).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/365#issuecomment-499476462:594,simpl,simply,594,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/365#issuecomment-499476462,2,['simpl'],['simply']
Usability,"Hi @taylorreiter,. I was wrong — there was simply a bug that, in single end mode, everything was being written out with the `u` flag. This is now fixed in develop. It will be in the next release. Sorry about that!. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/748#issuecomment-1146205498:43,simpl,simply,43,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/748#issuecomment-1146205498,2,['simpl'],['simply']
Usability,"Hi @teshomem,. If you want to proceed with transcript-level differential expression, _all transcripts are relevant_. That is, the relevant tools (e.g. DESeq2, limma-voom, Sleuth, etc.) will expect to be provided with _all_ quantified isoforms for each gene. They will then automatically apply their own filtering criteria to determine which transcripts to actually test for DE. . If you want to proceed with DE at the gene level (and hence want to aggregate the quantification information from the level of transcripts to genes), the easiest option is to use the [tximport](http://bioconductor.org/packages/release/bioc/html/tximport.html) package. It can import all of the quantifications from multiple runs of Salmon, aggregate them to the gene level, and produce a count matrix that can then be used with traditional count-based gene-level DE tools. I would recommend the pipeline Salmon => tximport => DESeq2 for gene-level DE analysis. Finally, the best place for questions like this, that don't have to do with a specific bug or feature request for the Salmon software, is the [Google user group](https://groups.google.com/forum/#!forum/sailfish-users). This way, other users will be more likely to provide you with feedback and help answer your questions.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/154#issuecomment-329974141:1222,feedback,feedback,1222,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/154#issuecomment-329974141,2,['feedback'],['feedback']
Usability,"Hi @tillea,. So I went through the list of deps pulled in by `apt build-dep salmon` and the minimal set I gave above. I tried to make the smallest number of changes I could to the `apt build-dep salmon` list while also removing things that are clearly outdated (we no longer use jellyfish, rapmap, etc. and we use the header-only version of spdlog). As a result I came up with this list of dependencies. The offending dependency seems to be `libcereal-dev`. Specifically, I was able to install just this list of dependencies (minus `libcereal-dev`) atop a clean `debian:testing` and get a working version where the only thing downloaded from the internet was the appropriate version of the pufferfish files grabbed by `fetchPufferfish.sh` in the `1.10.0` release. Once I installed `libcereal-dev` with `apt-get install`, and rebuilt, then I got the segfault mentioned at the top of this issue. So, it seems that we either have to let `salmon` build it's own libcereal, or figure out what the problem is with the library upstream. Please let me know if this you observe this same behavior as well (also @nileshpatra may want to try this out). If so, perhaps we can get `libstaden` updated upstream, and then use this as the new dep list for `salmon`. I installed these deps with a simple `xargs apt-get install -y < deps_sorted_updated.txt` (without `libcereal-dev` for the working version, and with it included, as below, for the segfault). Best,; Rob. [deps_sorted_updated.txt](https://github.com/COMBINE-lab/salmon/files/10949233/deps_sorted_updated.txt)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464986376:244,clear,clearly,244,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464986376,4,"['clear', 'simpl']","['clearly', 'simple']"
Usability,"Hi @tmms1 ,. > I think that each such line corresponds to an equivalence class (EC). The first entry on each row is the number of transcripts in the EC. This is followed by the transcripts (more correctly, indices you can use to obtain the transcripts). Then you have the number of reads with in the EC, followed by the number of barcodes (~cells). For each barcode, you have an index that can be used to retrieve the identity of the barcode, followed by the number of UMIs within that barcode, the sequence of the UMI and lastly the number of reads associated with that UMI. This is correct !. Unfortunately you goal is not very clear to me and the output matrix depends on that. I understand that you wan't a matrix of dimension |eq_class X cells| but if you wan't the values in the matrix to be read count then you have to add the counts of all the UMIs in class across the cells; and if you wan't the values in the matrix to be the frequency of the unique UMIs then just count the UMIs you wan't instead of reads.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/728#issuecomment-1029328067:630,clear,clear,630,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/728#issuecomment-1029328067,2,['clear'],['clear']
Usability,"Hi @tobi-te ,; Salmon is a two-phase algorithm i.e. online and offline. The first phase i.e. online-phase learns various parameters before starting the offline-phase (order doesn't matter). Like most online learning algorithm Salmon also expects the input to be randomized enough to avoid bias or in the case of Salmon *possibly* nudge the offline-phase towards a local-minima, which can vary according to the data (not always). I think in your case even though the learnt online parameters are biased (because of non-random order) the estimated abundances at the end are corrected by the offline-phase pretty well and you are observing the similar results.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/155#issuecomment-331262951:106,learn,learns,106,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/155#issuecomment-331262951,6,['learn'],"['learning', 'learns', 'learnt']"
Usability,"Hi @tomsing1 ,; Apologies for the slow response, I was out of country for a while. Thanks for your kind words and starting a very interesting suggestion.; It’s fascinating to see, how methods being used in single-cell RNA-seq is coming full circle back to the bulk RNA-seq experiments. We have to do some more digging to say clearly about the caveats of using Alevin with the mentioned 3’ bulk RNA-seq experiments but given the understanding from the picture of the shared image we don’t see any obvious show stoppers; although below mentioned concerns should be kept in mind while using Alevin for bulk data deduplication:. Alevin solves the problem pretty well for protocols where fragmentation of the cDNA molecule happens post PCR amplification. There might be some concerns about over-deduplication of the UMI if fragmenation happens before amplification. Although in current form, Illumina sample index can be given as an external whitelist to Alevin but user should be aware that Alevin performs a sequence correction step before starting any optimizations.; Alevin is designed for droplets based protocols, where one end of Paired end read is just the CB/UMI (i.e. no read sequence) and therefore Alevin can’t optimally use the full paired end information of the bulk 3' protocol if its both end has read-sequence for example the ambiguous mapping resolution based on a previously/empirically known approximate fragment length. We would be more than happy to help/discuss, how does the results look in bulk 3’ tagged protocols or if you have particular suggestions about what improvements can be done in Alevin.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/306#issuecomment-439530193:325,clear,clearly,325,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/306#issuecomment-439530193,2,['clear'],['clearly']
Usability,"Hi @uros-sipetic!. Unfortunately, as you suggest, there really is no good way to infer the fragment length distribution from only single-end reads. Rather, this flag determines how the conditional probability of single-end fragments near the beginning (if in the rc orientation) or end (if in the forward orientation) of the transcript are determined. A single-end read does not have any known fragment length. But we do know that e.g. fragments very close to the end or beginning of the transcript are rather unlikely. In this case, we can integrate (sum) over all possibilities to assign a conditional probability. This is what salmon does. For a single-end read (assume forward orientation for simplicity) at position i on a transcript of length n, we consider the conditional fragment length probability to be given by F_n(n-i), where f_n is the conditional fragment length distribution conditioned on the transcript length (maximum observable length) being n and F_n is the cumulative distribution function of f_n. Intuitively, this means that fragments very close to transcript ends will get a smaller conditional probability, while those farther from the end will get larger conditional probabilities. The `--noSingleFragProb` flag simply turns off this conditional probability all together. It is _not_ recommended to disable the single-end fragment length probability modeling. We have evidence from testing that it improves quantification accuracy. Thus, I would suggest _not_ setting the `--noSingleFragProb` flag. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/575#issuecomment-711061553:697,simpl,simplicity,697,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/575#issuecomment-711061553,5,"['Intuit', 'simpl']","['Intuitively', 'simplicity', 'simply']"
Usability,"Hi @vals,. So there was a very subtle bug in `useFSPD` that would (in a very non-reproducible manner) trigger such a segfault. It was related to some very tricky locking behavior. However, the manner in which `useFSPD` corrected for position specific bias isn't actually compatible with our new sequence-specific and fragment-gc bias models. Thus, I've deprecated `useFSPD`. The replacement is the flag `posBias`. This models the same type of positional bias, but does so in a way that is compatible with our other bias models. It also doesn't rely on the tricky threading behavior, so it should be more stable. Unlike sequence-specific and fragment-gc bias, however, the `posBias` option is still _experimental_ in the 0.7.0 release. However, we have been testing it internally, and I'd be very grateful for your feedback if you have a chance to try it out. Assuming things look good, we can promote it from experimental in the next release.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/64#issuecomment-241234373:814,feedback,feedback,814,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/64#issuecomment-241234373,2,['feedback'],['feedback']
Usability,"Hi @vasisht,. Actually, the settings of these flags aren't incorrect according to the [SAM spec](https://samtools.github.io/hts-specs/SAMv1.pdf):. > Bit 0x4 is the only reliable place to tell whether the read is unmapped. If 0x4 is set, no assumptions can be made about RNAME, POS, CIGAR, MAPQ, and bits 0x2, 0x100, and 0x800. That is, if the unmapped flag is set, then there is not a specific ""correct"" setting for these other fields, since they should most likely be ignored anyway. That being said, concordant with some small changes in the [most-recent RapMap](https://github.com/COMBINE-lab/RapMap/releases/tag/v0.4.0), the CIGAR string will be set to `*` for unmapped reads in future versions of Salmon. We may consider setting other fields to `*` for unmapped reads to simplify the output, but, as the SAM spec suggests, these fields offer quite a bit of freedom in terms of ""legal"" values if the unmapped flag is set anyway.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/94#issuecomment-250350189:776,simpl,simplify,776,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/94#issuecomment-250350189,2,['simpl'],['simplify']
Usability,"Hi @wdecoster,. Thanks for reporting this. One restriction that needs to be better documented (actually, I have to make sure it is properly documented at all!) is that the library type should come _before_ the reads they describe. That is, you should consider passing `-l SF -r {}` rather than `-r {} -l SF`. The reason for this is that the `-r` and `-1,-2` parameters are repeatable so you could, conceivably, pass multiple reads of different library types. However, this is a feature that nobody uses and frankly doesn't make too much sense (so I'll consider removing it in the future to simplify library type parsing). For the time being, I'll also consider printing a warning message when a read file is encountered without an explicitly pre-defined library type (in that case, the behavior, as you saw, is to assume an unstranded library). Could you let me know if passing `-l` before `-r` resolves the issue for you. As to your other suggestion. The internal capitalization rules follow those for camel-case naming of variables (as opposed to separating words with`_`). However, I realize this is somewhat esoteric and even among those who are familiar with such conventions, an arbitrary preference. I'll look into aliasing this flag (and maybe others) to be usable with different names as well. I just have to check how to do this (and if it is possible) with boost's program options.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/177#issuecomment-347524360:590,simpl,simplify,590,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/177#issuecomment-347524360,4,"['simpl', 'usab']","['simplify', 'usable']"
Usability,"Hi @xinbindai,. What you are seeing in both Salmon and RSEM is the expected behavior. This is because, to a large extent, the entire purpose of these tools is to appropriately allocate mulit-mapping reads. In your case, it is likely the case that one of the two very similar transcripts could account for all of the reads, while the other could not. For example, image I have a simple scenario where I have two transcripts:. ```; ACACACTGTGTGTG; ACACACGGTGTGTG; ```. Now, imagine I observe the ""reads"":. ```; ACAC; ACAC; CACA; CACA; ACTG; CTGT; GTGT; TGTG; TGTG; ```. The majority of these reads could have come from either transcript (and are equally likely to have come from both). However, the fact that we observe `ACGT` and `CTGT` is rather strong evidence that we could explain all of the reads via the first transcript while positing 0 (or close to 0) abundance for the second. On a much larger scale, this is what Salmon and RSEM are doing --- they are finding the most likely abundances of the transcripts given the observed data (the reads). When there is unique evidence of one of the two variants, and no unique evidence of the other, the maximum likelihood estimate for the variant with no unique evidence is very small. I'm not sure how many reads you are mapping, but you likely got a somewhat different estimate from eXpress since it tends to regularize it's abundance estimates a bit more strongly than Salmon or RSEM. That being said, this is the intended behavior of these tools, they are meant to probabilistically allocate multi-mapping fragments to similar transcripts in a manner that maximizes a global likelihood, so I don't think that what you are seeing is un-expected. In fact, it is consistent with the probabilistic model that underlies all three tools.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/107#issuecomment-263408444:378,simpl,simple,378,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/107#issuecomment-263408444,2,['simpl'],['simple']
Usability,"Hi @yagam-fluent,. Thanks for the excellent question. We should update the documentation regarding this option. Basically, in `salmon alevin`, we assumptions about expected read orientation are applied as ""hard filters"". That is, the behavior is equivalent to `--incompatPrior 0`, so that aligninments not in the prescribed orientation are simply not considered as invalid alignments. This is because in the case of single-cell processing, we (the community in general) currently do not have as sophisticated of probabilistic models for resolving UMI origins and gene abundances, and so algorithms typically do not take into account a ""wrong orientation"" probability. So, in `salmon alevin` if you are using alevin itself for the quantification, then hard filtering will be applied based on the expectations of `--libType`. On the other hand, if you are using `salmon alevin` to simply map the reads for subsequent processing with [`alevin-fry`](https://github.com/COMBINE-lab/alevin-fry) (i.e. `salmon alevin .... --rad` or `salmon alevin ... --sketch`), then *no* filtering is applied to mapping orientation, and instead you filter reads by orientation later in `alevin-fry`'s `generate-permit-list` step. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/749#issuecomment-1038325742:340,simpl,simply,340,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/749#issuecomment-1038325742,4,['simpl'],['simply']
Usability,"Hi @yeodynasty,. There are two different ways to tackle this question. The first relies on the fact that the correction employed by salmon for GC bias is done via the adjustment of transcript effective lengths. Here, you could compare the effective length in the quant.sf file to the effective length you would get ignoring GC-fragment (or other bias). Granted, the latter is not written down in the file here, but it is straightforward to calculate since salmon also writes out the fragment length distribution. ; The effective length discarding bias estimates is simply the transcript length, minus the mean of the conditional fragment length distribution (the fragment length distribution from 0 up to the transcript length, re-normalized to be an appropriate probability distribution). If you look at the differences between these values, you can infer how much bias correction was applied. Specifically, when the bias-corrected length is longer than the non bias-corrected length, then these transcripts are over-represented in sequencing and the bias correction aims to reduce their estimated abundance. On the other hand, when the bias-corrected length is shorter than the non bias-corrected length, then these transcripts are under-represented in sequencing and the bias correction aims to increase their estimated abundance.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/578#issuecomment-717267531:565,simpl,simply,565,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/578#issuecomment-717267531,2,['simpl'],['simply']
Usability,"Hi Alex,. The appropriate way to _force_ salmon to use the library type as a hard constraint is to pass the option `--incompatPrior 0.0` on the command line. This will tell salmon that it should consider a fragment mapping different than the library type to be impossible (i.e. this mapping should simply be discarded). This will actually be the default behavior starting from the next release anyway, as the current behavior seems to confuse more people than not. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/67#issuecomment-388863963:298,simpl,simply,298,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/67#issuecomment-388863963,2,['simpl'],['simply']
Usability,"Hi Avi,. Thanks for the detailed reply. I was able to run it (see logs below), but I had to use `ISR`, not `ISF` to get it to work. I also had to add these two settings as well; `--freqThreshold 1 --lowRegionMinNumBarcodes 100`. . I am not sure why the `ISF` option didn't work, but probably it has something to do with the guide sequences I was provided. At any rate, I have a few other questions I hope you can help me answer. 1. Why does increasing --maxNumBarcodes to 200000 results in no barcodes getting corrected? (See log for Run 2 below). What is the rationale for the current default of 100000? ; 2. For the downstream analysis of such data, I usually work with both the read and UMI counts, but `quants_mat.gz` only contains the UMI counts. Can Alevin a produce a matrix of read counts as well. It would be a great feature to add. For now, what is easiest way to get the cell x feature matrix of read counts if I use the ` --dumpEq` or `--dumpBfh` flags? Can *tximport* be used for this or do I need to use the Python [parser]([https://github.com/k3yavi/vpolo/blob/master/vpolo/alevin/parser.pyl]) first?. I will be sending you some reads from the experiments for unit testing shortly. Thanks!. Run 1: `salmon alevin -l ISR --citeseq --barcodeLength 16 --umiLength 10 --end 5 --featureStart 19 --featureLength 21 --maxNumBarcodes 100000 --freqThreshold 1 --lowRegionMinNumBarcodes 100`. > 20-06-04 12:24:47.610] [alevinLog] [info] set CITE-seq minScoreFraction parameter to : 0.797619; > [2020-06-04 12:24:47.610] [alevinLog] [info] Found 64 transcripts(+0 decoys, +0 short and +0 duplicate names in the index); > [2020-06-04 12:24:47.610] [alevinLog] [info] Filled with 64 txp to gene entries ; > [2020-06-04 12:24:47.610] [alevinLog] [info] Found all transcripts to gene mappings; > [2020-06-04 12:24:47.616] [alevinLog] [info] Processing barcodes files (if Present) ; > ; > [2020-06-04 12:26:04.322] [alevinLog] [info] Done barcode density calculation.; > [2020-06-04 12:26:04.322] [alev",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638991199:324,guid,guide,324,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638991199,2,['guid'],['guide']
Usability,"Hi Avi,. Yes I just asked and the guide sequences were reverse complemented. I was looking through the results and comparing it with the output of another alignment software. I noticed that there are substantially fewer UMI per guide (in cell) throughout ( see figures for comparison). . ![image](https://user-images.githubusercontent.com/9895004/83803410-7eb16f80-a67a-11ea-832d-562c88dafef3.png) ; ![image](https://user-images.githubusercontent.com/9895004/83803427-8709aa80-a67a-11ea-9ea4-f66ca447a65c.png). Also, the number of UMIs per cell barcode is consistently lower and there is around 796 barcodes that are not found in the 10X whitelist, the majority of which tend to have 1 UMI count only. Here is tally, where the TRUE column indicates the barcode is found in the whitelist. The row names indicate the total number of UMIs; ; ![image](https://user-images.githubusercontent.com/9895004/83803984-7279e200-a67b-11ea-8578-fc863f94f714.png). It would be great if you can implement the index hopping correction in Alevin. The software we have works fine if the number of samples is not too large. If had known how to code in C++, I would have implemented part of the code more efficiently using Rcpp. Please let me know if you ever decide to add this feature to Salmon. I am more than happy to help. Rick,",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639088909:34,guid,guide,34,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639088909,4,['guid'],['guide']
Usability,"Hi Jason,. Thanks for the kind words, and for the detailed issue! This is sort of a tough one, since salmon tries to work out the relative abundance of these different transcripts in the way that maximizes the likelihood of the observed data (or, more specifically, maximized the ELBO in the variational Bayesian framework). Of course, you seem to know that already :). One thought that comes to mind, though, is the following. The default settings for salmon favor sparsity of the solution pretty strongly — it is important to explain the data with as few distinct transcripts as possible. While this often seems a nice thing to do, it can tend to lead to the type of behavior that you are seeing. The way to modify this is to alter the `--vbPrior` parameter to salmon. Basically, this number encodes the prior observation weight that should be attributed to each isoform _before_ accounting for the data. The default value for this parameter is 0.01. Small values (<< 1) are sparsity inducing, while larger values are not (and values close to 1 and above actually penalize sparsity). You could try quantifying with a few (larger) values of this parameter to see if any of them give allocations among these isoforms that seem to make more sense to you (or that agree more strongly with any alternative assays). Actually, I'd be very interested in hearing any feedback you have about this if you find a setting that is more in line with what you expect!. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-622566744:1360,feedback,feedback,1360,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-622566744,2,['feedback'],['feedback']
Usability,"Hi Jason,. Thanks for the super-detailed feedback! A couple of thoughts / questions:. > FYI, I am getting a segfault when I run only --posBias in the current salmon version, but if I run all the models together like --gcBias --seqBias --posBias, it completes fine. ~~Do you have a small example (ref / read pair) that reproduces this? It would be great to figure out why and fix it. We could split that into a new issue if you'd rather.~~. P.S. Nevermind; thanks to you mentioning this, I was able to track it down and fix it in develop!. > As I understand the selective alignment, the alignment scores are passed to the quantification step, but the position of the reads is not used downstream. . Well, yes and no. We make extensive use of the position when estimate the implied fragment length (distance between paired end reads) and then model the conditional probability of this fragment based on the global fragment length distribution. This is just as much as is done by e.g. RSEM. However, you are right that there is no notion of using the coverage profile in estimation (more on this below)!. > Also, my intuition for these transcripts is not really a coverage ""bias"" . My intuition agrees with yours here completely. First, this isn't really a coverage bias as we use the normal definition of the term. Second, the positional bias modeling in salmon is not on a per-transcript level (since that would be an astronomical number of different parameters to learn, and any procedure would almost certainly overfit). Instead, it groups transcripts into length bins, and learns a distinct coverage bias model per-bin. > It would be neat if Salmon could detect these kinds of dramatic dropoffs and add a warning or something... even if not incorporating the information into the quants... it could even be a good QC step to identify large deletions/insertions over a gene body. As far as I know, there are NO rnaseq quant programs that would handle this, because even something like a STAR -> RSEM ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623047035:41,feedback,feedback,41,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623047035,2,['feedback'],['feedback']
Usability,"Hi Kadir,. So, the short answer is that on a _single sample_ the `-g` flag and `tximport` do something very similar. However, the real benefit of `tximport` is that it has access to _all_ of the samples when doing transcript to gene-level aggregation. . So, while Salmon with the `-g` flag will estimate the average expressed gene length in each sample, `tximport` will also have knowledge of how the average gene length varies across all samples. Also, `tximport` provides a few different options for how, exactly, you wish to aggregate. Generally, the `-g` option is completely reasonable, but `tximport` is the same in the simple case and better in the general case.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/169#issuecomment-341731522:626,simpl,simple,626,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/169#issuecomment-341731522,2,['simpl'],['simple']
Usability,"Hi Kivanc,. Thanks for the kind words, and thank you for the _extremely detailed_ report. Reports like this are a model of what every developer wishes a user did before filing an issue :). First, let me clear up what seems like might be a small source of confusion. Since both of the salmon runs are from v1.1.0, _neither_ of these are making use of quasi-mapping. Specifically, newer versions of salmon _only_ perform selective alignment (and this makes the `--validateMappings` command line argument redundant in newer versions, though we keep it so as to maximize backward compatibility with command line parameters people may be using). So, the main difference between your two salmon runs is inclusion of the decoy set. This almost certainly means that the reads that map in your second set of salmon runs but not your first are being assigned to decoys in the first case. To try and get a better handle on this, could you upload a `meta_info.json` file from both runs? This file lives in the `aux_info` directory, and it will provide information about e.g. how many reads were best mapped to decoys and were discarded for this reason. The guarantee you get from the selective alignment is that, if the fragment is discarded by decoy mapping, it maps _strictly better_ to the decoy than to the non-decoy sequence. There are many reasons this could happen. One is rRNA contamination, another could be that reads are coming from processed pseudogenes that are not properly in your annotation, yet a third is that your sample has a considerable fraction of reads spanning exon-intron junctions (in this case, the read will map better to the corresponding location on the genome, and worse to the annotate transcript where the intronic sequence is not present). Now, figuring out exactly which of these cases you are in is a bit more difficult, but one approach would be to pick one of the samples with the biggest differences and map to the reads to the genome with e.g. STAR or HISAT2 to see what y",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/479#issuecomment-578848875:203,clear,clear,203,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/479#issuecomment-578848875,2,['clear'],['clear']
Usability,"Hi Rob and team,. the geneMap option wasn't automatically detecting my gff file as a transcript->gene mapping in the correct format, instead treating it as a simple mapping and yielding interestingly a single result in `quant.gene.sf`, ""UTR"" (which lies in column 3 of the GFF; unclear to me why it didn't pull from column 2 instead, yielding gene names ""Ensembl"" and ""Havana""). Anyway, I found that Salmon is really only matching on the extension `.gtf` , **instead of `.gtf or .gff` as the help text indicates** :; ```; -g [ --geneMap ] arg File containing a mapping of; transcripts to genes. If this file is; provided Salmon will output both; quant.sf and quant.genes.sf files,; where the latter contains aggregated; gene-level abundance estimates. The; transcript to gene mapping should be; provided as either a GTF file, or a in; a simple tab-delimited format where; each line contains the name of a; transcript and the gene to which it; belongs separated by a tab. The; extension of the file is used to; determine how the file should be; parsed. Files ending in '.gtf' or; '.gff' are assumed to be in GTF format;; files with any other extension are; assumed to be in the simple format. ```; The offending comparison in `SalmonUtils.cpp` is here:; https://github.com/COMBINE-lab/salmon/blob/335c34b196205c6aebe4ddcc12c380eb47f5043a/src/SalmonUtils.cpp#L2241. While I have brought this to attention, it would be nice to also check for the extension `gff3` as well, since this is what Gencode supplies (and many people tend to append the `3` to the extension in practice). Kind regards and thanks for doing great science",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/114:158,simpl,simple,158,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/114,3,['simpl'],['simple']
Usability,"Hi Rob, . Thanks for the quick reply. I'm looking into it and will try this with an updated install of GCC >= 5.2.; The system default gcc is 4.8.5 but I set it to use a different install using environment modules to load gcc-4.9.2 but some environment variables may not have been set correctly, hence why the build file switches to a lower-version GCC but it isn't clear why it looks for 4.8.2 despite that.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/296#issuecomment-422891645:366,clear,clear,366,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/296#issuecomment-422891645,2,['clear'],['clear']
Usability,"Hi Rob,. Thanks! That's brilliant. Just what I needed. Now I've realised what I've done. I simply hadn't checked the manual for a while and in my mind the default (max) k had morphed from 31 into 35 (silly me, really need to check the manual more). . All the best, and thanks again!; Dan",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/632#issuecomment-779421124:91,simpl,simply,91,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/632#issuecomment-779421124,2,['simpl'],['simply']
Usability,"Hi Rob,. The joint distribution of the read and UMI counts can contain important information. The majority of observations (CB + guide combination) lie along a well defined experiment-specific mean trend whose slope is given by the coverage ( ratio of reads to UMIs). Also the same regularity can be observed when aggregating across the cell barcodes. See figure below. The points below the black horizontal line are cells with less than 100 reads. ![image](https://user-images.githubusercontent.com/9895004/83791774-30937080-a668-11ea-9b44-937ba8f69b34.png). At the guide level, it would look like this . ![image](https://user-images.githubusercontent.com/9895004/83792096-941d9e00-a668-11ea-9b26-976332f639fe.png). In general, I often find myself needing to work with read counts. For example, the read counts can be used to estimate the hopping rate and detect hopped reads in multiplexed scRNAseq data as we show in this recent paper https://www.nature.com/articles/s41467-020-16522-z . Rick,",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639005220:129,guid,guide,129,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639005220,4,['guid'],['guide']
Usability,"Hi Rob. I thought about this a little bit more. I am confused. We build the index from decoys. My understanding is that only reads that map to the decoy will be quantified. I am surprised to see that the name for mapped reads would show up in the unmapped_names.txt file. It seems like I need to use something like. Grep -v “$d”. to find the reads that did not map. Is this correct? I have been given the task of exploring our unmapped reads. Running grep is not a big deal. I just want to make sure I do not mess up my downstream analysis. By the way our lab is a huge fan of Salmon. ctrl.1.unmapped]$ cut -d "" "" -f 2 aux_info/unmapped_names.txt | sort | uniq -c; 519916 d; 39097 m1; 34534 m2; 747447 u. Kind regards. Andy. From: Rob Patro ***@***.***>; Reply-To: COMBINE-lab/salmon ***@***.***>; Date: Thursday, May 6, 2021 at 1:53 PM; To: COMBINE-lab/salmon ***@***.***>; Cc: ""andrew e. davidson"" ***@***.***>, Mention ***@***.***>; Subject: Re: [COMBINE-lab/salmon] salmon --writeUnmappedNames produced undocumented result (#657). Hi @aedavids<https://github.com/aedavids>,. Thanks for catching that this is undocumented! This means that the mapping type was determined as mapping to a decoy sequence. When we added this output into the code, the documentation wasn't updated accordingly. We'll update the documentation. Best,; Rob. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/COMBINE-lab/salmon/issues/657#issuecomment-833857753>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AN3VWAQ35L6PU3DKXYIM4ODTML6TPANCNFSM44HLOFXQ>.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/657#issuecomment-833928924:1007,undo,undocumented,1007,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/657#issuecomment-833928924,4,['undo'],['undocumented']
Usability,"Hi Rob. Thanks for the explination. Andy. From: Rob Patro ***@***.***>; Reply-To: COMBINE-lab/salmon ***@***.***>; Date: Friday, May 14, 2021 at 1:41 PM; To: COMBINE-lab/salmon ***@***.***>; Cc: ""andrew e. davidson"" ***@***.***>, Mention ***@***.***>; Subject: Re: [COMBINE-lab/salmon] salmon --writeUnmappedNames produced undocumented result (#657). Hi @aedavids<https://github.com/aedavids>,. Sorry for the delay in replying to your reply here. So I think what you suggest is the right solution, and there are some strange historical reasons we write the decoy names out in the unmapped file. We build the index from decoys. My understanding is that only reads that map to the decoy will be quantified. I am surprised to see that the name for mapped reads would show up in the unmapped_names.txt file. Well, it's the case the decoys are not be quantified. That is, only the target transcripts will appear in the quant.sf file, no decoys should be present there. The main purpose of the decoys is to account for reads not from target transcripts that might otherwise be sequenced in the sample. The reason we report the decoy mapping fragments in the unmapped names file is, as I said, a historical contingency. Basically, since we're not mapping the decoys to targets and counting them toward quantification, one might be interested in knowing where the decoy sequences come from. At some point, the easiest way to do this was just to place the name of these fragments in the unmapped names file (with the d tag) and then grab the reads and go fishing with them in some other way. However, I totally understand why including them in the unmapped names file is confusing. During selective-alignment, if we assign a fragment as best mapping to a decoy, it doesn't get assigned to a quantifiable target, but it's not technically unmapped in the same sense as the other unmapped reads. That is, we know it comes from the decoy sequence, that the alignment score is at least the minimum required, and tha",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/657#issuecomment-843255628:323,undo,undocumented,323,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/657#issuecomment-843255628,2,['undo'],['undocumented']
Usability,"Hi Ryan,. The difficulty is, indeed, exactly as you specify. Given a single-end read, one does not know the length of the _fragment_ from which it originates. In this case the ""right"" thing to do (the best thing we can do) is to consider the read as starting / ending a fragment of every possible length allowed by the user-provided fragment length distribution (with the contribution of each possible fragment weighted by the probability of observing a fragment of that length). In order to make this computationally feasible, one would have to do some clever pre-computation and thing a bit more about how to efficiently update the observed GC model (right now, each mapping contributes a single weight to the model, but under the naive implementation in the single-end case, each mapping would contribute different weights to each bin of the observed GC-bias curve, which would slow things down considerably). Also, as you point out, the quality of the correction would depend somewhat on the user providing appropriate parameters for the fragment length distribution mean and standard deviation — but this seems reasonable in the single-end case. That being said, I'm sure there's a way to handle this efficiently, I'd just have to think about it a bit. Regarding your second question; Salmon learns the fragment length distribution in paired-end data, but not with single-end data. Single-end data can provide a little bit of information (e.g. there is in upper bound on fragment lengths that one can infer based on single-end reads based on how far they map from the end of the transcript), but not enough information to reliably infer a fragment length distribution. cc @mikelove in case he has any thoughts on this.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/83#issuecomment-243833424:1297,learn,learns,1297,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/83#issuecomment-243833424,2,['learn'],['learns']
Usability,"Hi Stephen,. So, the variation you see when you re-run salmon multiple times is _expected_ to be different (and _much_ smaller) than the variance you see when bootstrapping. Why is this? When you re-run salmon, the only variance you are seeing is due to small differences in the order of observations / updates from the streaming collapsed variational Bayes phase of the algorithm. This, in turn can have a _slight_ effect on the initialization conditions of the offline phase of the algorithm, and some of the parameters learned for the auxiliary parameters. However, in each run, you are observing _exactly_ the same set of reads and salmon is producing _exactly_ the same set of alignments; only the order and therefore some of the streaming updates change. So, we expect the final estimated abundances to be _very_ similar to each other. However, when salmon performs bootstrapping, it is actually resampling _with replacement_, from the counts of the range-factorized equivalence classes. Roughly, we expect this resampling to be similar to if we re-sampled _with replacement_ from the original set of input reads. That is, we are re-sampling from our population sample — the observed set of reads — to estimate the variance due to inference. So, for the bootstrap re-samplings, we expect significantly more variance than between subsequent runs of salmon, because the observations from which we are making the inference are actually changing. It is possible e.g. that some uniquely mapped reads may not be chosen in some bootstrap sample (since we are re-sampling the observed read count, but doing so _with replacement_), and so the estimates of sets of related isoforms will change in those samples. Thus, since the observations themselves are changing, we expect the estimates to display greater variance. In fact, this is the main goal of performing the bootstrapping (or Gibbs sampling) — to estimate the uncertainty due to inference if we had observed many reads coming from the same under",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/466#issuecomment-568828362:522,learn,learned,522,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/466#issuecomment-568828362,2,['learn'],['learned']
Usability,"Hi Warren,. I apologize for the short response --- I'm on my way to a meeting. I'm assuming that what was happening before was simply that the problem was diagnosed during VBEM as soon as it pops up, whereas, the NaNs are allowed to propagate during the standard EM. If I had to guess (and this is just a guess), I would blame edge effects in the FSPD for the appearance of `NaN`s (not sure why this goes away without bias correction though!). Also, were I to disable a feature, that (`--useFSPD`) would be the one I would choose to disable since it usually has a negligible effect. That being said, I would be **very** grateful if you were able to produce a dataset that exhibits this issue, as I'd like to fix this ASAP. My guess is that it's a rather small issue, but the problem is that NANs propagate quickly and without mercy!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/50#issuecomment-197891864:127,simpl,simply,127,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/50#issuecomment-197891864,2,['simpl'],['simply']
Usability,"Hi all (@Gaura / @gmarcais),. While this has languished somewhat as we try to figure out what regex engine to include and how best to package it, I wanted to mention that I am attempting something similar in rust (which has a canonical regex crate which, I believe, is supposed to be among the fast ones). That repo is over on [seq_geom_xform](https://github.com/COMBINE-lab/seq_geom_xform) and it relies on [seq_geom_parser](https://github.com/COMBINE-lab/seq_geom_parser). I like @Gaura's geometry string specification, so we're going with that for time time being. If you want to chime in or start a discussion on either of those repos, please do let me know if you have any other thoughts on this generalized scheme. The purpose of the `seq_geom_xform` crate is actually that it will be *both* a rust library (to allow parsing complex geometry descriptions as a regex and extract the relevant sequence) *and* a stand-alone executable that can do streaming sequence transformation from a ""complex"" barcode geometry (e.g. the sciseq3 above) to a ""simple"" geometry (fixed position and fixed length barcode and UMI). Thus, one could imagine (at the cost of sticking a rust executable in the invocation here) replacing this feature by a streaming invocation to `seq_geom_xform` that would take the compressed fastq files as input along with the geometry specification, and which would output two streams (one for each read) with a simplified geometry that could be parsed in the simpler format. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1447552961:1049,simpl,simple,1049,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1447552961,6,['simpl'],"['simple', 'simpler', 'simplified']"
Usability,"Hi all,. I just wanted to provide this space to start a discussion and get feedback about what people believe to be the most sensible _default_ settings for Salmon (in different modes). We're happy to discuss any suggestions, but can start with some specific questions. Here is the most basic. Right now, Salmon has an ""opt-in"" philosophy. That is, a default run starts with the most basic features, and users opt-in to anything that has non-trivial cost (e.g. gibbs sampling, bias correction, and even things that have close to trivial cost but may not always be useful like dumping the equivalence classes to disk). Perhaps some of these defaults should be re-considered, or perhaps this philosophy makes sense as long as the ""opt-in"" behavior is made clear? It's worth noting that one current benefit of this ""opt-in"" mentality is that defaults are more _consistent_ among data-types. For example, GC-bias modeling for single-end libraries is still a feature in testing (on the develop branch), and so could not reasonably be made default at the current time.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/109:75,feedback,feedback,75,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/109,2,"['clear', 'feedback']","['clear', 'feedback']"
Usability,"Hi all. I'm doing a fairly simple RNA Seq experiment right now, but ran into a problem when trying to quantify reads from the chloroplast (A. thaliana). For the entire analysis, I am using the nf-core/rnaseq pipeline (default parameters) which gives me Alignment (STAR) based counts from Salmon at the end and additional counts from FeatureCounts. The whole pipeline runs without problems and the mapping looks good. When I compare the number of reads between Salmon and FeatureCounts, the results are pretty much the same for the nucleus, but for the chloroplast they differ dramatically (e.g. psbI or ATCG00080: Salmon: 24; FeatureCounts: 9277). Looking at the mapping, I would say that FeatureCounts is definitely closer to reality here. ; When I dig deeper, it seems that the genes with the biggest difference between the two analyses are very small genes (e.g. psbI is only 111bp) or tRNAs (which should be removed by the prep method; these would be excluded from the analysis anyway). ; I have now tried several things: I used the nf-core/rnaseq pipeline, skipping the alignment part (--skip_alignment) and using Salmon as a pseudo-aligner (--pseudo_aligner: salmon), which gave results for the chloroplast reads that are quite close to the alignment-based determination by Salmon (e.g. psbI: 372).; I also tried using the pseudo-alignment without the pipeline (indexing: salmon index -t input.fa -r transcripts_index -k 31 pseudomapping: salmon quant -i transcripts_index -l A -1 sequencingdata_R1.fastq.gz -2 sequencingdata_R2.fastq.gz --validate mapping - o transcripts.quant). The result was that the chloroplast numbers were now roughly between the salmon counts from the pipeline and the counts from the pipeline with FeatureCounts. I skipped the trimming part here, so differences are to be expected, but they still seem very high (e.g. psbI 2677).; First, I have no idea where the difference between counts with and without pipelines comes from. I tried to find out what parameters the p",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/798:27,simpl,simple,27,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/798,1,['simpl'],['simple']
Usability,"Hi everyone,. I have two questions. Some motiviation: I'm working on figuring out how to support hg38 with the alt alleles for using transcriptome alignments or the SA method. I'd prefer to just use the whole genome alignments since we generate those for QC purposes anyway. STAR doesn't work with the alt alleles so we can't use it for hg38 and have to use hisat2 for hg38 with alts, but hisat2 doesn't have the genome-to-transcriptome shifter built in. I'm reluctant to use the ubu sam-xlate tool to do genome to transcriptome mappings since that project looks abandoned and I'm not super clear on what Salmon is expecting the format to be for the shifted file. So my current plan is to use the SA method and provide decoys. I have two questions:. 1) Am I going to need to ignore the alt alleles when creating the decoys file? My version of the decoys for hg38 with the alt-alleles has about twice as many decoy regions as the one calculated on just the toplevel chromosomes. 2) What is the minimal format that Salmon is expecting the transcriptome mapped file to look like? Do I need to just report which transcript and which position for every transcript a read overlaps, or do I need to fix the CIGAR string too?",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/371:591,clear,clear,591,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/371,1,['clear'],['clear']
Usability,"Hi guys,. Which existing dependencies would you like to be able to use? There are some of these libraries that cannot be replaced by already installed variants. Specifically,; - BWA --- since the version that is pulled in and used actually requires we expose certain functionality for our lightweight alignment procedure (though this dependency may go away all together if we deprecate lightweight alignment in favor of quasi-mapping).; - Jellyfish --- here, we require the ability to use jellyfish as a library. Specifically, we rely on some headers that are not installed with the standard package. Perhaps here there could be some synergy with Guillaume on making all of the things Salmon uses part of the standard Jellyfish install, but, at least currently, this isn't the case. The CMake build system already looks for existing versions of the following before fetching them:; - Boost; - tbb; - jemalloc. So, the the remaining guys are `libgff` (which is just some small libraryification of a gff parser that I put together a while ago, I don't know that it's in any package manager --- is it? It doesn't even have an associated install script) and `staden IO lib`. For Staden, I'd be happy to have it look for an existing installation, but there is no FindStaden.cmake that I know of, and I don't really know how to write FindX.cmake files appropriately. However, I'd be happy to learn and / or accept pull requests.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-193559957:1386,learn,learn,1386,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/19#issuecomment-193559957,2,['learn'],['learn']
Usability,"Hi vals,; Cutoffs for Salmon as well as STAR+featurecounts/RSEM are all >0, no matter it is normalized value (RPKM, TPM) or rawcount. To my knowledge, there shouldn't be a hugh difference between different pipeline in terms of number of detected genes. Somehow, I think Salmon is over-sensitive to some extent. It's good to know that there will be small >0 expression on most genes. That makes the thing clear~. Best!; Gary",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/120#issuecomment-279960488:404,clear,clear,404,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/120#issuecomment-279960488,2,['clear'],['clear']
Usability,"Hi! I'm really sorry for taking so long to get back to you; things have been quite hectic this semester. The reason it's not being show is because it's been placed in a parameter group that is not made visible by default; the `--posBias` option itself is still available. It's definitely still experimental in that it has not been tested nearly as thoroughly as the other bias models. However, it is useable. Once we have performed more testing, it will migrate into the normal options and be better documented. If you gather any useful data while using this flag, we'd love some feedback!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/191#issuecomment-367448963:580,feedback,feedback,580,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/191#issuecomment-367448963,2,['feedback'],['feedback']
Usability,"Hi, . Running much of anything in command line is new to me. I ran the line below without success. . > ./bin/salmon quant -t transcripts.fa -l OSR -a myseq.bam -o salmon_quant. I keep getting the error below and am not sure why. . > [jointLog] [critical] Note: Alignment-free mapping (i.e. mapping without subsequent selective-alignment) has not yet been throughly tested under the pufferfish-based index and using the pufferfish-based mapping strategies. Thus, disabling of selective-alignment is not currently allowed. We may, potentially explore re-enabling this option in future versions of salmon. I am betting this is something really simple. I'd appreciate any help... Thank you!",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/511:641,simpl,simple,641,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/511,1,['simpl'],['simple']
Usability,"Hi, ; I've been trying to run alevin for single cell data. I've been using test data and the salmon alevin command seems to work right until the end, and then the core is dumped just as counts are in the csv format. I've also tried running it without --dumpCsvCounts and this also results in a segmentation fault. . What I was running:; salmon alevin -l ISR -1 ./hgmm_100_S1_L002_001.fastq.1.gz -2 ./hgmm_100_S1_L002_001.fastq.2.gz --chromium -i geneset.dir/geneset_coding_exons.salmon.index -p 10 -o salmon.dir/hgmm_100_S1_L002_001 --tgMap transcript2geneMap.tsv --dumpCsvCounts. Final part of output:; Analyzed 287 cells (100% of all).; [2019-01-25 11:14:44.509] [alevinLog] [info] Total 46729.00 UMI after deduplicating.; [2019-01-25 11:14:44.509] [alevinLog] [warning] Skipped 63 barcodes due to No mapped read; [2019-01-25 11:14:44.529] [alevinLog] [info] Clearing EqMap; Might take some time.; [2019-01-25 11:14:44.561] [alevinLog] [info] Starting Import of the gene count matrix of size 224x19879.; [2019-01-25 11:14:44.576] [alevinLog] [info] Done initializing the empty matrix.; [2019-01-25 11:14:45.067] [alevinLog] [info] Done Importing gene count matrix for dimension 224x19879; [2019-01-25 11:14:45.770] [alevinLog] [info] Starting dumping cell v gene counts in csv format; Segmentation fault (core dumped) . I am running version 0.12.0 of salmon, installed via bioconda. I have also allocated 30GB of memory for the job, so this isn't a memory issue.; I have seen other users having similar issues using salmon quant having installed salmon through conda and the suggestions have been to install from binaries. This is not an option as salmon needs to be run easily using a conda environment. ; Has any headway been made into fixing the bioconda build?. Thanks,; Anna",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/337:861,Clear,Clearing,861,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/337,1,['Clear'],['Clearing']
Usability,"Hi, such a beautiful RNA-seq analysis tool!!!. So when I used it I have a question: does the relatively high(0.9~) or low(0.1~) strand bias mean that the library is stranded? I can't well understand the exact meaning of this value. Could you give me some guidance? Great gratitude for you~~~",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/762:255,guid,guidance,255,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/762,1,['guid'],['guidance']
Usability,"Hi,. I am testing Alevin, and would like to compare against Cell Ranger on my data set. While primary mapping statistics indicate more reads mapped, I would like to compare the results in the final analysis, in Seurat. Many steps rely on HGNC Gene symbols as opposed to Ensemble IDs. ### What is the best way to convert ensembl IDs to gene symbol in Alevin?. Alevin (aligned as in this [gist](https://gist.github.com/k3yavi/c501705ed2d29b12b0d10cf78b3ed001#file-alevin-default-ipynb), imported to R in this [tutorial](https://combine-lab.github.io/alevin-tutorial/2018/running-alevin/)) returns ensembl IDs in format like ""ENSG00000215910.7"". ```R; require(""fishpond""); require(""tximport""); ; files <- file.path(""[...]/alevin/quants_mat.gz""); file.exists(files); txi <- tximport(files, type=""alevin"");; rownames( txi$counts); ``` . I am currently converting these using biomart with suboptimal adaptations:. ```R; BiocManager::install(""biomaRt""); require('biomaRt'); mart <- useDataset(""hsapiens_gene_ensembl"", useMart(""ensembl"")); genes <- rownames(txi$counts); df$id <- NA; meta.genes <- getBM(attributes = c(""ensembl_gene_id"",""external_gene_name"", ""description""), ; values = genes, mart = mart ); ```; Manual adaptations:. 1. I trim IDs after dot (""ENSG00000215910.7"" → ""ENSG00000215910”); 2. I remove NA values (not all trimmed gene IDs are found in biomaRt); 3. I add up counts of genes (per ENS.ID) with the same gene symbol, e.g. “Y_RNA” or “HSPA14”. ```R; g.LookUp = meta.genes[,2]; names(g.LookUp) = meta.genes[,1]; ; # 1. Trim; ensembl_ID.simple =str_split_fixed(genes,pattern = '\\.', n=2)[,1]; ; genes.converted = g.LookUp[ensembl_ID.simple]; any.duplicated(genes.converted); ; # ...etc; ```. Is there a better way to convert IDs, possibly implemented in Alevin / Salmon?",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/448:1549,simpl,simple,1549,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/448,2,['simpl'],['simple']
Usability,"Hi,. I have been running salmon v1.4.0 on 324 samples. In 8 samples I did not get any quantification and the process ended with a warning like "".....salmon was only able to assign 0 fragments to transcripts in the index...."". The command line I used is as follow (I simplified the paths and file names):; salmon quant -p 20 -i Salmon_Index -l A --seqBias --gcBias --biasSpeedSamp -1 $FASTQ1.R1.fastq.gz -2 $FASTQ2.R2.fastq.gz -o $outDIR --validateMappings. These same 8 samples were processed with HISAT2 and the overall alignment rate was above 80%. I attached the log file for one of the 8 runs; [logFile.txt](https://github.com/COMBINE-lab/salmon/files/5846381/logFile.txt). Do you have any suggestions ? do you need more info ?. Thanks",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/616:266,simpl,simplified,266,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/616,1,['simpl'],['simplified']
Usability,"Hi,; Basically Alevin performs CB sequence correction within 1 distance hamming ball, the intuition being the set of real CB should ideally be more than 1 edit distance away.; Here I think the x axis gives you the count of reads for a CB before sequence correction and on y axis post sequence correction. Hope it helps",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/488#issuecomment-591733839:90,intuit,intuition,90,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/488#issuecomment-591733839,2,['intuit'],['intuition']
Usability,"Hi,; I am used to work with RNA-seq data sets from human or mouse (thus well-annotated organisms), for which I always use Salmon.; Now a colleague of mine asked whether I could help him with analyzing a data set obtained from a non-model organism (A) for which even no reference transcriptome is available. I therefore would like to map the reads to the transcriptome of the closest species (B) available in ENSEMBL. [It basically resembles the situation mentioned [here](https://www.biostars.org/p/253396/) at the BioStars forum, but then at the transcriptome level]. . I started by running Salmon using the settings I normally use for mouse, but the the percentage of mapped reads is extremely low, i.e varying between 0.5-2%. That it would be lower than usual I expected, but not this low....; Because I cannot easily see the forest for the trees, I would appreciate if some suggestions could be given that in effect 'relax' the criteria for mapping, eventually resulting in an increased mapping%. Thanks!; G. My code/arguments:; Input: 150 bp paired-end RNA-seq data.; Average number of reads per sample: ~22M. Transcriptome index file is 'decoyed'; generated with default settings (k=31). Salmon arguments:; ```; /home/guidoh/SALMON/salmon-latest_linux_x86_64/bin/salmon quant -i ./Lotgi1_combined_index \; 	--libType A \; 	--seqBias \; 	--gcBias \; 	--biasSpeedSamp 5 \; 	--validateMappings \; 	--numGibbsSamples 20 \; 	-1 ${F1} \; 	-2 ${R1} \; 	-o ${salmonsubdir}$fn4; ```",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/403:1224,guid,guidoh,1224,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/403,1,['guid'],['guidoh']
Usability,"Hi,; I don't want to report a bug, but rather have 2 (unrelated) questions:; Because we don't generate that many RNA-seq data sets, I am using Salmon every now and then. I really like the program (speed!) and the obtained results. - Since I don't use Salmon on a daily basis, I usually have (would like) to update Salmon to its latest release. For these the binaries you (used to) provide are very convenient. I noticed that these are not explicitly linked to anymore on the page `https://github.com/COMBINE-lab/salmon/releases`, although these still are available through [this link](https://github.com/COMBINE-lab/salmon/files/2099291/salmon-latest_linux_x86_64.tar.gz) that is regularly posted on this Github 'forum'. Please note that I learned you favor the Bioconda route for keeping Salmon up to date. Nevertheless, provided it doesn't take too much effort, I would appreciate it very much if you could still make the binaries available. - My 2nd question has to do with some basic QC-ing: I am currently analyzing a set of 96 mouse samples. While running Salmon, I noticed most samples do have a nice percentage of mapped reads (>80%), but I also noticed that for samples this percentage was much lower (<50%).; Q: Is there an easy way of obtaining these numbers (""percent_mapped"") for all samples that were mapped in a Salmon run (without manually reviewing all 96 samples the 'meta_info.json' file)? In other words, how to obtain an 'overall log file'?. Thanks,; Guido",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/252:740,learn,learned,740,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/252,2,"['Guid', 'learn']","['Guido', 'learned']"
Usability,"Hi,; I would like quantify guide-RNAs (based on 5'-tagged scRNAseq 10X feature barcoding) using Alevin. Read 1 is 26bps long (16 CB +10 UMI) and Read 2 is 58bps long (19 constant region + 21 guide sequence). Now, when I use the following settings . `salmon alevin -l ISR --barcodeLength 16 --umiLength 10 --end 5 --featureStart 19 --featureLength 21 `. I get this error . > `Transcript to Gene Map File not provided`. . However, when I use the following instead. `salmon alevin -l ISR --citeseq --featureStart 19 --featureLength 21; `. It works but since `--citeseq` assumes `--umiLength=12`, I get the following output . > `[2020-06-03 13:53:30.298] [alevinLog] [info] set CITE-seq minScoreFraction parameter to : 0.797619; > ; > [2020-06-03 13:53:30.298] [alevinLog] [info] Found 64 transcripts(+0 decoys, +0 short and +0 duplicate names in the index); > [2020-06-03 13:53:30.298] [alevinLog] [info] Filled with 64 txp to gene entries ; > [2020-06-03 13:53:30.298] [alevinLog] [info] Found all transcripts to gene mappings; > [2020-06-03 13:53:30.304] [alevinLog] [info] Processing barcodes files (if Present) ; > ; > ; > processed 52 Million barcodes; > ; > [2020-06-03 13:54:43.733] [alevinLog] [info] Done barcode density calculation.; > [2020-06-03 13:54:43.733] [alevinLog] [info] # Barcodes Used: 52200250 / 52200250.; > [2020-06-03 13:54:43.826] [alevinLog] [info] Forcing to use 100000 cells; > [2020-06-03 13:54:43.964] [alevinLog] [info] Throwing 49909 barcodes with < 10 reads; > [2020-06-03 13:54:43.984] [alevinLog] [info] Total 50092(has 201 low confidence) barcodes; > [2020-06-03 13:54:44.191] [alevinLog] [info] Done True Barcode Sampling; > [2020-06-03 13:54:44.285] [alevinLog] [info] Total 1.70493% reads will be thrown away because of noisy Cellular barcodes.; > [2020-06-03 13:54:45.790] [alevinLog] [info] Done populating Z matrix; > [2020-06-03 13:54:45.790] [alevinLog] [info] Total 0 CB got sequence corrected; > [2020-06-03 13:54:45.790] [alevinLog] [info] Done indexing B",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531:27,guid,guide-RNAs,27,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531,2,['guid'],"['guide', 'guide-RNAs']"
Usability,"Hi,; Thank you for the detailed explanation. ; For the first question, ideally you should include the alternate alleles. But they should be part of the transcriptome, instead of the genome. We expect the size of the decoys to double if alt alleles are included in the genome. This is because the decoys are simply regions of high sequence identity between a transcript and the genome. Hence, with alleles as part of the genome, each transcript will map almost equally well to alleles.; If you're running salmon in the alignment mode, the input bam/sam file should include the CIGAR string as well. There is a flag, `--noErrorModel`, to ignore the CIGAR but that is not recommended, since salmon uses the information for scoring the alignments. ; I hope that answers your concerns.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/371#issuecomment-501432106:307,simpl,simply,307,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/371#issuecomment-501432106,2,['simpl'],['simply']
Usability,"Hi,; When generating an index for the latest human gencode transcriptome (release 35) I noticed this message:; `[2020-11-25 09:42:04.534] [puff::index::jointLog] [warning] Entry with header [ENST00000674361.1|ENSG00000241743.4|OTTHUMG00000022220.5|OTTHUMT00000530527.1|XACT-203|XACT|347561|lncRNA|] was longer than 200000 nucleotides. This is probably a chromosome instead of a transcript.`. Since I don't recall that I have seen this notification before when doing previous analyses, I had a look at this particular transcript. It turns out it indeed has been annotated as a (very long!), but apparently true transcript (a lncRNA):; `Transcript: XACT-203 ENST00000674361.1, Exons: 2, Coding exons: 0, Transcript length: 347,561 bps. Manual annotation (determined on a case-by-case basis) from the Havana project.`; See [here](http://www.ensembl.org/Homo_sapiens/Transcript/Summary?db=core;g=ENSG00000241743;r=X:113616300-114059289;t=ENST00000674361).; ; I realize that this is not really a bug (you have to set such cutoff at some (likely arbitrary??) value), and it applies to only a single human transcript, but considering this case, would it also be OK to set the cutoff to e.g. 400k (instead of 200k)?. Thanks for addressing my curiosity!; Guido. **Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**; - salmon 1.3.0; **To Reproduce**; - I followed [this workflow](https://combine-lab.github.io/alevin-tutorial/2019/selective-alignment/) but using the latest human gencode files.; **Desktop (please complete the following information):**; - OS: Linux Fedora",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/591:1246,Guid,Guido,1246,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/591,1,['Guid'],['Guido']
Usability,"Hi,; after reading reading the docs at http://salmon.readthedocs.io/en/latest/salmon.html it seems to me nowhere was mentioned how to input single file with read pairs, occasionally with some singletons. Is that not supported? Please make it clear in the docs if the only way to feed salmon is via separate fwd and reverse files (and no singletons supported if -1 and -2 args are used). While at it, in teh same page in section `Quasi-mapping-based mode (including lightweight alignment)` is hidden how to index reference trasncriptome. Please move those parts at the beginning, before discussing `Providing multiple read files to Salmon`. Thank you.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/240:242,clear,clear,242,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/240,1,['clear'],['clear']
Usability,"Hi,; i met a problem when installing the index for salmon. The feedback suggests that ""server did not respond before timeout"". This problem is shown in the following picture.; I've already given it enough space for running, while it seems that it was stuck in the first step. And the index file only contains ""pre_indexing.log ref_indexing.log""; So could you please help me to solve this problem?; Thanks; ![image](https://user-images.githubusercontent.com/100278952/155299114-10a7e3b7-bf08-49aa-824d-48dcbaa1fd71.png)",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/755:63,feedback,feedback,63,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/755,1,['feedback'],['feedback']
Usability,"Hi,; in your documentation, you clearly state that salmon expects a ""random"" order of reads and you suggest to shuffle the read files.; In my experiments, I created a set of unshuffled and shuffled .bam files (using samtools bamshuf). The resulting quant.sf files always were exactly identical. Is shuffling not longer needed (or probably never was for .bam files)? Or has salmon a built-in shuffling function?. Cheers,; Tobi",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/155:32,clear,clearly,32,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/155,1,['clear'],['clearly']
Usability,"Hi,; would you mind cleaning up the STDOUT and STDERR output from `salmon quant` and `salmon index`? Commonly `STDOUT` should be used for normal output messages and `STDERR` for errors or at worst warnings. Salmon writes most of the messages to `STDERR`. 1. `Version Info: This is the most recent version of Salmon.` is output to `STDOUT`. I find it useless. If salmon run some network connection to figure out its version it is `a)` prone to errors, `b)` I would expect a fat warning in the documentation a `phone home` feature is builtin, `c)` it is likely to fail on more network-restricted installations. Or, `d)`, the message is incorrect. I suggest drop the message altogether. 2. `salmon quant` writes a lot of normal messages to `STDERR`. Please use `STDOUT` instead. If a program exits with a non-zero exit code it is common to read its `STDERR` output to learn what was the cause for the error. It is awkward to realize there is lots of unrelated text. Please follow common rules on Unix. 3. The docs at http://salmon.readthedocs.io/en/latest/salmon.html did not mention the `fmd` index is just a plain index from `bwa`. Why don't you instruct users to use `bwa index` instead? It would be clearer (if that is the type of index you employ). 4. `salmon index` behavior. ```; salmon index -t Homo_sapiens.GRCh38.cdna.all.fa -i Homo_sapiens.GRCh38.cdna.all --type quasi -k 31; index [""Homo_sapiens.GRCh38.cdna.all""] did not previously exist . . . creating it; [2018-06-25 19:25:57.122] [jLog] [info] building index; RapMap Indexer. [Step 1 of 4] : counting k-mers; [2018-06-25 19:25:57.176] [jointLog] [warning] Entry with header [ENST00000434970.2], had length less than the k-mer length of 31 (perhaps after poly-A clipping); [2018-06-25 19:25:57.176] [jointLog] [warning] Entry with header [ENST00000448914.1], had length less than the k-mer length of 31 (perhaps after poly-A clipping); ...; [2018-06-25 19:26:07.297] [jointLog] [warning] Entry with header [ENST00000579054.1], had length l",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/242:865,learn,learn,865,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/242,1,['learn'],['learn']
Usability,"Hi:; Recently, I learned to use salmon in our lncRNA research project. I am confused in a point. ; As shown in the documentation (https://salmon.readthedocs.io/en/latest/salmon.html), according to our understanding, if we want those incompatible mappings will be discarded, the incompatPrior should be set as 0.0. And our RNA-Seq library type is dUTP based strand-specific RNA-Seq, so we should use ISR. ; But I am confused with https://gitter.im/COMBINE-lab/salmon?at=594a76d402c480e67268f02b and https://github.com/COMBINE-lab/salmon/issues/116; we want the expression level of antisense. Since there are about 0.5~1% reads can be the wrong reads mapped to the reverse strand of the gene (dUTP stranded protocol, the strand error (i.e. % of reads sequenced from the wrong strand of the RNA) is typically 0.5-1%). Can we use the incompatPrior option and get the expression level of antisense(right) in a single run?; This is our command line `salmon quant -i Ath_TX.index -l ISR -1 test_R1.fq.gz -2 test_R2.fq.gz -o TEST_TX_QUANT --incompatPrior 0.0 --seqBias --gcBias --threads 20`.; That those wrong mapped alignments (they didn't follow the ISR fule, maybe the error from the error of process of library construction) will be discarded.; Thank you and all the best.; Linhua",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/182:17,learn,learned,17,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/182,1,['learn'],['learned']
Usability,"I actually didn't test it :). I'll confirm the current behavior tomorrow. Thanks for following up on this!. > On Jan 3, 2016, at 8:37 PM, Rob Patro notifications@github.com wrote:; > ; > Actually, @mdshw5 --- it's not quite clear to me why the parser isn't doing the right thing in this case. If you take a look at how the paired-end sequence parser is actually populating the internal buffer (e.g. here), it is reading one entry from stream1 and then one entry from stream2. I'm guessing there may be some issue with having two different handles open to the same fifo? However, that doesn't seem like it should be a problem. Given the way the code is actually reading from the different streams, it's not clear to me why it's not currently working as expected. I'll try and take a deeper look.; > ; > —; > Reply to this email directly or view it on GitHub.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-168566647:224,clear,clear,224,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-168566647,4,['clear'],['clear']
Usability,"I also wonder why salmon not output original reads counts. update:. Because it is more accurate. DeSeq2 should accept it. As for now, maybe we could simply round to the nearest integer. > NumReads — This is salmon’s estimate of the number of reads mapping to each transcript that was quantified. It is an “estimate” insofar as it is the expected number of reads that have originated from each transcript given the structure of the uniquely mapping and multi-mapping reads and the relative abundance estimates for each transcript.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/437#issuecomment-751189286:149,simpl,simply,149,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/437#issuecomment-751189286,2,['simpl'],['simply']
Usability,"I am not sure what this `-m` flag refers to. It is not currently an option, and doesn't appear to clearly have been one in the past either.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/678#issuecomment-1138623879:98,clear,clearly,98,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/678#issuecomment-1138623879,2,['clear'],['clearly']
Usability,"I am trying to quantify these data at the transcript level which is why the number of features is this big. For the PBMC3k I was trying with a transcript to gene --tgMap but was still seeing the same error. I realized I forgot to update the path to the run.sh script when calling the 0.12.0 binary (I updated the path to the binary but no to the script). When running the wrapper in the 0.12.0 folder I could succesfully run alevin on the CD14 dataset, with or without the --forceCells 4000 flag. I tried to run alevin-0.12.0 on the PBMC 3k dataset but I got the same error. I am now trying to run it on all the FACS-sorted samples and I will see how that goes. I feel this is happening slightly inconsistently (although very frequently). Notably, it either happens after `Clearing EqMap; Might take some time.` or `Starting Import of the gene count matrix of size 5344x167268.`. I have had it happen once in the middle of the `Analyzed xxx cells (yy% of all)` phase. I just managed to succesfully process the CD19+ B cells from the 10x v1 dataset, I'll attempt to process the other FACS sorted samples overnight and let you know how it went. Thank you",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-445109075:773,Clear,Clearing,773,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-445109075,1,['Clear'],['Clearing']
Usability,"I can try '^' and '$' after lunch. I didn't test any other library, since boost was already a pre-requisite for salmon and my focus was on getting it to work first. But now that it is done, other libraries can be tried. However, at this moment, I'm not clear about the effort and speed-up ratio.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1013348732:253,clear,clear,253,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/734#issuecomment-1013348732,2,['clear'],['clear']
Usability,"I faced the same problem and found a simple solution. The trick is at line 585 of the cMakeList.txt. ""if (${TBB_VERSION} VERSION_GREATER_EQUAL 2018.0)"". It checks if you have tbb version 2018 or above. If you install tbb BEFORE running cmake, it will fulfill the requirement and bypass installing tbb in the make command, hence bypass the error. The solution:; 1. Delete the salmon folder and download a fresh one from github; 2. sudo apt update (this step is very important, to update the packages to be above version 2018) ; 3. sudo apt-get install libtbb-dev; 4. (Optional) apt-cache policy libtbb-dev (check the version of libtbb, it should be 2019 or above); 5. Then follows the standard installation (cmake, make etc.) The error should disappear and compile successfully. Thanks!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/497#issuecomment-610977958:37,simpl,simple,37,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/497#issuecomment-610977958,2,['simpl'],['simple']
Usability,"I have a similar problem.; Attached are:; 1. gtf file, where clearly, the gene_ id and transcript_id are provided; 2. quant files are as followed for gene and transcripts; 3. my command as followed:; ---. /gpfsdata/apps/salmon-latest_linux_x86_64/bin/salmon quant \; -i /gpfshome/hockchuan/SALMON/GCF_900626175.2_cs10_index \; -l ISR \; -1 /gpfsdata/JangiLab/hockchuan/170302/2.Trimmomatic_output/clean_HEADBANDSTEM_1.fastq.gz \; -2 /gpfsdata/JangiLab/hockchuan/170302/2.Trimmomatic_output/clean_HEADBANDSTEM_2.fastq.gz \; --seqBias \; --gcBias \; --posBias \; --incompatPrior 0.0 \; --geneMap /gpfsdata/JangiLab/hockchuan/cs10_reference_genome/GCF_900626175.2_cs10_genomic.gtf \; --recoverOrphans \; --allowDovetail \; --threads $NSLOTS \; --dumpEq \; --minScoreFraction 0.65 \; --writeMappings /gpfshome/hockchuan/SALMON/MAP/HEADBANDSTEM \; --fldMean 250 \; --fldSD 25 \; --writeOrphanLinks \; --writeUnmappedNames \; --quiet \; -o /gpfshome/hockchuan/SALMON/HEADBANDSTEM_quant; ---. [fewLines.gtf.txt](https://github.com/COMBINE-lab/salmon/files/5383013/fewLines.gtf.txt); [quant.genes.txt](https://github.com/COMBINE-lab/salmon/files/5382998/quant.genes.txt); [quant.txt](https://github.com/COMBINE-lab/salmon/files/5382999/quant.txt)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/569#issuecomment-708949661:61,clear,clearly,61,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/569#issuecomment-708949661,2,['clear'],['clearly']
Usability,"I have already run them all (successfully) separately as pairs, but for downstream analysis I need them to be a single library, so I thought it would be simpler to run them as multiple input files..?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/329#issuecomment-446212203:153,simpl,simpler,153,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/329#issuecomment-446212203,2,['simpl'],['simpler']
Usability,"I have couple of simple question on ""list of dir"" to supply part.; 1) DO i have to supply the complete path or just names of dir as a txt file?. I tried both and it does not work! But when i try one folder in the dir it works. salmon quantmerge --quants barcode01_quant -o all_barcodes_merged.txt; Version Info: This is the most recent version of salmon.; [2019-10-16 14:15:06.726] [mergeLog] [info] samples: [ barcode01_quant ]; [2019-10-16 14:15:06.726] [mergeLog] [info] sample names : [ barcode01_quant ]; [2019-10-16 14:15:06.726] [mergeLog] [info] output column : TPM; [2019-10-16 14:15:06.726] [mergeLog] [info] output file : all_barcodes_merged.txt; [2019-10-16 14:15:06.726] [mergeLog] [info] Parsing barcode01_quant/quant.sf. ###; When i try a list of all the folders. almon quantmerge --quants quant_dir_list.txt -o all_barcodes_merged.txt; Version Info: This is the most recent version of salmon.; [2019-10-16 14:15:54.698] [mergeLog] [info] samples: [ quant_dir_list.txt ]; [2019-10-16 14:15:54.698] [mergeLog] [info] sample names : [ quant_dir_list.txt ]; [2019-10-16 14:15:54.698] [mergeLog] [info] output column : TPM; [2019-10-16 14:15:54.698] [mergeLog] [info] output file : all_barcodes_merged.txt; [2019-10-16 14:15:54.698] [mergeLog] [critical] The sample directory quant_dir_list.txt either doesn't exist, or doesn't contain a quant.sf file. head quant_dir_list.txt; barcode01_quant; barcode02_quant; barcode03_quant; barcode04_quant; barcode05_quant; barcode06_quant; barcode07_quant; barcode08_quant. I have even tried with complete path to the dir and it fails. What am i doing wrong. Thanks",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/179#issuecomment-542828122:17,simpl,simple,17,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/179#issuecomment-542828122,2,['simpl'],['simple']
Usability,"I like the opt-in structure, I think in general keeping models simple by default is a good way of doing things. I know people just run programs without reading documentation and expect it to work perfectly. But I think somewhere, maybe even in the default quantification help, there should be a table or decision tree with information about how to choose options. E.g. > ""Did you do random hexamer priming? -> Use the --seqBias option.""",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/109#issuecomment-267003338:63,simpl,simple,63,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/109#issuecomment-267003338,2,['simpl'],['simple']
Usability,"I see. TopHat actually aligns the reads to the genome (using Bowtie and a strategy to perform split-read mapping). The results of TopHat, then, are meant to be used with tools like Cufflinks, which expects reads to be mapped directly to the genome rather than to the transcriptome. Salmon, on the other hand, works like tools such as RSEM / eXpress, which expect alignments to the transcriptome directly. This can be accomplished by either mapping the reads directly to the transcript sequences (using e.g. Bowtie2 / BWA-MEM) or by mapping the reads to the genome using a tool such as STAR, and telling it to project the alignments onto genomic coordinates. However, I should mention that the easiest thing to do is to simply have Salmon build and index on your transcript set and then pass it the raw (compressed) FASTQ files directly. Since Salmon provides an accurate and lightweight alignment proxy, it can accurately assess transcript abundance estimates directly from the raw (unaligned) sequenced reads. If you have questions about using either of these modes, please take a look at [the documentation](https://salmon.readthedocs.io/en/latest/). I'd also be happy to answer any other questions you might have.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/131#issuecomment-293273710:719,simpl,simply,719,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/131#issuecomment-293273710,2,['simpl'],['simply']
Usability,"I think something like this (like samtools, kallisto etc. ```; salmon v0.6.0 - description here. Usage: salmon <COMMAND> [-h | options]. Commands:; index Create a salmon index; quant Count blah; swim Whatever; ```. would be _much_ clearer than the current help. ```; salmon --help; Allowed Options:; -v [ --version ] print version string; --no-version-check don't check with the server to see if this is the; latest version; -h [ --help ] produce help message. Salmon v0.6.0; ===============. Please invoke salmon with one of the following commands {index, quant, swim}.; For more information on the options for these particular methods, use the -h; flag along with the method name. For example:. salmon index -h. will give you detailed help information about the index command.; ```",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/72:231,clear,clearer,231,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/72,1,['clear'],['clearer']
Usability,"I think we should sort out this issue step by step. If you say `libstaden` has an important bugfix we should upgrade to the latest version in any case. Do you have a link to this bug? I admit this update simply slipped through - we should have upgraded this in the beginning of this year. Usually we try to follow upstream closely (which we failed for salmon blatantly for several reasons - one is the close connection to pufferfish).; Regarding `pufferfish`: We tried hard to get `pufferfish` packaged but failed (due to the use of other versions of `spdlog`, `cereal`, and `fmt`) However, since we can't run `fetchPufferfish.sh` *inside the build process* I was running it separately and added the downloaded source in [debian/external/pufferfish](https://salsa.debian.org/med-team/salmon/-/tree/master/debian/external/pufferfish) So I think the requirement of salmon should be fulfilled. I confirm your feeling that pufferfish is important for the current issue.; However, in the test I did when opening this bug report I did not do that pre-downloading of pufferfish since I was building right in the downloaded source tarball. `libpufferfish-dev` was not installed by `apt build-dep salmon` since this package does not exist.; Kind regards, Andreas.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464878371:204,simpl,simply,204,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464878371,2,['simpl'],['simply']
Usability,I tried re-installing salmon today after seeing your message. A simple `conda install salmon` worked for me this time. I don't know why it was giving me an error back then and not one now though....,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1137154359:64,simpl,simple,64,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1137154359,2,['simpl'],['simple']
Usability,I will be trying your suggestion out. I might be able to share with you a toy dataset with a fewer number of guides. I will update you as soon as I get it.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639618956:109,guid,guides,109,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639618956,2,['guid'],['guides']
Usability,"I'll have to check if the ignoring of the `CPPFLAGS` is a problem with bwa's build system, or if I'm simply neglecting to pass the environment along properly.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/45#issuecomment-193960879:101,simpl,simply,101,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/45#issuecomment-193960879,2,['simpl'],['simply']
Usability,"I'm curious too if there is any specific feedback from the devs on whether using salmon on bacterial coding sequences is generally seen as appropriate or not? (sorry if this information is already available elsewhere, I've looked a bit and not seen it yet)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/350#issuecomment-582077473:41,feedback,feedback,41,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/350#issuecomment-582077473,2,['feedback'],['feedback']
Usability,"I'm going to cc @dpryan79 on this — does it just not finish? It seems to work within our GitHub CI, where we have to grab the prebuilt salmon to test `simpleaf`.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/895#issuecomment-1784122719:151,simpl,simpleaf,151,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/895#issuecomment-1784122719,2,['simpl'],['simpleaf']
Usability,"I'm in touch with the people administrating the cluster as well and based on their guidance I ran alevin with exclusive access, however that did not help.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-447403587:83,guid,guidance,83,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-447403587,2,['guid'],['guidance']
Usability,"I'm looking for some guidance on recommendations / best practices for quantifying direct RNA / cDNA Nanopore reads using Salmon. It is my understanding that the selective alignment algorithm Salmon employs is not well-suited for long reads (#602), and therefore the software needs to be run in alignment mode for accurate counting. My main question then concerns the optimal parameters for the upstream alignment step. The ONT community seems to have settled on using minimap2 for this, but beyond that the guidance gets a bit murky... The [minimap2](https://github.com/lh3/minimap2/#map-long-splice) documentation suggests the following command for mapping long RNA reads:. `minimap2 -ax splice:hq -uf ref.fa reads.fq > aln.sam`. This approach seems to employ a splicing aware algorithm against a genomic reference, using canonical splicing signals to help map the transcripts. However, this method doesn't seem to be applicable to Salmon given the requirement that the reads are aligned directly to the transcriptome (hence the need to account for splicing with '_-ac splice_' is lost). An alternative approach I've seen (i.e., the one used in ONT's own DGE [pipeline](https://github.com/nanoporetech/pipeline-transcriptome-de)) is to use minimap2 to align to the transcriptome reference but to retain a large number of secondary mappings (-N 100 in minimap2):. `minimap2 -ax map-ont -N 100 transcriptome.fa reads.fq`. This makes more sense in terms of the _-ax_ preset used, but I guess I'm just wondering then what the optimal input for Salmon would be in order to get the most accurate count data? I know secondary mappings are important for the algorithm to calculate uncertainty / maximum likelihood, but is there an recommend number of these to retain? The logic behind allowing for a high number of secondary alignments when using a transcriptome reference is to account for the high similarity among isoforms. From a high-level view I could see how this might be problematic though, dependin",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/790:21,guid,guidance,21,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/790,2,['guid'],['guidance']
Usability,"I'm planning on using your wonderful Salmon tool v0.12.0 for generating TPM counts with a view to quantifying relative abundance of certain bacterial antibiotic resistance genes in my shotgun (human gut) metagenomes. So as to ensure strict mappings to the genes of interest, I would like to set the value of the flag '--minScoreFraction' to 0.90. Since its a metagenome with a truck-load of genes from several microbes, I plan to quantify only those genes that show >=90% identity at the nucleotide-level to the known antibiotic resistance genes (of interest). My question here really is whether setting the flag minScoreFraction to 0.90 achieves anything close to what I've in mind? Below is the full command line I used for Salmon-based quantification of the tetracycline resistance gene tetW. salmon quant --meta -i amr_indices/tetW_index -l A -1 Corr_clean_phiclean_10_8_L001_R1_001.fastq.gz -2 Corr_clean_phiclean_10_8_L001_R2_001.fastq.gz -o 10_tetW_test_quant --mimicStrictBT2 --validateMappings --minScoreFraction=0.90. I would highly appreciate any feedback from you in this regard. Many thanks in advance for your time.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/330:1058,feedback,feedback,1058,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/330,1,['feedback'],['feedback']
Usability,"I'm using Salmon to quantify isoforms in TCGA short-read data, which have fairly short reads (48-50 bp, generally). I noted on the documentation that a k-mer size of 31 while building the index is good for 75 bp and up, but shortening that length might be better for smaller reads. How short of an index should I use for TCGA, and how should I go about thinking about which number is optimal? I'm not sure what the tradeoffs are, and don't want to randomly pick a number smaller than 31 that may not be best. Thanks so much for any help or guidance you can provide! I've used STAR+RSEM, Kallisto, and have now settled on Salmon for my project, and I am really, really happy with its versatility, speed, and accuracy. Excellent work on this tool!. Kindest regards,; Ryan Englander. MD/PhD Candidate, GS3; Jackson Laboratory for Genomic Medicine",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/807:540,guid,guidance,540,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/807,1,['guid'],['guidance']
Usability,"I've run into this (or a similar) issue attempting to install Salmon on the UC Berkeley HPC cluster. Iconv was present within one of our Python installs, but that didn't seem to have the header files, so I installed libiconv/1.16 thinking this was a dependency issue. Unfortunately this didn't seem to help. Any guidance would be greatly appreciated. Here is my build script to the point of failure:; ```sh; #!/bin/sh ; MODULE_HOME=/clusterfs/vector/home/groups/software/sl-7.x86_64; PACKAGE_NAME=salmon; GITHUB_URL=https://api.github.com/repos/COMBINE-lab/salmon/releases/latest; VERSION=$(curl -s $GITHUB_URL | \; grep '""tag_name"":' | \; cut -d : -f 2,3 | \; tr -d \"",v | \; xargs); LATEST_RELEASE=$(curl -s $GITHUB_URL | \; grep '""tarball_url""' | \; cut -d : -f 2,3 | \; tr -d \"", | \; xargs); module load gcc/7.4.0 cmake/3.15.1 boost/1.70.0-gcc libiconv/1.16; export CC=`which gcc`; export CXX=`which c++`. cd $MODULE_HOME; mkdir -p source/$PACKAGE_NAME/$VERSION; INSTALL_DIR=$MODULE_HOME/modules/$PACKAGE_NAME/$VERSION; mkdir -p $INSTALL_DIR; mkdir -p modfiles/$PACKAGE_NAME. cd source/$PACKAGE_NAME/$VERSION; wget $LATEST_RELEASE -O - | tar -xz --strip-components 1; cmake -DBOOST_ROOT=/global/software/sl-7.x86_64/modules/gcc/7.4.0/boost/1.70.0-gcc -DCMAKE_INSTALL_PREFIX=$INSTALL_DIR; make; ```; And the tail of the output from make:. ```; creating: /clusterfs/vector/home/groups/software/sl-7.x86_64/source/salmon/1.5.1/scripts/../external/pufferfish-salmon-v1.5.1/tests/compile_tests/; inflating: /clusterfs/vector/home/groups/software/sl-7.x86_64/source/salmon/1.5.1/scripts/../external/pufferfish-salmon-v1.5.1/tests/compile_tests/int128_numeric_limits.cpp ; -- fetch PUFFERFISH exit code 0; -- Found ZLIB: /usr/lib64/libz.so (found version ""1.2.11"") ; -- Performing Test Iconv_IS_BUILT_IN; -- Performing Test Iconv_IS_BUILT_IN - Failed; CMake Error at /global/home/groups/consultsw/sl-7.x86_64/modules/cmake/3.15.1/share/cmake-3.15/Modules/FindPackageHandleStandardArgs.cmake:137 (message",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/453#issuecomment-862737315:312,guid,guidance,312,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/453#issuecomment-862737315,2,['guid'],['guidance']
Usability,"If you can already use DESeq2, then using tximport should not make it any harder at all. Given the tximport data, getting it into DESeq2 is as easy as. ```; dds <- DESeqDataSetFromTximport(txi, sampleTable, ~condition); ```. as shown in the [tximport vignette](https://bioconductor.org/packages/release/bioc/vignettes/tximport/inst/doc/tximport.html#Introduction). . Regarding outputting ""original read counts""; salmon *does* output the estimates for the number of reads deriving from each transcript. If the question is, why is this number not an integer, that's because the best estimate (the maximum likelihood estimate) is often not integral. Tools that simply count reads (e.g. HTSeq) produce integer counts, but these are in no way ""original read counts"" for the corresponding genes, and are usually less accurate (farther from the true number of fragments deriving from a transcript / gene) than the estimates produced by salmon. The fact that the best estimate is often not an integer is a direct result of the fact one is considering a statistical model and taking expectations.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/437#issuecomment-751190682:658,simpl,simply,658,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/437#issuecomment-751190682,2,['simpl'],['simply']
Usability,"Implementing a simple Gibbs sampler within Alevin to accept the option `--numCellGibbsSamples` and produce the `mean`, `variance`, and Gibbs estimates in the same format as of `--numCellBootstraps`. The default `thinning factor` is set to be `16`. . Additionally, we add `--dumpCellEq` to dump the deduplicated gene-level equivalence classes per cell.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/515:15,simpl,simple,15,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/515,1,['simpl'],['simple']
Usability,"In this case, it is likely treating the left and right reads as orphans when mapping. Therefore, you're losing basically all of the benefit of having paired-end reads (which can be considerable) and also increasing the probability of spurious mapping (orphans generally map much more ambiguously than properly paired reads). Since you have the paired-end files, you should try to repair them (using something like BBMap's [re-pair tool](https://jgi.doe.gov/data-and-tools/software-tools/bbtools/bb-tools-user-guide/repair-guide/)) to get back properly-paired FASTQ files for analysis. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/793#issuecomment-1220164752:509,guid,guide,509,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/793#issuecomment-1220164752,4,['guid'],['guide']
Usability,"Is it possible to use alevin with cell barcodes that have constant regions within them (see example below)?. bbbbbbccccccccccccbbbbbbcccccccccccc bbbbbb. **Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**. **Describe the bug**; A clear and concise description of what the bug is. **To Reproduce**; Steps and data to reproduce the behavior:. Specifically, please provide at least the following information:. * Which version of salmon was used?; * How was salmon installed (compiled, downloaded executable, through bioconda)?; * Which reference (e.g. transcriptome) was used?; * Which read files were used?; * Which which program options were used?. **Expected behavior**; A clear and concise description of what you expected to happen. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX]; - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux the output of `uname -a` and `lsb_release -a`]. **Additional context**; Add any other context about the problem here.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/654:264,clear,clear,264,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/654,2,['clear'],['clear']
Usability,"Issue with salmon for bulk RNA-seq. The following code was run to invoke salmon:; ```; docker run --rm -v /labs/Resources/mmulatta/MMUL_10:/mnt/indexdir/ resources/salmon salmon index -t /mnt/indexdir/gentrome.fa -d /mnt/indexdir/decoys.txt -p 8 -i /mnt/indexdir/index.salmon; ```; however, everytime I run it, I get the following error: ; Exception : [Error: The index version file /labs/khatrilab/Resources/mmulatta/MMUL_10/index.salmon/versionInfo.json doesn’t seem to exist. Please try re-building the salmon index.] . when in fact, the file exists. the gentrome.fa and decoys.txt files were created by following this tutorial (clearly changing the genome to mmulatta); https://combine-lab.github.io/alevin-tutorial/2019/selective-alignment/ . Why is salmon not finding the index file that's clearly present in the given folder path?",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/559:632,clear,clearly,632,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/559,2,['clear'],['clearly']
Usability,"Just a heads up, issue #266 has been added and the solution is currently available in the source build from the develop branch. We will include this to master with the next planned release of Salmon v0.11.3. Thanks again for the useful feedbacks and comments.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/253#issuecomment-412352411:236,feedback,feedbacks,236,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/253#issuecomment-412352411,2,['feedback'],['feedbacks']
Usability,"Just an idea. Would it be possible to assign an environment variable, such as SALMON_NO_VERSION_CHECK, whose existence overrides version checking? This wouldn't break compatibility with older scripts because they wouldn't have the variable in the first place. In non-networked nodes, an admin can simply set this variable and users will run salmon as usual.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/486#issuecomment-617326919:297,simpl,simply,297,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/486#issuecomment-617326919,2,['simpl'],['simply']
Usability,"Just in case it helps, I've written a script to splice out cell barcode linker sequences and shift them to before the polyA. In the process of doing this, it also does a 2-distance hamming correction of cell barcode and linker regions. All operations assume there are no INDELs:. https://gitlab.com/gringer/bioinfscripts/-/blob/master/synthSquish.pl. [usual disclaimers apply: I cannot guarantee that this works; use at your own risk]. This script could be used as a stop-gap measure to pre-process Rhapsody reads for use with Alevin via the undocumented custom length settings [--end 5, --barcodeLength 27, --umiLength 8]",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/628#issuecomment-776417938:542,undo,undocumented,542,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/628#issuecomment-776417938,2,['undo'],['undocumented']
Usability,"Lemme work with the reads you forwarded, is it possible to share the guide sequence as well ? Otherwise I won't be able to check the mapping rate.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639204641:69,guid,guide,69,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639204641,2,['guid'],['guide']
Usability,"NO BUG! I am presenting bulk RNA seq to non-bioinformaticians and wanted to go over how Salmon works in simple terms. . I tried understanding all the algorithms and models underlying the tool, but need help in explaining it more simply to a crowd of non-mathematicians. How would you explain the quasi mapping and quantification broadly and in simple terms? No need to get into deeper details. Just want an overview of a complicated mathematical pipeline. Presentation is on Monday so would really appreciate a timely response.; Thanks!",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/926:104,simpl,simple,104,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/926,3,['simpl'],"['simple', 'simply']"
Usability,No bug - How to explain Salmon workflow simply ? (avoid mathematics-heavy explanation),MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/926:40,simpl,simply,40,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/926,2,['simpl'],['simply']
Usability,"No, that shouldn't cause a problem. When I ran your command (including the `ISF` and placing the `--libType` after the set of reads), my run still completed successfully (and didn't produce any warnings during Gibbs sampling). Salmon's behavior when running in unstranded mode on stranded data is simply to map the reads in the orientation they match, and to report on the console (and in the log) that there was a mapping bias (i.e. that the data look stranded). Specifically, here is what I get when I run (a close approximation of) your command. ```; $salmon quant --index Salmon_index_hg38.analysisSet_knownGene --unmatedReads SRR2454059.fq.gz --libType ISF --useVBOpt --output test_quant --; numGibbsSamples 100 --threads 16; Version Info: This is the most recent **development version** of Salmon.; ### salmon (mapping-based) v0.7.3; ### [ program ] => salmon; ### [ command ] => quant; ### [ index ] => { Salmon_index_hg38.analysisSet_knownGene }; ### [ unmatedReads ] => { SRR2454059.fq.gz }; ### [ libType ] => { ISF }; ### [ useVBOpt ] => { }; ### [ output ] => { test_quant }; ### [ numGibbsSamples ] => { 100 }; ### [ threads ] => { 16 }; Logs will be written to test_quant/logs; [2016-12-13 22:38:54.413] [jointLog] [info] parsing read library format; [2016-12-13 22:38:54.413] [jointLog] [info] There is 1 library.; [2016-12-13 22:38:56.240] [stderrLog] [info] Loading Suffix Array; [2016-12-13 22:38:56.240] [jointLog] [info] Loading Quasi index; [2016-12-13 22:38:56.240] [jointLog] [info] Loading 32-bit quasi index; [2016-12-13 22:39:01.268] [stderrLog] [info] Loading Transcript Info; [2016-12-13 22:39:02.630] [stderrLog] [info] Loading Rank-Select Bit Array; [2016-12-13 22:39:03.041] [stderrLog] [info] There were 182608 set bits in the bit array; [2016-12-13 22:39:03.159] [stderrLog] [info] Computing transcript lengths; [2016-12-13 22:39:03.160] [stderrLog] [info] Waiting to finish loading hash; [2016-12-13 22:39:07.653] [stderrLog] [info] Done loading index; [2016-12-13 22",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266934878:297,simpl,simply,297,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266934878,2,['simpl'],['simply']
Usability,"Nope; nothing special. Once you've installed conda, you simply do:. ```; $ conda config --add channels conda-forge; $ conda config --add channels bioconda; $ conda create -n salmon salmon=0.10.1; ```. then it will give you instructions on how to activate the environment to run salmon.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/232#issuecomment-394755128:56,simpl,simply,56,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/232#issuecomment-394755128,2,['simpl'],['simply']
Usability,"Oh wow 14k v 126k is indeed a big difference, is it possible to share the Alevin log for your run ? From the logs you attached it's not clear what's the mapping rate. May I also ask to look at another log file inside the logs folder, called salmon_quant.log. that would have more information regarding the mapping rate.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639161938:136,clear,clear,136,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639161938,2,['clear'],['clear']
Usability,"Ok @DarwinAwardWinner, I think it's fixed for real this time. The issue was stemming from an uninitialized prior value in the Gibbs sampler under VBOpt mode (the initialization code was updated on the develop branch, which is where the bug was introduced). This, in turn, was leading to `nan` being passed as the alpha parameter of `std::gamma_distribution`. With the `-Ofast` optimization flags, at least, this leads `std::gamma_distribution()` to hang forever in an infinite loop. Clearly, `nan` should not be passed to `std::gamma_distribution()`, but I'd argue the behavior of looping forever here is not great. Anyway, I fixed the initialization bug, so that this nan should never pop up. Just to be safe, I also changed the default optimization flag to `-O3` so that at least `nan` and `inf` can be properly tested. Since the TBB code and the parallel sampling weren't causing the issue, I've added them back in. Could you please test the latest push (40584e62859fb65463188b50d132c1eb622b21f0) and verify that this resolves the issue for you (*hopefully*!)?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267877253:483,Clear,Clearly,483,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267877253,1,['Clear'],['Clearly']
Usability,"Ok all; another update. The issue I raise above still exists (differences between calls to `ksw_extz` and `ksw_extz2sse`). *However*, I think that what is happening in this case is actually explained more simply. That is, the positions being reported by salmon are _correct_ given the optimal alignment. Specifically, salmon is performing an end-to-end alignment of the read, and the optimal alignment here includes an indel of length 3 in the initial portion of the read. If we were outputting the CIGAR string along with the position, then the bases would line up because the ""off by 3"" issue that happens above for the reads would be addressed when walking the CIGAR. However, we don't (currently) output the CIGAR — rather, we output a decoy CIGAR that does not represent the optimal alignment as computed by ksw2. So, if we assume all matches / mismatches (an indel-free prefix for this read), then we see the position shift noted in the initial bug report. I think the easiest solution, for the time being at least, is to report the position as if the prefix before the first MEM is indel free under the optimal alignment (even if it is not and the optimal score reflects that). However, if there are other suggestions for the best way to address this, I'm open to those as well.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/475#issuecomment-574719940:205,simpl,simply,205,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/475#issuecomment-574719940,2,['simpl'],['simply']
Usability,"Ok, I figured it out :) — these two *decoy* references are (1) identical with each other and (2) collide with *another* decoy reference. Currently, the way we process decoys, we don't allow duplicate decoys (it makes even less sense to allow duplicate decoys than to allow duplicate transcripts). However, the reason indexing worked with `k=17` is not because of `k` but because of the `--keepDuplicates` flag. With that flag, these decoys get added. I think the right thing for us to do on our part is to remove duplicate *decoys* if they appear in the reference and the user has not passed `--keepDuplicates`. . However, for the time being, I think the best thing to do is simply to remove `AABR07022993.1` and `AABR07023006.1` from the `toplevel` file and from `decoys.txt`, since the sequence they contain is already represented in the decoy part of the index. This will represent a full and comprehensive SAF index. I'm pinging @k3yavi to see if he has any good idea about the easiest way to cull these duplicate refs from the input files.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/505#issuecomment-613480649:675,simpl,simply,675,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/505#issuecomment-613480649,2,['simpl'],['simply']
Usability,"Okay my alevin run finished, and I got a mapping rate of just 6.1% and 2254 cells detected. My `lib_format_counts.json` contains the following:. ```; {; ""read_files"": ""[ SRR10174292_2.fastq.gz, SRR10174292_1.fastq.gz]"",; ""expected_format"": ""ISR"",; ""compatible_fragment_ratio"": 1.0,; ""num_compatible_fragments"": 15259749,; ""num_assigned_fragments"": 15259749,; ""num_frags_with_concordant_consistent_mappings"": 0,; ""num_frags_with_inconsistent_or_orphan_mappings"": 61866895,; ""strand_mapping_bias"": 0.0,; ""MSF"": 0,; ""OSF"": 0,; ""ISF"": 0,; ""MSR"": 0,; ""OSR"": 0,; ""ISR"": 0,; ""SF"": 0,; ""SR"": 0,; ""MU"": 0,; ""OU"": 0,; ""IU"": 0,; ""U"": 0; }; ```. so lots of fragments are discarded for one reason or another, and it's not clear whether the library type assignment is working properly, sort of like my initial example above. Separately, I'm running zUMIs on the same files and will report back with those data when the run is complete",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-985038970:709,clear,clear,709,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-985038970,2,['clear'],['clear']
Usability,"Okay, thanks @k3yavi. Just to be clear- you're saying I should derive the whitelist from the filtered_cb_frequency rather than the raw? This is a much smaller file in the case of the bad data above (more so than I'd expect from the cb correction, 984), so I was afraid it had already been subjected to knee detection. I also note that it's also not in fact sorted by default.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-490914214:33,clear,clear,33,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-490914214,2,['clear'],['clear']
Usability,"On Sun, Nov 01, 2015 at 06:15:19AM -0800, Rob Patro wrote:. > I, too, would like to see the relative performance of the two libraries. The only challenge is in making the comparison apples-to-apples (i.e. enabling multi-threaded parsing in seqtk with minimal overhead ??? a concurrent queue is cheap, but not free). . Other points worth considering:; - there's a runtime overhead to constantly changing sequencing formats. Some; programs want split, others want interleaved. We've settled on interleaved; because it enables streaming, which is a major win (2-4x performance); and; also because having one file is better than having 2 or 4.; - the management overhead to keeping track of many files is less for experts,; but is pretty significant for beginners. Enabling multiple input formats ++. So I think it'd be great to have the basic functionality, identify where; there are performance problems, and then simply note them for future ;). I would like to enable -1 and -2 in khmer scripts, but for our usual use cases; (multiple sequencing files being normalized and/or partitioned and/or error; trimmed) the command line syntax is too confusing ATM.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-152829225:912,simpl,simply,912,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-152829225,2,['simpl'],['simply']
Usability,"Pinging @mikelove, who is certainly the person to give the best answer here. One clear difference to note though is that TPM is a length-normalized measure, while CPM is not. This alone means they will exhibit nontrivial differences.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/812#issuecomment-1323774035:81,clear,clear,81,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/812#issuecomment-1323774035,2,['clear'],['clear']
Usability,"Really simple question: can Alevin deal with the additional feature tags possible from 10Xv3? If not, will it at some point?",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/381:7,simpl,simple,7,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/381,1,['simpl'],['simple']
Usability,Resume after skipQuant?,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/567:0,Resume,Resume,0,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/567,1,['Resume'],['Resume']
Usability,"Rob,. Brilliant - I forgot that I built the boost libraries from whatever version of gcc was on the standard distribution. I have included -DFETCH_BOOST=TRUE, do you know why I am receiving the following error regarding a missing when executing make?. [ 5%] Performing configure step for 'libboost'; Building Boost.Build engine with toolset gcc... tools/build/src/engine/bin.linuxx86_64/b2; Detecting Python version... 2.7; Detecting Python root... /usr; Unicode/ICU support for Boost.Regex?... not found.; Generating Boost.Build configuration in project-config.jam... Bootstrapping is done. To build, run:. ./b2. To adjust configuration, edit 'project-config.jam'.; Further information:. - Command line help:; ./b2 --help. - Getting started guide:; http://www.boost.org/more/getting_started/unix-variants.html. - Boost.Build documentation:; http://www.boost.org/build/doc/html/index.html. using gcc : : /opt/gcc-8.2.0/bin/g++ ); [ 6%] Performing build step for 'libboost'; opt.jam: No such file or directory; /opt/salmon/external/boost_1_66_0/tools/build/src/build/toolset.jam:43: in toolset.using; ERROR: rule ""opt.init"" unknown in module ""toolset"".; /opt/salmon/external/boost_1_66_0/tools/build/src/build-system.jam:461: in process-explicit-toolset-requests; /opt/salmon/external/boost_1_66_0/tools/build/src/build-system.jam:527: in load; /opt/salmon/external/boost_1_66_0/tools/build/src/kernel/modules.jam:295: in import; /opt/salmon/external/boost_1_66_0/tools/build/src/kernel/bootstrap.jam:139: in boost-build; /opt/salmon/external/boost_1_66_0/boost-build.jam:17: in module scope; make[2]: *** [libboost-prefix/src/libboost-stamp/libboost-build] Error 1; make[1]: *** [CMakeFiles/libboost.dir/all] Error 2; make: *** [all] Error 2. Thanks for all your help!. Nate",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/309#issuecomment-436834099:742,guid,guide,742,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/309#issuecomment-436834099,2,['guid'],['guide']
Usability,"SK_ID p"" ~/source/BLBnew.txt). salmon quant -i ~/data/genome/MSU7new_transcript.index -l A \; -1 ~/results/trimmingSheng/${line}1.paired.fastq \; -2 ~/results/trimmingSheng/${line}2.paired.fastq --numBootstraps=30 \; -p 12 -o ~/results/salmon_quant_Sheng_new/${line} --seqBias --gcBias --validateMappings. Specifically, please provide at least the following information:. * Which version of salmon was used?; Salmon/0.8.2-IGB-gcc-4.9.4-Python-2.7.13 Salmon/0.11.3-IGB-gcc-4.9.4; Salmon/0.9.1-IGB-gcc-4.9.4 Salmon/0.12.0-IGB-gcc-8.2.0 (D). * How was salmon installed (compiled, downloaded executable, through bioconda)?; through the biocluster in the University. * Which reference (e.g. transcriptome) was used?; converted the genomic fasta file to transcriptomic fasta file (described above); ; * Which read files were used?; the raw sequencing reads and the trimmed reads from the paired-end data. * Which which program options were used?; described above. **Expected behavior**; A clear and concise description of what you expected to happen. I've used the quassi mapping of Salmon using different versions several times and I expect to get different mapping rate per sample. I also expect to get different values of the parameters in the quant.sf parameters across all genes and across samples.; . **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. ### For version 0.8. This is similar across all samples:; Name Length EffectiveLength TPM NumReads; LOC_Os01g01010.1 3017 250 28.8836 527.392; LOC_Os01g01010.2 2218 250 1.84062 33.6083; LOC_Os01g01019.1 1127 250 0.0547668 1; LOC_Os01g01030.1 2464 250 4.43611 81; LOC_Os01g01040.4 1524 250 0.941635 17.1935; LOC_Os01g01040.1 2508 250 11.5632 211.135; LOC_Os01g01040.2 2482 250 8.02081 146.454; LOC_Os01g01040.3 2583 250 8.55554 156.218; LOC_Os01g01050.1 2039 250 17.2333 314.667. ### The counted total reads, observed total fragments, and the mapping rate is similar for all samples for both the raw-dat ",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/346:4787,clear,clear,4787,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/346,1,['clear'],['clear']
Usability,"Salmon version: 0.13.1 (installed via pre-compiled binary). I used salmon to quantify some samples and wanted to use the `quantmerge` command to produce a combined table. However, the merged table I got as output only contained 17 lines (of 52228 in the quant.genes.sf files). I was able to identify that the problem was related somehow to the ""Name"" column itself, although I didn't find any obvious pattern for failure. For example, if I rename all the genes to simply ""1"", ""2"", ... and then `quantmerge`, I get a properly combined table with all samples/genes. Looking back at the ""original"" data with the gene names, I find that the truncated merged table consistently/always truncates immediately *after* processing some gene names. For example, the 16th gene name in my ""quant.genes.sf"" table happens to be ""Erdr1"". If this line is moved to the top of that file, then the merged table will truncate at 2 (the header counting for one of those, obviously). Unfortunately, it's not just ""Erdr1"". If that line is moved to the end of the file, or deleted entirely, there is another failure at gene ""Gm28674"", which happens to be the 19th gene. And so on for a very large number of names (I gave up after removing ~30 one at a time). I've now tested with a few different samples and with a number of randomly selected subsets of the original quant files and the behavior is consistent. I can't figure out what the pattern is, but ""Erdr1"", ""Gm28674"", and all the other genes I discovered with my ad-hoc process above, always cause `quantmerge` to truncate the output.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/356:464,simpl,simply,464,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/356,1,['simpl'],['simply']
Usability,"Scanning dependencies of target salmon; [ 86%] Building CXX object src/CMakeFiles/salmon.dir/EMUtils.cpp.o; c++: error: -pg and -fomit-frame-pointer are incompatible; src/CMakeFiles/salmon.dir/build.make:62: recipe for target 'src/CMakeFiles/salmon.dir/EMUtils.cpp.o' failed; make[2]: *** [src/CMakeFiles/salmon.dir/EMUtils.cpp.o] Error 1; CMakeFiles/Makefile2:790: recipe for target 'src/CMakeFiles/salmon.dir/all' failed; make[1]: *** [src/CMakeFiles/salmon.dir/all] Error 2; Makefile:162: recipe for target 'all' failed; make: *** [all] Error 2. Specifically, please provide at least the following information:. * Which version of salmon was used? v1.4.0; * How was salmon installed (compiled, downloaded executable, through bioconda)? compiled; * Which reference (e.g. transcriptome) was used? Encountered compile error, so not to index/quant step yet; * Which read files were used? same as above; * Which which program options were used? same as above. **Expected behavior**; A clear and concise description of what you expected to happen.; I expect to finish ""make"" command without encountering compile error while using debug mode(""-DCMAKE_BUILD_TYPE=Debug"" ). **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem.; ![image](https://user-images.githubusercontent.com/24876498/103148237-98daa880-4798-11eb-9944-a104c41f75cf.png). **Desktop (please complete the following information):**; - OS: CentOS7; - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux the output of `uname -a` and `lsb_release -a`]; ""uname -a""; Linux 3.10.0-1062.18.1.el7.x86_64 #1 SMP Tue Mar 17 23:49:17 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux. ""lsb_release -a""; LSB Version:	:core-4.1-amd64:core-4.1-noarch:cxx-4.1-amd64:cxx-4.1-noarch:desktop-4.1-amd64:desktop-4.1-noarch:languages-4.1-amd64:languages-4.1-noarch:printing-4.1-amd64:printing-4.1-noarch; Distributor ID:	CentOS; Description:	CentOS Linux release 7.7.1908 (Core); Release:	7.7.1908; Codenam",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/608:2878,clear,clear,2878,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/608,1,['clear'],['clear']
Usability,"Seems to work on some of the test at my end, let me know if its still a problem. The command to use would be; ```; salmon alevin -l ISR --citeseq --barcodeLength 16 --umiLength 10 --end 5 --featureStart 19 --featureLength 21; ```. One thing to note, since it's a 5' protocol, you might have to change `-lISR` to `-lISF` since the 5` protocol expects the single-cell reads from the forward strand, unlike 3' where we expect the reads from reverse. It should not be a problem for the guide/feature barcodes though.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638444905:482,guid,guide,482,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638444905,2,['guid'],['guide']
Usability,"Side note: does Salmon learn the fragment length distribution from the data, using the user-provided values as a starting point? Is it even possible to do this for stranded single-end data? (I know it's possible for unstranded single-end.)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/83#issuecomment-243813359:23,learn,learn,23,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/83#issuecomment-243813359,2,['learn'],['learn']
Usability,"So I got the data and am trying to repro the issue now (thanks!). Quick question. I noticed in your example command you have `--libType ISF`. However, you have single-end reads, so the appropriate library type would be `SF` (i.e., they can't be ""inward"" facing reads, b/c there is no mate for each read). When I run your command as is, but replace `ISF` as `SF`, my run completes successfully, and I don't get any `errorminEQClassWeight` output. Could you let me know if this makes any difference for you (also, sorry that, apparently, we're not outputting a useful error message when one passes in a paired-end library type with single-end data). edit: Actually, it's even stranger. I noticed that in your command the library type comes *after* the reads to which it refers, but in this case, Salmon will not apply that library type to those reads (which explains why you're not getting a warning message). The restriction that the `--libType` flag comes before the reads it describes is buried in [the docs](http://salmon.readthedocs.io/en/latest/salmon.html#using-salmon), but I definitely need to make that clearer. Anyway, the point is that, in this case, Salmon should apply the ""default"" single-end library type (i.e., `U`) to your reads. So, presumably, that was what was happening when you saw the strange behavior during Gibbs sampling (and is also what was happening when my Gibbs sampling run completed successfully).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266927204:1111,clear,clearer,1111,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266927204,2,['clear'],['clearer']
Usability,"So, it turns out that with the dependency setup that is pulled in, I can't even get `salmon` to build without `USE_SHARED=TRUE`. I think at this point, it's not clear the segfault is due to something that is broken / can be fixed in the salmon code itself. Rather, it's likely due to a misversioning of a dependency that is pulled in and then linked against. For the time being, I think the options are to do a more ""standard"" build (i.e. like the first one I suggested that pull in only that minimal set of dependencies and let salmon itself statically link the rest), or to try and look at the upstream shared libraries being linked and figure out which of them is misversioned. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464124885:161,clear,clear,161,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464124885,2,['clear'],['clear']
Usability,"So, it won't let me use .fq.1 and .fq.2 - it has to be .1.fq and .2.fq. I think either allowing a 'force' or simply checking to see if the file is FASTQ would be great.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/28:109,simpl,simply,109,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/28,1,['simpl'],['simply']
Usability,"Sorry if I wasn't clear. Also, maybe I am trying to bluntly transpose a; metric that comes from alignment-based quantification. Yes, sequencing; saturation relies on UMI, using the transcript reads associated to the UMIs. I am not sure to understand the difference between resolving ambiguity; or collision at the transcript level, with the evaluation of sequencing; saturation in mind. To be more precise, I am not sure to see how it; could be a problem in this computation. But I am probably missing an; important point?. The idea of quasi-mapping as I understand is identifying the transcripts; from which the reads could have originated, generating a quantification.; For the sequencing saturation, we don't really need to know where the; read align on the transcript sequence, we just want to know that the; read comes from one single transcript, a unique UMI. So if I am right,; it is possible to summarize this quantification at the level of UMIs,; and have an idea of the duplication level of the transcripts that have; been tagged with UMIs. From what I understand, this is where alevin; perform the deduplication computation to have a correct idea of the; transcript amount when UMI are added, prior amplifications resulting; from the RT/PCR steps. So I was imagining it could be possible to take the gene quantifications; from (de)duplicated UMIs, gene quantifications from unique UMIs, using; them to have an idea of the amount/ratio of redundant information in the; sequencing data, producing a metric very similar to the seq sat from the; 10x definition.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/267#issuecomment-414331344:18,clear,clear,18,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/267#issuecomment-414331344,2,['clear'],['clear']
Usability,"Sorry if I wasn't clear. I did try with and without the --chromium; option, with the same error. I just have try the exact command you provided (including the --chromium; flag), with option in the same order. The command log is then:; ### salmon (single-cell-based) v0.11.1; ### [ program ] => salmon; ### [ command ] => alevin; ### [ threads ] => { 10 }; ### [ libType ] => { ISR }; ### [ chromium ] => { }; ### [ mates1 ] => {; /path/to/downloads/10xPBMC/pbmc4k_S1_L001_R1_001.fastq.gz }; ### [ mates2 ] => {; /path/to/downloads/10xPBMC/pbmc4k_S1_L001_R2_001.fastq.gz }; ### [ index ] => { /path/to/salmonIndex }; ### [ output ] => { alevin_output }; ### [ tgMap ] => { tx2gene.tsv }. Now it seems to work. I'll tell you if the whole alignment is; successfull when it will end. Note that when I use the --chromium flag earlier in the command, ie:. salmon --no-version-check --chromium alevin -p 10 -lISR -1 [...]. The log contains:; ### salmon (single-cell-based) v0.11.1; ### [ program ] => salmon; ### [ command ] => alevin; ### [ ] => { alevin }; ### [ threads ] => { 10 }; ### [ libType ] => { ISR }",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/264#issuecomment-410331030:18,clear,clear,18,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/264#issuecomment-410331030,2,['clear'],['clear']
Usability,"Sounds good, just wanted to give you the heads up, as we are working on some other part of the salmon pipeline, currently I can't give you an ETA when would the new version of salmon be available. If For the time being the choice are either you can compile the develop branch of salmon or I can forward you a linux usable salmon binary.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/416#issuecomment-523090214:315,usab,usable,315,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/416#issuecomment-523090214,2,['usab'],['usable']
Usability,"Thank you @rached-97, for the incredibly thorough follow-up to the original issue. I agree that the work you put into not only reporting the issue thoroughly to begin with, but following up with your findings, will certainly help others who might encounter related issues in the future. Since salmon seems not to be at fault here, I'll close the issue. I do recommend taking this over to the bioconductor forums, where the community is _incredibly_ responsive; I imagine you'll have a resolution in no time. Thanks again for the excellent report and follow-up!. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826117612:449,responsiv,responsive,449,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826117612,2,['responsiv'],['responsive']
Usability,"Thank you for the clear and thorough explanation, @rob-p . Now I understand exactly why this is happening. I like your idea for the “throw-away” run for Salmon, and the short example command you sketched out is exactly what I had said in mind as I read your words. Reworking the core Salmon algorithm to do some gymnastics with re-processing the first 10,000 reads would not be elegant or worth your time. I think the workaround you proposed is a perfectly good solution. If in the long run many other people find this useful, perhaps an easier fix would be to make a new command in Salmon that just bails after the first 10k reads automatically and returns the detected library orientation upon termination of the command; e.g. in Bash:. `mylibtype=$(salmon quant —getLibType -r reads.fq.gz)`; `salmon quant —libType $mylibtype -r reads.fq.gz`. Thank you for the great software and for being so attentive to detail and our questions.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/489#issuecomment-738896890:18,clear,clear,18,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/489#issuecomment-738896890,2,['clear'],['clear']
Usability,"Thank you for the swift answer!. We are working with [BD Rhapsody](https://www.bdbiosciences.com/en-us/instruments/research-instruments/single-cell-multiomics/single-cell-analysis-system), which uses a complex barcode structure (you can read about this in their [bioinformatics handbook](https://www.bd.com/documents/guides/user-guides/GMX_BD-Rhapsody-genomics-informatics_UG_EN.pdf) on page 14). The extracted, combined CB is 27bp long, which is why the default sanity check was too low for our purposes. In terms of cell numbers, BD Rhapsody appears to generate a lot of ""false-positive cells"", actually (we are seeing up to 90% of false positives). This is expected, and also mentioned in their bioinformatics handbook (pages 23-25), but appears to be an issue for the alevin cell detection: with standard settings this is approximately two orders of magnitude lower than expected, `--expectCells` improves matters drastically, however. We have opted for removing the false positives in post-processing ourselves - the low count depth population is very easily identifiable. In terms of performance, a complete alevin run on 150M reads (25k expected cells) takes around 1.5 hours using 10 threads, which is perfectly reasonable for us.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/445#issuecomment-551083490:317,guid,guides,317,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/445#issuecomment-551083490,4,['guid'],['guides']
Usability,"Thank you for verifying @zhangchipku, and thank you very much for the kind words! We appreciate the feedback and input from our users like yourself. We'll prioritize the soft-clipping functionality for upcoming releases (maybe even the next if we can make that work in time). For the time being, I can recommend `fastp` as a fairly efficient / fast trimmer that. It might even be able to work in a streaming fashion so that you could pipe the trimmed reads directly to salmon.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-586548443:100,feedback,feedback,100,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-586548443,2,['feedback'],['feedback']
Usability,"Thank you, well I do have valid pairs and remaining singletons in different files, it just was not clear one cannot use a file with interleaved reads. Of course I dropped the file (as an intermediate from the disk as I hoped to keep only the combined, interleaved file with pairs). So I re-created it. BTW, I can recommend `reformat.sh` from https://sourceforge.net/projects/bbmap/ bundle, it is a nice tool to split/reorder/merge FASTQ files. I infer you suggest people to use only pairs and forget the singletons, right? Or, could combine the results of two executions somehow together ...? Maybe not worth the efforts? I have quite a few singleton reads in addition to valid pairs, though.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/240#issuecomment-400057894:99,clear,clear,99,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/240#issuecomment-400057894,2,['clear'],['clear']
Usability,"Thanks @Munfred for sharing the file. I'll take a look into this. re> whitelist; I should have been more clear about this. I didn't mean to say the full 737k CB, what I meant was using the actual whitelisted CB by cellranger, which are as you say was 300. Usually they are stored in a folder with name `filtered_gene_bc_matrices`, Although you might have to remove `-1` from their name since cellranger adds it to specify the sample index.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/245#issuecomment-402571397:105,clear,clear,105,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/245#issuecomment-402571397,2,['clear'],['clear']
Usability,"Thanks @Ryan-Zhu ,. A couple of thoughts.; To me the data seem a little noisy as a lot of CB/reads are thrown away due to ""knee"" thresholding.; Check https://github.com/COMBINE-lab/salmon/issues/362 if you wanna play with how to customize alevin for user-define whitelisting. Having said that this is how you can parse the data from alevin.; Alevin use 1277 CB after its knee thresholding + 638 low confidence Barcode for downstream whitelisting = total 1915 CBs.; If you check the warning in the log it says :. ```; [2019-06-12 15:07:08.152] [alevinLog] [warning] Skipped 313 barcodes due to No mapped read; ```; Basically it means out of 1915, 313 didn't had any read mapped to them, so alevin doesn't report them in the output matrix. Alevin reports 1915 - 313 = 1602 CBs both in `.mtx` and `quants_mat.gz` file. You can check the order of the CB in the `quants_mat_rows.txt` file, which has 1602 rows/CBs. If you don't provide alevin with external whitelist alevin tries to do post whitelisting of it's own. Basically out of the 1277 high confidence CBs alevin initially find out through knee it assigns 647 CBs as final whitelisted CB as found in the `whitelist.txt` file. If you wan't to subsample these CBs you have to extract the information from the `.mtx` or `quants_mat.gz` file. You can check a simple python parse of the `quants_mat.gz` file [here](https://github.com/k3yavi/vpolo/blob/master/vpolo/alevin/parser.py#L187-L230).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/374#issuecomment-501846672:1307,simpl,simple,1307,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/374#issuecomment-501846672,2,['simpl'],['simple']
Usability,"Thanks @Ryan-Zhu for your feedbacks and the suggestion.; I apologize for the trouble you had to face while working with the alevin output.; We will prepare better from the next release and try updating the external dependencies first before making an official release. ; Just wanted to give you the heads up that I have also updated the bug for the scientific notation in the `mtx` format. It's in the develop branch of alevin, if you have time please let me know if it works for you. Thanks again.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/380#issuecomment-502828416:26,feedback,feedbacks,26,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/380#issuecomment-502828416,2,['feedback'],['feedbacks']
Usability,"Thanks @k3yavi !If you can forward me a Linux portable binary that would be great. Whenever I try to compile something on my computer, I fail half of the time . I have Ubuntu 18.04. I will ask permission to share with you part of the data and get back to you. Also, does Alevin use 10x cell barcode whitelist internally to correct barcodes? And do you recommend using the `--naiveEqclass`; option when there are only 64 guide sequences as features?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638487530:420,guid,guide,420,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638487530,2,['guid'],['guide']
Usability,"Thanks @k3yavi for the clarification. In my example case the files are not cell disjoint, being multiple lanes run from the same library. Obviously I can use just one lane for the training, but to be clear: in the real world in this situation all files for a library need to be run together, right?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/434#issuecomment-540400660:200,clear,clear,200,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/434#issuecomment-540400660,2,['clear'],['clear']
Usability,"Thanks @rfarouni for the updates. > With --minScoreFraction 0.607 I get a way much better mapping rate. I wonder if there is way to determine the optimal value empirically?. Glad to hear that, may I ask what percent of the reads are mapping now ? It's not clear from the alevin logs you shared but I think the total number of deduplicated UMIs are similar to your baseline experiment. I think defining an optimal empirical threshold is a great idea but the issue is that 21 length barcodes are kind of in the middle i.e. a tad longer than the regular barcodes and somewhat smaller than a full read. The full read alignment process indeed allows more erroneous reads to map but 21 is a bit too short to work with. @rob-p might have more thoughts on this one. > But now there are a lot of barcodes that are not in the whitelist. Thanks again for checking this, it is indeed concerning. However, as I was mentioning earlier in a regular single-cell experiment we end up throwing away almost all of these very low frequency count cellular barcodes. I'd say even 45 reads CBs are most probably a noise and will be filtered away, because only a fraction of the reads will map and after deduplication it'll result in significantly low count in 1 cellular barcode. > Also with the default setting of --freqThreshold, no CB correction gets done. I can check why is this happening, let me know once you have a toy dataset to play with.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-640093397:256,clear,clear,256,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-640093397,2,['clear'],['clear']
Usability,"Thanks @rob-p I am glad you and others have found it useful. The actual bbmap.sh and bbduk.sh commands for SE data are in the links to Phil Ewels' multiqc GH. . Just like salmon indexing kmer size choice, one can tinker with the **_```k, hdist, minq and other parameters```_** of bbduk depending on how good/bad the data is. Needless to state, bbduk is the swiss-army-knife for sequence reads quality assessment with whole range of parameters to tweak . https://jgi.doe.gov/data-and-tools/bbtools/bb-tools-user-guide/bbduk-guide/ suggests; ![image](https://user-images.githubusercontent.com/8467214/78302368-a3695980-7508-11ea-990d-4b6e008e3f07.png)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-608105756:511,guid,guide,511,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-608105756,4,['guid'],['guide']
Usability,"Thanks @tamuanand for the (as always) detailed and clear question! Since this directly involves `tximport` and `DESeq2` downstream, let me also ping @mikelove here.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/581#issuecomment-719143923:51,clear,clear,51,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/581#issuecomment-719143923,2,['clear'],['clear']
Usability,"Thanks Rob!; For both providing the binary download again, and pointing me to MultiQC (meanwhile got a informative QC report). :); Guido",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/252#issuecomment-405540123:131,Guid,Guido,131,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/252#issuecomment-405540123,1,['Guid'],['Guido']
Usability,"Thanks Rob. I am using alevin with libType of ISR. When I looked at the SAM file after setting the writeMapping option, I observed that ~1% had the ""reverse alignment"" flag set to 1 (the only flags field that had this flag set was 341, all the rest had that bit set to 0). It's not clear to me whether alevin uses those reads for UMI counting, and if so, what's the best way to turn off this behavior.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/749#issuecomment-1038381121:282,clear,clear,282,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/749#issuecomment-1038381121,2,['clear'],['clear']
Usability,"Thanks a lot @rob-p and @k3yavi .; I wanted your advise on something more intricate. Asking since you people are the pioneers in this aspect of problem solving.; I have to determine the expression of GFP and Transposon sequence in the transcriptome.; I read the material posted on the link https://salmon.readthedocs.io/en/latest/salmon.html.; It instructs this to be done in 2 different ways-; There are two options for generating a decoy-aware transcriptome:. The first is to compute a set of decoy sequences by mapping the annotated transcripts you wish to index against a hard-masked version of the organism’s genome. This can be done with e.g. MashMap2, and we provide some simple scripts to greatly simplify this whole process. Specifically, you can use the generateDecoyTranscriptome.sh script, whose instructions you can find in this README. The second is to use the entire genome of the organism as the decoy sequence. This can be done by concatenating the genome to the end of the transcriptome you want to index and populating the decoys.txt file with the chromosome names. Detailed instructions on how to prepare this type of decoy sequence is available here. This scheme provides a more comprehensive set of decoys, but, obviously, requires considerably more memory to build the index. I tried the 2nd approach. Combined the GFP,Transposon and the genome FASTA files, indexed it , constructed the decoy according to the given instructions given here https://combine-lab.github.io/alevin-tutorial/2019/selective-alignment/.; When I ran Salmon (version 1.2.1_linux_x86_64) it did not report anything in the quant files (I know that these samples have high GFP and Transposon expression in these samples). The 1st approach is giving me problems to the construction of the GTF file and then memory usage. The instructions say - generateDecoyTranscriptome.sh — Located in the scripts/ directory, this is a preprocessing script for creating augmented hybrid fasta file for salmon index. It cons",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/737#issuecomment-1022416973:679,simpl,simple,679,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/737#issuecomment-1022416973,4,['simpl'],"['simple', 'simplify']"
Usability,"Thanks for the feedback!. I tried playing with the vbPrior setting and observed that, as you noted, higher increases of the vbPrior tended to flatten out the read apportionment, such that as the vbPrior increased the two transcripts became increasingly similar in their final expression (presumably they would eventually hit 50/50). It's good to know how that settings affects my data, but this is not quite what I was hoping for... . Ideally, the short transcript would get nearly *all* of the reads, rather than splitting the reads 50/50 or, with the default settings, giving nearly all the reads to the longer transcript. I realized that, as a human, the reason the short transcript is obviously the dominant one is how the reads pileup in the alignment. There are hundreds of reads mapping to both transcripts, but NO reads map to the 5' of the long transcript. As I understand the selective alignment, the alignment scores are passed to the quantification step, but the *position* of the reads is not used downstream. In order to pass my human intuition along here, the software would need to pay attention to the coverage bias of the reads mapping to the transcripts and assign a penalty when two otherwise identical transcripts have a different coverage variance across the transcript. This sounds like what the --posBias flag should incorporate into the effective lengths, but it doesn't have much effect on these transcripts for me (FYI, I am getting a segfault when I run only --posBias in the current salmon version, but if I run all the models together like --gcBias --seqBias --posBias, it completes fine). . Also, my intuition for these transcripts is not really a coverage ""bias"" as much as the read depth absolutely plummeting at the 5' end of the long transcript. It would be neat if Salmon could detect these kinds of dramatic dropoffs and add a warning or something... even if not incorporating the information into the quants... it could even be a good QC step to identify large de",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623043651:15,feedback,feedback,15,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623043651,2,['feedback'],['feedback']
Usability,"Thanks for the quick reply. Do you have a place you could share the contents of `outputs/hs.grch39.index`? It seems to me that the index is clearly not being fully constructed, but it would be ideal to compare this with an index that I know is correct and look for specific differences. Thanks,; Rob. P.s. any details about your specific system might also be useful to help debug.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/197#issuecomment-467214391:140,clear,clearly,140,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/197#issuecomment-467214391,2,['clear'],['clearly']
Usability,"Thanks for the thorough suggestions. Actually, we fall into the easier case since Salmon does not support mixing single and paired-end reads in a single BAM file. When performing quantification on a single sample, the reads for that sample must follow a uniform library type. For paired-end reads, the BAM file can contain paired-end and single-end alignments (i.e. orphans), but the reads must all have been paired _in sequencing_. Mixing different library types in the BAM file makes it difficult to assess the compatibility of a fragment with the expected library type, especially if fragments from the different library types are expected to exist in a specific ratio in the input. Anyway, my main motivation for having the separate `AS` and `AP` types was to prevent the need to ""peek"" in the file, since, currently, there is not an easy way to peek the first read without opening the first file twice. However, I've decided that the benefit of having the same uniform (and simpler) interface of `A` always representing automatic library type detection is probably worth it, so I've pushed this implementation (commit 6116b2a). So, when the user provides the `A` library type, Salmon will peek into the first record in the BAM file to determine if the fragment was paired in sequencing or not, and will then set the single / paired-end status on that basis. The only corollary to this is that, in alignment-based mode, the `A` flag is not compatible with an input stream (i.e. the input must be a regular file). I will be sure to document this when I update the docs for the version bump.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/79#issuecomment-242399463:979,simpl,simpler,979,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/79#issuecomment-242399463,2,['simpl'],['simpler']
Usability,"Thanks- Jonathan. Yikes, that bad quality one looks like particularly bad quality, I have an example that looks like that in my failed examples. Were you able to recover usable data from it?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-490510234:170,usab,usable,170,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/362#issuecomment-490510234,2,['usab'],['usable']
Usability,"That is interesting. The attempt in the double redirect was to include all alignment records from the second sam file simply concatenated to the first. Assuming the SAM files contain the same header, this should be OK (simply another way to treat them as a single input). However this warning suggests that there were references in the file passed to `-t` that did not have a corresponding entry in the SAM file. Yet, with the redirect, the first sam file should contain the full header. I don't have a clear understanding of why this would happen yet.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/271#issuecomment-707349051:118,simpl,simply,118,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/271#issuecomment-707349051,6,"['clear', 'simpl']","['clear', 'simply']"
Usability,That sounds like a very good way of doing it :-). I'm sorry I was not clear enough - my question was acutally meant for a single sequence - let me try again:; Lets say we have a read pair where one mate maps fine - but the other mate have a problem - half of it is an adapter (or low quality sequence with to many errors). How would Salmon currently handle this situation where the first half of a sequence (e.g. nt 1-50) could be quasi-mapped to a transcript but the second half (nt 51-100) did not match anywhere? Would the the second half cause the whole sequence to be discarded or would it be enough that the first half matched for it to be considered/counted?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/150#issuecomment-354955072:70,clear,clear,70,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/150#issuecomment-354955072,2,['clear'],['clear']
Usability,The Arabidopsis example in the getting started guide ([https://combine-lab.github.io/salmon/getting_started/](https://combine-lab.github.io/salmon/getting_started/)) seems to work fine on FreeBSD 13.0 with salmon installed via miniconda per instructions above.,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/419#issuecomment-989865038:47,guid,guide,47,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/419#issuecomment-989865038,2,['guid'],['guide']
Usability,"The `AS:i:-2147483648` is a sentinel value basically meaning the alignment was below the minimum acceptable quality. You can simply ignore those (its the min signed 32-bit integer). Let me think about your other question (and ping @mikelove), and get back to you.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/528#issuecomment-639157711:125,simpl,simply,125,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/528#issuecomment-639157711,2,['simpl'],['simply']
Usability,"The answer here could simply be 'no' 😄 but as this question came up recently for me, and it is one I've seen mentioned on the `nf-core/scrna` slack, I figured I'd raise it here to get your thoughts. . There is a standard CellRanger workflow for the 10x V(D)J approach (https://support.10xgenomics.com/single-cell-vdj/software/pipelines/latest/using/vdj). Is this something remotely achievable with `alevin/alevin-fry`? It would be great for those who have matched 10x scRNA-seq to be able to process everything with the same package!",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/861:22,simpl,simply,22,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/861,1,['simpl'],['simply']
Usability,"The documentation states. >If your alignments for the sample you want to quantify appear in multiple .bam/.sam files, then you can simply provide the Salmon -a parameter with a (space-separated) list of these files. But I somehow can't get that to work. I have two bam files, each of them with (different) STAR alignments to the same reference. When I pass either one of them, salmon works just fine, e.g. with the following commands:. ```; salmon quant -t transcripts.fasta -l IU -p 2 -o quantitation/quant.sf -a run1/Aligned.toTranscriptome.out.bam; # or; salmon quant -t transcripts.fasta -l IU -p 2 -o quantitation/quant.sf -a run2/Aligned.toTranscriptome.out.bam; ```; But when I try to pass both of them, I get the following error:. ```; salmon quant -t transcripts.fasta -l IU -p 2 -o quantitation/quant.sf) -a run1/Aligned.toTranscriptome.out.bam run2/Aligned.toTranscriptome.out.bam. Version Info: This is the most recent version of Salmon.; # salmon (alignment-based) v0.7.2; # [ program ] => salmon; # [ command ] => quant; # [ targets ] => { transcripts.fasta }; # [ libType ] => { IU }; # [ threads ] => { 2 }; # [ output ] => { sample1/quantitation }; # [ alignments ] => { run1/Aligned.toTranscriptome.out.bam run2/Aligned.toTranscriptome.out.bam }; Library format { type:paired end, relative orientation:inward, strandedness:unstranded }; Logs will be written to quantitation/logs; numQuantThreads = 2; parseThreads = 2; Checking that provided alignment files have consistent headers . . . done; Populating targets from aln = ""run1/Aligned.toTranscriptome.out.bam"", fasta = ""transcripts.fasta"" . . .replaced 0 non-ACGT nucleotides with random nucleotides; done. processed 0 reads in current roundSegmentation fault (core dumped); ```. The `Checking that provided alignment files have consistent headers . . . done` line seems to indicate that both bam files were recognized and that the headers matched. . Any hints on what might be going on?",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/104:131,simpl,simply,131,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/104,1,['simpl'],['simply']
Usability,"The easiest way is probably to mount the external data / the relevant external directories as a [volume](https://docs.docker.com/engine/admin/volumes/volumes/#create-and-manage-volumes) when you run the docker command. The TLDR version of that page is [here](https://stackoverflow.com/questions/42625947/docker-input-output-outside-the-container). Basically, you simply map some location on your host system to some directory _inside_ the docker image, and then the executable in the container can read and write directly to that volume.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/164#issuecomment-338278307:363,simpl,simply,363,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/164#issuecomment-338278307,2,['simpl'],['simply']
Usability,"The issue relates to the error message, so maybe I will close the issue in terms of being able to run the program without generating the error message. However, I think something still doesn't seem right, and I thought I should make that clear. <table>; <tbody>; <tr>; <th align=""center"">Method</th>; <th align=""center"">SRR13313130</th>; <th align=""center"">10x_pbmc_5k</th>; </tr>; <tr>; 	 <td align=""left"">CellRanger</td>; <td align=""center"">9,974 cells</td>; <td align=""center"">4,956 cells</td>; </tr>; <tr>; 	 <td align=""left"">STARsolo</td>; <td align=""center"">7,587 cells</br><i>(Summary.csv)</i></td>; <td align=""center"">4,586 cells</br><i>(Summary.csv)</i></td>; </tr>; <tr>; 	 <td align=""left"">Alevin</td>; <td align=""center""><b>814 cell barcodes?</b></td>; <td align=""center""> 856,224 cell barcodes</td>; </tr>; <tr>; 	 <td align=""left"">Kallisto</td>; <td align=""center"">79,254 cells</br><i>(BUSpaRse)</i></td>; <td align=""center"">47,598 cells</br><i>(BUSpaRse)</i></td>; </tr>; <tr>. </tbody>; </table>. For Alevin and Kallisto, I am not so worried about the exact values for cell barcodes (versus cells), since I was expecting extra work was needed to estimate a cell count from a distribution of measurements for each cell barcode. However, the number of cell barcodes should be larger than the number of cells, and that seems to match for everything except Alevin for this sample (SRR13313130). In other words, for sample, I think that this is the command that generates the fewest errors/warnings/notes:. `/path/to/salmon alevin -l ISF --chromium -1 $R1 -2 $R2 -i $REF -p 4 -o $ID --tgMap $MAP`. However, I think the cell barcode count is too small. **Is there anything else that you would recommend trying?**",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-882751952:238,clear,clear,238,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-882751952,2,['clear'],['clear']
Usability,"There has been a small amount of discussion about the BD Rhapsody barcode / sequence format (e.g. see [here](https://github.com/COMBINE-lab/salmon/issues/445#issuecomment-551083490)), but it would be great if the option could be integrated into the code. BD has produced a [Single Cell Genomics Bioinformatics Handbook](https://www.bd.com/documents/guides/user-guides/GMX_BD-Rhapsody-genomics-informatics_UG_EN.pdf) which has the following information about the R1 read structure on pg 14:. 5' CLS1 - L1 - CLS2 - L2 - CLS3 - UMI - poly(T); 9 12 9 13 9 8 18; [1-9] [22-30] [44-52][53-60]. > **Cell Label** Information of the cell label is captured by bases in three sections (CLS1, CLS2, CLS3) along each R1 read. Two common sequences (L1, L2) separate the three CLSs, and the presence of L1 and L2 relates to the way the capture oligonucleotide probes on the beads are constructed. By design, each CLS has one of 96 predefined sequences, which has a Hamming distance of at least four bases and an edit distance of at least two bases apart. A cell label is defined by the unique combination of predefined sequences in the three CLSs. Thus, the maximum possible number of cell labels is 96^3 (884,736). A cell label is represented by an index between 1–96^3. > Reads are first checked for perfect matches in all three pre-designed CLS sequences at the expected locations, CLS1:; position 1–9, CLS2: position 22–30, and CLS3: position 44–52. Reads with perfect matches are kept. In other words...; - Concatenate subsequences 1-9, 22-30, and 44-52 to form a 27-base cell label; - Extract subsequence 53-60 as the UMI . > **UMI** By design, the UMI is a string of eight randomers immediately downstream of CLS3. If the CLSs have perfect matches or base substitutions, the UMI sequence is at position 53–60. For reads with insertions or deletions within the CLSs, the UMI sequence is eight bases immediately following the end of the identified CLS3. R2 reads are transcript-only, and are expected to match a",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/628:349,guid,guides,349,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/628,2,['guid'],['guides']
Usability,"These messages have been removed in 0.9.0. Also, the read parser has had a considerable overhaul to avoid simply busy waiting in a situation like this where the processing is much slower than the disk. Let me know if this problem is resolved on your end.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/152#issuecomment-346981211:106,simpl,simply,106,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/152#issuecomment-346981211,2,['simpl'],['simply']
Usability,"This is failing on our local drone CI during runtime. The log output is :. ```; + echo ""[Testing quant]""; [Testing quant]; + ./.drone/test_quant.sh; Holy build box activated; Prefix: /hbb_exe; CFLAGS: -g -O2 -fvisibility=hidden -I/hbb_exe/include ; LDFLAGS: -L/hbb_exe/lib -static-libstdc++; STATICLIB_CFLAGS: -g -O2 -fvisibility=hidden -I/hbb_exe/include ; SHLIB_CFLAGS: -g -O2 -fvisibility=hidden -I/hbb_exe/include ; SHLIB_LDFLAGS: -L/hbb_exe/lib -static-libstdc++; [Drone test] current path : /drone/src/github.com/COMBINE-lab/salmon; [Drone test] making quant test directory; [Drone test] run nextflow pipeline; N E X T F L O W ~ version 0.29.1; Launching `tests/test_quant.nf` [curious_gilbert] - revision: 4f25b30301; [warm up] executor > local; [91/922fac] Submitted process > buildIndex; ERROR ~ Error executing process > 'buildIndex'; Caused by:; Process `buildIndex` terminated with an error exit status (127); Command executed:; /drone/src/github.com/COMBINE-lab/salmon/bin/salmon index -t Homo_sapiens.GRCh37.75.cdna.pc.fa -i nfindex; Command exit status:; 127; Command output:; (empty); Command error:; /drone/src/github.com/COMBINE-lab/salmon/bin/salmon: error while loading shared libraries: libjemalloc.so.2: cannot open shared object file: No such file or directory; Work dir:; /drone/src/github.com/COMBINE-lab/salmon/work/91/922facec25da43edd4a2ce82f2289d; Tip: when you have fixed the problem you can continue the execution appending to the nextflow command line the option `-resume`; -- Check '.nextflow.log' file for detail; ```. So, it seems to be due to failure to find the dynamic shared library for jemalloc. Any idea why that might be?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/348#issuecomment-472495264:1497,resume,resume,1497,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/348#issuecomment-472495264,2,['resume'],['resume']
Usability,"This pull-request is for develop branch.; This fixes https://github.com/COMBINE-lab/salmon/issues/275 . The reason of the build error was because b2 was always built with ""gcc"".; I added something like below code. ```; echo ""using gcc : ${CC_VERSION} : ${CMAKE_CXX_COMPILER} ;"" > ${CMAKE_CURRENT_SOURCE_DIR}/external/boost_1_66_0/tools/build/src/user-config.jam. /path/to/b2 .. toolset=${CC} ...; ```; ; There are still challenges to fix it. 1. The `make test` was finished with timeout. When setting `travis_wait 30 make test`, still failed with the timeout. Maybe we need to change the unit test logic to output something (log or progress bar) regularly to `stdout` during the test process or change the test logic itself. It is freezing at the below point. ```; /usr/local/cmake-3.9.2/bin/ctest --force-new-ctest-process ; Test project /home/travis/build/junaruga/salmon/build; Start 1: unit_tests; ```. 2. The `b2` parameter string `toolset=gcc-7 cxxflags=-std=c++14` is duplicated like this. Maybe we can change the logic in `CMakeLists.txt`. ```; CC=/usr/bin/gcc-7 CXX=/usr/bin/g++-7 /home/travis/build/junaruga/salmon/external/boost_1_66_0/b2 -d0 -j2 --with-iostreams --with-atomic --with-chrono --with-container --with-date_time --with-exception --with-filesystem --with-graph --with-graph_parallel --with-math --with-program_options --with-system --with-locale --with-timer toolset=gcc-7 toolset=gcc-7 cxxflags=-std=c++14 ""cxxflags= -std=c++14 -I/home/travis/build/junaruga/salmon/external/install/include -L/home/travis/build/junaruga/salmon/external/install/lib"" link=static install; ```. 3. `CMakeLists.txt` and `cmake/*.cmake` have a mixture of the different code formatting style. Aligning for formatting those make us read the files easier. I found the useful information for that. [1][2][3][4].; * 2 or 4 space indent?; * ""Tab"" indent is unintentionally used maybe.; * `set(...)` or `set (...)`.; * `set or SET`. [1] the KDE cmake coding style: https://community.kde.org/Policies/CMake",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/276:632,progress bar,progress bar,632,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/276,1,['progress bar'],['progress bar']
Usability,This seems like a fairly simple job for an external tool as well. What did you have in mind? Just transcript --> genomic coordinates in a table or are you interested in visualizing the pseudobam output mapped to genomic coordinates?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/193#issuecomment-371818629:25,simpl,simple,25,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/193#issuecomment-371818629,2,['simpl'],['simple']
Usability,"To keep the code simpler:. ```; txi <- tximport(files, type = ""salmon"", tx2gene = tx2gene, countsFromAbundance = ""lengthScaledTPM""); # then below...; dds <- DESeqDataSetFromTximport(txi, sampleTable, ~condition); ```. DESeq2 will do the right thing based on the value of `txi$countsFromAbundance`. This is the point of the importer functions. We also have them in tximeta for edgeR and limma. (You can still use tximeta with organisms other than human, mouse, or fly, you just have to run `makeLinkedTxome` and point to the GTF for your organism. It's just one step really.)",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/581#issuecomment-719806601:17,simpl,simpler,17,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/581#issuecomment-719806601,2,['simpl'],['simpler']
Usability,"To whom it may concern,. I am running Salmon with ""--numBootstraps 100"", but I am unsure where the bootstrapped estimates are doing. Are they incorporated directly into the *.quant.sf file, or is the only output from bootstrapping sent to the ""bootstraps.gz"" file? Thanks so much for any guidance you can provide!. Kindest regards,; Ryan Englander",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/818:288,guid,guidance,288,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/818,1,['guid'],['guidance']
Usability,"To whom it may concern,. I have been using Salmon to quantify RNA-seq data using a new long-read RNA sequencing-based GTF I have developed. When I run Salmon on RNA-seq samples from TCGA (read length = 50 bp, kmer length = 21), I tend to get ~95% of reads mapping to my transcriptome. However, when I use the same script to run my pipeline on in-house sequenced data (read length = 150 bp, kmer length = 21), I am getting only around 80-85% of reads mapping to my transcriptome. According to STAR, >90% (usually >95%) of these same in-house samples mapped to the genome. Why am I getting lower mapping rates? Could read length have something to do with it? Thanks so much for any advice or guidance you can provide. Script: ; [5_runSalmon.sh.zip](https://github.com/COMBINE-lab/salmon/files/10262688/5_runSalmon.sh.zip); (The only difference between my TCGA and in-house runs are that for TCGA I use ""-i IU"" and for my in-house samples I use ""-i ISR"" due to differences in the strandedness of the prep protocols). Yours most sincerely,; Ryan Englander",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/819:690,guid,guidance,690,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/819,1,['guid'],['guidance']
Usability,"Updated Expected behavior: ; A clear and concise description of what you expected to happen.; I aim to retain all gene IDs, and for those represented by multiple lines, I intend to calculate the sum of values for each unique gene ID. I came across a few posts regarding this issue, but have not found a good solution for salmon quantmerge yet",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/910#issuecomment-1918166379:31,clear,clear,31,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/910#issuecomment-1918166379,2,['clear'],['clear']
Usability,"Use Gencode is the simple solution. Also Gencode combines coding and non-coding while Ensembl has these as two FASTA files. What I'm thinking is that, `tximeta` can solve this for Ensembl post-hoc by simply renaming the duplicate transcripts after looking up the name of the transcript from the standard chromosome. it won't disrupt the function of `tximeta` because we index the sequence of the txome which doesn't care about the names of the duplicate transcripts",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/249#issuecomment-407831888:19,simpl,simple,19,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/249#issuecomment-407831888,4,['simpl'],"['simple', 'simply']"
Usability,"Using the rest of the same configure flags without `-DUSE_SHARED_LIBS=TRUE`, the build does not link properly. I think you should try building without these extra flags. Since the LTO seems not to be a problem on this system, a simple `cmake .. && make` should work. In the mean time, I'll try and pare back the configure command line to find the maximum viable interpolation between our different configurations. --Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464012294:228,simpl,simple,228,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/835#issuecomment-1464012294,2,['simpl'],['simple']
Usability,"We might have to go through the paper and the dropseq guidelines to check what really changed.; You might wanna check https://github.com/COMBINE-lab/salmon/issues/247, we actually have a hidden option to do customized umi/CB length options, however this goes into a little more unexplored territory and requires a bit more testing. We'd appreciate your feedback if you happen to run this mode.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/258#issuecomment-408191888:54,guid,guidelines,54,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/258#issuecomment-408191888,4,"['feedback', 'guid']","['feedback', 'guidelines']"
Usability,"Well, if they *were* paired end, they would be ISF. I assumed that Salmon would simply ignore the pairing information if you fed it single-end reads. (I think this is how some other tools work, maybe?) I'll retry with fixed library specifications and see if that fixes things. Edit: I just noticed your edit. I'll reply again in a minute.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266932730:80,simpl,simply,80,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-266932730,2,['simpl'],['simply']
Usability,"Where does `extract-libdivsufsort.cmake` live? I don't find it in the `salmon` repository. Is it generated automatically by `cmake`? The following patch/hack using `unzip` works around the `cmake -E tar xfz` bug for me. It seems to only affect extracting the `libdivsufsort.zip`, perhaps because it's a `.zip`. If that is the case, and there's a `.tar.gz` distribution of `libdivsufsort`, then there may be a simple fix. ``` diff; --- libdivsufsort-prefix/src/libdivsufsort-stamp/extract-libdivsufsort.cmake.orig 2016-03-07 22:02:35.000000000 -0800; +++ libdivsufsort-prefix/src/libdivsufsort-stamp/extract-libdivsufsort.cmake 2016-03-07 22:06:49.000000000 -0800; @@ -23,7 +23,7 @@; # Extract it:; #; message(STATUS ""extracting... [tar xfz]""); -execute_process(COMMAND ${CMAKE_COMMAND} -E tar xfz ${filename}; +execute_process(COMMAND unzip ${filename}; WORKING_DIRECTORY ${ut_dir}; RESULT_VARIABLE rv). ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/10#issuecomment-193623757:409,simpl,simple,409,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/10#issuecomment-193623757,2,['simpl'],['simple']
Usability,"While I definitely trust the jemalloc devs, I do know that such things are possible, as a release is simply associated with a tagged commit, which _can_ be changed via a forced update to the tags. I know because, in my early days using git + GitHub, I did such a foolish thing. So, while I'm sure that the jemalloc devs wouldn't change the file associated with a tag, and while there are safeguards (e.g. check that the file we get matches the SHA of what we expect), simply pulling from a fork is a convenient way to handle this ""generally"" (for packages not as production-quality as jemalloc, or where the developers might not have tagged a release corresponding to what we need). I completely understand that you don't want to link against a standard jemalloc if we compile some strange version with custom modifications. However, here, we simply want to use the vanilla jemalloc. In fact, when salmon is built under bioconda, this is exactly what we do (we link against the conda jemalloc >= 5.1.0).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/288#issuecomment-420339510:101,simpl,simply,101,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/288#issuecomment-420339510,6,['simpl'],['simply']
Usability,"Yea; so I think the only way to do this currently (without me modifying the jellyfish parser) is to just use 2 fifos. I could put together a simple bash or python script together for this if there is interest (until we support interleaved format natively, which I'll add to the feature list).",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-168516778:141,simpl,simple,141,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-168516778,2,['simpl'],['simple']
Usability,"Yeah, this is definitely not your issue. In fact, I just figured out that my explanation above was incomplete. **You don't need to investigate anything on your end**. I simply didn't flush the entire contents of a FASTA file to disk before calling `salmon index`. In the course of tracking down the issue I fixed some of my code indentation, bringing some of my code into a more global scope, where the `with` context handler I was using to hold the FASTA file open went out of scope, flushing my final writes to disk. Sigh...",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/132#issuecomment-303813062:169,simpl,simply,169,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/132#issuecomment-303813062,2,['simpl'],['simply']
Usability,"Yep, I think that's right and it is expected that every sample would have different number of cells/cellular barcodes. The general idea is to use a frequency distribution to separate high quality barcodes from low quality post quantification. I'm sorry that you are facing issues with v2, but the error simply means you are providing the full list of 737k barcodes which is not an expected behavior for the `--whitelist` flag and in a typical 10x/ Dropseq based experiment one would expect ~10-12k cells/CB.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-878695672:303,simpl,simply,303,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/682#issuecomment-878695672,2,['simpl'],['simply']
Usability,"Yes ! it's other error that I can't find . but I try : . ```; Last login: Thu Jun 30 15:14:51 on ttys002; Benjamin@u932-ulm-2-57030119-6834 ~ % conda config --add channels defaults; conda config --add channels bioconda; conda config --add channels conda-forge; Warning: 'conda-forge' already in 'channels' list, moving to the top; Benjamin@u932-ulm-2-57030119-6834 ~ % conda install salmon; Collecting package metadata (current_repodata.json): failed. CondaHTTPError: HTTP 000 CONNECTION FAILED for url <https://conda.anaconda.org/conda-forge/osx-arm64/current_repodata.json>; Elapsed: -. An HTTP error occurred when trying to retrieve this URL.; HTTP errors are often intermittent, and a simple retry will get you on your way.; 'https://conda.anaconda.org/conda-forge/osx-arm64'; ```. ```; Benjamin@u932-ulm-2-57030119-6834 ~ % conda config --show channels ; channels:; - conda-forge; - bioconda; - defaults; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171223414:689,simpl,simple,689,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171223414,2,['simpl'],['simple']
Usability,"Yes, I wonder if there is some sort of simple formatting issue that could be at fault here. Having a look at the file(s) would make it much easier to diagnose.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/540#issuecomment-648250382:39,simpl,simple,39,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/540#issuecomment-648250382,2,['simpl'],['simple']
Usability,"Yes, absolutely, above I meant in scRNA-seq context, my apologies if it was not clear.; Here, you are right we might have to think of ways to provide whitelist cellular barcode. One another thing you can try is providing the full 10x expected whitelisted cellular barcodes to alevin through `--whitelist` command.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-640698401:80,clear,clear,80,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-640698401,2,['clear'],['clear']
Usability,"Yup, and the fact that this ended up as `MU` is strange, since the library type frequencies clearly suggest `IU` (since `ISF` and `ISR` counts seem to dominate). Could it be the result of having the FASTQ files generated by converting from BAM which some sort of bias in the beginning reads? The automatic detection uses the first 10,000 reads to decide --- if these are mapped in a biased way, that could be the cause.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/137#issuecomment-406366598:92,clear,clearly,92,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/137#issuecomment-406366598,2,['clear'],['clearly']
Usability,"Yup, the execution is *definitely* inside the Gibbs sampler at that point, since that's the code that sets up the progress bar etc. So, I'll focus my attention there until (if/when) we can get a specific offending function name. Thanks so much for all your help tracking this down so far; I really appreciate it!",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267428600:114,progress bar,progress bar,114,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/111#issuecomment-267428600,2,['progress bar'],['progress bar']
Usability,"Yup; I think there are some potential places for improvement (e.g. the interleaved splitting code could be incorporated directly into this script, and the parsing could be improved to handle multiple interleaved files directly), but it seems to work pretty well. Also, when making this, I learned about the `trap` command, which should do what we want in terms of ensuring that any created fifos are cleaned up.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-168727465:289,learn,learned,289,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-168727465,2,['learn'],['learned']
Usability,"[Here's](https://gist.github.com/rob-p/963848ba35fb49fefaa3) a sketch of a shell script-based solution that might work. It relies on [this](https://gist.github.com/nathanhaigh/3521724) shell script to do the de-interleaving (but it can use whichever tool we might decide is best for the job). You'd run it with the interleaved file like so:. ```; ./runner.sh salmon quant -i index -l IU --interleaved interleaved.fq -o interleaved_quant; ```. Basically, the script checks to see if the `--interleaved` parameter is present. If so, it handles making the fifos and constructing the proper salmon command with them. Otherwise, if there is no --interleaved file, it simply runs the command as given.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-168582355:662,simpl,simply,662,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/29#issuecomment-168582355,2,['simpl'],['simply']
Usability,"] [info] Total Unique barcodes found: 604589; > [2020-06-04 12:26:10.936] [alevinLog] [info] Used Barcodes except Whitelist: 88156; > [2020-06-04 12:26:11.113] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify; > ; > [2020-06-04 12:26:11.113] [alevinLog] [info] parsing read library format; > [2020-06-04 12:27:21.373] [alevinLog] [info] Starting optimizer; > ; > [2020-06-04 12:27:22.086] [alevinLog] [warning] mrna file not provided; using is 1 less feature for whitelisting; > [2020-06-04 12:27:22.086] [alevinLog] [warning] rrna file not provided; using is 1 less feature for whitelisting; > [2020-06-04 12:27:22.409] [alevinLog] [info] Total 23937.00 UMI after deduplicating.; > [2020-06-04 12:27:22.409] [alevinLog] [info] Total 91 BiDirected Edges.; > [2020-06-04 12:27:22.409] [alevinLog] [info] Total 82 UniDirected Edges.; > [2020-06-04 12:27:22.409] [alevinLog] [warning] Skipped 82268 barcodes due to No mapped read; > [2020-06-04 12:27:22.412] [alevinLog] [info] Clearing EqMap; Might take some time.; > [2020-06-04 12:27:22.418] [alevinLog] [warning] Num Low confidence barcodes too less 1 < 100.Can't performing whitelisting; Skipping; > [2020-06-04 12:27:22.418] [alevinLog] [info] Finished optimizer. Run 2: `salmon alevin -l ISR --citeseq --barcodeLength 16 --umiLength 10 --end 5 --featureStart 19 --featureLength 21 --maxNumBarcodes 200000 --freqThreshold 1 --lowRegionMinNumBarcodes 100`. > [2020-06-04 12:40:45.455] [alevinLog] [info] set CITE-seq minScoreFraction parameter to : 0.797619; > [2020-06-04 12:40:45.456] [alevinLog] [info] Found 64 transcripts(+0 decoys, +0 short and +0 duplicate names in the index); > [2020-06-04 12:40:45.456] [alevinLog] [info] Filled with 64 txp to gene entries ; > [2020-06-04 12:40:45.456] [alevinLog] [info] Found all transcripts to gene mappings; > [2020-06-04 12:40:45.461] [alevinLog] [info] Processing barcodes files (if Present) ; > ; > [2020-06-04 12:42:01.202] [alevinLog] [info] Done barcode density calculation.; ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638991199:3804,Clear,Clearing,3804,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-638991199,1,['Clear'],['Clearing']
Usability,"`419663 Segmentation fault (core dumped) `; **To Reproduce**; Steps and data to reproduce the behavior:; Code ran:; `salmon quant --ont -p 24 -t ${ref} -l U -a ""007_D14_transcript.bam"" ""007_D1_transcript.bam"" ""014_D14_transcript.bam"" ""014_D1_transcript.bam"" ""069_D14_transcript.bam"" ""069_D1_transcript.bam"" ""127_D14_transcript.bam"" ""127_D1_transcript.bam"" ""36S_D14_transcript.bam"" ""36S_D1_transcript.bam"" ""SCTI_D14_transcript.bam"" ""SCTI_D1_transcript.bam"" ""SCTI_D1_2000ng_transcript.bam"" ""ioGLUT_D7_transcript.bam"" ""ioMGL_D10_transcript.bam"" -o ${output}/transcripts_quant`. Specifically, please provide at least the following information:; * Which version of salmon was used? 1.10.2; * How was salmon installed (compiled, downloaded executable, through bioconda)? module installed on HPC; * Which reference (e.g. transcriptome) was used? gencode.v44.transcriptome (Human); * Which read files were used? bam; * Which program options were used? salmon quant. **Expected behavior**; A clear and concise description of what you expected to happen.; Salmon quant to generate quant output.; **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. ```; Version Server Response: Not Found; # salmon (alignment-based) v1.10.2; # [ program ] => salmon ; # [ command ] => quant ; # [ ont ] => { }; # [ threads ] => { 24 }; # [ targets ] => { /scratch/users/k19022845/refgenome/gencode.v44.transcripts.fa }; # [ libType ] => { U }; # [ alignments ] => { 007_D14_transcript.bam 007_D1_transcript.bam 014_D14_transcript.bam 014_D1_transcript.bam 069_D14_transcript.bam 069_D1_transcript.bam 127_D14_transcript.bam 127_D1_transcript.bam 36S_D14_transcript.bam 36S_D1_transcript.bam SCTI_D14_transcript.bam SCTI_D1_transcript.bam SCTI_D1_2000ng_transcript.bam ioGLUT_D7_transcript.bam ioMGL_D10_transcript.bam }; # [ output ] => { /scratch/prj/ppn_microglia_mod/directrna/salmon/transcripts_quant }; Logs will be written to /scratch/prj/ppn_microglia_mod/directrna/salmon/tra",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/923:1099,clear,clear,1099,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/923,1,['clear'],['clear']
Usability,"```; Benjamin@u932-ulm-2-57030119-6834 ~ % conda install salmon; Collecting package metadata (current_repodata.json): failed. CondaHTTPError: HTTP 000 CONNECTION FAILED for url <https://conda.anaconda.org/conda-forge/osx-arm64/current_repodata.json>; Elapsed: -. An HTTP error occurred when trying to retrieve this URL.; HTTP errors are often intermittent, and a simple retry will get you on your way.; 'https://conda.anaconda.org/conda-forge/osx-arm64'; ```. ```; Benjamin@u932-ulm-2-57030119-6834 ~ % conda config --show channels; channels:; - conda-forge; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171204474:363,simpl,simple,363,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/724#issuecomment-1171204474,2,['simpl'],['simple']
Usability,"alignment, the alignment scores are passed to the quantification step, but the position of the reads is not used downstream. . Well, yes and no. We make extensive use of the position when estimate the implied fragment length (distance between paired end reads) and then model the conditional probability of this fragment based on the global fragment length distribution. This is just as much as is done by e.g. RSEM. However, you are right that there is no notion of using the coverage profile in estimation (more on this below)!. > Also, my intuition for these transcripts is not really a coverage ""bias"" . My intuition agrees with yours here completely. First, this isn't really a coverage bias as we use the normal definition of the term. Second, the positional bias modeling in salmon is not on a per-transcript level (since that would be an astronomical number of different parameters to learn, and any procedure would almost certainly overfit). Instead, it groups transcripts into length bins, and learns a distinct coverage bias model per-bin. > It would be neat if Salmon could detect these kinds of dramatic dropoffs and add a warning or something... even if not incorporating the information into the quants... it could even be a good QC step to identify large deletions/insertions over a gene body. As far as I know, there are NO rnaseq quant programs that would handle this, because even something like a STAR -> RSEM pipeline just projects read counts to the transcriptome and doesn't incorporate the coverage information. These are **great** points! A couple of thoughts. First, you are right that salmon, RSEM, etc. don't use coverage information in the way you describe here. One piece of software you might look into is [Salmon Anomaly Detection](https://github.com/Kingsford-Group/sad) (paper [here](https://www.cell.com/cell-systems/pdf/S2405-4712(19)30381-3.pdf)). This is sort of akin to what you are suggesting, and post-processes salmon output by looking for anomalous coverage",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623047035:1575,learn,learns,1575,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623047035,2,['learn'],['learns']
Usability,"approach right. I believe, It takes time and understanding to develop a good model for data generated from any technology and that's what we have been trying to do with salmon for years, piece by piece. Having said that, we don't mean to discourage people from trying salmon, that's one of the way we learn how can we improve the model even further. Now, coming back to your original question about using QuantSeq with salmon and how the paper above approach to solve it. I have a couple of thoughts:; 1.) Like you said, from the reading of their command line argument they didn't use the `nolengthcorrection` and I am surprised about the results myself. Since you have experience with the technology, you are best person to explore the difference in using and not using the length correction with salmon, that's why I shared.; 2.) Salmon models the transcript lengths in its quantification model. The basic intuition being longer length transcripts have higher probability of a read being sampled from them and has to be corrected for when using relative count metrices (like TPM) to avoid length bias. The logic behind `noLengthCorrection` is to _not_ correct for length for 3' protocol since we expect all the reads from one end of the transcript and if we do length correction, I hypothesize, we might end up biasing the estimates on the opposite direction; however the effect size of this hypothesis is still an open question and seemingly from the results from the paper it has minor effect. On the flip side may be it does have effect but their baseline estimates were not great and any improvement is good, for that again since you have experience with the data it's good to know / test what's going on.; 3.) A little experimental thought, although `noLengthCorrection` flag can generate decent estimates, it's actually fully disabling the length effect, which in my opinion we can do better as you look at Figure 1B of the paper it shows some length based affect but again we don't know how ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565256512:1813,intuit,intuition,1813,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565256512,2,['intuit'],['intuition']
Usability,"ath(dir, ""salmon"", samples$run, ""quant.sf.gz""); names(files) <- paste0(""sample"", 1:6); txi.salmon <- tximport(files, type = ""salmon"", tx2gene = tx2gene); head(txi.salmon$counts). ```; Why the confusion - https://bioconductor.org/packages/devel/bioc/vignettes/tximport/inst/doc/tximport.html#Downstream_DGE_in_Bioconductor - states ; - The two methods we provide here are: “original counts and offset” or “bias corrected counts without an offset”. Passing txi to DESeqDataSetFromTximport as outlined below is correct: the function creates the appropriate offset for you to perform gene-level differential expression; - The second method is to use the tximport argument countsFromAbundance=""lengthScaledTPM"" or ""scaledTPM"", and then to use the gene-level count matrix txi$counts directly as you would a regular count matrix with these software. Let’s call this method “bias corrected counts without an offset”. Now, if I were to use the 2nd bullet as guide, shouldn't txi be generated this way for use with DESeq -- see the addition of `countsFromAbundance = ""lengthScaledTPM""` to tximport line. ```; files <- file.path(dir, ""salmon"", samples$run, ""quant.sf.gz""); names(files) <- paste0(""sample"", 1:6); txi.salmon <- tximport(files, type = ""salmon"", tx2gene = tx2gene, countsFromAbundance = ""lengthScaledTPM""); head(txi.salmon$counts); write.csv(as.data.frame(txi.salmon$counts), file = ""tx2gene_NumReads.csv""); ```. And then use the tx2gene_NumReads.csv with DESeqDataSetFromMatrix, where the countData comes after reading in tx2gene_NumReads.csv upstream in the code. **Note**: I am using DESeqDataSetFromMatrix here and not DESeqDataSetFromTximport as I have used tximport with countsFromAbundance=lengthScaledTPM. ```; library(""DESeq2""); dds <- DESeqDataSetFromMatrix(countData = cts,; colData = coldata,; design = ~ condition); dds; ```. I also saw these 2 links - https://hbctraining.github.io/DGE_workshop_salmon/lessons/07_DGE_summarizing_workflow.html and https://hbctraining.github.io/DGE_work",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/581:2358,guid,guide,2358,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/581,1,['guid'],['guide']
Usability,bType ] => { ISR }; ### [ mates1 ] => { SRR6054189.sra_1.fastq }; ### [ mates2 ] => { SRR6054189.sra_2.fastq }; ### [ dropseq ] => { }; ### [ index ] => {~/Documents/CordBlood/data/index_15 }; ### [ threads ] => { 4 }; ### [ output ] => {~/Documents/CordBlood/data/alevin4p_out_combined }; ### [ tgMap ] => {~/Documents/CordBlood/data/txp2gene.tsv }; ### [ dumpCsvCounts ] => { }. [2018-07-26 11:15:08.510] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2018-07-26 11:15:08.524] [alevinLog] [info] Processing barcodes files (if Present) . ; processed 471 Million barcodes. [2018-07-26 11:25:20.231] [alevinLog] [info] Done barcode density calculation.; [2018-07-26 11:25:20.231] [alevinLog] [info] # Barcodes Used: 470701906 / 471465434.; [2018-07-26 11:25:30.228] [alevinLog] [info] Knee found left boundary at 202 ; [2018-07-26 11:25:31.135] [alevinLog] [info] Gauss Corrected Boundary at 22 ; [2018-07-26 11:25:31.135] [alevinLog] [info] Learned InvCov: 1044.2 normfactor: 295.235; [2018-07-26 11:25:31.135] [alevinLog] [info] Total 222(has 200 low confidence) barcodes; [2018-07-26 11:25:31.440] [alevinLog] [info] Done True Barcode Sampling; [2018-07-26 11:25:31.789] [alevinLog] [info] Done populating Z matrix; [2018-07-26 11:25:31.793] [alevinLog] [info] Done indexing Barcodes; [2018-07-26 11:25:31.793] [alevinLog] [info] Total Unique barcodes found: 10630133; [2018-07-26 11:25:31.793] [alevinLog] [info] Used Barcodes except Whitelist: 10603; [2018-07-26 11:25:31.938] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2018-07-26 11:25:31.939] [alevinLog] [info] parsing read library format; [2018-07-26 11:25:31.949] [jointLog] [info] There is 1 library.; [2018-07-26 11:25:32.331] [jointLog] [info] Loading Quasi index; [2018-07-26 11:25:32.331] [jointLog] [info] Loading 32-bit quasi index; [2018-07-26 11:25:32.357] [stderrLog] [info] Loading Suffix Array ; [2018-07-26 11:26:09.413] [stderrLog] [info] L,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/258:1960,Learn,Learned,1960,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/258,1,['Learn'],['Learned']
Usability,"be present there. The main purpose of the decoys is to account for reads not from target transcripts that might otherwise be sequenced in the sample. The reason we report the decoy mapping fragments in the unmapped names file is, as I said, a historical contingency. Basically, since we're not mapping the decoys to targets and counting them toward quantification, one might be interested in knowing where the decoy sequences come from. At some point, the easiest way to do this was just to place the name of these fragments in the unmapped names file (with the d tag) and then grab the reads and go fishing with them in some other way. However, I totally understand why including them in the unmapped names file is confusing. During selective-alignment, if we assign a fragment as best mapping to a decoy, it doesn't get assigned to a quantifiable target, but it's not technically unmapped in the same sense as the other unmapped reads. That is, we know it comes from the decoy sequence, that the alignment score is at least the minimum required, and that it maps better to the decoy than to any non-decoy target. That's quite different that ""truly"" unmapped fragments where we find no mapping for the fragment within the required score threshold. Anyway, I hope the answer is useful for you. If you want to select only unmapped reads that were matched to neither your target sequences (transcripts) nor to the decoy sequences, then your grep command should do the trick. However, if you want to look at all of the reads that simply didn't contribute to the counts in the quant.sf file, then you'd want to look at everything in the unmapped names file. Let me know if you have any other questions!. Best,; Rob. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/COMBINE-lab/salmon/issues/657#issuecomment-841492751>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AN3VWAUROTOCPHB6SKMA2ETTNWDF5ANCNFSM44HLOFXQ>.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/657#issuecomment-843255628:2473,simpl,simply,2473,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/657#issuecomment-843255628,2,['simpl'],['simply']
Usability,"bit on a few of @k3yavi's answers. 1&2) Yes; if you want to use SAF, you no longer need mashmap, as what you are essentially doing is treating the entire genome as a ""decoy"". As @k3yavi alludes, SA is still useful when you need to run in a very memory-constrained environment. After adopting the new [pufferfish-based](https://github.com/COMBINE-lab/pufferfish/tree/develop) index, the size of the transcriptome plush mashmap 2 decoys becomes considerably smaller than the previous size of the transcriptome in earlier versions of salmon (<= 0.15.0). However, depending on the organism, indexing the entire genome as decoy, even though it yields the best accuracy, does require a bit more memory, as specified in the release notes for the 0.99 betas and 1.0.0. 3) Yes; it is still possible to use `salmon index` without any decoy sequence. In this case, one can expect results similar to if you had aligned to the target transcriptome using Bowtie2. In this case, you perform indexing by simply not providing any `--decoy` flag to the `index` command. In that case, all of the records in the target fasta will be treated as valid and quantifiable targets. Of course, for reasons detailed in the pre-print --- the high _sensitivity_ of both Bowtie2 and selective-alignment --- we recommend including either mashmap-derived decoys or the organism's genome as a decoy whenever possible. . 4) Related to @k3yavi's response and my elaboration above: we have dropped quasi-mapping from 1.0.0 (though something akin to it may return in the future if there is sufficient demand and if the shortcomings described in the manuscript can be overcome). However, as I mention in part 3 above, this doesn't mean it's not possible to use v1.0.0 without an explicit decoy sequence. The `--decoy` flag of the indexing command is optional, not required. We will update this in the documentation making it more explicit. However, as @k3yavi points out, it is true that if you wish to use quasi-mapping and selective-alig",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/442#issuecomment-549195390:1061,simpl,simply,1061,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/442#issuecomment-549195390,2,['simpl'],['simply']
Usability,"ce) barcodes; > [2023-08-17 22:13:23.660] [alevinLog] [info] Done True Barcode Sampling; (some lines later); > [2023-08-17 22:14:04.046] [jointLog] [info] Computed 0 rich equivalence classes for further processing; > [2023-08-17 22:14:04.046] [jointLog] [info] Counted 0 total reads in the equivalence classes; > [2023-08-17 22:14:04.047] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 0; > [2023-08-17 22:14:04.083] [jointLog] [info] Mapping rate = 0%. It ultimately dies with a floating point error, probably for dividing by 0 somewhere. . The command I'm running is (and note that I have r1 and r2 swapped, per some other guidance. It dies earlier during barcode processing otherwise):. > salmon alevin -i /ref/gencode.v43.transcripts/ -l ISR -1 r2.fastq.gz -2 r1.fastq.gz -p 30 --splitseqV2 --tgMap /ref/gencode.v43_full.txMap -o salmon_output --expectCells 400. I tried to make it simpler and simpler, so that's a salmon index I made myself with no decoys, just the gencode transcript fasta with the software version I'm trying to run (salmon 1.10.2, from the combinelab/salmon docker hub), gencode v43 (I know, it's a version behind, but it's what I'm using elsewhere...) and hg38. It's handling the barcodes fine and recovering approximately the right amount (it's a sub-library with a few hundred cells to check the quality of the library before sequencing the full experiment). But it's failing to quantitate any of the reads. Oddly, just quantitating the read1 file with; > salmon quant -i /ref/gencode.v43.transcripts/ -l ISR -r r1.fastq.gz -p 30 -o work/salmon_output. behaves as expected and prints this and proceeds. > [2023-08-17 22:21:17.619] [jointLog] [info] Computed 618403 rich equivalence classes for further processing; > [2023-08-17 22:21:17.619] [jointLog] [info] Counted 6085013 total reads in the equivalence classes; > [2023-08-17 22:21:17.632] [jointLog] [info] Number of mappings discarded because of alignment score : 166235099.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/867:1434,simpl,simpler,1434,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/867,2,['simpl'],['simpler']
Usability,"coys.txt -p 12 -i salmon_index --gencode; ```; 4. Run salmon ; ```; IDX=""/scratch/scratch/skgtjzw/workspace/middle_aged_microglia/salmon_quantification_SAF/salmon_index/""; for fn in /scratch/scratch/skgtjzw/workspace/middle_aged_microglia/salmon_quantification_SAF/SRR{2557119..2557121}; do; samp=`basename ${fn}`; echo ""Processing sample ${samp}""; salmon quant -i $IDX -l A -1 ${fn}_1.fastq.gz -2 ${fn}_2.fastq.gz -p 8 \; --validateMappings \; -o quants/${samp}_quant \; --gcBias; done; ```. Specifically, please provide at least the following information:. * Which version of salmon was used?; 1.4.0; * How was salmon installed (compiled, downloaded executable, through bioconda)?; 1.3.0 salmon was installed by miniconda, then updated to 1.4.0 via miniconda ; * Which reference (e.g. transcriptome) was used?; Gencode_human/release_36/gencode.v36.transcripts.fa.gz; * Which read files were used?; fastq.gz file with 150 paired reads ; * Which which program options were used?. **Expected behavior**; A clear and concise description of what you expected to happen. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. **Desktop (please complete the following information):**; On a cluster with Ubuntu Linux. **Additional context**; I was running the default method of building index with only the gencode.v36.transcripts.fa.gz, and the mapping rate for my fastq files were 42-55%, which i think is quite low (based on what i read, it is expected to be around 70%). Then, I thought i might give a go with building decoy-aware transcriptome index, and this did not go well as i presented above. . I found an old post with the similar issue, which the conclusion was that the index building was not completed due to memory allocation on the cluster. I was wondering if this is the same with my case, what memory allocation should i ask the admin for to do this index building job? Any guidance on this would be greatly appreciated, and thank you in advance!",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/603:3789,clear,clear,3789,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/603,2,"['clear', 'guid']","['clear', 'guidance']"
Usability,"ctor: 1097.45; [2019-07-09 09:17:07.597] [alevinLog] [info] Total 41.2673% reads will be thrown away because of noisy Cellular barcodes.; [2019-07-09 09:17:07.597] [alevinLog] [info] Total [32m1192[0m(has [32m397[0m low confidence) barcodes; [2019-07-09 09:17:07.765] [alevinLog] [info] Done True Barcode Sampling; [2019-07-09 09:17:08.039] [alevinLog] [info] Done populating Z matrix; [2019-07-09 09:17:08.067] [alevinLog] [info] Done indexing Barcodes; [2019-07-09 09:17:08.067] [alevinLog] [info] Total Unique barcodes found: 7881525; [2019-07-09 09:17:08.067] [alevinLog] [info] Used Barcodes except Whitelist: 84951; [2019-07-09 09:17:08.128] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2019-07-09 09:17:08.128] [alevinLog] [info] parsing read library format; [2019-07-09 10:02:26.992] [alevinLog] [info] Starting optimizer. [2019-07-09 10:13:56.661] [alevinLog] [info] Total 99488568.00 UMI after deduplicating.; [2019-07-09 10:13:56.701] [alevinLog] [info] Clearing EqMap; Might take some time.; [2019-07-09 10:14:11.020] [alevinLog] [info] Starting Import of the gene count matrix of size 1192x60053.; [2019-07-09 10:14:11.286] [alevinLog] [info] Done initializing the empty matrix.; [2019-07-09 10:14:13.421] [alevinLog] [info] Done Importing gene count matrix for dimension 1192x60053; [2019-07-09 10:14:13.622] [alevinLog] [info] Starting white listing; [2019-07-09 10:14:13.627] [alevinLog] [info] Done importing order of barcodes ""quants_mat_rows.txt"" file.; [2019-07-09 10:14:13.627] [alevinLog] [info] Total 1192 barcodes found; [2019-07-09 10:14:13.627] [alevinLog] [warning] mrna file not provided; using is 1 less feature for whitelisting; [2019-07-09 10:14:13.627] [alevinLog] [warning] rrna file not provided; using is 1 less feature for whitelisting; [2019-07-09 10:14:13.627] [alevinLog] [info] Starting to make feature Matrix; [2019-07-09 10:14:13.885] [alevinLog] [info] Done making regular featues; [2019-07-09 10:14:13.885] [alevinLog] [info] Do",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/396#issuecomment-510547693:1547,Clear,Clearing,1547,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/396#issuecomment-510547693,1,['Clear'],['Clearing']
Usability,"d handle this, because even something like a STAR -> RSEM pipeline just projects read counts to the transcriptome and doesn't incorporate the coverage information. These are **great** points! A couple of thoughts. First, you are right that salmon, RSEM, etc. don't use coverage information in the way you describe here. One piece of software you might look into is [Salmon Anomaly Detection](https://github.com/Kingsford-Group/sad) (paper [here](https://www.cell.com/cell-systems/pdf/S2405-4712(19)30381-3.pdf)). This is sort of akin to what you are suggesting, and post-processes salmon output by looking for anomalous coverage profiles. It can both flag ""suspicious"" transcripts, and can also sometimes move reads around to mitigate anomalous coverage. Another tool / metric you might consider is the junction coverage compatibility (paper [here](https://www.life-science-alliance.org/content/2/1/e201800175)). While both of these approaches get at some of the core intuitions you raise in your response, they are both rather ""heavyweight"", and neither, of course, is built into salmon. So, I **completely agree** that a lightweight version of something like SAD would be great to have built _into_ salmon. Specifically, it makes a lot of sense to have some component of the likelihood account for the coverage profile of transcripts. While I don't know of any widely-used and actively maintained quantification tools that do this, the idea for this was proposed in the [iReckon paper](https://www.ncbi.nlm.nih.gov/pubmed/23204306) and a coverage-based heuristic was introduced. However, the coverage was not directly incorporated into the likelihood. Rather, a variant of the normal likelihood function was used and then coverage was used to select between different potential solutions that were otherwise of similar likelihood. Given issues like the one you see here, and the ones that we observed in the JCC paper and that Cong and Carl observed in the SAD paper, it seems clear that it would b",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623047035:2911,intuit,intuitions,2911,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623047035,2,['intuit'],['intuitions']
Usability,"detection:. - fail to detect adpaters automatically - (https://github.com/OpenGene/fastp/issues/222 and https://github.com/OpenGene/fastp/issues/205). - [incorrect automatic adapter detection](https://github.com/OpenGene/fastp/issues/240). - [inconsistent behavior with different runs](https://github.com/OpenGene/fastp/issues/231). 3. When I see the above, I am bit skeptical using fastp for qc/adapter trimming. . After lot of trials with bbduk and fastp, I have decided to use bbduk and bbmap for my high throughput analysis. Below, I explain my reasoning behind those choices: . **_```Note - edited this on 02-Apr-2020 to have the correct order of operations ```_** . 1. **_STEP 1 - run bbmap.sh on raw fatsq file to remove contaminants as appropriate (rRNA, mitochondrial, chloroplast)_**; - You have alluded to the importance of removing contaminants [in this post](https://github.com/COMBINE-lab/salmon/issues/160#issuecomment-334762498); >However, the other thing to try is simply to align one of these samples to the genome with a tool like STAR or HISAT2 and look at their mapping rate to known features. If it's similar, then the other reads could be accounted for by e.g. intron retention or even contamination. Finally, [@vals has an excellent series of blog posts on investigating and addressing low mapping rates](http://www.nxn.se/valent/2017/9/18/low-mapping-rate-5-human-dna-contamination); - bbmap Command ([based of this biostars post](https://www.biostars.org/p/143019/#210890)):; `bbmap.sh in=read_1.fq.gz ref=rRNA_Chlor_Mito.fa maxindel=1 minid=0.95 outu=clean_read_1.fq.gz nodisk`; - Strategy:; `use the rRNA+Mito+Chloroplast file and map the reads using bbmap, then collect the unmapped reads (clean_read_1.fq.gz) for my downstream analysis`. 2. **_STEP 2 - run bbduk.sh on the outu files from bbmap step -- the outu stands for output unmapped - as stated in the logic above, anything that is unmapped to the rRNA_Chlor_Mito.fa is a clean read for downstream analysis_**. I us",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209:2391,simpl,simply,2391,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/485#issuecomment-597393209,2,['simpl'],['simply']
Usability,"ecoy will be quantified. I am surprised to see that the name for mapped reads would show up in the unmapped_names.txt file.; ; Well, it's the case the decoys are *not* be quantified. That is, only the target transcripts will appear in the `quant.sf` file, no decoys should be present there. The main purpose of the decoys is to account for reads _not_ from target transcripts that might otherwise be sequenced in the sample.; ; The reason we report the decoy mapping fragments in the unmapped names file is, as I said, a historical contingency. Basically, since we're not mapping the decoys to targets and counting them toward quantification, one might be interested in knowing _where_ the decoy sequences come from. At some point, the easiest way to do this was just to place the name of these fragments in the unmapped names file (with the `d` tag) and then grab the reads and go fishing with them in some other way. However, I totally understand why including them in the unmapped names file is confusing. During selective-alignment, if we assign a fragment as best mapping to a decoy, it doesn't get assigned to a quantifiable target, but it's not technically unmapped in the same sense as the other unmapped reads. That is, we know it comes from the decoy sequence, that the alignment score is at least the minimum required, and that it maps better to the decoy than to any non-decoy target. That's quite different that ""truly"" unmapped fragments where we find no mapping for the fragment within the required score threshold. Anyway, I hope the answer is useful for you. If you want to select only unmapped reads that were matched to *neither* your target sequences (transcripts) *nor* to the decoy sequences, then your `grep` command should do the trick. However, if you want to look at all of the reads that simply didn't contribute to the counts in the `quant.sf` file, then you'd want to look at everything in the unmapped names file. Let me know if you have any other questions!. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/657#issuecomment-841492751:2120,simpl,simply,2120,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/657#issuecomment-841492751,2,['simpl'],['simply']
Usability,"ed more RAM? Or it is a bug.; ; More info as below:; [2018-10-24 11:14:15.505] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2018-10-24 11:14:15.505] [jointLog] [info] parsing read library format; [2018-10-24 11:14:15.505] [jointLog] [info] There is 1 library.; [2018-10-24 11:14:15.627] [jointLog] [info] Loading Quasi index; [2018-10-24 11:14:15.629] [jointLog] [info] Loading 32-bit quasi index; [2018-10-24 11:14:15.633] [stderrLog] [info] Loading Suffix Array; [2018-10-24 11:14:17.090] [stderrLog] [info] Loading Transcript Info; [2018-10-24 11:14:17.691] [stderrLog] [info] Loading Rank-Select Bit Array; [2018-10-24 11:14:18.293] [stderrLog] [info] There were 309,566 set bits in the bit array; [2018-10-24 11:14:18.819] [stderrLog] [info] Computing transcript lengths; [2018-10-24 11:14:18.820] [stderrLog] [info] Waiting to finish loading hash; [2018-10-24 11:15:46.171] [jointLog] [info] done; [2018-10-24 11:15:46.171] [jointLog] [info] Index contained 309,566 targets; [2018-10-24 11:15:46.171] [stderrLog] [info] Done loading index. **To Reproduce**; Steps and data to reproduce the behavior:. Specifically, please provide at least the following information:. * Which version of salmon was used? 0.11.3; * How was salmon installed (compiled, downloaded executable, through bioconda)?. downloaded execitable. * Which reference (e.g. transcriptome) was used?; human; * Which read files were used?; * Which which program options were used?; All default. **Expected behavior**; A clear and concise description of what you expected to happen. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX] Linux; - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux the output of `uname -a` and `lsb_release -a`]. **Additional context**; Add any other context about the problem here.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/304:2118,clear,clear,2118,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/304,1,['clear'],['clear']
Usability,"ed; [2022-12-03 15:58:24.122] [alevinLog] [info] Done indexing Barcodes; [2022-12-03 15:58:24.122] [alevinLog] [info] Total Unique barcodes found: 16409283; [2022-12-03 15:58:24.122] [alevinLog] [info] Used Barcodes except Whitelist: 187465; [2022-12-03 15:58:24.389] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2022-12-03 15:58:24.389] [alevinLog] [info] parsing read library format; [2022-12-03 16:17:47.714] [alevinLog] [info] Starting optimizer. [2022-12-03 16:17:47.868] [alevinLog] [warning] mrna file not provided; using is 1 less feature for whitelisting; [2022-12-03 16:17:47.868] [alevinLog] [warning] rrna file not provided; using is 1 less feature for whitelisting; [2022-12-03 16:18:01.362] [alevinLog] [info] Total 17192510.00 UMI after deduplicating.; [2022-12-03 16:18:01.362] [alevinLog] [info] Total 1333800 BiDirected Edges.; [2022-12-03 16:18:01.362] [alevinLog] [info] Total 181036 UniDirected Edges.; [2022-12-03 16:18:01.432] [alevinLog] [info] Clearing EqMap; Might take some time.; [2022-12-03 16:18:08.522] [alevinLog] [info] Starting white listing of 5460 cells; [2022-12-03 16:18:08.522] [alevinLog] [info] Starting to make feature Matrix; [2022-12-03 16:18:08.535] [alevinLog] [info] Done making feature Matrix; [2022-12-03 16:18:09.324] [alevinLog] [info] Finished white listing; [2022-12-03 16:18:09.513] [alevinLog] [info] Finished optimizer. Salmon_quant log:; [2022-12-03 15:43:11.767] [jointLog] [info] setting maxHashResizeThreads to 48; [2022-12-03 15:43:11.767] [jointLog] [info] Fragment incompatibility prior below threshold. ; Incompatible fragments will be ignored.; [2022-12-03 15:43:11.767] [jointLog] [info] The --mimicBT2, --mimicStrictBT2 and --hardFilter flags imply mapping validation (--validateMappings). Enabling mapping validation.; [2022-12-03 15:43:11.767] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2022-12-03 15:43:11.767] [",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/814:3649,Clear,Clearing,3649,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/814,1,['Clear'],['Clearing']
Usability,"efault. RSEM uses the EM algorithm, and salmon uses the variational Bayesian EM algorithm. The latter tends to induce more sparse solutions. This is simply because they are optimizing slightly different objectives. It is very difficult to say in general if one is ""better"" than the other in a blanket way, but [there is previous literature to support that the VBEM may be more accurate](https://academic.oup.com/bioinformatics/article/29/18/2292/239795). However, while RSEM only implements the EM algorithm, salmon actually implements and provides a switch to use either. So, if you want to test the effect of this difference, you can run salmon with the `--useEM` algorithm. This will tell salmon to use the ""classic"" EM algorithm and will eliminate this source of variation. * As with the other question you asked, there may be a _small_ discrepancy depending on when enforcement of a stranded library kicks in under salmon's `A` library type. You can eliminate that variable by simply providing `-l SF` to match the library type being used with RSEM. * Coming back to the `IndelSoftclipSingleend` parameter I mentioned in the first point; RSEM disallows indels in the alignments that it quantifies. This means that to produce RSEM-compatible input, STAR must not align reads that contain indels. While this won't generally have a big effect for many transcripts, it can certainly affect the abundance estimates for transcripts in your sample where the sample you are quantifying has (indel) variation with respect to the reference annotation. We touch upon that a bit as well in the [paper I mentioned above](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-020-02151-8). * Finally, and likely the smallest source of potential differences, is that there are other implementation details that differ between salmon and RSEM (e.g. exactly how the fragment length distribution is used to compute the effective transcript length, exactly how the alignment score of a read is used to as",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/612#issuecomment-758004590:3672,simpl,simply,3672,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/612#issuecomment-758004590,2,['simpl'],['simply']
Usability,"eger width = 32; [2023-03-15 20:35:37.482] [puff::index::jointLog] [info] seqSize = 2,210,067,304; [2023-03-15 20:35:37.482] [puff::index::jointLog] [info] rankSize = 2,210,067,304; [2023-03-15 20:35:37.482] [puff::index::jointLog] [info] edgeVecSize = 0; [2023-03-15 20:35:37.482] [puff::index::jointLog] [info] num keys = 1,869,461,974; ^M[Building BooPHF] 0.194% elapsed: 0 min 0 sec remaining: 3 min 39 sec^M[Building BooPHF] 0.206% elapsed: 0 min 0 sec remaining: 3 min 33 sec^M[Building BooPHF] 0.394% elapsed: 0 min 1 sec remaining: 2 min 45 sec^M[Building BooPHF] 0.406% elapsed: 0 min 1 sec remaining: 2 min 44 sec^M[Building BooPHF] 0.594% elapsed: 0 min 1 sec remaining: 2 m; psed: 0 min 56 sec remaining: 1 min 16 sec^M[Building BooPHF] 42.4 % elapsed: 0 min 56 sec remaining: 1 min 16 sec^M[Building BooPHF] 42.6 % elapsed: 0 min 56 sec remaining: 1 min 15 sec^M[Building BooPHF] 42.6 % elapsed: 0 min 56 sec remaining: 1 min 15 sec^M[Building BooPHF] 42.8 % elapsed: 0 min 56 sec remaining: 1 min 15 sec^M[Building BooPHF] 42.; salmon index was invoked improperly.; For usage information, try salmon index --help; ````. **To Reproduce**; Steps and data to reproduce the behavior:. `salmon index -t input.fa -i input.index`. Specifically, please provide at least the following information:. * Which version of salmon was used? - 1.10.1; * How was salmon installed (compiled, downloaded executable, through bioconda)? - biconda; * Which reference (e.g. transcriptome) was used? - metagenome; * Which read files were used? ; * Which which program options were used?. **Expected behavior**; A clear and concise description of what you expected to happen. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX] Linux- HPC; - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux the output of `uname -a` and `lsb_release -a`]. Thanks.; Ugur",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/837:6287,clear,clear,6287,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/837,1,['clear'],['clear']
Usability,"ellranger to aggregate the counts and it looks like the following:; * As I was saying earlier aggregation step was happening downstream of count/quantification of the gene count matrix, at least in cellranger pipeline.; > When doing large studies involving multiple biological samples (or multiple libraries or replicates of the same sample), it is best to run cellranger count on each of the libraries individually, and then pool the results using cellranger aggr. * It looks like they have three different modes to normalize the libraries; > There are three normalization modes:; mapped: (default) Subsample reads from higher-depth libraries until they all have an equal number of confidently mapped reads per cell.; raw: Subsample reads from higher-depth libraries until they all have an equal number of total (i.e. raw, mapping-independent) reads per cell.; none: Do not normalize at all. * Although it's not clear, what do they mean by `equal number of confidently mapped reads per cell`, does it mean median reads per cell ? Like you tried to show in the above plot the distribution can be very uneven. But the part that troubles me more is once `count` information has been generated it has lost the read level information, since we have deduplicated them, then how do they use the read counts to normalize. Unless that is dumped too, not clear. Quoting your text from above:; > Alternatively, could a subsampling covariate be added to the probabilistic quantification model of alevin. I think we can definitely work on correcting the subsampling bias in the probabilistic model of Alevin but we might need a little more understanding of what's going on with the cellranger and why your way of aggregation is not working as intended. Unfortunately, I think we have to dig deeper into the cellranger codebase to really understand that and if possible, might need some subset of the relevant data to replicate your issue and work on improving that. Also, I am wondering, what's your way of check",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/305#issuecomment-433453155:1312,clear,clear,1312,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/305#issuecomment-433453155,2,['clear'],['clear']
Usability,"ellular barcodes.; [2019-07-18 14:15:58.709] [alevinLog] [info] Done populating Z matrix; [2019-07-18 14:15:58.741] [alevinLog] [info] Total 56814 CB got sequence corrected; [2019-07-18 14:15:58.750] [alevinLog] [info] Done indexing Barcodes; [2019-07-18 14:15:58.750] [alevinLog] [info] Total Unique barcodes found: 687531; [2019-07-18 14:15:58.750] [alevinLog] [info] Used Barcodes except Whitelist: 44516; [2019-07-18 14:15:58.973] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify; [2019-07-18 14:15:58.973] [alevinLog] [info] parsing read library format; [2019-07-18 14:24:27.923] [alevinLog] [info] Starting optimizer; [2019-07-18 14:24:28.655] [alevinLog] [warning] 24 mitorna gene(s) does not have transcript in the reference; [2019-07-18 14:24:28.655] [alevinLog] [info] Total 13 usable mRna genes; [2019-07-18 14:24:28.656] [alevinLog] [warning] 558 ribosomal rna gene(s) does not have transcript in the reference; [2019-07-18 14:24:28.656] [alevinLog] [info] Total 0 usable rRna genes; [2019-07-18 14:30:09.475] [alevinLog] [info] Total 4282454.00 UMI after deduplicating.; [2019-07-18 14:30:09.475] [alevinLog] [info] Total 5378060 BiDirected Edges.; [2019-07-18 14:30:09.475] [alevinLog] [info] Total 958944 UniDirected Edges.; [2019-07-18 14:30:09.475] [alevinLog] [warning] Skipped 28272 barcodes due to No mapped read; [2019-07-18 14:30:09.552] [alevinLog] [info] Finished optimizer; ```. ## R code (How to Use alevin with Seurat). ```; > library(here); > library(tidyverse); > library(Seurat); > library(tximport); > library(tictoc). > files <- file.path(here(""alevin_output/alevin/quants_mat.gz"")); > file.exists(files); [1] TRUE; >; > tic(""starts...""); > txi <- tximport(files, type=""alevin""; > toc(); starts...: 728.506 sec elapsed; > sessionInfo(); ```; R version 3.6.1 (2019-07-05); Platform: x86_64-conda_cos6-linux-gnu (64-bit); Running under: CentOS Linux 7 (Core). Matrix products: default; BLAS/LAPACK: /gpfs/data/software/anaconda3/envs/R3.6/lib/libopenb",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/404:2215,usab,usable,2215,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/404,1,['usab'],['usable']
Usability,"environment: failed with repodata from current_repodata.json, will retry with next repodata source.; Collecting package metadata (repodata.json): / Killed. this is the first time I've encountered an issue where something that is ""supposed"" to be there can't be found. Adam H. Freedman, PhD; Data Scientist; Faculty of Arts & Sciences Informatics Group; Harvard University; 38 Oxford St; Cambridge, MA 02138; phone: +001 310 415 7145; ________________________________; From: Rob Patro ***@***.***>; Sent: Sunday, October 29, 2023 10:01 AM; To: COMBINE-lab/salmon ***@***.***>; Cc: Freedman, Adam ***@***.***>; State change ***@***.***>; Subject: Re: [COMBINE-lab/salmon] anaconda version of salmon outdated, missing decoys option (Issue #895). I'm going to cc @dpryan79<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_dpryan79&d=DwMFaQ&c=WO-RGvefibhHBZq3fL85hQ&r=MITI_LEJgyr1a24IMFAlSaZIPxMpOUT21T7L3fg4CjA&m=mSC4skssR3kpqIDO5fXv00Vk9PrFQeVf0OH62EOgXZ9hbM31qjkaQra0z60JiEA_&s=hPsmfTmSAfiwDhS2JFQyD0EUHl5m5sbj_n46DYj6tdM&e=> on this — does it just not finish? It seems to work within our GitHub CI, where we have to grab the prebuilt salmon to test simpleaf. —; Reply to this email directly, view it on GitHub<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_COMBINE-2Dlab_salmon_issues_895-23issuecomment-2D1784122719&d=DwMFaQ&c=WO-RGvefibhHBZq3fL85hQ&r=MITI_LEJgyr1a24IMFAlSaZIPxMpOUT21T7L3fg4CjA&m=mSC4skssR3kpqIDO5fXv00Vk9PrFQeVf0OH62EOgXZ9hbM31qjkaQra0z60JiEA_&s=6Y-rQOzzAA-t9QV8NyfcMVeySD2an4xeN1HsDqa6VpQ&e=>, or unsubscribe<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_notifications_unsubscribe-2Dauth_ADBMMUDFRQIHN4AMNBHWCN3YBZOUTAVCNFSM6AAAAAA6UYYPGOVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTOOBUGEZDENZRHE&d=DwMFaQ&c=WO-RGvefibhHBZq3fL85hQ&r=MITI_LEJgyr1a24IMFAlSaZIPxMpOUT21T7L3fg4CjA&m=mSC4skssR3kpqIDO5fXv00Vk9PrFQeVf0OH62EOgXZ9hbM31qjkaQra0z60JiEA_&s=ckSFRx1FekMV-wL0KtdZFPdtgCB1DiAziHIsdrF0cKQ&e=>.; You are receiving this because you mo",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/895#issuecomment-1784126021:1425,simpl,simpleaf,1425,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/895#issuecomment-1784126021,2,['simpl'],['simpleaf']
Usability,"er,; s2 = as.vector(gencode[[x]]) %>% as.character; ). out2 <- reshape2::melt(out2) %>% as.data.table; colnames(out2) <- c('myFasta', 'GencodeMatureFasta', 'seqMatch'); out2[ , myFastaSeqType := 'premature']. # my premature complement vs gencode mature; out3 <- smoothDot(; s1 = as.vector(premature.tx[[x]] %>% complement) %>% as.character,; s2 = as.vector(gencode[[x]]) %>% as.character; ). out3 <- reshape2::melt(out3) %>% as.data.table; colnames(out3) <- c('myFasta', 'GencodeMatureFasta', 'seqMatch'); out3[ , myFastaSeqType := 'premature (complement)']. out <- rbind(out1, out2, out3); out[ , tx_strand := strand(anot[which(anot$transcript_id == x)[1], ]) %>% as.character]. return(out); }; ) %>% rbindlist(., idcol = 'tx_id'). # pdf(dotPlot.fname, width = 8, height = 6). ggp <- ggplot(mapping = aes(x = myFasta, y = GencodeMatureFasta, fill = seqMatch), data = to.plot) +; geom_tile(width = 1, height = 1) +; scale_fill_manual(; values = c('TRUE' = 'black', 'FALSE' = 'white'),; guide = F; ) + scale_x_continuous(; expand = c(0, 0); ) + scale_y_continuous(; expand = c(0, 0); ) +; theme_bw(base_size = 10) +; theme(; panel.grid = element_blank(), panel.background = element_blank() # element_rect(fill = 'grey'); ) +; facet_wrap(paste('tx strand:', tx_strand) ~ paste('tx ID:', tx_id) + paste('myFasta seq type:', myFastaSeqType), ncol = 3, scales = 'free'). print(ggp). # dev.off(). ```. R session info:; ```; R version 4.0.2 (2020-06-22); Platform: x86_64-pc-linux-gnu (64-bit); Running under: CentOS Linux 7 (Core). Matrix products: default; BLAS/LAPACK: [hidden]/easybuild/software/2017/Core/imkl/2018.3.222/compilers_and_libraries_2018.3.222/linux/mkl/lib/intel64_lin/libmkl_gf_lp64.so. locale:; [1] LC_CTYPE=en_CA.UTF-8 LC_NUMERIC=C LC_TIME=en_CA.UTF-8 LC_COLLATE=en_CA.UTF-8 ; [5] LC_MONETARY=en_CA.UTF-8 LC_MESSAGES=en_CA.UTF-8 LC_PAPER=en_CA.UTF-8 LC_NAME=C ; [9] LC_ADDRESS=C LC_TELEPHONE=C LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C . attached base packages:; [1] parallel stats4",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191:10493,guid,guide,10493,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191,2,['guid'],['guide']
Usability,"file as input corresponding to the stringtie gtf file.; **To Reproduce**; Steps and data to reproduce the behavior:; Trasncript fasta file corres[onding to the stringtie generated gtf file used for salmon indexing with the following command.; `salmon index -t stringtie.fasta -i annotation_merged_index -p 20 -k 31`; THe index output used for salmon quantification with the following command; `salmon quant -i matchedtranscript_index/ -l ISR -1 ../../12_1_trimmed_R1.fastq -2 ../../12_1_trimmed_R2.fastq --gcBias --seqBias --posBias --dumpEqWeights -o salmon_output_rerun --writeMappings=salmon_output_rerun/mapping.sam -p 20`. Actual transcript IDs; ```; transcript	gene; 1 MSTRG.1.1	MSTRG.1; 2 MSTRG.1.2	MSTRG.1; 3 MSTRG.1.3	MSTRG.1; 4	BGIOSGA002578-TA	MSTRG.1; 5 MSTRG.1.5	MSTRG.1; 6 MSTRG.1.6	MSTRG.1; ```; Output quant.sf file:; ```; transcript count TPM; 1 BGIOSGA002568-TA 5692.000 5.840431; 2 MSTRG.3 1165.181 0.825116; 3 MSTRG.3 15240.169 10.700565; 4 MSTRG.3 5233.400 3.656954; 5 MSTRG.3 34.780 0.027226; 6 MSTRG.3 5219.345 3.916051; 7 MSTRG.3 4.277 0.003473; ```; Rscript used to read the quant.sf file. ```; library(dplyr); tmp <- read.delim(""quant.sf"", header = TRUE, as.is = TRUE); idx <- grep(""^STRG\\.|^CHS\\."", tmp$Name, invert = TRUE); tmp$Name[idx] <- gsub(""\\.[0-9]+$"", """", tmp$Name[idx]); tmp %>% dplyr::rename(transcript = Name, count = NumReads) %>%; dplyr::select(transcript, count, TPM); ```. Specifically, please provide at least the following information:. * Which version of salmon was used?; v0.14.0; * How was salmon installed (compiled, downloaded executable, through bioconda)?; bioconda; * Which reference (e.g. transcriptome) was used?; transcriptome; * Which read files were used?; paired-end illumina read files. **Expected behavior**; A clear and concise description of what you expected to happen.; Expected to retrieve the full name of transcript IDs. **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX]; Cluster with centOS",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/427:1982,clear,clear,1982,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/427,1,['clear'],['clear']
Usability,"g] [info] Done loading index; [2019-01-29 15:49:56.077] [jointLog] [info] done; [2019-01-29 15:49:56.077] [jointLog] [info] Index contained 58,086 targets; processed 287 Million fragments; hits: 152080339, hits per frag: 0.529087. [2019-01-29 16:05:46.677] [jointLog] [info] Computed 58,128 rich equivalence classes for further processing; [2019-01-29 16:05:46.677] [jointLog] [info] Counted 58,047,553 total reads in the equivalence classes; [2019-01-29 16:05:46.678] [jointLog] [warning] Found 21006 reads with `N` in the UMI sequence and ignored the reads.; Please report on github if this number is too large; [2019-01-29 16:05:46.678] [jointLog] [info] Mapping rate = 20.1566%. [2019-01-29 16:05:46.678] [jointLog] [info] finished quantifyLibrary(); [2019-01-29 16:05:51.316] [alevinLog] [info] Starting optimizer. **Analyzed 4000 cells (100% of all).**; [2019-01-29 16:06:27.447] [alevinLog] [info] Total 20167967.00 UMI after deduplicating.; [2019-01-29 16:06:27.475] [alevinLog] [info] Clearing EqMap; Might take some time.; [2019-01-29 16:06:39.341] [alevinLog] [info] Starting Import of the gene count matrix of size 4000x29574.; [2019-01-29 16:06:40.089] [alevinLog] [info] Done initializing the empty matrix.; [2019-01-29 16:06:45.902] [alevinLog] [info] Done Importing gene count matrix for dimension 4000x29574; 0.00248159 1.3538e-06 0.000205983 221334; 0.00714905 1.09739e-06 0.000617623 71036.5; [2019-01-29 16:06:46.603] [alevinLog] [info] Starting white listing; [2019-01-29 16:06:46.615] [alevinLog] [info] Done importing order of barcodes ""quants_mat_rows.txt"" file.; [2019-01-29 16:06:46.615] [alevinLog] [info] Total 4000 barcodes found; [2019-01-29 16:06:46.615] [alevinLog] [warning] mrna file not provided; using is 1 less feature for whitelisting; [2019-01-29 16:06:46.615] [alevinLog] [warning] rrna file not provided; using is 1 less feature for whitelisting; [2019-01-29 16:06:46.615] [alevinLog] [info] Starting to make feature Matrix; [2019-01-29 16:06:46.790] [alevinLo",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/340:2879,Clear,Clearing,2879,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/340,1,['Clear'],['Clearing']
Usability,"ge of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; [2018-12-06 11:14:56.533] [jointLog] [info] Usage of --validateMappings implies use of range factorization. rangeFactorizationBins is being set to 4; [2018-12-06 11:14:56.534] [jointLog] [info] Usage of --validateMappings implies a default consensus slack of 1. Setting consensusSlack to 1.; [2018-12-06 11:14:56.534] [jointLog] [info] Using default value of 0.8 for minScoreFraction in Alevin; [2018-12-06 11:14:56.540] [alevinLog] [info] Processing barcodes files (if Present) . ; processed 267 Million barcodes. [2018-12-06 11:16:47.491] [alevinLog] [info] Done barcode density calculation.; [2018-12-06 11:16:47.491] [alevinLog] [info] # Barcodes Used: 267451749 / 267548197.; [2018-12-06 11:16:52.732] [alevinLog] [info] Knee found left boundary at 11955 ; [2018-12-06 11:16:54.977] [alevinLog] [info] Gauss Corrected Boundary at 4345 ; [2018-12-06 11:16:54.977] [alevinLog] [info] Learned InvCov: 713.683 normfactor: 1183.93; [2018-12-06 11:16:54.985] [alevinLog] [info] Total 31.0106% reads will be thrown away because of noisy Cellular barcodes.; [2018-12-06 11:16:54.985] [alevinLog] [info] Total 5344(has 999 low confidence) barcodes; [2018-12-06 11:16:55.059] [alevinLog] [info] Done True Barcode Sampling; [2018-12-06 11:16:55.395] [alevinLog] [info] Done populating Z matrix; [2018-12-06 11:16:55.453] [alevinLog] [info] Done indexing Barcodes; [2018-12-06 11:16:55.453] [alevinLog] [info] Total Unique barcodes found: 4180559; [2018-12-06 11:16:55.453] [alevinLog] [info] Used Barcodes except Whitelist: 134856; [2018-12-06 11:16:56.218] [jointLog] [info] There are 2 libraries.; [2018-12-06 11:16:56.292] [jointLog] [info] Loading Quasi index; [2018-12-06 11:16:56.294] [jointLog] [info] Loading 32-bit quasi index; [2018-12-06 11:16:56.205] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2018-12-06 11:16:56.218] [alevinLog] [info] parsing read l",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-445008548:5296,Learn,Learned,5296,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-445008548,1,['Learn'],['Learned']
Usability,gram ] => salmon ; ### [ command ] => alevin ; ### [ libType ] => { ISR }; ### [ mates1 ] => { hgmm_100_S1_L001_001.fastq.1.gz }; ### [ mates2 ] => { hgmm_100_S1_L001_001.fastq.2.gz }; ### [ chromium ] => { }; ### [ index ] => { geneset.dir/geneset_coding_exons.salmon.index/ }; ### [ output ] => { salmon.dir/ }; ### [ tgMap ] => { transcript2geneMap.tsv }; ### [ dumpCsvCounts ] => { }. [2019-01-29 09:54:57.898] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-01-29 09:54:57.916] [alevinLog] [info] Processing barcodes files (if Present) . ; processed 0 Million barcodes. [2019-01-29 09:54:59.693] [alevinLog] [info] Done barcode density calculation.; [2019-01-29 09:54:59.693] [alevinLog] [info] # Barcodes Used: 902561 / 912145.; [2019-01-29 09:55:04.490] [alevinLog] [info] Knee found left boundary at 391 ; [2019-01-29 09:55:04.817] [alevinLog] [info] Gauss Corrected Boundary at 99 ; [2019-01-29 09:55:04.817] [alevinLog] [info] Learned InvCov: 114.535 normfactor: 147.323; [2019-01-29 09:55:04.817] [alevinLog] [info] Total 289(has 190 low confidence) barcodes; [2019-01-29 09:55:04.822] [alevinLog] [info] Done True Barcode Sampling; [2019-01-29 09:55:04.855] [alevinLog] [info] Done populating Z matrix; [2019-01-29 09:55:04.855] [alevinLog] [info] Done indexing Barcodes; [2019-01-29 09:55:04.855] [alevinLog] [info] Total Unique barcodes found: 70316; [2019-01-29 09:55:04.855] [alevinLog] [info] Used Barcodes except Whitelist: 184; [2019-01-29 09:55:04.882] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2019-01-29 09:55:04.882] [alevinLog] [info] parsing read library format; [2019-01-29 09:55:05.014] [stderrLog] [info] Loading Suffix Array ; [2019-01-29 09:55:04.882] [jointLog] [info] There is 1 library.; [2019-01-29 09:55:05.012] [jointLog] [info] Loading Quasi index; [2019-01-29 09:55:05.013] [jointLog] [info] Loading 32-bit quasi index; [2019-01-29 09:55:06.105] [stderrLog] [info] Load,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722:2023,Learn,Learned,2023,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722,1,['Learn'],['Learned']
Usability,"h_sd: 25.001769513739427. Sample: Gam_3h_RT_rep2_RL5404_quant; frag_length_mean: 250.0000097391447; frag_length_sd: 25.001769513739427. Sample: Gam_3h_RT_rep3_RL5405_quant; frag_length_mean: 250.0000097391447; frag_length_sd: 25.001769513739427. Sample: Gam_6h_37C_rep1_RL5390_quant; frag_length_mean: 250.0000097391447; frag_length_sd: 25.001769513739427. Sample: Gam_6h_37C_rep2_RL5391_quant; frag_length_mean: 250.0000097391447; frag_length_sd: 25.001769513739427. Sample: Gam_6h_37C_rep3_RL5410_quant; frag_length_mean: 250.0000097391447; frag_length_sd: 25.001769513739427. Sample: Gam_6h_4C_rep1_RL5392_quant; frag_length_mean: 250.0000097391447; frag_length_sd: 25.001769513739427. Sample: Gam_6h_4C_rep2_RL5393_quant; frag_length_mean: 250.0000097391447; frag_length_sd: 25.001769513739427. Sample: Gam_6h_4C_rep3_RL5411_quant; frag_length_mean: 250.0000097391447; frag_length_sd: 25.001769513739427. Sample: Gam_6h_RT_rep1_RL5389_quant; frag_length_mean: 250.0000097391447; frag_length_sd: 25.001769513739427. Sample: Gam_6h_RT_rep2_RL5408_quant; frag_length_mean: 250.0000097391447; frag_length_sd: 25.001769513739427. Sample: Gam_6h_RT_rep3_RL5409_quant; frag_length_mean: 250.0000097391447; frag_length_sd: 25.001769513739427```. **To Reproduce**; Steps and data to reproduce the behavior:. Specifically, please provide at least the following information:. * Which version of salmon was used?; v1.10.0; * How was salmon installed (compiled, downloaded executable, through bioconda)?; Binary; * Which reference (e.g. transcriptome) was used?; Moss (Physco) v6.1 that I had generated ; * Which read files were used?; ; * Which which program options were used?; `-l A -p 16 --validateMappings --numBootstraps 100 --seqBias --gcBias`. **Expected behavior**; A clear and concise description of what you expected to happen. **Desktop (please complete the following information):**; - OS: Linux server: Rocky Linux release 8.5 (Green Obsidian); - Version Rocky Linux release 8.5 (Green Obsidian)",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/948:3359,clear,clear,3359,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/948,1,['clear'],['clear']
Usability,"he transcripts. The first used BAM files where shuffled (with samtools bamshuf) as recommended in the docs. To exclude an error on my side I did:; - try unshuffled BAM files --> Segfault; - try older Salmon Version (7.2) --> Segfault; - build Salmon from source --> Segfault; - use different transcriptdata (see below) --> Segfault. The segfault happens after all reads (in all files) are processed:; `processed 48000000 reads in current roundSegmentation fault`. ### Example workflow:. Get the read data from [here](https://trace.ncbi.nlm.nih.gov/Traces/sra/sra.cgi?run=ERR1433122) for example with SRA Toolkit:; `vdb-dump -f fastq --gzip --output-file test.fastq.gz ERR1433122`. Then use STAR:. First build a genome index for the reference transcriptset from [here](https://ics.hutton.ac.uk/atRTD/) and the [TAIR10 genome](https://www.arabidopsis.org/download/index-auto.jsp?dir=%2Fdownload_files%2FGenes%2FTAIR10_genome_release%2FTAIR10_chromosome_files); You probably have to rename the chromosomes either in the .gtf or .fas file, to have consistent names. `STAR --runThreadN 4 --runMode genomeGenerate --genomeDir genome_index/ --genomeFastaFiles TAIR10_chr_all_edited.fas --sjdbGTFfile AtRTD2_19April2016.gtf --sjdbOverhang 100`. Then map:. `STAR --runThreadN 4 --genomeDir genome_index --readFilesCommand zcat --readFilesIn test.fastq.gz --sjdbOverhang 100 --sjdbGTFfile AtRTD2_19April2016.gtf --outFileNamePrefix mapping/ --quantMode TranscriptomeSAM`. and make a .fa file from the genome and the .gtf with:; `gffread -w gff_merged.fa -g TAIR10_chr_all_edited.fas AtRTD2_19April2016.gtf`. Now make a copy of the ""Aligned.toTranscriptome.out.bam"" (for the sake of simplicity) and try; `salmon quant -l A -a Aligned.toTranscriptome.out.bam Aligned.toTranscriptome.out_copy.bam -t gff_merged.fa -o ./out/`. Then the above mentioned segfault happens. The only workaround I found is to merge the BAM files of the replicates with ""samtools merge"". Any idea why the segfault appears?. Cheers,; Tobi",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/145:1893,simpl,simplicity,1893,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/145,1,['simpl'],['simplicity']
Usability,"here, for instance. What do the flags and qualities represent?. It is just a SAM file without CIGAR strings. The flags have the same (normal) interpretation for SAM records. However the CIGAR strings are not meaningful (apart from what is required for the file to undergo valid processing with samtools). The records additionally contain tags about the number of targets to which a fragment multi-maps, and the alignment score of the read pair to the current target (in the `AS` flag). The records themself are just normal SAM records, but with a trivial CIGAR strong. > More importantly, is there a way to filter the pseudobam files to find the reads corresponding to the counts/NumReads in the quant.sf output file? Do the normal samtools quality and flag filters work to subset e.g. uniquely-mapped reads, or do those concepts not really apply to these pseudobams?. There is no easy way to filter so the above condition is satisfied, as the NumReads are obtained by proportional allocation of the reads according to the underlying probabilistic model of salmon. Specifically, the NumReads column of the quantification file corresponds to summing over the _expectation_ of all of the latent variables that represent fragment to transcript assignment so that, apart from uniquely-mapped reads, there is no way to say that a fragment _definitely_ came from a transcript. However, you should still be able to easily filter out uniquely mapped reads, and you can interpret them in a relatively unambiguous way. Also, you could filter on the `AS` tag as well. For a given read, if there is a single transcript where the `AS` value is much larger than the others for this read, it is overwhelmingly likely that the read originated from the transcript with the unique best `AS` score. @shangguandong1996 : The SAM file _does_ contain positions (and orientations, and alignment scores) for each read. It is simply that the positions are with respect to the transcriptome and not with respect to the genome.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/528#issuecomment-639065653:3146,simpl,simply,3146,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/528#issuecomment-639065653,2,['simpl'],['simply']
Usability,"how the data are processed that is worth being aware of before you write such samples off. * There is a change in default behavior between salmon < 0.13 and >= 0.13 with which mappings are considered as ""concordant"" and therefore used for quantification by default. Specifically, starting with 0.14, ""dovetail"" alignments [(as described in the Bowtie2 manual)](http://bowtie-bio.sourceforge.net/bowtie2/manual.shtml#bowtie2-options-dovetail) are considered discordant. This is the same default behavior imposed by Bowtie2. If you look in the `meta_info.json` file for some of these samples (which is in the `aux_info` subdirectory of the quantification directory for a sample), you can see how many mappings are being discarded by virtue of being dovetail mappings. It is possible to allow such alignments (consider them as concordant) by passing the `--allowDovetail` flag. It is not the case that such alignments are always ""bad"", its simply that one would not expect many fragments to align in such a way, and if these constitute the overwhelming majority of the mappings, one might be suspicious about the underlying data. * Selective alignment actually _aligns_ the reads to the transcriptome. For this purpose, it performs end-to-end alignment. This means that if you suspect that the sample may contain adapters or very low-quality read ends, the reads should be trimmed prior to quantification. It is, therefore, worth checking how the mapping rate changes for some of these samples if the reads are trimmed first. * Selective alignment is more robust than quasi-mapping to the chosen value of `-k`, the minimum match length used when searching for alignments. I noticed that some of the samples contain relatively short reads, so you might see if the mapping rate changes if you adopt a smaller value of `-k` in the index (e.g. we use `23` in the [pre-print](https://www.biorxiv.org/content/10.1101/657874v2.full.pdf)). * You mention that this index doesn't contain any decoy sequence. This ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/482#issuecomment-582734798:2407,simpl,simply,2407,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/482#issuecomment-582734798,2,['simpl'],['simply']
Usability,i-TTCGTGAA_lane-001-chunk-001.fastq.gz read-I1_si-TTCGTGAA_lane-002-chunk-000.fastq.gz read-I1_si-TTCGTGAA_lane-003-chunk-003.fastq.gz read-I1_si-TTCGTGAA_lane-004-chunk-002.fastq.gz }. [2018-09-11 16:28:53.158] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2018-09-11 16:28:53.158] [jointLog] [warning] You seem to have passed in both un-paired reads and paired-end reads. It is not currently possible to quantify hybrid library types in salmon.; [2018-09-11 16:28:53.164] [alevinLog] [info] Processing barcodes files (if Present) . ; processed 535 Million barcodes. [2018-09-11 16:33:49.759] [alevinLog] [info] Done barcode density calculation.; [2018-09-11 16:33:49.759] [alevinLog] [info] # Barcodes Used: 534903498 / 535096394.; [2018-09-11 16:33:55.869] [alevinLog] [info] Knee found left boundary at 11740 ; [2018-09-11 16:33:59.242] [alevinLog] [info] Gauss Corrected Boundary at 4345 ; [2018-09-11 16:33:59.242] [alevinLog] [info] Learned InvCov: 713.683 normfactor: 1183.93; [2018-09-11 16:33:59.242] [alevinLog] [info] Total 5344(has 999 low confidence) barcodes; [2018-09-11 16:33:59.358] [alevinLog] [info] Done True Barcode Sampling; [2018-09-11 16:33:59.891] [alevinLog] [info] Done populating Z matrix; [2018-09-11 16:33:59.972] [alevinLog] [info] Done indexing Barcodes; [2018-09-11 16:33:59.972] [alevinLog] [info] Total Unique barcodes found: 4180559; [2018-09-11 16:33:59.972] [alevinLog] [info] Used Barcodes except Whitelist: 173007; [2018-09-11 16:34:00.783] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2018-09-11 16:34:00.784] [alevinLog] [info] parsing read library format; [2018-09-11 16:34:00.784] [jointLog] [info] There are 2 libraries.; [2018-09-11 16:34:00.868] [jointLog] [info] Loading Quasi index; [2018-09-11 16:34:00.876] [jointLog] [info] Loading 32-bit quasi index; [2018-09-11 16:34:00.876] [stderrLog] [info] Loading Suffix Array ; [2018-09-11 16:34:18.777] [stderrLog] [i,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/294:10179,Learn,Learned,10179,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/294,1,['Learn'],['Learned']
Usability,"ias in the current salmon version, but if I run all the models together like --gcBias --seqBias --posBias, it completes fine. ~~Do you have a small example (ref / read pair) that reproduces this? It would be great to figure out why and fix it. We could split that into a new issue if you'd rather.~~. P.S. Nevermind; thanks to you mentioning this, I was able to track it down and fix it in develop!. > As I understand the selective alignment, the alignment scores are passed to the quantification step, but the position of the reads is not used downstream. . Well, yes and no. We make extensive use of the position when estimate the implied fragment length (distance between paired end reads) and then model the conditional probability of this fragment based on the global fragment length distribution. This is just as much as is done by e.g. RSEM. However, you are right that there is no notion of using the coverage profile in estimation (more on this below)!. > Also, my intuition for these transcripts is not really a coverage ""bias"" . My intuition agrees with yours here completely. First, this isn't really a coverage bias as we use the normal definition of the term. Second, the positional bias modeling in salmon is not on a per-transcript level (since that would be an astronomical number of different parameters to learn, and any procedure would almost certainly overfit). Instead, it groups transcripts into length bins, and learns a distinct coverage bias model per-bin. > It would be neat if Salmon could detect these kinds of dramatic dropoffs and add a warning or something... even if not incorporating the information into the quants... it could even be a good QC step to identify large deletions/insertions over a gene body. As far as I know, there are NO rnaseq quant programs that would handle this, because even something like a STAR -> RSEM pipeline just projects read counts to the transcriptome and doesn't incorporate the coverage information. These are **great** points! A cou",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623047035:1113,intuit,intuition,1113,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623047035,2,['intuit'],['intuition']
Usability,"ile. First, I've been using salmon for years and I love all the updates that have come about recently. The new selective alignment mode is an amazing upgrade!. My general question here is how to quantify various truncated isoforms of the same transcript. I'm working in S. cerevisiae and I am not referring to isoform switching via alternative splicing, but various isoforms that are fully contained as a subset of a larger transcript sequence. Imagine a standard gene that gives rise to a 1000 bp transcript. Through alternative promoter usage or post-transcriptional processing, it can give rise a truncated form that is identical to the parent transcript, except only has sequence from bases 400 to 1000. I know this scenario is similar to detecting differential splice forms, and indeed when I see overlapping genes that nonetheless have some unique sequence, salmon does an excellent job at fractionally apportioning the reads. In this particular case, however, it seems that because all mappings to the truncated isoform also give perfect mappings to the longer isoform, even a single few reads mapping uniquely to the longer isoform is enough evidence for the salmon EM algorithm (I assume that's the relevant part?) to give *all* of the reads to the long isoform. To visualize the problem, I'm attaching an image of alignments over a transcript that is only expressed as a portion of the annotated parent transcript. If i encode the short and long forms as separate transcripts in salmon fasta index, all of the reads get assigned to the longer form with the options I've tried. My question then is whether there's a combination of salmon quant options that would optimize apportioning the reads better for this class of transcript, or whether it's simply not going to work given the underlying assumptions in the software?. Thanks a ton for any help,; Jason. ![hmlalpha2_truncated_example](https://user-images.githubusercontent.com/10292386/80483743-6c217900-890b-11ea-8469-4883914d8ec0.png)",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514:1896,simpl,simply,1896,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514,1,['simpl'],['simply']
Usability,in ; ### [ libType ] => { A }; ### [ mates1 ] => { data/mSpT3_S2_L001_R1_001.fastq data/mSpT3_S2_L002_R1_001.fastq }; ### [ mates2 ] => { data/mSpT3_S2_L001_R2_001.fastq data/mSpT3_S2_L002_R2_001.fastq }; ### [ dropseq ] => { }; ### [ threads ] => { 10 }; ### [ output ] => { mSpT3 }; ### [ index ] => { mouse_cdna }; ### [ tgMap ] => { biomart.csv }. [2018-08-29 11:26:45.317] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2018-08-29 11:26:45.325] [alevinLog] [info] Processing barcodes files (if Present) . ; processed 18 Million barcodes. [2018-08-29 11:28:11.683] [alevinLog] [info] Done barcode density calculation.; [2018-08-29 11:28:11.683] [alevinLog] [info] # Barcodes Used: 18693290 / 18712858.; [2018-08-29 11:28:17.405] [alevinLog] [info] Knee found left boundary at 2385 ; [2018-08-29 11:28:19.290] [alevinLog] [warning] Gauss Prediction 0 Too far from knee prediction skipping it; [2018-08-29 11:28:19.290] [alevinLog] [info] Learned InvCov: 568.346 normfactor: 688.271; [2018-08-29 11:28:19.290] [alevinLog] [info] Total 3385(has 1000 low confidence) barcodes; [2018-08-29 11:28:19.297] [alevinLog] [info] Done True Barcode Sampling; [2018-08-29 11:28:19.433] [alevinLog] [info] Done populating Z matrix; [2018-08-29 11:28:19.437] [alevinLog] [info] Done indexing Barcodes; [2018-08-29 11:28:19.437] [alevinLog] [info] Total Unique barcodes found: 215368; [2018-08-29 11:28:19.437] [alevinLog] [info] Used Barcodes except Whitelist: 8563; [2018-08-29 11:28:19.464] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2018-08-29 11:28:19.477] [alevinLog] [info] parsing read library format; [2018-08-29 11:28:19.477] [jointLog] [info] There is 1 library.; [2018-08-29 11:28:27.306] [stderrLog] [info] Loading Suffix Array ; [2018-08-29 11:28:27.290] [jointLog] [info] Loading Quasi index; [2018-08-29 11:28:27.304] [jointLog] [info] Loading 32-bit quasi index; [2018-08-29 11:29:47.334] [stderrLog] [info] ,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/281:2501,Learn,Learned,2501,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/281,1,['Learn'],['Learned']
Usability,"ion](https://github.com/Kingsford-Group/sad) (paper [here](https://www.cell.com/cell-systems/pdf/S2405-4712(19)30381-3.pdf)). This is sort of akin to what you are suggesting, and post-processes salmon output by looking for anomalous coverage profiles. It can both flag ""suspicious"" transcripts, and can also sometimes move reads around to mitigate anomalous coverage. Another tool / metric you might consider is the junction coverage compatibility (paper [here](https://www.life-science-alliance.org/content/2/1/e201800175)). While both of these approaches get at some of the core intuitions you raise in your response, they are both rather ""heavyweight"", and neither, of course, is built into salmon. So, I **completely agree** that a lightweight version of something like SAD would be great to have built _into_ salmon. Specifically, it makes a lot of sense to have some component of the likelihood account for the coverage profile of transcripts. While I don't know of any widely-used and actively maintained quantification tools that do this, the idea for this was proposed in the [iReckon paper](https://www.ncbi.nlm.nih.gov/pubmed/23204306) and a coverage-based heuristic was introduced. However, the coverage was not directly incorporated into the likelihood. Rather, a variant of the normal likelihood function was used and then coverage was used to select between different potential solutions that were otherwise of similar likelihood. Given issues like the one you see here, and the ones that we observed in the JCC paper and that Cong and Carl observed in the SAD paper, it seems clear that it would be a big win for a quantification tool to include some sort of built-in lightweight model for things like this. The big questions are (1) how do you fold this type of intuition formally into the probabilistic model and (2) is it possible to incorporate this information efficiently? I'm _very_ interested in pursuing something like this if it can be made to work efficiently. Thanks!; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623047035:3922,clear,clear,3922,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623047035,4,"['clear', 'intuit']","['clear', 'intuition']"
Usability,"ions); message(""Boost_FOUND = ${Boost_FOUND}""); endif(); ; EOD; patch -p0 <mypatch; module load cmake; module load io_lib; module load libgff; module load libtbb; # module load pufferfish #ignored even if set; mkdir build; cd build; cmake \; -DCMAKE_INSTALL_PREFIX=$TOPDIR \; -DSTADEN_ROOT=$ROOT_IO_LIB \; -DGFF_ROOT=$ROOT_LIBGFF \; -DTBB_ROOT=$ROOT_LIBTBB \; -DCMAKE_VERBOSE_MAKEFILE:BOOL=ON \; -DBOOST_LIBRARYDIR=/usr/lib64/boost169 \; -DBOOST_INCLUDEDIR=/usr/include/boost169 \; -DBoost_NO_SYSTEM_PATHS=ON \; .. 2>&1 | tee cmake_2020_06_23.log; make -j 4 2>&1 | tee build_2020_06_23.log; make test # both passed; make install 2>&1 | tee install_2020_06_23.log; cd ..; cp sample_data.tgz $TOPDIR; module_generate_from_directory.sh \; $package \; $pversion \; CentOS/vanilla \; $TOPDIR \; ""Fast highly-accurate, transcript-level quantification estimates from RNA-seq data."" \; ""https://github.com/COMBINE-lab/salmon""; ```. When the following commands are run in an XFCE4 terminal or an uxterm (black text, white background) using the sample data provided in the distribution:. ```; gunzip -c sample_data.tgz | (cd /tmp; tar -xf -); module load salmon; cd /tmp/sample_data; salmon index -t transcripts.fasta -i sample_salmon_fmd_index --type puff; salmon quant -i sample_salmon_fmd_index \; -l IU \; -1 reads_1.fastq -2 reads_2.fastq \; -o sample_salmon_fmd_quant. ```; the output line:. ```; [2020-06-23 13:58:50.657] [jointLog] [warning] Only 10000 fragments were mapped, but the number of burn-in fragments was set to 5000000.; The effective lengths have been computed using the observed mappings.; ```. is emitted in yellow. Yellow on white is nearly impossible to read. The rest of the text is black (as it should be). If the final command is instead:. ```; salmon quant -i sample_salmon_fmd_index \; -l IU \; -1 reads_1.fastq -2 reads_2.fastq \; -o sample_salmon_fmd_quant >/tmp/sq.log 2>&1. ```. There are no embedded control codes in the sq.log file. Changing the terminal to white text on bl",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/541:2046,ux,uxterm,2046,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/541,1,['ux'],['uxterm']
Usability,"it's not clear if the right fix is to pin the boost version [here](https://github.com/bioconda/bioconda-recipes/blob/master/recipes/salmon/meta.yaml), or just to go with the ""always use conda-forge on installs"" strategy in the documentation. I will consult with experts.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/480#issuecomment-579829090:9,clear,clear,9,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/480#issuecomment-579829090,2,['clear'],['clear']
Usability,"jointLog] [info] Loading Quasi index; [2018-12-06 11:16:56.294] [jointLog] [info] Loading 32-bit quasi index; [2018-12-06 11:16:56.205] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2018-12-06 11:16:56.218] [alevinLog] [info] parsing read library format; [2018-12-06 11:16:56.296] [stderrLog] [info] Loading Suffix Array ; [2018-12-06 11:16:56.846] [stderrLog] [info] Loading Transcript Info ; [2018-12-06 11:16:57.009] [stderrLog] [info] Loading Rank-Select Bit Array; [2018-12-06 11:16:57.046] [stderrLog] [info] There were 167,268 set bits in the bit array; [2018-12-06 11:16:57.063] [stderrLog] [info] Computing transcript lengths; [2018-12-06 11:16:57.064] [stderrLog] [info] Waiting to finish loading hash; [2018-12-06 11:17:00.929] [jointLog] [info] done; [2018-12-06 11:17:00.929] [jointLog] [info] Index contained 167,268 targets. processed 267 Million fragmentsrrLog] [info] Done loading index; hits: 844899161, hits per frag: 3.15864^[[D. [2018-12-06 11:45:12.188] [jointLog] [info] Computed 118,295 rich equivalence classes for further processing; [2018-12-06 11:45:12.188] [jointLog] [info] Counted 154,595,094 total reads in the equivalence classes ; [2018-12-06 11:45:12.188] [jointLog] [warning] Found 115077 reads with `N` in the UMI sequence and ignored the reads.; Please report on github if this number is too large; [2018-12-06 11:45:12.188] [jointLog] [info] Mapping rate = 57.7821%. [2018-12-06 11:45:12.188] [jointLog] [info] finished quantifyLibrary(); [2018-12-06 11:45:13.385] [alevinLog] [info] Starting optimizer. Analyzed 5344 cells (100% of all).; [2018-12-06 11:49:42.634] [alevinLog] [info] Total 4845644.00 UMI after deduplicating.; [2018-12-06 11:49:42.722] [alevinLog] [info] Clearing EqMap; Might take some time.; [2018-12-06 11:49:47.400] [alevinLog] [info] Starting Import of the gene count matrix of size 5344x167268.; Exception : [std::bad_alloc]; alevin was invoked improperly.; For usage information, try alevin --help; Exiting.; ```",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-445008548:7766,Clear,Clearing,7766,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/328#issuecomment-445008548,1,['Clear'],['Clearing']
Usability,"l have neighboring genomic DNA). I wanted to see how this ratio changes between samples (for example, in a snoRNA processing-defective mutant strain), but quickly realized this is not easily done in salmon or any other quant tools because the processed transcript is entirely a subset of the sequence of the pre-processed transcript. The only way to accurately quantify it is to use the coverage information, which as you agreed is not really taken into account downstream. If Salmon could incorporate the coverage information to solve this class of problem, that would indeed be a **huge win**. I think the ncRNA example would be both a great biologically-interesting motivating problem, as well as a good technical benchmark for implementing any new methods. It could even be used as a secondary RNA velocity measure in scRNA seq data, provided the method used can detect these (non-polyadenylated) transcripts. > The big questions are (1) how do you fold this type of intuition formally into the probabilistic model and (2) is it possible to incorporate this information efficiently?. This is definitely your domain of expertise (and I know it's a rhetorical question but I'd love to throw some ideas out here)... I can think of a few mostly heuristical approaches.... . 1) when apportioning reads to transcripts, after the mapping phase, incorporate a notion of ""evenness"" into the EM step... reads that decrease the variance in coverage are favored over reads that increase the variance (so, define read depth per 10 bp window or something and calculate the variance across all windows for the transcript, then try to assign reads such that they minimize read depth variance per isoform). The problem here is actual coverage biases may then masquerade as alternative transcript isoforms... 2) Use the information from the unique sequences between the transcripts... the read depth over unique regions updates the prior on the overall transcript abundance, and the otherwise non-unique reads get ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623963851:2510,intuit,intuition,2510,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623963851,2,['intuit'],['intuition']
Usability,"l_whitelist"": 109,; ""low_conf_cbs"": 201,; ""num_features"": 0,; ""no_read_mapping_cbs"": 21,; ""final_num_cbs"": 288,; ""deduplicated_umis"": 46357,; ""mean_umis_per_cell"": 160,; ""mean_genes_per_cell"": 39; }. [2021-09-20 22:27:11.264] [alevinLog] [info] Found 5757 transcripts(+16 decoys, +8 short and +0 duplicate names in the index); [2021-09-20 22:27:11.271] [alevinLog] [info] Filled with 5765 txp to gene entries; [2021-09-20 22:27:11.272] [alevinLog] [info] Found all transcripts to gene mappings; [2021-09-20 22:27:11.282] [alevinLog] [info] Processing barcodes files (if Present). [2021-09-20 22:30:06.824] [alevinLog] [info] Done barcode density calculation.; [2021-09-20 22:30:06.824] [alevinLog] [info] # Barcodes Used: ESC[32m89886851ESC[0m / ESC[31m89886851ESC[0m.; [2021-09-20 22:30:09.717] [alevinLog] [info] Knee found left boundary at ESC[32m 1051 ESC[0m; [2021-09-20 22:30:11.442] [alevinLog] [info] Gauss Corrected Boundary at ESC[32m 109 ESC[0m; [2021-09-20 22:30:11.442] [alevinLog] [info] Learned InvCov: 796.079 normfactor: 896.047; [2021-09-20 22:30:11.442] [alevinLog] [info] Total ESC[32m310ESC[0m(has ESC[32m201ESC[0m low confidence) barcodes; [2021-09-20 22:30:12.167] [alevinLog] [info] Done True Barcode Sampling; [2021-09-20 22:30:12.316] [alevinLog] [warning] Total 55.6923% reads will be thrown away because of noisy Cellular barcodes.; [2021-09-20 22:30:12.333] [alevinLog] [info] Done populating Z matrix; [2021-09-20 22:30:12.334] [alevinLog] [info] Total 7602 CB got sequence corrected; [2021-09-20 22:30:12.334] [alevinLog] [info] Done indexing Barcodes; [2021-09-20 22:30:12.334] [alevinLog] [info] Total Unique barcodes found: 675135; [2021-09-20 22:30:12.334] [alevinLog] [info] Used Barcodes except Whitelist: 7515; [2021-09-20 22:30:13.043] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2021-09-20 22:30:13.044] [alevinLog] [info] parsing read library format; [2021-09-20 22:33:09.346] [alevinLog] [info] Starting optimizer. [2021-09-20 22:33",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/706:2986,Learn,Learned,2986,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/706,1,['Learn'],['Learned']
Usability,ld is just the GNU linker.; I still think it's not able to find the zlib **library** file since the error at `-lz` where `-l` gives the namespace of the library.; If you are confident about the inclusion of the `Zlib` then can you try clearing the cmake cache (i.e. remove the file CMakeCache.txt) and build again?,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/141#issuecomment-314430634:235,clear,clearing,235,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/141#issuecomment-314430634,2,['clear'],['clearing']
Usability,le-cell_skin_analysis//Data/Cheng-2018/CB_UMI//sample.fastq }; ### [ index ] => { /mnt/beegfs/alexmascension/STAR//hg38/salmon_index/ }; ### [ threads ] => { 40 }; ### [ output ] => { /mnt/beegfs/alexmascension/Projects/Single-cell_skin_analysis//Data/Cheng-2018//Alevin/sample }; ### [ end ] => { 5 }; ### [ barcodeLength ] => { 16 }; ### [ umiLength ] => { 10 }; ### [ dumpUmiGraph ] => { }; ### [ tgMap ] => { /mnt/beegfs/alexmascension/STAR//hg38/dict_transcript_gene.tsv }. [2019-06-23 18:08:02.553] [alevinLog] [info] Processing barcodes files (if Present) . ; processed 107 Million barcodes. [2019-06-23 18:11:30.689] [alevinLog] [info] Done barcode density calculation.; [2019-06-23 18:11:30.689] [alevinLog] [info] # Barcodes Used: 105189924 / 107347363.; [2019-06-23 18:11:34.706] [alevinLog] [info] Knee found left boundary at 184 ; [2019-06-23 18:11:52.364] [alevinLog] [warning] Gauss Prediction 13594 Too far from knee prediction skipping it; [2019-06-23 18:11:52.364] [alevinLog] [info] Learned InvCov: 254.933 normfactor: 13034.5; [2019-06-23 18:11:52.364] [alevinLog] [info] Total 384(has 200 low confidence) barcodes; [2019-06-23 18:11:52.383] [alevinLog] [info] Done True Barcode Sampling; [2019-06-23 18:11:52.489] [alevinLog] [warning] Total 91.1983% reads will be thrown away because of noisy Cellular barcodes.; [2019-06-23 18:11:52.507] [alevinLog] [info] Done populating Z matrix; [2019-06-23 18:11:52.507] [alevinLog] [info] Done indexing Barcodes; [2019-06-23 18:11:52.507] [alevinLog] [info] Total Unique barcodes found: 561683; [2019-06-23 18:11:52.507] [alevinLog] [info] Used Barcodes except Whitelist: 104; [2019-06-23 18:11:53.211] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2019-06-23 18:11:53.224] [alevinLog] [info] parsing read library format; [2019-06-23 18:11:53.484] [stderrLog] [info] Loading Suffix Array ; [2019-06-23 18:11:53.225] [jointLog] [info] There is 1 library.; [2019-06-23 18:11:53.482] [jointLog] [info] Loading Quasi i,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/386:4162,Learn,Learned,4162,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/386,1,['Learn'],['Learned']
Usability,"lmon tries to assign the reads as equally as possible to every duplicate transcript, but of course if we have for example 21 reads and 4 transcript, they will have respectively 5,5,5 and 6 reads, which can explain the small differences I see. ; Is it correct?; (anyway, in this way i can explain the first two genes which have respectively a read count of 3639 and 3631, but for the last two genes a difference of 32 reads sounds too big to me) . This can be a problem for me, since I belive that the issue of the duplicate transcripts derives from haplotypic genes, such as RPS18 which has more than one ENSG ID (i.e. ENSG00000226225 and ENSG00000231500). ENSG00000231500 is absent in the pipeline without the flag, while in the pipeline with the flag the expression level is ""splitted"" between the two genes (which are actually only one gene). both the results I obtain don't represent the ""reality"".; I'm afraid I will have to remove all the ""ambigous"" genes from the reference, keeping only the ones with the ""canonical"" ENSG ID; since I'm doing a ""pan-genes"" analysis, and the number of duplicate transcript is ~11,000, this can be painful...; Has anyone ever encountered a problem like this? Is someone using a reference transcriptome that is already ""clean"" from haplotypic genes? also, do the 11k duplicate genes derive only from haplytipic genes, or there are other strange biological things that I am not considering?. Last question (which is not about duplicate transcript but about tximport...tell me if it is off topic and i will ask elsewhere); For the gene ENSG00000231500.6, tximport reports an expression of 164.677488, while the sum of the TPM of the transcript of that gene is 163.659568 (a very small difference, but still a difference); I checked the tx2gene ""dictionary"" I used in tximport and it seems ok (i.e. there aren't other transcripts belonging to that gene).; Is this normal?. Hope everything is clear.; Thank you very much in advance, and sorry for the very long post.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/310:3914,clear,clear,3914,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/310,1,['clear'],['clear']
Usability,mc3k_fastqs/read-I1_si-GTTGCATG_lane-002-chunk-000.fastq.gz pbmc3k_fastqs/read-I1_si-TAAATCGT_lane-001-chunk-001.fastq.gz pbmc3k_fastqs/read-I1_si-TAAATCGT_lane-002-chunk-000.fastq.gz }. [2018-12-05 16:30:15.406] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2018-12-05 16:30:15.406] [jointLog] [warning] You seem to have passed in both un-paired reads and paired-end reads. It is not currently possible to quantify hybrid library types in salmon.; [2018-12-05 16:30:15.416] [alevinLog] [info] Processing barcodes files (if Present) . ; processed 185 Million barcodes. [2018-12-05 16:31:41.387] [alevinLog] [info] Done barcode density calculation.; [2018-12-05 16:31:41.387] [alevinLog] [info] # Barcodes Used: 185898660 / 185980783.; [2018-12-05 16:31:47.863] [alevinLog] [info] Knee found left boundary at 2926 ; [2018-12-05 16:31:50.571] [alevinLog] [info] Gauss Corrected Boundary at 2858 ; [2018-12-05 16:31:50.571] [alevinLog] [info] Learned InvCov: 166.8 normfactor: 2759.5; [2018-12-05 16:31:50.571] [alevinLog] [info] Total 3856(has 998 low confidence) barcodes; [2018-12-05 16:31:50.638] [alevinLog] [info] Done True Barcode Sampling; [2018-12-05 16:31:50.935] [alevinLog] [info] Done populating Z matrix; [2018-12-05 16:31:51.000] [alevinLog] [info] Done indexing Barcodes; [2018-12-05 16:31:51.000] [alevinLog] [info] Total Unique barcodes found: 3825581; [2018-12-05 16:31:51.000] [alevinLog] [info] Used Barcodes except Whitelist: 138266; [2018-12-05 16:31:51.087] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2018-12-05 16:31:51.087] [alevinLog] [info] parsing read library format; [2018-12-05 16:31:51.087] [jointLog] [info] There are 2 libraries.; [2018-12-05 16:31:51.161] [jointLog] [info] Loading Quasi index; [2018-12-05 16:31:51.162] [jointLog] [info] Loading 32-bit quasi index; [2018-12-05 16:31:51.164] [stderrLog] [info] Loading Suffix Array ; [2018-12-05 16:31:51.808] [stderrLog] [info,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/328:11760,Learn,Learned,11760,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/328,1,['Learn'],['Learned']
Usability,"mon (bulk mode) or alevin (single-cell mode)?**; Salmon (bulk); **Describe the bug**; I have a Illumina TruSeq Stranded Ribozero library and when I use salmon with -l A, it detects the libraries as either ISF or IU (for different indexes). The mapping rate is about 50-75% per index. However, as I understand it, Illumina TruSeq stranded libraries are supposed to be ISR? When I use -l ISR, i get much lower mapping rates so I'm a bit confused. Am I wrong about the library type for TruSeq Stranded, or is there a mistake in the Salmon docs? . **To Reproduce**; Steps and data to reproduce the behavior:. Specifically, please provide at least the following information:. * Which version of salmon was used?; Latest (0.14.1); * How was salmon installed (compiled, downloaded executable, through bioconda)?; conda, using a Snakemake workflow (ARMOR, from Mark Robinson's lab); * Which reference (e.g. transcriptome) was used?; Arabidopsis thaliana, from ensembl; * Which read files were used?; * Which which program options were used?; salmon (mapping-based) v0.14.1; [ program ] => salmon; [ command ] => quant; [ index ] => { /mnt/EPHEMERAL/sabineRNASEQ/ARMOR/reference/SalmonIndex/Arabidopsis_thaliana }; [ libType ] => { ISR }; [ mates1 ] => { /mnt/EPHEMERAL/sabineRNASEQ/trimmedfastq/12-0-rve-30-3_R1.fastq.gz }; [ mates2 ] => { /mnt/EPHEMERAL/sabineRNASEQ/trimmedfastq/12-0-rve-30-3_R2.fastq.gz }; [ output ] => { /mnt/EPHEMERAL/sabineRNASEQ/ARMOR/output/salmon/12-0-rve-30-3 }; [ numBootstraps ] => { 100 }; [ seqBias ] => { }; [ gcBias ] => { }; [ validateMappings ] => { }; [ ] => { o--fldMean }; [ ] => { 250 }; [ fldSD ] => { 25 }; [ threads ] => { 7 }. **Expected behavior**; A clear and concise description of what you expected to happen. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. **Desktop (please complete the following information):**; - OS: Ubuntu; - Version ; **Additional context**; Add any other context about the problem here.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/393:1725,clear,clear,1725,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/393,1,['clear'],['clear']
Usability,"mon for mapping and quantification, there is a separate background thread that simply consumes reads from file and puts them in memory for quantification, and while e.g. pairing information between files is guaranteed to be preserved, exact read order is not. This can lead to differences in the order in which reads are processed and, as a result, differences in the initialization conditions of the optimization. The ultimate result is that for transcripts that have large inferential uncertainty, different numbers of reads can be assigned between runs. We have thought *a lot* about this behavior, what it means, and how the `NumRead` values should best be communicated to users. At the end of the day, the `NumReads` constitute the expected value of latent variables inferred in a _very_ high-dimensional space (# of parameters is at least the number of transcripts). Therefore, there are certain transcripts, whose estimated number of reads simply have _tremendous_ inferential uncertainty — and small perturbations in the initial conditions of the optimization will lead to different estimated values for their abundances. For those transcripts where you observe such fluctuations between runs, this is simply evidence that the precision that can be confidently placed on those estimates is below the degree of variation you observe. Treating these transcripts in downstream analysis as more certain can easily lead to spurious inferences regarding things like differential transcript expression or usage. . One can make an argument for trying to provide a way to enforce removal of this variation (which, granted, would be a challenge). However, the reason we decided against even attempting this is because it doesn't properly address any issue with respect to an actual biological analysis. That is, even if you could fix, precisely, the update order and initialization conditions for a specific sample to eliminate any variation between runs, almost all experiments consist of multiple samp",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/613#issuecomment-757989858:1753,simpl,simply,1753,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/613#issuecomment-757989858,2,['simpl'],['simply']
Usability,"mple - this is confusing to explain in text format, but all comes down to the sequential nature of how the cells acquire barcodes in this protocol. We start with a 96-well plate, where each of the top 48 wells contain BOTH an oligo-dT barcode and random hexamer barcode. The samples then get added to each well. Biochemistry happens. Then you pool all the cells together, split them back out into 48 wells again, and each well gets its own BC2. Then repeat for BC3. . So a given transcript may get amplified via one of two amplification primers (oligo-dT or random hexamer), but after that, will get a single BC2 sequence and BC3 sequence added after that. In Fig 1A of the Rosenberg paper, it's as though there isn't _just_ an orange sequence carrying out reverse transcription, there are actually two different (known) sequences associated with different routes of amplification per cell. . The net effect is that a given cell can contain transcripts that have a sequence like this:; AACGTGAT-CTGTAGCC-ACACAGAA. or like this:; GATAGACA-CTGTAGCC-ACACAGAA. where maybe the first sequence was amplified by oligo-dT and the second was amplified via a random hexamer. Because they have the same BC2 and BC3 sequence, and the BC1 sequences match a known pairing, we know they come from the same cell and therefore the data should be merged. . Any lab running these experiments will have a table of known pairings (ie the two barcodes added to each of first 48 wells), so that they can be merged and treated as though they came from the same cell. This can either be handled upstream of salmon/alevin as a preprocessing step, like what my slow perl script can do, or it can be handled internally. Having alevin do the collapsing would likely be a lot faster and means the FASTQs don't need any editing, which would be preferable, but I would understand if that is out of scope for you all. . Hopefully that explanation is clear, but if you have any other questions on this I'd be happy to meet and discuss",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-937918722:2333,clear,clear,2333,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699#issuecomment-937918722,2,['clear'],['clear']
Usability,"ndefined reference to `boost::program_options::abstract_variables_map::operator[](std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const'; libsalmon_core.a(SalmonUtils.cpp.o): In function `salmon::utils::validateOptionsMapping_(SalmonOpts&, boost::program_options::variables_map&)':; SalmonUtils.cpp:(.text+0xd13f): undefined reference to `boost::program_options::abstract_variables_map::operator[](std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const'; libsalmon_core.a(SalmonUtils.cpp.o): In function `salmon::utils::processQuantOptions(SalmonOpts&, boost::program_options::variables_map&, int)':; SalmonUtils.cpp:(.text+0xeb97): undefined reference to `boost::program_options::abstract_variables_map::operator[](std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const'; SalmonUtils.cpp:(.text+0xec0a): undefined reference to `boost::program_options::abstract_variables_map::operator[](std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const'; libsalmon_core.a(SalmonUtils.cpp.o):SalmonUtils.cpp:(.text+0xf846): more undefined references to `boost::program_options::abstract_variables_map::operator[](std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const' follow; collect2: error: ld returned 1 exit status; make[2]: *** [src/unitTests] Error 1; make[1]: *** [src/CMakeFiles/unitTests.dir/all] Error 2; make: *** [all] Error 2. I have the following environment variables set:. INCLUDE=/opt/boost-1.67.0/include:/opt/gcc-8.2.0/include; C_INDLUE_PATH=/opt/boost-1.67.0/include; LD_LIBRARY_PATH=/opt/boost-1.67.0/lib:/opt/gcc-8.2.0/lib64:/opt/gcc-8.2.0/lib/gcc/x86_64-pc-linux-gnu/8.2.0; CPLUS_INCLUDE_PATH=/opt/boost-1.67.0/include:/opt/gcc-8.2.0/include; CXX=/opt/gcc-8.2.0/bin/g++; CC=/opt/gcc-8.2.0/bin/gcc. My cmake command was simply cmake -DCMAKE_INSTALL_PREFIX:PATH=/opt/salmon ../. Thanks!. -Nate",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/309:2707,simpl,simply,2707,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/309,1,['simpl'],['simply']
Usability,"ne already (1 moving part at a time). I am trying to run it through Alevin and it keeps failing with printing to the screen:. > [2023-08-17 22:13:22.207] [alevinLog] [info] Done barcode density calculation.; > [2023-08-17 22:13:22.207] [alevinLog] [info] # Barcodes Used: 15722231 / 15722593.; > [2023-08-17 22:13:22.910] [alevinLog] [info] Total 545(has 201 low confidence) barcodes; > [2023-08-17 22:13:23.660] [alevinLog] [info] Done True Barcode Sampling; (some lines later); > [2023-08-17 22:14:04.046] [jointLog] [info] Computed 0 rich equivalence classes for further processing; > [2023-08-17 22:14:04.046] [jointLog] [info] Counted 0 total reads in the equivalence classes; > [2023-08-17 22:14:04.047] [jointLog] [info] Number of fragments discarded because they are best-mapped to decoys : 0; > [2023-08-17 22:14:04.083] [jointLog] [info] Mapping rate = 0%. It ultimately dies with a floating point error, probably for dividing by 0 somewhere. . The command I'm running is (and note that I have r1 and r2 swapped, per some other guidance. It dies earlier during barcode processing otherwise):. > salmon alevin -i /ref/gencode.v43.transcripts/ -l ISR -1 r2.fastq.gz -2 r1.fastq.gz -p 30 --splitseqV2 --tgMap /ref/gencode.v43_full.txMap -o salmon_output --expectCells 400. I tried to make it simpler and simpler, so that's a salmon index I made myself with no decoys, just the gencode transcript fasta with the software version I'm trying to run (salmon 1.10.2, from the combinelab/salmon docker hub), gencode v43 (I know, it's a version behind, but it's what I'm using elsewhere...) and hg38. It's handling the barcodes fine and recovering approximately the right amount (it's a sub-library with a few hundred cells to check the quality of the library before sequencing the full experiment). But it's failing to quantitate any of the reads. Oddly, just quantitating the read1 file with; > salmon quant -i /ref/gencode.v43.transcripts/ -l ISR -r r1.fastq.gz -p 30 -o work/salmon_output. behaves",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/867:1173,guid,guidance,1173,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/867,1,['guid'],['guidance']
Usability,"nfo] Index contained 64 targets; > [2020-06-03 13:54:46.552] [jointLog] [info] Number of decoys : 0; > ; > [2020-06-03 13:54:46.493] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify; > ; > processed 52 Million fragmentsvinLog] [info] parsing read library format; > hits: 0, hits per frag: 0; > ; > [2020-06-03 13:55:42.905] [alevinLog] [info] Starting optimizer; > ; > [2020-06-03 13:55:42.931] [alevinLog] [warning] mrna file not provided; using is 1 less feature for whitelisting; > [2020-06-03 13:55:42.931] [alevinLog] [warning] rrna file not provided; using is 1 less feature for whitelisting; > [2020-06-03 13:55:42.933] [alevinLog] [info] Total 0.00 UMI after deduplicating.; > [2020-06-03 13:55:42.933] [alevinLog] [info] Total 0 BiDirected Edges.; > [2020-06-03 13:55:42.933] [alevinLog] [info] Total 0 UniDirected Edges.; > [2020-06-03 13:55:42.933] [alevinLog] [warning] Skipped 50091 barcodes due to No mapped read; > [2020-06-03 13:55:42.934] [alevinLog] [info] Clearing EqMap; Might take some time.; > [2020-06-03 13:55:42.940] [alevinLog] [warning] Num Low confidence barcodes too less 1 < 200.Can't performing whitelisting; Skipping; > [2020-06-03 13:55:42.940] [alevinLog] [info] Finished optimizer; > `. I also tried . `salmon alevin -l ISR --chromium --featureStart 19 --featureLength 21 --tgMap guide_to_gene.tsv`. But I get the following output. > `; > [2020-06-03 13:47:17.330] [alevinLog] [info] Found 64 transcripts(+0 decoys, +0 short and +0 duplicate names in the index); > [2020-06-03 13:47:17.330] [alevinLog] [info] Filled with 64 txp to gene entries ; > [2020-06-03 13:47:17.330] [alevinLog] [info] Found all transcripts to gene mappings; > [2020-06-03 13:47:17.336] [alevinLog] [info] Processing barcodes files (if Present) ; > ; > processed 52 Million barcodes; > ; > [2020-06-03 13:48:30.047] [alevinLog] [info] Done barcode density calculation.; > [2020-06-03 13:48:30.047] [alevinLog] [info] # Barcodes Used: 52200250 / 52200250.; > [2020-06-03 13",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531:3530,Clear,Clearing,3530,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531,1,['Clear'],['Clearing']
Usability,"nfo] Total Unique barcodes found: 604589; > [2020-06-04 17:56:29.557] [alevinLog] [info] Used Barcodes except Whitelist: 88156; > [2020-06-04 17:56:30.294] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify; > ; > [2020-06-04 17:56:30.294] [alevinLog] [info] parsing read library format; > [2020-06-04 17:57:36.339] [alevinLog] [info] Starting optimizer; > ; > ; > [2020-06-04 17:57:37.051] [alevinLog] [warning] mrna file not provided; using is 1 less feature for whitelisting; > [2020-06-04 17:57:37.051] [alevinLog] [warning] rrna file not provided; using is 1 less feature for whitelisting; > [2020-06-04 17:57:37.338] [alevinLog] [info] Total 23937.00 UMI after deduplicating.; > [2020-06-04 17:57:37.338] [alevinLog] [info] Total 91 BiDirected Edges.; > [2020-06-04 17:57:37.338] [alevinLog] [info] Total 82 UniDirected Edges.; > [2020-06-04 17:57:37.338] [alevinLog] [warning] Skipped 82268 barcodes due to No mapped read; > [2020-06-04 17:57:37.341] [alevinLog] [info] Clearing EqMap; Might take some time.; > [2020-06-04 17:57:37.348] [alevinLog] [warning] Num Low confidence barcodes too less 1 < 10.Can't performing whitelisting; Skipping; > [2020-06-04 17:57:37.348] [alevinLog] [info] Finished optimizer; > ; > . salmon_quant.log. > [2020-06-04 17:55:11.700] [jointLog] [info] setting maxHashResizeThreads to 7; > [2020-06-04 17:55:11.700] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; > [2020-06-04 17:55:11.700] [jointLog] [info] The --mimicBT2, --mimicStrictBT2 and --hardFilter flags imply mapping validation (--validateMappings). Enabling mapping validation.; > [2020-06-04 17:55:11.700] [jointLog] [info] Usage of --validateMappings implies use of minScoreFraction. Since not explicitly specified, it is being set to 0.65; > [2020-06-04 17:55:11.700] [jointLog] [info] The use of range-factorized equivalence classes does not make sense in conjunction with --hardFilter. Disabling range-factorized equiva",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639196415:2429,Clear,Clearing,2429,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/531#issuecomment-639196415,1,['Clear'],['Clearing']
Usability,"ng 32-bit quasi index; [2019-01-29 09:56:54.551] [stderrLog] [info] Loading Transcript Info ; [2019-01-29 09:56:54.826] [stderrLog] [info] Loading Rank-Select Bit Array; [2019-01-29 09:56:54.883] [stderrLog] [info] There were 80,511 set bits in the bit array; [2019-01-29 09:56:54.908] [stderrLog] [info] Computing transcript lengths; [2019-01-29 09:56:54.908] [stderrLog] [info] Waiting to finish loading hash; [2019-01-29 09:57:09.336] [stderrLog] [info] Done loading index; [2019-01-29 09:57:09.336] [jointLog] [info] done; [2019-01-29 09:57:09.336] [jointLog] [info] Index contained 80,511 targets. processed 2 Million fragments; hits: 812181, hits per frag: 0.326777. [2019-01-29 09:57:36.647] [alevinLog] [info] Starting optimizer; [2019-01-29 09:57:36.587] [jointLog] [info] Computed 12,933 rich equivalence classes for further processing; [2019-01-29 09:57:36.587] [jointLog] [info] Counted 242,520 total reads in the equivalence classes ; [2019-01-29 09:57:36.601] [jointLog] [warning] Only 242520 fragments were mapped, but the number of burn-in fragments was set to 5000000.; The effective lengths have been computed using the observed mappings. [2019-01-29 09:57:36.601] [jointLog] [info] Mapping rate = 8.94141%. [2019-01-29 09:57:36.601] [jointLog] [info] finished quantifyLibrary(). Analyzed 293 cells (100% of all).; [2019-01-29 09:57:40.090] [alevinLog] [info] Total 206902 UMI after deduplicating.; [2019-01-29 09:57:40.091] [alevinLog] [warning] Skipped 71 barcodes due to No mapped read; [2019-01-29 09:57:40.110] [alevinLog] [info] Clearing EqMap; Might take some time.; [2019-01-29 09:57:40.176] [alevinLog] [info] Starting Import of the gene count matrix.; [2019-01-29 09:57:41.168] [alevinLog] [info] Done Importing gene count matrix for dimension 222x19879; [2019-01-29 09:57:41.168] [alevinLog] [info] Starting dumping cell v gene counts in csv format; Segmentation fault (core dumped); ```. I then installed through conda salmon=0.12.0. Both times it failed with core dump.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722:9901,Clear,Clearing,9901,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722,1,['Clear'],['Clearing']
Usability,"ng of these considerations. It’s good to think about how data processing choices may affect your results and you are being thoughtful here. I wouldn’t say that, generally, alignment-free tools are more accurate than alignment-based ones. For example, you might look at our recent paper on how [alignment and mapping methodology can influence abundance estimation even when holding the quantification approach fixed](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-020-02151-8), or [this paper on the corner cases of alignment-free methodology](https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-018-4869-5) (note the second paper pre-dates the first, and the new selective-alignment methodology in salmon should largely address the issues raised in that paper). However, the bigger and more meaningful distinction is between methods that attempt to properly quantify abundance (generally using a generative statistical model) — including methods like RSEM, BitSeq, salmon, etc., and those that try to simply count aligned reads — including methods like HTSeq and featureCounts. Generally, the former type of methods are more accurate than the latter at both the gene level and the former can also offer transcript-level estimates if desired (counting based methods generally cannot). Finally, to your question more directly, I don’t believe that model misspecification that may result due to not knowing the fragment length distribution will generally have enough of a deleterious effect on the probabilistic quantification methods to degrade their performance to the level of counting based methods. I would still argue to prefer probabilistic quantification (i.e. salmon) to read counting, even if you don’t know the fragment length distribution. As I mentioned above, it may change the maximum likelihood estimates a bit, but should do so across all samples, hopefully minimizing the downstream effects on differential analysis. Good luck with your analysis!. Best,; Rob",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/127#issuecomment-750943952:1081,simpl,simply,1081,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/127#issuecomment-750943952,2,['simpl'],['simply']
Usability,"nst&) const'; SalmonUtils.cpp:(.text+0x39b7): undefined reference to `boost::program_options::abstract_variables_map::operator[](std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const'; libsalmon_core.a(SalmonUtils.cpp.o): In function `salmon::utils::validateOptionsMapping_(SalmonOpts&, boost::program_options::variables_map&)':; SalmonUtils.cpp:(.text+0xec56): undefined reference to `boost::program_options::abstract_variables_map::operator[](std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const'; libsalmon_core.a(SalmonUtils.cpp.o):SalmonUtils.cpp:(.text+0xec92): more undefined references to `boost::program_options::abstract_variables_map::operator[](std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&) const' follow; collect2: error: ld returned 1 exit status; make[2]: *** [src/unitTests] Error 1; make[1]: *** [src/CMakeFiles/unitTests.dir/all] Error 2; make: *** [all] Error 2. **Is the bug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**. **Describe the bug**; A clear and concise description of what the bug is. **To Reproduce**; Steps and data to reproduce the behavior:. Specifically, please provide at least the following information:. * Which version of salmon was used?; * How was salmon installed (compiled, downloaded executable, through bioconda)?; * Which reference (e.g. transcriptome) was used?; * Which read files were used?; * Which which program options were used?. **Expected behavior**; A clear and concise description of what you expected to happen. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX]; - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux the output of `uname -a` and `lsb_release -a`]. **Additional context**; Add any other context about the problem here.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/551:2365,clear,clear,2365,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/551,2,['clear'],['clear']
Usability,"nt; ReadExperimentT = ReadExperiment<EquivalenceClassBuilder<TGValue> >; size_t = long unsigned int]::__lambda33}) (fastx_parser::FastxParser<fastx_parser::ReadSeq>*&)’; get_deleter()(__p);; ^; /opt/build/salmon/src/SalmonQuantify.cpp:1964:39: note: candidate is:; auto parserPtrDeleter = [&salmonOpts](auto* p) -> void {; ^; /opt/build/salmon/src/SalmonQuantify.cpp:1964:53: note: processReadLibrary(ReadExperimentT&, ReadLibrary&, SalmonIndex*, std::vector<Transcript>&, ClusterForest&, std::atomic<long unsigned int>&, std::atomic<long unsigned int>&, std::atomic<long unsigned int>&, bool, std::atomic<bool>&, ForgettingMassCalculator&, FragmentLengthDistribution&, SalmonOpts&, double, bool, std::mutex&, size_t, std::vector<std::vector<AlignmentGroup<AlnT> > >&, volatile bool&) [with AlnT = rapmap::utils::QuasiAlignment; ReadExperimentT = ReadExperiment<EquivalenceClassBuilder<TGValue> >; size_t = long unsigned int]::__lambda33; auto parserPtrDeleter = [&salmonOpts](auto* p) -> void {; ^; /opt/build/salmon/src/SalmonQuantify.cpp:1964:53: note: candidate expects 0 arguments, 1 provided; make[2]: *** [src/CMakeFiles/salmon.dir/SalmonQuantify.cpp.o] Error 1; make[1]: *** [src/CMakeFiles/salmon.dir/all] Error 2; make: *** [all] Error 2`. * Which version of salmon was used?; Salmon 0.3.2; * How was salmon installed (compiled, downloaded executable, through bioconda)?; Cloned from git as latest source and attempted to cmake + make && make install . **Expected behavior**; A clear and concise description of what you expected to happen.; Expecting the makefile to use c++14 correctly to process the ""auto p"" variable the way it is intended within the template functions. See SalmonQuantify.cpp:1964 with errors regarding ""p was not declared in this scope"". . **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX]; Centos 7 ; - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux the output of `uname -a` and `lsb_release -a`]; 7.4",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/296:49947,clear,clear,49947,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/296,1,['clear'],['clear']
Usability,ntification) v0.11.3; ### [ program ] => salmon ; ### [ command ] => alevin ; ### [ libType ] => { ISR }; ### [ mates1 ] => { big.fastq.1.gz }; ### [ mates2 ] => { big.fastq.2.gz }; ### [ chromium ] => { }; ### [ index ] => { geneset.dir/geneset_coding_exons.salmon.index/ }; ### [ output ] => { salmon.dir/ }; ### [ tgMap ] => { transcript2geneMap.tsv }; ### [ dumpCsvCounts ] => { }. [2019-01-29 09:56:37.731] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2019-01-29 09:56:37.749] [alevinLog] [info] Processing barcodes files (if Present) . ; processed 2 Million barcodes. [2019-01-29 09:56:43.029] [alevinLog] [info] Done barcode density calculation.; [2019-01-29 09:56:43.029] [alevinLog] [info] # Barcodes Used: 2695632 / 2712324.; [2019-01-29 09:56:52.900] [alevinLog] [info] Knee found left boundary at 692 ; [2019-01-29 09:56:53.219] [alevinLog] [info] Gauss Corrected Boundary at 100 ; [2019-01-29 09:56:53.219] [alevinLog] [info] Learned InvCov: 114.414 normfactor: 148.807; [2019-01-29 09:56:53.219] [alevinLog] [info] Total 293(has 193 low confidence) barcodes; [2019-01-29 09:56:53.224] [alevinLog] [info] Done True Barcode Sampling; [2019-01-29 09:56:53.254] [alevinLog] [info] Done populating Z matrix; [2019-01-29 09:56:53.255] [alevinLog] [info] Done indexing Barcodes; [2019-01-29 09:56:53.255] [alevinLog] [info] Total Unique barcodes found: 125401; [2019-01-29 09:56:53.255] [alevinLog] [info] Used Barcodes except Whitelist: 1256; [2019-01-29 09:56:53.281] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2019-01-29 09:56:53.281] [alevinLog] [info] parsing read library format; [2019-01-29 09:56:53.412] [stderrLog] [info] Loading Suffix Array ; [2019-01-29 09:56:53.281] [jointLog] [info] There is 1 library.; [2019-01-29 09:56:53.410] [jointLog] [info] Loading Quasi index; [2019-01-29 09:56:53.411] [jointLog] [info] Loading 32-bit quasi index; [2019-01-29 09:56:54.551] [stderrLog] [info] Lo,MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722:7420,Learn,Learned,7420,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/337#issuecomment-458481722,1,['Learn'],['Learned']
Usability,"ode-scanning-workflow) for detailed documentation on how to configure a CodeQL workflow. Questions? Check out the FAQ below!. ### FAQ; <details>; <summary>Click here to expand the FAQ section</summary>. #### How often will the code scanning analysis run?; By default, code scanning will trigger a scan with the CodeQL engine on the following events:; * On every pull request — to flag up potential security problems for you to investigate before merging a PR.; * On every push to your default branch and other protected branches — this keeps the analysis results on your repository’s *Security* tab up to date.; * Once a week at a fixed time — to make sure you benefit from the latest updated security analysis even when no code was committed or PRs were opened. #### What will this cost?; Nothing! The CodeQL engine will run inside GitHub Actions, making use of your [unlimited free compute minutes for public repositories](https://docs.github.com/en/actions/learn-github-actions/usage-limits-billing-and-administration#about-billing-for-github-actions). #### What types of problems does CodeQL find?; The CodeQL engine that powers GitHub code scanning is the exact same engine that powers LGTM.com. The exact set of rules has been tweaked slightly, but you should see almost exactly the same types of alerts as you were used to on LGTM.com: we’ve enabled the [`security-and-quality` query suite](https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs) for you. #### How do I upgrade my CodeQL engine?; No need! New versions of the CodeQL analysis are constantly deployed on GitHub.com; your repository will automatically benefit from the most recently released version. #### The analysis doesn’t seem to be working; If you get an error in GitHub Actions that indicates that CodeQL wasn’t able to analyze your code, please [follow the instructions here](https://docs.github.com/en/co",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/pull/815:2559,learn,learn-github-actions,2559,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/pull/815,1,['learn'],['learn-github-actions']
Usability,"okies, I think I see the issue. So look at the following lines in the log:; ```; [2019-06-17 21:21:44.518] [alevinLog] [info] Total 824863; [2019-06-17 21:22:47.680] [alevinLog] [info] Total Unique barcodes found: 3474567; ```; What it means is alevin found total: `3,474,567` unique CB in the whole sample and keeps `824,863` CB for further processing which is ~23% of the CB. So all the `keepCBFraction` values above 0.23 would have no effect. If you wan't to generate the `whitelist.txt`, alevin has to have some low confidence CB to learn from, so I am guessing in your case any value from 0.15-0.20 should ideally work. Having said that, I am still exploring why even setting `freqThreshold` to 0, alevin not considers all `3M` CB for processing, I guess there is some kind of filter which is coming into the picture but I might need a bit more time to explore that. I will update here once I figure it out. Thanks again for raising the issue and investing your time in improving alevin.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/379#issuecomment-503344686:537,learn,learn,537,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/379#issuecomment-503344686,2,['learn'],['learn']
Usability,"on for the problems you are facing in alevin. >Your first question was related to alevin quantifying very less number of reads. To answer that,; if you look at the log, at the first few lines, alevin warns about ~91% of the reads being thrown away because; of the noisy CBs. The problem is alevin’s first “knee"" estimation is overshooting in predicting the first boundary. You will find https://github.com/COMBINE-lab/salmon/issues/362 issue to be; very useful in understanding that. As a summary if you look at the plot I attached it has bi-modalities,; which is generally not the case and alevin is greedily finding the threshold at the first ~100 cells. If this; happens the general direction is to help alevin by proving a upper bound, in case of your data; would be ~14000 cells. You can tell alevin with `—expectCells 14000` and alevin start to work; normally and logs ~12% of the data is noisy. >You second question was a little complicated to answer. Seemingly, your salmon index has transcript with; same exact name `ENST00000399966.9`, occurring twice with different sequences. Just by looking at the index,; I am unsure it’s actually present in the reference or its salmon indexing messing up. If I Assume it was actually; present two times in the reference, alevin should report it instead of exiting abruptly in the middle of quantification.; Although, alevin does warns:; ```; [2019-07-04 14:12:32.519] [alevinLog] [warning] Found 1 transcripts with duplicate names; ```; >However, the bug i.e. not being able to distinguish duplicate names of the transcript, has been ; fixed and pushed in the develop branch of salmon. Alevin was reporting the error at the stage of quantification too, ; if you dump the logs in a file, but it was invisible in the console as it was over written my complex progress bar. . >Once I process it through the modified pipeline, alevin finished normally and I am attaching the quants generated; by alevin. >Thanks again for forwarding the data.; Best,; —Avi",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/386#issuecomment-508754845:2022,progress bar,progress bar,2022,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/386#issuecomment-508754845,2,['progress bar'],['progress bar']
Usability,"oothly while 7 samples end with ""Segmentation fault (core dumped)"". **To Reproduce**; Steps and data to reproduce the behavior:; run salmon quant in 276 samples on HPC, 7 failed with ""Segmentation fault (core dumped)"". But by changing the p from 16 to 64, 2 of them won't be stopped by this error. Specifically, please provide at least the following information:. * Which version of salmon was used? v1.10.2; * How was salmon installed (compiled, downloaded executable, through bioconda)? bioconda ; * Which reference (e.g. transcriptome) was used? GRCh38 transcripts from gencode v44; * Which read files were used? paired-end bulk RNA seq file in fastq.gz format; * Which which program options were used? ; …/miniconda3/envs/salmon1/bin/salmon quant -i …/share/references/gencode/salmon_index --libType A ; -1 $read1 \; -2 $read2 \; -p 16 \; --validateMappings \; --gcBias \; --seqBias \; --recoverOrphans \; --rangeFactorizationBins 4 \; --output $outdir. **Expected behavior**; A clear and concise description of what you expected to happen.; Salmon quant to produce quant.sf file. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem.; ```shell; Version Info Exception: server did not respond before timeout; ### salmon (selective-alignment-based) v1.10.2; ### [ program ] => salmon ; ### [ command ] => quant ; ### [ index ] => { /share/references/gencode/salmon_index }; ### [ libType ] => { A }; ### [ mates1 ] => { RNA_1.fastq.gz }; ### [ mates2 ] => { RNA_2.fastq.gz }; ### [ threads ] => { 16 }; ### [ validateMappings ] => { }; ### [ gcBias ] => { }; ### [ seqBias ] => { }; ### [ recoverOrphans ] => { }; ### [ rangeFactorizationBins ] => { 4 }; ### [ output ] => { salmon.standard/sample }; Logs will be written to salmon.standard/sample/logs; [2024-11-01 05:13:59.563] [jointLog] [info] setting maxHashResizeThreads to 16; [2024-11-01 05:13:59.563] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will b",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/971:1218,clear,clear,1218,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/971,1,['clear'],['clear']
Usability,"ort as many use cases as possible but since it involves multiples developers it's hard to know the intrinsic details about every use-case by all the developers. Having said that, salmon is primarily designed for bulk RNA-seq quantification and as the help page you shared says -- `noLengthCorrection` is experimental. . I agree with all three comments above regarding the paper I shared. In fact, that was my reading as well, like I said I am not sure about the intricacies involved with QuantSeq ""technology"" and that's why I forwarded to you for confirming. I understand the difference between Lexogen and Quantseq but what I meant was more data specific knowledge as I _personally_ don't find ""one model fits all"" kind of approach right. I believe, It takes time and understanding to develop a good model for data generated from any technology and that's what we have been trying to do with salmon for years, piece by piece. Having said that, we don't mean to discourage people from trying salmon, that's one of the way we learn how can we improve the model even further. Now, coming back to your original question about using QuantSeq with salmon and how the paper above approach to solve it. I have a couple of thoughts:; 1.) Like you said, from the reading of their command line argument they didn't use the `nolengthcorrection` and I am surprised about the results myself. Since you have experience with the technology, you are best person to explore the difference in using and not using the length correction with salmon, that's why I shared.; 2.) Salmon models the transcript lengths in its quantification model. The basic intuition being longer length transcripts have higher probability of a read being sampled from them and has to be corrected for when using relative count metrices (like TPM) to avoid length bias. The logic behind `noLengthCorrection` is to _not_ correct for length for 3' protocol since we expect all the reads from one end of the transcript and if we do length correc",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565256512:1206,learn,learn,1206,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/449#issuecomment-565256512,2,['learn'],['learn']
Usability,"ped; [2019-07-18 14:15:52.078] [alevinLog] [info] Total 161284 white-listed Barcodes; [2019-07-18 14:15:52.259] [alevinLog] [info] Total 5.95793% reads will be thrown away because of noisy Cellular barcodes.; [2019-07-18 14:15:58.709] [alevinLog] [info] Done populating Z matrix; [2019-07-18 14:15:58.741] [alevinLog] [info] Total 56814 CB got sequence corrected; [2019-07-18 14:15:58.750] [alevinLog] [info] Done indexing Barcodes; [2019-07-18 14:15:58.750] [alevinLog] [info] Total Unique barcodes found: 687531; [2019-07-18 14:15:58.750] [alevinLog] [info] Used Barcodes except Whitelist: 44516; [2019-07-18 14:15:58.973] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify; [2019-07-18 14:15:58.973] [alevinLog] [info] parsing read library format; [2019-07-18 14:24:27.923] [alevinLog] [info] Starting optimizer; [2019-07-18 14:24:28.655] [alevinLog] [warning] 24 mitorna gene(s) does not have transcript in the reference; [2019-07-18 14:24:28.655] [alevinLog] [info] Total 13 usable mRna genes; [2019-07-18 14:24:28.656] [alevinLog] [warning] 558 ribosomal rna gene(s) does not have transcript in the reference; [2019-07-18 14:24:28.656] [alevinLog] [info] Total 0 usable rRna genes; [2019-07-18 14:30:09.475] [alevinLog] [info] Total 4282454.00 UMI after deduplicating.; [2019-07-18 14:30:09.475] [alevinLog] [info] Total 5378060 BiDirected Edges.; [2019-07-18 14:30:09.475] [alevinLog] [info] Total 958944 UniDirected Edges.; [2019-07-18 14:30:09.475] [alevinLog] [warning] Skipped 28272 barcodes due to No mapped read; [2019-07-18 14:30:09.552] [alevinLog] [info] Finished optimizer; ```. ## R code (How to Use alevin with Seurat). ```; > library(here); > library(tidyverse); > library(Seurat); > library(tximport); > library(tictoc). > files <- file.path(here(""alevin_output/alevin/quants_mat.gz"")); > file.exists(files); [1] TRUE; >; > tic(""starts...""); > txi <- tximport(files, type=""alevin""; > toc(); starts...: 728.506 sec elapsed; > sessionInfo(); ```; R version 3.6.1 (2",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/404:2026,usab,usable,2026,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/404,1,['usab'],['usable']
Usability,"ple_S1_L001_R1_001.fastq -2 ../clean/sample_S1_L001_R2_001.fastq --chromiumV3 -i ../../dna/00.ref_genome/sample/salmon_index_allmRNA -p 40 -o test_alevin_allmRNA --tgMap ../../dna/00.ref_genome/sample/alltxp2gene.tsv`. > [2021-01-25 16:22:09.565] [alevinLog] [info] Found 43030 transcripts(+0 decoys, +0 short and +0 duplicate names in the index); [2021-01-25 16:22:09.615] [alevinLog] [info] Filled with 43030 txp to gene entries; [2021-01-25 16:22:09.620] [alevinLog] [info] Found all transcripts to gene mappings; [2021-01-25 16:22:09.631] [alevinLog] [info] Processing barcodes files (if Present); [2021-01-25 16:26:35.067] [alevinLog] [info] Done barcode density calculation.; [2021-01-25 16:26:35.067] [alevinLog] [info] # Barcodes Used: 188934609 / 188934609.; [2021-01-25 16:26:42.979] [alevinLog] [info] Knee found left boundary at 21; [2021-01-25 16:27:05.707] [alevinLog] [warning] Gauss Prediction 4969 Too far from knee prediction skipping it; [2021-01-25 16:27:05.707] [alevinLog] [info] Learned InvCov: 556.394 normfactor: 9159.58; [2021-01-25 16:27:05.707] [alevinLog] [info] Total 222(has 201 low confidence) barcodes; [2021-01-25 16:27:06.573] [alevinLog] [info] Done True Barcode Sampling; [2021-01-25 16:27:07.383] [alevinLog] [warning] Total **96.7029% reads will be thrown away** because of noisy Cellular barcodes.; [2021-01-25 16:27:07.412] [alevinLog] [info] Done populating Z matrix; [2021-01-25 16:27:07.414] [alevinLog] [info] Total 3667 CB got sequence corrected; [2021-01-25 16:27:07.414] [alevinLog] [info] Done indexing Barcodes; [2021-01-25 16:27:07.414] [alevinLog] [info] Total Unique barcodes found: 3896665; [2021-01-25 16:27:07.414] [alevinLog] [info] Used Barcodes except Whitelist: 3667; [2021-01-25 16:27:07.498] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify; [2021-01-25 16:27:07.498] [alevinLog] [info] parsing read library format; [2021-01-25 16:30:54.542] [alevinLog] [info] Starting optimizer; [2021-01-25 16:30:54.782] [alevinLog] ",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/620:3375,Learn,Learned,3375,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/620,1,['Learn'],['Learned']
Usability,"ple_S1_L001_R1_001.fastq -2 ../clean/sample_S1_L001_R2_001.fastq --chromiumV3 -i ../../dna/00.ref_genome/sample/salmon_index_allmRNA -p 40 -o test_alevin_allmRNA --tgMap ../../dna/00.ref_genome/sample/alltxp2gene.tsv`. > [2021-01-25 16:22:09.565] [alevinLog] [info] Found 43030 transcripts(+0 decoys, +0 short and +0 duplicate names in the index); [2021-01-25 16:22:09.615] [alevinLog] [info] Filled with 43030 txp to gene entries; [2021-01-25 16:22:09.620] [alevinLog] [info] Found all transcripts to gene mappings; [2021-01-25 16:22:09.631] [alevinLog] [info] Processing barcodes files (if Present); [2021-01-25 16:26:35.067] [alevinLog] [info] Done barcode density calculation.; [2021-01-25 16:26:35.067] [alevinLog] [info] # Barcodes Used: 188934609 / 188934609.; [2021-01-25 16:26:42.979] [alevinLog] [info] Knee found left boundary at 21; [2021-01-25 16:27:05.707] [alevinLog] [warning] Gauss Prediction 4969 Too far from knee prediction skipping it; [2021-01-25 16:27:05.707] [alevinLog] [info] Learned InvCov: 556.394 normfactor: 9159.58; [2021-01-25 16:27:05.707] [alevinLog] [info] Total 222(has 201 low confidence) barcodes; [2021-01-25 16:27:06.573] [alevinLog] [info] Done True Barcode Sampling; [2021-01-25 16:27:07.383] [alevinLog] [warning] Total **96.7029% reads will be thrown away** because of noisy Cellular barcodes.; [2021-01-25 16:27:07.412] [alevinLog] [info] Done populating Z matrix; [2021-01-25 16:27:07.414] [alevinLog] [info] Total 3667 CB got sequence corrected; [2021-01-25 16:27:07.414] [alevinLog] [info] Done indexing Barcodes; [2021-01-25 16:27:07.414] [alevinLog] [info] Total Unique barcodes found: 3896665; [2021-01-25 16:27:07.414] [alevinLog] [info] Used Barcodes except Whitelist: 3667; [2021-01-25 16:27:07.498] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify; [2021-01-25 16:27:07.498] [alevinLog] [info] parsing read library format; [2021-01-25 16:30:54.542] [alevinLog] [info] Starting optimizer; [2021-01-25 16:30:54.782] [alevinLog] ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/340#issuecomment-766311567:2443,Learn,Learned,2443,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/340#issuecomment-766311567,1,['Learn'],['Learned']
Usability,"ples (or multiple libraries or replicates of the same sample), it is best to run cellranger count on each of the libraries individually, and then pool the results using cellranger aggr. * It looks like they have three different modes to normalize the libraries; > There are three normalization modes:; mapped: (default) Subsample reads from higher-depth libraries until they all have an equal number of confidently mapped reads per cell.; raw: Subsample reads from higher-depth libraries until they all have an equal number of total (i.e. raw, mapping-independent) reads per cell.; none: Do not normalize at all. * Although it's not clear, what do they mean by `equal number of confidently mapped reads per cell`, does it mean median reads per cell ? Like you tried to show in the above plot the distribution can be very uneven. But the part that troubles me more is once `count` information has been generated it has lost the read level information, since we have deduplicated them, then how do they use the read counts to normalize. Unless that is dumped too, not clear. Quoting your text from above:; > Alternatively, could a subsampling covariate be added to the probabilistic quantification model of alevin. I think we can definitely work on correcting the subsampling bias in the probabilistic model of Alevin but we might need a little more understanding of what's going on with the cellranger and why your way of aggregation is not working as intended. Unfortunately, I think we have to dig deeper into the cellranger codebase to really understand that and if possible, might need some subset of the relevant data to replicate your issue and work on improving that. Also, I am wondering, what's your way of checking the batch effect and comparing Alevin and Cellranger aggregation? Just a guess, the tSNE plots of the two samples are separating out very clearly, if possible if you can share the figures and the analysis (may be a notebook) to us, we can help and investigate more thoroughly.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/305#issuecomment-433453155:1745,clear,clear,1745,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/305#issuecomment-433453155,4,['clear'],"['clear', 'clearly']"
Usability,"poly-A tails from 0 transcripts; [2020-04-07 21:12:14.599] [jointLog] [info] Building rank-select dictionary and saving to disk; [2020-04-07 21:12:14.599] [jointLog] [info] done; Elapsed time: 5.7764e-05s; [2020-04-07 21:12:14.606] [jointLog] [info] Writing sequence data to file . . . ; [2020-04-07 21:12:14.607] [jointLog] [info] done; Elapsed time: 0.000590993s; [2020-04-07 21:12:14.614] [jointLog] [info] Building 32-bit suffix array (length of generalized text is 28,577); [2020-04-07 21:12:14.616] [jointLog] [info] Building suffix array . . . ; success; saving to disk . . . done; Elapsed time: 0.000716831s; done; Elapsed time: 0.0107059s; ```; Specifically, please provide at least the following information:. * Which version of salmon was used? 1.1.0, 1.0.0 and 0.14.1; * How was salmon installed (compiled, downloaded executable, through bioconda)? GitHub binary; * Which reference (e.g. transcriptome) was used? sample data from GitHub release; * Which read files were used? none; * Which which program options were used? -k 31 -i index -t sample_data/transcripts.fasta. **Expected behavior**; A clear and concise description of what you expected to happen.; I expected salmon 1.1.0 to run without a core-dump and produce similar results to 0.14.1. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX] Ubuntu 18.04.4 LTS; - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux the output of `uname -a` and `lsb_release -a`]; Linux firefly 5.3.0-40-generic #32~18.04.1-Ubuntu SMP Mon Feb 3 14:05:59 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux. **Additional context**; Using ""bcbio-nextgen"", with ""salmon 1.1.0"" installed by Anaconda: Removed this version because of core-dumps and installed the binary releases of ""salmon"" 1.1.0 then 0.41.1 from GitHub in /usr/local. Did stand-alone tests with sample data from the GitHub binary release.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/500:2682,clear,clear,2682,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/500,1,['clear'],['clear']
Usability,"possible with the `conda update --all` command. but the bottleneck is salmon, which has very old dependencies, and it's a dilemma either to update salmon from 0.8.1 (pretty old buggy version) to the latest one (0.11.3) and downgrade a bunch of other important packages, or vice versa. **Describe the bug**; a bug is a species of animal kingdom, a small insect (just kidding). **To Reproduce**; Steps and data to reproduce the behavior:; ```; $ conda update salmon; Solving environment: done. ## Package Plan ##. environment location: /home/software/anaconda2. added / updated specs: ; - salmon. The following packages will be downloaded:. package | build; ---------------------------|-----------------; salmon-0.11.3 | h86b0361_2 2.9 MB bioconda; blas-1.0 | mkl 6 KB; numpy-1.14.3 | py27h28100ab_1 41 KB; ------------------------------------------------------------; Total: 3.0 MB. The following packages will be UPDATED:. jemalloc: 4.5.0-0 bioconda --> 5.1.0-hfc679d8_0 conda-forge; libgcc-ng: 7.2.0-hdf63c60_3 conda-forge --> 8.2.0-hdf63c60_1 ; libstdcxx-ng: 7.2.0-hdf63c60_3 conda-forge --> 8.2.0-hdf63c60_1 ; salmon: 0.8.1-0 bioconda --> 0.11.3-h86b0361_2 bioconda . The following packages will be DOWNGRADED:. blas: 1.1-openblas conda-forge --> 1.0-mkl ; fastqc: 0.11.7-5 bioconda --> 0.11.6-2 bioconda ; gsl: 2.4-blas_openblash47a8a8e_1 conda-forge [blas_openblas] --> 2.1-2 conda-forge; numpy: 1.15.1-py27_blas_openblashd3ea46f_1 conda-forge [blas_openblas] --> 1.14.3-py27h28100ab_1 ; openjdk: 8.0.144-zulu8.23.0.3_2 conda-forge --> 8.0.121-1 ; scikit-learn: 0.19.2-py27_blas_openblasha84fab4_201 conda-forge [blas_openblas] --> 0.19.1-py27hedc7406_0 ; scipy: 1.1.0-py27_blas_openblash7943236_201 conda-forge [blas_openblas] --> 1.1.0-py27hd20e5f9_0; ```. **Expected behavior**; salmon should be updated to the latest version without the requirement of downgrading of its dependencies. Linux nscc04 2.6.32-696.30.1.el6.x86_64 #1 SMP Fri May 18 11:50:44 EDT 2018 x86_64 x86_64 x86_64 GNU/Linux",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/286:1699,learn,learn,1699,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/286,1,['learn'],['learn']
Usability,"ranscript_id); anot.pre <- anot.pre[lengths(anot.pre) > 1] %>% range %>% unlist %>% sort # only consider transcripts with > 1 exon. anot.pre$transcript_range <- as.character(anot.pre); anot.pre$gene_id <- anot[match(names(anot.pre), anot$transcript_id), ]$gene_id. # collapse replicate pre-mature transcripts per gene...; names(anot.pre) <- anot.pre$premature_group <- sapply(; split(; names(anot.pre),; paste(anot.pre$gene_id, anot.pre$transcript_range, sep = '_'); ),; paste, collapse = ';'; )[; paste(anot.pre$gene_id, anot.pre$transcript_range, sep = '_'); ]. # ... need to convert GR to data.table before unique because unique method for GR class ignores metadata and rownames; anot.pre <- as.data.table(anot.pre) %>% unique %>% makeGRangesFromDataFrame(., keep.extra.columns = T); names(anot.pre) <- anot.pre$premature_group. ### Read human genome sequence ####; message('Loading genome sequence...'). dna <- readDNAStringSet(filepath = genome.fasta). # simplify chromosome names; names(dna) <- sapply(strsplit(names(dna), ' '), '[', 1). dna <- dna[chromosomes] # subset chrom 1-22, X, Y, MT. ### Read Gencode transcript sequences ####; gencode <- readDNAStringSet(gencode.tx.fasta); names(gencode) <- gsub(; pattern = '\\|.*', replacement = '',; x = names(gencode); ). ### Sample transcripts on + and - strand (and avoid premature transcripts with multiple mature counterparts for simplicity); anot.pre <- anot.pre[order(width(anot.pre), decreasing = F), ]. chosenOnesP <- anot.pre[; strand(anot.pre) == '+' & !grepl(';', anot.pre$premature_group) & anot.pre$premature_group %in% names(gencode) & !duplicated(anot.pre$premature_group) &; anot.pre$premature_group %in% anot[anot$transcript_source == 'ensembl_havana']$transcript_id; ]$premature_group[1]. chosenOnesM <- anot.pre[; strand(anot.pre) == '-' & !grepl(';', anot.pre$premature_group) & anot.pre$premature_group %in% names(gencode) & !duplicated(anot.pre$premature_group) &; anot.pre$premature_group %in% anot[anot$transcript_source =",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191:5783,simpl,simplify,5783,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/655#issuecomment-826035191,2,['simpl'],['simplify']
Usability,"re being discarded because they have no alignment to annotated transcripts above the minimum allowable score, and an additional `1,099,008` are being discarded because they have only dovetail mappings. . We discard dovetail mappings by default, but you can admit them with `--allowDovetail`. The other `2,776,678` fragments are discarded because, though there are seeds for mapping that match, they do not have sufficiently high alignment score to be allowed for mapping. This default behavior, too, can be modified. The main flags that affect the behavior here are `--minScoreFraction`, where a lower number allows lower-quality alignments through and also the `--softclipOverhangs` flag which will decrease the penalty on alignments that overhang the end of an annotated transcript. However, it's worth noting that this is up to `3,875,686` more reads that might be mappable. This number is non-trivial, but quite far from the 90% rate of STAR. The rest of the reads, however, simply don't have support for alignment against the annotated transcriptome. **This suggests to me that STAR is probably aligning a lot of reads outside of annotated genes**. If you build the salmon index [using a full decoy of the genome](https://combine-lab.github.io/alevin-tutorial/2019/selective-alignment/), then you might be able to evaluate intergenic mapping in the output in terms of `Number of fragments discarded because they are best-mapped to decoys`. However, in that case, these reads still won't contribute to transcript expression, as they do not align to annotated transcripts. Finally, if you suspect these reads might be coming from genes expressed in your sample but not present in the annotation, you might consider performing a transcript assembly on your data, using a tool like [scallop2](https://github.com/Shao-Group/scallop2) or [stringtie](https://github.com/gpertea/stringtie). Best,; Rob. P.S. I'm closing the thread, since I think the above answers your direct question, but please feel fr",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/775#issuecomment-1126361719:1039,simpl,simply,1039,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/775#issuecomment-1126361719,2,['simpl'],['simply']
Usability,"rgets. processed 185 Million fragments; hits: 690426925, hits per frag: 3.72226. [2018-12-05 16:57:31.421] [jointLog] [info] Computed 215,739 rich equivalence classes for further processing; [2018-12-05 16:57:31.421] [jointLog] [info] Counted 131,957,987 total reads in the equivalence classes ; [2018-12-05 16:57:31.421] [jointLog] [warning] 0.000112378% of fragments were shorter than the k used to build the index (31).; If this fraction is too large, consider re-building the index with a smaller k.; The minimum read size found was 24. [2018-12-05 16:57:31.421] [jointLog] [warning] Found 539897 reads with `N` in the UMI sequence and ignored the reads.; Please report on github if this number is too large; [2018-12-05 16:57:31.421] [jointLog] [info] Mapping rate = 70.9532%. [2018-12-05 16:57:31.421] [jointLog] [info] finished quantifyLibrary(); [2018-12-05 16:57:35.529] [alevinLog] [info] Starting optimizer. Analyzed 3856 cells (100% of all).; [2018-12-05 17:04:51.878] [alevinLog] [info] Total 47125847 UMI after deduplicating.; [2018-12-05 17:04:51.928] [alevinLog] [info] Clearing EqMap; Might take some time.; [2018-12-05 17:05:04.064] [alevinLog] [info] Starting Import of the gene count matrix.; Exception : [std::bad_alloc]; alevin was invoked improperly.; For usage information, try alevin --help; Exiting.; ```. **Desktop (please complete the following information):**; Ubuntu 14.04 LTS; 3.13.0-143-generic #192-Ubuntu SMP Tue Feb 27 10:45:36 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux; Distributor ID:	Ubuntu; Description:	Ubuntu 14.04.5 LTS; Release:	14.04; Codename:	trusty. **Additional context**; If I include only a subset of the fastq files, the command completes with no error. I have succeeded in running up to 3 of the files (3 *I1*, 3 *I2* and 3 *RA* files), but got the above-mentioned error when running it on 4 or more fastq files. I read that std::bad_alloc was usually caused by memory issues. The system I am using has 128Gb of RAM available. Thank you for your help",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/328:14376,Clear,Clearing,14376,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/328,1,['Clear'],['Clearing']
Usability,rom GENCODE mm10 assembly. Steps and data to reproduce the behavior:; salmon alevin -l ISR -1 neuron_10k_v3_S1_L001_R1_001.fastq.gz neuron_10k_v3_S1_L002_R1_001.fastq.gz -2 neuron_10k_v3_S1_L001_R2_001.fastq.gz neuron_10k_v3_S1_L002_R2_001.fastq.gz --chromium -i map_index -p 8 -o output_10 --tgMap txp2gene.tsv --dumpCsvCounts. **Shell output** ; [2018-11-29 22:24:41.269] [jointLog] [info] Fragment incompatibility prior below threshold. Incompatible fragments will be ignored.; [2018-11-29 22:24:41.283] [alevinLog] [info] Processing barcodes files (if Present). processed 178 Million barcodes. [2018-11-29 22:28:03.040] [alevinLog] [info] Done barcode density calculation.; [2018-11-29 22:28:03.040] [alevinLog] [info] # Barcodes Used: 178139795 / 178174830.; [2018-11-29 22:28:08.333] [alevinLog] [info] Knee found left boundary at 11347; [2018-11-29 22:28:16.264] [alevinLog] [warning] Gauss Prediction 11502 Too far from knee prediction skipping it; [2018-11-29 22:28:16.264] [alevinLog] [info] Learned InvCov: 180.957 normfactor: 13235.2; [2018-11-29 22:28:16.264] [alevinLog] [info] Total 12346(has 999 low confidence) barcodes; [2018-11-29 22:28:16.397] [alevinLog] [info] Done True Barcode Sampling; [2018-11-29 22:28:17.414] [alevinLog] [info] Done populating Z matrix; [2018-11-29 22:28:17.434] [alevinLog] [info] Done indexing Barcodes; [2018-11-29 22:28:17.434] [alevinLog] [info] Total Unique barcodes found: 3773873; [2018-11-29 22:28:17.434] [alevinLog] [info] Used Barcodes except Whitelist: 49866; [2018-11-29 22:28:18.184] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2018-11-29 22:28:18.184] [alevinLog] [info] parsing read library format; [2018-11-29 22:28:18.184] [jointLog] [info] There is 1 library.; [2018-11-29 22:28:18.324] [jointLog] [info] Loading Quasi index; [2018-11-29 22:28:18.325] [jointLog] [info] Loading 32-bit quasi index; [2018-11-29 22:28:18.325] [stderrLog] [info] Loading Suffix Array; [2018-11-29 22:28:19.339] [stderrLog] [info],MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/324:1331,Learn,Learned,1331,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/324,1,['Learn'],['Learned']
Usability,"rrLog] [info] Done loading index; [2018-12-05 15:12:34.297] [jointLog] [info] done; [2018-12-05 15:12:34.297] [jointLog] [info] Index contained 167,268 targets. processed 267 Million fragments; hits: 892324990, hits per frag: 3.33692. [2018-12-05 15:45:46.198] [jointLog] [info] Computed 185,593 rich equivalence classes for further processing; [2018-12-05 15:45:46.198] [jointLog] [info] Counted 163,106,139 total reads in the equivalence classes ; [2018-12-05 15:45:46.199] [jointLog] [warning] Found 115077 reads with `N` in the UMI sequence and ignored the reads.; Please report on github if this number is too large; [2018-12-05 15:45:46.199] [jointLog] [info] Mapping rate = 60.9633%. [2018-12-05 15:45:46.199] [jointLog] [info] finished quantifyLibrary(); [2018-12-05 15:45:47.617] [alevinLog] [info] Starting optimizer. Analyzed 5344 cells (100% of all).; [2018-12-05 15:47:14.597] [alevinLog] [info] Total 1870793 UMI after deduplicating.; [2018-12-05 15:47:14.693] [alevinLog] [info] Clearing EqMap; Might take some time.; [2018-12-05 15:47:18.921] [alevinLog] [info] Starting Import of the gene count matrix.; Exception : [std::bad_alloc]; alevin was invoked improperly.; For usage information, try alevin --help; Exiting.; ```. PBMC 3k shell log:; ```; ~/software/salmon/scripts/v1_10x/run.sh salmon alevin -lISR -b pbmc3k_fastqs/ --gemcode -i ../transcripts_index_salmon/ -p 8 -o alevin_output --tgMap ../hg_transcriptome/tx2gene.tsv. TEMPDIR is /tmp/tmp.WnzMm7GQBO; Running command [salmon alevin -lISR --gemcode -i ../transcripts_index_salmon/ -p 8 -o alevin_output --tgMap ../hg_transcriptome/tx2gene.tsv -1 /tmp/tmp.WnzMm7GQBO/p1.fa -2 /tmp/tmp.WnzMm7GQBO/p2.fa -r pbmc3k_fastqs/read-I1_si-ACGCGGAA_lane-001-chunk-001.fastq.gz; pbmc3k_fastqs/read-I1_si-ACGCGGAA_lane-002-chunk-000.fastq.gz; pbmc3k_fastqs/read-I1_si-CGCTATCC_lane-001-chunk-001.fastq.gz; pbmc3k_fastqs/read-I1_si-CGCTATCC_lane-002-chunk-000.fastq.gz; pbmc3k_fastqs/read-I1_si-GTTGCATG_lane-001-chunk-001.fastq.gz; pbmc",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/328:8618,Clear,Clearing,8618,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/328,1,['Clear'],['Clearing']
Usability,"rray + ranks ); final hash 0 bits (0.00 %) (nb in final hash 0). My script to build the above index:. ~/salmon/bin/salmon index \; -t mouse_cDNA_ref/mus_cdna.fa.gz \; -i indexs/alt_long_index \; -k 31. My HPCC run on CentOS. . My script to run salmon quant:. ~/salmon/bin/salmon quant -i mnt/home/oconn341/salmon/indexs/alt_long_index -l A -1 preprocs_fastq/ERAP1_EAE_2270_S4/ERAP1_EAE_2270_S4_R1_001.fastq.gz -2 preprocs_fastq/ERAP1_EAE_2270_S4/ERAP1_EAE_2270_S4_R2_001.fastq.gz -o preprocs_fastq/ERAP1_EAE_2270_S4 --validateMappings --rangeFactorizationBins 4 --gcBias --seqBias. ; **To Reproduce**; Steps and data to reproduce the behavior:. Reproduces every time . Specifically, please provide at least the following information:. * Which version of salmon was used? V1.5.2; * How was salmon installed (compiled, downloaded executable, through bioconda)? Pre-compiled binary ; * Which reference (e.g. transcriptome) was used? Mus_musculus.GRCm39.cdna.all.fa.gz; * Which read files were used? see above; * Which which program options were used? see above. **Expected behavior**; A clear and concise description of what you expected to happen. **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX] CentOS ; - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux the output of `uname -a` and `lsb_release -a`]. **Additional context**; Add any other context about the problem here. I am thinking this is an issue w/ building the index. If there is a pre-made index w/ or w/o decoys for mouse that you can direct me to I would appreciate it. Following the link posted in the salmon documentation about pre-made index's is not helpful and I am not sure how to download them from there. A simpler option would be appreciated. . Thanks!. UPDATE: This was solved by using an index generated by a friend So apparently the issue is w/ building the index.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/696:8134,clear,clear,8134,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/696,2,"['clear', 'simpl']","['clear', 'simpler']"
Usability,"rrespond to multiple sequences. **To Reproduce**; Steps and data to reproduce the behavior:; 1. Merging quantifications with Salmon:; salmon quantmerge \; --quants temp/salmon/L1EHI0900465--Q_S1_N6.quant \; -o result/salmon/gene_L1EHI0900465--Q_S1_N6.TPM; 2. Searching for a specific gene ID in the quantification file:; grep ""k141_1346622_1"" temp/salmon/L1EHI0900465--Q_S1_N6.quant/quant.sf; # Multiple lines are found for this gene ID; 3. Searching for the same gene ID in the resulting TPM file:; grep ""k141_1346622_1"" result/salmon/gene_L1EHI0900465--Q_S1_N6.TPM; #No results are found, which is unexpected. <img width=""1166"" alt=""截屏2024-01-30 21 56 23"" src=""https://github.com/COMBINE-lab/salmon/assets/19604271/b77e5aa4-aadc-4a17-bdde-b998ce14d72c"">; <img width=""1056"" alt=""截屏2024-01-30 21 55 28"" src=""https://github.com/COMBINE-lab/salmon/assets/19604271/877cfa9b-0484-4937-87b2-e987679e09e3"">. Specifically, please provide at least the following information:. * Which version of salmon was used? salmon 1.4.0; * How was salmon installed (compiled, downloaded executable, through bioconda)? conda install salmon -y; * Which reference (e.g. transcriptome) was used? metagenome data; * Which read files were used? L1EHI0900465--Q_S1_N6.quant/; * Which which program options were used?; salmon quantmerge \; --quants temp/salmon/L1EHI0900465--Q_S1_N6.quant \; -o result/salmon/gene_L1EHI0900465--Q_S1_N6.TPM. **Expected behavior**; A clear and concise description of what you expected to happen.; I hope to keep all the gene IDs and for those who contains more than one line, take average values for each gene ID. . **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX]; - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux the output of `uname -a` and `lsb_release -a`]. **Additional context**; Add any other context about the problem here.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/910:1747,clear,clear,1747,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/910,1,['clear'],['clear']
Usability,"s_with_N"": 17295,; ""noisy_cb_reads"": 708796684,; ""noisy_umi_reads"": 149640,; ""used_reads"": 444430595,; ""mapping_rate"": 4.019738736091838,; ""reads_in_eqclasses"": 46363434,; ""total_cbs"": 132768705,; ""used_cbs"": 398369,; ""initial_whitelist"": 5383,; ""low_conf_cbs"": 1000,; ""num_features"": 5,; ""no_read_mapping_cbs"": 148,; ""final_num_cbs"": 3931,; ""deduplicated_umis"": 24178832,; ""mean_umis_per_cell"": 6150,; ""mean_genes_per_cell"": 2810; ```. This, in conjunction with the fact that running with `-l A` suggests incorrectly the data are unstranded (`IU`), led @mikelove to suspect alevin may be skipping the libType guesswork that salmon typically performs. . I know these data are of reasonably good quality, because I have instead processed them using [zUMIs](https://github.com/sdparekh/zUMIs), which supports SPLiT-seq data. A side-by-side of the same FASTQs processed this way using alevin or using zUMIs gave me ~270 cells that pass filters (alevin) vs ~50k cells that pass filters (zUMIs), so something is definitely up here. . I'd like to confirm a few details and ask for some guidance on how to move forward:. 1. Is the reversal of R1/R2 like I did here necessary/recommended/correct?; 2. Is alevin truly skipping the libType identification bits such that I need to know which architecture to use? If so, how do I know?; 3. Why are so many CBs called as ""noisy"" here?; 4. Why is the mapping rate so low?; 5. Is there anything else I'm missing that can explain the unexpectedly poor outcome, or some other reason why this approach will not work for these data? . I've also attached here the top 1000 lines of each R1/R2-corrected FASTQ (ParseBio) in the hopes that was somehow helpful in diagnosis, but I can share more reads or the full files some other way if needed. [head_R1.fastq.txt](https://github.com/COMBINE-lab/salmon/files/7068550/head_R1.fastq.txt); [head_R2_corrected.fastq.txt](https://github.com/COMBINE-lab/salmon/files/7068551/head_R2_corrected.fastq.txt). Thanks so much!. Jeremy",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/699:6882,guid,guidance,6882,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/699,1,['guid'],['guidance']
Usability,salmon --writeUnmappedNames produced undocumented result,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/657:37,undo,undocumented,37,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/657,2,['undo'],['undocumented']
Usability,"script set and the vector of conditional probability bins into which the mapping falls with respect to each transcript in the equivalence class. This means that range-factorized equivalence classes can have multiple classes of fragments that map to the same set of transcripts, but with different conditional probabilities. Additionally, for each bin, the average conditional probability of fragments arising from that bin is maintained. What you are seeing printed out are the transcript sets, followed by the conditional bin indexes. Starting in the next release (and currently in the develop branch), we've cleaned up the interaction of the range-factorized equivalence classes with the `--dumpEq` and `--dumpEqWeights` flags. If you run with the `--dumpEqWeights` flags, salmon will dump the transcript sets, followed by the conditional probability vector, followed by the fragment count. If you run with the `--dumpEq` flag, it will collapse all of the range-factorized equivalence classes into ""simple"" equivalence classes by combining classes with the same transcript set (but different conditional probability vectors) and summing the corresponding fragment counts. This, of course, is a lossy transformation, and the equivalence classes will no longer represent the relevant conditional probabilities used during inference. Also, since the range-factorized equivalence classes allow for (but probabilistically down-weight) non-optimal mappings of fragments to transcripts, these collapsed equivalence classes will tend to have bigger labels (i.e. more transcripts) which might be difficult to properly interpret without the relevant conditional probabilities. The `--hardFilter` flag will filter out transcripts that have non-best alignment scores (a big component of the conditional fragment probability), but that can have a negative effect on the modeling and inference. We'll update the documentation accordingly when we cut the next release to make all of these interactions more clear.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/402#issuecomment-517041654:1906,simpl,simple,1906,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/402#issuecomment-517041654,4,"['clear', 'simpl']","['clear', 'simple']"
Usability,"ssed 278000000 positions^M^Mprocessed 279000000 positions^M^Mprocessed 280000000 positions^M^Mprocessed 281000000 positions^M^Mprocessed 282000000 positions^M^Mprocessed 283000000 positions^M^Mprocessed 284000000 positions^M^Mprocessed 285000000 positions^M^Mprocessed 286000000 positions^M^Mprocessed 287000000 positions^M^Mprocessed 288000000 positions^M^Mprocessed 289000000 positions; khash had 109134690 keys; saving hash to disk . . . done; Elapsed time: 12.6069s; [2018-06-25 19:29:02.297] [jLog] [info] done building index; ```. It would be more interesting to see what filename is used for the index. Showing the ""basename"" of the index file is not very helpful. I would prefer to see the filename(s) on the beginning and end lines:. ```; index [""Homo_sapiens.GRCh38.cdna.all""] did not previously exist . . . creating it; [2018-06-25 19:25:57.122] [jLog] [info] building index; ...; [2018-06-25 19:29:02.297] [jLog] [info] done building index; ```. 5. The duplicates have same sequence or ID or both? The message should be clearer. I wonder what are these duplicates in a human cdna predicted, as available from `ftp://ftp.ensembl.org/pub/release-92/fasta/homo_sapiens/cdna`; :. ```; [2018-06-25 19:26:07.480] [jointLog] [warning] Removed 11768 transcripts that were sequence duplicates of indexed transcripts.; ```. 6. For the bwa-based index again, the logs are too verbose on one hand and on the second, they do not say what files were created. I doubt any file with *prefix* `Homo_sapiens.GRCh38.cdna.all/bwaidx` was created. ```; + salmon index -t Homo_sapiens.GRCh38.cdna.all.fa -i Homo_sapiens.GRCh38.cdna.all --type fmd; outputPrefix = ""Homo_sapiens.GRCh38.cdna.all/bwaidx""; [2018-06-25 19:29:02.497] [jLog] [info] building index; [bwa_index] Pack FASTA... 2.87 sec; [bwa_index] Construct BWT for the packed sequence...; [BWTIncCreate] textLength=609536484, availableWord=54888760; [BWTIncConstructFromPacked] 10 iterations done. 87569268 characters processed.; [BWTIncConstructFromP",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/242:13202,clear,clearer,13202,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/242,1,['clear'],['clearer']
Usability,sts/fastq/S1_L002_R2_001.fastq.gz /Users/james/GitHub/scrnaseq/.tests/fastq/S1_L003_R2_001.fastq.gz /Users/james/GitHub/scrnaseq/.tests/fastq/S1_L004_R2_001.fastq.gz }; ### [ output ] => { results/salmon/alevin/S1 }; ### [ threads ] => { 1 }; ### [ tgMap ] => { results/eisar/GRCh38.p13/GRCh38.p13.tx2gene.tsv }; ### [ chromiumV3 ] => { }; ### [ mrna ] => { results/gffread/GRCh38.p13/GRCh38.p13.mrna.txt }; ### [ rrna ] => { results/gffread/GRCh38.p13/GRCh38.p13.rrna.txt }. [2021-04-09 12:16:37.708] [alevinLog] [info] Found all transcripts to gene mappings; [2021-04-09 12:16:37.722] [alevinLog] [info] Processing barcodes files (if Present). [2021-04-09 12:16:37.728] [alevinLog] [info] Done barcode density calculation.; [2021-04-09 12:16:37.728] [alevinLog] [info] # Barcodes Used: 4000 / 4000.; [2021-04-09 12:16:37.729] [alevinLog] [info] Knee found left boundary at 102; [2021-04-09 12:16:37.862] [alevinLog] [info] Gauss Corrected Boundary at 52; [2021-04-09 12:16:37.862] [alevinLog] [info] Learned InvCov: 419.096 normfactor: 100.648; [2021-04-09 12:16:37.862] [alevinLog] [info] Total 195(has 201 low confidence) barcodes; [2021-04-09 12:16:37.883] [alevinLog] [info] Done True Barcode Sampling; [2021-04-09 12:16:37.884] [alevinLog] [info] Total 15.7% reads will be thrown away because of noisy Cellular barcodes.; [2021-04-09 12:16:37.892] [alevinLog] [info] Done populating Z matrix; [2021-04-09 12:16:37.892] [alevinLog] [info] Total 0 CB got sequence corrected; [2021-04-09 12:16:37.892] [alevinLog] [info] Done indexing Barcodes; [2021-04-09 12:16:37.892] [alevinLog] [info] Total Unique barcodes found: 822; [2021-04-09 12:16:37.892] [alevinLog] [info] Used Barcodes except Whitelist: 0; [2021-04-09 12:16:37.914] [alevinLog] [info] Done with Barcode Processing; Moving to Quantify. [2021-04-09 12:16:37.914] [alevinLog] [info] parsing read library format; [2021-04-09 12:16:37.914] [jointLog] [info] There is 1 library.; [2021-04-09 12:16:38.027] [jointLog] [info] Loading puffer,MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/647:3113,Learn,Learned,3113,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/647,1,['Learn'],['Learned']
Usability,"sue if you'd rather.~~. P.S. Nevermind; thanks to you mentioning this, I was able to track it down and fix it in develop!. > As I understand the selective alignment, the alignment scores are passed to the quantification step, but the position of the reads is not used downstream. . Well, yes and no. We make extensive use of the position when estimate the implied fragment length (distance between paired end reads) and then model the conditional probability of this fragment based on the global fragment length distribution. This is just as much as is done by e.g. RSEM. However, you are right that there is no notion of using the coverage profile in estimation (more on this below)!. > Also, my intuition for these transcripts is not really a coverage ""bias"" . My intuition agrees with yours here completely. First, this isn't really a coverage bias as we use the normal definition of the term. Second, the positional bias modeling in salmon is not on a per-transcript level (since that would be an astronomical number of different parameters to learn, and any procedure would almost certainly overfit). Instead, it groups transcripts into length bins, and learns a distinct coverage bias model per-bin. > It would be neat if Salmon could detect these kinds of dramatic dropoffs and add a warning or something... even if not incorporating the information into the quants... it could even be a good QC step to identify large deletions/insertions over a gene body. As far as I know, there are NO rnaseq quant programs that would handle this, because even something like a STAR -> RSEM pipeline just projects read counts to the transcriptome and doesn't incorporate the coverage information. These are **great** points! A couple of thoughts. First, you are right that salmon, RSEM, etc. don't use coverage information in the way you describe here. One piece of software you might look into is [Salmon Anomaly Detection](https://github.com/Kingsford-Group/sad) (paper [here](https://www.cell.com/cell-sy",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623047035:1464,learn,learn,1464,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623047035,2,['learn'],['learn']
Usability,"surprisingly, after building a salmon conda env, when building an index I got the following error:. `exception : [unrecognised option '--decoys']. Exiting.`. I then ran salmon index --help , and there was no -d/--decoys option. and; `salmon -v ` returned ; salmon 0.13.1. the tag on https://anaconda.org/bioconda/salmon , last uploaded a few months ago suggests it is for 1.10.2 , which is clearly not the case. not sure if this was done by someone other than any of the salmon developers, but it definitely creates headaches for groups trying to automate expression analysis workflows using snakemake/conda",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/895:390,clear,clearly,390,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/895,1,['clear'],['clearly']
Usability,"thanks. From: Rob Patro ***@***.***>; Reply-To: COMBINE-lab/salmon ***@***.***>; Date: Thursday, May 6, 2021 at 1:53 PM; To: COMBINE-lab/salmon ***@***.***>; Cc: ""andrew e. davidson"" ***@***.***>, Mention ***@***.***>; Subject: Re: [COMBINE-lab/salmon] salmon --writeUnmappedNames produced undocumented result (#657). Hi @aedavids<https://github.com/aedavids>,. Thanks for catching that this is undocumented! This means that the mapping type was determined as mapping to a decoy sequence. When we added this output into the code, the documentation wasn't updated accordingly. We'll update the documentation. Best,; Rob. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/COMBINE-lab/salmon/issues/657#issuecomment-833857753>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AN3VWAQ35L6PU3DKXYIM4ODTML6TPANCNFSM44HLOFXQ>.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/657#issuecomment-833861332:290,undo,undocumented,290,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/657#issuecomment-833861332,4,['undo'],['undocumented']
Usability,"the case for reads from unspliced pre-mRNAs that are even extending a small fraction into the introns (hence better scoring on the decoys). The 2 FASTQ files for one of the samples I was describing above can be found as R4171*.fastq.gz at this globus link: http://research.libd.org/globus/jhpce_bsp2-dlpfc/index.html. I used just the main chromosomes with Gencode v41 annotation (slightly ""curated"" to remove read-through and ""retained intron"" annotated transcripts). I am attaching 3 `meta_info.json` outputs for the 3 ways I ran salmon on this sample:. - [tx_only.meta_info.json.gz](https://github.com/COMBINE-lab/salmon/files/11006627/tx_only.meta_info.json.gz) : no decoys, **without** `--validateMappings`; - [gentrome_full.meta_info.json.gz](https://github.com/COMBINE-lab/salmon/files/11006628/gentrome_full.meta_info.json.gz) : with `--validateMappings`, decoys are full chromosome sequences appended to the transcripts file, ; - [gentrome_mashed.meta_info.json.gz](https://github.com/COMBINE-lab/salmon/files/11006629/gentrome_mashed.meta_info.json.gz) : with `--validateMappings`, decoys prepared with mashmap as instructed [here](https://github.com/COMBINE-lab/SalmonTools/blob/master/README.md). It would be great to be able to use Salmon's ""wicked fast"" mapping engine to estimate intronic and intergenic reads at the same time, so I'm considering to make better use of the `writeMappings` output for that purpose, by preparing the decoys in a specific way (extracting intronic and intergenic sequences as distinctively labeled decoys and count the mappings to each label from Salmon's SAM output -- would that work?). I am wondering, due to pre-mRNAs found in rRNA-depletion (ribo-zero) samples, it might be better to artifically add the unspliced transcripts into the mix along with the ""reference"" annotation transcripts, so they also get quantified during the EM-guided probabilistic distribution of reads across this mix of pre-mRNAs + mature RNAs in each locus.. What do you think?",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/779#issuecomment-1474451463:1938,guid,guided,1938,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/779#issuecomment-1474451463,2,['guid'],['guided']
Usability,"this tutorial](https://satijalab.org/seurat/articles/multimodal_vignette) up to the line where the `adt` assay is added and confirmed that the resulting object had two assays present. I think this may be a versioning issue related to what types of objects can be added into layers (aka slots) in a Seurat object. For reference, here are some details of the objects involved:; ```; > class(brain); [1] ""Seurat""; attr(,""package""); [1] ""SeuratObject""; > class(image.data); [1] ""VisiumV2""; attr(,""package""); [1] ""Seurat""; ```. It is worth noting that I installed Salmon using the docker image found [here](https://hub.docker.com/r/combinelab/salmon) approximately three months ago. The version number I see is `1.10.3`. Below is my sessionInfo output as well. My best guess is that I have to adjust the object type for `image.data` here to something that can be coerced into a slot in the `brain` Seurat object, but I am not sure what object that should be. Let me know if I am making a simple mistake here too, I am quite rusty with the nuances of R. Thank you for your consideration and I hope to hear from the team soon!. ```; > sessionInfo(); R version 4.3.3 (2024-02-29); Platform: x86_64-conda-linux-gnu (64-bit); Running under: Ubuntu 22.04.4 LTS. Matrix products: default; BLAS/LAPACK: /home/chris/anaconda3/envs/r_and_python/lib/libopenblasp-r0.3.27.so; LAPACK version 3.12.0. locale:; [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C ; [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 ; [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 ; [7] LC_PAPER=en_US.UTF-8 LC_NAME=C ; [9] LC_ADDRESS=C LC_TELEPHONE=C ; [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C . time zone: America/New_York; tzcode source: system (glibc). attached base packages:; [1] stats graphics grDevices utils datasets methods base . other attached packages:; [1] Seurat_5.1.0 SeuratObject_5.0.2 sp_2.1-4 patchwork_1.2.0 ; [5] ggplot2_3.5.1 devtools_2.4.5 usethis_2.2.3 tximport_1.30.0 ; [9] fishpond_2.8.0 . loaded via a namespace",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/942:1948,simpl,simple,1948,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/942,1,['simpl'],['simple']
Usability,"thubusercontent.com/10292386/86509800-6b8bdf80-bd9f-11ea-9a9f-bbfea99e2703.png); <img width=""485"" alt=""KCC4_table"" src=""https://user-images.githubusercontent.com/10292386/86509801-6d55a300-bd9f-11ea-9c69-8e269fc3ab1c.png"">. In this example, there are two regions in KCC4 with obviously different coverage. Ideally we would be able to have a default KCC4 transcript and a truncated isoform in the salmon index, and it would assign the reads appropriately, even though all of the reads that map to the truncated form would also multimap to the long form. Again, you can see in the table that salmon assigns reads parsimoniously to both transcripts with the default options, but with the length bias modeling turned off ALL of the reads are assigned to the long transcript. I also added a third transcript to the right end of the transcript which is inconsistent with the coverage profile and, as hoped, salmon did not assign any reads to that variant. So, in these two scenarios the default options produce nice results in line with our human intuition. 2. **Failure scenario with default options:** ; ![PDI1_example](https://user-images.githubusercontent.com/10292386/86509895-3df36600-bda0-11ea-8f0b-df0de4fefa31.png); <img width=""383"" alt=""PDI1_table"" src=""https://user-images.githubusercontent.com/10292386/86509897-40ee5680-bda0-11ea-9566-9f2bdab464f0.png"">. In this example there are four genes (oriented in the same direction) with wildly different expression levels. I added a ""PDI1_SuperTranscript"" which stretches from the 5' end of PDI1 to the 3' end of POF1 (so, all reads from all 4 genes would multimap to the super transcript). This is a contrived example to illustrate the technical details, but you could imagine similar biological scenarios, especially regarding splicing isoforms. With the default options, you get the counterintuitive result that all of the reads from just MGR1 and POF1 (the two lowest abundance transcripts) are assigned to the super transcript. EMC1 loses ~50% o",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-653747847:5122,intuit,intuition,5122,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-653747847,2,['intuit'],['intuition']
Usability,"together like --gcBias --seqBias --posBias, it completes fine. ~~Do you have a small example (ref / read pair) that reproduces this? It would be great to figure out why and fix it. We could split that into a new issue if you'd rather.~~. P.S. Nevermind; thanks to you mentioning this, I was able to track it down and fix it in develop!. > As I understand the selective alignment, the alignment scores are passed to the quantification step, but the position of the reads is not used downstream. . Well, yes and no. We make extensive use of the position when estimate the implied fragment length (distance between paired end reads) and then model the conditional probability of this fragment based on the global fragment length distribution. This is just as much as is done by e.g. RSEM. However, you are right that there is no notion of using the coverage profile in estimation (more on this below)!. > Also, my intuition for these transcripts is not really a coverage ""bias"" . My intuition agrees with yours here completely. First, this isn't really a coverage bias as we use the normal definition of the term. Second, the positional bias modeling in salmon is not on a per-transcript level (since that would be an astronomical number of different parameters to learn, and any procedure would almost certainly overfit). Instead, it groups transcripts into length bins, and learns a distinct coverage bias model per-bin. > It would be neat if Salmon could detect these kinds of dramatic dropoffs and add a warning or something... even if not incorporating the information into the quants... it could even be a good QC step to identify large deletions/insertions over a gene body. As far as I know, there are NO rnaseq quant programs that would handle this, because even something like a STAR -> RSEM pipeline just projects read counts to the transcriptome and doesn't incorporate the coverage information. These are **great** points! A couple of thoughts. First, you are right that salmon, RSEM, etc. ",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623047035:1182,intuit,intuition,1182,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623047035,2,['intuit'],['intuition']
Usability,"too many mismatches |	0; % of reads unmapped: too many mismatches |	0.00%; Number of reads unmapped: too short |	0; % of reads unmapped: too short |	0.00%; Number of reads unmapped: other |	4006; % of reads unmapped: other |	0.00%; CHIMERIC READS:; Number of chimeric reads |	0; % of chimeric reads |	0.00%; ```. It was really better but I am afraid that I have really low quality (I try the parameter 0.3 when I wrote these lines ), I filtered again with samtools -f 2 -F3840 and the salmon counts which is still very low : 24323720 counts. I used samtools flagstat to see what happens after the filter and we get this?; ```; 48983692 + 0 in total (QC-passed reads + QC-failed reads); 0 + 0 secondary; 0 + 0 supplementary; 0 + 0 duplicates; 48983692 + 0 mapped (100.00% : N/A); 48983692 + 0 paired in sequencing; 24491846 + 0 read1; 24491846 + 0 read2; 48983692 + 0 properly paired (100.00% : N/A); 48983692 + 0 with itself and mate mapped; 0 + 0 singletons (0.00% : N/A); 0 + 0 with mate mapped to a different chr; 0 + 0 with mate mapped to a different chr (mapQ>=5); ```. I don't understand why I'm losing so many counts, is it because I'm filtering? But still I have to filter to get the properly pairs... For the sorting it's totally my fault I read the doc wrong but even by not sorting I get very low results not usable less than 26%. The experimentation is done on oak, on 4 times 3 late samples and 3 early samples of dormancy were recovered and we made a TruSeq stranded illumina on these samples. I use a gene model built by my team with the 25808 genes that the oak has as reference. For this part ""Is this a polyA selection or ribosomal depletion prep"" I don't know, I'll find out. To be honest I am totally lost because I don't understand what's wrong in my analysis.... Thank you very much for your help once again . Kisekya. EDIT:. I discover that I have 59 millions of duplicates in my data...; I tried to delete it after filtering my proper pair I get bad records 38% of mapping ...",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/676#issuecomment-874540664:4711,usab,usable,4711,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/676#issuecomment-874540664,2,['usab'],['usable']
Usability,"top is what you get if you sum the abundances of these two transcripts. The main point is that the inferential relative variance (adjusted ratio of the variance over the mean) is _much_ smaller for the sum of these transcripts than for either individually. This is strong evidence that they are _inherently_ uncertain given the read evidence and alignments used for quantification. The tool described in that paper, called [`terminus`](https://github.com/COMBINE-lab/terminus), is a tool for automatically finding such groups of transcripts. Anyway, once you have the Gibbs samples in hand, we can walk you though how to do some assessment of these transcripts (tagging @hiraksarkar here since he's most likely to have access to scripts that will let us look at the posterior samples from individual transcripts). Similarly, if you can provide the quantification directory, we can help examine this too. If this is the case, that the posterior distributions are highly anti-correlated, it is likely that the ambiguity you are seeing is simply inherent given the alignments salmon is being provided. If you have the quantification folder resulting from the same sample using selective alignment, we could compare and contrast the two. At that point, there are a few options depending on how deeply you want to dive. You could try to see how STAR and selective alignment are mapping differently to these transcripts. One potential difference is that STAR is _a lot_ more happy to softclip reads, which selective alignment won't do by default (you can test the effect with the `--softclipOverhangs` to allow selective alignment to softclip reads that hang off the transcript end or `--softclip` to allow softclips anywhere). Note that selective alignment may _still_ be a bit more conservative than STAR about softclips simply because of the nature of the scoring function it uses. This might give you a sense if one of these alignment methodologies is more consistent with your expectations in this case",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/600#issuecomment-740363115:3086,simpl,simply,3086,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/600#issuecomment-740363115,2,['simpl'],['simply']
Usability,"tting the reads 50/50 or, with the default settings, giving nearly all the reads to the longer transcript. I realized that, as a human, the reason the short transcript is obviously the dominant one is how the reads pileup in the alignment. There are hundreds of reads mapping to both transcripts, but NO reads map to the 5' of the long transcript. As I understand the selective alignment, the alignment scores are passed to the quantification step, but the *position* of the reads is not used downstream. In order to pass my human intuition along here, the software would need to pay attention to the coverage bias of the reads mapping to the transcripts and assign a penalty when two otherwise identical transcripts have a different coverage variance across the transcript. This sounds like what the --posBias flag should incorporate into the effective lengths, but it doesn't have much effect on these transcripts for me (FYI, I am getting a segfault when I run only --posBias in the current salmon version, but if I run all the models together like --gcBias --seqBias --posBias, it completes fine). . Also, my intuition for these transcripts is not really a coverage ""bias"" as much as the read depth absolutely plummeting at the 5' end of the long transcript. It would be neat if Salmon could detect these kinds of dramatic dropoffs and add a warning or something... even if not incorporating the information into the quants... it could even be a good QC step to identify large deletions/insertions over a gene body. As far as I know, there are NO rnaseq quant programs that would handle this, because even something like a STAR -> RSEM pipeline just projects read counts to the transcriptome and doesn't incorporate the coverage information. So, for now my workaround is to just modify the transcripts so they are non-overlapping in the transcriptome fasta or to manually count reads after looking at the alignments, but I'd love to hear any more thoughts you have on this problem. Thanks,; Jason",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623043651:1631,intuit,intuition,1631,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/514#issuecomment-623043651,2,['intuit'],['intuition']
Usability,"ug primarily related to salmon (bulk mode) or alevin (single-cell mode)?**; salmon; **Describe the bug**; A clear and concise description of what the bug is.; The cDNA fasta file contains 176241 ENSTs,but the result file only contains 166667 ENSTs.; **To Reproduce**; Steps and data to reproduce the behavior:; The steps and data are as follows. ; Specifically, please provide at least the following information:. * Which version of salmon was used? v0.9.1; * How was salmon installed (compiled, downloaded executable, through bioconda)?; downloaded executable; * Which reference (e.g. transcriptome) was used? ; Homo_sapiens.GRCh38.cdna.all.fa obtained from Ensembl release 83; * Which read files were used? ; GSE41009; * Which which program options were used? ; Building index: salmon index -t filepath/Homo_sapiens.GRCh38.cdna.all.fa -i V83-homo_index --type quasi -k 31; Quantification: salmon quant -p 50 -i filepath/V83-homo_index -l IU -1 ESC-SRR574820_1.fastq ESC-SRR574821_1.fastq -2 ESC-SRR574820_2.fastq ESC-SRR574821_2.fastq -o ESC-quantification. **Expected behavior**; A clear and concise description of what you expected to happen.; The result file should contain all the ENSTs existed in cDNA fasta file.; **Screenshots**; If applicable, add screenshots or terminal output to help explain your problem. **Desktop (please complete the following information):**; - OS: [e.g. Ubuntu Linux, OSX]; - Version [ If you are on OSX, the output of `sw_vers`. If you are on linux the output of `uname -a` and `lsb_release -a`]; uname -a; Linux mn1 2.6.32-431.29.2.2.ky3.1.x86_64 #1 SMP Thu Sep 25 10:15:09 CST 2014 x86_64 x86_64 x86_64 GNU/Linux. lsb_release -a; LSB Version:	:base-4.0-amd64:base-4.0-noarch:core-4.0-amd64:core-4.0-noarch:graphics-4.0-amd64:graphics-4.0-noarch:printing-4.0-amd64:printing-4.0-noarch; Distributor ID:	NeoKylin; Description:	NeoKylin release 3.2 (Carambola); Release:	3.2; Codename:	Carambola; **Additional context**; Add any other context about the problem here.",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/255:1095,clear,clear,1095,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/255,1,['clear'],['clear']
Usability,"ulty of Arts & Sciences Informatics Group; Harvard University; 38 Oxford St; Cambridge, MA 02138; phone: +001 310 415 7145; ________________________________; From: Rob Patro ***@***.***>; Sent: Sunday, October 29, 2023 11:01 AM; To: COMBINE-lab/salmon ***@***.***>; Cc: Freedman, Adam ***@***.***>; Mention ***@***.***>; Subject: Re: [COMBINE-lab/salmon] anaconda version of salmon outdated, missing decoys option (Issue #895). Hi @adamfreedman<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_adamfreedman&d=DwMCaQ&c=WO-RGvefibhHBZq3fL85hQ&r=MITI_LEJgyr1a24IMFAlSaZIPxMpOUT21T7L3fg4CjA&m=40O3raH84f_BIZ3HF7nqTYSO2FehGrGHL9b7sqT7LIpWZjFmA3BLxNDTHoz420jp&s=kxY9gCLGWZJp-dp7l31S6M5u2RuUTeWXVrKmaydpo5o&e=>,. I think this is just conda being very very very slow (and potentially broken). The following works fine for me (and finishes in ~1 minute):. mamba create -n salmon -c conda-forge -c bioconda salmon=1.10.2. Can you use the mamba resolver in your environment? Conda has become hardly usable over the years, but mamba works quite well as a fast replacement. I'll also note that I swapped the order of conda-forge and bioconda as the docs specify that bioconda should preferably come last in the list of channels. --Rob. —; Reply to this email directly, view it on GitHub<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_COMBINE-2Dlab_salmon_issues_895-23issuecomment-2D1784137337&d=DwMCaQ&c=WO-RGvefibhHBZq3fL85hQ&r=MITI_LEJgyr1a24IMFAlSaZIPxMpOUT21T7L3fg4CjA&m=40O3raH84f_BIZ3HF7nqTYSO2FehGrGHL9b7sqT7LIpWZjFmA3BLxNDTHoz420jp&s=GNiCXqUbJLM16QBJ5PNAqv-rsgDdpCpcvezPXO_riWk&e=>, or unsubscribe<https://urldefense.proofpoint.com/v2/url?u=https-3A__github.com_notifications_unsubscribe-2Dauth_ADBMMUCOMVRRPOAZQL2EIITYBZVT5AVCNFSM6AAAAAA6UYYPGOVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTOOBUGEZTOMZTG4&d=DwMCaQ&c=WO-RGvefibhHBZq3fL85hQ&r=MITI_LEJgyr1a24IMFAlSaZIPxMpOUT21T7L3fg4CjA&m=40O3raH84f_BIZ3HF7nqTYSO2FehGrGHL9b7sqT7LIpWZjFmA3BLxNDTHoz420jp&s=54-iPwwQkGRgqbmGQptKb3",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/895#issuecomment-1784196835:1378,usab,usable,1378,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/895#issuecomment-1784196835,2,['usab'],['usable']
Usability,"um, eventually outputting the following after processing the reads:. ```; [2018-07-24 10:56:20.712] [jointLog] [info] Computed 9968 rich equivalence classes for further processing; [2018-07-24 10:56:20.712] [jointLog] [info] Counted 2785976 total reads in the equivalence classes; [2018-07-24 10:56:20.729] [jointLog] [warning] Only 2785976 fragments were mapped, but the number of burn-in fragments was set to 5000000.; The effective lengths have been computed using the observed mappings. [2018-07-24 10:56:20.729] [jointLog] [warning] Found 82730645 reads with CB+UMI length smaller than expected.Please report on github if this number is too large; [2018-07-24 10:56:20.729] [jointLog] [info] Mapping rate = 0.590918%. ```. and then this after processing the cells:; ```; [2018-07-24 10:56:23.180] [alevinLog] [info] Total 21135 UMI after deduplicating.; [2018-07-24 10:56:23.180] [alevinLog] [warning] Skipped 4 barcodes due to No mapped read; [2018-07-24 10:56:23.213] [alevinLog] [info] Clearing EqMap; Might take some time.; [2018-07-24 10:56:23.230] [alevinLog] [info] Starting Import of the gene count matrix.; [2018-07-24 10:56:23.743] [alevinLog] [info] Done Importing gene count matrix for dimension 290x57964; [2018-07-24 10:56:23.743] [alevinLog] [info] Starting dumping cell v gene counts in csv format; [2018-07-24 10:56:29.089] [alevinLog] [info] Finished dumping csv counts; [2018-07-24 10:56:29.089] [alevinLog] [info] Starting white listing; [2018-07-24 10:56:29.090] [alevinLog] [info] Done importing order of barcodes ""quants_mat_rows.txt"" file.; [2018-07-24 10:56:29.090] [alevinLog] [info] Total 290 barcodes found; [2018-07-24 10:56:29.090] [alevinLog] [warning] mrna file not provided; using is 1 less feature for whitelisting; [2018-07-24 10:56:29.090] [alevinLog] [warning] rrna file not provided; using is 1 less feature for whitelisting; [2018-07-24 10:56:29.090] [alevinLog] [info] Starting to make feature Matrix; [2018-07-24 10:56:29.354] [alevinLog] [info] Done maki",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/258:4747,Clear,Clearing,4747,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/258,1,['Clear'],['Clearing']
Usability,"undate}_${runid}_${indexpair}_quant`. Upon importing `quant.sf`files into R with `tximeta` and executing the function `summarizeToGene()` for` DESeq2` analysis I've been checking the validity of my top hits and have run into some confusion surrounding how to best handle counts assigned to an excessive number of alternate haplotypes/patches for some genes. These features have differing Ensembl gene IDs (but identical gene names) and are evidently not duplicate sequences as they have not been collapsed by salmon and differ in length. Gene counts are dispersed across different combinations of these haplotypes across samples, which isn't very amenable to gene level differential expression analysis. The KIR locus (which is notoriously confusing and full of differing gene content haplotypes) is of particular interest to us and influenced precisely by this issue. As shown below, there are 34 versions of _KIR3DL2_ assigned gene counts across our samples:. `> rowRanges(gse)[grep(""KIR3DL2"", rowRanges(gse)$gene_name)]`; [KIR3DL2.txt](https://github.com/COMBINE-lab/salmon/files/4883051/KIR3DL2.txt). The salmon counts look like this:; `assays(gse)$counts[grep(""KIR3DL2"", rowRanges(gse)$symbol),][,1:5]`; [counts.txt](https://github.com/COMBINE-lab/salmon/files/4883045/counts.txt). There are around 500 other genes in which this occurs also (including all KIRs and HLAs), with no clear ""dominant"" haplotype to which the majority of reads are assigned for a given sample. Are there any suggestions as to how to progress here? Is it completely unreasonable for me to sum the counts across all haplotypes for a given gene prior to carrying on with `DESeq2`? I'm wary there could be issues with concatenating features with differing lengths, GC content etc. and subsequent normalisation. Is there an upstream step with salmon that could be used to provided summed gene level counts across all haplotypes? Should I use a different reference?. Any help would be much appreciated!. Kind regards,; Aimee",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/544:1961,clear,clear,1961,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/544,1,['clear'],['clear']
Usability,"vin (single-cell mode)?**; Alevin; **Describe the bug**; A clear and concise description of what the bug is.; Reanalyzing published Drop-Seq data the alevin analysis results in drastically fewer barcodes accepted than the published dataset. Published dataset contains 3000 CBs for the specific sample (authors report that 70% of [these] putative cells from WT mice met QC criteria), alevin result contains 459 CBs.; A similar highly abbreviated CB result was obtained with reanalysis of SRR8889412. **To Reproduce**; Steps and data to reproduce the behavior:. Data used from Sample: https://www.ebi.ac.uk/ena/browser/view/SRR8889411; Publication: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6925218/#; Specific Sample: https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSM3720936. Alevin was run using no special parameters with the --dropseq flags. The only significant protocol deviation was in index construction (see below). Specifically, please provide at least the following information:. * Which version of salmon was used?; v1.4.0; * How was salmon installed (compiled, downloaded executable, through bioconda)?; Salmon was run in stock docker container; * Which reference (e.g. transcriptome) was used?; Full decoy Index generated on Gencode M25 per Alevin Velocity tutorial with a k=17 (dataset has 50bp R2 Reads); Introns were extracted with 49bp flanking sequence. ; ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M25/gencode.vM25.annotation.gtf.gz. * Which read files were used?; Data used from Sample: https://www.ebi.ac.uk/ena/browser/view/SRR8889411; * Which which program options were used?; --dropseq -l ISR. **Expected behavior**; A clear and concise description of what you expected to happen.; Cell calls should be ballpark similar to published result (3000 original vs. 459 alevin). **Tar of Alevin Output directory**; [WT01_P7_WT_Cerebellum_alevin.output.tar.gz](https://github.com/COMBINE-lab/salmon/files/5953855/WT01_P7_WT_Cerebellum_alevin.output.tar.gz)",MatchSource.ISSUE,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/625:1730,clear,clear,1730,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/625,1,['clear'],['clear']
Usability,"w/o any modification to the fastq on both of your sample to generate the gene count matrices. I already did that, in downstream analyses I have a batch effect issue related to the sequencing depth. >that's why we recommend using the Seurat package downstream of the Alevin quantified matrices. I have some experience with downstream analyses with Seurat, Pagoda, Scater, scanpy and a few other tools, and I am aware of batch correction methods like CCA or MNN. But that is not what I am looking for here. I did both CCA and MNN but I loose some important information in the resulting eigenspaces or corrected matrix. I believe the proper way to correct my batch effect is to simply fix the difference between my two libraries, ie. the sequencing depth in this case. As I explained in my first message, cellranger aggregate (subsampling based on the amount of mapped reads) works very well in my case, correct the effect without any loss or modification of important genes in our scientific question. Not CCA or MNN. I would like to be able to do the same from the alevin quantifications. So I am looking for a proper way to apply a correction before/during/after the alevin quantification, in a way similar to what cellranger do with STAR. Alternatively, could a subsampling covariate be added to the probalistic quantification model of alevin (if I understand it well), in sort that such a discrepency bewteen samples would be corrected?. I did look at the mappedUMI file:. ![image](https://user-images.githubusercontent.com/34892073/47551835-85ef9380-d903-11e8-893f-2a684576437b.png). So an option you would recommend is to simply compute the subsampling coefficient for a median ratio bewteen samples? I am expecting quite uneven distributions/variance in the mappedUMI between samples (partly due to a huge difference in term of proliferation that occur with a fraction of cells in only one sample). Still, cellranger aggregate correct it nicely. Thanks again for your prompt answer and comments.",MatchSource.ISSUE_COMMENT,COMBINE-lab,salmon,v1.10.1,https://github.com/COMBINE-lab/salmon/issues/305#issuecomment-433319913:2562,simpl,simply,2562,https://combine-lab.github.io/salmon,https://github.com/COMBINE-lab/salmon/issues/305#issuecomment-433319913,2,['simpl'],['simply']
