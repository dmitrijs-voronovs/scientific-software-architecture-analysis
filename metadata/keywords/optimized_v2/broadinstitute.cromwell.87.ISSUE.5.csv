quality_attribute,sentence,source,author,repo,version,id,keyword,matched_word,match_idx,wiki,url,total_similar,target_keywords,target_matched_words
Integrability,Womtool: Flag to list workflow dependencies (Approach 2) [BA-3501],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5098:31,depend,dependencies,31,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5098,1,['depend'],['dependencies']
Integrability,Womtool: Flag to list workflow dependencies [BA-3501],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5073:31,depend,dependencies,31,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5073,1,['depend'],['dependencies']
Integrability,Won't go green until https://github.com/broadinstitute/wdl4s/pull/67. Includes better error messages and halting failure for RuntimeExceptions during expression evaluation.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1863:92,message,messages,92,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1863,1,['message'],['messages']
Integrability,"WorkerThread.java:107); [2016-10-27 13:10:46,94] [info] Waiting for 1 workflows to abort...; [2016-10-27 13:10:47,94] [info] Waiting for 1 workflows to abort...; [2016-10-27 13:10:48,94] [info] Waiting for 1 workflows to abort...; [2016-10-27 13:10:49,94] [info] Waiting for 1 workflows to abort...; [2016-10-27 13:10:50,94] [info] Waiting for 1 workflows to abort...; ^C[2016-10-27 13:10:51,94] [info] Waiting for 1 workflows to abort...; [2016-10-27 13:10:52,94] [info] Waiting for 1 workflows to abort...; [2016-10-27 13:10:53,94] [info] Waiting for 1 workflows to abort...; [2016-10-27 13:10:54,94] [info] Waiting for 1 workflows to abort...; [2016-10-27 13:10:55,94] [info] Waiting for 1 workflows to abort...; [2016-10-27 13:10:56,94] [info] Waiting for 1 workflows to abort...; [2016-10-27 13:10:57,16] [error] Exception not convertible into handled response; com.google.api.client.googleapis.json.GoogleJsonResponseException: 404 Not Found; {; ""code"" : 404,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Not Found"",; ""reason"" : ""notFound""; } ],; ""message"" : ""Not Found""; }; at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145); at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113); at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:432); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469); at com.google.cloud.hadoop.util.AbstractGoogleAsyncWriteChannel$UploadOperation.call(AbstractGoogleAsyncWriteChannel.java:357); at jav",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1631:17231,message,message,17231,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1631,2,['message'],['message']
Integrability,"WorkflowDescriptorActor.scala:491)""; },; {; causedBy: [ ],; message: ""scala.util.Either.flatMap(Either.scala:338)""; },; {; causedBy: [ ],; message: ""cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.validateWdlNamespace(MaterializeWorkflowDescriptorActor.scala:490)""; },; {; causedBy: [ ],; message: ""cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$lifecycle$materialization$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor(MaterializeWorkflowDescriptorActor.scala:231)""; },; {; causedBy: [ ],; message: ""cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$1.$anonfun$applyOrElse$1(MaterializeWorkflowDescriptorActor.scala:157)""; },; {; causedBy: [ ],; message: ""scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:304)""; },; {; causedBy: [ ],; message: ""scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37)""; },; {; causedBy: [ ],; message: ""scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60)""; },; {; causedBy: [ ],; message: ""akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55)""; },; {; causedBy: [ ],; message: ""akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91)""; },; {; causedBy: [ ],; message: ""scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)""; },; {; causedBy: [ ],; message: ""scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81)""; },; {; causedBy: [ ],; message: ""akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:91)""; },; {; causedBy: [ ],; message: ""akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40)""; },; {; causedBy: [ ],; message: ""akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:43)""; },; {; causedBy: [ ],; message: ""akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)""; },; {; causedB",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3143:2679,message,message,2679,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3143,1,['message'],['message']
Integrability,"WorkflowStoreActor stopped; [2018-09-14 13:20:05,36] [info] Shutting down JobExecutionTokenDispenser - Timeout = 5 seconds; [2018-09-14 13:20:05,39] [info] JobExecutionTokenDispenser stopped; [2018-09-14 13:20:05,40] [info] WorkflowLogCopyRouter stopped; [2018-09-14 13:20:05,40] [info] Shutting down WorkflowManagerActor - Timeout = 3600 seconds; [2018-09-14 13:20:05,40] [info] WorkflowManagerActor All workflows finished; [2018-09-14 13:20:05,40] [info] WorkflowManagerActor stopped; [2018-09-14 13:20:05,40] [info] Connection pools shut down; [2018-09-14 13:20:05,41] [info] Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds; [2018-09-14 13:20:05,41] [info] Shutting down JobStoreActor - Timeout = 1800 seconds; [2018-09-14 13:20:05,41] [info] SubWorkflowStoreActor stopped; [2018-09-14 13:20:05,41] [info] Shutting down CallCacheWriteActor - Timeout = 1800 seconds; [2018-09-14 13:20:05,41] [info] Shutting down ServiceRegistryActor - Timeout = 1800 seconds; [2018-09-14 13:20:05,42] [info] Shutting down DockerHashActor - Timeout = 1800 seconds; [2018-09-14 13:20:05,42] [info] JobStoreActor stopped; [2018-09-14 13:20:05,42] [info] Shutting down IoProxy - Timeout = 1800 seconds; [2018-09-14 13:20:05,42] [info] CallCacheWriteActor Shutting down: 0 queued messages to process; [2018-09-14 13:20:05,42] [info] WriteMetadataActor Shutting down: 0 queued messages to process; [2018-09-14 13:20:05,43] [info] CallCacheWriteActor stopped; [2018-09-14 13:20:05,43] [info] DockerHashActor stopped; [2018-09-14 13:20:05,43] [info] IoProxy stopped; [2018-09-14 13:20:05,43] [info] KvWriteActor Shutting down: 0 queued messages to process; [2018-09-14 13:20:05,43] [info] ServiceRegistryActor stopped; [2018-09-14 13:20:05,47] [info] Database closed; [2018-09-14 13:20:05,47] [info] Stream materializer shut down; [2018-09-14 13:20:05,48] [info] WDL HTTP import resolver closed; Workflow caab4283-a3d4-4966-85ba-56d0992c8f00 transitioned to state Failed; (p3cwl) [jeremiah@localhost ~]$ ; ```.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4103:9787,message,messages,9787,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4103,3,['message'],['messages']
Integrability,"Would it be possible to make cromwell available as a maven dependency?. There are a lot of very useful utilities with regards to `wdl` parsing etc. It would be amazing to build homegrown tools around this ecosystem, and also to contribute back missing parts / useful additions to workflow management in general. I think in particular taking into consideration the complexity of parsing the wdl language, this would be extremely helpful!. Thanks anyways for this amazing tool and wish you all a great weekend!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6543:59,depend,dependency,59,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6543,1,['depend'],['dependency']
Integrability,Wrap ask errors from WSCWA to avoid ClassCastException.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3826:0,Wrap,Wrap,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3826,2,['Wrap'],['Wrap']
Integrability,Wrap hash values from cromwell-backend,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/457:0,Wrap,Wrap,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/457,1,['Wrap'],['Wrap']
Integrability,Wrap test in eventually to make sure metadata of workflow is flushed before we ask for it. This changed a bit when we set the default batch size from 1 -> 200,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2395:0,Wrap,Wrap,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2395,1,['Wrap'],['Wrap']
Integrability,"Yesterday there was a config change that targeted the /stats endpoint rather than /status to assess Cromwell vitality. Unfortunately this accidentally seems to have DOSed Cromwell and produced tons of messages like the following in the logs. Cromwell effectively locked up and needed a hard restart to recover. I don't think the rate at which /stats was called was excessively high. The counting mechanism is apparently sending messages around to the whole graph of execution actors when it seems like a more efficient means of answering the stats question should be possible. Even if turns out a more efficient calculation isn't possible, the current system doesn't appear to be taking sub workflow actors into account correctly and I don't even know how the MWDA and WIA got caught up in this. ```; WARN c.e.w.l.e.SubWorkflowExecutionActor - unhandled event JobCountQuery in state SubWorkflowRunningState; ```. ```; WARN c.e.w.l.m.MaterializeWorkflowDescriptorActor - MaterializeWorkflowDescriptorActor [UUID(XXXXX)]: received an unhandled message Event(JobCountQuery,()) in state MaterializingState; ```. ```; WARN c.e.w.l.i.WorkflowInitializationActor - WorkflowInitializationActor-XXXXX [UUID(XXXXX)]: received an unhandled message: Event(JobCountQuery,WorkflowLifecycleActorData(Set(Actor[XXXXX]),List(),Map(),List())); ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3683:201,message,messages,201,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3683,4,['message'],"['message', 'messages']"
Integrability,Your FOSSA integration was successful! Attached in this PR is a badge and license report to track scan status in your README. Below are docs for integrating FOSSA license checks into your CI:. - [CircleCI](http://fossa.io/docs/integrating-tools/circleci/); - [TravisCI](http://fossa.io/docs/integrating-tools/travisci/); - [Jenkins](https://github.com/fossas/fossa-jenkins-plugin); - [Other](https://github.com/fossas/license-cli),MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3471:11,integrat,integration,11,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3471,4,['integrat'],"['integrating', 'integrating-tools', 'integration']"
Integrability,[28 Hotfix] Return better 404 message when calls can't be found,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2407:30,message,message,30,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2407,1,['message'],['message']
Integrability,[30_hotfix] Treat a message 13 as premptible when the VM is preemptible (#3162),MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3163:20,message,message,20,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3163,1,['message'],['message']
Integrability,[34] Catch other message type when cache copy fails,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3997:17,message,message,17,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3997,1,['message'],['message']
Integrability,[52 Hotfix] Give the IoClientHelper a chance to interpret messages before running our FSM specific logic [BA-6524],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5593:58,message,messages,58,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5593,1,['message'],['messages']
Integrability,[53 hotfix] GcsBatchFlow should be resilient to exceptions with null error message happening on attempt to execute GCS batch request [BW-411],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5998:75,message,message,75,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5998,1,['message'],['message']
Integrability,[CI branch for #5232] Changed protocol for jcenter.bintray.com repo from http to https [BA-6055],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5233:30,protocol,protocol,30,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5233,1,['protocol'],['protocol']
Integrability,[Develop] Return better 404 message when calls can't be found,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2406:28,message,message,28,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2406,1,['message'],['message']
Integrability,"[Disclaimer]; This ~~heavily~~ lacks unit ~~and integration~~ testing.; See ~~https://github.com/broadinstitute/cromwell/issues/4010~~, https://github.com/broadinstitute/cromwell/issues/4009, ~~https://github.com/broadinstitute/cromwell/issues/4007~~. Edit: ; - Closed 4010 after new tests were added for the ftp impl of cloud nio. The core cloud nio code is still largely untested so leaving 4009 open.; - CWL conformance tests can be run on Travis as a CRON job once this PR is merged, which should be enough for 4007. ---. I tried to split commits by general topics if that helps...; Contains:; - The ~woodward~ [Woodard](https://en.wikipedia.org/wiki/Alfre_Woodard) abstraction; - An FTP implementation of the abstraction (more on that below); - Changes to the TES backend to accommodate for other filesystems than SFS; - Configurable glob command (the one that links files to be globbed into a directory); - Setup for testing the cwl conformance suite on Travis. ~~Disabled because it would very likely fail most of the time since I doubt the FTP server we have could handle concurrent travis runs.~~ (now as a CRON job). Since FTP inherently does not allow parallelism and concurrent requests, it is necessary to create as many connections as concurrent requests we want. Because most ftp servers will limit the number of concurrent connections, the FTP implementation pools FTP clients and reuses them across async operations in Cromwell. That's the reason for all the pooling logic. Threads in need of a client when the pool is empty will block until they can get one.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4008:48,integrat,integration,48,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4008,1,['integrat'],['integration']
Integrability,"[Jira issue](https://broadworkbench.atlassian.net/browse/BA-5943). Using Cromwell 44 and PAPI v2, occasionally machines in GCE are preempted but not handled as such. Metadata snippet:. ```; ""failures"": [; {; ""causedBy"": [],; ""message"": ""Task test_combine.combine:NA:1 failed. The job was stopped before the command finished. PAPI error code 10. The assigned worker has failed to complete the operation""; }; ],; ""jobId"": ""projects/finngen-refinery-dev/operations/18318369325465658337"",; ""backend"": ""PAPIv2"",; ""end"": ""2019-08-20T14:54:37.214Z"",; ```. Stackdriver log snippet:. ```; {; ""insertId"": ""15cmu2qg1chkm09"",; ""jsonPayload"": {; ""event_timestamp_us"": ""1566312261571808"",; ""actor"": {; ""user"": ""system""; },; ""resource"": {; ""name"": ""google-pipelines-worker-6eba778d59d69dcfe9189620b91117c5"",; ""type"": ""instance"",; ""zone"": ""europe-west1-b"",; ""id"": ""1966470788939888666""; },; ""trace_id"": ""systemevent-1566312254625-5908d7d8b55f5-68011c08-d6e13e66"",; ""event_type"": ""GCE_OPERATION_DONE"",; ""operation"": {; ""id"": ""1400679280860576170"",; ""name"": ""systemevent-1566312254625-5908d7d8b55f5-68011c08-d6e13e66"",; ""type"": ""operation"",; ""zone"": ""europe-west1-b""; },; ""event_subtype"": ""compute.instances.preempted"",; ""info"": [; {; ""code"": ""STATUS_MESSAGE"",; ""detail_message"": ""Instance was preempted.""; }; ],; ""version"": ""1.2""; },; ```. Although this happens rarely, it causes large workflows to fail and we'd like to avoid rerunning such workflows because at scale other issues may arise with e.g. call caching timeouts, and things are more manageable without otherwise unnecessary reruns. Any help would be much appreciated!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5136:226,message,message,226,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5136,1,['message'],['message']
Integrability,[LCM] Backend interface definition,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/550:14,interface,interface,14,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/550,1,['interface'],['interface']
Integrability,[No Ticket] Bump dependencies,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6285:17,depend,dependencies,17,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6285,1,['depend'],['dependencies']
Integrability,"[Per @mbookman]; This pull request is an initial update to address:. CROM-6718: FR: Add flag for minimizing chance of GCP cross-region network egress charges being incurred. This PR specifically focuses on the risks of egress charges incurred due to call caching. The framing of the approach here, which is a bit broader than originally noted in CROM-6718, is:; Make call caching location-aware, prioritizing copies that minimize egress charges.; Add a workflow option enabling control of what egress charges can be incurred for call cache copying.; The new workflow option would be:. call_cache_egress: [none, continental, global]. where the values affect whether call cache copies can incur egress charges:; none: only within-region copies are allowed, which generate no egress charges; continental: within content copies are allowed; within-content copies have reduced costs, such as $0.01 / GB in the US; global: copies across all regions are allowed. Cross-content egress charges can be much higher (ranging from $0.08 / GB up to $0.23 / GB). ### CURRENT STATUS OF PR:; These first few commits are a WIP/request for feedback. I would love discussion on what the best approach would be. The idea for this initial approach is to raise an exception right before copying cached outputs if the bucket locations would cause an egress charge (depending on workflow option). The CallCacheJobActor continue attempting to copy outputs until it finds one that doesn't cause an egress charge (depending on workflow option), or until it determines cache miss. . If the above approach is reasonable then I would need coding advice on:; 1) How do I properly use GcsBatchCommandBuilder.locationCommand (or something similar) in the CacheHitCopyingActor?; 2) How do I properly get the WorkflowOption CallCacheEgress in the CacheHitCopyingActor?",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6324:1341,depend,depending,1341,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6324,2,['depend'],['depending']
Integrability,[Test Reliability] Better message around StatsDInstrumentationSpec failures,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4387:26,message,message,26,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4387,1,['message'],['message']
Integrability,"[The ticket](https://broadworkbench.atlassian.net/browse/DDO-2190) has a ton more info and I talked with @aednichols about this--the short version is:; - Whatever is doing the HTTP request to Cromwell (Akka?) does not set the Host header ([per MDN](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Host)) if it has been customized beforehand; - We've accidentally been doing that by copying the _request's_ headers that came into CromIAM, which obviously include the Host header correlating to CromIAM itself; - Thus CromIAM sends requests to Cromwell with an incorrect Host header; - This hasn't mattered before because Cromwell's Layer 4 load balancer doesn't care and Cromwell's Apache proxy didn't actually need to do host-based routing because it just forwards everything to one app, Cromwell; - This suddenly matters a lot now because BEEs use an Nginx controller for ingress instead of a GCP Layer 4 load balancer, and _it_ needs to use host-based routing; - TL;DR: CromIAM is proxying to Cromwell wrong-ish and it very much does not work in BEEs. Solution: strip out the Host header just like CromIAM already does for Timeout-Access, and everything is happy. The impact to live environments should be zero because they clearly didn't care about the header before. If this fails anywhere, Argo sees the failure immediately like it did for BEEs, and it sees it in a way that any deployment or promotion would be halted because CromIAM would fail to come online from Argo's perspective.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6803:742,rout,routing,742,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6803,2,['rout'],['routing']
Integrability,[WM-2291] Callback API contract tests between Cromwell and CBAS,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7251:23,contract,contract,23,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7251,1,['contract'],['contract']
Integrability,[WM-2555] Cromwell -> ECM contract test,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7405:26,contract,contract,26,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7405,1,['contract'],['contract']
Integrability,"[WX-1107](https://broadworkbench.atlassian.net/browse/WX-1107?atlOrigin=eyJpIjoiNTM5ZGY2MzMyYWM5NGE2MThjMzg3NDAzOTY0YjZmMzYiLCJwIjoiaiJ9). One of our Integration Tests was failing due to a python dependency issue described [here](https://github.com/docker/docker-py/issues/3113). Long story short, using an older version of `requests` is a workaround to an issue that exists in the python `docker` package. Until that package gets updated, our script will fail due to the docker library passing an invalid argument to the requests library. . This fix forces the github runner that is running the HoricromtalDeadlock test to downgrade its `requests` package, resolving the issue. This change will not affect anything other than that one test. . [WX-1107]: https://broadworkbench.atlassian.net/browse/WX-1107?atlOrigin=eyJpIjoiNWRkNTljNzYxNjVmNDY3MDlhMDU5Y2ZhYzA5YTRkZjUiLCJwIjoiZ2l0aHViLWNvbS1KU1cifQ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7131:150,Integrat,Integration,150,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7131,2,"['Integrat', 'depend']","['Integration', 'dependency']"
Integrability,[WX-1361] Remove Confusing Error Message,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7449:33,Message,Message,33,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7449,1,['Message'],['Message']
Integrability,[WX-1782] Cloud Billing Dependency + Updates,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7490:24,Depend,Dependency,24,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7490,1,['Depend'],['Dependency']
Integrability,"[WX-968](https://broadworkbench.atlassian.net/browse/WX-968). - Gave Centaur the ability to authenticate with Azure Blob Storage and count files at a particular path. ; - Added file counting to our single, lonely, overworked, and under-appreciated azure integration test. . I'm new to Scala. Please feel free to be pedantic and nitpicky in your comments! . [WX-968]: https://broadworkbench.atlassian.net/browse/WX-968?atlOrigin=eyJpIjoiNWRkNTljNzYxNjVmNDY3MDlhMDU5Y2ZhYzA5YTRkZjUiLCJwIjoiZ2l0aHViLWNvbS1KU1cifQ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7104:254,integrat,integration,254,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7104,1,['integrat'],['integration']
Integrability,[develop edition] GcsBatchFlow should be resilient to exceptions with null error message happening on attempt to execute GCS batch request [BW-411],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5994:81,message,message,81,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5994,1,['message'],['message']
Integrability,"[info] Shutting down WorkflowLogCopyRouter - Timeout = 5 seconds; [2018-08-30 17:53:41,15] [info] Shutting down JobExecutionTokenDispenser - Timeout = 5 seconds; [2018-08-30 17:53:41,15] [info] JobExecutionTokenDispenser stopped; [2018-08-30 17:53:41,17] [info] WorkflowLogCopyRouter stopped; [2018-08-30 17:53:41,17] [info] Shutting down WorkflowManagerActor - Timeout = 3600 seconds; [2018-08-30 17:53:41,17] [info] WorkflowManagerActor All workflows finished; [2018-08-30 17:53:41,17] [info] WorkflowManagerActor stopped; [2018-08-30 17:53:41,17] [info] Connection pools shut down; [2018-08-30 17:53:41,18] [info] Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds; [2018-08-30 17:53:41,18] [info] SubWorkflowStoreActor stopped; [2018-08-30 17:53:41,18] [info] Shutting down JobStoreActor - Timeout = 1800 seconds; [2018-08-30 17:53:41,18] [info] Shutting down CallCacheWriteActor - Timeout = 1800 seconds; [2018-08-30 17:53:41,19] [info] CallCacheWriteActor Shutting down: 0 queued messages to process; [2018-08-30 17:53:41,19] [info] CallCacheWriteActor stopped; [2018-08-30 17:53:41,18] [info] Shutting down ServiceRegistryActor - Timeout = 1800 seconds; [2018-08-30 17:53:41,19] [info] Shutting down DockerHashActor - Timeout = 1800 seconds; [2018-08-30 17:53:41,19] [info] KvWriteActor Shutting down: 0 queued messages to process; [2018-08-30 17:53:41,19] [info] WriteMetadataActor Shutting down: 0 queued messages to process; [2018-08-30 17:53:41,19] [info] DockerHashActor stopped; [2018-08-30 17:53:41,19] [info] Shutting down IoProxy - Timeout = 1800 seconds; [2018-08-30 17:53:41,19] [info] JobStoreActor stopped; [2018-08-30 17:53:41,19] [info] IoProxy stopped; [2018-08-30 17:53:41,19] [info] ServiceRegistryActor stopped; [2018-08-30 17:53:41,23] [info] Database closed; [2018-08-30 17:53:41,23] [info] Stream materializer shut down; [2018-08-30 17:53:41,29] [info] Automatic shutdown of the async connection; [2018-08-30 17:53:41,29] [info] Gracefully shutdown sentry thread",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4062:5718,message,messages,5718,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4062,1,['message'],['messages']
Integrability,"] Shutting down CallCacheWriteActor - Timeout = 1800 seconds; [2018-08-30 17:53:41,19] [info] CallCacheWriteActor Shutting down: 0 queued messages to process; [2018-08-30 17:53:41,19] [info] CallCacheWriteActor stopped; [2018-08-30 17:53:41,18] [info] Shutting down ServiceRegistryActor - Timeout = 1800 seconds; [2018-08-30 17:53:41,19] [info] Shutting down DockerHashActor - Timeout = 1800 seconds; [2018-08-30 17:53:41,19] [info] KvWriteActor Shutting down: 0 queued messages to process; [2018-08-30 17:53:41,19] [info] WriteMetadataActor Shutting down: 0 queued messages to process; [2018-08-30 17:53:41,19] [info] DockerHashActor stopped; [2018-08-30 17:53:41,19] [info] Shutting down IoProxy - Timeout = 1800 seconds; [2018-08-30 17:53:41,19] [info] JobStoreActor stopped; [2018-08-30 17:53:41,19] [info] IoProxy stopped; [2018-08-30 17:53:41,19] [info] ServiceRegistryActor stopped; [2018-08-30 17:53:41,23] [info] Database closed; [2018-08-30 17:53:41,23] [info] Stream materializer shut down; [2018-08-30 17:53:41,29] [info] Automatic shutdown of the async connection; [2018-08-30 17:53:41,29] [info] Gracefully shutdown sentry threads.; [2018-08-30 17:53:41,29] [info] Shutdown finished.; ```; Command-line tools are subject to usability standards identical to those of our other user interfaces. Unless the intended audience of this tool is Cromwell engineers, the class names in the above output are misleading. For example, in the line:; ```; CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; ```; a user may want to investigate the terms ""batch size"" and ""process rate"" through the documentation or forums, which will likely have meaning. CallCacheWriteActor, on the other hand, is likely an implementation detail that probably adds confusion rather than clarity. hello_world_0.wdl:; ```wdl; workflow HelloWorld {. 	call WriteGreeting; }. task WriteGreeting {. 	command {; 		echo ""Hello World""; 	}; 	output {; 		File outfile = stdout(); 	}; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4062:6875,interface,interfaces,6875,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4062,1,['interface'],['interfaces']
Integrability,"_This issue may just be around the error reporting, rather than an actual bug_; - develop branch (post-0.22); - local backend; - yes docker; - single workflow mode. What do the Job Execution errors mean? I _think_ this happens when there is an issue with the docker image, but I have not confirmed. Regardless, the error message is not very useful to an end user. And it makes the actual error harder to find. ```; [2016-10-23 01:54:34,66] [error] Actor Actor[akka://cromwell-system/user/SingleWorkflowRunnerActor/WorkflowManagerActor/WorkflowActor-54e13b6c-33e4-4777-a4bd-f7b2876c2df5/WorkflowExecutionActor-54e13b6c-33e4-4777-a4bd-f7b2876c2df5/54e13b6c-33e4-4777-a4bd-f7b2876c2df5-EngineJobExecutionActor-crsp_validation_workflow.clinical_sensitivity_run_create_seg_gt_table:0:1#-1129669881] stopped without returning its Job Execution Token. Reclaiming it!; [2016-10-23 01:54:34,66] [error] Actor Actor[akka://cromwell-system/user/SingleWorkflowRunnerActor/WorkflowManagerActor/WorkflowActor-54e13b6c-33e4-4777-a4bd-f7b2876c2df5/WorkflowExecutionActor-54e13b6c-33e4-4777-a4bd-f7b2876c2df5/54e13b6c-33e4-4777-a4bd-f7b2876c2df5-EngineJobExecutionActor-crsp_validation_workflow.purity_run_create_seg_gt_table:4:1#1335133828] stopped without returning its Job Execution Token. Reclaiming it!; [2016-10-23 01:54:34,66] [error] Actor Actor[akka://cromwell-system/user/SingleWorkflowRunnerActor/WorkflowManagerActor/WorkflowActor-54e13b6c-33e4-4777-a4bd-f7b2876c2df5/WorkflowExecutionActor-54e13b6c-33e4-4777-a4bd-f7b2876c2df5/54e13b6c-33e4-4777-a4bd-f7b2876c2df5-EngineJobExecutionActor-crsp_validation_workflow.clinical_sensitivity_run_create_seg_gt_table:2:1#276570369] stopped without returning its Job Execution Token. Reclaiming it!; [2016-10-23 01:54:34,66] [error] Actor Actor[akka://cromwell-system/user/SingleWorkflowRunnerActor/WorkflowManagerActor/WorkflowActor-54e13b6c-33e4-4777-a4bd-f7b2876c2df5/WorkflowExecutionActor-54e13b6c-33e4-4777-a4bd-f7b2876c2df5/54e13b6c-33e4-4777-a4bd-f7b2876c2d",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1612:321,message,message,321,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1612,1,['message'],['message']
Integrability,"_cnloh_dir"": ""splits/"",; ""case_gatk_acnv_workflow.seg_param_eta"": 0.05,; ""case_gatk_acnv_workflow.seg_param_trim"": 0.025,; ""case_gatk_acnv_workflow.plots_dir"": ""plots/"",; ""case_gatk_acnv_workflow.seg_param_pmethod"": ""HYBRID"",; ""case_gatk_acnv_workflow.seg_param_nperm"": 10000,; ""case_gatk_acnv_workflow.PoN"": ""/data/ice_rcs_eval.v1.pd250.spark.pon"",; ""case_gatk_acnv_workflow.input_bam_list"": ""/home/lichtens/eval-gatk-protected/scripts/crsp_validation/crsp_validation_bam_list_local_paths.txt"",; ""case_gatk_acnv_workflow.ref_fasta"": ""/data/ref/Homo_sapiens_assembly19.fasta"",; ""case_gatk_acnv_workflow.enable_gc_correction"": true,; ""case_gatk_acnv_workflow.wgsBinSize"": 10000,; ""case_gatk_acnv_workflow.seg_param_undoPrune"": 0.05,; ""case_gatk_acnv_workflow.gatk_jar"": ""/root/gatk-protected.jar"",; ""case_gatk_acnv_workflow.seg_param_nmin"": 200,; ""case_gatk_acnv_workflow.target_file"": ""/data/target/ice_targets.tsv""; },; ""submission"": ""2016-09-23T13:53:05.453Z"",; ""status"": ""Failed"",; ""failures"": [; {; ""message"": ""Call case_gatk_acnv_workflow.TumorCalculateTargetCoverage: return code was -1""; }; ],; ""end"": ""2016-09-23T13:53:29.816Z"",; ""start"": ""2016-09-23T13:53:06.277Z""; }; ```. local_application.conf. ```; webservice {; port = 8000; interface = 0.0.0.0; instance.name = ""reference""; }. akka {; loggers = [""akka.event.slf4j.Slf4jLogger""]; actor {; default-dispatcher {; fork-join-executor {; # Number of threads = min(parallelism-factor * cpus, parallelism-max); # Below are the default values set by Akka, uncomment to tune these. #parallelism-factor = 3.0; #parallelism-max = 64; }; }; }. dispatchers {; # A dispatcher for actors performing blocking io operations; # Prevents the whole system from being slowed down when waiting for responses from external resources for instance; io-dispatcher {; type = Dispatcher; executor = ""fork-join-executor""; # Using the forkjoin defaults, this can be tuned if we wish; }. # A dispatcher for actors handling API operations; # Keeps the API responsive r",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1480:82733,message,message,82733,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1480,1,['message'],['message']
Integrability,"_workflow.aggregate_data: return code was -1""; }, {; ""message"": ""Call aggregate_data_workflow.aggregate_data: return code was -1""; }, {; ""message"": ""Call aggregate_data_workflow.aggregate_data: return code was -1""; }],; ""jobId"": ""2957"",; ""backend"": ""JES"",; ""end"": ""2016-12-02T15:05:42.655Z"",; ""stderr"": ""/cromwell-executions/aggregate_data_workflow/3608d6ca-fbb4-4232-b197-268058470bfc/call-aggregate_data/execution/stderr"",; ""callRoot"": ""/cromwell-executions/aggregate_data_workflow/3608d6ca-fbb4-4232-b197-268058470bfc/call-aggregate_data"",; ""attempt"": 1,; ""executionEvents"": [...]; },; ""outputs"": {. },; ""workflowRoot"": ""gs://fc-2d3fd356-e3be-4953-92f1-60af623e6fa5/9ea737cd-a512-4c62-820c-dd1505ea7676/aggregate_data_workflow/3608d6ca-fbb4-4232-b197-268058470bfc"",; ""id"": ""3608d6ca-fbb4-4232-b197-268058470bfc"",; ""inputs"": {...; },; ""submission"": ""2016-12-01T21:21:40.188Z"",; ""status"": ""Failed"",; ""failures"": [{; ""message"": ""Call aggregate_data_workflow.aggregate_data: return code was -1""; }, {; ""message"": ""Call aggregate_data_workflow.aggregate_data: return code was -1""; }, {; ""message"": ""Call aggregate_data_workflow.aggregate_data: return code was -1""; }],; ""workflowLog"": ""gs://fc-2d3fd356-e3be-4953-92f1-60af623e6fa5/9ea737cd-a512-4c62-820c-dd1505ea7676/workflow.logs/workflow.3608d6ca-fbb4-4232-b197-268058470bfc.log"",; ""end"": ""2016-12-02T15:05:42.868Z"",; ""start"": ""2016-12-02T15:05:40.873Z""; }; ```. Here there's no ""message"" and there are ""timestamp"" and ""failure"". ```; {; ""workflowName"": ""aggregate_data_workflow"",; ""submittedFiles"": {; ""options"": ""{\n \""default_runtime_attributes\"": {\n \""zones\"": \""us-central1-b\""\n },\n \""google_project\"": \""broad-dsde-dev\"",\n \""auth_bucket\"": \""gs://cromwell-auth-broad-dsde-dev\"",\n \""refresh_token\"": \""cleared\"",\n \""account_name\"": \""abaumann.firecloud@gmail.com\"",\n \""jes_gcs_root\"": \""gs://fc-5539c024-3ba8-4ed1-97c3-82fed2675776/1626e6be-60ed-48b1-9bbc-a3fdef4a90f5\""\n}"",; ""inputs"": ""{\""aggregate_data_workflow.aggregate_data.input_a",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2037:4934,message,message,4934,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2037,1,['message'],['message']
Integrability,"_workflow.aggregate_data: return code was -1""; }, {; ""message"": ""Call aggregate_data_workflow.aggregate_data: return code was -1""; }],; ""jobId"": ""2957"",; ""backend"": ""JES"",; ""end"": ""2016-12-02T15:05:42.655Z"",; ""stderr"": ""/cromwell-executions/aggregate_data_workflow/3608d6ca-fbb4-4232-b197-268058470bfc/call-aggregate_data/execution/stderr"",; ""callRoot"": ""/cromwell-executions/aggregate_data_workflow/3608d6ca-fbb4-4232-b197-268058470bfc/call-aggregate_data"",; ""attempt"": 1,; ""executionEvents"": [...]; },; ""outputs"": {. },; ""workflowRoot"": ""gs://fc-2d3fd356-e3be-4953-92f1-60af623e6fa5/9ea737cd-a512-4c62-820c-dd1505ea7676/aggregate_data_workflow/3608d6ca-fbb4-4232-b197-268058470bfc"",; ""id"": ""3608d6ca-fbb4-4232-b197-268058470bfc"",; ""inputs"": {...; },; ""submission"": ""2016-12-01T21:21:40.188Z"",; ""status"": ""Failed"",; ""failures"": [{; ""message"": ""Call aggregate_data_workflow.aggregate_data: return code was -1""; }, {; ""message"": ""Call aggregate_data_workflow.aggregate_data: return code was -1""; }, {; ""message"": ""Call aggregate_data_workflow.aggregate_data: return code was -1""; }],; ""workflowLog"": ""gs://fc-2d3fd356-e3be-4953-92f1-60af623e6fa5/9ea737cd-a512-4c62-820c-dd1505ea7676/workflow.logs/workflow.3608d6ca-fbb4-4232-b197-268058470bfc.log"",; ""end"": ""2016-12-02T15:05:42.868Z"",; ""start"": ""2016-12-02T15:05:40.873Z""; }; ```. Here there's no ""message"" and there are ""timestamp"" and ""failure"". ```; {; ""workflowName"": ""aggregate_data_workflow"",; ""submittedFiles"": {; ""options"": ""{\n \""default_runtime_attributes\"": {\n \""zones\"": \""us-central1-b\""\n },\n \""google_project\"": \""broad-dsde-dev\"",\n \""auth_bucket\"": \""gs://cromwell-auth-broad-dsde-dev\"",\n \""refresh_token\"": \""cleared\"",\n \""account_name\"": \""abaumann.firecloud@gmail.com\"",\n \""jes_gcs_root\"": \""gs://fc-5539c024-3ba8-4ed1-97c3-82fed2675776/1626e6be-60ed-48b1-9bbc-a3fdef4a90f5\""\n}"",; ""inputs"": ""{\""aggregate_data_workflow.aggregate_data.input_array\"":[\""bar, baz\""]}"",; ""workflow"": ""task aggregate_data {\n\tArray[File] input_ar",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2037:5018,message,message,5018,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2037,1,['message'],['message']
Integrability,"`IoReadForbiddenFailure` was introduced [here](https://github.com/broadinstitute/cromwell/pull/4359/files#diff-a3a03acc0bf129942cf77c19d96e9128R30); However some code ([example](https://github.com/broadinstitute/cromwell/blob/develop/backend/src/main/scala/cromwell/backend/standard/callcaching/StandardFileHashingActor.scala#L94)) is still expecting to receive an `IoFailure`, which `IoReadForbiddenFailure` isn't, hence logging an unexpected message received and hanging indefinitely (waiting for a never coming `IoFailure`)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4374:444,message,message,444,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4374,1,['message'],['message']
Integrability,"```$anon$1 was thrown during property evaluation. (SharedFileSystemJobExecutionActorSpec.scala:119)&#010; Message: A timeout occurred waiting for a future to complete. Queried 21 times, sleeping 500 milliseconds between each query.```. ```A timeout occurred waiting for a future to complete. Queried 21 times, sleeping 500 milliseconds between each query.```. https://fc-jenkins.dsp-techops.broadinstitute.org/job/cromwell-test-runner/165/. If one needs more info please talk to @ndbolliger",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4222:106,Message,Message,106,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4222,1,['Message'],['Message']
Integrability,"```; $ echo 'version development. workflow main {; call main { input: s1 = ""x"", s2 = ""y"" }; output { Array[File] f = main.f }; }. task main {; input {; String s1; String s2; }. command <<<; set -euo pipefail; mkdir d; touch ""d/~{s1}""; touch ""d/~{s2}""; echo -e ""d/~{s1}\nd/~{s2}""; >>>. output {; Directory d = ""d""; Array[File] f = read_lines(stdout()); }. runtime {; docker: ""debian:stable-slim""; }; }' > main.wdl; ```. This workflow when run on Google Cloud using Cromwell 74:; ```; $ java -Dconfig.file=PAPIv2.conf -jar cromwell-74.jar run main.wdl; ```; will succeed. When run on Google Cloud using Cromwell 75:; ```; $ java -Dconfig.file=PAPIv2.conf -jar cromwell-75.jar run main.wdl; ```; the workflow will fail with message:; ```; GCS output file not found: gs://xxx/cromwell-executions/main/01234567-89ab-cdef-0123-456789abcdef/call-main/d; ```; However, the directory is correctly delocalized:; ```; $ gsutil ls -l gs://xxx/cromwell-executions/main/01234567-89ab-cdef-0123-456789abcdef/call-main/d; 0 2022-02-13T00:00:00Z gs://xxx/cromwell-executions/main/01234567-89ab-cdef-0123-456789abcdef/call-main/d/x; 0 2022-02-13T00:00:00Z gs://xxx/cromwell-executions/main/01234567-89ab-cdef-0123-456789abcdef/call-main/d/y; TOTAL: 2 objects, 0 bytes (0 B); ```. The delocalization script is aware that `d` is directory:; ```; $ gsutil cat gs://xxx/cromwell-executions/main/01234567-89ab-cdef-0123-456789abcdef/call-main/gcs_delocalization.sh; source '/cromwell_root/gcs_transfer.sh'. timestamped_message 'Delocalization script execution started...'. # xxx; delocalize_6c578056c74a8d9a80724855ddac131c=(; ""mccarroll-mocha"" # project; ""3"" # max attempts; ""150M"" # parallel composite upload threshold, will not be used for directory types; ""file""; ""gs://xxx/cromwell-executions/main/01234567-89ab-cdef-0123-456789abcdef/call-main/memory_retry_rc""; ""/cromwell_root/memory_retry_rc""; ""optional""; ""text/plain; charset=UTF-8""; ""file""; ""gs://xxx/cromwell-executions/main/01234567-89ab-cdef-0123-456789abcdef/c",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6677:721,message,message,721,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6677,1,['message'],['message']
Integrability,"```; The code passed to eventually never returned normally. Attempted 14 times over 5.123310162 seconds. Last failure message: Vector(""hola"", ""hello"", ""bonjour"") was not equal to Vector(""hola"", ""hello"", ""bonjour"", ""aurevoir"").; ```. ```; tc: BatchingDbWriter should process again when previous processing finished and we're still over batch size (each time with same test case); ```. https://fc-jenkins.dsp-techops.broadinstitute.org/job/cromwell-test-runner/161/testReport/cromwell.core.actor/BatchActorSpec/BatchingDbWriter_should_process_again_when_previous_processing_finished_and_we_re_still_over_batch_size/. If one needs more info, please talk to @ndbolliger",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4223:118,message,message,118,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4223,1,['message'],['message']
Integrability,"```; {; ""causedBy"": [],; ""message"": ""Bad output 'GatherVcfs.output_vcf_index': No such field 'tbi' on type String. Report this bug! Static validation failed.""; }; ```. from wdl snippet: ; ```; output {; File output_vcf = ""~{output_vcf_filename}""; File output_vcf_index = ""~{output_vcf_filename}"".tbi; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3863:26,message,message,26,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3863,1,['message'],['message']
Integrability,```The code passed to eventually never returned normally. Attempted 51 times over 3.8950992149999997 seconds. Last failure message: HighLoad was not equal to NormalLoad.```. `https://broadinstitute.atlassian.net/browse/GAWB-3876`. ```tc: LoadControllerServiceActor should update global load level periodically (each time with same test case)```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4237:123,message,message,123,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4237,1,['message'],['message']
Integrability,`handleWorkflowSuccess` in `WorkflowExecutionActor` attempts to print out a log message which include the outputs. This doesn't go so well when the outputs are ginormous.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1770:80,message,message,80,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1770,1,['message'],['message']
Integrability,`sync` in shell wrapper really glugs the server when lots of wf submitted,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2057:16,wrap,wrapper,16,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2057,1,['wrap'],['wrapper']
Integrability,"a.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: io.grpc.StatusRuntimeException: UNAVAILABLE: io exception; Channel Pipeline: [SslHandler#0, ProtocolNegotiators$ClientTlsHandler#0, WriteBufferingAndExceptionHandler#0, DefaultChannelPipeline$TailContext#0]; at io.grpc.Status.asRuntimeException(Status.java:539); ... 14 common frames omitted; Caused by: javax.net.ssl.SSLHandshakeException: General OpenSslEngine problem; at io.grpc.netty.shaded.io.netty.handler.ssl.ReferenceCountedOpenSslEngine.handshakeException(ReferenceCountedOpenSslEngine.java:1907); at io.grpc.netty.shaded.io.netty.handler.ssl.ReferenceCountedOpenSslEngine.wrap(ReferenceCountedOpenSslEngine.java:834); at java.base/javax.net.ssl.SSLEngine.wrap(SSLEngine.java:564); at io.grpc.netty.shaded.io.netty.handler.ssl.SslHandler.wrap(SslHandler.java:1041); at io.grpc.netty.shaded.io.netty.handler.ssl.SslHandler.wrapNonAppData(SslHandler.java:927); at io.grpc.netty.shaded.io.netty.handler.ssl.SslHandler.unwrap(SslHandler.java:1409); at io.grpc.netty.shaded.io.netty.handler.ssl.SslHandler.unwrapNonAppData(SslHandler.java:1327); at io.grpc.netty.shaded.io.netty.handler.ssl.SslHandler.access$1800(SslHandler.java:169); at io.grpc.netty.shaded.io.netty.handler.ssl.SslHandler$SslTasksRunner.resumeOnEventExecutor(SslHandler.java:1718); at io.grpc.netty.shaded.io.netty.handler.ssl.SslHandler$SslTasksRunner.access$2000(SslHandler.java:1609); at io.grpc.netty.shaded.io.netty.handler.ssl.SslHandler$SslTasksRunner$2.run(SslHandler.java:1770); at io.grpc.netty.shaded.io.netty.util.concurrent.AbstractEventExecutor.runTask(AbstractEventExecutor.java:174); at io.grpc.netty.shaded.io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:167); at io.grpc.netty.shaded.io.netty.util.concurrent.SingleThreadEven",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7551:5334,wrap,wrap,5334,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7551,1,['wrap'],['wrap']
Integrability,"a:49); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: io.grpc.StatusRuntimeException: UNAVAILABLE: io exception; Channel Pipeline: [SslHandler#0, ProtocolNegotiators$ClientTlsHandler#0, WriteBufferingAndExceptionHandler#0, DefaultChannelPipeline$TailContext#0]; at io.grpc.Status.asRuntimeException(Status.java:539); ... 14 common frames omitted; Caused by: javax.net.ssl.SSLHandshakeException: General OpenSslEngine problem; at io.grpc.netty.shaded.io.netty.handler.ssl.ReferenceCountedOpenSslEngine.handshakeException(ReferenceCountedOpenSslEngine.java:1907); at io.grpc.netty.shaded.io.netty.handler.ssl.ReferenceCountedOpenSslEngine.wrap(ReferenceCountedOpenSslEngine.java:834); at java.base/javax.net.ssl.SSLEngine.wrap(SSLEngine.java:564); at io.grpc.netty.shaded.io.netty.handler.ssl.SslHandler.wrap(SslHandler.java:1041); at io.grpc.netty.shaded.io.netty.handler.ssl.SslHandler.wrapNonAppData(SslHandler.java:927); at io.grpc.netty.shaded.io.netty.handler.ssl.SslHandler.unwrap(SslHandler.java:1409); at io.grpc.netty.shaded.io.netty.handler.ssl.SslHandler.unwrapNonAppData(SslHandler.java:1327); at io.grpc.netty.shaded.io.netty.handler.ssl.SslHandler.access$1800(SslHandler.java:169); at io.grpc.netty.shaded.io.netty.handler.ssl.SslHandler$SslTasksRunner.resumeOnEventExecutor(SslHandler.java:1718); at io.grpc.netty.shaded.io.netty.handler.ssl.SslHandler$SslTasksRunner.access$2000(SslHandler.java:1609); at io.grpc.netty.shaded.io.netty.handler.ssl.SslHandler$SslTasksRunner$2.run(SslHandler.java:1770); at io.grpc.netty.shaded.io.netty.util.concurrent.AbstractEventExecutor.runTask(AbstractEventExecutor.java:174); at io.grpc.netty.shaded.io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExe",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7551:5252,wrap,wrap,5252,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7551,1,['wrap'],['wrap']
Integrability,"aW9uUXVldWU; > operations/EMPd46GLLBj1iYrpkrCipPsBIKX3tPnnByoPcHJvZHVjdGlvblF1ZXVl; > operations/ENTd46GLLBiN8JPluoXAzFUgpfe0-ecHKg9wcm9kdWN0aW9uUXVldWU; > operations/EMPehaqLLBiS7p7OzdzYu5wBIKX3tPnnByoPcHJvZHVjdGlvblF1ZXVl. > ------------------------------- ; > kcibul@broadinstitute.org <kcibul@broadinstitute.org> #2 Jan 8, 2018 03:52PM ; > This is important to understand so Cromwell can do the right thing. It ; > hasn't been clear in the past why we sometimes get 13s on these preemptible ; > jobs ; > ; > Kristian Cibulskis ; > Director of Platform Engineering, Data Sciences Platform ; > Broad Institute of MIT and Harvard ; > kcibul@broadinstitute.org ; > ; > ; > ------------------------------- ; > ferrara@broadinstitute.org <ferrara@broadinstitute.org> #3 Jan 10, 2018 08:58AM ; > Not sure if you need any additional opsids - let me know if you do. While I have not gathered specific statistics on the frequency of this happening - our operations staff reports that it is not unusual for this to happen up to dozen or so times a day where the ""Message 13:"" failures cause the entire workflow to fail and need to be re-submitted. I would only assume that at a task level it is happening more often and as long as it does happen three times in succession for the same task - our ops team may not even notice it. Since the retry covers it up. ; > ; > But it can cause considerable amount of delay on completing a sample. The time spent to do the 3 retries but then the time it takes for a human to notice the failure and re-submit the entire thing again. For ""normal"" preemption - we have codified things in our WDL such that when failures occur - it is usually something unusual. With the higher occurrence of ""Message 13"" cause workflow failures - there is a new added step that needs to be looked at first. Did the workflow fail due to ""Message 13""?; > ; > At a minimal it would be nice to understand what are the circumstances a ""Message 13"" failure happens - so the Red/Cromwell team ca",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3157:3764,Message,Message,3764,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3157,1,['Message'],['Message']
Integrability,ableBatch.run(BatchingExecutor.scala:90); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: java.net.SocketException: Socket is closed; at sun.security.ssl.SSLSocketImpl.getInputStream(SSLSocketImpl.java:2218); at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:642); at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1536); at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1441); at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480); at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:338); at com.google.api.client.http.javanet.NetHttpResponse.<init>(NetHttpResponse.java:37); at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:94); at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); at com.google.cloud.storage.spi.DefaultStorageRpc.open(DefaultStorageRpc.java:563); at com.google.cloud.storage.BlobWriteChannel.<init>(BlobWriteChannel.java:36); at com.google.cloud.storage.StorageImpl.writer(StorageImpl.java:476); at com.google.cloud.storage.StorageImpl.writer(StorageImpl.java:471); at com.google.cloud.storage.StorageImpl.writer(StorageImpl.java:70); at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.newWriteChannel(CloudStorageFil\; eSystemProvider.java:327); at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.newByteChannel(CloudStorageFile\; SystemProvider.java:220); at java.nio.file.spi.FileSystemProvi,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2009:3056,protocol,protocol,3056,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2009,1,['protocol'],['protocol']
Integrability,"ace. -->. <!-- You'll want to go to https://broadworkbench.atlassian.net/projects/BA/issues and then tell us: -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->; ; Jobs which required gpuType: ""nvidia-tesla-t4"", nvidiaDriverVersion: ""418.40.04"", failed. Our pipeline backend is Google : genomics.googleapis.com; ""jes"": {; ""endpointUrl"": ""https://genomics.googleapis.com/"",; ""zone"": ""us-central1-f"",; ....; },. job runtimeAttributes:; ...; ""preemptible"": ""1"",; ""gpuCount"": ""1"",; ""failOnStderr"": ""false"",; ""bootDiskSizeGb"": ""70"",; ""disks"": ""local-disk 70 SSD"",; ""continueOnReturnCode"": ""0"",; ""gpuType"": ""nvidia-tesla-t4"",; ""nvidiaDriverVersion"": ""418.40.04"",; ""maxRetries"": ""0"",; ""cpu"": ""8"",; ""cpuMin"": ""1"",; ""noAddress"": ""false"",; ""zone"": ""us-central1-f"",; ""memoryMin"": ""2 GB"",; ""memory"": ""64 GB"". Jobs failed with following message:; ""Task wf_quip_lymphocyte_segmentation_incep_v01052021.quip_lymphocyte_segmentation:NA:1 failed. The job was stopped before the command finished. PAPI error code 2. Execution failed: generic::unknown: installing drivers: container exited with unexpected exit code 1: + COS_KERNEL_INFO_FILENAME=kernel_info\n+ COS_KERNEL_SRC_ARCHIVE=kernel-src.tar.gz\n+ COS_KERNEL_SRC_HEADER=kernel-headers.tgz\n+ TOOLCHAIN_URL_FILENAME=toolchain_url\n+ TOOLCHAIN_ARCHIVE=toolchain.tar.xz\n+ TOOLCHAIN_ENV_FILENAME=toolchain_env\n+ TOOLCHAIN_PKG_DIR=/build/cos-tools\n+ CHROMIUMOS_SDK_GCS=https://storage.googleapis.com/chromiumos-sdk\n+ ROOT_OS_RELEASE=/root/etc/os-release\n+ KERNEL_SRC_DIR=/build/usr/src/linux\n+ KERNEL_SRC_HEADER=/build/usr/src/linux-headers\n+ NVIDIA_DRIVER_VERSION=450.51.06\n+ NVIDIA_DRIVER_MD5SUM=\n+ NVIDIA_INSTALL_DIR_HOST=/var/lib/nvidia\n+ NVIDIA_INSTALL_DIR_CONTAINER=/usr/local/nvidia\n+ ROOT_MOUNT_DIR=/root\n+ CACHE_FILE=/usr/local/nvidia/.cache\n+ LOCK_FILE=/root/tmp/cos_gpu_installer_lock\",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6195:1823,message,message,1823,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6195,1,['message'],['message']
Integrability,add integration test capability,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2375:4,integrat,integration,4,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2375,1,['integrat'],['integration']
Integrability,"airs distribution considered concordantly mapped. Default: 0.995\\n\"",\n \""inputBinding\"": {\n \""prefix\"": \""--concordantreadpairdistribution\""\n },\n \""default\"": \""0.995\"",\n \""id\"": \""#gridss-2.9.4.cwl/concordantreadpairdistribution\""\n },\n {\n \""type\"": [\n \""null\"",\n \""File\""\n ],\n \""doc\"": \""Optional - configuration file use to override default GRIDSS settings.\\n\"",\n \""inputBinding\"": {\n \""prefix\"": \""--configuration\""\n },\n \""id\"": \""#gridss-2.9.4.cwl/configuration\""\n },\n {\n \""type\"": [\n \""null\"",\n \""boolean\""\n ],\n \""doc\"": \""Optional - use the system version of bwa instead of the in-process version packaged with GRIDSS\\n\"",\n \""inputBinding\"": {\n \""prefix\"": \""--externalaligner\""\n },\n \""default\"": false,\n \""id\"": \""#gridss-2.9.4.cwl/externalaligner\""\n },\n {\n \""type\"": [\n \""null\"",\n \""string\""\n ],\n \""doc\"": \""Optional - location of GRIDSS jar\\n\"",\n \""inputBinding\"": {\n \""prefix\"": \""--jar\""\n },\n \""default\"": \""/opt/gridss/gridss-2.9.4-gridss-jar-with-dependencies.jar\"",\n \""id\"": \""#gridss-2.9.4.cwl/jar\""\n },\n {\n \""type\"": \""boolean\"",\n \""doc\"": \""zero-based assembly job index (only required when performing parallel assembly across multiple computers)\\n\"",\n \""inputBinding\"": {\n \""prefix\"": \""--jobindex\""\n },\n \""default\"": false,\n \""id\"": \""#gridss-2.9.4.cwl/jobindex\""\n },\n {\n \""type\"": \""boolean\"",\n \""doc\"": \""total number of assembly jobs (only required when performing parallel assembly across multiple computers). Note than an assembly jobs is required after all indexed jobs have been completed to gather the output files together.\\n\"",\n \""inputBinding\"": {\n \""prefix\"": \""--jobnodes\""\n },\n \""default\"": false,\n \""id\"": \""#gridss-2.9.4.cwl/jobnodes\""\n },\n {\n \""type\"": [\n \""null\"",\n \""string\""\n ],\n \""doc\"": \""size of JVM heap for assembly and variant calling.\\n\"",\n \""inputBinding\"": {\n \""prefix\"": \""--jvmheap\""\n },\n \""default\"": \""$(get_max_memory_from_runtime_memory(runtime.ram))m\"",\n \""id\"": \""#gri",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5826:74136,depend,dependencies,74136,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5826,1,['depend'],['dependencies']
Integrability,"akka.actor.ActorCell.receiveMessage(ActorCell.scala:527); at akka.actor.ActorCell.invoke(ActorCell.scala:496); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); at akka.dispatch.Mailbox.run(Mailbox.scala:224); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). [2017-12-05 09:40:31,67] [warn] Couldn't find a suitable DSN, defaulting to a Noop one.; [2017-12-05 09:40:31,68] [info] Using noop to send events.; [2017-12-05 09:40:31,70] [info] WorkflowManagerActor WorkflowActor-6a6ee0eb-5576-43af-a64c-8ed7d288bbc5 is in a terminal state: WorkflowFailedState; [2017-12-05 09:40:35,79] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2017-12-05 09:40:35,81] [info] Message [cromwell.core.actor.StreamActorHelper$StreamFailed] without sender to Actor[akka://cromwell-system/deadLetters] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2017-12-05 09:40:35,81] [info] Message [cromwell.core.actor.StreamActorHelper$StreamFailed] without sender to Actor[akka://cromwell-system/deadLetters] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; Workflow 6a6ee0eb-5576-43af-a64c-8ed7d288bbc5 transitioned to state Failed; [2017-12-05 09:40:35,85] [info] Automatic shutdown of the async connection; [2017-12-05 09:40:35,85] [info] Gracefully shutdown sentry threads.; [2017-12-05 09:40:35,85] [info] Shutdown finished.; ```; As a work-around, I needed to replace ; ```; if ( b1 && b2 )",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2992:5641,Message,Message,5641,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2992,1,['Message'],['Message']
Integrability,"alidate or some error handling should have caught that? Instead it just didn't make it through JES and said it 'failed to localize inputs'. But Brad pointed out that I think I used swagger to validate not wdltools, so this could be entirely my fault, as he said those may not be in sync / up to date wise? I wasn't aware. Anyways here was my situation in case it's at all helpful, the missing var is **File gender_mask_bed**:. ```; workflow GenomeStripBamWorkflow {; String sample_name; String bam_name; String analysis_directory; File bam; File ref_fasta; File ref_fasta_index; File ref_dict; File ref_genome_sizes; File ploidy_map; File copy_number_mask; File copy_number_mask_index; File read_depth_mask; File ref_profile; File genome_mask; File genome_mask_index; File configs. ##This is the call that had the issue, there are some before it that it depends on, ; ##but not for the missing input (gender_mask_bed); call CallSampleGender as CallSampleGender {; input:; analysis_directory = analysis_directory,; ref_fasta = ref_fasta,; ref_fasta_index = ref_fasta_index,; ref_dict = ref_dict,; genome_mask = genome_mask,; genome_mask_index = genome_mask_index,; ploidy_map = ploidy_map,; header_bam = ExtractBamSubset.header_bam,; header_bam_index = IndexHeaders.header_index,; gender_mask_bed = gender_mask_bed,; read_count_index = Index.read_count_index; }; }; ```. And here's the task, which does have the missing variable **File gender_mask_bed**. ```; task CallSampleGender {; String analysis_directory; File ref_fasta; File ref_fasta_index; File ref_dict; File genome_mask; File genome_mask_index; File ploidy_map; File header_bam; File header_bam_index; File gender_mask_bed; File read_count_index. command {; mkdir ${analysis_directory}; java -Xmx4000m \; -classpath /usr/gitc/svtoolkit2.00/lib/SVToolkit.jar:/usr/gitc/svtoolkit2.00/lib/gatk/GenomeAnalysisTK.jar \; org.broadinstitute.sv.apps.CallSampleGender \; -R ${ref_fasta} \; -genomeMaskFile ${genome_mask} \; -ploidyMapFile ${ploidy_m",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2874:3767,depend,depends,3767,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2874,1,['depend'],['depends']
Integrability,"allable.call(UnaryCallable.java:112); 		at cromwell.backend.google.batch.api.GcpBatchApiRequestHandler.$anonfun$submit$1(GcpBatchApiRequestHandler.scala:11); 		at cromwell.backend.google.batch.api.GcpBatchApiRequestHandler.withClient(GcpBatchApiRequestHandler.scala:29); 		at cromwell.backend.google.batch.api.GcpBatchApiRequestHandler.submit(GcpBatchApiRequestHandler.scala:9); 		at cromwell.backend.google.batch.actors.GcpBatchBackendSingletonActor$$anonfun$normalReceive$1.$anonfun$applyOrElse$1(GcpBatchBackendSingletonActor.scala:65); 		at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:678); 		at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467); 		at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:41); 		at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:49); 		at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 		at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 		at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 		at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); ```. It seems that Cromwell only accepts public VPC network with names starting as `global/networks/...`, while my actual network name was automatically attached by prefix `projects/${projectId}/global/networks/` (as shown in Line 1 of the error message above). I just wonder if this is because I have something wrong in my conf file, or I missed some setup at GCP Batch side. Thanks!. I'm using Cromwell v87. And my conf file is. ```; ...; backend {; ...; providers {; GCPBATCH {; actor-factory = ""cromwell.backend.google.batch.GcpBatchBackendLifecycleActorFactory""; config {; ...; virtual-private-cloud {; network-label-key = ""my-private-network""; subnetwork-label-key = ""my-private-subnetwork""; auth = ""application-default""; }; ...; }; }; ```. where `my-private-network` and `my-private-subnetwork` are GCP project labels.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7500:4772,message,message,4772,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7500,1,['message'],['message']
Integrability,"ameters"": {}, ; ""jobDefinition"": ""arn:aws:batch:us-east-1:260062248592:job-definition/hc_Haplotypecaller-hc_HC_GVCF:19527"", ; ""statusReason"": ""Essential container in task exited"", ; ""jobId"": ""7c2d29c2-f04e-4b3f-8579-915a6fbc9033"", ; ""attempts"": [{; ""startedAt"": 1558552881926, ""container"": {; ""taskArn"": ""arn:aws:ecs:us-east-1:260062248592:task/78221618-403c-4b10-b9e1-6c1534a44723"", ; ""containerInstanceArn"": ""arn:aws:ecs:us-east-1:260062248592:container-instance/3cfe8456-fd3e-420d-91bc-aa1d8d134194"", ; ""logStreamName"": ""hc_Haplotypecaller-hc_HC_GVCF/default/78221618-403c-4b10-b9e1-6c1534a44723"", ; ""exitCode"": 0}, ""stoppedAt"": 1558553539743, ""statusReason"": ""Essential container in task exited""}], ; ""jobQueue"": ""arn:aws:batch:us-east-1:260062248592:job-queue/GenomicsDefaultQueue-80d8b8f0-15ed-11e9-b8b7-12ddf705bbc4"", ; ""dependsOn"": [], ; ""startedAt"": 1558552881926, ; ""jobName"": ""Haplotypecaller_HC_GVCF"", ; ""createdAt"": 1558552763368, ""stoppedAt"": 1558553539743}]}; ```. Clearly, the AWS Batch job parameters are referencing a completely different set of input files from the set described in the workflow log. In this particular case, the job described in the log was started via cromwell run using v36 on an isolated EC2 instance, while the workflow described by the job parameters json was submitted to a cromwell v36.1 server running on a completely separate EC2 instance. This would point to call caching NOT being the problem but a more fundamental issue with how Cromwell interfaces with the AWS Batch backend to submit jobs. We've also observed this result using Cromwell v40 and 41, the latter using a completely new stack created just for that version, in both run and server modes. If more information is needed, please reach out and we'll provide what we can; the transient nature of the Batch job parameters and the lack of a set of cases that reliably reproduce this error has made it difficult for us to investigate and we're hoping developer assistance can get this resolved.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5004:16484,interface,interfaces,16484,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5004,1,['interface'],['interfaces']
Integrability,"anged between jobs it will create a new cache entry. Md5sums are not used because it is extremely compute intensive for large files. Path+modtime should guarantee that files are the same. . I have expanded the SFS test scala file so it properly tests the new `cached-inputs` strategy. I have added information on how to use the strategy in the docs, and added this PR to the changelog. ### Help still needed. There are two things that I could not figure out without cromwell developer help:. ~~* Checking whether a file exists and copying it to the cache should never be done by multiple threads simeltaneously. I have used the `synchronized` method to prevent this. I used an object for this, because I am sure it is unique within the JVM at cromwell runtime. This works fine, but I can imagine this can be solved in a nicer way using akka? However the akka documentation is an extensive jungle on its own, and requires quite some expertise to navigate. I could not find very quickly what I needed, and the `synchronization` primitive works fine. It is also **just 2 lines of extra code**. So if the akka solution is quite elegant as well I would like to learn about that. If not, well, it is not too bad having 2 lines of understandable commented code that is not ""the proper way of doing things(TM)"".~~. * I used the SFS scalatests to make sure everything worked correctly. However this did not test whether the thread safety was working correctly. I have added a test wdl in centaur: `standardTestCases/cached_copy/cached_copy.wdl`. This workflow creates 10 jobs that read the same input file. This workflow will crash if the `cached-inputs` cache is not used in a thread-safe way. I tested this manually with `java -Dbackend.providers.Local.config.filesystems.local.localization.0=""cached-copy"" -jar server/target/scala-2.12/cromwell-41-*-SNAP.jar run centaur/src/main/resources/standardTestCases/cached_copy/cached_copy.wdl` . Is there a way to integrate such a test in scalatest file? I have tr",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4900:2600,synchroniz,synchronization,2600,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900,1,['synchroniz'],['synchronization']
Integrability,anonfun$run$1.apply(BatchingExecutor.scala:91); at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72); at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: java.net.SocketException: Socket is closed; at sun.security.ssl.SSLSocketImpl.getInputStream(SSLSocketImpl.java:2218); at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:642); at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1536); at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1441); at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480); at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:338); at com.google.api.client.http.javanet.NetHttpResponse.<init>(NetHttpResponse.java:37); at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:94); at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); at com.google.cloud.storage.spi.DefaultStorageRpc.open(DefaultStorageRpc.java:563); at com.google.cloud.storage.BlobWriteChannel.<init>(BlobWriteChannel.java:36); at com.google.cloud.storage.StorageImpl.writer(StorageImpl.java:476); at com.google.cloud.storage.StorageImpl.writer(StorageImpl.java:471); at com.google.cloud.storage.StorageImpl.writer(StorageImpl.java:70); at com.google.cloud.storage.contrib.nio,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2009:2796,protocol,protocol,2796,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2009,1,['protocol'],['protocol']
Integrability,"ase_gatk_acnv_workflow.seg_param_nperm"": 10000,; ""case_gatk_acnv_workflow.PoN"": ""/data/ice_rcs_eval.v1.pd250.spark.pon"",; ""case_gatk_acnv_workflow.input_bam_list"": ""/home/lichtens/eval-gatk-protected/scripts/crsp_validation/crsp_validation_bam_list_local_paths.txt"",; ""case_gatk_acnv_workflow.ref_fasta"": ""/data/ref/Homo_sapiens_assembly19.fasta"",; ""case_gatk_acnv_workflow.enable_gc_correction"": true,; ""case_gatk_acnv_workflow.wgsBinSize"": 10000,; ""case_gatk_acnv_workflow.seg_param_undoPrune"": 0.05,; ""case_gatk_acnv_workflow.gatk_jar"": ""/root/gatk-protected.jar"",; ""case_gatk_acnv_workflow.seg_param_nmin"": 200,; ""case_gatk_acnv_workflow.target_file"": ""/data/target/ice_targets.tsv""; },; ""submission"": ""2016-09-23T13:53:05.453Z"",; ""status"": ""Failed"",; ""failures"": [; {; ""message"": ""Call case_gatk_acnv_workflow.TumorCalculateTargetCoverage: return code was -1""; }; ],; ""end"": ""2016-09-23T13:53:29.816Z"",; ""start"": ""2016-09-23T13:53:06.277Z""; }; ```. local_application.conf. ```; webservice {; port = 8000; interface = 0.0.0.0; instance.name = ""reference""; }. akka {; loggers = [""akka.event.slf4j.Slf4jLogger""]; actor {; default-dispatcher {; fork-join-executor {; # Number of threads = min(parallelism-factor * cpus, parallelism-max); # Below are the default values set by Akka, uncomment to tune these. #parallelism-factor = 3.0; #parallelism-max = 64; }; }; }. dispatchers {; # A dispatcher for actors performing blocking io operations; # Prevents the whole system from being slowed down when waiting for responses from external resources for instance; io-dispatcher {; type = Dispatcher; executor = ""fork-join-executor""; # Using the forkjoin defaults, this can be tuned if we wish; }. # A dispatcher for actors handling API operations; # Keeps the API responsive regardless of the load of workflows being run; api-dispatcher {; type = Dispatcher; executor = ""fork-join-executor""; }. # A dispatcher for engine actors; # Because backends behaviour is unpredictable (potentially blocking, slow) th",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1480:82968,interface,interface,82968,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1480,1,['interface'],['interface']
Integrability,askInvocation.run(AbstractDispatcher.scala:39); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: javax.net.ssl.SSLHandshakeException: Remote host closed connection during handshake; at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:980); at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1363); at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1391); at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1375); at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:563); at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185); at sun.net.www.protocol.https.HttpsURLConnectionImpl.connect(HttpsURLConnectionImpl.java:153); at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93); at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469); at com.google.cloud.storage.spi.DefaultStorageRpc.get(DefaultStorageRpc.java:320); ... 31 more; Caused by: java.io.EOFException: SSL peer shut down incorrectly; at sun.security.ssl.InputRecord.read(InputRecord.java:505); at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:961); ... 43 more```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1782:4533,protocol,protocol,4533,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1782,1,['protocol'],['protocol']
Integrability,"at one of the goals is reliability/scalability, I thought I'd make a PR out of it since it might provide a base for discussion. This branch has an IO Actor that handles *some* of the IO that has to be done both on the engine and the backend side. Specifically the script.sh upload, rc file reading, stderr file size reading, call cache copying (on JES), workflow outputs copying is done using this mechanism.; The actor is under the service registry umbrella, that was to be able to test it more rapidly (as the service registry is already wired up pretty much everywhere), but it should probably be it's own top level actor. Due to the Future-based approach we took in the backend interface, the IO messages (copy, read, write, delete file...) are declined into 2 different flavors:; - A classic Command -> Response; - A Promise based version, that takes a promise in the command message itself to be completed when the operation finishes. This allow for the actor to integrate with parts of the code that can't (easily) handle the response as a message. The underlying implementation of the IO Actor is a router, but could be swapped for something else. Each worker tries to perform the operation, and once it's complete (successfully or not) either sends a message back or completes the promise depending on the command flavor.; Retries are handled by keeping an exponential backoff object in the command itself. If the failure is retryable, the worker sends the command message back to the router after waiting for the appropriate backoff time. The message will then be rerouted when a worker is available.; Note that the actual time before the command is picked up again by another worker could be longer than intended if all workers are busy and the command spends time in the mailbox. ; A command will be retried as many times as possible (considering exponentially long waiting times in between retries) until a threshold amount of time has passed since the first try (10 minutes by default).",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1831:1269,rout,router,1269,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1831,6,"['depend', 'message', 'rout']","['depending', 'message', 'router']"
Integrability,"atabase; File query; String name; String mode. command {; diamond ${mode} -d ${database} -q ${query} \; --more-sensitive -o ${name}.m8 \; -f 6 sseqid qseq score pident stitle qcovhsp qtitle \; }. runtime {; docker: ""quay.io/comp-bio-aging/diamond:latest""; }. output {; File out = name + "".m8""; }. }. task copy {; Array[File] files; String destination. command {; mkdir -p ${destination}; cp -L -R -u ${sep=' ' files} ${destination}; }. output {; Array[File] out = files; }; }; ```; and here is an example of the input:; ```json. Diamond_Blast.mode = ""blastp""; Diamond_Blast.query = ""/pipelines/indexes/GRAY_WHALE/NTJE01P.1.fasta""; Diamond_Blast.threads = 8; Diamond_Blast.result_name = ""graywhale_in_minkywhale_blastp""; Diamond_Blast.db = ""/pipelines/indexes/diamond/MINKY_WHALE_GCF_000493695.1.dmnd""; Diamond_Blast.results_folder = ""/pipelines/results/graywhale/transcriptome/diamond/blastp""; ```; when I run the workflow many times with input changes I get the following:; ```. name | status | stdout | stderr | cache | shard; -- | -- | -- | -- | -- | --; Diamond_Blast.copy_results | Done | /pipelines/cromwell_1/cromwell-executions/Diamond_Blast/da1376f4-6f31-403f-941d-e8c36483897e/call-copy_results/execution/stdout | /pipelines/cromwell_1/cromwell-executions/Diamond_Blast/da1376f4-6f31-403f-941d-e8c36483897e/call-copy_results/execution/stderr | Cache Hit: fdda40c0-a501-456c-a903-954aa52af83d:Diamond_Blast.copy_results:-1 | -1; Diamond_Blast.diamond_blast | Done | /pipelines/cromwell_1/cromwell-executions/Diamond_Blast/da1376f4-6f31-403f-941d-e8c36483897e/call-diamond_blast/execution/stdout | /pipelines/cromwell_1/cromwell-executions/Diamond_Blast/da1376f4-6f31-403f-941d-e8c36483897e/call-diamond_blast/execution/stderr | Cache Miss | -1; ```; that shows that the task diamond_blast recomputes while the copy task copies the cached result, in other words it sends the same file as previous time, totally ignoring the changes of output in the diamond_blast task from which it depends!!!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3044:3153,depend,depends,3153,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3044,1,['depend'],['depends']
Integrability,"atley/pact4s/releases/tag/v0.10.1-java8) - [Version Diff](https://github.com/jbwheatley/pact4s/compare/v0.9.0...v0.10.1-java8). ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>🔍 Files still referring to the old version number</summary>. The following files still refer to the old version number (0.9.0).; You might want to review and update them manually.; ```; centaur/src/main/resources/integrationTestCases/Somatic/CNV-Pair/cnv_somatic_pair_workflow_do_gc_wes.inputs; centaur/src/main/resources/integrationTestCases/Somatic/CNV-Panel/cnv_somatic_panel_workflow_do_gc_wes.inputs; centaur/src/main/resources/integrationTestCases/Somatic/Mutect2/Mutect2.aws.inputs; centaur/src/main/resources/integrationTestCases/Somatic/Mutect2/Mutect2.inputs; centaur/src/main/resources/integrationTestCases/germline/haplotype-caller-workflow/HaplotypeCallerWF.json; centaur/src/main/resources/integrationTestCases/germline/single-sample-production-workflow/PairedEndSingleSampleWf.options.json; centaur/src/main/resources/integrationTestCases/germline/single-sample-workflow/processing-for-variant-discovery-gatk4.hg38.wgs.inputs.json; centaur/src/main/resources/integrationTestCases/green/arrays/arrays.wdl; womtool/src/test/resources/validate/wdl_draft3/valid/HaplotypeCallerWF/HaplotypeCallerWF.inputs.json; womtool/src/test/resources/validate/wdl_draft3/valid/cnv_somatic_pair_workflow/cnv_somatic_pair_workflow.inputs.json; womtool/src/test/resources/validate/wdl_draft3/valid/joint-discovery-gatk/joint-discovery-gatk.inputs.j",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7294:1249,integrat,integrationTestCases,1249,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7294,1,['integrat'],['integrationTestCases']
Integrability,"atter (file in read_lines(shard_fofn)){; 		call SelectVariants{; 			input:; 				vcf=file,; 				intervals=interval_list; 		}; 	}; ```. where `shard fofn` has 20k+ lines inside of it. When running this workflow different shards failed ; with one of two errors. 30-50 different shards would fail each retry. ```; {; failures: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [ ],; message: ""Data received in non-data state: 6""; }; ],; message: ""Connection has been shutdown: javax.net.ssl.SSLProtocolException: Data received in non-data state: 6""; }; ],; message: ""Connection has been shutdown: javax.net.ssl.SSLProtocolException: Data received in non-data state: 6""; }; ],; message: ""All reopens failed""; }; ],; message: ""vcf""; }; ],; message: ""Input evaluation for Call mergeAndGetSites.SelectVariants failed.""; }; ],; message: ""Couldn't resolve all inputs for mergeAndGetSites.SelectVariants at index Some(778).""; }; ],; attempt: 1,; shardIndex: 778; },; ```; or . ```; {; failures: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [ ],; message: ""Connection closed prematurely: bytesRead = 34066, Content-Length = 2974047""; }; ],; message: ""Connection closed prematurely: bytesRead = 34066, Content-Length = 2974047""; }; ],; message: ""All reopens failed""; }; ],; message: ""vcf""; }; ],; message: ""Input evaluation for Call mergeAndGetSites.SelectVariants failed.""; }; ],; message: ""Couldn't resolve all inputs for mergeAndGetSites.SelectVariants at index Some(19820).""; }; ],; attempt: 1,; shardIndex: 19820; }; ]; },; ```. When I take the `read_lines(shard_fofn)` and assign it to a variable and then pass that to the scatter everything works fine. Is this just bad luck or is there possibly a real issue here?. ```; 	Array[File] fofn_files = read_lines(shard_fofn). 	scatter (file in fofn_files){; 		call SelectVariants{; 			input:; 				vcf=file,; 				intervals=interval_list; 		}; 	}; ``",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2965:1257,message,message,1257,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2965,6,['message'],['message']
Integrability,"ave two `write_tsv()` calls in the command block. This code works fine locally. ```; task trim_adapter { # trim adapters and merge trimmed fastqs; 	# parameters from workflow; 	Array[Array[File]] fastqs 		# [merge_id][end_id]; 	Array[Array[String]] adapters 	# [merge_id][end_id]; 	Boolean paired_end; 	# mandatory; 	Boolean auto_detect_adapter		# automatically detect/trim adapters; 	# optional; 	Int? min_trim_len 		# minimum trim length for cutadapt -m; 	Float? err_rate			# Maximum allowed adapter error rate ; 							# for cutadapt -e	; 	# resource; 	Int? cpu; 	Int? mem_mb; 	Int? time_hr; 	String? disks. 	command {; 		python $(which encode_trim_adapter.py) \; 			${write_tsv(fastqs)} \; 			${""--adapters "" + write_tsv(adapters)} \; 			${if paired_end then ""--paired-end"" else """"} \; 			${if auto_detect_adapter then ""--auto-detect-adapter"" else """"} \; 			${""--min-trim-len "" + min_trim_len} \; 			${""--err-rate "" + err_rate} \; 			${""--nth "" + select_first([cpu,4])}; 	}; 	output {; 		# WDL glob() globs in an alphabetical order; 		# so R1 and R2 can be switched, which results in an; 		# unexpected behavior of a workflow; 		# so we prepend merge_fastqs_'end'_ (R1 or R2); 		# to the basename of original filename; 		# this prefix will be later stripped in bowtie2 task; 		Array[File] trimmed_merged_fastqs = glob(""merge_fastqs_R?_*.fastq.gz""); 	}; 	runtime {; 		cpu : select_first([cpu,2]); 		memory : ""${select_first([mem_mb,'10000'])} MB""; 		time : select_first([time_hr,24]); 		disks : select_first([disks,""local-disk 100 HDD""]); 	}; }; ```; with Google JES backend, second call of write_tsv() doesn't seem to correctly pass temporary tsv file into a docker container. `${write_tsv()}` works fine.; `${""some string "" + write_tsv()}` does not work. It still has URI prefix `gs://`. ```; [2017-12-07 13:37:45,35] [info] JesAsyncBackendJobExecutionActor [17f0658fatac.trim_adapter:1:1]: python $(which encode_trim_adapter.py) \; /cromwell_root/atac-seq-pipeline-workflows/ENCSR889WQX/atac/17f",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3032:731,adapter,adapters,731,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3032,3,['adapter'],"['adapter', 'adapters']"
Integrability,"b link in FAQ (<a href=""https://github-redirect.dependabot.com/junit-team/junit4/issues/1672"">#1672</a>)</li>; <li><a href=""https://github.com/junit-team/junit4/commit/3a5c6b4d08f408c8ca6a8e0bae71a9bc5a8f97e8""><code>3a5c6b4</code></a> Deprecated since jdk9 replacing constructor instance of Double and Float (<a href=""https://github-redirect.dependabot.com/junit-team/junit4/issues/1660"">#1660</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/junit-team/junit4/compare/r4.13...r4.13.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=junit:junit&package-manager=maven&previous-version=4.13&new-version=4.13.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/configuring-github-dependabot-security-updates). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5941:4297,depend,dependabot,4297,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5941,1,['depend'],['dependabot']
Integrability,"b was stopped before the command finished. PAPI error code 2. Execution failed: generic::unknown: pulling image: docker pull: running [\""docker\"" \""pull\"" \""us.gcr.io/xxx/xxx@sha256:xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\""]: exit status 1 (standard error: \""error pulling image configuration: error parsing HTTP 400 response body: invalid character '<' looking for beginning of value: \\\""<?xml version='1.0' encoding='UTF-8'?><Error><Code>UserProjectMissing</Code><Message>Bucket is a requester pays bucket but no user project provided.</Message><Details>Bucket is Requester Pays bucket but no billing project id provided for non-owner.</Details></Error>\\\""\\n\"")"",`. I understand that the issue is that the Google bucket where the docker is located is requester pays and Cromwell does not know what to do in this case, but it is not immediately clear what I should do to fix it. It would be a great improvement if Cromwell could interpret this response and provide a more informative error message so that the user could immediately know what needs to be addressed. In particular, I am not fully sure what I should be doing. These are excerpts from my configuration file:; ```; ...; engine {; filesystems {; gcs {; auth = ""service-account""; project = ""xxx""; }; }; }; ...; services {; MetadataService {; ...; config {; carbonite-metadata-service {; filesystems {; gcs {; auth = ""service-account""; }; }; ...; }; }; }; }; ...; backend {; default = PAPIv2. providers {; PAPIv2 {; actor-factory = ""cromwell.backend.google.pipelines.v2beta.PipelinesApiLifecycleActorFactory""; config {; project = ""xxx""; ...; filesystems {; gcs {; auth = ""service-account""; project = ""xxx""; ...; }; }; ...; }; }; }; }; ...; ```; Where should the configuration for telling Cromwell which project to use when pulling dockers be?. I also do not understand why this issue arises at all as the Google bucket with the dockers is a us multi-region bucket and the computation is in us-central1, so there ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6235:1139,message,message,1139,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6235,1,['message'],['message']
Integrability,"b.com/FredHutch/reproducible-workflows/blob/master/WDL/unpaired-panel-consensus-variants-human/frankenstein.wdl. Input file: https://github.com/FredHutch/reproducible-workflows/blob/master/WDL/unpaired-panel-consensus-variants-human/map-variantcall-hg38.json. Possibly related to #4412 but not sure as I don't see the same error message. When submitting a workflow via the cromwell server we **consistently** see a failure to hash some items in S3 resulting in call caching being disabled for the run. We have seen this for a number of workflows, here we are including just one. . Call caching is a **hugely** important feature for us and if it is not available we may would have to reconsider using Cromwell. I think I have discussed with @ruchim the fact that all objects in S3 have a hash already computed (the ETag header) so there should not be timeouts in computing these hashes as they are available with a head request (you don't need to download the whole object). . Error message (extract from `/metadata` output):. ```; ""callCaching"": {; ""hashFailures"": [; {; ""causedBy"": [],; ""message"": ""Hashing request timed out for: s3://bucketname/cromwell-tests/Panel_BWA_GATK4_Samtools_Var_Annotate/162c863f-c22a-4b7c-bb37-f5195b329b36/call-ApplyBQSR/shard-0/smallTestData.hg38.recal.bam""; }; ],; ""allowResultReuse"": false,; ""hit"": false,; ""result"": ""Cache Miss"",; ""effectiveCallCachingMode"": ""CallCachingOff""; },; ```. Config file:. ```; include required(classpath(""application"")). call-caching {; enabled = true; invalidate-bad-cache-results = true; }. database {; # Store metadata in a file on disk that can grow much larger than RAM limits.; profile = ""slick.jdbc.HsqldbProfile$""; db {; driver = ""org.hsqldb.jdbcDriver""; url = ""jdbc:hsqldb:file:aws-database;shutdown=false;hsqldb.tx=mvcc""; connectionTimeout = 3000; }; }. aws {; application-name = ""cromwell""; auths = [; {; name = ""default""; scheme = ""default""; }; {; name = ""assume-role-based-on-another""; scheme = ""assume_role""; base-auth = ""d",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4563:1025,message,message,1025,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563,1,['message'],['message']
Integrability,"b.com/circe/circe/compare/v0.13.0...v0.14.1). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/92f43ce5f010fa03daeb2625a3f9c1b1be80cca5/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Files still referring to the old version number</summary>. The following files still refer to the old version number (0.13.0).; You might want to review and update them manually.; ```; centaur/src/main/resources/integrationTestCases/cwl/bcbio/gvcf-joint-workflow/steps/process_alignment.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/gvcf-joint-workflow/steps/variantcall_batch_region.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/prealign-workflow/steps/variantcall_batch_region.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/rnaseq-workflow/steps/prepare_sample.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/somatic-workflow/steps/detect_sv.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/somatic-workflow/steps/process_alignment.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/somatic-workflow/steps/variantcall_batch_region.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/svcall-workflow/steps/detect_sv.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/svcall-workflow/steps/process_alignment.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/svcall-workflow/steps/variantcall_batch_region.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/wes_chr21_test-workflow-gcp/steps/detect_sv.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/wes_chr21_test-workflow-gcp/steps/process_alignment.cwl",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6410:1619,integrat,integrationTestCases,1619,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6410,1,['integrat'],['integrationTestCases']
Integrability,"b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>🔍 Files still referring to the old version number</summary>. The following files still refer to the old version number (0.9.0).; You might want to review and update them manually.; ```; centaur/src/main/resources/integrationTestCases/Somatic/CNV-Pair/cnv_somatic_pair_workflow_do_gc_wes.inputs; centaur/src/main/resources/integrationTestCases/Somatic/CNV-Panel/cnv_somatic_panel_workflow_do_gc_wes.inputs; centaur/src/main/resources/integrationTestCases/Somatic/Mutect2/Mutect2.aws.inputs; centaur/src/main/resources/integrationTestCases/Somatic/Mutect2/Mutect2.inputs; centaur/src/main/resources/integrationTestCases/germline/haplotype-caller-workflow/HaplotypeCallerWF.json; centaur/src/main/resources/integrationTestCases/germline/single-sample-production-workflow/PairedEndSingleSampleWf.options.json; centaur/src/main/resources/integrationTestCases/germline/single-sample-workflow/processing-for-variant-discovery-gatk4.hg38.wgs.inputs.json; centaur/src/main/resources/integrationTestCases/green/arrays/arrays.wdl; womtool/src/test/resources/validate/wdl_draft3/valid/HaplotypeCallerWF/HaplotypeCallerWF.inputs.json; womtool/src/test/resources/validate/wdl_draft3/valid/cnv_somatic_pair_workflow/cnv_somatic_pair_workflow.inputs.json; womtool/src/test/resources/validate/wdl_draft3/valid/joint-discovery-gatk/joint-discovery-gatk.inputs.json; ```; </details>; <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""io.github.jbwheatley"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""io.github.jbwheatley"" }; }]; ```; </details>. <sup>; labels: library-update, early-semver-major, semver-spec-minor, old-ve",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7294:1760,integrat,integrationTestCases,1760,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7294,1,['integrat'],['integrationTestCases']
Integrability,"b5-be67-4756-b168-130450081cfb/call-PrintsToFileTest`. JSON input. ```json; {; ""TestOutputMultipleFiles.dummy_array"": [""chr1"", ""chr2""]; }. ```; And the WDL script; ```wdl; workflow TestOutputMultipleFiles {. Array[String] dummy_array. scatter (ele in dummy_array) {; call PrintsToFile as PrintsToFileTest {; input:; out_prefix = ele,; to_print = ele; }; }. output {; Array[Array[File]] matrix = [PrintsToFileTest.out_txt, ; PrintsToFileTest.out_md]; }; }. task PrintsToFile {. String out_prefix; String to_print. command {; touch ${out_prefix}.txt; echo ""${to_print}"" > ${out_prefix}.txt; # delibrately forgetting to generate a file, so cromwell should capture that and report failure; # touch ${out_prefix}.md; # echo ""${to_print}"" > ${out_prefix}.md; }. runtime {; docker: ""ubuntu:trusty""; disks: ""local-disk "" + ""10"" + "" HDD""; cpu: ""1""; preemptible: 1; }. output {; File out_txt = ""${out_prefix}.txt""; File out_md = ""${out_prefix}.md""; }; }. ```. -------------. If the workflow has multiple tasks, and downstream tasks depends on (i.e. File input) upstream task that should have produced the file as output, previously the workflow would fail, now the workflow just hangs there. Example (ID: 55f8ac4e-a6e1-4b1f-9086-f6d04fec5bb8, location: `gs://broad-dsde-methods/cromwell-execution-34/TestMultiStage/55f8ac4e-a6e1-4b1f-9086-f6d04fec5bb8`). some json input content, WDL below:. ```wdl; workflow TestMultiStage {. Array[String] dummy_array. scatter (ele in dummy_array) {; call PrintsToFile as UpstreamPrintToFile {; input:; out_prefix = ele,; to_print = ele; }. output {; UpstreamPrintToFile.out_txt; UpstreamPrintToFile.out_md; }; }. call DownstreamConsumer {; input:; txt_array = UpstreamPrintToFile.out_txt,; md_array = UpstreamPrintToFile.out_md; }. output {; File merged_txt = DownstreamConsumer.cat_txt; File merged_md = DownstreamConsumer.cat_md; }; }. # upstream task that supposed to be producing 2 out files; task PrintsToFile {. String out_prefix; String to_print. command {; touch ${o",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4147:1660,depend,depends,1660,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4147,1,['depend'],['depends']
Integrability,"bWriteChannel$1.run(BlobWriteChannel.java:49); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at com.google.cloud.RetryHelper.doRetry(RetryHelper.java:179); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:244); 	at com.google.cloud.storage.BlobWriteChannel.flushBuffer(BlobWriteChannel.java:46); 	at com.google.cloud.BaseWriteChannel.close(BaseWriteChannel.java:149); 	at com.google.cloud.storage.contrib.nio.CloudStorageWriteChannel.close(CloudStorageWriteChannel.java:57); 	at java.nio.channels.Channels$1.close(Channels.java:178); 	at java.nio.file.Files.write(Files.java:3300); 	at cromwell.backend.impl.jes.io.package$PathEnhanced$.writeAsJson$extension(package.scala:13); 	at cromwell.backend.impl.jes.JesInitializationActor$$anonfun$cromwell$backend$impl$jes$JesInitializationActor$$writeAuthenticationFile$1$$anonfun$apply$5.apply(JesInitializationActor.scala:80); 	at cromwell.backend.impl.jes.JesInitializationActor$$anonfun$cromwell$backend$impl$jes$JesInitializationActor$$writeAuthenticationFile$1$$anonfun$apply$5.apply(JesInitializationActor.scala:80); 	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24); 	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24); 	... 6 more; Caused by: com.google.api.client.http.HttpResponseException: 503 Service Unavailable; {; ""error"": {; ""errors"": [; {; ""domain"": ""global"",; ""reason"": ""backendError"",; ""message"": ""Backend Error""; }; ],; ""code"": 503,; ""message"": ""Backend Error""; }; }. 	at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1070); 	at com.google.cloud.storage.spi.DefaultStorageRpc.write(DefaultStorageRpc.java:518); 	... 20 more. [INFO] [01/27/2017 14:39:36.101] [cromwell-system-akka.dispatchers.engine-dispatcher-5] [akka://cromwell-system/user/cromwell-service/WorkflowManagerActor] WorkflowManagerActor WorkflowActor-732474fd-88b0-4a5e-ad19-5ee5cd71d141 is in a terminal state: WorkflowFailedState; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1924:4098,message,message,4098,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1924,2,['message'],['message']
Integrability,"butes"": {; ""docker"": ""broadinstitute/gatk-protected:24e6bdc0c058eaa9abe63e1987418d0c144fef8e"",; ""failOnStderr"": false,; ""continueOnReturnCode"": ""0""; },; ""cache"": {; ""allowResultReuse"": true; },; ""Effective call caching mode"": ""ReadAndWriteCache"",; ""inputs"": {; ""input_bam"": ""/data/private/SM-74P4H.bam"",; ""ref_fasta"": ""/data/ref/Homo_sapiens_assembly19.fasta"",; ""keep_duplicate_reads"": true,; ""grouping"": ""SAMPLE"",; ""disable_all_read_filters"": false,; ""ref_fasta_fai"": ""/data/ref/Homo_sapiens_assembly19.fasta.fai"",; ""bam_idx"": ""/data/private/SM-74P4H.bai"",; ""entity_id"": ""SM-74P4H"",; ""disable_sequence_dictionary_validation"": true,; ""mem"": 2,; ""gatk_jar"": ""/root/gatk-protected.jar"",; ""transform"": ""PCOV"",; ""isWGS"": false,; ""ref_fasta_dict"": ""/data/ref/Homo_sapiens_assembly19.dict"",; ""padded_target_file"": ""/home/lichtens/test_eval/cromwell-executions/case_gatk_acnv_workflow/ecf3a99c-634e-42d6-9e25-1ebba542098c/call-PadTargets/execution/targets.padded.tsv""; },; ""returnCode"": -1,; ""failures"": [; {; ""message"": ""Call case_gatk_acnv_workflow.TumorCalculateTargetCoverage: return code was -1""; }; ],; ""jobId"": ""28216"",; ""backend"": ""Local"",; ""end"": ""2016-09-23T13:53:28.554Z"",; ""stderr"": ""/home/lichtens/test_eval/cromwell-executions/case_gatk_acnv_workflow/ecf3a99c-634e-42d6-9e25-1ebba542098c/call-TumorCalculateTargetCoverage/shard-14/execution/stderr"",; ""callRoot"": ""/home/lichtens/test_eval/cromwell-executions/case_gatk_acnv_workflow/ecf3a99c-634e-42d6-9e25-1ebba542098c/call-TumorCalculateTargetCoverage/shard-14"",; ""attempt"": 1,; ""executionEvents"": [; {; ""startTime"": ""2016-09-23T13:53:25.040Z"",; ""description"": ""Pending"",; ""endTime"": ""2016-09-23T13:53:25.122Z""; },; {; ""startTime"": ""2016-09-23T13:53:25.122Z"",; ""description"": ""PreparingJob"",; ""endTime"": ""2016-09-23T13:53:25.164Z""; },; {; ""startTime"": ""2016-09-23T13:53:25.164Z"",; ""description"": ""CheckingCallCache"",; ""endTime"": ""2016-09-23T13:53:25.291Z""; },; {; ""startTime"": ""2016-09-23T13:53:25.291Z"",; ""description"": ""RunningJob"",; ""endT",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1480:68669,message,message,68669,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1480,1,['message'],['message']
Integrability,"c-7c69317ba0a2/call-PairedFastQsToUnmappedBAM/inputs/-2135135022/S000021_S7367Nr1.2.fastq.gz --OUTPUT S7367Nr1.unmapped.bam --READ_GROUP_NAME S7367Nr1 --SAMPLE_NAME S4431Nr1 --LIBRARY_NAME TwistCore+RefSeq+Mito-Panel --PLATFORM_UNIT platform_unit --PLATFORM Illumina --SEQUENCING_CENTER CeGaT --RUN_DATE 2021-10-10T06:00:00+0000 --USE_SEQUENTIAL_FASTQS false --SORT_ORDER queryname --MIN_Q 0 --MAX_Q 93 --STRIP_UNPAIRED_MATE_NUMBER false --ALLOW_AND_IGNORE_EMPTY_LINES false --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 2 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX false --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false; 2023-02-03 12:38:34 [Fri Feb 03 09:38:34 GMT 2023] Executing as root@d65fc5b7d470 on Linux 5.15.49-linuxkit amd64; OpenJDK 64-Bit Server VM 1.8.0_242-8u242-b08-0ubuntu3~18.04-b08; Deflater: Intel; Inflater: Intel; Provider GCS is available; Picard version: Version:4.3.0.0; 2023-02-03 12:38:35 INFO 2023-02-03 09:38:35 FastqToSam Auto-detected quality format as: Standard.; 2023-02-03 12:39:08 INFO 2023-02-03 09:39:08 FastqToSam Processed 1,000,000 records. Elapsed time: 00:00:32s. Time for last 1,000,000: 32s. Last read position: */*`. I tried via Java 18.0.1.1 JDK and also later with 1.8.0_202 JDK. I also tried with the conda installation where Java dependency of OpenJDK 11.0.15 is automatically installed. I also tried combinations with Cromwell 69, 80 and 84. None of them works. They all have the same problem. It only works if I use Cromwell version 55 along with Java 1.8.0_202 JDK. It would be amazing if you look into this, as we would love to use the latest Cromwell versions and benefit from the conda environment. Thanks!. Machine info: `Darwin Ibrahims-MacBook-Pro.local 22.2.0 Darwin Kernel Version 22.2.0: Fri Nov 11 02:04:44 PST 2022; root:xnu-8792.61.2~4/RELEASE_ARM64_T8103 arm64`. MacOS = Ventura 13.1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6998:3105,depend,dependency,3105,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6998,1,['depend'],['dependency']
Integrability,"cal-disk -> /cromwell_root (10GB PERSISTENT_SSD); [2016-04-28 15:35:51,728] [warn] JesBackend [1cb9c1d2:jes_task]: 400 Bad Request; {; ""code"" : 400,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Invalid value for field \""resources.disk.name\"": 4fd1d1e01455dfdd4eabcf02c1abaf55\nDisk names must follow rules at https://cloud.google.com/compute/docs/reference/latest/disks#name"",; ""reason"" : ""badRequest""; } ],; ""message"" : ""Invalid value for field \""resources.disk.name\"": 4fd1d1e01455dfdd4eabcf02c1abaf55\nDisk names must follow rules at https://cloud.google.com/compute/docs/reference/latest/disks#name"",; ""status"" : ""INVALID_ARGUMENT""; }; com.google.api.client.googleapis.json.GoogleJsonResponseException: 400 Bad Request; {; ""code"" : 400,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Invalid value for field \""resources.disk.name\"": 4fd1d1e01455dfdd4eabcf02c1abaf55\nDisk names must follow rules at https://cloud.google.com/compute/docs/reference/latest/disks#name"",; ""reason"" : ""badRequest""; } ],; ""message"" : ""Invalid value for field \""resources.disk.name\"": 4fd1d1e01455dfdd4eabcf02c1abaf55\nDisk names must follow rules at https://cloud.google.com/compute/docs/reference/latest/disks#name"",; ""status"" : ""INVALID_ARGUMENT""; }; at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145); at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113); at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321); at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1056); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); at com.google.api.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/757:2491,message,message,2491,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/757,1,['message'],['message']
Integrability,"ces__aliases__human:var,genome_resources__aliases__snpeff:var,reference__snpeff__GRCh37_75:var,resources:var,description:var'[0m; [2018-05-02 15:16:55,18] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mbc4644da[0mbatch_for_variantcall:NA:1]: executing: sbatch -J cromwell_bc4644da_batch_for_variantcall -D /projects/ngs/oncology/dev/bcbio_validation_workflows/somatic-giab-mix/cromwell_work/cromwell-executions/main-somatic-giab-mix.cwl/bc4644da-87f9-4765-9791-9011a2fae80f/call-batch_for_variantcall -o /projects/ngs/oncology/dev/bcbio_validation_workflows/somatic-giab-mix/cromwell_work/cromwell-executions/main-somatic-giab-mix.cwl/bc4644da-87f9-4765-9791-9011a2fae80f/call-batch_for_variantcall/execution/stdout -e /projects/ngs/oncology/dev/bcbio_validation_workflows/somatic-giab-mix/cromwell_work/cromwell-executions/main-somatic-giab-mix.cwl/bc4644da-87f9-4765-9791-9011a2fae80f/call-batch_for_variantcall/execution/stderr -t 1-00:00 -p core --cpus-per-task=1 --mem=4026 --wrap ""/usr/bin/env bash /projects/ngs/oncology/dev/bcbio_validation_workflows/somatic-giab-mix/cromwell_work/cromwell-executions/main-somatic-giab-mix.cwl/bc4644da-87f9-4765-9791-9011a2fae80f/call-batch_for_variantcall/execution/script""; [2018-05-02 15:16:57,63] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mbc4644da[0mbatch_for_variantcall:NA:1]: job id: 134053; [2018-05-02 15:16:57,66] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mbc4644da[0mbatch_for_variantcall:NA:1]: Status change from - to WaitingForReturnCodeFile; [2018-05-02 15:17:05,03] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mbc4644da[0mbatch_for_variantcall:NA:1]: Status change from WaitingForReturnCodeFile to Done; [2018-05-02 15:22:54,62] [[38;5;1merror[0m] Failed to hash null; java.io.FileNotFoundException: Cannot hash file null because it can't be found; 	at cromwell.backend.impl.sfs.config.ConfigHashingStrategy.usingStandardInitData$1(ConfigHashingStrategy.scala:46); 	at cromwell.backend.i",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3584:4051,wrap,wrap,4051,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3584,1,['wrap'],['wrap']
Integrability,"cified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.known_indels_sites_VCFs' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_mu' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_alt' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_bwt' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.known_indels_sites_indices' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_dict' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_bed' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_fasta' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.dbSNP_vcf_index' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.dbSNP_vcf' not specified.""; }; ],; message: ""Workflow input processing failed""; }; ],; ```. But once I filled these out in my inputs json I then got this error. ```; [; {; causedBy: [; {; causedBy: [ ],; message: ""Missing inputs for subworkflow call SomaticRoot.TumorAlignment at index None: read_length, ref_fasta, agg_preemptible_tries, ref_dict, haplotype_database_file, ref_alt, ref_ann, known_indels_sites_indices, dbSNP_vcf, ref_sa, dbSNP_vcf_index, unmapped_bam_suffix, ref_amb, contamination_sites_ud, contamination_sites_bed, ref_bwt, ref_fasta_index, increase_disk_size, fingerprint_genotypes_file, preemptible_tries, known_indels_sites_VCFs, contamination_sites_mu, wgs_coverage_interval_list, ref_pac.""; }; ],; message: ""Couldn't resolve all inputs for SomaticRoot.TumorAlignment at index None.""; }; ],; ```. I think I",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2912:2742,message,message,2742,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2912,1,['message'],['message']
Integrability,"cker} bash \; ""$(echo ${script} | sed -e 's@.*cromwell-executions@/cromwell-executions@')""; """"""; filesystems {; local {; localization: [""hard-link""]; caching {; duplication-strategy: [""hard-link""]; hasing-strategy: ""fingerprint""; check-sibling-md5: true; fingerprint-size: 1048576 # 1 MB ; }; }; }; }; }; # For running jobs by submitting them from an interactive node to the cluster; SLURM {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; concurrent-job-limit = 500; root = ""cromwell-executions""; dockerRoot = ""/cromwell-executions"". runtime-attributes = """"""; Int cpus = 1; String mem = ""2g""; String dx_timeout; String? docker; """"""; check-alive = ""squeue -j ${job_id}""; exit-code-timeout-seconds = 500; job-id-regex = ""Submitted batch job (\\d+).*"". submit = """"""; sbatch \; --partition ind-shared \; --nodes 1 \; --job-name=${job_name} \; -o ${out} -e ${err} \; --ntasks-per-node=${cpus} \; --mem=${mem} \; -c ${cpus} \; --time=$(echo ${dx_timeout} | sed -e 's/ //g' -e 's/\([0-9]\+\)h\([0-9]\+\)m/\1:\2:00/' -e 's/\([0-9]\+\)h/\1:00:00/' -e 's/\([0-9]\+\)m/\1:00/') \; --chdir ${cwd} \; --wrap ""/bin/bash ${script}""; """"""; kill = ""scancel ${job_id}"". # We're asking bash-within-singularity to run the script, but the script's location on the machine; # is different then the location its mounted to in the container, so need to change the path with sed; submit-docker = """"""; sbatch \; --partition ind-shared \; --nodes 1 \; --job-name=${job_name} \; -o ${out} -e ${err} \; --ntasks-per-node=${cpus} \; --mem=${mem} \; -c ${cpus} \; --time=$(echo ${dx_timeout} | sed -e 's/ //g' -e 's/\([0-9]\+\)h\([0-9]\+\)m/\1:\2:00/' -e 's/\([0-9]\+\)h/\1:00:00/' -e 's/\([0-9]\+\)m/\1:00/') \; --chdir ${cwd} \; --wrap ""; singularity exec --containall --bind ${cwd}:${docker_cwd} docker://${docker} bash \; \""$(echo ${script} | sed -e 's@.*cromwell-executions@/cromwell-executions@')\""; ""; """"""; kill-docker = ""scancel ${job_id}"". filesystems {; local {; localizat",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7108:5836,wrap,wrap,5836,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7108,1,['wrap'],['wrap']
Integrability,"cle.execution.WorkflowExecutionActor.akka$actor$Timers$$super$aroundReceive(WorkflowExecutionActor.scala:57); 	at akka.actor.Timers.aroundReceive(Timers.scala:51); 	at akka.actor.Timers.aroundReceive$(Timers.scala:40); 	at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActor.aroundReceive(WorkflowExecutionActor.scala:57); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:614); 	at akka.actor.ActorCell.invoke(ActorCell.scala:583); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:268); 	at akka.dispatch.Mailbox.run(Mailbox.scala:229); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:241); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); 2024-03-12 18:49:15 cromwell-system-akka.actor.default-dispatcher-3 INFO - Message [cromwell.engine.workflow.lifecycle.EngineLifecycleActorAbortCommand$] from Actor[akka://cromwell-system/user/cromwell-service/WorkflowManagerActor/WorkflowActor-262d278a-cc62-4458-9150-f31976c2c554#401797350] to Actor[akka://cromwell-system/user/cromwell-service/WorkflowManagerActor/WorkflowActor-262d278a-cc62-4458-9150-f31976c2c554/WorkflowExecutionActor-262d278a-cc62-4458-9150-f31976c2c554#-742739735] was not delivered. [1] dead letters encountered, no more dead letters will be logged. If this is not an expected behavior, then [Actor[akka://cromwell-system/user/cromwell-service/WorkflowManagerActor/WorkflowActor-262d278a-cc62-4458-9150-f31976c2c554/WorkflowExecutionActor-262d278a-cc62-4458-9150-f31976c2c554#-742739735]] may have terminated unexpectedly, This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; ```; ```; {; 	""status"": ""Aborting"",; 	""id"": ""262d278a-cc62-4458-9150-f31976c2c5",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7385:6581,Message,Message,6581,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7385,1,['Message'],['Message']
Integrability,"cle.execution.WorkflowExecutionActor.akka$actor$Timers$$super$aroundReceive(WorkflowExecutionActor.scala:57); 	at akka.actor.Timers.aroundReceive(Timers.scala:51); 	at akka.actor.Timers.aroundReceive$(Timers.scala:40); 	at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActor.aroundReceive(WorkflowExecutionActor.scala:57); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:614); 	at akka.actor.ActorCell.invoke(ActorCell.scala:583); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:268); 	at akka.dispatch.Mailbox.run(Mailbox.scala:229); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:241); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); 2024-03-12 20:24:51 cromwell-system-akka.actor.default-dispatcher-4 INFO - Message [cromwell.engine.workflow.lifecycle.EngineLifecycleActorAbortCommand$] from Actor[akka://cromwell-system/user/cromwell-service/WorkflowManagerActor/WorkflowActor-a06a4c5e-fbf7-4c1d-ac71-b036aaf48fbc#2096097107] to Actor[akka://cromwell-system/user/cromwell-service/WorkflowManagerActor/WorkflowActor-a06a4c5e-fbf7-4c1d-ac71-b036aaf48fbc/WorkflowExecutionActor-a06a4c5e-fbf7-4c1d-ac71-b036aaf48fbc#659989485] was not delivered. [1] dead letters encountered, no more dead letters will be logged. If this is not an expected behavior, then [Actor[akka://cromwell-system/user/cromwell-service/WorkflowManagerActor/WorkflowActor-a06a4c5e-fbf7-4c1d-ac71-b036aaf48fbc/WorkflowExecutionActor-a06a4c5e-fbf7-4c1d-ac71-b036aaf48fbc#659989485]] may have terminated unexpectedly, This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; ```; ```; {; 	""status"": ""Aborting"",; 	""id"": ""a06a4c5e-fbf7-4c1d-ac71-b036aaf48fb",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7386:8344,Message,Message,8344,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7386,1,['Message'],['Message']
Integrability,"commit/a5d205c7956dbed302b3bb5ecde5ba4299f0b646""><code>a5d205c</code></a> Fix GitHub link in FAQ (<a href=""https://github-redirect.dependabot.com/junit-team/junit4/issues/1672"">#1672</a>)</li>; <li><a href=""https://github.com/junit-team/junit4/commit/3a5c6b4d08f408c8ca6a8e0bae71a9bc5a8f97e8""><code>3a5c6b4</code></a> Deprecated since jdk9 replacing constructor instance of Double and Float (<a href=""https://github-redirect.dependabot.com/junit-team/junit4/issues/1660"">#1660</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/junit-team/junit4/compare/r4.13...r4.13.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=junit:junit&package-manager=maven&previous-version=4.13&new-version=4.13.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/configuring-github-dependabot-security-updates). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5941:4151,Depend,Dependabot,4151,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5941,1,['Depend'],['Dependabot']
Integrability,"cromwell version: 29-675e865-SNAP. I have a `read_lines` call inside of a `scatter` definition like . ```; scatter (file in read_lines(shard_fofn)){; 		call SelectVariants{; 			input:; 				vcf=file,; 				intervals=interval_list; 		}; 	}; ```. where `shard fofn` has 20k+ lines inside of it. When running this workflow different shards failed ; with one of two errors. 30-50 different shards would fail each retry. ```; {; failures: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [ ],; message: ""Data received in non-data state: 6""; }; ],; message: ""Connection has been shutdown: javax.net.ssl.SSLProtocolException: Data received in non-data state: 6""; }; ],; message: ""Connection has been shutdown: javax.net.ssl.SSLProtocolException: Data received in non-data state: 6""; }; ],; message: ""All reopens failed""; }; ],; message: ""vcf""; }; ],; message: ""Input evaluation for Call mergeAndGetSites.SelectVariants failed.""; }; ],; message: ""Couldn't resolve all inputs for mergeAndGetSites.SelectVariants at index Some(778).""; }; ],; attempt: 1,; shardIndex: 778; },; ```; or . ```; {; failures: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [ ],; message: ""Connection closed prematurely: bytesRead = 34066, Content-Length = 2974047""; }; ],; message: ""Connection closed prematurely: bytesRead = 34066, Content-Length = 2974047""; }; ],; message: ""All reopens failed""; }; ],; message: ""vcf""; }; ],; message: ""Input evaluation for Call mergeAndGetSites.SelectVariants failed.""; }; ],; message: ""Couldn't resolve all inputs for mergeAndGetSites.SelectVariants at index Some(19820).""; }; ],; attempt: 1,; shardIndex: 19820; }; ]; },; ```. When I take the `read_lines(shard_fofn)` and assign it to a variable and then pass that to the scatter everything works fine. Is this just bad luck or is there possibly a real issue here?. ```; 	Array[File] fofn_files = read_lines(shard_fofn). 	scatter (file",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2965:550,message,message,550,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2965,6,['message'],['message']
Integrability,"cs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>🔍 Files still referring to the old version number</summary>. The following files still refer to the old version number (0.9.0).; You might want to review and update them manually.; ```; centaur/src/main/resources/integrationTestCases/Somatic/CNV-Pair/cnv_somatic_pair_workflow_do_gc_wes.inputs; centaur/src/main/resources/integrationTestCases/Somatic/CNV-Panel/cnv_somatic_panel_workflow_do_gc_wes.inputs; centaur/src/main/resources/integrationTestCases/Somatic/Mutect2/Mutect2.aws.inputs; centaur/src/main/resources/integrationTestCases/Somatic/Mutect2/Mutect2.inputs; centaur/src/main/resources/integrationTestCases/germline/haplotype-caller-workflow/HaplotypeCallerWF.json; centaur/src/main/resources/integrationTestCases/germline/single-sample-production-workflow/PairedEndSingleSampleWf.options.json; centaur/src/main/resources/integrationTestCases/germline/single-sample-workflow/processing-for-variant-discovery-gatk4.hg38.wgs.inputs.json; centaur/src/main/resources/integrationTestCases/green/arrays/arrays.wdl; womtool/src/test/resources/validate/wdl_draft3/valid/HaplotypeCallerWF/HaplotypeCallerWF.inputs.json; womtool/src/test/resources/validate/wdl_draft3/valid/cnv_somatic_pair_workflow/cnv_somatic_pair_workflow.inputs.json; womtool/src/test/resources/validate/wdl_draft3/valid/joint-discovery-gatk/joint-discovery-gatk.inputs.json; ```; </details>; <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""io.github.jbwheatley"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""io.github.jbwheatley"" }; }]; ```; </details>. <sup>; labels: library-update, early-semver-major, semver-spec-minor, old-version-remains, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7294:1901,integrat,integrationTestCases,1901,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7294,5,"['depend', 'integrat']","['dependency', 'dependencyOverrides', 'integrationTestCases']"
Integrability,"ctor.scala:136); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:527); at akka.actor.ActorCell.invoke(ActorCell.scala:496); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); at akka.dispatch.Mailbox.run(Mailbox.scala:224); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). [2017-12-05 20:11:24,83] [warn] Couldn't find a suitable DSN, defaulting to a Noop one.; [2017-12-05 20:11:24,84] [info] Using noop to send events.; [2017-12-05 20:11:24,85] [info] WorkflowManagerActor WorkflowActor-159210e6-fa6a-4a99-b386-5931ae245324 is in a terminal state: WorkflowFailedState; [2017-12-05 20:11:32,22] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2017-12-05 20:11:32,25] [info] Message [cromwell.core.actor.StreamActorHelper$StreamFailed] without sender to Actor[akka://cromwell-system/deadLetters] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2017-12-05 20:11:32,26] [info] Message [cromwell.core.actor.StreamActorHelper$StreamFailed] without sender to Actor[akka://cromwell-system/deadLetters] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; Workflow 159210e6-fa6a-4a99-b386-5931ae245324 transitioned to state Failed; [2017-12-05 20:11:32,30] [info] Automatic shutdown of the async connection; [2017-12-05 20:11:32,30] [info] Gracefully shutdown sentry threads.; [2017-12-05 20:11:32,30] [info] Shutdown finished.; ```; This code worked with `cromwell-29.jar`.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3007:6079,Message,Message,6079,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3007,2,['Message'],['Message']
Integrability,"currently looking at a Proof of Concept with Cromwell and AWS batch.; We trying to understand the **CallCaching** trigger(s), as we require this if the next step in a multi-step workflow breaks. Currently, we have set up the in-memory version and are not using any form of database. We have added the following to the configuration file:; `call-caching {; enabled = true; invalidate-bad-cache-results = true; }`. **Question 1.**. Can call caching be initiated if there is only the in-memory database, as below is not clear regarding this?; _""Cromwell's call cache is maintained in its database. In order for call caching to be used on any previously run jobs, it is best to configure Cromwell to point to a MySQL database instead of the default in-memory database. This way any invocation of Cromwell (either with run or server subcommands) will be able to utilize results from all calls that are in that database.""_. Secondly, if this can. **Question 2.**. Can call caching be initiated if a scatter, wraps a workflow, which then wraps tools.; Or will the entire workflow need to be in one script? (I have attached an example as zip); And, the options file.; [DsTrim - Broken.zip](https://github.com/broadinstitute/cromwell/files/3842334/DsTrim.-.Broken.zip). **Question 3.**. What exactly triggers callcaching to change from ""CallCachingOff"" to on, in the following result?; `; ""callCaching"": {; ""effectiveCallCachingMode"": ""CallCachingOff"",; ""allowResultReuse"": false,; ""hit"": false,; ""result"": ""Cache Miss""; },`. **If the in-memory is the issue, then please close and we will set-up a UAT correctly.; If not any additional assistance or comments will be most apprecitated.** . ###; ### IMPORTANT: Please file new issues over in our Jira issue tracker!; ###; ### https://broadworkbench.atlassian.net/projects/BA/issues; ###; ### You may need to create an account before you can view/create issues.; ###. <!--; Hi! Thanks for taking the time to report feedback. Before posting an issue over in Jira",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5280:1107,wrap,wraps,1107,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5280,2,['wrap'],['wraps']
Integrability,"cutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:49); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: io.grpc.StatusRuntimeException: UNAVAILABLE: io exception; Channel Pipeline: [SslHandler#0, ProtocolNegotiators$ClientTlsHandler#0, WriteBufferingAndExceptionHandler#0, DefaultChannelPipeline$TailContext#0]; at io.grpc.Status.asRuntimeException(Status.java:539); ... 14 common frames omitted; Caused by: javax.net.ssl.SSLHandshakeException: General OpenSslEngine problem; at io.grpc.netty.shaded.io.netty.handler.ssl.ReferenceCountedOpenSslEngine.handshakeException(ReferenceCountedOpenSslEngine.java:1907); at io.grpc.netty.shaded.io.netty.handler.ssl.ReferenceCountedOpenSslEngine.wrap(ReferenceCountedOpenSslEngine.java:834); at java.base/javax.net.ssl.SSLEngine.wrap(SSLEngine.java:564); at io.grpc.netty.shaded.io.netty.handler.ssl.SslHandler.wrap(SslHandler.java:1041); at io.grpc.netty.shaded.io.netty.handler.ssl.SslHandler.wrapNonAppData(SslHandler.java:927); at io.grpc.netty.shaded.io.netty.handler.ssl.SslHandler.unwrap(SslHandler.java:1409); at io.grpc.netty.shaded.io.netty.handler.ssl.SslHandler.unwrapNonAppData(SslHandler.java:1327); at io.grpc.netty.shaded.io.netty.handler.ssl.SslHandler.access$1800(SslHandler.java:169); at io.grpc.netty.shaded.io.netty.handler.ssl.SslHandler$SslTasksRunner.resumeOnEventExecutor(SslHandler.java:1718); at io.grpc.netty.shaded.io.netty.handler.ssl.SslHandler$SslTasksRunner.access$2000(SslHandler.java:1609); at io.grpc.netty.shaded.io.netty.handler.ssl.SslHandler$SslTasksRunner$2.run(SslHandler.java:1770); at io.grpc.netty.shaded.io.netty.util.concurrent.AbstractEventExecutor.runTask(AbstractEventExecutor.java:174); at io.grpc.netty.shaded.io",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7551:5169,wrap,wrap,5169,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7551,1,['wrap'],['wrap']
Integrability,"d 6 different adult normal tissues were purchased from different sources (Agilent, Biochain and OriGene). The qualities of these total RNA were tested using the Agilent Bioanalyzer 2100 Eukaryote Total RNA Nano Series II. Only total RNAs with a RIN score of more than 7 were used for RNA-Seq library construction\nRibosomal RNA (rRNA) was removed from total RNA using the RiboMinus™ Eukaryote Kit for RNA-Seq from Ambion. The ribosomal RNA depleted RNA fraction is termed the RiboMinus™ RNA fraction and is enriched in polyadenylated (polyA) mRNA, non-polyadenylated RNA, pre-processed RNA, tRNA, and may also contain regulatory RNA molecules such as microRNA (miRNA) and short interfering RNA (siRNA), snRNA, and other RNA transcripts of yet unknown function. Ambion RiboMinus rRNA depletion was performed as described in the manufacturer’s protocol (Pub. Part no.: 100004590, Rev. date 2 December 2011) following the standard protocol.\nTruSeq RNA Sample Preparation was performed on the RiboMinus™ RNA fraction as described in the manufacturer’s protocol (Pub. Part no.: 15026495 Rev. F March 2014) following the low sample protocol.\nThe libraries were sequenced on Illumina’s HiSeq 2000 instrument following standard protocol."",; ""processing"" : ""Data quality check using fastQC version 0.11.2.\nAlignment of unpaired unstranded reads using STAR version 2.4.0.\nQuantification of transcripts and isoforms using RSEM version 1.2.21 using rsem-calculate-expression, both alignment and quantification was done using the STAR_RSEM.sh pipeline (https://github.com/ENCODE-DCC/long-rna-seq-pipeline/blob/master/DAC/STAR_RSEM.sh)\nThe programe featurecounts version 1.4.6-p2 from the SourceForge Subread package was used to produce a summary file of counts from all the alignement .bam files.\nThe summary file of counts (RNAseq.counts) was used to plot the multidimensional scaling plot using edgeR version 3.1.3.\nThe *.osc.gz files were loaded into the genome browser ZENBU and was used visualize the ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4519:1776,protocol,protocol,1776,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4519,1,['protocol'],['protocol']
Integrability,"d a proxy.\n""; }],; ""workflowLog"": ""gs://fc-2d3fd356-e3be-4953-92f1-60af623e6fa5/b6b190d6-8640-4638-94cd-15f16b194f38/workflow.logs/workflow.c386672d-0248-4968-9b1a-114f5f5c4706.log"",; ""end"": ""2017-01-30T19:14:20.002Z"",; ""start"": ""2017-01-30T19:00:03.040Z""; }. ```; Here it's an array of ""message""s; ```; {; ""workflowName"": ""aggregate_data_workflow"",; ""submittedFiles"": {... },; ""calls"": {; ""aggregate_data_workflow.aggregate_data"": [{; ""retryableFailure"": false,; ""executionStatus"": ""Failed"",; ""stdout"": ""/cromwell-executions/aggregate_data_workflow/3608d6ca-fbb4-4232-b197-268058470bfc/call-aggregate_data/execution/stdout"",; ""shardIndex"": -1,; ""runtimeAttributes"": {; ""docker"": ""broadgdac/aggregate_data:31"",; ""failOnStderr"": false,; ""continueOnReturnCode"": ""0""; },; ""cache"": {; ""allowResultReuse"": true; },; ""Effective call caching mode"": ""CallCachingOff"",; ""inputs"": {...; },; ""returnCode"": -1,; ""failures"": [{; ""message"": ""Call aggregate_data_workflow.aggregate_data: return code was -1""; }, {; ""message"": ""Call aggregate_data_workflow.aggregate_data: return code was -1""; }, {; ""message"": ""Call aggregate_data_workflow.aggregate_data: return code was -1""; }],; ""jobId"": ""2957"",; ""backend"": ""JES"",; ""end"": ""2016-12-02T15:05:42.655Z"",; ""stderr"": ""/cromwell-executions/aggregate_data_workflow/3608d6ca-fbb4-4232-b197-268058470bfc/call-aggregate_data/execution/stderr"",; ""callRoot"": ""/cromwell-executions/aggregate_data_workflow/3608d6ca-fbb4-4232-b197-268058470bfc/call-aggregate_data"",; ""attempt"": 1,; ""executionEvents"": [...]; },; ""outputs"": {. },; ""workflowRoot"": ""gs://fc-2d3fd356-e3be-4953-92f1-60af623e6fa5/9ea737cd-a512-4c62-820c-dd1505ea7676/aggregate_data_workflow/3608d6ca-fbb4-4232-b197-268058470bfc"",; ""id"": ""3608d6ca-fbb4-4232-b197-268058470bfc"",; ""inputs"": {...; },; ""submission"": ""2016-12-01T21:21:40.188Z"",; ""status"": ""Failed"",; ""failures"": [{; ""message"": ""Call aggregate_data_workflow.aggregate_data: return code was -1""; }, {; ""message"": ""Call aggregate_data_workflow.aggregate_",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2037:3986,message,message,3986,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2037,1,['message'],['message']
Integrability,d out; java.net.SocketTimeoutException: Read timed out; at java.net.SocketInputStream.socketRead0(Native Method); at java.net.SocketInputStream.socketRead(SocketInputStream.java:116); at java.net.SocketInputStream.read(SocketInputStream.java:171); at java.net.SocketInputStream.read(SocketInputStream.java:141); at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); at sun.security.ssl.InputRecord.read(InputRecord.java:503); at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:975); at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:933); at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); at java.io.BufferedInputStream.read(BufferedInputStream.java:345); at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:735); at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:678); at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1587); at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1492); at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480); at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:347); at com.google.api.client.http.javanet.NetHttpResponse.<init>(NetHttpResponse.java:37); at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:143); at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:84); at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1040); at com.google.api.client.googleapis.batch.BatchRequest.execute(BatchRequest.java:233); at cromwell.backend.google.pipelines.common.api.PipelinesApiRequestWorker.runBatch(PipelinesApiRequestWorker.scala:59); at cromwell.backend.google.pipelines.common.api.PipelinesApiRequestWorker.cromwell$backend$google$pipelines$common$a,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4914:2322,protocol,protocol,2322,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4914,1,['protocol'],['protocol']
Integrability,"d"" and fails with this stack trace on ""30-a3ea825-SNAP"" using the Pipelines API backend. ```; failures: [; {; causedBy: [; {; causedBy: [ ],; message: ""This workflow contains a cyclic dependency on SomaticPairedEndSingleSampleWorkflow.$scatter_2""; },; {; causedBy: [ ],; message: ""wdl.Scope.childGraphNodesSorted(Scope.scala:52)""; },; {; causedBy: [ ],; message: ""wdl.Scope.childGraphNodesSorted$(Scope.scala:43)""; },; {; causedBy: [ ],; message: ""wdl.WdlWorkflow.childGraphNodesSorted$lzycompute(WdlWorkflow.scala:63)""; },; {; causedBy: [ ],; message: ""wdl.WdlWorkflow.childGraphNodesSorted(WdlWorkflow.scala:63)""; },; {; causedBy: [ ],; message: ""wdl.WdlGraphNode$.buildWomGraph(WdlGraphNode.scala:140)""; },; {; causedBy: [ ],; message: ""wdl.WdlWorkflow$.womWorkflowDefinition(WdlWorkflow.scala:52)""; },; {; causedBy: [ ],; message: ""wdl.WdlWorkflow.womDefinition$lzycompute(WdlWorkflow.scala:73)""; },; {; causedBy: [ ],; message: ""wdl.WdlWorkflow.womDefinition(WdlWorkflow.scala:73)""; },; {; causedBy: [ ],; message: ""wdl.WdlInputParsing$.buildWomExecutable(WdlInputParsing.scala:27)""; },; {; causedBy: [ ],; message: ""wdl.WdlNamespaceWithWorkflow.womExecutable(WdlNamespace.scala:98)""; },; {; causedBy: [ ],; message: ""cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.$anonfun$validateWdlNamespace$15(MaterializeWorkflowDescriptorActor.scala:493)""; },; {; causedBy: [ ],; message: ""scala.util.Either.flatMap(Either.scala:338)""; },; {; causedBy: [ ],; message: ""cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.$anonfun$validateWdlNamespace$13(MaterializeWorkflowDescriptorActor.scala:491)""; },; {; causedBy: [ ],; message: ""scala.util.Either.flatMap(Either.scala:338)""; },; {; causedBy: [ ],; message: ""cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.validateWdlNamespace(MaterializeWorkflowDescriptorActor.scala:490)""; },; {; causedBy: [ ],; message: ""cromwell.engine.workflow.lifecyc",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3143:1048,message,message,1048,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3143,1,['message'],['message']
Integrability,"d' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_amb' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.preemptible_tries' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_sa' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.known_indels_sites_VCFs' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_mu' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_alt' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_bwt' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.known_indels_sites_indices' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_dict' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_bed' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_fasta' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.dbSNP_vcf_index' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.dbSNP_vcf' not specified.""; }; ],; message: ""Workflow input processing failed""; }; ],; ```. But once I filled these out in my inputs json I then got this error. ```; [; {; causedBy: [; {; causedBy: [ ],; message: ""Missing inputs for subworkflow call SomaticRoot.TumorAlignment at index None: read_length, ref_fasta, agg_preemptible_tries, ref_dict, haplotype_database_file, ref_alt, ref_ann, known_indels_sites_indices, dbSNP_vcf, ref_sa, dbSNP_vcf_index, unmapped_bam_suffix, r",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2912:2390,message,message,2390,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2912,1,['message'],['message']
Integrability,"d(classpath(""application"")). webservice {; }. akka {; http {; server {; }; }; }. system {; io {; }; input-read-limits {; }; job-rate-control {; jobs = 2; per = 1 second; }. abort {; scan-frequency: 30 seconds; cache {; enabled: true; concurrency: 1; ttl: 20 minutes; size: 100000; }; }. dns-cache-ttl: 3 minutes; }. workflow-options {; default {; }; }. call-caching {; enabled = true; }. google {; }. docker {; hash-lookup {; }; }. engine {; filesystems {; local {; }; }; }. languages {; WDL {; versions {; ""draft-2"" {; }; ""1.0"" {; }; }; }; CWL {; versions {; ""v1.0"" {; }; }; }; }. backend {; default = ""SLURM"". providers {. SLURM {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; concurrent-job-limit = 500; runtime-attributes = """"""; Int runtime_minutes = 720; Int cpus = 1; Int requested_memory_mb_per_core = 8000; String queue = ""short""; """""". exit-code-timeout-seconds = 600. submit = """"""; sbatch -J ${job_name} -D ${cwd} -o ${out} -e ${err} -t ${runtime_minutes} -p ${queue} \; ${""-n "" + cpus} \; --mem-per-cpu=${requested_memory_mb_per_core} \; --constraint=""groups"" \; --qos=ded_reich \; --account=""reich"" \; --wrap ""/usr/bin/env bash ${script}""; """"""; kill = ""scancel ${job_id}""; check-alive = ""squeue -j ${job_id}""; job-id-regex = ""Submitted batch job (\\d+).*"". filesystems {; local {; localization: [; ""hard-link"", ""soft-link"", ""copy""; ]. caching {; duplication-strategy: [; ""soft-link""; ]. hashing-strategy: ""path"". check-sibling-md5: false; }; }; }. default-runtime-attributes {; failOnStderr: false; continueOnReturnCode: 0; }; }; }; }; }. services {; MetadataService {; }. Instrumentation {; }; HealthMonitor {; config {; }; }; LoadController {; config {; }; }; }. database {; driver = ""slick.jdbc.MySQLProfile$"". db {; driver = ""com.mysql.cj.jdbc.Driver""; url = ""jdbc:mysql://database.host/callcachingdatabase?rewriteBatchedStatements=true""; user = ${USER}; password = ${MYSQL_DB_PW}; connectionTimeout = 5000; }. migration {; }; }. ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6929:3531,wrap,wrap,3531,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6929,1,['wrap'],['wrap']
Integrability,"d6b353e699397eb090a1fd27411fa24""><code>c29dd82</code></a> Change version to 4.13.1-SNAPSHOT</li>; <li><a href=""https://github.com/junit-team/junit4/commit/1d174861f0b64f97ab0722bb324a760bfb02f567""><code>1d17486</code></a> Add a link to assertThrows in exception testing</li>; <li><a href=""https://github.com/junit-team/junit4/commit/543905df72ff10364b94dda27552efebf3dd04e9""><code>543905d</code></a> Use separate line for annotation in Javadoc</li>; <li><a href=""https://github.com/junit-team/junit4/commit/510e906b391e7e46a346e1c852416dc7be934944""><code>510e906</code></a> Add sub headlines to class Javadoc</li>; <li><a href=""https://github.com/junit-team/junit4/commit/610155b8c22138329f0723eec22521627dbc52ae""><code>610155b</code></a> Merge pull request from GHSA-269g-pwp5-87pp</li>; <li><a href=""https://github.com/junit-team/junit4/commit/b6cfd1e3d736cc2106242a8be799615b472c7fec""><code>b6cfd1e</code></a> Explicitly wrap float parameter for consistency (<a href=""https://github-redirect.dependabot.com/junit-team/junit4/issues/1671"">#1671</a>)</li>; <li><a href=""https://github.com/junit-team/junit4/commit/a5d205c7956dbed302b3bb5ecde5ba4299f0b646""><code>a5d205c</code></a> Fix GitHub link in FAQ (<a href=""https://github-redirect.dependabot.com/junit-team/junit4/issues/1672"">#1672</a>)</li>; <li><a href=""https://github.com/junit-team/junit4/commit/3a5c6b4d08f408c8ca6a8e0bae71a9bc5a8f97e8""><code>3a5c6b4</code></a> Deprecated since jdk9 replacing constructor instance of Double and Float (<a href=""https://github-redirect.dependabot.com/junit-team/junit4/issues/1660"">#1660</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/junit-team/junit4/compare/r4.13...r4.13.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=junit:junit&package-manager=maven&previous-version=4.13&new-version=4.13.1)](https://docs.github.com/en/github/managing-security-vu",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5941:3082,depend,dependabot,3082,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5941,1,['depend'],['dependabot']
Integrability,"d: generic::unknown: installing drivers: container exited with unexpected exit code 1: + COS_KERNEL_INFO_FILENAME=kernel_info\n+ COS_KERNEL_SRC_ARCHIVE=kernel-src.tar.gz\n+ COS_KERNEL_SRC_HEADER=kernel-headers.tgz\n+ TOOLCHAIN_URL_FILENAME=toolchain_url\n+ TOOLCHAIN_ARCHIVE=toolchain.tar.xz\n+ TOOLCHAIN_ENV_FILENAME=toolchain_env\n+ TOOLCHAIN_PKG_DIR=/build/cos-tools\n+ CHROMIUMOS_SDK_GCS=https://storage.googleapis.com/chromiumos-sdk\n+ ROOT_OS_RELEASE=/root/etc/os-release\n+ KERNEL_SRC_DIR=/build/usr/src/linux\n+ KERNEL_SRC_HEADER=/build/usr/src/linux-headers\n+ NVIDIA_DRIVER_VERSION=450.51.06\n+ NVIDIA_DRIVER_MD5SUM=\n+ NVIDIA_INSTALL_DIR_HOST=/var/lib/nvidia\n+ NVIDIA_INSTALL_DIR_CONTAINER=/usr/local/nvidia\n+ ROOT_MOUNT_DIR=/root\n+ CACHE_FILE=/usr/local/nvidia/.cache\n+ LOCK_FILE=/root/tmp/cos_gpu_installer_lock\n+ LOCK_FILE_FD=20\n+ set +x\n[INFO 2021-02-22 23:09:17 UTC] PRELOAD: false\n[INFO 2021-02-22 23:09:17 UTC] Running on COS build id 13310.1209.10\n[INFO 2021-02-22 23:09:17 UTC] Data dependencies (e.g. kernel source) will be fetched from https://storage.googleapis.com/cos-tools/13310.1209.10\n[INFO 2021-02-22 23:09:17 UTC] Getting the kernel source repository path.\n[INFO 2021-02-22 23:09:17 UTC] Obtaining kernel_info file from https://storage.googleapis.com/cos-tools/13310.1209.10/kernel_info\n[INFO 2021-02-22 23:09:19 UTC] Downloading kernel_info file from https://storage.googleapis.com/cos-tools/13310.1209.10/kernel_info\n\nreal\t0m0.072s\nuser\t0m0.013s\nsys\t0m0.006s\n[INFO 2021-02-22 23:09:19 UTC] Checking if this is the only cos-gpu-installer that is running.\n[INFO 2021-02-22 23:09:19 UTC] Checking if third party kernel modules can be installed\n[INFO 2021-02-22 23:09:19 UTC] Checking cached version\n[INFO 2021-02-22 23:09:19 UTC] Cache file /usr/local/nvidia/.cache not found.\n[INFO 2021-02-22 23:09:19 UTC] Did not find cached version, building the drivers...\n[INFO 2021-02-22 23:09:19 UTC] Downloading GPU installer ... \n[INFO 2021-02-22 23:09",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6195:3024,depend,dependencies,3024,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6195,1,['depend'],['dependencies']
Integrability,"d; [2022-12-15 21:28:53,46] [info] Shutting down WorkflowStoreActor - Timeout = 5 seconds; [2022-12-15 21:28:53,46] [info] Aborting all running workflows.; [2022-12-15 21:28:53,46] [info] 0 workflows released by cromid-b254006; [2022-12-15 21:28:53,47] [info] WorkflowStoreActor stopped; [2022-12-15 21:28:53,47] [info] Shutting down WorkflowLogCopyRouter - Timeout = 5 seconds; [2022-12-15 21:28:53,47] [info] WorkflowLogCopyRouter stopped; [2022-12-15 21:28:53,47] [info] Shutting down JobExecutionTokenDispenser - Timeout = 5 seconds; [2022-12-15 21:28:53,47] [info] JobExecutionTokenDispenser stopped; [2022-12-15 21:28:53,47] [info] Shutting down WorkflowManagerActor - Timeout = 3600 seconds; [2022-12-15 21:28:53,47] [info] WorkflowManagerActor: All workflows finished; [2022-12-15 21:28:53,47] [info] WorkflowManagerActor stopped; [2022-12-15 21:28:53,71] [info] Connection pools shut down; [2022-12-15 21:28:53,71] [info] Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds; [2022-12-15 21:28:53,71] [info] Shutting down JobStoreActor - Timeout = 1800 seconds; [2022-12-15 21:28:53,71] [info] Shutting down CallCacheWriteActor - Timeout = 1800 seconds; [2022-12-15 21:28:53,71] [info] Shutting down ServiceRegistryActor - Timeout = 1800 seconds; [2022-12-15 21:28:53,71] [info] Shutting down DockerHashActor - Timeout = 1800 seconds; [2022-12-15 21:28:53,71] [info] Shutting down IoProxy - Timeout = 1800 seconds; [2022-12-15 21:28:53,71] [info] CallCacheWriteActor Shutting down: 0 queued messages to process; [2022-12-15 21:28:53,72] [info] SubWorkflowStoreActor stopped; [2022-12-15 21:28:53,72] [info] JobStoreActor stopped; [2022-12-15 21:28:53,72] [info] CallCacheWriteActor stopped; [2022-12-15 21:28:53,72] [info] IoProxy stopped; [2022-12-15 21:28:53,74] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2022-12-15 21:28:53,74] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6971:50604,message,messages,50604,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6971,1,['message'],['messages']
Integrability,"dJobExecutionActor.scala:74); at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustExecuteOrRecover$1(AsyncBackendJobExecutionActor.scala:65); at cromwell.core.retry.Retry$.withRetry(Retry.scala:38); at cromwell.backend.async.AsyncBackendJobExecutionActor.withRetry(AsyncBackendJobExecutionActor.scala:61); at cromwell.backend.async.AsyncBackendJobExecutionActor.cromwell$backend$async$AsyncBackendJobExecutionActor$$robustExecuteOrRecover(AsyncBackendJobExecutionActor.scala:65); at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$receive$1.applyOrElse(AsyncBackendJobExecutionActor.scala:88); at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); at akka.actor.Actor.aroundReceive(Actor.scala:517); at akka.actor.Actor.aroundReceive$(Actor.scala:515); at cromwell.backend.impl.aws.AwsBatchAsyncBackendJobExecutionActor.aroundReceive(AwsBatchAsyncBackendJobExecutionActor.scala:74); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:588); at akka.actor.ActorCell.invoke(ActorCell.scala:557); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258); at akka.dispatch.Mailbox.run(Mailbox.scala:225); at akka.dispatch.Mailbox.exec(Mailbox.scala:235); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); ```. I understand why this is happening - Cromwell is simply sending too many requests to AWS Batch over a short space of time. However the limit is apparently 500 per second (https://forums.aws.amazon.com/thread.jspa?messageID=708581), so perhaps Cromwell is doing something unusual. In the short term, I think the best solution is to catch this exception, sleep for a while, and then continue sending requests.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4303:8302,message,messageID,8302,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4303,1,['message'],['messageID']
Integrability,"d](https://github.com/circe/circe); * [io.circe:circe-shapes](https://github.com/circe/circe). from 0.13.0 to 0.14.1.; [GitHub Release Notes](https://github.com/circe/circe/releases/tag/v0.14.1) - [Version Diff](https://github.com/circe/circe/compare/v0.13.0...v0.14.1). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/92f43ce5f010fa03daeb2625a3f9c1b1be80cca5/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Files still referring to the old version number</summary>. The following files still refer to the old version number (0.13.0).; You might want to review and update them manually.; ```; centaur/src/main/resources/integrationTestCases/cwl/bcbio/gvcf-joint-workflow/steps/process_alignment.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/gvcf-joint-workflow/steps/variantcall_batch_region.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/prealign-workflow/steps/variantcall_batch_region.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/rnaseq-workflow/steps/prepare_sample.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/somatic-workflow/steps/detect_sv.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/somatic-workflow/steps/process_alignment.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/somatic-workflow/steps/variantcall_batch_region.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/svcall-workflow/steps/detect_sv.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/svcall-workflow/steps/process_alignment.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/svcall-workflow/steps/variantcall_batch_region.c",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6410:1398,integrat,integrationTestCases,1398,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6410,1,['integrat'],['integrationTestCases']
Integrability,"d_name isn't null, return that. Otherwise return sample_name + \\\""_N\\\"" if sample_type is normal or sample_name + \\\""_T\\\"" if sample_type is tumour */ if (specified_name !== null){ return specified_name; } else if (sample_type === \\\""normal\\\"") { return sample_name + \\\""_N\\\""; } else if (sample_type === \\\""tumor\\\"") { return sample_name + \\\""_T\\\""; } else { /* Unsure what happened here */ return \\\""\\\""; } }\""\n ],\n \""class\"": \""InlineJavascriptRequirement\""\n },\n {\n \""class\"": \""MultipleInputFeatureRequirement\""\n },\n {\n \""class\"": \""StepInputExpressionRequirement\""\n }\n ],\n \""inputs\"": [\n {\n \""type\"": [\n \""null\"",\n \""File\""\n ],\n \""doc\"": \""bed file of het SNP locations used by amber as -loci\\n\"",\n \""id\"": \""#bafsnps_amber\""\n },\n {\n \""type\"": [\n \""null\"",\n \""File\""\n ],\n \""doc\"": \""Optional - BED file containing regions to ignore\\n\"",\n \""id\"": \""#blacklist_gridss\""\n },\n {\n \""type\"": [\n \""null\"",\n \""File\""\n ],\n \""doc\"": \""Single breakend pon bed file\\n\"",\n \""id\"": \""#breakend_pon_gripss\""\n },\n {\n \""type\"": [\n \""null\"",\n \""File\""\n ],\n \""doc\"": \""Paired breakpoint hotspot bedpe file\\n\"",\n \""id\"": \""#breakpoint_hotspot_gripss\""\n },\n {\n \""type\"": [\n \""null\"",\n \""File\""\n ],\n \""doc\"": \""Paired breakpoint pon bedpe file\\n\"",\n \""id\"": \""#breakpoint_pon_gripss\""\n },\n {\n \""type\"": [\n \""null\"",\n \""int\""\n ],\n \""doc\"": \""threshold for # SVs in clusters to skip chaining routine (default = 2000)\\n\"",\n \""id\"": \""#chaining_sv_limit_linx\""\n },\n {\n \""type\"": [\n \""null\"",\n \""boolean\""\n ],\n \""doc\"": \""Optional - Discover and annotate gene fusions\\n\"",\n \""id\"": \""#check_drivers_linx\""\n },\n {\n \""type\"": [\n \""null\"",\n \""boolean\""\n ],\n \""doc\"": \""Optional - discover and annotate gene fusions\\n\"",\n \""id\"": \""#check_fusions_linx\""\n },\n {\n \""type\"": [\n \""null\"",\n \""File\""\n ],\n \""doc\"": \""list of known fragile sites - specify Chromosome,PosStart,PosEnd - fragile_sites.csv\\n\"",\n \""id\"": \""#fragile_",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5826:104770,rout,routine,104770,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5826,1,['rout'],['routine']
Integrability,"date this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>🔍 Files still referring to the old version number</summary>. The following files still refer to the old version number (0.9.0).; You might want to review and update them manually.; ```; centaur/src/main/resources/integrationTestCases/Somatic/CNV-Pair/cnv_somatic_pair_workflow_do_gc_wes.inputs; centaur/src/main/resources/integrationTestCases/Somatic/CNV-Panel/cnv_somatic_panel_workflow_do_gc_wes.inputs; centaur/src/main/resources/integrationTestCases/Somatic/Mutect2/Mutect2.aws.inputs; centaur/src/main/resources/integrationTestCases/Somatic/Mutect2/Mutect2.inputs; centaur/src/main/resources/integrationTestCases/germline/haplotype-caller-workflow/HaplotypeCallerWF.json; centaur/src/main/resources/integrationTestCases/germline/single-sample-production-workflow/PairedEndSingleSampleWf.options.json; centaur/src/main/resources/integrationTestCases/germline/single-sample-workflow/processing-for-variant-discovery-gatk4.hg38.wgs.inputs.json; centaur/src/main/resources/integrationTestCases/green/arrays/arrays.wdl; womtool/src/test/resources/validate/wdl_draft3/valid/HaplotypeCallerWF/HaplotypeCallerWF.inputs.json; womtool/src/test/resources/validate/wdl_draft3/valid/cnv_somatic_pair_workflow/cnv_somatic_pair_workflow.inputs.json; womtool/src/test/resources/validate/wdl_draft3/valid/joint-discovery-gatk/joint-discovery-gatk.inputs.json; ```; </details>; <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7294:1444,integrat,integrationTestCases,1444,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7294,1,['integrat'],['integrationTestCases']
Integrability,dependency problems,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2021:0,depend,dependency,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2021,1,['depend'],['dependency']
Integrability,depends on #488,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/489:0,depend,depends,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/489,1,['depend'],['depends']
Integrability,depends on #497,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/506:0,depend,depends,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/506,1,['depend'],['depends']
Integrability,depends on #784,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/788:0,depend,depends,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/788,1,['depend'],['depends']
Integrability,depends on #788 . This is really important for our users so they don't lose all their metadata!,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/789:0,depend,depends,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/789,1,['depend'],['depends']
Integrability,"dful of cache hits(~30). Cromwell will stop responding to api requests and after some time with logs being written the workflow that was getting the cache hits will hit 503 and timeout errors. When running the workflow with `read_from_cache=false` we run into none of these errors. Timeout Error. ```; 2016-05-05 17:37:02,285 cromwell-system-akka.actor.default-dispatcher-25 WARN - Configured registration timeout of 1 second expired, stoppingw; ```. 503 Error. ```; Exception occurred while attempting to copy outputs from gs://broad-gotc-dev-storage/cromwell_execution/JointGenotyping/ccba2c79-c998-4f03-b736-af097391db66/call-SplitGvcf/shard-50 to gs://broad-gotc-dev-storage/cromwell_execution/JointGenotyping/7164dc88-af61-4ea6-8a73-f0b79594ae9a/call-SplitGvcf/shard-50. com.google.api.client.googleapis.json.GoogleJsonResponseException: 503 Service Unavailable. {. ""code"" : 503,. ""errors"" : [ {. ""domain"" : ""global"",. ""message"" : ""Backend Error"",. ""reason"" : ""backendError"". } ],. ""message"" : ""Backend Error"". }. at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClientRequest.java:321) ~[cromwell.jar:0.19]. at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1056) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419) ~[cromwell.jar:0.19]. at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.jav",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/794:1226,message,message,1226,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/794,1,['message'],['message']
Integrability,"dinstitute/wdl4s/pull/257) and associated cromwell PRs. But if the uninitialized optional declaration on [this line](https://github.com/broadinstitute/centaur/pull/242/files#diff-cc04c14d68a6a1a6d8d8366fc0c2f88cR48) is uncommented, the workflow fails. (Deliberately not quoting since lines don't wrap and anyway the thumbs downs are apropos). 2017-11-14 18:00:05,062 cromwell-system-akka.dispatchers.engine-dispatcher-33 INFO - Retrieved 1 workflows from the WorkflowStoreActor; 2017-11-14 18:00:05,093 cromwell-system-akka.dispatchers.engine-dispatcher-33 INFO - MaterializeWorkflowDescriptorActor [UUID(4b725606)]: Call-to-Backend assignments: decls.sub_decls.second_task -> Local, decls.sub_decls.first_task -> Local; 2017-11-14 18:00:06,129 cromwell-system-akka.dispatchers.engine-dispatcher-26 INFO - WorkflowExecutionActor-4b725606-6d2a-4cf2-b23b-e5971f52b7dd [UUID(4b725606)]: Starting calls: SubWorkflow-sudecls:-1:1; 2017-11-14 18:00:06,130 cromwell-system-akka.actor.default-dispatcher-50 INFO - Message [cromwell.subworkflowstore.SubWorkflowStoreActor$SubWorkflowStoreRegisterSuccess] from Actor[akka://cromwell-system/user/cromwell-service/SubWorkflowStoreActor#-388497585] to Actor[akka://cromwell-system/user/cromwell-service/WorkflowManagerActor/WorkflowActor-4b725606-6d2a-4cf2-b23b-e5971f52b7dd/WorkflowExecutionActor-4b725606-6d2a-4cf2-b23b-e5971f52b7dd/SubWorkflowExecutionActor-SubWorkflow-sudecls:-1:1#-1890869436] was not delivered. [5] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; 2017-11-14 18:00:06,132 cromwell-system-akka.dispatchers.engine-dispatcher-27 ERROR - WorkflowManagerActor Workflow 4b725606-6d2a-4cf2-b23b-e5971f52b7dd failed (during ExecutingWorkflowState): ; 2017-11-14 18:00:06,133 cromwell-system-akka.dispatchers.engine-dispatcher-27 INFO - WorkflowManagerActor WorkflowActor-4b725606-6d2a-4cf2-b23b-e5971f52b7dd is in a terminal state:",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2902:1590,Message,Message,1590,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2902,1,['Message'],['Message']
Integrability,dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); 	at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72); 	at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); 	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: java.util.NoSuchElementException; 	at java.util.ArrayList$Itr.next(ArrayList.java:854); 	at scala.collection.convert.Wrappers$JIteratorWrapper.next(Wrappers.scala:43); 	at scala.collection.IterableLike$class.head(IterableLike.scala:107); 	at scala.collection.AbstractIterable.head(Iterable.scala:54); 	at cromwell.backend.impl.aws.AwsAsyncJobExecutionActor.execute(AwsAsyncJobExecutionActor.scala:53); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$executeAsync$1.apply(StandardAsyncExecutionActor.scala:242); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$executeAsync$1.apply(StandardAsyncExecutionActor.scala:242); 	at scala.util.Try$.apply(Try.scala:192); 	at cromwell.backend.standard.StandardAsyncExecutionActor$class.executeAsync(StandardAsyncExecutionActor.scala:242); 	at cromwell.backend.impl.aws.AwsAsyncJobExecutionActor.executeAsync(AwsAsyncJobExecutionActor.scala:23); 	at cromwell.backend.standard.StandardAsyncExecutionActor$class.executeOrRecover(StandardAsyncExecutionActor.scala:502); 	at cromwell.backend.impl.aws.AwsAsyncJobExecutionActor.executeOrRecover(AwsAsyncJobExecutionActor.scala:2,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1966:1906,Wrap,Wrappers,1906,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1966,1,['Wrap'],['Wrappers']
Integrability,"dlGraphNode.scala:140)""; },; {; causedBy: [ ],; message: ""wdl.WdlWorkflow$.womWorkflowDefinition(WdlWorkflow.scala:52)""; },; {; causedBy: [ ],; message: ""wdl.WdlWorkflow.womDefinition$lzycompute(WdlWorkflow.scala:73)""; },; {; causedBy: [ ],; message: ""wdl.WdlWorkflow.womDefinition(WdlWorkflow.scala:73)""; },; {; causedBy: [ ],; message: ""wdl.WdlInputParsing$.buildWomExecutable(WdlInputParsing.scala:27)""; },; {; causedBy: [ ],; message: ""wdl.WdlNamespaceWithWorkflow.womExecutable(WdlNamespace.scala:98)""; },; {; causedBy: [ ],; message: ""cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.$anonfun$validateWdlNamespace$15(MaterializeWorkflowDescriptorActor.scala:493)""; },; {; causedBy: [ ],; message: ""scala.util.Either.flatMap(Either.scala:338)""; },; {; causedBy: [ ],; message: ""cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.$anonfun$validateWdlNamespace$13(MaterializeWorkflowDescriptorActor.scala:491)""; },; {; causedBy: [ ],; message: ""scala.util.Either.flatMap(Either.scala:338)""; },; {; causedBy: [ ],; message: ""cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.validateWdlNamespace(MaterializeWorkflowDescriptorActor.scala:490)""; },; {; causedBy: [ ],; message: ""cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$lifecycle$materialization$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor(MaterializeWorkflowDescriptorActor.scala:231)""; },; {; causedBy: [ ],; message: ""cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$1.$anonfun$applyOrElse$1(MaterializeWorkflowDescriptorActor.scala:157)""; },; {; causedBy: [ ],; message: ""scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:304)""; },; {; causedBy: [ ],; message: ""scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37)""; },; {; causedBy: [ ],; message: ""scala.concurrent.impl.Callback",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3143:1729,message,message,1729,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3143,1,['message'],['message']
Integrability,"ds on FC Prod. The `EXPLAIN` output on CaaS Prod looks like:. ```; mysql> EXPLAIN select...; +----+--------------------+--------------------+------+---------------------------------------------+-------------------------------+---------+-------------------------------------------+--------+------------------------------------+; | id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |; +----+--------------------+--------------------+------+---------------------------------------------+-------------------------------+---------+-------------------------------------------+--------+------------------------------------+; | 1 | PRIMARY | x2 | ALL | NULL | NULL | NULL | NULL | 185900 | Using where |; | 4 | DEPENDENT SUBQUERY | CUSTOM_LABEL_ENTRY | ref | UC_CUSTOM_LABEL_ENTRY_CLK_WEU,SYS_IDX_11226 | UC_CUSTOM_LABEL_ENTRY_CLK_WEU | 1070 | const,cromwell.x2.WORKFLOW_EXECUTION_UUID | 1 | Using index condition; Using where |; | 3 | DEPENDENT SUBQUERY | CUSTOM_LABEL_ENTRY | ref | UC_CUSTOM_LABEL_ENTRY_CLK_WEU,SYS_IDX_11226 | UC_CUSTOM_LABEL_ENTRY_CLK_WEU | 1070 | const,cromwell.x2.WORKFLOW_EXECUTION_UUID | 1 | Using index condition; Using where |; | 2 | DEPENDENT SUBQUERY | CUSTOM_LABEL_ENTRY | ref | UC_CUSTOM_LABEL_ENTRY_CLK_WEU,SYS_IDX_11226 | UC_CUSTOM_LABEL_ENTRY_CLK_WEU | 1070 | const,cromwell.x2.WORKFLOW_EXECUTION_UUID | 1 | Using index condition; Using where |; +----+--------------------+--------------------+------+---------------------------------------------+-------------------------------+---------+-------------------------------------------+--------+------------------------------------+; ```; The referenced index on `CUSTOM_LABEL_ENTRY` is `UC_CUSTOM_LABEL_ENTRY_CLK_WEU` which looks like:; ```; mysql> show index from CUSTOM_LABEL_ENTRY;; +--------------------+------------+-------------------------------+--------------+-------------------------+-----------+-------------+----------+--------+------+------------+---------+---------------+; | T",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4598:1722,DEPEND,DEPENDENT,1722,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4598,1,['DEPEND'],['DEPENDENT']
Integrability,"e docker container. It seems like only the first argument is actually being used. This isn't an issue with my python script, because I can run it directly and everything works fine. Cromwell showing the command line:; ```; cromwell_1 | 2018-11-12 06:57:56,451 cromwell-system-akka.dispatchers.backend-dispatcher-40 INFO - PipelinesApiAsyncBackendJobExecutionActor [UUID(5d4c4459)germline_variant_calling.fastqc:0:1]: `/app/fastqc_docker.py --output-dir . --read ""/cromwell_root/genovic-test-data/cardiom/NA12878_CARDIACM_MUTATED_L001_R1.fastq.gz"" --format fastq`; ```. Cromwell failing with an error because the `--read` argument is missing (even though you can see it's not, in the above log):; ```; cromwell_1 | java.lang.Exception: Task germline_variant_calling.fastqc:0:1 failed. The job was stopped before the command finished. PAPI error code 10. 11: Docker run failed: command failed: usage: fastqc_docker.py [-h] -r READ -o OUTPUT_DIR [-c CONTAMINANTS]; cromwell_1 | [-a ADAPTERS] [-l LIMITS] [-f FORMAT] [-n NO_GROUP]; cromwell_1 | [-e EXTRA_OPTIONS]; cromwell_1 | fastqc_docker.py: error: argument -r/--read is required; cromwell_1 | . See logs at gs://genovic-cromwell/cromwell-execution/trio/f5454139-c51d-4d04-ae0a-9b9d4ce650aa/call-germline_variant_calling/shard-0/germline_variant_calling/5d4c4459-a91c-4d3b-8ca4-b98457134750/call-fastqc/shard-0/; cromwell_1 | at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor$.StandardException(PipelinesApiAsyncBackendJobExecutionActor.scala:79); cromwell_1 | at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleFailedRunStatus$1(PipelinesApiAsyncBackendJobExecutionActor.scala:585); cromwell_1 | at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:592); cromwell_1 | at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecution",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4381:1268,ADAPTER,ADAPTERS,1268,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4381,1,['ADAPTER'],['ADAPTERS']
Integrability,"e f` and `String s` from the inputs json I get an failure message. To make sure I was giving the workflow the correct inputs json I first ran it with bad inputs on purpose and got expected failures; ```; status: ""Failed"",; failures: [; {; causedBy: [; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_pac' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.agg_preemptible_tries' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_ann' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.wgs_coverage_interval_list' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_fasta_index' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.unmapped_bam_suffix' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_ud' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_amb' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.preemptible_tries' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_sa' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.known_indels_sites_VCFs' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_mu' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_alt' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_bwt' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.known_",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2912:1317,message,message,1317,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2912,1,['message'],['message']
Integrability,"e: ""akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55)""; },; {; causedBy: [ ],; message: ""akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91)""; },; {; causedBy: [ ],; message: ""scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)""; },; {; causedBy: [ ],; message: ""scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81)""; },; {; causedBy: [ ],; message: ""akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:91)""; },; {; causedBy: [ ],; message: ""akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40)""; },; {; causedBy: [ ],; message: ""akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:43)""; },; {; causedBy: [ ],; message: ""akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)""; },; {; causedBy: [ ],; message: ""akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)""; },; {; causedBy: [ ],; message: ""akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)""; },; {; causedBy: [ ],; message: ""akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)""; }; ],; message: ""Workflow input processing failed""; }; ],; ```. I think the culprit has something to do with both the root and sub workflow both having a task called `GatherbamFiles` because when I renamed the task in the subworkflow (and all subsequent necessary renames) the workflow ran fine. When I tried to make a simple example of this I couldn't get the error to pop up again so I'm definitely missing some nuances of the cause. The root workflow passes womtool-30.1.jar validation. Root workflow - [SomaticPairedSingleSampleWf.txt](https://github.com/broadinstitute/cromwell/files/1635810/SomaticPairedSingleSampleWf.txt). Sub workflow - [SplitLargeRG.txt](https://github.com/broadinstitute/cromwell/files/1635814/SplitLargeRG.txt). Dependencies zip - [SomaticPairedSingleSampleWfDepend",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3143:3792,message,message,3792,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3143,1,['message'],['message']
Integrability,"e;shutdown=false;hsqldb.tx=mvcc; [2018-08-30 17:36:10,85] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2018-08-30 17:36:10,87] [info] [RenameWorkflowOptionsInMetadata] 100%; [2018-08-30 17:36:11,02] [info] Running with database db.url = jdbc:hsqldb:mem:5893545c-e081-4c3d-827d-000af3765fc4;shutdown=false;hsqldb.tx=mvcc; [2018-08-30 17:36:11,72] [info] Slf4jLogger started; Exception in thread ""main"" cromwell.CromwellEntryPoint$$anon$1: ERROR: Unable to submit workflow to Cromwell::; Workflow source does not exist: does-not-exist.wdl; 	at cromwell.CromwellEntryPoint$.$anonfun$validOrFailSubmission$1(CromwellEntryPoint.scala:219); 	at cats.data.Validated.valueOr(Validated.scala:48); 	at cromwell.CromwellEntryPoint$.validOrFailSubmission(CromwellEntryPoint.scala:219); 	at cromwell.CromwellEntryPoint$.validateRunArguments(CromwellEntryPoint.scala:215); 	at cromwell.CromwellEntryPoint$.runSingle(CromwellEntryPoint.scala:56); 	at cromwell.CromwellApp$.runCromwell(CromwellApp.scala:14); 	at cromwell.CromwellApp$.delayedEndpoint$cromwell$CromwellApp$1(CromwellApp.scala:25); 	at cromwell.CromwellApp$delayedInit$body.apply(CromwellApp.scala:3); 	at scala.Function0.apply$mcV$sp(Function0.scala:34); 	at scala.Function0.apply$mcV$sp$(Function0.scala:34); 	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:12); 	at scala.App.$anonfun$main$1$adapted(App.scala:76); 	at scala.collection.immutable.List.foreach(List.scala:389); 	at scala.App.main(App.scala:76); 	at scala.App.main$(App.scala:74); 	at cromwell.CromwellApp$.main(CromwellApp.scala:3); 	at cromwell.CromwellApp.main(CromwellApp.scala); ```; Command-line tools are subject to usability standards identical to those of our other user interfaces. Unless the intended audience of this tool is Cromwell engineers, the stacktrace information is likely overwhelming—that is, the signal-to-noise ratio of this output can likely be improved.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4060:2009,interface,interfaces,2009,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4060,1,['interface'],['interfaces']
Integrability,"eBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; [2023-02-04 08:55:07,22] [info] Metadata summary refreshing every 2 seconds.; [2023-02-04 08:55:07,26] [info] KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; [2023-02-04 08:55:07,26] [info] WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; [2023-02-04 08:55:07,26] [info] CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; [2023-02-04 08:55:07,63] [info] JobExecutionTokenDispenser - Distribution rate: 50 per 1 seconds.; [2023-02-04 08:55:07,64] [info] SingleWorkflowRunnerActor: Version 34-unknown-SNAP; [2023-02-04 08:55:07,65] [info] SingleWorkflowRunnerActor: Submitting workflow; [2023-02-04 08:55:07,68] [info] Unspecified type (Unspecified version) workflow 48f62f22-25fe-4f0f-b5fe-21191f035abd submitted; [2023-02-04 08:55:07,72] [info] SingleWorkflowRunnerActor: Workflow submitted [38;5;2m48f62f22-25fe-4f0f-b5fe-21191f035abd[0m; [2023-02-04 08:55:07,75] [info] 1 new workflows fetched; [2023-02-04 08:55:07,75] [info] WorkflowManagerActor Starting workflow [38;5;2m48f62f22-25fe-4f0f-b5fe-21191f035abd[0m; [2023-02-04 08:55:07,76] [[38;5;220mwarn[0m] SingleWorkflowRunnerActor: received unexpected message: Done in state RunningSwraData; [2023-02-04 08:55:07,79] [[38;5;220mwarn[0m] Couldn't find a suitable DSN, defaulting to a Noop one.; [2023-02-04 08:55:07,79] [info] Using noop to send events.; [2023-02-04 08:55:07,81] [info] WorkflowManagerActor Successfully started WorkflowActor-48f62f22-25fe-4f0f-b5fe-21191f035abd; [2023-02-04 08:55:07,81] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2023-02-04 08:55:07,81] [info] WorkflowStoreHeartbeatWriteActor configured to flush with batch size 10000 and process rate 2 minutes.; [2023-02-04 08:55:07,81] [info] MaterializeWorkflowDescriptorActor [[38;5;2m48f62f22[0m]: Parsing workflow as WDL 1.0; [2023-02-04 08:55:08,24] [[38;5;1merror[0m] Workflo",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6999:2370,message,message,2370,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6999,1,['message'],['message']
Integrability,ead0(Native Method); at java.net.SocketInputStream.socketRead(SocketInputStream.java:116); at java.net.SocketInputStream.read(SocketInputStream.java:171); at java.net.SocketInputStream.read(SocketInputStream.java:141); at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); at sun.security.ssl.InputRecord.read(InputRecord.java:503); at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:975); at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:933); at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); at java.io.BufferedInputStream.read(BufferedInputStream.java:345); at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:735); at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:678); at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1587); at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1492); at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480); at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:347); at com.google.api.client.http.javanet.NetHttpResponse.<init>(NetHttpResponse.java:37); at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:143); at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:84); at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1040); at com.google.api.client.googleapis.batch.BatchRequest.execute(BatchRequest.java:233); at cromwell.backend.google.pipelines.common.api.PipelinesApiRequestWorker.runBatch(PipelinesApiRequestWorker.scala:59); at cromwell.backend.google.pipelines.common.api.PipelinesApiRequestWorker.cromwell$backend$google$pipelines$common$api$PipelinesApiRequestWorker$$handleBatch(PipelinesApiRequestWorker.scala:53); at cromwell.ba,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4914:2415,protocol,protocol,2415,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4914,1,['protocol'],['protocol']
Integrability,eam.java:141) ~[na:1.8.0_72];   at sun.security.ssl.InputRecord.readFully(InputRecord.java:465) ~[na:1.8.0_72];   at sun.security.ssl.InputRecord.read(InputRecord.java:503) ~[na:1.8.0_72];   at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973) ~[na:1.8.0_72];   at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930) ~[na:1.8.0_72];   at sun.security.ssl.AppInputStream.read(AppInputStream.java:105) ~[na:1.8.0_72];   at java.io.BufferedInputStream.fill(BufferedInputStream.java:246) ~[na:1.8.0_72];   at java.io.BufferedInputStream.read1(BufferedInputStream.java:286) ~[na:1.8.0_72];   at java.io.BufferedInputStream.read(BufferedInputStream.java:345) ~[na:1.8.0_72];   at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:704) ~[na:1.8.0_72];   at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:647) ~[na:1.8.0_72];   at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1536) ~[na:1.8.0_72];   at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1441) ~[na:1.8.0_72];   at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480) ~[na:1.8.0_72];   at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:338) ~[na:1.8.0_72];   at com.google.api.client.http.javanet.NetHttpResponse.<init>(NetHttpResponse.java:37) ~[cromwell.jar:0.19];   at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:94) ~[cromwell.jar:0.19];   at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(A,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/826:1582,protocol,protocol,1582,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/826,1,['protocol'],['protocol']
Integrability,eam.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.read(InputRecord.java:503); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:704); 	at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:647); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1569); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1474); 	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:338); 	at com.google.api.client.http.javanet.NetHttpResponse.<init>(NetHttpResponse.java:37); 	at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:94); 	at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469); 	at com.google.cloud.storage.spi.DefaultStorageRpc.rewrite(DefaultStorageRpc.java:590); 	at com.google.cloud.storage.spi.DefaultStorageRpc.openRewrite(DefaultStorageRpc.java:578); 	at com.google.cloud.storage.StorageImpl$15.call(StorageImpl.java:419); 	at com.google.cloud.storage.StorageI,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2229:4559,protocol,protocol,4559,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2229,1,['protocol'],['protocol']
Integrability,"ect.internals.TrampolineEC$JVMTrampoline.super$startLoop(TrampolineEC.scala:93); at cats.effect.internals.TrampolineEC$JVMTrampoline.$anonfun$startLoop$1(TrampolineEC.scala:93); at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81); at cats.effect.internals.TrampolineEC$JVMTrampoline.startLoop(TrampolineEC.scala:93); at cats.effect.internals.Trampoline.execute(Trampoline.scala:43); at cats.effect.internals.TrampolineEC.execute(TrampolineEC.scala:44); at cats.effect.internals.Callback$AsyncIdempotentCallback.apply(Callback.scala:133); at cats.effect.internals.Callback$AsyncIdempotentCallback.apply(Callback.scala:120); at cats.effect.Async$$anon$1.run(Async.scala:275); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); [2019-02-11 10:13:27,63] [info] Message [cromwell.docker.DockerInfoActor$DockerInfoFailedResponse] from Actor[akka://cromwell-system/user/HealthMonitorDockerHashActor#-638598959] to Actor[akka://cromwell-system/deadLetters] was not delivered. [1] dead letters encountered, no more dead letters will be logged. If this is not an expected behavior, then [Actor[akka://cromwell-system/deadLetters]] may have terminated unexpectedly, This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2019-02-11 10:13:27,65] [info] WorkflowExecutionActor-52999e15-953f-44d6-aaae-1774c74d2910 [52999e15]: Workflow test1 complete. Final Outputs:; {; ""test1.hello.out"": ""/spin1/users/wresch/test_data/cromwell/test1/cromwell-executions/test1/52999e15-953f-44d6-aaae-1774c74d2910/call-hello/execution/World.txt""; }; [2019-02-11 10:13:27,69] [info] WorkflowManagerActor WorkflowActor-52999e15-953f-44d6-aaae-1774c74d2910 is in a terminal state: WorkflowS",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4626:13826,Message,Message,13826,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4626,1,['Message'],['Message']
Integrability,"ed$lzycompute(WdlWorkflow.scala:63)""; },; {; causedBy: [ ],; message: ""wdl.WdlWorkflow.childGraphNodesSorted(WdlWorkflow.scala:63)""; },; {; causedBy: [ ],; message: ""wdl.WdlGraphNode$.buildWomGraph(WdlGraphNode.scala:140)""; },; {; causedBy: [ ],; message: ""wdl.WdlWorkflow$.womWorkflowDefinition(WdlWorkflow.scala:52)""; },; {; causedBy: [ ],; message: ""wdl.WdlWorkflow.womDefinition$lzycompute(WdlWorkflow.scala:73)""; },; {; causedBy: [ ],; message: ""wdl.WdlWorkflow.womDefinition(WdlWorkflow.scala:73)""; },; {; causedBy: [ ],; message: ""wdl.WdlInputParsing$.buildWomExecutable(WdlInputParsing.scala:27)""; },; {; causedBy: [ ],; message: ""wdl.WdlNamespaceWithWorkflow.womExecutable(WdlNamespace.scala:98)""; },; {; causedBy: [ ],; message: ""cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.$anonfun$validateWdlNamespace$15(MaterializeWorkflowDescriptorActor.scala:493)""; },; {; causedBy: [ ],; message: ""scala.util.Either.flatMap(Either.scala:338)""; },; {; causedBy: [ ],; message: ""cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.$anonfun$validateWdlNamespace$13(MaterializeWorkflowDescriptorActor.scala:491)""; },; {; causedBy: [ ],; message: ""scala.util.Either.flatMap(Either.scala:338)""; },; {; causedBy: [ ],; message: ""cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.validateWdlNamespace(MaterializeWorkflowDescriptorActor.scala:490)""; },; {; causedBy: [ ],; message: ""cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$lifecycle$materialization$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor(MaterializeWorkflowDescriptorActor.scala:231)""; },; {; causedBy: [ ],; message: ""cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$1.$anonfun$applyOrElse$1(MaterializeWorkflowDescriptorActor.scala:157)""; },; {; causedBy: [ ],; message: ""scala.concurrent.Future.$anonfun$fla",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3143:1529,message,message,1529,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3143,1,['message'],['message']
Integrability,"edback. Before posting an issue over in Jira tracker, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're almost in the right place. -->. <!-- You'll want to go to https://broadworkbench.atlassian.net/projects/BA/issues and then tell us: -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->. Hi,. I recently encountered an issue on running Cromwell jobs on AWS Batch. In brief, all of my testing WDL jobs failed with the following error message:. ```; 2021-09-23 00:08:18,813 INFO - Submitting taskId: cumulus.cluster-None-1, job definition : arn:aws:batch:us-west-2:752311211819:job-definition/cromwell_quay_io_cumulus_cumulus_1_4_377407181fbea1f33a22931df258b16d20d4c6ab3:1, script: s3://gred-cumulus-dev/scripts/c157137e2097795846ae1f4069ccd7a2; 2021-09-23 00:08:20,269 cromwell-system-akka.dispatchers.backend-dispatcher-118 INFO - AwsBatchAsyncBackendJobExecutionActor [UUID(cf00212c)cumulus.cluster:NA:1]: job id: 12836c6a-6d1a-4429-bb86-68b8f9883acf; 2021-09-23 00:08:20,287 cromwell-system-akka.dispatchers.backend-dispatcher-118 INFO - AwsBatchAsyncBackendJobExecutionActor [UUID(cf00212c)cumulus.cluster:NA:1]: Status change from - to Initializing; 2021-09-23 00:12:17,120 cromwell-system-akka.dispatchers.backend-dispatcher-136 INFO - AwsBatchAsyncBackendJobExecutionActor [UUID(cf00212c)cumulus.cluster:NA:1]: Status change from Initializing to Running; 2021-09-23 00:14:08,015 cromwell-system-a",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6504:1080,message,message,1080,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6504,1,['message'],['message']
Integrability,"ehavior in PAPI that causes the task to hang for half an hour!. Since PAPI is on its way out and this error message still seems to be checked in [a different test case](https://github.com/broadinstitute/cromwell/pull/4718/files#diff-a348345a036a680f8e29070f0972f61b09f3f640f26b188504d69d5a7f71b554), I am recommending we just delete the test instead of spending any more time on this. ```; > gcloud beta lifesciences operations describe projects/1005074806481/locations/us-central1/operations/8650136336352694244 --format=json; {; ""done"": true,; ""error"": {; ""code"": 9,; ""message"": ""Execution failed: generic::failed_precondition: while running \""-c /bin/bash /cromwell_root/gcs_localization.sh\"": unexpected exit status 1 was not ignored""; },; ""metadata"": {; ""@type"": ""type.googleapis.com/google.cloud.lifesciences.v2beta.Metadata"",; ""createTime"": ""2023-12-04T20:36:45.056562Z"",; ""endTime"": ""2023-12-04T21:10:43.697318162Z"" # <- WTF!!; }; [...]; ```. ```; Long duration; Warning: arning] Using a password on the command line interface can be insecure.; +--------------------------------------+-----------------+----------------------------+----------------------------+; | name | RUNTIME_MINUTES | start | end |; +--------------------------------------+-----------------+----------------------------+----------------------------+; | localize_file_larger_than_disk_space | 35 | 2023-12-05 01:01:27.836000 | 2023-12-05 01:37:10.789000 |; | lots_of_inputs | 32 | 2023-12-05 01:02:03.292000 | 2023-12-05 01:34:26.490000 |; | draft3_call_cache_capoeira | 27 | 2023-12-05 01:03:01.338000 | 2023-12-05 01:30:34.171000 |; ```. ```; Late finishers; Warning: arning] Using a password on the command line interface can be insecure.; +------------------------------------------+-----------------+----------------------------+----------------------------+; | name | runtime_minutes | start | END |; +------------------------------------------+-----------------+----------------------------+------------------------",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7330:1454,interface,interface,1454,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7330,1,['interface'],['interface']
Integrability,"ell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.$anonfun$validateWdlNamespace$15(MaterializeWorkflowDescriptorActor.scala:493)""; },; {; causedBy: [ ],; message: ""scala.util.Either.flatMap(Either.scala:338)""; },; {; causedBy: [ ],; message: ""cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.$anonfun$validateWdlNamespace$13(MaterializeWorkflowDescriptorActor.scala:491)""; },; {; causedBy: [ ],; message: ""scala.util.Either.flatMap(Either.scala:338)""; },; {; causedBy: [ ],; message: ""cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.validateWdlNamespace(MaterializeWorkflowDescriptorActor.scala:490)""; },; {; causedBy: [ ],; message: ""cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$lifecycle$materialization$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor(MaterializeWorkflowDescriptorActor.scala:231)""; },; {; causedBy: [ ],; message: ""cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$1.$anonfun$applyOrElse$1(MaterializeWorkflowDescriptorActor.scala:157)""; },; {; causedBy: [ ],; message: ""scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:304)""; },; {; causedBy: [ ],; message: ""scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37)""; },; {; causedBy: [ ],; message: ""scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60)""; },; {; causedBy: [ ],; message: ""akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55)""; },; {; causedBy: [ ],; message: ""akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91)""; },; {; causedBy: [ ],; message: ""scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)""; },; {; causedBy: [ ],; message: ""scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81)""; },; {; causedBy: [ ],; message: ""akka.dispatch.BatchingExec",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3143:2274,message,message,2274,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3143,1,['message'],['message']
Integrability,"elog.md) - [Changelog](https://bitbucket.org/snakeyaml/snakeyaml/src/master/Changelog.rst) - [Changelog](https://bitbucket.org/snakeyaml/snakeyaml/src/master/changelog.markdown) - [Changelog](https://bitbucket.org/snakeyaml/snakeyaml/src/master/changelog.md) - [Changelog](https://bitbucket.org/snakeyaml/snakeyaml/src/master/changelog.rst). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/9367739b48d1bae5766674e547f8cdf8a82d318a/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Files still referring to the old version number</summary>. The following files still refer to the old version number (1.33).; You might want to review and update them manually.; ```; core/src/test/resources/hello_goodbye_scattered_papiv2.json; docs/developers/bitesize/ci/Cromwell_Deployment_Strategies.svg; project/Dependencies.scala; scripts/metadata_comparison/test/resources/comparer/papiv1_version3_good.json; scripts/metadata_comparison/test/resources/comparer/papiv2_version3_good.json; scripts/metadata_comparison/test/resources/comparer/version3_comparison_good.csv; src/ci/resources/papi_v2_reference_image_manifest.conf; ```; </details>; <details>; <summary>Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""org.yaml"", artifactId = ""snakeyaml"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""org.yaml"", artifactId = ""snakeyaml"" }; }]; ```; </details>. labels: test-library-update, old-version-remains, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7081:2949,Depend,Dependencies,2949,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7081,5,"['Depend', 'depend']","['Dependencies', 'dependency', 'dependencyOverrides']"
Integrability,"elpath:jes_task-rc.txt; [2016-04-28 15:35:51,648] [info] JES Pipeline [1cb9c1d2:jes_task]: Mounts:; c98942d68bf4c33728f1adef1bfd9ccc -> /mnt/mnt1 (3GB PERSISTENT_SSD); 4fd1d1e01455dfdd4eabcf02c1abaf55 -> /mnt/mnt2 (500GB PERSISTENT_HDD); local-disk -> /cromwell_root (10GB PERSISTENT_SSD); [2016-04-28 15:35:51,728] [warn] JesBackend [1cb9c1d2:jes_task]: 400 Bad Request; {; ""code"" : 400,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Invalid value for field \""resources.disk.name\"": 4fd1d1e01455dfdd4eabcf02c1abaf55\nDisk names must follow rules at https://cloud.google.com/compute/docs/reference/latest/disks#name"",; ""reason"" : ""badRequest""; } ],; ""message"" : ""Invalid value for field \""resources.disk.name\"": 4fd1d1e01455dfdd4eabcf02c1abaf55\nDisk names must follow rules at https://cloud.google.com/compute/docs/reference/latest/disks#name"",; ""status"" : ""INVALID_ARGUMENT""; }; com.google.api.client.googleapis.json.GoogleJsonResponseException: 400 Bad Request; {; ""code"" : 400,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Invalid value for field \""resources.disk.name\"": 4fd1d1e01455dfdd4eabcf02c1abaf55\nDisk names must follow rules at https://cloud.google.com/compute/docs/reference/latest/disks#name"",; ""reason"" : ""badRequest""; } ],; ""message"" : ""Invalid value for field \""resources.disk.name\"": 4fd1d1e01455dfdd4eabcf02c1abaf55\nDisk names must follow rules at https://cloud.google.com/compute/docs/reference/latest/disks#name"",; ""status"" : ""INVALID_ARGUMENT""; }; at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145); at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113); at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest$1.interceptResponse(AbstractGoogleClient",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/757:2263,message,message,2263,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/757,1,['message'],['message']
Integrability,"entation of the S3 filesystem in Cromwell:. - There's an implementation of [S3 specific](https://github.com/broadinstitute/cromwell/blob/develop/filesystems/s3/src/main/scala/cromwell/filesystems/s3/batch/S3BatchIoCommand.scala) IoCommands but they are not effectively being treated in any specific way anywhere. They would need to be matched [here](https://github.com/broadinstitute/cromwell/blob/develop/engine/src/main/scala/cromwell/engine/io/IoActor.scala#L119) and processed subsequently in an S3 specific manner, like it's currently done for GCS, to be useful. Because this isn't the case now, the S3 code in `S3BatchIoCommand` is effectively never called.; - It works because there is an implementation of java nio for S3. The `S3BatchIoCommand` ends up in the [NioFlow](https://github.com/broadinstitute/cromwell/blob/develop/engine/src/main/scala/cromwell/engine/io/nio/NioFlow.scala) which uses the methods of the nio interface to execute the commands.; **A big issue is that the nio interface does not have a ""hash"" method**. To work around that, the `NioFlow` [streams down the content and md5s it](https://github.com/broadinstitute/cromwell/blob/ec67d653c58c9c5b4b25609731a8082f3b540fe6/engine/src/main/scala/cromwell/engine/io/nio/NioFlow.scala#L111), [unless told otherwise](https://github.com/broadinstitute/cromwell/blob/ec67d653c58c9c5b4b25609731a8082f3b540fe6/engine/src/main/scala/cromwell/engine/io/nio/NioFlow.scala#L109). This is what's currently happening to S3 files. As a final twist, it turns out the [pattern match on GcsPath](https://github.com/broadinstitute/cromwell/blob/ec67d653c58c9c5b4b25609731a8082f3b540fe6/engine/src/main/scala/cromwell/engine/io/nio/NioFlow.scala#L109) in the hash method is actually just a fail safe but is not really needed. That is because some `IoCommand`s, including the `IoHashCommand`, are subclassed as `GcsBatchIoCommand`s and are processed through the [GcsBatchFlow](https://github.com/broadinstitute/cromwell/blob/develop/engine/src",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4463:1043,interface,interface,1043,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4463,1,['interface'],['interface']
Integrability,"entationPath); ```. Parts of a metric name expected to vary frequently could be stored as a key-value pair in the same list, and StatsD and Prometheus could simply handle it differently: StatsD could ignore the key and use the value to get the exact metric name as before, while Prometheus could assemble the name from just the strings and pass the key-value pairs as the labels. Unfortunately, union types are a Scala 3 thing. In Scala 2 we get `Either`, a manually-boxed type. :((((. So I did this:. ```scala; private type LowVariantPart = String; private type HighVariantPart = (String, String); private type InternalPath = NonEmptyList[Either[LowVariantPart, HighVariantPart]]. implicit class InstrumentationPath (val internalPath: InternalPath) { ... }; object InstrumentationPath { ... }. CromwellBucket(prefix: List[String], path: InstrumentationPath); ```. The implicit class provides a similar conceptual interface to the NonEmptyList, except it handles the necessary boxing (it also the includes some convenience methods that were already on a `implicit class EnhancedStatsDPath(val path: InstrumentationPath) extends AnyVal`). The object effectively provides constructors to handle the now-internal NonEmptyList invariant. What does all this mean?. Some screenshots of the sorts of changes this causes:; 1 -; ![Screen Shot 2022-02-16 at 4 30 35 PM](https://user-images.githubusercontent.com/29168264/154361303-4a7d7632-3af9-4a45-8b2d-5eae75b48999.png); 2 -; ![Screen Shot 2022-02-16 at 4 31 20 PM](https://user-images.githubusercontent.com/29168264/154361314-8c6627ec-5ad3-459b-b4b8-f6e98e2f3944.png); 3 -; ![Screen Shot 2022-02-16 at 4 31 34 PM](https://user-images.githubusercontent.com/29168264/154361319-ed0ca693-24d8-40c0-be24-1d7d0ee7252b.png); 4 -; ![Screen Shot 2022-02-16 at 4 36 36 PM](https://user-images.githubusercontent.com/29168264/154361325-f30cd35a-b3c5-445f-b589-b7a2afbd447c.png). There's a file of passing tests for the new InstrumentationPath class [here](https://githu",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6681:3611,interface,interface,3611,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6681,1,['interface'],['interface']
Integrability,"eq"",; ""selection"" : ""cDNA"",; ""source"" : ""transcriptomic""; },; ""extraction"" : {; ""source"" : ""Biochain Adult Liver"",; ""molecule"" : ""total RNA"",; ""protocol"" : ""2 different fetal normal tissues and 6 different adult normal tissues were purchased from different sources (Agilent, Biochain and OriGene). The qualities of these total RNA were tested using the Agilent Bioanalyzer 2100 Eukaryote Total RNA Nano Series II. Only total RNAs with a RIN score of more than 7 were used for RNA-Seq library construction\nRibosomal RNA (rRNA) was removed from total RNA using the RiboMinus™ Eukaryote Kit for RNA-Seq from Ambion. The ribosomal RNA depleted RNA fraction is termed the RiboMinus™ RNA fraction and is enriched in polyadenylated (polyA) mRNA, non-polyadenylated RNA, pre-processed RNA, tRNA, and may also contain regulatory RNA molecules such as microRNA (miRNA) and short interfering RNA (siRNA), snRNA, and other RNA transcripts of yet unknown function. Ambion RiboMinus rRNA depletion was performed as described in the manufacturer’s protocol (Pub. Part no.: 100004590, Rev. date 2 December 2011) following the standard protocol.\nTruSeq RNA Sample Preparation was performed on the RiboMinus™ RNA fraction as described in the manufacturer’s protocol (Pub. Part no.: 15026495 Rev. F March 2014) following the low sample protocol.\nThe libraries were sequenced on Illumina’s HiSeq 2000 instrument following standard protocol."",; ""processing"" : ""Data quality check using fastQC version 0.11.2.\nAlignment of unpaired unstranded reads using STAR version 2.4.0.\nQuantification of transcripts and isoforms using RSEM version 1.2.21 using rsem-calculate-expression, both alignment and quantification was done using the STAR_RSEM.sh pipeline (https://github.com/ENCODE-DCC/long-rna-seq-pipeline/blob/master/DAC/STAR_RSEM.sh)\nThe programe featurecounts version 1.4.6-p2 from the SourceForge Subread package was used to produce a summary file of counts from all the alignement .bam files.\nThe summary file o",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4519:1569,protocol,protocol,1569,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4519,1,['protocol'],['protocol']
Integrability,"es](https://github.com/sbt/sbt-assembly/releases/tag/v1.1.1) - [Version Diff](https://github.com/sbt/sbt-assembly/compare/v1.1.0...v1.1.1). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/2dc2301e75aea6c2d0c49b89d6092f7d4f134b40/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Files still referring to the old version number</summary>. The following files still refer to the old version number (1.1.0).; You might want to review and update them manually.; ```; CHANGELOG.md; centaur/src/main/resources/integrationTestCases/cwl/bcbio/gvcf-joint-workflow/steps/variantcall_batch_region.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/prealign-workflow/steps/variantcall_batch_region.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/somatic-workflow/steps/variantcall_batch_region.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/svcall-workflow/steps/variantcall_batch_region.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/wes_chr21_test-workflow-gcp/steps/variantcall_batch_region.cwl; cloud-nio/cloud-nio-impl-drs/src/main/scala/cloud/nio/impl/drs/DrsCloudNioFileSystemProvider.scala; cwl/src/test/resources/cwl/lodash.js; ```; </details>; <details>; <summary>Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.eed3si9n"", artifactId = ""sbt-assembly"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""@monthly"" },; dependency = { groupId = ""com.eed3si9n"", artifactId = ""sbt-assembly"" };",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6850:1090,integrat,integrationTestCases,1090,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6850,1,['integrat'],['integrationTestCases']
Integrability,"es_task {; command {; echo ""Hello JES!""; }; runtime {; docker: ""ubuntu:latest""; memory: ""4G""; cpu: ""3""; zones: ""us-central1-c us-central1-a""; disks: ""/mnt/mnt1 3 SSD, /mnt/mnt2 500 HDD""; }; }; workflow jes_workflow {; call jes_task; }; ```. and the console output:. ```; [2016-04-28 15:35:51,218] [info] JesBackend [1cb9c1d2:jes_task]: echo ""Hello JES!""; Apr 28, 2016 3:35:51 PM com.google.api.client.googleapis.services.AbstractGoogleClient <init>; WARNING: Application name is not set. Call Builder#setApplicationName.; [2016-04-28 15:35:51,646] [info] JES Pipeline [1cb9c1d2:jes_task]: Inputs:; exec -> disk:local-disk relpath:exec.sh; [2016-04-28 15:35:51,647] [info] JES Pipeline [1cb9c1d2:jes_task]: Outputs:; jes_task-rc.txt -> disk:local-disk relpath:jes_task-rc.txt; [2016-04-28 15:35:51,648] [info] JES Pipeline [1cb9c1d2:jes_task]: Mounts:; c98942d68bf4c33728f1adef1bfd9ccc -> /mnt/mnt1 (3GB PERSISTENT_SSD); 4fd1d1e01455dfdd4eabcf02c1abaf55 -> /mnt/mnt2 (500GB PERSISTENT_HDD); local-disk -> /cromwell_root (10GB PERSISTENT_SSD); [2016-04-28 15:35:51,728] [warn] JesBackend [1cb9c1d2:jes_task]: 400 Bad Request; {; ""code"" : 400,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Invalid value for field \""resources.disk.name\"": 4fd1d1e01455dfdd4eabcf02c1abaf55\nDisk names must follow rules at https://cloud.google.com/compute/docs/reference/latest/disks#name"",; ""reason"" : ""badRequest""; } ],; ""message"" : ""Invalid value for field \""resources.disk.name\"": 4fd1d1e01455dfdd4eabcf02c1abaf55\nDisk names must follow rules at https://cloud.google.com/compute/docs/reference/latest/disks#name"",; ""status"" : ""INVALID_ARGUMENT""; }; com.google.api.client.googleapis.json.GoogleJsonResponseException: 400 Bad Request; {; ""code"" : 400,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Invalid value for field \""resources.disk.name\"": 4fd1d1e01455dfdd4eabcf02c1abaf55\nDisk names must follow rules at https://cloud.google.com/compute/docs/reference/latest/disks#name"",; ""reason"" : ""badRequest"";",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/757:1664,message,message,1664,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/757,1,['message'],['message']
Integrability,"ess the output of mutually exclusive tasks later. More involved example: ; ```; # variant_call_after_earlyQC_filtering is an optional task, so variant_call_after_earlyQC_filtering.errorcode is an optional type; if(defined(variant_call_after_earlyQC_filtering.errorcode)) {. # variant_call_after_earlyQC_filtering is a scattered task, so variant_call_after_earlyQC_filtering.errorcode is an array; # this length check should be redundant with the defined check earlier, but neither of them seem to work properly; if(length(variant_call_after_earlyQC_filtering.errorcode) > 0) {; 	; # get the first (0th) value and coerce it into type String; 	String coerced_vc_filtered_errorcode = select_first([variant_call_after_earlyQC_filtering.errorcode[0], ""FALLBACK""]); 	call echo as echo_a {input: integer=length(variant_call_after_earlyQC_filtering.errorcode), string=variant_call_after_earlyQC_filtering.errorcode[0]}; 	call echo as echo_b {input: string=coerced_vc_filtered_errorcode}; call echo_array as echo_c {input: strings=variant_call_after_earlyQC_filtering.errorcode}; }; }; ```. Output:; * echo_a will echo ""1"" for input _integer_ and an empty string for input _string_; * echo_b will echo ""FALLBACK"" for input _string_; * echo_c will cause an error ; * `""message"":""Cannot interpolate Array[String?] into a command string with attribute set [PlaceholderAttributeSet(None,None,None,Some( ))]""`; * This error occurs even if echo_array takes in non-optional Array[String?] or Array[String?]?. [An example WDL, which passes womtool and miniwdl check, is available here.](https://gist.github.com/aofarrel/547c35468c248331b678b3f766f83591) It actually shows the issue twice -- once in the section starting with `if(defined(variant_call_after_earlyQC_filtering.errorcode)) {` and once in the section starting with `if(defined(profile_bam.strain)) {`. Interestingly, the results of echo_b implies that select_first() is a more accurate way of checking if a variable is defined than the built-in defined().",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7201:1881,message,message,1881,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7201,1,['message'],['message']
Integrability,"etect_adapter		# automatically detect/trim adapters; 	# optional; 	Int? min_trim_len 		# minimum trim length for cutadapt -m; 	Float? err_rate			# Maximum allowed adapter error rate ; 							# for cutadapt -e	; 	# resource; 	Int? cpu; 	Int? mem_mb; 	Int? time_hr; 	String? disks. 	command {; 		python $(which encode_trim_adapter.py) \; 			${write_tsv(fastqs)} \; 			${""--adapters "" + write_tsv(adapters)} \; 			${if paired_end then ""--paired-end"" else """"} \; 			${if auto_detect_adapter then ""--auto-detect-adapter"" else """"} \; 			${""--min-trim-len "" + min_trim_len} \; 			${""--err-rate "" + err_rate} \; 			${""--nth "" + select_first([cpu,4])}; 	}; 	output {; 		# WDL glob() globs in an alphabetical order; 		# so R1 and R2 can be switched, which results in an; 		# unexpected behavior of a workflow; 		# so we prepend merge_fastqs_'end'_ (R1 or R2); 		# to the basename of original filename; 		# this prefix will be later stripped in bowtie2 task; 		Array[File] trimmed_merged_fastqs = glob(""merge_fastqs_R?_*.fastq.gz""); 	}; 	runtime {; 		cpu : select_first([cpu,2]); 		memory : ""${select_first([mem_mb,'10000'])} MB""; 		time : select_first([time_hr,24]); 		disks : select_first([disks,""local-disk 100 HDD""]); 	}; }; ```; with Google JES backend, second call of write_tsv() doesn't seem to correctly pass temporary tsv file into a docker container. `${write_tsv()}` works fine.; `${""some string "" + write_tsv()}` does not work. It still has URI prefix `gs://`. ```; [2017-12-07 13:37:45,35] [info] JesAsyncBackendJobExecutionActor [17f0658fatac.trim_adapter:1:1]: python $(which encode_trim_adapter.py) \; /cromwell_root/atac-seq-pipeline-workflows/ENCSR889WQX/atac/17f0658f-a4ac-4af8-a8c6-c8910c7f303c/call-trim_adapter/shard-1/write_tsv_1dec3320bf1ad48ec05404d0a505d12b.tmp \; --adapters gs://atac-seq-pipeline-workflows/ENCSR889WQX/atac/17f0658f-a4ac-4af8-a8c6-c8910c7f303c/call-trim_adapter/shard-1/write_tsv_d3da014369f27e577cdffc1919be7d8e.tmp \; \; --auto-detect-adapter \; \; \; --nth 2; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3032:2142,adapter,adapters,2142,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3032,2,['adapter'],"['adapter', 'adapters']"
Integrability,"f010fa03daeb2625a3f9c1b1be80cca5/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Files still referring to the old version number</summary>. The following files still refer to the old version number (0.13.0).; You might want to review and update them manually.; ```; centaur/src/main/resources/integrationTestCases/cwl/bcbio/gvcf-joint-workflow/steps/process_alignment.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/gvcf-joint-workflow/steps/variantcall_batch_region.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/prealign-workflow/steps/variantcall_batch_region.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/rnaseq-workflow/steps/prepare_sample.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/somatic-workflow/steps/detect_sv.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/somatic-workflow/steps/process_alignment.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/somatic-workflow/steps/variantcall_batch_region.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/svcall-workflow/steps/detect_sv.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/svcall-workflow/steps/process_alignment.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/svcall-workflow/steps/variantcall_batch_region.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/wes_chr21_test-workflow-gcp/steps/detect_sv.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/wes_chr21_test-workflow-gcp/steps/process_alignment.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/wes_chr21_test-workflow-gcp/steps/variantcall_batch_region.cwl; ```; </details>; <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""io.circe"" } ]; ```; </details>. labels: library-update, semver-minor, old-version-remains",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6410:2031,integrat,integrationTestCases,2031,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6410,8,"['depend', 'integrat']","['dependency', 'integrationTestCases']"
Integrability,"f_dict = ref_dict,; tumor_bam = p.left.left,; tumor_bam_index = p.left.right,; tumor_sample_name = sub(sub(p.left.left, ""[/]*.*/"", """"), ""\\.bam$"", """"),; normal_bam = p.right.left,; normal_bam_index = p.right.right,; normal_sample_name = sub(sub(p.right.left, ""[/]*.*/"", """"), ""\\.bam$"", """"),; scatter_count = scatter_count,; dbsnp = dbSNPVCF,; dbsnp_index = dbsnp_index,; cosmic = cosmicVCF,; cosmic_index = cosmic_index,; is_run_orientation_bias_filter = true,; is_run_oncotator = false,; oncotator_docker = ""broadinstitute/oncotator:1.9.2.0-eval-gatk-protected"",; m2_docker = ""broadinstitute/gatk-protected@sha256:08bf9835dabb5b694164dae8312bac8d8012b9d907341f30d3c8e262a0f121d6"",; preemptible_attempts = preemptible,; onco_ds_local_db_dir = ""/root/onco_dbdir/"",; artifact_modes = [""G/T"", ""C/T""],; picard_jar = picard_jar; }; # New WDL added here that calls a task, not a workflow; # NOTE: Even when I put the VcfToIntervals task inline in this WDL file, I get the same exact error.; call dl_ob_training_m2.VcfToIntervals as vcf2i {; input:; vcf = m2_tn.filtered_vcf,; entity_id=sub(sub(p.left.left, ""[/]*.*/"", """"), ""\\.bam$"", """"); }; ### End new WDL; }. output {; Array[File] unfiltered_vcf = m2_tn.unfiltered_vcf; Array[File] unfiltered_vcf_index = m2_tn.unfiltered_vcf_index; Array[File] filtered_vcf = m2_tn.filtered_vcf; Array[File] filtered_vcf_index = m2_tn.filtered_vcf_index; }; }; ```. Here is the error message I get using wdltool 0.8 and 0.12 (and cromwell):. ```; ERROR: Expression will not evaluate (line 82, col 42):. entity_id=sub(sub(p.left.left, ""[/]*.*/"", """"), ""\\.bam$"", """"). ```. I tried a few things:; - ``entity_id=sub(sub(p.left.left, ""[/]*.*/"", """"), ""\\.bam$"", """")`` --> ``entity_id=p.left.left`` gives same error; - ``entity_id=sub(sub(p.left.left, ""[/]*.*/"", """"), ""\\.bam$"", """")`` --> ``entity_id=p.left`` makes the error go away (though now the WDL is semantically incorrect); - Even when I put the VcfToIntervals task inline in this WDL file, I get the same exact error.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2334:2821,message,message,2821,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2334,1,['message'],['message']
Integrability,"flow up to 3 times if any type of failure is encountered. # Why it would be valuable. For people running many instances of a well-tested workflow, such as Green Team and Mint Team production at Broad, the vast majority of failures are due to transient problems in the cloud, and it is very time consuming to deal with them. Having this auto-retry capability in Cromwell would be a huge help in making these workflows more robust and would greatly reduce the amount of manual work required to relaunch failed workflows (or save people from having to write their own bespoke scripts to auto-retry failed workflows). Having retries at the task level (rather than having to resubmit the whole workflow) would also be more efficient, especially when call caching is not in use. # Difference from existing issue. I believe this feature would satisfy the use cases of many (but not all) of the commenters on #1991, but in a simpler way. In contrast to that issue, no error messages need to be parsed here and there is no added functionality around auto increasing memory or disk. (For Mint Team produciton, we're interested in something like #1991, too, especially the stderr pattern matching, but I am guessing it would take longer to make happen given the wdl changes required, etc. The issue I'm filing here is the low hanging fruit for us.). # Combining with preemptibles. There is a question to resolve about what to do for a preemptible task in a workflow where failed_task_retries has also been set. My preference would be to make them additive. If the task says ""preemptible: 5"" and the workflow says ""failed_task_retries: 3"", then Cromwell will retry that task up to 8 times. The first 3 retries will use a preemptible machine -- regardless of the reason for the error. Additional retries beyond that will not use a preemptible machine. This approach would let failed_task_retries act as a floor for the entire workflow that guarantees all tasks, preemptible or not, will retry at least failed_task_",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3161:1417,message,messages,1417,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3161,1,['message'],['messages']
Integrability,g/job/cromwell-test-runner/1025/. java.util.concurrent.TimeoutException: Futures timed out after [1 second] at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:255) at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:259) at scala.concurrent.Await$.$anonfun$result$1(package.scala:215) at scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:53) at scala.concurrent.Await$.result(package.scala:142) at akka.http.scaladsl.testkit.RouteTest.responseAs(RouteTest.scala:70) at akka.http.scaladsl.testkit.RouteTest.responseAs$(RouteTest.scala:68) at cromiam.webservice.SwaggerServiceSpec.responseAs(SwaggerServiceSpec.scala:17) at cromiam.webservice.SwaggerServiceSpec.$anonfun$new$2(SwaggerServiceSpec.scala:30) at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58) at akka.http.scaladsl.testkit.RouteTest.$anonfun$check$1(RouteTest.scala:56) at akka.http.scaladsl.testkit.RouteTestResultComponent$RouteTestResult.$tilde$greater(RouteTestResultComponent.scala:50) at cromiam.webservice.SwaggerServiceSpec.$anonfun$new$1(SwaggerServiceSpec.scala:27) at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85) at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83) at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104) at org.scalatest.Transformer.apply(Transformer.scala:22) at org.scalatest.Transformer.apply(Transformer.scala:20) at org.scalatest.FlatSpecLike$$anon$1.apply(FlatSpecLike.scala:1682) at org.scalatest.TestSuite.withFixture(TestSuite.scala:196) at org.scalatest.TestSuite.withFixture$(TestSuite.scala:195) at org.scalatest.FlatSpec.withFixture(FlatSpec.scala:1685) at org.scalatest.FlatSpecLike.invokeWithFixture$1(FlatSpecLike.scala:1680) at org.scalatest.FlatSpecLike.$anonfun$runTest$1(FlatSpecLike.scala:1692) at org.scalatest.SuperEngine.runTestImpl(Engine.scala:289) at org.scalatest.FlatSpecLike.runTest(FlatSpecLike.scala:1692) at org.scalatest.FlatSpecLike.runTest$(FlatSpecLike.scala:1674) at org.scalat,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4357:1043,Rout,RouteTestResultComponent,1043,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4357,1,['Rout'],['RouteTestResultComponent']
Integrability,"gle.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469); at com.google.cloud.hadoop.util.AbstractGoogleAsyncWriteChannel$UploadOperation.call(AbstractGoogleAsyncWriteChannel.java:357); at java.util.concurrent.FutureTask.run(FutureTask.java:266); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:409); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); [2016-10-27 13:10:12,13] [error] Exception not convertible into handled response; com.google.api.client.googleapis.json.GoogleJsonResponseException: 404 Not Found; {; ""code"" : 404,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Not Found"",; ""reason"" : ""notFound""; } ],; ""message"" : ""Not Found""; }; at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145); at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113); at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:432); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469); at com.google.cloud.hadoop.util.AbstractGoogleAsyncWriteChannel$UploadOperation.call(AbstractGoogleAsyncWriteChannel.java:357); at jav",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1631:3493,message,message,3493,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1631,2,['message'],['message']
Integrability,"gleapis/google-auth-library-java) from 1.1.0 to 1.3.0.; [GitHub Release Notes](https://github.com/googleapis/google-auth-library-java/releases/tag/v1.3.0) - [Version Diff](https://github.com/googleapis/google-auth-library-java/compare/v1.1.0...v1.3.0). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/00809e6249b134635f71919c17c1c81603beb22d/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Files still referring to the old version number</summary>. The following files still refer to the old version number (1.1.0).; You might want to review and update them manually.; ```; CHANGELOG.md; centaur/src/main/resources/integrationTestCases/cwl/bcbio/gvcf-joint-workflow/steps/variantcall_batch_region.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/prealign-workflow/steps/variantcall_batch_region.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/somatic-workflow/steps/variantcall_batch_region.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/svcall-workflow/steps/variantcall_batch_region.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/wes_chr21_test-workflow-gcp/steps/variantcall_batch_region.cwl; cloud-nio/cloud-nio-impl-drs/src/main/scala/cloud/nio/impl/drs/DrsCloudNioFileSystemProvider.scala; cwl/src/test/resources/cwl/lodash.js; project/plugins.sbt; ```; </details>; <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.auth"", artifactId = ""google-auth-library-oauth2-http"" } ]; ```; </details>. labels: library-update, early-semver-mino",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6608:1055,integrat,integrationTestCases,1055,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6608,1,['integrat'],['integrationTestCases']
Integrability,"gure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>🔍 Files still referring to the old version number</summary>. The following files still refer to the old version number (0.9.0).; You might want to review and update them manually.; ```; centaur/src/main/resources/integrationTestCases/Somatic/CNV-Pair/cnv_somatic_pair_workflow_do_gc_wes.inputs; centaur/src/main/resources/integrationTestCases/Somatic/CNV-Panel/cnv_somatic_panel_workflow_do_gc_wes.inputs; centaur/src/main/resources/integrationTestCases/Somatic/Mutect2/Mutect2.aws.inputs; centaur/src/main/resources/integrationTestCases/Somatic/Mutect2/Mutect2.inputs; centaur/src/main/resources/integrationTestCases/germline/haplotype-caller-workflow/HaplotypeCallerWF.json; centaur/src/main/resources/integrationTestCases/germline/single-sample-production-workflow/PairedEndSingleSampleWf.options.json; centaur/src/main/resources/integrationTestCases/germline/single-sample-workflow/processing-for-variant-discovery-gatk4.hg38.wgs.inputs.json; centaur/src/main/resources/integrationTestCases/green/arrays/arrays.wdl; womtool/src/test/resources/validate/wdl_draft3/valid/HaplotypeCallerWF/HaplotypeCallerWF.inputs.json; womtool/src/test/resources/validate/wdl_draft3/valid/cnv_somatic_pair_workflow/cnv_somatic_pair_workflow.inputs.json; womtool/src/test/resources/validate/wdl_draft3/valid/joint-discovery-gatk/joint-discovery-gatk.inputs.json; ```; </details>; <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""io.github.jbwheatley"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { gr",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7294:1631,integrat,integrationTestCases,1631,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7294,1,['integrat'],['integrationTestCases']
Integrability,"hangelog.rst) - [Changelog](https://bitbucket.org/snakeyaml/snakeyaml/src/master/changelog.md) - [Changelog](https://bitbucket.org/snakeyaml/snakeyaml/src/master/changelog.markdown) - [Changelog](https://bitbucket.org/snakeyaml/snakeyaml/src/master/changelog.rst) - [Changelog](https://bitbucket.org/snakeyaml/snakeyaml/src/master/CHANGES.md) - [Changelog](https://bitbucket.org/snakeyaml/snakeyaml/src/master/CHANGES.markdown) - [Changelog](https://bitbucket.org/snakeyaml/snakeyaml/src/master/CHANGES.rst). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/00809e6249b134635f71919c17c1c81603beb22d/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Files still referring to the old version number</summary>. The following files still refer to the old version number (1.29).; You might want to review and update them manually.; ```; centaur/src/test/resources/centaur/test/metadata/failingInSeveralWaysMetadata.json; core/src/test/resources/hello_goodbye_scattered_papiv2.json; docs/developers/bitesize/ci/Cromwell_Deployment_Strategies.svg; docs/developers/bitesize/workflowParsing/forkjoin_graph.svg; docs/developers/bitesize/workflowParsing/wdlToWdlom_hermes.svg; scripts/metadata_comparison/test/resources/comparer/papiv1_version3_good.json; scripts/metadata_comparison/test/resources/comparer/papiv2_version3_good.json; ```; </details>; <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""org.yaml"", artifactId = ""snakeyaml"" } ]; ```; </details>. labels: test-library-update, old-version-remains, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6635:3456,depend,dependency,3456,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6635,1,['depend'],['dependency']
Integrability,"hard-linked to `<call_dir>/inputs`. When the same file is needed again it will check if the file already exists in the `cached-inputs` and then hard-link it. This saves all the time needed for copying. ### Technical notes; File collisions are prevented by appending the last modified time epoch millisecond to the name of the cached file. If the input file is changed between jobs it will create a new cache entry. Md5sums are not used because it is extremely compute intensive for large files. Path+modtime should guarantee that files are the same. . I have expanded the SFS test scala file so it properly tests the new `cached-inputs` strategy. I have added information on how to use the strategy in the docs, and added this PR to the changelog. ### Help still needed. There are two things that I could not figure out without cromwell developer help:. ~~* Checking whether a file exists and copying it to the cache should never be done by multiple threads simeltaneously. I have used the `synchronized` method to prevent this. I used an object for this, because I am sure it is unique within the JVM at cromwell runtime. This works fine, but I can imagine this can be solved in a nicer way using akka? However the akka documentation is an extensive jungle on its own, and requires quite some expertise to navigate. I could not find very quickly what I needed, and the `synchronization` primitive works fine. It is also **just 2 lines of extra code**. So if the akka solution is quite elegant as well I would like to learn about that. If not, well, it is not too bad having 2 lines of understandable commented code that is not ""the proper way of doing things(TM)"".~~. * I used the SFS scalatests to make sure everything worked correctly. However this did not test whether the thread safety was working correctly. I have added a test wdl in centaur: `standardTestCases/cached_copy/cached_copy.wdl`. This workflow creates 10 jobs that read the same input file. This workflow will crash if the `cached-i",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4900:2220,synchroniz,synchronized,2220,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900,1,['synchroniz'],['synchronized']
Integrability,"hat making them optional like `String? memory_mb` and then using syntax like `${""--mem "" + round(memory_mb) + ""m""} \` in the submit script means that argument will only be added if `memory` is defined, and will be omitted if `memory` is not defined. I've followed the documentation as closely as I can. However, when I try to submit a test job without `cpu` and `memory` set as a runtime attribute, I get a failure with these exceptions:; ```; cromwell.core.CromwellAggregatedException: Initialization Failure:; Runtime validation failed:; 	Task myTask has an invalid runtime attribute cpu = !! NOT FOUND !!; 	Task myTask has an invalid runtime attribute memory = !! NOT FOUND !!; 	at cromwell.engine.workflow.WorkflowActor$$anonfun$3.applyOrElse(WorkflowActor.scala:356); 	at cromwell.engine.workflow.WorkflowActor$$anonfun$3.applyOrElse(WorkflowActor.scala:339); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35); 	at akka.actor.FSM.processEvent(FSM.scala:707); 	at akka.actor.FSM.processEvent$(FSM.scala:704); ```. Here is the test WDL I'm using:. ```; # Example workflow; # Declare WDL version 1.0 if working in Terra; version 1.0; workflow myWorkflow {; call myTask. }. task myTask {; command <<<; echo ""hello world""; >>>; output {; String out = read_string(stdout()); }; }; ```. And my complete configuration for this backend:; ```; backend {; default = slurm. providers {; slurm {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory"" ; config {; runtime-attributes = """"""; Int? runtime_minutes; Int? cpu; Float? memory_mb; String? docker; String? partition; """""". submit = """"""; sbatch \; --wait \; -J ${job_name} \; -D ${cwd} \; -o ${out} \; -e ${err} \; ${""-t "" + runtime_minutes} \; ${""-c "" + cpu} \; ${""--mem "" + round(memory_mb) + ""m""} \; ${""-p "" + partition} \; --wrap ""/bin/bash ${script}""; """""". kill = ""scancel ${job_id}""; check-alive = ""squeue -j ${job_id}""; job-id-regex = ""Submitted batch job (\\d+).*""; }; }; }; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7455:2768,wrap,wrap,2768,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7455,1,['wrap'],['wrap']
Integrability,"he purpose of this task is to prove the memory-retry mechanism is configured correctly in our system. Result of TestBadCommandRetry:; The memory-error-key is caught and memory is increased as defined in memory-retry-multiplier.; I also see this failure message in metadata.json:; _""message"": ""stderr for job `MemoryRetryTest.TestBadCommandRetry:NA:1` contained one of the `memory-retry-error-keys: [Killed]` specified in the Cromwell config. Job might have run out of memory.""_. Grepping metadata for memory of this job, I see the expected behaviour:; ""memory"": ""1 GB"",; ""memory"": ""2 GB"",. The second task, **TestOutOfMemoryRetry** is designed to fail do to real out of memory error.; The purpose of this task is to shoe that memory-retry mechanism is not working when a task runs out of memory, even if ""Killed"" is written to stderr. Result of TestOutOfMemoryRetry:; When this task is run, it fails but **the job is retried with the same amount of memory**.; This time I see the following failure message:; _""message"": ""Task MemoryRetryTest.TestOutOfMemoryRetry:NA:1 failed. The job was stopped before the command finished. PAPI error code 9. Execution failed: generic::failed_precondition: while running \""/cromwell_root/script\"": unexpected exit status 137 was not ignored\n[UserAction] Unexpected exit status 137 while running \""/cromwell_root/script\"": Killed\n"",_. Grepping metadata for memory of this job, I see the memory expension is not working:; ""memory"": ""1 GB"",; ""memory"": ""1 GB"",; ; I have verified ""Killed"" is written correctly to stderr :; ```; gsutil cat gs://<out_bucket>/cromwell-execution/MemoryRetryTest/3035199e-bf2b-49a2-be87-483; 9e96a08eb/call-TestOutOfMemoryRetry/stderr; Killed ; ``` . We have also noticed that in the out of memory case, no retrurnCode is written to the metadata. **Test wdl for reproduction:**; `version 1.0. workflow MemoryRetryTest {; input {; String message = ""Killed""; }; call TestOutOfMemoryRetry {}; call TestBadCommandRetry {}; }. task TestOutOfMe",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7205:1388,message,message,1388,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7205,2,['message'],['message']
Integrability,"hi all,; I'm trying to run cromwell 84 will the following config, with, as far as I understand, a local HTSQLDB cache :. ```; include required(classpath(""application"")); # the file below was fixed in https://github.com/broadinstitute/cromwell/issues/7007; include ""SGE.conf"". call-caching {; 	enabled = true; invalidate-bad-cache-results = false; }. database {; profile = ""slick.jdbc.HsqldbProfile$""; db {; driver = ""org.hsqldb.jdbcDriver""; url = """"""; jdbc:hsqldb:file:cromwell-executions/cromwell-db/cromwell-db;; shutdown=false;; hsqldb.default_table_type=cached;hsqldb.tx=mvcc;; hsqldb.result_max_memory_rows=10000;; hsqldb.large_data=true;; hsqldb.applog=1;; hsqldb.lob_compressed=true;; hsqldb.script_format=3; """"""; connectionTimeout = 120000; numThreads = 1; }; }; ```. but when I execute the workflow . `java -Dconfig.file=${PWD}/app.conf -jar ${CROMWELL_JAR} run test.wdl --inputs input.json`. the configuration takes a long time with messages about `Checkpoint...` that takes about 10 minutes. . ```; (...); [2023-02-08 16:24:28,90] [info] dataFileCache commit start; [2023-02-08 16:24:28,91] [info] dataFileCache commit end; [2023-02-08 16:24:28,94] [info] checkpointClose end; [2023-02-08 16:24:28,96] [info] Checkpoint end - txts: 3051; [2023-02-08 16:24:29,05] [info] Checkpoint start; [2023-02-08 16:24:29,05] [info] checkpointClose start; [2023-02-08 16:24:29,07] [info] checkpointClose synched; [2023-02-08 16:24:29,08] [info] checkpointClose script done; [2023-02-08 16:24:29,08] [info] dataFileCache commit start; [2023-02-08 16:24:29,20] [info] dataFileCache commit end; [2023-02-08 16:24:29,53] [info] checkpointClose end; [2023-02-08 16:24:29,53] [info] Checkpoint end - txts: 3058; [2023-02-08 16:24:29,53] [info] Checkpoint start; [2023-02-08 16:24:29,53] [info] checkpointClose start; [2023-02-08 16:24:30,52] [info] checkpointClose synched; [2023-02-08 16:24:30,52] [info] checkpointClose script done; [2023-02-08 16:24:30,52] [info] dataFileCache commit start; [2023-02-08 16",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7009:943,message,messages,943,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7009,1,['message'],['messages']
Integrability,hod); 	at java.net.SocketInputStream.socketRead(SocketInputStream.java:116); 	at java.net.SocketInputStream.read(SocketInputStream.java:171); 	at java.net.SocketInputStream.read(SocketInputStream.java:141); 	at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); 	at sun.security.ssl.InputRecord.read(InputRecord.java:503); 	at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973); 	at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:704); 	at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:647); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1569); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1474); 	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:338); 	at com.google.api.client.http.javanet.NetHttpResponse.<init>(NetHttpResponse.java:37); 	at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:94); 	at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469); 	at com.google.cloud.storage.spi.DefaultStorageRpc.rewrite(DefaultStorageRpc.java:590); 	at com.google.cloud.storage.spi,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2229:4390,protocol,protocol,4390,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2229,1,['protocol'],['protocol']
Integrability,"https://broadinstitute.atlassian.net/browse/GAWB-3950. https://fc-jenkins.dsp-techops.broadinstitute.org/view/Testing/view/Test%20Runners/job/cromwell-test-runner/790/; https://fc-jenkins.dsp-techops.broadinstitute.org/job/cromwell-test-runner/833/; https://fc-jenkins.dsp-techops.broadinstitute.org/job/cromwell-test-runner/804/. tc: KeyValueServiceActor should insert a key/value; tc: KeyValueServiceActor should return error if key doesn't exist; tc: KeyValueServiceActor should be able to overwrite values. {quote}; org.scalatest.exceptions.TestFailedException: The future returned an exception of type: akka.pattern.AskTimeoutException, with message: Ask timed out on [Actor[akka://KeyValueServiceActorSpec/user/$a#-1019375090]] after [200000 ms]. Sender[null] sent message of type ""cromwell.services.keyvalue.KeyValueServiceActor$KvPut"".. at org.scalatest.concurrent.Futures$FutureConcept.tryTryAgain$1(Futures.scala:531) at org.scalatest.concurrent.Futures$FutureConcept.futureValueImpl(Futures.scala:550) at org.scalatest.concurrent.Futures$FutureConcept.futureValueImpl$(Futures.scala:479) at org.scalatest.concurrent.ScalaFutures$$anon$1.futureValueImpl(ScalaFutures.scala:275) at org.scalatest.concurrent.Futures$FutureConcept.futureValue(Futures.scala:476) at org.scalatest.concurrent.Futures$FutureConcept.futureValue$(Futures.scala:475) at org.scalatest.concurrent.ScalaFutures$$anon$1.futureValue(ScalaFutures.scala:275) at cromwell.services.keyvalue.impl.KeyValueServiceActorSpec.$anonfun$new$2(KeyValueServiceActorSpec.scala:46) at ; {quote}",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4320:647,message,message,647,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4320,2,['message'],['message']
Integrability,"https://cromwell.gotc-int.broadinstitute.org/swagger/index.html?url=/swagger/cromwell.yaml#!/Workflows/post_workflows_version_id_abort. When going through swagger, the abort takes a long time and then gives an error: ; Response Code 500; ""status"": ""error"",; ""message"": ""The server was not able to produce a timely response to your request."". The workflow is removed from WORKFLOW_STORE_ENTRY but the associated jobs are still present in JOB_STORE_ENTRY. . There are no errors in the logs: ; `; 2016-12-12 18:22:26,139 cromwell-system-akka.dispatchers.engine-dispatcher-1282 INFO - WorkflowExecutionActor [UUID(8a965a5e)]: Abort received. Aborting 11 EJEAs; 2016-12-12 18:29:42,727 cromwell-system-akka.dispatchers.engine-dispatcher-120 INFO - WorkflowExecutionActor [UUID(73be7f27)]: Abort received. Aborting 13 EJEAs; 2016-12-12 18:31:29,146 cromwell-system-akka.dispatchers.engine-dispatcher-120 INFO - WorkflowExecutionActor [UUID(13965e09)]: Abort received. Aborting 10 EJEAs; 2016-12-12 18:31:46,093 cromwell-system-akka.dispatchers.engine-dispatcher-120 INFO - WorkflowExecutionActor [UUID(804a56b6)]: Abort received. Aborting 11 EJEAs; 2016-12-12 18:32:05,063 cromwell-system-akka.dispatchers.engine-dispatcher-120 INFO - WorkflowExecutionActor [UUID(2c6302c8)]: Abort received. Aborting 6 EJEAs; 2016-12-12 18:32:25,094 cromwell-system-akka.dispatchers.engine-dispatcher-1282 INFO - WorkflowExecutionActor [UUID(793dd16f)]: Abort received. Aborting 5 EJEAs; 2016-12-12 18:32:38,555 cromwell-system-akka.dispatchers.engine-dispatcher-1282 INFO - WorkflowExecutionActor [UUID(4fddebd4)]: Abort received. Aborting 13 EJEAs; 2016-12-12 18:32:50,674 cromwell-system-akka.dispatchers.engine-dispatcher-120 INFO - WorkflowExecutionActor [UUID(aadd5082)]: Abort received. Aborting 7 EJEAs; 2016-12-12 18:33:01,265 cromwell-system-akka.dispatchers.engine-dispatcher-1282 INFO - WorkflowExecutionActor [UUID(edaa9993)]: Abort received. Aborting 4 EJEAs; 2016-12-12 18:33:12,453 cromwell-system-akka.disp",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1775:259,message,message,259,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1775,1,['message'],['message']
Integrability,"https://cromwell.readthedocs.io/en/stable/GettingHelp/ suggests that users get support at a forum that doesn't exist anymore. Normally when I find a dead link in docs, I just replace it in a PR, but I'm really not sure if there's anything to replace it with. There is a new GATK forum, but from what I've seen it doesn't really take questions about non-GATK WDLs even in the Community/Other section. There is a Cromwell Slack, but Slack is not available in all countries, isn't indexed, and the workspace is on a free plan (some old messages are already unavailable), so it's not a good option for actual support. The same goes for the OpenWDL Slack - not available in all places, not indexed by search engines, continuously overwriting itself due to being on a free plan. Terra Support is only focused on Terra-specific usage of Cromwell, even though it's common to test WDLs locally before running them in Terra.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6801:533,message,messages,533,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6801,1,['message'],['messages']
Integrability,https://developers.googleblog.com/2018/03/discontinuing-support-for-json-rpc-and.html. Since we only do homogeneous batch requests it should just be a matter of making sure our google client dependencies are up to date,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4281:191,depend,dependencies,191,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4281,1,['depend'],['dependencies']
Integrability,https://fc-jenkins.dsp-techops.broadinstitute.org/job/cromwell-test-runner/1025/. java.util.concurrent.TimeoutException: Futures timed out after [1 second] at scala.concurrent.impl.Promise$DefaultPromise.ready(Promise.scala:255) at scala.concurrent.impl.Promise$DefaultPromise.result(Promise.scala:259) at scala.concurrent.Await$.$anonfun$result$1(package.scala:215) at scala.concurrent.BlockContext$DefaultBlockContext$.blockOn(BlockContext.scala:53) at scala.concurrent.Await$.result(package.scala:142) at akka.http.scaladsl.testkit.RouteTest.responseAs(RouteTest.scala:70) at akka.http.scaladsl.testkit.RouteTest.responseAs$(RouteTest.scala:68) at cromiam.webservice.SwaggerServiceSpec.responseAs(SwaggerServiceSpec.scala:17) at cromiam.webservice.SwaggerServiceSpec.$anonfun$new$2(SwaggerServiceSpec.scala:30) at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58) at akka.http.scaladsl.testkit.RouteTest.$anonfun$check$1(RouteTest.scala:56) at akka.http.scaladsl.testkit.RouteTestResultComponent$RouteTestResult.$tilde$greater(RouteTestResultComponent.scala:50) at cromiam.webservice.SwaggerServiceSpec.$anonfun$new$1(SwaggerServiceSpec.scala:27) at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85) at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83) at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104) at org.scalatest.Transformer.apply(Transformer.scala:22) at org.scalatest.Transformer.apply(Transformer.scala:20) at org.scalatest.FlatSpecLike$$anon$1.apply(FlatSpecLike.scala:1682) at org.scalatest.TestSuite.withFixture(TestSuite.scala:196) at org.scalatest.TestSuite.withFixture$(TestSuite.scala:195) at org.scalatest.FlatSpec.withFixture(FlatSpec.scala:1685) at org.scalatest.FlatSpecLike.invokeWithFixture$1(FlatSpecLike.scala:1680) at org.scalatest.FlatSpecLike.$anonfun$runTest$1(FlatSpecLike.scala:1692) at org.scalatest.SuperEngine.runTestImpl(Engine.scala:289) at org.scalatest.FlatSpecLike.runTest(FlatSpecLike.scala:1692) at org.scalatest.FlatSpecLike.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4357:535,Rout,RouteTest,535,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4357,6,['Rout'],['RouteTest']
Integrability,"https://fc-jenkins.dsp-techops.broadinstitute.org/job/cromwell-test-runner/754. 02:11:16 cromwell-test_1 | [info] *** 1 TEST FAILED ***; 02:11:16 cromwell-test_1 | [info] EnhancedRhinoSandboxSpec:; 02:11:16 cromwell-test_1 | [info] EnhancedRhinoSandbox ; 02:11:16 cromwell-test_1 | [info] - should synchronize global ContextFactory initialization *** FAILED *** (1 second, 15 milliseconds); 02:11:16 cromwell-test_1 | [info] all threads did not complete successfully: Vector(true, false, false, false, false, false, false, false, true, false) did not contain only (true) (EnhancedRhinoSandboxSpec.scala:37); 02:11:16 cromwell-test_1 | [error] Failed: Total 125, Failed 1, Errors 0, Passed 124, Ignored 3; 02:11:16 cromwell-test_1 | [error] Failed tests:; 02:11:16 cromwell-test_1 | [error] 	cwl.internal.EnhancedRhinoSandboxSpec",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4306:298,synchroniz,synchronize,298,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4306,1,['synchroniz'],['synchronize']
Integrability,"https://fc-jenkins.dsp-techops.broadinstitute.org/job/cromwell-test-runner/793/consoleFull. 14:08:29 cromwell-test_1 | [info] - should execute calls with input files and localize them appropriately *** FAILED *** (13 seconds, 25 milliseconds); 14:08:29 cromwell-test_1 | [info] $anon$1 was thrown during property evaluation. (SharedFileSystemJobExecutionActorSpec.scala:119); 14:08:29 cromwell-test_1 | [info] Message: A timeout occurred waiting for a future to complete. Queried 21 times, sleeping 500 milliseconds between each query.; 14:08:29 cromwell-test_1 | [info] Location: (SharedFileSystemJobExecutionActorSpec.scala:137); 14:08:29 cromwell-test_1 | [info] Occurred at table row 2 (zero based, not counting headings), which had values (; 14:08:29 cromwell-test_1 | [info] conf = BackendConfigurationDescriptor(Config(SimpleConfigObject({""default-runtime-attributes"":{""continueOnReturnCode"":0,""cpu"":1,""failOnStderr"":false},""filesystems"":{""local"":{""localization"":[""soft-link""]}},""root"":""local-cromwell-executions""})),Config(SimpleConfigObject({}))),; 14:08:29 cromwell-test_1 | [info] isSymLink = true; 14:08:29 cromwell-test_1 | [info] ); 14:08:29 cromwell-test_1 | [info] org.scalatest.exceptions.TableDrivenPropertyCheckFailedException:; 14:08:29 cromwell-test_1 | [info] ...; 14:08:29 cromwell-test_1 | [info] at cromwell.backend.sfs.SharedFileSystemJobExecutionActorSpec.localizationSpec(SharedFileSystemJobExecutionActorSpec.scala:119); 14:08:29 cromwell-test_1 | [info] at cromwell.backend.sfs.SharedFileSystemJobExecutionActorSpec.$anonfun$new$4(SharedFileSystemJobExecutionActorSpec.scala:156); 14:08:29 cromwell-test_1 | [info] at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85); 14:08:29 cromwell-test_1 | [info] at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83); 14:08:29 cromwell-test_1 | [info] at org.scalatest.OutcomeOf$.outcomeOf(OutcomeOf.scala:104); 14:08:29 cromwell-test_1 | [info] at org.scalatest.Transformer.apply(Transformer.scala:22); 14:08:29 cromwell-t",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4319:410,Message,Message,410,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4319,1,['Message'],['Message']
Integrability,"hub.com/jbwheatley/pact4s). from `0.9.0` to `0.10.1-java8`. 📜 [GitHub Release Notes](https://github.com/jbwheatley/pact4s/releases/tag/v0.10.1-java8) - [Version Diff](https://github.com/jbwheatley/pact4s/compare/v0.9.0...v0.10.1-java8). ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>🔍 Files still referring to the old version number</summary>. The following files still refer to the old version number (0.9.0).; You might want to review and update them manually.; ```; centaur/src/main/resources/integrationTestCases/Somatic/CNV-Pair/cnv_somatic_pair_workflow_do_gc_wes.inputs; centaur/src/main/resources/integrationTestCases/Somatic/CNV-Panel/cnv_somatic_panel_workflow_do_gc_wes.inputs; centaur/src/main/resources/integrationTestCases/Somatic/Mutect2/Mutect2.aws.inputs; centaur/src/main/resources/integrationTestCases/Somatic/Mutect2/Mutect2.inputs; centaur/src/main/resources/integrationTestCases/germline/haplotype-caller-workflow/HaplotypeCallerWF.json; centaur/src/main/resources/integrationTestCases/germline/single-sample-production-workflow/PairedEndSingleSampleWf.options.json; centaur/src/main/resources/integrationTestCases/germline/single-sample-workflow/processing-for-variant-discovery-gatk4.hg38.wgs.inputs.json; centaur/src/main/resources/integrationTestCases/green/arrays/arrays.wdl; womtool/src/test/resources/validate/wdl_draft3/valid/HaplotypeCallerWF/HaplotypeCallerWF.inputs.json; womtool/src/test/resources/validate/wdl_draft3/valid/cnv_somatic_pair_workflow/cnv_somatic_pair_workflow.inputs",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7294:1140,integrat,integrationTestCases,1140,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7294,1,['integrat'],['integrationTestCases']
Integrability,"ication/octet-stream]...; / [0/1 files][ 0.0 B/ 3.7 MiB] 0% Done ; BadRequestException: 400 The maximum object length is 1024 characters, but got a name with 1055 characters: ''gcp/work_cromwell/main-somatic.cwl/c21b8bf4-9f80-45a3-9a23-f345b4d8f295/call-...''; CommandException: 1 file/object could not be transferred.; Copying file:///cromwell_root/bcbiotest/gcp/work_cromwell/main-somatic.cwl/c21b8bf4-9f80-45a3-9a23-f345b4d8f295/call-calculate_sv_coverage/shard-0/cromwell_root/bcbiotest/gcp/work_cromwell/main-somatic.cwl/c21b8bf4-9f80-45a3-9a23-f345b4d8f295/call-calculate_sv_bins/cromwell_root/bcbiotest/gcp/work_cromwell/main-somatic.cwl/c21b8bf4-9f80-45a3-9a23-f345b4d8f295/call-postprocess_alignment/shard-0/cromwell_root/bcbiotest/gcp/work_cromwell/main-somatic.cwl/c21b8bf4-9f80-45a3-9a23-f345b4d8f295/call-postprocess_alignment_to_rec/cromwell_root/bcbiotest/gcp/work_cromwell/main-somatic.cwl/c21b8bf4-9f80-45a3-9a23-f345b4d8f295/call-alignment/shard-0/wf-alignment.cwl/94c8f53c-dad4-4c48-9e09-f6927356f352/call-merge_split_alignments/cromwell_root/bcbiotest/gcp/work_cromwell/main-somatic.cwl/c21b8bf4-9f80-45a3-9a23-f345b4d8f295/call-alignment/shard-0/wf-alignment.cwl/94c8f53c-dad4-4c48-9e09-f6927356f352/call-process_alignment/shard-0/cromwell_root/align/Test2/Test2-sort.bam.bai [Content-Type=application/octet-stream]...; / [0/1 files][ 0.0 B/ 184.0 B] 0% Done ; BadRequestException: 400 The maximum object length is 1024 characters, but got a name with 1059 characters: ''gcp/work_cromwell/main-somatic.cwl/c21b8bf4-9f80-45a3-9a23-f345b4d8f295/call-...''; CommandException: 1 file/object could not be transferred.; ```; We could avoid in this case by shortening the folder name we're using for cromwell storage but I'm worried about hitting this later since it will be dependent on sample names (the `Test2` in these paths) and users correctly setting a short root path. Do you know where this limit originates from? Is there any way to work around it? Thanks for any suggestions.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4471:3212,depend,dependent,3212,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4471,1,['depend'],['dependent']
Integrability,in `when(WorkflowExecutionAbortingState)` there's a handler for `AbortedResponse` which appears to be doing some reasonable stuff but I can't find anything sending that message.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1376:169,message,message,169,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1376,1,['message'],['message']
Integrability,"in open\n response = self._open(req, data)\n File \""/usr/lib/python2.7/urllib2.py\"", line 419, in _open\n '_open', req)\n File \""/usr/lib/python2.7/urllib2.py\"", line 379, in _call_chain\n result = func(*args)\n File \""/usr/lib/python2.7/urllib2.py\"", line 1211, in http_open\n return self.do_open(httplib.HTTPConnection, req)\n File \""/usr/lib/python2.7/urllib2.py\"", line 1184, in do_open\n r = h.getresponse(buffering=True)\n File \""/usr/lib/python2.7/httplib.py\"", line 1072, in getresponse\n response.begin()\n File \""/usr/lib/python2.7/httplib.py\"", line 408, in begin\n version, status, reason = self._read_status()\n File \""/usr/lib/python2.7/httplib.py\"", line 366, in _read_status\n line = self.fp.readline()\n File \""/usr/lib/python2.7/socket.py\"", line 447, in readline\n data = self._sock.recv(self._rbufsize)\nsocket.timeout: timed out\n)""; java.lang.Exception: Task m2.Mutect2.M2:1:1 failed. JES error code 5. Message: 9: Failed to localize files: failed to copy the following files: ""gs://5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-10A-01D-A25E-08.2.bam -> /mnt/local-disk/5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-10A-01D-A25E-08.2.bam (cp failed: gsutil -q -m cp gs://5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-10A-01D-A25E-08.2.bam /mnt/local-disk/5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-10A-01D-A25E-08.2.bam, command failed: Traceback (most recent call last):\n File \""/usr/local/share/google/google-cloud-sdk/bin/bootstrapping/gsutil.py\"", line 75, in <module>\n main()\n File \""/usr/local/share/google/google-cloud-sdk/bin/bootstrapping/gsutil.py\"", line 22, in main\n project, account = bootstrapping.GetActiveProjectAndAccount()\n File \""/usr/local/share/google/google-cloud-sdk/bin/bootstrapping/bootstrapping.py\"", line 205, in GetActiveProjectAndAccount\n project_name = properties.VALUES.core.project",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2228:9165,Message,Message,9165,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2228,1,['Message'],['Message']
Integrability,"inWorkerThread.java:107); [2016-10-27 13:10:31,93] [info] Waiting for 1 workflows to abort...; [2016-10-27 13:10:32,93] [info] Waiting for 1 workflows to abort...; [2016-10-27 13:10:33,94] [info] Waiting for 1 workflows to abort...; [2016-10-27 13:10:34,94] [info] Waiting for 1 workflows to abort...; [2016-10-27 13:10:35,94] [info] Waiting for 1 workflows to abort...; [2016-10-27 13:10:36,94] [info] Waiting for 1 workflows to abort...; [2016-10-27 13:10:37,94] [info] Waiting for 1 workflows to abort...; [2016-10-27 13:10:38,94] [info] Waiting for 1 workflows to abort...; [2016-10-27 13:10:39,94] [info] Waiting for 1 workflows to abort...; [2016-10-27 13:10:40,94] [info] Waiting for 1 workflows to abort...; [2016-10-27 13:10:41,94] [info] Waiting for 1 workflows to abort...; [2016-10-27 13:10:42,05] [error] Exception not convertible into handled response; com.google.api.client.googleapis.json.GoogleJsonResponseException: 404 Not Found; {; ""code"" : 404,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Not Found"",; ""reason"" : ""notFound""; } ],; ""message"" : ""Not Found""; }; at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145); at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113); at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:432); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469); at com.google.cloud.hadoop.util.AbstractGoogleAsyncWriteChannel$UploadOperation.call(AbstractGoogleAsyncWriteChannel.java:357); at jav",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1631:12682,message,message,12682,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1631,2,['message'],['message']
Integrability,increase test timeout on akka http routes for slow CI envs,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4250:35,rout,routes,35,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4250,1,['rout'],['routes']
Integrability,"ing on a scatter job and some of the scatter jobs get a cache hit but others get a cache miss. . I have queried the METADATA_ENTRY table for the two workflows and all the call cache entries look identical. . Here is my process:. 1. I queried METADATA_ENTRY with this WHERE condition: `(WORKFLOW_EXECUTION_UUID ='29791b64-b47a-44ba-aff0-7ab48bc10677' or WORKFLOW_EXECUTION_UUID ='5de042e3-7a03-4c77-8972-f0e4cd010e4b') and CALL_FQN = 'sampleLevelWorkflow_WGS.align' and JOB_SCATTER_INDEX =0`; 2. I sort by METADATA_KEY; 3. Then I go down the list and compare the hashes for the two workflows for each METADATA_KEY. Here is a case where workflow 29791b64 is a restart of 5de042e3. (Workflow 5de042e3 is itself a restart but I don't think that is important here.) I have shown below all the records from METADATA_ENTRY that start with ""callCaching"" and they all look identical, yet it clearly says it is a ""Cache Miss"". **Is there anywhere I can see a log message stating exactly which hashes resulted in the cache miss?** I have tried to enable LOG_LEVEL=DEBUG but couldn't see it there. Thanks in advance for your help!. |WORKFLOW_EXECUTION_UUID|METADATA_KEY|METADATA_VALUE|; |-----------------------|------------|--------------|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:result|Cache Miss|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:result|Cache Miss|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hit|false|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hit|false|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:runtime attribute:failOnStderr|68934A3E9455FA72420237EB05902327|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:runtime attribute:failOnStderr|68934A3E9455FA72420237EB05902327|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:runtime attribute:docker|4AD3C387725244C1348F252B031B956D|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:runtime attribute:docker|4AD3C387725244C1348F252B031B956D|; |5de042e3-7a03-4c77-8972-f0",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7248:1049,message,message,1049,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7248,1,['message'],['message']
Integrability,"ing:. ```; {; ""workflowName"": ""echo_strings"",; ""submittedFiles"": {; ""inputs"": ""{...},; ""calls"": {; ""echo_strings.echo_files"": [{; ""preemptible"": false,; ""retryableFailure"": false,; ""executionStatus"": ""Failed"",; ""stdout"": ""gs://fc-2d3fd356-e3be-4953-92f1-60af623e6fa5/b6b190d6-8640-4638-94cd-15f16b194f38/echo_strings/c386672d-0248-4968-9b1a-114f5f5c4706/call-echo_files/echo_files-stdout.log"",; ""backendStatus"": ""Failed"",; ""shardIndex"": -1,; ""jes"": {; ""endpointUrl"": ""https://genomics.googleapis.com/"",; ""machineType"": ""us-central1-c/n1-standard-1"",; ""googleProject"": ""broad-dsde-dev"",; ""executionBucket"": ""gs://cromwell-dev/cromwell-executions"",; ""zone"": ""us-central1-c"",; ""instanceName"": ""ggp-3462354720519617596""; },; ""runtimeAttributes"": {...},; ""cache"": {; ""allowResultReuse"": true; },; ""Effective call caching mode"": ""CallCachingOff"",; ""inputs"": {...; },; ""failures"": [{; ""message"": ""Task c386672d-0248-4968-9b1a-114f5f5c4706:echo_files failed: error code 5. Message: 8: Failed to pull image ubuntu:latest: \""docker --config /tmp/.docker/ pull ubuntu:latest\"" failed: exit status 1: Pulling repository docker.io/library/ubuntu\nNetwork timed out while trying to connect to https://index.docker.io/v1/repositories/library/ubuntu/images. You may want to check your internet connection or if you are behind a proxy.\n""; }],; ""jobId"": ""operations/EJiq_oWfKxi8-N-X4qiwhjAgw7vetLsXKg9wcm9kdWN0aW9uUXVldWU"",; ""backend"": ""JES"",; ""end"": ""2017-01-30T19:14:19.708Z"",; ""stderr"": ""gs://fc-2d3fd356-e3be-4953-92f1-60af623e6fa5/b6b190d6-8640-4638-94cd-15f16b194f38/echo_strings/c386672d-0248-4968-9b1a-114f5f5c4706/call-echo_files/echo_files-stderr.log"",; ""callRoot"": ""gs://fc-2d3fd356-e3be-4953-92f1-60af623e6fa5/b6b190d6-8640-4638-94cd-15f16b194f38/echo_strings/c386672d-0248-4968-9b1a-114f5f5c4706/call-echo_files"",; ""attempt"": 1,; ""executionEvents"": [...],; ""backendLogs"": {; ""log"": ""gs://fc-2d3fd356-e3be-4953-92f1-60af623e6fa5/b6b190d6-8640-4638-94cd-15f16b194f38/echo_strings/c386672d-0248-4968-9b1a-114",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2037:1152,Message,Message,1152,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2037,1,['Message'],['Message']
Integrability,"inished; [2022-12-15 21:28:53,47] [info] WorkflowManagerActor stopped; [2022-12-15 21:28:53,71] [info] Connection pools shut down; [2022-12-15 21:28:53,71] [info] Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds; [2022-12-15 21:28:53,71] [info] Shutting down JobStoreActor - Timeout = 1800 seconds; [2022-12-15 21:28:53,71] [info] Shutting down CallCacheWriteActor - Timeout = 1800 seconds; [2022-12-15 21:28:53,71] [info] Shutting down ServiceRegistryActor - Timeout = 1800 seconds; [2022-12-15 21:28:53,71] [info] Shutting down DockerHashActor - Timeout = 1800 seconds; [2022-12-15 21:28:53,71] [info] Shutting down IoProxy - Timeout = 1800 seconds; [2022-12-15 21:28:53,71] [info] CallCacheWriteActor Shutting down: 0 queued messages to process; [2022-12-15 21:28:53,72] [info] SubWorkflowStoreActor stopped; [2022-12-15 21:28:53,72] [info] JobStoreActor stopped; [2022-12-15 21:28:53,72] [info] CallCacheWriteActor stopped; [2022-12-15 21:28:53,72] [info] IoProxy stopped; [2022-12-15 21:28:53,74] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2022-12-15 21:28:53,74] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2022-12-15 21:28:53,75] [info] WriteMetadataActor Shutting down: 0 queued messages to process; [2022-12-15 21:28:53,75] [info] KvWriteActor Shutting down: 0 queued messages to process; [2022-12-15 21:28:53,76] [info] ServiceRegistryActor stopped; [2022-12-15 21:28:53,77] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2022-12-15 21:28:53,77] [info] DockerHashActor stopped; [2022-12-15 21:28:53,80] [info] Database closed; [2022-12-15 21:28:53,80] [info] Stream materializer shut down; [2022-12-15 21:28:53,80] [info] WDL HTTP import resolver closed; Workflow 9e4f5894-f7e6-4e2f-be4b-f547d6de7fff transitioned to state Failed; $; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6971:51226,message,messages,51226,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6971,2,['message'],['messages']
Integrability,"inputs"": {...; },; ""returnCode"": -1,; ""failures"": [{; ""message"": ""Call aggregate_data_workflow.aggregate_data: return code was -1""; }, {; ""message"": ""Call aggregate_data_workflow.aggregate_data: return code was -1""; }, {; ""message"": ""Call aggregate_data_workflow.aggregate_data: return code was -1""; }],; ""jobId"": ""2957"",; ""backend"": ""JES"",; ""end"": ""2016-12-02T15:05:42.655Z"",; ""stderr"": ""/cromwell-executions/aggregate_data_workflow/3608d6ca-fbb4-4232-b197-268058470bfc/call-aggregate_data/execution/stderr"",; ""callRoot"": ""/cromwell-executions/aggregate_data_workflow/3608d6ca-fbb4-4232-b197-268058470bfc/call-aggregate_data"",; ""attempt"": 1,; ""executionEvents"": [...]; },; ""outputs"": {. },; ""workflowRoot"": ""gs://fc-2d3fd356-e3be-4953-92f1-60af623e6fa5/9ea737cd-a512-4c62-820c-dd1505ea7676/aggregate_data_workflow/3608d6ca-fbb4-4232-b197-268058470bfc"",; ""id"": ""3608d6ca-fbb4-4232-b197-268058470bfc"",; ""inputs"": {...; },; ""submission"": ""2016-12-01T21:21:40.188Z"",; ""status"": ""Failed"",; ""failures"": [{; ""message"": ""Call aggregate_data_workflow.aggregate_data: return code was -1""; }, {; ""message"": ""Call aggregate_data_workflow.aggregate_data: return code was -1""; }, {; ""message"": ""Call aggregate_data_workflow.aggregate_data: return code was -1""; }],; ""workflowLog"": ""gs://fc-2d3fd356-e3be-4953-92f1-60af623e6fa5/9ea737cd-a512-4c62-820c-dd1505ea7676/workflow.logs/workflow.3608d6ca-fbb4-4232-b197-268058470bfc.log"",; ""end"": ""2016-12-02T15:05:42.868Z"",; ""start"": ""2016-12-02T15:05:40.873Z""; }; ```. Here there's no ""message"" and there are ""timestamp"" and ""failure"". ```; {; ""workflowName"": ""aggregate_data_workflow"",; ""submittedFiles"": {; ""options"": ""{\n \""default_runtime_attributes\"": {\n \""zones\"": \""us-central1-b\""\n },\n \""google_project\"": \""broad-dsde-dev\"",\n \""auth_bucket\"": \""gs://cromwell-auth-broad-dsde-dev\"",\n \""refresh_token\"": \""cleared\"",\n \""account_name\"": \""abaumann.firecloud@gmail.com\"",\n \""jes_gcs_root\"": \""gs://fc-5539c024-3ba8-4ed1-97c3-82fed2675776/1626e6be-60ed-48b1-9",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2037:4850,message,message,4850,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2037,1,['message'],['message']
Integrability,"io/) describes itself as:. > Open-source error tracking that helps developers monitor and fix crashes in real time. Cromwell is using an deprecated version of the Sentry java bindings for logback called `raven-logback`. The current bindings are called `sentry-logback`. Additionally, the cromwell docs currently mention that sentry can be setup via the ""configuration value"" `sentry.dsn`. https://github.com/broadinstitute/cromwell/blob/b8d3d2fd4a583d3e46394efb104005c12cdf182d/docs/Logging.md#L48. https://github.com/broadinstitute/cromwell/blob/b8d3d2fd4a583d3e46394efb104005c12cdf182d/docs/Configuring.md#L345-L355. This is not correct as `raven-logback` nor its underlying library `raven` use Typesafe Config. Instead for `raven` the value must be set as a system property, or alternatively as a different environment variable. However the latest `sentry` library (and transitively `sentry-logback`) do allow code configuration via `Sentry.init`. **A/C:**; - Replace `raven-logback` dependency with `sentry-logback`; - ~Allow setting a `cromwell.sentry.*` stanza with Cromwell specific sentry configuration. Alternative namespaces could be `sentry.*` or `system.sentry.*`, but both namespaces may collide with other library/application configurations in the future!~; - ~Wire the `cromwell.sentry.*` HOCON fields into `Sentry.init`~; - ~Default the sentry DSN in `reference.conf` to a noop -OR- ensure that when an error is generated that the latest version of `sentry` does not output a ""suitable DSN"" warning~; - Update docs for Cromwell+Sentry in both `docs/Logging.md` and `docs/Configuring.md`; - ~Update `CHANGELOG.md` with configuration changes for Cromwell+Sentry~ Edit: Not necessary if still using sentry style configuration. **Links:**; - http://cromwell.readthedocs.io/en/develop/Configuring/#workflow-log-directory; - http://cromwell.readthedocs.io/en/develop/Logging/#workflow-logs; - (video) [Episode #108 - Tracking Errors with Sentry](https://www.youtube.com/watch?v=n5hWUD2CXd8)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3657:1609,depend,dependency,1609,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3657,1,['depend'],['dependency']
Integrability,"ion tool for structural variants.\nThe primary function of LINX is grouping together individual SV calls into distinct events\nand properly classify and annotating the event to understand both its mechanism and genomic impact.\n"",; ""requirements"": [; {; ""class"": ""ResourceRequirement"",; ""coresMin"": 4,; ""ramMin"": 16000; },; {; ""class"": ""DockerRequirement"",; ""dockerPull"": ""umccr/linx:1.10-beta""; },; {; ""class"": ""ShellCommandRequirement""; },; {; ""class"": ""InlineJavascriptRequirement"",; ""expressionLib"": [; ""var get_start_memory = function(){ /* Start with 2 Gb */ return 2000; }"",; ""var get_max_memory_from_runtime_memory = function(max_ram){ /* Get Max memory and subtract heap memory */ return max_ram - get_start_memory(); }""; ]; }; ],; ""baseCommand"": [; ""java"",; ""-Xms$(get_start_memory())m"",; ""-Xmx$(get_max_memory_from_runtime_memory(runtime.ram))m"",; ""-jar"",; ""/opt/linx/linx.jar""; ],; ""inputs"": [; {; ""type"": [; ""null"",; ""int""; ],; ""doc"": ""threshold for # SVs in clusters to skip chaining routine (default = 2000)\n"",; ""inputBinding"": {; ""prefix"": ""-chaining_sv_limit""; },; ""default"": 2000,; ""id"": ""#linx-1.10-beta.cwl/chaining_sv_limit""; },; {; ""type"": [; ""null"",; ""boolean""; ],; ""doc"": ""Optional - Discover and annotate gene fusions\n"",; ""inputBinding"": {; ""prefix"": ""-check_drivers""; },; ""default"": false,; ""id"": ""#linx-1.10-beta.cwl/check_drivers""; },; {; ""type"": [; ""null"",; ""boolean""; ],; ""doc"": ""Optional - discover and annotate gene fusions\n"",; ""inputBinding"": {; ""prefix"": ""-check_fusions""; },; ""default"": false,; ""id"": ""#linx-1.10-beta.cwl/check_fusions""; },; {; ""type"": [; ""null"",; ""string""; ],; ""doc"": ""[password]\n"",; ""inputBinding"": {; ""prefix"": ""-db_pass""; },; ""id"": ""#linx-1.10-beta.cwl/db_pass""; },; {; ""type"": [; ""null"",; ""string""; ],; ""doc"": ""[db_url]\n"",; ""inputBinding"": {; ""prefix"": ""-db_url""; },; ""id"": ""#linx-1.10-beta.cwl/db_url""; },; {; ""type"": [; ""null"",; ""string""; ],; ""doc"": ""[username]\n"",; ""inputBinding"": {; ""prefix"": ""-db_user""; },; ""id"": ""#linx-1.10-beta.c",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5826:21757,rout,routine,21757,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5826,1,['rout'],['routine']
Integrability,ion.; 2019/07/10 18:29:37 Localizing input dos://dg.4503/cbdb14f5-cc89-4481-bad7-2ef8f36a1290 -> /cromwell_root/topmed-irc-share/genomes/NWD127112.b38.irc.v1.cram; Compiling (synthetic)/ammonite/predef/interpBridge.sc; Compiling (synthetic)/ammonite/predef/DefaultPredef.sc; Compiling /scripts/dosUrlLocalizer.sc; Downloading https://repo1.maven.org/maven2/org/http4s/http4s-dsl_2.12/0.18.17/http4s-dsl_2.12-0.18.17.pom.sha1; Downloading https://repo1.maven.org/maven2/org/http4s/http4s-dsl_2.12/0.18.17/http4s-dsl_2.12-0.18.17.pom; https://repo1.maven.org/maven2/org/http4s/http4s-dsl_2.12/0.18.17/http4s-dsl_… ; https://repo1.maven.org/maven2/org/http4s/http4s-dsl_2.12/0.18.17/http4s-dsl_… . Downloaded https://repo1.maven.org/maven2/org/http4s/http4s-dsl_2.12/0.18.17/http4s-dsl_2.12-0.18.17.pom; Downloaded; ...; https://oss.sonatype.org/content/repositories/snapshots/org/apache/httpcompon… ; https://oss.sonatype.org/content/repositories/snapshots/org/apache/httpcompon… . Failed to resolve ivy dependencies:; org.apache.httpcomponents:httpcomponents-core:4.0.1 ; not found: /root/.ivy2/local/org.apache.httpcomponents/httpcomponents-core/4.0.1/ivys/ivy.xml; download error: Caught java.net.UnknownHostException: repo1.maven.org (repo1.maven.org) while downloading https://repo1.maven.org/maven2/org/apache/httpcomponents/httpcomponents-core/4.0.1/httpcomponents-core-4.0.1.pom; download error: Caught java.net.UnknownHostException: oss.sonatype.org (oss.sonatype.org) while downloading https://oss.sonatype.org/content/repositories/snapshots/org/apache/httpcomponents/httpcomponents-core/4.0.1/httpcomponents-core-4.0.1.pom; org.apache.commons:commons-parent:5 ; not found: /root/.ivy2/local/org.apache.commons/commons-parent/5/ivys/ivy.xml; download error: Caught java.net.UnknownHostException: repo1.maven.org (repo1.maven.org) while downloading https://repo1.maven.org/maven2/org/apache/commons/commons-parent/5/commons-parent-5.pom; download error: Caught java.net.UnknownHostException: o,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5069:3158,depend,dependencies,3158,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5069,1,['depend'],['dependencies']
Integrability,"ion/glob-4f26c666d13d1cb48973da7f646a7de2 2> /dev/null ) || ( ln merge_fastqs_R?_*.fastq.gz /sandbox/users/foucal-a/test_atac-pipe/cromwell-executions/atac/f4fd93fa-6f3a-42a6-94f2-459901d245c4/call-trim_adapter/shard-0/execution/glob-4f26c666d13d1cb48973da7f646a7de2 ). # list all the files that match the glob into a file called glob-[md5 of glob].list; ls -1 /sandbox/users/foucal-a/test_atac-pipe/cromwell-executions/atac/f4fd93fa-6f3a-42a6-94f2-459901d245c4/call-trim_adapter/shard-0/execution/glob-4f26c666d13d1cb48973da7f646a7de2 > /sandbox/users/foucal-a/test_atac-pipe/cromwell-executions/atac/f4fd93fa-6f3a-42a6-94f2-459901d245c4/call-trim_adapter/shard-0/execution/glob-4f26c666d13d1cb48973da7f646a7de2.list; ```; I have the error when the script tries to symlink all the files into the glob directory.; Here is the WDL code : ; ```; scatter( i in range(length(fastqs_)) ) {; # trim adapters and merge trimmed fastqs; call trim_adapter { input :; fastqs = fastqs_[i],; adapters = if length(adapters_)>0 then adapters_[i] else [],; paired_end = paired_end,; }; # align trimmed/merged fastqs with bowtie2s; call bowtie2 { input :; idx_tar = bowtie2_idx_tar,; fastqs = trim_adapter.trimmed_merged_fastqs, #[R1,R2]; paired_end = paired_end,; multimapping = multimapping,; }; }; ```; With the function :; ```; task trim_adapter { # trim adapters and merge trimmed fastqs; # parameters from workflow; Array[Array[File]] fastqs # [merge_id][read_end_id]; Array[Array[String]] adapters # [merge_id][read_end_id]; Boolean paired_end; # mandatory; Boolean? auto_detect_adapter # automatically detect/trim adapters; # optional; Int? min_trim_len # minimum trim length for cutadapt -m; Float? err_rate # Maximum allowed adapter error rate; # for cutadapt -e; # resource; Int? cpu; Int? mem_mb; Int? time_hr; #Commenting this line as a test. PRoblem with hard link; String? disks. command {; python $(which encode_trim_adapter.py) \; ${write_tsv(fastqs)} \; --adapters ${write_tsv(adapters)} \; ${if pair",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3876:2050,adapter,adapters,2050,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3876,2,['adapter'],['adapters']
Integrability,"ip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>🔍 Files still referring to the old version number</summary>. The following files still refer to the old version number (0.9.0).; You might want to review and update them manually.; ```; centaur/src/main/resources/integrationTestCases/Somatic/CNV-Pair/cnv_somatic_pair_workflow_do_gc_wes.inputs; centaur/src/main/resources/integrationTestCases/Somatic/CNV-Panel/cnv_somatic_panel_workflow_do_gc_wes.inputs; centaur/src/main/resources/integrationTestCases/Somatic/Mutect2/Mutect2.aws.inputs; centaur/src/main/resources/integrationTestCases/Somatic/Mutect2/Mutect2.inputs; centaur/src/main/resources/integrationTestCases/germline/haplotype-caller-workflow/HaplotypeCallerWF.json; centaur/src/main/resources/integrationTestCases/germline/single-sample-production-workflow/PairedEndSingleSampleWf.options.json; centaur/src/main/resources/integrationTestCases/germline/single-sample-workflow/processing-for-variant-discovery-gatk4.hg38.wgs.inputs.json; centaur/src/main/resources/integrationTestCases/green/arrays/arrays.wdl; womtool/src/test/resources/validate/wdl_draft3/valid/HaplotypeCallerWF/HaplotypeCallerWF.inputs.json; womtool/src/test/resources/validate/wdl_draft3/valid/cnv_somatic_pair_workflow/cnv_somatic_pair_workflow.inputs.json; womtool/src/test/resources/validate/wdl_draft3/valid/joint-discovery-gatk/joint-discovery-gatk.inputs.json; ```; </details>; <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""io.github.jbwheatley"" } ]; ```; Or, add this to slow down future updat",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7294:1524,integrat,integrationTestCases,1524,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7294,1,['integrat'],['integrationTestCases']
Integrability,"itHub Release Notes](https://github.com/googleapis/google-auth-library-java/releases/tag/v1.3.0) - [Version Diff](https://github.com/googleapis/google-auth-library-java/compare/v1.1.0...v1.3.0). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/00809e6249b134635f71919c17c1c81603beb22d/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Files still referring to the old version number</summary>. The following files still refer to the old version number (1.1.0).; You might want to review and update them manually.; ```; CHANGELOG.md; centaur/src/main/resources/integrationTestCases/cwl/bcbio/gvcf-joint-workflow/steps/variantcall_batch_region.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/prealign-workflow/steps/variantcall_batch_region.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/somatic-workflow/steps/variantcall_batch_region.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/svcall-workflow/steps/variantcall_batch_region.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/wes_chr21_test-workflow-gcp/steps/variantcall_batch_region.cwl; cloud-nio/cloud-nio-impl-drs/src/main/scala/cloud/nio/impl/drs/DrsCloudNioFileSystemProvider.scala; cwl/src/test/resources/cwl/lodash.js; project/plugins.sbt; ```; </details>; <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.auth"", artifactId = ""google-auth-library-oauth2-http"" } ]; ```; </details>. labels: library-update, early-semver-minor, semver-spec-minor, old-version-remains, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6608:1169,integrat,integrationTestCases,1169,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6608,5,"['depend', 'integrat']","['dependency', 'integrationTestCases']"
Integrability,"ith file strategy; The `file` strategy does work as it uses md5sums in order to calculate the file hash. An unfortunate side effect of this is that md5 uses massive system resources. On HPC systems that are the target for the sfs-backend, this is a big problem. Cromwell will be run from a submit node on the system and greedily grab all processing power on the submit node to calculate all the md5sums. . ## Md5sums; Md5sums are reliable hashes for file integrity, but this was not their intended purpose. Md5sum was intended as a cryptographic hash. A cryptographic hash has the following properties (wikipedia):; 1. it is deterministic, meaning that the same message always results in the same hash; 2. it is quick to compute the hash value for any given message; 3. it is infeasible to generate a message that yields a given hash value; 4. it is infeasible to find two different messages with the same hash value; 5. a small change to a message should change the hash value so extensively that the new hash value appears uncorrelated with the old hash value (avalanche effect). I contest point 2, in that many cryptographic explicitly strife for being slow to calculate in order to negate brute force attempts.; Anyway: for call caching we only need points 1. and 4. All the rest is unnecessary ballast. . ## xxHash; Luckily there is a hashing algorithm that is designed explicitly for content hashing only. It was made to generate reliably different hashes for file content as fast as possible. It's called [xxHash](https://www.xxhash.com). There are Java implementations available and I did [some extensive benchmarking](https://github.com/rhpvorderman/hashtest/) to find out which one was best. The xxh64 (xxhash for 64 bit machines) algorithm was 15 times faster than the java implementation of md5 we currently use in Cromwell. This PR implements the xxhash algorithm for call-caching in Cromwell:. + The default strategy will still be using md5 for backwards compatibility.; + A new `xxh64` ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5450:1429,message,message,1429,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5450,1,['message'],['message']
Integrability,"ity score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.fasterxml.jackson.core:jackson-databind&package-manager=maven&previous-version=2.13.4.1&new-version=2.13.4.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). You can trigger a rebase of this PR by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/broadinstitute/cromwell/network/alerts). </details>> **Note**; > Automatic rebases have been disabled on this pull request as it has been open for over 30 days.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7110:1500,depend,dependabot,1500,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7110,8,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability,"java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); [2016-10-27 13:11:05,95] [info] Waiting for 1 workflows to abort...; [2016-10-27 13:11:06,95] [info] Waiting for 1 workflows to abort...; [2016-10-27 13:11:07,95] [info] Waiting for 1 workflows to abort...; [2016-10-27 13:11:08,95] [info] Waiting for 1 workflows to abort...; [2016-10-27 13:11:09,95] [info] Waiting for 1 workflows to abort...; [2016-10-27 13:11:10,95] [info] Waiting for 1 workflows to abort...; [2016-10-27 13:11:11,95] [info] Waiting for 1 workflows to abort...; Killed; lichtens@lichtens-big:~/test_eval$ [2016-10-27 13:11:12,80] [error] Exception not convertible into handled response; com.google.api.client.googleapis.json.GoogleJsonResponseException: 404 Not Found; {; ""code"" : 404,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Not Found"",; ""reason"" : ""notFound""; } ],; ""message"" : ""Not Found""; }; at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145); at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113); at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:432); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469); at com.google.cloud.hadoop.util.AbstractGoogleAsyncWriteChannel$UploadOperation.call(AbstractGoogleAsyncWriteChannel.java:357); at jav",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1631:21821,message,message,21821,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1631,2,['message'],['message']
Integrability,"ka.dispatchers.service-dispatcher-30 ERROR - Sending Actor[akka://cromwell-system/user/cromwell-service/WorkflowManagerActor/WorkflowActor-84a51727-cfda-41e7-a03c-9e3af35eb0dc/MaterializeWorkflowDescriptorActor#972983209] failure message MetadataPutFailed(PutMetadataAction(Stream(MetadataEvent(MetadataKey(84a51727-cfda-41e7-a03c-9e3af35eb0dc,None,submittedFiles:imports:bar6.wdl),Some(MetadataValue(task doIt6 {; 	command { echo ""Help, world!"" }; 	output { String message = read_string(stdout()) }; },MetadataString)),2017-02-07T15:01:10.772+10:00), MetadataEvent(MetadataKey(84a51727-cfda-41e7-a03c-9e3af35eb0dc,None,submittedFiles:imports:bar4.wdl),Some(MetadataValue(task doIt4 {; 	command { echo ""Help, world!"" }; 	output { String message = read_string(stdout()) }; },MetadataString)),2017-02-07T15:01:10.774+10:00), MetadataEvent(MetadataKey(84a51727-cfda-41e7-a03c-9e3af35eb0dc,None,submittedFiles:imports:bar5.wdl),Some(MetadataValue(task doIt5 {; 	command { echo ""Help, world!"" }; 	output { String message = read_string(stdout()) }; },MetadataString)),2017-02-07T15:01:10.775+10:00), MetadataEvent(MetadataKey(84a51727-cfda-41e7-a03c-9e3af35eb0dc,None,submittedFiles:imports:bar3.wdl),Some(MetadataValue(task doIt3 {; 	command { echo ""Help, world!"" }; 	output { String message = read_string(stdout()) }; },MetadataString)),2017-02-07T15:01:10.776+10:00), MetadataEvent(MetadataKey(84a51727-cfda-41e7-a03c-9e3af35eb0dc,None,submittedFiles:imports:bar1.wdl),Some(MetadataValue(task doIt1 {; 	command { echo ""Help, world!"" }; 	output { String message = read_string(stdout()) }; },MetadataString)),2017-02-07T15:01:10.776+10:00), MetadataEvent(MetadataKey(84a51727-cfda-41e7-a03c-9e3af35eb0dc,None,submittedFiles:imports:bar9.wdl),Some(MetadataValue(task doIt9 {; 	command { echo ""Help, world!"" }; 	output { String message = read_string(stdout()) }; },MetadataString)),2017-02-07T15:01:10.777+10:00), MetadataEvent(MetadataKey(84a51727-cfda-41e7-a03c-9e3af35eb0dc,None,submittedFiles:imports:bar",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1959:2540,message,message,2540,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1959,1,['message'],['message']
Integrability,"kerThread.java:107); Caused by: cromwell.backend.google.pipelines.common.api.PipelinesApiRequestManager$GoogleJsonException: Request contains an invalid argument.; ... 21 more. [2021-08-13 10:45:10,13] [info] WorkflowManagerActor: Workflow actor for a15c46b7-5f93-46d6-94a2-28f656914866 completed with status 'Failed'. The workflow will be removed from the workflow store.; [2021-08-13 10:45:13,98] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2021-08-13 10:45:15,05] [info] Workflow polling stopped; [2021-08-13 10:45:15,07] [info] 0 workflows released by cromid-de31b6d; [2021-08-13 10:45:15,07] [info] Shutting down WorkflowStoreActor - Timeout = 5 seconds; ...; ```. Contents of hello.wdl:; ```; task hello {; String addressee; command {; echo ""Hello ${addressee}! Welcome to Cromwell . . . on Google Cloud!""; }; output {; String message = read_string(stdout()); }; runtime {; docker: ""ubuntu:latest""; }; }. workflow wf_hello {; call hello. output {; hello.message; }; }; ```. Contents of hello.inputs:; ```; {; ""wf_hello.hello.addressee"": ""World""; }; ```; Contents of cromwell.BROADexamples.v4.conf:; ```; # This is a ""default"" Cromwell example that is intended for you you to start with; # and edit for your needs. Specifically, you will be interested to customize; # the configuration based on your preferred backend (see the backends section; # below in the file). For backend-specific examples for you to copy paste here,; # please see the cromwell.backend.examples folder in the repository. The files; # there also include links to online documentation (if it exists). # This line is required. It pulls in default overrides from the embedded cromwell; # `reference.conf` (in core/src/main/resources) needed for proper performance of cromwell.; include required(classpath(""application"")). # Google configuration; google {. application-name = ""cromwell-demo"". auths = [; {; name = ""application-default""; scheme = ""application_default""; },; {; name = ""service-acco",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6469:8755,message,message,8755,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6469,1,['message'],['message']
Integrability,"ket.org/asomov/snakeyaml/src/master/CHANGES.rst). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/92f43ce5f010fa03daeb2625a3f9c1b1be80cca5/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Files still referring to the old version number</summary>. The following files still refer to the old version number (1.28).; You might want to review and update them manually.; ```; centaur/src/main/resources/standardTestCases/local_bourne/local_bourne.wdl; core/src/test/resources/hello_goodbye_scattered_papiv2.json; docs/developers/bitesize/workflowParsing/forkjoin_graph.svg; docs/developers/bitesize/workflowParsing/wdlToWdlom_hermes.svg; project/Dependencies.scala; scripts/metadata_comparison/test/resources/comparer/papiv2_version3_good.json; scripts/metadata_comparison/test/resources/comparer/version3_comparison_good.csv; src/ci/bin/test.inc.sh; src/ci/docker-compose/cromwell-test/docker-setup.sh; supportedBackends/google/pipelines/v2alpha1/src/main/scala/cromwell/backend/google/pipelines/v2alpha1/api/request/GetRequestHandler.scala; supportedBackends/google/pipelines/v2alpha1/src/test/scala/cromwell/backend/google/pipelines/v2alpha1/api/request/GetRequestHandlerSpec.scala; supportedBackends/google/pipelines/v2beta/src/main/scala/cromwell/backend/google/pipelines/v2beta/api/request/GetRequestHandler.scala; supportedBackends/google/pipelines/v2beta/src/test/scala/cromwell/backend/google/pipelines/v2beta/api/request/GetRequestHandlerSpec.scala; ```; </details>; <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6429:3012,Depend,Dependencies,3012,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6429,1,['Depend'],['Dependencies']
Integrability,"kka that you are using, e.g. if you use akka-actor [2.5.3 (resolved from current classpath)] all other core Akka modules MUST be of the same version. External projects like Alpakka, Persistence plugins or Akka HTTP etc. have their own version numbers - please make sure you're using a compatible set of libraries. ; Uncaught error from thread [default-akka.actor.default-dispatcher-5]: akka.actor.ActorCell.addFunctionRef(Lscala/Function2;)Lakka/actor/FunctionRef;, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for for ActorSystem[default]; java.lang.NoSuchMethodError: akka.actor.ActorCell.addFunctionRef(Lscala/Function2;)Lakka/actor/FunctionRef;; ...; ```; I'm essentially seeing exactly the behaviour described in reference [1] below, which is eviction warnings at compile time and then the runtime blow-up. The root cause seems to be that akka-http depends on an older version of akka-actor (2.4.19) than that specified for the project (2.5.3). Running `dependencyTree` task confirms:; ```; [info] +-com.typesafe.akka:akka-http-spray-json_2.12:10.0.9 [S]; [info] | +-com.typesafe.akka:akka-http_2.12:10.0.9 [S]; [info] | | +-com.typesafe.akka:akka-http-core_2.12:10.0.9 [S]; [info] | | +-com.typesafe.akka:akka-parsing_2.12:10.0.9 [S]; [info] | | | +-com.typesafe.akka:akka-actor_2.12:2.4.19 (evicted by: 2.5.3); ```; If I explicitly add dependency on the latest akka-stream as suggested in [2] and [3], the problem goes away:; ```; diff --git a/project/Dependencies.scala b/project/Dependencies.scala; index 0d77e2d3..7254fc61 100644; --- a/project/Dependencies.scala; +++ b/project/Dependencies.scala; @@ -141,6 +141,7 @@ object Dependencies {; ; val cromwellApiClientDependencies = List(; ""com.typesafe.akka"" %% ""akka-actor"" % akkaV,; + ""com.typesafe.akka"" %% ""akka-stream"" % akkaV,; ""com.typesafe.akka"" %% ""akka-http-spray-json"" % akkaHttpV,; ""com.github.pathikrit"" %% ""better-files"" % betterFilesV,; ""org.scalatest"" %% ""scalatest"" % scalatestV % Test,; ```. References:",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2579:1372,depend,dependencyTree,1372,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2579,1,['depend'],['dependencyTree']
Integrability,"kka.actor.ActorCell.invoke(ActorCell.scala:496); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); at akka.dispatch.Mailbox.run(Mailbox.scala:224); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). [2017-12-05 09:40:31,67] [warn] Couldn't find a suitable DSN, defaulting to a Noop one.; [2017-12-05 09:40:31,68] [info] Using noop to send events.; [2017-12-05 09:40:31,70] [info] WorkflowManagerActor WorkflowActor-6a6ee0eb-5576-43af-a64c-8ed7d288bbc5 is in a terminal state: WorkflowFailedState; [2017-12-05 09:40:35,79] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2017-12-05 09:40:35,81] [info] Message [cromwell.core.actor.StreamActorHelper$StreamFailed] without sender to Actor[akka://cromwell-system/deadLetters] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2017-12-05 09:40:35,81] [info] Message [cromwell.core.actor.StreamActorHelper$StreamFailed] without sender to Actor[akka://cromwell-system/deadLetters] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; Workflow 6a6ee0eb-5576-43af-a64c-8ed7d288bbc5 transitioned to state Failed; [2017-12-05 09:40:35,85] [info] Automatic shutdown of the async connection; [2017-12-05 09:40:35,85] [info] Gracefully shutdown sentry threads.; [2017-12-05 09:40:35,85] [info] Shutdown finished.; ```; As a work-around, I needed to replace ; ```; if ( b1 && b2 ) {; ```; with; ```; Boolean tmp = b1 && b2; if ( tmp ) {; ````",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2992:5984,Message,Message,5984,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2992,1,['Message'],['Message']
Integrability,l:. ```; #011at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); #011at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); #011at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); #011at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); #011at akka.dispatch.Mailbox.exec(Mailbox.scala:234); #011at akka.dispatch.Mailbox.run(Mailbox.scala:224); #011at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); #011at akka.actor.ActorCell.invoke(ActorCell.scala:495); #011at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); #011at cromwell.webservice.PerRequest$WithProps.aroundReceive(PerRequest.scala:97); #011at akka.actor.Actor$class.aroundReceive(Actor.scala:496); #011at cromwell.webservice.PerRequest$$anonfun$receive$1.applyOrElse(PerRequest.scala:41); #011at cromwell.webservice.PerRequest$class.cromwell$webservice$PerRequest$$complete(PerRequest.scala:58); #011at spray.routing.RequestContext.complete(RequestContext.scala:237); #011at spray.httpx.marshalling.ToResponseMarshaller$$anon$3.apply(Marshaller.scala:81); #011at spray.httpx.marshalling.ToResponseMarshaller$$anonfun$compose$1.apply(Marshaller.scala:69); #011at spray.httpx.marshalling.ToResponseMarshaller$$anonfun$compose$1.apply(Marshaller.scala:69); #011at spray.httpx.marshalling.BasicToResponseMarshallers$$anon$1.apply(BasicToResponseMarshallers.scala:22); #011at spray.httpx.marshalling.BasicToResponseMarshallers$$anon$1.apply(BasicToResponseMarshallers.scala:35); #011at spray.httpx.marshalling.Marshaller$$anon$2.apply(Marshaller.scala:47); #011at spray.httpx.marshalling.Marshaller$MarshallerDelegation$$anonfun$apply$2.apply(Marshaller.scala:60); #011at spray.httpx.marshalling.Marshaller$MarshallerDelegation$$anonfun$apply$2.apply(Marshaller.scala:61); #011at spray.httpx.marshalling.Marshaller$MarshallerDelegation$$anonfun$apply$1.apply(Marshaller.scala:58); #011at spray.httpx.marshalling.Marsha,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2438:1086,rout,routing,1086,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2438,1,['rout'],['routing']
Integrability,"ld probably have default values:; ```; [ERROR] [01/24/2019 11:09:59.741] [cromwell-system-akka.dispatchers.service-dispatcher-10] [akka://cromwell-system/user/SingleWorkflowRunnerActor/ServiceRegistryActor] Received ServiceRegistryMessage requ; esting service 'LoadController' for which no service is configured. Message: LoadMetric(NonEmptyList(CallCacheWriteActor),NormalLoad) ; [ERROR] [01/24/2019 11:09:59.731] [cromwell-system-akka.dispatchers.service-dispatcher-10] [akka://cromwell-system/user/SingleWorkflowRunnerActor/ServiceRegistryActor] Received ServiceRegistryMessage requ; esting service 'Instrumentation' for which no service is configured. Message: InstrumentationServiceMessage(CromwellGauge(CromwellBucket(List(job),NonEmptyList(callcaching, read, $y, queue)),0)); ```. ***. Here's my config file for Cromwell 36 (that works):; ```; backend {; default = spartan. providers {; spartan {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; runtime-attributes = """"""; Int runtime_minutes = 600; Int cpus = 2; Int requested_memory_mb_per_core = 8000; String? docker; """""". submit = """"""; sbatch -J ${job_name} -D ${cwd} -o ${out} -e ${err} -t ${runtime_minutes} \; ${""-c "" + cpus} \; --mem-per-cpu=${requested_memory_mb_per_core} \; --wrap ""/bin/bash ${script}""; """""". submit-docker = """"""; module load Singularity/2.5.0-intel-2017.u2 || true; singularity pull docker://${docker}; sbatch -J ${job_name} -D ${cwd} -o ${out} -e ${err} -t ${runtime_minutes} \; ${""-c "" + cpus} \; --mem-per-cpu=${requested_memory_mb_per_core} \; --wrap ""singularity exec -B ${cwd}:${docker_cwd} docker://${docker} ${job_shell} ${script}"" ; """""". kill = ""scancel ${job_id}""; check-alive = ""squeue -j ${job_id}""; job-id-regex = ""Submitted batch job (\\d+).*""; }; }; }; }; ```. Here's what I added to my config for 37 that causes the missing class errors:; ```; services { ; MetadataService { ; class = ""cromwell.services.metadata.impl.MetadataServiceActor""; }; } ; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4577:3949,wrap,wrap,3949,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4577,2,['wrap'],['wrap']
Integrability,"ldWU; > operations/EOCf-4iQLBjstJf68LiInBkgx_mw9zYqD3Byb2R1Y3Rpb25RdWV1ZQ; > operations/EOjA9oqQLBjtl7_8otWYjTQgx_mw9zYqD3Byb2R1Y3Rpb25RdWV1ZQ; > ; > broad-wgs-prod5, 2018-01-16T15:37:16Z, 2018-01-16T17:45:43Z, ggp-1801918915849415035, us-central1-c/n1-standard-16; > broad-wgs-prod5, 2018-01-16T15:37:16Z, 2018-01-16T15:46:25Z, ggp-1347601243842424591, us-east1-c/n1-standard-16; > broad-wgs-prod5, 2018-01-16T15:37:16Z, 2018-01-16T17:14:27Z, ggp-17952768368412969986, us-east1-c/n1-standard-16; > broad-wgs-prod5, 2018-01-16T20:41:42Z, 2018-01-16T22:28:14Z, ggp-17459223747282221022, us-central1-b/n1-standard-2; > broad-wgs-prod5, 2018-01-16T22:37:32Z, 2018-01-16T23:38:28Z, ggp-1817239588482439788, us-east1-c/n1-standard-2; > broad-wgs-prod5, 2018-01-16T23:46:08Z, 2018-01-17T14:57:19Z, ggp-3754421722448645101, us-east1-d/n1-standard-2. > ------------------------------- ; > ferrara@broadinstitute.org <ferrara@broadinstitute.org> #11 Jan 17, 2018 12:32PM ; > Mike, ; > ; > For comparison - the previous reported workflow also had a Message 14: type pre-emption. Which is what cromwell normally detects as pre-emption. Not sure what is difference between the above pre-emptions and the one below. Info as follows:; > ; > OPSID; > operations/ENOi-PyPLBioyJKO-s3GhY0BIMf5sPc2Kg9wcm9kdWN0aW9uUXVldWU; > ; > broad-wgs-prod5, 2018-01-16T15:37:17Z, 2018-01-16T16:43:22Z, ggp-10163246050849367080, us-east1-d/n1-standard-16. > ------------------------------- ; > gdk@google.com <gdk@google.com> Jan 17, 2018 01:36PM; > Accepted by gdk@google.com. > ------------------------------- ; > gdk@google.com <gdk@google.com> #12 Jan 17, 2018 02:52PM ; > The difference between 13 and 14 here is simply when PAPI notices that the VM has been shut down. They mean essentially the same thing, and cromwell should be able to retry with the same logic.; > ; > It looks like this might have been exacerbated because changed the shutdown behavior of VMs so that they won't stay around for 24h for debugging before th",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3157:8995,Message,Message,8995,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3157,1,['Message'],['Message']
Integrability,"le"" logic is never followed.; > ; > So my question is what is ""Message 13"" and how is it different from ""Message 14""? Below are OpsIDs for a set of tasks - the first are the ""Message 14"" (which again are normal preemption but I wanted to provide some for comparison to Message 13) and the second list are the ""Message 13"". This is just a small sample of Message 13 failures.; > ; > MESSAGE 14: ; > operations/ENWy-aWLLBi89uiD6_uZzNABIMf5sPc2Kg9wcm9kdWN0aW9uUXVldWU; > operations/EMzb1NeLLBj0jsHwufD1gHogpfe0-ecHKg9wcm9kdWN0aW9uUXVldWU; > operations/EOn3vcOKLBibqZWQsay6xlUgpfe0-ecHKg9wcm9kdWN0aW9uUXVldWU; > operations/EK3Nx_aKLBjUn5bp5oqJz9oBIJGGnffgCioPcHJvZHVjdGlvblF1ZXVl; > operations/EIyjs-eKLBiUx5LdqLi-kh8gkYad9-AKKg9wcm9kdWN0aW9uUXVldWU. > MESSAGE 13:; > operations/EMCgv6aLLBifhsPH4fzAufMBIL3p_s7RASoPcHJvZHVjdGlvblF1ZXVl; > operations/EPOYsKiLLBib6JnQtvmKzPoBIL3p_s7RASoPcHJvZHVjdGlvblF1ZXVl; > operations/EL-QlNKLLBjeuPH9gd3Ck24gven-ztEBKg9wcm9kdWN0aW9uUXVldWU; > operations/EK6y-aWLLBjV36D2ueHGsKYBIMf5sPc2Kg9wcm9kdWN0aW9uUXVldWU; > operations/EMPd46GLLBj1iYrpkrCipPsBIKX3tPnnByoPcHJvZHVjdGlvblF1ZXVl; > operations/ENTd46GLLBiN8JPluoXAzFUgpfe0-ecHKg9wcm9kdWN0aW9uUXVldWU; > operations/EMPehaqLLBiS7p7OzdzYu5wBIKX3tPnnByoPcHJvZHVjdGlvblF1ZXVl. > ------------------------------- ; > kcibul@broadinstitute.org <kcibul@broadinstitute.org> #2 Jan 8, 2018 03:52PM ; > This is important to understand so Cromwell can do the right thing. It ; > hasn't been clear in the past why we sometimes get 13s on these preemptible ; > jobs ; > ; > Kristian Cibulskis ; > Director of Platform Engineering, Data Sciences Platform ; > Broad Institute of MIT and Harvard ; > kcibul@broadinstitute.org ; > ; > ; > ------------------------------- ; > ferrara@broadinstitute.org <ferrara@broadinstitute.org> #3 Jan 10, 2018 08:58AM ; > Not sure if you need any additional opsids - let me know if you do. While I have not gathered specific statistics on the frequency of this happening - our operations staff repor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3157:2426,MESSAGE,MESSAGE,2426,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3157,1,['MESSAGE'],['MESSAGE']
Integrability,"ll-executions/aggregate_data_workflow/3608d6ca-fbb4-4232-b197-268058470bfc/call-aggregate_data"",; ""attempt"": 1,; ""executionEvents"": [...]; },; ""outputs"": {. },; ""workflowRoot"": ""gs://fc-2d3fd356-e3be-4953-92f1-60af623e6fa5/9ea737cd-a512-4c62-820c-dd1505ea7676/aggregate_data_workflow/3608d6ca-fbb4-4232-b197-268058470bfc"",; ""id"": ""3608d6ca-fbb4-4232-b197-268058470bfc"",; ""inputs"": {...; },; ""submission"": ""2016-12-01T21:21:40.188Z"",; ""status"": ""Failed"",; ""failures"": [{; ""message"": ""Call aggregate_data_workflow.aggregate_data: return code was -1""; }, {; ""message"": ""Call aggregate_data_workflow.aggregate_data: return code was -1""; }, {; ""message"": ""Call aggregate_data_workflow.aggregate_data: return code was -1""; }],; ""workflowLog"": ""gs://fc-2d3fd356-e3be-4953-92f1-60af623e6fa5/9ea737cd-a512-4c62-820c-dd1505ea7676/workflow.logs/workflow.3608d6ca-fbb4-4232-b197-268058470bfc.log"",; ""end"": ""2016-12-02T15:05:42.868Z"",; ""start"": ""2016-12-02T15:05:40.873Z""; }; ```. Here there's no ""message"" and there are ""timestamp"" and ""failure"". ```; {; ""workflowName"": ""aggregate_data_workflow"",; ""submittedFiles"": {; ""options"": ""{\n \""default_runtime_attributes\"": {\n \""zones\"": \""us-central1-b\""\n },\n \""google_project\"": \""broad-dsde-dev\"",\n \""auth_bucket\"": \""gs://cromwell-auth-broad-dsde-dev\"",\n \""refresh_token\"": \""cleared\"",\n \""account_name\"": \""abaumann.firecloud@gmail.com\"",\n \""jes_gcs_root\"": \""gs://fc-5539c024-3ba8-4ed1-97c3-82fed2675776/1626e6be-60ed-48b1-9bbc-a3fdef4a90f5\""\n}"",; ""inputs"": ""{\""aggregate_data_workflow.aggregate_data.input_array\"":[\""bar, baz\""]}"",; ""workflow"": ""task aggregate_data {\n\tArray[File] input_array\n\n\tcommand {\n echo \""foo\""\n\n\t}\n\n\toutput {\n\t\tArray[Array[File]] output_array = [input_array]\n\t}\n\n\truntime {\n\t\tdocker : \""broadgdac/aggregate_data:31\""\n\t}\n\n\tmeta {\n\t\tauthor : \""Tim DeFreitas\""\n\t\temail : \""timdef@broadinstitute.org\""\n\t}\n\n}\n\nworkflow aggregate_data_workflow {\n\tcall aggregate_data\n}""; },; ""calls"": {; ""aggr",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2037:5363,message,message,5363,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2037,1,['message'],['message']
Integrability,"log](https://bitbucket.org/snakeyaml/snakeyaml/src/master/changelog.md) - [Changelog](https://bitbucket.org/snakeyaml/snakeyaml/src/master/changelog.markdown) - [Changelog](https://bitbucket.org/snakeyaml/snakeyaml/src/master/changelog.rst) - [Changelog](https://bitbucket.org/snakeyaml/snakeyaml/src/master/CHANGES.md) - [Changelog](https://bitbucket.org/snakeyaml/snakeyaml/src/master/CHANGES.markdown) - [Changelog](https://bitbucket.org/snakeyaml/snakeyaml/src/master/CHANGES.rst). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/2dc2301e75aea6c2d0c49b89d6092f7d4f134b40/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Files still referring to the old version number</summary>. The following files still refer to the old version number (1.30).; You might want to review and update them manually.; ```; docs/developers/bitesize/workflowParsing/wdlToWdlom_hermes.svg; scripts/metadata_comparison/test/resources/comparer/papiv1_version3_good.json; scripts/metadata_comparison/test/resources/comparer/papiv2_version3_good.json; scripts/metadata_comparison/test/resources/comparer/version3_comparison_good.csv; ```; </details>; <details>; <summary>Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""org.yaml"", artifactId = ""snakeyaml"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""@monthly"" },; dependency = { groupId = ""org.yaml"", artifactId = ""snakeyaml"" }; }]; ```; </details>. labels: test-library-update, old-version-remains, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6900:3268,depend,dependency,3268,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6900,4,['depend'],"['dependency', 'dependencyOverrides']"
Integrability,"lowDescriptorActor.validateWdlNamespace(MaterializeWorkflowDescriptorActor.scala:490)""; },; {; causedBy: [ ],; message: ""cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$lifecycle$materialization$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor(MaterializeWorkflowDescriptorActor.scala:231)""; },; {; causedBy: [ ],; message: ""cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$1.$anonfun$applyOrElse$1(MaterializeWorkflowDescriptorActor.scala:157)""; },; {; causedBy: [ ],; message: ""scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:304)""; },; {; causedBy: [ ],; message: ""scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37)""; },; {; causedBy: [ ],; message: ""scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60)""; },; {; causedBy: [ ],; message: ""akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55)""; },; {; causedBy: [ ],; message: ""akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91)""; },; {; causedBy: [ ],; message: ""scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)""; },; {; causedBy: [ ],; message: ""scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81)""; },; {; causedBy: [ ],; message: ""akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:91)""; },; {; causedBy: [ ],; message: ""akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40)""; },; {; causedBy: [ ],; message: ""akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:43)""; },; {; causedBy: [ ],; message: ""akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)""; },; {; causedBy: [ ],; message: ""akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)""; },; {; causedBy: [ ],; message: ""akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)""; },; {; caus",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3143:2895,message,message,2895,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3143,1,['message'],['message']
Integrability,"luate parameters: %!(EXTRA string=parameter \\\""input_array-0\\\"" has invalid value: bar, baz)\"",\n \""reason\"" : \""badRequest\""\n } ],\n \""message\"" : \""Pipeline 9453747469251135900: Unable to evaluate parameters: %!(EXTRA string=parameter \\\""input_array-0\\\"" has invalid value: bar, baz)\"",\n \""status\"" : \""INVALID_ARGUMENT\""\n}""; }],; ""backend"": ""JES"",; ""end"": ""2016-08-01T19:58:05.000000Z"",; ""stderr"": ""gs://fc-5539c024-3ba8-4ed1-97c3-82fed2675776/1626e6be-60ed-48b1-9bbc-a3fdef4a90f5/aggregate_data_workflow/7be16669-0f81-4e19-96a0-dbe4b72cee8e/call-aggregate_data/aggregate_data-stderr.log"",; ""attempt"": 1,; ""executionEvents"": [],; ""backendLogs"": {; ""log"": ""gs://fc-5539c024-3ba8-4ed1-97c3-82fed2675776/1626e6be-60ed-48b1-9bbc-a3fdef4a90f5/aggregate_data_workflow/7be16669-0f81-4e19-96a0-dbe4b72cee8e/call-aggregate_data/aggregate_data.log""; },; ""start"": ""2016-08-01T19:56:48.000000Z""; }]; },; ""outputs"": {. },; ""id"": ""7be16669-0f81-4e19-96a0-dbe4b72cee8e"",; ""submission"": ""2016-08-01T19:56:48.000000Z"",; ""status"": ""Failed"",; ""end"": ""2016-08-01T19:58:05.000000Z"",; ""start"": ""2016-08-01T19:56:48.000000Z""; }; ```. Here the failures section has a nested structure.; ```; {; ""workflowName"": ""echo_strings"",; ""submittedFiles"": {; ""inputs"": ""...""; },; ""calls"": {. },; ""outputs"": {. },; ""id"": ""12677a12-bca2-41a6-b583-596262c7e0c7"",; ""inputs"": {...; },; ""submission"": ""2017-01-31T17:54:48.812Z"",; ""status"": ""Failed"",; ""failures"": [{; ""causedBy"": {; ""causedBy"": {; ""message"": ""connect timed out""; },; ""message"": ""Error getting access token for service account: ""; },; ""message"": ""Failed to upload authentication file""; }],; ""workflowLog"": ""gs://fc-2d3fd356-e3be-4953-92f1-60af623e6fa5/4503a3b1-5b50-4474-8a31-809e73510622/workflow.logs/workflow.12677a12-bca2-41a6-b583-596262c7e0c7.log"",; ""end"": ""2017-01-31T17:55:10.439Z"",; ""start"": ""2017-01-31T17:54:50.257Z""; }; ```. This inconsistency in the format of the failure messages makes it difficult to show properly formated failure messages in our UI.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2037:8812,message,message,8812,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2037,5,['message'],"['message', 'messages']"
Integrability,"ly/compare/v1.1.0...v1.1.1). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/2dc2301e75aea6c2d0c49b89d6092f7d4f134b40/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Files still referring to the old version number</summary>. The following files still refer to the old version number (1.1.0).; You might want to review and update them manually.; ```; CHANGELOG.md; centaur/src/main/resources/integrationTestCases/cwl/bcbio/gvcf-joint-workflow/steps/variantcall_batch_region.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/prealign-workflow/steps/variantcall_batch_region.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/somatic-workflow/steps/variantcall_batch_region.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/svcall-workflow/steps/variantcall_batch_region.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/wes_chr21_test-workflow-gcp/steps/variantcall_batch_region.cwl; cloud-nio/cloud-nio-impl-drs/src/main/scala/cloud/nio/impl/drs/DrsCloudNioFileSystemProvider.scala; cwl/src/test/resources/cwl/lodash.js; ```; </details>; <details>; <summary>Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.eed3si9n"", artifactId = ""sbt-assembly"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""@monthly"" },; dependency = { groupId = ""com.eed3si9n"", artifactId = ""sbt-assembly"" }; }]; ```; </details>. labels: sbt-plugin-update, early-semver-patch, semver-spec-patch, old-version-remains, com",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6850:1202,integrat,integrationTestCases,1202,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6850,1,['integrat'],['integrationTestCases']
Integrability,"m but require a pull request to introduce a new hook to Cromwell. And it doesn't look like the Cromwell team have been able to prioritise this. . My new thought is that we could use file locks (e.g. `flock` on linux) to deal with this issue, so that the first worker to run will create a file lock, then all subsequent workers will encounter that lock, and wait until it's removed before attempting to build or run the image. For example, we currently recommend this `submit-docker` configuration:. ```; submit-docker = """"""; # Ensure singularity is loaded if it's installed as a module; module load Singularity/3.0.1; ; # Build the Docker image into a singularity image; DOCKER_NAME=$(sed -e 's/[^A-Za-z0-9._-]/_/g' <<< ${docker}); IMAGE=${cwd}/$DOCKER_NAME.sif; if [ ! -f $IMAGE ]; then; singularity pull $IMAGE docker://${docker}; fi. # Submit the script to SLURM; sbatch \; --wait \; -J ${job_name} \; -D ${cwd} \; -o ${cwd}/execution/stdout \; -e ${cwd}/execution/stderr \; -t ${runtime_minutes} \; ${""-c "" + cpus} \; --mem-per-cpu=${requested_memory_mb_per_core} \; --wrap ""singularity exec --bind ${cwd}:${docker_cwd} $IMAGE ${job_shell} ${script}""; """"""; ```. I'm instead proposing this. Note the use of a single shared image directory (`/singularity_cache` in this example), and the use of `flock` to ensure the submit scripts aren't competing with each other:. ```; submit-docker = """"""; # Ensure singularity is loaded if it's installed as a module; module load Singularity/3.0.1; ; # Determine the filepath to the image; DOCKER_NAME=$(sed -e 's/[^A-Za-z0-9._-]/_/g' <<< ${docker}); IMAGE=/singularity_cache/$DOCKER_NAME.sif. # Wait for an exclusive lock on the image ; (; flock --exclusive 200; # Build the image; if [ ! -f $IMAGE ]; then; singularity pull $IMAGE docker://${docker}; fi; ) 200>/var/lock/$IMAGE. # Submit the script to SLURM; sbatch \; --wait \; -J ${job_name} \; -D ${cwd} \; -o ${cwd}/execution/stdout \; -e ${cwd}/execution/stderr \; -t ${runtime_minutes} \; ${""-c "" + cpus}",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5063:1658,wrap,wrap,1658,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5063,1,['wrap'],['wrap']
Integrability,"m using FireCloud (workspace: broad-firecloud-dsde/dsde-methods-sv-dev); <!-- Paste/Attach your workflow if possible: -->; The WDL can be found in GATK's repo: [cnv_germline_cohort_workflow.wdl](https://github.com/broadinstitute/gatk/blob/master/scripts/cnv_wdl/germline/cnv_germline_cohort_workflow.wdl) that imports [cnv_common_tasks.wdl](https://github.com/broadinstitute/gatk/blob/master/scripts/cnv_wdl/cnv_common_tasks.wdl). This is the graph that ```wdltools``` output for that WDL; [graph.pdf](https://github.com/broadinstitute/cromwell/files/2406647/graph.pdf); ![graph](https://user-images.githubusercontent.com/791104/45901323-88187c80-bdb0-11e8-91df-c9a61a12a96a.png). <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->. As you can see in the monitor's ""Failure"" [report ](https://portal.firecloud.org/#workspaces/broad-firecloud-dsde/dsde-methods-sv-dev/monitor/88f444ae-0898-4b5e-af0c-ede98216641d/6d980272-4aa7-4d32-ab90-84880a0723b2)```GermlineCNVCallerCohortMode``` scatter task never get calls before the dependent ```PostprocessGermineCNVCalls```.; <img width=""788"" alt=""screen shot 2018-09-21 at 3 21 43 pm"" src=""https://user-images.githubusercontent.com/791104/45901815-47b9fe00-bdb2-11e8-9043-9f771ee8bd9e.png"">. The log confirms this if one searches for ""Starting"":; ```; 2018-09-20 22:45:12,561 INFO - WorkflowExecutionActor-6d980272-4aa7-4d32-ab90-84880a0723b2 [UUID(6d980272)]: ; Starting CNVGermlineCohortWorkflow.PreprocessIntervals; 2018-09-20 23:03:42,454 INFO - WorkflowExecutionActor-6d980272-4aa7-4d32-ab90-84880a0723b2 [UUID(6d980272)]: ; Starting CNVGermlineCohortWorkflow.CollectCounts (95 shards), CNVGermlineCohortWorkflow.ScatterIntervals; 2018-09-21 02:12:52,275 INFO - WorkflowExecutionActor-6d980272-4aa7-4d32-ab90-84880a0723b2 [UUID(6d980272)]: ; Starting CNVGermlineCohortWorkflow.DetermineGermlineContigPloidyCohortMode; 2018-09-21 02:31:18,476 INFO - WorkflowExecutionActor-6d980272-4aa7-4d32",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4136:1729,depend,dependent,1729,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4136,1,['depend'],['dependent']
Integrability,"m-akka.dispatchers.engine-dispatcher-32 ERROR - WorkflowManagerActor Workflow c9dfd3ed-8be8-413f-af46-4692142b3248 failed (during ExecutingWorkflowState): Task JointGenotyping.ApplyRecalibration:16:1 failed. Job exited without an error, exit code 0. PAPI error code 9. Message: Execution failed: action 14: unexpected exit status 1 was not ignored; 9606 Execution failed: action 14: unexpected exit status 1 was not ignored; 9607 Unexpected exit status 1 while running ""/bin/sh -c gsutil cp /cromwell_root/stdout gs://cloud-cromwell-dev/cromwell_execution/travis/JointGenotyping/c9dfd3ed-8be8-413f-af46-4692142b3248/call-ApplyRecalibration/shard-16/stdout""; 9608 java.lang.Exception: Task JointGenotyping.ApplyRecalibration:16:1 failed. Job exited without an error, exit code 0. PAPI error code 9. Message: Execution failed: action 14: unexpected exit status 1 was not ignored; 9609 Execution failed: action 14: unexpected exit status 1 was not ignored; 9610 Unexpected exit status 1 while running ""/bin/sh -c gsutil cp /cromwell_root/stdout gs://cloud-cromwell-dev/cromwell_execution/travis/JointGenotyping/c9dfd3ed-8be8-413f-af46-4692142b3248/call-ApplyRecalibration/shard-16/stdout""; 9611 at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor$.StandardException(PipelinesApiAsyncBackendJobExecutionActor.scala:76); 9612 at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleFailedRunStatus$1(PipelinesApiAsyncBackendJobExecutionActor.scala:532); 9613 at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:539); 9614 at cromwell.backend.google.pipelines.common.PipelinesApiAsyncBackendJobExecutionActor.handleExecutionFailure(PipelinesApiAsyncBackendJobExecutionActor.scala:80); 9615 at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$handleExecutionResult$3(StandardAsyncExecutionActor.scala:1037); 9616 at sca",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3732:1012,Message,Message,1012,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3732,1,['Message'],['Message']
Integrability,"m/junit4/commit/3a5c6b4d08f408c8ca6a8e0bae71a9bc5a8f97e8""><code>3a5c6b4</code></a> Deprecated since jdk9 replacing constructor instance of Double and Float (<a href=""https://github-redirect.dependabot.com/junit-team/junit4/issues/1660"">#1660</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/junit-team/junit4/compare/r4.13...r4.13.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=junit:junit&package-manager=maven&previous-version=4.13&new-version=4.13.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/configuring-github-dependabot-security-updates). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5941:4416,Depend,Dependabot,4416,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5941,1,['Depend'],['Dependabot']
Integrability,"mToFastqAndBwaMemAndMba was preempted for the 1st time. The call will be restarted with another preemptible VM (max preemptible attempts number is 3). Error code Status{code=ABORTED, description=null, cause=null}. Message: 14: VM ggp-15030877962490231612 stopped unexpectedly.""; > ; > However we have seen a new error response. ""Error code 10: Message 13"" metadata output showing:; > ; > ""message"": ""Task PairedEndSingleSampleWorkflow.HaplotypeCaller:46:3 failed. JES error code 10. Message: 13: VM ggp-9289873678241352278 shut down unexpectedly.""; > ; > From what Cromwell team indicates is that ""Message 13"" is not the same as Message 14 - as such a different logic occurs within cromwell. Cromwell will try the task three times and after that it will just ""Fail"" the task. So the ""try 3 pre-emptible then try non-preemptible"" logic is never followed.; > ; > So my question is what is ""Message 13"" and how is it different from ""Message 14""? Below are OpsIDs for a set of tasks - the first are the ""Message 14"" (which again are normal preemption but I wanted to provide some for comparison to Message 13) and the second list are the ""Message 13"". This is just a small sample of Message 13 failures.; > ; > MESSAGE 14: ; > operations/ENWy-aWLLBi89uiD6_uZzNABIMf5sPc2Kg9wcm9kdWN0aW9uUXVldWU; > operations/EMzb1NeLLBj0jsHwufD1gHogpfe0-ecHKg9wcm9kdWN0aW9uUXVldWU; > operations/EOn3vcOKLBibqZWQsay6xlUgpfe0-ecHKg9wcm9kdWN0aW9uUXVldWU; > operations/EK3Nx_aKLBjUn5bp5oqJz9oBIJGGnffgCioPcHJvZHVjdGlvblF1ZXVl; > operations/EIyjs-eKLBiUx5LdqLi-kh8gkYad9-AKKg9wcm9kdWN0aW9uUXVldWU. > MESSAGE 13:; > operations/EMCgv6aLLBifhsPH4fzAufMBIL3p_s7RASoPcHJvZHVjdGlvblF1ZXVl; > operations/EPOYsKiLLBib6JnQtvmKzPoBIL3p_s7RASoPcHJvZHVjdGlvblF1ZXVl; > operations/EL-QlNKLLBjeuPH9gd3Ck24gven-ztEBKg9wcm9kdWN0aW9uUXVldWU; > operations/EK6y-aWLLBjV36D2ueHGsKYBIMf5sPc2Kg9wcm9kdWN0aW9uUXVldWU; > operations/EMPd46GLLBj1iYrpkrCipPsBIKX3tPnnByoPcHJvZHVjdGlvblF1ZXVl; > operations/ENTd46GLLBiN8JPluoXAzFUgpfe0-ecHKg9wcm9kdWN0aW9",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3157:1740,Message,Message,1740,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3157,5,['Message'],['Message']
Integrability,"mber-of-workflow-log-copy-workers = 10. # Default number of cache read workers; #number-of-cache-read-workers = 25. io {; # throttle {; # # Global Throttling - This is mostly useful for GCS and can be adjusted to match; # # the quota availble on the GCS API; # #number-of-requests = 100000; # #per = 100 seconds; # }. # Number of times an I/O operation should be attempted before giving up and failing it.; #number-of-attempts = 5; }. # Maximum number of input file bytes allowed in order to read each type.; # If exceeded a FileSizeTooBig exception will be thrown.; input-read-limits {; #lines = 128000; #bool = 7; #int = 19; #float = 50; #string = 128000; #json = 128000; #tsv = 128000; #map = 128000; #object = 128000; }. abort {; # These are the default values in Cromwell, in most circumstances there should not be a need to change them. # How frequently Cromwell should scan for aborts.; scan-frequency: 30 seconds. # The cache of in-progress aborts. Cromwell will add entries to this cache once a WorkflowActor has been messaged to abort.; # If on the next scan an 'Aborting' status is found for a workflow that has an entry in this cache, Cromwell will not ask; # the associated WorkflowActor to abort again.; cache {; enabled: true; # Guava cache concurrency.; concurrency: 1; # How long entries in the cache should live from the time they are added to the cache.; ttl: 20 minutes; # Maximum number of entries in the cache.; size: 100000; }; }. # Cromwell reads this value into the JVM's `networkaddress.cache.ttl` setting to control DNS cache expiration; dns-cache-ttl: 3 minutes; }. docker {; hash-lookup {; # Set this to match your available quota against the Google Container Engine API; #gcr-api-queries-per-100-seconds = 1000. # Time in minutes before an entry expires from the docker hashes cache and needs to be fetched again; #cache-entry-ttl = ""20 minutes"". # Maximum number of elements to be kept in the cache. If the limit is reached, old elements will be removed from the cache; ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6933:3421,message,messaged,3421,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6933,1,['message'],['messaged']
Integrability,"me` did work. I was using less complex workflows that did not have this problem at the time. ## Call-caching problems with file strategy; The `file` strategy does work as it uses md5sums in order to calculate the file hash. An unfortunate side effect of this is that md5 uses massive system resources. On HPC systems that are the target for the sfs-backend, this is a big problem. Cromwell will be run from a submit node on the system and greedily grab all processing power on the submit node to calculate all the md5sums. . ## Md5sums; Md5sums are reliable hashes for file integrity, but this was not their intended purpose. Md5sum was intended as a cryptographic hash. A cryptographic hash has the following properties (wikipedia):; 1. it is deterministic, meaning that the same message always results in the same hash; 2. it is quick to compute the hash value for any given message; 3. it is infeasible to generate a message that yields a given hash value; 4. it is infeasible to find two different messages with the same hash value; 5. a small change to a message should change the hash value so extensively that the new hash value appears uncorrelated with the old hash value (avalanche effect). I contest point 2, in that many cryptographic explicitly strife for being slow to calculate in order to negate brute force attempts.; Anyway: for call caching we only need points 1. and 4. All the rest is unnecessary ballast. . ## xxHash; Luckily there is a hashing algorithm that is designed explicitly for content hashing only. It was made to generate reliably different hashes for file content as fast as possible. It's called [xxHash](https://www.xxhash.com). There are Java implementations available and I did [some extensive benchmarking](https://github.com/rhpvorderman/hashtest/) to find out which one was best. The xxh64 (xxhash for 64 bit machines) algorithm was 15 times faster than the java implementation of md5 we currently use in Cromwell. This PR implements the xxhash algorithm for c",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5450:1371,message,messages,1371,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5450,1,['message'],['messages']
Integrability,message: [Attempted 2 time(s)] - FileNotFoundException: gs://cromwell-auth-perf-test-a/ea5553fc-7be0-44a2-aae2-683b4d312de6_auth.json,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4439:0,message,message,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4439,1,['message'],['message']
Integrability,"mktemp -d /tmp/tmp.XXXXXX)"". runtime-attributes = """"""; Int runtime_minutes = 60; Int cpu = 1; Int memory_mb = 3900; String? docker; """""". submit = """""" \; 'sbatch \; --wait \; -J ${job_name} \; -D ${cwd} \; -o ${out} \; -e ${err} \; -t ${runtime_minutes} \; -p batch,scavenger \; -c ${cpu} \; --mem $(( (${memory_mb} >= ${cpu} * 3900) ? ${memory_mb} : $(( ${cpu} * 3900 )) )) \; -N 1 \; --exclusive \; --wrap ""/bin/bash ${script}""'; """""". submit-docker = """""" \. # Make sure the SINGULARITY_CACHEDIR variable is set. If not use a default; # based on the users home.; module load apptainer; if [ -z $APPTAINER_CACHEDIR ];; then CACHE_DIR=$HOME/.apptainer/cache; else CACHE_DIR=$APPTAINER_CACHEDIR; fi; # Make sure cache dir exists so lock file can be created by flock; mkdir -p $CACHE_DIR; LOCK_FILE=$CACHE_DIR/apptainer_pull_flock; # Create an exclusive filelock with flock. --verbose is useful for; # for debugging, as is the echo command. These show up in `stdout.submit`.; flock --exclusive --timeout 900 $LOCK_FILE \; apptainer exec --containall /mainfs/wrgl/broadinstitute_warp_development/warp/images/${docker}.sif \; echo ""successfully pulled ${docker}!"". # Submit the script to SLURM. 'sbatch \; --wait \; -J ${job_name} \; -D ${cwd} \; -o ${cwd}/execution/stdout \; -e ${cwd}/execution/stderr \; -t ${runtime_minutes} \; -p batch,scavenger \; -c ${cpu} \; --mem $(( (${memory_mb} >= ${cpu} * 3900) ? ${memory_mb} : $(( ${cpu} * 3900 )) )) \; -N 1 \; --exclusive \; --wrap \; ""module load apptainer; apptainer exec \; --containall \; --bind /mainfs/wrgl/reference_files/reference_genome/gcp-public-data--broad-references:/mainfs/wrgl/reference_files/reference_genome/gcp-public-data--broad-references \; --bind ${cwd}:${docker_cwd} \; --bind /tmp:/tmp \; /mainfs/wrgl/broadinstitute_warp_development/warp/images/${docker}.sif \; ${job_shell} \; ${docker_script}""'; """""". kill = ""'scancel ${job_id}'"". check-alive = ""'squeue -j ${job_id}'"". job-id-regex = ""Submitted batch job (\\d+).*"". }; }; }; }",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7086:2679,wrap,wrap,2679,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7086,1,['wrap'],['wrap']
Integrability,"mory"": ""1 GB"",; ""memory"": ""2 GB"",. The second task, **TestOutOfMemoryRetry** is designed to fail do to real out of memory error.; The purpose of this task is to shoe that memory-retry mechanism is not working when a task runs out of memory, even if ""Killed"" is written to stderr. Result of TestOutOfMemoryRetry:; When this task is run, it fails but **the job is retried with the same amount of memory**.; This time I see the following failure message:; _""message"": ""Task MemoryRetryTest.TestOutOfMemoryRetry:NA:1 failed. The job was stopped before the command finished. PAPI error code 9. Execution failed: generic::failed_precondition: while running \""/cromwell_root/script\"": unexpected exit status 137 was not ignored\n[UserAction] Unexpected exit status 137 while running \""/cromwell_root/script\"": Killed\n"",_. Grepping metadata for memory of this job, I see the memory expension is not working:; ""memory"": ""1 GB"",; ""memory"": ""1 GB"",; ; I have verified ""Killed"" is written correctly to stderr :; ```; gsutil cat gs://<out_bucket>/cromwell-execution/MemoryRetryTest/3035199e-bf2b-49a2-be87-483; 9e96a08eb/call-TestOutOfMemoryRetry/stderr; Killed ; ``` . We have also noticed that in the out of memory case, no retrurnCode is written to the metadata. **Test wdl for reproduction:**; `version 1.0. workflow MemoryRetryTest {; input {; String message = ""Killed""; }; call TestOutOfMemoryRetry {}; call TestBadCommandRetry {}; }. task TestOutOfMemoryRetry {; command <<<; echo ""Killed"" >&2; tail /dev/zero; >>>; runtime {; docker: ""ubuntu:latest""; cpu: ""1""; memory: ""1 GB""; disks: ""local-disk "" + 16 + "" HDD""; maxRetries: 1; preemptible: 0; }; }. task TestBadCommandRetry {; command <<<; echo ""Killed"" >&2; bedtools intersect nothing with nothing; >>>; runtime {; docker: ""ubuntu:latest""; cpu: ""1""; memory: ""1 GB""; disks: ""local-disk "" + 16 + "" HDD""; maxRetries: 1; preemptible: 0; }; }`. input_json:; `{; ""MemoryRetryTest.message"": ""Killed""; }`. Would appreciate your kind assistence!; Doron Shem-Tov",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7205:2289,message,message,2289,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7205,2,['message'],['message']
Integrability,"mwell.backend.google.batch.api.GcpBatchApiRequestHandler.query(GcpBatchApiRequestHandler.scala:14); at cromwell.backend.google.batch.actors.GcpBatchBackendSingletonActor$$anonfun$normalReceive$1.$anonfun$applyOrElse$3(GcpBatchBackendSingletonActor.scala:80); at scala.concurrent.Future$.$anonfun$apply$1(Future.scala:678); at scala.concurrent.impl.Promise$Transformation.run(Promise.scala:467); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:41); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:49); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: io.grpc.StatusRuntimeException: UNAVAILABLE: io exception; Channel Pipeline: [SslHandler#0, ProtocolNegotiators$ClientTlsHandler#0, WriteBufferingAndExceptionHandler#0, DefaultChannelPipeline$TailContext#0]; at io.grpc.Status.asRuntimeException(Status.java:539); ... 14 common frames omitted; Caused by: javax.net.ssl.SSLHandshakeException: General OpenSslEngine problem; at io.grpc.netty.shaded.io.netty.handler.ssl.ReferenceCountedOpenSslEngine.handshakeException(ReferenceCountedOpenSslEngine.java:1907); at io.grpc.netty.shaded.io.netty.handler.ssl.ReferenceCountedOpenSslEngine.wrap(ReferenceCountedOpenSslEngine.java:834); at java.base/javax.net.ssl.SSLEngine.wrap(SSLEngine.java:564); at io.grpc.netty.shaded.io.netty.handler.ssl.SslHandler.wrap(SslHandler.java:1041); at io.grpc.netty.shaded.io.netty.handler.ssl.SslHandler.wrapNonAppData(SslHandler.java:927); at io.grpc.netty.shaded.io.netty.handler.ssl.SslHandler.unwrap(SslHandler.java:1409); at io.grpc.netty.shaded.io.netty.handler.ssl.SslHandler.unwrapNonAppData(SslHandler.java:1327); at io.grpc.netty.shaded.io.netty.handler.ssl.SslHandler.acce",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7551:4678,Protocol,ProtocolNegotiators,4678,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7551,1,['Protocol'],['ProtocolNegotiators']
Integrability,"my code end ENV:. config file: . backend {; providers {; SLURM {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {. filesystems {; local {; localization: [; ""soft-link"",; ""hard-link"",; ""copy""; ]; }; }. runtime-attributes = """"""; String time = ""2-0""; Int cpus = 2; Int memory = 8000; String queue = ""compute""; """""". submit = """"""; sbatch -J ${job_name} -D ${cwd} -o ${out} -e ${err} -t ${time} -p ${queue} \; ${""-c "" + cpus} \; --mem-per-cpu=${memory} \; --wrap ""/bin/bash ${script}""; """""". job-id-regex = ""Submitted batch job (\\d+).*""; kill = ""scancel ${job_id}""; check-alive = ""squeue -j ${job_id}""; }; }; }. wdl file :; task SamToFastqAndBwaMem {; ......; ......; command <<<; set -o pipefail; set -e. # set the bash variable needed for the command-line; bash_ref_fasta=${ref_fasta}. java -Dsamjdk.compression_level=${compression_level} ${java_opt} -jar ${gotc_path}picard.jar \; SamToFastq \; INPUT=${input_bam} \; FASTQ=/dev/stdout \; INTERLEAVE=true \; NON_PF=true \; | \; ${bwa_path}${bwa_commandline} /dev/stdin - 2> >(tee ${output_bam_basename}.bwa.stderr.log >&2) \; | \; samtools view -1 - > ${output_bam_basename}.bam. >>>; #runtime {; # backend: ""SLURM""; # memory: mem_size; # cpus: num_cpu; #}; output {; File output_bam = ""${output_bam_basename}.bam""; File bwa_stderr_log = ""${output_bam_basename}.bwa.stderr.log""; }; }. all parameters goes ok, but below are some problems:. 1:; Caused by: common.exception.AggregatedMessageException: Error(s):; :; Could not localize -> /nfs/disk3/user/gaoyuhui/github/test/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/8fc94dc1-722b-40d5-9840-9d6e4a66db21/call-SamToFastqAndBwaMem/inputs/-1845554049/test:; doesn't exist; Cannot localize directory with symbolic links; /nfs/disk3/user/gaoyuhui/github/test/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/8fc94dc1-722b-40d5-9840-9d6e4a66db21/call-SamToFastqAndBwaMem/inputs/-1845554049/test -> /nfs/disk3/user/gaoyuhui/github/test: Ope",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4703:500,wrap,wrap,500,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4703,1,['wrap'],['wrap']
Integrability,"n this issue. In all cases, if Cromwell fails to retrieve the docker hash for a task, for any reason, the corresponding call(s) will NOT be eligible for call caching, neither read nor write, regardless of the call caching configuration in effect. **When to get the hashes and what to do with them:**. 1. Cromwell will lookup the hashes corresponding to docker tags, for all docker attributes in all tasks in a workflow and its subworkflows, at Materialization time.; If the runtime attribute value can't be determined, the task in question will be ineligible for call caching. The only case when that should be true is if the attribute is an expression with variables depending on previous tasks being run. 2. If the hash lookup succeed, Cromwell will use that hash to perform any call cache read / write according to the call caching configuration in effect. It will also provide that hash, along with the original floating tag, to the backend when the job gets dispatched. 3. Backends will choose wether to use the hash or the floating tag. They will report to the engine which one they used, so that the engine can send this information to the metadata. **How to get the hash:**. 1. How to get the hash depends on the backend. Which means, at this time, that only workflows for which the backend is known statically at workflow submission time will be supported. 2. If the task is expected to run on the **Local Backend**, Cromwell will attempt to find the hash corresponding to the tag on the machine where it's being run. This first attempt must be done without executing a `pull` to avoid overriding the current local image, if it exits, with the remote repository version.; If the image is not present locally, cromwell will attempt to `pull` the image locally, and use the hash from the newly retrieved image. 3. If the task is expected to run on a **Non Local Backend**, cromwell will attempt to retrieve the image from a remote repository. The `DockerHashActor` can be used for that effect.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2048:1544,depend,depends,1544,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2048,1,['depend'],['depends']
Integrability,"n trimmed/merged fastqs with bowtie2s; call bowtie2 { input :; idx_tar = bowtie2_idx_tar,; fastqs = trim_adapter.trimmed_merged_fastqs, #[R1,R2]; paired_end = paired_end,; multimapping = multimapping,; }; }; ```; With the function :; ```; task trim_adapter { # trim adapters and merge trimmed fastqs; # parameters from workflow; Array[Array[File]] fastqs # [merge_id][read_end_id]; Array[Array[String]] adapters # [merge_id][read_end_id]; Boolean paired_end; # mandatory; Boolean? auto_detect_adapter # automatically detect/trim adapters; # optional; Int? min_trim_len # minimum trim length for cutadapt -m; Float? err_rate # Maximum allowed adapter error rate; # for cutadapt -e; # resource; Int? cpu; Int? mem_mb; Int? time_hr; #Commenting this line as a test. PRoblem with hard link; String? disks. command {; python $(which encode_trim_adapter.py) \; ${write_tsv(fastqs)} \; --adapters ${write_tsv(adapters)} \; ${if paired_end then ""--paired-end"" else """"} \; ${if select_first([auto_detect_adapter,false]) then ""--auto-detect-adapter"" else """"} \; ${""--min-trim-len "" + select_first([min_trim_len,5])} \; ${""--err-rate "" + select_first([err_rate,'0.1'])} \; ${""--nth "" + select_first([cpu,2])}; }; output {; # WDL glob() globs in an alphabetical order; # so R1 and R2 can be switched, which results in an; # unexpected behavior of a workflow; # so we prepend merge_fastqs_'end'_ (R1 or R2); # to the basename of original filename; # this prefix will be later stripped in bowtie2 task; Array[File] trimmed_merged_fastqs = glob(""merge_fastqs_R?_*.fastq.gz""); }; runtime {; cpu : select_first([cpu,2]); memory : ""${select_first([mem_mb,'12000'])} MB""; time : select_first([time_hr,24]); disks : select_first([disks,""local-disk 100 HDD""]); }; }; ```. My backend.conf :; ```; include required(classpath(""application"")). backend {; default=""SGE""; providers {; SGE {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; concurrent-job-limit = 10000; runtime-a",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3876:3114,adapter,adapters,3114,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3876,3,['adapter'],"['adapter', 'adapters']"
Integrability,"nStatus"": ""Failed"",; ""stdout"": ""gs://fc-5539c024-3ba8-4ed1-97c3-82fed2675776/1626e6be-60ed-48b1-9bbc-a3fdef4a90f5/aggregate_data_workflow/7be16669-0f81-4e19-96a0-dbe4b72cee8e/call-aggregate_data/aggregate_data-stdout.log"",; ""shardIndex"": -1,; ""outputs"": {. },; ""runtimeAttributes"": {; ""preemptible"": ""0"",; ""failOnStderr"": ""false"",; ""bootDiskSizeGb"": ""10"",; ""disks"": ""local-disk 10 SSD"",; ""continueOnReturnCode"": ""0"",; ""docker"": ""broadgdac/aggregate_data:31"",; ""cpu"": ""1"",; ""zones"": ""us-central1-b"",; ""memory"": ""2GB""; },; ""cache"": {; ""allowResultReuse"": true; },; ""inputs"": {; ""input_array"": [""bar, baz""]; },; ""failures"": [{; ""timestamp"": ""2016-08-01T19:58:04.704000Z"",; ""failure"": ""com.google.api.client.googleapis.json.GoogleJsonResponseException: 400 Bad Request\n{\n \""code\"" : 400,\n \""errors\"" : [ {\n \""domain\"" : \""global\"",\n \""message\"" : \""Pipeline 9453747469251135900: Unable to evaluate parameters: %!(EXTRA string=parameter \\\""input_array-0\\\"" has invalid value: bar, baz)\"",\n \""reason\"" : \""badRequest\""\n } ],\n \""message\"" : \""Pipeline 9453747469251135900: Unable to evaluate parameters: %!(EXTRA string=parameter \\\""input_array-0\\\"" has invalid value: bar, baz)\"",\n \""status\"" : \""INVALID_ARGUMENT\""\n}""; }],; ""backend"": ""JES"",; ""end"": ""2016-08-01T19:58:05.000000Z"",; ""stderr"": ""gs://fc-5539c024-3ba8-4ed1-97c3-82fed2675776/1626e6be-60ed-48b1-9bbc-a3fdef4a90f5/aggregate_data_workflow/7be16669-0f81-4e19-96a0-dbe4b72cee8e/call-aggregate_data/aggregate_data-stderr.log"",; ""attempt"": 1,; ""executionEvents"": [],; ""backendLogs"": {; ""log"": ""gs://fc-5539c024-3ba8-4ed1-97c3-82fed2675776/1626e6be-60ed-48b1-9bbc-a3fdef4a90f5/aggregate_data_workflow/7be16669-0f81-4e19-96a0-dbe4b72cee8e/call-aggregate_data/aggregate_data.log""; },; ""start"": ""2016-08-01T19:56:48.000000Z""; }]; },; ""outputs"": {. },; ""id"": ""7be16669-0f81-4e19-96a0-dbe4b72cee8e"",; ""submission"": ""2016-08-01T19:56:48.000000Z"",; ""status"": ""Failed"",; ""end"": ""2016-08-01T19:58:05.000000Z"",; ""start"": ""2016-08-01T19:56:48.0000",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2037:7288,message,message,7288,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2037,2,['message'],['message']
Integrability,"nal error `Outcome` does not seem to be forwarded to the `Reporter`. Instead we may need to implement our own fork of `withRetry` that captures and forwards the original exception before retrying the test, wiring the original error to our custom `Reporter` in some way or via some singleton cache. For an external system to aggregate the errors something like https://logit.io/ could be used but https://sentry.io/ is specifically built for error triage. As the above features will only be implemented for ScalaTest, any tests using ScalaCheck directly should be refactored to use ScalaTest's ""ScalaCheck-style"" property based testing. That way any failing property based tests will be tracked as well using our reporting. Because this feature is likely to be used across all cromwell artifacts/subprojects we should decide if we either want to either:; 1. Update every project in `build.sbt` with a `.dependsOn(common, ""test->test"")`; 2. Add scalatest and sentry as `Provided` dependencies to `common` such that they won't be transitively included by default; 3. Create a new `cromwell.test` artifact and use either of the above outside of `cromwell.common`. **A/C:**; - Switch tests directly using scalacheck over to scalatest's scalacheck-style specs; - Create a custom scalatest helper/reporter that retries a failed test a configurable number of times; - Add custom reporter to scalatest settings in `Testing.scala`; - Assuming using sentry for error reporting from Travis:; - Add sentry DSN configuration values to Vault; - Update `build_application.inc.conf` to use a noop sentry DSN by default; - Create a `sentry_application.inc.conf.ctmpl` file that uses sentry configuration values from Vault; - `build_application.inc.conf` attempts to import a `sentry_application.inc.conf` file that overrides the sentry configuration; - NOTE: When `build_application.inc.conf` is missing it will be skipped by the HOCON library. **Links:**; - https://github.com/broadinstitute/cromwell/issues/3657; - ht",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3658:2654,depend,dependencies,2654,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3658,1,['depend'],['dependencies']
Integrability,"ner_subworkflow`/LEVEL_2A and LEVEL_2B); ``` wdl; import ""inner_subworkflow.wdl"" as inner. workflow outer_subworkflow {; scatter (i in range(2)) {; call inner.inner_subworkflow as inner_subworkflow; }; }; ```; * `inner_subworkflow.wdl`/LEVEL_2A and LEVEL_2B then runs a task with a scatter and a scatter of 3 across a final subworkflow (`call sub_workflow.sub_subworkflow`/ LEVEL_2_X__3_Y); ``` wdl; import ""sub_subworkflow.wdl"" as sub_subworkflow. task hello_world {; command {; echo 'Hello, world!'; echo 'blah' > output.txt ; }. output {; String message = read_string(stdout()); File outputFile = ""output.txt""; }. runtime {; docker: ""ubuntu:latest""; }; }. workflow inner_subworkflow {; scatter (i in range(4)) {; call hello_world; }; scatter (i in range(3)) {; call sub_subworkflow.sub_subworkflow; }; }; ```; * This final `sub_subworkflow.wdl` then runs a scatter across a task:; ``` wdl; task sub_hello_world {; command {; echo 'Hello from sub.sub_workflow, world!'; }. output {; String message = read_string(stdout()); }. runtime {; docker: ""ubuntu:latest""; }; }. workflow sub_subworkflow {; scatter (i in range(2)) {; call sub_hello_world; }; }; ```. In tree form you have something like this:; * ROOT_WORKFLOW `main_workflow.wdl`; * LEVEL_1 `outer_subworkflow.wdl`; * LEVEL_2A `inner_subworkflow.wdl`; * LEVEL_2_A__3_A `sub_subworkflow.wdl`; * LEVEL_2_A__3_B `sub_subworkflow.wdl`; * LEVEL_2_A__3_C `sub_subworkflow.wdl`; * LEVEL_2B `inner_subworkflow.wdl`; * LEVEL_2_B__3_A `sub_subworkflow.wdl`; * LEVEL_2_B__3_B `sub_subworkflow.wdl`; * LEVEL_2_B__3_C `sub_subworkflow.wdl`. LEVEL_2 `inner_subworkflow.wdl` task outputs end up here:; ```; cromwell-executions/main_workflow/ecb081a4-0166-4f9f-a2a8-20a50f8e9b19/; call-outer_subworkflow/outer.outer_subworkflow/53f62151-1c36-4e2f-8bff-0a2a90d7d8c5/; call-inner_subworkflow/shard-0/inner.inner_subworkflow/cd65e57c-12ee-4213-a698-c98dd0a973fd/; call-hello_world/shard-0/cacheCopy/execution/rc; or (in more readible form); cromwell-executions/m",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7387:3284,message,message,3284,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7387,1,['message'],['message']
Integrability,"nfiguring it at the Cromwell level, so e.g. any user of Terra (or any other hosted Cromwell with PAPIv2 backend) could get usage reports without having to configure anything. The metrics are reported in their GCP project, so a user gets automatic access to them as long as they're a viewer. We could also easily expose a link to workflow- and task-level reports in Job Manager UI, so they will be literally point-and-click away. Each timepoint is designed to be self-sufficient, as it is labeled with:; - Cromwell-specific values, such as workflow ID, task call name, index and attempt.; - GCP instance values such as instance name, zone, number of CPU cores, total memory and disk size. Here's an example graph of cpu/memory/disk utilization for one of our production workflows, as it is running right now - one can already see we could probably save ~40% of the cost:; <img width=""1869"" alt=""screen shot 2019-01-02 at 4 43 20 pm"" src=""https://user-images.githubusercontent.com/137337/50614108-c0e6e800-0ead-11e9-9ef4-02029725a44c.png"">. Reporting itself costs very little if anything at all, because Stackdriver provides a generous free tier worth ~65K instance-hours each month, and ~$0.0006 per instance-hour after that (at the current rate of 5 metric points reported each minute). @kshakir suggested using a ""vendor-neutral"" reporting library such as [Micrometer.io](http://micrometer.io/), although I have reservations around that - mostly because that may require additional setup and we want this to ""just work""; but also because the implementation is currently PAPIv2-specific anyway, so it is already non-vendor agnostic. Likewise, one could export metrics from Stackdriver monitoring if they wanted to. But we're open to the idea. Finally, I haven't added any tests yet, as it's unclear in which shape or form (if at all) you'd like to integrate this code. Thanks in advance for any feedback!; ~[@broadinstitute/wintergreen](https://github.com/orgs/broadinstitute/teams/wintergreen) team.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4510:4131,integrat,integrate,4131,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4510,1,['integrat'],['integrate']
Integrability,"nfo] Shutting down WorkflowLogCopyRouter - Timeout = 5 seconds; [2018-08-27 02:04:26,93] [info] Shutting down JobExecutionTokenDispenser - Timeout = 5 seconds; [2018-08-27 02:04:26,93] [info] JobExecutionTokenDispenser stopped; [2018-08-27 02:04:26,93] [info] Shutting down WorkflowManagerActor - Timeout = 3600 seconds; [2018-08-27 02:04:26,93] [info] WorkflowLogCopyRouter stopped; [2018-08-27 02:04:26,94] [info] WorkflowManagerActor stopped; [2018-08-27 02:04:26,94] [info] WorkflowManagerActor All workflows finished; [2018-08-27 02:04:26,94] [info] Connection pools shut down; [2018-08-27 02:04:26,94] [info] Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds; [2018-08-27 02:04:26,95] [info] Shutting down JobStoreActor - Timeout = 1800 seconds; [2018-08-27 02:04:26,95] [info] Shutting down CallCacheWriteActor - Timeout = 1800 seconds; [2018-08-27 02:04:26,96] [info] CallCacheWriteActor Shutting down: 0 queued messages to process; [2018-08-27 02:04:26,96] [info] Shutting down ServiceRegistryActor - Timeout = 1800 seconds; [2018-08-27 02:04:26,96] [info] WriteMetadataActor Shutting down: 0 queued messages to process; [2018-08-27 02:04:26,96] [info] KvWriteActor Shutting down: 0 queued messages to process; [2018-08-27 02:04:26,96] [info] Shutting down DockerHashActor - Timeout = 1800 seconds; [2018-08-27 02:04:26,96] [info] ServiceRegistryActor stopped; [2018-08-27 02:04:26,96] [info] Shutting down IoProxy - Timeout = 1800 seconds; [2018-08-27 02:04:26,96] [info] SubWorkflowStoreActor stopped; [2018-08-27 02:04:26,96] [info] DockerHashActor stopped; [2018-08-27 02:04:26,97] [info] IoProxy stopped; [2018-08-27 02:04:26,97] [info] JobStoreActor stopped; [2018-08-27 02:04:26,97] [info] CallCacheWriteActor stopped; [2018-08-27 02:04:27,00] [info] Database closed; [2018-08-27 02:04:27,00] [info] Stream materializer shut down; [2018-08-27 02:04:27,06] [info] Automatic shutdown of the async connection; [2018-08-27 02:04:27,06] [info] Gracefully shutdown sentry threads.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4039:7326,message,messages,7326,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4039,2,['message'],['messages']
Integrability,"nfo] Shutting down WorkflowLogCopyRouter - Timeout = 5 seconds; [2018-08-30 17:53:41,15] [info] Shutting down JobExecutionTokenDispenser - Timeout = 5 seconds; [2018-08-30 17:53:41,15] [info] JobExecutionTokenDispenser stopped; [2018-08-30 17:53:41,17] [info] WorkflowLogCopyRouter stopped; [2018-08-30 17:53:41,17] [info] Shutting down WorkflowManagerActor - Timeout = 3600 seconds; [2018-08-30 17:53:41,17] [info] WorkflowManagerActor All workflows finished; [2018-08-30 17:53:41,17] [info] WorkflowManagerActor stopped; [2018-08-30 17:53:41,17] [info] Connection pools shut down; [2018-08-30 17:53:41,18] [info] Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds; [2018-08-30 17:53:41,18] [info] SubWorkflowStoreActor stopped; [2018-08-30 17:53:41,18] [info] Shutting down JobStoreActor - Timeout = 1800 seconds; [2018-08-30 17:53:41,18] [info] Shutting down CallCacheWriteActor - Timeout = 1800 seconds; [2018-08-30 17:53:41,19] [info] CallCacheWriteActor Shutting down: 0 queued messages to process; [2018-08-30 17:53:41,19] [info] CallCacheWriteActor stopped; [2018-08-30 17:53:41,18] [info] Shutting down ServiceRegistryActor - Timeout = 1800 seconds; [2018-08-30 17:53:41,19] [info] Shutting down DockerHashActor - Timeout = 1800 seconds; [2018-08-30 17:53:41,19] [info] KvWriteActor Shutting down: 0 queued messages to process; [2018-08-30 17:53:41,19] [info] WriteMetadataActor Shutting down: 0 queued messages to process; [2018-08-30 17:53:41,19] [info] DockerHashActor stopped; [2018-08-30 17:53:41,19] [info] Shutting down IoProxy - Timeout = 1800 seconds; [2018-08-30 17:53:41,19] [info] JobStoreActor stopped; [2018-08-30 17:53:41,19] [info] IoProxy stopped; [2018-08-30 17:53:41,19] [info] ServiceRegistryActor stopped; [2018-08-30 17:53:41,23] [info] Database closed; [2018-08-30 17:53:41,23] [info] Stream materializer shut down; [2018-08-30 17:53:41,29] [info] Automatic shutdown of the async connection; [2018-08-30 17:53:41,29] [info] Gracefully shutdown sentry threads.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4062:6050,message,messages,6050,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4062,2,['message'],['messages']
Integrability,"ng as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/92f43ce5f010fa03daeb2625a3f9c1b1be80cca5/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Files still referring to the old version number</summary>. The following files still refer to the old version number (0.13.0).; You might want to review and update them manually.; ```; centaur/src/main/resources/integrationTestCases/cwl/bcbio/gvcf-joint-workflow/steps/process_alignment.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/gvcf-joint-workflow/steps/variantcall_batch_region.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/prealign-workflow/steps/variantcall_batch_region.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/rnaseq-workflow/steps/prepare_sample.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/somatic-workflow/steps/detect_sv.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/somatic-workflow/steps/process_alignment.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/somatic-workflow/steps/variantcall_batch_region.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/svcall-workflow/steps/detect_sv.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/svcall-workflow/steps/process_alignment.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/svcall-workflow/steps/variantcall_batch_region.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/wes_chr21_test-workflow-gcp/steps/detect_sv.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/wes_chr21_test-workflow-gcp/steps/process_alignment.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/wes_chr21_test-workflow-gcp/steps/variantcall_",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6410:1731,integrat,integrationTestCases,1731,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6410,1,['integrat'],['integrationTestCases']
Integrability,"ngExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91); at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81); at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:91); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:43); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); ```; :hmmm:. chrisl [4:50 PM]; that sort of looks like the kind of error message I put in when I’m 99% sure a situation is impossible…. mcovarr [4:50 PM]; workflows that are picked up but have old heartbeats will look eligible for pickup, but they won't actually get run and you'll see that message. chrisl [4:50 PM]; oh, or that :slightly_smiling_face:. kshakir [4:51 PM]; I see 13 of these:; ```; 024bf23f-b7a3-4ede-bddf-938321ac570f; 26707981-d32b-4814-ba1f-4e5f27f739dc; 52fe6d61-2ba8-4c79-8a50-e365b355e36b; 5cbeca9f-c686-45a9-ab57-167379029964; 627a48a3-1584-42de-9b57-ee7a859b08d1; 6ed1070c-e478-47f2-8ea9-7ccc656bbba9; 70786146-ac4e-4d26-9906-ba211fde03f9; 8de76a93-6b66-4c29-a2fe-31e6cd1f969e; 8f07ade2-0a6d-40df-b886-cf99e3a1ed13; 9bda3e3d-1e17-4406-87e3-9ec7f71f4822; cb4b3331-193a-4c22-a95d-40f1ac9b53d6; dc9ded6f-463f-4cb1-a71a-0503c53f702a; f6644044-f4af-412a-a978-12ff080af3e1; ```; (edited). mcovarr [4:51 PM]; yeah that's from the 2/3 of horizontal Cromwell we implemented. mcovarr [4:52 PM]; but not sure why this is happening in this specific case. kshakir [4:52 PM]; How does :heartbeat:-ing work? There was a restart event in the middle of these workflows.; i think. mcovarr [4:55 PM]; timer in t",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3673:2265,message,message,2265,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3673,1,['message'],['message']
Integrability,"nge https://bioinformatics.stackexchange.com/search?q=cromwell; Slack https://join.slack.com/t/cromwellhq/shared_invite/zt-dxmmrtye-JHxwKE53rfKE_ZWdOHIB4g; -->; This is a remark on https://github.com/broadinstitute/cromwell/blob/master/docs/tutorials/HPCSlurmWithLocalScratch.md there is a feature on slum config to edit the sbatch command. You could add in a find and replace in the config to do the same as the tutorial. you can skip the first part of the tutorial by editing the slurm backend config (somewhat hotpatching the scripts on submission time). old submit ; submit = """"""; sbatch -J ${job_name} -D ${cwd} -o ${out} -e ${err} -t ${runtime_minutes} -p ${queue} ${""-c "" +; cpu} --mem ${memory_mb} --wrap ""/bin/bash ${script}""; """""". new submit for slurm auto configured job dir: ; submit = """"""; perl -i.bak -wpe 's/^tmpDir=.*/tmpdir=""\$TMPDIR""/g' ${script} && \; sbatch -J ${job_name} --tmp=${disk} -D ${cwd} -o ${out} -e ${err} -t ${runtime_minutes} -p ${queue} ${""-c "" +; cpu} --mem ${memory_mb} --wrap ""/bin/bash ${script}""; """""". new submit for /genomics/local/ (not tested tough): ; submit = """"""; perl -i.bak -wpe 's/^tmpDir=.*/tmpdir=""$(mkdir -p ""\/genomics_local\/\$PID_\$HOSTNAME""\/"" && echo ""\/genomics_local\/\$PID_\$HOSTNAME""\/""/g' ${script} && \; sbatch -J ${job_name} --tmp=${disk} -D ${cwd} -o ${out} -e ${err} -t ${runtime_minutes} -p ${queue} ${""-c "" +; cpu} --mem ${memory_mb} --wrap ""/bin/bash ${script}""; """""". <!-- Are you seeing something that looks like a bug? Please attach as much information as possible. -->; <!-- This is a clear feature cant you see -->. <!-- Which backend are you running? -->; The backend I'm running on is Slurm hpc with a version 1.0 workflow. This alternative workflow has its downsides but also benefits it is up to the hpc(user) to decide what works best in their own situation. ; <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7357:1608,wrap,wrap,1608,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7357,1,['wrap'],['wrap']
Integrability,"ns since in this case there is no need for a ""?"" in the ```y``` nor the ```x``` or the invokation of ```select_first```; however I have to say that I don't see why this ""coversion"" would be invalid but I'm not much of a wdl or scala expert. Now the for-sure issue here is that instead of failing indicating what is going on the workflow was still running and the offending task(s) were reported as ""Starting"" in the metadata and the timing and they stayed that way forever. . In order to find out what was going on I needed to install and run a locally v36 server (I usually use dsde-method's community cromwell servers). The logs show first the causing wdl bug like so:. ```; [ERROR] [03/19/2019 09:52:14.444] [cromwell-system-akka.dispatchers.engine-dispatcher-47] [akka://cromwell-system ... Could not construct array of type WomMaybeEmptyArrayType(WomOptionalType(WomMaybeEmptyArrayType(WomAnyType))) with this value: List(WomOptionalValue(WomMaybeEmptyArrayType(WomSingleFileType),Some([""gs:// .... 70.tsv.gz""])), []); ```; Notice that Skipped most of the message text showing (what I think are) the important bits . . This meesage is follow for java exception directly dump into the log output file. java.lang.UnsupportedOperationException: Could not construct array of type WomMaybeEmptyArrayType(W....z""])), []); at wom.values.WomArray$.apply(WomArray.scala:34); at wom.values.WomArray$.apply(WomArray.scala:38); at wdl.transforms.base.linking.expression.values.LiteralEvaluators$$anon$6.$anonfun$evaluateValue$16(LiteralEvaluators.scala:108); at cats.data.Validated.map(Validated.scala:194); ... After this exception there is a log [ERROR] entry appears reporting the exception and exception stack trace. The timing diagram show the tasks hanging in the ""Starting"" state forever and the metadata does not report anything apart than these tasks are ""Starting"". So the error is silenced and the only recurse left is to abort. A re-submit of the workflow would just get stuck in the same place.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4755:1608,message,message,1608,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4755,1,['message'],['message']
Integrability,"nting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); - `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language; - `@dependabot use these reviewers` will set the current reviewers as the default for future PRs for this repo and language; - `@dependabot use these assignees` will set the current assignees as the default for future PRs for this repo and language; - `@dependabot use this milestone` will set the current milestone as the default for future PRs for this repo and language. You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/broadinstitute/cromwell/network/alerts). </details>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5941:5119,depend,dependabot,5119,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5941,132,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability,"o/bar.wdl ; task doIt {; 	command { echo ""Help, world!"" }; 	output { String message = read_string(stdout()) }; }; ```. Submit to the server:; ```; curl http://localhost:8000/api/workflows/V1 -FwdlSource=@goodImport.wdl -FwdlDependencies=@foo.zip; ```. Now tailing the server logs, the first time this is submitted, the workflow succeeds and the log shows nothing out of the ordinary. But ""sometimes"" (meaning, I can submit it 5 times and not see it, or twice and see it both times) I see this:; ```; 2017-02-07 15:01:10,781 cromwell-system-akka.dispatchers.service-dispatcher-30 ERROR - Sending Actor[akka://cromwell-system/user/cromwell-service/WorkflowManagerActor/WorkflowActor-84a51727-cfda-41e7-a03c-9e3af35eb0dc/MaterializeWorkflowDescriptorActor#972983209] failure message MetadataPutFailed(PutMetadataAction(Stream(MetadataEvent(MetadataKey(84a51727-cfda-41e7-a03c-9e3af35eb0dc,None,submittedFiles:imports:bar6.wdl),Some(MetadataValue(task doIt6 {; 	command { echo ""Help, world!"" }; 	output { String message = read_string(stdout()) }; },MetadataString)),2017-02-07T15:01:10.772+10:00), MetadataEvent(MetadataKey(84a51727-cfda-41e7-a03c-9e3af35eb0dc,None,submittedFiles:imports:bar4.wdl),Some(MetadataValue(task doIt4 {; 	command { echo ""Help, world!"" }; 	output { String message = read_string(stdout()) }; },MetadataString)),2017-02-07T15:01:10.774+10:00), MetadataEvent(MetadataKey(84a51727-cfda-41e7-a03c-9e3af35eb0dc,None,submittedFiles:imports:bar5.wdl),Some(MetadataValue(task doIt5 {; 	command { echo ""Help, world!"" }; 	output { String message = read_string(stdout()) }; },MetadataString)),2017-02-07T15:01:10.775+10:00), MetadataEvent(MetadataKey(84a51727-cfda-41e7-a03c-9e3af35eb0dc,None,submittedFiles:imports:bar3.wdl),Some(MetadataValue(task doIt3 {; 	command { echo ""Help, world!"" }; 	output { String message = read_string(stdout()) }; },MetadataString)),2017-02-07T15:01:10.776+10:00), MetadataEvent(MetadataKey(84a51727-cfda-41e7-a03c-9e3af35eb0dc,None,submittedFiles:imports:bar",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1959:1998,message,message,1998,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1959,1,['message'],['message']
Integrability,"oadinstitute/cromwell/assets/47044104/c2fa4113-3f6b-47aa-ad8d-62ab55fb374c). ## Details about the example WDL. * A root workflow (`main_workflow.wdl`) creates a subworkflow (LEVEL_1), `call outer.outer_workflow`; ``` wdl; import ""outer_subworkflow.wdl"" as outer. workflow main_workflow {; call outer.outer_subworkflow; }; ```; * LEVEL_1 `outer_subworkflow.wdl` then creates a scatter of 2 across another subworkflow (`call inner.inner_subworkflow`/LEVEL_2A and LEVEL_2B); ``` wdl; import ""inner_subworkflow.wdl"" as inner. workflow outer_subworkflow {; scatter (i in range(2)) {; call inner.inner_subworkflow as inner_subworkflow; }; }; ```; * `inner_subworkflow.wdl`/LEVEL_2A and LEVEL_2B then runs a task with a scatter and a scatter of 3 across a final subworkflow (`call sub_workflow.sub_subworkflow`/ LEVEL_2_X__3_Y); ``` wdl; import ""sub_subworkflow.wdl"" as sub_subworkflow. task hello_world {; command {; echo 'Hello, world!'; echo 'blah' > output.txt ; }. output {; String message = read_string(stdout()); File outputFile = ""output.txt""; }. runtime {; docker: ""ubuntu:latest""; }; }. workflow inner_subworkflow {; scatter (i in range(4)) {; call hello_world; }; scatter (i in range(3)) {; call sub_subworkflow.sub_subworkflow; }; }; ```; * This final `sub_subworkflow.wdl` then runs a scatter across a task:; ``` wdl; task sub_hello_world {; command {; echo 'Hello from sub.sub_workflow, world!'; }. output {; String message = read_string(stdout()); }. runtime {; docker: ""ubuntu:latest""; }; }. workflow sub_subworkflow {; scatter (i in range(2)) {; call sub_hello_world; }; }; ```. In tree form you have something like this:; * ROOT_WORKFLOW `main_workflow.wdl`; * LEVEL_1 `outer_subworkflow.wdl`; * LEVEL_2A `inner_subworkflow.wdl`; * LEVEL_2_A__3_A `sub_subworkflow.wdl`; * LEVEL_2_A__3_B `sub_subworkflow.wdl`; * LEVEL_2_A__3_C `sub_subworkflow.wdl`; * LEVEL_2B `inner_subworkflow.wdl`; * LEVEL_2_B__3_A `sub_subworkflow.wdl`; * LEVEL_2_B__3_B `sub_subworkflow.wdl`; * LEVEL_2_B__3_C `sub_su",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7387:2841,message,message,2841,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7387,1,['message'],['message']
Integrability,"ob-limit = 10; # If an 'exit-code-timeout-seconds' value is specified:; # - check-alive will be run at this interval for every job; # - if a job is found to be not alive, and no RC file appears after this interval; # - Then it will be marked as Failed.; ## Warning: If set, Cromwell will run 'check-alive' for every job at this interval; exit-code-timeout-seconds = 360; filesystems {; local {; localization: [; # soft link does not work for docker with --contain. Hard links won't work; # across file systems; ""copy"", ""hard-link"", ""soft-link""; ]; caching {; duplication-strategy: [""copy"", ""hard-link"", ""soft-link""]; hashing-strategy: ""file""; }; }; }. #; runtime-attributes = """"""; Int runtime_minutes = 600; Int cpus = 3; Int requested_memory_mb_per_core = 8000; Int memory_mb = 40000; String? docker; String? partition; String? account; String? IMAGE; """""". submit = """"""; sbatch \; --wait \; --job-name=${job_name} \; --chdir=${cwd} \; --output=${out} \; --error=${err} \; --time=${runtime_minutes} \; ${""--cpus-per-task="" + cpus} \; --mem-per-cpu=${requested_memory_mb_per_core} \; --partition=wzhcexclu06 \; --wrap ""/bin/bash ${script}""; """""". submit-docker = """"""; # SINGULARITY_CACHEDIR needs to point to a directory accessible by; # the jobs (i.e. not lscratch). Might want to use a workflow local; # cache dir like in run.sh; source /work/share/ac7m4df1o5/bin/cromwell/set_singularity_cachedir.sh; SINGULARITY_CACHEDIR=/work/share/ac7m4df1o5/bin/cromwell/singularity-cache; source /work/share/ac7m4df1o5/bin/cromwell/test.sh ${docker}; echo ""SINGULARITY_CACHEDIR $SINGULARITY_CACHEDIR""; if [ -z $SINGULARITY_CACHEDIR ]; then; CACHE_DIR=$HOME/.singularity; else; CACHE_DIR=$SINGULARITY_CACHEDIR; fi; mkdir -p $CACHE_DIR; echo ""SINGULARITY_CACHEDIR $SINGULARITY_CACHEDIR""; LOCK_FILE=$CACHE_DIR/singularity_pull_flock. # we want to avoid all the cromwell tasks hammering each other trying; # to pull the container into the cache for the first time. flock works; # on GPFS, netapp, and vast (of course",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6933:7668,wrap,wrap,7668,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6933,1,['wrap'],['wrap']
Integrability,"ompare/v0.9.0...v0.10.1-java8). ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>🔍 Files still referring to the old version number</summary>. The following files still refer to the old version number (0.9.0).; You might want to review and update them manually.; ```; centaur/src/main/resources/integrationTestCases/Somatic/CNV-Pair/cnv_somatic_pair_workflow_do_gc_wes.inputs; centaur/src/main/resources/integrationTestCases/Somatic/CNV-Panel/cnv_somatic_panel_workflow_do_gc_wes.inputs; centaur/src/main/resources/integrationTestCases/Somatic/Mutect2/Mutect2.aws.inputs; centaur/src/main/resources/integrationTestCases/Somatic/Mutect2/Mutect2.inputs; centaur/src/main/resources/integrationTestCases/germline/haplotype-caller-workflow/HaplotypeCallerWF.json; centaur/src/main/resources/integrationTestCases/germline/single-sample-production-workflow/PairedEndSingleSampleWf.options.json; centaur/src/main/resources/integrationTestCases/germline/single-sample-workflow/processing-for-variant-discovery-gatk4.hg38.wgs.inputs.json; centaur/src/main/resources/integrationTestCases/green/arrays/arrays.wdl; womtool/src/test/resources/validate/wdl_draft3/valid/HaplotypeCallerWF/HaplotypeCallerWF.inputs.json; womtool/src/test/resources/validate/wdl_draft3/valid/cnv_somatic_pair_workflow/cnv_somatic_pair_workflow.inputs.json; womtool/src/test/resources/validate/wdl_draft3/valid/joint-discovery-gatk/joint-discovery-gatk.inputs.json; ```; </details>; <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7294:1360,integrat,integrationTestCases,1360,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7294,1,['integrat'],['integrationTestCases']
Integrability,"omwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$lifecycle$materialization$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor(MaterializeWorkflowDescriptorActor.scala:231)""; },; {; causedBy: [ ],; message: ""cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$1.$anonfun$applyOrElse$1(MaterializeWorkflowDescriptorActor.scala:157)""; },; {; causedBy: [ ],; message: ""scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:304)""; },; {; causedBy: [ ],; message: ""scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37)""; },; {; causedBy: [ ],; message: ""scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60)""; },; {; causedBy: [ ],; message: ""akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55)""; },; {; causedBy: [ ],; message: ""akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91)""; },; {; causedBy: [ ],; message: ""scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)""; },; {; causedBy: [ ],; message: ""scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81)""; },; {; causedBy: [ ],; message: ""akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:91)""; },; {; causedBy: [ ],; message: ""akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40)""; },; {; causedBy: [ ],; message: ""akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:43)""; },; {; causedBy: [ ],; message: ""akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)""; },; {; causedBy: [ ],; message: ""akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)""; },; {; causedBy: [ ],; message: ""akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)""; },; {; causedBy: [ ],; message: ""akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)""; }; ],; message: ""Work",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3143:3018,message,message,3018,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3143,1,['message'],['message']
Integrability,"on(Stream(MetadataEvent(MetadataKey(84a51727-cfda-41e7-a03c-9e3af35eb0dc,None,submittedFiles:imports:bar6.wdl),Some(MetadataValue(task doIt6 {; 	command { echo ""Help, world!"" }; 	output { String message = read_string(stdout()) }; },MetadataString)),2017-02-07T15:01:10.772+10:00), MetadataEvent(MetadataKey(84a51727-cfda-41e7-a03c-9e3af35eb0dc,None,submittedFiles:imports:bar4.wdl),Some(MetadataValue(task doIt4 {; 	command { echo ""Help, world!"" }; 	output { String message = read_string(stdout()) }; },MetadataString)),2017-02-07T15:01:10.774+10:00), MetadataEvent(MetadataKey(84a51727-cfda-41e7-a03c-9e3af35eb0dc,None,submittedFiles:imports:bar5.wdl),Some(MetadataValue(task doIt5 {; 	command { echo ""Help, world!"" }; 	output { String message = read_string(stdout()) }; },MetadataString)),2017-02-07T15:01:10.775+10:00), MetadataEvent(MetadataKey(84a51727-cfda-41e7-a03c-9e3af35eb0dc,None,submittedFiles:imports:bar3.wdl),Some(MetadataValue(task doIt3 {; 	command { echo ""Help, world!"" }; 	output { String message = read_string(stdout()) }; },MetadataString)),2017-02-07T15:01:10.776+10:00), MetadataEvent(MetadataKey(84a51727-cfda-41e7-a03c-9e3af35eb0dc,None,submittedFiles:imports:bar1.wdl),Some(MetadataValue(task doIt1 {; 	command { echo ""Help, world!"" }; 	output { String message = read_string(stdout()) }; },MetadataString)),2017-02-07T15:01:10.776+10:00), MetadataEvent(MetadataKey(84a51727-cfda-41e7-a03c-9e3af35eb0dc,None,submittedFiles:imports:bar9.wdl),Some(MetadataValue(task doIt9 {; 	command { echo ""Help, world!"" }; 	output { String message = read_string(stdout()) }; },MetadataString)),2017-02-07T15:01:10.777+10:00), MetadataEvent(MetadataKey(84a51727-cfda-41e7-a03c-9e3af35eb0dc,None,submittedFiles:imports:bar10.wdl),Some(MetadataValue(task doIt10 {; 	command { echo ""Help, world!"" }; 	output { String message = read_string(stdout()) }; },MetadataString)),2017-02-07T15:01:10.778+10:00), MetadataEvent(MetadataKey(84a51727-cfda-41e7-a03c-9e3af35eb0dc,None,submittedFiles:imports:b",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1959:2811,message,message,2811,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1959,1,['message'],['message']
Integrability,"on.MaterializeWorkflowDescriptorActor$$anonfun$1.$anonfun$applyOrElse$1(MaterializeWorkflowDescriptorActor.scala:157)""; },; {; causedBy: [ ],; message: ""scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:304)""; },; {; causedBy: [ ],; message: ""scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37)""; },; {; causedBy: [ ],; message: ""scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60)""; },; {; causedBy: [ ],; message: ""akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55)""; },; {; causedBy: [ ],; message: ""akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91)""; },; {; causedBy: [ ],; message: ""scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)""; },; {; causedBy: [ ],; message: ""scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81)""; },; {; causedBy: [ ],; message: ""akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:91)""; },; {; causedBy: [ ],; message: ""akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40)""; },; {; causedBy: [ ],; message: ""akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:43)""; },; {; causedBy: [ ],; message: ""akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)""; },; {; causedBy: [ ],; message: ""akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)""; },; {; causedBy: [ ],; message: ""akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)""; },; {; causedBy: [ ],; message: ""akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)""; }; ],; message: ""Workflow input processing failed""; }; ],; ```. I think the culprit has something to do with both the root and sub workflow both having a task called `GatherbamFiles` because when I renamed the task in the subworkflow (and all subsequent necessary renames) the workflow ran fine. When I tried to make a simple example of this I ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3143:3342,message,message,3342,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3143,1,['message'],['message']
Integrability,"on: 29-675e865-SNAP. I have a `read_lines` call inside of a `scatter` definition like . ```; scatter (file in read_lines(shard_fofn)){; 		call SelectVariants{; 			input:; 				vcf=file,; 				intervals=interval_list; 		}; 	}; ```. where `shard fofn` has 20k+ lines inside of it. When running this workflow different shards failed ; with one of two errors. 30-50 different shards would fail each retry. ```; {; failures: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [ ],; message: ""Data received in non-data state: 6""; }; ],; message: ""Connection has been shutdown: javax.net.ssl.SSLProtocolException: Data received in non-data state: 6""; }; ],; message: ""Connection has been shutdown: javax.net.ssl.SSLProtocolException: Data received in non-data state: 6""; }; ],; message: ""All reopens failed""; }; ],; message: ""vcf""; }; ],; message: ""Input evaluation for Call mergeAndGetSites.SelectVariants failed.""; }; ],; message: ""Couldn't resolve all inputs for mergeAndGetSites.SelectVariants at index Some(778).""; }; ],; attempt: 1,; shardIndex: 778; },; ```; or . ```; {; failures: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [; {; causedBy: [ ],; message: ""Connection closed prematurely: bytesRead = 34066, Content-Length = 2974047""; }; ],; message: ""Connection closed prematurely: bytesRead = 34066, Content-Length = 2974047""; }; ],; message: ""All reopens failed""; }; ],; message: ""vcf""; }; ],; message: ""Input evaluation for Call mergeAndGetSites.SelectVariants failed.""; }; ],; message: ""Couldn't resolve all inputs for mergeAndGetSites.SelectVariants at index Some(19820).""; }; ],; attempt: 1,; shardIndex: 19820; }; ]; },; ```. When I take the `read_lines(shard_fofn)` and assign it to a variable and then pass that to the scatter everything works fine. Is this just bad luck or is there possibly a real issue here?. ```; 	Array[File] fofn_files = read_lines(shard_fofn). 	scatter (file in fofn_files",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2965:990,message,message,990,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2965,1,['message'],['message']
Integrability,"ontext.scala:72); at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). ```. Then I see:. ```; [ERROR] [05/01/2017 17:36:04.203] [cromwell-system-akka.dispatchers.engine-dispatcher-84] [akka://cromwell-system/user/cromwell-service/WorkflowManagerActor] WorkflowManagerActor Workflow 5; 3e95ead-9026-4c13-89f9-f6c675214523 failed (during ExecutingWorkflowState): Task m2.Mutect2.M2:1:1 failed. JES error code 5. Message: 9: Failed to localize files: failed to copy the follow; ing files: ""gs://5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-10A-01D-A25E-08.2.bam -> /mnt/local-disk/5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD; /DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-10A-01D-A25E-08.2.bam (cp failed: gsutil -q -m cp gs://5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-10A-01D-A2; 5E-08.2.bam /mnt/local-disk/5aa919de-0aa0-43ec-9ec3-288481102b6d/tcga/STAD/DNA/WXS/BI/ILLUMINA/C440.TCGA-HU-A4H3-10A-01D-A25E-08.2.bam, command failed: Traceback (most recent call last):\n; File \""/usr/local/share/google/google-cloud-sdk/bin/bootstrapping/gsutil.py\"", line 75, in <module>\n main()\n File \""/usr/local/share/google/google-cloud-sdk/bin/bootstrapping/gsutil.; py\"", line 22, in main\n project, account = bootstrapping.GetActiveProjectAndAccount()\n File \""/usr/local/share/google/google-cloud-sdk/bin/bootstrapping/bootstrapping.py\"", line 205,; in GetActiveProjectAndAccount\n project_name = properties.VALUES.cor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2228:2606,Message,Message,2606,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2228,1,['Message'],['Message']
Integrability,"oogle-cloud-resourcemanager](https://github.com/googleapis/java-resourcemanager) from 1.0.4 to 1.1.2.; [GitHub Release Notes](https://github.com/googleapis/java-resourcemanager/releases/tag/v1.1.2) - [Changelog](https://github.com/googleapis/java-resourcemanager/blob/master/CHANGELOG.md) - [Version Diff](https://github.com/googleapis/java-resourcemanager/compare/v1.0.4...v1.1.2). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/6472b97b3365f2800f4202d1bf6b1d647bd2b0cc/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Files still referring to the old version number</summary>. The following files still refer to the old version number (1.0.4).; You might want to review and update them manually.; ```; centaur/src/main/resources/integrationTestCases/cwl/bcbio/gvcf-joint-workflow/steps/variantcall_batch_region.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/prealign-workflow/steps/variantcall_batch_region.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/somatic-workflow/steps/variantcall_batch_region.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/svcall-workflow/steps/variantcall_batch_region.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/wes_chr21_test-workflow-gcp/steps/variantcall_batch_region.cwl; project/Dependencies.scala; ```; </details>; <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.cloud"", artifactId = ""google-cloud-resourcemanager"" } ]; ```; </details>. labels: library-update, semver-minor, old-version-remains",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6519:1118,integrat,integrationTestCases,1118,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6519,7,"['Depend', 'depend', 'integrat']","['Dependencies', 'dependency', 'integrationTestCases']"
Integrability,"operation	. 2019/07/01 22:54:02 Starting container setup.; 2019/07/01 22:54:11 Done container setup.; 2019/07/01 22:54:17 Starting localization.; 2019/07/01 22:54:24 Localizing input dos://dg.4503/1406db81-91d7-4e57-ada3-40487199ed06 -> /cromwell_root/topmed-irc-share/genomes/NWD522711.b38.irc.v1.cram; Compiling (synthetic)/ammonite/predef/interpBridge.sc; ```. or. ```; Task ga4ghMd5.md5:NA:1 failed. The job was stopped before the command finished. PAPI error code 10. The assigned worker has failed to complete the operation	. 2019/07/10 19:25:06 Starting container setup.; 2019/07/10 19:25:14 Done container setup.; 2019/07/10 19:25:20 Starting localization.; 2019/07/10 19:25:26 Localizing input dos://dg.4503/1cba8116-a3d1-41e6-aab3-428e4f42e916 -> /cromwell_root/topmed-irc-share/genomes/NWD735861.b38.irc.v1.cram.crai; Compiling (synthetic)/ammonite/predef/interpBridge.sc; Compiling (synthetic)/ammonite/predef/DefaultPredef.sc; ```. In some cases, additional information is logged, as in the following example where Ammonite dependency failed:. ```; 2019/07/10 18:29:15 Starting container setup.; 2019/07/10 18:29:24 Done container setup.; 2019/07/10 18:29:31 Starting localization.; 2019/07/10 18:29:37 Localizing input dos://dg.4503/cbdb14f5-cc89-4481-bad7-2ef8f36a1290 -> /cromwell_root/topmed-irc-share/genomes/NWD127112.b38.irc.v1.cram; Compiling (synthetic)/ammonite/predef/interpBridge.sc; Compiling (synthetic)/ammonite/predef/DefaultPredef.sc; Compiling /scripts/dosUrlLocalizer.sc; Downloading https://repo1.maven.org/maven2/org/http4s/http4s-dsl_2.12/0.18.17/http4s-dsl_2.12-0.18.17.pom.sha1; Downloading https://repo1.maven.org/maven2/org/http4s/http4s-dsl_2.12/0.18.17/http4s-dsl_2.12-0.18.17.pom; https://repo1.maven.org/maven2/org/http4s/http4s-dsl_2.12/0.18.17/http4s-dsl_… ; https://repo1.maven.org/maven2/org/http4s/http4s-dsl_2.12/0.18.17/http4s-dsl_… . Downloaded https://repo1.maven.org/maven2/org/http4s/http4s-dsl_2.12/0.18.17/http4s-dsl_2.12-0.18.17.pom; Downloade",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5069:2003,depend,dependency,2003,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5069,1,['depend'],['dependency']
Integrability,"or.scala:54); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:614); 	at akka.actor.ActorCell.invoke(ActorCell.scala:583); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:268); 	at akka.dispatch.Mailbox.run(Mailbox.scala:229); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:241); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); [2023-11-07 14:51:17,39] [info] Message [cromwell.engine.workflow.lifecycle.EngineLifecycleActorAbortCommand$] from Actor[akka://cromwell-system/user/SingleWorkflowRunnerActor/WorkflowManagerActor/WorkflowActor-4e522458-e360-45e8-be15-2fc99652d692#-686070856] to Actor[akka://cromwell-system/user/SingleWorkflowRunnerActor/WorkflowManagerActor/WorkflowActor-4e522458-e360-45e8-be15-2fc99652d692/WorkflowExecutionActor-4e522458-e360-45e8-be15-2fc99652d692#-1420206102] was not delivered. [1] dead letters encountered, no more dead letters will be logged. If this is not an expected behavior, then [Actor[akka://cromwell-system/user/SingleWorkflowRunnerActor/WorkflowManagerActor/WorkflowActor-4e522458-e360-45e8-be15-2fc99652d692/WorkflowExecutionActor-4e522458-e360-45e8-be15-2fc99652d692#-1420206102]] may have terminated unexpectedly, This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; ```; In fact, the program becomes unresponsive to even a Ctrl+C kill command and I have to close the terminal entirely to stop it. . The WDL passes `womtool validate` (version 84) and was run using Cromwell version 84. . When run in Terra, the workflow just immediate goes into an aborting state without any helpful error message. It would be great to incorporate this type of support for `None` inside struct fields.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7249:7162,message,message,7162,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7249,1,['message'],['message']
Integrability,"or.scala:91); 	at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); 	at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72); 	at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); 	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: com.google.cloud.storage.StorageException: 503 Service Unavailable; {; ""error"": {; ""errors"": [; {; ""domain"": ""global"",; ""reason"": ""backendError"",; ""message"": ""Backend Error""; }; ],; ""code"": 503,; ""message"": ""Backend Error""; }; }. 	at com.google.cloud.storage.spi.DefaultStorageRpc.translate(DefaultStorageRpc.java:190); 	at com.google.cloud.storage.spi.DefaultStorageRpc.write(DefaultStorageRpc.java:536); 	at com.google.cloud.storage.BlobWriteChannel$1.run(BlobWriteChannel.java:49); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at com.google.cloud.RetryHelper.doRetry(RetryHelper.java:179); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:244); 	at com.google.cloud.storage.BlobWriteChannel.flushBuffer(BlobWriteChannel.java:46); 	at com.google.cloud.BaseWriteChannel.close(BaseWriteChannel.java:149); 	at com.google.cloud.storage.contrib.nio.CloudStorageWriteChannel.close(CloudStorageWriteChannel.java:57); 	at java.nio.channels.Channels$1.close(Channels.java:178); 	at java.nio.file.Files.write(Files.java:3300); 	at cromwell.backend.impl.jes.io.package$PathEnhanced$.writ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1890:3373,message,message,3373,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1890,4,['message'],['message']
Integrability,"ore attempting to build or run the image. For example, we currently recommend this `submit-docker` configuration:. ```; submit-docker = """"""; # Ensure singularity is loaded if it's installed as a module; module load Singularity/3.0.1; ; # Build the Docker image into a singularity image; DOCKER_NAME=$(sed -e 's/[^A-Za-z0-9._-]/_/g' <<< ${docker}); IMAGE=${cwd}/$DOCKER_NAME.sif; if [ ! -f $IMAGE ]; then; singularity pull $IMAGE docker://${docker}; fi. # Submit the script to SLURM; sbatch \; --wait \; -J ${job_name} \; -D ${cwd} \; -o ${cwd}/execution/stdout \; -e ${cwd}/execution/stderr \; -t ${runtime_minutes} \; ${""-c "" + cpus} \; --mem-per-cpu=${requested_memory_mb_per_core} \; --wrap ""singularity exec --bind ${cwd}:${docker_cwd} $IMAGE ${job_shell} ${script}""; """"""; ```. I'm instead proposing this. Note the use of a single shared image directory (`/singularity_cache` in this example), and the use of `flock` to ensure the submit scripts aren't competing with each other:. ```; submit-docker = """"""; # Ensure singularity is loaded if it's installed as a module; module load Singularity/3.0.1; ; # Determine the filepath to the image; DOCKER_NAME=$(sed -e 's/[^A-Za-z0-9._-]/_/g' <<< ${docker}); IMAGE=/singularity_cache/$DOCKER_NAME.sif. # Wait for an exclusive lock on the image ; (; flock --exclusive 200; # Build the image; if [ ! -f $IMAGE ]; then; singularity pull $IMAGE docker://${docker}; fi; ) 200>/var/lock/$IMAGE. # Submit the script to SLURM; sbatch \; --wait \; -J ${job_name} \; -D ${cwd} \; -o ${cwd}/execution/stdout \; -e ${cwd}/execution/stderr \; -t ${runtime_minutes} \; ${""-c "" + cpus} \; --mem-per-cpu=${requested_memory_mb_per_core} \; --wrap ""singularity exec --bind ${cwd}:${docker_cwd} $IMAGE ${job_shell} ${script}""; """"""; ```. I haven't tested this on our HPC cluster (it's down for maintenance sadly!), but I'm interested if this makes sense as something we could get into the containers tutorial in order to recommend to users. @illusional, @vsoch @geoffjentry",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5063:2641,wrap,wrap,2641,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5063,1,['wrap'],['wrap']
Integrability,"ore the break I was playing around trying to async-ify Cromwell's IO a bit more. It's not complete and needs clean up / refinements / tests, but considering that one of the goals is reliability/scalability, I thought I'd make a PR out of it since it might provide a base for discussion. This branch has an IO Actor that handles *some* of the IO that has to be done both on the engine and the backend side. Specifically the script.sh upload, rc file reading, stderr file size reading, call cache copying (on JES), workflow outputs copying is done using this mechanism.; The actor is under the service registry umbrella, that was to be able to test it more rapidly (as the service registry is already wired up pretty much everywhere), but it should probably be it's own top level actor. Due to the Future-based approach we took in the backend interface, the IO messages (copy, read, write, delete file...) are declined into 2 different flavors:; - A classic Command -> Response; - A Promise based version, that takes a promise in the command message itself to be completed when the operation finishes. This allow for the actor to integrate with parts of the code that can't (easily) handle the response as a message. The underlying implementation of the IO Actor is a router, but could be swapped for something else. Each worker tries to perform the operation, and once it's complete (successfully or not) either sends a message back or completes the promise depending on the command flavor.; Retries are handled by keeping an exponential backoff object in the command itself. If the failure is retryable, the worker sends the command message back to the router after waiting for the appropriate backoff time. The message will then be rerouted when a worker is available.; Note that the actual time before the command is picked up again by another worker could be longer than intended if all workers are busy and the command spends time in the mailbox. ; A command will be retried as many times as possi",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1831:1043,message,message,1043,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1831,1,['message'],['message']
Integrability,"orkQueue.runTask(ForkJoinPool.java:1339); 	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: com.google.cloud.storage.StorageException: 503 Service Unavailable; {; ""error"": {; ""errors"": [; {; ""domain"": ""global"",; ""reason"": ""backendError"",; ""message"": ""Backend Error""; }; ],; ""code"": 503,; ""message"": ""Backend Error""; }; }. 	at com.google.cloud.storage.spi.DefaultStorageRpc.translate(DefaultStorageRpc.java:190); 	at com.google.cloud.storage.spi.DefaultStorageRpc.write(DefaultStorageRpc.java:536); 	at com.google.cloud.storage.BlobWriteChannel$1.run(BlobWriteChannel.java:49); 	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511); 	at com.google.cloud.RetryHelper.doRetry(RetryHelper.java:179); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:244); 	at com.google.cloud.storage.BlobWriteChannel.flushBuffer(BlobWriteChannel.java:46); 	at com.google.cloud.BaseWriteChannel.close(BaseWriteChannel.java:149); 	at com.google.cloud.storage.contrib.nio.CloudStorageWriteChannel.close(CloudStorageWriteChannel.java:57); 	at java.nio.channels.Channels$1.close(Channels.java:178); 	at java.nio.file.Files.write(Files.java:3300); 	at cromwell.backend.impl.jes.io.package$PathEnhanced$.writeAsJson$extension(package.scala:13); 	at cromwell.backend.impl.jes.JesInitializationActor$$anonfun$cromwell$backend$impl$jes$JesInitializationActor$$writeAuthenticationFile$1.apply(JesInitializationActor.scala:62); 	... 24 more; Caused by: com.google.api.client.http.HttpResponseException: 503 Service Unavailable; {; ""error"": {; ""errors"": [; {; ""domain"": ""global"",; ""reason"": ""backendError"",; ""message"": ""Backend Error""; }; ],; ""code"": 503,; ""message"": ""Backend Error""; }; }. 	at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1070); 	at com.google.cloud.storage.spi.DefaultStorageRpc.write(DefaultStorageRpc.java:518); 	... 35 more; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1890:4747,message,message,4747,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1890,2,['message'],['message']
Integrability,"orker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: com.google.api.client.googleapis.json.GoogleJsonResponseException: 403 Forbidden; POST https://storage.googleapis.com/upload/storage/v1/b/xxx/o?projection=full&userProject=xxx&uploadType=multipart; {; ""code"" : 403,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""xxx@xxx.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project."",; ""reason"" : ""forbidden""; } ],; ""message"" : ""xxx@xxx.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project.""; }; 	at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:150); 	at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113); 	at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:555); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:475); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:592); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.create(HttpStorageRpc.java:305); 	... 22 more; ```. I have no idea what `serviceusage.services.use` is and how to activate it. The tutorial is also very weirdly written. It seems like there used to be a tutorial about JES/PAPIv1 and then it got updated with a notice for PAPIv2. It is completely unclear whether the user is supposed to use JES/PAPIv1 or PAPIv2. I do not understand why it has to be so complicated. Can Cromwell provide some useful message about what to do to set the required permissions?",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5594:8871,message,message,8871,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5594,1,['message'],['message']
Integrability,"orkflowRoot"": ""/b6b190d6-8640-4638-94cd-15f16b194f38/echo_strings/c386672d-0248-4968-9b1a-114f5f5c4706/"",; ""id"": ""c386672d-0248-4968-9b1a-114f5f5c4706"",; ""inputs"": {...; },; ""submission"": ""2017-01-30T19:00:00.796Z"",; ""status"": ""Failed"",; ""failures"": [{; ""message"": ""Task c386672d-0248-4968-9b1a-114f5f5c4706:echo_files failed: error code 5. Message: 8: Failed to pull image ubuntu:latest: \""docker --config /tmp/.docker/ pull ubuntu:latest\"" failed: exit status 1: Pulling repository docker.io/library/ubuntu\nNetwork timed out while trying to connect to https://index.docker.io/v1/repositories/library/ubuntu/images. You may want to check your internet connection or if you are behind a proxy.\n""; }],; ""workflowLog"": ""gs://fc-2d3fd356-e3be-4953-92f1-60af623e6fa5/b6b190d6-8640-4638-94cd-15f16b194f38/workflow.logs/workflow.c386672d-0248-4968-9b1a-114f5f5c4706.log"",; ""end"": ""2017-01-30T19:14:20.002Z"",; ""start"": ""2017-01-30T19:00:03.040Z""; }. ```; Here it's an array of ""message""s; ```; {; ""workflowName"": ""aggregate_data_workflow"",; ""submittedFiles"": {... },; ""calls"": {; ""aggregate_data_workflow.aggregate_data"": [{; ""retryableFailure"": false,; ""executionStatus"": ""Failed"",; ""stdout"": ""/cromwell-executions/aggregate_data_workflow/3608d6ca-fbb4-4232-b197-268058470bfc/call-aggregate_data/execution/stdout"",; ""shardIndex"": -1,; ""runtimeAttributes"": {; ""docker"": ""broadgdac/aggregate_data:31"",; ""failOnStderr"": false,; ""continueOnReturnCode"": ""0""; },; ""cache"": {; ""allowResultReuse"": true; },; ""Effective call caching mode"": ""CallCachingOff"",; ""inputs"": {...; },; ""returnCode"": -1,; ""failures"": [{; ""message"": ""Call aggregate_data_workflow.aggregate_data: return code was -1""; }, {; ""message"": ""Call aggregate_data_workflow.aggregate_data: return code was -1""; }, {; ""message"": ""Call aggregate_data_workflow.aggregate_data: return code was -1""; }],; ""jobId"": ""2957"",; ""backend"": ""JES"",; ""end"": ""2016-12-02T15:05:42.655Z"",; ""stderr"": ""/cromwell-executions/aggregate_data_workflow/3608d6ca-fbb4-4232-",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2037:3273,message,message,3273,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2037,1,['message'],['message']
Integrability,"orkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: cromwell.backend.google.pipelines.common.api.PipelinesApiRequestManager$GoogleJsonException: Request contains an invalid argument.; ... 21 more. [2021-08-13 10:45:10,13] [info] WorkflowManagerActor: Workflow actor for a15c46b7-5f93-46d6-94a2-28f656914866 completed with status 'Failed'. The workflow will be removed from the workflow store.; [2021-08-13 10:45:13,98] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2021-08-13 10:45:15,05] [info] Workflow polling stopped; [2021-08-13 10:45:15,07] [info] 0 workflows released by cromid-de31b6d; [2021-08-13 10:45:15,07] [info] Shutting down WorkflowStoreActor - Timeout = 5 seconds; ...; ```. Contents of hello.wdl:; ```; task hello {; String addressee; command {; echo ""Hello ${addressee}! Welcome to Cromwell . . . on Google Cloud!""; }; output {; String message = read_string(stdout()); }; runtime {; docker: ""ubuntu:latest""; }; }. workflow wf_hello {; call hello. output {; hello.message; }; }; ```. Contents of hello.inputs:; ```; {; ""wf_hello.hello.addressee"": ""World""; }; ```; Contents of cromwell.BROADexamples.v4.conf:; ```; # This is a ""default"" Cromwell example that is intended for you you to start with; # and edit for your needs. Specifically, you will be interested to customize; # the configuration based on your preferred backend (see the backends section; # below in the file). For backend-specific examples for you to copy paste here,; # please see the cromwell.backend.examples folder in the repository. The files; # there also include links to online documentation (if it exists). # This line is required. It pulls in default overrides from the embedded cromwell; # `reference.conf` (in core/src/main/resources) needed for proper performance of cromwell.; include required(classpath(""application"")). # Google configuration; google {. application-name = ""c",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6469:8628,message,message,8628,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6469,1,['message'],['message']
Integrability,"orted Issue; > I don't have specific numbers at this time, but over the past several weeks our production operations staff started noticing an odd behavior that we originally thought was just normal preemption. Normally we see preemption showing up as ""Error code 10: Message 14:"" - and cromwell takes care of re-submitting and following the logic coded in our WDLs. Try pre-emptibles 3 times then try a non-preemptible instance. ; > ; > cromwell metadata output:; > ; > ""message"": ""Task PairedEndSingleSampleWorkflow.SamToFastqAndBwaMemAndMba:1:1 failed. JES error code 10. Task 417bb61c-16cc-4fda-91d5-443ccba4da11:SamToFastqAndBwaMemAndMba was preempted for the 1st time. The call will be restarted with another preemptible VM (max preemptible attempts number is 3). Error code Status{code=ABORTED, description=null, cause=null}. Message: 14: VM ggp-15030877962490231612 stopped unexpectedly.""; > ; > However we have seen a new error response. ""Error code 10: Message 13"" metadata output showing:; > ; > ""message"": ""Task PairedEndSingleSampleWorkflow.HaplotypeCaller:46:3 failed. JES error code 10. Message: 13: VM ggp-9289873678241352278 shut down unexpectedly.""; > ; > From what Cromwell team indicates is that ""Message 13"" is not the same as Message 14 - as such a different logic occurs within cromwell. Cromwell will try the task three times and after that it will just ""Fail"" the task. So the ""try 3 pre-emptible then try non-preemptible"" logic is never followed.; > ; > So my question is what is ""Message 13"" and how is it different from ""Message 14""? Below are OpsIDs for a set of tasks - the first are the ""Message 14"" (which again are normal preemption but I wanted to provide some for comparison to Message 13) and the second list are the ""Message 13"". This is just a small sample of Message 13 failures.; > ; > MESSAGE 14: ; > operations/ENWy-aWLLBi89uiD6_uZzNABIMf5sPc2Kg9wcm9kdWN0aW9uUXVldWU; > operations/EMzb1NeLLBj0jsHwufD1gHogpfe0-ecHKg9wcm9kdWN0aW9uUXVldWU; > operations/EOn3vcO",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3157:1196,Message,Message,1196,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3157,2,"['Message', 'message']","['Message', 'message']"
Integrability,"ot specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_ann' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.wgs_coverage_interval_list' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_fasta_index' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.unmapped_bam_suffix' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_ud' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_amb' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.preemptible_tries' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_sa' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.known_indels_sites_VCFs' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_mu' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_alt' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_bwt' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.known_indels_sites_indices' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_dict' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_bed' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_fasta' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAl",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2912:1785,message,message,1785,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2912,1,['message'],['message']
Integrability,"ou don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/92f43ce5f010fa03daeb2625a3f9c1b1be80cca5/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Files still referring to the old version number</summary>. The following files still refer to the old version number (1.28).; You might want to review and update them manually.; ```; centaur/src/main/resources/standardTestCases/local_bourne/local_bourne.wdl; core/src/test/resources/hello_goodbye_scattered_papiv2.json; docs/developers/bitesize/workflowParsing/forkjoin_graph.svg; docs/developers/bitesize/workflowParsing/wdlToWdlom_hermes.svg; project/Dependencies.scala; scripts/metadata_comparison/test/resources/comparer/papiv2_version3_good.json; scripts/metadata_comparison/test/resources/comparer/version3_comparison_good.csv; src/ci/bin/test.inc.sh; src/ci/docker-compose/cromwell-test/docker-setup.sh; supportedBackends/google/pipelines/v2alpha1/src/main/scala/cromwell/backend/google/pipelines/v2alpha1/api/request/GetRequestHandler.scala; supportedBackends/google/pipelines/v2alpha1/src/test/scala/cromwell/backend/google/pipelines/v2alpha1/api/request/GetRequestHandlerSpec.scala; supportedBackends/google/pipelines/v2beta/src/main/scala/cromwell/backend/google/pipelines/v2beta/api/request/GetRequestHandler.scala; supportedBackends/google/pipelines/v2beta/src/test/scala/cromwell/backend/google/pipelines/v2beta/api/request/GetRequestHandlerSpec.scala; ```; </details>; <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""org.yaml"", artifactId = ""snakeyaml"" } ]; ```; </details>. labels: test-library-update, old-version-remains",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6429:3973,depend,dependency,3973,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6429,1,['depend'],['dependency']
Integrability,"ow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.$anonfun$validateWdlNamespace$13(MaterializeWorkflowDescriptorActor.scala:491)""; },; {; causedBy: [ ],; message: ""scala.util.Either.flatMap(Either.scala:338)""; },; {; causedBy: [ ],; message: ""cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.validateWdlNamespace(MaterializeWorkflowDescriptorActor.scala:490)""; },; {; causedBy: [ ],; message: ""cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$lifecycle$materialization$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor(MaterializeWorkflowDescriptorActor.scala:231)""; },; {; causedBy: [ ],; message: ""cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$1.$anonfun$applyOrElse$1(MaterializeWorkflowDescriptorActor.scala:157)""; },; {; causedBy: [ ],; message: ""scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:304)""; },; {; causedBy: [ ],; message: ""scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37)""; },; {; causedBy: [ ],; message: ""scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60)""; },; {; causedBy: [ ],; message: ""akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55)""; },; {; causedBy: [ ],; message: ""akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91)""; },; {; causedBy: [ ],; message: ""scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)""; },; {; causedBy: [ ],; message: ""scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81)""; },; {; causedBy: [ ],; message: ""akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:91)""; },; {; causedBy: [ ],; message: ""akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40)""; },; {; causedBy: [ ],; message: ""akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:43)""; },; {;",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3143:2571,message,message,2571,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3143,1,['message'],['message']
Integrability,"owDescriptorActor.scala:231)""; },; {; causedBy: [ ],; message: ""cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$1.$anonfun$applyOrElse$1(MaterializeWorkflowDescriptorActor.scala:157)""; },; {; causedBy: [ ],; message: ""scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:304)""; },; {; causedBy: [ ],; message: ""scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37)""; },; {; causedBy: [ ],; message: ""scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60)""; },; {; causedBy: [ ],; message: ""akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55)""; },; {; causedBy: [ ],; message: ""akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91)""; },; {; causedBy: [ ],; message: ""scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)""; },; {; causedBy: [ ],; message: ""scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81)""; },; {; causedBy: [ ],; message: ""akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:91)""; },; {; causedBy: [ ],; message: ""akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40)""; },; {; causedBy: [ ],; message: ""akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:43)""; },; {; causedBy: [ ],; message: ""akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)""; },; {; causedBy: [ ],; message: ""akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)""; },; {; causedBy: [ ],; message: ""akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)""; },; {; causedBy: [ ],; message: ""akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)""; }; ],; message: ""Workflow input processing failed""; }; ],; ```. I think the culprit has something to do with both the root and sub workflow both having a task called `GatherbamFiles` because when I renamed the task in the subworkflo",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3143:3230,message,message,3230,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3143,1,['message'],['message']
Integrability,pass with a warning message if no secure environment variables,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3103:20,message,message,20,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3103,1,['message'],['message']
Integrability,"pdates [com.eed3si9n:sbt-assembly](https://github.com/sbt/sbt-assembly) from 1.1.0 to 1.1.1.; [GitHub Release Notes](https://github.com/sbt/sbt-assembly/releases/tag/v1.1.1) - [Version Diff](https://github.com/sbt/sbt-assembly/compare/v1.1.0...v1.1.1). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/2dc2301e75aea6c2d0c49b89d6092f7d4f134b40/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Files still referring to the old version number</summary>. The following files still refer to the old version number (1.1.0).; You might want to review and update them manually.; ```; CHANGELOG.md; centaur/src/main/resources/integrationTestCases/cwl/bcbio/gvcf-joint-workflow/steps/variantcall_batch_region.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/prealign-workflow/steps/variantcall_batch_region.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/somatic-workflow/steps/variantcall_batch_region.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/svcall-workflow/steps/variantcall_batch_region.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/wes_chr21_test-workflow-gcp/steps/variantcall_batch_region.cwl; cloud-nio/cloud-nio-impl-drs/src/main/scala/cloud/nio/impl/drs/DrsCloudNioFileSystemProvider.scala; cwl/src/test/resources/cwl/lodash.js; ```; </details>; <details>; <summary>Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.eed3si9n"", artifactId = ""sbt-assembly"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pul",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6850:976,integrat,integrationTestCases,976,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6850,1,['integrat'],['integrationTestCases']
Integrability,"pecified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.unmapped_bam_suffix' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_ud' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_amb' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.preemptible_tries' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_sa' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.known_indels_sites_VCFs' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_mu' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_alt' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_bwt' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.known_indels_sites_indices' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_dict' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_bed' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_fasta' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.dbSNP_vcf_index' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.dbSNP_vcf' not specified.""; }; ],; message: ""Workflow input processing failed""; }; ],; ```. But once I filled these out in my inputs json I then got this error. ```; [; {; causedBy: [; {; causedBy: [ ],; message: ""Missing inputs for subw",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2912:2149,message,message,2149,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2912,1,['message'],['message']
Integrability,ply$mcV$sp(NioFlow.scala:53); 	at cromwell.engine.io.nio.NioFlow$$anonfun$write$1.apply(NioFlow.scala:52); 	at cromwell.engine.io.nio.NioFlow$$anonfun$write$1.apply(NioFlow.scala:52); 	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24); 	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24); 	... 6 more; Caused by: javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Broken pipe; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:95); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:704); 	at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:647); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1536); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1441); 	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:338); 	at com.google.api.client.http.javanet.NetHttpResponse.<init>(NetHttpResponse.java:37); 	at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:94); 	at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); 	at com.google.cloud.storage.spi.DefaultStorageRpc.write(DefaultStorageRpc.java:564); 	... 24 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Broken pipe; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketI,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2183:4635,protocol,protocol,4635,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2183,1,['protocol'],['protocol']
Integrability,"pressionLib"": [; ""var specified_name_or_sample_name_prefix = function(specified_name, sample_name, sample_type){ /* If specified_name isn't null, return that. Otherwise return sample_name + \""_N\"" if sample_type is normal or sample_name + \""_T\"" if sample_type is tumour */ if (specified_name !== null){ return specified_name; } else if (sample_type === \""normal\"") { return sample_name + \""_N\""; } else if (sample_type === \""tumor\"") { return sample_name + \""_T\""; } else { /* Unsure what happened here */ return \""\""; } }""; ],; ""class"": ""InlineJavascriptRequirement""; },; {; ""class"": ""MultipleInputFeatureRequirement""; },; {; ""class"": ""StepInputExpressionRequirement""; }; ],; ""inputs"": [; {; ""type"": [; ""null"",; ""File""; ],; ""doc"": ""bed file of het SNP locations used by amber as -loci\n"",; ""id"": ""#bafsnps_amber""; },; {; ""type"": [; ""null"",; ""File""; ],; ""doc"": ""Optional - BED file containing regions to ignore\n"",; ""id"": ""#blacklist_gridss""; },; {; ""type"": [; ""null"",; ""File""; ],; ""doc"": ""Single breakend pon bed file\n"",; ""id"": ""#breakend_pon_gripss""; },; {; ""type"": [; ""null"",; ""File""; ],; ""doc"": ""Paired breakpoint hotspot bedpe file\n"",; ""id"": ""#breakpoint_hotspot_gripss""; },; {; ""type"": [; ""null"",; ""File""; ],; ""doc"": ""Paired breakpoint pon bedpe file\n"",; ""id"": ""#breakpoint_pon_gripss""; },; {; ""type"": [; ""null"",; ""int""; ],; ""doc"": ""threshold for # SVs in clusters to skip chaining routine (default = 2000)\n"",; ""id"": ""#chaining_sv_limit_linx""; },; {; ""type"": [; ""null"",; ""boolean""; ],; ""doc"": ""Optional - Discover and annotate gene fusions\n"",; ""id"": ""#check_drivers_linx""; },; {; ""type"": [; ""null"",; ""boolean""; ],; ""doc"": ""Optional - discover and annotate gene fusions\n"",; ""id"": ""#check_fusions_linx""; },; {; ""type"": [; ""null"",; ""File""; ],; ""doc"": ""list of known fragile sites - specify Chromosome,PosStart,PosEnd - fragile_sites.csv\n"",; ""id"": ""#fragile_site_file_linx""; },; {; ""type"": [; ""null"",; ""int""; ],; ""doc"": ""Distance upstream of gene to consider a breakend applicable\n"",; ""id"":",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5826:38792,rout,routine,38792,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5826,1,['rout'],['routine']
Integrability,"ps log4j-core from 2.13.3 to 2.15.0. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=org.apache.logging.log4j:log4j-core&package-manager=maven&previous-version=2.13.3&new-version=2.15.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); - `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language; - `@de",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6587:724,Depend,Dependabot,724,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6587,9,"['Depend', 'depend']","['Dependabot', 'dependabot']"
Integrability,"ps log4j-core from 2.13.3 to 2.16.0. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=org.apache.logging.log4j:log4j-core&package-manager=maven&previous-version=2.13.3&new-version=2.16.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); - `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language; - `@de",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6592:724,Depend,Dependabot,724,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6592,9,"['Depend', 'depend']","['Dependabot', 'dependabot']"
Integrability,"ps log4j-core from 2.16.0 to 2.17.0. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=org.apache.logging.log4j:log4j-core&package-manager=maven&previous-version=2.16.0&new-version=2.17.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); - `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language; - `@de",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6595:724,Depend,Dependabot,724,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6595,9,"['Depend', 'depend']","['Dependabot', 'dependabot']"
Integrability,"ps log4j-core from 2.17.0 to 2.17.1. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=org.apache.logging.log4j:log4j-core&package-manager=maven&previous-version=2.17.0&new-version=2.17.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); - `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language; - `@de",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6640:724,Depend,Dependabot,724,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6640,9,"['Depend', 'depend']","['Dependabot', 'dependabot']"
Integrability,"ptorActor.scala:157)""; },; {; causedBy: [ ],; message: ""scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:304)""; },; {; causedBy: [ ],; message: ""scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37)""; },; {; causedBy: [ ],; message: ""scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60)""; },; {; causedBy: [ ],; message: ""akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55)""; },; {; causedBy: [ ],; message: ""akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91)""; },; {; causedBy: [ ],; message: ""scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)""; },; {; causedBy: [ ],; message: ""scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81)""; },; {; causedBy: [ ],; message: ""akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:91)""; },; {; causedBy: [ ],; message: ""akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40)""; },; {; causedBy: [ ],; message: ""akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:43)""; },; {; causedBy: [ ],; message: ""akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)""; },; {; causedBy: [ ],; message: ""akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)""; },; {; causedBy: [ ],; message: ""akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)""; },; {; causedBy: [ ],; message: ""akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)""; }; ],; message: ""Workflow input processing failed""; }; ],; ```. I think the culprit has something to do with both the root and sub workflow both having a task called `GatherbamFiles` because when I renamed the task in the subworkflow (and all subsequent necessary renames) the workflow ran fine. When I tried to make a simple example of this I couldn't get the error to pop up again so I'm definitely missing some nuances of the cause. The r",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3143:3439,message,message,3439,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3143,1,['message'],['message']
Integrability,putStream.read(SocketInputStream.java:170) ~[na:1.8.0_72];   at java.net.SocketInputStream.read(SocketInputStream.java:141) ~[na:1.8.0_72];   at sun.security.ssl.InputRecord.readFully(InputRecord.java:465) ~[na:1.8.0_72];   at sun.security.ssl.InputRecord.read(InputRecord.java:503) ~[na:1.8.0_72];   at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973) ~[na:1.8.0_72];   at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930) ~[na:1.8.0_72];   at sun.security.ssl.AppInputStream.read(AppInputStream.java:105) ~[na:1.8.0_72];   at java.io.BufferedInputStream.fill(BufferedInputStream.java:246) ~[na:1.8.0_72];   at java.io.BufferedInputStream.read1(BufferedInputStream.java:286) ~[na:1.8.0_72];   at java.io.BufferedInputStream.read(BufferedInputStream.java:345) ~[na:1.8.0_72];   at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:704) ~[na:1.8.0_72];   at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:647) ~[na:1.8.0_72];   at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1536) ~[na:1.8.0_72];   at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1441) ~[na:1.8.0_72];   at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480) ~[na:1.8.0_72];   at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:338) ~[na:1.8.0_72];   at com.google.api.client.http.javanet.NetHttpResponse.<init>(NetHttpResponse.java:37) ~[cromwell.jar:0.19];   at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:94) ~[cromwell.jar:0.19];   at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:3,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/826:1472,protocol,protocol,1472,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/826,1,['protocol'],['protocol']
Integrability,"q) pipeline and it turns out any `path` or `path+modtime` strategies do not work with containers. As is reported in these issues: #5405, #5370, #5346 . @cmarkello, @illusional, I am sorry that I insisted that `path+modtime` did work. I was using less complex workflows that did not have this problem at the time. ## Call-caching problems with file strategy; The `file` strategy does work as it uses md5sums in order to calculate the file hash. An unfortunate side effect of this is that md5 uses massive system resources. On HPC systems that are the target for the sfs-backend, this is a big problem. Cromwell will be run from a submit node on the system and greedily grab all processing power on the submit node to calculate all the md5sums. . ## Md5sums; Md5sums are reliable hashes for file integrity, but this was not their intended purpose. Md5sum was intended as a cryptographic hash. A cryptographic hash has the following properties (wikipedia):; 1. it is deterministic, meaning that the same message always results in the same hash; 2. it is quick to compute the hash value for any given message; 3. it is infeasible to generate a message that yields a given hash value; 4. it is infeasible to find two different messages with the same hash value; 5. a small change to a message should change the hash value so extensively that the new hash value appears uncorrelated with the old hash value (avalanche effect). I contest point 2, in that many cryptographic explicitly strife for being slow to calculate in order to negate brute force attempts.; Anyway: for call caching we only need points 1. and 4. All the rest is unnecessary ballast. . ## xxHash; Luckily there is a hashing algorithm that is designed explicitly for content hashing only. It was made to generate reliably different hashes for file content as fast as possible. It's called [xxHash](https://www.xxhash.com). There are Java implementations available and I did [some extensive benchmarking](https://github.com/rhpvorderman/has",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5450:1150,message,message,1150,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5450,1,['message'],['message']
Integrability,question : is there docker image for building cromwell ? . with all dependencies installed.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5868:68,depend,dependencies,68,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5868,1,['depend'],['dependencies']
Integrability,"r of VMs so that they won't stay around for 24h for debugging before the holidays. This means that when a VM is preempted it shuts down faster than it used to, and so PAPI may see the shutdown at a different point. > ------------------------------- ; > ferrara@broadinstitute.org <ferrara@broadinstitute.org> #13 Jan 17, 2018 03:08PM ; > So, gdk - will Message 13 - only happen with pre-emptibles? Will a non-preemptible vm that is somehow shutdown also end up getting a Message 13 returned? If so - then how can one tell the difference? I thought Message 14 only happened on pre-emptibles. > ------------------------------- ; > jgentry@broadinstitute.org <jgentry@broadinstitute.org> #14 Jan 17, 2018 03:13PM ; > Hi - ; > ; > In the past we've been told that Message 13 was a generic catch all for ; > something unexpected happening. For instance I'm pretty sure (but don't ; > have data to back this up) that we see 13s when not running a preemptible ; > instance. ; > ; > Cromwell retries both messages, but treats them differently. It will simply ; > retry on a 13, but for preemptibles we will switch from using a preemptible ; > to a standard instance after N preemptions. ; > ; > J ; > ; > ------------------------------- ; > gdk@google.com <gdk@google.com> #15 Jan 17, 2018 05:01PM ; > Hi Henry, Jeff,; > Message 13 can occur with non-preemptible instances as well. In cases where the controller sees an error and exits, if the PAPI servers don't see the instance shutting down then you'll see an error 13 as well.; > ; > I think the solution is to not differentiate your behavior on the content of the returned message, and always retry if the operation is showing as aborted and the instance was preemptible. > ------------------------------- ; > ferrara@broadinstitute.org <ferrara@broadinstitute.org> #16 Jan 18, 2018 07:20AM ; > Can Message 14's occur with non-preemptible instances? Like Message 13s cane?. > ------------------------------- ; > jgentry@broadinstitute.org <jgentry@broadi",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3157:10882,message,messages,10882,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3157,1,['message'],['messages']
Integrability,"r.wdl Ln 3 Col 1) Failed to import https://raw.githubusercontent.com/aofarrel/Stuart-WDL/segment_scatter/segment_scatter.wdl; (https://raw.githubusercontent.com/aofarrel/Stuart-WDL/segment_scatter/segment_scatter.wdl Ln 3 Col 1) Failed to import https://raw.githubusercontent.com/aofarrel/Stuart-WDL/segment_scatter/segment_scatter.wdl; (https://raw.githubusercontent.com/aofarrel/Stuart-WDL/segment_scatter/segment_scatter.wdl Ln 3 Col 1) Failed to import https://raw.githubusercontent.com/aofarrel/Stuart-WDL/segment_scatter/segment_scatter.wdl; (https://raw.githubusercontent.com/aofarrel/Stuart-WDL/segment_scatter/segment_scatter.wdl Ln 3 Col 1) Failed to import https://raw.githubusercontent.com/aofarrel/Stuart-WDL/segment_scatter/segment_scatter.wdl, exceeded import_max_depth; circular imports?; None; ```. ## Backends; * Terra (kind of); * Mac OS on womtool 76; * Ubuntu on womtool 56. I say ""kind of"" for Terra since I can't see the error message -- if you try to upload this workflow to the Broad Methods Repo, a 500 error will result, and I've a hunch that's the result of the stack overflow. ## Example workflow; ```; version 1.0. import ""https://raw.githubusercontent.com/aofarrel/Stuart-WDL/segment_scatter/segment_scatter.wdl""; # note: that workflow also has the line import ""https://raw.githubusercontent.com/aofarrel/Stuart-WDL/segment_scatter/segment_scatter.wdl""; # I meant to actually import ""https://raw.githubusercontent.com/aofarrel/Stuart-WDL/segment_scatter/segfault.wdl"". workflow Segment_Scatter {; 	input {; 		# if you input 10 files and n_segments = 5, each segment gets 2 files; 		Array[File] input_files; 		Int n_segments; 	}. 	call segfault.segfault {; 		input:; 			inputs = input_files,; 			n_segments = n_segments; 	}. 	scatter(segment in segfault.segments) {; 		call echo_files {; 			input:; 				files_to_echo = segment; 		}; 	}; }. task echo_files {; 	input {; 		Array[File] files_to_echo; 	}. 	command <<<; 	python3 << CODE; 	files = [""~{sep='"",""' files_to_echo",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6964:2816,message,message,2816,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6964,1,['message'],['message']
Integrability,"rCell.scala:487); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:238); at akka.dispatch.Mailbox.run(Mailbox.scala:220); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:397); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); [2016-08-08 08:33:09,747] [info] Updating WorkflowManager state. New Data: (4e20eafc-baae-4605-a010-adfa5f32ae46,Actor[akka://cromwell-system/user/WorkflowManagerActor/WorkflowActor-4e20eafc-baae-4605-a010-adfa5f32ae46#-904922324]); [2016-08-08 08:33:09,767] [info] WorkflowActor [←[38;5;2m4e20eafc←[0m]: Start(Some(Actor[akka://cromwell-system/user/SingleWorkflowRunnerActor#576120716])) message received; [2016-08-08 08:33:10,91] [info] WorkflowActor [←[38;5;2m4e20eafc←[0m]: ExecutionStoreCreated(Start(Some(Actor[akka://cromwellsystem/user/SingleWorkflowRunnerActor#576120716]))) message received; [2016-08-08 08:33:10,94] [info] SingleWorkflowRunnerActor: workflow ID ←[38;5;2m4e20eafc-baae-4605-a010-adfa5f32ae46←[0m; [2016-08-08 08:33:10,104] [info] WorkflowActor [←[38;5;2m4e20eafc←[0m]: Beginning transition from Submitted to Running.; [2016-08-08 08:33:10,106] [info] WorkflowActor [←[38;5;2m4e20eafc←[0m]: transitioning from Submitted to Running.; [2016-08-08 08:33:10,111] [info] WorkflowActor [←[38;5;2m4e20eafc←[0m]: starting calls: test.hello; [2016-08-08 08:33:10,111] [info] WorkflowActor [←[38;5;2m4e20eafc←[0m]: persisting status of hello to Starting.; [2016-08-08 08:33:10,121] [←[38;5;220mwarn←[0m] Found unsupported keys for backend 'LOCAL': bootDiskSizeGb, cpu, disks, memory, preemptible, zones; [2016-08-08 08:33:10,251] [info] WorkflowActor [←[38;5;2m4e20eafc←[0m]: inputs for call 'hello': name -> WdlString(String); [2016-08-0",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1261:6155,message,message,6155,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1261,2,['message'],['message']
Integrability,"r[akka://cromwell-system/user/WorkflowManagerActor#-1616857312]] after [5000 ms]; akka.pattern.AskTimeoutException: Ask timed out on [Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312]] after [5000 ms]; at akka.pattern.PromiseActorRef$$anonfun$1.apply$mcV$sp(AskSupport.scala:334); at akka.actor.Scheduler$$anon$7.run(Scheduler.scala:117); at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:599); at scala.concurrent.BatchingExecutor$class.execute(BatchingExecutor.scala:109); at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:597); at akka.actor.LightArrayRevolverScheduler$TaskHolder.executeTask(Scheduler.scala:467); at akka.actor.LightArrayRevolverScheduler$$anon$8.executeBucket$1(Scheduler.scala:419); at akka.actor.LightArrayRevolverScheduler$$anon$8.nextTick(Scheduler.scala:423); at akka.actor.LightArrayRevolverScheduler$$anon$8.run(Scheduler.scala:375); at java.lang.Thread.run(Thread.java:745); [2015-12-18 08:43:19,174] [info] Message [cromwell.engine.workflow.WorkflowManagerActor$RestartWorkflows] from Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] to Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2015-12-18 08:43:19,180] [info] Message [akka.actor.Status$Failure] from Actor[akka://cromwell-system/user/WorkflowManagerActor#-1616857312] to Actor[akka://cromwell-system/deadLetters] was not delivered. [2] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2015-12-18 08:43:19,182] [error] WorkflowManagerActor: Workflow failed submission: cannot create children while terminating or terminated; java.lang.IllegalStateException: cannot create children while t",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/334:2085,Message,Message,2085,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/334,1,['Message'],['Message']
Integrability,"ral scatter-gather blocks. We switched to a separate metadata database to address the Java heap problem that occurs with the in-memory database. We enabled debug logging to try and troubleshoot an unrelated problem. Most of the log output at the increased level is appears to be from HSQL. After running for about 8 hrs, the following error appears in the output and Cromwell hangs:; ```; Exception in thread ""Exec Stream Pumper"" java.lang.OutOfMemoryError: Required array length 2147483639 + 39 is too large; 	at java.base/jdk.internal.util.ArraysSupport.hugeLength(ArraysSupport.java:649); 	at java.base/jdk.internal.util.ArraysSupport.newLength(ArraysSupport.java:642); 	at java.base/java.io.ByteArrayOutputStream.ensureCapacity(ByteArrayOutputStream.java:100); 	at java.base/java.io.ByteArrayOutputStream.write(ByteArrayOutputStream.java:132); 	at org.apache.commons.io.output.ProxyOutputStream.write(ProxyOutputStream.java:92); 	at org.apache.commons.io.output.TeeOutputStream.write(TeeOutputStream.java:68); 	at org.apache.commons.exec.StreamPumper.run(StreamPumper.java:108); 	at java.base/java.lang.Thread.run(Thread.java:1623); ```. We are running Cromwell using Dockstore as a wrapper using the following command:; ```; dockstore workflow launch --local-entry BiobankScrubWorkflow.wdl --json inputs.json > dockstore.log 2>&1 &; ```. At the time the OOME occurs, the size of the dockstore.log file is approx 2147485425 bytes. Based on the ""Saving copy of Cromwell stdout to..."" messages at the end of a successful Cromwell run, it would appear that Cromwell is internally buffering the stdout and stderr streams to save at the end of the run. So when the size of the stdout or stderr exceeds the Java buffer max size, the OOME occurs. The Cromwell configuration we are using is the default with the exception of uncommenting the `database -> metadata` block and updating the docker run command to mount the local GCloud SDK configuration into the container to enable access to GCP resources.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7217:1457,wrap,wrapper,1457,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7217,2,"['message', 'wrap']","['messages', 'wrapper']"
Integrability,"read_json almost never work for me. Here is for instance a json that is totally valid but breaks read_json; ```; {; ""id"" : ""GSM1698568"",; ""gse"" : [; ""GSE69360""; ],; ""title"" : ""Biochain_Adult_Liver"",; ""sampleType"" : ""SRA"",; ""organism"" : {; ""name"" : ""Homo sapiens"",; ""taxid"" : ""9606""; },; ""sequencer"" : ""Illumina HiSeq 2000"",; ""characteristics"" : {; ""number of donors"" : ""1"",; ""age"" : ""64 years old"",; ""tissue"" : ""Liver"",; ""vendor"" : ""Biochain"",; ""isolate"" : ""Lot no.: B510092"",; ""gender"" : ""Male""; },; ""library"" : {; ""strategy"" : ""RNA-Seq"",; ""selection"" : ""cDNA"",; ""source"" : ""transcriptomic""; },; ""extraction"" : {; ""source"" : ""Biochain Adult Liver"",; ""molecule"" : ""total RNA"",; ""protocol"" : ""2 different fetal normal tissues and 6 different adult normal tissues were purchased from different sources (Agilent, Biochain and OriGene). The qualities of these total RNA were tested using the Agilent Bioanalyzer 2100 Eukaryote Total RNA Nano Series II. Only total RNAs with a RIN score of more than 7 were used for RNA-Seq library construction\nRibosomal RNA (rRNA) was removed from total RNA using the RiboMinus™ Eukaryote Kit for RNA-Seq from Ambion. The ribosomal RNA depleted RNA fraction is termed the RiboMinus™ RNA fraction and is enriched in polyadenylated (polyA) mRNA, non-polyadenylated RNA, pre-processed RNA, tRNA, and may also contain regulatory RNA molecules such as microRNA (miRNA) and short interfering RNA (siRNA), snRNA, and other RNA transcripts of yet unknown function. Ambion RiboMinus rRNA depletion was performed as described in the manufacturer’s protocol (Pub. Part no.: 100004590, Rev. date 2 December 2011) following the standard protocol.\nTruSeq RNA Sample Preparation was performed on the RiboMinus™ RNA fraction as described in the manufacturer’s protocol (Pub. Part no.: 15026495 Rev. F March 2014) following the low sample protocol.\nThe libraries were sequenced on Illumina’s HiSeq 2000 instrument following standard protocol."",; ""processing"" : ""Data quality check usin",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4519:679,protocol,protocol,679,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4519,1,['protocol'],['protocol']
Integrability,ream.read(SocketInputStream.java:141) ~[na:1.8.0_72]; at sun.security.ssl.InputRecord.readFully(InputRecord.java:465) ~[na:1.8.0_72]; at sun.security.ssl.InputRecord.read(InputRecord.java:503) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973) ~[na:1.8.0_72]; at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930) ~[na:1.8.0_72]; at sun.security.ssl.AppInputStream.read(AppInputStream.java:105) ~[na:1.8.0_72]; at java.io.BufferedInputStream.fill(BufferedInputStream.java:246) ~[na:1.8.0_72]; at java.io.BufferedInputStream.read1(BufferedInputStream.java:286) ~[na:1.8.0_72]; at java.io.BufferedInputStream.read(BufferedInputStream.java:345) ~[na:1.8.0_72]; at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:704) ~[na:1.8.0_72]; at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:647) ~[na:1.8.0_72]; at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1536) ~[na:1.8.0_72]; at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1441) ~[na:1.8.0_72]; at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480) ~[na:1.8.0_72]; at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:338) ~[na:1.8.0_72]; at com.google.api.client.http.javanet.NetHttpResponse.<init>(NetHttpResponse.java:37) ~[cromwell.jar:0.19]; at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:94) ~[cromwell.jar:0.19]; at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.media.MediaHttpUploader.executeCurrentRequestWithoutGZip(MediaHttpUploader.java:545) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.media.MediaHttpUploader.executeCurrentRequest(MediaHttpUploader.java:562) ~[cromwell.jar:0.19]; at com.google.api.client.googleapis.media.MediaHttpUploader.resumableUpload(MediaHttpUploader.java:419) ~[cromwell.jar:0.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/932:3223,protocol,protocol,3223,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/932,1,['protocol'],['protocol']
Integrability,"rectory; input_dir: fastqc_execute/output_directory; out: [output_directory]; <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->. at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: scala.NotImplementedError: This should not happen, please report this; at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:281); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$pollStatusAsync$1(StandardAsyncExecutionActor.scala:691); at scala.util.Try$.apply(Try.scala:209); ... 25 more. <!-- SLURM backend configuration -->; include required(classpath(""application"")). backend {; default = SLURM. providers {; SLURM {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; runtime-attributes = """"""; Int runtime_minutes = 600; Int cpus = 2; Int requested_memory_mb_per_core = 8000; String queue = ""cpu""; """""". # If an 'exit-code-timeout-seconds' value is specified:; # - When a job has not been alive for longer than this timeout; # - And has still not produced an RC file; # - Then it will be marked as Failed.; # Warning: If set, Cromwell has to run 'check-alive' for every job at regular intervals (unrelated to this timeout). # exit-code-timeout-seconds = 120. submit = """"""; sbatch -J ${job_name} -D ${cwd} -o ${out} -e ${err} -t ${runtime_minutes} -p ${queue} \; ${""-n "" + cpus} \; --mem-per-cpu=${requested_memory_mb_per_core} \; --wrap ""/usr/bin/env bash ${script}""; """"""; kill = ""scancel ${job_id}""; check-alive = ""squeue -j ${job_id}""; job-id-regex = ""Submitted batch job (\\d+).*""; }; }; }; }",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4560:2681,wrap,wrap,2681,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560,1,['wrap'],['wrap']
Integrability,"rent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); [2016-10-27 13:10:57,94] [info] Waiting for 1 workflows to abort...; [2016-10-27 13:10:58,94] [info] Waiting for 1 workflows to abort...; [2016-10-27 13:10:59,94] [info] Waiting for 1 workflows to abort...; [2016-10-27 13:11:00,94] [info] Waiting for 1 workflows to abort...; [2016-10-27 13:11:01,94] [info] Waiting for 1 workflows to abort...; [2016-10-27 13:11:02,95] [info] Waiting for 1 workflows to abort...; [2016-10-27 13:11:03,95] [info] Waiting for 1 workflows to abort...; [2016-10-27 13:11:04,95] [info] Waiting for 1 workflows to abort...; [2016-10-27 13:11:05,57] [error] Exception not convertible into handled response; com.google.api.client.googleapis.json.GoogleJsonResponseException: 404 Not Found; {; ""code"" : 404,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Not Found"",; ""reason"" : ""notFound""; } ],; ""message"" : ""Not Found""; }; at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145); at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113); at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:432); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469); at com.google.cloud.hadoop.util.AbstractGoogleAsyncWriteChannel$UploadOperation.call(AbstractGoogleAsyncWriteChannel.java:357); at jav",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1631:19539,message,message,19539,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1631,2,['message'],['message']
Integrability,repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/92f43ce5f010fa03daeb2625a3f9c1b1be80cca5/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Files still referring to the old version number</summary>. The following files still refer to the old version number (0.13.0).; You might want to review and update them manually.; ```; centaur/src/main/resources/integrationTestCases/cwl/bcbio/gvcf-joint-workflow/steps/process_alignment.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/gvcf-joint-workflow/steps/variantcall_batch_region.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/prealign-workflow/steps/variantcall_batch_region.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/rnaseq-workflow/steps/prepare_sample.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/somatic-workflow/steps/detect_sv.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/somatic-workflow/steps/process_alignment.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/somatic-workflow/steps/variantcall_batch_region.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/svcall-workflow/steps/detect_sv.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/svcall-workflow/steps/process_alignment.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/svcall-workflow/steps/variantcall_batch_region.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/wes_chr21_test-workflow-gcp/steps/detect_sv.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/wes_chr21_test-workflow-gcp/steps/process_alignment.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/wes_chr21_test-workflow-gcp/steps/variantcall_batch_region.cwl; ```; </details>; <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore ,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6410:1927,integrat,integrationTestCases,1927,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6410,1,['integrat'],['integrationTestCases']
Integrability,reword Cache Hit Message,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1470:17,Message,Message,17,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1470,1,['Message'],['Message']
Integrability,"ridge, MA 02142; Ph: 617-714-7905; Cell: 210-274-3172. ---. @scottfrazer commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200514792). I'm hesitant to try to follow the same rules as Bash for parsing a command because I worry that it'll be error prone and difficult to pin down the details. It feels like we'd essentially reimplement a Bash parser in WDL. It'd be difficult and hard to get the nuances of something like this:. ```; command {; python <<CODE; print(""#octothorps!!#""); CODE; }; ```. Maybe something as simple as syntax highlighting could help too... if `#`s are not highlighted differently in the command section then that could also be a hint. Granted, I know syntax highlighters won't always be used. ---. @eddiebroad commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200525363). If it's clear to WDL users how # is interpreted (or not interpreted) in the; command-block maybe that would be the best thing? Would a sentence/blurb; in the docs address this? Possibly as mentioned earlier good error; messages?. -eddie. On Wed, Mar 23, 2016 at 3:43 PM, Scott Frazer notifications@github.com; wrote:. > I'm hesitant to try to follow the same rules as Bash for parsing a command; > because I worry that it'll be error prone and difficult to pin down the; > details. It feels like we'd essentially reimplement a Bash parser in WDL.; > It'd be difficult and hard to get the nuances of something like this:; > ; > command {; > python <<CODE; > print(""#octothorps!!#""); > CODE; > }; > ; > Maybe something as simple as syntax highlighting could help too... if #s; > are not highlighted differently in the command section then that could also; > be a hint. Granted, I know syntax highlighters won't always be used.; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly or view it on GitHub; > https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200514",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2870:7686,message,messages,7686,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2870,1,['message'],['messages']
Integrability,"rkflowDefinition(WdlWorkflow.scala:52)""; },; {; causedBy: [ ],; message: ""wdl.WdlWorkflow.womDefinition$lzycompute(WdlWorkflow.scala:73)""; },; {; causedBy: [ ],; message: ""wdl.WdlWorkflow.womDefinition(WdlWorkflow.scala:73)""; },; {; causedBy: [ ],; message: ""wdl.WdlInputParsing$.buildWomExecutable(WdlInputParsing.scala:27)""; },; {; causedBy: [ ],; message: ""wdl.WdlNamespaceWithWorkflow.womExecutable(WdlNamespace.scala:98)""; },; {; causedBy: [ ],; message: ""cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.$anonfun$validateWdlNamespace$15(MaterializeWorkflowDescriptorActor.scala:493)""; },; {; causedBy: [ ],; message: ""scala.util.Either.flatMap(Either.scala:338)""; },; {; causedBy: [ ],; message: ""cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.$anonfun$validateWdlNamespace$13(MaterializeWorkflowDescriptorActor.scala:491)""; },; {; causedBy: [ ],; message: ""scala.util.Either.flatMap(Either.scala:338)""; },; {; causedBy: [ ],; message: ""cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.validateWdlNamespace(MaterializeWorkflowDescriptorActor.scala:490)""; },; {; causedBy: [ ],; message: ""cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$lifecycle$materialization$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor(MaterializeWorkflowDescriptorActor.scala:231)""; },; {; causedBy: [ ],; message: ""cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$1.$anonfun$applyOrElse$1(MaterializeWorkflowDescriptorActor.scala:157)""; },; {; causedBy: [ ],; message: ""scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:304)""; },; {; causedBy: [ ],; message: ""scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37)""; },; {; causedBy: [ ],; message: ""scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60)""; },; {; causedBy: [ ],; message: ""akka.dispatch.B",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3143:1808,message,message,1808,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3143,1,['message'],['message']
Integrability,"rovided in https://github.com/aws-samples/aws-genomics-workflows/blob/master/src/templates/cromwell/cromwell-aio.template.yaml. ; In summary, the set up is a EC2 instance running `java -jar cromwell.jar server` and calling AWS Batch to run WDL workflow using an attached EC2 instance profile. . I have no issue posting workflows and getting results. However, after a certain period of time, I will get `The security token included in the request is expired` error message logged by the cromwell server when I try to post a job. ; - I have checked that `~/.aws` and the AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY environment variable don't exist. ; - If I kill the server and restart it again, the server seem to pick up the new security token and I can post workflow again. ; - Checking `cromwell.config` (pasted below), all authentication methods are set to `default` which is documented to mean it is using `DefaultCredentialProvider` in the AWS Java SDK. That should be refreshing the security token? . Is this unexpected behaviour or did I configure something wrongly? . Thanks for your help!. ----. Config file for the cromwell serve:; ```; include required(classpath(""application"")). webservice {; interface = localhost; port = 8000; }. system {; job-rate-control {; jobs = 1; per = 2 second; }; }. aws {; application-name = ""cromwell""; auths = [{; name = ""default""; scheme = ""default""; }]; region = ""ap-southeast-2""; }. engine { filesystems { s3 { auth = ""default"" } } }. backend {; default = ""AWSBATCH""; providers {; AWSBATCH {; actor-factory = ""cromwell.backend.impl.aws.AwsBatchBackendLifecycleActorFactory""; config {; numSubmitAttempts = 10; numCreateDefinitionAttempts = 10; root = ""XXXX""; auth = ""default""; default-runtime-attributes { queueArn = ""XXXXX"" }; filesystems { s3 { auth = ""default"" } }; }; }; }; }; workflow-options {; workflow-log-dir = ""cromwell-workflow-logs""; workflow-log-temporary = false; }. call-caching {; enabled = true; invalidate-bad-cache-results = true; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5162:1317,interface,interface,1317,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5162,1,['interface'],['interface']
Integrability,"rows in exception testing</li>; <li><a href=""https://github.com/junit-team/junit4/commit/543905df72ff10364b94dda27552efebf3dd04e9""><code>543905d</code></a> Use separate line for annotation in Javadoc</li>; <li><a href=""https://github.com/junit-team/junit4/commit/510e906b391e7e46a346e1c852416dc7be934944""><code>510e906</code></a> Add sub headlines to class Javadoc</li>; <li><a href=""https://github.com/junit-team/junit4/commit/610155b8c22138329f0723eec22521627dbc52ae""><code>610155b</code></a> Merge pull request from GHSA-269g-pwp5-87pp</li>; <li><a href=""https://github.com/junit-team/junit4/commit/b6cfd1e3d736cc2106242a8be799615b472c7fec""><code>b6cfd1e</code></a> Explicitly wrap float parameter for consistency (<a href=""https://github-redirect.dependabot.com/junit-team/junit4/issues/1671"">#1671</a>)</li>; <li><a href=""https://github.com/junit-team/junit4/commit/a5d205c7956dbed302b3bb5ecde5ba4299f0b646""><code>a5d205c</code></a> Fix GitHub link in FAQ (<a href=""https://github-redirect.dependabot.com/junit-team/junit4/issues/1672"">#1672</a>)</li>; <li><a href=""https://github.com/junit-team/junit4/commit/3a5c6b4d08f408c8ca6a8e0bae71a9bc5a8f97e8""><code>3a5c6b4</code></a> Deprecated since jdk9 replacing constructor instance of Double and Float (<a href=""https://github-redirect.dependabot.com/junit-team/junit4/issues/1660"">#1660</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/junit-team/junit4/compare/r4.13...r4.13.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=junit:junit&package-manager=maven&previous-version=4.13&new-version=4.13.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/configuring-github-dependabot-security-updates). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (depend",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5941:3326,depend,dependabot,3326,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5941,1,['depend'],['dependabot']
Integrability,"rts to release 24 server intermittently gives errors in the logs. A simple workflow: ; `cat goodImport.wdl`:. ```; import ""bar.wdl"" as doIt. workflow testMe {; 	call doIt.doIt; }; ```; And a bunch of wdl tasks in a folder, only one of which is the actual dependency (`bar.wdl`); ```; conradL@qimr13054 ~]$ unzip -l foo.zip ; Archive: foo.zip; Length Date Time Name; --------- ---------- ----- ----; 0 02-07-2017 14:46 foo/; 99 02-07-2017 14:45 foo/bar7.wdl; 98 02-07-2017 14:00 foo/bar.wdl; 99 02-07-2017 14:46 foo/bar8.wdl; 99 02-07-2017 14:45 foo/bar2.wdl; 100 02-07-2017 14:45 foo/bar10.wdl; 99 02-07-2017 14:46 foo/bar9.wdl; 99 02-07-2017 14:45 foo/bar1.wdl; 99 02-07-2017 14:45 foo/bar3.wdl; 99 02-07-2017 14:45 foo/bar5.wdl; 99 02-07-2017 14:45 foo/bar4.wdl; 99 02-07-2017 14:45 foo/bar6.wdl; --------- -------; 1089 12 files; ```. The content of all the task dependencies is just a variation on:; ```; [conradL@qimr13054 ~]$ cat foo/bar.wdl ; task doIt {; 	command { echo ""Help, world!"" }; 	output { String message = read_string(stdout()) }; }; ```. Submit to the server:; ```; curl http://localhost:8000/api/workflows/V1 -FwdlSource=@goodImport.wdl -FwdlDependencies=@foo.zip; ```. Now tailing the server logs, the first time this is submitted, the workflow succeeds and the log shows nothing out of the ordinary. But ""sometimes"" (meaning, I can submit it 5 times and not see it, or twice and see it both times) I see this:; ```; 2017-02-07 15:01:10,781 cromwell-system-akka.dispatchers.service-dispatcher-30 ERROR - Sending Actor[akka://cromwell-system/user/cromwell-service/WorkflowManagerActor/WorkflowActor-84a51727-cfda-41e7-a03c-9e3af35eb0dc/MaterializeWorkflowDescriptorActor#972983209] failure message MetadataPutFailed(PutMetadataAction(Stream(MetadataEvent(MetadataKey(84a51727-cfda-41e7-a03c-9e3af35eb0dc,None,submittedFiles:imports:bar6.wdl),Some(MetadataValue(task doIt6 {; 	command { echo ""Help, world!"" }; 	output { String message = read_string(stdout()) }; },MetadataString)),",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1959:1066,message,message,1066,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1959,1,['message'],['message']
Integrability,runtime attribute override behavior depends upon variable name,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2068:36,depend,depends,36,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2068,1,['depend'],['depends']
Integrability,"s the error more precisely in `handleGoogleError`. I tested this by deliberately breaking the request so it always gets a `400` back. With the existing code, the log looks just like what we see in prod:. ```; 2023-11-01 19:54:12 cromwell-system-akka.dispatchers.backend-dispatcher-91 WARN - PAPI request worker had 2 failures making 5 requests: ; 400 Bad Request; POST https://lifesciences.googleapis.com/v2beta/projects/1005074806481/locations/us-central1/operations/6175597626605185257:cancel; {; ""code"": 400,; ""errors"": [; {; ""domain"": ""global"",; ""message"": ""Invalid JSON payload received. Unexpected token.\nasdf\n^ Payload appears to be compressed. It may either be corrupt or uncompressed data may be too large for the server to handle."",; ""reason"": ""parseError""; }; ],; ""message"": ""Invalid JSON payload received. Unexpected token.\nasdf\n^ Payload appears to be compressed. It may either be corrupt or uncompressed data may be too large for the server to handle."",; ""status"": ""INVALID_ARGUMENT""; }; ```. <img width=""1238"" alt=""Screenshot 2023-11-01 at 15 43 59"" src=""https://github.com/broadinstitute/cromwell/assets/1087943/63e4e788-517f-4f1e-a4ff-4075cec3e6d3"">. ---. Changing `throwExceptionOnExecuteError` to `false`, we see that we no longer throw an exception and we get the expected ""no longer running"" message in the log!. ```; 2023-11-01 19:57:48 cromwell-system-akka.dispatchers.backend-dispatcher-162 INFO - PAPI declined to abort job projects/1005074806481/locations/us-central1/operations/5250112889402522122 in workflow b70eafc9-66a7-4b22-b9bc-621c22b5a4ed, most likely because it is no longer running. Marking as finished. Message: Invalid JSON payload received. Unexpected token.; asdf; ^ Payload appears to be compressed. It may either be corrupt or uncompressed data may be too large for the server to handle.; ```. <img width=""1239"" alt=""Screenshot 2023-11-01 at 15 45 48"" src=""https://github.com/broadinstitute/cromwell/assets/1087943/5ce424c4-c3e0-4ffc-b078-f46e065da586"">",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7245:1432,message,message,1432,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7245,2,"['Message', 'message']","['Message', 'message']"
Integrability,"s/71697449:; > ------------------------------- ; > ferrara@broadinstitute.org <ferrara@broadinstitute.org> #1 Jan 8, 2018 09:25AM ; > Reported Issue; > I don't have specific numbers at this time, but over the past several weeks our production operations staff started noticing an odd behavior that we originally thought was just normal preemption. Normally we see preemption showing up as ""Error code 10: Message 14:"" - and cromwell takes care of re-submitting and following the logic coded in our WDLs. Try pre-emptibles 3 times then try a non-preemptible instance. ; > ; > cromwell metadata output:; > ; > ""message"": ""Task PairedEndSingleSampleWorkflow.SamToFastqAndBwaMemAndMba:1:1 failed. JES error code 10. Task 417bb61c-16cc-4fda-91d5-443ccba4da11:SamToFastqAndBwaMemAndMba was preempted for the 1st time. The call will be restarted with another preemptible VM (max preemptible attempts number is 3). Error code Status{code=ABORTED, description=null, cause=null}. Message: 14: VM ggp-15030877962490231612 stopped unexpectedly.""; > ; > However we have seen a new error response. ""Error code 10: Message 13"" metadata output showing:; > ; > ""message"": ""Task PairedEndSingleSampleWorkflow.HaplotypeCaller:46:3 failed. JES error code 10. Message: 13: VM ggp-9289873678241352278 shut down unexpectedly.""; > ; > From what Cromwell team indicates is that ""Message 13"" is not the same as Message 14 - as such a different logic occurs within cromwell. Cromwell will try the task three times and after that it will just ""Fail"" the task. So the ""try 3 pre-emptible then try non-preemptible"" logic is never followed.; > ; > So my question is what is ""Message 13"" and how is it different from ""Message 14""? Below are OpsIDs for a set of tasks - the first are the ""Message 14"" (which again are normal preemption but I wanted to provide some for comparison to Message 13) and the second list are the ""Message 13"". This is just a small sample of Message 13 failures.; > ; > MESSAGE 14: ; > operations/ENWy-aWLLBi",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3157:1066,Message,Message,1066,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3157,1,['Message'],['Message']
Integrability,"s: [; {; causedBy: [; {; causedBy: [ ],; message: ""This workflow contains a cyclic dependency on SomaticPairedEndSingleSampleWorkflow.$scatter_2""; },; {; causedBy: [ ],; message: ""wdl.Scope.childGraphNodesSorted(Scope.scala:52)""; },; {; causedBy: [ ],; message: ""wdl.Scope.childGraphNodesSorted$(Scope.scala:43)""; },; {; causedBy: [ ],; message: ""wdl.WdlWorkflow.childGraphNodesSorted$lzycompute(WdlWorkflow.scala:63)""; },; {; causedBy: [ ],; message: ""wdl.WdlWorkflow.childGraphNodesSorted(WdlWorkflow.scala:63)""; },; {; causedBy: [ ],; message: ""wdl.WdlGraphNode$.buildWomGraph(WdlGraphNode.scala:140)""; },; {; causedBy: [ ],; message: ""wdl.WdlWorkflow$.womWorkflowDefinition(WdlWorkflow.scala:52)""; },; {; causedBy: [ ],; message: ""wdl.WdlWorkflow.womDefinition$lzycompute(WdlWorkflow.scala:73)""; },; {; causedBy: [ ],; message: ""wdl.WdlWorkflow.womDefinition(WdlWorkflow.scala:73)""; },; {; causedBy: [ ],; message: ""wdl.WdlInputParsing$.buildWomExecutable(WdlInputParsing.scala:27)""; },; {; causedBy: [ ],; message: ""wdl.WdlNamespaceWithWorkflow.womExecutable(WdlNamespace.scala:98)""; },; {; causedBy: [ ],; message: ""cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.$anonfun$validateWdlNamespace$15(MaterializeWorkflowDescriptorActor.scala:493)""; },; {; causedBy: [ ],; message: ""scala.util.Either.flatMap(Either.scala:338)""; },; {; causedBy: [ ],; message: ""cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.$anonfun$validateWdlNamespace$13(MaterializeWorkflowDescriptorActor.scala:491)""; },; {; causedBy: [ ],; message: ""scala.util.Either.flatMap(Either.scala:338)""; },; {; causedBy: [ ],; message: ""cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.validateWdlNamespace(MaterializeWorkflowDescriptorActor.scala:490)""; },; {; causedBy: [ ],; message: ""cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$lifecycle$materializat",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3143:1149,message,message,1149,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3143,1,['message'],['message']
Integrability,"s</a>.</em></p>; <blockquote>; <h2>JUnit 4.13.1</h2>; <p>Please refer to the <a href=""https://github.com/junit-team/junit/blob/HEAD/doc/ReleaseNotes4.13.1.md"">release notes</a> for details.</p>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/junit-team/junit4/blob/main/doc/ReleaseNotes4.13.1.md"">junit's changelog</a>.</em></p>; <blockquote>; <h2>Summary of changes in version 4.13.1</h2>; <h1>Rules</h1>; <h3>Security fix: <code>TemporaryFolder</code> now limits access to temporary folders on Java 1.7 or later</h3>; <p>A local information disclosure vulnerability in <code>TemporaryFolder</code> has been fixed. See the published <a href=""https://github.com/junit-team/junit4/security/advisories/GHSA-269g-pwp5-87pp"">security advisory</a> for details.</p>; <h1>Test Runners</h1>; <h3>[Pull request <a href=""https://github-redirect.dependabot.com/junit-team/junit4/issues/1669"">#1669</a>:](<a href=""https://github-redirect.dependabot.com/junit-team/junit/pull/1669"">junit-team/junit#1669</a>) Make <code>FrameworkField</code> constructor public</h3>; <p>Prior to this change, custom runners could make <code>FrameworkMethod</code> instances, but not <code>FrameworkField</code> instances. This small change allows for both now, because <code>FrameworkField</code>'s constructor has been promoted from package-private to public.</p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/junit-team/junit4/commit/1b683f4ec07bcfa40149f086d32240f805487e66""><code>1b683f4</code></a> [maven-release-plugin] prepare release r4.13.1</li>; <li><a href=""https://github.com/junit-team/junit4/commit/ce6ce3aadc070db2902698fe0d3dc6729cd631f2""><code>ce6ce3a</code></a> Draft 4.13.1 release notes</li>; <li><a href=""https://github.com/junit-team/junit4/commit/c29dd8239d6b353e699397eb090a1fd27411fa24""><code>c29dd82</code></a> Change version to 4.13.1-SNAPSHOT</li>; <li><a href=""https://githu",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5941:1205,depend,dependabot,1205,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5941,1,['depend'],['dependabot']
Integrability,"sage, does this mean that my cache calls are failing.; we using the singularity method of task execution; ```; cromwell-system-akka.dispatchers.engine-dispatcher-27 WARN - BackendPreparationActor_for_bcfd9d26:UnmappedBamToAlignedBam.SamToFastqAndBwaMemAndMba:14:1 [UUID(bcfd9d26)]: Docker lookup failed; cala:35); ```. How do I set it up to enable caching calls?. ------------------------------------------------------------------------------------------; running file; ```; java -jar -Ddocker.hash-lookup.method=local -Ddocker.hash-lookup.enabled=true -Dwebservice.port=8088 -Dwebservice.interface=0.0.0.0 -Dconfig.file=/work/share/ac7m4df1o5/bin/cromwell/3_config/cromwellslurmsingularitynew.conf ./cromwell-84.jar server. ```; config ; ```; # This line is required. It pulls in default overrides from the embedded cromwell; # `reference.conf` (in core/src/main/resources) needed for proper performance of cromwell.; include required(classpath(""application"")). # Cromwell HTTP server settings; webservice {; #port = 8000; #interface = 0.0.0.0; #binding-timeout = 5s; #instance.name = ""reference""; }; call-caching {; enabled = true; invalidate-bad-cache-results = true; }. # Cromwell ""system"" settings; system {; # If 'true', a SIGINT will trigger Cromwell to attempt to abort all currently running jobs before exiting; #abort-jobs-on-terminate = false. # this tells Cromwell to retry the task with Nx memory when it sees either OutOfMemoryError or Killed in the stderr file.; memory-retry-error-keys = [""OutOfMemory"", ""Out Of Memory"",""Out of memory""]; # If 'true', a SIGTERM or SIGINT will trigger Cromwell to attempt to gracefully shutdown in server mode,; # in particular clearing up all queued database writes before letting the JVM shut down.; # The shutdown is a multi-phase process, each phase having its own configurable timeout. See the Dev Wiki for more details.; #graceful-server-shutdown = true. # Cromwell will cap the number of running workflows at N; #max-concurrent-workflows = 5000. ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6933:1104,interface,interface,1104,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6933,1,['interface'],['interface']
Integrability,sbt 0.13.16 tells us good info about our dependency issues,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2605:41,depend,dependency,41,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2605,1,['depend'],['dependency']
Integrability,"sbt.std.Transform$$anon$4.work(System.scala:67) at sbt.Execute.$anonfun$submit$2(Execute.scala:269) at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16) at sbt.Execute.work(Execute.scala:278) at sbt.Execute.$anonfun$submit$1(Execute.scala:269) at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:178) at sbt.CompletionService$$anon$2.call(CompletionService.scala:37) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) at java.util.concurrent.FutureTask.run(FutureTask.java:266) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748) Cause: akka.pattern.AskTimeoutException: Ask timed out on [Actor[akka://test-system-6/user/$l#-102797778]] after [30000 ms]. Sender[Actor[akka://test-system-6/system/testActor-24#-1294021439]] sent message of type ""cromwell.engine.workflow.SingleWorkflowRunnerActor$RunWorkflow$"". at akka.pattern.PromiseActorRef$.$anonfun$defaultOnTimeout$1(AskSupport.scala:596) at akka.pattern.PromiseActorRef$.$anonfun$apply$1(AskSupport.scala:606) at akka.actor.Scheduler$$anon$4.run(Scheduler.scala:205) at scala.concurrent.Future$InternalCallbackExecutor$.unbatchedExecute(Future.scala:870) at scala.concurrent.BatchingExecutor.execute(BatchingExecutor.scala:109) at scala.concurrent.BatchingExecutor.execute$(BatchingExecutor.scala:103) at scala.concurrent.Future$InternalCallbackExecutor$.execute(Future.scala:868) at akka.actor.LightArrayRevolverScheduler$TaskHolder.executeTask(LightArrayRevolverScheduler.scala:328) at akka.actor.LightArrayRevolverScheduler$$anon$4.executeBucket$1(LightArrayRevolverScheduler.scala:279) at akka.actor.LightArrayRevolverScheduler$$anon$4.nextTick(LightArrayRevolverScheduler.scala:283) at akka.actor.LightArrayRevolverScheduler$$anon$4.run(LightA",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4350:6446,message,message,6446,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4350,1,['message'],['message']
Integrability,"scala:43)""; },; {; causedBy: [ ],; message: ""wdl.WdlWorkflow.childGraphNodesSorted$lzycompute(WdlWorkflow.scala:63)""; },; {; causedBy: [ ],; message: ""wdl.WdlWorkflow.childGraphNodesSorted(WdlWorkflow.scala:63)""; },; {; causedBy: [ ],; message: ""wdl.WdlGraphNode$.buildWomGraph(WdlGraphNode.scala:140)""; },; {; causedBy: [ ],; message: ""wdl.WdlWorkflow$.womWorkflowDefinition(WdlWorkflow.scala:52)""; },; {; causedBy: [ ],; message: ""wdl.WdlWorkflow.womDefinition$lzycompute(WdlWorkflow.scala:73)""; },; {; causedBy: [ ],; message: ""wdl.WdlWorkflow.womDefinition(WdlWorkflow.scala:73)""; },; {; causedBy: [ ],; message: ""wdl.WdlInputParsing$.buildWomExecutable(WdlInputParsing.scala:27)""; },; {; causedBy: [ ],; message: ""wdl.WdlNamespaceWithWorkflow.womExecutable(WdlNamespace.scala:98)""; },; {; causedBy: [ ],; message: ""cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.$anonfun$validateWdlNamespace$15(MaterializeWorkflowDescriptorActor.scala:493)""; },; {; causedBy: [ ],; message: ""scala.util.Either.flatMap(Either.scala:338)""; },; {; causedBy: [ ],; message: ""cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.$anonfun$validateWdlNamespace$13(MaterializeWorkflowDescriptorActor.scala:491)""; },; {; causedBy: [ ],; message: ""scala.util.Either.flatMap(Either.scala:338)""; },; {; causedBy: [ ],; message: ""cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.validateWdlNamespace(MaterializeWorkflowDescriptorActor.scala:490)""; },; {; causedBy: [ ],; message: ""cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$lifecycle$materialization$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor(MaterializeWorkflowDescriptorActor.scala:231)""; },; {; causedBy: [ ],; message: ""cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$1.$anonfun$applyOrElse$1(MaterializeWorkflowDescriptorActor.s",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3143:1450,message,message,1450,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3143,1,['message'],['message']
Integrability,scala:91); 	at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); 	at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72); 	at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); 	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: java.util.NoSuchElementException; 	at java.util.ArrayList$Itr.next(ArrayList.java:854); 	at scala.collection.convert.Wrappers$JIteratorWrapper.next(Wrappers.scala:43); 	at scala.collection.IterableLike$class.head(IterableLike.scala:107); 	at scala.collection.AbstractIterable.head(Iterable.scala:54); 	at cromwell.backend.impl.aws.AwsAsyncJobExecutionActor.execute(AwsAsyncJobExecutionActor.scala:53); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$executeAsync$1.apply(StandardAsyncExecutionActor.scala:242); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$executeAsync$1.apply(StandardAsyncExecutionActor.scala:242); 	at scala.util.Try$.apply(Try.scala:192); 	at cromwell.backend.standard.StandardAsyncExecutionActor$class.executeAsync(StandardAsyncExecutionActor.scala:242); 	at cromwell.backend.impl.aws.AwsAsyncJobExecutionActor.executeAsync(AwsAsyncJobExecutionActor.scala:23); 	at cromwell.backend.standard.StandardAsyncExecutionActor$class.executeOrRecover(StandardAsyncExecutionActor.scala:502); 	at cromwell.backend.impl.aws.AwsAsyncJobExecutionActor.executeOrRecover(AwsAsyncJobEx,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1966:1875,Wrap,Wrappers,1875,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1966,1,['Wrap'],['Wrappers']
Integrability,set aws default region in integration tests,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4326:26,integrat,integration,26,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4326,1,['integrat'],['integration']
Integrability,"shared file system or a network file system when running a spark job in the spark standalone cluster mode. This implementation takes a wdl with the backend configuration specified as ""Spark"" and then generates the appropriate spark commands and monitoring process to ensure the job runs to completion. Meaning, details of the spark internals are completely abstracted from the user provided backends with different configurations containing different flavours of { master and deployMode } combinations are already set. Internally, we create a bash script containing a spark-submit (depending on the backend flavour selected at runtime) command using all the specified wdl runtime attributes which is then executed by Spark.  . Current deploy modes supported for any spark job:;   a - Client deploy mode using the spark standalone cluster manager;   b - Cluster deploy mode using the spark standalone cluster manager;   c - Client deploy mode using Yarn resource manager;   d - Cluster deploy mode using Yarn resource manager;   ; Future PR Plans:;   In this PR, the hadoop file system cannot be used as an input/output for the SBE because the Cromwell engine does not identify the protocol, and this results in the hdfs path being localized (soft-link, hard-link or copied).;   This is not a problem until the SBE tries to evaluate the output after a successful execution, and because it cannot interpret the protocol, it tries to look for an hdfs output locally which results in an error. Note: This is only the case when the spark job writes the output to an hdfs location. Then cromwell cannot find the output file for evaluation.   In the near **Future**, we plan to provide an hdfs client similar to that of the gcs to add support for the hdfs, primarily because hdfs is spark's natural file system.;   Note that this doesn't actually prevent spark from writing to the hdfs, in order words, the spark application can write or read from the hdfs if given hdfs locations as arguments. Reason for r",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1339:1419,protocol,protocol,1419,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1339,1,['protocol'],['protocol']
Integrability,"simply when PAPI notices that the VM has been shut down. They mean essentially the same thing, and cromwell should be able to retry with the same logic.; > ; > It looks like this might have been exacerbated because changed the shutdown behavior of VMs so that they won't stay around for 24h for debugging before the holidays. This means that when a VM is preempted it shuts down faster than it used to, and so PAPI may see the shutdown at a different point. > ------------------------------- ; > ferrara@broadinstitute.org <ferrara@broadinstitute.org> #13 Jan 17, 2018 03:08PM ; > So, gdk - will Message 13 - only happen with pre-emptibles? Will a non-preemptible vm that is somehow shutdown also end up getting a Message 13 returned? If so - then how can one tell the difference? I thought Message 14 only happened on pre-emptibles. > ------------------------------- ; > jgentry@broadinstitute.org <jgentry@broadinstitute.org> #14 Jan 17, 2018 03:13PM ; > Hi - ; > ; > In the past we've been told that Message 13 was a generic catch all for ; > something unexpected happening. For instance I'm pretty sure (but don't ; > have data to back this up) that we see 13s when not running a preemptible ; > instance. ; > ; > Cromwell retries both messages, but treats them differently. It will simply ; > retry on a 13, but for preemptibles we will switch from using a preemptible ; > to a standard instance after N preemptions. ; > ; > J ; > ; > ------------------------------- ; > gdk@google.com <gdk@google.com> #15 Jan 17, 2018 05:01PM ; > Hi Henry, Jeff,; > Message 13 can occur with non-preemptible instances as well. In cases where the controller sees an error and exits, if the PAPI servers don't see the instance shutting down then you'll see an error 13 as well.; > ; > I think the solution is to not differentiate your behavior on the content of the returned message, and always retry if the operation is showing as aborted and the instance was preemptible. > ------------------------------- ; > ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3157:10645,Message,Message,10645,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3157,1,['Message'],['Message']
Integrability,"sk_sequence.wdl"" as SingleTest. workflow run_multiple_tests {; scatter (i in range(30)){; call SingleTest.three_task_sequence{}; }; }; ```. three_task_sequence.wdl; ```; workflow three_task_sequence{; call print_nach. call print_nach_nachman {; input:; previous = print_nach.out; }. call print_nach_nachman_meuman{; input:; previous = print_nach_nachman.out; }; output{; Array[String] out = print_nach_nachman_meuman.out; }; }. task print_nach{; command{; echo ""nach""; }; output{; Array[String] out = read_lines(stdout()); }; runtime {; 	 docker: ""ubuntu:latest""; 	 maxRetries: 3; }; }. task print_nach_nachman{; Array[String] previous. command{; echo ${sep=' ' previous} "" nachman""; }; output{; Array[String] out = read_lines(stdout()); }; runtime {; docker: ""ubuntu:latest""; maxRetries: 3; }; ; }. task print_nach_nachman_meuman{; Array[String] previous. command{; echo ${sep=' ' previous} "" meuman""; }; output{; Array[String] out = read_lines(stdout()); }; runtime {; docker: ""ubuntu:latest""; maxRetries: 3; }; }; ```. Here is the cromwell-conf:; ```; // aws.conf; include required(classpath(""application"")). webservice {; port = 8001; interface = 0.0.0.0; }. aws {; application-name = ""cromwell""; auths = [{; name = ""default""; scheme = ""default""; }]; region = ""us-east-1""; }. engine {; filesystems {; s3 { auth = ""default"" }; }; }. backend {; default = ""AWSBATCH""; providers {; AWSBATCH {; actor-factory = ""cromwell.backend.impl.aws.AwsBatchBackendLifecycleActorFactory""; config {; root = ""s3://nrglab-cromwell-genomics/cromwell-execution""; auth = ""default"". numSubmitAttempts = 3; numCreateDefinitionAttempts = 3. concurrent-job-limit = 100. default-runtime-attributes {; queueArn: ""arn:aws:batch:us-east-1:66:job-queue/GenomicsDefaultQueue""; }. filesystems {; s3 {; auth = ""default""; }; }; }; }; }; }. system {; job-rate-control {; jobs = 1; per = 1 second; }; }; ```. Would appreciate help on this.; I wonder if cromwell was ever tested for many parallel sub-workflows running on AWS?. Thanks!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4687:2595,interface,interface,2595,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4687,1,['interface'],['interface']
Integrability,"son I first ran it with bad inputs on purpose and got expected failures; ```; status: ""Failed"",; failures: [; {; causedBy: [; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_pac' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.agg_preemptible_tries' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_ann' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.wgs_coverage_interval_list' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_fasta_index' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.unmapped_bam_suffix' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_ud' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_amb' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.preemptible_tries' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_sa' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.known_indels_sites_VCFs' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_mu' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_alt' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_bwt' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.known_indels_sites_indices' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.re",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2912:1443,message,message,1443,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2912,1,['message'],['message']
Integrability,"spatcher.scala:39); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:409); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); [2016-10-27 13:10:19,93] [info] Waiting for 1 workflows to abort...; [2016-10-27 13:10:20,93] [info] Waiting for 1 workflows to abort...; [2016-10-27 13:10:21,93] [info] Waiting for 1 workflows to abort...; [2016-10-27 13:10:22,93] [info] Waiting for 1 workflows to abort...; [2016-10-27 13:10:23,93] [info] Waiting for 1 workflows to abort...; [2016-10-27 13:10:24,84] [error] Exception not convertible into handled response; com.google.api.client.googleapis.json.GoogleJsonResponseException: 404 Not Found; {; ""code"" : 404,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Not Found"",; ""reason"" : ""notFound""; } ],; ""message"" : ""Not Found""; }; at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145); at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113); at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:432); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469); at com.google.cloud.hadoop.util.AbstractGoogleAsyncWriteChannel$UploadOperation.call(AbstractGoogleAsyncWriteChannel.java:357); at jav",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1631:7928,message,message,7928,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1631,2,['message'],['message']
Integrability,"specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_sa' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.known_indels_sites_VCFs' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_mu' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_alt' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_bwt' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.known_indels_sites_indices' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_dict' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_bed' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_fasta' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.dbSNP_vcf_index' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.dbSNP_vcf' not specified.""; }; ],; message: ""Workflow input processing failed""; }; ],; ```. But once I filled these out in my inputs json I then got this error. ```; [; {; causedBy: [; {; causedBy: [ ],; message: ""Missing inputs for subworkflow call SomaticRoot.TumorAlignment at index None: read_length, ref_fasta, agg_preemptible_tries, ref_dict, haplotype_database_file, ref_alt, ref_ann, known_indels_sites_indices, dbSNP_vcf, ref_sa, dbSNP_vcf_index, unmapped_bam_suffix, ref_amb, contamination_sites_ud, contamination_sites_bed, ref_bwt, ref_fasta_index, increase_disk_size, fingerprint_genotypes_file, preemptible_tries, known_indels_sites_VCFs, contamination_sites_mu, wgs_coverage_interval_list, ref_pac.""; }",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2912:2629,message,message,2629,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2912,1,['message'],['message']
Integrability,"src/ci/resources/slurm_application.conf. > # https://slurm.schedmd.com/squeue.html; > --; > 25 | check-alive = ""squeue -j ${job_id}"". The job state is being checked by the exit code: 0 means job not complete, non-zero is assumed to be job complete. This assumption is false. This is depending on site configured behavior about how quickly finished jobs are moved from the active controller the sacct database, as only after that happens the squeue command ""fails"" because the job isn't in the active DB anymore. Furthermore, if the job fails or is cancelled, cromwell will also falsely presume the job is complete since it's also no longer in the active DB. When the squeue command itself fails or times out, a non-zero exit code is also returned, which is again incorrectly interpreted as a completed job. . ""But if your squeue command fails you're whole machine is already broken!""; No. On a very busy slurm machine it is expected behavior that sometimes commands will time out when the controller is busy servicing a sudden burst of job submissions, state queries, job starts, or job completions. It would be an improvement to use sacct and check the job state like this:. check-alive = ""sacct -j ${job_id} -X -n -o state | grep -v COMPLETED"". That also decouples you from slurm controller noise, as sacct is going to a different database, but you'll still get the wrong results if _that_ database is down for some reason and the sacct command itself fails.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5400:283,depend,depending,283,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5400,1,['depend'],['depending']
Integrability,"stCanceled` event to each `Reporter` _without_ the original exception. The original error `Outcome` does not seem to be forwarded to the `Reporter`. Instead we may need to implement our own fork of `withRetry` that captures and forwards the original exception before retrying the test, wiring the original error to our custom `Reporter` in some way or via some singleton cache. For an external system to aggregate the errors something like https://logit.io/ could be used but https://sentry.io/ is specifically built for error triage. As the above features will only be implemented for ScalaTest, any tests using ScalaCheck directly should be refactored to use ScalaTest's ""ScalaCheck-style"" property based testing. That way any failing property based tests will be tracked as well using our reporting. Because this feature is likely to be used across all cromwell artifacts/subprojects we should decide if we either want to either:; 1. Update every project in `build.sbt` with a `.dependsOn(common, ""test->test"")`; 2. Add scalatest and sentry as `Provided` dependencies to `common` such that they won't be transitively included by default; 3. Create a new `cromwell.test` artifact and use either of the above outside of `cromwell.common`. **A/C:**; - Switch tests directly using scalacheck over to scalatest's scalacheck-style specs; - Create a custom scalatest helper/reporter that retries a failed test a configurable number of times; - Add custom reporter to scalatest settings in `Testing.scala`; - Assuming using sentry for error reporting from Travis:; - Add sentry DSN configuration values to Vault; - Update `build_application.inc.conf` to use a noop sentry DSN by default; - Create a `sentry_application.inc.conf.ctmpl` file that uses sentry configuration values from Vault; - `build_application.inc.conf` attempts to import a `sentry_application.inc.conf` file that overrides the sentry configuration; - NOTE: When `build_application.inc.conf` is missing it will be skipped by the HOCON li",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3658:2578,depend,dependsOn,2578,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3658,1,['depend'],['dependsOn']
Integrability,tch$$anonfun$run$1.apply(BatchingExecutor.scala:91); at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:72); at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: java.net.SocketException: Socket is closed; at sun.security.ssl.SSLSocketImpl.getInputStream(SSLSocketImpl.java:2218); at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:642); at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1536); at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1441); at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480); at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:338); at com.google.api.client.http.javanet.NetHttpResponse.<init>(NetHttpResponse.java:37); at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:94); at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); at com.google.cloud.storage.spi.DefaultStorageRpc.open(DefaultStorageRpc.java:563); at com.google.cloud.storage.BlobWriteChannel.<init>(BlobWriteChannel.java:36); at com.google.cloud.storage.StorageImpl.writer(StorageImpl.java:476); at com.google.cloud.storage.StorageImpl.writer(StorageImpl.java:471); at com.google.cloud.storage.StorageImpl.writer(StorageImpl.java:70); at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.newWriteChannel(CloudStorageFil\; eSystemProvider.java:327); ,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2009:2889,protocol,protocol,2889,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2009,1,['protocol'],['protocol']
Integrability,"tch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: io.grpc.StatusRuntimeException: UNAVAILABLE: io exception; Channel Pipeline: [SslHandler#0, ProtocolNegotiators$ClientTlsHandler#0, WriteBufferingAndExceptionHandler#0, DefaultChannelPipeline$TailContext#0]; at io.grpc.Status.asRuntimeException(Status.java:539); ... 14 common frames omitted; Caused by: javax.net.ssl.SSLHandshakeException: General OpenSslEngine problem; at io.grpc.netty.shaded.io.netty.handler.ssl.ReferenceCountedOpenSslEngine.handshakeException(ReferenceCountedOpenSslEngine.java:1907); at io.grpc.netty.shaded.io.netty.handler.ssl.ReferenceCountedOpenSslEngine.wrap(ReferenceCountedOpenSslEngine.java:834); at java.base/javax.net.ssl.SSLEngine.wrap(SSLEngine.java:564); at io.grpc.netty.shaded.io.netty.handler.ssl.SslHandler.wrap(SslHandler.java:1041); at io.grpc.netty.shaded.io.netty.handler.ssl.SslHandler.wrapNonAppData(SslHandler.java:927); at io.grpc.netty.shaded.io.netty.handler.ssl.SslHandler.unwrap(SslHandler.java:1409); at io.grpc.netty.shaded.io.netty.handler.ssl.SslHandler.unwrapNonAppData(SslHandler.java:1327); at io.grpc.netty.shaded.io.netty.handler.ssl.SslHandler.access$1800(SslHandler.java:169); at io.grpc.netty.shaded.io.netty.handler.ssl.SslHandler$SslTasksRunner.resumeOnEventExecutor(SslHandler.java:1718); at io.grpc.netty.shaded.io.netty.handler.ssl.SslHandler$SslTasksRunner.access$2000(SslHandler.java:1609); at io.grpc.netty.shaded.io.netty.handler.ssl.SslHandler$SslTasksRunner$2.run(SslHandler.java:1770); at io.grpc.netty.shaded.io.netty.util.concurrent.AbstractEventExecutor.runTask(AbstractEventExecutor.java:174); at io.grpc.netty.shaded.io.netty.util.concurrent.AbstractEventExecutor.safeExecute(AbstractEventExecutor.java:167); at io.grpc.netty.shaded.io.netty.util.concurrent.SingleThreadEventExecutor.runAllTasks(SingleThreadEventExecutor.java:470); at io.grpc.netty.shaded.io.net",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7551:5418,wrap,wrapNonAppData,5418,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7551,1,['wrap'],['wrapNonAppData']
Integrability,"tes"",; ""ttl"" : ""10 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; [2018-10-25 21:21:08,59] [info] Metadata summary refreshing every 2 seconds.; [2018-10-25 21:21:08,63] [info] KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; [2018-10-25 21:21:08,64] [info] CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; [2018-10-25 21:21:08,64] [info] WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; [2018-10-25 21:21:09,79] [info] JobExecutionTokenDispenser - Distribution rate: 50 per 1 seconds.; [2018-10-25 21:21:09,81] [info] SingleWorkflowRunnerActor: Version 34; [2018-10-25 21:21:09,82] [info] SingleWorkflowRunnerActor: Submitting workflow; [2018-10-25 21:21:09,86] [info] Unspecified type (Unspecified version) workflow 0bb77c74-4c5c-4314-8463-072e7055ee7c submitted; [2018-10-25 21:21:09,90] [info] SingleWorkflowRunnerActor: Workflow submitted 0bb77c74-4c5c-4314-8463-072e7055ee7c; [2018-10-25 21:21:09,91] [info] 1 new workflows fetched; [2018-10-25 21:21:09,91] [info] WorkflowManagerActor Starting workflow 0bb77c74-4c5c-4314-8463-072e7055ee7c; [2018-10-25 21:21:09,91] [warn] SingleWorkflowRunnerActor: received unexpected message: Done in state RunningSwraData; [2018-10-25 21:21:09,92] [warn] Couldn't find a suitable DSN, defaulting to a Noop one.; [2018-10-25 21:21:09,92] [info] Using noop to send events.; [2018-10-25 21:21:09,93] [info] WorkflowManagerActor Successfully started WorkflowActor-0bb77c74-4c5c-4314-8463-072e7055ee7c; [2018-10-25 21:21:09,93] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2018-10-25 21:21:09,93] [info] WorkflowStoreHeartbeatWriteActor configured to flush with batch size 10000 and process rate 2 minutes.; [2018-10-25 21:21:09,96] [info] MaterializeWorkflowDescriptorActor [0bb77c74]: Parsing workflow as WDL draft-2; [2018-10-25 21:21:10,57] [info] MaterializeWorkflowDescriptorActor [0bb77c74]: Call-to-Backend as",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4318:2629,message,message,2629,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4318,1,['message'],['message']
Integrability,"the following sample error:; ```; ""failures"": [; {; ""causedBy"": [; {; ""causedBy"": [; {; ""causedBy"": [],; ""message"": ""503 Service Unavailable\nBackend Error""; }; ],; ""message"": ""Could not read from gs://broad-epi-cromwell/workflows/ChipSeq/ce6a5671-baf6-4734-a32b-abf3d9138e9b/call-epitope_classifier/memory_retry_rc: 503 Service Unavailable\nBackend Error""; }; ],; ""message"": ""[Attempted 1 time(s)] - IOException: Could not read from gs://broad-epi-cromwell/workflows/ChipSeq/ce6a5671-baf6-4734-a32b-abf3d9138e9b/call-epitope_classifier/memory_retry_rc: 503 Service Unavailable\nBackend Error""; }; ]; ```. In https://github.com/broadinstitute/cromwell/issues/6154 @freeseek reports that Cromwell is unexpectedly failing to retry 504s and provides the following sample error:; ```; {; ""causedBy"": [; {; ""causedBy"": [; {; ""message"": ""504 Gateway Timeout\nGET https://storage.googleapis.com/download/storage/v1/b/mccarroll-mocha/o/cromwell%2Fcromwell-executions%2Fmocha%2F86d47e9a-5745-4ec0-b4eb-0164f073e5f4%2Fcall-idat2gtc%2Fshard-73%2Frc?alt=media"",; ""causedBy"": []; }; ],; ""message"": ""Could not read from gs://mccarroll-mocha/cromwell/cromwell-executions/mocha/86d47e9a-5745-4ec0-b4eb-0164f073e5f4/call-idat2gtc/shard-73/rc: 504 Gateway Timeout\nGET https://storage.googleapis.com/download/storage/v1/b/mccarroll-mocha/o/cromwell%2Fcromwell-executions%2Fmocha%2F86d47e9a-5745-4ec0-b4eb-0164f073e5f4%2Fcall-idat2gtc%2Fshard-73%2Frc?alt=media""; }; ],; ""message"": ""[Attempted 1 time(s)] - IOException: Could not read from gs://mccarroll-mocha/cromwell/cromwell-executions/mocha/86d47e9a-5745-4ec0-b4eb-0164f073e5f4/call-idat2gtc/shard-73/rc: 504 Gateway Timeout\nGET https://storage.googleapis.com/download/storage/v1/b/mccarroll-mocha/o/cromwell%2Fcromwell-executions%2Fmocha%2F86d47e9a-5745-4ec0-b4eb-0164f073e5f4%2Fcall-idat2gtc%2Fshard-73%2Frc?alt=media""; }; ```; Our regexes did not allow for the `\n` in the Google errors. I believe this bug came about when copy-pasting to create the test cases.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6155:1224,message,message,1224,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6155,2,['message'],['message']
Integrability,"ticing an odd behavior that we originally thought was just normal preemption. Normally we see preemption showing up as ""Error code 10: Message 14:"" - and cromwell takes care of re-submitting and following the logic coded in our WDLs. Try pre-emptibles 3 times then try a non-preemptible instance. ; > ; > cromwell metadata output:; > ; > ""message"": ""Task PairedEndSingleSampleWorkflow.SamToFastqAndBwaMemAndMba:1:1 failed. JES error code 10. Task 417bb61c-16cc-4fda-91d5-443ccba4da11:SamToFastqAndBwaMemAndMba was preempted for the 1st time. The call will be restarted with another preemptible VM (max preemptible attempts number is 3). Error code Status{code=ABORTED, description=null, cause=null}. Message: 14: VM ggp-15030877962490231612 stopped unexpectedly.""; > ; > However we have seen a new error response. ""Error code 10: Message 13"" metadata output showing:; > ; > ""message"": ""Task PairedEndSingleSampleWorkflow.HaplotypeCaller:46:3 failed. JES error code 10. Message: 13: VM ggp-9289873678241352278 shut down unexpectedly.""; > ; > From what Cromwell team indicates is that ""Message 13"" is not the same as Message 14 - as such a different logic occurs within cromwell. Cromwell will try the task three times and after that it will just ""Fail"" the task. So the ""try 3 pre-emptible then try non-preemptible"" logic is never followed.; > ; > So my question is what is ""Message 13"" and how is it different from ""Message 14""? Below are OpsIDs for a set of tasks - the first are the ""Message 14"" (which again are normal preemption but I wanted to provide some for comparison to Message 13) and the second list are the ""Message 13"". This is just a small sample of Message 13 failures.; > ; > MESSAGE 14: ; > operations/ENWy-aWLLBi89uiD6_uZzNABIMf5sPc2Kg9wcm9kdWN0aW9uUXVldWU; > operations/EMzb1NeLLBj0jsHwufD1gHogpfe0-ecHKg9wcm9kdWN0aW9uUXVldWU; > operations/EOn3vcOKLBibqZWQsay6xlUgpfe0-ecHKg9wcm9kdWN0aW9uUXVldWU; > operations/EK3Nx_aKLBjUn5bp5oqJz9oBIJGGnffgCioPcHJvZHVjdGlvblF1ZXVl; > operations",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3157:1335,Message,Message,1335,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3157,1,['Message'],['Message']
Integrability,"titute.org> #3 Jan 10, 2018 08:58AM ; > Not sure if you need any additional opsids - let me know if you do. While I have not gathered specific statistics on the frequency of this happening - our operations staff reports that it is not unusual for this to happen up to dozen or so times a day where the ""Message 13:"" failures cause the entire workflow to fail and need to be re-submitted. I would only assume that at a task level it is happening more often and as long as it does happen three times in succession for the same task - our ops team may not even notice it. Since the retry covers it up. ; > ; > But it can cause considerable amount of delay on completing a sample. The time spent to do the 3 retries but then the time it takes for a human to notice the failure and re-submit the entire thing again. For ""normal"" preemption - we have codified things in our WDL such that when failures occur - it is usually something unusual. With the higher occurrence of ""Message 13"" cause workflow failures - there is a new added step that needs to be looked at first. Did the workflow fail due to ""Message 13""?; > ; > At a minimal it would be nice to understand what are the circumstances a ""Message 13"" failure happens - so the Red/Cromwell team can determine if there is anything they can or should do differently. ; > ; > -Henry. > ------------------------------- ; > jgentry@broadinstitute.org <jgentry@broadinstitute.org> #4 Jan 12, 2018 11:45AM ; > As I'm fielding questions about why there's a cromwell bug\ for not properly retrying preemptions in these cases I wanted to bump this a bit. > ------------------------------- ; > ferrara@broadinstitute.org <ferrara@broadinstitute.org> #5 Jan 16, 2018 03:59PM ; > This is occurring more and more. It is starting to impact our through-put for our production pipeline processing. > ------------------------------- ; > kemp@google.com <kemp@google.com> #6 Jan 17, 2018 10:44AM ; > Nothing has changed in Pipelines API in this regard. I suspect either ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3157:4429,Message,Message,4429,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3157,1,['Message'],['Message']
Integrability,"tor [d57a5f97atac.filter:1:1]: python $(which encode_filter.py) \; /cromwell_root/atac-seq-pipeline-workflows/ENCSR889WQX/atac/d57a5f97-8542-4fcc-89c4-b7c487957dea/call-bowtie2/shard-1/glob-3bcbe4e7489c90f75e0523ac6f3a9385/ENCFF463QCX.trim.merged.R1.bam \; \; --multimapping 4 \; \; \; \; --nth 2; [2017-11-18 19:30:15,43] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.filter:1:1]: job id: operations/EMi1zpL9KxjduPXRuKr-7gYgtY36-tsbKg9wcm9kdWN0aW9uUXVldWU; [2017-11-18 19:30:26,72] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.filter:1:1]: Status change from - to Initializing; [2017-11-18 21:25:57,96] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:0:1]: Status change from Initializing to Failed; [2017-11-18 21:25:58,22] [error] WorkflowManagerActor Workflow d57a5f97-8542-4fcc-89c4-b7c487957dea failed (during ExecutingWorkflowState): Task atac.bowtie2:0:1 failed. JES error code 5. Message: 9: Failed to localize files: failed to copy the following files: ""gs://atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar -> /mnt/local-disk/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar (cp failed: gsutil -q -m cp gs://atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar /mnt/local-disk/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar, command failed: BadRequestException: 400 Bucket is requester pays bucket but no user project provided.\nCommandException: 1 file/object could not be transferred.\n)""; java.lang.Exception: Task atac.bowtie2:0:1 failed. JES error code 5. Message: 9: Failed to localize files: failed to copy the following files: ""gs://atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar -> /mnt/local-disk/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar (cp failed: gsutil -q -m cp gs://atac-seq-pipeline",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2916:3768,Message,Message,3768,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2916,1,['Message'],['Message']
Integrability,"tor.scala:537); 	at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActor.akka$actor$Timers$$super$aroundReceive(WorkflowExecutionActor.scala:54); 	at akka.actor.Timers.aroundReceive(Timers.scala:51); 	at akka.actor.Timers.aroundReceive$(Timers.scala:40); 	at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActor.aroundReceive(WorkflowExecutionActor.scala:54); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:614); 	at akka.actor.ActorCell.invoke(ActorCell.scala:583); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:268); 	at akka.dispatch.Mailbox.run(Mailbox.scala:229); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:241); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); [2023-11-07 14:51:17,39] [info] Message [cromwell.engine.workflow.lifecycle.EngineLifecycleActorAbortCommand$] from Actor[akka://cromwell-system/user/SingleWorkflowRunnerActor/WorkflowManagerActor/WorkflowActor-4e522458-e360-45e8-be15-2fc99652d692#-686070856] to Actor[akka://cromwell-system/user/SingleWorkflowRunnerActor/WorkflowManagerActor/WorkflowActor-4e522458-e360-45e8-be15-2fc99652d692/WorkflowExecutionActor-4e522458-e360-45e8-be15-2fc99652d692#-1420206102] was not delivered. [1] dead letters encountered, no more dead letters will be logged. If this is not an expected behavior, then [Actor[akka://cromwell-system/user/SingleWorkflowRunnerActor/WorkflowManagerActor/WorkflowActor-4e522458-e360-45e8-be15-2fc99652d692/WorkflowExecutionActor-4e522458-e360-45e8-be15-2fc99652d692#-1420206102]] may have terminated unexpectedly, This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; ```; In fact, the program becomes unrespon",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7249:5894,Message,Message,5894,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7249,1,['Message'],['Message']
Integrability,"tor: Submitting workflow; [2019-01-07 16:21:19,69] [info] Unspecified type (Unspecified version) workflow 18de8166-5f29-4288-9fa4-6741565446fd submitted; [2019-01-07 16:21:19,74] [info] SingleWorkflowRunnerActor: Workflow submitted [38;5;2m18de8166-5f29-4288-9fa4-6741565446fd[0m; [2019-01-07 16:21:19,75] [info] 1 new workflows fetched; [2019-01-07 16:21:19,77] [info] WorkflowManagerActor Starting workflow [38;5;2m18de8166-5f29-4288-9fa4-6741565446fd[0m; [2019-01-07 16:21:19,77] [info] WorkflowManagerActor Successfully started WorkflowActor-18de8166-5f29-4288-9fa4-6741565446fd; [2019-01-07 16:21:19,77] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2019-01-07 16:21:19,78] [info] WorkflowStoreHeartbeatWriteActor configured to flush with batch size 10000 and process rate 2 minutes.; [2019-01-07 16:21:19,80] [[38;5;220mwarn[0m] SingleWorkflowRunnerActor: received unexpected message: Done in state RunningSwraData; [2019-01-07 16:21:19,98] [info] MaterializeWorkflowDescriptorActor [[38;5;2m18de8166[0m]: Parsing workflow as WDL draft-2; [2019-01-07 16:21:21,18] [info] MaterializeWorkflowDescriptorActor [[38;5;2m18de8166[0m]: Call-to-Backend assignments: example.hello -> Local; [2019-01-07 16:21:23,89] [[38;5;1merror[0m] WorkflowManagerActor Workflow 18de8166-5f29-4288-9fa4-6741565446fd failed (during ExecutingWorkflowState): java.lang.RuntimeException: Failed to evaluate 'example.files' (reason 1 of 1): Evaluating glob(file_pattern) failed: glob(path, pattern) not implemented yet; 	at cromwell.engine.workflow.lifecycle.execution.keys.ExpressionKey.processRunnable(ExpressionKey.scala:29); 	at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActor.$anonfun$startRunnableNodes$7(WorkflowExecutionActor.scala:510); 	at cats.instances.ListInstances$$anon$1.$anonfun$traverse$2(list.scala:73); 	at cats.instances.ListInstances$$anon$1.loop$2(list.scala:63); 	at cats.instances.ListInstances$$anon$1.$anonfun$foldRight$2(list.scala:65); 	at cats.Eva",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4526:2975,message,message,2975,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4526,1,['message'],['message']
Integrability,"transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [INFO] [06/02/2016 19:49:46.377] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$ib/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib] $$ib transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib] $$ib transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.378] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user/$$ib/WorkflowInitializationActor-fd304efe-2bba-4859-9ffd-6ef7d4ae29d5] State is now terminal. Shutting down.; [WARN] [06/02/2016 19:49:46.381] [test-system-akka.actor.default-dispatcher-3] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$ib]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.495] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$kb] $$kb transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [WARN] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$kb]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.498",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/933:1294,message,message,1294,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/933,1,['message'],['message']
Integrability,"try/87492280-9828-4afa-b53e-bec675103c42/call-fail_oom/stderr"",; ""callRoot"": ""gs://encode-pipeline-test-runs/caper_out_10/mem_retry/87492280-9828-4afa-b53e-bec675103c42/call-fail_oom"",; ""attempt"": 1,; ""executionEvents"": [; {; ""description"": ""CallCacheReading"",; ""startTime"": ""2020-08-29T00:00:44.174Z"",; ""endTime"": ""2020-08-29T00:00:44.237Z""; },; {; ""startTime"": ""2020-08-29T00:00:42.044Z"",; ""description"": ""Pending"",; ""endTime"": ""2020-08-29T00:00:42.064Z""; },; {; ""description"": ""RunningJob"",; ""startTime"": ""2020-08-29T00:00:44.237Z"",; ""endTime"": ""2020-08-29T00:04:05.347Z""; },; {; ""startTime"": ""2020-08-29T00:00:42.531Z"",; ""endTime"": ""2020-08-29T00:00:44.174Z"",; ""description"": ""PreparingJob""; },; {; ""startTime"": ""2020-08-29T00:00:42.064Z"",; ""description"": ""RequestingExecutionToken"",; ""endTime"": ""2020-08-29T00:00:42.516Z""; },; {; ""endTime"": ""2020-08-29T00:00:42.531Z"",; ""description"": ""WaitingForValueStore"",; ""startTime"": ""2020-08-29T00:00:42.516Z""; }; ],; ""backendLogs"": {; ""log"": ""gs://encode-pipeline-test-runs/caper_out_10/mem_retry/87492280-9828-4afa-b53e-bec675103c42/call-fail_oom/fail_oom.log""; },; ""start"": ""2020-08-29T00:00:42.022Z""; }; ]; },; ""outputs"": {},; ""workflowRoot"": ""gs://encode-pipeline-test-runs/caper_out_10/mem_retry/87492280-9828-4afa-b53e-bec675103c42/"",; ""actualWorkflowLanguage"": ""WDL"",; ""id"": ""87492280-9828-4afa-b53e-bec675103c42"",; ""inputs"": {},; ""labels"": {; ""cromwell-workflow-id"": ""cromwell-87492280-9828-4afa-b53e-bec675103c42"",; ""caper-backend"": ""gcp"",; ""caper-user"": ""leepc12""; },; ""submission"": ""2020-08-29T00:00:38.568Z"",; ""status"": ""Failed"",; ""failures"": [; {; ""causedBy"": [; {; ""causedBy"": [],; ""message"": ""The compute backend terminated the job. If this termination is unexpected, examine likely causes such as preemption, running out of disk or memory on the compute instance, or exceeding the backend's maximum job duration.""; }; ],; ""message"": ""Workflow failed""; }; ],; ""end"": ""2020-08-29T00:04:06.071Z"",; ""start"": ""2020-08-29T00:00:38.789Z""; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5815:7219,message,message,7219,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5815,2,['message'],['message']
Integrability,"tsCaller -> JES, case_gatk_acnv_workflow.TumorPerformSeg -> JES, case_gatk_acnv_workflow.TumorCaller -> JES, case_gatk_acnv_workflow.AllelicCNV -> JES, case_gatk_acnv_workflow.NormalCorrectGCBias -> JES, case_gatk_acnv_workflow.NormalPerformSeg -> JES, case_gatk_acnv_workflow.NormalNormalizeSomaticReadCounts -> JES, case_gatk_acnv_workflow.PlotSegmentedCopyRatio -> JES, case_gatk_acnv_workflow.TumorCorrectGCBias -> JES, case_gatk_acnv_workflow.HetPulldown -> JES, case_gatk_acnv_workflow.PadTargets -> JES; [2016-10-27 13:10:07,81] [info] JES [6f995b2d]: Creating authentication file for workflow 6f995b2d-cf39-4be1-adfb-b6d0a961bd9c at; gs://my-cromwell-workflows-bucket/case_gatk_acnv_workflow/6f995b2d-cf39-4be1-adfb-b6d0a961bd9c/6f995b2d-cf39-4be1-adfb-b6d0a961bd9c_auth.json; [2016-10-27 13:10:08,17] [error] Exception not convertible into handled response; com.google.api.client.googleapis.json.GoogleJsonResponseException: 404 Not Found; {; ""code"" : 404,; ""errors"" : [ {; ""domain"" : ""global"",; ""message"" : ""Not Found"",; ""reason"" : ""notFound""; } ],; ""message"" : ""Not Found""; }; at com.google.api.client.googleapis.json.GoogleJsonResponseException.from(GoogleJsonResponseException.java:145); at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113); at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:432); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469); at com.google.cloud.hadoop.util.AbstractGoogleAsyncWriteChannel$UploadOperation.call(AbstractGoogleAsyncWriteChannel.java:357); at jav",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1631:1737,message,message,1737,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1631,2,['message'],['message']
Integrability,"t}""; """""". submit-docker = """"""; # SINGULARITY_CACHEDIR needs to point to a directory accessible by; # the jobs (i.e. not lscratch). Might want to use a workflow local; # cache dir like in run.sh; source /work/share/ac7m4df1o5/bin/cromwell/set_singularity_cachedir.sh; SINGULARITY_CACHEDIR=/work/share/ac7m4df1o5/bin/cromwell/singularity-cache; source /work/share/ac7m4df1o5/bin/cromwell/test.sh ${docker}; echo ""SINGULARITY_CACHEDIR $SINGULARITY_CACHEDIR""; if [ -z $SINGULARITY_CACHEDIR ]; then; CACHE_DIR=$HOME/.singularity; else; CACHE_DIR=$SINGULARITY_CACHEDIR; fi; mkdir -p $CACHE_DIR; echo ""SINGULARITY_CACHEDIR $SINGULARITY_CACHEDIR""; LOCK_FILE=$CACHE_DIR/singularity_pull_flock. # we want to avoid all the cromwell tasks hammering each other trying; # to pull the container into the cache for the first time. flock works; # on GPFS, netapp, and vast (of course only for processes on the same; # machine which is the case here since we're pulling it in the master; # process before submitting).; #flock --exclusive --timeout 1200 $LOCK_FILE \; # singularity exec --containall docker://${docker} \; # echo ""successfully pulled ${docker}!"" &> /dev/null. # Ensure singularity is loaded if it's installed as a module; module load apps/singularity/3.7.3. # Build the Docker image into a singularity image; #IMAGE=$(echo $SINGULARITY_CACHEDIR/pull/${docker}.sif|sed ""s#:#_#g""); #singularity build $IMAGE docker://${docker}. # Submit the script to SLURM; sbatch \; --wait \; --job-name=${job_name} \; --chdir=${cwd} \; --output=${cwd}/execution/stdout \; --error=${cwd}/execution/stderr \; --time=${runtime_minutes} \; ${""--cpus-per-task="" + cpus} \; --mem-per-cpu=${requested_memory_mb_per_core} \; --partition=wzhcexclu06 \; --wrap ""singularity exec --containall --bind ${cwd}:${docker_cwd} $SINGULARITY_CACHEDIR/pull/$docker_image.sif ${job_shell} ${docker_script}""; """""". kill = ""scancel ${job_id}""; check-alive = ""squeue -j ${job_id}""; job-id-regex = ""Submitted batch job (\\d+).*""; }; }. }; }. ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6933:9418,wrap,wrap,9418,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6933,1,['wrap'],['wrap']
Integrability,"ual SV calls into distinct events\\nand properly classify and annotating the event to understand both its mechanism and genomic impact.\\n\"",\n \""requirements\"": [\n {\n \""class\"": \""ResourceRequirement\"",\n \""coresMin\"": 4,\n \""ramMin\"": 16000\n },\n {\n \""class\"": \""DockerRequirement\"",\n \""dockerPull\"": \""umccr/linx:1.10-beta\""\n },\n {\n \""class\"": \""ShellCommandRequirement\""\n },\n {\n \""class\"": \""InlineJavascriptRequirement\"",\n \""expressionLib\"": [\n \""var get_start_memory = function(){ /* Start with 2 Gb */ return 2000; }\"",\n \""var get_max_memory_from_runtime_memory = function(max_ram){ /* Get Max memory and subtract heap memory */ return max_ram - get_start_memory(); }\""\n ]\n }\n ],\n \""baseCommand\"": [\n \""java\"",\n \""-Xms$(get_start_memory())m\"",\n \""-Xmx$(get_max_memory_from_runtime_memory(runtime.ram))m\"",\n \""-jar\"",\n \""/opt/linx/linx.jar\""\n ],\n \""inputs\"": [\n {\n \""type\"": [\n \""null\"",\n \""int\""\n ],\n \""doc\"": \""threshold for # SVs in clusters to skip chaining routine (default = 2000)\\n\"",\n \""inputBinding\"": {\n \""prefix\"": \""-chaining_sv_limit\""\n },\n \""default\"": 2000,\n \""id\"": \""#linx-1.10-beta.cwl/chaining_sv_limit\""\n },\n {\n \""type\"": [\n \""null\"",\n \""boolean\""\n ],\n \""doc\"": \""Optional - Discover and annotate gene fusions\\n\"",\n \""inputBinding\"": {\n \""prefix\"": \""-check_drivers\""\n },\n \""default\"": false,\n \""id\"": \""#linx-1.10-beta.cwl/check_drivers\""\n },\n {\n \""type\"": [\n \""null\"",\n \""boolean\""\n ],\n \""doc\"": \""Optional - discover and annotate gene fusions\\n\"",\n \""inputBinding\"": {\n \""prefix\"": \""-check_fusions\""\n },\n \""default\"": false,\n \""id\"": \""#linx-1.10-beta.cwl/check_fusions\""\n },\n {\n \""type\"": [\n \""null\"",\n \""string\""\n ],\n \""doc\"": \""[password]\\n\"",\n \""inputBinding\"": {\n \""prefix\"": \""-db_pass\""\n },\n \""id\"": \""#linx-1.10-beta.cwl/db_pass\""\n },\n {\n \""type\"": [\n \""null\"",\n \""string\""\n ],\n \""doc\"": \""[db_url]\\n\"",\n \""inputBinding\"": {\n \""prefix\"": \""-db_url\""\n },\n \""id\"": \""#linx-1.10",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5826:85264,rout,routine,85264,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5826,1,['rout'],['routine']
Integrability,"ualities of these total RNA were tested using the Agilent Bioanalyzer 2100 Eukaryote Total RNA Nano Series II. Only total RNAs with a RIN score of more than 7 were used for RNA-Seq library construction\nRibosomal RNA (rRNA) was removed from total RNA using the RiboMinus™ Eukaryote Kit for RNA-Seq from Ambion. The ribosomal RNA depleted RNA fraction is termed the RiboMinus™ RNA fraction and is enriched in polyadenylated (polyA) mRNA, non-polyadenylated RNA, pre-processed RNA, tRNA, and may also contain regulatory RNA molecules such as microRNA (miRNA) and short interfering RNA (siRNA), snRNA, and other RNA transcripts of yet unknown function. Ambion RiboMinus rRNA depletion was performed as described in the manufacturer’s protocol (Pub. Part no.: 100004590, Rev. date 2 December 2011) following the standard protocol.\nTruSeq RNA Sample Preparation was performed on the RiboMinus™ RNA fraction as described in the manufacturer’s protocol (Pub. Part no.: 15026495 Rev. F March 2014) following the low sample protocol.\nThe libraries were sequenced on Illumina’s HiSeq 2000 instrument following standard protocol."",; ""processing"" : ""Data quality check using fastQC version 0.11.2.\nAlignment of unpaired unstranded reads using STAR version 2.4.0.\nQuantification of transcripts and isoforms using RSEM version 1.2.21 using rsem-calculate-expression, both alignment and quantification was done using the STAR_RSEM.sh pipeline (https://github.com/ENCODE-DCC/long-rna-seq-pipeline/blob/master/DAC/STAR_RSEM.sh)\nThe programe featurecounts version 1.4.6-p2 from the SourceForge Subread package was used to produce a summary file of counts from all the alignement .bam files.\nThe summary file of counts (RNAseq.counts) was used to plot the multidimensional scaling plot using edgeR version 3.1.3.\nThe *.osc.gz files were loaded into the genome browser ZENBU and was used visualize the transcripts. Screen shots were captured.\nGenome_build: hg19 with Gencode V19 annotation\nSupplementary_files_fo",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4519:1854,protocol,protocol,1854,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4519,1,['protocol'],['protocol']
Integrability,"uffix' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_ud' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_amb' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.preemptible_tries' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_sa' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.known_indels_sites_VCFs' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_mu' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_alt' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_bwt' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.known_indels_sites_indices' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_dict' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_bed' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_fasta' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.dbSNP_vcf_index' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.dbSNP_vcf' not specified.""; }; ],; message: ""Workflow input processing failed""; }; ],; ```. But once I filled these out in my inputs json I then got this error. ```; [; {; causedBy: [; {; causedBy: [ ],; message: ""Missing inputs for subworkflow call SomaticRoot.TumorAlignment at index None: read_length, ref_fasta, agg_preemptible_tries, ref_dict,",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2912:2260,message,message,2260,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2912,1,['message'],['message']
Integrability,"ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.fasterxml.jackson.core:jackson-databind&package-manager=maven&previous-version=2.13.2.2&new-version=2.13.4.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); - `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language; - `@de",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6935:958,Depend,Dependabot,958,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6935,9,"['Depend', 'depend']","['Dependabot', 'dependabot']"
Integrability,"ummary refreshing every 2 seconds.; [2018-09-14 13:19:55,31] [info] KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; [2018-09-14 13:19:55,32] [info] WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; [2018-09-14 13:19:55,32] [info] CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; [2018-09-14 13:19:56,83] [info] JobExecutionTokenDispenser - Distribution rate: 50 per 1 seconds.; [2018-09-14 13:19:56,88] [info] SingleWorkflowRunnerActor: Version 35-fd560e9-SNAP; [2018-09-14 13:19:56,91] [info] SingleWorkflowRunnerActor: Submitting workflow; [2018-09-14 13:19:57,89] [info] CWL (Unspecified version) workflow caab4283-a3d4-4966-85ba-56d0992c8f00 submitted; [2018-09-14 13:19:57,90] [info] SingleWorkflowRunnerActor: Workflow submitted caab4283-a3d4-4966-85ba-56d0992c8f00; [2018-09-14 13:19:57,91] [info] 1 new workflows fetched; [2018-09-14 13:19:57,92] [info] WorkflowManagerActor Starting workflow caab4283-a3d4-4966-85ba-56d0992c8f00; [2018-09-14 13:19:57,93] [warn] SingleWorkflowRunnerActor: received unexpected message: Done in state RunningSwraData; [2018-09-14 13:19:57,96] [info] WorkflowManagerActor Successfully started WorkflowActor-caab4283-a3d4-4966-85ba-56d0992c8f00; [2018-09-14 13:19:57,96] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2018-09-14 13:19:57,96] [info] WorkflowStoreHeartbeatWriteActor configured to flush with batch size 10000 and process rate 2 minutes.; [2018-09-14 13:19:58,11] [info] MaterializeWorkflowDescriptorActor [caab4283]: Parsing workflow as CWL v1.0; [2018-09-14 13:20:00,08] [error] WorkflowManagerActor Workflow caab4283-a3d4-4966-85ba-56d0992c8f00 failed (during MaterializingWorkflowDescriptorState): cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anon$1: Workflow input processing failed:; Custom type file:///home/jeremiah/gdc-dnaseq-cwl/workflows/bamfastq_align/transform_pack.cwl#",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4103:2679,message,message,2679,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4103,1,['message'],['message']
Integrability,"ummary refreshing every 2 seconds.; [2018-09-14 13:21:51,44] [info] WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; [2018-09-14 13:21:51,45] [info] KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; [2018-09-14 13:21:51,51] [info] CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; [2018-09-14 13:21:52,32] [info] JobExecutionTokenDispenser - Distribution rate: 50 per 1 seconds.; [2018-09-14 13:21:52,35] [info] SingleWorkflowRunnerActor: Version 35-fd560e9-SNAP; [2018-09-14 13:21:52,36] [info] SingleWorkflowRunnerActor: Submitting workflow; [2018-09-14 13:21:52,42] [info] CWL (Unspecified version) workflow 6f311835-f1fe-4bbd-8fbb-c5543373d039 submitted; [2018-09-14 13:21:52,43] [info] SingleWorkflowRunnerActor: Workflow submitted 6f311835-f1fe-4bbd-8fbb-c5543373d039; [2018-09-14 13:21:52,43] [info] 1 new workflows fetched; [2018-09-14 13:21:53,05] [info] WorkflowManagerActor Starting workflow 6f311835-f1fe-4bbd-8fbb-c5543373d039; [2018-09-14 13:21:53,06] [warn] SingleWorkflowRunnerActor: received unexpected message: Done in state RunningSwraData; [2018-09-14 13:21:53,09] [info] WorkflowManagerActor Successfully started WorkflowActor-6f311835-f1fe-4bbd-8fbb-c5543373d039; [2018-09-14 13:21:53,09] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2018-09-14 13:21:53,10] [info] WorkflowStoreHeartbeatWriteActor configured to flush with batch size 10000 and process rate 2 minutes.; [2018-09-14 13:21:53,21] [info] MaterializeWorkflowDescriptorActor [6f311835]: Parsing workflow as CWL v1.0; [2018-09-14 13:21:55,91] [info] MaterializeWorkflowDescriptorActor [6f311835]: Call-to-Backend assignments: bam_ls_l -> Local, bam_readgroup_to_json -> Local, fastqc -> Local, json_to_sqlite -> Local, merge_readgroup_json_db -> Local, fastq_cleaner_se -> Local, picard_collecttargetedpcrmetrics_to_sqlite -> Local, biobambam_bamtofastq -> Local, readgroup_json_db -> Local, pic",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4103:20505,message,message,20505,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4103,1,['message'],['message']
Integrability,"ummary refreshing every 2 seconds.; [2018-10-25 21:17:12,98] [info] KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; [2018-10-25 21:17:12,98] [info] CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; [2018-10-25 21:17:12,98] [info] WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; [2018-10-25 21:17:13,79] [info] JobExecutionTokenDispenser - Distribution rate: 50 per 1 seconds.; [2018-10-25 21:17:13,80] [info] SingleWorkflowRunnerActor: Version 36; [2018-10-25 21:17:13,81] [info] SingleWorkflowRunnerActor: Submitting workflow; [2018-10-25 21:17:13,84] [info] Unspecified type (Unspecified version) workflow e22c6324-5aec-4694-8750-f62160e2ca81 submitted; [2018-10-25 21:17:13,85] [info] SingleWorkflowRunnerActor: Workflow submitted e22c6324-5aec-4694-8750-f62160e2ca81; [2018-10-25 21:17:13,85] [info] 1 new workflows fetched; [2018-10-25 21:17:13,85] [info] WorkflowManagerActor Starting workflow e22c6324-5aec-4694-8750-f62160e2ca81; [2018-10-25 21:17:13,86] [info] WorkflowManagerActor Successfully started WorkflowActor-e22c6324-5aec-4694-8750-f62160e2ca81; [2018-10-25 21:17:13,86] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2018-10-25 21:17:13,86] [warn] SingleWorkflowRunnerActor: received unexpected message: Done in state RunningSwraData; [2018-10-25 21:17:13,87] [info] WorkflowStoreHeartbeatWriteActor configured to flush with batch size 10000 and process rate 2 minutes.; [2018-10-25 21:17:13,95] [info] MaterializeWorkflowDescriptorActor [e22c6324]: Parsing workflow as WDL draft-2; [2018-10-25 21:17:14,52] [info] MaterializeWorkflowDescriptorActor [e22c6324]: Call-to-Backend assignments: test_opt_array.t1 -> Local; [2018-10-25 21:17:20,89] [info] WorkflowExecutionActor-e22c6324-5aec-4694-8750-f62160e2ca81 [e22c6324]: Starting test_opt_array.t1 (5 shards); [2018-10-25 21:17:22,98] [info] BackgroundConfigAsyncJobExecutionActor [e22c6324test_opt_array.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4318:11858,message,message,11858,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4318,1,['message'],['message']
Integrability,"umps log4j-api from 2.13.3 to 2.15.0. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=org.apache.logging.log4j:log4j-api&package-manager=maven&previous-version=2.13.3&new-version=2.15.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); - `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language; - `@de",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6586:722,Depend,Dependabot,722,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6586,9,"['Depend', 'depend']","['Dependabot', 'dependabot']"
Integrability,"umps log4j-api from 2.13.3 to 2.16.0. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=org.apache.logging.log4j:log4j-api&package-manager=maven&previous-version=2.13.3&new-version=2.16.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); - `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language; - `@de",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6591:722,Depend,Dependabot,722,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6591,9,"['Depend', 'depend']","['Dependabot', 'dependabot']"
Integrability,"umps log4j-api from 2.16.0 to 2.17.0. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=org.apache.logging.log4j:log4j-api&package-manager=maven&previous-version=2.16.0&new-version=2.17.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); - `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language; - `@de",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6594:722,Depend,Dependabot,722,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6594,9,"['Depend', 'depend']","['Dependabot', 'dependabot']"
Integrability,"umps log4j-api from 2.17.0 to 2.17.1. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=org.apache.logging.log4j:log4j-api&package-manager=maven&previous-version=2.17.0&new-version=2.17.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); - `@dependabot use these labels` will set the current labels as the default for future PRs for this repo and language; - `@de",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6639:722,Depend,Dependabot,722,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6639,9,"['Depend', 'depend']","['Dependabot', 'dependabot']"
Integrability,"un$1(BatchingExecutor.scala:91)""; },; {; causedBy: [ ],; message: ""scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)""; },; {; causedBy: [ ],; message: ""scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81)""; },; {; causedBy: [ ],; message: ""akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:91)""; },; {; causedBy: [ ],; message: ""akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40)""; },; {; causedBy: [ ],; message: ""akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:43)""; },; {; causedBy: [ ],; message: ""akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)""; },; {; causedBy: [ ],; message: ""akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)""; },; {; causedBy: [ ],; message: ""akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)""; },; {; causedBy: [ ],; message: ""akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)""; }; ],; message: ""Workflow input processing failed""; }; ],; ```. I think the culprit has something to do with both the root and sub workflow both having a task called `GatherbamFiles` because when I renamed the task in the subworkflow (and all subsequent necessary renames) the workflow ran fine. When I tried to make a simple example of this I couldn't get the error to pop up again so I'm definitely missing some nuances of the cause. The root workflow passes womtool-30.1.jar validation. Root workflow - [SomaticPairedSingleSampleWf.txt](https://github.com/broadinstitute/cromwell/files/1635810/SomaticPairedSingleSampleWf.txt). Sub workflow - [SplitLargeRG.txt](https://github.com/broadinstitute/cromwell/files/1635814/SplitLargeRG.txt). Dependencies zip - [SomaticPairedSingleSampleWfDependencies.zip](https://github.com/broadinstitute/cromwell/files/1635815/SomaticPairedSingleSampleWfDependencies.zip). Let me know if theres any more information that might be useful.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3143:3995,message,message,3995,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3143,2,"['Depend', 'message']","['Dependencies', 'message']"
Integrability,"unit4/issues/1672"">#1672</a>)</li>; <li><a href=""https://github.com/junit-team/junit4/commit/3a5c6b4d08f408c8ca6a8e0bae71a9bc5a8f97e8""><code>3a5c6b4</code></a> Deprecated since jdk9 replacing constructor instance of Double and Float (<a href=""https://github-redirect.dependabot.com/junit-team/junit4/issues/1660"">#1660</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/junit-team/junit4/compare/r4.13...r4.13.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=junit:junit&package-manager=maven&previous-version=4.13&new-version=4.13.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/configuring-github-dependabot-security-updates). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR a",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5941:4326,depend,dependabot-automerge-start,4326,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5941,2,['depend'],"['dependabot-automerge-end', 'dependabot-automerge-start']"
Integrability,ure.scala:24); at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: javax.net.ssl.SSLHandshakeException: Remote host closed connection during handshake; at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:980); at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1363); at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1391); at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1375); at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:563); at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185); at sun.net.www.protocol.https.HttpsURLConnectionImpl.connect(HttpsURLConnectionImpl.java:153); at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93); at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469); at com.google.cloud.storage.spi.DefaultStorageRpc.get(DefaultStorageRpc.java:320); ... 31 more; Caused by: java.io.EOFException: SSL peer shut down incorrectly; at sun.security.ssl.InputRecord.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1782:4336,protocol,protocol,4336,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1782,1,['protocol'],['protocol']
Integrability,urity.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:973) ~[na:1.8.0_72];   at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:930) ~[na:1.8.0_72];   at sun.security.ssl.AppInputStream.read(AppInputStream.java:105) ~[na:1.8.0_72];   at java.io.BufferedInputStream.fill(BufferedInputStream.java:246) ~[na:1.8.0_72];   at java.io.BufferedInputStream.read1(BufferedInputStream.java:286) ~[na:1.8.0_72];   at java.io.BufferedInputStream.read(BufferedInputStream.java:345) ~[na:1.8.0_72];   at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:704) ~[na:1.8.0_72];   at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:647) ~[na:1.8.0_72];   at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1536) ~[na:1.8.0_72];   at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1441) ~[na:1.8.0_72];   at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480) ~[na:1.8.0_72];   at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:338) ~[na:1.8.0_72];   at com.google.api.client.http.javanet.NetHttpResponse.<init>(NetHttpResponse.java:37) ~[cromwell.jar:0.19];   at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:94) ~[cromwell.jar:0.19];   at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:972) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352) ~[cromwell.jar:0.19];   at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469) ~[cromwell.jar:0.19];   at cromwell.engine.backend.io.filesystem.gcs.GcsFileSystemProvider$$anonfun$crc32cHash$1.apply(GcsFileSystemProvider.scala:191) ~[cromwell.j,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/826:1783,protocol,protocol,1783,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/826,1,['protocol'],['protocol']
Integrability,"utch/reproducible-workflows/blob/master/WDL/unpaired-panel-consensus-variants-human/map-variantcall-hg38.json. Possibly related to #4412 but not sure as I don't see the same error message. When submitting a workflow via the cromwell server we **consistently** see a failure to hash some items in S3 resulting in call caching being disabled for the run. We have seen this for a number of workflows, here we are including just one. . Call caching is a **hugely** important feature for us and if it is not available we may would have to reconsider using Cromwell. I think I have discussed with @ruchim the fact that all objects in S3 have a hash already computed (the ETag header) so there should not be timeouts in computing these hashes as they are available with a head request (you don't need to download the whole object). . Error message (extract from `/metadata` output):. ```; ""callCaching"": {; ""hashFailures"": [; {; ""causedBy"": [],; ""message"": ""Hashing request timed out for: s3://bucketname/cromwell-tests/Panel_BWA_GATK4_Samtools_Var_Annotate/162c863f-c22a-4b7c-bb37-f5195b329b36/call-ApplyBQSR/shard-0/smallTestData.hg38.recal.bam""; }; ],; ""allowResultReuse"": false,; ""hit"": false,; ""result"": ""Cache Miss"",; ""effectiveCallCachingMode"": ""CallCachingOff""; },; ```. Config file:. ```; include required(classpath(""application"")). call-caching {; enabled = true; invalidate-bad-cache-results = true; }. database {; # Store metadata in a file on disk that can grow much larger than RAM limits.; profile = ""slick.jdbc.HsqldbProfile$""; db {; driver = ""org.hsqldb.jdbcDriver""; url = ""jdbc:hsqldb:file:aws-database;shutdown=false;hsqldb.tx=mvcc""; connectionTimeout = 3000; }; }. aws {; application-name = ""cromwell""; auths = [; {; name = ""default""; scheme = ""default""; }; {; name = ""assume-role-based-on-another""; scheme = ""assume_role""; base-auth = ""default""; role-arn = ""arn:aws:iam::xxx:role/fbucketname""; }; ]; // diff 1:; # region = ""us-west-2"" // uses region from ~/.aws/config set by aws configu",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4563:1132,message,message,1132,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4563,1,['message'],['message']
Integrability,"utionActor [d57a5f97atac.filter:1:1]: job id: operations/EMi1zpL9KxjduPXRuKr-7gYgtY36-tsbKg9wcm9kdWN0aW9uUXVldWU; [2017-11-18 19:30:26,72] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.filter:1:1]: Status change from - to Initializing; [2017-11-18 21:25:57,96] [info] JesAsyncBackendJobExecutionActor [d57a5f97atac.bowtie2:0:1]: Status change from Initializing to Failed; [2017-11-18 21:25:58,22] [error] WorkflowManagerActor Workflow d57a5f97-8542-4fcc-89c4-b7c487957dea failed (during ExecutingWorkflowState): Task atac.bowtie2:0:1 failed. JES error code 5. Message: 9: Failed to localize files: failed to copy the following files: ""gs://atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar -> /mnt/local-disk/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar (cp failed: gsutil -q -m cp gs://atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar /mnt/local-disk/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar, command failed: BadRequestException: 400 Bucket is requester pays bucket but no user project provided.\nCommandException: 1 file/object could not be transferred.\n)""; java.lang.Exception: Task atac.bowtie2:0:1 failed. JES error code 5. Message: 9: Failed to localize files: failed to copy the following files: ""gs://atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar -> /mnt/local-disk/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar (cp failed: gsutil -q -m cp gs://atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar /mnt/local-disk/atac-seq-pipeline-genome-data/mm10/bowtie2_index/mm10_no_alt_analysis_set_ENCODE.fasta.tar, command failed: BadRequestException: 400 Bucket is requester pays bucket but no user project provided.\nCommandException: 1 file/object could not be transferred.\n)""; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2916:4517,Message,Message,4517,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2916,1,['Message'],['Message']
Integrability,uture.scala:24); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: javax.net.ssl.SSLHandshakeException: Remote host closed connection during handshake; at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:980); at sun.security.ssl.SSLSocketImpl.performInitialHandshake(SSLSocketImpl.java:1363); at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1391); at sun.security.ssl.SSLSocketImpl.startHandshake(SSLSocketImpl.java:1375); at sun.net.www.protocol.https.HttpsClient.afterConnect(HttpsClient.java:563); at sun.net.www.protocol.https.AbstractDelegateHttpsURLConnection.connect(AbstractDelegateHttpsURLConnection.java:185); at sun.net.www.protocol.https.HttpsURLConnectionImpl.connect(HttpsURLConnectionImpl.java:153); at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:93); at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:419); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:352); at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:469); at com.google.cloud.storage.spi.DefaultStorageRpc.get(DefaultStorageRpc.java:320); ... 31 more; Caused by: java.io.EOFException: SSL peer shut down incorrectly; at sun.security.ssl.InputRecord.read(InputRecord.java:505); at sun.security.ssl.SSLSocketImpl.readRecord(SSLSo,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1782:4414,protocol,protocol,4414,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1782,1,['protocol'],['protocol']
Integrability,"va.lang.Exception: Job 2de677d8-0842-4e17-ab26-288ffc3d8aaa failed for reason: unknown error: . {JobName: cromwell-job,JobId: 2de677d8-0842-4e17-ab26-288ffc3d8aaa,JobQueue: arn:aws:batch:us-east-1:369228243869:job-queue/mcovarr-queue-nouveau,Status: FAILED,StatusReason: **Container.image contains invalid characters.**,CreatedAt: 1488362254138,DependsOn: [],JobDefinition: arn:aws:batch:us-east-1:369228243869:job-definition/cromwell-job-definition:125,Parameters: {},Container: {**Image: library/python@sha256:d23845e4757f13266b42877c25b845e455127b85ec12e5d551bec5d8162e7cd4**,Vcpus: 1,Memory: 1907,Command: [/bin/sh, -c, /bin/bash /usr/share/iodir/91a31bc2-ad38-4853-8bd6-fa456c66021b/cromwell-executions/PairedEndSingleSampleWorkflow/91a31bc2-ad38-4853-8bd6-fa456c66021b/PairedEndSingleSampleWorkflow-CheckFinalVcfExtension-NA-1/script > /usr/share/iodir/91a31bc2-ad38-4853-8bd6-fa456c66021b/cromwell-executions/PairedEndSingleSampleWorkflow/91a31bc2-ad38-4853-8bd6-fa456c66021b/PairedEndSingleSampleWorkflow-CheckFinalVcfExtension-NA-1/stdout 2> /usr/share/iodir/91a31bc2-ad38-4853-8bd6-fa456c66021b/cromwell-executions/PairedEndSingleSampleWorkflow/91a31bc2-ad38-4853-8bd6-fa456c66021b/PairedEndSingleSampleWorkflow-CheckFinalVcfExtension-NA-1/stderr < /dev/null || echo -1 > /usr/share/iodir/91a31bc2-ad38-4853-8bd6-fa456c66021b/cromwell-executions/PairedEndSingleSampleWorkflow/91a31bc2-ad38-4853-8bd6-fa456c66021b/PairedEndSingleSampleWorkflow-CheckFinalVcfExtension-NA-1/rc],Volumes: [{Host: {SourcePath: /usr/share/iodir},Name: cromwell-volume}],Environment: [],MountPoints: [{ContainerPath: /usr/share/iodir,ReadOnly: false,SourceVolume: cromwell-volume}],Ulimits: [],}}. For this reason found in the ECS javadocs:. ```; Amazon ECS task definitions currently only support tags as image identifiers within a specified repository; (and not <code>sha256</code> digests); ```. Of course it would be preferable if these digests actually were supported by ECS, in which case we wouldn't need to",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2044:429,Depend,DependsOn,429,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2044,1,['Depend'],['DependsOn']
Integrability,"ve$(Actor.scala:512); 	at cromwell.backend.standard.callcaching.StandardFileHashingActor.akka$actor$Timers$$super$aroundReceive(StandardFileHashingActor.scala:59); 	at akka.actor.Timers.aroundReceive(Timers.scala:44); 	at akka.actor.Timers.aroundReceive$(Timers.scala:36); 	at cromwell.backend.standard.callcaching.StandardFileHashingActor.aroundReceive(StandardFileHashingActor.scala:59); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:527); 	at akka.actor.ActorCell.invoke(ActorCell.scala:496); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:234); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); [2018-05-02 15:22:54,89] [info] Message [cromwell.backend.standard.callcaching.StandardFileHashingActor$SingleFileHashRequest] from Actor[akka://cromwell-system/user/SingleWorkflowRunnerActor/WorkflowManagerActor/WorkflowActor-bc4644da-87f9-4765-9791-9011a2fae80f/WorkflowExecutionActor-bc4644da-87f9-4765-9791-9011a2fae80f/bc4644da-87f9-4765-9791-9011a2fae80f-EngineJobExecutionActor-batch_for_variantcall:NA:1/ejha_for_bc4644da-87f9-4765-9791-9011a2fae80f:BackendJobDescriptorKey_CommandCallNode_batch_for_variantcall:-1:1/CCHashingJobActor-bc4644da-batch_for_variantcall:NA:1#-1192719839] to Actor[akka://cromwell-system/user/SingleWorkflowRunnerActor/WorkflowManagerActor/WorkflowActor-bc4644da-87f9-4765-9791-9011a2fae80f/WorkflowExecutionActor-bc4644da-87f9-4765-9791-9011a2fae80f/bc4644da-87f9-4765-9791-9011a2fae80f-EngineJobExecutionActor-batch_for_variantcall:NA:1/ejha_for_bc4644da-87f9-4765-9791-9011a2fae80f:BackendJobDescriptorKey_CommandCallNode_batch_for_variantcall:-1:1/CCHashingJobActor-bc4644da-batch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3584:8566,Message,Message,8566,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3584,1,['Message'],['Message']
Integrability,"ver logs, the first time this is submitted, the workflow succeeds and the log shows nothing out of the ordinary. But ""sometimes"" (meaning, I can submit it 5 times and not see it, or twice and see it both times) I see this:; ```; 2017-02-07 15:01:10,781 cromwell-system-akka.dispatchers.service-dispatcher-30 ERROR - Sending Actor[akka://cromwell-system/user/cromwell-service/WorkflowManagerActor/WorkflowActor-84a51727-cfda-41e7-a03c-9e3af35eb0dc/MaterializeWorkflowDescriptorActor#972983209] failure message MetadataPutFailed(PutMetadataAction(Stream(MetadataEvent(MetadataKey(84a51727-cfda-41e7-a03c-9e3af35eb0dc,None,submittedFiles:imports:bar6.wdl),Some(MetadataValue(task doIt6 {; 	command { echo ""Help, world!"" }; 	output { String message = read_string(stdout()) }; },MetadataString)),2017-02-07T15:01:10.772+10:00), MetadataEvent(MetadataKey(84a51727-cfda-41e7-a03c-9e3af35eb0dc,None,submittedFiles:imports:bar4.wdl),Some(MetadataValue(task doIt4 {; 	command { echo ""Help, world!"" }; 	output { String message = read_string(stdout()) }; },MetadataString)),2017-02-07T15:01:10.774+10:00), MetadataEvent(MetadataKey(84a51727-cfda-41e7-a03c-9e3af35eb0dc,None,submittedFiles:imports:bar5.wdl),Some(MetadataValue(task doIt5 {; 	command { echo ""Help, world!"" }; 	output { String message = read_string(stdout()) }; },MetadataString)),2017-02-07T15:01:10.775+10:00), MetadataEvent(MetadataKey(84a51727-cfda-41e7-a03c-9e3af35eb0dc,None,submittedFiles:imports:bar3.wdl),Some(MetadataValue(task doIt3 {; 	command { echo ""Help, world!"" }; 	output { String message = read_string(stdout()) }; },MetadataString)),2017-02-07T15:01:10.776+10:00), MetadataEvent(MetadataKey(84a51727-cfda-41e7-a03c-9e3af35eb0dc,None,submittedFiles:imports:bar1.wdl),Some(MetadataValue(task doIt1 {; 	command { echo ""Help, world!"" }; 	output { String message = read_string(stdout()) }; },MetadataString)),2017-02-07T15:01:10.776+10:00), MetadataEvent(MetadataKey(84a51727-cfda-41e7-a03c-9e3af35eb0dc,None,submittedFiles:imports:bar",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1959:2269,message,message,2269,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1959,1,['message'],['message']
Integrability,"version numbers - please make sure you're using a compatible set of libraries. ; Uncaught error from thread [default-akka.actor.default-dispatcher-5]: akka.actor.ActorCell.addFunctionRef(Lscala/Function2;)Lakka/actor/FunctionRef;, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for for ActorSystem[default]; java.lang.NoSuchMethodError: akka.actor.ActorCell.addFunctionRef(Lscala/Function2;)Lakka/actor/FunctionRef;; ...; ```; I'm essentially seeing exactly the behaviour described in reference [1] below, which is eviction warnings at compile time and then the runtime blow-up. The root cause seems to be that akka-http depends on an older version of akka-actor (2.4.19) than that specified for the project (2.5.3). Running `dependencyTree` task confirms:; ```; [info] +-com.typesafe.akka:akka-http-spray-json_2.12:10.0.9 [S]; [info] | +-com.typesafe.akka:akka-http_2.12:10.0.9 [S]; [info] | | +-com.typesafe.akka:akka-http-core_2.12:10.0.9 [S]; [info] | | +-com.typesafe.akka:akka-parsing_2.12:10.0.9 [S]; [info] | | | +-com.typesafe.akka:akka-actor_2.12:2.4.19 (evicted by: 2.5.3); ```; If I explicitly add dependency on the latest akka-stream as suggested in [2] and [3], the problem goes away:; ```; diff --git a/project/Dependencies.scala b/project/Dependencies.scala; index 0d77e2d3..7254fc61 100644; --- a/project/Dependencies.scala; +++ b/project/Dependencies.scala; @@ -141,6 +141,7 @@ object Dependencies {; ; val cromwellApiClientDependencies = List(; ""com.typesafe.akka"" %% ""akka-actor"" % akkaV,; + ""com.typesafe.akka"" %% ""akka-stream"" % akkaV,; ""com.typesafe.akka"" %% ""akka-http-spray-json"" % akkaHttpV,; ""com.github.pathikrit"" %% ""better-files"" % betterFilesV,; ""org.scalatest"" %% ""scalatest"" % scalatestV % Test,; ```. References:; [1] https://github.com/akka/akka-http/issues/1101#issuecomment-299864185; [2] https://github.com/akka/akka-http/issues/1101#issuecomment-299923102; [3] http://akka.io/blog/news/2017/05/03/akka-http-10.0.6-released#compatibility-notes",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2579:1756,depend,dependency,1756,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2579,6,"['Depend', 'depend']","['Dependencies', 'dependency']"
Integrability,"version: `""cromwell"": ""30-f58c191-SNAP""`. I'm trying to get metadata for some workflows and it seems that for workflows whose subworkflows were running when cromwell was restarted are unable to retrieve their metadata. `/api/workflows/v1/8e9802db-f846-4ea5-a72c-55f257e53abe/metadata?expandSubWorkflows=true` . returns; ```; The server was not able to produce a timely response to your request.; Please try again in a short while!; ```; even if i try compressed payload or any other kind of trick I could think of. . If I try grabbing the metadata without expanding the subworkflows. `/api/workflows/v1/8e9802db-f846-4ea5-a72c-55f257e53abe/metadata?expandSubWorkflows=false`. returns the metadata just fine almost instantly. If I try to get the metadata of the subworkflow(s) directly it works as well. These workflows also have interesting responses to `includeKeys` parameter. When trying to get only the key `calls` from the workflow that was timing out (in hopes to make it not time out by requesting less data) . `/api/workflows/v1/8e9802db-f846-4ea5-a72c-55f257e53abe/metadata?expandSubWorkflows=true&includeKey=calls`. returns; ```; {; ""status"": ""error"",; ""message"": ""Received unexpected response while waiting for sub workflow metadata.""; }; ```; note `calls` is a key that normally doesn't return anything so normally you would expect to get. `/api/workflows/v1/905e2b4c-908d-4e93-a99c-ad20f6e4c41a/metadata?expandSubWorkflows=true&includeKey=calls`; ```; {}; ```; if you try to filter down the metadata to a key that does exist in the metadata like. `/api/workflows/v1/8e9802db-f846-4ea5-a72c-55f257e53abe/metadata?expandSubWorkflows=true&includeKey=call`. returns; ```; The server was not able to produce a timely response to your request.; Please try again in a short while!; ```; for the workflow that was restarted mid run (like it did when we were asking for the full metadata); and returns the `calls` metadata successfully for the workflow that always returned the metadata.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3209:1164,message,message,1164,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3209,1,['message'],['message']
Integrability,"w terminal. Shutting down.; [WARN] [06/02/2016 19:49:46.381] [test-system-akka.actor.default-dispatcher-3] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$ib]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.494] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.495] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$kb] $$kb transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [WARN] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$kb]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb] $$kb transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb] $$kb transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb/WorkflowInitializationActor-7218c3a1-5155-4921-9adb-d96c52c32200] State is now terminal. Shutting down.; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/933:2149,message,message,2149,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/933,1,['message'],['message']
Integrability,"w$lifecycle$materialization$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor(MaterializeWorkflowDescriptorActor.scala:231)""; },; {; causedBy: [ ],; message: ""cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$1.$anonfun$applyOrElse$1(MaterializeWorkflowDescriptorActor.scala:157)""; },; {; causedBy: [ ],; message: ""scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:304)""; },; {; causedBy: [ ],; message: ""scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37)""; },; {; causedBy: [ ],; message: ""scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60)""; },; {; causedBy: [ ],; message: ""akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55)""; },; {; causedBy: [ ],; message: ""akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91)""; },; {; causedBy: [ ],; message: ""scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)""; },; {; causedBy: [ ],; message: ""scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81)""; },; {; causedBy: [ ],; message: ""akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:91)""; },; {; causedBy: [ ],; message: ""akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40)""; },; {; causedBy: [ ],; message: ""akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:43)""; },; {; causedBy: [ ],; message: ""akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)""; },; {; causedBy: [ ],; message: ""akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)""; },; {; causedBy: [ ],; message: ""akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)""; },; {; causedBy: [ ],; message: ""akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)""; }; ],; message: ""Workflow input processing failed""; }; ],; ```. I think the culprit has something to do with both the root and ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3143:3124,message,message,3124,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3143,1,['message'],['message']
Integrability,w.scala:52); 	at cromwell.engine.io.nio.NioFlow$$anonfun$write$1.apply(NioFlow.scala:52); 	at scala.concurrent.impl.Future$PromiseCompletingRunnable.liftedTree1$1(Future.scala:24); 	at scala.concurrent.impl.Future$PromiseCompletingRunnable.run(Future.scala:24); 	... 6 more; Caused by: javax.net.ssl.SSLException: Connection has been shutdown: javax.net.ssl.SSLException: java.net.SocketException: Broken pipe; 	at sun.security.ssl.SSLSocketImpl.checkEOF(SSLSocketImpl.java:1541); 	at sun.security.ssl.AppInputStream.read(AppInputStream.java:95); 	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246); 	at java.io.BufferedInputStream.read1(BufferedInputStream.java:286); 	at java.io.BufferedInputStream.read(BufferedInputStream.java:345); 	at sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:704); 	at sun.net.www.http.HttpClient.parseHTTP(HttpClient.java:647); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream0(HttpURLConnection.java:1536); 	at sun.net.www.protocol.http.HttpURLConnection.getInputStream(HttpURLConnection.java:1441); 	at java.net.HttpURLConnection.getResponseCode(HttpURLConnection.java:480); 	at sun.net.www.protocol.https.HttpsURLConnectionImpl.getResponseCode(HttpsURLConnectionImpl.java:338); 	at com.google.api.client.http.javanet.NetHttpResponse.<init>(NetHttpResponse.java:37); 	at com.google.api.client.http.javanet.NetHttpRequest.execute(NetHttpRequest.java:94); 	at com.google.api.client.http.HttpRequest.execute(HttpRequest.java:981); 	at com.google.cloud.storage.spi.DefaultStorageRpc.write(DefaultStorageRpc.java:564); 	... 24 more; Caused by: javax.net.ssl.SSLException: java.net.SocketException: Broken pipe; 	at sun.security.ssl.Alerts.getSSLException(Alerts.java:208); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1949); 	at sun.security.ssl.SSLSocketImpl.fatal(SSLSocketImpl.java:1906); 	at sun.security.ssl.SSLSocketImpl.handleException(SSLSocketImpl.java:1870); 	at sun.security.ssl.SSLSocketImpl.handleExcepti,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2183:4729,protocol,protocol,4729,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2183,1,['protocol'],['protocol']
Integrability,"wState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.498] [test-system-akka.actor.default-dispatcher-7] [akka://test-system/user/$$kb/WorkflowInitializationActor-7218c3a1-5155-4921-9adb-d96c52c32200] State is now terminal. Shutting down.; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$a] $a: Call-to-Backend assignments: three_step.ps -> local, three_step.cgrep -> local, three_step.wc -> local; [INFO] [06/02/2016 19:49:46.544] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$a] $a transition from ReadyToMaterializeState to MaterializationSuccessfulState: shutting down; [INFO] [06/02/2016 19:49:46.544] [pool-7-thread-2-ScalaTest-running-WorkflowActorSpec] [akka://test-system/user/$$mb] $$mb transitioning from WorkflowUnstartedState to MaterializingWorkflowDescriptorState; [WARN] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-5] [akka://test-system/user] unhandled message from TestActor[akka://test-system/user/$$mb]: cromwell.engine.workflow.WorkflowActor$WorkflowFailedResponse; [INFO] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$mb] $$mb transitioning from InitializingWorkflowState to WorkflowFailedState; [INFO] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$mb] $$mb transition from InitializingWorkflowState to WorkflowFailedState: shutting down; [INFO] [06/02/2016 19:49:46.546] [test-system-akka.actor.default-dispatcher-6] [akka://test-system/user/$$mb/WorkflowInitializationActor-93102a71-3bff-432b-beb6-5506dcc13159] State is now terminal. Shutting down.; [info] WorkflowActorSpec:; [info] ShadowWorkflowActor; [info] - should move from WorkflowUnstartedState to MaterializingWorkflowDescriptorState *** FAILED ***; [info] WorkflowFailedState was not equal to MaterializingWorkflowDescriptorState (WorkflowActorSpec.scala:45); [info] - should trans",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/933:3598,message,message,3598,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/933,1,['message'],['message']
Integrability,"we working on an HPC without root and network and I often get the following message, does this mean that my cache calls are failing.; we using the singularity method of task execution; ```; cromwell-system-akka.dispatchers.engine-dispatcher-27 WARN - BackendPreparationActor_for_bcfd9d26:UnmappedBamToAlignedBam.SamToFastqAndBwaMemAndMba:14:1 [UUID(bcfd9d26)]: Docker lookup failed; cala:35); ```. How do I set it up to enable caching calls?. ------------------------------------------------------------------------------------------; running file; ```; java -jar -Ddocker.hash-lookup.method=local -Ddocker.hash-lookup.enabled=true -Dwebservice.port=8088 -Dwebservice.interface=0.0.0.0 -Dconfig.file=/work/share/ac7m4df1o5/bin/cromwell/3_config/cromwellslurmsingularitynew.conf ./cromwell-84.jar server. ```; config ; ```; # This line is required. It pulls in default overrides from the embedded cromwell; # `reference.conf` (in core/src/main/resources) needed for proper performance of cromwell.; include required(classpath(""application"")). # Cromwell HTTP server settings; webservice {; #port = 8000; #interface = 0.0.0.0; #binding-timeout = 5s; #instance.name = ""reference""; }; call-caching {; enabled = true; invalidate-bad-cache-results = true; }. # Cromwell ""system"" settings; system {; # If 'true', a SIGINT will trigger Cromwell to attempt to abort all currently running jobs before exiting; #abort-jobs-on-terminate = false. # this tells Cromwell to retry the task with Nx memory when it sees either OutOfMemoryError or Killed in the stderr file.; memory-retry-error-keys = [""OutOfMemory"", ""Out Of Memory"",""Out of memory""]; # If 'true', a SIGTERM or SIGINT will trigger Cromwell to attempt to gracefully shutdown in server mode,; # in particular clearing up all queued database writes before letting the JVM shut down.; # The shutdown is a multi-phase process, each phase having its own configurable timeout. See the Dev Wiki for more details.; #graceful-server-shutdown = true. # Cromwell wi",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6933:76,message,message,76,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6933,2,"['interface', 'message']","['interface', 'message']"
Integrability,"womDefinition(WdlWorkflow.scala:73)""; },; {; causedBy: [ ],; message: ""wdl.WdlInputParsing$.buildWomExecutable(WdlInputParsing.scala:27)""; },; {; causedBy: [ ],; message: ""wdl.WdlNamespaceWithWorkflow.womExecutable(WdlNamespace.scala:98)""; },; {; causedBy: [ ],; message: ""cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.$anonfun$validateWdlNamespace$15(MaterializeWorkflowDescriptorActor.scala:493)""; },; {; causedBy: [ ],; message: ""scala.util.Either.flatMap(Either.scala:338)""; },; {; causedBy: [ ],; message: ""cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.$anonfun$validateWdlNamespace$13(MaterializeWorkflowDescriptorActor.scala:491)""; },; {; causedBy: [ ],; message: ""scala.util.Either.flatMap(Either.scala:338)""; },; {; causedBy: [ ],; message: ""cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.validateWdlNamespace(MaterializeWorkflowDescriptorActor.scala:490)""; },; {; causedBy: [ ],; message: ""cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$lifecycle$materialization$MaterializeWorkflowDescriptorActor$$buildWorkflowDescriptor(MaterializeWorkflowDescriptorActor.scala:231)""; },; {; causedBy: [ ],; message: ""cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$1.$anonfun$applyOrElse$1(MaterializeWorkflowDescriptorActor.scala:157)""; },; {; causedBy: [ ],; message: ""scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:304)""; },; {; causedBy: [ ],; message: ""scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37)""; },; {; causedBy: [ ],; message: ""scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60)""; },; {; causedBy: [ ],; message: ""akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55)""; },; {; causedBy: [ ],; message: ""akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3143:1996,message,message,1996,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3143,1,['message'],['message']
Integrability,"work with containers. As is reported in these issues: #5405, #5370, #5346 . @cmarkello, @illusional, I am sorry that I insisted that `path+modtime` did work. I was using less complex workflows that did not have this problem at the time. ## Call-caching problems with file strategy; The `file` strategy does work as it uses md5sums in order to calculate the file hash. An unfortunate side effect of this is that md5 uses massive system resources. On HPC systems that are the target for the sfs-backend, this is a big problem. Cromwell will be run from a submit node on the system and greedily grab all processing power on the submit node to calculate all the md5sums. . ## Md5sums; Md5sums are reliable hashes for file integrity, but this was not their intended purpose. Md5sum was intended as a cryptographic hash. A cryptographic hash has the following properties (wikipedia):; 1. it is deterministic, meaning that the same message always results in the same hash; 2. it is quick to compute the hash value for any given message; 3. it is infeasible to generate a message that yields a given hash value; 4. it is infeasible to find two different messages with the same hash value; 5. a small change to a message should change the hash value so extensively that the new hash value appears uncorrelated with the old hash value (avalanche effect). I contest point 2, in that many cryptographic explicitly strife for being slow to calculate in order to negate brute force attempts.; Anyway: for call caching we only need points 1. and 4. All the rest is unnecessary ballast. . ## xxHash; Luckily there is a hashing algorithm that is designed explicitly for content hashing only. It was made to generate reliably different hashes for file content as fast as possible. It's called [xxHash](https://www.xxhash.com). There are Java implementations available and I did [some extensive benchmarking](https://github.com/rhpvorderman/hashtest/) to find out which one was best. The xxh64 (xxhash for 64 bit machin",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5450:1246,message,message,1246,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5450,1,['message'],['message']
Integrability,wrong cyclic dependency error,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3176:13,depend,dependency,13,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3176,1,['depend'],['dependency']
Integrability,"x"": ""--blacklist""; },; ""id"": ""#gridss-2.9.4.cwl/blacklist""; },; {; ""type"": ""string"",; ""doc"": ""portion of 6 sigma read pairs distribution considered concordantly mapped. Default: 0.995\n"",; ""inputBinding"": {; ""prefix"": ""--concordantreadpairdistribution""; },; ""default"": ""0.995"",; ""id"": ""#gridss-2.9.4.cwl/concordantreadpairdistribution""; },; {; ""type"": [; ""null"",; ""File""; ],; ""doc"": ""Optional - configuration file use to override default GRIDSS settings.\n"",; ""inputBinding"": {; ""prefix"": ""--configuration""; },; ""id"": ""#gridss-2.9.4.cwl/configuration""; },; {; ""type"": [; ""null"",; ""boolean""; ],; ""doc"": ""Optional - use the system version of bwa instead of the in-process version packaged with GRIDSS\n"",; ""inputBinding"": {; ""prefix"": ""--externalaligner""; },; ""default"": false,; ""id"": ""#gridss-2.9.4.cwl/externalaligner""; },; {; ""type"": [; ""null"",; ""string""; ],; ""doc"": ""Optional - location of GRIDSS jar\n"",; ""inputBinding"": {; ""prefix"": ""--jar""; },; ""default"": ""/opt/gridss/gridss-2.9.4-gridss-jar-with-dependencies.jar"",; ""id"": ""#gridss-2.9.4.cwl/jar""; },; {; ""type"": ""boolean"",; ""doc"": ""zero-based assembly job index (only required when performing parallel assembly across multiple computers)\n"",; ""inputBinding"": {; ""prefix"": ""--jobindex""; },; ""default"": false,; ""id"": ""#gridss-2.9.4.cwl/jobindex""; },; {; ""type"": ""boolean"",; ""doc"": ""total number of assembly jobs (only required when performing parallel assembly across multiple computers). Note than an assembly jobs is required after all indexed jobs have been completed to gather the output files together.\n"",; ""inputBinding"": {; ""prefix"": ""--jobnodes""; },; ""default"": false,; ""id"": ""#gridss-2.9.4.cwl/jobnodes""; },; {; ""type"": [; ""null"",; ""string""; ],; ""doc"": ""size of JVM heap for assembly and variant calling.\n"",; ""inputBinding"": {; ""prefix"": ""--jvmheap""; },; ""default"": ""$(get_max_memory_from_runtime_memory(runtime.ram))m"",; ""id"": ""#gridss-2.9.4.cwl/jvmheap""; },; {; ""type"": ""boolean"",; ""doc"": ""keep intermediate files. Not recommended ex",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5826:11930,depend,dependencies,11930,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5826,1,['depend'],['dependencies']
Integrability,"xxxxx-xxxxx-xxxxx"". caching {; # When a cache hit is found, the following duplication strategy will be followed to use the cached outputs; # Possible values: ""copy"", ""reference"". Defaults to ""copy""; # ""copy"": Copy the output files; # ""reference"": DO NOT copy the output files but point to the original output files instead.; # Will still make sure than all the original output files exist and are accessible before; # going forward with the cache hit.; duplication-strategy = ""copy""; }; }; }. default-runtime-attributes {; cpu: 4; failOnStderr: false; continueOnReturnCode: 0; memory: ""2 GB""; bootDiskSizeGb: 10; # Allowed to be a String, or a list of Strings; disks: ""local-disk 10 SSD""; noAddress: false; preemptible: 0; zones: [""us-central1-a"", ""us-central1-b""]; }. include ""papi_v2_reference_image_manifest.conf""; }; }; }; }; ```. WDL:. ```; task hello {; String addressee ; command {; echo ""Hello ${addressee}! Welcome to Cromwell . . . on Google Cloud!"" ; }; output {; String message = read_string(stdout()); }; runtime {; docker: ""ubuntu:latest""; }; }. workflow wf_hello {; call hello. output {; hello.message; }; }; ```. input. ```; {; ""wf_hello.hello.addressee"": ""World""; }; ```. Gcloud log (edited):. ```; done: true; metadata:; '@type': type.googleapis.com/google.cloud.lifesciences.v2beta.Metadata; createTime: '2021-08-03T15:21:55.984657Z'; endTime: '2021-08-03T15:24:03.533702405Z'; events:; - description: Worker released; timestamp: '2021-08-03T15:24:03.533702405Z'; workerReleased:; instance: google-pipelines-worker-xxxxxx; zone: us-central1-b; - containerStopped:; actionId: 19; description: Stopped running ""-c python -c 'import base64; print(base64.b64decode(\""xxxxxx""));'; > /tmp/xxxxxx.sh && chmod u+x /tmp/xxxxxx.sh; && sh /tmp/xxxxxx.sh""; timestamp: '2021-08-03T15:24:02.823519462Z'; - containerStarted:; actionId: 19; description: Started running ""-c python -c 'import base64; print(base64.b64decode(\""xxxxxx""));'; > /tmp/xxxxxx.sh && chmod u+x /tmp/xxxxxx.sh; && sh /tmp/xx",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6462:6235,message,message,6235,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6462,1,['message'],['message']
Integrability,"y d; }. command <<<; set -euo pipefail; ls ""~{d}""; >>>. output {; String s = read_string(stdout()); }. runtime {; docker: ""debian:stable-slim""; }; }; ```. On a first `141477ef-e8e6-4fb9-ae58-5c2e8a646088` run, callCaching for `task2` is negative, as it should, with this error:; ```; ""callCaching"": {; ""hashFailures"": [; {; ""causedBy"": [; {; ""message"": ""gs://my-bucket/cromwell-executions/main/141477ef-e8e6-4fb9-ae58-5c2e8a646088/call-task1/dir"",; ""causedBy"": []; }; ],; ""message"": ""[Attempted 1 time(s)] - FileNotFoundException: gs://my-bucket/cromwell-executions/main/141477ef-e8e6-4fb9-ae58-5c2e8a646088/call-task1/dir""; }; ],; ""allowResultReuse"": false,; ""hit"": false,; ""result"": ""Cache Miss"",; ""effectiveCallCachingMode"": ""CallCachingOff""; },; ```. Now though, the directory has been created as a result of the WDL succeeding:; ```; $ gsutil ls gs://my-bucket/cromwell-executions/main/141477ef-e8e6-4fb9-ae58-5c2e8a646088/call-task1/dir; gs://my-bucket/cromwell-executions/main/141477ef-e8e6-4fb9-ae58-5c2e8a646088/call-task1/dir/file; ```. On a second `2690f8a5-4cd4-45e2-a93a-55125a1107f8` run, callCaching for `task2` is negative again though, with this error:; ```; ""callCaching"": {; ""hashFailures"": [; {; ""causedBy"": [; {; ""message"": ""gs://my-bucket/cromwell-executions/main/141477ef-e8e6-4fb9-ae58-5c2e8a646088/call-task1/dir"",; ""causedBy"": []; }; ],; ""message"": ""[Attempted 1 time(s)] - FileNotFoundException: gs://my-bucket/cromwell-executions/main/141477ef-e8e6-4fb9-ae58-5c2e8a646088/call-task1/dir""; }; ],; ""allowResultReuse"": false,; ""hit"": false,; ""result"": ""Cache Miss"",; ""effectiveCallCachingMode"": ""CallCachingOff""; },; ```; However, the directory `gs://my-bucket/cromwell-executions/main/141477ef-e8e6-4fb9-ae58-5c2e8a646088/call-task1/dir` does exist from the previous run, so I am puzzled by the `FileNotFoundException` exception. Is it the case that directories cannot get cached by Crowmell and therefore callCaching does not work for tasks that have `Directory` as inputs?",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6509:1715,message,message,1715,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6509,2,['message'],['message']
Integrability,"y/ubuntu/images. You may want to check your internet connection or if you are behind a proxy.\n""; }],; ""workflowLog"": ""gs://fc-2d3fd356-e3be-4953-92f1-60af623e6fa5/b6b190d6-8640-4638-94cd-15f16b194f38/workflow.logs/workflow.c386672d-0248-4968-9b1a-114f5f5c4706.log"",; ""end"": ""2017-01-30T19:14:20.002Z"",; ""start"": ""2017-01-30T19:00:03.040Z""; }. ```; Here it's an array of ""message""s; ```; {; ""workflowName"": ""aggregate_data_workflow"",; ""submittedFiles"": {... },; ""calls"": {; ""aggregate_data_workflow.aggregate_data"": [{; ""retryableFailure"": false,; ""executionStatus"": ""Failed"",; ""stdout"": ""/cromwell-executions/aggregate_data_workflow/3608d6ca-fbb4-4232-b197-268058470bfc/call-aggregate_data/execution/stdout"",; ""shardIndex"": -1,; ""runtimeAttributes"": {; ""docker"": ""broadgdac/aggregate_data:31"",; ""failOnStderr"": false,; ""continueOnReturnCode"": ""0""; },; ""cache"": {; ""allowResultReuse"": true; },; ""Effective call caching mode"": ""CallCachingOff"",; ""inputs"": {...; },; ""returnCode"": -1,; ""failures"": [{; ""message"": ""Call aggregate_data_workflow.aggregate_data: return code was -1""; }, {; ""message"": ""Call aggregate_data_workflow.aggregate_data: return code was -1""; }, {; ""message"": ""Call aggregate_data_workflow.aggregate_data: return code was -1""; }],; ""jobId"": ""2957"",; ""backend"": ""JES"",; ""end"": ""2016-12-02T15:05:42.655Z"",; ""stderr"": ""/cromwell-executions/aggregate_data_workflow/3608d6ca-fbb4-4232-b197-268058470bfc/call-aggregate_data/execution/stderr"",; ""callRoot"": ""/cromwell-executions/aggregate_data_workflow/3608d6ca-fbb4-4232-b197-268058470bfc/call-aggregate_data"",; ""attempt"": 1,; ""executionEvents"": [...]; },; ""outputs"": {. },; ""workflowRoot"": ""gs://fc-2d3fd356-e3be-4953-92f1-60af623e6fa5/9ea737cd-a512-4c62-820c-dd1505ea7676/aggregate_data_workflow/3608d6ca-fbb4-4232-b197-268058470bfc"",; ""id"": ""3608d6ca-fbb4-4232-b197-268058470bfc"",; ""inputs"": {...; },; ""submission"": ""2016-12-01T21:21:40.188Z"",; ""status"": ""Failed"",; ""failures"": [{; ""message"": ""Call aggregate_data_workflow.aggregate_d",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2037:3902,message,message,3902,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2037,1,['message'],['message']
Integrability,"y: [ ],; message: ""akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91)""; },; {; causedBy: [ ],; message: ""scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12)""; },; {; causedBy: [ ],; message: ""scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81)""; },; {; causedBy: [ ],; message: ""akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:91)""; },; {; causedBy: [ ],; message: ""akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40)""; },; {; causedBy: [ ],; message: ""akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:43)""; },; {; causedBy: [ ],; message: ""akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260)""; },; {; causedBy: [ ],; message: ""akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339)""; },; {; causedBy: [ ],; message: ""akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979)""; },; {; causedBy: [ ],; message: ""akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107)""; }; ],; message: ""Workflow input processing failed""; }; ],; ```. I think the culprit has something to do with both the root and sub workflow both having a task called `GatherbamFiles` because when I renamed the task in the subworkflow (and all subsequent necessary renames) the workflow ran fine. When I tried to make a simple example of this I couldn't get the error to pop up again so I'm definitely missing some nuances of the cause. The root workflow passes womtool-30.1.jar validation. Root workflow - [SomaticPairedSingleSampleWf.txt](https://github.com/broadinstitute/cromwell/files/1635810/SomaticPairedSingleSampleWf.txt). Sub workflow - [SplitLargeRG.txt](https://github.com/broadinstitute/cromwell/files/1635814/SplitLargeRG.txt). Dependencies zip - [SomaticPairedSingleSampleWfDependencies.zip](https://github.com/broadinstitute/cromwell/files/1635815/SomaticPairedSingleSampleWfDependenc",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3143:3897,message,message,3897,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3143,1,['message'],['message']
Integrability,"} > $MUTECT1_CS; cat ${sep =' ' mutect1_cs} | grep -Pv '#'|grep -Pv '^contig' >> $MUTECT1_CS. #mutect2 call_stats merging; MUTECT2_CS=""MuTect2.call_stats.txt""; cat ${mutect2_cs[0]} |grep -P '^#' > $MUTECT2_CS ;; cat ${sep=' ' mutect2_cs} |grep -Pv '^#' >> $MUTECT2_CS ;; -eddie. On Wed, Mar 23, 2016 at 3:25 PM, Scott Frazer notifications@github.com; wrote:. > @tmdefreitas https://github.com/tmdefreitas Yes, that is definitely; > possible.; > ; > However, we try to not make assumptions about the type of characters that; > your script can have in it. I'm perhaps being a little overly cautious, but; > I'd hate for there to be a case where somebody wants to use a # in their; > command but it gets interpreted as a comment. That could lead to the same; > kind of confusion that we're seeing now.; > ; > I vacillate on this because I also see the pragmatism in implementing your; > suggestion for the common case. In most cases I can think of, a # is a; > comment; > ; > Maybe some approach like Eddie's where I can have the parser give a better; > error message is the best solution.; > ; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly or view it on GitHub; > https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200505343. ## . Edward A. Salinas; Senior Software Engineer - Getz Lab; Broad Institute of MIT and Harvard; 75 Ames Street, Rm 4013; Cambridge, MA 02142; Ph: 617-714-7905; Cell: 210-274-3172. ---. @tmdefreitas commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200510863). @eddiebroad But those are all quoted strings, and don't look the same as a WDL comment. From an implementation perspective, doesn't cromwell pipe the command block to /bin/bash anyway? And following bash rules unquoted `#` characters start a comment, so maybe WDL just has to follow the same comment parsing rules as bash?. ---. @eddiebroad commented on [Wed Mar 23 2016](https://github.com/broadins",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2870:4599,message,message,4599,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2870,1,['message'],['message']
Integrability,"},; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.wgs_coverage_interval_list' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_fasta_index' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.unmapped_bam_suffix' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_ud' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_amb' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.preemptible_tries' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_sa' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.known_indels_sites_VCFs' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_mu' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_alt' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_bwt' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.known_indels_sites_indices' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_dict' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.contamination_sites_bed' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.ref_fasta' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.dbSNP_vcf_index' not specified.""; },; {; causedBy: [ ],; message: ""Required workflow input 'SomaticRoot.TumorAlignment.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2912:1912,message,message,1912,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2912,1,['message'],['message']
Integrability,~Draft PR for Travis to mull over~ Ready for review! I did a smoke test on a FiaB as well to make sure CromIAM was cool with the dependency changes.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6646:129,depend,dependency,129,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6646,1,['depend'],['dependency']
Integrability,"~This PR is set to merge to `rsa_ss_jdr_integration_with_test` as it contains the JDR integration test. This way the localizer changes are tested against 2 drs centaur tests.~; ~Once [PR-5719](https://github.com/broadinstitute/cromwell/pull/5719) is merged to develop, the base of this PR will change to develop.~. ~Do not merge this PR before PR-5719 is merged to develop.~. Update: [PR-5719](https://github.com/broadinstitute/cromwell/pull/5719) has been merged. The base of this PR has now been updated to `develop`.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5740:86,integrat,integration,86,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5740,1,['integrat'],['integration']
Integrability,… instead of in the route tests,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1854:20,rout,route,20,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1854,1,['rout'],['route']
Integrability,"…old performance increase under load prior to DB gumming up. . Things to note:; - Effectively removes Metadata acks & failure notices (see #1811) via no longer emitting the messages but does not fully remove them. They still technically exist, I'll remove them as part of a separate PR; - Completely reworks `CromwellApiServiceSpec` to actually be testing `CromwellApiService` and not a general integration test of our REST endpoints. Two specific tests didn't make the cut (#1828 and #1829) I'll address in separate PRs. There were other tests which did not make the cut but were already effectively being tested in their appropriate units.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1836:173,message,messages,173,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1836,2,"['integrat', 'message']","['integration', 'messages']"
Modifiability,	 at mouse.AnyOps$.$bar$greater$extension(any.scala:8); 	 at cromwell.backend.standard.StandardAsyncExecutionActor.runtimeEnvironment(StandardAsyncExecutionActor.scala:479); 	 at cromwell.backend.standard.StandardAsyncExecutionActor.runtimeEnvironment$(StandardAsyncExecutionActor.scala:479); 	 at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.runtimeEnvironment$lzycompute(ConfigAsyncJobExecutionActor.scala:215); 	 at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.runtimeEnvironment(ConfigAsyncJobExecutionActor.scala:215); 	 at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand(StandardAsyncExecutionActor.scala:637); 	 at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand$(StandardAsyncExecutionActor.scala:607); 	 at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.instantiatedCommand$lzycompute(ConfigAsyncJobExecutionActor.scala:215); 	 at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.instantiatedCommand(ConfigAsyncJobExecutionActor.scala:215); 	 at cromwell.backend.standard.StandardAsyncExecutionActor.commandScriptContents(StandardAsyncExecutionActor.scala:383); 	 at cromwell.backend.standard.StandardAsyncExecutionActor.commandScriptContents$(StandardAsyncExecutionActor.scala:382); 	 at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.commandScriptContents(ConfigAsyncJobExecutionActor.scala:215); 	 at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.writeScriptContents(SharedFileSystemAsyncJobExecutionActor.scala:175); 	 at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.writeScriptContents$(SharedFileSystemAsyncJobExecutionActor.scala:174); 	 at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.writeScriptContents(ConfigAsyncJobExecutionActor.scala:215); 	 at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.execute(SharedFileSystemAsyncJobExecut,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6757:5739,config,config,5739,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6757,1,['config'],['config']
Modifiability, 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseKey(ConfigDocumentParser.java:279); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseObject(ConfigDocumentParser.java:450); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseValue(ConfigDocumentParser.java:247); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseObject(ConfigDocumentParser.java:458); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parse(ConfigDocumentParser.java:648); 	at com.typesafe.config.impl.ConfigDocumentParser.parse(ConfigDocumentParser.java:14); 	at com.typesafe.config.impl.Parseable.rawParseValue(Parseable.java:260); 	at com.typesafe.config.impl.Parseable.rawParseValue(Parseable.java:248); 	at com.typesafe.config.impl.Parseable.parseValue(Parseable.java:180); 	at com.typesafe.config.impl.Parseable.parseValue(Parseable.java:174); 	at com.typesafe.config.impl.Parseable.parse(Parseable.java:299); 	at com.typesafe.config.ConfigFactory.parseFile(ConfigFactory.java:689); 	at com.typesafe.config.DefaultConfigLoadingStrategy.parseApplicationConfig(DefaultConfigLoadingStrategy.java:51); 	at com.typesafe.config.ConfigFactory.defaultApplication(ConfigFactory.java:473); 	at com.typesafe.config.ConfigFactory$1.call(ConfigFactory.java:259); 	at com.typesafe.config.ConfigFactory$1.call(ConfigFactory.java:256); 	at com.typesafe.config.impl.ConfigImpl$LoaderCache.getOrElseUpdate(ConfigImpl.java:65); 	at com.typesafe.config.impl.ConfigImpl.computeCachedConfig(ConfigImpl.java:92); 	at com.typesafe.config.ConfigFactory.load(ConfigFactory.java:256); 	at com.typesafe.config.ConfigFactory.load(ConfigFactory.java:232); 	at cromwell.CromwellEntryPoint$.config$lzycompute(CromwellEntryPoint.scala:39); 	at cromwell.CromwellEntryPoint$.config(CromwellEntryPoint.scala:39); 	at cromwell.CromwellEntryPoint$.<init>(CromwellEntryPoint.scala:42); 	at cromwell.CromwellEntryPoint$.<clinit>(CromwellEntryPoint.scala); ```. In other words it te,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4549:2918,Config,ConfigFactory,2918,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4549,1,['Config'],['ConfigFactory']
Modifiability, 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.instantiatedCommand$lzycompute(ConfigAsyncJobExecutionActor.scala:113); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.instantiatedCommand(ConfigAsyncJobExecutionActor.scala:113); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor$class.execute(SharedFileSystemAsyncJobExecutionActor.scala:130); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.execute(ConfigAsyncJobExecutionActor.scala:113); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$executeOrRecover$2.apply(StandardAsyncExecutionActor.scala:264); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$executeOrRecover$2.apply(StandardAsyncExecutionActor.scala:258); 	at scala.util.Try$.apply(Try.scala:192); 	at cromwell.backend.standard.StandardAsyncExecutionActor$class.executeOrRecover(StandardAsyncExecutionActor.scala:258); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.executeOrRecover(ConfigAsyncJobExecutionActor.scala:113); 	at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$cromwell$backend$async$AsyncBackendJobExecutionActor$$robustExecuteOrRecover$1.apply(AsyncBackendJobExecutionActor.scala:56); 	at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$cromwell$backend$async$AsyncBackendJobExecutionActor$$robustExecuteOrRecover$1.apply(AsyncBackendJobExecutionActor.scala:56); 	at cromwell.core.retry.Retry$.withRetry(Retry.scala:37); 	at cromwell.backend.async.AsyncBackendJobExecutionActor$class.withRetry(AsyncBackendJobExecutionActor.scala:52); 	at cromwell.backend.async.AsyncBackendJobExecutionActor$class.cromwell$backend$async$AsyncBackendJobExecutionActor$$robustExecuteOrRecover(AsyncBackendJobExecutionActor.scala:56); 	at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$receive$1.applyOrElse(AsyncBackendJobExecutionActor.scala:80); 	at scala.PartialFunction$OrElse.a,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1944:4414,config,config,4414,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1944,2,['config'],['config']
Modifiability, 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.instantiatedCommand$lzycompute(ConfigAsyncJobExecutionActor.scala:113); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.instantiatedCommand(ConfigAsyncJobExecutionActor.scala:113); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor$class.execute(SharedFileSystemAsyncJobExecutionActor.scala:136); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.execute(ConfigAsyncJobExecutionActor.scala:113); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$executeOrRecover$2.apply(StandardAsyncExecutionActor.scala:306); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$executeOrRecover$2.apply(StandardAsyncExecutionActor.scala:300); 	at scala.util.Try$.apply(Try.scala:192); 	at cromwell.backend.standard.StandardAsyncExecutionActor$class.executeOrRecover(StandardAsyncExecutionActor.scala:300); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.executeOrRecover(ConfigAsyncJobExecutionActor.scala:113); 	at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$cromwell$backend$async$AsyncBackendJobExecutionActor$$robustExecuteOrRecover$1.apply(AsyncBackendJobExecutionActor.scala:47); 	at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$cromwell$backend$async$AsyncBackendJobExecutionActor$$robustExecuteOrRecover$1.apply(AsyncBackendJobExecutionActor.scala:47); 	at cromwell.core.retry.Retry$.withRetry(Retry.scala:37); 	at cromwell.backend.async.AsyncBackendJobExecutionActor$class.withRetry(AsyncBackendJobExecutionActor.scala:43); 	at cromwell.backend.async.AsyncBackendJobExecutionActor$class.cromwell$backend$async$AsyncBackendJobExecutionActor$$robustExecuteOrRecover(AsyncBackendJobExecutionActor.scala:47); 	at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$receive$1.applyOrElse(AsyncBackendJobExecutionActor.scala:71); 	at scala.PartialFunction$OrElse.a,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1950:4137,config,config,4137,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1950,1,['config'],['config']
Modifiability, 	at cromwell.backend.impl.sfs.config.DeclarationValidation$$anonfun$fromDeclarations$1.apply(DeclarationValidation.scala:17); 	at cromwell.backend.impl.sfs.config.DeclarationValidation$$anonfun$fromDeclarations$1.apply(DeclarationValidation.scala:17); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72); 	at scala.collection.AbstractIterable.foreach(Iterable.scala:54); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.AbstractTraversable.map(Traversable.scala:104); 	at cromwell.backend.impl.sfs.config.DeclarationValidation$.fromDeclarations(DeclarationValidation.scala:17); 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations$lzycompute(ConfigInitializationActor.scala:38); 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations(ConfigInitializationActor.scala:37); 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder$lzycompute(ConfigInitializationActor.scala:47); 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder(ConfigInitializationActor.scala:46); 	at cromwell.backend.sfs.SharedFileSystemInitializationActor.coerceDefaultRuntimeAttributes(SharedFileSystemInitializationActor.scala:90); 	at cromwell.backend.BackendWorkflowInitializationActor$class.validateRuntimeAttributes(BackendWorkflowInitializationActor.scala:138); 	at cromwell.backend.BackendWorkflowInitializationActor$class.initSequence(BackendWorkflowInitializationActor.scala:171); 	at cromwell.backend.sfs.SharedFileSystemInitializationActor.initSequence(SharedFileSystemInitializationActor.scala:37); 	at cromwell.ba,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1737:2054,Config,ConfigInitializationActor,2054,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1737,1,['Config'],['ConfigInitializationActor']
Modifiability," ""doc"": ""Optional - location of the GRIDSS assembly BAM. This file will be created by GRIDSS.\n"",; ""inputBinding"": {; ""prefix"": ""--assembly""; },; ""default"": "".assembly.bam"",; ""id"": ""#gridss-2.9.4.cwl/assembly""; },; {; ""type"": [; ""null"",; ""File""; ],; ""doc"": ""Optional - BED file containing regions to ignore\n"",; ""inputBinding"": {; ""prefix"": ""--blacklist""; },; ""id"": ""#gridss-2.9.4.cwl/blacklist""; },; {; ""type"": ""string"",; ""doc"": ""portion of 6 sigma read pairs distribution considered concordantly mapped. Default: 0.995\n"",; ""inputBinding"": {; ""prefix"": ""--concordantreadpairdistribution""; },; ""default"": ""0.995"",; ""id"": ""#gridss-2.9.4.cwl/concordantreadpairdistribution""; },; {; ""type"": [; ""null"",; ""File""; ],; ""doc"": ""Optional - configuration file use to override default GRIDSS settings.\n"",; ""inputBinding"": {; ""prefix"": ""--configuration""; },; ""id"": ""#gridss-2.9.4.cwl/configuration""; },; {; ""type"": [; ""null"",; ""boolean""; ],; ""doc"": ""Optional - use the system version of bwa instead of the in-process version packaged with GRIDSS\n"",; ""inputBinding"": {; ""prefix"": ""--externalaligner""; },; ""default"": false,; ""id"": ""#gridss-2.9.4.cwl/externalaligner""; },; {; ""type"": [; ""null"",; ""string""; ],; ""doc"": ""Optional - location of GRIDSS jar\n"",; ""inputBinding"": {; ""prefix"": ""--jar""; },; ""default"": ""/opt/gridss/gridss-2.9.4-gridss-jar-with-dependencies.jar"",; ""id"": ""#gridss-2.9.4.cwl/jar""; },; {; ""type"": ""boolean"",; ""doc"": ""zero-based assembly job index (only required when performing parallel assembly across multiple computers)\n"",; ""inputBinding"": {; ""prefix"": ""--jobindex""; },; ""default"": false,; ""id"": ""#gridss-2.9.4.cwl/jobindex""; },; {; ""type"": ""boolean"",; ""doc"": ""total number of assembly jobs (only required when performing parallel assembly across multiple computers). Note than an assembly jobs is required after all indexed jobs have been completed to gather the output files together.\n"",; ""inputBinding"": {; ""prefix"": ""--jobnodes""; },; ""default"": false,; ""id"": ""#gridss-2.9.4.cwl/jobno",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5826:11464,config,configuration,11464,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5826,1,['config'],['configuration']
Modifiability," # Copy paste the contents of a backend provider in this section; # Examples in cromwell.example.backends include:; # LocalExample: What you should use if you want to define a new backend provider; # AWS: Amazon Web Services; # BCS: Alibaba Cloud Batch Compute; # TES: protocol defined by GA4GH; # TESK: the same, with kubernetes support; # Google Pipelines, v2 (PAPIv2); # Docker; # Singularity: a container safe for HPC; # Singularity+Slurm: and an example on Slurm; # udocker: another rootless container solution; # udocker+slurm: also exemplified on slurm; # HtCondor: workload manager at UW-Madison; # LSF: the Platform Load Sharing Facility backend; # SGE: Sun Grid Engine; # SLURM: workload manager. # Note that these other backend examples will need tweaking and configuration.; # Please open an issue https://www.github.com/broadinstitute/cromwell if you have any questions; slurm {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; # Root directory where Cromwell writes job results in the container. This value; # can be used to specify where the execution folder is mounted in the container.; # it is used for the construction of the docker_cwd string in the submit-docker; # value above.; dockerRoot = ""/cromwell-executions"". concurrent-job-limit = 10; # If an 'exit-code-timeout-seconds' value is specified:; # - check-alive will be run at this interval for every job; # - if a job is found to be not alive, and no RC file appears after this interval; # - Then it will be marked as Failed.; ## Warning: If set, Cromwell will run 'check-alive' for every job at this interval; exit-code-timeout-seconds = 360; filesystems {; local {; localization: [; # soft link does not work for docker with --contain. Hard links won't work; # across file systems; ""copy"", ""hard-link"", ""soft-link""; ]; caching {; duplication-strategy: [""copy"", ""hard-link"", ""soft-link""]; hashing-strategy: ""file""; }; }; }. #; runtime-attributes = """"""; Int runtime_minutes =",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6933:6200,Config,ConfigBackendLifecycleActorFactory,6200,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6933,2,"['Config', 'config']","['ConfigBackendLifecycleActorFactory', 'config']"
Modifiability," # Funcotator inputs; Boolean? run_funcotator; String? sequencing_center; String? sequence_source; String? funco_reference_version; String? funco_output_format; Boolean? funco_compress; Boolean? funco_use_gnomad_AF; File? funco_data_sources_tar_gz; String? funco_transcript_selection_mode; File? funco_transcript_selection_list; Array[String]? funco_annotation_defaults; Array[String]? funco_annotation_overrides; Array[String]? funcotator_excluded_fields; Boolean? funco_filter_funcotations; String? funcotator_extra_args. String funco_default_output_format = ""MAF""; ; # Use as a last resort to increase the disk given to every task in case of ill behaving data; Int? emergency_extra_disk; }. Int contig_size = select_first([min_contig_size, 1000000]); Int preemptible_or_default = select_first([preemptible, 2]); Int max_retries_or_default = select_first([max_retries, 2]). Runtime standard_runtime = {""gatk_docker"": gatk_docker, ""gatk_override"": gatk_override,; ""max_retries"": max_retries_or_default, ""preemptible"": preemptible_or_default, ""cpu"": small_task_cpu,; ""machine_mem"": small_task_mem * 1000, ""command_mem"": small_task_mem * 1000 - 500,; ""disk"": small_task_disk, ""boot_disk_size"": boot_disk_size}. scatter (normal_bam in zip(normal_bams, normal_bais)) {; call m2.Mutect2 {; input:; intervals = intervals,; ref_fasta = ref_fasta,; ref_fai = ref_fai,; ref_dict = ref_dict,; tumor_reads = normal_bam.left,; tumor_reads_index = normal_bam.right,; scatter_count = scatter_count,; m2_extra_args = select_first([m2_extra_args, """"]) + ""--max-mnp-distance 0"",; gatk_override = gatk_override,; gatk_docker = gatk_docker,; preemptible = preemptible,; max_retries = max_retries,; pon = pon,; pon_idx = pon_idx,; gnomad = gnomad,; gnomad_idx = gnomad_idx; }; }. output {; Array[File] normal_calls = Mutect2.filtered_vcf; Array[File] normal_calls_idx = Mutect2.filtered_vcf_idx. }; }. ```; <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5347:6479,config,configuration,6479,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5347,1,['config'],['configuration']
Modifiability," ###; ### You may need to create an account before you can view/create issues.; ###. <!--; Hi! Thanks for taking the time to report feedback. Before posting an issue over in Jira tracker, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're almost in the right place. -->. <!-- You'll want to go to https://broadworkbench.atlassian.net/projects/BA/issues and then tell us: -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->; ; Jobs which required gpuType: ""nvidia-tesla-t4"", nvidiaDriverVersion: ""418.40.04"", failed. Our pipeline backend is Google : genomics.googleapis.com; ""jes"": {; ""endpointUrl"": ""https://genomics.googleapis.com/"",; ""zone"": ""us-central1-f"",; ....; },. job runtimeAttributes:; ...; ""preemptible"": ""1"",; ""gpuCount"": ""1"",; ""failOnStderr"": ""false"",; ""bootDiskSizeGb"": ""70"",; ""disks"": ""local-disk 70 SSD"",; ""continueOnReturnCode"": ""0"",; ""gpuType"": ""nvidia-tesla-t4"",; ""nvidiaDriverVersion"": ""418.40.04"",; ""maxRetries"": ""0"",; ""cpu"": ""8"",; ""cpuMin"": ""1"",; ""noAddress"": ""false"",; ""zone"": ""us-central1-f"",; ""memoryMin"": ""2 GB"",; ""memory"": ""64 GB"". Jobs failed with following message:; ""Task wf_quip_lymphocyte_segmentation_incep_v01052021.quip_lymphocyte_segmentation:NA:1 failed. The job was stopped before the command finished. PAPI error code 2. Execution failed: generic::unknown: installing drivers: container exited with unexpected exit code 1: + COS_KERNEL_INFO_FILENAME=kernel_info\n+ C",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6195:1063,config,configuration,1063,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6195,1,['config'],['configuration']
Modifiability," -jar cromwell-36.jar run glob.wdl; ```. The following output results:. ```; [2019-01-07 16:21:06,14] [info] Running with database db.url = jdbc:hsqldb:mem:094e8bf9-be0f-4d7c-854a-0cf1a15dc0d7;shutdown=false;hsqldb.tx=mvcc; [2019-01-07 16:21:16,40] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2019-01-07 16:21:16,42] [info] [RenameWorkflowOptionsInMetadata] 100%; [2019-01-07 16:21:16,62] [info] Running with database db.url = jdbc:hsqldb:mem:2efc8123-f7e8-4fe3-abed-48d1bcf8eb97;shutdown=false;hsqldb.tx=mvcc; [2019-01-07 16:21:17,27] [info] Slf4jLogger started; [2019-01-07 16:21:17,78] [info] Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-231ef13"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; [2019-01-07 16:21:17,87] [info] Metadata summary refreshing every 2 seconds.; [2019-01-07 16:21:17,94] [info] WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; [2019-01-07 16:21:18,00] [info] KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; [2019-01-07 16:21:18,02] [info] CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; [2019-01-07 16:21:19,53] [info] JobExecutionTokenDispenser - Distribution rate: 50 per 1 seconds.; [2019-01-07 16:21:19,58] [info] SingleWorkflowRunnerActor: Version 36; [2019-01-07 16:21:19,61] [info] SingleWorkflowRunnerActor: Submitting workflow; [2019-01-07 16:21:19,69] [info] Unspecified type (Unspecified version) workflow 18de8166-5f29-4288-9fa4-6741565446fd submitted; [2019-01-07 16:21:19,74] [info] SingleWorkflowRunnerActor: Workflow submitted [38;5;2m18de8166-5f29-4288-9fa4-6741565446fd[0m; [2019-01-07 16:21:19,75] [info] 1 new workflows fetched; [2019-01-07 16:21:19,77] [info] WorkflowManagerActor Starting workflow [38;5;2m18de8166-5f29-4288-9fa4-6741565446fd[0m; [2019-01-07 16:21",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4526:1546,config,configured,1546,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4526,1,['config'],['configured']
Modifiability," 1-00:00 -p core --cpus-per-task=1 --mem=4026 --wrap ""/usr/bin/env bash /projects/ngs/oncology/dev/bcbio_validation_workflows/somatic-giab-mix/cromwell_work/cromwell-executions/main-somatic-giab-mix.cwl/bc4644da-87f9-4765-9791-9011a2fae80f/call-batch_for_variantcall/execution/script""; [2018-05-02 15:16:57,63] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mbc4644da[0mbatch_for_variantcall:NA:1]: job id: 134053; [2018-05-02 15:16:57,66] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mbc4644da[0mbatch_for_variantcall:NA:1]: Status change from - to WaitingForReturnCodeFile; [2018-05-02 15:17:05,03] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mbc4644da[0mbatch_for_variantcall:NA:1]: Status change from WaitingForReturnCodeFile to Done; [2018-05-02 15:22:54,62] [[38;5;1merror[0m] Failed to hash null; java.io.FileNotFoundException: Cannot hash file null because it can't be found; 	at cromwell.backend.impl.sfs.config.ConfigHashingStrategy.usingStandardInitData$1(ConfigHashingStrategy.scala:46); 	at cromwell.backend.impl.sfs.config.ConfigHashingStrategy.getHash(ConfigHashingStrategy.scala:57); 	at cromwell.backend.impl.sfs.config.ConfigBackendFileHashingActor.customHashStrategy(ConfigBackendFileHashingActor.scala:26); 	at cromwell.backend.standard.callcaching.StandardFileHashingActor$$anonfun$fileHashingReceive$1.applyOrElse(StandardFileHashingActor.scala:79); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at akka.actor.Actor.aroundReceive(Actor.scala:514); 	at akka.actor.Actor.aroundReceive$(Actor.scala:512); 	at cromwell.backend.standard.callcaching.StandardFileHashingActor.akka$actor$Timers$$super$aroundReceive(StandardFileHashingActor.scala:59); 	at akka.actor.Timers.aroundReceive(Timers.scala:44); 	at akka.actor.Timers.aroundReceive$(Timers.scala:36); 	at cromwell.backend.standard.callcaching.StandardFileHashingActor.aroundReceive(StandardF",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3584:5004,Config,ConfigHashingStrategy,5004,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3584,1,['Config'],['ConfigHashingStrategy']
Modifiability," 16:15:32 GMT; Server: Docker Registry; X-XSS-Protection: 1; mode=block; X-Frame-Options: SAMEORIGIN; Alt-Svc: quic="":443""; ma=2592000; v=""41,39,38,37,35"". {; ""name"": ""unused"",; ""tag"": ""unused"",; ""architecture"": ""amd64"",; ""fsLayers"": [; {; ""blobSum"": ""sha256:a3ed95caeb02ffe68cdd9fd84406680ae93d633cb16422d00e8a7c22955b46d4""; },; {; ""blobSum"": ""sha256:1c4816548d6a2a08f89c304bf09503e791a338c4be90629610152124c7285d3f""; }; ],; ""history"": [; {; ""v1Compatibility"": ""{\""architecture\"":\""amd64\"",\""config\"":{\""ArgsEscaped\"":true,\""AttachStderr\"":false,\""AttachStdin\"":false,\""AttachStdout\"":false,\""Cmd\"":[\""/bin/bash\""],\""Domainname\"":\""\"",\""Entrypoint\"":[],\""Env\"":[\""PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\""],\""ExposedPorts\"":{},\""Hostname\"":\""6f82340aefbb\"",\""Image\"":\""sha256:7e927fe855b39870a9d03f4c3f8ae4b764d5e6847cdd0b7cee4be942e1ccc871\"",\""Labels\"":{},\""MacAddress\"":\""\"",\""NetworkDisabled\"":false,\""OnBuild\"":[],\""OpenStdin\"":false,\""Shell\"":[],\""StdinOnce\"":false,\""StopSignal\"":\""\"",\""Tty\"":false,\""User\"":\""\"",\""Volumes\"":{},\""WorkingDir\"":\""\""},\""container\"":\""be8ce157bc5ce90906f21220f2fd1442baa95c7284eead432626d6f1b4ac182e\"",\""container_config\"":{\""ArgsEscaped\"":true,\""AttachStderr\"":false,\""AttachStdin\"":false,\""AttachStdout\"":false,\""Cmd\"":[\""/bin/sh\"",\""-c\"",\""#(nop) \"",\""CMD [\\\""/bin/bash\\\""]\""],\""Domainname\"":\""\"",\""Entrypoint\"":[],\""Env\"":[\""PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\""],\""ExposedPorts\"":{},\""Hostname\"":\""6f82340aefbb\"",\""Image\"":\""sha256:7e927fe855b39870a9d03f4c3f8ae4b764d5e6847cdd0b7cee4be942e1ccc871\"",\""Labels\"":{},\""MacAddress\"":\""\"",\""NetworkDisabled\"":false,\""OnBuild\"":[],\""OpenStdin\"":false,\""Shell\"":[],\""StdinOnce\"":false,\""StopSignal\"":\""\"",\""Tty\"":false,\""User\"":\""\"",\""Volumes\"":{},\""WorkingDir\"":\""\""},\""created\"":\""2017-08-07T23:50:27.564116691Z\"",\""docker_version\"":\""17.03.1-ce\"",\""id\"":\""0a8d1e311b7797cd62611f599600a2e4633e4a7d1df9c1119141bd99c4842beb\"",\""os\"":\""linux\"",\""parent\"":\""63",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2826:2222,config,config,2222,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2826,1,['config'],['config']
Modifiability," 17:53:19,24] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2018-08-30 17:53:19,26] [info] [RenameWorkflowOptionsInMetadata] 100%; [2018-08-30 17:53:19,39] [info] Running with database db.url = jdbc:hsqldb:mem:146c8707-d56e-4f58-a2de-df327f328109;shutdown=false;hsqldb.tx=mvcc; [2018-08-30 17:53:20,13] [info] Slf4jLogger started; [2018-08-30 17:53:20,68] [info] Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-232861f"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; [2018-08-30 17:53:20,92] [info] Metadata summary refreshing every 2 seconds.; [2018-08-30 17:53:21,02] [info] CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; [2018-08-30 17:53:21,03] [info] KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; [2018-08-30 17:53:21,03] [info] WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; [2018-08-30 17:53:21,89] [info] JobExecutionTokenDispenser - Distribution rate: 50 per 1 seconds.; [2018-08-30 17:53:21,95] [info] SingleWorkflowRunnerActor: Version 34; [2018-08-30 17:53:21,97] [info] SingleWorkflowRunnerActor: Submitting workflow; [2018-08-30 17:53:22,05] [info] Unspecified type (Unspecified version) workflow 4dbd7d1c-e7e8-4f83-9750-5c638d1567bc submitted; [2018-08-30 17:53:22,16] [info] SingleWorkflowRunnerActor: Workflow submitted 4dbd7d1c-e7e8-4f83-9750-5c638d1567bc; [2018-08-30 17:53:22,16] [info] 1 new workflows fetched; [2018-08-30 17:53:22,16] [info] WorkflowManagerActor Starting workflow 4dbd7d1c-e7e8-4f83-9750-5c638d1567bc; [2018-08-30 17:53:22,17] [info] WorkflowManagerActor Successfully started WorkflowActor-4dbd7d1c-e7e8-4f83-9750-5c638d1567bc; [2018-08-30 17:53:22,17] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2018-08-30 17:53:22,18] [warn] SingleWorkflowRunnerActor: received u",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4062:1257,config,configured,1257,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4062,1,['config'],['configured']
Modifiability," 21:17:12,03] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2018-10-25 21:17:12,04] [info] [RenameWorkflowOptionsInMetadata] 100%; [2018-10-25 21:17:12,13] [info] Running with database db.url = jdbc:hsqldb:mem:c7a7ec22-dec6-4fae-a53b-6c9933402fa9;shutdown=false;hsqldb.tx=mvcc; [2018-10-25 21:17:12,59] [info] Slf4jLogger started; [2018-10-25 21:17:12,88] [info] Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-f5ccf1c"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; [2018-10-25 21:17:12,90] [info] Metadata summary refreshing every 2 seconds.; [2018-10-25 21:17:12,98] [info] KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; [2018-10-25 21:17:12,98] [info] CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; [2018-10-25 21:17:12,98] [info] WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; [2018-10-25 21:17:13,79] [info] JobExecutionTokenDispenser - Distribution rate: 50 per 1 seconds.; [2018-10-25 21:17:13,80] [info] SingleWorkflowRunnerActor: Version 36; [2018-10-25 21:17:13,81] [info] SingleWorkflowRunnerActor: Submitting workflow; [2018-10-25 21:17:13,84] [info] Unspecified type (Unspecified version) workflow e22c6324-5aec-4694-8750-f62160e2ca81 submitted; [2018-10-25 21:17:13,85] [info] SingleWorkflowRunnerActor: Workflow submitted e22c6324-5aec-4694-8750-f62160e2ca81; [2018-10-25 21:17:13,85] [info] 1 new workflows fetched; [2018-10-25 21:17:13,85] [info] WorkflowManagerActor Starting workflow e22c6324-5aec-4694-8750-f62160e2ca81; [2018-10-25 21:17:13,86] [info] WorkflowManagerActor Successfully started WorkflowActor-e22c6324-5aec-4694-8750-f62160e2ca81; [2018-10-25 21:17:13,86] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2018-10-25 21:17:13,86] [warn] SingleWorkflowRunnerActor: received u",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4318:10841,config,configured,10841,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4318,1,['config'],['configured']
Modifiability," 21:21:07,82] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2018-10-25 21:21:07,84] [info] [RenameWorkflowOptionsInMetadata] 100%; [2018-10-25 21:21:07,95] [info] Running with database db.url = jdbc:hsqldb:mem:d98689d1-c87b-486c-aa55-626823fb3bb1;shutdown=false;hsqldb.tx=mvcc; [2018-10-25 21:21:08,32] [info] Slf4jLogger started; [2018-10-25 21:21:08,56] [info] Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-fcf9c1d"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; [2018-10-25 21:21:08,59] [info] Metadata summary refreshing every 2 seconds.; [2018-10-25 21:21:08,63] [info] KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; [2018-10-25 21:21:08,64] [info] CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; [2018-10-25 21:21:08,64] [info] WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; [2018-10-25 21:21:09,79] [info] JobExecutionTokenDispenser - Distribution rate: 50 per 1 seconds.; [2018-10-25 21:21:09,81] [info] SingleWorkflowRunnerActor: Version 34; [2018-10-25 21:21:09,82] [info] SingleWorkflowRunnerActor: Submitting workflow; [2018-10-25 21:21:09,86] [info] Unspecified type (Unspecified version) workflow 0bb77c74-4c5c-4314-8463-072e7055ee7c submitted; [2018-10-25 21:21:09,90] [info] SingleWorkflowRunnerActor: Workflow submitted 0bb77c74-4c5c-4314-8463-072e7055ee7c; [2018-10-25 21:21:09,91] [info] 1 new workflows fetched; [2018-10-25 21:21:09,91] [info] WorkflowManagerActor Starting workflow 0bb77c74-4c5c-4314-8463-072e7055ee7c; [2018-10-25 21:21:09,91] [warn] SingleWorkflowRunnerActor: received unexpected message: Done in state RunningSwraData; [2018-10-25 21:21:09,92] [warn] Couldn't find a suitable DSN, defaulting to a Noop one.; [2018-10-25 21:21:09,92] [info] Using noop to send events.; [2018-10-2",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4318:1821,config,configured,1821,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4318,1,['config'],['configured']
Modifiability," : ""5 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; 2019-07-21 23:34:37,771 cromwell-system-akka.actor.default-dispatcher-3 INFO - KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; 2019-07-21 23:34:37,918 cromwell-system-akka.dispatchers.service-dispatcher-14 INFO - Metadata summary refreshing every 1 second.; 2019-07-21 23:34:38,046 WARN - 'docker.hash-lookup.gcr-api-queries-per-100-seconds' is being deprecated, use 'docker.hash-lookup.gcr.throttle' instead (see reference.conf); 2019-07-21 23:34:38,160 cromwell-system-akka.dispatchers.service-dispatcher-13 INFO - WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; 2019-07-21 23:34:38,160 cromwell-system-akka.dispatchers.engine-dispatcher-26 INFO - JobStoreWriterActor configured to flush with batch size 1000 and process rate 1 second.; 2019-07-21 23:34:38,594 cromwell-system-akka.dispatchers.engine-dispatcher-28 INFO - CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; 2019-07-21 23:34:38,667 cromwell-system-akka.dispatchers.engine-dispatcher-28 INFO - JobExecutionTokenDispenser - Distribution rate: 50 per 1 seconds.; 2019-07-21 23:34:39,131 cromwell-system-akka.dispatchers.backend-dispatcher-36 INFO - Running with 3 PAPI request workers; 2019-07-21 23:34:39,132 cromwell-system-akka.dispatchers.backend-dispatcher-36 INFO - PAPI request worker batch interval is 33333 milliseconds; 2019-07-21 23:34:39,157 cromwell-system-akka.dispatchers.backend-dispatcher-37 INFO - PAPI request worker batch interval is 33333 milliseconds; 2019-07-21 23:34:39,233 cromwell-system-akka.dispatchers.backend-dispatcher-38 INFO - PAPI request worker batch interval is 33333 milliseconds; ```. but then it immediately starts printing these errors:; ```; 2019-07-21 23:34:40,010 cromwell-system-akka.actor.default-dispatcher-32 ERROR - Error searching for abort requests; java.sql.SQLSyntaxErrorException: You have an error ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5084:2761,config,configured,2761,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5084,1,['config'],['configured']
Modifiability," = ""secret_secret""; },; {; name = ""service-account""; scheme = ""service_account""; service-account-id = ""my-service-account""; pem-file = ""/path/to/file.pem""; }; ]; }. engine {; // This instructs the engine which filesystems are at its disposal to perform any IO operation that it might need.; // For instance, WDL variables declared at the Workflow level will be evaluated using the filesystems declared here.; // If you intend to be able to run workflows with this kind of declarations:; // workflow {; // String str = read_string(""gs://bucket/my-file.txt""); // }; // You will need to provide the engine with a gcs filesystem; // Note that the default filesystem (local) is always available.; //filesystems {; // gcs {; // auth = ""application-default""; // }; //}; }. backend {; default = ""Local""; providers {; Local {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; concurrent-job-limit = 28; run-in-background = true; runtime-attributes = ""String? docker""; submit = ""/bin/bash ${script}""; submit-docker = ""docker run --rm -v ${cwd}:${docker_cwd} -i ${docker} /bin/bash < ${script}"". // Root directory where Cromwell writes job results. This directory must be; // visible and writeable by the Cromwell process as well as the jobs that Cromwell; // launches.; root: ""cromwell-executions"". filesystems {; gcs {; // A reference to a potentially different auth for manipulating files via engine functions.; auth = ""application-default""; }. local {; // Cromwell makes a link to your input files within <root>/<workflow UUID>/workflow-inputs; // The following are strategies used to make those links. They are ordered. If one fails; // The next one is tried:; //; // hard-link: attempt to create a hard-link to the file; // copy: copy the file; // soft-link: create a symbolic link to the file; //; // NOTE: soft-link will be skipped for Docker jobs; localization: [; ""soft-link"", ""hard-link"", ""copy""; ]; }; }; }; }; }; }. services {; KeyValue {; class = ""c",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1480:87898,Config,ConfigBackendLifecycleActorFactory,87898,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1480,2,"['Config', 'config']","['ConfigBackendLifecycleActorFactory', 'config']"
Modifiability," = ""us-central1"". # Restrict access to VM metadata. Useful in cases when untrusted containers are running under a service; # account not owned by the submitting user; restrict-metadata-access = false. # Pipelines v2 only: specify the number of times localization and delocalization operations should be attempted; # There is no logic to determine if the error was transient or not, everything is retried upon failure; # Defaults to 3; localization-attempts = 3. # Specifies the minimum file size for `gsutil cp` to use parallel composite uploads during delocalization.; # Parallel composite uploads can result in a significant improvement in delocalization speed for large files; # but may introduce complexities in downloading such files from GCS, please see; # https://cloud.google.com/storage/docs/gsutil/commands/cp#parallel-composite-uploads for more information.; #; # If set to 0 parallel composite uploads are turned off. The default Cromwell configuration turns off; # parallel composite uploads, this sample configuration turns it on for files of 150M or larger.; parallel-composite-upload-threshold=""150M""; }. # Controls how batched requests to PAPI are handled:; batch-requests {; timeouts {; # Timeout when attempting to connect to PAPI to make requests:; # read = 10 seconds. # Timeout waiting for batch responses from PAPI:; #; # Note: Try raising this value if you see errors in logs like:; # WARN - PAPI request worker PAPIQueryWorker-[...] terminated. 99 run creation requests, 0 status poll requests, and 0 abort requests will be reconsidered. If any of those succeeded in the cloud before the batch request failed, they might be run twice.; # ERROR - Read timed out; # connect = 10 seconds; }; }; filesystems {; gcs {; # A reference to a potentially different auth for manipulating files via engine functions.; auth = ""application-default""; # Google project which will be billed for the requests; project = ""xxxxx-xxxxx-xxxxx"". caching {; # When a cache hit is found, the following",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6462:4276,config,configuration,4276,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6462,2,['config'],['configuration']
Modifiability," GS URLs referencing the same data and does work. The workflow fails with:; ```; java.io.FileNotFoundException: Cannot hash file https://storage.googleapis.com/bcbiodata/test_bcbio_cwl/testdata/genom; es/hg19/seq/hg19.fa; ```; when running tasks. The files get downloaded to the input directories but get numerical values instead of the original file names so never seem to sync over and get translated correctly to the workflow; ```; ls -lh cromwell_work/cromwell-executions/main-somatic.cwl/eaa632df-52a8-4aae-826f-647a42fa7145/call-prep_samples_to_rec/inputs/1515144/; total 136K; -rw------- 2 chapmanb chapmanb 292 Sep 26 14:07 225050424226294657; -rw------- 2 chapmanb chapmanb 43 Sep 26 14:07 2612405277530248055; -rw------- 2 chapmanb chapmanb 43 Sep 26 14:07 503001634356675169; -rw------- 2 chapmanb chapmanb 292 Sep 26 14:07 5802330287039666628; -rw------- 2 chapmanb chapmanb 43 Sep 26 14:07 5809676514510180826; -rw------- 2 chapmanb chapmanb 43 Sep 26 14:07 6090832304768530540; -rw------- 2 chapmanb chapmanb 43 Sep 26 14:07 6105514522473810611; -rw------- 3 chapmanb chapmanb 37K Sep 26 14:07 6807576659333162957; -rw------- 3 chapmanb chapmanb 150 Sep 26 14:07 6853384576121493061; -rw------- 2 chapmanb chapmanb 292 Sep 26 14:07 7483350933664987331; -rw------- 2 chapmanb chapmanb 292 Sep 26 14:07 7538690575330349970; -rw------- 3 chapmanb chapmanb 37K Sep 26 14:07 7691692211431528147; -rw------- 2 chapmanb chapmanb 292 Sep 26 14:07 7783203266940950463; -rw------- 3 chapmanb chapmanb 150 Sep 26 14:07 8389565043859020157; -rw------- 2 chapmanb chapmanb 43 Sep 26 14:07 8932347409858620277; -rw------- 2 chapmanb chapmanb 292 Sep 26 14:07 993751307168383758; ```; My configuration is:; ```; engine {; filesystems {; gcs {; auth = ""application-default""; }; http {}; }; }. backend {; providers {; Local {; config {; filesystems {; http { }; }; }; }; }; }; ```; Am I doing anything wrong with my configuration or setup that I could tweak? Thanks so much for any pointers/suggestions.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4184:2105,config,configuration,2105,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4184,3,['config'],"['config', 'configuration']"
Modifiability, Mar 09 00:55:25 web start-cromwell.sh[110916]: at org.apache.commons.codec.digest.DigestUtils.md5Hex(DigestUtils.java:310); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.backend.impl.sfs.config.HashFileStrategy.$anonfun$hash$3(ConfigHashingStrategy.scala:82); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.util.TryWithResource$.$anonfun$tryWithResource$1(TryWithResource.scala:16); Mar 09 00:55:25 web start-cromwell.sh[110916]: at scala.util.Try$.apply(Try.scala:209); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.util.TryWithResource$.tryWithResource(TryWithResource.scala:10); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.backend.impl.sfs.config.HashFileStrategy.hash(ConfigHashingStrategy.scala:82); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.backend.impl.sfs.config.ConfigHashingStrategy.usingStandardInitData$1(ConfigHashingStrategy.scala:52); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.backend.impl.sfs.config.ConfigHashingStrategy.getHash(ConfigHashingStrategy.scala:57); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.backend.impl.sfs.config.ConfigBackendFileHashingActor.customHashStrategy(ConfigBackendFileHashingActor.scala:26); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.backend.standard.callcaching.StandardFileHashingActor$$anonfun$fileHashingReceive$1.applyOrElse(StandardFileHashingActor.scala:73); Mar 09 00:55:25 web start-cromwell.sh[110916]: at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); Mar 09 00:55:25 web start-cromwell.sh[110916]: at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); Mar 09 00:55:25 web start-cromwell.sh[110916]: at akka.actor.Actor.aroundReceive(Actor.scala:514); Mar 09 00:55:25 web start-cromwell.sh[110916]: at akka.actor.Actor.aroundReceive$(Actor.scala:512); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.backend.standard.callcaching.StandardFileHashingActor.aroundReceive(Standa,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3383:2924,config,config,2924,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3383,1,['config'],['config']
Modifiability," Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->. When trying to configure metadata-archive in cromwell server by adding the configuration below:; ```; archive-metadata {; # A filesystem able to access the specified bucket:; filesystems {; gcs {; # A reference to the auth to use for storing and retrieving metadata:; auth = ""user-service-account""; }; }. # Which bucket to use for storing the archived metadata; bucket = ""{{ backend_bucket }}""; }; ```. when the user-service-account auth is declared up in the configuration :; ```; google {. application-name = ""cromwell"". auths = [; {; name = ""user-service-account""; scheme = ""user_service_account""; }; ]; }; ```; We got the following error in Cromwell server initialization :; cromwell_1 | [ERROR] [06/21/2023 11:55:25.094] [cromwell-system-akka.actor.default-dispatcher-30] [akka://cromwell-system/user] Failed to parse the archive-metadata config:; cromwell_1 | Failed to construct archiver path builders from factories (reason 1 of 1): Missing parameters in workflow options: user_service_account_json; cromwell_1 | akka.actor.ActorInitializationException: akka://cromwell-system/user/cromwell-service/ServiceRegistryActor/MetadataService: exception during creation; cromwell_1 | 	at akka.actor.ActorInitializationException$.apply(Actor.scala:202); cromwell_1 | 	at akka.actor.ActorCell.create(ActorCell.scala:698); cromwell_1 | 	at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:549); cromwell_1 | 	at akka.actor.ActorCell.systemInvoke(ActorCell.scala:571); cromwell_1 | 	at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:293); cromwell_1 | 	at akka.dispatch.Mailbox.run(Mailbox.scala:228); cromwell_1 | 	at akka.dispatch.Mailbox.exec(Mailbox.scala:241); cromwell_1 | 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260). this code line causes the error above:; https://github.com/broadinstitute/cromwell/blob/develop/services/src/main/scala/cromwell/",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7171:1520,config,config,1520,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7171,1,['config'],['config']
Modifiability," [2018-10-25 21:21:09,81] [info] SingleWorkflowRunnerActor: Version 34; [2018-10-25 21:21:09,82] [info] SingleWorkflowRunnerActor: Submitting workflow; [2018-10-25 21:21:09,86] [info] Unspecified type (Unspecified version) workflow 0bb77c74-4c5c-4314-8463-072e7055ee7c submitted; [2018-10-25 21:21:09,90] [info] SingleWorkflowRunnerActor: Workflow submitted 0bb77c74-4c5c-4314-8463-072e7055ee7c; [2018-10-25 21:21:09,91] [info] 1 new workflows fetched; [2018-10-25 21:21:09,91] [info] WorkflowManagerActor Starting workflow 0bb77c74-4c5c-4314-8463-072e7055ee7c; [2018-10-25 21:21:09,91] [warn] SingleWorkflowRunnerActor: received unexpected message: Done in state RunningSwraData; [2018-10-25 21:21:09,92] [warn] Couldn't find a suitable DSN, defaulting to a Noop one.; [2018-10-25 21:21:09,92] [info] Using noop to send events.; [2018-10-25 21:21:09,93] [info] WorkflowManagerActor Successfully started WorkflowActor-0bb77c74-4c5c-4314-8463-072e7055ee7c; [2018-10-25 21:21:09,93] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2018-10-25 21:21:09,93] [info] WorkflowStoreHeartbeatWriteActor configured to flush with batch size 10000 and process rate 2 minutes.; [2018-10-25 21:21:09,96] [info] MaterializeWorkflowDescriptorActor [0bb77c74]: Parsing workflow as WDL draft-2; [2018-10-25 21:21:10,57] [info] MaterializeWorkflowDescriptorActor [0bb77c74]: Call-to-Backend assignments: test_opt_array.t1 -> Local; [2018-10-25 21:21:12,86] [info] WorkflowExecutionActor-0bb77c74-4c5c-4314-8463-072e7055ee7c [0bb77c74]: Condition met: 'go'. Running conditional section; [2018-10-25 21:21:16,98] [info] WorkflowExecutionActor-0bb77c74-4c5c-4314-8463-072e7055ee7c [0bb77c74]: Starting test_opt_array.t1 (5 shards); [2018-10-25 21:21:19,02] [info] BackgroundConfigAsyncJobExecutionActor [0bb77c74test_opt_array.t1:2:1]: echo 2 > out.txt; [2018-10-25 21:21:19,02] [info] BackgroundConfigAsyncJobExecutionActor [0bb77c74test_opt_array.t1:4:1]: echo 4 > out.txt; [2018-10-25 21:21:19,02] [info] Backg",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4318:3092,config,configured,3092,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4318,1,['config'],['configured']
Modifiability," [warn] Couldn't find a suitable DSN, defaulting to a Noop one.; ```. This appears to be because `raven-logback` is activated in logback.xml but is not configured by default in Cromwell. **Background:**; [Sentry](https://sentry.io/) describes itself as:. > Open-source error tracking that helps developers monitor and fix crashes in real time. Cromwell is using an deprecated version of the Sentry java bindings for logback called `raven-logback`. The current bindings are called `sentry-logback`. Additionally, the cromwell docs currently mention that sentry can be setup via the ""configuration value"" `sentry.dsn`. https://github.com/broadinstitute/cromwell/blob/b8d3d2fd4a583d3e46394efb104005c12cdf182d/docs/Logging.md#L48. https://github.com/broadinstitute/cromwell/blob/b8d3d2fd4a583d3e46394efb104005c12cdf182d/docs/Configuring.md#L345-L355. This is not correct as `raven-logback` nor its underlying library `raven` use Typesafe Config. Instead for `raven` the value must be set as a system property, or alternatively as a different environment variable. However the latest `sentry` library (and transitively `sentry-logback`) do allow code configuration via `Sentry.init`. **A/C:**; - Replace `raven-logback` dependency with `sentry-logback`; - ~Allow setting a `cromwell.sentry.*` stanza with Cromwell specific sentry configuration. Alternative namespaces could be `sentry.*` or `system.sentry.*`, but both namespaces may collide with other library/application configurations in the future!~; - ~Wire the `cromwell.sentry.*` HOCON fields into `Sentry.init`~; - ~Default the sentry DSN in `reference.conf` to a noop -OR- ensure that when an error is generated that the latest version of `sentry` does not output a ""suitable DSN"" warning~; - Update docs for Cromwell+Sentry in both `docs/Logging.md` and `docs/Configuring.md`; - ~Update `CHANGELOG.md` with configuration changes for Cromwell+Sentry~ Edit: Not necessary if still using sentry style configuration. **Links:**; - http://cromwell.re",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3657:1444,variab,variable,1444,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3657,1,['variab'],['variable']
Modifiability," \""id\"": \""#gridss-2.9.4.cwl/jobnodes\""\n },\n {\n \""type\"": [\n \""null\"",\n \""string\""\n ],\n \""doc\"": \""size of JVM heap for assembly and variant calling.\\n\"",\n \""inputBinding\"": {\n \""prefix\"": \""--jvmheap\""\n },\n \""default\"": \""$(get_max_memory_from_runtime_memory(runtime.ram))m\"",\n \""id\"": \""#gridss-2.9.4.cwl/jvmheap\""\n },\n {\n \""type\"": \""boolean\"",\n \""doc\"": \""keep intermediate files. Not recommended except for debugging due to the high disk usage.\\n\"",\n \""inputBinding\"": {\n \""prefix\"": \""--keepTempFiles\""\n },\n \""default\"": false,\n \""id\"": \""#gridss-2.9.4.cwl/keepTempFiles\""\n },\n {\n \""type\"": [\n \""null\"",\n \""string\""\n ],\n \""doc\"": \""comma separated labels to use in the output VCF for the input files.\\nSupporting read counts for input files with the same label are aggregated\\n(useful for multiple sequencing runs of the same sample).\\nLabels default to input filenames, unless a single read group with a non-empty sample name\\nexists in which case the read group sample name is used\\n(which can be disabled by \\\""useReadGroupSampleNameCategoryLabel=false\\\"" in the configuration file).\\nIf labels are specified, they must be specified for all input files.\\n\"",\n \""inputBinding\"": {\n \""prefix\"": \""--labels\""\n },\n \""id\"": \""#gridss-2.9.4.cwl/labels\""\n },\n {\n \""type\"": [\n \""null\"",\n \""int\""\n ],\n \""doc\"": \""Optional - maximum coverage. Regions with coverage in excess of this are ignored.\\n\"",\n \""inputBinding\"": {\n \""prefix\"": \""--maxcoverage\""\n },\n \""id\"": \""#gridss-2.9.4.cwl/maxcoverage\""\n },\n {\n \""type\"": \""boolean\"",\n \""doc\"": \""do not use JNI native code acceleration libraries (snappy, GKL, ssw, bwa).\\n\"",\n \""inputBinding\"": {\n \""prefix\"": \""--nojni\""\n },\n \""default\"": false,\n \""id\"": \""#gridss-2.9.4.cwl/nojni\""\n },\n {\n \""type\"": \""string\"",\n \""doc\"": \""output gzipped VCF file\\n\"",\n \""inputBinding\"": {\n \""prefix\"": \""--output\""\n },\n \""id\"": \""#gridss-2.9.4.cwl/output\""\n },\n {\n \""type\"": [\n \""null\"",\n ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5826:75937,config,configuration,75937,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5826,1,['config'],['configuration']
Modifiability," `womtool validate` (and it validated fine on Terra with the automatic validation they do). But the job would run about halfway and then automatically switch to ""Aborting"" status with no explanation or error message. The workflow would eventually fail after a huge delay (about 22 hours), and there would be no real error message. All tasks that ran were successful (but not all tasks ran). # Minimal WDL example. Here is a working example:. ```wdl; version 1.0. workflow my_workflow {; call my_task; }. task my_task {; command {; echo ""hello world""; }; output {; File out = stdout(); }; }; ```. And here is a non-working example that still validates fine using `womtool validate`:. ```wdl; version 1.0. workflow my_workflow {; input {; Boolean run_task; }. if (run_task) {; call my_task; }. output {; File out = select_first([my_task.out, stdout()]); }; }. task my_task {; command {; echo ""hello world""; }; output {; File out = stdout(); }; }; ```. The above gives; ```console; (cromwell) [sfleming@laptop:~/cromwell]$ womtool validate test.wdl ; Success!; ```. # The problem. The problem is that the non-working WDL example above should not validate successfully, as it is NOT a valid WDL. The `stdout()` built-in inside the `select_first()` in the `output` block of the `workflow` is not actually allowed. It will cause a very bizarre error when this WDL is run. # What am I asking for?. 1. Fix `womtool validate` to catch these kinds of errors. Also happens with `stderr()`.; 2. Provide an actionable error message when this kind of edge case ends up being run by Cromwell. Right now it automatically moves to ""Aborting"" status with no error message at all. Very hard to diagnose!. # Other information. I found this error using `miniwdl check`, which correctly identified the error, just FYI. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6976:2564,config,configuration,2564,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6976,1,['config'],['configuration']
Modifiability," a bug? Then great! You're almost in the right place. -->. <!-- You'll want to go to https://broadworkbench.atlassian.net/projects/BA/issues and then tell us: -->. <!-- Which backend are you running? -->; Our backend: ; GCP PAPIv2 ; actor-factory = ""cromwell.backend.google.pipelines.v2alpha1.PipelinesApiLifecycleActorFactory"". endpoint-url = ""https://genomics.googleapis.com/"". <!-- Paste/Attach your workflow if possible: -->; workflow runtime; runtime {; docker: ""us.gcr.io/cloudypipelines-com/til_segmentation:1.5""; bootDiskSizeGb: 70; disks: ""local-disk 70 SSD""; memory: ""52 GB""; cpu: ""8""; maxRetries: 1; gpuCount: 1; zones: ""us-east1-d us-east1-c us-central1-a us-central1-c us-west1-a us-west1-b""; ##gpuType: ""nvidia-tesla-k80""; gpuType: ""nvidia-tesla-t4""; nvidiaDriverVersion: ""418.40.04""; ##nvidiaDriverVersion: ""418.87.00""; ; }. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->; #### Recently, Our All workflows with GPU failed under the same configurations which most of workflows used to work on Cromwell 48, we updated to the latest Cromwell 52, still had the same errors, see belowL. 2020-08-04 23:44:00,228 cromwell-system-akka.dispatchers.engine-dispatcher-38 INFO - WorkflowManagerActor Workflow f1dca11c-ea29-48b1-9691-9f30c9e59154 failed (during ExecutingWorkflowState): java.lang.Exception: Task wf_quip_lymphocyte_segmentation_v03232020.quip_lymphocyte_segmentation:NA:2 failed. The job was stopped before the command finished. PAPI error code 2. Execution failed: generic::unknown: installing drivers: container exited with unexpected exit code 1: + COS_DOWNLOAD_GCS=https://storage.googleapis.com/cos-tools; + COS_KERNEL_SRC_GIT=https://chromium.googlesource.com/chromiumos/third_party/kernel; + COS_KERNEL_SRC_ARCHIVE=kernel-src.tar.gz; + TOOLCHAIN_URL_FILENAME=toolchain_url; + TOOLCHAIN_ARCHIVE=toolchain.tar.xz; + TOOLCHAIN_ENV_FILENAME=toolchain_env; + CHROMIUMOS_SDK_GCS=https://storage.googleapis.com/chrom",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5714:1648,config,configuration,1648,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5714,2,['config'],"['configuration', 'configurations']"
Modifiability," activated in logback.xml but is not configured by default in Cromwell. **Background:**; [Sentry](https://sentry.io/) describes itself as:. > Open-source error tracking that helps developers monitor and fix crashes in real time. Cromwell is using an deprecated version of the Sentry java bindings for logback called `raven-logback`. The current bindings are called `sentry-logback`. Additionally, the cromwell docs currently mention that sentry can be setup via the ""configuration value"" `sentry.dsn`. https://github.com/broadinstitute/cromwell/blob/b8d3d2fd4a583d3e46394efb104005c12cdf182d/docs/Logging.md#L48. https://github.com/broadinstitute/cromwell/blob/b8d3d2fd4a583d3e46394efb104005c12cdf182d/docs/Configuring.md#L345-L355. This is not correct as `raven-logback` nor its underlying library `raven` use Typesafe Config. Instead for `raven` the value must be set as a system property, or alternatively as a different environment variable. However the latest `sentry` library (and transitively `sentry-logback`) do allow code configuration via `Sentry.init`. **A/C:**; - Replace `raven-logback` dependency with `sentry-logback`; - ~Allow setting a `cromwell.sentry.*` stanza with Cromwell specific sentry configuration. Alternative namespaces could be `sentry.*` or `system.sentry.*`, but both namespaces may collide with other library/application configurations in the future!~; - ~Wire the `cromwell.sentry.*` HOCON fields into `Sentry.init`~; - ~Default the sentry DSN in `reference.conf` to a noop -OR- ensure that when an error is generated that the latest version of `sentry` does not output a ""suitable DSN"" warning~; - Update docs for Cromwell+Sentry in both `docs/Logging.md` and `docs/Configuring.md`; - ~Update `CHANGELOG.md` with configuration changes for Cromwell+Sentry~ Edit: Not necessary if still using sentry style configuration. **Links:**; - http://cromwell.readthedocs.io/en/develop/Configuring/#workflow-log-directory; - http://cromwell.readthedocs.io/en/develop/Logging/#wo",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3657:1540,config,configuration,1540,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3657,1,['config'],['configuration']
Modifiability, akka.actor.ActorInitializationException: akka://cromwell-system/user/SingleWorkflowRunnerActor/ServiceRegistryActor: exception during creation ; at akka.actor.ActorInitializationException$.apply(Actor.scala:193) ; at akka.actor.ActorCell.create(ActorCell.scala:669) ; at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:523) ; at akka.actor.ActorCell.systemInvoke(ActorCell.scala:545) ; at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:283) ; at akka.dispatch.Mailbox.run(Mailbox.scala:224) ; at akka.dispatch.Mailbox.exec(Mailbox.scala:235) ; at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) ; at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) ; at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) ; at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) ; Caused by: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'services' ; at com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:156) ; at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:174) ; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:188) ; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:193) ; at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:268) ; at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:41) ; at cromwell.services.ServiceRegistryActor$.serviceNameToPropsMap(ServiceRegistryActor.scala:35) ; at cromwell.services.ServiceRegistryActor.serviceProps(ServiceRegistryActor.scala:63) ; at cromwell.services.ServiceRegistryActor.<init>(ServiceRegistryActor.scala:65) ; at cromwell.services.ServiceRegistryActor$.$anonfun$props$1(ServiceRegistryActor.scala:25) ; at akka.actor.TypedCreatorFunctionConsumer.produce(IndirectActorProducer.scala:87) ; at akka.actor.Props.newActor(Props.scala:212) ; at akka.actor.ActorCell.newActor(ActorCell.scala:624) ; at akka.actor.ActorC,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4577:1491,config,config,1491,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4577,1,['config'],['config']
Modifiability, akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: java.lang.Exception: Failed command instantiation; at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand(StandardAsyncExecutionActor.scala:576); at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand$(StandardAsyncExecutionActor.scala:511); at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.instantiatedCommand$lzycompute(ConfigAsyncJobExecutionActor.scala:200); at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.instantiatedCommand(ConfigAsyncJobExecutionActor.scala:200); at cromwell.backend.standard.StandardAsyncExecutionActor.commandScriptContents(StandardAsyncExecutionActor.scala:319); at cromwell.backend.standard.StandardAsyncExecutionActor.commandScriptContents$(StandardAsyncExecutionActor.scala:318); at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.commandScriptContents(ConfigAsyncJobExecutionActor.scala:200); at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.writeScriptContents(SharedFileSystemAsyncJobExecutionActor.scala:175); at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.writeScriptContents$(SharedFileSystemAsyncJobExecutionActor.scala:174); at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.cromwell$backend$sfs$BackgroundAsyncJobExecutionActor$$super$writeScriptContents(ConfigAsyncJobExecutionActor.scala:200); at cromwell.backend.sfs.BackgroundAsyncJobExecutionActor.writeScriptContents(BackgroundAsyncJobExecutionActor.scala:12); at cromwell.backend.sfs.BackgroundAsyncJobExecutionActor.writeScriptContents$(BackgroundAsyncJobExecutionActor.scala:11); at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.writeScriptContents(ConfigAsyncJobExecutionActor.scala:200); at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.execute(SharedFileSystemAsyncJobExecutionActor.scala:15,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5092:3260,Config,ConfigAsyncJobExecutionActor,3260,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5092,1,['Config'],['ConfigAsyncJobExecutionActor']
Modifiability, at cromwell.backend.standard.StandardAsyncExecutionActor.commandScriptContents$(StandardAsyncExecutionActor.scala:318); at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.commandScriptContents(ConfigAsyncJobExecutionActor.scala:200); at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.writeScriptContents(SharedFileSystemAsyncJobExecutionActor.scala:175); at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.writeScriptContents$(SharedFileSystemAsyncJobExecutionActor.scala:174); at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.cromwell$backend$sfs$BackgroundAsyncJobExecutionActor$$super$writeScriptContents(ConfigAsyncJobExecutionActor.scala:200); at cromwell.backend.sfs.BackgroundAsyncJobExecutionActor.writeScriptContents(BackgroundAsyncJobExecutionActor.scala:12); at cromwell.backend.sfs.BackgroundAsyncJobExecutionActor.writeScriptContents$(BackgroundAsyncJobExecutionActor.scala:11); at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.writeScriptContents(ConfigAsyncJobExecutionActor.scala:200); at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.execute(SharedFileSystemAsyncJobExecutionActor.scala:158); at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.execute$(SharedFileSystemAsyncJobExecutionActor.scala:155); at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.execute(ConfigAsyncJobExecutionActor.scala:200); at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$executeAsync$1(StandardAsyncExecutionActor.scala:639); at scala.util.Try$.apply(Try.scala:209); at cromwell.backend.standard.StandardAsyncExecutionActor.executeAsync(StandardAsyncExecutionActor.scala:639); at cromwell.backend.standard.StandardAsyncExecutionActor.executeAsync$(StandardAsyncExecutionActor.scala:639); at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.executeAsync(ConfigAsyncJobExecutionActor.scala:200); at cromwell.back,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5092:4039,config,config,4039,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5092,1,['config'],['config']
Modifiability," backend configuration, since whether this is something you want to do or not will depend on the infrastucture your workflow is running on. One potential way to configure this, might be to add multipliers for certain runtime attributes in the backend configuration:; ```; [...]; config {; runtime-attributes = """"""; Int? cpu = 1; Int? memory = 4; """"""; runtime-attribute-retry-multipliers = {; memory: 1.5; }; [...]; }; [...]; ```. This would, for example, cause the memory attribute to be multiplied by `1.5` with each retry. For the first attempt it would be `4`, for the the second `6`, the third `9` etc. Another option might be that the values here indicate a fraction of the original attribute which it should be increased it by each retry, so in the above example it would be: `4` -> `10` -> `16` etc. You would probably want set a lower value in that case, though. Another option would be to supply a list of numbers with each indicating a multiplier for a certain attempt. A value of `[1.5, 2]` (or maybe `[1, 1.5, 2]`) would cause the value to be multiplied by `1.5` on the second attempt and `2` on the third, repeating the last multiplier if neccesary. (ie. `4` -> `6` -> `8` -> `8`). <!--; Hi! Thanks for taking the time to report feedback. Before posting an issue here, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're in the right place. -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4346:2235,config,configuration,2235,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4346,1,['config'],['configuration']
Modifiability, com.typesafe.config.ConfigFactory.parseResourcesAnySyntax(ConfigFactory.java:1083); at com.typesafe.config.impl.SimpleIncluder.includeResourceWithoutFallback(SimpleIncluder.java:123); at com.typesafe.config.impl.SimpleIncluder.includeResources(SimpleIncluder.java:109); at com.typesafe.config.impl.ConfigParser$ParseContext.parseInclude(ConfigParser.java:181); at com.typesafe.config.impl.ConfigParser$ParseContext.parseObject(ConfigParser.java:237); at com.typesafe.config.impl.ConfigParser$ParseContext.parseValue(ConfigParser.java:103); at com.typesafe.config.impl.ConfigParser$ParseContext.parse(ConfigParser.java:415); at com.typesafe.config.impl.ConfigParser.parse(ConfigParser.java:25); at com.typesafe.config.impl.Parseable.rawParseValue(Parseable.java:263); at com.typesafe.config.impl.Parseable.rawParseValue(Parseable.java:250); at com.typesafe.config.impl.Parseable.parseValue(Parseable.java:180); at com.typesafe.config.impl.Parseable.parseValue(Parseable.java:174); at com.typesafe.config.impl.Parseable.parse(Parseable.java:301); at com.typesafe.config.ConfigFactory.parseFile(ConfigFactory.java:793); at com.typesafe.config.ConfigFactory.parseApplicationReplacement(ConfigFactory.java:1166); at com.typesafe.config.DefaultConfigLoadingStrategy.parseApplicationConfig(DefaultConfigLoadingStrategy.java:11); at com.typesafe.config.ConfigFactory.defaultApplication(ConfigFactory.java:532); at com.typesafe.config.ConfigFactory$1.call(ConfigFactory.java:264); at com.typesafe.config.ConfigFactory$1.call(ConfigFactory.java:261); at com.typesafe.config.impl.ConfigImpl$LoaderCache.getOrElseUpdate(ConfigImpl.java:66); at com.typesafe.config.impl.ConfigImpl.computeCachedConfig(ConfigImpl.java:93); at com.typesafe.config.ConfigFactory.load(ConfigFactory.java:261); at com.typesafe.config.ConfigFactory.load(ConfigFactory.java:237); at cromwell.languages.util.ImportResolver$HttpResolver$.apply(ImportResolver.scala:237); at womtool.input.WomGraphMaker$.importResolvers$lzycompute$1(WomGrap,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7255:2223,config,config,2223,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7255,1,['config'],['config']
Modifiability," creating a `CallableTaskDefinition` structure. This structure has an empty meta section. When rewriting `foo` in draft-2, this works as expected. . ```wdl; version 1.0. task foo {; input {; String buf ; }; command {}; output {; String s = buf; } ; meta {; type : ""native"",; id: ""applet-xxxx""; }; }; ```. This is the code used to parse the task: ; ```scala; // Extract the only task from a namespace ; def getMainTask(bundle: WomBundle) : CallableTaskDefinition = {; // check if the primary is nonempty ; val task: Option[CallableTaskDefinition] = bundle.primaryCallable match {; case Some(task : CallableTaskDefinition) => Some(task); case Some(exec : ExecutableTaskDefinition) => Some(exec.callableTaskDefinition); case _ => None; }; task match {; case Some(x) => x; case None =>; // primary is empty, check the allCallables map ; if (bundle.allCallables.size != 1); throw new Exception(""WDL file must contains exactly one task""); val (_, task) = bundle.allCallables.head; task match {; case task : CallableTaskDefinition => task; case exec : ExecutableTaskDefinition => exec.callableTaskDefinition; case _ => throw new Exception(""Cannot find task inside WDL file""); 		}; }; }. def parseWdlTask(wfSource: String) : CallableTaskDefinition = {; val languageFactory =; if (wfSource.startsWith(""version 1.0"") ||; wfSource.startsWith(""version draft-3"")) {; new WdlDraft3LanguageFactory(ConfigFactory.empty()); } else {; new WdlDraft2LanguageFactory(ConfigFactory.empty()); }. val bundleChk: Checked[WomBundle] =; languageFactory.getWomBundle(wfSource, ""{}"", List.empty, List(languageFactory)); val womBundle = bundleChk match {; case Left(errors) => throw new Exception(s""""""|WOM validation errors: ; | ${errors} ; |"""""".stripMargin); case Right(bundle) => bundle; }; val task: Option[CallableTaskDefinition] = bundle.primaryCallable match {; case Some(task : CallableTaskDefinition) => Some(task); case Some(exec : ExecutableTaskDefinition) => Some(exec.callableTaskDefinition); case _ => None; }. }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4709:1465,Config,ConfigFactory,1465,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4709,2,['Config'],['ConfigFactory']
Modifiability," cromwell.CromwellApp.main(CromwellApp.scala); Caused by: com.typesafe.config.ConfigException$Parse: /data/cephfs/punim0751/spartan.conf: 27: expecting a close parentheses ')' here, not: end of file; 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseError(ConfigDocumentParser.java:201); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseError(ConfigDocumentParser.java:197); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseKey(ConfigDocumentParser.java:279); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseObject(ConfigDocumentParser.java:450); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseValue(ConfigDocumentParser.java:247); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseObject(ConfigDocumentParser.java:458); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parse(ConfigDocumentParser.java:648); 	at com.typesafe.config.impl.ConfigDocumentParser.parse(ConfigDocumentParser.java:14); 	at com.typesafe.config.impl.Parseable.rawParseValue(Parseable.java:260); 	at com.typesafe.config.impl.Parseable.rawParseValue(Parseable.java:248); 	at com.typesafe.config.impl.Parseable.parseValue(Parseable.java:180); 	at com.typesafe.config.impl.Parseable.parseValue(Parseable.java:174); 	at com.typesafe.config.impl.Parseable.parse(Parseable.java:299); 	at com.typesafe.config.ConfigFactory.parseFile(ConfigFactory.java:689); 	at com.typesafe.config.DefaultConfigLoadingStrategy.parseApplicationConfig(DefaultConfigLoadingStrategy.java:51); 	at com.typesafe.config.ConfigFactory.defaultApplication(ConfigFactory.java:473); 	at com.typesafe.config.ConfigFactory$1.call(ConfigFactory.java:259); 	at com.typesafe.config.ConfigFactory$1.call(ConfigFactory.java:256); 	at com.typesafe.config.impl.ConfigImpl$LoaderCache.getOrElseUpdate(ConfigImpl.java:65); 	at com.typesafe.config.impl.ConfigImpl.computeCachedConfig(ConfigImpl.java:92); 	at com.typesafe.config.ConfigFactory.loa",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4549:2507,Config,ConfigDocumentParser,2507,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4549,1,['Config'],['ConfigDocumentParser']
Modifiability, cromwell.backend.sfs.SharedFileSystem$$anonfun$localizeInputs$1.applyOrElse(SharedFileSystem.scala:199); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); 	at scala.util.Failure.recoverWith(Try.scala:203); 	at cromwell.backend.sfs.SharedFileSystem$class.localizeInputs(SharedFileSystem.scala:199); 	at cromwell.backend.sfs.SharedFileSystemJobCachingActorHelper$$anon$1.localizeInputs(SharedFileSystemJobCachingActorHelper.scala:40); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor$$anonfun$commandLinePreProcessor$1.apply(SharedFileSystemAsyncJobExecutionActor.scala:127); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor$$anonfun$commandLinePreProcessor$1.apply(SharedFileSystemAsyncJobExecutionActor.scala:127); 	at cromwell.backend.wdl.Command$.instantiate(Command.scala:27); 	at cromwell.backend.standard.StandardAsyncExecutionActor$class.instantiatedCommand(StandardAsyncExecutionActor.scala:83); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.instantiatedCommand$lzycompute(ConfigAsyncJobExecutionActor.scala:113); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.instantiatedCommand(ConfigAsyncJobExecutionActor.scala:113); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor$class.execute(SharedFileSystemAsyncJobExecutionActor.scala:136); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.execute(ConfigAsyncJobExecutionActor.scala:113); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$executeOrRecover$2.apply(StandardAsyncExecutionActor.scala:306); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$executeOrRecover$2.apply(StandardAsyncExecutionActor.scala:300); 	at scala.util.Try$.apply(Try.scala:192); 	at cromwell.backend.standard.StandardAsyncExecutionActor$class.executeOrRecover(StandardAsyncExecutionActor.scala:300); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecuti,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1950:3171,config,config,3171,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1950,1,['config'],['config']
Modifiability," cromwell.backend.standard.callcaching.StandardFileHashingActor.aroundReceive(StandardFileHashingActor.scala:59); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:527); 	at akka.actor.ActorCell.invoke(ActorCell.scala:496); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:234); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); [2018-05-02 15:22:54,71] [[38;5;1merror[0m] bc4644da:batch_for_variantcall:-1:1: Hash error, disabling call caching for this job.; java.io.FileNotFoundException: Cannot hash file null because it can't be found; 	at cromwell.backend.impl.sfs.config.ConfigHashingStrategy.usingStandardInitData$1(ConfigHashingStrategy.scala:46); 	at cromwell.backend.impl.sfs.config.ConfigHashingStrategy.getHash(ConfigHashingStrategy.scala:57); 	at cromwell.backend.impl.sfs.config.ConfigBackendFileHashingActor.customHashStrategy(ConfigBackendFileHashingActor.scala:26); 	at cromwell.backend.standard.callcaching.StandardFileHashingActor$$anonfun$fileHashingReceive$1.applyOrElse(StandardFileHashingActor.scala:79); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at akka.actor.Actor.aroundReceive(Actor.scala:514); 	at akka.actor.Actor.aroundReceive$(Actor.scala:512); 	at cromwell.backend.standard.callcaching.StandardFileHashingActor.akka$actor$Timers$$super$aroundReceive(StandardFileHashingActor.scala:59); 	at akka.actor.Timers.aroundReceive(Timers.scala:44); 	at akka.actor.Timers.aroundReceive$(Timers.scala:36); 	at cromwell.backend.standard.callcaching.StandardFileHashingActor.aroundReceive(StandardF",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3584:6917,Config,ConfigHashingStrategy,6917,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3584,1,['Config'],['ConfigHashingStrategy']
Modifiability," development, so that I don't have to repeat multi-hour steps. However, I'm currently seeing ~8 minute delays for processing cache hits. With multiple steps in serial, this means that nothing in my pipeline starts running till 14 minutes after I start the run. Can you help me fix that?. Thank you for the help!. Happy to provide any more info than the below if that's helpful. I'm running with cromwell 84. Here's the command I'm running `java -Dconfig.file=workflow/cromwell.conf -jar utilities/cromwell-84.jar run workflow/expanse_workflow.wdl`. Here's my configuration (ignore the SLURM part, I'm not using it yet). Potentially important bits:; * I'm running with the local backend.; * I'm using symlink caching so that should be fast, with path+timestamp hash codes so the whole file doesn't need to be read; * I'm using the file based Hsql database. I don't see why that should matter, but maybe it does.; ```; # See https://cromwell.readthedocs.io/en/stable/Configuring/; # only use double quotes!; include required(classpath(""application"")). system {; abort-jobs-on-terminate = true; io {; number-of-requests = 30; per = 1 second; }; }. ## file based persistent database; database {; profile = ""slick.jdbc.HsqldbProfile$""; db {; driver = ""org.hsqldb.jdbcDriver""; url = """"""; jdbc:hsqldb:file:cromwell-executions/cromwell-db/cromwell-db;; shutdown=false;; hsqldb.default_table_type=cached;hsqldb.tx=mvcc;; hsqldb.result_max_memory_rows=10000;; hsqldb.large_data=true;; hsqldb.applog=1;; hsqldb.lob_compressed=true;; hsqldb.script_format=3; """"""; connectionTimeout = 120000; numThreads = 1; }; }. call-caching {; enabled = true; }. backend {; default = ""Local""; providers { ; Local {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; concurrent-job-limit = 10; run-in-background = true; submit = ""/usr/bin/env bash ${script}""; root = ""cromwell-executions""; filesystems {; local {; localization: [""soft-link""]; caching {; duplication-strategy: [""soft",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6971:1104,Config,Configuring,1104,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6971,1,['Config'],['Configuring']
Modifiability, download error: Caught java.net.UnknownHostException: oss.sonatype.org (oss.sonatype.org) while downloading https://oss.sonatype.org/content/repositories/snapshots/org/apache/httpcomponents/httpcomponents-core/4.0.1/httpcomponents-core-4.0.1.pom; org.apache.commons:commons-parent:5 ; not found: /root/.ivy2/local/org.apache.commons/commons-parent/5/ivys/ivy.xml; download error: Caught java.net.UnknownHostException: repo1.maven.org (repo1.maven.org) while downloading https://repo1.maven.org/maven2/org/apache/commons/commons-parent/5/commons-parent-5.pom; download error: Caught java.net.UnknownHostException: oss.sonatype.org (oss.sonatype.org) while downloading https://oss.sonatype.org/content/repositories/snapshots/org/apache/commons/commons-parent/5/commons-parent-5.pom; ...; CommandException: No URLs matched: /cromwell_root/stderr; 2019/07/10 18:38:31 Delocalizing output /cromwell_root/rc -> gs://fc-94bba050-4ef1-42fb-8436-cd89da17ec53/306ddffc-0ee6-46ff-ac3e-5069668a0eb0/ga4ghMd5/a14f0b9d-839c-4684-863c-93d0e8e2d527/call-md5/rc; 2019/07/10 18:38:32 rm -f $HOME/.config/gcloud/gce && gsutil cp /cromwell_root/rc gs://fc-94bba050-4ef1-42fb-8436-cd89da17ec53/306ddffc-0ee6-46ff-ac3e-5069668a0eb0/ga4ghMd5/a14f0b9d-839c-4684-863c-93d0e8e2d527/call-md5/ failed; CommandException: No URLs matched: /cromwell_root/rc; 2019/07/10 18:38:32 Waiting 5 seconds and retrying; 2019/07/10 18:38:38 rm -f $HOME/.config/gcloud/gce && gsutil cp /cromwell_root/rc gs://fc-94bba050-4ef1-42fb-8436-cd89da17ec53/306ddffc-0ee6-46ff-ac3e-5069668a0eb0/ga4ghMd5/a14f0b9d-839c-4684-863c-93d0e8e2d527/call-md5/ failed; CommandException: No URLs matched: /cromwell_root/rc; 2019/07/10 18:38:38 Waiting 5 seconds and retrying; 2019/07/10 18:38:44 rm -f $HOME/.config/gcloud/gce && gsutil cp /cromwell_root/rc gs://fc-94bba050-4ef1-42fb-8436-cd89da17ec53/306ddffc-0ee6-46ff-ac3e-5069668a0eb0/ga4ghMd5/a14f0b9d-839c-4684-863c-93d0e8e2d527/call-md5/ failed; CommandException: No URLs matched: /cromwell_root/rc; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5069:4621,config,config,4621,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5069,3,['config'],['config']
Modifiability," for slower-running jobs.; // This is the maximum polling interval (in seconds):; maximum-polling-interval = 600. // Optional Dockerhub Credentials. Can be used to access private docker images.; dockerhub {; // account = """"; // token = """"; }. genomics {; // A reference to an auth defined in the `google` stanza at the top. This auth is used to create; // Pipelines and manipulate auth JSONs.; auth = ""application-default""; // Endpoint for APIs, no reason to change this unless directed by Google.; endpoint-url = ""https://genomics.googleapis.com/""; // This allows you to use an alternative service account to launch jobs, by default uses default service account; compute-service-account = ""default""; }. filesystems {; gcs {; // A reference to a potentially different auth for manipulating files via engine functions.; auth = ""application-default""; project = ""project-test1""; }; }; }; }; }; }; ```. I created the service account from https://cloud.google.com/docs/authentication/getting-started and give the role: Project -> Owner. I've downloaded Google Cloud SDK and run these; ```; gcloud auth login juha.wilppu@gmail.com; gcloud auth application-default login; gcloud config set project project-test1; gsutil ls gs://project-test1 // This command works, so authentication is successful.; ```; **project-test1-59b66448c3ab.json**; ```; {; ""type"": ""service_account"",; ""project_id"": ""project-test1"",; ""private_key_id"": ""59b66448c3ab730097135e1dba83b375a6b57ea3"",; ""private_key"": ""-----BEGIN PRIVATE KEY-----\n(Omitted)\n-----END PRIVATE KEY-----\n"",; ""client_email"": ""project-service@project-test1.iam.gserviceaccount.com"",; ""client_id"": ""104927211954691424974"",; ""auth_uri"": ""https://accounts.google.com/o/oauth2/auth"",; ""token_uri"": ""https://accounts.google.com/o/oauth2/token"",; ""auth_provider_x509_cert_url"": ""https://www.googleapis.com/oauth2/v1/certs"",; ""client_x509_cert_url"": ""https://www.googleapis.com/robot/v1/metadata/x509/project-service%40project-test1.iam.gserviceaccount.com""; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3690:5753,config,config,5753,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3690,1,['config'],['config']
Modifiability," https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're in the right place. -->; I clone the source code and assembly the jar. when try to run a sge job, I got and error. the log is following:. [2018-06-21 20:36:29,51] [error] DispatchedConfigAsyncJobExecutionActor [7ec0863atestsge.filter:NA:1]: Error attempting to Execute; java.lang.IllegalArgumentException: No coercion defined from '1' of type 'eu.timepit.refined.api.Refined' to 'Int'.; at wom.types.WomType.coerceRawValue(WomType.scala:36); at wom.types.WomType.coerceRawValue$(WomType.scala:27); at wom.types.WomIntegerType$.coerceRawValue(WomIntegerType.scala:9); at cromwell.backend.impl.sfs.config.DeclarationValidation.$anonfun$extractWdlValueOption$1(DeclarationValidation.scala:113); at scala.Option.map(Option.scala:146); at cromwell.backend.impl.sfs.config.DeclarationValidation.extractWdlValueOption(DeclarationValidation.scala:113); at cromwell.backend.impl.sfs.config.ConfigAsyncJobExecutionActor.$anonfun$runtimeAttributeInputs$1(ConfigAsyncJobExecutionActor.scala:163). <!-- Which backend are you running? -->; I use the SGE backend ; <!-- Paste/Attach your workflow if possible: -->; this is my WDL workflow; """"""; workflow testsge{; String Outdir; String JobName=""filter""; call filter{input:outdir=Outdir,jobname=JobName}; }. task filter{; String outdir; String jobname; command<<<; echo ""test successful"" >>${outdir}/log.stdout; echo 1; perl -we '{print STDERR 2;}'; Script=""${jobname}""; Sleep=$SGE_TASK_ID; QsubRcControl=3; QsubType=1; >>>; runtime{; backend:""SGE""; memory:""1 GB""; sge_queue:""test.q -P test -t 1-3""; sge_project:""test""; jobs_name:""${jobname}""; }; output{; String presuccess=""done""; Int rc=read_lines(stdout())[0]; }; }; """"""; <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->; this my runtime-attributes setting in the reference.conf file. runtime-attributes = """"""; Int cpu = 1; Float? memory_gb; Str",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3805:1458,Config,ConfigAsyncJobExecutionActor,1458,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3805,1,['Config'],['ConfigAsyncJobExecutionActor']
Modifiability," if we either want to either:; 1. Update every project in `build.sbt` with a `.dependsOn(common, ""test->test"")`; 2. Add scalatest and sentry as `Provided` dependencies to `common` such that they won't be transitively included by default; 3. Create a new `cromwell.test` artifact and use either of the above outside of `cromwell.common`. **A/C:**; - Switch tests directly using scalacheck over to scalatest's scalacheck-style specs; - Create a custom scalatest helper/reporter that retries a failed test a configurable number of times; - Add custom reporter to scalatest settings in `Testing.scala`; - Assuming using sentry for error reporting from Travis:; - Add sentry DSN configuration values to Vault; - Update `build_application.inc.conf` to use a noop sentry DSN by default; - Create a `sentry_application.inc.conf.ctmpl` file that uses sentry configuration values from Vault; - `build_application.inc.conf` attempts to import a `sentry_application.inc.conf` file that overrides the sentry configuration; - NOTE: When `build_application.inc.conf` is missing it will be skipped by the HOCON library. **Links:**; - https://github.com/broadinstitute/cromwell/issues/3657; - http://www.scalatest.org/user_guide/using_the_runner#specifyingReporters; - http://www.scalatest.org/user_guide/writing_scalacheck_style_properties; - http://doc.scalatest.org/3.0.1-2.12/org/scalatest/concurrent/Eventually.html; - http://doc.scalatest.org/3.0.1-2.12/org/scalatest/Retries.html; - http://doc.scalatest.org/3.0.1-2.12/org/scalatest/Reporter.html; - http://doc.scalatest.org/3.0.1-2.12/org/scalatest/events/TestFailed.html; - http://doc.scalatest.org/3.0.1-2.12/org/scalatest/events/TestCanceled.html; - https://github.com/scalatest/scalatest/blob/3.0.1/scalatest/src/main/resources/org/scalatest/ScalaTestBundle.properties#L664; - https://github.com/scalatest/scalatest/blob/3.0.1/scalatest/src/main/scala/org/scalatest/Retries.scala#L565-L577; - https://github.com/broadinstitute/cromwell/blob/b8d3d2fd4a583d",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3658:3494,config,configuration,3494,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3658,1,['config'],['configuration']
Modifiability," is deprecated. Please use cromwell.backend.google.pipelines.v1alpha2.PipelinesApiLifecycleActorFactory for PAPI v1 or cromwell.backend.google.pipelines.v2alpha1.PipelinesApiLifecycleActorFactory for PAPI v2; [2018-08-27 02:04:06,16] [warn] Couldn't find a suitable DSN, defaulting to a Noop one.; [2018-08-27 02:04:06,16] [info] Using noop to send events.; [2018-08-27 02:04:06,43] [info] Slf4jLogger started; [2018-08-27 02:04:06,64] [info] Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-be06fbc"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; [2018-08-27 02:04:06,71] [info] Metadata summary refreshing every 2 seconds.; [2018-08-27 02:04:06,81] [info] KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; [2018-08-27 02:04:06,81] [info] WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; [2018-08-27 02:04:06,91] [info] CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; [2018-08-27 02:04:07,85] [info] JobExecutionTokenDispenser - Distribution rate: 50 per 1 seconds.; [2018-08-27 02:04:07,88] [info] SingleWorkflowRunnerActor: Version 34; [2018-08-27 02:04:07,90] [info] SingleWorkflowRunnerActor: Submitting workflow; [2018-08-27 02:04:07,91] [info] PAPIQueryManager Running with 3 workers; [2018-08-27 02:04:07,91] [info] JES batch polling interval is 33333 milliseconds; [2018-08-27 02:04:07,92] [info] JES batch polling interval is 33333 milliseconds; [2018-08-27 02:04:07,93] [info] JES batch polling interval is 33333 milliseconds; [2018-08-27 02:04:07,98] [info] Unspecified type (Unspecified version) workflow 967af8b6-0d68-44c4-b04e-204674333468 submitted; [2018-08-27 02:04:08,05] [info] SingleWorkflowRunnerActor: Workflow submitted 967af8b6-0d68-44c4-b04e-204674333468; [2018-08-27 02:04:08,05] [info] 1 new workflows fetched; [2018-08-27 02:04:08,05] [info] WorkflowManagerActor Starting workfl",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4039:2417,config,configured,2417,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4039,1,['config'],['configured']
Modifiability," latest, and you can change this behavior by defining `DOCKER_TAG` either in the config or circle environment (I don't see a reason to do this). Note that deploy is ONLY set up to happen on pushes to master (and you can change this to also be develop, if you choose, or to be both and then to deploy to tags `<branch>-<commit>` or something like that. ## Background; This was first done at the repo [vsoch/cromwell](https://github.com/vsoch/cromwell/pull/1) to test since I can't set it up for the broadinstitute. The (finally) working test is at [https://circleci.com/gh/vsoch/cromwell/11](https://circleci.com/gh/vsoch/cromwell/11). I forgot that I can't have volumes, so it took me many tries to remember this, derp :P . When adding to the repository here, the following additional work will be needed for setup:. - Turn on the repository to build at circleci. The first build, since there is no `.circici/config.yml` will probably just yell at you for having ""Version 1.0"" or not finding a config.; - You will want to turn on building forked pull requests in the settings; - Under environment variables, define the following:; - `DOCKER_USER` should be the user to authenticate pushing; - `DOCKER_PASS` password for that user (**important** do not turn on also testing of forked pull requests on their branch (different setting from above) as this could compromise these credentials.; - `CONTAINER_NAME` should be something like `broadinstiutute/cromwell-dev`. - The tag will always build the commit id, and then latest. If you want to change this behavior, define `DOCKER_TAG`.; - ensure the branch logic (when things are triggered) is to your liking.; - update the repo badge to be cromwell here and not on vsoch (after you connect the two!). I noticed that there is no sbt version set (in some config file) - would this make sense to do?. ```bash; [warn] No sbt.version set in project/build.properties, base directory: /; [info] Set current project to root (in build file:/); [info] 1.2.1; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4015:2205,variab,variables,2205,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4015,2,"['config', 'variab']","['config', 'variables']"
Modifiability," message always results in the same hash; 2. it is quick to compute the hash value for any given message; 3. it is infeasible to generate a message that yields a given hash value; 4. it is infeasible to find two different messages with the same hash value; 5. a small change to a message should change the hash value so extensively that the new hash value appears uncorrelated with the old hash value (avalanche effect). I contest point 2, in that many cryptographic explicitly strife for being slow to calculate in order to negate brute force attempts.; Anyway: for call caching we only need points 1. and 4. All the rest is unnecessary ballast. . ## xxHash; Luckily there is a hashing algorithm that is designed explicitly for content hashing only. It was made to generate reliably different hashes for file content as fast as possible. It's called [xxHash](https://www.xxhash.com). There are Java implementations available and I did [some extensive benchmarking](https://github.com/rhpvorderman/hashtest/) to find out which one was best. The xxh64 (xxhash for 64 bit machines) algorithm was 15 times faster than the java implementation of md5 we currently use in Cromwell. This PR implements the xxhash algorithm for call-caching in Cromwell:. + The default strategy will still be using md5 for backwards compatibility.; + A new `xxh64` strategy is implemented using the 64-bit xxhash algorithm. (I didn't make the xxh32 algorithm available. Is there any Cromwell server still running on 32-bit?) This can be set in the call caching configuration.; + A new `fingerprint` strategy suggested by @illusional, which takes the modtime, size and a xxh64 hash of the first 10 mb of the file to create a virtually unique fingerprint.; + The `file` strategy get's a new alias `md5` which is more clear. Although `file` will still work in the config for backwards compatibility. . I feel we should move to xxh64 as default after it has proven itself in a few releases. The speed-up is an order of magnitude.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5450:2685,config,configuration,2685,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5450,2,['config'],"['config', 'configuration']"
Modifiability," message is emitted from `raven-logback` about a ""suitable DSN"". ```; [2018-05-18 21:17:10,79] [warn] SingleWorkflowRunnerActor: received unexpected message: Done in state RunningSwraData; [2018-05-18 21:17:10,80] [warn] Couldn't find a suitable DSN, defaulting to a Noop one.; ```. This appears to be because `raven-logback` is activated in logback.xml but is not configured by default in Cromwell. **Background:**; [Sentry](https://sentry.io/) describes itself as:. > Open-source error tracking that helps developers monitor and fix crashes in real time. Cromwell is using an deprecated version of the Sentry java bindings for logback called `raven-logback`. The current bindings are called `sentry-logback`. Additionally, the cromwell docs currently mention that sentry can be setup via the ""configuration value"" `sentry.dsn`. https://github.com/broadinstitute/cromwell/blob/b8d3d2fd4a583d3e46394efb104005c12cdf182d/docs/Logging.md#L48. https://github.com/broadinstitute/cromwell/blob/b8d3d2fd4a583d3e46394efb104005c12cdf182d/docs/Configuring.md#L345-L355. This is not correct as `raven-logback` nor its underlying library `raven` use Typesafe Config. Instead for `raven` the value must be set as a system property, or alternatively as a different environment variable. However the latest `sentry` library (and transitively `sentry-logback`) do allow code configuration via `Sentry.init`. **A/C:**; - Replace `raven-logback` dependency with `sentry-logback`; - ~Allow setting a `cromwell.sentry.*` stanza with Cromwell specific sentry configuration. Alternative namespaces could be `sentry.*` or `system.sentry.*`, but both namespaces may collide with other library/application configurations in the future!~; - ~Wire the `cromwell.sentry.*` HOCON fields into `Sentry.init`~; - ~Default the sentry DSN in `reference.conf` to a noop -OR- ensure that when an error is generated that the latest version of `sentry` does not output a ""suitable DSN"" warning~; - Update docs for Cromwell+Sentry in both `",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3657:1215,Config,Configuring,1215,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3657,1,['Config'],['Configuring']
Modifiability," mkdir -p $CACHE_DIR; # downloads sifs only one at a time; apptainer sif db doesn't handle concurrency well; out=$(flock --exclusive --timeout 1800 $LOCK_FILE apptainer pull $IMAGE docker://${docker} 2>&1); ret=$?; if [[ $ret == 0 ]]; then; echo ""Successfully pulled ${docker}!""; else; if [[ $(echo $out | grep ""exists"" ) ]]; then; echo ""Image file already exists, ${docker}!""; else; echo ""Failed to pull ${docker}"" >> /dev/stderr; exit $ret; fi; fi; #full path to sif for qsub command; IMAGE=""$APPTAINER_PULLFOLDER/$IMAGE""; qsub \; -terse \; -V \; -b y \; -N ""${job_name}"" \; -wd ""${cwd}"" \; -o ""${out}.qsub"" \; -e ""${err}.qsub"" \; -pe smp ""${cpu}"" \; ${""-l mem_free="" + memory_gb + ""g""} \; ${""-q "" + sge_queue} \; ${""-P "" + sge_project} \; apptainer exec --cleanenv --bind ""${cwd}:${docker_cwd},<path>"" ""$IMAGE"" ""${job_shell}"" ""${docker_script}""; """""". default-runtime-attributes; {; failOnStderr: false; continueOnReturnCode: 0; }; }; }. sge_docker {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {. runtime-attributes = """"""; String time = ""11:00:00""; Int cpu = 4; Float? memory_gb; String sge_queue = ""hammer.q""; String? sge_project; String? docker; """""". submit = """"""; qsub \; -terse \; -V \; -b y \; -N ${job_name} \; -wd ${cwd} \; -o ${out}.qsub \; -e ${err}.qsub \; -pe smp ${cpu} \; ${""-l mem_free="" + memory_gb + ""g""} \; ${""-q "" + sge_queue} \; ${""-P "" + sge_project} \; /usr/bin/env bash ${script}; """""". kill = ""qdel ${job_id}""; check-alive = ""qstat -j ${job_id}""; job-id-regex = ""(\\d+)"". submit-docker = """""" ; qsub \; -terse \; -V \; -b y \; -N ${job_name} \; -wd ${cwd} \; -o ${out}.qsub \; -e ${err}.qsub \; -pe smp ${cpu} \; ${""-l mem_free="" + memory_gb + ""g""} \; ${""-q "" + sge_queue} \; ${""-P "" + sge_project} \; ""docker exec -v ${cwd}:${docker_cwd} -v <path> ${job_shell} ${docker_script}""; """""". default-runtime-attributes; {; failOnStderr: false; continueOnReturnCode: 0; }; }; } ; }; Local; {; actor-factory = ""cromwell.backend.impl.s",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7480:4705,config,config,4705,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7480,1,['config'],['config']
Modifiability," name-for-call-caching-purposes, slow-job-warning-time; 2019-07-21 23:34:36,976 INFO - Slf4jLogger started; 2019-07-21 23:34:37,408 cromwell-system-akka.dispatchers.engine-dispatcher-7 INFO - Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-673c553"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""failureShutdownDuration"" : ""5 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; 2019-07-21 23:34:37,771 cromwell-system-akka.actor.default-dispatcher-3 INFO - KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; 2019-07-21 23:34:37,918 cromwell-system-akka.dispatchers.service-dispatcher-14 INFO - Metadata summary refreshing every 1 second.; 2019-07-21 23:34:38,046 WARN - 'docker.hash-lookup.gcr-api-queries-per-100-seconds' is being deprecated, use 'docker.hash-lookup.gcr.throttle' instead (see reference.conf); 2019-07-21 23:34:38,160 cromwell-system-akka.dispatchers.service-dispatcher-13 INFO - WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; 2019-07-21 23:34:38,160 cromwell-system-akka.dispatchers.engine-dispatcher-26 INFO - JobStoreWriterActor configured to flush with batch size 1000 and process rate 1 second.; 2019-07-21 23:34:38,594 cromwell-system-akka.dispatchers.engine-dispatcher-28 INFO - CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; 2019-07-21 23:34:38,667 cromwell-system-akka.dispatchers.engine-dispatcher-28 INFO - JobExecutionTokenDispenser - Distribution rate: 50 per 1 seconds.; 2019-07-21 23:34:39,131 cromwell-system-akka.dispatchers.backend-dispatcher-36 INFO - Running with 3 PAPI request workers; 2019-07-21 23:34:39,132 cromwell-system-akka.dispatchers.backend-dispatcher-36 INFO - PAPI request worker batch interval is 33333 milliseconds; 2019-07-21 23:34:39,157 cromwell-system-akka.dispatchers.backend-dispatcher-37 INFO - PAPI request worker batch interval is 33333 milliseconds; 2019-07-21 23:34:39,233 cromwe",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5084:2413,config,configured,2413,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5084,1,['config'],['configured']
Modifiability," name-for-call-caching-purposes: PAPI; slow-job-warning-time: ""24 hours""; genomics-api-queries-per-100-seconds = 1000; maximum-polling-interval = 600; request-workers = 3; genomics {; auth = ""application-default""; endpoint-url = ""https://genomics.googleapis.com/""; location = ""us-west1""; restrict-metadata-access = false; localization-attempts = 3; parallel-composite-upload-threshold=""150M""; }; filesystems {; gcs {; auth = ""application-default""; project = ""xxxx""; caching {; duplication-strategy = ""copy""; }; }; http { }; }; default-runtime-attributes {; cpu: 1; failOnStderr: false; continueOnReturnCode: 0; memory: ""2048 MB""; bootDiskSizeGb: 10; disks: ""local-disk 10 SSD""; noAddress: false; preemptible: 0; zones: [""us-west1-a"", ""us-west1-b""]; }; include ""papi_v2_reference_image_manifest.conf""; }; }; }; }; ```; When I run with the above config using:; ```; java -Dconfig.file=genomics.conf -jar cromwell-66.jar run cumulus.wdl -i cumulus_inputs.json; ```; I am getting the following error message:; ```; [2021-08-24 22:05:33,60] [info] WorkflowManagerActor: Workflow 6cc303b4-295d-49fa-a996-b5cf7ec9beea failed (during ExecutingWorkflowState): java.lang.Exception: Task cumulus.cluster:NA:1 failed. The job was stopped before the command finished. PAPI error code 3. Execution failed: allocating: creating instance: inserting instance: Invalid value for field 'resource.networkInterfaces[0].network': ''. The referenced network resource cannot be found.; ```; I have tried passing the vpc and subnet id using the following config:; ```; virtual-private-cloud {; network-label-key = ""xxx""; subnetwork-label-key = ""xxx""; auth = ""application-default""; }; ```. The above values are my actual vpc and subnet id/name. However, it is still giving me that error message. Is there something I am missing from a configuration perspective. Any help would be greatly appreciated. Our VPC network's are not created in auto mode and that is not something we have control over unfortunately. Thanks,; -Simran",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6477:2299,config,config,2299,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6477,2,['config'],"['config', 'configuration']"
Modifiability," output count, runtime attribute, output expression, input count, backend name, command template, input. - What are the downsides with `check-sibling-md5`, can it be used in conjunction with `system.file-hash-cache`. - **Is the only way to use call-caching with containers without fully hashing the file?**. ## Possible resolutions. I was thinking the following might be potential solutions for my problem, but I don't know how good / bad they are, and they'd require changes to Cromwell. - Potential for a _cheaper_ (and potentially dirtier) hash for files? ; - When cromwell links from a cached result, store a map of { newpath : original } link to use or call caching, so when the hashDifferential is calculated, it uses the hash of the original cached result. (This would mean we could use the path+modtime strategy). ## Current attempt. I realised I may have run into another error here: https://github.com/broadinstitute/cromwell/issues/5348. This is my current configuration, it will successfully pull cache for the FIRST step in a workflow, but then fail afterwards. <details><summary>Click to show configuration</summary><p>. ```hocon; include required(classpath(""application"")). system: {; ""job-shell"": ""/bin/sh"",; ""cromwell_id"": ""cromwell-fdcce1"",; ""cromwell_id_random_suffix"": false; }; database: {; ""db"": {; ""driver"": ""com.mysql.cj.jdbc.Driver"",; ""url"": ""jdbc:mysql://localhost/cromwell?rewriteBatchedStatements=true&useSSL=false&serverTimezone=UTC"",; ""user"": ""root"",; ""connectionTimeout"": 5000; },; ""profile"": ""slick.jdbc.MySQLProfile$""; }; backend: {; ""default"": ""Local"",; ""providers"": {; ""Local"": {; ""actor-factory"": ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory"",; ""config"": {; ""root"": ""/Users/franklinmichael/janis/cache_test/20200110_090106_f8ee04/janis/execution"",; ""filesystems"": {; ""local"": {; ""caching"": {; ""hashing-strategy"": ""path+modtime""; }; }; }; }; }; }; }; call-caching: {; ""enabled"": true; }; ```; </p></details>. Thanks in advance for your help!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5346:4005,config,configuration,4005,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5346,6,"['Config', 'config', 'rewrite']","['ConfigBackendLifecycleActorFactory', 'config', 'configuration', 'rewriteBatchedStatements']"
Modifiability," quality reads; Int low_quality_cutoff; Int read_length_cutoff; String adapters_1; String adapters_2; Int trim_start_R1; Int trim_end_R1; Int trim_start_R2; Int trim_end_R2; String TAG. #information memory for each task; Int memory_task1; Int memory_task2. #Start the call. Array[Array[String]] files_and_metadata = read_tsv(meta_data). scatter(files_and_metadata_row in files_and_metadata) {; String sampleName = files_and_metadata_row[0]; File f1 = files_and_metadata_row[1]; File f2 = files_and_metadata_row[2]; String? barcode = files_and_metadata_row[3]; #if the barcode is passed, proceed with it.; if (defined(barcode)) {; call trimCellBarcode {; input:; f1=f1,; f2=f2,; sampleName=sampleName,; barcode=barcode,; monitoring_script=monitoring_script,; command=command,; memory_task1=memory_task1,; bases=bases; }; }; #if the barcode is not passed, proceed with the trimming of the adapters only; if (!defined(barcode)) {; call trimAdaptersWithoutBarcodes{; input:; input_r1=f1,; input_r2=f2,; sampleName=sampleName,; low_quality_cutoff=low_quality_cutoff,; read_length_cutoff=read_length_cutoff,; adapters_1=adapters_1,; adapters_2=adapters_2,; trim_start_R1=trim_start_R1,; trim_end_R1=trim_end_R1,; trim_start_R2=trim_start_R2,; trim_end_R2=trim_end_R2,; monitoring_script=monitoring_script,; memory_task2=memory_task2,; TAG=TAG; }; }; call trimAdapters {; input:; input_r1=trimCellBarcode.fastqDebarcodedR1,; input_r2=trimCellBarcode.fastqDebarcodedR2,; sampleName=sampleName,; barcode=barcode,; low_quality_cutoff=low_quality_cutoff,; read_length_cutoff=read_length_cutoff,; adapters_1=adapters_1,; adapters_2=adapters_2,; trim_start_R1=trim_start_R1,; trim_end_R1=trim_end_R1,; trim_start_R2=trim_start_R2,; trim_end_R2=trim_end_R2,; monitoring_script=monitoring_script,; memory_task2=memory_task2,; TAG=TAG; }; } ; }. task trimCellBarcode {; File f1; File f2; String sampleName; String? barcode; File command; Int bases; File? monitoring_script; Int memory_task1. command <<<; set -euo pip",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5396:2658,adapt,adapters,2658,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5396,1,['adapt'],['adapters']
Modifiability," recent call last):; File ""/home/cdompierre/gdc-client/bin/build/gdc-client/out00-PYZ.pyz/multiprocessing.process"", line 258, in _bootstrap; File ""/home/cdompierre/gdc-client/bin/build/gdc-client/out00-PYZ.pyz/multiprocessing.process"", line 114, in run; File ""/home/cdompierre/gdc-client/bin/build/gdc-client/out00-PYZ.pyz/multiprocessing.managers"", line 550, in _run_server; File ""/home/cdompierre/gdc-client/bin/build/gdc-client/out00-PYZ.pyz/multiprocessing.managers"", line 162, in __init__; File ""/home/cdompierre/gdc-client/bin/build/gdc-client/out00-PYZ.pyz/multiprocessing.connection"", line 132, in __init__; File ""/home/cdompierre/gdc-client/bin/build/gdc-client/out00-PYZ.pyz/multiprocessing.connection"", line 256, in __init__; File ""/home/cdompierre/gdc-client/bin/build/gdc-client/out00-PYZ.pyz/socket"", line 224, in meth; error: AF_UNIX path too long; ```. The Python `mulitprocessing` library appears to create sockets in `$TMPDIR`. If the `$TMPDIR` path is too long then the path to the socket extends past the length limits for socket paths. This can be reproduced by running the following command with `tmp_dbg` set to 80 characters long. 79 characters works ok. ```shell; docker run -it --rm docker.io/broadinstitute/gdc_downloader:1.0 bash -c '; # 1 2 3 4 5 6 7 8; tmp_dbg=/234567890123456789012345678901234567890123456789012345678901234567890123456789; tmp_dbg=/2345678901234567890123456789012345678901234567890123456789012345678901234567890; tmpDir=$(; set -e; tmpDir=""$(mkdir -p ""${tmp_dbg}"" && echo ""${tmp_dbg}"")""; echo ""$tmpDir""; ); chmod 777 ""$tmpDir""; export _JAVA_OPTIONS=-Djava.io.tmpdir=""$tmpDir""; export TMPDIR=""$tmpDir"". python /opt/src/gdc_downloader.py 6ca4c640-758d-455d-ba5b-b965069a39b4/nationwidechildrens.org_biospecimen.TCGA-4C-A93U.xml; '; ```. A/C:; - A centaur test that checks that generated `$TMPDIR` paths are always shorter than some reasonable length. Because different backends with-or-without docker may generate different paths for `$TMPDIR` the test s",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3647:1325,extend,extends,1325,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3647,1,['extend'],['extends']
Modifiability," right place. -->. If you see I've configured root to be root = ""/fast/gdr/uat/cromwell-executions"". but randomly sometime workflows when I check cromwell api metadata it is pointing to old root which was /g/cromwell/cromwell-executions. . Note I'm running cromwell in server mode with mariadb. I've cleaned and deleted all tables from mariadb. restarted the server as well. Can't find any other config/cache file where it has saved old address. Sometime workflows are fine pointing to new root but sometime not. <!-- Which backend are you running? -->; SLURM on cromwell 36. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->. backend {; # Override the default backend.; default = ""PhoenixSLURM"". # The list of providers.; providers {. PhoenixSLURM {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; runtime-attributes = """"""; String userid; String partitions; String memory_per_node; Int nodes; Int cores; String time; """""". # If an 'exit-code-timeout-seconds' value is specified:; # - When a job has not been alive for longer than this timeout; # - And has still not produced an RC file; # - Then it will be marked as Failed.; # Warning: If set, Cromwell has to run 'check-alive' for every job at regular intervals (unrelated to this timeout). exit-code-timeout-seconds = 600. submit = """"""; chmod 770 -R ${cwd}; sudo change-files.sh ${userid} ${cwd}; phoenix_home_cwd=""/home/${userid}""; phoenix_home_out=""/home/${userid}/stdout""; phoenix_home_err=""/home/${userid}/stderr"". phoenix_script=${script}_phonix; cat ${script} | sed -s ""s@#\!/bin/bash@#\!/bin/bash\nsource '/etc/profile' @g"" > $phoenix_script. sbatch --uid=${userid} --gid=${userid} \; -J ${job_name} \; -p ${partitions} \; -N ${nodes} \; -n ${cores} \; --mem=${memory_per_node} \; --time=${time} \; -D $phoenix_home_cwd \; -o $phoenix_home_out \; -e $phoenix_home_err \; $phoen",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4404:1498,Config,ConfigBackendLifecycleActorFactory,1498,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4404,2,"['Config', 'config']","['ConfigBackendLifecycleActorFactory', 'config']"
Modifiability," scala.App.main$(App.scala:74); 	at cromwell.CromwellApp$.main(CromwellApp.scala:3); 	at cromwell.CromwellApp.main(CromwellApp.scala); Caused by: com.typesafe.config.ConfigException$Parse: /data/cephfs/punim0751/spartan.conf: 27: expecting a close parentheses ')' here, not: end of file; 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseError(ConfigDocumentParser.java:201); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseError(ConfigDocumentParser.java:197); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseKey(ConfigDocumentParser.java:279); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseObject(ConfigDocumentParser.java:450); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseValue(ConfigDocumentParser.java:247); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseObject(ConfigDocumentParser.java:458); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parse(ConfigDocumentParser.java:648); 	at com.typesafe.config.impl.ConfigDocumentParser.parse(ConfigDocumentParser.java:14); 	at com.typesafe.config.impl.Parseable.rawParseValue(Parseable.java:260); 	at com.typesafe.config.impl.Parseable.rawParseValue(Parseable.java:248); 	at com.typesafe.config.impl.Parseable.parseValue(Parseable.java:180); 	at com.typesafe.config.impl.Parseable.parseValue(Parseable.java:174); 	at com.typesafe.config.impl.Parseable.parse(Parseable.java:299); 	at com.typesafe.config.ConfigFactory.parseFile(ConfigFactory.java:689); 	at com.typesafe.config.DefaultConfigLoadingStrategy.parseApplicationConfig(DefaultConfigLoadingStrategy.java:51); 	at com.typesafe.config.ConfigFactory.defaultApplication(ConfigFactory.java:473); 	at com.typesafe.config.ConfigFactory$1.call(ConfigFactory.java:259); 	at com.typesafe.config.ConfigFactory$1.call(ConfigFactory.java:256); 	at com.typesafe.config.impl.ConfigImpl$LoaderCache.getOrElseUpdate(ConfigImpl.java:65); 	at com.typesafe.config.impl.Confi",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4549:2419,Config,ConfigDocumentParser,2419,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4549,1,['Config'],['ConfigDocumentParser']
Modifiability," stop inconsistencies like this from happening, [since it currently does not seem to give guidance on this particular issue](https://github.com/openwdl/wdl/blob/main/versions/1.0/SPEC.md#whitespace-strings-identifiers-constants). (Linking WDL 1.0 spec since that's what Cromwell currently supports.). Personally I'd prefer if strings were interpreted literally, ie `/` does not need to be escaped, but that might conflict with the typical JSON standard. Consistency is more important than my mild distaste for escaping. ## related issues; https://github.com/broadinstitute/cromwell/issues/3990#issuecomment-415665749. ## miniwdl comparison (not necessarily the ideal, just to illustrate point 4 on expected behavior); * miniwdl will accept `^chrEBV$|^NC|_random$|Un_|^HLA\-|_alt$|hap\d$` as a variable default or as hardcoded variable, and will handle it literally as written, as long as the workflow author followed shellcheck's recommendation and used quotes in the command section (ie `--excludePatt ""~{excludePattern}""`); * miniwdl will also accept escaping the characters as a variable default/hardcode, and interprets `^chrEBV$|^NC|_random$|Un_|^HLA\\-|_alt$|hap\\d$` as `^chrEBV$|^NC|_random$|Un_|^HLA\-|_alt$|hap\d$`; * miniwdl will not accept `^chrEBV$|^NC|_random$|Un_|^HLA\-|_alt$|hap\d$` as an input variable via JSON because JSON parsers are just kind of built like that. the two problematic parts are \- and \d. However, you can get around this by escaping those slashes, ie `^chrEBV$|^NC|_random$|Un_|^HLA\\-|_alt$|hap\\d$` does get interpreted as `^chrEBV$|^NC|_random$|Un_|^HLA\-|_alt$|hap\d$`. In other words, miniwdl and Cromwell are both internally inconsistent, and inconsistent compared to each other. miniwdl does not parse variables internally consistently as a consequence of its JSON parser. Cromwell is also internally inconsistent, but additionally can't handle the unescaped string as a default/hardcoded variable even those those don't go thru a JSON parser. ## screensho",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7167:3020,variab,variable,3020,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7167,4,['variab'],['variable']
Modifiability," the `develop` branch:; > You can find a description of options and example stanzas in the [Cromwell Example Configuration](https://www.github.com/broadinstitute/cromwell/tree/develop/cromwell.examples.conf), along with backend provider examples in the [Example Providers Folder](https://www.github.com/broadinstitute/cromwell/tree/develop/cromwell.example.backends).; 4. After seeing that a big perf bottleneck was Cromwell hashing files, I enabled all of the call caching options and also enabled `check-sibling-md5` so that it could use pre-computed hashes instead. To my surprise, this did nothing because it only works when the configured `actor-factory` is `cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory`! The documentation does **not** make that sufficiently clear:; - The `hashing-strategy` and `check-sibling-md5` options are listed under the `Local Filesystem` section (and configured under `config.filesystems.local.caching` which led me to believe they would work with any provider configured for local filesystem (e.g., TES). This is not the case, and they are in fact tied to the actor factory implementation and the only actor factory with support is `ConfigBackendLifecycleActorFactory` (as far as I could tell).; - The documentation does make mention of mention:; > When running a job on the **Config (Shared Filesystem) backend**, Cromwell provides some additional options in the backend's config section. However neither a Config nor a Shared Filesystem backend are mentionend in the documentation, although SFS is found under [Filesystems](https://cromwell.readthedocs.io/en/stable/filesystems/Filesystems/). Therefore, I think the docs need additional clarity on config concepts like provider and actor-factory vs what we are referring to at a high-level as a ""backend"" (which is in fact just the `ConfigBackendLifecycleActorFactory` implementation with some config specific to that ""backend""). As well, I would suggest an implementation of the call caching",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4810:2644,config,configured,2644,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4810,1,['config'],['configured']
Modifiability," the class of each service, even though they should probably have default values:; ```; [ERROR] [01/24/2019 11:09:59.741] [cromwell-system-akka.dispatchers.service-dispatcher-10] [akka://cromwell-system/user/SingleWorkflowRunnerActor/ServiceRegistryActor] Received ServiceRegistryMessage requ; esting service 'LoadController' for which no service is configured. Message: LoadMetric(NonEmptyList(CallCacheWriteActor),NormalLoad) ; [ERROR] [01/24/2019 11:09:59.731] [cromwell-system-akka.dispatchers.service-dispatcher-10] [akka://cromwell-system/user/SingleWorkflowRunnerActor/ServiceRegistryActor] Received ServiceRegistryMessage requ; esting service 'Instrumentation' for which no service is configured. Message: InstrumentationServiceMessage(CromwellGauge(CromwellBucket(List(job),NonEmptyList(callcaching, read, $y, queue)),0)); ```. ***. Here's my config file for Cromwell 36 (that works):; ```; backend {; default = spartan. providers {; spartan {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; runtime-attributes = """"""; Int runtime_minutes = 600; Int cpus = 2; Int requested_memory_mb_per_core = 8000; String? docker; """""". submit = """"""; sbatch -J ${job_name} -D ${cwd} -o ${out} -e ${err} -t ${runtime_minutes} \; ${""-c "" + cpus} \; --mem-per-cpu=${requested_memory_mb_per_core} \; --wrap ""/bin/bash ${script}""; """""". submit-docker = """"""; module load Singularity/2.5.0-intel-2017.u2 || true; singularity pull docker://${docker}; sbatch -J ${job_name} -D ${cwd} -o ${out} -e ${err} -t ${runtime_minutes} \; ${""-c "" + cpus} \; --mem-per-cpu=${requested_memory_mb_per_core} \; --wrap ""singularity exec -B ${cwd}:${docker_cwd} docker://${docker} ${job_shell} ${script}"" ; """""". kill = ""scancel ${job_id}""; check-alive = ""squeue -j ${job_id}""; job-id-regex = ""Submitted batch job (\\d+).*""; }; }; }; }; ```. Here's what I added to my config for 37 that causes the missing class errors:; ```; services { ; MetadataService { ; class = ""cromwell.services",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4577:3605,config,config,3605,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4577,1,['config'],['config']
Modifiability," token queue status. Effective log interval = None; 2021-09-27 13:48:13,186 cromwell-system-akka.dispatchers.api-dispatcher-41 INFO - Unspecified type (Unspecified version) workflow 075e0cf3-194b-4f53-a43d-d31f0b370f79 submitted; 2021-09-27 13:48:20,474 cromwell-system-akka.dispatchers.engine-dispatcher-32 INFO - 1 new workflows fetched by cromid-69bdc1a: 075e0cf3-194b-4f53-a43d-d31f0b370f79; 2021-09-27 13:48:20,484 cromwell-system-akka.dispatchers.engine-dispatcher-9 INFO - WorkflowManagerActor: Starting workflow UUID(075e0cf3-194b-4f53-a43d-d31f0b370f79); 2021-09-27 13:48:20,511 cromwell-system-akka.dispatchers.engine-dispatcher-9 INFO - WorkflowManagerActor: Successfully started WorkflowActor-075e0cf3-194b-4f53-a43d-d31f0b370f79; 2021-09-27 13:48:20,511 cromwell-system-akka.dispatchers.engine-dispatcher-9 INFO - Retrieved 1 workflows from the WorkflowStoreActor; 2021-09-27 13:48:20,547 cromwell-system-akka.dispatchers.engine-dispatcher-28 INFO - WorkflowStoreHeartbeatWriteActor configured to flush with batch size 10000 and process rate 2 minutes.; Sep 27, 2021 1:48:20 PM com.google.auth.oauth2.DefaultCredentialsProvider warnAboutProblematicCredentials; WARNING: Your application has authenticated using end user credentials from Google Cloud SDK. We recommend that most server applications use service accounts instead. If your application continues to use end user credentials from Cloud SDK, you might receive a ""quota exceeded"" or ""API not enabled"" error. For more information about service accounts, see https://cloud.google.com/docs/authentication/.; 2021-09-27 13:48:21,326 cromwell-system-akka.dispatchers.engine-dispatcher-28 INFO - MaterializeWorkflowDescriptorActor [UUID(075e0cf3)]: Parsing workflow as WDL draft-2; 2021-09-27 13:48:22,359 cromwell-system-akka.dispatchers.engine-dispatcher-28 INFO - MaterializeWorkflowDescriptorActor [UUID(075e0cf3)]: Call-to-Backend assignments: wf_hello.hello -> PAPIv2; 2021-09-27 13:48:24,671 cromwell-system-akka.dispatchers.en",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6506:9439,config,configured,9439,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6506,1,['config'],['configured']
Modifiability," will be able to utilize results from all calls that are in that database.""_. Secondly, if this can. **Question 2.**. Can call caching be initiated if a scatter, wraps a workflow, which then wraps tools.; Or will the entire workflow need to be in one script? (I have attached an example as zip); And, the options file.; [DsTrim - Broken.zip](https://github.com/broadinstitute/cromwell/files/3842334/DsTrim.-.Broken.zip). **Question 3.**. What exactly triggers callcaching to change from ""CallCachingOff"" to on, in the following result?; `; ""callCaching"": {; ""effectiveCallCachingMode"": ""CallCachingOff"",; ""allowResultReuse"": false,; ""hit"": false,; ""result"": ""Cache Miss""; },`. **If the in-memory is the issue, then please close and we will set-up a UAT correctly.; If not any additional assistance or comments will be most apprecitated.** . ###; ### IMPORTANT: Please file new issues over in our Jira issue tracker!; ###; ### https://broadworkbench.atlassian.net/projects/BA/issues; ###; ### You may need to create an account before you can view/create issues.; ###. <!--; Hi! Thanks for taking the time to report feedback. Before posting an issue over in Jira tracker, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're almost in the right place. -->. <!-- You'll want to go to https://broadworkbench.atlassian.net/projects/BA/issues and then tell us: -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5280:2849,config,configuration,2849,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5280,1,['config'],['configuration']
Modifiability," {; cromwell_1 | ; cromwell_1 | docker run \; cromwell_1 | --rm -i \; cromwell_1 | ${""--user "" + docker_user} \; cromwell_1 | --entrypoint /bin/bash \; cromwell_1 | -v ${cwd}:${docker_cwd} \; cromwell_1 | ${docker} ${script}; cromwell_1 | ; cromwell_1 | }; cromwell_1 | }; cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigWdlNamespace.<init>(ConfigWdlNamespace.scala:50); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace$lzycompute(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations$lzycompute(ConfigInitializationActor.scala:40); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations(ConfigInitializationActor.scala:39); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder$lzycompute(ConfigInitializationActor.scala:49); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder(ConfigInitializationActor.scala:48); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.coerceDefaultRuntimeAttributes(StandardInitializationActor.scala:78); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$class.validateRuntimeAttributes(BackendWorkflowInitializationActor.scala:121); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$class.initSequence(BackendWorkflowInitializationActor.scala:154); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.initSequence(StandardInitializationActor.scala:42); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$$anonfun$receive$1$$anonfun$applyOrElse$2.apply(BackendWorkflowInitializationActor.scala:146); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationAc",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2284:3357,Config,ConfigInitializationActor,3357,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2284,1,['Config'],['ConfigInitializationActor']
Modifiability," | ; cromwell_1 | String job_id; cromwell_1 | String job_name; cromwell_1 | String cwd; cromwell_1 | String out; cromwell_1 | String err; cromwell_1 | String script; cromwell_1 | ; cromwell_1 | String docker_cwd; cromwell_1 | String? docker Int? max_runtime = 2; cromwell_1 | command {; cromwell_1 | ; cromwell_1 | docker run \; cromwell_1 | --rm -i \; cromwell_1 | ${""--user "" + docker_user} \; cromwell_1 | --entrypoint /bin/bash \; cromwell_1 | -v ${cwd}:${docker_cwd} \; cromwell_1 | ${docker} ${script}; cromwell_1 | ; cromwell_1 | }; cromwell_1 | }; cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigWdlNamespace.<init>(ConfigWdlNamespace.scala:50); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace$lzycompute(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations$lzycompute(ConfigInitializationActor.scala:40); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations(ConfigInitializationActor.scala:39); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder$lzycompute(ConfigInitializationActor.scala:49); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder(ConfigInitializationActor.scala:48); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.coerceDefaultRuntimeAttributes(StandardInitializationActor.scala:78); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$class.validateRuntimeAttributes(BackendWorkflowInitializationActor.scala:121); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$class.initSequence(BackendWorkflowInitializationActor.scala:154); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActo",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2284:3074,Config,ConfigInitializationActor,3074,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2284,1,['Config'],['ConfigInitializationActor']
Modifiability," | String job_name; cromwell_1 | String cwd; cromwell_1 | String out; cromwell_1 | String err; cromwell_1 | String script; cromwell_1 | ; cromwell_1 | String docker_cwd; cromwell_1 | String? docker Int? max_runtime = 2; cromwell_1 | command {; cromwell_1 | ; cromwell_1 | docker run \; cromwell_1 | --rm -i \; cromwell_1 | ${""--user "" + docker_user} \; cromwell_1 | --entrypoint /bin/bash \; cromwell_1 | -v ${cwd}:${docker_cwd} \; cromwell_1 | ${docker} ${script}; cromwell_1 | ; cromwell_1 | }; cromwell_1 | }; cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigWdlNamespace.<init>(ConfigWdlNamespace.scala:50); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace$lzycompute(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations$lzycompute(ConfigInitializationActor.scala:40); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations(ConfigInitializationActor.scala:39); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder$lzycompute(ConfigInitializationActor.scala:49); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder(ConfigInitializationActor.scala:48); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.coerceDefaultRuntimeAttributes(StandardInitializationActor.scala:78); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$class.validateRuntimeAttributes(BackendWorkflowInitializationActor.scala:121); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$class.initSequence(BackendWorkflowInitializationActor.scala:154); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.initSequence(StandardInitializationActor.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2284:3134,Config,ConfigInitializationActor,3134,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2284,1,['Config'],['ConfigInitializationActor']
Modifiability," | }; cromwell_1 | }; cromwell_1 | ; cromwell_1 | ; cromwell_1 | task submit_docker {; cromwell_1 | ; cromwell_1 | String job_id; cromwell_1 | String job_name; cromwell_1 | String cwd; cromwell_1 | String out; cromwell_1 | String err; cromwell_1 | String script; cromwell_1 | ; cromwell_1 | String docker_cwd; cromwell_1 | String? docker Int? max_runtime = 2; cromwell_1 | command {; cromwell_1 | ; cromwell_1 | docker run \; cromwell_1 | --rm -i \; cromwell_1 | ${""--user "" + docker_user} \; cromwell_1 | --entrypoint /bin/bash \; cromwell_1 | -v ${cwd}:${docker_cwd} \; cromwell_1 | ${docker} ${script}; cromwell_1 | ; cromwell_1 | }; cromwell_1 | }; cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigWdlNamespace.<init>(ConfigWdlNamespace.scala:50); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace$lzycompute(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations$lzycompute(ConfigInitializationActor.scala:40); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations(ConfigInitializationActor.scala:39); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder$lzycompute(ConfigInitializationActor.scala:49); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder(ConfigInitializationActor.scala:48); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.coerceDefaultRuntimeAttributes(StandardInitializationActor.scala:78); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$class.validateRuntimeAttributes(BackendWorkflowInitializationActor.scala:121); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$class.initSequence(BackendWorkflowIniti",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2284:2968,config,configWdlNamespace,2968,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2284,2,"['Config', 'config']","['ConfigInitializationActor', 'configWdlNamespace']"
Modifiability," |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:File R2Fastq|""9f1cf8859a902eb75202a5c048cd43aa-388""|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input:File R1Fastq|""62396abd6b589747ee16034888c9a0b5-381""|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input:File R1Fastq|""62396abd6b589747ee16034888c9a0b5-381""|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:input count|9BF31C7FF062936A96D3C8BD1F8F2FF3|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:input count|9BF31C7FF062936A96D3C8BD1F8F2FF3|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:command template|7BCEDB02C5FC300FF83F07417B49229E|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:command template|7BCEDB02C5FC300FF83F07417B49229E|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:hashes:backend name|2267EF43AEF6BB551F414FEC2390F68A|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:hashes:backend name|2267EF43AEF6BB551F414FEC2390F68A|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:effectiveCallCachingMode|ReadAndWriteCache|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:effectiveCallCachingMode|ReadAndWriteCache|; |29791b64-b47a-44ba-aff0-7ab48bc10677|callCaching:allowResultReuse|true|; |5de042e3-7a03-4c77-8972-f0e4cd010e4b|callCaching:allowResultReuse|true|. <!--; Hi! Thanks for taking the time to report feedback. Please check whether your question is already answered in our:; Documentation http://cromwell.readthedocs.io/en/develop/; Bioinformatics Stack Exchange https://bioinformatics.stackexchange.com/search?q=cromwell; Slack https://join.slack.com/t/cromwellhq/shared_invite/zt-dxmmrtye-JHxwKE53rfKE_ZWdOHIB4g; -->. <!-- Are you seeing something that looks like a bug? Please attach as much information as possible. -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7248:8022,config,configuration,8022,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7248,1,['config'],['configuration']
Modifiability," }; [2019-01-07 16:21:17,87] [info] Metadata summary refreshing every 2 seconds.; [2019-01-07 16:21:17,94] [info] WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; [2019-01-07 16:21:18,00] [info] KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; [2019-01-07 16:21:18,02] [info] CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; [2019-01-07 16:21:19,53] [info] JobExecutionTokenDispenser - Distribution rate: 50 per 1 seconds.; [2019-01-07 16:21:19,58] [info] SingleWorkflowRunnerActor: Version 36; [2019-01-07 16:21:19,61] [info] SingleWorkflowRunnerActor: Submitting workflow; [2019-01-07 16:21:19,69] [info] Unspecified type (Unspecified version) workflow 18de8166-5f29-4288-9fa4-6741565446fd submitted; [2019-01-07 16:21:19,74] [info] SingleWorkflowRunnerActor: Workflow submitted [38;5;2m18de8166-5f29-4288-9fa4-6741565446fd[0m; [2019-01-07 16:21:19,75] [info] 1 new workflows fetched; [2019-01-07 16:21:19,77] [info] WorkflowManagerActor Starting workflow [38;5;2m18de8166-5f29-4288-9fa4-6741565446fd[0m; [2019-01-07 16:21:19,77] [info] WorkflowManagerActor Successfully started WorkflowActor-18de8166-5f29-4288-9fa4-6741565446fd; [2019-01-07 16:21:19,77] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2019-01-07 16:21:19,78] [info] WorkflowStoreHeartbeatWriteActor configured to flush with batch size 10000 and process rate 2 minutes.; [2019-01-07 16:21:19,80] [[38;5;220mwarn[0m] SingleWorkflowRunnerActor: received unexpected message: Done in state RunningSwraData; [2019-01-07 16:21:19,98] [info] MaterializeWorkflowDescriptorActor [[38;5;2m18de8166[0m]: Parsing workflow as WDL draft-2; [2019-01-07 16:21:21,18] [info] MaterializeWorkflowDescriptorActor [[38;5;2m18de8166[0m]: Call-to-Backend assignments: example.hello -> Local; [2019-01-07 16:21:23,89] [[38;5;1merror[0m] WorkflowManagerActor Workflow 18de8166-5f29-4288-9fa4-6741565446fd failed (during ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4526:2810,config,configured,2810,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4526,1,['config'],['configured']
Modifiability,"! Thanks for taking the time to report feedback. Before posting an issue over in Jira tracker, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're almost in the right place. -->; [2022-03-03 19:26:59,66] [info] WorkflowManagerActor: Workflow 496206d8-8854-48c1-abed-3717510ceb4e failed (during ExecutingWorkflowState): cromwell.engine.io.IoAttempts$EnhancedCromwellIoException: [Attempted 1 time(s)] - IOException: Could not read from s3://mys3-cloudformation/cromwell-execution/wf_hello/496206d8-8854-48c1-abed-3717510ceb4e/call-hello/hello-rc.txt: s3://s3.amazonaws.com/mys3-cloudformation/cromwell-execution/wf_hello/496206d8-8854-48c1-abed-3717510ceb4e/call-hello/hello-rc.txt; Caused by: java.io.IOException: Could not read from s3://mys3-cloudformation/cromwell-execution/wf_hello/496206d8-8854-48c1-abed-3717510ceb4e/call-hello/hello-rc.txt: s3://s3.amazonaws.com/mys3-cloudformation/cromwell-execution/wf_hello/496206d8-8854-48c1-abed-3717510ceb4e/call-hello/hello-rc.txt. <!-- You'll want to go to https://broadworkbench.atlassian.net/projects/BA/issues and then tell us: -->; ![image](https://user-images.githubusercontent.com/96741804/156643007-76a24c99-509c-4480-8484-df1c6f7b9c72.png). <!-- Which backend are you running? -->. AWS Batch. <!-- Paste/Attach your workflow if possible: -->. I have see this as an issue previously reported ; I am trying to set up a genomics work flow using AWS batch and Cromwell . How to solve this issue; <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6695:2138,config,configuration,2138,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6695,1,['config'],['configuration']
Modifiability,"![image](https://user-images.githubusercontent.com/45682016/93409722-13f30f80-f8ca-11ea-89cd-bc544cea69ad.png). cromwell version: 53. config file. [aws.txt](https://github.com/broadinstitute/cromwell/files/5235741/aws.txt). ###wdl part. ```; version 1.0. task task1 {. input {; File simg; }. command {; du /cromwell_root/; du /yuce/; find *.simg; singularity exec ${simg} echo hello > hello.txt; du /cromwell_root/; }. runtime{; docker:""kongdeju/singularity:v3.4.0""; }. output {; File outfile = ""hello.txt""; }; }. ```. ### json part. ```; {; ""test.task2.simg"": ""s3://yuce/simgs/alpine.simg"",; ""test.task1.simg"": ""s3://yuce/simgs/alpine.simg""; }. ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5861:134,config,config,134,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5861,1,['config'],['config']
Modifiability,"""; url = """"""; jdbc:hsqldb:file:cromwell-executions/cromwell-db/cromwell-db;; shutdown=false;; hsqldb.default_table_type=cached;hsqldb.tx=mvcc;; hsqldb.result_max_memory_rows=10000;; hsqldb.large_data=true;; hsqldb.applog=1;; hsqldb.lob_compressed=true;; hsqldb.script_format=3; """"""; connectionTimeout = 120000; numThreads = 1; }; }. call-caching {; enabled = true; }. backend {; default = ""Local""; providers { ; Local {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; concurrent-job-limit = 10; run-in-background = true; submit = ""/usr/bin/env bash ${script}""; root = ""cromwell-executions""; filesystems {; local {; localization: [""soft-link""]; caching {; duplication-strategy: [""soft-link""]; hasing-strategy: [""path+modtime""]; }; }; }; }; }; SLURM {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; concurrent-job-limit = 500; runtime-attributes = """"""; Int threads = 1; String memory = ""2g""; String dx_timeout; """"""; submit = """"""; sbatch; --account <account>; --partition ind-shared; --nodes 1; --job-name=${job_name}-%j; # --output=logs/{job_name}/$j.out; 	 -o ${out} -e ${err} ; --mail-type FAIL --mail-user <email-address>; --ntasks-per-node=${threads}; --mem=${memory}; --time=${dx_timeout}; --parsable; --chdir ${cwd}; """"""; kill = ""scancel ${job_id}""; check-alive = ""squeue -j ${job_id}""; job-id-regex = ""Submitted batch job (\\d+).*""; }; }; }}; ```. Here's the log printed to the terminal. Notice the jump from [2022-12-15 21:15:03,84] to [2022-12-15 21:22:59,01]; ```; $ java -Dconfig.file=workflow/cromwell.conf -jar utilities/cromwell-84.jar run workflow/expanse_workflow.wdl; [2022-12-15 21:14:44,99] [info] Running with database db.url =; jdbc:hsqldb:file:cromwell-executions/cromwell-db/cromwell-db;; shutdown=false;; hsqldb.default_table_type=cached;hsqldb.tx=mvcc;; hsqldb.result_max_memory_rows=10000;; hsqldb.large_data=true;; hsqldb.applog=1;; hsqldb.lob_compressed=true;; hsqldb.script",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6971:2258,Config,ConfigBackendLifecycleActorFactory,2258,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6971,2,"['Config', 'config']","['ConfigBackendLifecycleActorFactory', 'config']"
Modifiability,"""real return code"" stored; submit-docker = """"""; docker run \; --cidfile ${docker_cid} \; -i \; ${""--user "" + docker_user} \; --entrypoint /bin/bash \; -v ${cwd}:${docker_cwd} \; ${docker} ${script}; rc=$(docker wait `cat ${docker_cid}`); docker rm `cat ${docker_cid}`; exit $rc; """"""; }; ```. The log shows the following stack-trace:. ```; [2018-03-09 15:31:16,47] [error] Failed to properly flush metadata to database; java.sql.SQLException: java.lang.OutOfMemoryError: Java heap space; 	at org.hsqldb.jdbc.JDBCUtil.sqlException(Unknown Source); 	at org.hsqldb.jdbc.JDBCUtil.sqlException(Unknown Source); 	at org.hsqldb.jdbc.JDBCPreparedStatement.addBatch(Unknown Source); 	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.addBatch(HikariProxyPreparedStatement.java); 	at slick.jdbc.JdbcActionComponent$InsertActionComposerImpl$MultiInsertAction.$anonfun$run$15(JdbcActionComponent.scala:531); 	at slick.jdbc.JdbcActionComponent$InsertActionComposerImpl$MultiInsertAction.$anonfun$run$15$adapted(JdbcActionComponent.scala:529); 	at scala.collection.Iterator.foreach(Iterator.scala:929); 	at scala.collection.Iterator.foreach$(Iterator.scala:929); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1417); 	at scala.collection.IterableLike.foreach(IterableLike.scala:71); 	at scala.collection.IterableLike.foreach$(IterableLike.scala:70); 	at scala.collection.AbstractIterable.foreach(Iterable.scala:54); 	at slick.jdbc.JdbcActionComponent$InsertActionComposerImpl$MultiInsertAction.$anonfun$run$14(JdbcActionComponent.scala:529); 	at slick.jdbc.JdbcBackend$SessionDef.withPreparedStatement(JdbcBackend.scala:372); 	at slick.jdbc.JdbcBackend$SessionDef.withPreparedStatement$(JdbcBackend.scala:367); 	at slick.jdbc.JdbcBackend$BaseSession.withPreparedStatement(JdbcBackend.scala:434); 	at slick.jdbc.JdbcActionComponent$InsertActionComposerImpl.preparedInsert(JdbcActionComponent.scala:502); 	at slick.jdbc.JdbcActionComponent$InsertActionComposerImpl$MultiInsertAction.run(JdbcActionC",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3387:2624,adapt,adapted,2624,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3387,1,['adapt'],['adapted']
Modifiability,"""scMeth.adapters_2"": ""AGATCGGAAGAGCGTCGTGTAGGGA""; }. ```. ### configuration named as `your_2.conf` file is:; ```; include required(classpath(""application"")); ```. ### Run as:; `java -jar -Dconfig.file=your_2.conf cromwell-42.jar run -i scMeth_input_3.json scMeth_v2.wdl.sh`. ### Error is:. ```; [2019-07-10 14:32:46,75] [info] Running with database db.url = jdbc:hsqldb:mem:fad09ca5-b589-4874-b5de-bbd1dc0064fe;shutdown=false;hsqldb.tx=mvcc; [2019-07-10 14:32:53,36] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2019-07-10 14:32:53,38] [info] [RenameWorkflowOptionsInMetadata] 100%; [2019-07-10 14:32:53,46] [info] Running with database db.url = jdbc:hsqldb:mem:39174976-89f7-4769-a52c-7d5a4afc6cf4;shutdown=false;hsqldb.tx=mvcc; [2019-07-10 14:32:53,81] [info] Slf4jLogger started; [2019-07-10 14:32:54,07] [info] Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-1cf43fa"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""failureShutdownDuration"" : ""5 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; [2019-07-10 14:32:54,11] [info] Metadata summary refreshing every 1 second.; [2019-07-10 14:32:54,12] [warn] 'docker.hash-lookup.gcr-api-queries-per-100-seconds' is being deprecated, use 'docker.hash-lookup.gcr.throttle' instead (see reference.conf); [2019-07-10 14:32:54,12] [info] CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; [2019-07-10 14:32:54,13] [info] KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; [2019-07-10 14:32:54,13] [info] WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; [2019-07-10 14:32:54,18] [info] JobExecutionTokenDispenser - Distribution rate: 50 per 1 seconds.; [2019-07-10 14:32:54,43] [info] SingleWorkflowRunnerActor: Version 42; [2019-07-10 14:32:54,44] [info] SingleWorkflowRunnerActor: Submitting workflow; [2019-07-10 14:32:54",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5066:4835,config,configuration,4835,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5066,1,['config'],['configuration']
Modifiability,"# Command submitted to cromwell server (v52). ```; curl -X POST --header ""Accept: application/json"" -v ""localhost:8000/api/workflows/v1"" -F ""workflowSource=@gridss-purple.packed.json"" -F ""workflowInputs=@gridss-purple.packed.input.json"" -F ""workflowOptions=@/opt/cromwell/configs/options.json"" -F ""workflowType=CWL"" -F ""workflowTypeVersion=v1.0"" -F ""workflowRoot=main""; ```. # Inputs. ## gridss-purple.packed.json. <details>. <summary> Click to expand! </summary>. ```; {; ""$graph"": [; {; ""class"": ""CommandLineTool"",; ""doc"": ""AMBER is designed to generate a tumor BAF file for use in PURPLE from a provided VCF of likely heterozygous SNP sites.\n\nWhen using paired reference/tumor bams,\nAMBER confirms these sites as heterozygous in the reference sample bam then calculates the\nallelic frequency of corresponding sites in the tumor bam.\nIn tumor only mode, all provided sites are examined in the tumor with additional filtering then applied.\n\nThe Bioconductor copy number package is then used to generate pcf segments from the BAF file.\n\nWhen using paired reference/tumor data, AMBER is also able to:\n1. detect evidence of contamination in the tumor from homozygous sites in the reference; and\n2. facilitate sample matching by recording SNPs in the germline\n"",; ""requirements"": [; {; ""dockerPull"": ""quay.io/biocontainers/hmftools-amber:3.3--0"",; ""class"": ""DockerRequirement""; },; {; ""expressionLib"": [; ""var get_start_memory = function(){ /* Start with 2 Gb */ return 2000; }"",; ""var get_max_memory_from_runtime_memory = function(max_ram){ /* Get Max memory and subtract heap memory */ return max_ram - get_start_memory(); }""; ],; ""class"": ""InlineJavascriptRequirement""; },; {; ""coresMin"": 16,; ""ramMin"": 32000,; ""class"": ""ResourceRequirement""; },; {; ""class"": ""ShellCommandRequirement""; }; ],; ""baseCommand"": [; ""AMBER""; ],; ""arguments"": [; {; ""prefix"": ""-Xms"",; ""separate"": false,; ""valueFrom"": ""$(get_start_memory())m"",; ""position"": -2; },; {; ""prefix"": ""-Xmx"",; ""separate"": false,; ""val",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5826:272,config,configs,272,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5826,1,['config'],['configs']
Modifiability,"# See https://cromwell.readthedocs.io/en/stable/Configuring/; # only use double quotes!; include required(classpath(""application"")). system {; abort-jobs-on-terminate = true; io {; number-of-requests = 30; per = 1 second; }; }. ## file based persistent database; database {; profile = ""slick.jdbc.HsqldbProfile$""; db {; driver = ""org.hsqldb.jdbcDriver""; url = """"""; jdbc:hsqldb:file:cromwell-executions/cromwell-db/cromwell-db;; shutdown=false;; hsqldb.default_table_type=cached;hsqldb.tx=mvcc;; hsqldb.result_max_memory_rows=10000;; hsqldb.large_data=true;; hsqldb.applog=1;; hsqldb.lob_compressed=true;; hsqldb.script_format=3; """"""; connectionTimeout = 120000; numThreads = 1; }; }. call-caching {; enabled = true; }. backend {; default = ""Local""; providers { ; Local {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; concurrent-job-limit = 10; run-in-background = true; submit = ""/usr/bin/env bash ${script}""; root = ""cromwell-executions""; filesystems {; local {; localization: [""soft-link""]; caching {; duplication-strategy: [""soft-link""]; hasing-strategy: [""path+modtime""]; }; }; }; }; }; SLURM {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; concurrent-job-limit = 500; runtime-attributes = """"""; Int threads = 1; String memory = ""2g""; String dx_timeout; """"""; submit = """"""; sbatch; --account <account>; --partition ind-shared; --nodes 1; --job-name=${job_name}-%j; # --output=logs/{job_name}/$j.out; 	 -o ${out} -e ${err} ; --mail-type FAIL --mail-user <email-address>; --ntasks-per-node=${threads}; --mem=${memory}; --time=${dx_timeout}; --parsable; --chdir ${cwd}; """"""; kill = ""scancel ${job_id}""; check-alive = ""squeue -j ${job_id}""; job-id-regex = ""Submitted batch job (\\d+).*""; }; }; }}; ```. Here's the log printed to the terminal. Notice the jump from [2022-12-15 21:15:03,84] to [2022-12-15 21:22:59,01]; ```; $ java -Dconfig.file=workflow/cromwell.conf -jar utilities/cromwell-84.jar ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6971:1878,Config,ConfigBackendLifecycleActorFactory,1878,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6971,2,"['Config', 'config']","['ConfigBackendLifecycleActorFactory', 'config']"
Modifiability,"# Summary. Currently Cromwell will retry tasks that fail in Pipelines API due to preemption, with the number of retries configurable on a task by task basis. It would be very helpful if this could be generalized, so that I could tell Cromwell to retry all tasks that fail -- for any reason, not just preemption. I imagine this being configured via a workflow option like ""failed_task_retries: 3"", which would tell Cromwell to run each task in the workflow up to 3 times if any type of failure is encountered. # Why it would be valuable. For people running many instances of a well-tested workflow, such as Green Team and Mint Team production at Broad, the vast majority of failures are due to transient problems in the cloud, and it is very time consuming to deal with them. Having this auto-retry capability in Cromwell would be a huge help in making these workflows more robust and would greatly reduce the amount of manual work required to relaunch failed workflows (or save people from having to write their own bespoke scripts to auto-retry failed workflows). Having retries at the task level (rather than having to resubmit the whole workflow) would also be more efficient, especially when call caching is not in use. # Difference from existing issue. I believe this feature would satisfy the use cases of many (but not all) of the commenters on #1991, but in a simpler way. In contrast to that issue, no error messages need to be parsed here and there is no added functionality around auto increasing memory or disk. (For Mint Team produciton, we're interested in something like #1991, too, especially the stderr pattern matching, but I am guessing it would take longer to make happen given the wdl changes required, etc. The issue I'm filing here is the low hanging fruit for us.). # Combining with preemptibles. There is a question to resolve about what to do for a preemptible task in a workflow where failed_task_retries has also been set. My preference would be to make them additive. If t",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3161:120,config,configurable,120,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3161,2,['config'],"['configurable', 'configured']"
Modifiability,"## About this PR; 📦 Updates ; * [ch.qos.logback:logback-access](https://github.com/qos-ch/logback); * [ch.qos.logback:logback-classic](https://github.com/qos-ch/logback); * [ch.qos.logback:logback-core](https://github.com/qos-ch/logback). from `1.2.11` to `1.2.12`. ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""ch.qos.logback"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""ch.qos.logback"" }; }]; ```; </details>. <sup>; labels: library-update, early-semver-patch, semver-spec-patch, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7260:522,Config,Configure,522,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7260,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## About this PR; 📦 Updates ; * [com.dimafeng:testcontainers-scala-mariadb](https://github.com/testcontainers/testcontainers-scala); * [com.dimafeng:testcontainers-scala-mysql](https://github.com/testcontainers/testcontainers-scala); * [com.dimafeng:testcontainers-scala-postgresql](https://github.com/testcontainers/testcontainers-scala); * [com.dimafeng:testcontainers-scala-scalatest](https://github.com/testcontainers/testcontainers-scala). from `0.40.10` to `0.40.17`. 📜 [GitHub Release Notes](https://github.com/testcontainers/testcontainers-scala/releases/tag/v0.40.17) - [Version Diff](https://github.com/testcontainers/testcontainers-scala/compare/v0.40.10...v0.40.17). ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.dimafeng"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""com.dimafeng"" }; }]; ```; </details>. <sup>; labels: test-library-update, early-semver-minor, semver-spec-patch, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7270:935,Config,Configure,935,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7270,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## About this PR; 📦 Updates ; * [io.circe:circe-core](https://github.com/circe/circe); * [io.circe:circe-generic](https://github.com/circe/circe); * [io.circe:circe-literal](https://github.com/circe/circe); * [io.circe:circe-parser](https://github.com/circe/circe); * [io.circe:circe-refined](https://github.com/circe/circe); * [io.circe:circe-shapes](https://github.com/circe/circe). from `0.14.1` to `0.14.6`. 📜 [GitHub Release Notes](https://github.com/circe/circe/releases/tag/v0.14.6) - [Version Diff](https://github.com/circe/circe/compare/v0.14.1...v0.14.6). ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""io.circe"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""io.circe"" }; }]; ```; </details>. <sup>; labels: library-update, early-semver-minor, semver-spec-patch, version-scheme:early-semver, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7292:822,Config,Configure,822,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7292,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## About this PR; 📦 Updates ; * [io.github.jbwheatley:pact4s-circe](https://github.com/jbwheatley/pact4s); * [io.github.jbwheatley:pact4s-scalatest](https://github.com/jbwheatley/pact4s). from `0.9.0` to `0.10.1-java8`. 📜 [GitHub Release Notes](https://github.com/jbwheatley/pact4s/releases/tag/v0.10.1-java8) - [Version Diff](https://github.com/jbwheatley/pact4s/compare/v0.9.0...v0.10.1-java8). ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>🔍 Files still referring to the old version number</summary>. The following files still refer to the old version number (0.9.0).; You might want to review and update them manually.; ```; centaur/src/main/resources/integrationTestCases/Somatic/CNV-Pair/cnv_somatic_pair_workflow_do_gc_wes.inputs; centaur/src/main/resources/integrationTestCases/Somatic/CNV-Panel/cnv_somatic_panel_workflow_do_gc_wes.inputs; centaur/src/main/resources/integrationTestCases/Somatic/Mutect2/Mutect2.aws.inputs; centaur/src/main/resources/integrationTestCases/Somatic/Mutect2/Mutect2.inputs; centaur/src/main/resources/integrationTestCases/germline/haplotype-caller-workflow/HaplotypeCallerWF.json; centaur/src/main/resources/integrationTestCases/germline/single-sample-production-workflow/PairedEndSingleSampleWf.options.json; centaur/src/main/resources/integrationTestCases/germline/single-sample-workflow/processing-for-variant-discovery-gatk4.hg38.wgs.inputs.json; centaur/src/main/resources/integrationTestCases/green/arrays/arrays.wdl; womtool/src/test/resources/validate/wdl_draft3/valid/H",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7294:653,Config,Configure,653,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7294,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## About this PR; 📦 Updates ; * [org.http4s:http4s-ember-client](https://github.com/http4s/http4s); * [org.http4s:http4s-ember-server](https://github.com/http4s/http4s). from `0.21.31` to `0.21.34`. 📜 [GitHub Release Notes](https://github.com/http4s/http4s/releases/tag/v0.21.34) - [Version Diff](https://github.com/http4s/http4s/compare/v0.21.31...v0.21.34). ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""org.http4s"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""org.http4s"" }; }]; ```; </details>. <sup>; labels: library-update, early-semver-minor, semver-spec-patch, version-scheme:early-semver, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7311:616,Config,Configure,616,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7311,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## About this PR; 📦 Updates ; * [org.junit.jupiter:junit-jupiter-api](https://github.com/junit-team/junit5); * [org.junit.jupiter:junit-jupiter-engine](https://github.com/junit-team/junit5); * [org.junit.jupiter:junit-jupiter-params](https://github.com/junit-team/junit5). from `5.9.3` to `5.10.1`. ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""org.junit.jupiter"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""org.junit.jupiter"" }; }]; ```; </details>. <sup>; labels: library-update, early-semver-minor, semver-spec-minor, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7312:555,Config,Configure,555,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7312,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## About this PR; 📦 Updates ; * [org.typelevel:alleycats-core](https://github.com/typelevel/cats); * [org.typelevel:cats-core](https://github.com/typelevel/cats). from `2.7.0` to `2.10.0`. 📜 [GitHub Release Notes](https://github.com/typelevel/cats/releases/tag/v2.10.0) - [Version Diff](https://github.com/typelevel/cats/compare/v2.7.0...v2.10.0). ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>🔍 Files still referring to the old version number</summary>. The following files still refer to the old version number (2.7.0).; You might want to review and update them manually.; ```; services/src/test/scala/cromwell/services/database/QueryTimeoutSpec.scala; ```; </details>; <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""org.typelevel"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""org.typelevel"" }; }]; ```; </details>. <sup>; labels: library-update, early-semver-minor, semver-spec-minor, version-scheme:early-semver, old-version-remains, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7320:604,Config,Configure,604,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7320,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## About this PR; 📦 Updates [cglib:cglib-nodep](https://github.com/cglib/cglib) from `3.2.7` to `3.2.12`. ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""cglib"", artifactId = ""cglib-nodep"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""cglib"", artifactId = ""cglib-nodep"" }; }]; ```; </details>. <sup>; labels: library-update, early-semver-patch, semver-spec-patch, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7259:362,Config,Configure,362,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7259,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## About this PR; 📦 Updates [com.azure.resourcemanager:azure-resourcemanager](https://github.com/Azure/azure-sdk-for-java) from `2.18.0` to `2.33.0`. ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.azure.resourcemanager"", artifactId = ""azure-resourcemanager"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""com.azure.resourcemanager"", artifactId = ""azure-resourcemanager"" }; }]; ```; </details>. <sup>; labels: library-update, early-semver-minor, semver-spec-minor, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7269:406,Config,Configure,406,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7269,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## About this PR; 📦 Updates [com.azure:azure-core-http-okhttp](https://github.com/Azure/azure-sdk-for-java) from `1.11.10` to `1.11.17`. ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.azure"", artifactId = ""azure-core-http-okhttp"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""com.azure"", artifactId = ""azure-core-http-okhttp"" }; }]; ```; </details>. <sup>; labels: library-update, early-semver-patch, semver-spec-patch, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7262:393,Config,Configure,393,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7262,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## About this PR; 📦 Updates [com.azure:azure-core-management](https://github.com/Azure/azure-sdk-for-java) from `1.7.1` to `1.11.9`. ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>🔍 Files still referring to the old version number</summary>. The following files still refer to the old version number (1.7.1).; You might want to review and update them manually.; ```; project/Dependencies.scala; ```; </details>; <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.azure"", artifactId = ""azure-core-management"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""com.azure"", artifactId = ""azure-core-management"" }; }]; ```; </details>. <sup>; labels: library-update, early-semver-minor, semver-spec-minor, old-version-remains, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7263:389,Config,Configure,389,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7263,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## About this PR; 📦 Updates [com.azure:azure-core-test](https://github.com/Azure/azure-sdk-for-java) from `1.18.0` to `1.18.1`. ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>🔍 Files still referring to the old version number</summary>. The following files still refer to the old version number (1.18.0).; You might want to review and update them manually.; ```; cloud-nio/cloud-nio-impl-drs/src/test/scala/cloud/nio/impl/drs/DrsPathResolverSpec.scala; ```; </details>; <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.azure"", artifactId = ""azure-core-test"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""com.azure"", artifactId = ""azure-core-test"" }; }]; ```; </details>. <sup>; labels: library-update, early-semver-patch, semver-spec-patch, old-version-remains, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7264:384,Config,Configure,384,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7264,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## About this PR; 📦 Updates [com.azure:azure-core](https://github.com/Azure/azure-sdk-for-java) from `1.40.0` to `1.45.1`. ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.azure"", artifactId = ""azure-core"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""com.azure"", artifactId = ""azure-core"" }; }]; ```; </details>. <sup>; labels: library-update, early-semver-minor, semver-spec-minor, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7261:379,Config,Configure,379,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7261,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## About this PR; 📦 Updates [com.azure:azure-identity-extensions](https://github.com/azure/azure-sdk-for-java) from `1.1.4` to `1.1.10`. ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.azure"", artifactId = ""azure-identity-extensions"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""com.azure"", artifactId = ""azure-identity-extensions"" }; }]; ```; </details>. <sup>; labels: library-update, early-semver-patch, semver-spec-patch, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7266:393,Config,Configure,393,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7266,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## About this PR; 📦 Updates [com.azure:azure-identity](https://github.com/Azure/azure-sdk-for-java) from `1.9.1` to `1.9.2`. ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.azure"", artifactId = ""azure-identity"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""com.azure"", artifactId = ""azure-identity"" }; }]; ```; </details>. <sup>; labels: library-update, early-semver-patch, semver-spec-patch, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7265:381,Config,Configure,381,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7265,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## About this PR; 📦 Updates [com.azure:azure-storage-blob](https://github.com/Azure/azure-sdk-for-java) from `12.23.0-beta.1` to `12.23.1`. ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.azure"", artifactId = ""azure-storage-blob"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""com.azure"", artifactId = ""azure-storage-blob"" }; }]; ```; </details>. <sup>; labels: library-update, early-semver-pre-release, semver-spec-pre-release, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7267:396,Config,Configure,396,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7267,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## About this PR; 📦 Updates [com.azure:azure-storage-common](https://github.com/Azure/azure-sdk-for-java) from `12.22.0-beta.1` to `12.22.1`. ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.azure"", artifactId = ""azure-storage-common"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""com.azure"", artifactId = ""azure-storage-common"" }; }]; ```; </details>. <sup>; labels: library-update, early-semver-pre-release, semver-spec-pre-release, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7268:398,Config,Configure,398,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7268,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## About this PR; 📦 Updates [com.eed3si9n:sbt-assembly](https://github.com/sbt/sbt-assembly) from `1.1.1` to `2.1.5` ⚠. 📜 [GitHub Release Notes](https://github.com/sbt/sbt-assembly/releases/tag/v2.1.5) - [Version Diff](https://github.com/sbt/sbt-assembly/compare/v1.1.1...v2.1.5). ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>🔍 Files still referring to the old version number</summary>. The following files still refer to the old version number (1.1.1).; You might want to review and update them manually.; ```; womtool/src/test/resources/validate/wdl_draft3/valid/arrays_v1/arrays_v1.inputs.json; ```; </details>; <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.eed3si9n"", artifactId = ""sbt-assembly"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""com.eed3si9n"", artifactId = ""sbt-assembly"" }; }]; ```; </details>. <sup>; labels: sbt-plugin-update, early-semver-major, semver-spec-major, old-version-remains, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7271:537,Config,Configure,537,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7271,3,"['Config', 'config', 'plugin']","['Configure', 'configuration', 'plugin-update']"
Modifiability,"## About this PR; 📦 Updates [com.fasterxml.jackson.dataformat:jackson-dataformat-xml](https://github.com/FasterXML/jackson-dataformat-xml) from `2.13.3` to `2.13.5`. ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.fasterxml.jackson.dataformat"", artifactId = ""jackson-dataformat-xml"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""com.fasterxml.jackson.dataformat"", artifactId = ""jackson-dataformat-xml"" }; }]; ```; </details>. <sup>; labels: library-update, early-semver-patch, semver-spec-patch, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7272:422,Config,Configure,422,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7272,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## About this PR; 📦 Updates [com.github.cb372:sbt-explicit-dependencies](https://github.com/cb372/sbt-explicit-dependencies) from `0.2.16` to `0.3.1`. 📜 [GitHub Release Notes](https://github.com/cb372/sbt-explicit-dependencies/releases/tag/v0.3.1) - [Version Diff](https://github.com/cb372/sbt-explicit-dependencies/compare/v0.2.16...v0.3.1). ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.github.cb372"", artifactId = ""sbt-explicit-dependencies"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""com.github.cb372"", artifactId = ""sbt-explicit-dependencies"" }; }]; ```; </details>. <sup>; labels: sbt-plugin-update, early-semver-major, semver-spec-minor, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7273:599,Config,Configure,599,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7273,3,"['Config', 'config', 'plugin']","['Configure', 'configuration', 'plugin-update']"
Modifiability,"## About this PR; 📦 Updates [com.github.sbt:junit-interface](https://github.com/sbt/junit-interface) from `0.13.2` to `0.13.3`. 📜 [GitHub Release Notes](https://github.com/sbt/junit-interface/releases/tag/v0.13.3) - [Version Diff](https://github.com/sbt/junit-interface/compare/v0.13.2...v0.13.3). ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>🔍 Files still referring to the old version number</summary>. The following files still refer to the old version number (0.13.2).; You might want to review and update them manually.; ```; project/Dependencies.scala; ```; </details>; <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.github.sbt"", artifactId = ""junit-interface"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""com.github.sbt"", artifactId = ""junit-interface"" }; }]; ```; </details>. <sup>; labels: library-update, early-semver-minor, semver-spec-patch, old-version-remains, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7274:554,Config,Configure,554,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7274,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## About this PR; 📦 Updates [com.google.api-client:google-api-client-jackson2](https://github.com/googleapis/google-api-java-client) from `2.1.4` to `2.2.0`. 📜 [GitHub Release Notes](https://github.com/googleapis/google-api-java-client/releases/tag/v2.2.0) - [Version Diff](https://github.com/googleapis/google-api-java-client/compare/v2.1.4...v2.2.0). ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.api-client"", artifactId = ""google-api-client-jackson2"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""com.google.api-client"", artifactId = ""google-api-client-jackson2"" }; }]; ```; </details>. <sup>; labels: library-update, early-semver-minor, semver-spec-minor, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7276:609,Config,Configure,609,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7276,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## About this PR; 📦 Updates [com.google.api.grpc:proto-google-cloud-batch-v1](https://github.com/googleapis/google-cloud-java) from `0.18.0` to `0.30.0`. 📜 [GitHub Release Notes](https://github.com/googleapis/google-cloud-java/releases/tag/v0.30.0) - [Version Diff](https://github.com/googleapis/google-cloud-java/compare/v0.18.0...v0.30.0). ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.api.grpc"", artifactId = ""proto-google-cloud-batch-v1"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""com.google.api.grpc"", artifactId = ""proto-google-cloud-batch-v1"" }; }]; ```; </details>. <sup>; labels: library-update, early-semver-major, semver-spec-minor, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7277:598,Config,Configure,598,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7277,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## About this PR; 📦 Updates [com.google.api.grpc:proto-google-cloud-resourcemanager-v3](https://github.com/googleapis/google-cloud-java) from `1.17.0` to `1.32.0`. ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>🔍 Files still referring to the old version number</summary>. The following files still refer to the old version number (1.17.0).; You might want to review and update them manually.; ```; project/Dependencies.scala; ```; </details>; <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.api.grpc"", artifactId = ""proto-google-cloud-resourcemanager-v3"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""com.google.api.grpc"", artifactId = ""proto-google-cloud-resourcemanager-v3"" }; }]; ```; </details>. <sup>; labels: library-update, early-semver-minor, semver-spec-minor, old-version-remains, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7278:420,Config,Configure,420,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7278,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## About this PR; 📦 Updates [com.google.api:gax-grpc](https://github.com/googleapis/sdk-platform-java) from `2.25.0` to `2.38.0`. ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>🔍 Files still referring to the old version number</summary>. The following files still refer to the old version number (2.25.0).; You might want to review and update them manually.; ```; project/Dependencies.scala; ```; </details>; <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.api"", artifactId = ""gax-grpc"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""com.google.api"", artifactId = ""gax-grpc"" }; }]; ```; </details>. <sup>; labels: library-update, early-semver-minor, semver-spec-minor, old-version-remains, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7275:386,Config,Configure,386,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7275,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## About this PR; 📦 Updates [com.google.auth:google-auth-library-oauth2-http](https://github.com/googleapis/google-auth-library-java) from `1.5.3` to `1.20.0`. 📜 [GitHub Release Notes](https://github.com/googleapis/google-auth-library-java/releases/tag/v1.20.0) - [Version Diff](https://github.com/googleapis/google-auth-library-java/compare/v1.5.3...v1.20.0). ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.auth"", artifactId = ""google-auth-library-oauth2-http"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""com.google.auth"", artifactId = ""google-auth-library-oauth2-http"" }; }]; ```; </details>. <sup>; labels: library-update, early-semver-minor, semver-spec-minor, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7281:617,Config,Configure,617,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7281,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## About this PR; 📦 Updates [com.google.cloud:google-cloud-batch](https://github.com/googleapis/google-cloud-java) from `0.18.0` to `0.30.0`. 📜 [GitHub Release Notes](https://github.com/googleapis/google-cloud-java/releases/tag/v0.30.0) - [Version Diff](https://github.com/googleapis/google-cloud-java/compare/v0.18.0...v0.30.0). ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.cloud"", artifactId = ""google-cloud-batch"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""com.google.cloud"", artifactId = ""google-cloud-batch"" }; }]; ```; </details>. <sup>; labels: library-update, early-semver-major, semver-spec-minor, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7282:586,Config,Configure,586,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7282,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## About this PR; 📦 Updates [com.google.cloud:google-cloud-bigquery](https://github.com/googleapis/java-bigquery) from `2.25.0` to `2.34.2`. 📜 [GitHub Release Notes](https://github.com/googleapis/java-bigquery/releases/tag/v2.34.2) - [Version Diff](https://github.com/googleapis/java-bigquery/compare/v2.25.0...v2.34.2). ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>🔍 Files still referring to the old version number</summary>. The following files still refer to the old version number (2.25.0).; You might want to review and update them manually.; ```; project/Dependencies.scala; ```; </details>; <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.cloud"", artifactId = ""google-cloud-bigquery"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""com.google.cloud"", artifactId = ""google-cloud-bigquery"" }; }]; ```; </details>. <sup>; labels: library-update, early-semver-minor, semver-spec-minor, old-version-remains, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7283:577,Config,Configure,577,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7283,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## About this PR; 📦 Updates [com.google.cloud:google-cloud-resourcemanager](https://github.com/googleapis/google-cloud-java) from `1.17.0` to `1.32.0`. ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>🔍 Files still referring to the old version number</summary>. The following files still refer to the old version number (1.17.0).; You might want to review and update them manually.; ```; project/Dependencies.scala; ```; </details>; <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.cloud"", artifactId = ""google-cloud-resourcemanager"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""com.google.cloud"", artifactId = ""google-cloud-resourcemanager"" }; }]; ```; </details>. <sup>; labels: library-update, early-semver-minor, semver-spec-minor, old-version-remains, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7284:408,Config,Configure,408,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7284,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## About this PR; 📦 Updates [com.google.cloud:google-cloud-storage](https://github.com/googleapis/java-storage) from `2.17.2` to `2.29.1`. 📜 [GitHub Release Notes](https://github.com/googleapis/java-storage/releases/tag/v2.29.1) - [Version Diff](https://github.com/googleapis/java-storage/compare/v2.17.2...v2.29.1). ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>🔍 Files still referring to the old version number</summary>. The following files still refer to the old version number (2.17.2).; You might want to review and update them manually.; ```; project/Dependencies.scala; ```; </details>; <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.cloud"", artifactId = ""google-cloud-storage"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""com.google.cloud"", artifactId = ""google-cloud-storage"" }; }]; ```; </details>. <sup>; labels: library-update, early-semver-minor, semver-spec-minor, old-version-remains, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7285:573,Config,Configure,573,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7285,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## About this PR; 📦 Updates [com.typesafe:config](https://github.com/lightbend/config) from `1.4.2` to `1.4.3`. 📜 [GitHub Release Notes](https://github.com/lightbend/config/releases/tag/v1.4.3) - [Version Diff](https://github.com/lightbend/config/compare/v1.4.2...v1.4.3). ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.typesafe"", artifactId = ""config"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""com.typesafe"", artifactId = ""config"" }; }]; ```; </details>. <sup>; labels: library-update, early-semver-patch, semver-spec-patch, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7286:42,config,config,42,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7286,8,"['Config', 'config']","['Configure', 'config', 'configuration']"
Modifiability,"## About this PR; 📦 Updates [commons-codec:commons-codec](https://github.com/apache/commons-codec) from `1.15` to `1.16.0`. ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>🔍 Files still referring to the old version number</summary>. The following files still refer to the old version number (1.15).; You might want to review and update them manually.; ```; docs/developers/bitesize/workflowParsing/wdlToWdlom_wdlom.svg; project/Dependencies.scala; scripts/metadata_comparison/test/resources/comparer/papiv1_version3_good.json; scripts/metadata_comparison/test/resources/comparer/papiv2_version3_good.json; ```; </details>; <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""commons-codec"", artifactId = ""commons-codec"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""commons-codec"", artifactId = ""commons-codec"" }; }]; ```; </details>. <sup>; labels: library-update, old-version-remains, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7287:380,Config,Configure,380,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7287,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## About this PR; 📦 Updates [commons-io:commons-io](https://commons.apache.org/proper/commons-io/) from `2.11.0` to `2.15.1`. ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>🔍 Files still referring to the old version number</summary>. The following files still refer to the old version number (2.11.0).; You might want to review and update them manually.; ```; project/Dependencies.scala; ```; </details>; <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""commons-io"", artifactId = ""commons-io"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""commons-io"", artifactId = ""commons-io"" }; }]; ```; </details>. <sup>; labels: library-update, early-semver-minor, semver-spec-minor, old-version-remains, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7288:382,Config,Configure,382,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7288,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## About this PR; 📦 Updates [commons-net:commons-net](https://commons.apache.org/proper/commons-net/) from `3.8.0` to `3.10.0`. ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""commons-net"", artifactId = ""commons-net"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""commons-net"", artifactId = ""commons-net"" }; }]; ```; </details>. <sup>; labels: library-update, early-semver-minor, semver-spec-minor, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7289:384,Config,Configure,384,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7289,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## About this PR; 📦 Updates [eu.timepit:refined](https://github.com/fthomas/refined) from `0.10.1` to `0.10.3`. 📜 [GitHub Release Notes](https://github.com/fthomas/refined/releases/tag/v0.10.3) - [Version Diff](https://github.com/fthomas/refined/compare/v0.10.1...v0.10.3). ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""eu.timepit"", artifactId = ""refined"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""eu.timepit"", artifactId = ""refined"" }; }]; ```; </details>. <sup>; labels: library-update, early-semver-minor, semver-spec-patch, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7290:530,Config,Configure,530,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7290,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## About this PR; 📦 Updates [io.circe:circe-config](https://github.com/circe/circe-config) from `0.8.0` to `0.10.1`. 📜 [GitHub Release Notes](https://github.com/circe/circe-config/releases/tag/v0.10.1). ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""io.circe"", artifactId = ""circe-config"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""io.circe"", artifactId = ""circe-config"" }; }]; ```; </details>. <sup>; labels: library-update, early-semver-major, semver-spec-minor, version-scheme:early-semver, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7291:44,config,config,44,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7291,7,"['Config', 'config']","['Configure', 'config', 'configuration']"
Modifiability,"## About this PR; 📦 Updates [io.circe:circe-optics](https://github.com/circe/circe-optics) from `0.14.1` to `0.15.0`. 📜 [GitHub Release Notes](https://github.com/circe/circe-optics/releases/tag/v0.15.0) - [Version Diff](https://github.com/circe/circe-optics/compare/v0.14.1...v0.15.0). ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>🔍 Files still referring to the old version number</summary>. The following files still refer to the old version number (0.14.1).; You might want to review and update them manually.; ```; project/Dependencies.scala; ```; </details>; <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""io.circe"", artifactId = ""circe-optics"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""io.circe"", artifactId = ""circe-optics"" }; }]; ```; </details>. <sup>; labels: library-update, early-semver-major, semver-spec-minor, version-scheme:early-semver, old-version-remains, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7293:542,Config,Configure,542,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7293,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## About this PR; 📦 Updates [io.grpc:grpc-core](https://github.com/grpc/grpc-java) from `1.54.1` to `1.54.2`. 📜 [GitHub Release Notes](https://github.com/grpc/grpc-java/releases/tag/v1.54.2) - [Version Diff](https://github.com/grpc/grpc-java/compare/v1.54.1...v1.54.2). ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""io.grpc"", artifactId = ""grpc-core"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""io.grpc"", artifactId = ""grpc-core"" }; }]; ```; </details>. <sup>; labels: library-update, early-semver-patch, semver-spec-patch, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7295:526,Config,Configure,526,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7295,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## About this PR; 📦 Updates [io.projectreactor:reactor-test](https://github.com/reactor/reactor-core) from `3.4.29` to `3.4.34`. 📜 [GitHub Release Notes](https://github.com/reactor/reactor-core/releases/tag/v3.4.34) - [Version Diff](https://github.com/reactor/reactor-core/compare/v3.4.29...v3.4.34). ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""io.projectreactor"", artifactId = ""reactor-test"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""io.projectreactor"", artifactId = ""reactor-test"" }; }]; ```; </details>. <sup>; labels: library-update, early-semver-patch, semver-spec-patch, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7296:557,Config,Configure,557,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7296,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## About this PR; 📦 Updates [io.sentry:sentry-logback](https://github.com/getsentry/sentry-java) from `5.7.4` to `7.0.0` ⚠. 📜 [GitHub Release Notes](https://github.com/getsentry/sentry-java/releases/tag/7.0.0) - [Version Diff](https://github.com/getsentry/sentry-java/compare/5.7.4...7.0.0). ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""io.sentry"", artifactId = ""sentry-logback"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""io.sentry"", artifactId = ""sentry-logback"" }; }]; ```; </details>. <sup>; labels: library-update, early-semver-major, semver-spec-major, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7297:548,Config,Configure,548,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7297,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## About this PR; 📦 Updates [io.swagger:swagger-parser](https://github.com/swagger-api/swagger-parser) from `1.0.56` to `1.0.68`. 📜 [GitHub Release Notes](https://github.com/swagger-api/swagger-parser/releases/tag/v1.0.68) - [Version Diff](https://github.com/swagger-api/swagger-parser/compare/v1.0.56...v1.0.68). ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""io.swagger"", artifactId = ""swagger-parser"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""io.swagger"", artifactId = ""swagger-parser"" }; }]; ```; </details>. <sup>; labels: test-library-update, early-semver-patch, semver-spec-patch, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7298:570,Config,Configure,570,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7298,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## About this PR; 📦 Updates [net.minidev:json-smart](https://github.com/netplex/json-smart-v2) from `2.4.10` to `2.4.11`. 📜 [GitHub Release Notes](https://github.com/netplex/json-smart-v2/releases/tag/2.4.11) - [Version Diff](https://github.com/netplex/json-smart-v2/compare/2.4.10...2.4.11). ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""net.minidev"", artifactId = ""json-smart"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""net.minidev"", artifactId = ""json-smart"" }; }]; ```; </details>. <sup>; labels: library-update, early-semver-patch, semver-spec-patch, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7300:549,Config,Configure,549,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7300,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## About this PR; 📦 Updates [org.apache.commons:commons-lang3](https://commons.apache.org/proper/commons-lang/) from `3.12.0` to `3.14.0`. ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""org.apache.commons"", artifactId = ""commons-lang3"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""org.apache.commons"", artifactId = ""commons-lang3"" }; }]; ```; </details>. <sup>; labels: library-update, early-semver-minor, semver-spec-minor, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7301:395,Config,Configure,395,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7301,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## About this PR; 📦 Updates [org.apache.tika:tika-core](https://tika.apache.org/) from `2.3.0` to `2.9.1`. ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>🔍 Files still referring to the old version number</summary>. The following files still refer to the old version number (2.3.0).; You might want to review and update them manually.; ```; centaur/src/main/resources/integrationTestCases/germline/single-sample-workflow/processing-for-variant-discovery-gatk4.hg38.wgs.aws.inputs.json; centaur/src/main/resources/integrationTestCases/germline/single-sample-workflow/processing-for-variant-discovery-gatk4.hg38.wgs.inputs.json; ```; </details>; <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""org.apache.tika"", artifactId = ""tika-core"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""org.apache.tika"", artifactId = ""tika-core"" }; }]; ```; </details>. <sup>; labels: library-update, early-semver-minor, semver-spec-minor, old-version-remains, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7303:363,Config,Configure,363,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7303,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## About this PR; 📦 Updates [org.codehaus.janino:janino](https://github.com/janino-compiler/janino) from `3.1.7` to `3.1.11`. 📜 [GitHub Release Notes](https://github.com/janino-compiler/janino/releases/tag/v3.1.11) - [Version Diff](https://github.com/janino-compiler/janino/compare/3.1.7...3.1.11) - [Version Diff](https://github.com/janino-compiler/janino/compare/v3.1.7...v3.1.11). ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""org.codehaus.janino"", artifactId = ""janino"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""org.codehaus.janino"", artifactId = ""janino"" }; }]; ```; </details>. <sup>; labels: library-update, early-semver-patch, semver-spec-patch, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7307:640,Config,Configure,640,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7307,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## About this PR; 📦 Updates [org.glassfish.jersey.inject:jersey-hk2](https://github.com/eclipse-ee4j/jersey) from `2.32` to `2.41`. 📜 [GitHub Release Notes](https://github.com/eclipse-ee4j/jersey/releases/tag/2.41) - [Version Diff](https://github.com/eclipse-ee4j/jersey/compare/2.32...2.41). ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>🔍 Files still referring to the old version number</summary>. The following files still refer to the old version number (2.32).; You might want to review and update them manually.; ```; project/Dependencies.scala; scripts/metadata_comparison/test/resources/comparer/papiv1_version3_good.json; scripts/metadata_comparison/test/resources/comparer/papiv2_version3_good.json; scripts/metadata_comparison/test/resources/comparer/version3_comparison_good.csv; ```; </details>; <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""org.glassfish.jersey.inject"", artifactId = ""jersey-hk2"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""org.glassfish.jersey.inject"", artifactId = ""jersey-hk2"" }; }]; ```; </details>. <sup>; labels: library-update, old-version-remains, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7308:549,Config,Configure,549,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7308,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## About this PR; 📦 Updates [org.gnieh:diffson-spray-json](https://github.com/gnieh/diffson) from `4.1.1` to `4.4.0`. 📜 [GitHub Release Notes](https://github.com/gnieh/diffson/releases/tag/v4.4.0). ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""org.gnieh"", artifactId = ""diffson-spray-json"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""org.gnieh"", artifactId = ""diffson-spray-json"" }; }]; ```; </details>. <sup>; labels: library-update, early-semver-minor, semver-spec-minor, version-scheme:early-semver, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7309:454,Config,Configure,454,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7309,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## About this PR; 📦 Updates [org.hsqldb:hsqldb](http://hsqldb.org) from `2.6.1` to `2.7.2`. ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>🔍 Files still referring to the old version number</summary>. The following files still refer to the old version number (2.6.1).; You might want to review and update them manually.; ```; project/Dependencies.scala; ```; </details>; <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""org.hsqldb"", artifactId = ""hsqldb"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""org.hsqldb"", artifactId = ""hsqldb"" }; }]; ```; </details>. <sup>; labels: library-update, early-semver-minor, semver-spec-minor, old-version-remains, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7310:348,Config,Configure,348,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7310,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## About this PR; 📦 Updates [org.mariadb.jdbc:mariadb-java-client](https://github.com/mariadb-corporation/mariadb-connector-j) from `2.7.4` to `2.7.11`. 📜 [GitHub Release Notes](https://github.com/mariadb-corporation/mariadb-connector-j/releases/tag/2.7.11) - [Changelog](https://github.com/mariadb-corporation/mariadb-connector-j/blob/master/CHANGELOG.md) - [Version Diff](https://github.com/mariadb-corporation/mariadb-connector-j/compare/2.7.4...2.7.11). ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""org.mariadb.jdbc"", artifactId = ""mariadb-java-client"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""org.mariadb.jdbc"", artifactId = ""mariadb-java-client"" }; }]; ```; </details>. <sup>; labels: library-update, early-semver-patch, semver-spec-patch, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7314:714,Config,Configure,714,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7314,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## About this PR; 📦 Updates [org.mockito:mockito-core](https://github.com/mockito/mockito) from `4.11.0` to `5.7.0` ⚠. 📜 [GitHub Release Notes](https://github.com/mockito/mockito/releases/tag/v5.7.0) - [Version Diff](https://github.com/mockito/mockito/compare/v4.11.0...v5.7.0). ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""org.mockito"", artifactId = ""mockito-core"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""org.mockito"", artifactId = ""mockito-core"" }; }]; ```; </details>. <sup>; labels: library-update, early-semver-major, semver-spec-major, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7315:535,Config,Configure,535,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7315,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## About this PR; 📦 Updates [org.scala-graph:graph-core](https://github.com/scala-graph/scala-graph) from `1.13.1` to `1.13.6`. ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""org.scala-graph"", artifactId = ""graph-core"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""org.scala-graph"", artifactId = ""graph-core"" }; }]; ```; </details>. <sup>; labels: library-update, early-semver-patch, semver-spec-patch, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7316:384,Config,Configure,384,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7316,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## About this PR; 📦 Updates [org.scala-lang:scala-library](https://github.com/scala/scala) from `2.13.9` to `2.13.12`. 📜 [GitHub Release Notes](https://github.com/scala/scala/releases/tag/v2.13.12) - [Version Diff](https://github.com/scala/scala/compare/v2.13.9...v2.13.12). ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""org.scala-lang"", artifactId = ""scala-library"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""org.scala-lang"", artifactId = ""scala-library"" }; }]; ```; </details>. <sup>; labels: library-update, early-semver-patch, semver-spec-patch, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7317:531,Config,Configure,531,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7317,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## About this PR; 📦 Updates [org.scalatest:scalatest](https://github.com/scalatest/scalatest) from `3.2.15` to `3.2.17`. 📜 [GitHub Release Notes](https://github.com/scalatest/scalatest/releases/tag/release-3.2.17) - [Version Diff](https://github.com/scalatest/scalatest/compare/release-3.2.15...release-3.2.17). ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""org.scalatest"", artifactId = ""scalatest"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""org.scalatest"", artifactId = ""scalatest"" }; }]; ```; </details>. <sup>; labels: library-update, early-semver-patch, semver-spec-patch, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7318:568,Config,Configure,568,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7318,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## About this PR; 📦 Updates [org.scoverage:sbt-scoverage](https://github.com/scoverage/sbt-scoverage) from `2.0.4` to `2.0.9`. 📜 [GitHub Release Notes](https://github.com/scoverage/sbt-scoverage/releases/tag/v2.0.9) - [Version Diff](https://github.com/scoverage/sbt-scoverage/compare/v2.0.4...v2.0.9). ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""org.scoverage"", artifactId = ""sbt-scoverage"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""org.scoverage"", artifactId = ""sbt-scoverage"" }; }]; ```; </details>. <sup>; labels: sbt-plugin-update, early-semver-patch, semver-spec-patch, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7319:558,Config,Configure,558,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7319,3,"['Config', 'config', 'plugin']","['Configure', 'configuration', 'plugin-update']"
Modifiability,"## About this PR; 📦 Updates [org.typelevel:kittens](https://github.com/typelevel/kittens) from `2.3.2` to `3.1.0` ⚠. 📜 [GitHub Release Notes](https://github.com/typelevel/kittens/releases/tag/v3.1.0) - [Version Diff](https://github.com/typelevel/kittens/compare/v2.3.2...v3.1.0). ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>🔍 Files still referring to the old version number</summary>. The following files still refer to the old version number (2.3.2).; You might want to review and update them manually.; ```; project/Dependencies.scala; ```; </details>; <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""org.typelevel"", artifactId = ""kittens"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""org.typelevel"", artifactId = ""kittens"" }; }]; ```; </details>. <sup>; labels: library-update, early-semver-major, semver-spec-major, version-scheme:early-semver, old-version-remains, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7321:536,Config,Configure,536,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7321,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## About this PR; 📦 Updates [org.typelevel:mouse](https://github.com/typelevel/mouse) from `1.0.11` to `1.2.2`. 📜 [GitHub Release Notes](https://github.com/typelevel/mouse/releases/tag/v1.2.2) - [Version Diff](https://github.com/typelevel/mouse/compare/v1.0.11...v1.2.2). ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>🔍 Files still referring to the old version number</summary>. The following files still refer to the old version number (1.0.11).; You might want to review and update them manually.; ```; .sdkmanrc; ```; </details>; <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""org.typelevel"", artifactId = ""mouse"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""org.typelevel"", artifactId = ""mouse"" }; }]; ```; </details>. <sup>; labels: library-update, early-semver-minor, semver-spec-minor, version-scheme:early-semver, old-version-remains, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7322:528,Config,Configure,528,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7322,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## About this PR; 📦 Updates [org.yaml:snakeyaml](https://bitbucket.org/snakeyaml/snakeyaml/src) from `1.33` to `2.2`. ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>🔍 Files still referring to the old version number</summary>. The following files still refer to the old version number (1.33).; You might want to review and update them manually.; ```; core/src/test/resources/hello_goodbye_scattered_papiv2.json; project/Dependencies.scala; scripts/metadata_comparison/test/resources/comparer/papiv1_version3_good.json; scripts/metadata_comparison/test/resources/comparer/papiv2_version3_good.json; scripts/metadata_comparison/test/resources/comparer/version3_comparison_good.csv; src/ci/resources/papi_v2_reference_image_manifest.conf; ```; </details>; <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""org.yaml"", artifactId = ""snakeyaml"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""org.yaml"", artifactId = ""snakeyaml"" }; }]; ```; </details>. <sup>; labels: test-library-update, old-version-remains, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7324:374,Config,Configure,374,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7324,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## About this PR; 📦 Updates [se.marcuslonnberg:sbt-docker](https://github.com/marcuslonnberg/sbt-docker) from `1.9.0` to `1.11.0`. 📜 [GitHub Release Notes](https://github.com/marcuslonnberg/sbt-docker/releases/tag/v1.11.0) - [Changelog](https://github.com/marcuslonnberg/sbt-docker/blob/master/CHANGELOG.md) - [Version Diff](https://github.com/marcuslonnberg/sbt-docker/compare/v1.9.0...v1.11.0). ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>🔍 Files still referring to the old version number</summary>. The following files still refer to the old version number (1.9.0).; You might want to review and update them manually.; ```; project/Dependencies.scala; ```; </details>; <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""se.marcuslonnberg"", artifactId = ""sbt-docker"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""se.marcuslonnberg"", artifactId = ""sbt-docker"" }; }]; ```; </details>. <sup>; labels: sbt-plugin-update, early-semver-minor, semver-spec-minor, old-version-remains, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7325:653,Config,Configure,653,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7325,3,"['Config', 'config', 'plugin']","['Configure', 'configuration', 'plugin-update']"
Modifiability,"## About this PR; 📦 Updates bio.terra:workspace-manager-client from `0.254.452-SNAPSHOT` to `0.254.966-SNAPSHOT`. ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>🔍 Files still referring to the old version number</summary>. The following files still refer to the old version number (0.254.452-SNAPSHOT).; You might want to review and update them manually.; ```; project/Dependencies.scala; ```; </details>; <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""bio.terra"", artifactId = ""workspace-manager-client"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""bio.terra"", artifactId = ""workspace-manager-client"" }; }]; ```; </details>. <sup>; labels: library-update, early-semver-minor, semver-spec-patch, old-version-remains, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7258:370,Config,Configure,370,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7258,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## About this PR; 📦 Updates com.google.apis:google-api-services-cloudkms from `v1-rev20230421-2.0.0` to `v1-rev20231012-2.0.0`. ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.apis"", artifactId = ""google-api-services-cloudkms"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""com.google.apis"", artifactId = ""google-api-services-cloudkms"" }; }]; ```; </details>. <sup>; labels: library-update, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7279:384,Config,Configure,384,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7279,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## About this PR; 📦 Updates com.google.apis:google-api-services-lifesciences from `v2beta-rev20220916-2.0.0` to `v2beta-rev20230707-2.0.0`. ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.apis"", artifactId = ""google-api-services-lifesciences"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""com.google.apis"", artifactId = ""google-api-services-lifesciences"" }; }]; ```; </details>. <sup>; labels: library-update, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7280:396,Config,Configure,396,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7280,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## About this PR; 📦 Updates mysql:mysql-connector-java from `8.0.28` to `8.0.33`. ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""mysql"", artifactId = ""mysql-connector-java"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""mysql"", artifactId = ""mysql-connector-java"" }; }]; ```; </details>. <sup>; labels: library-update, early-semver-patch, semver-spec-patch, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7299:338,Config,Configure,338,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7299,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## About this PR; 📦 Updates org.apache.commons:commons-text from `1.10.0` to `1.11.0`. ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""org.apache.commons"", artifactId = ""commons-text"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""org.apache.commons"", artifactId = ""commons-text"" }; }]; ```; </details>. <sup>; labels: library-update, early-semver-minor, semver-spec-minor, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7302:343,Config,Configure,343,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7302,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## About this PR; 📦 Updates org.broadinstitute.dsde.workbench:workbench-google from `0.21-5c9c4f6` to `0.30-2147824`. ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""org.broadinstitute.dsde.workbench"", artifactId = ""workbench-google"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""org.broadinstitute.dsde.workbench"", artifactId = ""workbench-google"" }; }]; ```; </details>. <sup>; labels: library-update, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7304:374,Config,Configure,374,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7304,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## About this PR; 📦 Updates org.broadinstitute.dsde.workbench:workbench-google from `0.21-5c9c4f6` to `0.30-5781917`. ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/9ac858c7e61f43ed3648f0fabc7104d0951cce67/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""org.broadinstitute.dsde.workbench"", artifactId = ""workbench-google"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""org.broadinstitute.dsde.workbench"", artifactId = ""workbench-google"" }; }]; ```; </details>. <sup>; labels: library-update, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7331:374,Config,Configure,374,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7331,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## About this PR; 📦 Updates org.broadinstitute.dsde.workbench:workbench-model from `0.15-f9f0d4c` to `0.19-8376167`. ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""org.broadinstitute.dsde.workbench"", artifactId = ""workbench-model"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""org.broadinstitute.dsde.workbench"", artifactId = ""workbench-model"" }; }]; ```; </details>. <sup>; labels: library-update, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7305:373,Config,Configure,373,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7305,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## About this PR; 📦 Updates org.broadinstitute.dsde.workbench:workbench-util from `0.6-65bba14` to `0.10-8376167`. ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""org.broadinstitute.dsde.workbench"", artifactId = ""workbench-util"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""org.broadinstitute.dsde.workbench"", artifactId = ""workbench-util"" }; }]; ```; </details>. <sup>; labels: library-update, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7306:371,Config,Configure,371,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7306,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## About this PR; 📦 Updates org.liquibase:liquibase-core from `4.8.0` to `4.25.0`. ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""org.liquibase"", artifactId = ""liquibase-core"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""org.liquibase"", artifactId = ""liquibase-core"" }; }]; ```; </details>. <sup>; labels: library-update, early-semver-minor, semver-spec-minor, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7313:339,Config,Configure,339,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7313,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## About this PR; 📦 Updates org.webjars:swagger-ui from `4.5.2` to `4.19.1`. ## Usage; ✅ **Please merge!**. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/57f91b22bf9b52c8cc7ea9474b188ac173019619/docs/repo-specific-configuration.md) file. _Have a fantastic day writing Scala!_. <details>; <summary>⚙ Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""org.webjars"", artifactId = ""swagger-ui"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""org.webjars"", artifactId = ""swagger-ui"" }; }]; ```; </details>. <sup>; labels: library-update, early-semver-minor, semver-spec-minor, commit-count:1; </sup>",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7323:333,Config,Configure,333,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7323,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"## Bug. I am trying to run a workflow using the GCP backend, however no matter what set of configurations I use, I am unable to have it succeed. The workflows Batch task appears to fail on the 3rd task, just after the `Setup Container`. This is basically causing every task to fail for some strange reason. ```; docker: invalid spec: /mnt/disks/cromwell_root:/mnt/disks/cromwell_root:: empty section between colons.; ```. [This](https://cromwellhq.slack.com/archives/CGQ7WK5A6/p1697484861117659) thread suggested that the logic in [these two lines](https://github.com/broadinstitute/cromwell/blob/86/supportedBackends/google/batch/src/main/scala/cromwell/backend/google/batch/runnable/RunnableBuilder.scala#L63-L64) may be the culprit under specific condirtions. ## Information. Cromwell Version: 87-c9d4ce4; <!-- Which backend are you running? -->; Backend: GCP Batch; <!-- Paste/Attach your workflow if possible: -->; ```; version 1.0. task hello {. input {; String name; }; command <<<; echo 'hello ~{name}!'; >>>. output {; File response = stdout(); }. runtime {; docker: ""ubuntu:latest""; cpu: 1; memory: ""3.75 GB""; }; }; workflow test {; call hello. output {; File response = hello.response; }; }; ```. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->; ```hoco; backend {; default = ""batch""; providers {; batch {; actor-factory = ""cromwell.backend.google.batch.GcpBatchBackendLifecycleActorFactory""; config {. # The Project To execute in; project = ""${compute_project}"". # The bucket where outputs will be written to; root = ""gs://${bucket}"". # Polling for completion backs-off gradually for slower-running jobs.; # This is the maximum polling interval (in seconds):; maximum-polling-interval = 600. # Optional configuration to use high security network (Virtual Private Cloud) for running jobs.; # See https://cromwell.readthedocs.io/en/stable/backends/Google/ for more details.; # virtual-private-cloud {; # network-label-key = ""n",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7238:91,config,configurations,91,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7238,1,['config'],['configurations']
Modifiability,"## Bug; Cromwell appears to be improperly tokenizing string interpolations when using a variable that is prepended by the letters: `if` in any format. It seems to think that this is actually the start of a conditional `if _ then _ else` block instead of a variable name. The parser does not appear to be discriminating against the lack of whitespace in variables with the form `if[a-zA-Z0-9_]+` and fails to parse with an error. ### How to reproduce. ```; cat <<EOF > test.wdl; version 1.0; task test_task {; String ifl_token=""a""; command <<<; echo ""~{ifl_token}""; >>>; }. workflow test {; call test_task; }; EOF. java -jar cromwell-84.jar run. test.wdl; ```. ### Expected; 1. The workflow to parse correctly and to echo `a` when running. ### Actual Error. The workflow fails to parse with the following error:. ```; [2022-11-25 11:10:39,68] [info] WorkflowManagerActor: Workflow 45701495-7113-40d6-ac32-dab5247f37e7 failed (during MaterializingWorkflowDescriptorState): cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anon$1: Workflow input processing failed:; ERROR: Unexpected symbol (line 5, col 20) when parsing 'e'. Expected then, got ""}"". echo ""~{ifl_token}""; ^. $e = :identifier <=> :lparen $_gen23 :rparen -> FunctionCall( name=$0, params=$2 ); ; 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$lifecycle$materialization$MaterializeWorkflowDescriptorActor$$workflowInitializationFailed(MaterializeWorkflowDescriptorActor.scala:257); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:227); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:222); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35); ```. ### Environment:; Tested on:; - Cromwell 84; ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6956:88,variab,variable,88,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6956,3,['variab'],"['variable', 'variables']"
Modifiability,"## Discussion \#1; ```; bshifaw [3:59 PM]; Hi Chris, ; The featured joint calling method is using NIO.; https://portal.firecloud.org/#methods/gatk/joint-discovery-gatk4/9/wdl; Is this the method you are referencing? (edited). bshifaw [4:28 PM]; @vdauwera, just confirmed with @jsoto. The wdl isn’t using NIO when importing the GVCFs. Due to a change in the wdl we decide to implement to best leverage the FC data model (using an array of input files instead of a sample name map file). (edited). Collapse; cwhelan [9:48 PM]; right, that’s the method i was using. vdauwera [11:22 PM]; oooh that’s an interesting case that would benefit from the flexible data models work — this would be great to show @andreah; ```. ## Discussion \#2. ```; cwhelan [11:17 AM]; ie it’s trying to localize each gvcf to each shard instance. tjeandet [11:17 AM]; do you have an idea of how many input files each shard has ?. Collapse; cwhelan [11:17 AM]; 555 samples; ```. # Takeaways. Run https://portal.firecloud.org/#methods/gatk/joint-discovery-gatk4/9/wdl in a non-production environment w/ 555 samples and try to reproduce issue w/ hashing timeouts. We predict they will not occur as cromwell production was seeing elevated CPU usage due to it's /stats endpoint being hit repeatedly.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3712:644,flexible,flexible,644,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3712,1,['flexible'],['flexible']
Modifiability,"## Motivation. A significant limitation of using the Google Backend on Cromwell today is that [only N* machine types](https://github.com/broadinstitute/cromwell/blob/develop/supportedBackends/google/batch/src/main/scala/cromwell/backend/google/batch/util/GcpBatchMachineConstraints.scala#L29-L32) can be used on GCP. In particular, N* machine types do not provide access to modern GPUs and users interested in running workflows on GPUs are limited to older NVIDIA T4 or V100 accelerators. ## Proposal. Add support for standard machine types, which would allow running workflows on a much broader range of machine types on GCP, including those configured with modern GPUs (e.g.: NVIDIA A100, H100). Related: https://github.com/broadinstitute/cromwell/issues/6558",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7535:643,config,configured,643,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7535,1,['config'],['configured']
Modifiability,"## Symptom; I can run test and assembly tasks succesfully on cromwellApiClient subproject, but If I write my own small test class that uses `cromwell.api.CromwellClient` it fails at runtime with:; ```; Detected java.lang.NoSuchMethodError error, which MAY be caused by incompatible Akka versions on the classpath. Please note that a given Akka version MUST be the same across all modules of Akka that you are using, e.g. if you use akka-actor [2.5.3 (resolved from current classpath)] all other core Akka modules MUST be of the same version. External projects like Alpakka, Persistence plugins or Akka HTTP etc. have their own version numbers - please make sure you're using a compatible set of libraries. ; Uncaught error from thread [default-akka.actor.default-dispatcher-5]: akka.actor.ActorCell.addFunctionRef(Lscala/Function2;)Lakka/actor/FunctionRef;, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for for ActorSystem[default]; java.lang.NoSuchMethodError: akka.actor.ActorCell.addFunctionRef(Lscala/Function2;)Lakka/actor/FunctionRef;; ...; ```; I'm essentially seeing exactly the behaviour described in reference [1] below, which is eviction warnings at compile time and then the runtime blow-up. The root cause seems to be that akka-http depends on an older version of akka-actor (2.4.19) than that specified for the project (2.5.3). Running `dependencyTree` task confirms:; ```; [info] +-com.typesafe.akka:akka-http-spray-json_2.12:10.0.9 [S]; [info] | +-com.typesafe.akka:akka-http_2.12:10.0.9 [S]; [info] | | +-com.typesafe.akka:akka-http-core_2.12:10.0.9 [S]; [info] | | +-com.typesafe.akka:akka-parsing_2.12:10.0.9 [S]; [info] | | | +-com.typesafe.akka:akka-actor_2.12:2.4.19 (evicted by: 2.5.3); ```; If I explicitly add dependency on the latest akka-stream as suggested in [2] and [3], the problem goes away:; ```; diff --git a/project/Dependencies.scala b/project/Dependencies.scala; index 0d77e2d3..7254fc61 100644; --- a/project/Dependencies.scala; +++ b/project",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2579:586,plugin,plugins,586,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2579,1,['plugin'],['plugins']
Modifiability,"## basic issue; `womtool validate` does not catch all scenarios where you are defining a new variable based on an optional variable. Instead, Cromwell fails at runtime -- even if it is actually impossible for that optional variable to be undefined. [A working example is available](https://github.com/aofarrel/myco/commit/e7f9ba6951d1b0fe5b3c1a650835312dd2b6e68f), but it is a complex WDL, so a more basic example is listed below. ## background; WDL doesn't really have a proper understanding of mutual exclusivity, so it doesn't realize that anything under a ""is optional variable X defined?"" block can only happen if optional variable X is defined. In other words, if variant_caller.errorcode has type Array[String?], the following code block is invalid, and womtool correctly flags it as such:. ```; if(defined(variant_caller.errorcode)) { ; 	Array[String] not_optional_error_code = variant_caller.errorcode; }; ```. > Failed to process declaration 'Array[String] varcall_error_if_earlyQC_filtered = variant_call_after_earlyQC_filtering.errorcode' (reason 1 of 1): Cannot coerce expression of type 'Array[String?]' to 'Array[String]'. The normal workaround for this is to use select_first() with a bogus fallback value, since the `defined` check means that fallback value will never be selected. ```; if(defined(variant_caller.errorcode)) { ; 	Array[String] not_optional_error_code = select_first([variant_caller.errorcode, [""according to all known laws of aviation""]]); }; ```. The same holds true if I only care about the first (index 0) variable in the array. That's the case for me, since the actual workflow I'm working on will be run on Terra data tables, eg each instance of the workflow only gets one sample but dozens of instances of the workflow will be created. For compatibility reasons I cannot convert the variant caller into a non-scattered task, so its error code will still have type Array[String]? even though that array will only have one value. ```; if(defined(variant_caller.er",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7194:93,variab,variable,93,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7194,5,['variab'],['variable']
Modifiability,"### Description. - Define new workflow option for workflow outputs mode, move or copy; - Enhance Centaur to allow nested directories of `.test` files, which is required for the next step to be sane; - Relocate regression tests for existing copy behavior so they actually run; - Add test for new move mode; - Created new `centaur-ci-us-east1` bucket in `broad-dsde-cromwell-dev` and used it to replace `cloud-cromwell-dev-self-cleaning-fast` bucket. It was really hard to tell whether one was successfully testing a cross-region move. ### Release Notes Confirmation. The move mode is documented but is not ready for a release note because we are not updating metadata yet. #### `CHANGELOG.md`; - [ ] I updated `CHANGELOG.md` in this PR; - [x] I assert that this change shouldn't be included in `CHANGELOG.md` because it doesn't impact community users. #### Terra Release Notes; - [ ] I added a suggested release notes entry in this Jira ticket; - [x] I assert that this change doesn't need Jira release notes because it doesn't impact Terra users",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7472:89,Enhance,Enhance,89,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7472,1,['Enhance'],['Enhance']
Modifiability,"### Description. After using it in practice for a while, here's a small round of changes:; - Remove JDK. This was by far the largest by megabytes and the most fickle build process. It was really only there in case I wanted to use `jstack` as a backup if I couldn't connect YourKit; but we now have a [blessed procedure](https://docs.google.com/document/d/1bmlrM3lpNP2c1_wnm2TzQmvtbsid2g-ZEdx41LcsECw/edit) to run YourKit in any environment.; - Message-of-the-day on container login. Enhanced situational awareness to make sure you're on the container you want, and the container is running the version you think it is. Without the JDK, the image is 634 MB, only 16% larger than baseline at 547 MB. MOTD example:; ```; > kubectl exec -it -n terra-dev cromwell1-runner-76f7b5d5df-qpwdl -c cromwell1-runner-app -- bash; Version 88-6e242af-DEBUG built at 2024-05-21 18:07:36; root@cromwell1-runner-76f7b5d5df-qpwdl:/# ; ```. ### Release Notes Confirmation. #### `CHANGELOG.md`; - [ ] I updated `CHANGELOG.md` in this PR; - [x] I assert that this change shouldn't be included in `CHANGELOG.md` because it doesn't impact community users. #### Terra Release Notes; - [ ] I added a suggested release notes entry in this Jira ticket; - [x] I assert that this change doesn't need Jira release notes because it doesn't impact Terra users",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7443:483,Enhance,Enhanced,483,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7443,1,['Enhance'],['Enhanced']
Modifiability,"### Description. As part of preparing for the fall 2024 audit, we were asked to fix the permissions on the various healthcheck buckets such as `gs://cromwell-ping-me-dev`. It would have taken some tinkering to make sure the permissions are secure enough _and_ the healthcheck still works, so I decided to drop the healthcheck. I am not aware of any times it's helped us and doesn't pass the ""would we add this today"" test. The only notable bucket we'd want to make sure Cromwell itself has permissions on is the workflow archiver - and it uses [a separate service account from the rest of Cromwell](https://github.com/broadinstitute/terra-helmfile/blob/master/charts/cromwell/templates/config/_cromwell.conf.tpl#L267-L271), so it's not a valid test. ### Release Notes Confirmation. #### `CHANGELOG.md`; - [x] I updated `CHANGELOG.md` in this PR; - [ ] I assert that this change shouldn't be included in `CHANGELOG.md` because it doesn't impact community users. #### Terra Release Notes; - [ ] I added a suggested release notes entry in this Jira ticket; - [x] I assert that this change doesn't need Jira release notes because it doesn't impact Terra users",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7533:686,config,config,686,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7533,1,['config'],['config']
Modifiability,"### Description. Currently, and as described in https://github.com/broadinstitute/cromwell/issues/7535, only general-purpose machine types are supported in Google Backend, which prevents running wdl workflows on many machine types available on GCP, including those provisioned with modern GPUs. I believe the simplest and most general solution would be to pass the machine type directly from the wdl configuration to the Google Batch API. The idea is that this approach would be more resilient to machine types being added or deprecated on GCP, as users would only need to update their wdl workflows in such cases. An alternative approach of mapping machine specs (e.g.: cpu platform and gpu requirements) to standard machine types would potentially introduce an additional layer of maintenance with little benefit. This PR adds support for a new standardMachineType key in the runtime section, which is only parsed for the Google backend. ### Testing. I deployed this internally and verified I can successfully run the following wdl workflow:. ```; version 1.0. task nvidia_smi {; input {; String docker_version; }. command <<<; nvidia-smi. touch .done; echo ""Finished at $(date)""; >>>. runtime {; docker: <internal image>; disks: ""local-disk 50 SSD""; memory: ""32G""; preemptible: 0; gpuCount: 1; gpuType: ""nvidia-tesla-a100""; standardMachineType: ""a2-highgpu-1g""; }. output {; File done = "".done""; }; }. workflow nvidia_smi_wf {; input {; String docker_version; }; ; call nvidia_smi as nvidia_smi_call {; input:; docker_version = docker_version; }. output {; File done = "".done""; }; }; ```. ### Next steps. - [ ] Confirm this approach is in the right direction with the cromwell team.; - [ ] Work on proper unit tests and get this PR ready to be merged. ### Release Notes Confirmation. #### `CHANGELOG.md`; - [ ] I updated `CHANGELOG.md` in this PR; - [ ] I assert that this change shouldn't be included in `CHANGELOG.md` because it doesn't impact community users. #### Terra Release Notes; - [ ] I a",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7545:400,config,configuration,400,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7545,1,['config'],['configuration']
Modifiability,"### Description. Fix a couple of PAPI v2 Centaur test to actually run on the backends they suggested they were running on, add an IntelliJ run config for PAPI v2. ### Release Notes Confirmation. #### `CHANGELOG.md`; - [ ] I updated `CHANGELOG.md` in this PR; - [x] I assert that this change shouldn't be included in `CHANGELOG.md` because it doesn't impact community users. #### Terra Release Notes; - [ ] I added a suggested release notes entry in this Jira ticket; - [x] I assert that this change doesn't need Jira release notes because it doesn't impact Terra users",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7511:143,config,config,143,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7511,1,['config'],['config']
Modifiability,"### Description. Instead of pushing the logs file after the job completes, the logs are now streamed to GCS. This is how it works:; - Mount the main GCS bucket as a disk in the VM filesystem.; - Configure Batch to store the logs in the mounted disk.; - The log file belongs to the same path used by the task files. Notes:; - I haven't found a way to `tail` the GCS file but running `cat` continuously display the new logs.; - I'm not sure whether the logs are streamed live or when the runnable completes, if needed, I can evaluate this.; - There are some tricks I used to get this done, I'm open to suggestions for improving the approach.; - Follows up from #7491. ### Release Notes Confirmation. #### `CHANGELOG.md`; - [x] I updated `CHANGELOG.md` in this PR; - [ ] I assert that this change shouldn't be included in `CHANGELOG.md` because it doesn't impact community users. #### Terra Release Notes; - [ ] I added a suggested release notes entry in this Jira ticket; - [ ] I assert that this change doesn't need Jira release notes because it doesn't impact Terra users",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7529:195,Config,Configure,195,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7529,1,['Config'],['Configure']
Modifiability,"### Description. Jira: https://broadworkbench.atlassian.net/browse/WX-1835. Note: the scheduled logging will happen even if `quota-exhaustion-job-start-control` is disabled. This is because even if JobTokenDispenser doesn't account for quota exhausted groups, Cromwell is always recording which groups are in quota exhaustion. And scheduled logging will help easily see that list even if the feature `quota-exhaustion-job-start-control` is disabled. Example logs at different times:; ```; 2024-09-12 18:32:11 cromwell-system-akka.dispatchers.engine-dispatcher-24 INFO - GroupMetricsActor configured to log groups experiencing quota exhaustion at interval of 5 minutes.; 2024-09-12 18:37:11 cromwell-system-akka.dispatchers.engine-dispatcher-58 INFO - Hog groups currently experiencing quota exhaustion: 3. Group IDs: [cromwell-dev, sshah-test-1, sshah-test-2].; ....; 2024-09-12 18:42:11 cromwell-system-akka.dispatchers.engine-dispatcher-71 INFO - Hog groups currently experiencing quota exhaustion: 1. Group IDs: [cromwell-dev].; ....; 2024-09-12 19:02:12 cromwell-system-akka.dispatchers.engine-dispatcher-60 INFO - Hog groups currently experiencing quota exhaustion: 0. Group IDs: [].; ```. ### Release Notes Confirmation. #### `CHANGELOG.md`; - [ ] I updated `CHANGELOG.md` in this PR; - [x] I assert that this change shouldn't be included in `CHANGELOG.md` because it doesn't impact community users. #### Terra Release Notes; - [ ] I added a suggested release notes entry in this Jira ticket; - [x] I assert that this change doesn't need Jira release notes because it doesn't impact Terra users",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7539:588,config,configured,588,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7539,1,['config'],['configured']
Modifiability,"### Description. LogsPolicy is now configurable. - When the ""logs-policy"" config entry is missing, ""CLOUD_LOGGING"" is set which is the default policy from Batch.; - When the ""logs-policy"" is set to ""PATH"", a ""task.log"" file is stored within the file system under the task files, this is later pushed to Google Cloud Storage. This is an exampel where ""task.log"" can be found:; - `gs://project-id/cromwell-execution-root/workflow-name/workflow-id/call-myTask/task.log` (workflow-id would be a UUID). ### Release Notes Confirmation. #### `CHANGELOG.md`; - [x] I updated `CHANGELOG.md` in this PR; - [ ] I assert that this change shouldn't be included in `CHANGELOG.md` because it doesn't impact community users. #### Terra Release Notes; - [ ] I added a suggested release notes entry in this Jira ticket; - [ ] I assert that this change doesn't need Jira release notes because it doesn't impact Terra users",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7491:35,config,configurable,35,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7491,2,['config'],"['config', 'configurable']"
Modifiability,### Description. Remove unused config key. ### Release Notes Confirmation. #### `CHANGELOG.md`; - [ ] I updated `CHANGELOG.md` in this PR; - [x] I assert that this change shouldn't be included in `CHANGELOG.md` because it doesn't impact community users. #### Terra Release Notes; - [ ] I added a suggested release notes entry in this Jira ticket; - [x] I assert that this change doesn't need Jira release notes because it doesn't impact Terra users,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7577:31,config,config,31,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7577,1,['config'],['config']
Modifiability,"### Description. Run config for developers to be easily able to exercise the GCP Batch backend locally. To use:. 1. Start a mysql container by running `processes/release_processes/scripts/start_publish_mysql_docker.sh`; 1. Run this config in IntelliJ: 'Repo template: Cromwell GCPBATCH server'. ### Release Notes Confirmation. Dev-only, no release notes.; #### `CHANGELOG.md`. - [ ] I updated `CHANGELOG.md` in this PR; - [x] I assert that this change shouldn't be included in `CHANGELOG.md` because it doesn't impact community users. #### Terra Release Notes; - [ ] I added a suggested release notes entry in this Jira ticket; - [x] I assert that this change doesn't need Jira release notes because it doesn't impact Terra users",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7492:21,config,config,21,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7492,2,['config'],['config']
Modifiability,"### Description. The PR exercises the ""retry with more memory"" Centaur tests on the GCP Batch backend. Minimal changes to production code, all of which are in the GCP Batch backend:. - The constant`RunnableUtils#MountPoint` was created with value `/mnt/disks/cromwell_root` and applied where appropriate.; - A copy/paste bug in code brought over from PAPIv2 was corrected (the `/cromwell_root` of PAPIv2 has become `/mnt/disks/cromwell_root` in Batch), using the constant described above.; - If a job fails, the *last* event message is now propagated rather than the first event message. The first event message is often a benign state transition, while the last event message is more likely to contain the actual reason for job failure.; ; Unfortunately Cromwell does not allow for dynamic backend selection (i.e. the backend name cannot be a variable), which necessitated copy/paste/renaming the Centaur test WDLs from their PAPIv2 versions, hence the magnitude of these diffs. The existing `preemptible_and_memory_retry ` Centaur test is heavily tailored to the quirks of Papi v2: a preemptible PAPI VM deletes itself and depends on the Lifesciences system mistaking that for a preemption event. tbh this is kind of a weird test and as I don't know how to induce a preemption on demand, I simply `ignore`d the GCPBATCH version. ### Release Notes Confirmation. #### `CHANGELOG.md`; - [x] I updated `CHANGELOG.md` in this PR; - [ ] I assert that this change shouldn't be included in `CHANGELOG.md` because it doesn't impact community users. #### Terra Release Notes; - [ ] I added a suggested release notes entry in this Jira ticket; - [x] I assert that this change doesn't need Jira release notes because it doesn't impact Terra users",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7494:844,variab,variable,844,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7494,1,['variab'],['variable']
Modifiability,"### Description. This PR refactors & renames the `CostCatalogHelper` into the `PollResultMonitorActor`. Doing this allows the helper to asynchronously communicate with the `CostCatalogService`, which it needs to do in order to calculate a VM Cost Per Hour. . ### Release Notes Confirmation. #### `CHANGELOG.md`; - [ ] I updated `CHANGELOG.md` in this PR; - [x] I assert that this change shouldn't be included in `CHANGELOG.md` because it doesn't impact community users. #### Terra Release Notes; - [ ] I added a suggested release notes entry in this Jira ticket; - [x] I assert that this change doesn't need Jira release notes because it doesn't impact Terra users",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7544:25,refactor,refactors,25,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7544,1,['refactor'],['refactors']
Modifiability,"### Description. This should have no effect on our existing Bard usage, just removes errors logged when NOT using Bard. * Base config was incorrect, so Bard was not registered in the Service Registry by default; * `BardEventingActor.receive` had no handling for receiving a `BardEvent` when eventing was disabled... and also nothing has ever checked for enablement before creating and sending these events. ### Release Notes Confirmation. #### `CHANGELOG.md`; - [ ] I updated `CHANGELOG.md` in this PR; - [x] I assert that this change shouldn't be included in `CHANGELOG.md` because it doesn't impact community users. #### Terra Release Notes; - [ ] I added a suggested release notes entry in this Jira ticket; - [x] I assert that this change doesn't need Jira release notes because it doesn't impact Terra users",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7566:127,config,config,127,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7566,1,['config'],['config']
Modifiability,"### Description. While testing on Dev, I discovered that the Wom traversal in `moveOrIdentity` is woefully inadequate. We need to support structs, maps, pairs, etc. to call this feature complete. In researching how to address this, I discovered `womValueToMetadataEvents` which seems like a much better pre-existing piece of code that already traverses all Wom types. After [cleaning it up](https://github.com/broadinstitute/cromwell/pull/7499/files#diff-854b47290dea5287619fbe2c8cbcc3db06552b4a84d3456552e261efd086ad8cL246-L266) in https://github.com/broadinstitute/cromwell/pull/7499, this PR enhances it with file location mapping. The Centaur test verifies mapping of a file in a map in a pair in a struct. Recursion!. ```; struct FooStruct {; Int simple; Pair[Array[Int], Map[String, File]] complex; }; ```. ### Release Notes Confirmation. #### `CHANGELOG.md`; - [ ] I updated `CHANGELOG.md` in this PR; - [x] I assert that this change shouldn't be included in `CHANGELOG.md` because it doesn't impact community users. #### Terra Release Notes; - [ ] I added a suggested release notes entry in this Jira ticket; - [x] I assert that this change doesn't need Jira release notes because it doesn't impact Terra users",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7509:595,enhance,enhances,595,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7509,1,['enhance'],['enhances']
Modifiability,### Description; Change in Google Cloud Batch Backend VPC configuration attributes to remove trailing slash in network subnet address. Google Cloud Backend no longer supports a trailing slash in the URL. ### Release Notes Confirmation. #### `CHANGELOG.md`; - [ ] I updated `CHANGELOG.md` in this PR; - [ ] I assert that this change shouldn't be included in `CHANGELOG.md` because it doesn't impact community users. #### Terra Release Notes; - [ ] I added a suggested release notes entry in this Jira ticket; - [ ] I assert that this change doesn't need Jira release notes because it doesn't impact Terra users,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7504:58,config,configuration,58,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7504,1,['config'],['configuration']
Modifiability,"### Motivation:. For motivation see the [metadata design doc](https://docs.google.com/document/d/1VYnzk97yTtllozO9ivZpZQTwrsY5T0wGqxlvAbrEQgg/edit?ts=5d5d601c#heading=h.iqo65dknl60s). . Briefly, the intention is to move the ""rendering"" process inside the `ServiceRegistryActor` so that in the future calls to the ServiceRegistry return JSON rather than event lists. This allows the ""pre-rendered JSON"" metadata service to fulfil the same service interface as the ""database-event driven"" metadata service. ### PR Review Guidance. Most of the PR is noise but the ""signal"" is very important to get right!. Things to consider when reviewing this (perhaps otherwise unwieldy) PR:. - Does the actor structure in the diagrams below make sense?; - ... and does it match reality as implemented in this PR?; - Have the newly introduced actors been implemented well? (ie please review these as though they were brand new actors); - `ReadMetadataRegulatorActor`; - `MetadataBuilderActor`; - `ReadDatabaseMetadataWorkerActor`; - Have the responsibilities of the replaced actors been taken care of appropriately?; - Has the API of Cromwell changed inappropriately?; - I had to refactor the `CallCacheDiffActor` because it was using the metadata service directly. Did I do a good job? And are its new tests appropriately equivalent to its old ones?; - Are there sufficient tests between unit, CI and ""perf"" to make you feel good about me merging this PR?; - Am I forgetting anything?. ### Structure before the changes:. ![Before BA-5842_ Metadata Service Actor (3)](https://user-images.githubusercontent.com/13006282/64040517-426d4380-cb2b-11e9-8a40-fa11edd33b58.png). ### Structure after the changes:. ![After BA-5842_ Metadata Service Actor](https://user-images.githubusercontent.com/13006282/64040066-24531380-cb2a-11e9-8a74-98d7c976e6ec.png). ### Concerns. This feels slightly more risky than normal because the refactor was pretty fiddly and I was ""test driven"" for a significant portion of the refactor - mainl",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5150:1163,refactor,refactor,1163,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5150,1,['refactor'],['refactor']
Modifiability,"#### Background. For background information see [this design doc](https://docs.google.com/document/d/1QqXuURg1HlwAymaQkwCL6v9HA5NWsp1pbribvGafNt0/edit?ts=5c6c875c#heading=h.56f418pyjwq8). #### Concept. * Allow Cromwell to spin up PAPIv2 jobs on high security networks ; * At project-creation time, scripts may create a high-security network for that project and record the network name in the project metadata.; * If these fields exist, Cromwell should honor them. #### Proposal. * Use a key in Cromwell's configuration to locate the appropriate project metadata; * For example, perhaps: ; ```; backend {; providers {; PAPIv2 {; config {; backend.providers.PAPIv2.config.vpc {; name: ""terra-network""; subnetwork: ""terra-subnetwork""; }; }; }; }; }; ```; * When about to submit a job to PAPI, see whether the `name` field exists in the configuration.; * If so, check whether the specified label exists in the Google project, eg:; ```; $ gcloud projects describe my-fc-project. createTime: '2017-07-07T17:07:10.345Z'; labels:; terra-network: firecloud; terra-subnetwork: firecloud; lifecycleState: ACTIVE; name: my-fc-project; ```; * If so, deduce a `NETWORK_PATH` by combining the `GOOGLE_PROJECT_ID` (from workflow options) and `NETWORK_NAME` (the label value) as: `projects/GOOGLE_PROJECT_ID/global/networks/NETWORK_NAME`; * Include this in the PAPI request:; ```; pipeline.resources.virtualMachine.network: {; name: NETWORK_PATH; }; ```; * If both the `name` and `subnetwork` fields are defined in configuration, and both exist as project labels:; * The `SUBNETWORK` is the raw value of the `subnetwork` label in the google project; * We additionally provide the subnetwork in the PAPI request:; ```; pipeline.resources.virtualMachine.network: {; name: NETWORK_PATH; subnetwork: SUBNETWORK; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4806:506,config,configuration,506,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4806,5,['config'],"['config', 'configuration']"
Modifiability,"###; ### IMPORTANT: Please file new issues over in our Jira issue tracker!; ###; ### https://broadworkbench.atlassian.net/projects/BA/issues; ###; ### You may need to create an account before you can view/create issues.; ###. ![Screen Shot 2021-12-01 at 4 39 47 PM](https://user-images.githubusercontent.com/4966343/144191887-75590326-1edb-442d-b2eb-ffb04968a964.png); <!--; Hi! Thanks for taking the time to report feedback. Before posting an issue over in Jira tracker, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're almost in the right place. -->. <!-- You'll want to go to https://broadworkbench.atlassian.net/projects/BA/issues and then tell us: -->. <!-- Which backend are you running? -->; Local. <!-- Paste/Attach your workflow if possible: -->; WholeGenomeGermlineSingleSample_develop 3.0.0; https://github.com/broadinstitute/warp/releases/tag/WholeGenomeGermlineSingleSample_develop. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->; [cromwell.conf.zip](https://github.com/broadinstitute/cromwell/files/7631795/cromwell.conf.zip). $ java -jar -Dconfig.file=cromwell.conf cromwell-71.jar server; $ curl -X POST --header ""Accept: application/json"" -v ""0.0.0.0:8000/api/workflows/v1"" -F ""workflowSource=@WholeGenomeGermlineSingleSample_develop.wdl"" -F ""workflowInputs=@WholeGenomeGermlineSingleSample_develop.inputs.local.json"" -F ""workflowDependencies=@WholeGenomeGermlineSingleSample_develop.zip""",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6582:1353,config,configuration,1353,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6582,1,['config'],['configuration']
Modifiability,"###; ### IMPORTANT: Please file new issues over in our Jira issue tracker!; ###; ### https://broadworkbench.atlassian.net/projects/BA/issues; ###; ### You may need to create an account before you can view/create issues.; ###. <!--. Hi! Thanks for taking the time to report feedback. Before posting an issue over in Jira tracker, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're almost in the right place. -->. <!-- You'll want to go to https://broadworkbench.atlassian.net/projects/BA/issues and then tell us: -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->; We want to submit workflow pipelines on GCP on specified Custom machine type, such as E2, N1, N2, n1-standard-8, etc. can you please support that?; Thanks!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6217:1063,config,configuration,1063,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6217,1,['config'],['configuration']
Modifiability,"###; ### IMPORTANT: Please file new issues over in our Jira issue tracker!; ###; ### https://broadworkbench.atlassian.net/projects/BA/issues; ###; ### You may need to create an account before you can view/create issues.; ###. <!--; Hi! Thanks for taking the time to report feedback. Before posting an issue over in Jira tracker, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're almost in the right place. -->. <!-- You'll want to go to https://broadworkbench.atlassian.net/projects/BA/issues and then tell us: -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6459:1063,config,configuration,1063,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6459,5,['config'],['configuration']
Modifiability,"###; ### IMPORTANT: Please file new issues over in our Jira issue tracker!; ###; ### https://broadworkbench.atlassian.net/projects/BA/issues; ###; ### You may need to create an account before you can view/create issues.; ###. <!--; Hi! Thanks for taking the time to report feedback. Before posting an issue over in Jira tracker, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're almost in the right place. -->. <!-- You'll want to go to https://broadworkbench.atlassian.net/projects/BA/issues and then tell us: -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->. Hi, ; Can I ask a question? I think it's related with ; https://github.com/broadinstitute/cromwell/issues/4212. I found the `job_name` is the UUID and it's assigned with subworkflow's UUID if there is a subworflow. What I would like to ask is if there is any other system variables that store the main UUID. As we have our own backend implementation, we need to pass the main UUID to the backend. . Thanks, ; Seung",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6005:1063,config,configuration,1063,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6005,2,"['config', 'variab']","['configuration', 'variables']"
Modifiability,"###; ### IMPORTANT: Please file new issues over in our Jira issue tracker!; ###; ### https://broadworkbench.atlassian.net/projects/BA/issues; ###; ### You may need to create an account before you can view/create issues.; ###. <!--; Hi! Thanks for taking the time to report feedback. Before posting an issue over in Jira tracker, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're almost in the right place. -->. <!-- You'll want to go to https://broadworkbench.atlassian.net/projects/BA/issues and then tell us: -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->. hello, ; Support for wdl step-by-step?; After executing a step, wait for the command to execute the next step.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5537:1063,config,configuration,1063,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5537,1,['config'],['configuration']
Modifiability,"###; ### IMPORTANT: Please file new issues over in our Jira issue tracker!; ###; ### https://broadworkbench.atlassian.net/projects/BA/issues; ###; ### You may need to create an account before you can view/create issues.; ###. <!--; Hi! Thanks for taking the time to report feedback. Before posting an issue over in Jira tracker, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're almost in the right place. -->. <!-- You'll want to go to https://broadworkbench.atlassian.net/projects/BA/issues and then tell us: -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->; Cromwell version is 55; We had submitted workflow pipelines on GCP PAPIv2 (https://genomics.googleapis.com/), in WDL file, set cpu: ""4"", memory: ""48 GB"", the actual VM created as custom (8 vCPUs, 48 GB memory), for ""memory"": ""64 GB"" ""cpu"": ""8"", the actual VM created as (10 vCPU, 64 GB), Cromwell did not created VM as configured in WDL. Thanks",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6216:1063,config,configuration,1063,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6216,2,['config'],"['configuration', 'configured']"
Modifiability,"###; ### IMPORTANT: Please file new issues over in our Jira issue tracker!; ###; ### https://broadworkbench.atlassian.net/projects/BA/issues; ###; ### You may need to create an account before you can view/create issues.; ###. <!--; Hi! Thanks for taking the time to report feedback. Before posting an issue over in Jira tracker, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're almost in the right place. -->. <!-- You'll want to go to https://broadworkbench.atlassian.net/projects/BA/issues and then tell us: -->. <!-- Which backend are you running? -->. endpoint-url = ""https://genomics.googleapis.com/""; Cromwell version 55. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->; All job submissions stopped working today with errors:; Unable to complete PAPI request due to system or connection error (PipelinesApiRequestHandler actor termination caught by manager)"". Error messages from Cromwell logs:; cromwell.backend.google.pipelines.common.api.PipelinesApiRequestWorker$$anon$1: A batch of PAPI status requests failed. The request manager will retry automatically up to 10 times. The error was: 404 Not Found; POST https://genomics.googleapis.com/batch; <!DOCTYPE html>; <html lang=en>; <meta charset=utf-8>; <meta name=viewport content=""initial-scale=1, minimum-scale=1, width=device-width"">; <title>Error 404 (Not Found)!!1</title>; ...",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6203:1135,config,configuration,1135,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6203,1,['config'],['configuration']
Modifiability,"###; ### IMPORTANT: Please file new issues over in our Jira issue tracker!; ###; ### https://broadworkbench.atlassian.net/projects/BA/issues; ###; ### You may need to create an account before you can view/create issues.; ###. <!--; Hi! Thanks for taking the time to report feedback. Before posting an issue over in Jira tracker, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're almost in the right place. -->. <!-- You'll want to go to https://broadworkbench.atlassian.net/projects/BA/issues and then tell us: -->. <!-- Which backend are you running? -->; The backend the workflow pipelines is https://genomics.googleapis.com/. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->; Error message: ; The job was stopped before the command finished. PAPI error code 14. Execution failed: worker was terminated. The job was running on non-preemptible VM, with one instance of nvidia-tesla-t4 attached, nvidiaDriverVersion: 418.40.04. . What does ""PAPI error code 14"" mean? Can you suggest what we should do with it?. Thanks!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6306:1135,config,configuration,1135,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6306,1,['config'],['configuration']
Modifiability,"###; ### IMPORTANT: Please file new issues over in our Jira issue tracker!; ###; ### https://broadworkbench.atlassian.net/projects/BA/issues; ###; ### You may need to create an account before you can view/create issues.; ###. <!--; Hi! Thanks for taking the time to report feedback. Before posting an issue over in Jira tracker, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're almost in the right place. -->. Cromwell lacks support for Shared VPC setup in GCP. Shared VPC model is quite common to large enterprises. Searching for the support I came across the pull request https://github.com/broadinstitute/cromwell/pull/6225 The code changes in this pull request seems to address the shared vpc support. What are the plans to get this on the roadmap for upcoming versions?. <!-- You'll want to go to https://broadworkbench.atlassian.net/projects/BA/issues and then tell us: -->. <!-- Which backend are you running? -->. GCP. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6443:1434,config,configuration,1434,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6443,1,['config'],['configuration']
Modifiability,"###; ### IMPORTANT: Please file new issues over in our Jira issue tracker!; ###; ### https://broadworkbench.atlassian.net/projects/BA/issues; ###; ### You may need to create an account before you can view/create issues.; ###. Hi there,; I'm running Cromwell on a SLURM compute node, so I have enough RAM for the workflow database. Cromwell is used to coordinate this workflow: https://github.com/gatk-workflows/gatk4-somatic-snvs-indels/blob/master/mutect2.wdl on google cloud. When I scancel the SLURM job the google api continues to create VM instances even though the Cromwell job has been killed. How can this be prevented?. <!--; Hi! Thanks for taking the time to report feedback. Before posting an issue over in Jira tracker, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're almost in the right place. -->. <!-- You'll want to go to https://broadworkbench.atlassian.net/projects/BA/issues and then tell us: -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5380:1466,config,configuration,1466,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5380,1,['config'],['configuration']
Modifiability,"###; ### IMPORTANT: Please file new issues over in our Jira issue tracker!; ###; ### https://broadworkbench.atlassian.net/projects/BA/issues; ###; ### You may need to create an account before you can view/create issues.; ###. Hi this is not an issue but a question. I am running scatter to align 114 samples using bwa. I use scatter in the workflow and then set the config to `concurrent-job-limit = 10` but this **still crashes my HPC server**. Can you let me know how to limit the jobs in scatter?. my.conf; ```; include required(classpath(""application"")). call-caching {; enabled = true; }. backend {; 	providers {; 		BackendName {; 			actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; 			config {; 				concurrent-job-limit = 10; 			}; 		}; 	}; }; ```. workflow where samples is 114 sample structs with fastqs; ```; scatter (s in samples) {; 		call bwa_task.Mem as bwa {; 			input :; 				trim = trim,; 				read1 = s.read1,; 				#read2 = s.read2,; 				bwaIndex = bwaIndex,; 				outputPrefix = s.outputPrefix,; 				readgroup = s.readgroup,; 				runtime_params = standard_runtime_bwa	; 		}; 		; 		; 		call samtools.sort as samsort {; 			input :; 				sam = bwa.outputSam,; 				outputPrefix = s.outputPrefix,; 				runtime_params = standard_runtime_samtools; 		}; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6188:366,config,config,366,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6188,4,"['Config', 'config']","['ConfigBackendLifecycleActorFactory', 'config']"
Modifiability,"###; ### IMPORTANT: Please file new issues over in our Jira issue tracker!; ###; ### https://broadworkbench.atlassian.net/projects/BA/issues; ###; ### You may need to create an account before you can view/create issues.; ###; The early release of Cromwell had a script that included some steps of executions and the docker run commands. Currently we are using Cromwell release 52, that script or similar script is not found, for reproducible purpose, our users want to know the actual commands, for example, if three runtime attributes are supplied: gpuType, gpuCount and nvidiaDriverVersion, what is the command line of docker run after NVIDIA driver installed?. Thanks!. <!--; Hi! Thanks for taking the time to report feedback. Before posting an issue over in Jira tracker, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're almost in the right place. -->. <!-- You'll want to go to https://broadworkbench.atlassian.net/projects/BA/issues and then tell us: -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5792:1510,config,configuration,1510,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5792,1,['config'],['configuration']
Modifiability,"#4492 added a new `${CROMWELL_BUILD_CENTAUR_TEST_ADDITIONAL_PARAMETERS}`. This parameter is not used in most places. (Anywhere at the moment?) The way the variable is wired it currently resolves to `''`. When fed into `cromwell_test.sh` this empty `''` causes [`getopts`](https://github.com/broadinstitute/cromwell/blob/2326dd82cf579af7f50bcf92c59a44171ff26c8c/centaur/test_cromwell.sh#L45) to stop processing arguments. Thus, any `-e excluded`, `-i included`, `-d directory` etc. placed *after* `${CROMWELL_BUILD_CENTAUR_TEST_ADDITIONAL_PARAMETERS}` confusingly stops being parsed. A/C:; - Remove `${CROMWELL_BUILD_CENTAUR_TEST_ADDITIONAL_PARAMETERS}` if it really is unused. _OR_. - Wire in `${CROMWELL_BUILD_CENTAUR_TEST_ADDITIONAL_PARAMETERS}` any-other-way such that when it isn't provided it doesn't accidentally short circuit `getopts`. Example discussion: https://unix.stackexchange.com/questions/278544/how-to-pass-array-to-bash-shell-script",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4915:155,variab,variable,155,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4915,1,['variab'],['variable']
Modifiability,"#4989 continues to evolve the ~~release~~ publish WDL by running the commands via Docker. We should also add a nightly test that checks if the WDL and upcoming publish will still work. The test would be nightly because it would need to write to the ""Releases"" page of a GitHub repo. At the moment there are APIs for [creating repository forks](https://developer.github.com/v3/repos/forks/), but not for deleting / resetting forks. So instead, a single GitHub organization may be created (`broadinstitute-publish-test`?) that will contain a ""standing"" fork of `cromwell` and `homebrew-core`. The test plan is:. Setup:; - Delete all ""Releases"" from `broadinstitute-publish-test/cromwell`; - Force sync branches and tags to `broadinstitute-publish-test/cromwell`; - Force sync branches and tags to `broadinstitute-publish-test/homebrew-core`; - Get the latest version number from `broadinstitute/cromwell` and copy it to a new ""Release"" on `broadinstitute-publish-test/cromwell` (A release with empty text and no artifacts is ok! Just needs to exist w/ the version number.). Run test:; - Run the WDL for a major-release with organization `broadinstitute-publish-test`; - Run the WDL for a minor-release with organization `broadinstitute-publish-test`. Verify:; - Ensure the `broadinstitute-publish-test/cromwell` major-release exists; - Check both the cromwell and womtool artifacts are attached; - For now don't check release notes; - Ensure the `broadinstitute-publish-test/cromwell` minor-release exists; - Check both the cromwell and womtool artifacts are attached; - For now don't check release notes; - Ensure the PR for `broadinstitute-publish-test/homebrew-core` major-release exists; - Ensure the PR for `broadinstitute-publish-test/homebrew-core` minor-release exists. Alternative:; - Two separate nightly jobs:; 1. Run major release on `develop`; 2. Run minor release on `<latest>_hotfix`",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4994:19,evolve,evolve,19,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4994,1,['evolve'],['evolve']
Modifiability,"$2: Failed to evaluate job outputs:; Bad output 'print_nach_nachman_meuman.out': [Attempted 1 time(s)] - IOException: Could not read from s3://nrglab-cromwell-genomics/cromwell-execution/run_multiple_tests/b6b9322c-3929-4b72-9598-45d97dfb858d/call-test_cromwell_on_aws/shard-61/SingleTest.test_cromwell_on_aws/f8ecf673-ed61-4b06-b1d6-c20f7efe986e/call-print_nach_nachman_meuman/print_nach_nachman_meuman-stdout.log: Cannot access file: s3://s3.amazonaws.com/nrglab-cromwell-genomics/cromwell-execution/run_multiple_tests/b6b9322c-3929-4b72-9598-45d97dfb858d/call-test_cromwell_on_aws/shard-61/SingleTest.test_cromwell_on_aws/f8ecf673-ed61-4b06-b1d6-c20f7efe986e/call-print_nach_nachman_meuman/print_nach_nachman_meuman-stdout.log; at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$handleExecutionSuccess$1(StandardAsyncExecutionActor.scala:867); ```. The error occurs when running many sub-workflows within a single wrapping workflow.; The environment is configured correctly, and the test usually passes when running <30 subworkflows. Here are the workflows:. run_multiple_test.wdl; ```; import ""three_task_sequence.wdl"" as SingleTest. workflow run_multiple_tests {; scatter (i in range(30)){; call SingleTest.three_task_sequence{}; }; }; ```. three_task_sequence.wdl; ```; workflow three_task_sequence{; call print_nach. call print_nach_nachman {; input:; previous = print_nach.out; }. call print_nach_nachman_meuman{; input:; previous = print_nach_nachman.out; }; output{; Array[String] out = print_nach_nachman_meuman.out; }; }. task print_nach{; command{; echo ""nach""; }; output{; Array[String] out = read_lines(stdout()); }; runtime {; 	 docker: ""ubuntu:latest""; 	 maxRetries: 3; }; }. task print_nach_nachman{; Array[String] previous. command{; echo ${sep=' ' previous} "" nachman""; }; output{; Array[String] out = read_lines(stdout()); }; runtime {; docker: ""ubuntu:latest""; maxRetries: 3; }; ; }. task print_nach_nachman_meuman{; Array[String] previous. command{; echo ${sep=' ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4687:1306,config,configured,1306,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4687,1,['config'],['configured']
Modifiability,$ParseContext.parse(ConfigParser.java:415); at com.typesafe.config.impl.ConfigParser.parse(ConfigParser.java:25); at com.typesafe.config.impl.Parseable.rawParseValue(Parseable.java:263); at com.typesafe.config.impl.Parseable.rawParseValue(Parseable.java:250); at com.typesafe.config.impl.Parseable.parseValue(Parseable.java:180); at com.typesafe.config.impl.Parseable.parseValue(Parseable.java:174); at com.typesafe.config.impl.Parseable.parse(Parseable.java:301); at com.typesafe.config.ConfigFactory.parseFile(ConfigFactory.java:793); at com.typesafe.config.ConfigFactory.parseApplicationReplacement(ConfigFactory.java:1166); at com.typesafe.config.DefaultConfigLoadingStrategy.parseApplicationConfig(DefaultConfigLoadingStrategy.java:11); at com.typesafe.config.ConfigFactory.defaultApplication(ConfigFactory.java:532); at com.typesafe.config.ConfigFactory$1.call(ConfigFactory.java:264); at com.typesafe.config.ConfigFactory$1.call(ConfigFactory.java:261); at com.typesafe.config.impl.ConfigImpl$LoaderCache.getOrElseUpdate(ConfigImpl.java:66); at com.typesafe.config.impl.ConfigImpl.computeCachedConfig(ConfigImpl.java:93); at com.typesafe.config.ConfigFactory.load(ConfigFactory.java:261); at com.typesafe.config.ConfigFactory.load(ConfigFactory.java:237); at cromwell.languages.util.ImportResolver$HttpResolver$.apply(ImportResolver.scala:237); at womtool.input.WomGraphMaker$.importResolvers$lzycompute$1(WomGraphMaker.scala:28); at womtool.input.WomGraphMaker$.importResolvers$1(WomGraphMaker.scala:27); at womtool.input.WomGraphMaker$.$anonfun$getBundleAndFactory$1(WomGraphMaker.scala:39); at scala.util.Either.flatMap(Either.scala:352); at womtool.input.WomGraphMaker$.getBundleAndFactory(WomGraphMaker.scala:30); at womtool.input.WomGraphMaker$.fromFiles(WomGraphMaker.scala:46); at womtool.validate.Validate$.validate(Validate.scala:26); at womtool.WomtoolMain$.dispatchCommand(WomtoolMain.scala:54); at womtool.WomtoolMain$.runWomtool(WomtoolMain.scala:161); at womtool.WomtoolMain$.del,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7255:2796,Config,ConfigImpl,2796,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7255,1,['Config'],['ConfigImpl']
Modifiability,$ParseContext.parseValue(ConfigParser.java:103); at com.typesafe.config.impl.ConfigParser$ParseContext.parse(ConfigParser.java:415); at com.typesafe.config.impl.ConfigParser.parse(ConfigParser.java:25); at com.typesafe.config.impl.Parseable.rawParseValue(Parseable.java:263); at com.typesafe.config.impl.Parseable.rawParseValue(Parseable.java:250); at com.typesafe.config.impl.Parseable.parseValue(Parseable.java:180); at com.typesafe.config.impl.Parseable.parseValue(Parseable.java:174); at com.typesafe.config.impl.Parseable.parse(Parseable.java:301); at com.typesafe.config.ConfigFactory.parseFile(ConfigFactory.java:793); at com.typesafe.config.ConfigFactory.parseApplicationReplacement(ConfigFactory.java:1166); at com.typesafe.config.DefaultConfigLoadingStrategy.parseApplicationConfig(DefaultConfigLoadingStrategy.java:11); at com.typesafe.config.ConfigFactory.defaultApplication(ConfigFactory.java:532); at com.typesafe.config.ConfigFactory$1.call(ConfigFactory.java:264); at com.typesafe.config.ConfigFactory$1.call(ConfigFactory.java:261); at com.typesafe.config.impl.ConfigImpl$LoaderCache.getOrElseUpdate(ConfigImpl.java:66); at com.typesafe.config.impl.ConfigImpl.computeCachedConfig(ConfigImpl.java:93); at com.typesafe.config.ConfigFactory.load(ConfigFactory.java:261); at com.typesafe.config.ConfigFactory.load(ConfigFactory.java:237); at cromwell.languages.util.ImportResolver$HttpResolver$.apply(ImportResolver.scala:237); at womtool.input.WomGraphMaker$.importResolvers$lzycompute$1(WomGraphMaker.scala:28); at womtool.input.WomGraphMaker$.importResolvers$1(WomGraphMaker.scala:27); at womtool.input.WomGraphMaker$.$anonfun$getBundleAndFactory$1(WomGraphMaker.scala:39); at scala.util.Either.flatMap(Either.scala:352); at womtool.input.WomGraphMaker$.getBundleAndFactory(WomGraphMaker.scala:30); at womtool.input.WomGraphMaker$.fromFiles(WomGraphMaker.scala:46); at womtool.validate.Validate$.validate(Validate.scala:26); at womtool.WomtoolMain$.dispatchCommand(WomtoolMain.scala:54,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7255:2715,config,config,2715,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7255,1,['config'],['config']
Modifiability,"$anonfun$main$1$adapted(App.scala:76); 	at scala.collection.immutable.List.foreach(List.scala:389); 	at scala.App.main(App.scala:76); 	at scala.App.main$(App.scala:74); 	at cromwell.CromwellApp$.main(CromwellApp.scala:3); 	at cromwell.CromwellApp.main(CromwellApp.scala); Caused by: com.typesafe.config.ConfigException$Parse: /data/cephfs/punim0751/spartan.conf: 27: expecting a close parentheses ')' here, not: end of file; 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseError(ConfigDocumentParser.java:201); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseError(ConfigDocumentParser.java:197); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseKey(ConfigDocumentParser.java:279); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseObject(ConfigDocumentParser.java:450); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseValue(ConfigDocumentParser.java:247); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseObject(ConfigDocumentParser.java:458); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parse(ConfigDocumentParser.java:648); 	at com.typesafe.config.impl.ConfigDocumentParser.parse(ConfigDocumentParser.java:14); 	at com.typesafe.config.impl.Parseable.rawParseValue(Parseable.java:260); 	at com.typesafe.config.impl.Parseable.rawParseValue(Parseable.java:248); 	at com.typesafe.config.impl.Parseable.parseValue(Parseable.java:180); 	at com.typesafe.config.impl.Parseable.parseValue(Parseable.java:174); 	at com.typesafe.config.impl.Parseable.parse(Parseable.java:299); 	at com.typesafe.config.ConfigFactory.parseFile(ConfigFactory.java:689); 	at com.typesafe.config.DefaultConfigLoadingStrategy.parseApplicationConfig(DefaultConfigLoadingStrategy.java:51); 	at com.typesafe.config.ConfigFactory.defaultApplication(ConfigFactory.java:473); 	at com.typesafe.config.ConfigFactory$1.call(ConfigFactory.java:259); 	at com.typesafe.config.ConfigFactory$1.call(ConfigFact",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4549:2272,Config,ConfigDocumentParser,2272,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4549,1,['Config'],['ConfigDocumentParser']
Modifiability,$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72); 	at scala.collection.AbstractIterable.foreach(Iterable.scala:54); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.AbstractTraversable.map(Traversable.scala:104); 	at cromwell.backend.impl.sfs.config.DeclarationValidation$.fromDeclarations(DeclarationValidation.scala:17); 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations$lzycompute(ConfigInitializationActor.scala:38); 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations(ConfigInitializationActor.scala:37); 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder$lzycompute(ConfigInitializationActor.scala:47); 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder(ConfigInitializationActor.scala:46); 	at cromwell.backend.sfs.SharedFileSystemInitializationActor.coerceDefaultRuntimeAttributes(SharedFileSystemInitializationActor.scala:90); 	at cromwell.backend.BackendWorkflowInitializationActor$class.validateRuntimeAttributes(BackendWorkflowInitializationActor.scala:138); 	at cromwell.backend.BackendWorkflowInitializationActor$class.initSequence(BackendWorkflowInitializationActor.scala:171); 	at cromwell.backend.sfs.SharedFileSystemInitializationActor.initSequence(SharedFileSystemInitializationActor.scala:37); 	at cromwell.backend.BackendWorkflowInitializationActor$$anonfun$receive$1$$anonfun$applyOrElse$4.apply(BackendWorkflowInitializationActor.scala:163); 	at cromwell.backend.BackendWorkflowInitializationActor$$anonfun$receive$1$$anonfun$applyOrElse$4.apply(BackendWorkflowInitializationActor.scala:163); 	at cromwell.backend.BackendLifecycleActor$class.performActionThenRespond(BackendLifecycle,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1737:2440,config,config,2440,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1737,1,['config'],['config']
Modifiability,$map$1.apply(TraversableLike.scala:234); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72); 	at scala.collection.AbstractIterable.foreach(Iterable.scala:54); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.AbstractTraversable.map(Traversable.scala:104); 	at wdl4s.Task$$anonfun$instantiateCommand$1.apply(Task.scala:107); 	at wdl4s.Task$$anonfun$instantiateCommand$1.apply(Task.scala:107); 	at scala.util.Try$.apply(Try.scala:192); 	at wdl4s.Task.instantiateCommand(Task.scala:107); 	at cromwell.backend.impl.sfs.config.ConfigAsyncJobExecutionActor$class.writeTaskScript(ConfigAsyncJobExecutionActor.scala:55); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.writeTaskScript(ConfigAsyncJobExecutionActor.scala:124); 	at cromwell.backend.impl.sfs.config.ConfigAsyncJobExecutionActor$class.processArgs(ConfigAsyncJobExecutionActor.scala:39); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.processArgs$lzycompute(ConfigAsyncJobExecutionActor.scala:124); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.processArgs(ConfigAsyncJobExecutionActor.scala:124); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor$class.executeScript(SharedFileSystemAsyncJobExecutionActor.scala:220); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.executeScript(ConfigAsyncJobExecutionActor.scala:124); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor$$anonfun$executeOrRecover$2.apply(SharedFileSystemAsyncJobExecutionActor.scala:192); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor$$anonfun$executeOrRecover$2.apply(SharedFileSystemAsyncJobExecutionActor.scala:189); 	at scala.util.Try$.apply(Try.scala:192); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecuti,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1765:2624,Config,ConfigAsyncJobExecutionActor,2624,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1765,1,['Config'],['ConfigAsyncJobExecutionActor']
Modifiability,"${CLEAN_SAMPLE}.bai"", ""/seq/picard_aggregation/${PROJECT}/${CLEAN_SAMPLE}/current/${CLEAN_SAMPLE}.bai""]; 		 File genotypes = ""/seq/references/reference_genotypes/non-hapmap/${PROJECT}/Homo_sapiens_assembly19/${CLEAN_SAMPLE}.vcf"". 		 call Fingerprint {; 		 	input:; 		 		PICARD=PICARD,; 		 		input_bam=bams[0],; 		 		input_bam_index=indexes[0],; 			 haplotype_database_file=haplotype_database_file,; 		 	 	genotypes=genotypes,; 				sample=SAMPLE,; 		 }. 		 call Fingerprint as FingerprintOther {; 		 	input:; 		 		PICARD=PICARD,; 		 		input_bam=bams[1],; 		 		input_bam_index=indexes[1],; 			 haplotype_database_file=haplotype_database_file,; 		 	 	genotypes=genotypes,; 				sample=COMPARE_SAMPLE,; 		 }. 		 call CrossCheckFingerprints {; 	 		input:; 	 			PICARD=PICARD,; 	 			input_bams=bams,; 	 			input_bam_indexes=indexes,; 	 			haplotype_database_file=haplotype_database_file,; 	 			metrics_filename=CLEAN_SAMPLE+""_and_""+CLEAN_COMPARE_SAMPLE+"".crosscheck""; 		 }. 		 output {; 		 	Fingerprint.*; 		 	FingerprintOther.*; 		 	CrossCheckFingerprints.*; 		 }; 	}; }; ```. And a json to go with it:; ```; {; ""FingerprintSamples.PICARD"": ""/seq/software/picard/current/bin/picard.jar"",; ""FingerprintSamples.haplotype_database_file"": ""/seq/references/Homo_sapiens_assembly19/v1/Homo_sapiens_assembly19.haplotype_database.txt"",; ""FingerprintSamples.SamplesTSV"": ""sampleSetTest.txt""; }; ```. This is sampleSetTest.txt: ; [SampleSetTest.txt](https://github.com/broadinstitute/cromwell/files/694627/SampleSetTest.txt). All of the individual tasks seem to work, but when it begins the scatter it fails to start most of the tasks. I don't see a pattern to which it seems to start. It then reports QueuedInCromwell on the started tasks, even though they seem to have finished with output. This fails **both** in SGE and Local backends. There is a suspicion that this might be due to declaring variables inside of the scatter? I'm going to try extracting all variable declaration into a task to see if that works.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1826:4073,variab,variables,4073,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1826,2,['variab'],"['variable', 'variables']"
Modifiability,"'s been a regression, or it's slightly different somehow. ---. @kbergin commented on [Wed Mar 30 2016](https://github.com/broadinstitute/wdltool/issues/8#issuecomment-203469521). I also observed something similar. One of my tasks was failing because I had an input designated as an input in the call, and in the task, but it actually wasn't an input for the workflow nor in the json. I feel like validate or some error handling should have caught that? Instead it just didn't make it through JES and said it 'failed to localize inputs'. But Brad pointed out that I think I used swagger to validate not wdltools, so this could be entirely my fault, as he said those may not be in sync / up to date wise? I wasn't aware. Anyways here was my situation in case it's at all helpful, the missing var is **File gender_mask_bed**:. ```; workflow GenomeStripBamWorkflow {; String sample_name; String bam_name; String analysis_directory; File bam; File ref_fasta; File ref_fasta_index; File ref_dict; File ref_genome_sizes; File ploidy_map; File copy_number_mask; File copy_number_mask_index; File read_depth_mask; File ref_profile; File genome_mask; File genome_mask_index; File configs. ##This is the call that had the issue, there are some before it that it depends on, ; ##but not for the missing input (gender_mask_bed); call CallSampleGender as CallSampleGender {; input:; analysis_directory = analysis_directory,; ref_fasta = ref_fasta,; ref_fasta_index = ref_fasta_index,; ref_dict = ref_dict,; genome_mask = genome_mask,; genome_mask_index = genome_mask_index,; ploidy_map = ploidy_map,; header_bam = ExtractBamSubset.header_bam,; header_bam_index = IndexHeaders.header_index,; gender_mask_bed = gender_mask_bed,; read_count_index = Index.read_count_index; }; }; ```. And here's the task, which does have the missing variable **File gender_mask_bed**. ```; task CallSampleGender {; String analysis_directory; File ref_fasta; File ref_fasta_index; File ref_dict; File genome_mask; File genome_mask_index",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2874:3686,config,configs,3686,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2874,1,['config'],['configs']
Modifiability,"()); 	}; }; ```; error log; ```; $ java -jar /users/leepc12/code/cromwell/./target/scala-2.12/cromwell-31-d716fd2-SNAP.jar run test_conditionals_in_cromwell-30.wdl; Picked up _JAVA_OPTIONS: -Xms256M -Xmx1024M -XX:ParallelGCThreads=1; [2017-12-05 20:11:15,13] [info] Running with database db.url = jdbc:hsqldb:mem:7e58cfd2-b9b6-47f9-bda1-6fe045e7a665;shutdown=false;hsqldb.tx=mvcc; [2017-12-05 20:11:21,83] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2017-12-05 20:11:21,84] [info] [RenameWorkflowOptionsInMetadata] 100%; [2017-12-05 20:11:22,02] [info] Running with database db.url = jdbc:hsqldb:mem:e02f9206-cb15-468a-929a-82676a83a9b8;shutdown=false;hsqldb.tx=mvcc; [2017-12-05 20:11:22,47] [info] Slf4jLogger started; [2017-12-05 20:11:22,67] [info] Metadata summary refreshing every 2 seconds.; [2017-12-05 20:11:22,68] [info] Starting health monitor with the following checks: DockerHub, Engine Database; [2017-12-05 20:11:22,69] [info] WriteMetadataActor configured to write to the database with batch size 200 and flush rate 5 seconds.; [2017-12-05 20:11:22,71] [info] CallCacheWriteActor configured to write to the database with batch size 100 and flush rate 3 seconds.; [2017-12-05 20:11:23,78] [info] SingleWorkflowRunnerActor: Submitting workflow; [2017-12-05 20:11:23,82] [info] Workflow 159210e6-fa6a-4a99-b386-5931ae245324 submitted.; [2017-12-05 20:11:23,82] [info] SingleWorkflowRunnerActor: Workflow submitted 159210e6-fa6a-4a99-b386-5931ae245324; [2017-12-05 20:11:23,82] [info] 1 new workflows fetched; [2017-12-05 20:11:23,82] [info] WorkflowManagerActor Starting workflow 159210e6-fa6a-4a99-b386-5931ae245324; [2017-12-05 20:11:23,83] [info] WorkflowManagerActor Successfully started WorkflowActor-159210e6-fa6a-4a99-b386-5931ae245324; [2017-12-05 20:11:23,83] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2017-12-05 20:11:24,82] [error] WorkflowManagerActor Workflow 159210e6-fa6a-4a9",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3007:1680,config,configured,1680,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3007,1,['config'],['configured']
Modifiability,(BlockContext.scala:72); 	at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:90); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:39); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(AbstractDispatcher.scala:415); 	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: java.lang.IllegalArgumentException; 	at sun.nio.fs.UnixPath.subpath(UnixPath.java:346); 	at sun.nio.fs.UnixPath.subpath(UnixPath.java:43); 	at cromwell.backend.io.JobPathsWithDocker.toDockerPath(JobPathsWithDocker.scala:35); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor$class.toUnixPath(SharedFileSystemAsyncJobExecutionActor.scala:107); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.toUnixPath(ConfigAsyncJobExecutionActor.scala:113); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor$$anonfun$commandLineValueMapper$1.apply(SharedFileSystemAsyncJobExecutionActor.scala:127); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor$$anonfun$commandLineValueMapper$1.apply(SharedFileSystemAsyncJobExecutionActor.scala:127); 	at wdl4s.command.ParameterCommandPart.instantiate(ParameterCommandPart.scala:55); 	at wdl4s.Task$$anonfun$instantiateCommand$1$$anonfun$apply$2.apply(Task.scala:108); 	at wdl4s.Task$$anonfun$instantiateCommand$1$$anonfun$apply$2.apply(Task.scala:108); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.IterableLike$clas,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1944:8437,config,config,8437,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1944,1,['config'],['config']
Modifiability,(ChannelInputStream.java:65); at sun.nio.ch.ChannelInputStream.read(ChannelInputStream.java:109); at sun.nio.ch.ChannelInputStream.read(ChannelInputStream.java:103); - locked <0x00000006c54b2ec8> (a sun.nio.ch.ChannelInputStream); at org.apache.commons.codec.digest.DigestUtils.updateDigest(DigestUtils.java:798); at org.apache.commons.codec.digest.DigestUtils.digest(DigestUtils.java:50); at org.apache.commons.codec.digest.DigestUtils.md5(DigestUtils.java:274); at org.apache.commons.codec.digest.DigestUtils.md5Hex(DigestUtils.java:310); at cromwell.backend.impl.sfs.config.HashFileStrategy$$anonfun$hash$3.apply(ConfigHashingStrategy.scala:70); at cromwell.backend.impl.sfs.config.HashFileStrategy$$anonfun$hash$3.apply(ConfigHashingStrategy.scala:70); at cromwell.util.TryWithResource$$anonfun$tryWithResource$1.apply(TryWithResource.scala:16); at scala.util.Try$.apply(Try.scala:192); at cromwell.util.TryWithResource$.tryWithResource(TryWithResource.scala:10); at cromwell.backend.impl.sfs.config.HashFileStrategy.hash(ConfigHashingStrategy.scala:70); at cromwell.backend.impl.sfs.config.ConfigHashingStrategy.getHash(ConfigHashingStrategy.scala:47); at cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory$$anonfun$fileHashingFunction$1.apply(ConfigBackendLifecycleActorFactory.scala:45); at cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory$$anonfun$fileHashingFunction$1.apply(ConfigBackendLifecycleActorFactory.scala:45); at cromwell.backend.callcaching.FileHashingActor$$anonfun$receive$1$$anonfun$1.apply(FileHashingActor.scala:21); at cromwell.backend.callcaching.FileHashingActor$$anonfun$receive$1$$anonfun$1.apply(FileHashingActor.scala:21); at scala.Option.map(Option.scala:146); at cromwell.backend.callcaching.FileHashingActor$$anonfun$receive$1.applyOrElse(FileHashingActor.scala:21); at akka.actor.Actor$class.aroundReceive(Actor.scala:484); at cromwell.backend.callcaching.FileHashingActor.aroundReceive(FileHashingActor.scala:16); at akka.actor,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1597:1768,config,config,1768,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1597,1,['config'],['config']
Modifiability,"(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); ```; I also tried on another computer and another GCP project just to verify that it is not a cache problem. I don't know what is wrong. Seems like the service account has a problem, but I did everything the same way as when it worked. **Some detailed information:**. I have tried Cromwell 31.1 and 31. I start Cromwell using this command; `java -Dconfig.file=google.conf -jar cromwell-31.jar server`. **google.conf**; (I have changed the actual project name to generic ""project""); ```; include required(classpath(""application"")). google {. application-name = ""cromwell"". auths = [; {; name = ""application-default""; scheme = ""application_default""; }; ]; }. engine {; filesystems {; gcs {; auth = ""application-default""; project = ""project-test1""; }; }; }. backend {; default = ""JES""; providers {; JES {; actor-factory = ""cromwell.backend.impl.jes.JesBackendLifecycleActorFactory""; config {; // Google project; project = ""project-test1"". // Base bucket for workflow executions; root = ""gs://project-test1/cromwell-execution"". // Polling for completion backs-off gradually for slower-running jobs.; // This is the maximum polling interval (in seconds):; maximum-polling-interval = 600. // Optional Dockerhub Credentials. Can be used to access private docker images.; dockerhub {; // account = """"; // token = """"; }. genomics {; // A reference to an auth defined in the `google` stanza at the top. This auth is used to create; // Pipelines and manipulate auth JSONs.; auth = ""application-default""; // Endpoint for APIs, no reason to change this unless directed by Google.; endpoint-url = ""https://genomics.googleapis.com/""; // This allows you to use an alternative service account to launch jobs, by default uses default service account; compute-service-account = ""default""; }. filesystems {; gcs {; // A reference to a potentially different auth for manipulating files via engine functions.; aut",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3690:4392,config,config,4392,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3690,1,['config'],['config']
Modifiability,"(TrampolineEC.scala:93); at cats.effect.internals.Trampoline.execute(Trampoline.scala:43); at cats.effect.internals.TrampolineEC.execute(TrampolineEC.scala:44); at cats.effect.internals.Callback$AsyncIdempotentCallback.apply(Callback.scala:133); at cats.effect.internals.Callback$AsyncIdempotentCallback.apply(Callback.scala:120); at cats.effect.Async$$anon$1.run(Async.scala:275); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:745); [2019-02-11 10:13:27,63] [info] Message [cromwell.docker.DockerInfoActor$DockerInfoFailedResponse] from Actor[akka://cromwell-system/user/HealthMonitorDockerHashActor#-638598959] to Actor[akka://cromwell-system/deadLetters] was not delivered. [1] dead letters encountered, no more dead letters will be logged. If this is not an expected behavior, then [Actor[akka://cromwell-system/deadLetters]] may have terminated unexpectedly, This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2019-02-11 10:13:27,65] [info] WorkflowExecutionActor-52999e15-953f-44d6-aaae-1774c74d2910 [52999e15]: Workflow test1 complete. Final Outputs:; {; ""test1.hello.out"": ""/spin1/users/wresch/test_data/cromwell/test1/cromwell-executions/test1/52999e15-953f-44d6-aaae-1774c74d2910/call-hello/execution/World.txt""; }; [2019-02-11 10:13:27,69] [info] WorkflowManagerActor WorkflowActor-52999e15-953f-44d6-aaae-1774c74d2910 is in a terminal state: WorkflowSucceededState; [2019-02-11 10:13:35,97] [info] SingleWorkflowRunnerActor workflow finished with status 'Succeeded'.; {; ""outputs"": {; ""test1.hello.out"": ""/spin1/users/wresch/test_data/cromwell/test1/cromwell-executions/test1/52999e15-953f-44d6-aaae-1774c74d2910/call-hello/execution/World.txt""; },; ""id"": ""52999e15-953f-44d6-aaae-1774c74d2910""; }; [2019-02-11 10:13:36,30] [info] Workflow",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4626:14272,config,configuration,14272,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4626,1,['config'],['configuration']
Modifiability,"(cromwell version 35-5f86a05-SNAP). call caching version from previous run . <!--; Hi! Thanks for taking the time to report feedback. Before posting an issue here, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're in the right place. -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4330:786,config,configuration,786,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4330,1,['config'],['configuration']
Modifiability,"), however, if test.wdl is located in the root directory it will be found (`/test.wdl`).; ```; version 1.0. import ""test.wdl"" as test. workflow test2 {; call test.sayHello as blah {; input:; name=""Grog""; }. output {; String out = blah.blah; }; }; ```; test.wdl looks like this:; ```; version 1.0. task sayHello {; input {; String name; }. command {; echo Hello, ~{name}; }. output {; String blah = read_string(stdout()); }; }; ```; The following is mentioned in the printed output:; ```; Failed to import 'test.wdl' (reason 1 of 2): Failed to resolve 'test.wdl' using resolver: 'relative to directory / (without escaping None)' (reason 1 of 1): Import file not found: test.wdl; Failed to import 'test.wdl' (reason 2 of 2): Failed to resolve 'test.wdl' using resolver: 'http importer' (reason 1 of 1): Cannot import 'test.wdl' relative to nothing; ```; Looking at the cromwell source code I suspect the problem lies with the directory path being given to `DirectoryResolver` in `localFilesystemResolvers` ([this line](https://github.com/broadinstitute/cromwell/blob/develop/engine/src/main/scala/cromwell/engine/workflow/lifecycle/materialization/MaterializeWorkflowDescriptorActor.scala#L271)). <!--; Hi! Thanks for taking the time to report feedback. Before posting an issue here, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're in the right place. -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3986:2330,config,configuration,2330,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3986,1,['config'],['configuration']
Modifiability,); 	at scala.collection.AbstractIterable.foreach(Iterable.scala:54); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.AbstractTraversable.map(Traversable.scala:104); 	at wdl4s.Task$$anonfun$instantiateCommand$1.apply(Task.scala:107); 	at wdl4s.Task$$anonfun$instantiateCommand$1.apply(Task.scala:107); 	at scala.util.Try$.apply(Try.scala:192); 	at wdl4s.Task.instantiateCommand(Task.scala:107); 	at cromwell.backend.impl.sfs.config.ConfigAsyncJobExecutionActor$class.writeTaskScript(ConfigAsyncJobExecutionActor.scala:55); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.writeTaskScript(ConfigAsyncJobExecutionActor.scala:124); 	at cromwell.backend.impl.sfs.config.ConfigAsyncJobExecutionActor$class.processArgs(ConfigAsyncJobExecutionActor.scala:39); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.processArgs$lzycompute(ConfigAsyncJobExecutionActor.scala:124); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.processArgs(ConfigAsyncJobExecutionActor.scala:124); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor$class.executeScript(SharedFileSystemAsyncJobExecutionActor.scala:220); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.executeScript(ConfigAsyncJobExecutionActor.scala:124); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor$$anonfun$executeOrRecover$2.apply(SharedFileSystemAsyncJobExecutionActor.scala:192); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor$$anonfun$executeOrRecover$2.apply(SharedFileSystemAsyncJobExecutionActor.scala:189); 	at scala.util.Try$.apply(Try.scala:192); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor$class.executeOrRecover(SharedFileSystemAsyncJobExecutionActor.scala:188); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.executeOrRecover(ConfigAsyncJobExecutionActor.scala:124); 	at cromwell.backend.async.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1765:2881,config,config,2881,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1765,1,['config'],['config']
Modifiability,); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72); 	at scala.collection.AbstractIterable.foreach(Iterable.scala:54); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.AbstractTraversable.map(Traversable.scala:104); 	at wdl4s.Task$$anonfun$instantiateCommand$1.apply(Task.scala:107); 	at wdl4s.Task$$anonfun$instantiateCommand$1.apply(Task.scala:107); 	at scala.util.Try$.apply(Try.scala:192); 	at wdl4s.Task.instantiateCommand(Task.scala:107); 	at cromwell.backend.impl.sfs.config.ConfigAsyncJobExecutionActor$class.writeTaskScript(ConfigAsyncJobExecutionActor.scala:55); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.writeTaskScript(ConfigAsyncJobExecutionActor.scala:124); 	at cromwell.backend.impl.sfs.config.ConfigAsyncJobExecutionActor$class.processArgs(ConfigAsyncJobExecutionActor.scala:39); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.processArgs$lzycompute(ConfigAsyncJobExecutionActor.scala:124); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.processArgs(ConfigAsyncJobExecutionActor.scala:124); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor$class.executeScript(SharedFileSystemAsyncJobExecutionActor.scala:220); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.executeScript(ConfigAsyncJobExecutionActor.scala:124); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor$$anonfun$executeOrRecover$2.apply(SharedFileSystemAsyncJobExecutionActor.scala:192); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor$$anonfun$executeOrRecover$2.apply(SharedFileSystemAsyncJobExecutionActor.scala:189); 	at scala.util.Try$.apply(Try.scala:192); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor$class.executeOrRecover(SharedFileSystemAsyncJobExecutionActor.scala:188); 	at cromwell.backend.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1765:2741,config,config,2741,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1765,1,['config'],['config']
Modifiability,); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72); 	at scala.collection.AbstractIterable.foreach(Iterable.scala:54); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.AbstractTraversable.map(Traversable.scala:104); 	at wdl4s.Task$$anonfun$instantiateCommand$1.apply(Task.scala:107); 	at wdl4s.Task$$anonfun$instantiateCommand$1.apply(Task.scala:107); 	at scala.util.Try$.apply(Try.scala:192); 	at wdl4s.Task.instantiateCommand(Task.scala:107); 	at cromwell.backend.impl.sfs.config.ConfigAsyncJobExecutionActor$class.writeTaskScript(ConfigAsyncJobExecutionActor.scala:55); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.writeTaskScript(ConfigAsyncJobExecutionActor.scala:124); 	at cromwell.backend.impl.sfs.config.ConfigAsyncJobExecutionActor$class.processArgs(ConfigAsyncJobExecutionActor.scala:39); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.processArgs$lzycompute(ConfigAsyncJobExecutionActor.scala:124); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.processArgs(ConfigAsyncJobExecutionActor.scala:124); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor$class.executeScript(SharedFileSystemAsyncJobExecutionActor.scala:220); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.executeScript(ConfigAsyncJobExecutionActor.scala:124); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor$$anonfun$executeOrRecover$2.apply(SharedFileSystemAsyncJobExecutionActor.scala:192); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor$$anonfun$executeOrRecover$2.apply(SharedFileSystemAsyncJobExecutionActor.scala:189); 	at scala.util.Try$.apply(Try.scala:192); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor$class.executeOrRecover(SharedF,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1765:2671,Config,ConfigAsyncJobExecutionActor,2671,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1765,1,['Config'],['ConfigAsyncJobExecutionActor']
Modifiability,"); Caused by: com.typesafe.config.ConfigException$Parse: /data/cephfs/punim0751/spartan.conf: 27: expecting a close parentheses ')' here, not: end of file; 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseError(ConfigDocumentParser.java:201); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseError(ConfigDocumentParser.java:197); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseKey(ConfigDocumentParser.java:279); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseObject(ConfigDocumentParser.java:450); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseValue(ConfigDocumentParser.java:247); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseObject(ConfigDocumentParser.java:458); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parse(ConfigDocumentParser.java:648); 	at com.typesafe.config.impl.ConfigDocumentParser.parse(ConfigDocumentParser.java:14); 	at com.typesafe.config.impl.Parseable.rawParseValue(Parseable.java:260); 	at com.typesafe.config.impl.Parseable.rawParseValue(Parseable.java:248); 	at com.typesafe.config.impl.Parseable.parseValue(Parseable.java:180); 	at com.typesafe.config.impl.Parseable.parseValue(Parseable.java:174); 	at com.typesafe.config.impl.Parseable.parse(Parseable.java:299); 	at com.typesafe.config.ConfigFactory.parseFile(ConfigFactory.java:689); 	at com.typesafe.config.DefaultConfigLoadingStrategy.parseApplicationConfig(DefaultConfigLoadingStrategy.java:51); 	at com.typesafe.config.ConfigFactory.defaultApplication(ConfigFactory.java:473); 	at com.typesafe.config.ConfigFactory$1.call(ConfigFactory.java:259); 	at com.typesafe.config.ConfigFactory$1.call(ConfigFactory.java:256); 	at com.typesafe.config.impl.ConfigImpl$LoaderCache.getOrElseUpdate(ConfigImpl.java:65); 	at com.typesafe.config.impl.ConfigImpl.computeCachedConfig(ConfigImpl.java:92); 	at com.typesafe.config.ConfigFactory.load(ConfigFactory.java:256); 	at com.typesafe.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4549:2555,config,config,2555,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4549,1,['config'],['config']
Modifiability,"); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: common.exception.AggregatedMessageException: Error(s):; Could not evaluate expression: ""-l h_vmem="" + memory + ""G"": Cannot perform operation: -l h_vmem= + WomLong(4); at common.validation.Validation$ValidationTry$.toTry$extension1(Validation.scala:77); at common.validation.Validation$ValidationTry$.toTry$extension0(Validation.scala:73); at cromwell.backend.impl.sfs.config.ConfigAsyncJobExecutionActor.writeTaskScript(ConfigAsyncJobExecutionActor.scala:107); at cromwell.backend.impl.sfs.config.ConfigAsyncJobExecutionActor.writeTaskScript$(ConfigAsyncJobExecutionActor.scala:55); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.writeTaskScript(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.impl.sfs.config.ConfigAsyncJobExecutionActor.processArgs(ConfigAsyncJobExecutionActor.scala:43); at cromwell.backend.impl.sfs.config.ConfigAsyncJobExecutionActor.processArgs$(ConfigAsyncJobExecutionActor.scala:39); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.processArgs$lzycompute(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.processArgs(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.makeProcessRunner(SharedFileSystemAsyncJobExecutionActor.scala:174); at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.makeProcessRunner$(SharedFileSystemAsyncJobExecutionActor.scala:171); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.makeProcessRunner(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.$anonfun$execute$2(SharedFileSystemAsyncJobExecutionActor.scala:145);",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4659:2407,config,config,2407,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4659,1,['config'],['config']
Modifiability,); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.writeTaskScript(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.impl.sfs.config.ConfigAsyncJobExecutionActor.processArgs(ConfigAsyncJobExecutionActor.scala:43); at cromwell.backend.impl.sfs.config.ConfigAsyncJobExecutionActor.processArgs$(ConfigAsyncJobExecutionActor.scala:39); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.processArgs$lzycompute(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.processArgs(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.makeProcessRunner(SharedFileSystemAsyncJobExecutionActor.scala:174); at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.makeProcessRunner$(SharedFileSystemAsyncJobExecutionActor.scala:171); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.makeProcessRunner(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.$anonfun$execute$2(SharedFileSystemAsyncJobExecutionActor.scala:145); at scala.util.Either.fold(Either.scala:188); at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.execute(SharedFileSystemAsyncJobExecutionActor.scala:144); at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.execute$(SharedFileSystemAsyncJobExecutionActor.scala:139); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.execute(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$executeAsync$1(StandardAsyncExecutionActor.scala:637); at scala.util.Try$.apply(Try.scala:209); at cromwell.backend.standard.StandardAsyncExecutionActor.executeAsync(StandardAsyncExecutionActor.scala:637); at cromwell.backend.standard.StandardAsyncExecutionActor.executeAsync$(StandardAsyncExecutionActor.scala:637); at cromwell.backend.impl.sfs.config,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4659:3238,Config,ConfigAsyncJobExecutionActor,3238,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4659,1,['Config'],['ConfigAsyncJobExecutionActor']
Modifiability,); at org.asynchttpclient.resolver.RequestHostnameResolver.resolve(RequestHostnameResolver.java:50); at org.asynchttpclient.netty.request.NettyRequestSender.resolveAddresses(NettyRequestSender.java:355); at org.asynchttpclient.netty.request.NettyRequestSender.sendRequestWithNewChannel(NettyRequestSender.java:298); at org.asynchttpclient.netty.request.NettyRequestSender.sendRequestWithCertainForceConnect(NettyRequestSender.java:140); at org.asynchttpclient.netty.request.NettyRequestSender.sendRequest(NettyRequestSender.java:111); at org.asynchttpclient.DefaultAsyncHttpClient.execute(DefaultAsyncHttpClient.java:240); at org.asynchttpclient.DefaultAsyncHttpClient.executeRequest(DefaultAsyncHttpClient.java:209); at org.asynchttpclient.BoundRequestBuilder.execute(BoundRequestBuilder.java:35); at com.softwaremill.sttp.asynchttpclient.AsyncHttpClientBackend.$anonfun$send$1(AsyncHttpClientBackend.scala:53); at com.softwaremill.sttp.asynchttpclient.AsyncHttpClientBackend.$anonfun$send$1$adapted(AsyncHttpClientBackend.scala:42); at cats.effect.IO$.$anonfun$async$1(IO.scala:1042); at cats.effect.IO$.$anonfun$async$1$adapted(IO.scala:1040); at cats.effect.internals.IORunLoop$RestartCallback.start(IORunLoop.scala:329); at cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:118); at cats.effect.internals.IORunLoop$.start(IORunLoop.scala:35); at cats.effect.IO.unsafeRunAsync(IO.scala:269); at cats.effect.IO.unsafeToFuture(IO.scala:341); at cromwell.languages.util.ImportResolver$.$anonfun$httpResolverWithHeaders$1(ImportResolver.scala:92); at common.transforms.package$CheckedAtoB$.$anonfun$firstSuccess$2(package.scala:25); at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:122); at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:118); at scala.collection.immutable.List.foldLeft(List.scala:86); at common.transforms.package$CheckedAtoB$.$anonfun$firstSuccess$1(package.scala:22); at cats.data.Kleisli.$anonf,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3977:2244,adapt,adapted,2244,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3977,1,['adapt'],['adapted']
Modifiability,"* JES; * cromwell-30.jar. I have two `write_tsv()` calls in the command block. This code works fine locally. ```; task trim_adapter { # trim adapters and merge trimmed fastqs; 	# parameters from workflow; 	Array[Array[File]] fastqs 		# [merge_id][end_id]; 	Array[Array[String]] adapters 	# [merge_id][end_id]; 	Boolean paired_end; 	# mandatory; 	Boolean auto_detect_adapter		# automatically detect/trim adapters; 	# optional; 	Int? min_trim_len 		# minimum trim length for cutadapt -m; 	Float? err_rate			# Maximum allowed adapter error rate ; 							# for cutadapt -e	; 	# resource; 	Int? cpu; 	Int? mem_mb; 	Int? time_hr; 	String? disks. 	command {; 		python $(which encode_trim_adapter.py) \; 			${write_tsv(fastqs)} \; 			${""--adapters "" + write_tsv(adapters)} \; 			${if paired_end then ""--paired-end"" else """"} \; 			${if auto_detect_adapter then ""--auto-detect-adapter"" else """"} \; 			${""--min-trim-len "" + min_trim_len} \; 			${""--err-rate "" + err_rate} \; 			${""--nth "" + select_first([cpu,4])}; 	}; 	output {; 		# WDL glob() globs in an alphabetical order; 		# so R1 and R2 can be switched, which results in an; 		# unexpected behavior of a workflow; 		# so we prepend merge_fastqs_'end'_ (R1 or R2); 		# to the basename of original filename; 		# this prefix will be later stripped in bowtie2 task; 		Array[File] trimmed_merged_fastqs = glob(""merge_fastqs_R?_*.fastq.gz""); 	}; 	runtime {; 		cpu : select_first([cpu,2]); 		memory : ""${select_first([mem_mb,'10000'])} MB""; 		time : select_first([time_hr,24]); 		disks : select_first([disks,""local-disk 100 HDD""]); 	}; }; ```; with Google JES backend, second call of write_tsv() doesn't seem to correctly pass temporary tsv file into a docker container. `${write_tsv()}` works fine.; `${""some string "" + write_tsv()}` does not work. It still has URI prefix `gs://`. ```; [2017-12-07 13:37:45,35] [info] JesAsyncBackendJobExecutionActor [17f0658fatac.trim_adapter:1:1]: python $(which encode_trim_adapter.py) \; /cromwell_root/atac-seq-pipeline-w",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3032:141,adapt,adapters,141,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3032,4,['adapt'],"['adapter', 'adapters']"
Modifiability,"* Upgrade from deprecated `trusty` dist to `xenial` (needed to get psutil 5.6.4 working); * Switch from Oracle JDK to OpenJDK (needed for the change above, xenial only supports Java 9 to 14); * Fix mistakes and deprecations in `mkdocs.yml` since the configuration of the `xenial` image treats `mkdocs` warnings as errors which fail the `checkPublish` build; * Don't explicitly start `munged` for the SLURM build since it seems to already be started in `xenial`. The `munged` bit would especially benefit from @kshakir 's input, I'm pretty sure that could be done better.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5262:250,config,configuration,250,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5262,1,['config'],['configuration']
Modifiability,* added support for a FileRoller logback configuration; * made both logback.xml files in repo the same; * rearrange to single logback.xml,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1710:41,config,configuration,41,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1710,1,['config'],['configuration']
Modifiability,"**Backend**: PAPIv2; **Cromwell version**: 38-6725312. When a task output is referenced by a variable, `read_*` functions fail to delocalize a file if the file name is referenced by a variable, instead of as a literal string. This might be related to https://github.com/broadinstitute/cromwell/issues/3698. Example:; ```wdl; version 1.0. workflow TestFailureDelocalize {; call Test. output {; String test = Test.out; }; }. task Test {; String testFile = ""test.txt"". command {; echo OK > ~{testFile}; }. output {; String out = read_string(testFile); }. runtime {; docker: ""debian:stable-slim""; }; }; ```. If I change the syntax to; ```wdl; String out = read_string(""~{testFile}""); ```; then the file is delocalized successfully.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4901:93,variab,variable,93,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4901,2,['variab'],['variable']
Modifiability,"**Backend:** AWS. **Workflow:** https://github.com/FredHutch/reproducible-workflows/blob/master/WDL/unpaired-panel-consensus-variants-human/broad-containers-workflow.wdl; **First input json:** https://github.com/FredHutch/reproducible-workflows/blob/master/WDL/unpaired-panel-consensus-variants-human/broad-containers-parameters.json; **Second input json is LIKE this one, but refers to a batch of 100 input datasets:** https://github.com/FredHutch/reproducible-workflows/blob/master/WDL/unpaired-panel-consensus-variants-human/broad-containers-batchofOne.json. **Config:** ; Installed the cromwell version in PR #4790. . **Error:**; ```; ""callCaching"": {; ""allowResultReuse"": true,; ""hit"": false,; ""result"": ""Cache Miss"",; ""effectiveCallCachingMode"": ""ReadAndWriteCache"",; ""hitFailures"": [; {; ""dd860da7-bed8-4e70-812c-227f4e6fead8:Panel_BWA_GATK4_Samtools_Var_Annotate_Split.SamToFastq:0"": [; {; ""causedBy"": [; {; ""causedBy"": [],; ""message"": ""The specified copy source is larger than the maximum allowable size for a copy source: 5368709120 (Service: S3, Status Code: 400, Request ID: AE0D7E6A63C706E5)""; }; ],; ""message"": ""[Attempted 1 time(s)] - S3Exception: The specified copy source is larger than the maximum allowable size for a copy source: 5368709120 (Service: S3, Status Code: 400, Request ID: AE0D7E6A63C706E5)""; }; ```. This version of Cromwell does seem to successfully access and copy a cached file from a previous workflow at least on the first task in a shard. This workflow is essentially a batch in which each row of a batch file is passed to a shard and then the tasks run independently on each input dataset and they never gather. However, when the files get larger than the single test data set it seems it can't get to the previous file in order to determine if there's a hit.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4805:564,Config,Config,564,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4805,1,['Config'],['Config']
Modifiability,"**Edit:** I've encountered more issues here, so putting this on pause. ---. **Short version:** rather than an InstrumentationPath being a `NonEmptyList[String]`, it is now [a more complex type](https://github.com/broadinstitute/cromwell/blob/DDO-1728-handle-metric-variance/services/src/main/scala/cromwell/services/instrumentation/CromwellInstrumentation.scala#L48). Everything else is refactoring to match that change. **Long version:**. There's basically two competing models for metric names--""lots of metrics, no labels"" and ""smaller a number of metrics, with labels for variation"". Statsd uses the first, and Prometheus (and Stackdriver too, ideally) use the second. By way of example:. ```; api.response.count.200; ```. versus. ```; api_response_count{code=""200""}; ```. This boils down to how the different systems query metrics. In a StatsD world, you can have a query like `api.response.count.*`, but that's not possible for Prometheus/Stackdriver--the actual metric name needs to be fully static, and you conceptually do `api_response_count{code=""*""}`. Cromwell metric names right now are this:. ```scala; type InstrumentationPath = NonEmptyList[String]. CromwellBucket(prefix: List[String], path: InstrumentationPath); ```. Metric names are guaranteed to not be empty by the path. The path is what is actually assembled in code and passed around, and prefix (or an empty list) is added at the outer edge--most of Cromwell treats the `NonEmptyList[String]` as the metric name. When the metrics are actually sent to StatsD, the strings are joined with periods and sent off. I spent several days trying to figure out a way to reliably parse labels out from these names, and I couldn't figure it out. There's two key pieces of info known at the time the `NonEmptyList[String]` is assembled that are not recorded:; - When a particular string being added to the list is expected to vary frequently (and thus needs to be a label); - What that string means (labels are key-value pairs and we're usu",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6681:387,refactor,refactoring,387,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6681,1,['refactor'],['refactoring']
Modifiability,"**WORKAROUND:** Explicitly `mkdir` (as necessary) and `export` a new `$TMPDIR` at the top of your task command, for example `export TMPDIR=/tmp` should work. Setting the `TMPDIR` environment variable to a long path will cause an error in Python `mulitprocessing` library. ```; Process SyncManager-1: ; Traceback (most recent call last):; File ""/home/cdompierre/gdc-client/bin/build/gdc-client/out00-PYZ.pyz/multiprocessing.process"", line 258, in _bootstrap; File ""/home/cdompierre/gdc-client/bin/build/gdc-client/out00-PYZ.pyz/multiprocessing.process"", line 114, in run; File ""/home/cdompierre/gdc-client/bin/build/gdc-client/out00-PYZ.pyz/multiprocessing.managers"", line 550, in _run_server; File ""/home/cdompierre/gdc-client/bin/build/gdc-client/out00-PYZ.pyz/multiprocessing.managers"", line 162, in __init__; File ""/home/cdompierre/gdc-client/bin/build/gdc-client/out00-PYZ.pyz/multiprocessing.connection"", line 132, in __init__; File ""/home/cdompierre/gdc-client/bin/build/gdc-client/out00-PYZ.pyz/multiprocessing.connection"", line 256, in __init__; File ""/home/cdompierre/gdc-client/bin/build/gdc-client/out00-PYZ.pyz/socket"", line 224, in meth; error: AF_UNIX path too long; ```. The Python `mulitprocessing` library appears to create sockets in `$TMPDIR`. If the `$TMPDIR` path is too long then the path to the socket extends past the length limits for socket paths. This can be reproduced by running the following command with `tmp_dbg` set to 80 characters long. 79 characters works ok. ```shell; docker run -it --rm docker.io/broadinstitute/gdc_downloader:1.0 bash -c '; # 1 2 3 4 5 6 7 8; tmp_dbg=/234567890123456789012345678901234567890123456789012345678901234567890123456789; tmp_dbg=/2345678901234567890123456789012345678901234567890123456789012345678901234567890; tmpDir=$(; set -e; tmpDir=""$(mkdir -p ""${tmp_dbg}"" && echo ""${tmp_dbg}"")""; echo ""$tmpDir""; ); chmod 777 ""$tmpDir""; export _JAVA_OPTIONS=-Djava.io.tmpdir=""$tmpDir""; export TMPDIR=""$tmpDir"". python /opt/src/gdc_downloader.py",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3647:191,variab,variable,191,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3647,1,['variab'],['variable']
Modifiability,"*See comment below on how to fix/address*. - cromwell-27-c89c83f-SNAP.jar; - JES backend; - server mode; - local mysql. I have a database block that looks exactly like the one in the example (from the error message), yet I still get the error message. I tried a diff on the database blocks, between the example and my database block, so I am sure that they match. Is this just a mistake in the error message itself? . This is blocking me. The error:. ```; Caused by: java.lang.Exception:; *******************************; ***** DEPRECATION MESSAGE *****; *******************************. Use of configuration path 'database.driver' has been deprecated. Replace with a ""profile"" element instead, e.g:. database {; #driver = ""slick.driver.MySQLDriver$"" #old; profile = ""slick.jdbc.MySQLProfile$"" #new; db {; driver = ""com.mysql.jdbc.Driver""; url = ""jdbc:mysql://host/cromwell?rewriteBatchedStatements=true""; user = ""user""; password = ""pass""; connectionTimeout = 5000; }; }. Cromwell thanks you. at cromwell.services.SingletonServicesStore$.<init>(ServicesStore.scala:70); at cromwell.services.SingletonServicesStore$.<clinit>(ServicesStore.scala); ... 22 more. ```. My conf file for database:; ```; database {; #driver = ""slick.driver.MySQLDriver$""; profile = ""slick.jdbc.MySQLProfile$""; db {; driver = ""com.mysql.jdbc.Driver""; url = ""jdbc:mysql://localhost/cromwell_24?useSSL=false&rewriteBatchedStatements=true""; user = ""root""; password = ""blahblah""; connectionTimeout = 5000; }; }. ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2217:595,config,configuration,595,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2217,3,"['config', 'rewrite']","['configuration', 'rewriteBatchedStatements']"
Modifiability,"+PrintGCDateStamps -XX:+PrintGCDetails \; -Xloggc:gc_log.log -Xms4000m"" \; BaseRecalibrator \; -R ${ref_fasta} \; -I ${input_bam} \; --useOriginalQualities \; -O ${recalibration_report_filename} \; -knownSites ${dbSNP_vcf} \; -knownSites ${sep="" -knownSites "" known_indels_sites_VCFs} \; -L ${sep="" -L "" sequence_group_interval}; }; runtime {; docker: ""us.gcr.io/broad-gotc-prod/genomes-in-the-cloud:2.3.2-1510681135""; memory: ""6 GB""; disks: ""local-disk "" + disk_size + "" HDD""; preemptible: preemptible_tries; }; output {; File recalibration_report = ""${recalibration_report_filename}""; }; }; ```. And here is my cromwell server config:. ```scala; include required(classpath(""application"")). webservice {; port = 8000; }. system {; workflow-restart = true; }. engine {; filesystems {. gcs {; auth = ""service-account""; }. http {}. local {; localization: [; ""hard-link"", ""soft-link"", ""copy""; ]; }; }; }. backend {; default = ""Local""; providers {. Local {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; max-concurrent-workflows = 1; concurrent-job-limit = 1; }; }. PAPIv2 {; actor-factory = ""cromwell.backend.google.pipelines.v2alpha1.PipelinesApiLifecycleActorFactory""; config {; project = ""bioinfo-XXXXXXX""; root = ""gs://XXXXXXXX""; genomics-api-queries-per-100-seconds = 1000; max-concurrent-workflows = 80; concurrent-job-limit = 200; maximum-polling-interval = 600. genomics {; # Config from google stanza; auth = ""service-account"". ; # Endpoint for APIs, no reason to change this unless directed by Google.; endpoint-url = ""https://genomics.googleapis.com/""; localization-attempts = 3; }. filesystems {; gcs {; # A reference to a potentially different auth for manipulating files via engine functions.; auth = ""service-account""; }; }; }; }; }; }. # Google authentication; google {; application-name = ""cromwell""; auths = [; {; name = ""application-default""; scheme = ""application_default""; },; {; name = ""service-account""; scheme = ""service_account""",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4336:1984,config,config,1984,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4336,1,['config'],['config']
Modifiability,", ""command_mem"": small_task_mem * 1000 - 500,; ""disk"": small_task_disk, ""boot_disk_size"": boot_disk_size}. scatter (normal_bam in zip(normal_bams, normal_bais)) {; call m2.Mutect2 {; input:; intervals = intervals,; ref_fasta = ref_fasta,; ref_fai = ref_fai,; ref_dict = ref_dict,; tumor_reads = normal_bam.left,; tumor_reads_index = normal_bam.right,; scatter_count = scatter_count,; m2_extra_args = select_first([m2_extra_args, """"]) + "" --max-mnp-distance 0"",; gatk_override = gatk_override,; gatk_docker = gatk_docker,; preemptible = preemptible,; max_retries = max_retries,; pon = pon,; pon_idx = pon_idx,; gnomad = gnomad,; gnomad_idx = gnomad_idx; }; }. output {; Array[File] normal_calls = Mutect2.filtered_vcf; Array[File] normal_calls_idx = Mutect2.filtered_vcf_idx. }; }. ```; <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->; ```; include required(classpath(""application"")); google {; application-name = ""cromwell""; auths = [; { ; name = ""application-default""; scheme = ""application_default""; }; ]; }; engine {; filesystems {; gcs {; auth = ""application-default""; }; }; }; backend {; default = ""JES""; providers {; JES {; actor-factory = ""cromwell.backend.impl.jes.JesBackendLifecycleActorFactory""; config {; // Google project; project = ""calico-uk-biobank""; compute-service-account = ""default""; // Base bucket for workflow executions; root = ""nicholas-b-test""; // Polling for completion backs-off gradually for slower-running jobs.; // This is the maximum polling interval (in seconds):; maximum-polling-interval = 600; // Optional Dockerhub Credentials. Can be used to access private docker images.; dockerhub {; // account = """"; // token = """"; }; genomics {; // A reference to an auth defined in the `google` stanza at the top. This auth is used to create; // Pipelines and manipulate auth JSONs.; auth = ""application-default""; // Endpoint for APIs, no reason to change this unless directed by Google.; endpoint-url = ""https:",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5352:4880,config,configuration,4880,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5352,1,['config'],['configuration']
Modifiability,", each phase having its own configurable timeout. See the Dev Wiki for more details.; 	graceful-server-shutdown = true; max-concurrent-workflows = 5000. io {; throttle {; # # Global Throttling - This is mostly useful for GCS and can be adjusted to match; # # the quota availble on the GCS API; number-of-requests = 100000; per = 100 seconds; }; }; }. akka {; # Optionally set / override any akka settings; http {; server {; # Increasing these timeouts allow rest api responses for very large jobs; # to be returned to the user. When the timeout is reached the server would respond; # `The server was not able to produce a timely response to your request.`; # https://gatkforums.broadinstitute.org/wdl/discussion/10209/retrieving-metadata-for-large-workflows; request-timeout = 600s; idle-timeout = 600s; }; }; }. services {; MetadataService {; #class = ""cromwell.services.metadata.impl.MetadataServiceActor""; config {; metadata-read-row-number-safety-threshold = 2000000; # # For normal usage the default value of 200 should be fine but for larger/production environments we recommend a; # # value of at least 500. There'll be no one size fits all number here so we recommend benchmarking performance and; # # tuning the value to match your environment.; db-batch-size = 700; }; }; }. google {. application-name = ""cromwell""; auths = [; {; name = ""application-default""; scheme = ""application_default""; }; ]; }. docker {; hash-lookup {; method = ""remote""; }; }. engine {; filesystems {; gcs {; auth = ""application-default""; }; }; }. call-caching {; enabled = true; }. backend {; default = GCPBATCH; providers {; GCPBATCH {; // life sciences; actor-factory = ""cromwell.backend.google.batch.GcpBatchBackendLifecycleActorFactory""; config {; ## Google project; project = ""$PROJECT"". ## Base bucket for workflow executions; root = ""$BUCKET""; name-for-call-caching-purposes: PAPI; #60000/min in google; ##genomics-api-queries-per-100-seconds = 90000; virtual-private-cloud {; network-name = ""$NET""; subnetwo",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7356:9003,config,config,9003,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7356,1,['config'],['config']
Modifiability,",; I am trying to run a workflow written in WDL using Cromwell v.65. The workflow reports the following error in the stdout:; ```[2023-08-11 14:21:11,58] [error] SingleWorkflowRunnerActor received Failure message: Metadata for workflow <UUID> exists in database but cannot be served because row count of 3138431 exceeds configured limit of 1000000.; cromwell.services.MetadataTooLargeNumberOfRowsException: Metadata for workflow <UUID> exists in database but cannot be served because row count of 3138431 exceeds configured limit of 1000000.```; This is after having edited the `cromwell.conf` as suggested in [this thread](https://github.com/broadinstitute/cromwell/issues/2519). The configuration file used is as follows (edited to remove the main script):; ```; include required(classpath(""application"")); backend {; default = LSF; providers {; LSF {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; exit-code-timeout-seconds = 300; runtime-attributes = """"""; Int cpu; Int memory_mb; String? lsf_queue; String? lsf_project; String? docker; """""". submit = """"""; bsub \; -q ${lsf_queue} \; -P ${lsf_project} \; -J ${job_name} \; -cwd ${cwd} \; -o ${out} \; -e ${err} \; -n ${cpu} \; -R 'rusage[mem=${memory_mb}] span[hosts=1]' \; -M ${memory_mb} \; /usr/bin/env bash ${script}; """""". submit-docker = """"""; module load tools/singularity/3.8.3; SINGULARITY_MOUNTS='<redacted>'; export SINGULARITY_CACHEDIR=$HOME/.singularity/cache; LOCK_FILE=$SINGULARITY_CACHEDIR/singularity_pull_flock. export SINGULARITY_DOCKER_USERNAME=<redacted>; export SINGULARITY_DOCKER_PASSWORD=<redacted>. flock --exclusive --timeout 900 $LOCK_FILE \; singularity exec docker://${docker} \; echo ""Sucessfully pulled ${docker}"". bsub \; -q ${lsf_queue} \; -P ${lsf_project} \; -J ${job_name} \; -cwd ${cwd} \; -o ${out} \; -e ${err} \; -n ${cpu} \; -R 'rusage[mem=${memory_mb}] span[hosts=1]' \; -M ${memory_mb} \; singularity exec --containall $SINGULARITY_MOUNTS --bind ${cwd}:${d",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7203:923,Config,ConfigBackendLifecycleActorFactory,923,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7203,2,"['Config', 'config']","['ConfigBackendLifecycleActorFactory', 'config']"
Modifiability,"- 0.23; - SGE backend; - single workflow; - no docker. The wdl in question (a simpler WDL can be made easily). Look at how it scatters over a variable that does not exist. I would expect cromwell to give an error message and exit.; ```; # This is **broken.wdl**; # This simple, *unsupported* WDL takes in a VCF from M2 and a tumor bam file.; # It produces a new VCF with the filtering results. workflow test_ob_filter {; # tsv; # entity_id vcf tumor_bam_file; File input_table; Array[Array[String]] m2_vcfs = read_tsv(input_table); File db_snp; String gatk_jar; File ref_fasta. scatter (row in THIS_VAR_DOES_NOT_EXIST) {; call CollectSequencingArtifactMetrics {; input:; entity_id=row[0],; bam_file=row[2],; gatk_jar=gatk_jar,; ref_fasta=ref_fasta,; output_location_prepend=row[0]; }; call FilterByOrientationBias {; input:; entity_id=row[0],; gatk_jar=gatk_jar,; m2_vcf=row[1],; pre_adapter_detail_metrics=CollectSequencingArtifactMetrics.pre_adapter_detail_metrics; }; }. call MakeSummaryFileList {; input:; files=FilterByOrientationBias.orientation_bias_vcf_summary,; output_file=""summary_table.txt""; }; }. task CollectSequencingArtifactMetrics {; String entity_id; File bam_file; String output_location_prepend; String gatk_jar; # /seq/references/Homo_sapiens_assembly19/v1/Homo_sapiens_assembly19.fasta; File ref_fasta. command {; java -jar ${gatk_jar} CollectSequencingArtifactMetrics -I ${bam_file} -O ${output_location_prepend} -R ${ref_fasta} --VALIDATION_STRINGENCY SILENT; }. output {; File pre_adapter_detail_metrics = ""${output_location_prepend}.pre_adapter_detail_metrics""; File pre_adapter_summary_metrics = ""${output_location_prepend}.pre_adapter_summary_metrics""; File bait_bias_detail_metrics = ""${output_location_prepend}.bait_bias_detail_metrics""; File bait_bias_summary_metrics = ""${output_location_prepend}.bait_bias_summary_metrics""; }; }. task FilterByOrientationBias {; String entity_id; String gatk_jar; File m2_vcf; File pre_adapter_detail_metrics. command {; java -jar ${ga",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1774:142,variab,variable,142,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1774,1,['variab'],['variable']
Modifiability,- Add dood to the ci docker compose used by jenkins.; - Run ci docker under user `hoggett`.; - Pass mysql creds to cromwell unit tests running in jenkins.; - Do not remove rendered creds via `sbt clean`.; - Reduce configs to `sbt test` and `sbt alltests:test`.; - Otherwise use the environment variable `CROMWEL_SBT_TEST_EXCLUDE_TAGS`.; - Tests don't need to be run in the directory `cromwell`.; - Only push artifacts on travis.; - Simplify skipping docker push.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4169:214,config,configs,214,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4169,2,"['config', 'variab']","['configs', 'variable']"
Modifiability,"- Added `scalafmt.conf` to the repo, which includes our linting rules.; - This is essentially a copy of the [Leonardo one](https://github.com/DataBiosphere/leonardo/blob/develop/.scalafmt.conf), although I bumped the version and avoided using deprecated syntax. It should be functionally identical.; - Ran the `scalafmt` CLI tool on to apply the formatting rules to all files. We shouldn't need the CLI tool moving forward since IntelliJ is perfectly capable of formatting individual files. ; - Setup:; - Get the `scala` plugin for IntelliJ. You likely already have it.; - Restart IntelliJ. ; - (optional) `Settings > Editor > Code Style > Scala` to turn on ""Reformat on Save"". ; - Planning on creating a Github Action in a a different branch.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7257:521,plugin,plugin,521,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7257,1,['plugin'],['plugin']
Modifiability,"- Added comment that WDL can only handle increasing version numbers; - Sort through the first page of releases instead of using the latest-release-by-date; - Exit WDL commands that contain unset variables or have pipe failures (set -uo pipefail); - Exit WDL commands on the first error (set -e); - Log WDL commands verbosely as they run (set -x); - Replaced usages of docker/python runtimes with brew'ed jq; - Remove call to sbt test from minor releases, thus operating like major releases; - Made the WDL input ""organization"" mandatory instead of optional; - Copy release notes for major releases from develop instead of master; - Copy release notes for minor releases from hotfix branches; - Pointed to correct homebrew pull request template; - Added additional homebrew test as required in the homebrew pull request template; - Fail the WDL call/workflow if any of homebrew's build/test/verify tasks fail",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4744:195,variab,variables,195,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4744,1,['variab'],['variables']
Modifiability,"- Added functionality to Cromwell so that a sas token can be provided as an environment variable to TES tasks ; - Added some functionality to BlobPath to help with WSM stuff; - Acknowledging that adding Terra specific stuff to a generic Azure concept isn't ideal. This seems like the least invasive way of getting the required data, since it allows us to take advantage of the already instantiated filesystems + their configuration.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7241:88,variab,variable,88,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7241,2,"['config', 'variab']","['configuration', 'variable']"
Modifiability,"- Added recovery functionality using KV service.; - In the next iteration will refactor to use a Doc store (Mongo, Couchbase) generic service implementation or continue using KV service but with a refactor in order to support not just SQL DBs as KV store but any other kind of DB. I think the best may be to work on a DAL or if it's not possible just modify the service to support other providers. Let me know what do you think on this.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1250:79,refactor,refactor,79,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1250,2,['refactor'],['refactor']
Modifiability,- Additional wiring for the cromwell terminator.; - Reduced duplicate calls to ConfigFactory.load().; - Increased ability to pass around test configs.; - Provide names for more actors.; - Instrument failures in batch actors.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4785:79,Config,ConfigFactory,79,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4785,2,"['Config', 'config']","['ConfigFactory', 'configs']"
Modifiability,"- Adds a way to lookup docker hashes from local machine, thanks @kshakir !; - ~~Adds a config option to disable docker lookup entirely.~~; - Disable docker lookup if the backend does not support docker. ~~@LeeTL1220 this is slightly different from what we talked this morning but I think it should still enable your use case.; If you disable docker hash lookup on the SGE cromwell server, you'll still have call caching and there will be no lookup (so it won't fail..).~~",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2139:87,config,config,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2139,1,['config'],['config']
Modifiability,"- Allow a `0` value for CWL `outDirMin` and `tmpDirMin` resource attributes; - Adds an optional section to the language factory to define a command to run after the user's action that will return output files that can only be known at runtime; - Only defined for CWL for now, which will remove unnecessary pull of jq for WDL tasks on PAPI2; - Docker image and command can both be changed in the configuration; - The PAPI2 logic that handles delocalization of those file strips away some redundant pieces in the delocalized paths to reduce the overall length of the path",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4358:395,config,configuration,395,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4358,1,['config'],['configuration']
Modifiability,"- As sentry may drop some metadata, print the metadata to slf4j.; - For centaur-restarting-cromwell, remember if cromwell was alive, and log more of the connection status.; - Pass more jenkins variables through docker.; - Increase papi v2 cwl conformance test timeout due to problematic test 55.; - Use pr branch name during pr builds.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4021:193,variab,variables,193,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4021,1,['variab'],['variables']
Modifiability,"- Better localization and delocalization of directories in PAPI2 using hidden files to cover for empty directories; - IWDR localization is not baked in the CWL code anymore but left to the backend. This allows for the PAPI backend to opt out of it since localization is done directly on the VM.; - ~~Use configurable `job-shell` instead of hardcoded `/bin/bash`~~ It fixes 117 but also makes a bunch of centaur tests fail, so leaving as is for now.; - Refactors Pipelines conversions in v2 (w/ typeclasses !); - Allow for lazy evaluation of file and directory literals so that they can be written when the backend and the appropriate IoFunctions are known. This only partially covers the possible cases. It needs a deeper tech talk discussion. This is orthogonal to the above and only here to avoid a later rebase (the files changed overlap with the refactoring mentioned).; - Partially replaces the custom `MemorySize` with [squants](https://github.com/typelevel/squants); - Turns the CPU runtime validation from an `Int` to a `Int Refined Positive`; - Automatically fits the resources requirements in the task to the [GCE constraints](https://cloud.google.com/compute/docs/instances/creating-instance-with-custom-machine-type#specifications)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3697:304,config,configurable,304,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3697,3,"['Refactor', 'config', 'refactor']","['Refactors', 'configurable', 'refactoring']"
Modifiability,- Bonus: New config option to preresolve DrsPath to GcsPath when possible,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6031:13,config,config,13,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6031,1,['config'],['config']
Modifiability,"- Disabled redundant `lots_of_inputs.test` test, which uses `lots_of_inputs.wdl` like `lots_of_inputs_papiv2.test` and makes analysis confusing; - Removed unused configs, mostly from PAPIv2 Alpha; - Removed unused suites, mostly from PAPIv2 Alpha; - Removed Travis, Jenkins, and CircleCI references from `test.inc.sh`. This includes `case` statements, as well as all functions that were called exclusively in the removed `case` statements.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7336:162,config,configs,162,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7336,1,['config'],['configs']
Modifiability,- Enables 121 on PAPIv2; - Refactors Pipelines conversions in v2 (w/ typeclasses !); - Partially replaces the custom `MemorySize` with [squants](https://github.com/typelevel/squants); - Turns the CPU runtime validation from an `Int` to a `Int Refined Positive`; - Automatically fits the resources requirements in the task to the [GCE constraints](https://cloud.google.com/compute/docs/instances/creating-instance-with-custom-machine-type#specifications); - Allow for lazy evaluation of file and directory literals so that they can be written when the backend and the appropriate IoFunctions are known,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3694:27,Refactor,Refactors,27,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3694,1,['Refactor'],['Refactors']
Modifiability,"- Forked dbms tests into earliest and latest tests, with platform as a separate enum; - Run additional docker containers for latest dbms versions; - Run dbms tests as a separate travis job due to more containers & tests; - Generate dbms test configs, and ""how to"" messages to run docker and reset db; - Fixed dbms tests that were not closing their connections; - Verify that most projects are aggregated, and therefore tested by `sbt test`",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5175:242,config,configs,242,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5175,1,['config'],['configs']
Modifiability,- GcpBatchAsyncBackendJobExecutionActor -> pollBackOff had maxInterval value hardcoded instead of using the config entry.; - GcpBatchTestConfig was still referencing papi instead of batch.; - Rename PipelinesApiEmptyMountedDisk to BatchApiEmptyMountedDisk.; - GcpBatchAsyncBackendJobExecutionActorSpec was still referencing pipelines instead of batch.; - Localization was referencing papi instead of batch.; - RunnableUtils had unused definitions which are now deleted.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7428:108,config,config,108,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7428,1,['config'],['config']
Modifiability,"- No frills github action that either passes, or fails with a list of files that need to be fixed. ; - Formatted `ContinuousIntegration.scala` since that slipped in before this github action did. ; - `scalafmt` can be executed locally in a number of ways:; - IntelliJ Integration: Works as long as the `scala` plugin is installed. `Option + Command + L` formats the current file.; - `sbt scalafmtCheckAll`; - Install the `scalafmt` CLI tool directly via [brew](https://scalameta.org/scalafmt/docs/installation.html) and [coursier](https://get-coursier.io/docs/cli-installation).",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7337:310,plugin,plugin,310,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7337,1,['plugin'],['plugin']
Modifiability,- People should be able to change the backend name in the config without losing their call cache; - People should (probably?) be able to upgrade from PAPI1 to PAPI2 without losing their call cache,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3955:58,config,config,58,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3955,1,['config'],['config']
Modifiability,"- Refactor all CI TRAVIS_* variables back into create_build_variables(); - Detect hotfixes using git instead of TRAVIS variables; - Using ""force ci"" now runs all sub builds even on push; - All centaur tests should contribute to codecov; - Moved ci source files under src/ci; - Write ci log files under target/ci instead of $PWD; - Write ci generated files under target/ci, instead of sending secrets to src; - Jar file searches now return most recently modified jar; - Added allowPublicKeyRetrieval=true to MySQL url generation; - Removed cloudwell test as the combo of horicromtal + deadlock tests the same features",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5202:2,Refactor,Refactor,2,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5202,3,"['Refactor', 'variab']","['Refactor', 'variables']"
Modifiability,- Refactor the metadata building. - sort events by timestamp from the DB query. - add CRDT for call execution status. - compress metadata response. - fix timing diagram,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2180:2,Refactor,Refactor,2,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2180,1,['Refactor'],['Refactor']
Modifiability,"- Refactor things slightly to give the `typeEvaluators` access to the `typeAliases` map, which contains all the struct definitions ; - Make a `typeEvaluator` for StructLiterals",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7402:2,Refactor,Refactor,2,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7402,1,['Refactor'],['Refactor']
Modifiability,- Refactored more `Future` to `IO`.; - Hard-coded pretty-printed json now returns correct content-type.; - Check content-type of responses in tests.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4624:2,Refactor,Refactored,2,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4624,1,['Refactor'],['Refactored']
Modifiability,"- Refactored the DrsLocalizer to better handle multiple large downloads.; - Now, the DrsLocalizer will resolve all URLs up front, and then invoke the `getm` tool with a manifest containing all files to download. This improves download performance.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7214:2,Refactor,Refactored,2,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7214,1,['Refactor'],['Refactored']
Modifiability,"- Refactoring the `TaskExecutionContext` (and children) into `BackendCall`. `BackendCall` represents the marriage of a (you guessed it...) `Backend` and a `Call`. The `BackendCall` also stores the `Map[LocallyQualifiedName, WdlValue]`. A `BackendCall` is basically a way to package up a (Call + Backend + Inputs) so you can simply do `.execute` with no parameters and it can start running.; ; This actually sets us up nicely for tasks to define which backend they run on (if we choose to support that). This could be implemented simply by honoring a runtime section like this.; ; ```; task sge_task {; command { ... }; runtime {; backend: ""sge""; }; }; ```; ; At the time we're creating the `BackendCall`, we just switch on the 'backend' value on the task, and either return a `SgeBackendCall`, `LocalBackendCall`, or `JesBackendCall` (depending on what we support); - Add SGE backend based off of Local Backend; - Created a `LocalFileSystemOperations` trait which fulfills some of the `Backend` API. SGE and Local backends currently make an assumption: the Cromwell process writes everything to filesystem paths and jobs that Cromwell launch can see and write into those directories. So operations like initializing a workflow or post-processing a job that has completed are the same between SGE and Local backends.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/145:2,Refactor,Refactoring,2,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/145,1,['Refactor'],['Refactoring']
Modifiability,"- Removed `martha_v2` response parsing; - When traversing files using a mapper function then mapper does the exclusion; - Use serialized class instead of config string replace for Martha request generation; - Request partial responses from Martha; - Use JDK standard responses for missing file attributes (size=0, time=epoch, hash=None); - Copy `timeCreated` from DOS/DRS to file attributes; - Martha `read_string()` uses `gsUri` (gs://bucket/name) instead of `bucket` and `name`; - Martha localization uses safer file paths still based on the DOS/DRS URI; - Reading DOS/DRS content uses the config google auth type, not always Bond-or-USA; - Google config auth types support ADC=SA, passing in scopes to ADC; - Google auth type `UserMode` no longer requires config values that it was ignoring; - Allow skipping docker build-and-push by specifying the `CROMWELL_BUILD_PAPI_DOCKER_IMAGE_DRS`; - `papi-v2-usa` backend now ALWAYS uses the USA just like Terra/FC does",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5912:154,config,config,154,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5912,4,['config'],['config']
Modifiability,"- Removes the `fetchSize` configuration because it turns out we need to pin it at `Integer.MIN_VALUE`; - Pins the `fetchSize` at `Integer.MIN_VALUE`, for the same reason; - Adds more frequent metrics outputs during large workflow uploads, AND when there is nothing being uploaded",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6314:26,config,configuration,26,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6314,1,['config'],['configuration']
Modifiability,"- Renamed existing ""upgrade"" tests to ""wdl_upgrade"".; - Refactored concept of `cron` as `y`/`n` to `centaur_type` of `standard`/`integration`/`engineUpgrade`.; - Before starting engine upgrade tests, run new sql checks for rows in metadata/jobKeyValue tables.; - Shutting down cromwell after wdl and engine upgrade tests.; - Rendering ci resources under `target`, instead of under `src`.; - Writing centaur logs under `target`.; - Logging the command used to start cromwell from centaur.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4132:56,Refactor,Refactored,56,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4132,1,['Refactor'],['Refactored']
Modifiability,"- Replaced to-be-deprecated Credential (no 's') with Adapter around Credentials; - Removed dupe credentials adapting from PipelinesApiFactoryInterface; - Move service specific scopes (KMS, Genomics) out of GoogleAuthMode; - Changed credential creation methods to take scala collections",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5013:53,Adapt,Adapter,53,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5013,2,"['Adapt', 'adapt']","['Adapter', 'adapting']"
Modifiability,"- Runs a perf test automatically as supplied in the jenkins job; - Tests are described as centaur tests and run with centaur; - At the end of the test run, pushes the workflow metadata, crowmell logs, statsd metrics and VM logs up to GCS; - Destroys the VM and associated CloudSQL after the test has run; - Adds a proxy in the docker compose that will redirect statsd metrics to the hosted grafana as well as write them down to a file that will be pushed to gcs at the end of the workflow; - Custom cromwell configuration per test; - Custom centaur configuration per test. As side effects on centaur:; - Now accepts `http(s)` and `gs` urls in the workflow / inputs / options section; - Can push metadata to GCS at the end of a test; - Metadata query parameters can be configured to accommodate for very large workflows. Example of test run output: https://console.cloud.google.com/storage/browser/cromwell-perf-test-reporting/hello/35-1632b40-SNAP/perf-test-130/?project=broad-dsde-cromwell-perf&organizationId=548622027621",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4123:508,config,configuration,508,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4123,3,['config'],"['configuration', 'configured']"
Modifiability,"- SGE backend; - cromwell v29. The following WDL works:; ```; # Runtime parameters; Int? mem; String gatk_docker; Int? preemptible_attempts; Int? disk_space_gb. Int final_mem=select_first([mem, 3]); ... snip....; runtime {; memory: select_first([mem, 3]) + "" GB""; ....snip....; ```. BUT the below WDL gives me an error that the + operator is not supported for optional variables, please use select_first. However, the variable final_mem is not optional:. ```; ....; # Everything is the same as the working WDL, except:; runtime {; memory: final_mem + "" GB""; ....; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2643:369,variab,variables,369,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2643,2,['variab'],"['variable', 'variables']"
Modifiability,"- There are *five* different authentication schemes (It looks like ""four"" is a typo); - Made each of the five options subheaders under ""Configuring Authentication"" for clarity",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5529:136,Config,Configuring,136,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5529,1,['Config'],['Configuring']
Modifiability,"- Upgraded Liquibase to latest; - ~Workaround Liquibase UniqueConstraint ""caching"" bug~ EDIT: Bug was fixed in liquibase!; - Fixed S3 SPI config to avoid Liquibase warnings; - Removed unused DB upgrade environment variables; - Test various DB combinations using centaur local",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6091:138,config,config,138,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6091,2,"['config', 'variab']","['config', 'variables']"
Modifiability,"- We were behind the times and did not have the required config, fixed that.; - Added a hook to set the copyright automatically.; - Fixed web hook, each PR now builds docs and has a live link to the branch's version thereof. ![Screenshot 2024-05-06 at 13 26 02](https://github.com/broadinstitute/cromwell/assets/1087943/7434da80-55f2-4b81-b6f9-2c847e39fea0)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7420:57,config,config,57,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7420,1,['config'],['config']
Modifiability,- Workaround Travis Docker issue; - Added heartbeats to docker tests; - DRYed conformance tests; - Fixed centaur tests where an empty CBCTAP early terminated getopts; - Introduced non-Travis-specific variable for GitHub PR branch names; - Switched from cd to pushd/popd,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4930:200,variab,variable,200,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4930,1,['variab'],['variable']
Modifiability,"- [x] Add AWS creds to Vault. Done: `secret/dsde/cromwell/common/cromwell-aws`; - [x] Use AWS creds to setup an environment in AWS; - [x] Create a queue in AWS Batch; - [x] Create an S3 bucket for storing Cromwell outputs; - [ ] Gitignore the AWS credentials file; - [x] Create [src/ci/resources](https://github.com/broadinstitute/cromwell/tree/develop/src/ci/resources)/aws_application.conf.ctmpl; - [x] Reference the AWS creds from Vault; - [x] Add in the AWS Batch Queue name; - [x] Add the S3 bucket for storing Travis results; - [ ] Update [src/ci/bin/testCentaurAws.sh](https://github.com/broadinstitute/cromwell/blob/develop/src/ci/bin/testCentaurAws.sh) and run locally until it passes; - [ ] Insert `cromwell::build::setup_secure_resources` before `cromwell::build::assemble_jars`; - [ ] Exclude failed tests as necessary using `-e should_work_but_does_not_on_aws`; - [ ] If the AWS Batch queue was not hardcoded, export an environment variable with the queue name in `testCentaurAws.sh`; - [ ] Prepend `BUILD_TYPE=centaurAws` into the [.travis.yaml](https://github.com/broadinstitute/cromwell/blob/develop/.travis.yml) env matrix. See other centaur scripts and resources under [src/ci](https://github.com/broadinstitute/cromwell/blob/develop/src/ci) for examples.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3964:945,variab,variable,945,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3964,1,['variab'],['variable']
Modifiability,- [x] Clarify the options / configuration names,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1018:28,config,configuration,28,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1018,1,['config'],['configuration']
Modifiability,"- [x] update README; - [x] let everybody know they need to update their configs; - [x] create ticket describing surprising `src` + `test` config overlay, not to be fixed as part of this work! (https://github.com/broadinstitute/cromwell/issues/768)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/766:72,config,configs,72,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/766,2,['config'],"['config', 'configs']"
Modifiability,"- cromwell 0.25; - local backend + docker; - single workflow mode; - call caching disabled. Seems like the workflow completed just fine, but I still get an error. *This is transient* I have run the exact same workflow in exact same configuration multiple times and the error appears to happen ~50% of the time. ```; ....snip....; [2017-03-20 15:30:35,10] [info] SingleWorkflowRunnerActor workflow finished with status 'Succeeded'.; {; ""outputs"": {; ""Mutect2_Multi.contamination_tables"": [""null"", ""null""],; ""Mutect2_Multi.filtered_vcf_files"": [""/home/lichtens/debug_m2_wdl/cromwell-executions/Mutect2_Multi/0239d302-1154-4c39-9870-55574d000765/call-Mutect2/shard-0/Mutect2/7b579210-dfee-4740-ab6e-c1f65bc64014/call-Filter/execution/synthetic.challenge.set1.tumor-vs-synthetic.challenge.set1.normal-filtered.vcf"", ""/home/lichtens/debug_m2_wdl/cromwell-executions/Mutect2_Multi/0239d302-1154-4c39-9870-55574d000765/call-Mutect2/shard-1/Mutect2/56dd28f2-d4af-449d-961a-eface7c9a288/call-Filter/execution/background.synth.challenge2.snvs.svs.tumorbackground-vs-synthetic.challenge.set2.normal-filtered.vcf""],; ""Mutect2_Multi.filtered_vcfs"": ""/home/lichtens/debug_m2_wdl/cromwell-executions/Mutect2_Multi/0239d302-1154-4c39-9870-55574d000765/call-filteredOutputList/execution/filtered.list"",; ""Mutect2_Multi.unfiltered_vcf_files"": [""/home/lichtens/debug_m2_wdl/cromwell-executions/Mutect2_Multi/0239d302-1154-4c39-9870-55574d000765/call-Mutect2/shard-0/Mutect2/7b579210-dfee-4740-ab6e-c1f65bc64014/call-MergeVCFs/execution/synthetic.challenge.set1.tumor-vs-synthetic.challenge.set1.normal.vcf"", ""/home/lichtens/debug_m2_wdl/cromwell-executions/Mutect2_Multi/0239d302-1154-4c39-9870-55574d000765/call-Mutect2/shard-1/Mutect2/56dd28f2-d4af-449d-961a-eface7c9a288/call-MergeVCFs/execution/background.synth.challenge2.snvs.svs.tumorbackground-vs-synthetic.challenge.set2.normal.vcf""],; ""Mutect2_Multi.ob_filtered_vcf_files"": [""/home/lichtens/debug_m2_wdl/cromwell-executions/Mutect2_Multi/0239d302-1154-4c39-987",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2079:232,config,configuration,232,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2079,1,['config'],['configuration']
Modifiability,- martha endpoint is specified in config; - martha_v3 has different response structure and supports Terra data repo; - Terra data repo integration tests are not included are in https://github.com/broadinstitute/cromwell/pull/5719. Closes https://broadworkbench.atlassian.net/browse/WA-180,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5710:34,config,config,34,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5710,1,['config'],['config']
Modifiability,- more logging in EjeaMultipleCallCacheCopyAttemptsSpec; - more logging of the centaur config during app startup; - all tests now output the heartbeat after common setup; - shorter centaur max workflow length for non-cron jobs; - exit horicromtal test when any of the containers fail,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6202:87,config,config,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6202,1,['config'],['config']
Modifiability,"- single workflow mode; - JES backend; - Google VM; - 0.23. ```; ....snip...; [2016-12-06 01:52:49,82] [warn] Unrecognized configuration key(s) for Jes: genomics-api-queries-per-100-seconds, dockerhub.token, dockerhub.account, genomics.compute-service-account; ....snip....; ```. As far as I can tell, I am using the same keys as in the reference conf file. Worked in previous dev builds with same structure (though fewer keys). @kcibul This is important, though I would not be surprised if this was user error. From the configuration:. ```; ...snip...; JES {; actor-factory = ""cromwell.backend.impl.jes.JesBackendLifecycleActorFactory""; config {; # Google project; project = ""broad-dsde-methods""; ; # Base bucket for workflow executions; root = ""gs://broad-dsde-methods/cromwell-executions-eval-gatk-protected/""; ; # Set this to the lower of the two values ""Queries per 100 seconds"" and ""Queries per 100 seconds per user"" for; # your project.; #; # Used to help determine maximum throughput to the Google Genomics API. Setting this value too low will; # cause a drop in performance. Setting this value too high will cause QPS based locks from Google.; # 1000 is the default ""Queries per 100 seconds per user"", 50000 is the default ""Queries per 100 seconds""; # See https://cloud.google.com/genomics/quotas for more information; genomics-api-queries-per-100-seconds = 1000; ; # Polling for completion backs-off gradually for slower-running jobs.; # This is the maximum polling interval (in seconds):; maximum-polling-interval = 600; ; # Optional Dockerhub Credentials. Can be used to access private docker images. REMOVED HERE; dockerhub {; account = ""user_manually_removed""; token = ""password_manually_removed""; }; ; genomics {; # A reference to an auth defined in the `google` stanza at the top. This auth is used to create; # Pipelines and manipulate auth JSONs.; auth = ""application-default""; ; // alternative service account to use on the launched compute instance; // NOTE: If combined with servi",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1748:123,config,configuration,123,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1748,3,['config'],"['config', 'configuration']"
Modifiability,"- v28; - JES backend. With the below changes to a reference.conf, I would expect my jobs to be distributed between us-central1-f and -c, but when I check the VM instances, they are all still going to us-central1-b, the cromwell default. . Do I have the default-zones in the correct location in the hierarchy? This was taken from reference.conf, but might have gotten stale in v28. Here is a snippet of my configuration:. ```; backend {; default = ""JES""; providers {; JES {; actor-factory = ""cromwell.backend.impl.jes.JesBackendLifecycleActorFactory""; 	 .... snip...; 	 genomics {; 			....snip.... 			 # Specifies the zone(s) to use for JES jobs unless overridden by a task's runtime attributes; 			 default-zones = [""us-central1-f"", ""us-central1-c""]; 		....snip....; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2527:405,config,configuration,405,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2527,1,['config'],['configuration']
Modifiability,"---. > All hoped-for things will come to you; > Who have the strength to watch and wait,; > Our longings spur the steeds of Fate,; > This has been said by one who knew. ---. - Don't set defaults for CI build variables ; - Removed many unused CI build variables ; - Renamed CI build variables based on generation and/or usage; - Ensure only passed values for CI build variables are used ; - Fixed tests that were using defaults and not passing in variables ; - Render centaur refresh tokens instead of rewriting json in memory ; - Don't use a bash wrapper-process for launching docker-compose from centaur ; - Pass centaur CI variables to docker-compose using env directly ; - Print docker-compose logs when centaur is unable to run `docker-compose up` ; - Better local docker-compose CI debugging with `crmdmm=y testFoo.sh` ; - Fix local CI debugging that was looking for `[force ci]` on prior commit ; - Allow force pushes to GitHub to use `[force ci]` syntax ; - Left `conformanceTesk` references while stubbing unused test ; - Consolidate tag generation for various docker images ; - Consolidate sbt invocation to build various docker images ; - On local tests, cache docker images just like assembly jars ; - Consistent level of verbosity on CI docker pushes and pulls ; - Moved conformance CI env-based-customization out of the reference.conf",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5738:625,variab,variables,625,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5738,6,['variab'],['variables']
Modifiability,"-07-10 14:32:53,46] [info] Running with database db.url = jdbc:hsqldb:mem:39174976-89f7-4769-a52c-7d5a4afc6cf4;shutdown=false;hsqldb.tx=mvcc; [2019-07-10 14:32:53,81] [info] Slf4jLogger started; [2019-07-10 14:32:54,07] [info] Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-1cf43fa"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""failureShutdownDuration"" : ""5 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; [2019-07-10 14:32:54,11] [info] Metadata summary refreshing every 1 second.; [2019-07-10 14:32:54,12] [warn] 'docker.hash-lookup.gcr-api-queries-per-100-seconds' is being deprecated, use 'docker.hash-lookup.gcr.throttle' instead (see reference.conf); [2019-07-10 14:32:54,12] [info] CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; [2019-07-10 14:32:54,13] [info] KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; [2019-07-10 14:32:54,13] [info] WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; [2019-07-10 14:32:54,18] [info] JobExecutionTokenDispenser - Distribution rate: 50 per 1 seconds.; [2019-07-10 14:32:54,43] [info] SingleWorkflowRunnerActor: Version 42; [2019-07-10 14:32:54,44] [info] SingleWorkflowRunnerActor: Submitting workflow; [2019-07-10 14:32:54,48] [info] Unspecified type (Unspecified version) workflow 41d3eecf-c5a9-42e4-8a29-8be9c252b7f5 submitted; [2019-07-10 14:32:54,50] [info] SingleWorkflowRunnerActor: Workflow submitted 41d3eecf-c5a9-42e4-8a29-8be9c252b7f5; [2019-07-10 14:32:54,50] [info] 1 new workflows fetched by cromid-1cf43fa: 41d3eecf-c5a9-42e4-8a29-8be9c252b7f5; [2019-07-10 14:32:54,51] [info] WorkflowManagerActor Starting workflow 41d3eecf-c5a9-42e4-8a29-8be9c252b7f5; [2019-07-10 14:32:54,51] [info] WorkflowManagerActor Successfully started WorkflowActor-41d3eecf-c5a9-42e4-8a29-8be9c252b7f5; [2019-07-10 14:32:54,52] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2019-07-10 1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5066:5582,config,configured,5582,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5066,1,['config'],['configured']
Modifiability,"-4e17-ab26-288ffc3d8aaa failed for reason: unknown error: . {JobName: cromwell-job,JobId: 2de677d8-0842-4e17-ab26-288ffc3d8aaa,JobQueue: arn:aws:batch:us-east-1:369228243869:job-queue/mcovarr-queue-nouveau,Status: FAILED,StatusReason: **Container.image contains invalid characters.**,CreatedAt: 1488362254138,DependsOn: [],JobDefinition: arn:aws:batch:us-east-1:369228243869:job-definition/cromwell-job-definition:125,Parameters: {},Container: {**Image: library/python@sha256:d23845e4757f13266b42877c25b845e455127b85ec12e5d551bec5d8162e7cd4**,Vcpus: 1,Memory: 1907,Command: [/bin/sh, -c, /bin/bash /usr/share/iodir/91a31bc2-ad38-4853-8bd6-fa456c66021b/cromwell-executions/PairedEndSingleSampleWorkflow/91a31bc2-ad38-4853-8bd6-fa456c66021b/PairedEndSingleSampleWorkflow-CheckFinalVcfExtension-NA-1/script > /usr/share/iodir/91a31bc2-ad38-4853-8bd6-fa456c66021b/cromwell-executions/PairedEndSingleSampleWorkflow/91a31bc2-ad38-4853-8bd6-fa456c66021b/PairedEndSingleSampleWorkflow-CheckFinalVcfExtension-NA-1/stdout 2> /usr/share/iodir/91a31bc2-ad38-4853-8bd6-fa456c66021b/cromwell-executions/PairedEndSingleSampleWorkflow/91a31bc2-ad38-4853-8bd6-fa456c66021b/PairedEndSingleSampleWorkflow-CheckFinalVcfExtension-NA-1/stderr < /dev/null || echo -1 > /usr/share/iodir/91a31bc2-ad38-4853-8bd6-fa456c66021b/cromwell-executions/PairedEndSingleSampleWorkflow/91a31bc2-ad38-4853-8bd6-fa456c66021b/PairedEndSingleSampleWorkflow-CheckFinalVcfExtension-NA-1/rc],Volumes: [{Host: {SourcePath: /usr/share/iodir},Name: cromwell-volume}],Environment: [],MountPoints: [{ContainerPath: /usr/share/iodir,ReadOnly: false,SourceVolume: cromwell-volume}],Ulimits: [],}}. For this reason found in the ECS javadocs:. ```; Amazon ECS task definitions currently only support tags as image identifiers within a specified repository; (and not <code>sha256</code> digests); ```. Of course it would be preferable if these digests actually were supported by ECS, in which case we wouldn't need to disable Cromwell's sha256 rewrites.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2044:2111,rewrite,rewrites,2111,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2044,1,['rewrite'],['rewrites']
Modifiability,"-Xms256M -Xmx1024M -XX:ParallelGCThreads=1; [2017-12-05 09:40:22,36] [info] Running with database db.url = jdbc:hsqldb:mem:ee347d5b-2cdf-4b76-b68a-dc5d09a93aeb;shutdown=false;hsqldb.tx=mvcc; [2017-12-05 09:40:28,42] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2017-12-05 09:40:28,44] [info] [RenameWorkflowOptionsInMetadata] 100%; [2017-12-05 09:40:28,54] [info] Running with database db.url = jdbc:hsqldb:mem:68a1b424-aa08-4f22-bc04-952c5eb83e7e;shutdown=false;hsqldb.tx=mvcc; [2017-12-05 09:40:29,02] [info] Slf4jLogger started; [2017-12-05 09:40:29,28] [info] Metadata summary refreshing every 2 seconds.; [2017-12-05 09:40:29,29] [info] Starting health monitor with the following checks: DockerHub, Engine Database; [2017-12-05 09:40:29,30] [info] WriteMetadataActor configured to write to the database with batch size 200 and flush rate 5 seconds.; [2017-12-05 09:40:29,35] [info] CallCacheWriteActor configured to write to the database with batch size 100 and flush rate 3 seconds.; [2017-12-05 09:40:30,63] [info] SingleWorkflowRunnerActor: Submitting workflow; [2017-12-05 09:40:30,68] [info] Workflow 6a6ee0eb-5576-43af-a64c-8ed7d288bbc5 submitted.; [2017-12-05 09:40:30,68] [info] SingleWorkflowRunnerActor: Workflow submitted 6a6ee0eb-5576-43af-a64c-8ed7d288bbc5; [2017-12-05 09:40:30,69] [info] 1 new workflows fetched; [2017-12-05 09:40:30,69] [info] WorkflowManagerActor Starting workflow 6a6ee0eb-5576-43af-a64c-8ed7d288bbc5; [2017-12-05 09:40:30,70] [info] WorkflowManagerActor Successfully started WorkflowActor-6a6ee0eb-5576-43af-a64c-8ed7d288bbc5; [2017-12-05 09:40:30,70] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2017-12-05 09:40:31,66] [error] WorkflowManagerActor Workflow 6a6ee0eb-5576-43af-a64c-8ed7d288bbc5 failed (during MaterializingWorkflowDescriptorState): Workflow input processing failed:; Unable to build WOM node for If '$if_0': Two or more nodes have the same FullyQua",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2992:1607,config,configured,1607,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2992,1,['config'],['configured']
Modifiability,"-Xms256M -Xmx1024M -XX:ParallelGCThreads=1; [2017-12-05 20:11:15,13] [info] Running with database db.url = jdbc:hsqldb:mem:7e58cfd2-b9b6-47f9-bda1-6fe045e7a665;shutdown=false;hsqldb.tx=mvcc; [2017-12-05 20:11:21,83] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2017-12-05 20:11:21,84] [info] [RenameWorkflowOptionsInMetadata] 100%; [2017-12-05 20:11:22,02] [info] Running with database db.url = jdbc:hsqldb:mem:e02f9206-cb15-468a-929a-82676a83a9b8;shutdown=false;hsqldb.tx=mvcc; [2017-12-05 20:11:22,47] [info] Slf4jLogger started; [2017-12-05 20:11:22,67] [info] Metadata summary refreshing every 2 seconds.; [2017-12-05 20:11:22,68] [info] Starting health monitor with the following checks: DockerHub, Engine Database; [2017-12-05 20:11:22,69] [info] WriteMetadataActor configured to write to the database with batch size 200 and flush rate 5 seconds.; [2017-12-05 20:11:22,71] [info] CallCacheWriteActor configured to write to the database with batch size 100 and flush rate 3 seconds.; [2017-12-05 20:11:23,78] [info] SingleWorkflowRunnerActor: Submitting workflow; [2017-12-05 20:11:23,82] [info] Workflow 159210e6-fa6a-4a99-b386-5931ae245324 submitted.; [2017-12-05 20:11:23,82] [info] SingleWorkflowRunnerActor: Workflow submitted 159210e6-fa6a-4a99-b386-5931ae245324; [2017-12-05 20:11:23,82] [info] 1 new workflows fetched; [2017-12-05 20:11:23,82] [info] WorkflowManagerActor Starting workflow 159210e6-fa6a-4a99-b386-5931ae245324; [2017-12-05 20:11:23,83] [info] WorkflowManagerActor Successfully started WorkflowActor-159210e6-fa6a-4a99-b386-5931ae245324; [2017-12-05 20:11:23,83] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2017-12-05 20:11:24,82] [error] WorkflowManagerActor Workflow 159210e6-fa6a-4a99-b386-5931ae245324 failed (during MaterializingWorkflowDescriptorState): Workflow input processing failed:; Unable to build WOM node for If '$if_2': Unable to build WOM node for Scatter '$s",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3007:1815,config,configured,1815,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3007,1,['config'],['configured']
Modifiability,"-a12c-24aced32f3b6 failed (during ExecutingWorkflowState): Job helloHaplotypeCaller.haplotypeCaller:NA:1 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.; Check the content of stderr for potential additional information: /home/centos/cromwell-executions/helloHaplotypeCaller/bf90a37b-6ffa-4122-a12c-24aced32f3b6/call-haplotypeCaller/execution/stderr; [2017-10-04 06:07:31,37] [info] WorkflowManagerActor WorkflowActor-bf90a37b-6ffa-4122-a12c-24aced32f3b6 is in a terminal state: WorkflowFailedState; [2017-10-04 06:07:35,37] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2017-10-04 06:07:35,41] [info] Message [cromwell.engine.workflow.WorkflowManagerActor$RetrieveNewWorkflows$] without sender to Actor[akka://cromwell-system/user/SingleWorkflowRunnerActor/WorkflowManagerActor#-1816723107] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; Workflow bf90a37b-6ffa-4122-a12c-24aced32f3b6 transitioned to state Failed; [2017-10-04 06:07:35,44] [info] Automatic shutdown of the async connection; [2017-10-04 06:07:35,44] [info] Gracefully shutdown sentry threads.; [2017-10-04 06:07:35,44] [info] Shutdown finished.; ```. Ans this is the output from the stderr file; ```; vi /home/centos/cromwell-executions/helloHaplotypeCaller/bf90a37b-6ffa-4122-a12c-24aced32f3b6/call-haplotypeCaller/execution/stderr; ^[[32m BwaSpark ^[[31m(BETA Tool) ^[[36mBWA on Spark^[[0m; ^[[32m CollectBaseDistributionByCycleSpark ^[[31m(BETA Tool) ^[[36mCollectBaseDistributionByCycle on Spark^[[0m; ^[[32m CollectInsertSizeMetricsSpark ^[[31m(BETA Tool) ^[[36mCollect Insert Size Distribution on Spark^[[0m; ^[[32m CollectMultipleMetricsSpark ^[[31m(BETA Tool) ^[[36mA ""meta-metrics"" calculating program that produces multiple metrics for the provided SAM/BAM/CRA",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2673:6634,config,configuration,6634,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2673,1,['config'],['configuration']
Modifiability,"-files). Thanks to all the great help you've provided we now have compatible WDL output that passes validation:. https://github.com/bcbio/test_bcbio_cwl/blob/master/run_info-cwl-wdl. This is brilliant, and I'd like to move into testing runs with Cromwell. Before starting this, there is one major area I know we're missing in the conversion, handling of secondary files and directories of files. CWL has the notion of secondaryFiles (http://www.commonwl.org/v1.0/Workflow.html#File) which you can use to block these and ensure they get staged/run next to each other. I use this in bcbio and wanted to figure out the best way to map it into WDL. There are two cases we use these for:. - Index files associated with compressed inputs, like BAM bai indices and bgzip VCF tbi indices. These are a single index file attached to the original file that should get staged in the same directory when running.; - Directories of index files like bwa or snpeff. These are a bit trickier since they can have many files and a variable number depending on the input. What is the recommended way to deal with these cases in WDL? I'll have to re-engineer bcbio to be able to represent and pass these and wanted to do so in a way that was forward compatible with WDL's thoughts and plans. I've seen recommendations on current hacks like explicitly declaring the indexes as separate files, or tarring up a directory of files and passing that as input. I'm not clear enough on staging files from WDL/Cromwell to understand if these are guaranteed to always go in the right place (bai next to bam, all indexes in the same directory). Thanks for any thoughts/suggestions/tips. This Issue was generated from your [forums] ; [forums]: http://gatkforums.broadinstitute.org/wdl/discussion/9299/secondary-index-files-and-directories-in-wdl/p1. ---. @vdauwera commented on [Thu May 04 2017](https://github.com/broadinstitute/dsde-docs/issues/1996#issuecomment-299359050). @katevoss this is a very common request from the Cromwel",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2269:2105,variab,variable,2105,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2269,1,['variab'],['variable']
Modifiability,-system-akka.dispatchers.backend-dispatcher-53 ERROR - DispatchedConfigAsyncJobExecutionActor [UUID(514f031f)AlignStar.star:NA:1]: Error attempting to Execute; java.lang.Exception: Failed command instantiation; at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand(StandardAsyncExecutionActor.scala:536); at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand$(StandardAsyncExecutionActor.scala:471); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.instantiatedCommand$lzycompute(ConfigAsyncJobExecutionActor.scala:208); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.instantiatedCommand(ConfigAsyncJobExecutionActor.scala:208); at cromwell.backend.standard.StandardAsyncExecutionActor.commandScriptContents(StandardAsyncExecutionActor.scala:265); at cromwell.backend.standard.StandardAsyncExecutionActor.commandScriptContents$(StandardAsyncExecutionActor.scala:264); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.commandScriptContents(ConfigAsyncJobExecutionActor.scala:208); at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.writeScriptContents(SharedFileSystemAsyncJobExecutionActor.scala:141); at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.writeScriptContents$(SharedFileSystemAsyncJobExecutionActor.scala:140); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.writeScriptContents(ConfigAsyncJobExecutionActor.scala:208); at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.execute(SharedFileSystemAsyncJobExecutionActor.scala:124); at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.execute$(SharedFileSystemAsyncJobExecutionActor.scala:121); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.execute(ConfigAsyncJobExecutionActor.scala:208); at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$executeAsync$1(StandardAsyncExecutionActor.scala:599); ,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3927:1806,config,config,1806,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3927,1,['config'],['config']
Modifiability,"-team/junit4/issues/1671"">#1671</a>)</li>; <li><a href=""https://github.com/junit-team/junit4/commit/a5d205c7956dbed302b3bb5ecde5ba4299f0b646""><code>a5d205c</code></a> Fix GitHub link in FAQ (<a href=""https://github-redirect.dependabot.com/junit-team/junit4/issues/1672"">#1672</a>)</li>; <li><a href=""https://github.com/junit-team/junit4/commit/3a5c6b4d08f408c8ca6a8e0bae71a9bc5a8f97e8""><code>3a5c6b4</code></a> Deprecated since jdk9 replacing constructor instance of Double and Float (<a href=""https://github-redirect.dependabot.com/junit-team/junit4/issues/1660"">#1660</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/junit-team/junit4/compare/r4.13...r4.13.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=junit:junit&package-manager=maven&previous-version=4.13&new-version=4.13.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/configuring-github-dependabot-security-updates). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5941:4102,config,configuring-github-dependabot-security-updates,4102,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5941,1,['config'],['configuring-github-dependabot-security-updates']
Modifiability,"-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're in the right place. -->; I clone the source code and assembly the jar. when try to run a sge job, I got and error. the log is following:. [2018-06-21 20:36:29,51] [error] DispatchedConfigAsyncJobExecutionActor [7ec0863atestsge.filter:NA:1]: Error attempting to Execute; java.lang.IllegalArgumentException: No coercion defined from '1' of type 'eu.timepit.refined.api.Refined' to 'Int'.; at wom.types.WomType.coerceRawValue(WomType.scala:36); at wom.types.WomType.coerceRawValue$(WomType.scala:27); at wom.types.WomIntegerType$.coerceRawValue(WomIntegerType.scala:9); at cromwell.backend.impl.sfs.config.DeclarationValidation.$anonfun$extractWdlValueOption$1(DeclarationValidation.scala:113); at scala.Option.map(Option.scala:146); at cromwell.backend.impl.sfs.config.DeclarationValidation.extractWdlValueOption(DeclarationValidation.scala:113); at cromwell.backend.impl.sfs.config.ConfigAsyncJobExecutionActor.$anonfun$runtimeAttributeInputs$1(ConfigAsyncJobExecutionActor.scala:163). <!-- Which backend are you running? -->; I use the SGE backend ; <!-- Paste/Attach your workflow if possible: -->; this is my WDL workflow; """"""; workflow testsge{; String Outdir; String JobName=""filter""; call filter{input:outdir=Outdir,jobname=JobName}; }. task filter{; String outdir; String jobname; command<<<; echo ""test successful"" >>${outdir}/log.stdout; echo 1; perl -we '{print STDERR 2;}'; Script=""${jobname}""; Sleep=$SGE_TASK_ID; QsubRcControl=3; QsubType=1; >>>; runtime{; backend:""SGE""; memory:""1 GB""; sge_queue:""test.q -P test -t 1-3""; sge_project:""test""; jobs_name:""${jobname}""; }; output{; String presuccess=""done""; Int rc=read_lines(stdout())[0]; }; }; """"""; <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->; this my runtime-attributes setting in the reference.conf file. runtime-attributes = """"""; Int cpu = 1; Flo",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3805:1451,config,config,1451,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3805,1,['config'],['config']
Modifiability,". . <!-- Paste/Attach your workflow if possible: -->; I have a very simple example workflow. ; ```; workflow test{; call task_A {}; }. task task_A{; command{; echo 'testing'; }; }; ```. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->; ```; include required(classpath(""application"")). webservice {; }. akka {; http {; server {; }; }; }. system {; io {; }; input-read-limits {; }; job-rate-control {; jobs = 2; per = 1 second; }. abort {; scan-frequency: 30 seconds; cache {; enabled: true; concurrency: 1; ttl: 20 minutes; size: 100000; }; }. dns-cache-ttl: 3 minutes; }. workflow-options {; default {; }; }. call-caching {; enabled = true; }. google {; }. docker {; hash-lookup {; }; }. engine {; filesystems {; local {; }; }; }. languages {; WDL {; versions {; ""draft-2"" {; }; ""1.0"" {; }; }; }; CWL {; versions {; ""v1.0"" {; }; }; }; }. backend {; default = ""SLURM"". providers {. SLURM {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; concurrent-job-limit = 500; runtime-attributes = """"""; Int runtime_minutes = 720; Int cpus = 1; Int requested_memory_mb_per_core = 8000; String queue = ""short""; """""". exit-code-timeout-seconds = 600. submit = """"""; sbatch -J ${job_name} -D ${cwd} -o ${out} -e ${err} -t ${runtime_minutes} -p ${queue} \; ${""-n "" + cpus} \; --mem-per-cpu=${requested_memory_mb_per_core} \; --constraint=""groups"" \; --qos=ded_reich \; --account=""reich"" \; --wrap ""/usr/bin/env bash ${script}""; """"""; kill = ""scancel ${job_id}""; check-alive = ""squeue -j ${job_id}""; job-id-regex = ""Submitted batch job (\\d+).*"". filesystems {; local {; localization: [; ""hard-link"", ""soft-link"", ""copy""; ]. caching {; duplication-strategy: [; ""soft-link""; ]. hashing-strategy: ""path"". check-sibling-md5: false; }; }; }. default-runtime-attributes {; failOnStderr: false; continueOnReturnCode: 0; }; }; }; }; }. services {; MetadataService {; }. Instrumentation {; }; HealthMonitor {; config",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6929:3041,config,config,3041,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6929,1,['config'],['config']
Modifiability,". Cromwell: (https://github.com/broadinstitute/cromwell/releases/tag/0.19.3). ```; >java -jar cromwell.jar run hello.wdl hello.json; [2016-08-08 08:33:03,503] [info] Slf4jLogger started; [2016-08-08 08:33:03,533] [info] RUN sub-command; [2016-08-08 08:33:03,533] [info] WDL file: hello.wdl; [2016-08-08 08:33:03,533] [info] Inputs: hello.json; [2016-08-08 08:33:03,573] [info] SingleWorkflowRunnerActor: launching workflow; [2016-08-08 08:33:04,203] [info] Running with database db.url = jdbc:hsqldb:mem:7e19faf1-d831-4edc-83fa-086ef9b16cd3;shutdown=false;hsqldb.tx=mvcc; [2016-08-08 08:33:08,947] [info] WorkflowManagerActor submitWorkflow input id =None, effective id = 4e20eafc-baae-4605-a010-adfa5f32ae46; [2016-08-08 08:33:09,687] [←[38;5;220mwarn←[0m] Failed to get application default credentials; java.io.IOException: The Application Default Credentials are not available. They are available if running in Google Compute Engine. Otherwise, the environment variable GOOGLE_APPLICATION_CREDENTIALS must be defined pointing to a file defining the credentials. See https://developers.google.com/accounts/docs/application-default-credentials for more information.; at com.google.api.client.googleapis.auth.oauth2.DefaultCredentialProvider.getDefaultCredential(DefaultCredentialProvider.java:93); at com.google.api.client.googleapis.auth.oauth2.GoogleCredential.getApplicationDefault(GoogleCredential.java:213); at com.google.api.client.googleapis.auth.oauth2.GoogleCredential.getApplicationDefault(GoogleCredential.java:191); at cromwell.util.google.GoogleCredentialFactory.forApplicationDefaultCredentials(GoogleCredentialFactory.scala:125); at cromwell.util.google.GoogleCredentialFactory.fromCromwellAuthScheme$lzycompute(GoogleCredentialFactory.scala:64); at cromwell.util.google.GoogleCredentialFactory.fromCromwellAuthScheme(GoogleCredentialFactory.scala:61); at cromwell.engine.backend.io.filesystem.gcs.StorageFactory$$anonfun$cromwellAuthenticated$1.apply(StorageFactory.scala:20); at cro",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1261:1200,variab,variable,1200,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1261,1,['variab'],['variable']
Modifiability,....by using a Travis [encryption key](https://docs.travis-ci.com/user/encryption-keys/) rather than an environment variable. Results: https://travis-ci.com/broadinstitute/cromwell/builds/98563607,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4582:116,variab,variable,116,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4582,1,['variab'],['variable']
Modifiability,".40.04/NVIDIA-Linux-x86_64-418.40.04.run; ls: cannot access '/build/usr/src/linux': No such file or directory; [INFO 2020-08-04 23:40:11 UTC] Kernel sources not found locally, downloading; [INFO 2020-08-04 23:40:11 UTC] Kernel source archive download URL: https://storage.googleapis.com/cos-tools/12871.1174.0/kernel-src.tar.gz. real	0m2.220s; user	0m0.183s; sys	0m0.338s; [INFO 2020-08-04 23:40:18 UTC] Setting up compilation environment; [INFO 2020-08-04 23:40:18 UTC] Obtaining toolchain_env file from https://storage.googleapis.com/cos-tools/12871.1174.0/toolchain_env. real	0m0.126s; user	0m0.014s; sys	0m0.001s; [INFO 2020-08-04 23:40:18 UTC] Downloading toolchain from https://storage.googleapis.com/cos-tools/12871.1174.0/toolchain.tar.xz. real	0m11.907s; user	0m0.428s; sys	0m1.039s; [INFO 2020-08-04 23:41:17 UTC] Configuring environment variables for cross-compilation; [INFO 2020-08-04 23:41:17 UTC] Configuring installation directories; [INFO 2020-08-04 23:41:17 UTC] Updating container's ld cache; [INFO 2020-08-04 23:41:20 UTC] Configuring kernel sources; [INFO 2020-08-04 23:41:42 UTC] Modifying kernel version magic string in source files; [INFO 2020-08-04 23:41:42 UTC] Running Nvidia installer. ERROR: The kernel module failed to load, because it was not signed by a key; that is trusted by the kernel. Please try installing the driver; again, and set the --module-signing-secret-key and; --module-signing-public-key options on the command line, or run the; installer in expert mode to enable the interactive module signing; prompts. ERROR: Unable to load the kernel module 'nvidia.ko'. This happens most; frequently when this kernel module was built against the wrong or; improperly configured kernel sources, with a version of gcc that; differs from the one used to build the target kernel, or if another; driver, such as nouveau, is present and prevents the NVIDIA kernel; module from obtaining ownership of the NVIDIA GPU(s), or no NVIDIA; GPU installed in this system is suppo",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5714:4646,Config,Configuring,4646,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5714,4,"['Config', 'variab']","['Configuring', 'variables']"
Modifiability,".ActorCell.create(ActorCell.scala:669) ; at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:523) ; at akka.actor.ActorCell.systemInvoke(ActorCell.scala:545) ; at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:283) ; at akka.dispatch.Mailbox.run(Mailbox.scala:224) ; at akka.dispatch.Mailbox.exec(Mailbox.scala:235) ; at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) ; at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) ; at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) ; at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) ; Caused by: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'services' ; at com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:156) ; at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:174) ; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:188) ; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:193) ; at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:268) ; at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:41) ; at cromwell.services.ServiceRegistryActor$.serviceNameToPropsMap(ServiceRegistryActor.scala:35) ; at cromwell.services.ServiceRegistryActor.serviceProps(ServiceRegistryActor.scala:63) ; at cromwell.services.ServiceRegistryActor.<init>(ServiceRegistryActor.scala:65) ; at cromwell.services.ServiceRegistryActor$.$anonfun$props$1(ServiceRegistryActor.scala:25) ; at akka.actor.TypedCreatorFunctionConsumer.produce(IndirectActorProducer.scala:87) ; at akka.actor.Props.newActor(Props.scala:212) ; at akka.actor.ActorCell.newActor(ActorCell.scala:624) ; at akka.actor.ActorCell.create(ActorCell.scala:650) ; ... 9 more ; ```. If I add in a `services` stanza, though, it asks me to define the class of each service, even though they should probably have default values:; ```; [ERROR] [01/24/2019 11:09:5",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4577:1719,config,config,1719,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4577,1,['config'],['config']
Modifiability,.ConfigDocumentParser$ParseContext.parseError(ConfigDocumentParser.java:197); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseKey(ConfigDocumentParser.java:279); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseObject(ConfigDocumentParser.java:450); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseValue(ConfigDocumentParser.java:247); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseObject(ConfigDocumentParser.java:458); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parse(ConfigDocumentParser.java:648); 	at com.typesafe.config.impl.ConfigDocumentParser.parse(ConfigDocumentParser.java:14); 	at com.typesafe.config.impl.Parseable.rawParseValue(Parseable.java:260); 	at com.typesafe.config.impl.Parseable.rawParseValue(Parseable.java:248); 	at com.typesafe.config.impl.Parseable.parseValue(Parseable.java:180); 	at com.typesafe.config.impl.Parseable.parseValue(Parseable.java:174); 	at com.typesafe.config.impl.Parseable.parse(Parseable.java:299); 	at com.typesafe.config.ConfigFactory.parseFile(ConfigFactory.java:689); 	at com.typesafe.config.DefaultConfigLoadingStrategy.parseApplicationConfig(DefaultConfigLoadingStrategy.java:51); 	at com.typesafe.config.ConfigFactory.defaultApplication(ConfigFactory.java:473); 	at com.typesafe.config.ConfigFactory$1.call(ConfigFactory.java:259); 	at com.typesafe.config.ConfigFactory$1.call(ConfigFactory.java:256); 	at com.typesafe.config.impl.ConfigImpl$LoaderCache.getOrElseUpdate(ConfigImpl.java:65); 	at com.typesafe.config.impl.ConfigImpl.computeCachedConfig(ConfigImpl.java:92); 	at com.typesafe.config.ConfigFactory.load(ConfigFactory.java:256); 	at com.typesafe.config.ConfigFactory.load(ConfigFactory.java:232); 	at cromwell.CromwellEntryPoint$.config$lzycompute(CromwellEntryPoint.scala:39); 	at cromwell.CromwellEntryPoint$.config(CromwellEntryPoint.scala:39); 	at cromwell.CromwellEntryPoint$.<init>(CromwellEntryPoint.scala:42); 	at cromwell.Cromw,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4549:2845,config,config,2845,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4549,1,['config'],['config']
Modifiability,.DigestUtils.digest(DigestUtils.java:50); Mar 09 00:55:25 web start-cromwell.sh[110916]: at org.apache.commons.codec.digest.DigestUtils.md5(DigestUtils.java:274); Mar 09 00:55:25 web start-cromwell.sh[110916]: at org.apache.commons.codec.digest.DigestUtils.md5Hex(DigestUtils.java:310); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.backend.impl.sfs.config.HashFileStrategy.$anonfun$hash$3(ConfigHashingStrategy.scala:82); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.util.TryWithResource$.$anonfun$tryWithResource$1(TryWithResource.scala:16); Mar 09 00:55:25 web start-cromwell.sh[110916]: at scala.util.Try$.apply(Try.scala:209); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.util.TryWithResource$.tryWithResource(TryWithResource.scala:10); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.backend.impl.sfs.config.HashFileStrategy.hash(ConfigHashingStrategy.scala:82); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.backend.impl.sfs.config.ConfigHashingStrategy.usingStandardInitData$1(ConfigHashingStrategy.scala:52); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.backend.impl.sfs.config.ConfigHashingStrategy.getHash(ConfigHashingStrategy.scala:57); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.backend.impl.sfs.config.ConfigBackendFileHashingActor.customHashStrategy(ConfigBackendFileHashingActor.scala:26); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.backend.standard.callcaching.StandardFileHashingActor$$anonfun$fileHashingReceive$1.applyOrElse(StandardFileHashingActor.scala:73); Mar 09 00:55:25 web start-cromwell.sh[110916]: at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); Mar 09 00:55:25 web start-cromwell.sh[110916]: at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); Mar 09 00:55:25 web start-cromwell.sh[110916]: at akka.actor.Actor.aroundReceive(Actor.scala:514); Mar 09 00:55:25 web start-cromwell.sh[110916]: at akka.actor.Actor.arou,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3383:2762,config,config,2762,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3383,1,['config'],['config']
Modifiability,".apply(JFunction0$mcV$sp.java:12); 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81); 	at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:91); 	at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); 	at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:43); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: akka.http.scaladsl.unmarshalling.Unmarshaller$UnsupportedContentTypeException: Unsupported Content-Type, supported: application/json; 	at akka.http.scaladsl.unmarshalling.Unmarshaller$UnsupportedContentTypeException$.apply(Unmarshaller.scala:158); 	at akka.http.scaladsl.unmarshalling.Unmarshaller$EnhancedFromEntityUnmarshaller$.$anonfun$forContentTypes$3(Unmarshaller.scala:114); 	at akka.http.scaladsl.unmarshalling.Unmarshaller$$anon$1.apply(Unmarshaller.scala:58); 	at akka.http.scaladsl.unmarshalling.Unmarshaller.$anonfun$transform$3(Unmarshaller.scala:23); 	at akka.http.scaladsl.unmarshalling.Unmarshaller$$anon$1.apply(Unmarshaller.scala:58); 	at akka.http.scaladsl.unmarshalling.Unmarshaller.$anonfun$transform$3(Unmarshaller.scala:23); 	at akka.http.scaladsl.unmarshalling.Unmarshaller$$anon$1.apply(Unmarshaller.scala:58); 	at akka.http.scaladsl.unmarshalling.Unmarshal.to(Unmarshal.scala:25); 	at cromiam.sam.SamClient.$anonfun$collectionsForUser$1(SamClient.scala:52); 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:304); 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); 	... 12 more; ```. Unmarshalling section where the response may not always be `HTTP 200` and the entity could actually be an error HTML string: https://github.com/broadinstitute/cr",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3622:2968,Enhance,EnhancedFromEntityUnmarshaller,2968,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3622,1,['Enhance'],['EnhancedFromEntityUnmarshaller']
Modifiability,.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.executeOrRecover(ConfigAsyncJobExecutionActor.scala:208); at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustExecuteOrRecover$1(AsyncBackendJobExecutionActor.scala:65); at cromwell.core.retry.Retry$.withRetry(Retry.scala:37); at cromwell.backend.async.AsyncBackendJobExecutionActor.withRetry(AsyncBackendJobExecutionActor.scala:61); at cromwell.backend.async.AsyncBackendJobExecutionActor.cromwell$backend$async$AsyncBackendJobExecutionActor$$robustExecuteOrRecover(AsyncBackendJobExecutionActor.scala:65); at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$receive$1.applyOrElse(AsyncBackendJobExecutionActor.scala:88); at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); at akka.actor.Actor.aroundReceive(Actor.scala:514); at akka.actor.Actor.aroundReceive$(Actor.scala:512); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.aroundReceive(ConfigAsyncJobExecutionActor.scala:208); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:527); at akka.actor.ActorCell.invoke(ActorCell.scala:496); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); at akka.dispatch.Mailbox.run(Mailbox.scala:224); at akka.dispatch.Mailbox.exec(Mailbox.scala:234); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: common.exception.AggregatedMessageException: Error(s):; Optional value was not set and no 'default' attribute was provided; Optional value was not set and no 'default' attribute was provided; at common.validation.Validation$ValidationTry$.toTry$extension1(Validation.scala:60); at common.validation.Validation$,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3927:4438,config,config,4438,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3927,1,['config'],['config']
Modifiability,.base/sun.nio.fs.UnixPath.subpath(UnixPath.java:328); 	 at java.base/sun.nio.fs.UnixPath.subpath(UnixPath.java:43); 	 at cromwell.core.path.NioPathMethods.subpath(NioPathMethods.scala:18); 	 at cromwell.core.path.NioPathMethods.subpath$(NioPathMethods.scala:18); 	 at cromwell.core.path.DefaultPath.subpath(DefaultPathBuilder.scala:55); 	 at cromwell.backend.io.JobPathsWithDocker.toDockerPath(JobPathsWithDocker.scala:56); 	 at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.$anonfun$mapCommandLineWomFile$1(SharedFileSystemAsyncJobExecutionActor.scala:147); 	 at wom.values.WomSingleFile.mapFile(WomFile.scala:201); 	 at wom.values.WomSingleFile.mapFile(WomFile.scala:182); 	 at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.mapCommandLineWomFile(SharedFileSystemAsyncJobExecutionActor.scala:145); 	 at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.mapCommandLineWomFile$(SharedFileSystemAsyncJobExecutionActor.scala:144); 	 at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.mapCommandLineWomFile(ConfigAsyncJobExecutionActor.scala:215); 	 at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$commandLineValueMapper$2(StandardAsyncExecutionActor.scala:206); 	 at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$mapOrNoResolve$1(StandardAsyncExecutionActor.scala:168); 	 at wom.WomFileMapper$.$anonfun$mapWomFiles$1(WomFileMapper.scala:24); 	 at scala.util.Try$.apply(Try.scala:213); 	 at wom.WomFileMapper$.mapWomFiles(WomFileMapper.scala:24); 	 at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$mapOrNoResolve$2(StandardAsyncExecutionActor.scala:163); 	 at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$commandLineValueMapper$1(StandardAsyncExecutionActor.scala:206); 	 at mouse.AnyOps$.$bar$greater$extension(any.scala:8); 	 at cromwell.backend.standard.StandardAsyncExecutionActor.localize$1(StandardAsyncExecutionActor.scala:474); 	 at cromwell.backend.standard.Standa,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6757:3047,config,config,3047,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6757,1,['config'],['config']
Modifiability,.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72); 	at scala.collection.AbstractIterable.foreach(Iterable.scala:54); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.AbstractTraversable.map(Traversable.scala:104); 	at wdl4s.Task$$anonfun$instantiateCommand$1.apply(Task.scala:108); 	at wdl4s.Task$$anonfun$instantiateCommand$1.apply(Task.scala:108); 	at scala.util.Try$.apply(Try.scala:192); 	at wdl4s.Task.instantiateCommand(Task.scala:108); 	at cromwell.backend.wdl.Command$$anonfun$instantiate$1.apply(Command.scala:28); 	at cromwell.backend.wdl.Command$$anonfun$instantiate$1.apply(Command.scala:27); 	at scala.util.Success.flatMap(Try.scala:231); 	at cromwell.backend.wdl.Command$.instantiate(Command.scala:27); 	at cromwell.backend.standard.StandardAsyncExecutionActor$class.instantiatedCommand(StandardAsyncExecutionActor.scala:80); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.instantiatedCommand$lzycompute(ConfigAsyncJobExecutionActor.scala:113); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.instantiatedCommand(ConfigAsyncJobExecutionActor.scala:113); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor$class.execute(SharedFileSystemAsyncJobExecutionActor.scala:130); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.execute(ConfigAsyncJobExecutionActor.scala:113); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$executeOrRecover$2.apply(StandardAsyncExecutionActor.scala:264); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$executeOrRecover$2.apply(StandardAsyncExecutionActor.scala:258); 	at scala.util.Try$.apply(Try.scala:192); 	at cromwell.backend.standard.StandardAsyncExecutionActor$class.executeOrRecover(StandardAsyncExecutionActor.scala:258); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecuti,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1944:3448,config,config,3448,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1944,2,['config'],['config']
Modifiability,".com/broadinstitute/cromwell/blob/a333f65b8e80ae37091a5629e0331c2105aeefeb/supportedBackends/google/batch/src/main/scala/cromwell/backend/google/batch/api/request/GcpBatchGroupedRequests.scala) are covered by [GcpBatchGroupedRequestsSpec](https://github.com/broadinstitute/cromwell/blob/a333f65b8e80ae37091a5629e0331c2105aeefeb/supportedBackends/google/batch/src/test/scala/cromwell/backend/google/batch/api/request/GcpBatchGroupedRequestsSpec.scala); 3. Should we set [GcpBatchAsyncBackendJobExecutionActor#requestsAbortAndDiesImmediately](https://github.com/broadinstitute/cromwell/blob/a333f65b8e80ae37091a5629e0331c2105aeefeb/supportedBackends/google/batch/src/main/scala/cromwell/backend/google/batch/actors/GcpBatchAsyncBackendJobExecutionActor.scala#L220) to `false`? this is set by PAPI but it causes a centaur test to fail.; 4. While this is inherited from PAPI, I think we need to change the behavior but I'd like to get a 2nd option, increasing `request-workers` also increases the worker's delay to pull work, for example, setting this value to `100` or above causes would cause the delay to become ~18m which seems insane (see [BatchApiRequestManager.scala](https://github.com/broadinstitute/cromwell/blob/cee36d98755d2163f279600786bd60d6226835f0/supportedBackends/google/batch/src/main/scala/cromwell/backend/google/batch/api/BatchApiRequestManager.scala#L67)), putting an upper limit on the delay seems worth it, any thoughts?; 5. Do we need to get anything else for the job execution events? see below and [BatchRequestExecutor#getEventList](https://github.com/broadinstitute/cromwell/blob/a333f65b8e80ae37091a5629e0331c2105aeefeb/supportedBackends/google/batch/src/main/scala/cromwell/backend/google/batch/api/request/BatchRequestExecutor.scala#L196). <details>; <summary>Execution events details</summary>. What GCP provides:. ```; Event type=STATUS_CHANGED; time=seconds: 1712173852,nanos: 952604950; taskState=STATE_UNSPECIFIED,; description=Job state is set from QUEUED to SCHEDU",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7412:2861,inherit,inherited,2861,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7412,1,['inherit'],['inherited']
Modifiability,".conf: java.io.IOException: resource not found on classpath: application.conf, application.json: java.io.IOException: resource not found on classpath: application.json, application.properties: java.io.IOException: resource not found on classpath: application.properties; at com.typesafe.config.impl.SimpleIncluder.fromBasename(SimpleIncluder.java:236); at com.typesafe.config.impl.ConfigImpl.parseResourcesAnySyntax(ConfigImpl.java:133); at com.typesafe.config.ConfigFactory.parseResourcesAnySyntax(ConfigFactory.java:1083); at com.typesafe.config.impl.SimpleIncluder.includeResourceWithoutFallback(SimpleIncluder.java:123); at com.typesafe.config.impl.SimpleIncluder.includeResources(SimpleIncluder.java:109); at com.typesafe.config.impl.ConfigParser$ParseContext.parseInclude(ConfigParser.java:181); at com.typesafe.config.impl.ConfigParser$ParseContext.parseObject(ConfigParser.java:237); at com.typesafe.config.impl.ConfigParser$ParseContext.parseValue(ConfigParser.java:103); at com.typesafe.config.impl.ConfigParser$ParseContext.parse(ConfigParser.java:415); at com.typesafe.config.impl.ConfigParser.parse(ConfigParser.java:25); at com.typesafe.config.impl.Parseable.rawParseValue(Parseable.java:263); at com.typesafe.config.impl.Parseable.rawParseValue(Parseable.java:250); at com.typesafe.config.impl.Parseable.parseValue(Parseable.java:180); at com.typesafe.config.impl.Parseable.parseValue(Parseable.java:174); at com.typesafe.config.impl.Parseable.parse(Parseable.java:301); at com.typesafe.config.ConfigFactory.parseFile(ConfigFactory.java:793); at com.typesafe.config.ConfigFactory.parseApplicationReplacement(ConfigFactory.java:1166); at com.typesafe.config.DefaultConfigLoadingStrategy.parseApplicationConfig(DefaultConfigLoadingStrategy.java:11); at com.typesafe.config.ConfigFactory.defaultApplication(ConfigFactory.java:532); at com.typesafe.config.ConfigFactory$1.call(ConfigFactory.java:264); at com.typesafe.config.ConfigFactory$1.call(ConfigFactory.java:261); at com.typesafe.con",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7255:1783,config,config,1783,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7255,1,['config'],['config']
Modifiability,.config.DispatchedConfigAsyncJobExecutionActor.instantiatedCommand$lzycompute(ConfigAsyncJobExecutionActor.scala:208); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.instantiatedCommand(ConfigAsyncJobExecutionActor.scala:208); at cromwell.backend.standard.StandardAsyncExecutionActor.commandScriptContents(StandardAsyncExecutionActor.scala:265); at cromwell.backend.standard.StandardAsyncExecutionActor.commandScriptContents$(StandardAsyncExecutionActor.scala:264); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.commandScriptContents(ConfigAsyncJobExecutionActor.scala:208); at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.writeScriptContents(SharedFileSystemAsyncJobExecutionActor.scala:141); at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.writeScriptContents$(SharedFileSystemAsyncJobExecutionActor.scala:140); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.writeScriptContents(ConfigAsyncJobExecutionActor.scala:208); at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.execute(SharedFileSystemAsyncJobExecutionActor.scala:124); at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.execute$(SharedFileSystemAsyncJobExecutionActor.scala:121); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.execute(ConfigAsyncJobExecutionActor.scala:208); at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$executeAsync$1(StandardAsyncExecutionActor.scala:599); at scala.util.Try$.apply(Try.scala:209); at cromwell.backend.standard.StandardAsyncExecutionActor.executeAsync(StandardAsyncExecutionActor.scala:599); at cromwell.backend.standard.StandardAsyncExecutionActor.executeAsync$(StandardAsyncExecutionActor.scala:599); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.executeAsync(ConfigAsyncJobExecutionActor.scala:208); at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover(StandardA,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3927:2279,Config,ConfigAsyncJobExecutionActor,2279,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3927,1,['Config'],['ConfigAsyncJobExecutionActor']
Modifiability,".exec(Mailbox.scala:234); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); [2018-03-09 15:52:58,29] [error] Failed to properly flush metadata to database; java.sql.SQLException: java.lang.OutOfMemoryError: Java heap space; 	at org.hsqldb.jdbc.JDBCUtil.sqlException(Unknown Source); 	at org.hsqldb.jdbc.JDBCUtil.sqlException(Unknown Source); 	at org.hsqldb.jdbc.JDBCPreparedStatement.addBatch(Unknown Source); 	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.addBatch(HikariProxyPreparedStatement.java); 	at slick.jdbc.JdbcActionComponent$InsertActionComposerImpl$MultiInsertAction.$anonfun$run$15(JdbcActionComponent.scala:531); 	at slick.jdbc.JdbcActionComponent$InsertActionComposerImpl$MultiInsertAction.$anonfun$run$15$adapted(JdbcActionComponent.scala:529); 	at scala.collection.Iterator.foreach(Iterator.scala:929); 	at scala.collection.Iterator.foreach$(Iterator.scala:929); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1417); 	at scala.collection.IterableLike.foreach(IterableLike.scala:71); 	at scala.collection.IterableLike.foreach$(IterableLike.scala:70); 	at scala.collection.AbstractIterable.foreach(Iterable.scala:54); 	at slick.jdbc.JdbcActionComponent$InsertActionComposerImpl$MultiInsertAction.$anonfun$run$14(JdbcActionComponent.scala:529); 	at slick.jdbc.JdbcBackend$SessionDef.withPreparedStatement(JdbcBackend.scala:372); 	at slick.jdbc.JdbcBackend$SessionDef.withPreparedStatement$(JdbcBackend.scala:367); 	at slick.jdbc.JdbcBackend$BaseSession.withPreparedStatement(JdbcBackend.scala:434); 	at slick.jdbc.JdbcActionComponent$InsertActionComposerImpl.preparedInsert(JdbcActionComponent.scala:502); 	at slick.jdbc.JdbcActionComponent$InsertActionComposerImpl$MultiInsertAction.run(JdbcActionC",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3387:11773,adapt,adapted,11773,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3387,1,['adapt'],['adapted']
Modifiability,.execute(ProxyPreparedStatement.java:44); 	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.execute(HikariProxyPreparedStatement.java); 	at slick.jdbc.StatementInvoker.results(StatementInvoker.scala:38); 	at slick.jdbc.StatementInvoker.iteratorTo(StatementInvoker.scala:21); 	at slick.jdbc.Invoker.foreach(Invoker.scala:47); 	at slick.jdbc.Invoker.foreach$(Invoker.scala:46); 	at slick.jdbc.StatementInvoker.foreach(StatementInvoker.scala:15); 	at slick.jdbc.StreamingInvokerAction.run(StreamingInvokerAction.scala:22); 	at slick.jdbc.StreamingInvokerAction.run$(StreamingInvokerAction.scala:20); 	at slick.jdbc.JdbcActionComponent$QueryActionExtensionMethodsImpl$$anon$1.run(JdbcActionComponent.scala:216); 	at slick.jdbc.JdbcActionComponent$QueryActionExtensionMethodsImpl$$anon$1.run(JdbcActionComponent.scala:216); 	at slick.dbio.SynchronousDatabaseAction$FusedAndThenAction.$anonfun$run$4(DBIOAction.scala:533); 	at slick.dbio.SynchronousDatabaseAction$FusedAndThenAction.$anonfun$run$4$adapted(DBIOAction.scala:533); 	at scala.collection.Iterator.foreach(Iterator.scala:944); 	at scala.collection.Iterator.foreach$(Iterator.scala:944); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1432); 	at scala.collection.IterableLike.foreach(IterableLike.scala:71); 	at scala.collection.IterableLike.foreach$(IterableLike.scala:70); 	at scala.collection.AbstractIterable.foreach(Iterable.scala:54); 	at slick.dbio.SynchronousDatabaseAction$FusedAndThenAction.run(DBIOAction.scala:533); 	at slick.dbio.SynchronousDatabaseAction$$anon$11.run(DBIOAction.scala:570); 	at slick.dbio.SynchronousDatabaseAction$$anon$6.run(DBIOAction.scala:469); 	at slick.dbio.SynchronousDatabaseAction$$anon$10.run(DBIOAction.scala:561); 	at slick.dbio.SynchronousDatabaseAction$$anon$7.run(DBIOAction.scala:486); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:275); 	at java.util.concurrent.T,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5084:5480,adapt,adapted,5480,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5084,1,['adapt'],['adapted']
Modifiability,.google.cloud.storage.StorageException: 503 Service Unavailable; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:189); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:335); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:191); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:188); 	at com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:94); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:54); 	at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:188); 	at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:202); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.readAttributes(CloudStorageFileSystemProvider.java:579); 	at java.nio.file.Files.readAttributes(Files.java:1737); 	at java.nio.file.Files.size(Files.java:2332); 	at better.files.File.$anonfun$size$1(File.scala:502); 	at better.files.File.$anonfun$size$1$adapted(File.scala:502); 	at scala.collection.Iterator$$anon$10.next(Iterator.scala:448); 	at scala.collection.Iterator.foreach(Iterator.scala:929); 	at scala.collection.Iterator.foreach$(Iterator.scala:929); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1417); 	at scala.collection.TraversableOnce.foldLeft(TraversableOnce.scala:157); 	at scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:155); 	at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1417); 	at scala.collection.TraversableOnce.sum(TraversableOnce.scala:216); 	at scala.collection.TraversableOnce.sum$(TraversableOnce.scala:216); 	at scala.collection.AbstractIterator.sum(Iterator.scala:1417); 	at better.files.File.size(File.scala:502); 	at cromwell.core.path.BetterFileMethods.size(BetterFileMethods.scala:323); 	at cromwell.core.path.BetterFileMethods.size$(BetterFileMethods.scala:323); 	at cromwell.filesystems.gcs.GcsPath.size(GcsPathBuilder.scala:179); 	at cromwell.backend.wdl.ReadLikeFu,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2576:4964,adapt,adapted,4964,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2576,1,['adapt'],['adapted']
Modifiability,".java:150); 	at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:113); 	at com.google.api.client.googleapis.services.json.AbstractGoogleJsonClientRequest.newExceptionOnError(AbstractGoogleJsonClientRequest.java:40); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:555); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.executeUnparsed(AbstractGoogleClientRequest.java:475); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.execute(AbstractGoogleClientRequest.java:592); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.create(HttpStorageRpc.java:305); 	... 22 common frames omitted; [2020-07-27 18:34:01,11] [info] WorkflowManagerActor Workflow 3d2d7a27-7c37-42c7-8c96-de7efef896e3 failed (during ExecutingWorkflowState): cromwell.engine.io.IoAttempts$EnhancedCromwellIoException: [Attempted 1 time(s)] - StorageException: xxx@xxx.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project.; Caused by: com.google.cloud.storage.StorageException: xxx@xxx.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project.; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:227); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.create(HttpStorageRpc.java:308); 	at com.google.cloud.storage.StorageImpl$3.call(StorageImpl.java:213); 	at com.google.cloud.storage.StorageImpl$3.call(StorageImpl.java:210); 	at com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:105); 	at com.google.cloud.RetryHelper.run(RetryHelper.java:76); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:50); 	at com.google.cloud.storage.StorageImpl.internalCreate(StorageImpl.java:209); 	at com.google.cloud.storage.StorageImpl.create(StorageImpl.java:171); 	at",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5594:4746,Enhance,EnhancedCromwellIoException,4746,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5594,1,['Enhance'],['EnhancedCromwellIoException']
Modifiability,.java:197); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseKey(ConfigDocumentParser.java:279); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseObject(ConfigDocumentParser.java:450); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseValue(ConfigDocumentParser.java:247); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseObject(ConfigDocumentParser.java:458); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parse(ConfigDocumentParser.java:648); 	at com.typesafe.config.impl.ConfigDocumentParser.parse(ConfigDocumentParser.java:14); 	at com.typesafe.config.impl.Parseable.rawParseValue(Parseable.java:260); 	at com.typesafe.config.impl.Parseable.rawParseValue(Parseable.java:248); 	at com.typesafe.config.impl.Parseable.parseValue(Parseable.java:180); 	at com.typesafe.config.impl.Parseable.parseValue(Parseable.java:174); 	at com.typesafe.config.impl.Parseable.parse(Parseable.java:299); 	at com.typesafe.config.ConfigFactory.parseFile(ConfigFactory.java:689); 	at com.typesafe.config.DefaultConfigLoadingStrategy.parseApplicationConfig(DefaultConfigLoadingStrategy.java:51); 	at com.typesafe.config.ConfigFactory.defaultApplication(ConfigFactory.java:473); 	at com.typesafe.config.ConfigFactory$1.call(ConfigFactory.java:259); 	at com.typesafe.config.ConfigFactory$1.call(ConfigFactory.java:256); 	at com.typesafe.config.impl.ConfigImpl$LoaderCache.getOrElseUpdate(ConfigImpl.java:65); 	at com.typesafe.config.impl.ConfigImpl.computeCachedConfig(ConfigImpl.java:92); 	at com.typesafe.config.ConfigFactory.load(ConfigFactory.java:256); 	at com.typesafe.config.ConfigFactory.load(ConfigFactory.java:232); 	at cromwell.CromwellEntryPoint$.config$lzycompute(CromwellEntryPoint.scala:39); 	at cromwell.CromwellEntryPoint$.config(CromwellEntryPoint.scala:39); 	at cromwell.CromwellEntryPoint$.<init>(CromwellEntryPoint.scala:42); 	at cromwell.CromwellEntryPoint$.<clinit>(CromwellEntryPoint.scala); ```. In other w,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4549:2911,config,config,2911,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4549,1,['config'],['config']
Modifiability,.java:25); at com.typesafe.config.impl.Parseable.rawParseValue(Parseable.java:263); at com.typesafe.config.impl.Parseable.rawParseValue(Parseable.java:250); at com.typesafe.config.impl.Parseable.parseValue(Parseable.java:180); at com.typesafe.config.impl.Parseable.parseValue(Parseable.java:174); at com.typesafe.config.impl.Parseable.parse(Parseable.java:301); at com.typesafe.config.ConfigFactory.parseFile(ConfigFactory.java:793); at com.typesafe.config.ConfigFactory.parseApplicationReplacement(ConfigFactory.java:1166); at com.typesafe.config.DefaultConfigLoadingStrategy.parseApplicationConfig(DefaultConfigLoadingStrategy.java:11); at com.typesafe.config.ConfigFactory.defaultApplication(ConfigFactory.java:532); at com.typesafe.config.ConfigFactory$1.call(ConfigFactory.java:264); at com.typesafe.config.ConfigFactory$1.call(ConfigFactory.java:261); at com.typesafe.config.impl.ConfigImpl$LoaderCache.getOrElseUpdate(ConfigImpl.java:66); at com.typesafe.config.impl.ConfigImpl.computeCachedConfig(ConfigImpl.java:93); at com.typesafe.config.ConfigFactory.load(ConfigFactory.java:261); at com.typesafe.config.ConfigFactory.load(ConfigFactory.java:237); at cromwell.languages.util.ImportResolver$HttpResolver$.apply(ImportResolver.scala:237); at womtool.input.WomGraphMaker$.importResolvers$lzycompute$1(WomGraphMaker.scala:28); at womtool.input.WomGraphMaker$.importResolvers$1(WomGraphMaker.scala:27); at womtool.input.WomGraphMaker$.$anonfun$getBundleAndFactory$1(WomGraphMaker.scala:39); at scala.util.Either.flatMap(Either.scala:352); at womtool.input.WomGraphMaker$.getBundleAndFactory(WomGraphMaker.scala:30); at womtool.input.WomGraphMaker$.fromFiles(WomGraphMaker.scala:46); at womtool.validate.Validate$.validate(Validate.scala:26); at womtool.WomtoolMain$.dispatchCommand(WomtoolMain.scala:54); at womtool.WomtoolMain$.runWomtool(WomtoolMain.scala:161); at womtool.WomtoolMain$.delayedEndpoint$womtool$WomtoolMain$1(WomtoolMain.scala:166); at womtool.WomtoolMain$delayedInit$body.appl,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7255:2915,Config,ConfigImpl,2915,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7255,1,['Config'],['ConfigImpl']
Modifiability,.java:263); at com.typesafe.config.impl.Parseable.rawParseValue(Parseable.java:250); at com.typesafe.config.impl.Parseable.parseValue(Parseable.java:180); at com.typesafe.config.impl.Parseable.parseValue(Parseable.java:174); at com.typesafe.config.impl.Parseable.parse(Parseable.java:301); at com.typesafe.config.ConfigFactory.parseFile(ConfigFactory.java:793); at com.typesafe.config.ConfigFactory.parseApplicationReplacement(ConfigFactory.java:1166); at com.typesafe.config.DefaultConfigLoadingStrategy.parseApplicationConfig(DefaultConfigLoadingStrategy.java:11); at com.typesafe.config.ConfigFactory.defaultApplication(ConfigFactory.java:532); at com.typesafe.config.ConfigFactory$1.call(ConfigFactory.java:264); at com.typesafe.config.ConfigFactory$1.call(ConfigFactory.java:261); at com.typesafe.config.impl.ConfigImpl$LoaderCache.getOrElseUpdate(ConfigImpl.java:66); at com.typesafe.config.impl.ConfigImpl.computeCachedConfig(ConfigImpl.java:93); at com.typesafe.config.ConfigFactory.load(ConfigFactory.java:261); at com.typesafe.config.ConfigFactory.load(ConfigFactory.java:237); at cromwell.languages.util.ImportResolver$HttpResolver$.apply(ImportResolver.scala:237); at womtool.input.WomGraphMaker$.importResolvers$lzycompute$1(WomGraphMaker.scala:28); at womtool.input.WomGraphMaker$.importResolvers$1(WomGraphMaker.scala:27); at womtool.input.WomGraphMaker$.$anonfun$getBundleAndFactory$1(WomGraphMaker.scala:39); at scala.util.Either.flatMap(Either.scala:352); at womtool.input.WomGraphMaker$.getBundleAndFactory(WomGraphMaker.scala:30); at womtool.input.WomGraphMaker$.fromFiles(WomGraphMaker.scala:46); at womtool.validate.Validate$.validate(Validate.scala:26); at womtool.WomtoolMain$.dispatchCommand(WomtoolMain.scala:54); at womtool.WomtoolMain$.runWomtool(WomtoolMain.scala:161); at womtool.WomtoolMain$.delayedEndpoint$womtool$WomtoolMain$1(WomtoolMain.scala:166); at womtool.WomtoolMain$delayedInit$body.apply(WomtoolMain.scala:27); at scala.Function0.apply$mcV$sp(Function0.scala,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7255:2978,Config,ConfigFactory,2978,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7255,1,['Config'],['ConfigFactory']
Modifiability,.map(Traversable.scala:104) ~[cromwell.jar:0.19];   at cromwell.engine.db.slick.SlickDataAccess$$anonfun$46.apply(SlickDataAccess.scala:569) ~[cromwell.jar:0.19];   at cromwell.engine.db.slick.SlickDataAccess$$anonfun$46.apply(SlickDataAccess.scala:568) ~[cromwell.jar:0.19];   at slick.backend.DatabaseComponent$DatabaseDef$$anonfun$runInContext$1.apply(DatabaseComponent.scala:146) ~[cromwell.jar:0.19];   at slick.backend.DatabaseComponent$DatabaseDef$$anonfun$runInContext$1.apply(DatabaseComponent.scala:146) ~[cromwell.jar:0.19];   at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:251) ~[cromwell.jar:0.19];   at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:249) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable.run_aroundBody0(Promise.scala:32) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable$AjcClosure1.run(Promise.scala:1) ~[cromwell.jar:0.19];   at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation$$anonfun$aroundExecution$1.apply(FutureInstrumentation.scala:44) ~[cromwell.jar:0.19];   at kamon.trace.Tracer$.withContext(TracerModule.scala:53) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation.aroundExecution(FutureInstrumentation.scala:43) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:31) ~[cromwell.jar:0.19];   at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121) ~[cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/810:6233,Adapt,AdaptedForkJoinTask,6233,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/810,1,['Adapt'],['AdaptedForkJoinTask']
Modifiability,".py) \; ${write_tsv(fastqs)} \; --adapters ${write_tsv(adapters)} \; ${if paired_end then ""--paired-end"" else """"} \; ${if select_first([auto_detect_adapter,false]) then ""--auto-detect-adapter"" else """"} \; ${""--min-trim-len "" + select_first([min_trim_len,5])} \; ${""--err-rate "" + select_first([err_rate,'0.1'])} \; ${""--nth "" + select_first([cpu,2])}; }; output {; # WDL glob() globs in an alphabetical order; # so R1 and R2 can be switched, which results in an; # unexpected behavior of a workflow; # so we prepend merge_fastqs_'end'_ (R1 or R2); # to the basename of original filename; # this prefix will be later stripped in bowtie2 task; Array[File] trimmed_merged_fastqs = glob(""merge_fastqs_R?_*.fastq.gz""); }; runtime {; cpu : select_first([cpu,2]); memory : ""${select_first([mem_mb,'12000'])} MB""; time : select_first([time_hr,24]); disks : select_first([disks,""local-disk 100 HDD""]); }; }; ```. My backend.conf :; ```; include required(classpath(""application"")). backend {; default=""SGE""; providers {; SGE {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; concurrent-job-limit = 10000; runtime-attributes= """"""; Int? cpu=1; Int? memory=4; String? disks; String? time; String? preemptible; """"""; submit = """"""; qsub \; -terse \; -V \; -b n \; -wd ${cwd} \; -N ${job_name} \; ${'-pe smp ' + cpu} \; ${'-l h_vmem=' + memory + ""G""} \; -o ${out} \; -e ${err} \; ${script}; """"""; kill = ""qdel ${job_id}""; check-alive = ""qstat -j ${job_id}""; job-id-regex = ""(\\d+)"". filesystems {; local {; localization: [; ""soft-link"",""copy"",""hard-link""; ]; caching {; duplication-strategy: [ ""soft-link"",""copy"",""hard-link""]; hashing-strategy: ""file""; }; }; }; }; }; }; }; engine{; filesystems{; local{; localization: [; ""soft-link"",""copy"",""hard-link""; ]; caching {; duplication-strategy: [ ""soft-link"",""copy"",""hard-link""]; hashing-strategy: ""file""; }; }; }; }; ```. I wonder if there is something wrong with my config files or if Cromwell's localization is at fault.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3876:4141,config,config,4141,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3876,4,"['Config', 'config']","['ConfigBackendLifecycleActorFactory', 'config']"
Modifiability,".scala:12); 	at scala.App.$anonfun$main$1$adapted(App.scala:76); 	at scala.collection.immutable.List.foreach(List.scala:389); 	at scala.App.main(App.scala:76); 	at scala.App.main$(App.scala:74); 	at cromwell.CromwellApp$.main(CromwellApp.scala:3); 	at cromwell.CromwellApp.main(CromwellApp.scala); Caused by: com.typesafe.config.ConfigException$Parse: /data/cephfs/punim0751/spartan.conf: 27: expecting a close parentheses ')' here, not: end of file; 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseError(ConfigDocumentParser.java:201); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseError(ConfigDocumentParser.java:197); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseKey(ConfigDocumentParser.java:279); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseObject(ConfigDocumentParser.java:450); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseValue(ConfigDocumentParser.java:247); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseObject(ConfigDocumentParser.java:458); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parse(ConfigDocumentParser.java:648); 	at com.typesafe.config.impl.ConfigDocumentParser.parse(ConfigDocumentParser.java:14); 	at com.typesafe.config.impl.Parseable.rawParseValue(Parseable.java:260); 	at com.typesafe.config.impl.Parseable.rawParseValue(Parseable.java:248); 	at com.typesafe.config.impl.Parseable.parseValue(Parseable.java:180); 	at com.typesafe.config.impl.Parseable.parseValue(Parseable.java:174); 	at com.typesafe.config.impl.Parseable.parse(Parseable.java:299); 	at com.typesafe.config.ConfigFactory.parseFile(ConfigFactory.java:689); 	at com.typesafe.config.DefaultConfigLoadingStrategy.parseApplicationConfig(DefaultConfigLoadingStrategy.java:51); 	at com.typesafe.config.ConfigFactory.defaultApplication(ConfigFactory.java:473); 	at com.typesafe.config.ConfigFactory$1.call(ConfigFactory.java:259); 	at com.typesafe.config.Config",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4549:2260,config,config,2260,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4549,1,['config'],['config']
Modifiability,".sfs.config.ConfigBackendLifecycleActorFactory""; config {; concurrent-job-limit = 10; run-in-background = true; root = ""cromwell-executions""; dockerRoot = ""/cromwell-executions""; runtime-attributes = """"""; String? docker; """"""; submit = ""/usr/bin/env bash ${script}"". # We're asking bash-within-singularity to run the script, but the script's location on the machine; # is different then the location its mounted to in the container, so need to change the path with sed; submit-docker = """"""; singularity exec --containall --bind ${cwd}:${docker_cwd} docker://${docker} bash \; ""$(echo ${script} | sed -e 's@.*cromwell-executions@/cromwell-executions@')""; """"""; filesystems {; local {; localization: [""hard-link""]; caching {; duplication-strategy: [""hard-link""]; hasing-strategy: ""fingerprint""; check-sibling-md5: true; fingerprint-size: 1048576 # 1 MB ; }; }; }; }; }; # For running jobs by submitting them from an interactive node to the cluster; SLURM {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; concurrent-job-limit = 500; root = ""cromwell-executions""; dockerRoot = ""/cromwell-executions"". runtime-attributes = """"""; Int cpus = 1; String mem = ""2g""; String dx_timeout; String? docker; """"""; check-alive = ""squeue -j ${job_id}""; exit-code-timeout-seconds = 500; job-id-regex = ""Submitted batch job (\\d+).*"". submit = """"""; sbatch \; --partition ind-shared \; --nodes 1 \; --job-name=${job_name} \; -o ${out} -e ${err} \; --ntasks-per-node=${cpus} \; --mem=${mem} \; -c ${cpus} \; --time=$(echo ${dx_timeout} | sed -e 's/ //g' -e 's/\([0-9]\+\)h\([0-9]\+\)m/\1:\2:00/' -e 's/\([0-9]\+\)h/\1:00:00/' -e 's/\([0-9]\+\)m/\1:00/') \; --chdir ${cwd} \; --wrap ""/bin/bash ${script}""; """"""; kill = ""scancel ${job_id}"". # We're asking bash-within-singularity to run the script, but the script's location on the machine; # is different then the location its mounted to in the container, so need to change the path with sed; submit-docker = """"""; sbatch \; --pa",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7108:5131,config,config,5131,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7108,1,['config'],['config']
Modifiability,"/257) and associated cromwell PRs. But if the uninitialized optional declaration on [this line](https://github.com/broadinstitute/centaur/pull/242/files#diff-cc04c14d68a6a1a6d8d8366fc0c2f88cR48) is uncommented, the workflow fails. (Deliberately not quoting since lines don't wrap and anyway the thumbs downs are apropos). 2017-11-14 18:00:05,062 cromwell-system-akka.dispatchers.engine-dispatcher-33 INFO - Retrieved 1 workflows from the WorkflowStoreActor; 2017-11-14 18:00:05,093 cromwell-system-akka.dispatchers.engine-dispatcher-33 INFO - MaterializeWorkflowDescriptorActor [UUID(4b725606)]: Call-to-Backend assignments: decls.sub_decls.second_task -> Local, decls.sub_decls.first_task -> Local; 2017-11-14 18:00:06,129 cromwell-system-akka.dispatchers.engine-dispatcher-26 INFO - WorkflowExecutionActor-4b725606-6d2a-4cf2-b23b-e5971f52b7dd [UUID(4b725606)]: Starting calls: SubWorkflow-sudecls:-1:1; 2017-11-14 18:00:06,130 cromwell-system-akka.actor.default-dispatcher-50 INFO - Message [cromwell.subworkflowstore.SubWorkflowStoreActor$SubWorkflowStoreRegisterSuccess] from Actor[akka://cromwell-system/user/cromwell-service/SubWorkflowStoreActor#-388497585] to Actor[akka://cromwell-system/user/cromwell-service/WorkflowManagerActor/WorkflowActor-4b725606-6d2a-4cf2-b23b-e5971f52b7dd/WorkflowExecutionActor-4b725606-6d2a-4cf2-b23b-e5971f52b7dd/SubWorkflowExecutionActor-SubWorkflow-sudecls:-1:1#-1890869436] was not delivered. [5] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; 2017-11-14 18:00:06,132 cromwell-system-akka.dispatchers.engine-dispatcher-27 ERROR - WorkflowManagerActor Workflow 4b725606-6d2a-4cf2-b23b-e5971f52b7dd failed (during ExecutingWorkflowState): ; 2017-11-14 18:00:06,133 cromwell-system-akka.dispatchers.engine-dispatcher-27 INFO - WorkflowManagerActor WorkflowActor-4b725606-6d2a-4cf2-b23b-e5971f52b7dd is in a terminal state: WorkflowFailedState",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2902:2117,config,configuration,2117,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2902,1,['config'],['configuration']
Modifiability,/SM-612V6.bam:; gs://broad-dsde-methods/takuto/na12878-crsp-ice/SM-612V6.bam doesn't exists; null; 500 Internal Server Error; Backend Error; 500 Internal Server Error; Backend Error; at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$commandLinePreProcessor$1$$anonfun$apply$1.applyOrElse(StandardAsyncExecutionActor.scala:106); at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$commandLinePreProcessor$1$$anonfun$apply$1.applyOrElse(StandardAsyncExecutionActor.scala:105); at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:36); at scala.util.Failure.recoverWith(Try.scala:203); at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$commandLinePreProcessor$1.apply(StandardAsyncExecutionActor.scala:105); at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$commandLinePreProcessor$1.apply(StandardAsyncExecutionActor.scala:105); at cromwell.backend.wdl.Command$.instantiate(Command.scala:27); at cromwell.backend.standard.StandardAsyncExecutionActor$class.instantiatedCommand(StandardAsyncExecutionActor.scala:198); at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.instantiatedCommand$lzycompute(ConfigAsyncJobExecutionActor.scala:107); at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.instantiatedCommand(ConfigAsyncJobExecutionActor.scala:107); at cromwell.backend.standard.StandardAsyncExecutionActor$class.commandScriptContents(StandardAsyncExecutionActor.scala:170); at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.commandScriptContents(ConfigAsyncJobExecutionActor.scala:107); at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor$class.writeScriptContents(SharedFileSystemAsyncJobExecutionActor.scala:136); at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.cromwell$backend$sfs$BackgroundAsyncJobExecutionActor$$super$writeScriptContents(ConfigAsyncJobExecutionActor.scala:107); ....snip....; ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2011:2845,config,config,2845,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2011,8,"['Config', 'config']","['ConfigAsyncJobExecutionActor', 'config']"
Modifiability,"/WorkflowManagerActor/WorkflowActor-814c47aa-9d11-4c81-a08c-f2b77c002b46#617869376] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2017-01-20 09:33:07,58] [error] WorkflowManagerActor Workflow 814c47aa-9d11-4c81-a08c-f2b77c002b46 failed (during ExecutingWorkflowState): Call aggregate_mafs_workflow.aggregate_mafs:NA:1: return code was 1; java.lang.RuntimeException: Call aggregate_mafs_workflow.aggregate_mafs:NA:1: return code was 1; 	at cromwell.backend.standard.StandardAsyncExecutionActor$class.handleExecutionResult(StandardAsyncExecutionActor.scala:432); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.handleExecutionResult(ConfigAsyncJobExecutionActor.scala:113); 	at cromwell.backend.standard.StandardAsyncExecutionActor$class.handlePollSuccess(StandardAsyncExecutionActor.scala:370); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.handlePollSuccess(ConfigAsyncJobExecutionActor.scala:113); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$poll$2.apply(StandardAsyncExecutionActor.scala:333); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$poll$2.apply(StandardAsyncExecutionActor.scala:332); 	at scala.util.Success$$anonfun$map$1.apply(Try.scala:237); 	at scala.util.Try$.apply(Try.scala:192); 	at scala.util.Success.map(Try.scala:237); 	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237); 	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237); 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); 	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); 	at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:91); 	at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); 	at akka.dispatch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1906:13740,config,config,13740,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1906,1,['config'],['config']
Modifiability,"/` in strings inconsistently. In some cases, it is dropped without throwing an error, in other cases it will cause an error immediately. If the string is in the WDL file itself, womtool does not detect any issues with it but it will not be handled as expected as runtime. ## use case and how to reproduce; [goleft indexcov ](https://github.com/brentp/goleft/tree/master/indexcov#indexcov) defaults to this value for --excludePattern:; `""^chrEBV$|_random$|Un_|^HLA|_alt$|hap$""`. So I set `String excludePattern = ""^chrEBV$|_random$|Un_|^HLA|_alt$|hap$""` in my WDL. That passes miniwdl check and womtool. But... * Terra will accept `^chrEBV$|^NC|_random$|Un_|^HLA\-|_alt$|hap\d$ `as a variable default or as hardcoded variable, but will handle it incorrectly -- it will not error, but it will be changed into `^chrEBV$|^NC|_random$|Un_|^HLA-|_alt$|hapd$`; * Terra will not accept `^chrEBV$|^NC|_random$|Un_|^HLA\-|_alt$|hap\d$` as an input variable via JSON; it will fail to import; * Terra will not accept `^chrEBV$|^NC|_random$|Un_|^HLA\-|_alt$|hap\d$` as an input variable if entered manually; it will throw token recognition error in the workflow menu and not allow you to submit; * Terra will accept the escaped version `^chrEBV$|^NC|_random$|Un_|^HLA\\-|_alt$|hap\\d$` as an input if entered manually or hardcoded, and will interpret it as `^chrEBV$|^NC|_random$|Un_|^HLA\-|_alt$|hap\d$`. Only tested via Terra-Cromwell, as I was previously told local-Cromwell is a lower development priority. ## expected behavior; 1. A user inputting a string as a variable vs that exact same string being a hardcoded default should be handled the same way.; 2. If Cromwell is supposed to handle `/` by requiring they be escaped as `//`, that should be documented if it isn't already.; 3. womtool should throw a warning when it sees a hardcoded variable/default with a `/` inside of it, and that warning should guide the user as to how it will be interpreted at runtime.; 4. The same workflow running in Cromwell",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7167:797,variab,variable,797,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7167,4,['variab'],['variable']
Modifiability,/cromwell-system/user/SingleWorkflowRunnerActor] No configuration setting found for key 'services' ; akka.actor.ActorInitializationException: akka://cromwell-system/user/SingleWorkflowRunnerActor/ServiceRegistryActor: exception during creation ; at akka.actor.ActorInitializationException$.apply(Actor.scala:193) ; at akka.actor.ActorCell.create(ActorCell.scala:669) ; at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:523) ; at akka.actor.ActorCell.systemInvoke(ActorCell.scala:545) ; at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:283) ; at akka.dispatch.Mailbox.run(Mailbox.scala:224) ; at akka.dispatch.Mailbox.exec(Mailbox.scala:235) ; at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) ; at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) ; at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) ; at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) ; Caused by: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'services' ; at com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:156) ; at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:174) ; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:188) ; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:193) ; at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:268) ; at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:41) ; at cromwell.services.ServiceRegistryActor$.serviceNameToPropsMap(ServiceRegistryActor.scala:35) ; at cromwell.services.ServiceRegistryActor.serviceProps(ServiceRegistryActor.scala:63) ; at cromwell.services.ServiceRegistryActor.<init>(ServiceRegistryActor.scala:65) ; at cromwell.services.ServiceRegistryActor$.$anonfun$props$1(ServiceRegistryActor.scala:25) ; at akka.actor.TypedCreatorFunctionConsumer.produce(IndirectActorProducer.scala:87) ; at akka.actor.Props.newA,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4577:1391,config,config,1391,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4577,1,['config'],['config']
Modifiability,"/cromwell.readthedocs.io/en/stable/tutorials/PipelinesApi101/#lets-get-started) example is out of date. In `google.conf` it still lists the configuration for ""JES"" backend. 2) In the same tutorial ([Setting up PAPIv2](https://cromwell.readthedocs.io/en/stable/tutorials/PipelinesApi101/#setting-up-papiv2)), the instructions for which roles to assign to the GCP service account are outdated. 3) Once the user puzzles together which parts to replace, the execution is still failing (for me at least).; I run the following command ` java -Dconfig.file=cromwell.BROADexamples.v4.conf -jar cromwell-66.jar run hello.wdl -i hello.inputs`, which results in the following `Request contains an invalid argument.` error (abbreviated to the relevant section):; ```; [2021-08-13 10:44:39,31] [info] Running with database db.url = jdbc:hsqldb:mem: ...; ...; [2021-08-13 10:44:54,04] [info] Reference disks feature for PAPIv2 backend is not configured.; [2021-08-13 10:44:54,46] [info] Slf4jLogger started; [2021-08-13 10:44:54,73] [info] Workflow heartbeat configuration:; ...; [2021-08-13 10:44:55,42] [info] Running with 3 PAPI request workers; ...; [2021-08-13 10:44:55,79] [info] Unspecified type (Unspecified version) workflow a15c46b7-5f93-46d6-94a2-28f656914866 submitted; ...; [2021-08-13 10:44:56,46] [info] Request manager PAPIQueryManager created new PAPI request worker PAPIQueryWorker-58e6b395-916e-4ba4-965a-0ec8f1c0760d with batch interval of 3333 milliseconds; ...; [2021-08-13 10:44:56,67] [info] MaterializeWorkflowDescriptorActor [a15c46b7]: Parsing workflow as WDL draft-2; [2021-08-13 10:44:58,79] [info] MaterializeWorkflowDescriptorActor [a15c46b7]: Call-to-Backend assignments: wf_hello.hello -> PAPIv2; [2021-08-13 10:45:00,31] [info] Not triggering log of token queue status. Effective log interval = None; [2021-08-13 10:45:01,35] [info] WorkflowExecutionActor-a15c46b7-5f93-46d6-94a2-28f656914866 [a15c46b7]: Starting wf_hello.hello; [2021-08-13 10:45:02,34] [info] Assigned new job ex",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6469:1507,config,configuration,1507,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6469,1,['config'],['configuration']
Modifiability,"/home/jeremiah/gdc-dnaseq-cwl/tools/samtools_idxstats_to_sqlite.cwl; [2018-09-14 13:21:50,17] [info] Pre-Processing /home/jeremiah/gdc-dnaseq-cwl/tools/samtools_stats.cwl; [2018-09-14 13:21:50,38] [info] Pre-Processing /home/jeremiah/gdc-dnaseq-cwl/tools/samtools_stats_to_sqlite.cwl; [2018-09-14 13:21:50,46] [info] Pre-Processing /home/jeremiah/gdc-dnaseq-cwl/workflows/bamfastq_align/integrity.cwl; [2018-09-14 13:21:50,64] [info] Pre-Processing /home/jeremiah/gdc-dnaseq-cwl/tools/ls_l.cwl; [2018-09-14 13:21:50,71] [info] Pre-Processing /home/jeremiah/gdc-dnaseq-cwl/tools/md5sum.cwl; [2018-09-14 13:21:50,81] [info] Pre-Processing /home/jeremiah/gdc-dnaseq-cwl/tools/sha256sum.cwl; [2018-09-14 13:21:50,87] [info] Pre-Processing /home/jeremiah/gdc-dnaseq-cwl/tools/integrity_to_sqlite.cwl; [2018-09-14 13:21:51,02] [info] Pre Processing Inputs...; [2018-09-14 13:21:51,27] [info] Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-6d01716"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; [2018-09-14 13:21:51,38] [info] Metadata summary refreshing every 2 seconds.; [2018-09-14 13:21:51,44] [info] WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; [2018-09-14 13:21:51,45] [info] KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; [2018-09-14 13:21:51,51] [info] CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; [2018-09-14 13:21:52,32] [info] JobExecutionTokenDispenser - Distribution rate: 50 per 1 seconds.; [2018-09-14 13:21:52,35] [info] SingleWorkflowRunnerActor: Version 35-fd560e9-SNAP; [2018-09-14 13:21:52,36] [info] SingleWorkflowRunnerActor: Submitting workflow; [2018-09-14 13:21:52,42] [info] CWL (Unspecified version) workflow 6f311835-f1fe-4bbd-8fbb-c5543373d039 submitted; [2018-09-14 13:21:52,43] [info] SingleWorkflowRunnerActor: Workflow submitted 6f311835-f1fe-4bbd-8fbb-c5543373d039; [",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4103:19165,config,configuration,19165,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4103,1,['config'],['configuration']
Modifiability,"/sched_debug"",; ""/proc/scsi"",; ""/sys/firmware""; ],; ""ReadonlyPaths"": [; ""/proc/bus"",; ""/proc/fs"",; ""/proc/irq"",; ""/proc/sys"",; ""/proc/sysrq-trigger""; ]; },; ""GraphDriver"": {; ""Data"": {; ""LowerDir"": ""/var/lib/docker/overlay2/aa7c784c947752f9736d649c2f7f1d1ff992e94a295a7d8b3281eb18b60192f0-init/diff:/var/lib/docker/overlay2/pi10oyxckwgkkcbtbhtopthgo/diff:/var/lib/docker/overlay2/ijx4ivzmz9j7r2z9sqnxxkfr2/diff:/var/lib/docker/overlay2/jv5021rm0ro1ncxdxk9z7z4z2/diff:/var/lib/docker/overlay2/l7ti7s4rs2dxrvvlh4xry72fn/diff:/var/lib/docker/overlay2/0ecrq5dfyezvcc19ewmxvgohh/diff:/var/lib/docker/overlay2/vpue5u7q3ouhkmqlyrwbg5n75/diff:/var/lib/docker/overlay2/eh958b0fn0cjj2btiaxfhimxg/diff:/var/lib/docker/overlay2/luqo2vxej2gtqb1i70juiilf3/diff:/var/lib/docker/overlay2/jn9pv5erse0hvoixil8mb2h0k/diff:/var/lib/docker/overlay2/trwrj89a2zln5c2wh9ci255nm/diff:/var/lib/docker/overlay2/8a43205cbfc58e029de1e272d9f65a3ce190c2dd009321376f08b51b8784cf2e/diff"",; ""MergedDir"": ""/var/lib/docker/overlay2/aa7c784c947752f9736d649c2f7f1d1ff992e94a295a7d8b3281eb18b60192f0/merged"",; ""UpperDir"": ""/var/lib/docker/overlay2/aa7c784c947752f9736d649c2f7f1d1ff992e94a295a7d8b3281eb18b60192f0/diff"",; ""WorkDir"": ""/var/lib/docker/overlay2/aa7c784c947752f9736d649c2f7f1d1ff992e94a295a7d8b3281eb18b60192f0/work""; },; ""Name"": ""overlay2""; },; ""Mounts"": [; {; ""Type"": ""bind"",; ""Source"": ""/private/var/folders/vp/327wktbj3wqb65q3v3n8qpxc0000gn/T/1667969838761-0/dockstore-is-cool/IS_THIS_TUBERCULOSIS/7570b5dc-4714-48a7-96b2-9c62245e3618/call-get_organism_names/shard-885"",; ""Destination"": ""/bark-bark/IS_THIS_TUBERCULOSIS/7570b5dc-4714-48a7-96b2-9c62245e3618/call-get_organism_names/shard-885"",; ""Mode"": """",; ""RW"": true,; ""Propagation"": ""rprivate""; }; ],; ""Config"": {; ""Hostname"": ""cf6f4828adc6"",; ""Domainname"": """",; ""User"": """",; ""AttachStdin"": true,; ""AttachStdout"": true,; ""AttachStderr"": true,; ""Tty"": false,; ""OpenStdin"": true,; ""StdinOnce"": true,; ""Env"": [; ""PATH=/root/miniconda3/bin:/bin:/root/edirect/:/bin/sratoolkit.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6946:6673,Config,Config,6673,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6946,1,['Config'],['Config']
Modifiability,/sun.nio.fs.UnixPath.subpath(UnixPath.java:43); 	 at cromwell.core.path.NioPathMethods.subpath(NioPathMethods.scala:18); 	 at cromwell.core.path.NioPathMethods.subpath$(NioPathMethods.scala:18); 	 at cromwell.core.path.DefaultPath.subpath(DefaultPathBuilder.scala:55); 	 at cromwell.backend.io.JobPathsWithDocker.toDockerPath(JobPathsWithDocker.scala:56); 	 at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.$anonfun$mapCommandLineWomFile$1(SharedFileSystemAsyncJobExecutionActor.scala:147); 	 at wom.values.WomSingleFile.mapFile(WomFile.scala:201); 	 at wom.values.WomSingleFile.mapFile(WomFile.scala:182); 	 at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.mapCommandLineWomFile(SharedFileSystemAsyncJobExecutionActor.scala:145); 	 at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.mapCommandLineWomFile$(SharedFileSystemAsyncJobExecutionActor.scala:144); 	 at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.mapCommandLineWomFile(ConfigAsyncJobExecutionActor.scala:215); 	 at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$commandLineValueMapper$2(StandardAsyncExecutionActor.scala:206); 	 at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$mapOrNoResolve$1(StandardAsyncExecutionActor.scala:168); 	 at wom.WomFileMapper$.$anonfun$mapWomFiles$1(WomFileMapper.scala:24); 	 at scala.util.Try$.apply(Try.scala:213); 	 at wom.WomFileMapper$.mapWomFiles(WomFileMapper.scala:24); 	 at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$mapOrNoResolve$2(StandardAsyncExecutionActor.scala:163); 	 at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$commandLineValueMapper$1(StandardAsyncExecutionActor.scala:206); 	 at mouse.AnyOps$.$bar$greater$extension(any.scala:8); 	 at cromwell.backend.standard.StandardAsyncExecutionActor.localize$1(StandardAsyncExecutionActor.scala:474); 	 at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$runtimeEnvironmentPathMapper$2(Standa,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6757:3115,Config,ConfigAsyncJobExecutionActor,3115,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6757,1,['Config'],['ConfigAsyncJobExecutionActor']
Modifiability,"/www.sherlock.stanford.edu/), a HPC running SLURM. . I have this WDL job:; ```; workflow myWorkflow {; call myTask; }. task myTask {; command {; echo ""hello world""; }; output {; String out = read_string(stdout()); }; }; ```. When I try to run:; ```; > java -jar ~/cromwell/cromwell-48.jar run echoHello.wdl; [2020-01-28 18:31:30,49] [info] Running with database db.url = jdbc:hsqldb:mem:15405fc3-f9d1-4db3-a492-6b12dfb77913;shutdown=false;hsqldb.tx=mvcc; [2020-01-28 18:31:37,96] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2020-01-28 18:31:37,98] [info] [RenameWorkflowOptionsInMetadata] 100%; [2020-01-28 18:31:38,06] [info] Running with database db.url = jdbc:hsqldb:mem:804bf0c2-e198-491b-8dce-708650038640;shutdown=false;hsqldb.tx=mvcc; [2020-01-28 18:31:38,48] [info] Slf4jLogger started; [2020-01-28 18:31:38,67] [info] Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-4defb12"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""failureShutdownDuration"" : ""5 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; Uncaught error from thread [cromwell-system-akka.dispatchers.engine-dispatcher-4]: Uncaught error from thread [cromwell-system-akka.dispatchers.service-dispatcher-7]: unable to create new native thread, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[cromwell-systemunable to create new native thread, Uncaught error from thread [cromwell-system-akka.dispatchers.io-dispatcher-15]; ]: unable to create new native thread, shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[cromwell-system]; [...]; ```. So I tried following the HPC/SLURM instructions and made a conf file:; ```; include required(classpath(""application"")). webservice {; port = 8080; }. backend {; providers {; Sherlock {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; runtime-attri",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5395:978,config,configuration,978,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5395,1,['config'],['configuration']
Modifiability,"0.apply$mcV$sp(Function0.scala:42); at scala.Function0.apply$mcV$sp$(Function0.scala:42); at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:17); at scala.App.$anonfun$main$1(App.scala:98); at scala.App.$anonfun$main$1$adapted(App.scala:98); at scala.collection.IterableOnceOps.foreach(IterableOnce.scala:575); at scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:573); at scala.collection.AbstractIterable.foreach(Iterable.scala:933); at scala.App.main(App.scala:98); at scala.App.main$(App.scala:96); at womtool.WomtoolMain$.main(WomtoolMain.scala:27); at womtool.WomtoolMain.main(WomtoolMain.scala); Caused by: com.typesafe.config.ConfigException$IO: application.conf: java.io.IOException: resource not found on classpath: application.conf; at com.typesafe.config.impl.Parseable.parseValue(Parseable.java:190); at com.typesafe.config.impl.Parseable.parseValue(Parseable.java:174); at com.typesafe.config.impl.Parseable.parse(Parseable.java:152); at com.typesafe.config.impl.SimpleIncluder.fromBasename(SimpleIncluder.java:185); ... 48 more; Caused by: java.io.IOException: resource not found on classpath: application.conf; at com.typesafe.config.impl.Parseable$ParseableResources.rawParseValue(Parseable.java:726); at com.typesafe.config.impl.Parseable$ParseableResources.rawParseValue(Parseable.java:701); at com.typesafe.config.impl.Parseable.parseValue(Parseable.java:180); ... 51 more; ```. <!-- Which backend are you running? -->. The backend I'm running on is slurm and local . <!-- Paste/Attach your workflow if possible: -->. Workflow link. <!-- Def not an joke about best practices. Also thanks for publishing the gatk best practices and the warp pipelines -->. https://github.com/mmterpstra/Bestie. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->. Below are the first few lines of the config shown. ```; #see also https://cromwell.readthedocs.io/en/stable/backends/SLURM/; # include the app",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7255:4950,config,config,4950,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7255,1,['config'],['config']
Modifiability,"0/execution; # make the directory which will keep the matching files; mkdir /sandbox/users/foucal-a/test_atac-pipe/cromwell-executions/atac/f4fd93fa-6f3a-42a6-94f2-459901d245c4/call-trim_adapter/shard-0/execution/glob-4f26c666d13d1cb48973da7f646a7de2. # symlink all the files into the glob directory; ( ln -L merge_fastqs_R?_*.fastq.gz /sandbox/users/foucal-a/test_atac-pipe/cromwell-executions/atac/f4fd93fa-6f3a-42a6-94f2-459901d245c4/call-trim_adapter/shard-0/execution/glob-4f26c666d13d1cb48973da7f646a7de2 2> /dev/null ) || ( ln merge_fastqs_R?_*.fastq.gz /sandbox/users/foucal-a/test_atac-pipe/cromwell-executions/atac/f4fd93fa-6f3a-42a6-94f2-459901d245c4/call-trim_adapter/shard-0/execution/glob-4f26c666d13d1cb48973da7f646a7de2 ). # list all the files that match the glob into a file called glob-[md5 of glob].list; ls -1 /sandbox/users/foucal-a/test_atac-pipe/cromwell-executions/atac/f4fd93fa-6f3a-42a6-94f2-459901d245c4/call-trim_adapter/shard-0/execution/glob-4f26c666d13d1cb48973da7f646a7de2 > /sandbox/users/foucal-a/test_atac-pipe/cromwell-executions/atac/f4fd93fa-6f3a-42a6-94f2-459901d245c4/call-trim_adapter/shard-0/execution/glob-4f26c666d13d1cb48973da7f646a7de2.list; ```; I have the error when the script tries to symlink all the files into the glob directory.; Here is the WDL code : ; ```; scatter( i in range(length(fastqs_)) ) {; # trim adapters and merge trimmed fastqs; call trim_adapter { input :; fastqs = fastqs_[i],; adapters = if length(adapters_)>0 then adapters_[i] else [],; paired_end = paired_end,; }; # align trimmed/merged fastqs with bowtie2s; call bowtie2 { input :; idx_tar = bowtie2_idx_tar,; fastqs = trim_adapter.trimmed_merged_fastqs, #[R1,R2]; paired_end = paired_end,; multimapping = multimapping,; }; }; ```; With the function :; ```; task trim_adapter { # trim adapters and merge trimmed fastqs; # parameters from workflow; Array[Array[File]] fastqs # [merge_id][read_end_id]; Array[Array[String]] adapters # [merge_id][read_end_id]; Boolean paired_e",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3876:1519,sandbox,sandbox,1519,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3876,2,['sandbox'],['sandbox']
Modifiability,"00000 and a write batch size of 100000; [2019-07-10 14:32:53,38] [info] [RenameWorkflowOptionsInMetadata] 100%; [2019-07-10 14:32:53,46] [info] Running with database db.url = jdbc:hsqldb:mem:39174976-89f7-4769-a52c-7d5a4afc6cf4;shutdown=false;hsqldb.tx=mvcc; [2019-07-10 14:32:53,81] [info] Slf4jLogger started; [2019-07-10 14:32:54,07] [info] Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-1cf43fa"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""failureShutdownDuration"" : ""5 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; [2019-07-10 14:32:54,11] [info] Metadata summary refreshing every 1 second.; [2019-07-10 14:32:54,12] [warn] 'docker.hash-lookup.gcr-api-queries-per-100-seconds' is being deprecated, use 'docker.hash-lookup.gcr.throttle' instead (see reference.conf); [2019-07-10 14:32:54,12] [info] CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; [2019-07-10 14:32:54,13] [info] KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; [2019-07-10 14:32:54,13] [info] WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; [2019-07-10 14:32:54,18] [info] JobExecutionTokenDispenser - Distribution rate: 50 per 1 seconds.; [2019-07-10 14:32:54,43] [info] SingleWorkflowRunnerActor: Version 42; [2019-07-10 14:32:54,44] [info] SingleWorkflowRunnerActor: Submitting workflow; [2019-07-10 14:32:54,48] [info] Unspecified type (Unspecified version) workflow 41d3eecf-c5a9-42e4-8a29-8be9c252b7f5 submitted; [2019-07-10 14:32:54,50] [info] SingleWorkflowRunnerActor: Workflow submitted 41d3eecf-c5a9-42e4-8a29-8be9c252b7f5; [2019-07-10 14:32:54,50] [info] 1 new workflows fetched by cromid-1cf43fa: 41d3eecf-c5a9-42e4-8a29-8be9c252b7f5; [2019-07-10 14:32:54,51] [info] WorkflowManagerActor Starting workflow 41d3eecf-c5a9-42e4-8a29-8be9c252b7f5; [2019-07-10 14:32:54,51] [info] WorkflowManagerActor Successfully started WorkflowActor-41d3eecf-c5a9-42e",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5066:5462,config,configured,5462,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5066,1,['config'],['configured']
Modifiability,"000; [2019-05-22 18:42:25,86] [info] [RenameWorkflowOptionsInMetadata] 100%; [2019-05-22 18:42:25,92] [info] Running with database db.url = jdbc:hsqldb:mem:d3111f9f-5515-48da-b4c2-c9014a6eb8ab;shutdown=false;hsqldb.tx=mvcc; [2019-05-22 18:42:26,15] [warn] Unrecognized configuration key(s) for AwsBatch: auth, numCreateDefinitionAttempts, numSubmitAttempts; [2019-05-22 18:42:26,41] [info] Slf4jLogger started; [2019-05-22 18:42:26,62] [info] Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-c5da692"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; [2019-05-22 18:42:26,66] [info] Metadata summary refreshing every 2 seconds.; [2019-05-22 18:42:26,69] [info] WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; [2019-05-22 18:42:26,69] [info] KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; [2019-05-22 18:42:26,71] [info] CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; [2019-05-22 18:42:27,30] [info] JobExecutionTokenDispenser - Distribution rate: 50 per 1 seconds.; [2019-05-22 18:42:27,31] [info] SingleWorkflowRunnerActor: Version 36; [2019-05-22 18:42:27,35] [info] Unspecified type (Unspecified version) workflow 3997371c-9513-4386-a579-a72639c6e960 submitted; [2019-05-22 18:42:27,36] [info] SingleWorkflowRunnerActor: Workflow submitted 3997371c-9513-4386-a579-a72639c6e960; [2019-05-22 18:42:27,36] [info] WorkflowManagerActor Starting workflow 3997371c-9513-4386-a579-a72639c6e960; [2019-05-22 18:42:27,36] [info] WorkflowManagerActor Successfully started WorkflowActor-3997371c-9513-4386-a579-a72639c6e960; ...; [2019-05-22 19:15:20,74] [info] 755021ae-948b-47f9-94a8-66b486bda47d-SubWorkflowActor-SubWorkflow-Haplotypecaller:0:1 [755021ae]: Starting Haplotypecaller.SplitFilesByChromosome; [2019-05-22 19:15:21,34] [info] AwsBatchAsyncBackendJobExecutionActor [755021aeHaplotypecaller.SplitFiles",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5004:2198,config,configured,2198,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5004,1,['config'],['configured']
Modifiability,"002b46#617869376] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2017-01-20 09:33:07,58] [error] WorkflowManagerActor Workflow 814c47aa-9d11-4c81-a08c-f2b77c002b46 failed (during ExecutingWorkflowState): Call aggregate_mafs_workflow.aggregate_mafs:NA:1: return code was 1; java.lang.RuntimeException: Call aggregate_mafs_workflow.aggregate_mafs:NA:1: return code was 1; 	at cromwell.backend.standard.StandardAsyncExecutionActor$class.handleExecutionResult(StandardAsyncExecutionActor.scala:432); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.handleExecutionResult(ConfigAsyncJobExecutionActor.scala:113); 	at cromwell.backend.standard.StandardAsyncExecutionActor$class.handlePollSuccess(StandardAsyncExecutionActor.scala:370); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.handlePollSuccess(ConfigAsyncJobExecutionActor.scala:113); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$poll$2.apply(StandardAsyncExecutionActor.scala:333); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$poll$2.apply(StandardAsyncExecutionActor.scala:332); 	at scala.util.Success$$anonfun$map$1.apply(Try.scala:237); 	at scala.util.Try$.apply(Try.scala:192); 	at scala.util.Success.map(Try.scala:237); 	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237); 	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237); 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); 	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); 	at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply$mcV$sp(BatchingExecutor.scala:91); 	at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExecutor.scala:91); 	at akka.dispatch.BatchingExecutor$BlockableBatch$$anonfun$run$1.apply(BatchingExec",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1906:13804,Config,ConfigAsyncJobExecutionActor,13804,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1906,1,['Config'],['ConfigAsyncJobExecutionActor']
Modifiability,00:55:25 web start-cromwell.sh[110916]: at org.apache.commons.codec.digest.DigestUtils.md5(DigestUtils.java:274); Mar 09 00:55:25 web start-cromwell.sh[110916]: at org.apache.commons.codec.digest.DigestUtils.md5Hex(DigestUtils.java:310); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.backend.impl.sfs.config.HashFileStrategy.$anonfun$hash$3(ConfigHashingStrategy.scala:82); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.util.TryWithResource$.$anonfun$tryWithResource$1(TryWithResource.scala:16); Mar 09 00:55:25 web start-cromwell.sh[110916]: at scala.util.Try$.apply(Try.scala:209); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.util.TryWithResource$.tryWithResource(TryWithResource.scala:10); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.backend.impl.sfs.config.HashFileStrategy.hash(ConfigHashingStrategy.scala:82); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.backend.impl.sfs.config.ConfigHashingStrategy.usingStandardInitData$1(ConfigHashingStrategy.scala:52); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.backend.impl.sfs.config.ConfigHashingStrategy.getHash(ConfigHashingStrategy.scala:57); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.backend.impl.sfs.config.ConfigBackendFileHashingActor.customHashStrategy(ConfigBackendFileHashingActor.scala:26); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.backend.standard.callcaching.StandardFileHashingActor$$anonfun$fileHashingReceive$1.applyOrElse(StandardFileHashingActor.scala:73); Mar 09 00:55:25 web start-cromwell.sh[110916]: at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); Mar 09 00:55:25 web start-cromwell.sh[110916]: at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); Mar 09 00:55:25 web start-cromwell.sh[110916]: at akka.actor.Actor.aroundReceive(Actor.scala:514); Mar 09 00:55:25 web start-cromwell.sh[110916]: at akka.actor.Actor.aroundReceive$(Actor.scala:512); Mar 09 00:55:25 web,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3383:2815,Config,ConfigHashingStrategy,2815,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3383,1,['Config'],['ConfigHashingStrategy']
Modifiability,"04 using conda-installed Cromwell:. `cromwell run ngs-ubuntu-20-04/iletisim/warp/pipelines/broad/dna_seq/germline/single_sample/exome/local_newGCP_ExomeGermlineSingleSample_deneme6_bcftools.wdl -i ngs-ubuntu-20-04/iletisim/json/S736Nr1.json -o ngs-ubuntu-20-04/iletisim/json/options2.json`. Getting the error:. ```; [2023-02-04 08:55:00,61] [info] Running with database db.url = jdbc:hsqldb:mem:bc9ad7e3-efc7-4f37-aecb-b283b104cbcd;shutdown=false;hsqldb.tx=mvcc; [2023-02-04 08:55:06,54] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2023-02-04 08:55:06,55] [info] [RenameWorkflowOptionsInMetadata] 100%; [2023-02-04 08:55:06,64] [info] Running with database db.url = jdbc:hsqldb:mem:a487ea75-b617-4523-a254-d0e694e68ff9;shutdown=false;hsqldb.tx=mvcc; [2023-02-04 08:55:06,92] [info] Slf4jLogger started; [2023-02-04 08:55:07,18] [info] Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-b625dba"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; [2023-02-04 08:55:07,22] [info] Metadata summary refreshing every 2 seconds.; [2023-02-04 08:55:07,26] [info] KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; [2023-02-04 08:55:07,26] [info] WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; [2023-02-04 08:55:07,26] [info] CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; [2023-02-04 08:55:07,63] [info] JobExecutionTokenDispenser - Distribution rate: 50 per 1 seconds.; [2023-02-04 08:55:07,64] [info] SingleWorkflowRunnerActor: Version 34-unknown-SNAP; [2023-02-04 08:55:07,65] [info] SingleWorkflowRunnerActor: Submitting workflow; [2023-02-04 08:55:07,68] [info] Unspecified type (Unspecified version) workflow 48f62f22-25fe-4f0f-b5fe-21191f035abd submitted; [2023-02-04 08:55:07,72] [info] SingleWorkflowRunnerActor: Workflow submit",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6999:976,config,configuration,976,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6999,1,['config'],['configuration']
Modifiability,07); 	at wdl4s.Task$$anonfun$instantiateCommand$1$$anonfun$apply$2.apply(Task.scala:107); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72); 	at scala.collection.AbstractIterable.foreach(Iterable.scala:54); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.AbstractTraversable.map(Traversable.scala:104); 	at wdl4s.Task$$anonfun$instantiateCommand$1.apply(Task.scala:107); 	at wdl4s.Task$$anonfun$instantiateCommand$1.apply(Task.scala:107); 	at scala.util.Try$.apply(Try.scala:192); 	at wdl4s.Task.instantiateCommand(Task.scala:107); 	at cromwell.backend.impl.sfs.config.ConfigAsyncJobExecutionActor$class.writeTaskScript(ConfigAsyncJobExecutionActor.scala:55); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.writeTaskScript(ConfigAsyncJobExecutionActor.scala:124); 	at cromwell.backend.impl.sfs.config.ConfigAsyncJobExecutionActor$class.processArgs(ConfigAsyncJobExecutionActor.scala:39); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.processArgs$lzycompute(ConfigAsyncJobExecutionActor.scala:124); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.processArgs(ConfigAsyncJobExecutionActor.scala:124); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor$class.executeScript(SharedFileSystemAsyncJobExecutionActor.scala:220); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.executeScript(ConfigAsyncJobExecutionActor.scala:124); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor$$anonfun$executeOrRecover$2.apply(SharedFileSystemAsyncJobExecutionActor.scala:192); 	at cromwell.backend.sfs.S,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1765:2414,Config,ConfigAsyncJobExecutionActor,2414,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1765,1,['Config'],['ConfigAsyncJobExecutionActor']
Modifiability,07f301befc000]; java.lang.Thread.State: RUNNABLE; at sun.nio.ch.FileDispatcherImpl.read0(Native Method); at sun.nio.ch.FileDispatcherImpl.read(FileDispatcherImpl.java:46); at sun.nio.ch.IOUtil.readIntoNativeBuffer(IOUtil.java:223); at sun.nio.ch.IOUtil.read(IOUtil.java:197); at sun.nio.ch.FileChannelImpl.read(FileChannelImpl.java:159); - locked <0x00000006c54b2e78> (a java.lang.Object); at sun.nio.ch.ChannelInputStream.read(ChannelInputStream.java:65); at sun.nio.ch.ChannelInputStream.read(ChannelInputStream.java:109); at sun.nio.ch.ChannelInputStream.read(ChannelInputStream.java:103); - locked <0x00000006c54b2ec8> (a sun.nio.ch.ChannelInputStream); at org.apache.commons.codec.digest.DigestUtils.updateDigest(DigestUtils.java:798); at org.apache.commons.codec.digest.DigestUtils.digest(DigestUtils.java:50); at org.apache.commons.codec.digest.DigestUtils.md5(DigestUtils.java:274); at org.apache.commons.codec.digest.DigestUtils.md5Hex(DigestUtils.java:310); at cromwell.backend.impl.sfs.config.HashFileStrategy$$anonfun$hash$3.apply(ConfigHashingStrategy.scala:70); at cromwell.backend.impl.sfs.config.HashFileStrategy$$anonfun$hash$3.apply(ConfigHashingStrategy.scala:70); at cromwell.util.TryWithResource$$anonfun$tryWithResource$1.apply(TryWithResource.scala:16); at scala.util.Try$.apply(Try.scala:192); at cromwell.util.TryWithResource$.tryWithResource(TryWithResource.scala:10); at cromwell.backend.impl.sfs.config.HashFileStrategy.hash(ConfigHashingStrategy.scala:70); at cromwell.backend.impl.sfs.config.ConfigHashingStrategy.getHash(ConfigHashingStrategy.scala:47); at cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory$$anonfun$fileHashingFunction$1.apply(ConfigBackendLifecycleActorFactory.scala:45); at cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory$$anonfun$fileHashingFunction$1.apply(ConfigBackendLifecycleActorFactory.scala:45); at cromwell.backend.callcaching.FileHashingActor$$anonfun$receive$1$$anonfun$1.apply(FileHashingActor.scala:,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1597:1341,config,config,1341,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1597,1,['config'],['config']
Modifiability,0916]: at cromwell.backend.impl.sfs.config.HashFileStrategy.$anonfun$hash$3(ConfigHashingStrategy.scala:82); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.util.TryWithResource$.$anonfun$tryWithResource$1(TryWithResource.scala:16); Mar 09 00:55:25 web start-cromwell.sh[110916]: at scala.util.Try$.apply(Try.scala:209); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.util.TryWithResource$.tryWithResource(TryWithResource.scala:10); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.backend.impl.sfs.config.HashFileStrategy.hash(ConfigHashingStrategy.scala:82); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.backend.impl.sfs.config.ConfigHashingStrategy.usingStandardInitData$1(ConfigHashingStrategy.scala:52); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.backend.impl.sfs.config.ConfigHashingStrategy.getHash(ConfigHashingStrategy.scala:57); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.backend.impl.sfs.config.ConfigBackendFileHashingActor.customHashStrategy(ConfigBackendFileHashingActor.scala:26); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.backend.standard.callcaching.StandardFileHashingActor$$anonfun$fileHashingReceive$1.applyOrElse(StandardFileHashingActor.scala:73); Mar 09 00:55:25 web start-cromwell.sh[110916]: at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); Mar 09 00:55:25 web start-cromwell.sh[110916]: at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); Mar 09 00:55:25 web start-cromwell.sh[110916]: at akka.actor.Actor.aroundReceive(Actor.scala:514); Mar 09 00:55:25 web start-cromwell.sh[110916]: at akka.actor.Actor.aroundReceive$(Actor.scala:512); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.backend.standard.callcaching.StandardFileHashingActor.aroundReceive(StandardFileHashingActor.scala:59); Mar 09 00:55:25 web start-cromwell.sh[110916]: at akka.actor.ActorCell.receiveMessage(ActorCell.scala:527); Mar 09 00:55:25 web start-,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3383:3077,Config,ConfigBackendFileHashingActor,3077,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3383,1,['Config'],['ConfigBackendFileHashingActor']
Modifiability,0916]: at org.apache.commons.codec.digest.DigestUtils.md5Hex(DigestUtils.java:310); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.backend.impl.sfs.config.HashFileStrategy.$anonfun$hash$3(ConfigHashingStrategy.scala:82); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.util.TryWithResource$.$anonfun$tryWithResource$1(TryWithResource.scala:16); Mar 09 00:55:25 web start-cromwell.sh[110916]: at scala.util.Try$.apply(Try.scala:209); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.util.TryWithResource$.tryWithResource(TryWithResource.scala:10); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.backend.impl.sfs.config.HashFileStrategy.hash(ConfigHashingStrategy.scala:82); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.backend.impl.sfs.config.ConfigHashingStrategy.usingStandardInitData$1(ConfigHashingStrategy.scala:52); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.backend.impl.sfs.config.ConfigHashingStrategy.getHash(ConfigHashingStrategy.scala:57); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.backend.impl.sfs.config.ConfigBackendFileHashingActor.customHashStrategy(ConfigBackendFileHashingActor.scala:26); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.backend.standard.callcaching.StandardFileHashingActor$$anonfun$fileHashingReceive$1.applyOrElse(StandardFileHashingActor.scala:73); Mar 09 00:55:25 web start-cromwell.sh[110916]: at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); Mar 09 00:55:25 web start-cromwell.sh[110916]: at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); Mar 09 00:55:25 web start-cromwell.sh[110916]: at akka.actor.Actor.aroundReceive(Actor.scala:514); Mar 09 00:55:25 web start-cromwell.sh[110916]: at akka.actor.Actor.aroundReceive$(Actor.scala:512); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.backend.standard.callcaching.StandardFileHashingActor.aroundReceive(StandardFileHashingActor.scala:59); Mar 09 00:,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3383:2961,Config,ConfigHashingStrategy,2961,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3383,1,['Config'],['ConfigHashingStrategy']
Modifiability,"0D355AC301859E4ABB5432138"",; ""command template"": ""AFAC58B849BD67585A857F538B8E92F6""; },; ""effectiveCallCachingMode"": ""ReadAndWriteCache"",; ""hit"": false,; ""result"": ""Cache Miss""; },; ```. ```; # simple sge apptainer conf (modified from the slurm one); #; workflow-options; {; workflow-log-dir: ""cromwell-workflow-logs""; workflow-log-temporary: false; workflow-failure-mode: ""ContinueWhilePossible""; default; {; workflow-type: WDL; workflow-type-version: ""draft-2""; }; }. database {; # Store metadata in a file on disk that can grow much larger than RAM limits.; metadata {; profile = ""slick.jdbc.MySQLProfile$""; db {; url = ""jdbc:mysql:<dburl>?rewriteBatchedStatements=true""; driver = ""com.mysql.cj.jdbc.Driver""; user = ""<user>""; password = ""<pass>"" ; connectionTimeout = 5000; }; }; }. call-caching; {; enabled = true; invalidate-bad-cache-result = true; }. docker {; hash-lookup {; enabled = true; }; }. backend {; default = sge; providers {. ; sge {; 	actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {. # Limits the number of concurrent jobs; #concurrent-job-limit = 5. # If an 'exit-code-timeout-seconds' value is specified:; # - check-alive will be run at this interval for every job; # - if a job is found to be not alive, and no RC file appears after this interval; # - Then it will be marked as Failed.; # Warning: If set, Cromwell will run 'check-alive' for every job at this interval. # exit-code-timeout-seconds = 120. runtime-attributes = """"""; String time = ""11:00:00""; Int cpu = 4; Float? memory_gb; String sge_queue = ""hammer.q""; String? sge_project; String? docker; """""". submit = """"""; qsub \; -terse \; -V \; -b y \; -N ${job_name} \; -wd ${cwd} \; -o ${out}.qsub \; -e ${err}.qsub \; -pe smp ${cpu} \; ${""-l mem_free="" + memory_gb + ""g""} \; ${""-q "" + sge_queue} \; ${""-P "" + sge_project} \; /usr/bin/env bash ${script}; """""". kill = ""qdel ${job_id}""; check-alive = ""qstat -j ${job_id}""; job-id-regex = ""(\\d+)"". submit-docker = """""" ; #locati",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7480:2297,config,config,2297,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7480,1,['config'],['config']
Modifiability,"0duB1nw. input fastq files can be retrieved here (they are small ~10000 reads each):. https://drive.google.com/file/d/1-c14Tja4zY3lyr6icFWT06stznR_-Zqr/view?usp=sharing; https://drive.google.com/file/d/1oJd_U9MjTllL0_kpNivw8I_LtSyvqpXH/view?usp=sharing. How can I solve this issue and make the workflow running smoothly?. ### Which backend are you running? ; I am running locally the workflow for now (because I am in the first phase of the development). ### Workflow is this:; ```; #workflow validated before running with: wdltool validate example.wdl and womtool validate scMeth_v2.wdl.sh -i scMeth_input_3.json. workflow scMeth {; # information for trimming the cell barcode; File command; Int bases; File input_fastq1; File input_fastq2; String sampleName. # information for trimming the adapters and low quality reads; File file_format; Int low_quality_cutoff; Int read_length_cutoff; String adapters_1; String adapters_2; Int trim_start_R1; Int trim_end_R1; Int trim_start_R2; Int trim_end_R2; String TAG; call trimCellBarcode {; input:; sampleName=sampleName,; bases=bases,; input_fastq1=input_fastq1,; input_fastq2=input_fastq2,; command=command; }; call trimAdapters {; input:; file_format=file_format,; input_r1 = trimCellBarcode.fastq_debarcoded_R1,; input_r2 = trimCellBarcode.fastq_debarcoded_R2,; low_quality_cutoff=low_quality_cutoff,; read_length_cutoff=read_length_cutoff,; adapters_1=adapters_1,; adapters_2=adapters_2,; trim_start_R1=trim_start_R1,; trim_end_R1=trim_end_R1,; trim_start_R2=trim_start_R2,; trim_end_R2=trim_end_R2,; TAG=TAG; }; }. task trimCellBarcode {; File command; Int bases; File input_fastq1; File input_fastq2; String sampleName; command {; perl ${command} paired ${input_fastq1} ${input_fastq2} ${bases} ${sampleName}.R1.debarcoded.fq.gz ${sampleName}.R2.debarcoded.fq.gz; }; output {; File fastq_debarcoded_R1 = ""${sampleName}.R1.debarcoded.fq.gz""; File fastq_debarcoded_R2 = ""${sampleName}.R2.debarcoded.fq.gz""; }; }. task trimAdapters {; File file_format",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5066:1490,adapt,adapters,1490,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5066,1,['adapt'],['adapters']
Modifiability,"0f/call-batch_for_variantcall/execution/stderr -t 1-00:00 -p core --cpus-per-task=1 --mem=4026 --wrap ""/usr/bin/env bash /projects/ngs/oncology/dev/bcbio_validation_workflows/somatic-giab-mix/cromwell_work/cromwell-executions/main-somatic-giab-mix.cwl/bc4644da-87f9-4765-9791-9011a2fae80f/call-batch_for_variantcall/execution/script""; [2018-05-02 15:16:57,63] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mbc4644da[0mbatch_for_variantcall:NA:1]: job id: 134053; [2018-05-02 15:16:57,66] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mbc4644da[0mbatch_for_variantcall:NA:1]: Status change from - to WaitingForReturnCodeFile; [2018-05-02 15:17:05,03] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mbc4644da[0mbatch_for_variantcall:NA:1]: Status change from WaitingForReturnCodeFile to Done; [2018-05-02 15:22:54,62] [[38;5;1merror[0m] Failed to hash null; java.io.FileNotFoundException: Cannot hash file null because it can't be found; 	at cromwell.backend.impl.sfs.config.ConfigHashingStrategy.usingStandardInitData$1(ConfigHashingStrategy.scala:46); 	at cromwell.backend.impl.sfs.config.ConfigHashingStrategy.getHash(ConfigHashingStrategy.scala:57); 	at cromwell.backend.impl.sfs.config.ConfigBackendFileHashingActor.customHashStrategy(ConfigBackendFileHashingActor.scala:26); 	at cromwell.backend.standard.callcaching.StandardFileHashingActor$$anonfun$fileHashingReceive$1.applyOrElse(StandardFileHashingActor.scala:79); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at akka.actor.Actor.aroundReceive(Actor.scala:514); 	at akka.actor.Actor.aroundReceive$(Actor.scala:512); 	at cromwell.backend.standard.callcaching.StandardFileHashingActor.akka$actor$Timers$$super$aroundReceive(StandardFileHashingActor.scala:59); 	at akka.actor.Timers.aroundReceive(Timers.scala:44); 	at akka.actor.Timers.aroundReceive$(Timers.scala:36); 	at cromwell.backend.standard.callcaching.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3584:4951,config,config,4951,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3584,1,['config'],['config']
Modifiability,"1 20:01:06,50] [info] BackgroundConfigAsyncJobExecutionActor [132d7527test.t1:NA:1]: Status change from WaitingForReturnCodeFile to Done; [2017-12-01 20:01:06,61] [error] WorkflowManagerActor Workflow 132d7527-a0af-4f08-8291-d935e7cd5632 failed (during ExecutingWorkflowState): Could not evaluate t1.out = if select_first([flag1,false]) then glob(""test1.txt"")[0] else glob(""test2.txt"")[0]; java.lang.RuntimeException: Could not evaluate t1.out = if select_first([flag1,false]) then glob(""test1.txt"")[0] else glob(""test2.txt"")[0]; at wdl4s.wdl.WdlTask$$anonfun$4.applyOrElse(WdlTask.scala:189); at wdl4s.wdl.WdlTask$$anonfun$4.applyOrElse(WdlTask.scala:188); at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34); at scala.util.Failure.recoverWith(Try.scala:232); at wdl4s.wdl.WdlTask.$anonfun$evaluateOutputs$2(WdlTask.scala:188); at scala.collection.TraversableOnce.$anonfun$foldLeft$1(TraversableOnce.scala:157); at scala.collection.TraversableOnce.$anonfun$foldLeft$1$adapted(TraversableOnce.scala:157); at scala.collection.Iterator.foreach(Iterator.scala:929); at scala.collection.Iterator.foreach$(Iterator.scala:929); at scala.collection.AbstractIterator.foreach(Iterator.scala:1417); at scala.collection.IterableLike.foreach(IterableLike.scala:71); at scala.collection.IterableLike.foreach$(IterableLike.scala:70); at scala.collection.AbstractIterable.foreach(Iterable.scala:54); at scala.collection.TraversableOnce.foldLeft(TraversableOnce.scala:157); at scala.collection.TraversableOnce.foldLeft$(TraversableOnce.scala:155); at scala.collection.AbstractTraversable.foldLeft(Traversable.scala:104); at wdl4s.wdl.WdlTask.evaluateOutputs(WdlTask.scala:181); at cromwell.backend.wdl.OutputEvaluator$.evaluateOutputs(OutputEvaluator.scala:15); at cromwell.backend.standard.StandardAsyncExecutionActor.evaluateOutputs(StandardAsyncExecutionActor.scala:406); at cromwell.backend.standard.StandardAsyncExecutionActor.evaluateOutputs$(StandardAsyncExecutionActor.scala:405)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2972:4067,adapt,adapted,4067,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2972,1,['adapt'],['adapted']
Modifiability,"1 | /bin/bash ${script}; cromwell_1 | }; cromwell_1 | }; cromwell_1 | ; cromwell_1 | ; cromwell_1 | task submit_docker {; cromwell_1 | ; cromwell_1 | String job_id; cromwell_1 | String job_name; cromwell_1 | String cwd; cromwell_1 | String out; cromwell_1 | String err; cromwell_1 | String script; cromwell_1 | ; cromwell_1 | String docker_cwd; cromwell_1 | String? docker Int? max_runtime = 2; cromwell_1 | command {; cromwell_1 | ; cromwell_1 | docker run \; cromwell_1 | --rm -i \; cromwell_1 | ${""--user "" + docker_user} \; cromwell_1 | --entrypoint /bin/bash \; cromwell_1 | -v ${cwd}:${docker_cwd} \; cromwell_1 | ${docker} ${script}; cromwell_1 | ; cromwell_1 | }; cromwell_1 | }; cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigWdlNamespace.<init>(ConfigWdlNamespace.scala:50); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace$lzycompute(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations$lzycompute(ConfigInitializationActor.scala:40); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations(ConfigInitializationActor.scala:39); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder$lzycompute(ConfigInitializationActor.scala:49); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder(ConfigInitializationActor.scala:48); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.coerceDefaultRuntimeAttributes(StandardInitializationActor.scala:78); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$class.validateRuntimeAttributes(BackendWorkflowInitializationActor.scala:121); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$cla",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2284:2942,Config,ConfigInitializationActor,2942,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2284,1,['Config'],['ConfigInitializationActor']
Modifiability,"1 | String script; cromwell_1 | ; cromwell_1 | String docker_cwd; cromwell_1 | String? docker Int? max_runtime = 2; cromwell_1 | command {; cromwell_1 | ; cromwell_1 | docker run \; cromwell_1 | --rm -i \; cromwell_1 | ${""--user "" + docker_user} \; cromwell_1 | --entrypoint /bin/bash \; cromwell_1 | -v ${cwd}:${docker_cwd} \; cromwell_1 | ${docker} ${script}; cromwell_1 | ; cromwell_1 | }; cromwell_1 | }; cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigWdlNamespace.<init>(ConfigWdlNamespace.scala:50); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace$lzycompute(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations$lzycompute(ConfigInitializationActor.scala:40); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations(ConfigInitializationActor.scala:39); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder$lzycompute(ConfigInitializationActor.scala:49); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder(ConfigInitializationActor.scala:48); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.coerceDefaultRuntimeAttributes(StandardInitializationActor.scala:78); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$class.validateRuntimeAttributes(BackendWorkflowInitializationActor.scala:121); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$class.initSequence(BackendWorkflowInitializationActor.scala:154); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.initSequence(StandardInitializationActor.scala:42); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$$anonfun$receive$1$$anon",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2284:3221,Config,ConfigInitializationActor,3221,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2284,1,['Config'],['ConfigInitializationActor']
Modifiability,"1 | String script; cromwell_1 | String? docker Int? max_runtime = 2; cromwell_1 | command {; cromwell_1 | /bin/bash ${script}; cromwell_1 | }; cromwell_1 | }; cromwell_1 | ; cromwell_1 | ; cromwell_1 | task submit_docker {; cromwell_1 | ; cromwell_1 | String job_id; cromwell_1 | String job_name; cromwell_1 | String cwd; cromwell_1 | String out; cromwell_1 | String err; cromwell_1 | String script; cromwell_1 | ; cromwell_1 | String docker_cwd; cromwell_1 | String? docker Int? max_runtime = 2; cromwell_1 | command {; cromwell_1 | ; cromwell_1 | docker run \; cromwell_1 | --rm -i \; cromwell_1 | ${""--user "" + docker_user} \; cromwell_1 | --entrypoint /bin/bash \; cromwell_1 | -v ${cwd}:${docker_cwd} \; cromwell_1 | ${docker} ${script}; cromwell_1 | ; cromwell_1 | }; cromwell_1 | }; cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigWdlNamespace.<init>(ConfigWdlNamespace.scala:50); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace$lzycompute(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations$lzycompute(ConfigInitializationActor.scala:40); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations(ConfigInitializationActor.scala:39); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder$lzycompute(ConfigInitializationActor.scala:49); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder(ConfigInitializationActor.scala:48); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.coerceDefaultRuntimeAttributes(StandardInitializationActor.scala:78); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$class.validateRuntimeAttributes(BackendWorkflowIn",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2284:2825,config,configWdlNamespace,2825,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2284,2,"['Config', 'config']","['ConfigInitializationActor', 'configWdlNamespace']"
Modifiability,1); cromwell_1 | 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); cromwell_1 | 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); cromwell_1 | 	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72); cromwell_1 | 	at scala.collection.AbstractIterable.foreach(Iterable.scala:54); cromwell_1 | 	at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241); cromwell_1 | 	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:104); cromwell_1 | 	at wdl4s.WdlNamespace$$anonfun$42.apply(WdlNamespace.scala:402); cromwell_1 | 	at wdl4s.WdlNamespace$$anonfun$42.apply(WdlNamespace.scala:401); cromwell_1 | 	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241); cromwell_1 | 	at scala.collection.TraversableLike$$anonfun$flatMap$1.apply(TraversableLike.scala:241); cromwell_1 | 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); cromwell_1 | 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); cromwell_1 | 	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72); cromwell_1 | 	at scala.collection.AbstractIterable.foreach(Iterable.scala:54); cromwell_1 | 	at scala.collection.TraversableLike$class.flatMap(TraversableLike.scala:241); cromwell_1 | 	at scala.collection.AbstractTraversable.flatMap(Traversable.scala:104); cromwell_1 | 	at wdl4s.WdlNamespace$.apply(WdlNamespace.scala:401); cromwell_1 | 	at wdl4s.WdlNamespace$$anonfun$wdl4s$WdlNamespace$$load$1.apply(WdlNamespace.scala:177); cromwell_1 | 	at wdl4s.WdlNamespace$$anonfun$wdl4s$WdlNamespace$$load$1.apply(WdlNamespace.scala:177); cromwell_1 | 	at scala.util.Try$.apply(Try.scala:192); cromwell_1 | 	at wdl4s.WdlNamespace$.wdl4s$WdlNamespace$$load(WdlNamespace.scala:176); cromwell_1 | 	at wdl4s.WdlNamespace$.loadUsingSource(WdlNamespace.scala:173); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigWdlNamespace.<init>(ConfigWdlNamespace.scala:48); cromwell_1 | 	... 26 more. ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2284:8972,config,config,8972,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2284,3,"['Config', 'config']","['ConfigWdlNamespace', 'config']"
Modifiability,"1-9011a2fae80f/call-batch_for_variantcall/execution/script""; [2018-05-02 15:16:57,63] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mbc4644da[0mbatch_for_variantcall:NA:1]: job id: 134053; [2018-05-02 15:16:57,66] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mbc4644da[0mbatch_for_variantcall:NA:1]: Status change from - to WaitingForReturnCodeFile; [2018-05-02 15:17:05,03] [info] DispatchedConfigAsyncJobExecutionActor [[38;5;2mbc4644da[0mbatch_for_variantcall:NA:1]: Status change from WaitingForReturnCodeFile to Done; [2018-05-02 15:22:54,62] [[38;5;1merror[0m] Failed to hash null; java.io.FileNotFoundException: Cannot hash file null because it can't be found; 	at cromwell.backend.impl.sfs.config.ConfigHashingStrategy.usingStandardInitData$1(ConfigHashingStrategy.scala:46); 	at cromwell.backend.impl.sfs.config.ConfigHashingStrategy.getHash(ConfigHashingStrategy.scala:57); 	at cromwell.backend.impl.sfs.config.ConfigBackendFileHashingActor.customHashStrategy(ConfigBackendFileHashingActor.scala:26); 	at cromwell.backend.standard.callcaching.StandardFileHashingActor$$anonfun$fileHashingReceive$1.applyOrElse(StandardFileHashingActor.scala:79); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at akka.actor.Actor.aroundReceive(Actor.scala:514); 	at akka.actor.Actor.aroundReceive$(Actor.scala:512); 	at cromwell.backend.standard.callcaching.StandardFileHashingActor.akka$actor$Timers$$super$aroundReceive(StandardFileHashingActor.scala:59); 	at akka.actor.Timers.aroundReceive(Timers.scala:44); 	at akka.actor.Timers.aroundReceive$(Timers.scala:36); 	at cromwell.backend.standard.callcaching.StandardFileHashingActor.aroundReceive(StandardFileHashingActor.scala:59); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:527); 	at akka.actor.ActorCell.invoke(ActorCell.scala:496); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); 	at akka.dispatch.Mail",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3584:5223,Config,ConfigBackendFileHashingActor,5223,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3584,1,['Config'],['ConfigBackendFileHashingActor']
Modifiability,"1-minute description of this: VariableReference had to become aware of where it was, because `p.left` might need a `Pair` called `p`'s `""left""` field, or it might need a `task` called `p`'s `""left""` output, depending on its scope, and the variable reference is different in each case (`p` and `p.left` respectively). Determining whether a reference is a member access or a task output reference is a bit inefficient right now, but I think it should be ok since it's only called during WDL instantiation (thereafter it's all just following the links in WOM objects)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2947:30,Variab,VariableReference,30,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2947,2,"['Variab', 'variab']","['VariableReference', 'variable']"
Modifiability,1. Added Cromwell-backend library as sub-project of Cromwell.; 2. Added base interfaces from Cromwell-backend.; 3. Tried to use SBT Git plugin for versioning but I couldn't get it work with sbt multi-projects. @geoffjentry and @scottfrazer could you please review this PR?,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/495:136,plugin,plugin,136,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/495,1,['plugin'],['plugin']
Modifiability,"1. Takes a `cromwell_id` from config or will just make up a `cromwell_id` based off a UUID if none is provided.; 2. Clears `cromwell_id`s and heartbeats on workflow store entries on clean shutdown.; 3. Any workflow with a null or expired heartbeat is fair game when sweeping for workflows.; 4. Actual SQL generated with Slick's`forUpdate` looks like: ```select `WORKFLOW_EXECUTION_UUID`, `WORKFLOW_DEFINITION`, `WORKFLOW_ROOT`, `WORKFLOW_TYPE`, `WORKFLOW_TYPE_VERSION`, `WORKFLOW_INPUTS`, `WORKFLOW_OPTIONS`, `WORKFLOW_STATE`, `SUBMISSION_TIME`, `IMPORTS_ZIP`, `CUSTOM_LABELS`, `CROMWELL_ID`, `HEARTBEAT_TIMESTAMP`, `WORKFLOW_STORE_ENTRY_ID` from `WORKFLOW_STORE_ENTRY` where (`HEARTBEAT_TIMESTAMP` is null) or (`HEARTBEAT_TIMESTAMP` < ?) order by `SUBMISSION_TIME` limit ? for update```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3399:30,config,config,30,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3399,1,['config'],['config']
Modifiability,"1. Takes a `cromwell_id` from config or will just make up a `cromwell_id` based off a randomly generated UUID if none is provided.; 2. Clears `cromwell_id`s and heartbeats on workflow store entries on clean shutdown.; 3. Any workflow with a null or expired heartbeat is fair game when sweeping for workflows.; 4. Actual SQL generated with Slick's`forUpdate` looks like the following when using the MySQL profile: ```select `WORKFLOW_EXECUTION_UUID`, `WORKFLOW_DEFINITION`, `WORKFLOW_ROOT`, `WORKFLOW_TYPE`, `WORKFLOW_TYPE_VERSION`, `WORKFLOW_INPUTS`, `WORKFLOW_OPTIONS`, `WORKFLOW_STATE`, `SUBMISSION_TIME`, `IMPORTS_ZIP`, `CUSTOM_LABELS`, `CROMWELL_ID`, `HEARTBEAT_TIMESTAMP`, `WORKFLOW_STORE_ENTRY_ID` from `WORKFLOW_STORE_ENTRY` where (`HEARTBEAT_TIMESTAMP` is null) or (`HEARTBEAT_TIMESTAMP` < ?) order by `SUBMISSION_TIME` limit ? for update```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3401:30,config,config,30,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3401,1,['config'],['config']
Modifiability,"1.1.0...v1.1.1). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/2dc2301e75aea6c2d0c49b89d6092f7d4f134b40/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Files still referring to the old version number</summary>. The following files still refer to the old version number (1.1.0).; You might want to review and update them manually.; ```; CHANGELOG.md; centaur/src/main/resources/integrationTestCases/cwl/bcbio/gvcf-joint-workflow/steps/variantcall_batch_region.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/prealign-workflow/steps/variantcall_batch_region.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/somatic-workflow/steps/variantcall_batch_region.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/svcall-workflow/steps/variantcall_batch_region.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/wes_chr21_test-workflow-gcp/steps/variantcall_batch_region.cwl; cloud-nio/cloud-nio-impl-drs/src/main/scala/cloud/nio/impl/drs/DrsCloudNioFileSystemProvider.scala; cwl/src/test/resources/cwl/lodash.js; ```; </details>; <details>; <summary>Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.eed3si9n"", artifactId = ""sbt-assembly"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""@monthly"" },; dependency = { groupId = ""com.eed3si9n"", artifactId = ""sbt-assembly"" }; }]; ```; </details>. labels: sbt-plugin-update, early-semver-patch, semver-spec-patch, old-version-remains, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6850:2148,plugin,plugin-update,2148,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6850,1,['plugin'],['plugin-update']
Modifiability,"12-15 21:14:52,43] [info] Checkpoint end - txts: 102088; [2022-12-15 21:14:52,43] [info] Checkpoint start; [2022-12-15 21:14:52,43] [info] checkpointClose start; [2022-12-15 21:14:52,43] [info] checkpointClose synched; [2022-12-15 21:14:52,46] [info] checkpointClose script done; [2022-12-15 21:14:52,46] [info] dataFileCache commit start; [2022-12-15 21:14:52,46] [info] dataFileCache commit end; [2022-12-15 21:14:52,49] [info] checkpointClose end; [2022-12-15 21:14:52,50] [info] Checkpoint end - txts: 102090; [2022-12-15 21:14:52,81] [info] Slf4jLogger started; [2022-12-15 21:14:53,15] [info] Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-b254006"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""failureShutdownDuration"" : ""5 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; [2022-12-15 21:14:53,38] [info] KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; [2022-12-15 21:14:53,44] [info] WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; [2022-12-15 21:14:53,44] [info] CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; [2022-12-15 21:14:53,44] [info] Metadata summary refreshing every 1 second.; [2022-12-15 21:14:53,44] [info] No metadata archiver defined in config; [2022-12-15 21:14:53,44] [info] No metadata deleter defined in config; [2022-12-15 21:14:53,55] [info] JobRestartCheckTokenDispenser - Distribution rate: 50 per 1 seconds.; [2022-12-15 21:14:53,66] [info] JobExecutionTokenDispenser - Distribution rate: 20 per 10 seconds.; [2022-12-15 21:14:53,78] [info] SingleWorkflowRunnerActor: Version 84; [2022-12-15 21:14:53,82] [info] SingleWorkflowRunnerActor: Submitting workflow; [2022-12-15 21:14:53,93] [info] Unspecified type (Unspecified version) workflow 9e4f5894-f7e6-4e2f-be4b-f547d6de7fff submitted; [2022-12-15 21:14:53,94] [info] SingleWorkflowRunnerActor: Workflow submitted 9e4f5894-f7e6-4e2f-be4b-f547d6de7fff; ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6971:12910,config,configured,12910,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6971,1,['config'],['configured']
Modifiability,"153039990-0d0b2c96-a33b-454f-9617-aee83137337a.PNG); [Cromwell-Error.docx](https://github.com/broadinstitute/cromwell/files/8026009/Cromwell-Error.docx); ; <!-- Paste/Attach your workflow if possible: -->; java -Dconfig.file=aws-cromwell-batch.conf -jar cromwell-75.jar run hello.wdl -i hello.inputs. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->; include required(classpath(""application"")). aws {. application-name = ""cromwell""; auths = [; {; name = ""default""; scheme = ""default""; }; ]; region = ""us-east-1""; }; engine {; filesystems {; s3.auth = ""default""; }; }; call-caching {; enabled = true; invalidate-bad-cache-results = true; }; docker {; hash-lookup {; enabled = false; # How should docker hashes be looked up. Possible values are ""local"" and ""remote""; # ""local"": Lookup hashes on the local docker daemon using the cli; # ""remote"": Lookup hashes on docker hub and gcr; method = ""remote""; }; }. backend {; default = ""AWSBATCH""; providers {; AWSBATCH {; actor-factory = ""cromwell.backend.impl.aws.AwsBatchBackendLifecycleActorFactory""; config {; numSubmitAttempts = 10; numCreateDefinitionAttempts = 10; concurrent-job-limit = 1000; root = ""s3://cromwell-aws-hello/cromwell-execution""; auth = ""default""; default-runtime-attributes {; queueArn = ""arn:aws:batch:us-east-1:XXXXXXXXX:job-queue/python-batch"" ,; scriptBucketName = ""cromwell-aws-hello"" ; }; filesystems {; s3 {; auth = ""default""; }; }; # Emit a warning if jobs last longer than this amount of time. This might indicate that something got stuck in the cloud.; slow-job-warning-time: 24 hours; }; }; }; }. [Cromwell-Error.docx](https://github.com/broadinstitute/cromwell/files/8026013/Cromwell-Error.docx); ![AWS-Batch](https://user-images.githubusercontent.com/25282254/153040332-625cb61a-062b-4766-96ea-8e129efb2b20.PNG); [config file.docx](https://github.com/broadinstitute/cromwell/files/8026025/config.file.docx). How to give Timeout options for Job definitions?",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6671:2478,config,config,2478,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6671,3,['config'],['config']
Modifiability,"17-01-20 09:33:07,58] [info] Message [cromwell.subworkflowstore.SubWorkflowStoreActor$SubWorkflowStoreCompleteSuccess] from Actor[akka://cromwell-system/user/SingleWorkflowRunnerActor/$b#-910401033] to Actor[akka://cromwell-system/user/SingleWorkflowRunnerActor/WorkflowManagerActor/WorkflowActor-814c47aa-9d11-4c81-a08c-f2b77c002b46#617869376] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2017-01-20 09:33:07,58] [error] WorkflowManagerActor Workflow 814c47aa-9d11-4c81-a08c-f2b77c002b46 failed (during ExecutingWorkflowState): Call aggregate_mafs_workflow.aggregate_mafs:NA:1: return code was 1; java.lang.RuntimeException: Call aggregate_mafs_workflow.aggregate_mafs:NA:1: return code was 1; 	at cromwell.backend.standard.StandardAsyncExecutionActor$class.handleExecutionResult(StandardAsyncExecutionActor.scala:432); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.handleExecutionResult(ConfigAsyncJobExecutionActor.scala:113); 	at cromwell.backend.standard.StandardAsyncExecutionActor$class.handlePollSuccess(StandardAsyncExecutionActor.scala:370); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.handlePollSuccess(ConfigAsyncJobExecutionActor.scala:113); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$poll$2.apply(StandardAsyncExecutionActor.scala:333); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$poll$2.apply(StandardAsyncExecutionActor.scala:332); 	at scala.util.Success$$anonfun$map$1.apply(Try.scala:237); 	at scala.util.Try$.apply(Try.scala:192); 	at scala.util.Success.map(Try.scala:237); 	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237); 	at scala.concurrent.Future$$anonfun$map$1.apply(Future.scala:237); 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:32); 	at akka.dispatch.BatchingExecutor$AbstractBatch.pr",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1906:13479,config,config,13479,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1906,1,['config'],['config']
Modifiability,190); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.reconnectToExistingJob(SharedFileSystemAsyncJobExecutionActor.scala:171); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.recover(SharedFileSystemAsyncJobExecutionActor.scala:159); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.recover$(SharedFileSystemAsyncJobExecutionActor.scala:159); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.recover(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$recoverAsync$1(StandardAsyncExecutionActor.scala:305); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.backend.standard.StandardAsyncExecutionActor.recoverAsync(StandardAsyncExecutionActor.scala:305); 	at cromwell.backend.standard.StandardAsyncExecutionActor.recoverAsync$(StandardAsyncExecutionActor.scala:305); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.recoverAsync(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover(StandardAsyncExecutionActor.scala:574); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover$(StandardAsyncExecutionActor.scala:569); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.executeOrRecover(ConfigAsyncJobExecutionActor.scala:190); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustExecuteOrRecover$1(AsyncBackendJobExecutionActor.scala:65); 	at cromwell.core.retry.Retry$.withRetry(Retry.scala:37); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.withRetry(AsyncBackendJobExecutionActor.scala:61); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.cromwell$backend$async$AsyncBackendJobExecutionActor$$robustExecuteOrRecover(AsyncBackendJobExecutionActor.scala:65); 	at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$receive$1.applyOrElse(AsyncBackendJobExecutionActor.scala:88); ,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2963:2279,Config,ConfigAsyncJobExecutionActor,2279,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2963,1,['Config'],['ConfigAsyncJobExecutionActor']
Modifiability,"1:14:52,43] [info] checkpointClose start; [2022-12-15 21:14:52,43] [info] checkpointClose synched; [2022-12-15 21:14:52,46] [info] checkpointClose script done; [2022-12-15 21:14:52,46] [info] dataFileCache commit start; [2022-12-15 21:14:52,46] [info] dataFileCache commit end; [2022-12-15 21:14:52,49] [info] checkpointClose end; [2022-12-15 21:14:52,50] [info] Checkpoint end - txts: 102090; [2022-12-15 21:14:52,81] [info] Slf4jLogger started; [2022-12-15 21:14:53,15] [info] Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-b254006"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""failureShutdownDuration"" : ""5 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; [2022-12-15 21:14:53,38] [info] KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; [2022-12-15 21:14:53,44] [info] WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; [2022-12-15 21:14:53,44] [info] CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; [2022-12-15 21:14:53,44] [info] Metadata summary refreshing every 1 second.; [2022-12-15 21:14:53,44] [info] No metadata archiver defined in config; [2022-12-15 21:14:53,44] [info] No metadata deleter defined in config; [2022-12-15 21:14:53,55] [info] JobRestartCheckTokenDispenser - Distribution rate: 50 per 1 seconds.; [2022-12-15 21:14:53,66] [info] JobExecutionTokenDispenser - Distribution rate: 20 per 10 seconds.; [2022-12-15 21:14:53,78] [info] SingleWorkflowRunnerActor: Version 84; [2022-12-15 21:14:53,82] [info] SingleWorkflowRunnerActor: Submitting workflow; [2022-12-15 21:14:53,93] [info] Unspecified type (Unspecified version) workflow 9e4f5894-f7e6-4e2f-be4b-f547d6de7fff submitted; [2022-12-15 21:14:53,94] [info] SingleWorkflowRunnerActor: Workflow submitted 9e4f5894-f7e6-4e2f-be4b-f547d6de7fff; [2022-12-15 21:14:53,96] [info] 1 new workflows fetched by cromid-b254006: 9e4f5894-f7e6-4e2f-be4b-f547d6de7fff; [2022-12",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6971:13031,config,configured,13031,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6971,1,['config'],['configured']
Modifiability,"1; 470 pool-8-th 2381; 470 pool-7-th 4751; 470 pool-7-th 2381; 470 pool-10-t 4751; 470 pool-10-t 2381; 282 G1 4751; 282 G1 2381; 188 blaze-tic 4751; 188 blaze-tic 2381; 94 VM 4751; 94 VM 2381; 94 java 4751; 94 java 2381; 94 db-9 4751; 94 db-9 2381; 94 db-8 4751; 94 db-8 2381; 94 db-7 4751; 94 db-7 2381; 94 db-6 4751; 94 db-6 2381; 94 db-5 4751; 94 db-5 2381; 94 db 4751; 94 db-4 4751; 94 db-4 2381; 94 db-3 4751; 94 db-3 2381; 94 db-2 4751; 94 db 2381; 94 db-2 2381; 94 db-20 4751; 94 db-20 2381; 94 db-19 4751; 94 db-19 2381; 94 db-18 4751; 94 db-18 2381; 94 db-17 4751; 94 db-17 2381; 94 db-16 4751; 94 db-16 2381; 94 db-15 4751; 94 db-15 2381; 94 db-1 4751 ...; ```. this is my java command; ```{shell}; java -Xms10M -Xmx125M -Dconfig.file=SGE.conf -jar cromwell-86.jar run xxx.wdl --inputs xxx.json; ```. SGE.conf file:; ```; # Documentation:; # https://cromwell.readthedocs.io/en/stable/backends/SGE. backend {; default = SGE. providers {; SGE {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {. # Limits the number of concurrent jobs; concurrent-job-limit = 5. # If an 'exit-code-timeout-seconds' value is specified:; # - check-alive will be run at this interval for every job; # - if a job is found to be not alive, and no RC file appears after this interval; # - Then it will be marked as Failed.; # Warning: If set, Cromwell will run 'check-alive' for every job at this interval. exit-code-timeout-seconds = 120. runtime-attributes = """"""; Int cpu = 1; Float? memory_gb; String? sge_queue = ""xxx""; String? sge_project = ""xxx""; """""". submit = """"""; qsub \; -terse \; -V \; -b y \; -N ${job_name} \; -wd ${cwd} \; -o ${out}.qsub \; -e ${err}.qsub \; ${""-l num_proc="" + cpu + "",virtual_free="" + memory_gb + ""g""} \; ${""-q "" + sge_queue} \; ${""-P "" + sge_project} \; -binding ${""linear:"" + cpu} \; /usr/bin/env bash ${script}; """""". kill = ""qdel ${job_id}""; check-alive = ""qstat -j ${job_id}""; job-id-regex = ""(\\d+)""; }; }; }; }. call-caching {; enab",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7571:1523,config,config,1523,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7571,1,['config'],['config']
Modifiability,"2 other minor things popped up while call caching the 10K joint genotyping: ; - We spend a fair amount of time creating `GcsPathBuilder`s, which we shouldn't since we only need one per workflow in theory. In practice we need to create a few more because we can't quite propagate the same one around everywhere. But before this PR we would create one per job which seems inefficient. One reason for this is that `JobPaths` extends `WorkflowPaths`, so when we convert the latter to the former we effectively re-instantiate a new `WorkflowPaths` every time. This PR changes that so that `JobPaths` takes a `WorkflowPaths` instead as one of its attribute to avoid unnecessary re-allocations.; - A small optimization to the execution store which allows quicker lookup of ""Done"" jobs which we do a lot in `runnableCalls`. Also added a benchmark test that measures the performance of `runnableCalls`. Below are the results before and after this change. The ""size"" corresponds to how many jobs in ""Done"" and ""NotStarted"" states are inserted in the execution store before calling `runnableCalls`. Results are in ms. Before:; ![screen shot 2017-04-19 at 3 24 15 pm](https://cloud.githubusercontent.com/assets/2978948/25305440/fcca5418-2748-11e7-8d2a-6f2c645f2ef3.png). After:; ![screen shot 2017-04-19 at 3 25 18 pm](https://cloud.githubusercontent.com/assets/2978948/25305444/06de3f00-2749-11e7-860f-a1c077f3243f.png)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2198:422,extend,extends,422,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2198,1,['extend'],['extends']
Modifiability,"2-8bd9-e905ebe70980;shutdown=false;hsqldb.tx=mvcc; [2018-08-27 02:04:05,58] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2018-08-27 02:04:05,60] [info] [RenameWorkflowOptionsInMetadata] 100%; [2018-08-27 02:04:05,75] [info] Running with database db.url = jdbc:hsqldb:mem:c850e4aa-3449-4d7e-bf04-4593fe287777;shutdown=false;hsqldb.tx=mvcc; [2018-08-27 02:04:06,15] [warn] This actor factory is deprecated. Please use cromwell.backend.google.pipelines.v1alpha2.PipelinesApiLifecycleActorFactory for PAPI v1 or cromwell.backend.google.pipelines.v2alpha1.PipelinesApiLifecycleActorFactory for PAPI v2; [2018-08-27 02:04:06,16] [warn] Couldn't find a suitable DSN, defaulting to a Noop one.; [2018-08-27 02:04:06,16] [info] Using noop to send events.; [2018-08-27 02:04:06,43] [info] Slf4jLogger started; [2018-08-27 02:04:06,64] [info] Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-be06fbc"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; [2018-08-27 02:04:06,71] [info] Metadata summary refreshing every 2 seconds.; [2018-08-27 02:04:06,81] [info] KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; [2018-08-27 02:04:06,81] [info] WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; [2018-08-27 02:04:06,91] [info] CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; [2018-08-27 02:04:07,85] [info] JobExecutionTokenDispenser - Distribution rate: 50 per 1 seconds.; [2018-08-27 02:04:07,88] [info] SingleWorkflowRunnerActor: Version 34; [2018-08-27 02:04:07,90] [info] SingleWorkflowRunnerActor: Submitting workflow; [2018-08-27 02:04:07,91] [info] PAPIQueryManager Running with 3 workers; [2018-08-27 02:04:07,91] [info] JES batch polling interval is 33333 milliseconds; [2018-08-27 02:04:07,92] [info] JES batch polling interval is 3",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4039:1885,config,configuration,1885,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4039,1,['config'],['configuration']
Modifiability,"268581 container_name/cromwellazure_cromwell_1[2296]: #011at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActor.aroundReceive(WorkflowExecutionActor.scala:54); Sep 1 16:44:47 vmce33268581 container_name/cromwellazure_cromwell_1[2296]: #011at akka.actor.ActorCell.receiveMessage(ActorCell.scala:614); Sep 1 16:44:47 vmce33268581 container_name/cromwellazure_cromwell_1[2296]: #011at akka.actor.ActorCell.invoke(ActorCell.scala:583); Sep 1 16:44:47 vmce33268581 container_name/cromwellazure_cromwell_1[2296]: #011at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:268); Sep 1 16:44:47 vmce33268581 container_name/cromwellazure_cromwell_1[2296]: #011at akka.dispatch.Mailbox.run(Mailbox.scala:229); Sep 1 16:44:47 vmce33268581 container_name/cromwellazure_cromwell_1[2296]: #011at akka.dispatch.Mailbox.exec(Mailbox.scala:241); Sep 1 16:44:47 vmce33268581 container_name/cromwellazure_cromwell_1[2296]: #011at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); Sep 1 16:44:47 vmce33268581 container_name/cromwellazure_cromwell_1[2296]: #011at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); Sep 1 16:44:47 vmce33268581 container_name/cromwellazure_cromwell_1[2296]: #011at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); Sep 1 16:44:47 vmce33268581 container_name/cromwellazure_cromwell_1[2296]: #011at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Sep 1 16:44:51 vmce33268581 container_name/cromwellazure_cromwell_1[2296]: 2022-09-01 16:44:51,173 cromwell-system-akka.dispatchers.engine-dispatcher-29033 INFO - WorkflowManagerActor: Workflow actor for 2cd0993c-94df-4663-923d-48bbce3feead completed with status 'Failed'. The workflow will be removed from the workflow store. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6904:6304,config,configuration,6304,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6904,1,['config'],['configuration']
Modifiability,2ec8> (a sun.nio.ch.ChannelInputStream); at org.apache.commons.codec.digest.DigestUtils.updateDigest(DigestUtils.java:798); at org.apache.commons.codec.digest.DigestUtils.digest(DigestUtils.java:50); at org.apache.commons.codec.digest.DigestUtils.md5(DigestUtils.java:274); at org.apache.commons.codec.digest.DigestUtils.md5Hex(DigestUtils.java:310); at cromwell.backend.impl.sfs.config.HashFileStrategy$$anonfun$hash$3.apply(ConfigHashingStrategy.scala:70); at cromwell.backend.impl.sfs.config.HashFileStrategy$$anonfun$hash$3.apply(ConfigHashingStrategy.scala:70); at cromwell.util.TryWithResource$$anonfun$tryWithResource$1.apply(TryWithResource.scala:16); at scala.util.Try$.apply(Try.scala:192); at cromwell.util.TryWithResource$.tryWithResource(TryWithResource.scala:10); at cromwell.backend.impl.sfs.config.HashFileStrategy.hash(ConfigHashingStrategy.scala:70); at cromwell.backend.impl.sfs.config.ConfigHashingStrategy.getHash(ConfigHashingStrategy.scala:47); at cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory$$anonfun$fileHashingFunction$1.apply(ConfigBackendLifecycleActorFactory.scala:45); at cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory$$anonfun$fileHashingFunction$1.apply(ConfigBackendLifecycleActorFactory.scala:45); at cromwell.backend.callcaching.FileHashingActor$$anonfun$receive$1$$anonfun$1.apply(FileHashingActor.scala:21); at cromwell.backend.callcaching.FileHashingActor$$anonfun$receive$1$$anonfun$1.apply(FileHashingActor.scala:21); at scala.Option.map(Option.scala:146); at cromwell.backend.callcaching.FileHashingActor$$anonfun$receive$1.applyOrElse(FileHashingActor.scala:21); at akka.actor.Actor$class.aroundReceive(Actor.scala:484); at cromwell.backend.callcaching.FileHashingActor.aroundReceive(FileHashingActor.scala:16); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); at akka.actor.ActorCell.invoke(ActorCell.scala:495); at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); at akka.dispatch.Mailbox.run(,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1597:1958,config,config,1958,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1597,1,['config'],['config']
Modifiability,"381); at cromwell.server.WorkflowManagerSystem$class.allowedBackends(WorkflowManagerSystem.scala:24); at cromwell.Main$$anon$1.allowedBackends(Main.scala:97); at cromwell.server.WorkflowManagerSystem$class.$init$(WorkflowManagerSystem.scala:27); at cromwell.Main$$anon$1.<init>(Main.scala:97); at cromwell.Main.<init>(Main.scala:97); at cromwell.Main$.delayedEndpoint$cromwell$Main$1(Main.scala:49); at cromwell.Main$delayedInit$body.apply(Main.scala:31); at scala.Function0$class.apply$mcV$sp(Function0.scala:34); at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:12); at scala.App$$anonfun$main$1.apply(App.scala:76); at scala.App$$anonfun$main$1.apply(App.scala:76); at scala.collection.immutable.List.foreach(List.scala:381); at scala.collection.generic.TraversableForwarder$class.foreach(TraversableForwarder.scala:35); at scala.App$class.main(App.scala:76); at cromwell.Main$.main(Main.scala:31); at cromwell.Main.main(Main.scala); ```. I managed to fix _this_ exception by changing the configuration file to. ```; backed {; defaultBackend = ""SGE""; backendsAllowed = [; ""Local"", ""SGE""; ]; providers { .... }; }; ```. However, this introduces another exception after a few seconds. . ```; [2016-09-13 17:39:24,467] [info] Slf4jLogger started; [2016-09-13 17:39:24,541] [info] RUN sub-command; [2016-09-13 17:39:24,542] [info] WDL file: pipeline.wdl; [2016-09-13 17:39:24,543] [info] Inputs: inputs.json; [2016-09-13 17:39:24,622] [info] SingleWorkflowRunnerActor: launching workflow; [2016-09-13 17:39:25,911] [info] Running with database db.url = jdbc:hsqldb:mem:${uniqueSchema};shutdown=false;hsqldb.tx=mvcc; [2016-09-13 17:39:33,39] [info] WorkflowManagerActor submitWorkflow input id = None, effective id = 8eab0d5a-925a-4e99-ae3b-f30dfadacb58; Uncaught error from thread [cromwell-system-akka.actor.default-dispatcher-2] shutting down JVM since 'akka.jvm-exit-on-fatal-error' is enabled for ActorSystem[cromwell-system]; java.lang.ExceptionInInitializerError; at cromwe",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1406:1984,config,configuration,1984,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1406,1,['config'],['configuration']
Modifiability,"3:19:19,53] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2018-09-14 13:19:19,55] [info] [RenameWorkflowOptionsInMetadata] 100%; [2018-09-14 13:19:19,67] [info] Running with database db.url = jdbc:hsqldb:mem:e41fe9de-508c-4f49-aeaa-ce7474d7c1e2;shutdown=false;hsqldb.tx=mvcc; [2018-09-14 13:19:20,18] [info] Slf4jLogger started; [2018-09-14 13:19:20,25] [info] Pre Processing Workflow...; [2018-09-14 13:19:20,65] [info] Pre-Processing /home/jeremiah/gdc-dnaseq-cwl/workflows/bamfastq_align/transform_pack.cwl; [2018-09-14 13:19:54,70] [info] Pre Processing Inputs...; [2018-09-14 13:19:54,94] [info] Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-89ab52b"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; [2018-09-14 13:19:55,04] [info] Metadata summary refreshing every 2 seconds.; [2018-09-14 13:19:55,31] [info] KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; [2018-09-14 13:19:55,32] [info] WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; [2018-09-14 13:19:55,32] [info] CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; [2018-09-14 13:19:56,83] [info] JobExecutionTokenDispenser - Distribution rate: 50 per 1 seconds.; [2018-09-14 13:19:56,88] [info] SingleWorkflowRunnerActor: Version 35-fd560e9-SNAP; [2018-09-14 13:19:56,91] [info] SingleWorkflowRunnerActor: Submitting workflow; [2018-09-14 13:19:57,89] [info] CWL (Unspecified version) workflow caab4283-a3d4-4966-85ba-56d0992c8f00 submitted; [2018-09-14 13:19:57,90] [info] SingleWorkflowRunnerActor: Workflow submitted caab4283-a3d4-4966-85ba-56d0992c8f00; [2018-09-14 13:19:57,91] [info] 1 new workflows fetched; [2018-09-14 13:19:57,92] [info] WorkflowManagerActor Starting workflow caab4283-a3d4-4966-85ba-56d0992c8f00; [2018-09-14 13:19:57,93] [warn] SingleWo",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4103:1630,config,configured,1630,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4103,1,['config'],['configured']
Modifiability,"3:40:18 UTC] Obtaining toolchain_env file from https://storage.googleapis.com/cos-tools/12871.1174.0/toolchain_env. real	0m0.126s; user	0m0.014s; sys	0m0.001s; [INFO 2020-08-04 23:40:18 UTC] Downloading toolchain from https://storage.googleapis.com/cos-tools/12871.1174.0/toolchain.tar.xz. real	0m11.907s; user	0m0.428s; sys	0m1.039s; [INFO 2020-08-04 23:41:17 UTC] Configuring environment variables for cross-compilation; [INFO 2020-08-04 23:41:17 UTC] Configuring installation directories; [INFO 2020-08-04 23:41:17 UTC] Updating container's ld cache; [INFO 2020-08-04 23:41:20 UTC] Configuring kernel sources; [INFO 2020-08-04 23:41:42 UTC] Modifying kernel version magic string in source files; [INFO 2020-08-04 23:41:42 UTC] Running Nvidia installer. ERROR: The kernel module failed to load, because it was not signed by a key; that is trusted by the kernel. Please try installing the driver; again, and set the --module-signing-secret-key and; --module-signing-public-key options on the command line, or run the; installer in expert mode to enable the interactive module signing; prompts. ERROR: Unable to load the kernel module 'nvidia.ko'. This happens most; frequently when this kernel module was built against the wrong or; improperly configured kernel sources, with a version of gcc that; differs from the one used to build the target kernel, or if another; driver, such as nouveau, is present and prevents the NVIDIA kernel; module from obtaining ownership of the NVIDIA GPU(s), or no NVIDIA; GPU installed in this system is supported by this NVIDIA Linux; graphics driver release. Please see the log entries 'Kernel module load error' and 'Kernel; messages' at the end of the file; '/usr/local/nvidia/nvidia-installer.log' for more information. ERROR: Installation has failed. Please see the file; '/usr/local/nvidia/nvidia-installer.log' for details. You may find; suggestions on fixing installation problems in the README available; on the Linux driver download page at www.nvidia.com.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5714:5525,config,configured,5525,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5714,1,['config'],['configured']
Modifiability,"3d1cb48973da7f646a7de2 > /sandbox/users/foucal-a/test_atac-pipe/cromwell-executions/atac/f4fd93fa-6f3a-42a6-94f2-459901d245c4/call-trim_adapter/shard-0/execution/glob-4f26c666d13d1cb48973da7f646a7de2.list; ```; I have the error when the script tries to symlink all the files into the glob directory.; Here is the WDL code : ; ```; scatter( i in range(length(fastqs_)) ) {; # trim adapters and merge trimmed fastqs; call trim_adapter { input :; fastqs = fastqs_[i],; adapters = if length(adapters_)>0 then adapters_[i] else [],; paired_end = paired_end,; }; # align trimmed/merged fastqs with bowtie2s; call bowtie2 { input :; idx_tar = bowtie2_idx_tar,; fastqs = trim_adapter.trimmed_merged_fastqs, #[R1,R2]; paired_end = paired_end,; multimapping = multimapping,; }; }; ```; With the function :; ```; task trim_adapter { # trim adapters and merge trimmed fastqs; # parameters from workflow; Array[Array[File]] fastqs # [merge_id][read_end_id]; Array[Array[String]] adapters # [merge_id][read_end_id]; Boolean paired_end; # mandatory; Boolean? auto_detect_adapter # automatically detect/trim adapters; # optional; Int? min_trim_len # minimum trim length for cutadapt -m; Float? err_rate # Maximum allowed adapter error rate; # for cutadapt -e; # resource; Int? cpu; Int? mem_mb; Int? time_hr; #Commenting this line as a test. PRoblem with hard link; String? disks. command {; python $(which encode_trim_adapter.py) \; ${write_tsv(fastqs)} \; --adapters ${write_tsv(adapters)} \; ${if paired_end then ""--paired-end"" else """"} \; ${if select_first([auto_detect_adapter,false]) then ""--auto-detect-adapter"" else """"} \; ${""--min-trim-len "" + select_first([min_trim_len,5])} \; ${""--err-rate "" + select_first([err_rate,'0.1'])} \; ${""--nth "" + select_first([cpu,2])}; }; output {; # WDL glob() globs in an alphabetical order; # so R1 and R2 can be switched, which results in an; # unexpected behavior of a workflow; # so we prepend merge_fastqs_'end'_ (R1 or R2); # to the basename of original filename; # t",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3876:2499,adapt,adapters,2499,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3876,4,['adapt'],"['adapter', 'adapters']"
Modifiability,"4 08:55:06,54] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2023-02-04 08:55:06,55] [info] [RenameWorkflowOptionsInMetadata] 100%; [2023-02-04 08:55:06,64] [info] Running with database db.url = jdbc:hsqldb:mem:a487ea75-b617-4523-a254-d0e694e68ff9;shutdown=false;hsqldb.tx=mvcc; [2023-02-04 08:55:06,92] [info] Slf4jLogger started; [2023-02-04 08:55:07,18] [info] Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-b625dba"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; [2023-02-04 08:55:07,22] [info] Metadata summary refreshing every 2 seconds.; [2023-02-04 08:55:07,26] [info] KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; [2023-02-04 08:55:07,26] [info] WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; [2023-02-04 08:55:07,26] [info] CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; [2023-02-04 08:55:07,63] [info] JobExecutionTokenDispenser - Distribution rate: 50 per 1 seconds.; [2023-02-04 08:55:07,64] [info] SingleWorkflowRunnerActor: Version 34-unknown-SNAP; [2023-02-04 08:55:07,65] [info] SingleWorkflowRunnerActor: Submitting workflow; [2023-02-04 08:55:07,68] [info] Unspecified type (Unspecified version) workflow 48f62f22-25fe-4f0f-b5fe-21191f035abd submitted; [2023-02-04 08:55:07,72] [info] SingleWorkflowRunnerActor: Workflow submitted [38;5;2m48f62f22-25fe-4f0f-b5fe-21191f035abd[0m; [2023-02-04 08:55:07,75] [info] 1 new workflows fetched; [2023-02-04 08:55:07,75] [info] WorkflowManagerActor Starting workflow [38;5;2m48f62f22-25fe-4f0f-b5fe-21191f035abd[0m; [2023-02-04 08:55:07,76] [[38;5;220mwarn[0m] SingleWorkflowRunnerActor: received unexpected message: Done in state RunningSwraData; [2023-02-04 08:55:07,79] [[38;5;220mwarn[0m] Couldn't find a suitable DSN, defaulting to a Noop one.; [",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6999:1508,config,configured,1508,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6999,1,['config'],['configured']
Modifiability,"4-unknown-SNAP; [2023-02-04 08:55:07,65] [info] SingleWorkflowRunnerActor: Submitting workflow; [2023-02-04 08:55:07,68] [info] Unspecified type (Unspecified version) workflow 48f62f22-25fe-4f0f-b5fe-21191f035abd submitted; [2023-02-04 08:55:07,72] [info] SingleWorkflowRunnerActor: Workflow submitted [38;5;2m48f62f22-25fe-4f0f-b5fe-21191f035abd[0m; [2023-02-04 08:55:07,75] [info] 1 new workflows fetched; [2023-02-04 08:55:07,75] [info] WorkflowManagerActor Starting workflow [38;5;2m48f62f22-25fe-4f0f-b5fe-21191f035abd[0m; [2023-02-04 08:55:07,76] [[38;5;220mwarn[0m] SingleWorkflowRunnerActor: received unexpected message: Done in state RunningSwraData; [2023-02-04 08:55:07,79] [[38;5;220mwarn[0m] Couldn't find a suitable DSN, defaulting to a Noop one.; [2023-02-04 08:55:07,79] [info] Using noop to send events.; [2023-02-04 08:55:07,81] [info] WorkflowManagerActor Successfully started WorkflowActor-48f62f22-25fe-4f0f-b5fe-21191f035abd; [2023-02-04 08:55:07,81] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2023-02-04 08:55:07,81] [info] WorkflowStoreHeartbeatWriteActor configured to flush with batch size 10000 and process rate 2 minutes.; [2023-02-04 08:55:07,81] [info] MaterializeWorkflowDescriptorActor [[38;5;2m48f62f22[0m]: Parsing workflow as WDL 1.0; [2023-02-04 08:55:08,24] [[38;5;1merror[0m] WorkflowManagerActor Workflow 48f62f22-25fe-4f0f-b5fe-21191f035abd failed (during MaterializingWorkflowDescriptorState): cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anon$1: Workflow input processing failed:; The label in the input is too long; java.base/java.net.IDN.toASCIIInternal(IDN.java:340); java.base/java.net.IDN.toASCII(IDN.java:122); java.base/java.net.IDN.toASCII(IDN.java:151); com.softwaremill.sttp.Uri.encodeHost(Uri.scala:171); com.softwaremill.sttp.Uri.toString(Uri.scala:122); com.softwaremill.sttp.asynchttpclient.AsyncHttpClientBackend.requestToAsync(AsyncHttpClientBackend.scala:152); com.softwar",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6999:2848,config,configured,2848,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6999,1,['config'],['configured']
Modifiability,"47:56,493 WARN - Skipping auto-registration; 2021-09-27 13:47:57,524 INFO - Reference disks feature for PAPIv2 backend is not configured.; 2021-09-27 13:47:58,075 INFO - Slf4jLogger started; 2021-09-27 13:47:58,470 cromwell-system-akka.dispatchers.engine-dispatcher-9 INFO - Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-69bdc1a"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""failureShutdownDuration"" : ""5 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; 2021-09-27 13:47:58,845 cromwell-system-akka.dispatchers.service-dispatcher-15 INFO - Metadata summary refreshing every 1 second.; 2021-09-27 13:47:58,865 cromwell-system-akka.dispatchers.service-dispatcher-15 INFO - No metadata archiver defined in config; 2021-09-27 13:47:58,865 cromwell-system-akka.dispatchers.service-dispatcher-15 INFO - No metadata deleter defined in config; 2021-09-27 13:47:58,926 cromwell-system-akka.dispatchers.engine-dispatcher-27 INFO - JobStoreWriterActor configured to flush with batch size 1000 and process rate 1 second.; 2021-09-27 13:47:58,929 cromwell-system-akka.dispatchers.service-dispatcher-14 INFO - WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; 2021-09-27 13:47:58,935 cromwell-system-akka.dispatchers.engine-dispatcher-30 INFO - CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; 2021-09-27 13:47:58,937 cromwell-system-akka.actor.default-dispatcher-7 INFO - KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; 2021-09-27 13:47:59,274 cromwell-system-akka.dispatchers.engine-dispatcher-31 INFO - JobExecutionTokenDispenser - Distribution rate: 20 per 10 seconds.; 2021-09-27 13:47:59,340 cromwell-system-akka.dispatchers.backend-dispatcher-34 INFO - Running with 3 PAPI request workers; 2021-09-27 13:47:59,340 cromwell-system-akka.dispatchers.backend-dispatcher-34 INFO - 'resetAllWorkers()' called to fill vector with 3 new workers; 2021-09-",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6506:6456,config,configured,6456,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6506,1,['config'],['configured']
Modifiability,"4842beb\"",\""os\"":\""linux\"",\""parent\"":\""633c756fc95cb19efd13b84a949066c65f5b6683d0922d1980b6a19deb855fa0\"",\""throwaway\"":true}""; },; {; ""v1Compatibility"": ""{\""id\"":\""633c756fc95cb19efd13b84a949066c65f5b6683d0922d1980b6a19deb855fa0\"",\""created\"":\""2017-08-07T23:50:27.303876981Z\"",\""container_config\"":{\""Cmd\"":[\""/bin/sh -c #(nop) ADD file:fb17197475bb59bfb365c41f28d4bc15134b8dcb8907819e7be54bce53328c03 in / \""]}}""; }; ],; ""schemaVersion"": 1,; ""signatures"": [; {; ""header"": {; ""jwk"": {; ""crv"": ""P-256"",; ""kid"": ""4DPT:XWGC:ESR7:JVJY:2RON:CMML:IXIT:QXQ5:LGLL:LPJF:PWDL:AJSO"",; ""kty"": ""EC"",; ""x"": ""BjSTZs2e-5wP1bu4deBughI6YALM3vbLbZL-CGBRcmM"",; ""y"": ""Qj5Fr4Z1BQRe4EXMe-75dOkvIDzP-0u5cks8my7hkCA""; },; ""alg"": ""ES256""; },; ""signature"": ""ewZ_2lh2-uWSpw5tcprbhoFvjLoxGqsI06YSlvq4w2eXB5EEpMsk5Jo6WYRBeYeJxv0vnoe7SbN_1qarBAU9uQ"",; ""protected"": ""eyJmb3JtYXRMZW5ndGgiOjIxOTUsImZvcm1hdFRhaWwiOiJmUSIsInRpbWUiOiIyMDE3LTExLTA2VDE2OjE2OjE4WiJ9""; }; ]; }; ```. ```bash; $ curl -i -s -H 'Accept: application/vnd.docker.distribution.manifest.v2+json' https://gcr.io/v2/google-containers/ubuntu-slim/manifests/0.14; HTTP/1.1 200 OK; Docker-Distribution-API-Version: registry/2.0; Content-Type: application/vnd.docker.distribution.manifest.v2+json; Content-Length: 529; Docker-Content-Digest: sha256:1d5c0118358fc7651388805e404fe491a80f489bf0e7c5f8ae4156250d6ec7d8; Date: Mon, 06 Nov 2017 16:16:59 GMT; Server: Docker Registry; X-XSS-Protection: 1; mode=block; X-Frame-Options: SAMEORIGIN; Alt-Svc: quic="":443""; ma=2592000; v=""41,39,38,37,35"". {; ""schemaVersion"": 2,; ""mediaType"": ""application/vnd.docker.distribution.manifest.v2+json"",; ""config"": {; ""mediaType"": ""application/vnd.docker.container.image.v1+json"",; ""size"": 1528,; ""digest"": ""sha256:fba1281b32ffd9048881f99d8de0218c71552c4c91f09844b4b189b16e51cdca""; },; ""layers"": [; {; ""mediaType"": ""application/vnd.docker.image.rootfs.diff.tar.gzip"",; ""size"": 18278657,; ""digest"": ""sha256:1c4816548d6a2a08f89c304bf09503e791a338c4be90629610152124c7285d3f""; }; ]; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2826:5308,config,config,5308,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2826,2,"['config', 'layers']","['config', 'layers']"
Modifiability,"4893-8dcf-465c27da13d7/call-ls/shard-2/inputs/home/redmar/devel/wdl/test/issue/womtool-31.jar""], [""/home/redmar/devel/wdl/test/issue/cromwell-executions/wf/977d0c47-9cf5-4893-8dcf-465c27da13d7/call-ls/shard-3/inputs/home/redmar/devel/wdl/test/issue/womtool-36.jar""]]; }. Cromwell Womtool 36. $ java -jar womtool-36.jar validate wf.wdl ; ; $ java -jar cromwell-36.jar run --inputs wf.json wf.wdl ; [2019-01-15 15:09:17,10] [info] Running with database db.url = jdbc:hsqldb:mem:e77f2c21-f28a-4571-ba89-d915b85b25fc;shutdown=false;hsqldb.tx=mvcc; [2019-01-15 15:09:22,59] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2019-01-15 15:09:22,60] [info] [RenameWorkflowOptionsInMetadata] 100%; [2019-01-15 15:09:22,67] [info] Running with database db.url = jdbc:hsqldb:mem:52af65c3-a08f-4d3a-a6bc-c97a3d7e1a3c;shutdown=false;hsqldb.tx=mvcc; [2019-01-15 15:09:22,97] [info] Slf4jLogger started; [2019-01-15 15:09:23,24] [info] Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-d961aae"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; .; .; [2019-01-15 15:09:29,85] [error] WorkflowManagerActor Workflow 5bc372e9-61f6-45fd-b178-60ed25529216 failed (during ExecutingWorkflowState): cromwell.engine.workflow.lifecycle.execution.job.preparation.JobPreparationActor$$anonfun$1$$anon$1: Call input and runtime attributes evaluation failed for ls:; Failed to evaluate input 'files' (reason 1 of 1): No coercion defined from wom value(s) '""womtool-31.jar""' of type 'File' to 'Array[File]'.; .; .; Workflow 5bc372e9-61f6-45fd-b178-60ed25529216 transitioned to state Failed. [issue.zip](https://github.com/broadinstitute/cromwell/files/2759990/issue.zip). I've attached the `wdl` and `json` files I've used, the input filenames are the `jar` files of both cromwell and womtool used to run the test workflow. I'm not attaching those because they are very large.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4550:2515,config,configuration,2515,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4550,1,['config'],['configuration']
Modifiability,5 web start-cromwell.sh[110916]: at org.apache.commons.codec.digest.DigestUtils.md5Hex(DigestUtils.java:310); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.backend.impl.sfs.config.HashFileStrategy.$anonfun$hash$3(ConfigHashingStrategy.scala:82); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.util.TryWithResource$.$anonfun$tryWithResource$1(TryWithResource.scala:16); Mar 09 00:55:25 web start-cromwell.sh[110916]: at scala.util.Try$.apply(Try.scala:209); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.util.TryWithResource$.tryWithResource(TryWithResource.scala:10); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.backend.impl.sfs.config.HashFileStrategy.hash(ConfigHashingStrategy.scala:82); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.backend.impl.sfs.config.ConfigHashingStrategy.usingStandardInitData$1(ConfigHashingStrategy.scala:52); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.backend.impl.sfs.config.ConfigHashingStrategy.getHash(ConfigHashingStrategy.scala:57); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.backend.impl.sfs.config.ConfigBackendFileHashingActor.customHashStrategy(ConfigBackendFileHashingActor.scala:26); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.backend.standard.callcaching.StandardFileHashingActor$$anonfun$fileHashingReceive$1.applyOrElse(StandardFileHashingActor.scala:73); Mar 09 00:55:25 web start-cromwell.sh[110916]: at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); Mar 09 00:55:25 web start-cromwell.sh[110916]: at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); Mar 09 00:55:25 web start-cromwell.sh[110916]: at akka.actor.Actor.aroundReceive(Actor.scala:514); Mar 09 00:55:25 web start-cromwell.sh[110916]: at akka.actor.Actor.aroundReceive$(Actor.scala:512); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.backend.standard.callcaching.StandardFileHashingActor.aroundReceive(StandardFileHashingA,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3383:2931,Config,ConfigHashingStrategy,2931,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3383,1,['Config'],['ConfigHashingStrategy']
Modifiability,5); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.writeScriptContents$(SharedFileSystemAsyncJobExecutionActor.scala:174); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.cromwell$backend$sfs$BackgroundAsyncJobExecutionActor$$super$writeScriptContents(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.sfs.BackgroundAsyncJobExecutionActor.writeScriptContents(BackgroundAsyncJobExecutionActor.scala:12); 	at cromwell.backend.sfs.BackgroundAsyncJobExecutionActor.writeScriptContents$(BackgroundAsyncJobExecutionActor.scala:11); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.writeScriptContents(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.execute(SharedFileSystemAsyncJobExecutionActor.scala:158); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.execute$(SharedFileSystemAsyncJobExecutionActor.scala:155); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.execute(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$executeAsync$1(StandardAsyncExecutionActor.scala:639); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeAsync(StandardAsyncExecutionActor.scala:639); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeAsync$(StandardAsyncExecutionActor.scala:639); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.executeAsync(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover(StandardAsyncExecutionActor.scala:954); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover$(StandardAsyncExecutionActor.scala:946); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.executeOrRecover(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.async.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5066:11646,config,config,11646,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5066,1,['config'],['config']
Modifiability,"6-e3be-4953-92f1-60af623e6fa5/b6b190d6-8640-4638-94cd-15f16b194f38/echo_strings/c386672d-0248-4968-9b1a-114f5f5c4706/call-echo_files/echo_files-stderr.log"",; ""callRoot"": ""gs://fc-2d3fd356-e3be-4953-92f1-60af623e6fa5/b6b190d6-8640-4638-94cd-15f16b194f38/echo_strings/c386672d-0248-4968-9b1a-114f5f5c4706/call-echo_files"",; ""attempt"": 1,; ""executionEvents"": [...],; ""backendLogs"": {; ""log"": ""gs://fc-2d3fd356-e3be-4953-92f1-60af623e6fa5/b6b190d6-8640-4638-94cd-15f16b194f38/echo_strings/c386672d-0248-4968-9b1a-114f5f5c4706/call-echo_files/echo_files.log""; },; ""start"": ""2017-01-30T19:00:03.896Z""; }]; },; ""outputs"": {. },; ""workflowRoot"": ""/b6b190d6-8640-4638-94cd-15f16b194f38/echo_strings/c386672d-0248-4968-9b1a-114f5f5c4706/"",; ""id"": ""c386672d-0248-4968-9b1a-114f5f5c4706"",; ""inputs"": {...; },; ""submission"": ""2017-01-30T19:00:00.796Z"",; ""status"": ""Failed"",; ""failures"": [{; ""message"": ""Task c386672d-0248-4968-9b1a-114f5f5c4706:echo_files failed: error code 5. Message: 8: Failed to pull image ubuntu:latest: \""docker --config /tmp/.docker/ pull ubuntu:latest\"" failed: exit status 1: Pulling repository docker.io/library/ubuntu\nNetwork timed out while trying to connect to https://index.docker.io/v1/repositories/library/ubuntu/images. You may want to check your internet connection or if you are behind a proxy.\n""; }],; ""workflowLog"": ""gs://fc-2d3fd356-e3be-4953-92f1-60af623e6fa5/b6b190d6-8640-4638-94cd-15f16b194f38/workflow.logs/workflow.c386672d-0248-4968-9b1a-114f5f5c4706.log"",; ""end"": ""2017-01-30T19:14:20.002Z"",; ""start"": ""2017-01-30T19:00:03.040Z""; }. ```; Here it's an array of ""message""s; ```; {; ""workflowName"": ""aggregate_data_workflow"",; ""submittedFiles"": {... },; ""calls"": {; ""aggregate_data_workflow.aggregate_data"": [{; ""retryableFailure"": false,; ""executionStatus"": ""Failed"",; ""stdout"": ""/cromwell-executions/aggregate_data_workflow/3608d6ca-fbb4-4232-b197-268058470bfc/call-aggregate_data/execution/stdout"",; ""shardIndex"": -1,; ""runtimeAttributes"": {; ""docker"": ""broadgdac/a",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2037:2700,config,config,2700,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2037,1,['config'],['config']
Modifiability,"6:xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\""]: exit status 1 (standard error: \""error pulling image configuration: error parsing HTTP 400 response body: invalid character '<' looking for beginning of value: \\\""<?xml version='1.0' encoding='UTF-8'?><Error><Code>UserProjectMissing</Code><Message>Bucket is a requester pays bucket but no user project provided.</Message><Details>Bucket is Requester Pays bucket but no billing project id provided for non-owner.</Details></Error>\\\""\\n\"")"",`. I understand that the issue is that the Google bucket where the docker is located is requester pays and Cromwell does not know what to do in this case, but it is not immediately clear what I should do to fix it. It would be a great improvement if Cromwell could interpret this response and provide a more informative error message so that the user could immediately know what needs to be addressed. In particular, I am not fully sure what I should be doing. These are excerpts from my configuration file:; ```; ...; engine {; filesystems {; gcs {; auth = ""service-account""; project = ""xxx""; }; }; }; ...; services {; MetadataService {; ...; config {; carbonite-metadata-service {; filesystems {; gcs {; auth = ""service-account""; }; }; ...; }; }; }; }; ...; backend {; default = PAPIv2. providers {; PAPIv2 {; actor-factory = ""cromwell.backend.google.pipelines.v2beta.PipelinesApiLifecycleActorFactory""; config {; project = ""xxx""; ...; filesystems {; gcs {; auth = ""service-account""; project = ""xxx""; ...; }; }; ...; }; }; }; }; ...; ```; Where should the configuration for telling Cromwell which project to use when pulling dockers be?. I also do not understand why this issue arises at all as the Google bucket with the dockers is a us multi-region bucket and the computation is in us-central1, so there should be no egress costs when pulling the docker and therefore no need for a billing project. Clearly I am not understanding this problem entirely. I would be grateful for a clari",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6235:1301,config,configuration,1301,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6235,1,['config'],['configuration']
Modifiability,"7 02:04:06,81] [info] WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; [2018-08-27 02:04:06,91] [info] CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; [2018-08-27 02:04:07,85] [info] JobExecutionTokenDispenser - Distribution rate: 50 per 1 seconds.; [2018-08-27 02:04:07,88] [info] SingleWorkflowRunnerActor: Version 34; [2018-08-27 02:04:07,90] [info] SingleWorkflowRunnerActor: Submitting workflow; [2018-08-27 02:04:07,91] [info] PAPIQueryManager Running with 3 workers; [2018-08-27 02:04:07,91] [info] JES batch polling interval is 33333 milliseconds; [2018-08-27 02:04:07,92] [info] JES batch polling interval is 33333 milliseconds; [2018-08-27 02:04:07,93] [info] JES batch polling interval is 33333 milliseconds; [2018-08-27 02:04:07,98] [info] Unspecified type (Unspecified version) workflow 967af8b6-0d68-44c4-b04e-204674333468 submitted; [2018-08-27 02:04:08,05] [info] SingleWorkflowRunnerActor: Workflow submitted 967af8b6-0d68-44c4-b04e-204674333468; [2018-08-27 02:04:08,05] [info] 1 new workflows fetched; [2018-08-27 02:04:08,05] [info] WorkflowManagerActor Starting workflow 967af8b6-0d68-44c4-b04e-204674333468; [2018-08-27 02:04:08,06] [warn] SingleWorkflowRunnerActor: received unexpected message: Done in state RunningSwraData; [2018-08-27 02:04:08,07] [info] WorkflowManagerActor Successfully started WorkflowActor-967af8b6-0d68-44c4-b04e-204674333468; [2018-08-27 02:04:08,07] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2018-08-27 02:04:08,09] [info] WorkflowStoreHeartbeatWriteActor configured to flush with batch size 10000 and process rate 2 minutes.; [2018-08-27 02:04:08,17] [info] MaterializeWorkflowDescriptorActor [967af8b6]: Parsing workflow as WDL draft-2; [2018-08-27 02:04:08,86] [info] MaterializeWorkflowDescriptorActor [967af8b6]: Call-to-Backend assignments: wgbs.flatten_ -> singularity; [2018-08-27 02:04:12,30] [info] WorkflowExecutionActor-967af8b6-0d68-44c4-b0",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4039:3858,config,configured,3858,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4039,1,['config'],['configured']
Modifiability,"7 13:47:58,845 cromwell-system-akka.dispatchers.service-dispatcher-15 INFO - Metadata summary refreshing every 1 second.; 2021-09-27 13:47:58,865 cromwell-system-akka.dispatchers.service-dispatcher-15 INFO - No metadata archiver defined in config; 2021-09-27 13:47:58,865 cromwell-system-akka.dispatchers.service-dispatcher-15 INFO - No metadata deleter defined in config; 2021-09-27 13:47:58,926 cromwell-system-akka.dispatchers.engine-dispatcher-27 INFO - JobStoreWriterActor configured to flush with batch size 1000 and process rate 1 second.; 2021-09-27 13:47:58,929 cromwell-system-akka.dispatchers.service-dispatcher-14 INFO - WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; 2021-09-27 13:47:58,935 cromwell-system-akka.dispatchers.engine-dispatcher-30 INFO - CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; 2021-09-27 13:47:58,937 cromwell-system-akka.actor.default-dispatcher-7 INFO - KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; 2021-09-27 13:47:59,274 cromwell-system-akka.dispatchers.engine-dispatcher-31 INFO - JobExecutionTokenDispenser - Distribution rate: 20 per 10 seconds.; 2021-09-27 13:47:59,340 cromwell-system-akka.dispatchers.backend-dispatcher-34 INFO - Running with 3 PAPI request workers; 2021-09-27 13:47:59,340 cromwell-system-akka.dispatchers.backend-dispatcher-34 INFO - 'resetAllWorkers()' called to fill vector with 3 new workers; 2021-09-27 13:48:00,372 cromwell-system-akka.dispatchers.backend-dispatcher-34 INFO - Request manager PAPIQueryManager created new PAPI request worker PAPIQueryWorker-9bdf68fb-2a83-40d7-9836-596fb3ff4aa2 with batch interval of 33333 milliseconds; 2021-09-27 13:48:00,381 cromwell-system-akka.dispatchers.backend-dispatcher-34 INFO - Request manager PAPIQueryManager created new PAPI request worker PAPIQueryWorker-51f769c6-7a82-4746-810c-c31fa5342ca3 with batch interval of 33333 milliseconds; 2021-09-27 13:48:00,382 cr",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6506:6965,config,configured,6965,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6506,1,['config'],['configured']
Modifiability,"7 16:21:16,40] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2019-01-07 16:21:16,42] [info] [RenameWorkflowOptionsInMetadata] 100%; [2019-01-07 16:21:16,62] [info] Running with database db.url = jdbc:hsqldb:mem:2efc8123-f7e8-4fe3-abed-48d1bcf8eb97;shutdown=false;hsqldb.tx=mvcc; [2019-01-07 16:21:17,27] [info] Slf4jLogger started; [2019-01-07 16:21:17,78] [info] Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-231ef13"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; [2019-01-07 16:21:17,87] [info] Metadata summary refreshing every 2 seconds.; [2019-01-07 16:21:17,94] [info] WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; [2019-01-07 16:21:18,00] [info] KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; [2019-01-07 16:21:18,02] [info] CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; [2019-01-07 16:21:19,53] [info] JobExecutionTokenDispenser - Distribution rate: 50 per 1 seconds.; [2019-01-07 16:21:19,58] [info] SingleWorkflowRunnerActor: Version 36; [2019-01-07 16:21:19,61] [info] SingleWorkflowRunnerActor: Submitting workflow; [2019-01-07 16:21:19,69] [info] Unspecified type (Unspecified version) workflow 18de8166-5f29-4288-9fa4-6741565446fd submitted; [2019-01-07 16:21:19,74] [info] SingleWorkflowRunnerActor: Workflow submitted [38;5;2m18de8166-5f29-4288-9fa4-6741565446fd[0m; [2019-01-07 16:21:19,75] [info] 1 new workflows fetched; [2019-01-07 16:21:19,77] [info] WorkflowManagerActor Starting workflow [38;5;2m18de8166-5f29-4288-9fa4-6741565446fd[0m; [2019-01-07 16:21:19,77] [info] WorkflowManagerActor Successfully started WorkflowActor-18de8166-5f29-4288-9fa4-6741565446fd; [2019-01-07 16:21:19,77] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2019-01-07 16:21:19,78] [info] WorkflowSto",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4526:1781,config,configured,1781,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4526,1,['config'],['configured']
Modifiability,74); at wdl.draft3.transforms.wdlom2wom.FileElementToWomBundle$$anon$1.toWomBundle(FileElementToWomBundle.scala:30); at wom.transforms.WomBundleMaker$Ops.toWomBundle(WomExecutableMaker.scala:16); at wom.transforms.WomBundleMaker$Ops.toWomBundle$(WomExecutableMaker.scala:16); at wom.transforms.WomBundleMaker$ops$$anon$2.toWomBundle(WomExecutableMaker.scala:16); at wdl.draft3.transforms.wdlom2wom.FileElementToWomBundle$.convert(FileElementToWomBundle.scala:83); at wdl.draft3.transforms.wdlom2wom.package$.$anonfun$fileElementToWomBundle$1(package.scala:13); at scala.util.Either$RightProjection.flatMap(Either.scala:702); at cats.instances.EitherInstances$$anon$1.flatMap(either.scala:36); at cats.instances.EitherInstances$$anon$1.flatMap(either.scala:32); at cats.data.Kleisli.$anonfun$andThen$1(Kleisli.scala:37); at languages.wdl.draft3.WdlDraft3LanguageFactory.getWomBundle(WdlDraft3LanguageFactory.scala:50); at womtool.input.WomGraphMaker$.$anonfun$getBundleAndFactory$1(WomGraphMaker.scala:49); at scala.util.Either.flatMap(Either.scala:338); at womtool.input.WomGraphMaker$.getBundleAndFactory(WomGraphMaker.scala:40); at womtool.input.WomGraphMaker$.getBundle(WomGraphMaker.scala:22); at womtool.validate.Validate$.validate(Validate.scala:14); at womtool.WomtoolMain$.dispatchCommand(WomtoolMain.scala:44); at womtool.WomtoolMain$.runWomtool(WomtoolMain.scala:125); at womtool.WomtoolMain$.delayedEndpoint$womtool$WomtoolMain$1(WomtoolMain.scala:130); at womtool.WomtoolMain$delayedInit$body.apply(WomtoolMain.scala:18); at scala.Function0.apply$mcV$sp(Function0.scala:34); at scala.Function0.apply$mcV$sp$(Function0.scala:34); at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:12); at scala.App.$anonfun$main$1$adapted(App.scala:76); at scala.collection.immutable.List.foreach(List.scala:389); at scala.App.main(App.scala:76); at scala.App.main$(App.scala:74); at womtool.WomtoolMain$.main(WomtoolMain.scala:18); at womtool.WomtoolMain.main(WomtoolMain.scala); ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3977:6133,adapt,adapted,6133,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3977,1,['adapt'],['adapted']
Modifiability,"784a16c613c62b8bec1c, the ""maybe_file with concatenation"" leaves a residual `gs://` path; all other interpolations are correctly relativized. On AWS with Cromwell 9341a4dac6145233f2a33b092a8fc443c18744ea, both concatenations leave residual `s3://` paths. On Local with Cromwell 7c52320b3844fb83959a784a16c613c62b8bec1c and an input file under my home directory, this throws an exception with the following trace:. ```; 2017-02-02 11:55:36,701 cromwell-system-akka.dispatchers.backend-dispatcher-44 ERROR - BackgroundConfigAsyncJobExecutionActor [UUID(5fdb357a)w.files:NA:1]: Error attempting to Execute; java.lang.IllegalArgumentException: null; 	at sun.nio.fs.UnixPath.subpath(UnixPath.java:346); 	at sun.nio.fs.UnixPath.subpath(UnixPath.java:43); 	at cromwell.backend.io.JobPathsWithDocker.toDockerPath(JobPathsWithDocker.scala:35); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor$class.toUnixPath(SharedFileSystemAsyncJobExecutionActor.scala:107); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.toUnixPath(ConfigAsyncJobExecutionActor.scala:113); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor$$anonfun$commandLineValueMapper$1.apply(SharedFileSystemAsyncJobExecutionActor.scala:127); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor$$anonfun$commandLineValueMapper$1.apply(SharedFileSystemAsyncJobExecutionActor.scala:127); 	at wdl4s.command.ParameterCommandPart.instantiate(ParameterCommandPart.scala:55); 	at wdl4s.Task$$anonfun$instantiateCommand$1$$anonfun$apply$2.apply(Task.scala:108); 	at wdl4s.Task$$anonfun$instantiateCommand$1$$anonfun$apply$2.apply(Task.scala:108); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.IterableLike$clas",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1944:1544,config,config,1544,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1944,1,['config'],['config']
Modifiability,"79] [info] BackgroundConfigAsyncJobExecutionActor [814c47aaaggregate_mafs_workflow.aggregate_mafs:NA:1]: BackgroundConfigAsyncJobExecutionActor [814c47aa:aggregate_mafs_workflow.aggregate_mafs:NA:1] Status change from - to SharedFileSystemRunStatus(false); [2017-01-20 09:33:07,55] [info] BackgroundConfigAsyncJobExecutionActor [814c47aaaggregate_mafs_workflow.aggregate_mafs:NA:1]: BackgroundConfigAsyncJobExecutionActor [814c47aa:aggregate_mafs_workflow.aggregate_mafs:NA:1] Status change from SharedFileSystemRunStatus(false) to SharedFileSystemRunStatus(true); [2017-01-20 09:33:07,58] [info] Message [cromwell.subworkflowstore.SubWorkflowStoreActor$SubWorkflowStoreCompleteSuccess] from Actor[akka://cromwell-system/user/SingleWorkflowRunnerActor/$b#-910401033] to Actor[akka://cromwell-system/user/SingleWorkflowRunnerActor/WorkflowManagerActor/WorkflowActor-814c47aa-9d11-4c81-a08c-f2b77c002b46#617869376] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2017-01-20 09:33:07,58] [error] WorkflowManagerActor Workflow 814c47aa-9d11-4c81-a08c-f2b77c002b46 failed (during ExecutingWorkflowState): Call aggregate_mafs_workflow.aggregate_mafs:NA:1: return code was 1; java.lang.RuntimeException: Call aggregate_mafs_workflow.aggregate_mafs:NA:1: return code was 1; 	at cromwell.backend.standard.StandardAsyncExecutionActor$class.handleExecutionResult(StandardAsyncExecutionActor.scala:432); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.handleExecutionResult(ConfigAsyncJobExecutionActor.scala:113); 	at cromwell.backend.standard.StandardAsyncExecutionActor$class.handlePollSuccess(StandardAsyncExecutionActor.scala:370); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.handlePollSuccess(ConfigAsyncJobExecutionActor.scala:113); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$po",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1906:12924,config,configuration,12924,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1906,1,['config'],['configuration']
Modifiability,"86bda47d/call-SplitFilesByChromosome/glob-6f4bc12a708659d4f5f3eecd1cdffff7/chr10.intervals \; -I /cromwell_root/s4-pbg-hc/HC_Dev_Run_5/Pipeline/RSM278260-6_8plex/pipeline_workflow/3997371c-9513-4386-a579-a72639c6e960/call-Haplotypecaller/shard-0/hc.Haplotypecaller/755021ae-948b-47f9-94a8-66b486bda47d/call-SplitFilesByChromosome/glob-313957810a5e411f50b17b2a7d630ef7/chr10.RSM278260-6_8plex.dedup.recal.bam \; -O RSM278260-6_8plex.hc.gvcf.gz \; -ERC GVCF \; \; [2019-05-22 19:19:19,34] [info] AwsBatchAsyncBackendJobExecutionActor [755021aeHaplotypecaller.HC_GVCF:6:1]: set -e; sambamba index -t 4 /cromwell_root/s4-pbg-hc/HC_Dev_Run_5/Pipeline/RSM278260-6_8plex/pipeline_workflow/3997371c-9513-4386-a579-a72639c6e960/call-Haplotypecaller/shard-0/hc.Haplotypecaller/755021ae-948b-47f9-94a8-66b486bda47d/call-SplitFilesByChromosome/glob-313957810a5e411f50b17b2a7d630ef7/chr15.RSM278260-6_8plex.dedup.recal.bam; gatk HaplotypeCaller \; --java-options -Djava.io.tmpdir='' \; -R /cromwell_root/s4-ngs-resources-sandbox/Genomic/Broad/hg19/ucsc.hg19.fasta \; --dbsnp /cromwell_root/s4-ngs-resources-sandbox/Variant/Broad/hg19/dbsnp_138.hg19.vcf.gz \; --native-pair-hmm-threads 16 \; -L /cromwell_root/s4-pbg-hc/HC_Dev_Run_5/Pipeline/RSM278260-6_8plex/pipeline_workflow/3997371c-9513-4386-a579-a72639c6e960/call-Haplotypecaller/shard-0/hc.Haplotypecaller/755021ae-948b-47f9-94a8-66b486bda47d/call-SplitFilesByChromosome/glob-6f4bc12a708659d4f5f3eecd1cdffff7/chr15.intervals \; -I /cromwell_root/s4-pbg-hc/HC_Dev_Run_5/Pipeline/RSM278260-6_8plex/pipeline_workflow/3997371c-9513-4386-a579-a72639c6e960/call-Haplotypecaller/shard-0/hc.Haplotypecaller/755021ae-948b-47f9-94a8-66b486bda47d/call-SplitFilesByChromosome/glob-313957810a5e411f50b17b2a7d630ef7/chr15.RSM278260-6_8plex.dedup.recal.bam \; -O RSM278260-6_8plex.hc.gvcf.gz \; -ERC GVCF \; \; [2019-05-22 19:19:19,34] [info] Submitting job to AWS Batch; [2019-05-22 19:19:19,34] [info] dockerImage: 260062248592.dkr.ecr.us-east-1.amazonaws.com/s4-alignan",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5004:7131,sandbox,sandbox,7131,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5004,1,['sandbox'],['sandbox']
Modifiability,91b-46a7-b892-86454be067fd failed (during MaterializingWorkflowDescriptorState): cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anon$1: Workflow input processing failed:; Boxed Error; scala.concurrent.impl.Promise$.resolver(Promise.scala:83); scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:280); scala.concurrent.Promise.complete(Promise.scala:49); scala.concurrent.Promise.complete$(Promise.scala:48); scala.concurrent.impl.Promise$DefaultPromise.complete(Promise.scala:183); scala.concurrent.Promise.failure(Promise.scala:100); scala.concurrent.Promise.failure$(Promise.scala:100); scala.concurrent.impl.Promise$DefaultPromise.failure(Promise.scala:183); cats.effect.IO.$anonfun$unsafeToFuture$2(IO.scala:328); scala.util.Either.fold(Either.scala:189); cats.effect.IO.$anonfun$unsafeToFuture$1(IO.scala:328); cats.effect.IO.$anonfun$unsafeToFuture$1$adapted(IO.scala:328); cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:98); cats.effect.internals.IORunLoop$.start(IORunLoop.scala:35); cats.effect.IO.unsafeRunAsync(IO.scala:257); cats.effect.IO.unsafeToFuture(IO.scala:328); cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$1.$anonfun$applyOrElse$1(MaterializeWorkflowDescriptorActor.scala:146); scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:303); scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91); scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81); akka.dispatch.BatchingExecutor$BlockableBatc,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3736:2531,adapt,adapted,2531,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736,1,['adapt'],['adapted']
Modifiability,"96); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:234); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); [2018-05-02 15:22:54,71] [[38;5;1merror[0m] bc4644da:batch_for_variantcall:-1:1: Hash error, disabling call caching for this job.; java.io.FileNotFoundException: Cannot hash file null because it can't be found; 	at cromwell.backend.impl.sfs.config.ConfigHashingStrategy.usingStandardInitData$1(ConfigHashingStrategy.scala:46); 	at cromwell.backend.impl.sfs.config.ConfigHashingStrategy.getHash(ConfigHashingStrategy.scala:57); 	at cromwell.backend.impl.sfs.config.ConfigBackendFileHashingActor.customHashStrategy(ConfigBackendFileHashingActor.scala:26); 	at cromwell.backend.standard.callcaching.StandardFileHashingActor$$anonfun$fileHashingReceive$1.applyOrElse(StandardFileHashingActor.scala:79); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at akka.actor.Actor.aroundReceive(Actor.scala:514); 	at akka.actor.Actor.aroundReceive$(Actor.scala:512); 	at cromwell.backend.standard.callcaching.StandardFileHashingActor.akka$actor$Timers$$super$aroundReceive(StandardFileHashingActor.scala:59); 	at akka.actor.Timers.aroundReceive(Timers.scala:44); 	at akka.actor.Timers.aroundReceive$(Timers.scala:36); 	at cromwell.backend.standard.callcaching.StandardFileHashingActor.aroundReceive(StandardFileHashingActor.scala:59); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:527); 	at akka.actor.ActorCell.invoke(ActorCell.scala:496); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); 	at akka.dispatch.Mail",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3584:7136,Config,ConfigBackendFileHashingActor,7136,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3584,1,['Config'],['ConfigBackendFileHashingActor']
Modifiability,"9B"",; ""runtime attribute"": {; ""docker"": ""4B2AB7B9EA875BF5290210F27BB9654D"",; ""continueOnReturnCode"": ""CFCD208495D565EF66E7DFF9F98764DA"",; ""failOnStderr"": ""68934A3E9455FA72420237EB05902327""; },; ""output expression"": {; ""File output_greeting"": ""DFC652723D8EBD4BB25CAC21431BB6C0""; },; ""input count"": ""CFCD208495D565EF66E7DFF9F98764DA"",; ""backend name"": ""2A2AB400D355AC301859E4ABB5432138"",; ""command template"": ""AFAC58B849BD67585A857F538B8E92F6""; },; ""effectiveCallCachingMode"": ""ReadAndWriteCache"",; ""hit"": false,; ""result"": ""Cache Miss""; },; ```. ```; # simple sge apptainer conf (modified from the slurm one); #; workflow-options; {; workflow-log-dir: ""cromwell-workflow-logs""; workflow-log-temporary: false; workflow-failure-mode: ""ContinueWhilePossible""; default; {; workflow-type: WDL; workflow-type-version: ""draft-2""; }; }. database {; # Store metadata in a file on disk that can grow much larger than RAM limits.; metadata {; profile = ""slick.jdbc.MySQLProfile$""; db {; url = ""jdbc:mysql:<dburl>?rewriteBatchedStatements=true""; driver = ""com.mysql.cj.jdbc.Driver""; user = ""<user>""; password = ""<pass>"" ; connectionTimeout = 5000; }; }; }. call-caching; {; enabled = true; invalidate-bad-cache-result = true; }. docker {; hash-lookup {; enabled = true; }; }. backend {; default = sge; providers {. ; sge {; 	actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {. # Limits the number of concurrent jobs; #concurrent-job-limit = 5. # If an 'exit-code-timeout-seconds' value is specified:; # - check-alive will be run at this interval for every job; # - if a job is found to be not alive, and no RC file appears after this interval; # - Then it will be marked as Failed.; # Warning: If set, Cromwell will run 'check-alive' for every job at this interval. # exit-code-timeout-seconds = 120. runtime-attributes = """"""; String time = ""11:00:00""; Int cpu = 4; Float? memory_gb; String sge_queue = ""hammer.q""; String? sge_project; String? docker; """""". submit = """"",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7480:1943,rewrite,rewriteBatchedStatements,1943,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7480,1,['rewrite'],['rewriteBatchedStatements']
Modifiability,": Evaluating files_and_metadata_row[3] failed: Failed to find index Success(WomInteger(3)); on array:\n\nSuccess([\""SRR5395068\"", \""SRR5395068_1.fastq.gz\"", \""SRR5395068_2.fastq.gz\""])\n\n3"",; ""causedBy"": []; ```; How can i avoid this? Or is there a way to accomplish what I am trying to do?. ### Which backend are you running? ; Unix terminal within slurm scheduler. ### Example meta_data files:; 1) without barcode; ```; SRR5395067	SRR5395067_1.fastq.gz	SRR5395067_2.fastq.gz	; SRR395068	SRR5395068_1.fastq.gz	SRR5395068_2.fastq.gz	; ```; 2) with barcode; ```; SRR5395067	SRR5395067_1.fastq.gz	SRR5395067_2.fastq.gz ATCGCT	; SRR395068	SRR5395068_1.fastq.gz	SRR5395068_2.fastq.gz ATCGGA; ```; ### Below my workflow:. workflow scMethTask3 {. #information about the monitoring scrip and the number of samples; File? monitoring_script; File meta_data. #information for trimming the cell barcode; File command; Int bases; ; #information for trimming the adapters and low quality reads; Int low_quality_cutoff; Int read_length_cutoff; String adapters_1; String adapters_2; Int trim_start_R1; Int trim_end_R1; Int trim_start_R2; Int trim_end_R2; String TAG. #information memory for each task; Int memory_task1; Int memory_task2. #Start the call. Array[Array[String]] files_and_metadata = read_tsv(meta_data). scatter(files_and_metadata_row in files_and_metadata) {; String sampleName = files_and_metadata_row[0]; File f1 = files_and_metadata_row[1]; File f2 = files_and_metadata_row[2]; String? barcode = files_and_metadata_row[3]; #if the barcode is passed, proceed with it.; if (defined(barcode)) {; call trimCellBarcode {; input:; f1=f1,; f2=f2,; sampleName=sampleName,; barcode=barcode,; monitoring_script=monitoring_script,; command=command,; memory_task1=memory_task1,; bases=bases; }; }; #if the barcode is not passed, proceed with the trimming of the adapters only; if (!defined(barcode)) {; call trimAdaptersWithoutBarcodes{; input:; input_r1=f1,; input_r2=f2,; sampleName=sampleName,; low_quality",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5396:1755,adapt,adapters,1755,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5396,1,['adapt'],['adapters']
Modifiability,": \""--assembly\""\n },\n \""default\"": \"".assembly.bam\"",\n \""id\"": \""#gridss-2.9.4.cwl/assembly\""\n },\n {\n \""type\"": [\n \""null\"",\n \""File\""\n ],\n \""doc\"": \""Optional - BED file containing regions to ignore\\n\"",\n \""inputBinding\"": {\n \""prefix\"": \""--blacklist\""\n },\n \""id\"": \""#gridss-2.9.4.cwl/blacklist\""\n },\n {\n \""type\"": \""string\"",\n \""doc\"": \""portion of 6 sigma read pairs distribution considered concordantly mapped. Default: 0.995\\n\"",\n \""inputBinding\"": {\n \""prefix\"": \""--concordantreadpairdistribution\""\n },\n \""default\"": \""0.995\"",\n \""id\"": \""#gridss-2.9.4.cwl/concordantreadpairdistribution\""\n },\n {\n \""type\"": [\n \""null\"",\n \""File\""\n ],\n \""doc\"": \""Optional - configuration file use to override default GRIDSS settings.\\n\"",\n \""inputBinding\"": {\n \""prefix\"": \""--configuration\""\n },\n \""id\"": \""#gridss-2.9.4.cwl/configuration\""\n },\n {\n \""type\"": [\n \""null\"",\n \""boolean\""\n ],\n \""doc\"": \""Optional - use the system version of bwa instead of the in-process version packaged with GRIDSS\\n\"",\n \""inputBinding\"": {\n \""prefix\"": \""--externalaligner\""\n },\n \""default\"": false,\n \""id\"": \""#gridss-2.9.4.cwl/externalaligner\""\n },\n {\n \""type\"": [\n \""null\"",\n \""string\""\n ],\n \""doc\"": \""Optional - location of GRIDSS jar\\n\"",\n \""inputBinding\"": {\n \""prefix\"": \""--jar\""\n },\n \""default\"": \""/opt/gridss/gridss-2.9.4-gridss-jar-with-dependencies.jar\"",\n \""id\"": \""#gridss-2.9.4.cwl/jar\""\n },\n {\n \""type\"": \""boolean\"",\n \""doc\"": \""zero-based assembly job index (only required when performing parallel assembly across multiple computers)\\n\"",\n \""inputBinding\"": {\n \""prefix\"": \""--jobindex\""\n },\n \""default\"": false,\n \""id\"": \""#gridss-2.9.4.cwl/jobindex\""\n },\n {\n \""type\"": \""boolean\"",\n \""doc\"": \""total number of assembly jobs (only required when performing parallel assembly across multiple computers). Note than an assembly jobs is required after all indexed jobs have been completed to gather the output files together.\\n\""",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5826:73603,config,configuration,73603,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5826,1,['config'],['configuration']
Modifiability,"://bitbucket.org/asomov/snakeyaml/src/master/Releases.rst) - [Release Notes](https://bitbucket.org/asomov/snakeyaml/src/master/releases.md) - [Release Notes](https://bitbucket.org/asomov/snakeyaml/src/master/releases.markdown) - [Release Notes](https://bitbucket.org/asomov/snakeyaml/src/master/releases.rst) - [Changelog](https://bitbucket.org/asomov/snakeyaml/src/master/CHANGELOG.md) - [Changelog](https://bitbucket.org/asomov/snakeyaml/src/master/CHANGELOG.markdown) - [Changelog](https://bitbucket.org/asomov/snakeyaml/src/master/CHANGELOG.rst) - [Changelog](https://bitbucket.org/asomov/snakeyaml/src/master/Changelog.md) - [Changelog](https://bitbucket.org/asomov/snakeyaml/src/master/Changelog.markdown) - [Changelog](https://bitbucket.org/asomov/snakeyaml/src/master/Changelog.rst) - [Changelog](https://bitbucket.org/asomov/snakeyaml/src/master/changelog.md) - [Changelog](https://bitbucket.org/asomov/snakeyaml/src/master/changelog.markdown) - [Changelog](https://bitbucket.org/asomov/snakeyaml/src/master/changelog.rst) - [Changelog](https://bitbucket.org/asomov/snakeyaml/src/master/CHANGES.md) - [Changelog](https://bitbucket.org/asomov/snakeyaml/src/master/CHANGES.markdown) - [Changelog](https://bitbucket.org/asomov/snakeyaml/src/master/CHANGES.rst). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/4c999c871afc48b47ca01211b35bb70b849ae19a/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""org.yaml"", artifactId = ""snakeyaml"" } ]; ```; </details>. labels: test-library-update",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5848:2287,Config,Configure,2287,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5848,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"://bitbucket.org/asomov/snakeyaml/src/master/Releases.rst) - [Release Notes](https://bitbucket.org/asomov/snakeyaml/src/master/releases.md) - [Release Notes](https://bitbucket.org/asomov/snakeyaml/src/master/releases.markdown) - [Release Notes](https://bitbucket.org/asomov/snakeyaml/src/master/releases.rst) - [Changelog](https://bitbucket.org/asomov/snakeyaml/src/master/CHANGELOG.md) - [Changelog](https://bitbucket.org/asomov/snakeyaml/src/master/CHANGELOG.markdown) - [Changelog](https://bitbucket.org/asomov/snakeyaml/src/master/CHANGELOG.rst) - [Changelog](https://bitbucket.org/asomov/snakeyaml/src/master/Changelog.md) - [Changelog](https://bitbucket.org/asomov/snakeyaml/src/master/Changelog.markdown) - [Changelog](https://bitbucket.org/asomov/snakeyaml/src/master/Changelog.rst) - [Changelog](https://bitbucket.org/asomov/snakeyaml/src/master/changelog.md) - [Changelog](https://bitbucket.org/asomov/snakeyaml/src/master/changelog.markdown) - [Changelog](https://bitbucket.org/asomov/snakeyaml/src/master/changelog.rst) - [Changelog](https://bitbucket.org/asomov/snakeyaml/src/master/CHANGES.md) - [Changelog](https://bitbucket.org/asomov/snakeyaml/src/master/CHANGES.markdown) - [Changelog](https://bitbucket.org/asomov/snakeyaml/src/master/CHANGES.rst). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/a2a47735b8b5ce3b0b0a9fa0a2cdf3b8405ff98d/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""org.yaml"", artifactId = ""snakeyaml"" } ]; ```; </details>. labels: test-library-update",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5687:2287,Config,Configure,2287,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5687,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"://join.slack.com/t/cromwellhq/shared_invite/zt-dxmmrtye-JHxwKE53rfKE_ZWdOHIB4g; -->. <!-- Are you seeing something that looks like a bug? Please attach as much information as possible. -->; Default application.json not found in classpath in precompiled jar on github (affecting multiple releases tested version 86 and 85). ; Tested to not be affected version 79/56. Main error below. Should be an easy fix. . ```; Exception in thread ""main"" com.typesafe.config.ConfigException$IO: application: application.conf: java.io.IOException: resource not found on classpath: application.conf, application.json: java.io.IOException: resource not found on classpath: application.json, application.properties: java.io.IOException: resource not found on classpath: application.properties; at com.typesafe.config.impl.SimpleIncluder.fromBasename(SimpleIncluder.java:236); at com.typesafe.config.impl.ConfigImpl.parseResourcesAnySyntax(ConfigImpl.java:133); at com.typesafe.config.ConfigFactory.parseResourcesAnySyntax(ConfigFactory.java:1083); at com.typesafe.config.impl.SimpleIncluder.includeResourceWithoutFallback(SimpleIncluder.java:123); at com.typesafe.config.impl.SimpleIncluder.includeResources(SimpleIncluder.java:109); at com.typesafe.config.impl.ConfigParser$ParseContext.parseInclude(ConfigParser.java:181); at com.typesafe.config.impl.ConfigParser$ParseContext.parseObject(ConfigParser.java:237); at com.typesafe.config.impl.ConfigParser$ParseContext.parseValue(ConfigParser.java:103); at com.typesafe.config.impl.ConfigParser$ParseContext.parse(ConfigParser.java:415); at com.typesafe.config.impl.ConfigParser.parse(ConfigParser.java:25); at com.typesafe.config.impl.Parseable.rawParseValue(Parseable.java:263); at com.typesafe.config.impl.Parseable.rawParseValue(Parseable.java:250); at com.typesafe.config.impl.Parseable.parseValue(Parseable.java:180); at com.typesafe.config.impl.Parseable.parseValue(Parseable.java:174); at com.typesafe.config.impl.Parseable.parse(Parseable.java:301); at com.t",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7255:1285,Config,ConfigFactory,1285,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7255,1,['Config'],['ConfigFactory']
Modifiability,":107); Caused by: common.exception.AggregatedMessageException: Error(s):; Could not evaluate expression: ""-l h_vmem="" + memory + ""G"": Cannot perform operation: -l h_vmem= + WomLong(4); at common.validation.Validation$ValidationTry$.toTry$extension1(Validation.scala:77); at common.validation.Validation$ValidationTry$.toTry$extension0(Validation.scala:73); at cromwell.backend.impl.sfs.config.ConfigAsyncJobExecutionActor.writeTaskScript(ConfigAsyncJobExecutionActor.scala:107); at cromwell.backend.impl.sfs.config.ConfigAsyncJobExecutionActor.writeTaskScript$(ConfigAsyncJobExecutionActor.scala:55); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.writeTaskScript(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.impl.sfs.config.ConfigAsyncJobExecutionActor.processArgs(ConfigAsyncJobExecutionActor.scala:43); at cromwell.backend.impl.sfs.config.ConfigAsyncJobExecutionActor.processArgs$(ConfigAsyncJobExecutionActor.scala:39); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.processArgs$lzycompute(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.processArgs(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.makeProcessRunner(SharedFileSystemAsyncJobExecutionActor.scala:174); at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.makeProcessRunner$(SharedFileSystemAsyncJobExecutionActor.scala:171); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.makeProcessRunner(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.$anonfun$execute$2(SharedFileSystemAsyncJobExecutionActor.scala:145); at scala.util.Either.fold(Either.scala:188); at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.execute(SharedFileSystemAsyncJobExecutionActor.scala:144); at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.exec",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4659:2642,config,config,2642,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4659,1,['config'],['config']
Modifiability,:109); at sun.nio.ch.ChannelInputStream.read(ChannelInputStream.java:103); - locked <0x00000006c54b2ec8> (a sun.nio.ch.ChannelInputStream); at org.apache.commons.codec.digest.DigestUtils.updateDigest(DigestUtils.java:798); at org.apache.commons.codec.digest.DigestUtils.digest(DigestUtils.java:50); at org.apache.commons.codec.digest.DigestUtils.md5(DigestUtils.java:274); at org.apache.commons.codec.digest.DigestUtils.md5Hex(DigestUtils.java:310); at cromwell.backend.impl.sfs.config.HashFileStrategy$$anonfun$hash$3.apply(ConfigHashingStrategy.scala:70); at cromwell.backend.impl.sfs.config.HashFileStrategy$$anonfun$hash$3.apply(ConfigHashingStrategy.scala:70); at cromwell.util.TryWithResource$$anonfun$tryWithResource$1.apply(TryWithResource.scala:16); at scala.util.Try$.apply(Try.scala:192); at cromwell.util.TryWithResource$.tryWithResource(TryWithResource.scala:10); at cromwell.backend.impl.sfs.config.HashFileStrategy.hash(ConfigHashingStrategy.scala:70); at cromwell.backend.impl.sfs.config.ConfigHashingStrategy.getHash(ConfigHashingStrategy.scala:47); at cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory$$anonfun$fileHashingFunction$1.apply(ConfigBackendLifecycleActorFactory.scala:45); at cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory$$anonfun$fileHashingFunction$1.apply(ConfigBackendLifecycleActorFactory.scala:45); at cromwell.backend.callcaching.FileHashingActor$$anonfun$receive$1$$anonfun$1.apply(FileHashingActor.scala:21); at cromwell.backend.callcaching.FileHashingActor$$anonfun$receive$1$$anonfun$1.apply(FileHashingActor.scala:21); at scala.Option.map(Option.scala:146); at cromwell.backend.callcaching.FileHashingActor$$anonfun$receive$1.applyOrElse(FileHashingActor.scala:21); at akka.actor.Actor$class.aroundReceive(Actor.scala:484); at cromwell.backend.callcaching.FileHashingActor.aroundReceive(FileHashingActor.scala:16); at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); at akka.actor.ActorCell.invoke(ActorCell.sc,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1597:1859,config,config,1859,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1597,1,['config'],['config']
Modifiability,:54); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.AbstractTraversable.map(Traversable.scala:104); 	at wdl4s.Task$$anonfun$instantiateCommand$1.apply(Task.scala:107); 	at wdl4s.Task$$anonfun$instantiateCommand$1.apply(Task.scala:107); 	at scala.util.Try$.apply(Try.scala:192); 	at wdl4s.Task.instantiateCommand(Task.scala:107); 	at cromwell.backend.impl.sfs.config.ConfigAsyncJobExecutionActor$class.writeTaskScript(ConfigAsyncJobExecutionActor.scala:55); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.writeTaskScript(ConfigAsyncJobExecutionActor.scala:124); 	at cromwell.backend.impl.sfs.config.ConfigAsyncJobExecutionActor$class.processArgs(ConfigAsyncJobExecutionActor.scala:39); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.processArgs$lzycompute(ConfigAsyncJobExecutionActor.scala:124); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.processArgs(ConfigAsyncJobExecutionActor.scala:124); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor$class.executeScript(SharedFileSystemAsyncJobExecutionActor.scala:220); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.executeScript(ConfigAsyncJobExecutionActor.scala:124); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor$$anonfun$executeOrRecover$2.apply(SharedFileSystemAsyncJobExecutionActor.scala:192); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor$$anonfun$executeOrRecover$2.apply(SharedFileSystemAsyncJobExecutionActor.scala:189); 	at scala.util.Try$.apply(Try.scala:192); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor$class.executeOrRecover(SharedFileSystemAsyncJobExecutionActor.scala:188); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.executeOrRecover(ConfigAsyncJobExecutionActor.scala:124); 	at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$cromwell$backend$async$A,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1765:2939,Config,ConfigAsyncJobExecutionActor,2939,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1765,1,['Config'],['ConfigAsyncJobExecutionActor']
Modifiability,":59); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:527); 	at akka.actor.ActorCell.invoke(ActorCell.scala:496); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:234); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); [2018-05-02 15:22:54,71] [[38;5;1merror[0m] bc4644da:batch_for_variantcall:-1:1: Hash error, disabling call caching for this job.; java.io.FileNotFoundException: Cannot hash file null because it can't be found; 	at cromwell.backend.impl.sfs.config.ConfigHashingStrategy.usingStandardInitData$1(ConfigHashingStrategy.scala:46); 	at cromwell.backend.impl.sfs.config.ConfigHashingStrategy.getHash(ConfigHashingStrategy.scala:57); 	at cromwell.backend.impl.sfs.config.ConfigBackendFileHashingActor.customHashStrategy(ConfigBackendFileHashingActor.scala:26); 	at cromwell.backend.standard.callcaching.StandardFileHashingActor$$anonfun$fileHashingReceive$1.applyOrElse(StandardFileHashingActor.scala:79); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); 	at akka.actor.Actor.aroundReceive(Actor.scala:514); 	at akka.actor.Actor.aroundReceive$(Actor.scala:512); 	at cromwell.backend.standard.callcaching.StandardFileHashingActor.akka$actor$Timers$$super$aroundReceive(StandardFileHashingActor.scala:59); 	at akka.actor.Timers.aroundReceive(Timers.scala:44); 	at akka.actor.Timers.aroundReceive$(Timers.scala:36); 	at cromwell.backend.standard.callcaching.StandardFileHashingActor.aroundReceive(StandardFileHashingActor.scala:59); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:527); 	at akka.actor.Acto",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3584:7017,Config,ConfigHashingStrategy,7017,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3584,1,['Config'],['ConfigHashingStrategy']
Modifiability,":76); 	at scala.collection.immutable.List.foreach(List.scala:389); 	at scala.App.main(App.scala:76); 	at scala.App.main$(App.scala:74); 	at cromwell.CromwellApp$.main(CromwellApp.scala:3); 	at cromwell.CromwellApp.main(CromwellApp.scala); Caused by: com.typesafe.config.ConfigException$Parse: /data/cephfs/punim0751/spartan.conf: 27: expecting a close parentheses ')' here, not: end of file; 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseError(ConfigDocumentParser.java:201); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseError(ConfigDocumentParser.java:197); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseKey(ConfigDocumentParser.java:279); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseObject(ConfigDocumentParser.java:450); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseValue(ConfigDocumentParser.java:247); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseObject(ConfigDocumentParser.java:458); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parse(ConfigDocumentParser.java:648); 	at com.typesafe.config.impl.ConfigDocumentParser.parse(ConfigDocumentParser.java:14); 	at com.typesafe.config.impl.Parseable.rawParseValue(Parseable.java:260); 	at com.typesafe.config.impl.Parseable.rawParseValue(Parseable.java:248); 	at com.typesafe.config.impl.Parseable.parseValue(Parseable.java:180); 	at com.typesafe.config.impl.Parseable.parseValue(Parseable.java:174); 	at com.typesafe.config.impl.Parseable.parse(Parseable.java:299); 	at com.typesafe.config.ConfigFactory.parseFile(ConfigFactory.java:689); 	at com.typesafe.config.DefaultConfigLoadingStrategy.parseApplicationConfig(DefaultConfigLoadingStrategy.java:51); 	at com.typesafe.config.ConfigFactory.defaultApplication(ConfigFactory.java:473); 	at com.typesafe.config.ConfigFactory$1.call(ConfigFactory.java:259); 	at com.typesafe.config.ConfigFactory$1.call(ConfigFactory.java:256); 	at com.typesafe.co",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4549:2318,Config,ConfigDocumentParser,2318,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4549,1,['Config'],['ConfigDocumentParser']
Modifiability,; 	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72); 	at scala.collection.AbstractIterable.foreach(Iterable.scala:54); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.AbstractTraversable.map(Traversable.scala:104); 	at wdl4s.Task$$anonfun$instantiateCommand$1.apply(Task.scala:107); 	at wdl4s.Task$$anonfun$instantiateCommand$1.apply(Task.scala:107); 	at scala.util.Try$.apply(Try.scala:192); 	at wdl4s.Task.instantiateCommand(Task.scala:107); 	at cromwell.backend.impl.sfs.config.ConfigAsyncJobExecutionActor$class.writeTaskScript(ConfigAsyncJobExecutionActor.scala:55); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.writeTaskScript(ConfigAsyncJobExecutionActor.scala:124); 	at cromwell.backend.impl.sfs.config.ConfigAsyncJobExecutionActor$class.processArgs(ConfigAsyncJobExecutionActor.scala:39); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.processArgs$lzycompute(ConfigAsyncJobExecutionActor.scala:124); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.processArgs(ConfigAsyncJobExecutionActor.scala:124); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor$class.executeScript(SharedFileSystemAsyncJobExecutionActor.scala:220); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.executeScript(ConfigAsyncJobExecutionActor.scala:124); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor$$anonfun$executeOrRecover$2.apply(SharedFileSystemAsyncJobExecutionActor.scala:192); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor$$anonfun$executeOrRecover$2.apply(SharedFileSystemAsyncJobExecutionActor.scala:189); 	at scala.util.Try$.apply(Try.scala:192); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor$class.executeOrRecover(SharedFileSystemAsyncJobExecutionActor.scala:188); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.executeOrReco,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1765:2810,Config,ConfigAsyncJobExecutionActor,2810,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1765,1,['Config'],['ConfigAsyncJobExecutionActor']
Modifiability,; 	at scala.util.Try$.apply(Try.scala:192); 	at wdl4s.Task.instantiateCommand(Task.scala:108); 	at cromwell.backend.wdl.Command$$anonfun$instantiate$1.apply(Command.scala:28); 	at cromwell.backend.wdl.Command$$anonfun$instantiate$1.apply(Command.scala:27); 	at scala.util.Success.flatMap(Try.scala:231); 	at cromwell.backend.wdl.Command$.instantiate(Command.scala:27); 	at cromwell.backend.standard.StandardAsyncExecutionActor$class.instantiatedCommand(StandardAsyncExecutionActor.scala:80); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.instantiatedCommand$lzycompute(ConfigAsyncJobExecutionActor.scala:113); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.instantiatedCommand(ConfigAsyncJobExecutionActor.scala:113); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor$class.execute(SharedFileSystemAsyncJobExecutionActor.scala:130); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.execute(ConfigAsyncJobExecutionActor.scala:113); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$executeOrRecover$2.apply(StandardAsyncExecutionActor.scala:264); 	at cromwell.backend.standard.StandardAsyncExecutionActor$$anonfun$executeOrRecover$2.apply(StandardAsyncExecutionActor.scala:258); 	at scala.util.Try$.apply(Try.scala:192); 	at cromwell.backend.standard.StandardAsyncExecutionActor$class.executeOrRecover(StandardAsyncExecutionActor.scala:258); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.executeOrRecover(ConfigAsyncJobExecutionActor.scala:113); 	at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$cromwell$backend$async$AsyncBackendJobExecutionActor$$robustExecuteOrRecover$1.apply(AsyncBackendJobExecutionActor.scala:56); 	at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$cromwell$backend$async$AsyncBackendJobExecutionActor$$robustExecuteOrRecover$1.apply(AsyncBackendJobExecutionActor.scala:56); 	at cromwell.core.retry.R,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1944:3916,Config,ConfigAsyncJobExecutionActor,3916,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1944,2,['Config'],['ConfigAsyncJobExecutionActor']
Modifiability,"; ""case_gatk_acnv_workflow.seg_param_nmin"": ""200"",; ""case_gatk_acnv_workflow.seg_param_eta"": ""0.05"",; ""case_gatk_acnv_workflow.seg_param_trim"": ""0.025"",; ""case_gatk_acnv_workflow.seg_param_undoSplits"": ""NONE"",; ""case_gatk_acnv_workflow.seg_param_undoPrune"": ""0.05"",; ""case_gatk_acnv_workflow.seg_param_undoSD"": ""3""; }; ```. WDL:. ``` wdl; #; # Case sample workflow for a list of pairs of case-control samples. Includes GATK CNV and ACNV. Supports both WGS and WES samples. This was tested on a3c7368 commit of gatk-protected.; #; # Notes:; #; # - the input file(input_bam_list) must contain a list of tab separated values in the following format(one or more lines must be supplied):; # tumor_entity tumor_bam tumor_bam_index normal_entity normal_bam normal_bam_index <--first input; # tumor_entity tumor_bam tumor_bam_index normal_entity normal_bam normal_bam_index <--second input; # etc...; #; # - set isWGS variable to true or false to specify whether to run a WGS or WES workflow respectively; #; # - file names will use the entity ID specified, but inside the file, the bam SM tag will typically be used.; #; # - target file (which must be in tsv format) is only used with WES workflow, WGS workflow generates its own targets (so user can pass any string as an argument); #; # - the WGS PoN must be generated with WGS samples; # ; # - THIS SCRIPT SHOULD BE CONSIDERED OF ""BETA"" QUALITY; #; # - Example invocation:; # java -jar cromwell.jar run case_gatk_acnv_workflow.wdl myParameters.json; # - See case_gatk_acnv_workflow_template.json for a template json file to modify with your own parameters (please save; # your modified version with a different filename and do not commit to gatk-protected repo).; #; # - Some call inputs might seem out of place - consult with the comments in task definitions for details; #; #############. workflow case_gatk_acnv_workflow {; # Workflow input files; File target_file; File ref_fasta; File ref_fasta_dict; File ref_fasta_fai; File common_snp_list; File i",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1480:4169,variab,variable,4169,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1480,1,['variab'],['variable']
Modifiability,"; ""command template"": ""AFAC58B849BD67585A857F538B8E92F6""; },; ""effectiveCallCachingMode"": ""ReadAndWriteCache"",; ""hit"": false,; ""result"": ""Cache Miss""; },; ```. ```; # simple sge apptainer conf (modified from the slurm one); #; workflow-options; {; workflow-log-dir: ""cromwell-workflow-logs""; workflow-log-temporary: false; workflow-failure-mode: ""ContinueWhilePossible""; default; {; workflow-type: WDL; workflow-type-version: ""draft-2""; }; }. database {; # Store metadata in a file on disk that can grow much larger than RAM limits.; metadata {; profile = ""slick.jdbc.MySQLProfile$""; db {; url = ""jdbc:mysql:<dburl>?rewriteBatchedStatements=true""; driver = ""com.mysql.cj.jdbc.Driver""; user = ""<user>""; password = ""<pass>"" ; connectionTimeout = 5000; }; }; }. call-caching; {; enabled = true; invalidate-bad-cache-result = true; }. docker {; hash-lookup {; enabled = true; }; }. backend {; default = sge; providers {. ; sge {; 	actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {. # Limits the number of concurrent jobs; #concurrent-job-limit = 5. # If an 'exit-code-timeout-seconds' value is specified:; # - check-alive will be run at this interval for every job; # - if a job is found to be not alive, and no RC file appears after this interval; # - Then it will be marked as Failed.; # Warning: If set, Cromwell will run 'check-alive' for every job at this interval. # exit-code-timeout-seconds = 120. runtime-attributes = """"""; String time = ""11:00:00""; Int cpu = 4; Float? memory_gb; String sge_queue = ""hammer.q""; String? sge_project; String? docker; """""". submit = """"""; qsub \; -terse \; -V \; -b y \; -N ${job_name} \; -wd ${cwd} \; -o ${out}.qsub \; -e ${err}.qsub \; -pe smp ${cpu} \; ${""-l mem_free="" + memory_gb + ""g""} \; ${""-q "" + sge_queue} \; ${""-P "" + sge_project} \; /usr/bin/env bash ${script}; """""". kill = ""qdel ${job_id}""; check-alive = ""qstat -j ${job_id}""; job-id-regex = ""(\\d+)"". submit-docker = """""" ; #location for .sif files and othe",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7480:2304,Config,ConfigBackendLifecycleActorFactory,2304,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7480,2,"['Config', 'config']","['ConfigBackendLifecycleActorFactory', 'config']"
Modifiability,; at cats.effect.internals.TrampolineEC$JVMTrampoline.super$startLoop(TrampolineEC.scala:93); at cats.effect.internals.TrampolineEC$JVMTrampoline.$anonfun$startLoop$1(TrampolineEC.scala:93); at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81); at cats.effect.internals.TrampolineEC$JVMTrampoline.startLoop(TrampolineEC.scala:93); at cats.effect.internals.Trampoline.execute(Trampoline.scala:43) ; at cats.effect.internals.TrampolineEC.execute(TrampolineEC.scala:44); at cats.effect.internals.IOBracket$BracketStart.apply(IOBracket.scala:60); at cats.effect.internals.IOBracket$BracketStart.apply(IOBracket.scala:41); at cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:134); at cats.effect.internals.IORunLoop$.start(IORunLoop.scala:34); at cats.effect.internals.IOBracket$.$anonfun$apply$1(IOBracket.scala:36); at cats.effect.internals.IOBracket$.$anonfun$apply$1$adapted(IOBracket.scala:33); at cats.effect.internals.IORunLoop$RestartCallback.start(IORunLoop.scala:328); at cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:117); at cats.effect.internals.IORunLoop$.start(IORunLoop.scala:34); at cats.effect.IO.unsafeRunAsync(IO.scala:258); at cats.effect.IO.unsafeToFuture(IO.scala:345); at cromwell.backend.impl.aws.AwsBatchAsyncBackendJobExecutionActor.executeAsync(AwsBatchAsyncBackendJobExecutionActor.scala:342); at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover(StandardAsyncExecutionActor.scala:943); at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover$(StandardAsyncExecutionActor.scala:935); at cromwell.backend.impl.aws.AwsBatchAsyncBackendJobExecutionActor.executeOrRecover(AwsBatchAsyncBackendJobExecutionActor.scala:74); at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustExecuteOrRecover$1(AsyncBackendJobExecutionActor.scala:65); at cromwell.cor,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4303:5671,adapt,adapted,5671,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4303,1,['adapt'],['adapted']
Modifiability,"; cromwell_1 | --rm -i \; cromwell_1 | ${""--user "" + docker_user} \; cromwell_1 | --entrypoint /bin/bash \; cromwell_1 | -v ${cwd}:${docker_cwd} \; cromwell_1 | ${docker} ${script}; cromwell_1 | ; cromwell_1 | }; cromwell_1 | }; cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigWdlNamespace.<init>(ConfigWdlNamespace.scala:50); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace$lzycompute(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.configWdlNamespace(ConfigInitializationActor.scala:37); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations$lzycompute(ConfigInitializationActor.scala:40); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.declarationValidations(ConfigInitializationActor.scala:39); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder$lzycompute(ConfigInitializationActor.scala:49); cromwell_1 | 	at cromwell.backend.impl.sfs.config.ConfigInitializationActor.runtimeAttributesBuilder(ConfigInitializationActor.scala:48); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.coerceDefaultRuntimeAttributes(StandardInitializationActor.scala:78); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$class.validateRuntimeAttributes(BackendWorkflowInitializationActor.scala:121); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$class.initSequence(BackendWorkflowInitializationActor.scala:154); cromwell_1 | 	at cromwell.backend.standard.StandardInitializationActor.initSequence(StandardInitializationActor.scala:42); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$$anonfun$receive$1$$anonfun$applyOrElse$2.apply(BackendWorkflowInitializationActor.scala:146); cromwell_1 | 	at cromwell.backend.BackendWorkflowInitializationActor$$anonfun$receive$1$$anonfun$applyOrElse$",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2284:3419,Config,ConfigInitializationActor,3419,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2284,1,['Config'],['ConfigInitializationActor']
Modifiability,"<!-- Are you seeing something that looks like a bug? Then great! You're almost in the right place. -->; Trying to set up a genomics workflow with AWS backend; References : https://aws.amazon.com/blogs/compute/using-cromwell-with-aws-batch/; https://cromwell.readthedocs.io/en/stable/tutorials/AwsBatch101/ . <!-- You'll want to go to https://broadworkbench.atlassian.net/projects/BA/issues and then tell us: -->. <!-- Which backend are you running? -->; AWS ; java -Dconfig.file=aws-cromwell-batch.conf -jar cromwell-75.jar run hello.wdl -i hello.inputs; ; ![AWS-Batch](https://user-images.githubusercontent.com/25282254/153039990-0d0b2c96-a33b-454f-9617-aee83137337a.PNG); [Cromwell-Error.docx](https://github.com/broadinstitute/cromwell/files/8026009/Cromwell-Error.docx); ; <!-- Paste/Attach your workflow if possible: -->; java -Dconfig.file=aws-cromwell-batch.conf -jar cromwell-75.jar run hello.wdl -i hello.inputs. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->; include required(classpath(""application"")). aws {. application-name = ""cromwell""; auths = [; {; name = ""default""; scheme = ""default""; }; ]; region = ""us-east-1""; }; engine {; filesystems {; s3.auth = ""default""; }; }; call-caching {; enabled = true; invalidate-bad-cache-results = true; }; docker {; hash-lookup {; enabled = false; # How should docker hashes be looked up. Possible values are ""local"" and ""remote""; # ""local"": Lookup hashes on the local docker daemon using the cli; # ""remote"": Lookup hashes on docker hub and gcr; method = ""remote""; }; }. backend {; default = ""AWSBATCH""; providers {; AWSBATCH {; actor-factory = ""cromwell.backend.impl.aws.AwsBatchBackendLifecycleActorFactory""; config {; numSubmitAttempts = 10; numCreateDefinitionAttempts = 10; concurrent-job-limit = 1000; root = ""s3://cromwell-aws-hello/cromwell-execution""; auth = ""default""; default-runtime-attributes {; queueArn = ""arn:aws:batch:us-east-1:XXXXXXXXX:job-queue/python-batch"" ,",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6671:1685,config,configuration,1685,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6671,1,['config'],['configuration']
Modifiability,"<!-- Are you seeing something that looks like a bug? Then great! You're in the right place. -->; ![2018-10-26 23 24 43](https://user-images.githubusercontent.com/4966343/47572651-79585300-d976-11e8-8027-a9bade3f91d4.png). <!-- Which backend are you running? -->; aws. <!-- Paste/Attach your workflow if possible: -->; https://github.com/broadinstitute/cromwell/blob/develop/centaur/src/main/resources/integrationTestCases/germline/haplotype-caller-workflow/HaplotypeCallerWF.aws.wdl. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->; AWS Access Key ID [****************R62Q]: ; AWS Secret Access Key [****************uDg5]:; Default region name [ap-northeast-2]:; Default output format [None]:",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4321:500,config,configuration,500,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4321,1,['config'],['configuration']
Modifiability,"<!-- Which backend are you running? -->; Backend: AWS backend. Link to Jira: https://broadworkbench.atlassian.net/browse/CROM-6712. Issue: ; From time to time I get the following error running a workflow on AWS. ```java; Could not build the path \""s3://bean-cromwell/cromwell-execution\"". It may refer to a filesystem not supported by this instance of Cromwell. Supported filesystems are: s3. Failures: \ns3: Unable to load region from any of the providers in the chain software.amazon.awssdk.regions.providers.DefaultAwsRegionProviderChain@7c812b7e: [software.amazon.awssdk.regions.providers.SystemSettingsRegionProvider@759440a5: Unable to load region from system settings. Region must be specified either via environment variable (AWS_REGION) or system property (aws.region)., software.amazon.awssdk.regions.providers.AwsProfileRegionProvider@2a8c03c1: No region provided in profile: default, software.amazon.awssdk.regions.providers.InstanceProfileRegionProvider@1bafe7dd: Unable to contact EC2 metadata service.] (SdkClientException)\n Please refer to the documentation for more information on how to configure filesystems: http://cromwell.readthedocs.io/en/develop/backends/HPC/#filesystems""; ```. This usually happens to one task generated from a scatter task.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6233:724,variab,variable,724,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6233,2,"['config', 'variab']","['configure', 'variable']"
Modifiability,"<!-- Which backend are you running? -->; SGE. conf:; ```; include required(classpath(""application"")). call-caching {; enabled = true; invalidate-bad-cache-results = true; }; workflow-options {; workflow-log-temporary = false; }; backend {; providers {; SGE {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; filesystems {; local {; caching {; # When copying a cached result, what type of file duplication should occur. Attempted in the order listed below:; duplication-strategy: [; ""soft-link"", ""copy""; ]. # Possible values: file, path; # ""file"" will compute an md5 hash of the file content.; # ""path"" will compute an md5 hash of the file path. This strategy will only be effective if the duplication-strategy (above) is set to ""soft-link"",; # in order to allow for the original file path to be hashed.; # Default: file; hashing-strategy: ""path""; }; }; }; ...; backend.default = SGE; database {; profile = ""slick.jdbc.MySQLProfile$""; db {; url = ""jdbc:mysql://0.0.0.0:40001/testuser_db?useSSL=false&rewriteBatchedStatements=true""; user = ""fake""; password = ""fake""; driver = ""com.mysql.jdbc.Driver""; connectionTimeout = 5000; }; }. system {; # Maximum number of input file bytes allowed in order to read each type.; # If exceeded a FileSizeTooBig exception will be thrown.; input-read-limits {; lines = 128000000; string = 128000000; json = 128000000; tsv = 128000000; map = 128000000; object = 128000000; }; }. ```. <!-- Paste/Attach your workflow if possible: -->; a modified version of : https://github.com/gatk-workflows/gatk4-data-processing. [workflow.0263ce1e-e1da-44c4-a49f-56fea7a6e1ea.log](https://github.com/broadinstitute/cromwell/files/2143529/workflow.0263ce1e-e1da-44c4-a49f-56fea7a6e1ea.log). A workflow is failing. It looks like cromwell attempts to localise some folder, ; ```/share/ScratchGeneral/evaben/cromwell/cromwell-executions/PreProcessingForVariantDiscovery_GATK4/0263ce1e-e1da-44c4-a49f-56fea7a6e1ea/call-SamToFastqAndBwaMem/",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3825:303,config,config,303,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3825,3,"['Config', 'config']","['ConfigBackendLifecycleActorFactory', 'config']"
Modifiability,"<!--; Hi! Thanks for taking the time to report feedback. Before posting an issue here, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're in the right place. -->. **Which backend are you running?**. broadinstitute/cromwell:36. **Paste/Attach your workflow if possible**. For any workflow, when I query its metadata endpoint with `excludeKey=calls` parameter, it returns a response with all `""calls""` key nevertheless. This doesn't seem to happen to other keys, like `inputs` or `submittedFiles`. Excluding `calls` would make a huge difference for us, because for large workflows it takes a long time for Cromwell to aggregate all calls, the response becomes large, and sometimes it even timeouts. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4362:1152,config,configuration,1152,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4362,1,['config'],['configuration']
Modifiability,"<!--; Hi! Thanks for taking the time to report feedback. Before posting an issue here, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're in the right place. -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3781:709,config,configuration,709,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3781,6,['config'],['configuration']
Modifiability,"<!--; Hi! Thanks for taking the time to report feedback. Before posting an issue here, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're in the right place. -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->. Hi folks,. I try to launch cromwell in its server mode, however I get the following error:. ```; java -jar ./cromwell-34.jar server; Exception in thread ""main"" java.lang.VerifyError: Uninitialized object exists on backward branch 209; Exception Details:; Location:; scala/collection/immutable/HashMap$HashTrieMap.split()Lscala/collection/immutable/Seq; @249: goto; Reason:; Error exists in the bytecode; Bytecode:; 0x0000000: 2ab6 0060 04a0 001e b200 b8b2 00bd 04bd; 0x0000010: 0002 5903 2a53 c000 bfb6 00c3 b600 c7c0; 0x0000020: 00c9 b02a b600 36b8 0040 3c1b 04a4 015e; 0x0000030: 1b05 6c3d 2a1b 056c 2ab6 0036 b700 cb3e; 0x0000040: 2ab6 0036 021d 787e 3604 2ab6 0036 0210; 0x0000050: 201d 647c 7e36 05bb 0019 59b2 00bd 2ab6; 0x0000060: 0038 c000 bfb6 00cf b700 d21c b600 d63a; 0x0000070: 0619 06c6 001a 1906 b600 dac0 0086 3a07; 0x0000080: 1906 b600 ddc0 0086 3a08 a700 0dbb 00df; 0x0000090: 5919 06b7 00e2 bf19 073a 0919 083a 0abb; 0x00000a0: 0002 5915 0419 09bb 0019 59b2 00bd 1909; 0x00000b0: c000 bfb6 00cf b700 d203 b800 e83a 0e3a. ```. OS: redhat 6.9 ; Java: ; ```; java -version; java version ""1.8.0_20""; Java(TM) SE Runtime Environment (build 1.8.0_20-b26); Java HotSpot(TM) 64-Bit Se",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4082:709,config,configuration,709,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4082,1,['config'],['configuration']
Modifiability,"<!--; Hi! Thanks for taking the time to report feedback. Before posting an issue here, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're in the right place. -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->; I am running Cromwell on GCP, launching a workflow that shards into ~5,000 pieces. I am getting the following error: `cromwell-system-akka.dispatchers.backend-dispatcher-150 ERROR - Read timed out`. ```; 2019-04-29 00:02:13,419 cromwell-system-akka.dispatchers.backend-dispatcher-139 INFO - PipelinesApiAsyncBackendJobExecutionActor [UUID(95b34a77)vcf2bigquery.convertVCF:2058:1]: Status chang; e from Running to Success; 2019-04-29 00:02:24,760 cromwell-system-akka.dispatchers.backend-dispatcher-150 ERROR - Read timed out; java.net.SocketTimeoutException: Read timed out; at java.net.SocketInputStream.socketRead0(Native Method); at java.net.SocketInputStream.socketRead(SocketInputStream.java:116); at java.net.SocketInputStream.read(SocketInputStream.java:171); at java.net.SocketInputStream.read(SocketInputStream.java:141); at sun.security.ssl.InputRecord.readFully(InputRecord.java:465); at sun.security.ssl.InputRecord.read(InputRecord.java:503); at sun.security.ssl.SSLSocketImpl.readRecord(SSLSocketImpl.java:975); at sun.security.ssl.SSLSocketImpl.readDataRecord(SSLSocketImpl.java:933); at sun.security.ssl.AppInputStream.read(AppInputStream.java:105); at java.io.BufferedInputStre",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4914:709,config,configuration,709,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4914,1,['config'],['configuration']
Modifiability,"<!--; Hi! Thanks for taking the time to report feedback. Before posting an issue here, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're in the right place. -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->; The [cromwell.examples.conf](https://github.com/broadinstitute/cromwell/blob/develop/cromwell.example.backends/cromwell.examples.conf) file seems to mix multiple styles in terms of delimiters. Some entries are colon delimited as if they were from JSON, e.g.:. ```; workflow-options {; # These workflow options will be encrypted when stored in the database; #encrypted-fields: []. # AES-256 key to use to encrypt the values in `encrypted-fields`; #base64-encryption-key: ""AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA="". # Directory where to write per workflow logs; #workflow-log-dir: ""cromwell-workflow-logs"". # When true, per workflow logs will be deleted after copying; #workflow-log-temporary: true. # Workflow-failure-mode determines what happens to other calls when a call fails. Can be either ContinueWhilePossible or NoNewCalls.; # Can also be overridden in workflow options. Defaults to NoNewCalls. Uncomment to change:; #workflow-failure-mode: ""ContinueWhilePossible"". default {; # When a workflow type is not provided on workflow submission, this specifies the default type.; #workflow-type: WDL. # When a workflow type version is not provided on workflow submission, this specifies th",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4913:709,config,configuration,709,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4913,1,['config'],['configuration']
Modifiability,"<!--; Hi! Thanks for taking the time to report feedback. Before posting an issue here, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're in the right place. -->. <!-- Which backend are you running? -->; Backend:; Local, no conf file. <!-- Paste/Attach your workflow if possible: -->. Workflow: Files are here:; https://github.com/FredHutch/reproducible-workflows/tree/master/CWL/SingleStepWorkflow. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->. Details (see also [this post](https://gatkforums.broadinstitute.org/wdl/discussion/23265/cwl-workflow-fails-running-locally#latest)):. I can run this workflow just fine using cwltool/cwl-runner as follows:. ```; cwl-runner bwa-memWorkflow.cwl localInputs.yml; ```. When I try and run it with cromwell I get an error that ""The job was aborted from outside Cromwell"" but I definitely did not abort it myself. Here is the command I used to run this workflow in Cromwell:. ```; java -jar cromwell-36.jar run bwa-memWorkflow.cwl -i localInputs.yml -p bwa-pe.cwl.zip; ```. (`bwa-pe.cwl.zip` just contains the dependency `bwa-pe.cwl`). And here's the full output of it:. https://gist.github.com/dtenenba/61bcf60f129b817cd894ee222789369a. My ultimate goal is to switch over to the AWS Batch back end (in case you are wondering why I don't just stick with cwltool) but first I wanted to get the workflow running locally in cromwell. Any ideas about this?",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4587:855,config,configuration,855,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4587,1,['config'],['configuration']
Modifiability,"<!--; Hi! Thanks for taking the time to report feedback. Before posting an issue here, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're in the right place. -->. If you see I've configured root to be root = ""/fast/gdr/uat/cromwell-executions"". but randomly sometime workflows when I check cromwell api metadata it is pointing to old root which was /g/cromwell/cromwell-executions. . Note I'm running cromwell in server mode with mariadb. I've cleaned and deleted all tables from mariadb. restarted the server as well. Can't find any other config/cache file where it has saved old address. Sometime workflows are fine pointing to new root but sometime not. <!-- Which backend are you running? -->; SLURM on cromwell 36. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->. backend {; # Override the default backend.; default = ""PhoenixSLURM"". # The list of providers.; providers {. PhoenixSLURM {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; runtime-attributes = """"""; String userid; String partitions; String memory_per_node; Int nodes; Int cores; String time; """""". # If an 'exit-code-timeout-seconds' value is specified:; # - When a job has not been alive for longer than this timeout; # - And has still not produced an RC file; # - Then it will be marked as Failed.; # Warning: If set, Cromwell has to run 'check-alive' for every job at regular intervals (unrelated to this timeout). exit-code-ti",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4404:618,config,configured,618,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4404,2,['config'],"['config', 'configured']"
Modifiability,"<!--; Hi! Thanks for taking the time to report feedback. Before posting an issue here, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're in the right place. -->; Hi all,. When running a workflow with `write_objects(Array[Struct])` in a task, the workflow fails with **runtime** error `Failed to evaluate input 'out' (reason 1 of 1): Failed to write_objects(...) (reason 1 of 1): Cannot TSV serialize a Array[WomCompositeType {\n a -> String \n}] (valid types are Array[Primitive], Array[Array[Primitive]], or Array[Object])` **if the array is empty**. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->; ```wdl; version 1.0. struct Input {; String a; }. workflow Test {; call test; }. task test {; input {; Array[Input] inputs = []; }. File out = write_objects(inputs). command {; cat '~{out}'; }. runtime {; docker: 'debian:stable-slim'; }; }; ```; <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->; Our Cromwell build is `37-a52c415-SNAP` (config available upon request)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4595:1345,config,configuration,1345,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4595,2,['config'],"['config', 'configuration']"
Modifiability,"<!--; Hi! Thanks for taking the time to report feedback. Before posting an issue here, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->; We are looking for a general guidance regarding how to use AWS EFS system with cromwell. ; Specifically, guidance of setup cromwell to recognize mounted EFS files in the backend and run jobs on AWS batch. . Details of what we have attempted to run the workflow using EFS on AWS:; - We tried specifying a aws EFS file system as one of the filesystems both within backend and engine constructs in addition to S3. But we get this error: ""Cannot find a filesystem with name efs in the configuration. Available filesystems: ftp, s3, demo-dos, gcs, oss, http"". If I just specify EFS, Cromwell does not start, errors out looking for S3. - Also, the EFS is mounted on my AWS batch computes. How do I specify the mount point to the container(I am asking this because, I don’t have control over creating AWS job definitions)?. We have checked lots of resources online but could not find any. And we have tried to ask questions on gatk forum with no luck: https://gatkforums.broadinstitute.org/wdl/discussion/23380/using-aws-backend-with-efs. Searched github issues, we found a similar issue opened here 7 days ago with no answer #4579 AWS backend with own source path to mount. Thanks for looking into this issue.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4602:986,config,configuration,986,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4602,1,['config'],['configuration']
Modifiability,"<!--; Hi! Thanks for taking the time to report feedback. Before posting an issue over in Jira tracker, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're almost in the right place. -->. <!-- You'll want to go to https://broadworkbench.atlassian.net/projects/BA/issues and then tell us: -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->. Hello,. I'm wondering if there is a way to specify the `zones` in Cromwell's configuration file that overwrites all the jobs executed through the Cromwell server running it. . When checking the documentation, I only found `config.default-runtime-attributes`, which only works when WDL tasks do not specify `zones`. I also see `config.runtime-attributes`, but it did not work. Could you please guide me on the issue? Thanks!. Sincerely,; Yiming",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6493:837,config,configuration,837,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6493,4,['config'],"['config', 'configuration']"
Modifiability,"<!--; Hi! Thanks for taking the time to report feedback. Before posting an issue over in Jira tracker, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're almost in the right place. -->. <!-- You'll want to go to https://broadworkbench.atlassian.net/projects/BA/issues and then tell us: -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->. Hi Cromwell team,; I am running a Cromwell server on Google Cloud have recently upgraded from Cromwell 50 to 53. I am running into an issue that I believe relates to how the new `monitoring_image_script` interacts with the docker entrypoint. I have docker images where each container needs to ping a license server for authentication, and this happens via and `ENTRYPOINT`-executed script called `auth.sh`. With Cromwell 53, this is no longer being run when the container is being executed. This is how the actual docker command . ```; # Cromwell 53; 2020/09/30 13:07:42 Running user action: docker run -v /mnt/local-disk:/cromwell_root --entrypoint=/bin/bash gcr.io/bioskryb/sentieon-201911-run@sha256:b4af9423297bb6566763b2c47b1da1620a68a4d34c210f0786a34a0ae85f62db /cromwell_root/script ; ```. ```; #Cromwell 50; 2020/09/23 06:03:37 Running user action: docker run -v /mnt/local-disk:/cromwell_root --entrypoint= gcr.io/bioskryb/sentieon-201911-run@sha256:b4af9423297bb6566763b2c47b1da1620a68a4d34c210f0786a34a0ae85f62db /bin/bash /cromwell_root/script ; ```. I h",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5901:837,config,configuration,837,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5901,1,['config'],['configuration']
Modifiability,"<!--; Hi! Thanks for taking the time to report feedback. Before posting an issue over in Jira tracker, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're almost in the right place. -->. <!-- You'll want to go to https://broadworkbench.atlassian.net/projects/BA/issues and then tell us: -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->. Hi,. I recently encountered an issue on running Cromwell jobs on AWS Batch. In brief, all of my testing WDL jobs failed with the following error message:. ```; 2021-09-23 00:08:18,813 INFO - Submitting taskId: cumulus.cluster-None-1, job definition : arn:aws:batch:us-west-2:752311211819:job-definition/cromwell_quay_io_cumulus_cumulus_1_4_377407181fbea1f33a22931df258b16d20d4c6ab3:1, script: s3://gred-cumulus-dev/scripts/c157137e2097795846ae1f4069ccd7a2; 2021-09-23 00:08:20,269 cromwell-system-akka.dispatchers.backend-dispatcher-118 INFO - AwsBatchAsyncBackendJobExecutionActor [UUID(cf00212c)cumulus.cluster:NA:1]: job id: 12836c6a-6d1a-4429-bb86-68b8f9883acf; 2021-09-23 00:08:20,287 cromwell-system-akka.dispatchers.backend-dispatcher-118 INFO - AwsBatchAsyncBackendJobExecutionActor [UUID(cf00212c)cumulus.cluster:NA:1]: Status change from - to Initializing; 2021-09-23 00:12:17,120 cromwell-system-akka.dispatchers.backend-dispatcher-136 INFO - AwsBatchAsyncBackendJobExecutionActor [UUID(cf00212c)cumulus.cluster:NA:1]: Status change from Initializing to R",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6504:837,config,configuration,837,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6504,1,['config'],['configuration']
Modifiability,"<!--; Hi! Thanks for taking the time to report feedback. Before posting an issue over in Jira tracker, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're almost in the right place. -->. <!-- You'll want to go to https://broadworkbench.atlassian.net/projects/BA/issues and then tell us: -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->; Hello,. I wonder if the LSF job array functionality was implemented in the latest Cromwell releases?. I found a couple of previous mentions on this (for AWS) a while ago:; [1](https://github.com/broadinstitute/cromwell/issues/4496); [2](https://github.com/broadinstitute/cromwell/issues/4707). If such functionality exists, are there docs on this subject?. Thank you!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6379:837,config,configuration,837,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6379,1,['config'],['configuration']
Modifiability,"<!--; Hi! Thanks for taking the time to report feedback. Before posting an issue over in Jira tracker, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're almost in the right place. -->. <!-- You'll want to go to https://broadworkbench.atlassian.net/projects/BA/issues and then tell us: -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->; I want to set AWS_BATCH_JOB_ATTEMPT in my pipeline. My pipeline is a cromwell wdl pipeline which utilizes AWS batch as the backend. I submit jobs like so. ```; curl -X POST ""http://172.31.77.179:8000/api/workflows/v1"" \; -H ""accept: application/json"" \; -F ""workflowSource=@rnaseq_pipeline.wdl"" \; -F ""workflowInputs=@rnaseq_pipeline.json"" \; -F ""workflowDependencies=@tasks.zip""; ```; From what I read on aws, they seem to set the environment variables for jobs through the websites GUI. I submit my jobs with curl, how would I add the AWS_BATCH_JOB_ATTEMPT value?. Any help would be appreciated, I am not familiar with either cromwell or batch.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5511:837,config,configuration,837,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5511,2,"['config', 'variab']","['configuration', 'variables']"
Modifiability,"<!--; Hi! Thanks for taking the time to report feedback. Before posting an issue over in Jira tracker, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're almost in the right place. -->. <!-- You'll want to go to https://broadworkbench.atlassian.net/projects/BA/issues and then tell us: -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->; I'm having issues running CWL workflows with Cromwell 44 whereas previously with 36.1, it passes. I have workarounds but I'm wondering which ones are issues and which ones are design changes. Here's my test script:; ```; #!/bin/bash; set -o pipefail; set -o nounset; set -o xtrace. wget https://github.com/broadinstitute/cromwell/releases/download/44/cromwell-44.jar; wget https://github.com/broadinstitute/cromwell/releases/download/36.1/cromwell-36.1.jar; wget https://raw.githubusercontent.com/common-workflow-language/common-workflow-language/master/v1.0/examples/1st-tool.cwl; wget https://raw.githubusercontent.com/common-workflow-language/common-workflow-language/master/v1.0/examples/echo-job.yml; zip imports.zip 1st-tool.cwl echo-job.yml; java -jar cromwell-36.1.jar run 1st-tool.cwl --inputs echo-job.yml; java -jar cromwell-36.1.jar run 1st-tool.cwl --inputs echo-job.yml --type cwl; java -jar cromwell-36.1.jar run 1st-tool.cwl --inputs echo-job.yml --type cwl --imports imports.zip; java -jar cromwell-44.jar run 1st-tool.cwl --inputs echo-job.yml; jav",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5085:837,config,configuration,837,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5085,1,['config'],['configuration']
Modifiability,"<!--; Hi! Thanks for taking the time to report feedback. Before posting an issue over in Jira tracker, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're almost in the right place. -->; I am trying to run Cromwell with Google backend using PAPIv2.conf. Is there a way NOT doing the project network label for network Virtual Private Network? So that I can give the full network and subnetwork address as parameter into the PAPIv2.conf file? . I saw the questions around supporting the shared VPC network in previous issues . May be using the path like ; --network=projects/host-gcp-project/global/networks/name-of-the-network ; --subnetwork=projects/host-gcp-project/regions/us-central1/subnetworks/name-of-the-subnetwork. <!-- You'll want to go to https://broadworkbench.atlassian.net/projects/BA/issues and then tell us: -->. <!-- Which backend are you running? -->; Backend: Google; <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6453:1390,config,configuration,1390,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6453,1,['config'],['configuration']
Modifiability,"<!--; Hi! Thanks for taking the time to report feedback. Please check whether your question is already answered in our:; Documentation http://cromwell.readthedocs.io/en/develop/; Bioinformatics Stack Exchange https://bioinformatics.stackexchange.com/search?q=cromwell; Slack https://join.slack.com/t/cromwellhq/shared_invite/zt-dxmmrtye-JHxwKE53rfKE_ZWdOHIB4g; -->. <!-- Are you seeing something that looks like a bug? Please attach as much information as possible. -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7117:578,config,configuration,578,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7117,2,['config'],['configuration']
Modifiability,"<!--; Hi! Thanks for taking the time to report feedback. Please check whether your question is already answered in our:; Documentation http://cromwell.readthedocs.io/en/develop/; Bioinformatics Stack Exchange https://bioinformatics.stackexchange.com/search?q=cromwell; Slack https://join.slack.com/t/cromwellhq/shared_invite/zt-dxmmrtye-JHxwKE53rfKE_ZWdOHIB4g; -->. <!-- Are you seeing something that looks like a bug? Please attach as much information as possible. -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->. When trying to configure metadata-archive in cromwell server by adding the configuration below:; ```; archive-metadata {; # A filesystem able to access the specified bucket:; filesystems {; gcs {; # A reference to the auth to use for storing and retrieving metadata:; auth = ""user-service-account""; }; }. # Which bucket to use for storing the archived metadata; bucket = ""{{ backend_bucket }}""; }; ```. when the user-service-account auth is declared up in the configuration :; ```; google {. application-name = ""cromwell"". auths = [; {; name = ""user-service-account""; scheme = ""user_service_account""; }; ]; }; ```; We got the following error in Cromwell server initialization :; cromwell_1 | [ERROR] [06/21/2023 11:55:25.094] [cromwell-system-akka.actor.default-dispatcher-30] [akka://cromwell-system/user] Failed to parse the archive-metadata config:; cromwell_1 | Failed to construct archiver path builders from factories (reason 1 of 1): Missing parameters in workflow options: user_service_account_json; cromwell_1 | akka.actor.ActorInitializationException: akka://cromwell-system/user/cromwell-service/ServiceRegistryActor/MetadataService: exception during creation; cromwell_1 | 	at akka.actor.ActorInitializationException$.apply(Actor.scala:202); cromwell_1 | 	at akka.actor.ActorCell.create(ActorCell.scala:698); crom",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7171:578,config,configuration,578,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7171,3,['config'],"['configuration', 'configure']"
Modifiability,"<!--; Hi! Thanks for taking the time to report feedback. Please check whether your question is already answered in our:; Documentation http://cromwell.readthedocs.io/en/develop/; Bioinformatics Stack Exchange https://bioinformatics.stackexchange.com/search?q=cromwell; Slack https://join.slack.com/t/cromwellhq/shared_invite/zt-dxmmrtye-JHxwKE53rfKE_ZWdOHIB4g; -->. <!-- Are you seeing something that looks like a bug? Please attach as much information as possible. -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->. womtool graph bug:; Exception in thread ""main"" java.util.NoSuchElementException: key not found: ScatterVariableNode(WomIdentifier(LocalName(lane),FullyQualifiedName(lane)),PlainAnonymousExpressionNode(WomIdentifier(LocalName(lane),FullyQualifiedName(lane)),WdlWomExpression(WdlExpression(<string:255:22 identifier ""TWVyZ2VJbnB1dFJlYWRz"">),[Scatter fqn=MAPRSEQSingleSampleMasterWF.$scatter_0, item=lane, collection=MergeInputReads]),WomMaybeEmptyArrayType(WomMaybeEmptyArrayType(WomSingleFileType)),Map(MergeInputReads -> ConnectedInputPort(MergeInputReads,WomMaybeEmptyArrayType(WomMaybeEmptyArrayType(WomSingleFileType)),GraphNodeOutputPort(MAPRSEQSingleSampleMasterWF.MergeInputReads),wom.graph.GraphNode$GraphNodeSetter$$Lambda$512/0x0000000800491040@2a9fd482))),WomMaybeEmptyArrayType(WomSingleFileType)); 	at scala.collection.immutable.Map$EmptyMap$.apply(Map.scala:101); 	at scala.collection.immutable.Map$EmptyMap$.apply(Map.scala:99); 	at wom.views.GraphPrint$.relevantAsUpstream$1(GraphPrint.scala:177); 	at wom.views.GraphPrint$.upstreamPortToRelevantNodes$1(GraphPrint.scala:187); 	at wom.views.GraphPrint$.$anonfun$upstreamLinks$1(GraphPrint.scala:190); 	at scala.collection.TraversableLike.$anonfun$flatMap$1(TraversableLike.scala:245); 	at scala.collection.immutable.Set$Set1.foreach(Set.scala:97); 	at scala.co",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6744:578,config,configuration,578,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6744,1,['config'],['configuration']
Modifiability,"<!--; Hi! Thanks for taking the time to report feedback. Please check whether your question is already answered in our:; Documentation http://cromwell.readthedocs.io/en/develop/; Bioinformatics Stack Exchange https://bioinformatics.stackexchange.com/search?q=cromwell; Slack https://join.slack.com/t/cromwellhq/shared_invite/zt-dxmmrtye-JHxwKE53rfKE_ZWdOHIB4g; -->. <!-- Are you seeing something that looks like a bug? Please attach as much information as possible. -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->; I `docker load` a image locally on my device, found that there is no digest of it. ; No internet connection, but with docker-loaded images, how can I run docker image locally?",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6940:578,config,configuration,578,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6940,1,['config'],['configuration']
Modifiability,"<!--; Hi! Thanks for taking the time to report feedback. Please check whether your question is already answered in our:; Documentation http://cromwell.readthedocs.io/en/develop/; Bioinformatics Stack Exchange https://bioinformatics.stackexchange.com/search?q=cromwell; Slack https://join.slack.com/t/cromwellhq/shared_invite/zt-dxmmrtye-JHxwKE53rfKE_ZWdOHIB4g; -->. <!-- Are you seeing something that looks like a bug? Please attach as much information as possible. -->. <!-- Which backend are you running? -->; Backend: GCP Batch; <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->. When running a workflow with `google_project` and/or `google_compute_service_account` workflow options defined, those two options don't take/have any effect on the workflow. The workflow executes in the project defined in the Batch backend config, using the service account defined in the Batch backend config. This breaks the ability to run workflows cross-project from a single cromwell instance with a single gcp backend (which was supported in PAPI). Workarounds like defining multiple backends (each for a separate project/compute sa) are not ideal. Looking through the Batch [backend code](https://github.com/broadinstitute/cromwell/blob/4cddc6163b0b1d73e02f3723a82634df852b754b/supportedBackends/google/batch/src/main/scala/cromwell/backend/google/batch/api/GcpBatchRequestFactoryImpl.scala#L168-L169), it seems the issue is the `parent` and `gcpSa` are populated from `batchAttributes` and `gcpBatchParameters` rather than `createParameters` where the workflow options would override the values defined in the backend config. The fix for this seems trivial, so I will submit a PR.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7459:598,config,configuration,598,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7459,4,['config'],"['config', 'configuration']"
Modifiability,"<!--; Hi! Thanks for taking the time to report feedback. Please check whether your question is already answered in our:; Documentation http://cromwell.readthedocs.io/en/develop/; Bioinformatics Stack Exchange https://bioinformatics.stackexchange.com/search?q=cromwell; Slack https://join.slack.com/t/cromwellhq/shared_invite/zt-dxmmrtye-JHxwKE53rfKE_ZWdOHIB4g; -->. <!-- Are you seeing something that looks like a bug? Please attach as much information as possible. -->; Cromwell doesn't resolve relative file imports when main wdl is referenced using URL in azure. However GCP does resolve these relative paths. . Ideally you can just point to the wdl on github or dockstore and it would resolve the url relative paths correctly. <!-- Which backend are you running? -->; Azure batch. <!-- Paste/Attach your workflow if possible: -->; https://github.com/broadinstitute/viral-pipelines/blob/master/pipes/WDL/workflows/fetch_sra_to_bam.wdl. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6936:955,config,configuration,955,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6936,1,['config'],['configuration']
Modifiability,"<!--; Hi! Thanks for taking the time to report feedback. Please check whether your question is already answered in our:; Documentation http://cromwell.readthedocs.io/en/develop/; Bioinformatics Stack Exchange https://bioinformatics.stackexchange.com/search?q=cromwell; Slack https://join.slack.com/t/cromwellhq/shared_invite/zt-dxmmrtye-JHxwKE53rfKE_ZWdOHIB4g; -->. <!-- Are you seeing something that looks like a bug? Please attach as much information as possible. -->; Default application.json not found in classpath in precompiled jar on github (affecting multiple releases tested version 86 and 85). ; Tested to not be affected version 79/56. Main error below. Should be an easy fix. . ```; Exception in thread ""main"" com.typesafe.config.ConfigException$IO: application: application.conf: java.io.IOException: resource not found on classpath: application.conf, application.json: java.io.IOException: resource not found on classpath: application.json, application.properties: java.io.IOException: resource not found on classpath: application.properties; at com.typesafe.config.impl.SimpleIncluder.fromBasename(SimpleIncluder.java:236); at com.typesafe.config.impl.ConfigImpl.parseResourcesAnySyntax(ConfigImpl.java:133); at com.typesafe.config.ConfigFactory.parseResourcesAnySyntax(ConfigFactory.java:1083); at com.typesafe.config.impl.SimpleIncluder.includeResourceWithoutFallback(SimpleIncluder.java:123); at com.typesafe.config.impl.SimpleIncluder.includeResources(SimpleIncluder.java:109); at com.typesafe.config.impl.ConfigParser$ParseContext.parseInclude(ConfigParser.java:181); at com.typesafe.config.impl.ConfigParser$ParseContext.parseObject(ConfigParser.java:237); at com.typesafe.config.impl.ConfigParser$ParseContext.parseValue(ConfigParser.java:103); at com.typesafe.config.impl.ConfigParser$ParseContext.parse(ConfigParser.java:415); at com.typesafe.config.impl.ConfigParser.parse(ConfigParser.java:25); at com.typesafe.config.impl.Parseable.rawParseValue(Parseable.java:263); at com.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7255:735,config,config,735,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7255,2,"['Config', 'config']","['ConfigException', 'config']"
Modifiability,"<!--; Hi! Thanks for taking the time to report feedback. Please check whether your question is already answered in our:; Documentation http://cromwell.readthedocs.io/en/develop/; Bioinformatics Stack Exchange https://bioinformatics.stackexchange.com/search?q=cromwell; Slack https://join.slack.com/t/cromwellhq/shared_invite/zt-dxmmrtye-JHxwKE53rfKE_ZWdOHIB4g; -->. <!-- Are you seeing something that looks like a bug? Please attach as much information as possible. -->; Hello, I'm trying to run a workflow locally and it gets stalled on BackgroundConfigAsyncJobExecutionActor [5b4a3086Regenie.RegenieStep1WholeGenomeModel:NA:1]: Status change from - to WaitingForReturnCode; <!-- Which backend are you running? -->; I'm using a local backend; <!-- Paste/Attach your workflow if possible: -->; I'm attaching the workflow which is written in WDL language; <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->; I'm attaching a screenshot of the configuration file and the input files which I provide to cromwell in json format; <img width=""988"" alt=""Screenshot 2023-08-02 at 3 27 39 PM"" src=""https://github.com/broadinstitute/cromwell/assets/56558154/e676859c-4f47-4f3a-ae20-68b2ead010e9"">. Also I'm proving the workflow called regenie.txt; [regenie.txt](https://github.com/broadinstitute/cromwell/files/12243956/regenie.txt); <img width=""714"" alt=""Screenshot 2023-08-02 at 3 29 07 PM"" src=""https://github.com/broadinstitute/cromwell/assets/56558154/567932ac-ce61-41dc-b1c1-8321c2ccab54"">; I'm providing the full log file as well. ; [regenie.log](https://github.com/broadinstitute/cromwell/files/12243995/regenie.log); If I run the commands locally without using a WDL workflow this runs in under 10 seconds in my local computer. . I appreciate any insight. . I'm using cromwell-85.jar and my java version is ; openjdk version ""17.0.6"" 2023-01-17; OpenJDK Runtime Environment Temurin-17.0.6+10 (build 17.0.6+10); OpenJDK 64-Bit Server VM Temur",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7191:871,config,configuration,871,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7191,2,['config'],['configuration']
Modifiability,"<!--; Hi! Thanks for taking the time to report feedback. Please check whether your question is already answered in our:; Documentation http://cromwell.readthedocs.io/en/develop/; Bioinformatics Stack Exchange https://bioinformatics.stackexchange.com/search?q=cromwell; Slack https://join.slack.com/t/cromwellhq/shared_invite/zt-dxmmrtye-JHxwKE53rfKE_ZWdOHIB4g; -->. <!-- Are you seeing something that looks like a bug? Please attach as much information as possible. -->; Hi!. We've been looking into migrating from PAPIv2 backend to GCPBATCH backend. Callcaching fails on GCPBATCH but not on PAPIv2 when using a private docker image in gcr.io. ; Is this a missing feature or a bug? The documentation on the subject could go either way, depending on whether GCPBATCH is part of the other backends or a subset of the pipelines backend (https://cromwell.readthedocs.io/en/latest/cromwell_features/CallCaching/). ; I do not think this is a configuration error, since the same config works with PAPIv2 backend, but if it is, what configuration options would be necessary for configuring gcr.io authentication when using GCPBATCH?. Errors from cromwell logs when task is being callcached:; ```; cromwell_1 | 2024-01-11 11:09:38 pool-9-thread-9 INFO - Manifest request failed for docker manifest V2, falling back to OCI manifest. Image: DockerImageIdentifierWithoutHash(Some(eu.gcr.io),Some(project),image_name,tag); cromwell_1 | cromwell.docker.registryv2.DockerRegistryV2Abstract$Unauthorized: 401 Unauthorized {""errors"":[{""code"":""UNAUTHORIZED"",""message"":""You don't have the needed permissions to perform this operation, and you may have invalid credentials. To authenticate your request, follow the steps in: https://cloud.google.com/container-registry/docs/advanced-authentication""}]}; cromwell_1 | 	at cromwell.docker.registryv2.DockerRegistryV2Abstract.$anonfun$getDigestFromResponse$1(DockerRegistryV2Abstract.scala:321); cromwell_1 | 	at map @ fs2.internal.CompileScope.$anonfun$close$9(CompileScope.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7356:936,config,configuration,936,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7356,4,['config'],"['config', 'configuration', 'configuring']"
Modifiability,"<!--; Hi! Thanks for taking the time to report feedback. Please check whether your question is already answered in our:; Documentation http://cromwell.readthedocs.io/en/develop/; Bioinformatics Stack Exchange https://bioinformatics.stackexchange.com/search?q=cromwell; Slack https://join.slack.com/t/cromwellhq/shared_invite/zt-dxmmrtye-JHxwKE53rfKE_ZWdOHIB4g; -->. <!-- Are you seeing something that looks like a bug? Please attach as much information as possible. -->; The GCP batch backend preemption handling seems to have issue. When preemption happens the job had very high possibility to be error. The typical error would be : time=“…” level=error msg=“error waiting for container:” . It will take the preempt events as the error from Cromwell logs. However, in the google batch console, it shows clearly ""preemption notice has received and will be processed"". . <!-- Which backend are you running? -->; GCP batch ; <!-- Paste/Attach your workflow if possible: -->; The workflow works perfectly in GCP life science backend; <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7407:1047,config,configuration,1047,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7407,1,['config'],['configuration']
Modifiability,"<!--; Hi! Thanks for taking the time to report feedback. Please check whether your question is already answered in our:; Documentation http://cromwell.readthedocs.io/en/develop/; Bioinformatics Stack Exchange https://bioinformatics.stackexchange.com/search?q=cromwell; Slack https://join.slack.com/t/cromwellhq/shared_invite/zt-dxmmrtye-JHxwKE53rfKE_ZWdOHIB4g; -->. Hi,. Since last week, our cromwell server instance on GCP started to encounter the following error in all the jobs:. ```; 2024-07-31 19:08:59 cromwell-system-akka.dispatchers.backend-dispatcher-35 WARN - PAPI request worker had 1 failures making 1 requests: ; Unable to complete PAPI request due to system or connection error (Unknown Error.); 2024-07-31 19:09:33 cromwell-system-akka.dispatchers.backend-dispatcher-56 WARN - PAPI request worker had 1 failures making 1 requests: ; Unable to complete PAPI request due to system or connection error (Unknown Error.); 2024-07-31 19:10:06 cromwell-system-akka.dispatchers.backend-dispatcher-56 WARN - PAPI request worker had 1 failures making 1 requests: ; Unable to complete PAPI request due to system or connection error (Unknown Error.); ```. However, with `Unknown Error` message, I don't know where to go for help. Do you have any suggestion?. Here are the configurations:. * Cromwell v85; * Genomics API; * PAPIv2 with `actor-factory = ""cromwell.backend.google.pipelines.v2alpha1.PipelinesApiLifecycleActorFactory""`. Many thanks!. <!-- Are you seeing something that looks like a bug? Please attach as much information as possible. -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7482:1275,config,configurations,1275,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7482,2,['config'],"['configuration', 'configurations']"
Modifiability,"<!--; Hi! Thanks for taking the time to report feedback. Please check whether your question is already answered in our:; Documentation http://cromwell.readthedocs.io/en/develop/; Bioinformatics Stack Exchange https://bioinformatics.stackexchange.com/search?q=cromwell; Slack https://join.slack.com/t/cromwellhq/shared_invite/zt-dxmmrtye-JHxwKE53rfKE_ZWdOHIB4g; -->. I believe there is an error in the information provided by the Reference Disk Support in the documents for using reference disk images in gcpbatch. I believe there is a ""["" missing or this bit is additional as there are 3 ""["" present in the example. When trying to run this on my cromwell config, I get a syntax error. This is regarding using GCPBatch and not PAPI V2 as mentioned in some examples:. This is what I think it should look like:. ``` ; reference-disk-localization-manifests = [ ; {; ""imageIdentifier"": ""projects/pmc-bdc-private-test-cromwell/global/images/omics-reference-disk-image"",; ""diskSizeGb"": 10, ; ""files"": [ ; {; ""path"": ""pmc-bdc-test-cromwell-references/hg38/v0/Homo_sapiens_assembly38.dict"",; ""crc32c"": 2158779318; },; {; ""path"": ""pmc-bdc-test-cromwell-references/hg38/v0/Homo_sapiens_assembly38.fasta"",; ""crc32c"": 420322484; },; {; ""path"": ""pmc-bdc-test-cromwell-references/hg38/v0/Homo_sapiens_assembly38.fasta.fai"",; ""crc32c"": 1970999569; }; ]; }; ] ; ```; Not sure if reference-disk-localization = [] is also correct",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7486:655,config,config,655,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7486,1,['config'],['config']
Modifiability,"<!--; Hi! Thanks for taking the time to report feedback. Please check whether your question is already answered in our:; Documentation http://cromwell.readthedocs.io/en/develop/; Bioinformatics Stack Exchange https://bioinformatics.stackexchange.com/search?q=cromwell; Slack https://join.slack.com/t/cromwellhq/shared_invite/zt-dxmmrtye-JHxwKE53rfKE_ZWdOHIB4g; -->. I'm using Cromwell v87 on GCP Genomics API. When submitting a job, the error I got is the following:. ```; Caused by: java.lang.IllegalStateException: You are currently running with version 2.2.0 of google-api-client. You need at least version 1.31.1 of google-api-client to run version 1.32.1 of the Genomics API library.; at com.google.common.base.Preconditions.checkState(Preconditions.java:534); at com.google.api.client.util.Preconditions.checkState(Preconditions.java:113); at com.google.api.services.genomics.v2alpha1.Genomics.<clinit>(Genomics.java:44); ... 12 common frames omitted; ```. It seems that I need to downgrade the version of `google-api-client`. However, I don't know how to do it on my machine. Could anyone help? Thanks!. <!-- Are you seeing something that looks like a bug? Please attach as much information as possible. -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7481:1323,config,configuration,1323,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7481,1,['config'],['configuration']
Modifiability,"<!--; Hi! Thanks for taking the time to report feedback. Please check whether your question is already answered in our:; Documentation http://cromwell.readthedocs.io/en/develop/; Bioinformatics Stack Exchange https://bioinformatics.stackexchange.com/search?q=cromwell; Slack https://join.slack.com/t/cromwellhq/shared_invite/zt-dxmmrtye-JHxwKE53rfKE_ZWdOHIB4g; -->; I am using `checkpointFile` in the `runtime` section of a WDL `task`. . I accidentally included a space in the checkpoint file name, and I see in the logs that this (probably) breaks checkpointing. <!-- Are you seeing something that looks like a bug? Please attach as much information as possible. -->; Log file shows; ```; CHECKPOINTING: Making local copy of /cromwell_root/noise_prompting_classical monocyte_H_shard0.csv; cp: can't create 'monocyte_H_shard0.csv-tmp/noise_prompting_classical': No such file or directory; cp: can't create 'monocyte_H_shard0.csv-tmp/monocyte_H_shard0.csv': No such file or directory; cp: can't create 'monocyte_H_shard0.csv-tmp/noise_prompting_classical': No such file or directory; CHECKPOINTING: Uploading new checkpoint content; ```. <!-- Which backend are you running? -->; Running on GCP via Terra. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->. When I remove the space in the filename, I see this in the logs, which appears to be working fine:. ```; CHECKPOINTING: Making local copy of /cromwell_root/noise_prompting_classical_monocyte_H_shard0.csv; CHECKPOINTING: Uploading new checkpoint content; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7441:1270,config,configuration,1270,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7441,1,['config'],['configuration']
Modifiability,"<!--; Hi! Thanks for taking the time to report feedback. Please check whether your question is already answered in our:; Documentation http://cromwell.readthedocs.io/en/develop/; Bioinformatics Stack Exchange https://bioinformatics.stackexchange.com/search?q=cromwell; Slack https://join.slack.com/t/cromwellhq/shared_invite/zt-dxmmrtye-JHxwKE53rfKE_ZWdOHIB4g; -->; I think the minimum to reproduce the bug is just. ```; Array[File] foo = []; Array[String]? bar = foo; ```. which fails with. ```; ""failures"": [; {; ""causedBy"": [; {; ""message"": ""Failed to evaluate 'bar' (reason 1 of 1): Evaluating foo failed: assertion failed: base member type WomMaybeEmptyArrayType(WomStringType) and womtype WomMaybeEmptyArrayType(WomSingleFileType) are not compatible"",; ""causedBy"": []; }; ],; ""message"": ""Workflow failed""; }; ],; ```. Interestingly enough, this passes if the array is non-empty, or if the target is not optional, or if the source is type `Array[String]`. I am running cromwell ""v85 (ish)"" according to the administrator. Backend is AWS batch.; <!-- Are you seeing something that looks like a bug? Please attach as much information as possible. -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7399:1262,config,configuration,1262,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7399,1,['config'],['configuration']
Modifiability,"<!--; Hi! Thanks for taking the time to report feedback. Please check whether your question is already answered in our:; Documentation http://cromwell.readthedocs.io/en/develop/; Bioinformatics Stack Exchange https://bioinformatics.stackexchange.com/search?q=cromwell; Slack https://join.slack.com/t/cromwellhq/shared_invite/zt-dxmmrtye-JHxwKE53rfKE_ZWdOHIB4g; -->; This is a remark on https://github.com/broadinstitute/cromwell/blob/master/docs/tutorials/HPCSlurmWithLocalScratch.md there is a feature on slum config to edit the sbatch command. You could add in a find and replace in the config to do the same as the tutorial. you can skip the first part of the tutorial by editing the slurm backend config (somewhat hotpatching the scripts on submission time). old submit ; submit = """"""; sbatch -J ${job_name} -D ${cwd} -o ${out} -e ${err} -t ${runtime_minutes} -p ${queue} ${""-c "" +; cpu} --mem ${memory_mb} --wrap ""/bin/bash ${script}""; """""". new submit for slurm auto configured job dir: ; submit = """"""; perl -i.bak -wpe 's/^tmpDir=.*/tmpdir=""\$TMPDIR""/g' ${script} && \; sbatch -J ${job_name} --tmp=${disk} -D ${cwd} -o ${out} -e ${err} -t ${runtime_minutes} -p ${queue} ${""-c "" +; cpu} --mem ${memory_mb} --wrap ""/bin/bash ${script}""; """""". new submit for /genomics/local/ (not tested tough): ; submit = """"""; perl -i.bak -wpe 's/^tmpDir=.*/tmpdir=""$(mkdir -p ""\/genomics_local\/\$PID_\$HOSTNAME""\/"" && echo ""\/genomics_local\/\$PID_\$HOSTNAME""\/""/g' ${script} && \; sbatch -J ${job_name} --tmp=${disk} -D ${cwd} -o ${out} -e ${err} -t ${runtime_minutes} -p ${queue} ${""-c "" +; cpu} --mem ${memory_mb} --wrap ""/bin/bash ${script}""; """""". <!-- Are you seeing something that looks like a bug? Please attach as much information as possible. -->; <!-- This is a clear feature cant you see -->. <!-- Which backend are you running? -->; The backend I'm running on is Slurm hpc with a version 1.0 workflow. This alternative workflow has its downsides but also benefits it is up to the hpc(user) to decide ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7357:511,config,config,511,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7357,4,['config'],"['config', 'configured']"
Modifiability,"<!--; Hi! Thanks for taking the time to report feedback. Please check whether your question is already answered in our:; Documentation http://cromwell.readthedocs.io/en/develop/; Bioinformatics Stack Exchange https://bioinformatics.stackexchange.com/search?q=cromwell; Slack https://join.slack.com/t/cromwellhq/shared_invite/zt-dxmmrtye-JHxwKE53rfKE_ZWdOHIB4g; -->; womtool cannot be used in cwl; <!-- Are you seeing something that looks like a bug? Please attach as much information as possible. -->. <!-- Which backend are you running? -->; java -jar womtool-84.jar validate hello_world.cwl; No getWomBundle method implemented in CWL v1; <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6973:706,config,configuration,706,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6973,1,['config'],['configuration']
Modifiability,"= ""europe-west4"". # Restrict access to VM metadata. Useful in cases when untrusted containers are running under a service; # account not owned by the submitting user; restrict-metadata-access = false. # Pipelines v2 only: specify the number of times localization and delocalization operations should be attempted; # There is no logic to determine if the error was transient or not, everything is retried upon failure; # Defaults to 3; localization-attempts = 3. # Specifies the minimum file size for `gsutil cp` to use parallel composite uploads during delocalization.; # Parallel composite uploads can result in a significant improvement in delocalization speed for large files; # but may introduce complexities in downloading such files from GCS, please see; # https://cloud.google.com/storage/docs/gsutil/commands/cp#parallel-composite-uploads for more information.; #; # If set to 0 parallel composite uploads are turned off. The default Cromwell configuration turns off; # parallel composite uploads, this sample configuration turns it on for files of 150M or larger.; parallel-composite-upload-threshold=""150M""; }. # Controls how batched requests to PAPI are handled:; batch-requests {; timeouts {; # Timeout when attempting to connect to PAPI to make requests:; # read = 10 seconds. # Timeout waiting for batch responses from PAPI:; #; # Note: Try raising this value if you see errors in logs like:; # WARN - PAPI request worker PAPIQueryWorker-[...] terminated. 99 run creation requests, 0 status poll requests, and 0 abort requests will be reconsidered. If any of those succeeded in the cloud before the batch request failed, they might be run twice.; # ERROR - Read timed out; # connect = 10 seconds; }; }; filesystems {; gcs {; # A reference to a potentially different auth for manipulating files via engine functions.; auth = ""service-account""; # Google project which will be billed for the requests; project = ""***-***"". caching {; # When a cache hit is found, the following duplication s",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6469:13922,config,configuration,13922,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6469,2,['config'],['configuration']
Modifiability,"= ""xxxxx""; root = ""gs://xxxx/cromwell_execution""; virtual-private-cloud {; network-label-key = ""xxx""; subnetwork-label-key = ""xxx""; auth = ""application-default""; }; name-for-call-caching-purposes: PAPI; slow-job-warning-time: ""24 hours""; genomics-api-queries-per-100-seconds = 1000; maximum-polling-interval = 600; request-workers = 3; genomics {; auth = ""application-default""; endpoint-url = ""https://genomics.googleapis.com/""; location = ""us-west1""; restrict-metadata-access = false; localization-attempts = 3; parallel-composite-upload-threshold=""150M""; }; filesystems {; gcs {; auth = ""application-default""; project = ""xxxx""; caching {; duplication-strategy = ""copy""; }; }; http { }; }; default-runtime-attributes {; cpu: 1; failOnStderr: false; continueOnReturnCode: 0; memory: ""2048 MB""; bootDiskSizeGb: 10; disks: ""local-disk 10 SSD""; noAddress: false; preemptible: 0; zones: [""us-west1-a"", ""us-west1-b""]; }; include ""papi_v2_reference_image_manifest.conf""; }; }; }; }; ```; When I run with the above config using:; ```; java -Dconfig.file=genomics.conf -jar cromwell-66.jar run cumulus.wdl -i cumulus_inputs.json; ```; I am getting the following error message:; ```; [2021-08-24 22:05:33,60] [info] WorkflowManagerActor: Workflow 6cc303b4-295d-49fa-a996-b5cf7ec9beea failed (during ExecutingWorkflowState): java.lang.Exception: Task cumulus.cluster:NA:1 failed. The job was stopped before the command finished. PAPI error code 3. Execution failed: allocating: creating instance: inserting instance: Invalid value for field 'resource.networkInterfaces[0].network': ''. The referenced network resource cannot be found.; ```; I have tried passing the vpc and subnet id using the following config:; ```; virtual-private-cloud {; network-label-key = ""xxx""; subnetwork-label-key = ""xxx""; auth = ""application-default""; }; ```. The above values are my actual vpc and subnet id/name. However, it is still giving me that error message. Is there something I am missing from a configuration perspective. ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6477:1613,config,config,1613,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6477,1,['config'],['config']
Modifiability,"= {HashSet@5518} size = 43; defaultCatalogName = null; defaultSchemaName = null; currentDateTimeFunction = ""CURRENT_TIMESTAMP""; sequenceNextValueFunction = null; sequenceCurrentValueFunction = null; dateFunctions = {ArrayList@5520} size = 1; unmodifiableDataTypes = {ArrayList@5521} size = 0; defaultAutoIncrementStartWith = {BigInteger@5522} ""1""; defaultAutoIncrementBy = {BigInteger@5522} ""1""; unquotedObjectsAreUppercased = null; quotingStrategy = {ObjectQuotingStrategy@5523} ""QUOTE_ALL_OBJECTS""; caseSensitive = {Boolean@5524} true; databaseChangeLogTableName = null; databaseChangeLogLockTableName = null; liquibaseTablespaceName = null; liquibaseSchemaName = null; liquibaseCatalogName = null; previousAutoCommit = {Boolean@5524} true; canCacheLiquibaseTableInfo = false; connection = {JdbcConnection@5525} ; outputDefaultSchema = true; outputDefaultCatalog = true; defaultCatalogSet = false; attributes = {HashMap@5526} size = 0; ```. `defaultCatalogName` and `defaultSchemaName` are all defined for the HSQLDB database so maybe it is something there?. Anyway it also does not run properly outside of the test configuration. Running cromwell (compiled from this branch) with the following configuration:; ```; database {; profile = ""slick.jdbc.SQLiteProfile$""; db {; driver = ""org.sqlite.JDBC""; url = ""jdbc:sqlite::memory:""; }; ```. Gives the following error:; ```; org.sqlite.SQLiteException: [SQLITE_ERROR] SQL error or missing database (near ""for"": syntax error); at org.sqlite.core.DB.newSQLException(DB.java:941); at org.sqlite.core.DB.newSQLException(DB.java:953); at org.sqlite.core.DB.throwex(DB.java:918); ```; Which is rather non-descript. . I have been digging for the entire afternoon, but I can not find the root cause. The other database types seem to work fine without lots of additional configuration, so I did not get much inspiration from that. Could somebody help me out? I will then do all the rest of the work, write the documentation etc. . Thanks!. Best regards,; Ruben",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5453:2147,config,configuration,2147,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5453,3,['config'],['configuration']
Modifiability,"> We use lots of different runtime attributes (bsub job submission parameters) in our workflows.  ; > ; > With existing Cromwell backends, you need to put all the possible runtime attributes in the code itself.  Would it be possible to let the user specify arbitrary runtime parameters only in the configuration file (not in the source code) that Cromwell just passes to the submit command?  ; > ; > We want to avoid asking for Cromwell code changes every time we decide to use a new bsub parameter. -- Pfizer",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1217:298,config,configuration,298,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1217,1,['config'],['configuration']
Modifiability,"@Horneth commented on [Fri May 12 2017](https://github.com/broadinstitute/centaur/issues/191). This is not necessarily a centaur ticket, more of a ""testing"" ticket. There is no easy way to test different **non-backend specific** config values of Cromwell in travis.; It would be nice to have some way to do that.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2896:229,config,config,229,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2896,1,['config'],['config']
Modifiability,@Horneth commented on [Mon Sep 11 2017](https://github.com/broadinstitute/wdl4s/issues/195). WOM currently uses the WDL CommandPart which contains WDL specific constructs (WdlFunctions); WOM should get its own CommandPart.; Also factor in the fact that tweaks will have to be made in the way the command is instantiated depending on the language or even language configuration (this might be better put in the TaskDefinition instead though),MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2717:363,config,configuration,363,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2717,1,['config'],['configuration']
Modifiability,"@Horneth commented on [Wed Nov 16 2016](https://github.com/broadinstitute/wdl4s/issues/48). ---. @meganshand commented on [Wed Nov 16 2016](https://github.com/broadinstitute/wdl4s/issues/48#issuecomment-261072803). The attached wdl results in an error message:. `Workflow has invalid declarations: : AggregatedException: : VariableNotFoundException: Variable 'generateArray' not found`. [scratch_3.wdl.txt](https://github.com/broadinstitute/wdl4s/files/595927/scratch_3.wdl.txt). ---. @Horneth commented on [Wed Nov 16 2016](https://github.com/broadinstitute/wdl4s/issues/48#issuecomment-261089538). @meganshand . This is actually a different problem - Cromwell doesn't support (yet) Workflow Declarations that reference call outputs. This wouldn't work either:. ```; task t {; command {; echo ""hello""; }; output {; String o = read_string(stdout()); }; }. workflow w {; call t; String declarationDependingOnCallOutput = t.o; }; ```. ---. @meganshand commented on [Wed Nov 16 2016](https://github.com/broadinstitute/wdl4s/issues/48#issuecomment-261092137). Oh no! This actually makes using zips infeasible, since I'd imagine in most cases the things you want to zip will be outputs from previous tasks. I suppose I can use a workaround where inside of a scatter loop I can create a task that takes in a File and Array[File] and outputs a Pair, then scatter over the output of that task outside of the original scatter. ---. @meganshand commented on [Wed Nov 16 2016](https://github.com/broadinstitute/wdl4s/issues/48#issuecomment-261095003). I tried that workaround with a task like this:. ```; task ZipUpWorkaround {; File unmapped_bam; Array[File] fastqs. command {; #do nothing; }; output {; Pair[File, Array[File]] p = [unmapped_bam, fastqs]; }; }; ```. and got this error message (after it submitted that task):; `Failed to evaluate outputs.: WdlTypeException: Arrays/Maps must have homogeneous types`. ---. @Horneth commented on [Wed Nov 16 2016](https://github.com/broadinstitute/wdl4s/issues/48",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2692:323,Variab,VariableNotFoundException,323,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2692,2,['Variab'],"['Variable', 'VariableNotFoundException']"
Modifiability,"@abaumann said that they're having a serious issue (due to BBQ) with workflows which have become stuck in non-terminal states. Set up some monitor which runs at a configurable period to look through all non-terminal workflows/calls and make sure that things are actually non-terminal, switching to terminal states as appropriate. This solution is viewed as a relatively painless (vs fixing it For Real) way of solving the problem, but if one sees an easier way of doing it that's even better.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/940:163,config,configurable,163,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/940,1,['config'],['configurable']
Modifiability,"@cjllanwarne Something went wrong with the latest release of the womtool.; The cromwell.jar does properly display the CLI usage when run.; ```; $ java -jar womtool-53.jar ; Exception in thread ""main"" java.lang.NoClassDefFoundError: scala/concurrent/duration/Duration; 	at scopt.Read$.liftedTree1$1(options.scala:67); 	at scopt.Read$.<init>(options.scala:66); 	at scopt.Read$.<clinit>(options.scala); 	at womtool.cmdline.WomtoolCommandLineParser.<init>(WomtoolCommandLineParser.scala:30); 	at womtool.cmdline.WomtoolCommandLineParser$.instance$lzycompute(WomtoolCommandLineParser.scala:13); 	at womtool.cmdline.WomtoolCommandLineParser$.instance(WomtoolCommandLineParser.scala:13); 	at womtool.WomtoolMain$.runWomtool(WomtoolMain.scala:158); 	at womtool.WomtoolMain$.delayedEndpoint$womtool$WomtoolMain$1(WomtoolMain.scala:166); 	at womtool.WomtoolMain$delayedInit$body.apply(WomtoolMain.scala:27); 	at scala.Function0.apply$mcV$sp(Function0.scala:39); 	at scala.Function0.apply$mcV$sp$(Function0.scala:39); 	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:17); 	at scala.App.$anonfun$main$1$adapted(App.scala:80); 	at scala.collection.immutable.List.foreach(List.scala:392); 	at scala.App.main(App.scala:80); 	at scala.App.main$(App.scala:78); 	at womtool.WomtoolMain$.main(WomtoolMain.scala:27); 	at womtool.WomtoolMain.main(WomtoolMain.scala); Caused by: java.lang.ClassNotFoundException: scala.concurrent.duration.Duration; 	at java.base/jdk.internal.loader.BuiltinClassLoader.loadClass(BuiltinClassLoader.java:581); 	at java.base/jdk.internal.loader.ClassLoaders$AppClassLoader.loadClass(ClassLoaders.java:178); 	at java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:522); 	... 18 more; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5808:1115,adapt,adapted,1115,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5808,1,['adapt'],['adapted']
Modifiability,"@cjllanwarne commented on [Mon May 22 2017](https://github.com/broadinstitute/wdl4s/issues/112). This problem presents itself when using `wdltool` but it looks like it's a match error coming from inside `WDL4S`. null.wdl:; ```; task empty{; command {}; output {; File out = ""${output}""; }; }; ```. On validate:; ```; $ java -jar target/scala-2.12/wdltool-0.11.jar validate ~/myWorkflows/null.wdl; null; ```. We can see more details when we try to graph it:; ```; $ java -jar target/scala-2.12/wdltool-0.11.jar graph ~/myWorkflows/null.wdl; Exception in thread ""main"" scala.MatchError: null; 	at wdl4s.expression.ValueEvaluator.evaluate(ValueEvaluator.scala:44); 	at wdl4s.WdlExpression$.evaluate(WdlExpression.scala:85); 	at wdl4s.WdlExpression.evaluate(WdlExpression.scala:161); 	at wdl4s.expression.ValueEvaluator.replaceInterpolationTag(ValueEvaluator.scala:20); 	at wdl4s.expression.ValueEvaluator.$anonfun$interpolate$2(ValueEvaluator.scala:33); 	at scala.collection.TraversableOnce.$anonfun$foldLeft$1(TraversableOnce.scala:157); 	at scala.collection.TraversableOnce.$anonfun$foldLeft$1$adapted(TraversableOnce.scala:157); ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2703:1093,adapt,adapted,1093,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2703,1,['adapt'],['adapted']
Modifiability,@danbills I ended up using the global conf in the interest of time.; I'm sure there's a better way to do it (@cjllanwarne suggested through the language factory configuration which seems a good idea). This is what the original ticket actually intended: https://github.com/broadinstitute/cromwell/issues/2611,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3669:161,config,configuration,161,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3669,1,['config'],['configuration']
Modifiability,"@danbills I was looking at the EJEA and on second thoughts it seemed a lot easier to just have it push the state transition to statsD directly.; I was thinking we could still use the ammonite script to aggregate transition time statistics about a single test run (which we can't really easily do in grafana) in a SQL table like you suggested before.; This way we could compare test by test how the measurements evolve, while grafana would show us ""real time"" how the timings are moving (which may even be useful in prod). Let me know what you think. Example from a test run (Y axis is ms):. <img width=""1416"" alt=""screen shot 2018-09-11 at 9 27 48 am"" src=""https://user-images.githubusercontent.com/2978948/45363248-02712180-b5a5-11e8-987f-f128e8bd3789.png"">. ~~Unrelated but I also took the opportunity to make execution events be pushed as they happen (the EJEA ones, not the backend ones - yet). This will hopefully give users more visibility on what's going on with their job in the timing diagram~~",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4083:411,evolve,evolve,411,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4083,1,['evolve'],['evolve']
Modifiability,"@egor-broad commented on [Fri Jun 09 2017](https://github.com/broadinstitute/wdltool/issues/31). The sample script is attached below.; Given a task call like that: ; ```; if (condition) {; call select as selectCondition {; input: ; sampleName=name, ; RefFasta=undeclaredVariable, #this variable does not exist; GATK=gatk, ; RefIndex=refIndex, ; RefDict=refDict, ; type=""SNP"", ; rawVCF=haplotypeCaller.rawVCF; }; }; ```; `wdltool inputs` command will generate the inputs just like everything is fine, but since the undeclaredVariable does not exist, when the task is executed, the run will exit with an error. You can try it with the attached script. ; However, this tool http://pb.opensource.epam.com:10000/ is able to notice the error (try and paste the script there and click ""build"", it will say ""Error: Undeclared variable is referenced: 'undeclaredVariable'). . [simpleVariantSelection.txt](https://github.com/broadinstitute/wdltool/files/1064633/simpleVariantSelection.txt)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2880:286,variab,variable,286,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2880,2,['variab'],['variable']
Modifiability,"@geoffjentry commented on [Tue Apr 26 2016](https://github.com/broadinstitute/centaur/issues/36). Initially Centaur loaded in its files for each test (wdl, inputs, etc) using a function which would throw an exception if it wasn't there. As the framework has evolved it has moved to a model that is more robust and would more accurately report what was going on there. Modify these file slurps to play nicer with the rest of the system",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2885:258,evolve,evolved,258,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2885,1,['evolve'],['evolved']
Modifiability,"@helgridly commented on [Thu Apr 13 2017](https://github.com/broadinstitute/wdl4s/issues/103). I'm loading a WDL in wdl4s using `WdlNamespaceWithWorkflow.load(my_wdl, Seq())` -- i.e. passing no import resolvers. If the WDL contains imports, I'd expect it to fail and complain that it can't resolve the imports because I haven't specified any resolvers. (In the current code, that'd be [here](https://github.com/broadinstitute/wdl4s/blob/develop/src/main/scala/wdl4s/WdlNamespace.scala#L198).). However, what actually happens is that wdl4s tries to turn the import into a `File` object [here](https://github.com/broadinstitute/wdl4s/blob/develop/src/main/scala/wdl4s/Import.scala#L18). If that's not a valid kind of file path (perhaps because of a custom URI scheme, or because you're running Windows and colons aren't allowed in filenames), wdl4s blows up with some java-native exception. (In the Windows case, that's `java.nio.file.InvalidPathException`.). TLDR: wdl4s should throw a useful error if your WDL contains imports but you haven't specified resolvers. It probably shouldn't attempt to load the imports outside the context of a resolver, either. ---. @helgridly commented on [Thu Apr 13 2017](https://github.com/broadinstitute/wdl4s/issues/103#issuecomment-293936559). I discussed this with @Horneth and he's provided me with a workaround: I can check for the existence of imports in my code by loading the AST directly using something like `Option(ast).map(_.getAttribute(""imports"")).toSeq` (lifted from [here](https://github.com/broadinstitute/wdl4s/blob/develop/src/main/scala/wdl4s/WdlNamespace.scala#L185)). So consider this a non-urgent enhancement rather than a cloud of fire.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2701:1654,enhance,enhancement,1654,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2701,1,['enhance'],['enhancement']
Modifiability,"@jsotobroad the default limit on results for the GCS list API is 1000. I made this configurable and bumped up the default to 50K. That number is basically pulled out of thin air, if you have a more informed suggestion of a good value to use that would be great. 😄 . I still need to figure out the least awkward place to shoehorn the documentation for this value in the README.md.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/710:83,config,configurable,83,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/710,1,['config'],['configurable']
Modifiability,"@mcovarr commented on [Mon Jan 30 2017](https://github.com/broadinstitute/centaur/issues/144). Brain-dumping this for the time being in favor of higher-priority work. Building on #140, confirm other JES parameters are making it to the VM as expected. . I have some WIP [here](https://github.com/broadinstitute/centaur/commit/d7f6a3aa26ea6abc37ce26c8399a39b30c9e9322). In developing this it became apparent that both GCE VM and JES metadata can be introspected, and in most cases this is boilerplate that would be common to all the `check_a_thing` tasks. This should be refactored out into a common script so it's not copy/pasted into each task. Probably the best way to do this is to have the inputs to each task include a common `String script` which would dump GCE VM and JES metadata to files. The `check_a_thing` tasks would then do something like:. ```; task check_a_thing {; String script; String specified_value_of_attr. command <<<; $(script) # writes jes_metadata.yaml and gce_metadata.yaml; grep -Po attr_pattern jes_metadata.yaml; >>>. output {; File jes_metadata = ""jes_metadata.yaml""; File gce_metadata = ""gce_metadata.yaml""; String attr_value = read_string(stdout()); }; ; runtime {; docker: ""google/cloud-sdk""; attr: ""${specified_value_of_attr}""; }; ```. This should confirm that Cromwell's intended attribute values are communicated into JES metadata correctly. It can also be useful to make sure that intent makes it to the GCE metadata correctly (this was particularly key for preemptible). And for attributes like memory or cpu it may also be useful to check that the machine is actually provisioned as expected (e.g. checking /proc/cpu or /proc/memory). ---. @ruchim commented on [Mon Jan 30 2017](https://github.com/broadinstitute/centaur/issues/144#issuecomment-276111326). Pinging @kcibul for prioritization -- Miguel brought this up at standup today that it's a very long list of JES attribute values that can be asserted against their expected values. If you believe any speci",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2892:569,refactor,refactored,569,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2892,1,['refactor'],['refactored']
Modifiability,"@mcovarr commented on [Mon Jul 31 2017](https://github.com/broadinstitute/wdl4s/issues/156). It appears that some relatively recent changes have greatly extended compile times into multiple minutes, probably due to Circe decoding and encoding. Investigate and see if there's anything that can be done to lessen the pain. ---. @geoffjentry commented on [Mon Jul 31 2017](https://github.com/broadinstitute/wdl4s/issues/156#issuecomment-319094471). @mcovarr ""anything that can be done"". Remove Circe autoencoding? :). On a serious note, wdl4s still needs to be bumped up to 2.12.3 which should help a bit. In fact I'll do that now. ---. @mcovarr commented on [Mon Jul 31 2017](https://github.com/broadinstitute/wdl4s/issues/156#issuecomment-319094942). We tried 2.12.3 locally and whatever improvement there was didn't rock our worlds. ---. @kshakir commented on [Wed Sep 13 2017](https://github.com/broadinstitute/wdl4s/issues/156#issuecomment-329144787). Some things to also try:. [![Generic Derivation: The Hard Parts—Travis Brown](http://img.youtube.com/vi/80h3hZidSeE/0.jpg)](https://youtu.be/80h3hZidSeE?t=34m7s ""Generic Derivation: The Hard Parts—Travis Brown""). ---. @danbills commented on [Mon Sep 18 2017](https://github.com/broadinstitute/wdl4s/issues/156#issuecomment-330304677). I propose we move everything JSON-related into a subproject that depends on the object model. . This would allow rapid development and testing of CWL -> WOM. . Json stuff is pretty small and contained so it wouldn't be too spaghetti-y.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2712:153,extend,extended,153,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2712,1,['extend'],['extended']
Modifiability,"@mcovarr commented on [Thu Sep 07 2017](https://github.com/broadinstitute/wdltool/issues/48). Per the link below, enhance wdltool to be able to detect malformed expressions. Expressions that can't be evaluated are okay and expected due to values not being available, but malformed expressions are not okay. https://gatkforums.broadinstitute.org/wdl/discussion/10311/error-evaluating-output-files-that-serve-as-input-files-for-following-step#latest",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2869:114,enhance,enhance,114,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2869,1,['enhance'],['enhance']
Modifiability,"@mcovarr commented on [Wed Aug 10 2016](https://github.com/broadinstitute/centaur/issues/97). Per broadinstitute/cromwell#1275, we have no real test for the workflow outputs API. Enhance Centaur to be able to call the outputs API.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2890:179,Enhance,Enhance,179,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2890,1,['Enhance'],['Enhance']
Modifiability,"@mwalker174 originally reported:. > Hi all, I’ve got a critical problem where call caching times out on a particular WDL task (`“message”: “Hashing request timed out for gs://...“’). This makes some sense since the task is checking ~200 files on each of ~200 shards. This is on cromwell v36/papiv2. I thinking bundling the files would probably fix this, but is there any way to increase the timeout limit in the server settings? Would upgrading to v38 help? Thanks!. There's currently a non-configurable 5 minute timeout per GCS hash request. Assuming no batching (which I didn't come across) for ~40K individual requests that's about 100 requests/second to GCS. I'm pretty sure w/ GCS request throttling & internal cromwell backoffs at least one of those requests would fail to return in 5 minutes.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4873:491,config,configurable,491,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4873,1,['config'],['configurable']
Modifiability,"@tmdefreitas commented on [Tue Mar 22 2016](https://github.com/broadinstitute/wdltool/issues/7). I came across this while helping a colleague debug her WDL file. When this WDL file is validated, wdltool claims an ""Error: finished parsing without consuming all tokens"", even though the error is commented out:. ```; task comment_bug {; #String an_input. command {; echo ""Alternate command""; # The following line has a WDL syntax error, but in a comment!; #echo {an_input} ; }. output {. }; }. workflow test {; call comment_bug; }; ```. EDIT: error message, for completeness:. ```; $ java -jar wdltool.jar validate comment_bug.wdl; ERROR: Finished parsing without consuming all tokens. output {; ^; ```. I can get rid of the error by changing the comment line to `#echo ${an_input}`. ; I think errors in comment lines should probably be ignored by the validator. As an aside, is there a more helpful error message for this? The message sounds like an unused input variable or something, not that the bracket syntax was off, so it was hard to diagnose (The above is a toy example, the real task had a much more complicated command). ---. @scottfrazer commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200416975). This is happening because the the `command {...}` section is parsed differently than the rest of WDL. The parser thinks that the closing brace in `#echo {an_input}` is actually trying to close the `command` section. If you use the alternative delimiters (`command <<< ... >>>`) this is another way to get around it. We parse the command as ""opaque strings intermixed with `${...}` blocks"". That means that the `#`-style comments inside a command section are not interpreted as WDL comments, but instead as part of the command. More thought would have to go into figuring out what the right thing to do here is. ---. @tmdefreitas commented on [Wed Mar 23 2016](https://github.com/broadinstitute/wdltool/issues/7#issuecomment-200442613). Admittedly",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2870:962,variab,variable,962,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2870,1,['variab'],['variable']
Modifiability,"@vdauwera commented on [Mon Apr 24 2017](https://github.com/broadinstitute/dsde-docs/issues/1996). Need to put in a Cromwell ticket for this. Basic ask: have Cromwell automatically look for (and co-localize) accessory files when given files with a specific extensions. E.g. if I give it foo.bam file it should look for foo.bai. . Note that sometimes it's just a matter of swapping the extension, but sometimes it's adding another extension, and there can be multiple accessory files, e.g. reference.fasta is always accompanied by both reference.fasta.fai and reference.dict. . This would ideally be configurable by the Cromwell admin, who would set up a list of primary file extensions and their accessory file naming patterns. Bonus points if the user can provide their own config on the command line to override the server's config. And also I want a pet unicorn that farts glitter. ----. WDL folks;; This is a followup from a recent discussion about getting compatible bcbio generated WDL (http://gatkforums.broadinstitute.org/wdl/discussion/9257/object-attribute-access-and-secondary-index-files). Thanks to all the great help you've provided we now have compatible WDL output that passes validation:. https://github.com/bcbio/test_bcbio_cwl/blob/master/run_info-cwl-wdl. This is brilliant, and I'd like to move into testing runs with Cromwell. Before starting this, there is one major area I know we're missing in the conversion, handling of secondary files and directories of files. CWL has the notion of secondaryFiles (http://www.commonwl.org/v1.0/Workflow.html#File) which you can use to block these and ensure they get staged/run next to each other. I use this in bcbio and wanted to figure out the best way to map it into WDL. There are two cases we use these for:. - Index files associated with compressed inputs, like BAM bai indices and bgzip VCF tbi indices. These are a single index file attached to the original file that should get staged in the same directory when running.; - Direc",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2269:599,config,configurable,599,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2269,3,['config'],"['config', 'configurable']"
Modifiability,"@vdauwera commented on [Wed Apr 12 2017](https://github.com/broadinstitute/dsde-docs/issues/1963). This needs to be discussed further with both workbench and cromwell peeps/POs. ----. This may have been asked before, but I can't find the relevant thread...; It looks like any change to a method configuration automatically triggers a version increase. It would be very useful to be able to control this. For example, changing a memory parameter should be possible without changing the version. In Firehose this was/is possible with the 'Outdate task' option. This Issue was generated from your [forums] ; [forums]: http://gatkforums.broadinstitute.org/firecloud/discussion/9388/versioning-of-method-configuration/p1. ---. @vdauwera commented on [Tue Apr 18 2017](https://github.com/broadinstitute/dsde-docs/issues/1963#issuecomment-295047979). @knoblett @katevoss This is a total can of worms that should probably be discussed with POs across teams. ---. @knoblett commented on [Wed Apr 19 2017](https://github.com/broadinstitute/dsde-docs/issues/1963#issuecomment-295445174). Is this a Red Team request or a FireCloud request? Seems more like the latter, but just want to clarify. ---. @vdauwera commented on [Wed Apr 19 2017](https://github.com/broadinstitute/dsde-docs/issues/1963#issuecomment-295453435). I think it cuts across both. There are Cromwell-level implications in terms of call caching.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2268:295,config,configuration,295,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2268,2,['config'],['configuration']
Modifiability,"A bash environment variable, HOME, is set unusally in exec.sh",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3421:19,variab,variable,19,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3421,1,['variab'],['variable']
Modifiability,A few more I/O configurable values,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3396:15,config,configurable,15,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3396,1,['config'],['configurable']
Modifiability,"A flexible way of capturing the data involved in a performance run for later analysis:. Capture the following into files and copy them into GCS somewhere, perhaps [perf bucket]/[perf name]/[cromwell version]. where perf name is a small enumerated list of things we want to perf test, e.g. (5_genome, TJeandet_Call_Cache). * reported metrics; * all metadata; * configuration. Once this is done, the user may delete the instance running cromwell, the DB. It may also choose not to report metrics to Perf Grafana",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4106:2,flexible,flexible,2,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4106,2,"['config', 'flexible']","['configuration', 'flexible']"
Modifiability,"A proposed config scheme to support multiple language frontends to Cromwell. Basically a simplified version of the backend scheme, this is just a strawman for discussion.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2379:11,config,config,11,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2379,1,['config'],['config']
Modifiability,"A significant amount of GotC failures are due to out of memory / disk errors.; Design a mechanism that allow to specify custom retry strategies that can modify runtime parameters based on failure modes. For example, “Retry on return code X with double the amount of memory and / or disk”. Thoughts:; - `currentAttempt()` wdl function to be used as a variable in a memory / disk formula; - monitor the job (monitoring script ?) to detect disk / memory overflows.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1847:350,variab,variable,350,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1847,1,['variab'],['variable']
Modifiability,"A simple grep through the source code reveals several hits with Log4j:. ```; CromwellRefdiskManifestCreator/pom.xml: <groupId>org.apache.logging.log4j</groupId>; CromwellRefdiskManifestCreator/pom.xml: <artifactId>log4j-core</artifactId>; CromwellRefdiskManifestCreator/pom.xml: <groupId>org.apache.logging.log4j</groupId>; CromwellRefdiskManifestCreator/pom.xml: <artifactId>log4j-api</artifactId>; CromwellRefdiskManifestCreator/src/main/java/org/broadinstitute/manifestcreator/CromwellRefdiskManifestCreatorApp.java:import org.apache.logging.log4j.Level;; CromwellRefdiskManifestCreator/src/main/java/org/broadinstitute/manifestcreator/CromwellRefdiskManifestCreatorApp.java:import org.apache.logging.log4j.LogManager;; CromwellRefdiskManifestCreator/src/main/java/org/broadinstitute/manifestcreator/CromwellRefdiskManifestCreatorApp.java:import org.apache.logging.log4j.Logger;; CromwellRefdiskManifestCreator/src/main/java/org/broadinstitute/manifestcreator/CromwellRefdiskManifestCreatorApp.java:import org.apache.logging.log4j.core.config.Configurator;; project/Dependencies.scala: // Replace all log4j usage with slf4j; project/Dependencies.scala: // https://www.slf4j.org/legacy.html#log4j-over-slf4j; project/Dependencies.scala: ""org.slf4j"" % ""log4j-over-slf4j"" % slf4jV; ```. I wasn't able to expose a vulnerability by using malicious code but my test is probably not extensive.; It looks like this lib is used in a packaging tool of Cromwell so probably not executed during production.; On the other hand, slj4j seems to be used everywere. Is that abstraction layer vulnerable ?. Could you please let us know if you believe Cromwell is affected by Log4shell ?. Thanks,",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6588:1039,config,config,1039,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6588,2,"['Config', 'config']","['Configurator', 'config']"
Modifiability,"A simple rewrite of a CKTS test in Centaur, I'm curious to hear what the waterfowl think before going too far down this path. Some other CTKS tests I've looked at would require adding a minor feature or two to Centaur (e.g., assertions for exclusivity of outputs) but so far nothing major.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4503:9,rewrite,rewrite,9,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4503,1,['rewrite'],['rewrite']
Modifiability,"A useful refactor of the summarizer FSM, and a log of where the summarizer has reached; - Don't be afraid to vote 👎 on the logging if you think it's going to be too noisy. Sample log message: `2019-02-13 12:52:19,609 cromwell-system-akka.dispatchers.service-dispatcher-97 INFO - Metadata summarizer has now reached: 52837`",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4645:9,refactor,refactor,9,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4645,1,['refactor'],['refactor']
Modifiability,"A user requested this [here](https://gatkforums.broadinstitute.org/firecloud/discussion/10272/workflow-function-sub-is-too-impatient-needs-to-wait-until-inputs-are-ready). They would like Cromwell to wait until after a task has run to try to resolve a workflow-level variable. Their specific use case is calling the `sub()` function inside the workflow, like so:. ```; workflow myWF {; call taskA; String myString = sub(taskA.out, ""_"", """"); }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2738:267,variab,variable,267,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2738,1,['variab'],['variable']
Modifiability,"A user today requested an `else` statement be added, in the conventional sense below:. ```; if (myBool) {; #do something; }; else {; #do something else; }; ```. I agree that adding something like this would enhance the readability we advertise for WDL, though I understand that this isn't completely pressing as there is currently a workaround (`if(!myBool)`). I leave this to your team to prioritize/discuss further as needed. You can find the original user question [here](http://gatkforums.broadinstitute.org/firecloud/discussion/9929/is-there-a-null-value-that-can-be-used-in-wdl-could-else-statements-be-added-to-conditionals).",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2436:207,enhance,enhance,207,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2436,1,['enhance'],['enhance']
Modifiability,A user who copy-pasted from this config inadvertently disabled summarization on his unicromtal instance.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6364:33,config,config,33,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6364,1,['config'],['config']
Modifiability,"AC: We require a unit test that recreates a deadlock occurs when workflow heartbeats are de-serialized (#4239). This is important because this is a problem we've seen before in production (prior to the serialization of heartbeats) and that's the *main* scenario we have to solve for as a requirement to be able to scale Cromwell horizontally. Since we've only really seen deadlock behavior in production, it seems running a unit test at high scale could be one possible way to reproduce the deadlocking error. For example:. Start 10K workflows (that just sleep) and configure the heartbeat-interval rate to be the shortest duration possible (or whatever is reasonable). One would have to check the Cromwell server logs to see if there's a SQL exception",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4414:566,config,configure,566,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4414,1,['config'],['configure']
Modifiability,AN-184 Remove unused Batch restrict-metadata-access config,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7577:52,config,config,52,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7577,1,['config'],['config']
Modifiability,AWS Batch Job Retry configuration with Cromwell,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6114:20,config,configuration,20,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6114,1,['config'],['configuration']
Modifiability,AWS profileName configuration,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5452:16,config,configuration,16,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5452,1,['config'],['configuration']
Modifiability,"Acceptance Criteria:. DevOps has deployed an instance ready to be configured using `summarizer` for `INSTANCE_TYPE` environment variable, [seen in this firecloud-develop PR](https://github.com/broadinstitute/firecloud-develop/pull/1590). In detail this consists of a terraform `instance` stanza with `count=1` or omitted.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4799:66,config,configured,66,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4799,2,"['config', 'variab']","['configured', 'variable']"
Modifiability,Access to optional variables in conditionals broken for WDL 1.0 (works w draft-2),MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4981:19,variab,variables,19,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4981,1,['variab'],['variables']
Modifiability,"Accommodate ""enhanced"" Requester Pays error messages [CROM-6820]",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6556:13,enhance,enhanced,13,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6556,1,['enhance'],['enhanced']
Modifiability,"According to https://cromwell.readthedocs.io/en/stable/backends/Google/; The format for the json file should be; ```; {; ""biocontainers/samtools:1.3.1"": ""projects/broad-dsde-cromwell-dev/global/images/v1-docker-biocontainers-samtools-1-3-1"",; ""gcr.io/gcp-runtimes/ubuntu_16_0_4:latest"": ""projects/broad-dsde-cromwell-dev/global/images/v1-docker-gcr-io-gcp-runtimes-ubuntu-16-0-4-latest"",; ...; }; ```. I followed this format but got this error; ```; [2022-11-20 18:17:16,88] [warn] Failed to build PipelinesApiConfigurationAttributes on attempt 1 of 3, retrying.; cromwell.backend.google.pipelines.common.PipelinesApiConfigurationAttributes$$anon$1: Google Pipelines API configuration is not valid: Errors:; Attempt to decode value on failed cursor: DownField(manifestFormatVersion); at cromwell.backend.google.pipelines.common.PipelinesApiConfigurationAttributes$.apply(PipelinesApiConfigurationAttributes.scala:307); at cromwell.backend.google.pipelines.common.PipelinesApiBackendLifecycleActorFactory.defaultBuildAttributes$1(PipelinesApiBackendLifecycleActorFactory.scala:32); at cromwell.backend.google.pipelines.common.PipelinesApiBackendLifecycleActorFactory.$anonfun$papiAttributes$1(PipelinesApiBackendLifecycleActorFactory.scala:34); at scala.util.Try$.apply(Try.scala:210); at cromwell.backend.google.pipelines.common.PipelinesApiBackendLifecycleActorFactory$.cromwell$backend$google$pipelines$common$PipelinesApiBackendLifecycleActorFactory$$build$1(PipelinesApiBackendLifecycleActorFactory.scala:109); at cromwell.backend.google.pipelines.common.PipelinesApiBackendLifecycleActorFactory$.robustBuildAttributes(PipelinesApiBackendLifecycleActorFactory.scala:120); at cromwell.backend.google.pipelines.common.PipelinesApiBackendLifecycleActorFactory.<init>(PipelinesApiBackendLifecycleActorFactory.scala:34); at cromwell.backend.google.pipelines.v2beta.PipelinesApiLifecycleActorFactory.<init>(PipelinesApiLifecycleActorFactory.scala:10); at java.base/jdk.internal.reflect.NativeConstructor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6953:671,config,configuration,671,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6953,1,['config'],['configuration']
Modifiability,Actor.$anonfun$runtimeEnvironment$1(StandardAsyncExecutionActor.scala:479); 	 at mouse.AnyOps$.$bar$greater$extension(any.scala:8); 	 at cromwell.backend.standard.StandardAsyncExecutionActor.runtimeEnvironment(StandardAsyncExecutionActor.scala:479); 	 at cromwell.backend.standard.StandardAsyncExecutionActor.runtimeEnvironment$(StandardAsyncExecutionActor.scala:479); 	 at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.runtimeEnvironment$lzycompute(ConfigAsyncJobExecutionActor.scala:215); 	 at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.runtimeEnvironment(ConfigAsyncJobExecutionActor.scala:215); 	 at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand(StandardAsyncExecutionActor.scala:637); 	 at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand$(StandardAsyncExecutionActor.scala:607); 	 at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.instantiatedCommand$lzycompute(ConfigAsyncJobExecutionActor.scala:215); 	 at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.instantiatedCommand(ConfigAsyncJobExecutionActor.scala:215); 	 at cromwell.backend.standard.StandardAsyncExecutionActor.commandScriptContents(StandardAsyncExecutionActor.scala:383); 	 at cromwell.backend.standard.StandardAsyncExecutionActor.commandScriptContents$(StandardAsyncExecutionActor.scala:382); 	 at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.commandScriptContents(ConfigAsyncJobExecutionActor.scala:215); 	 at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.writeScriptContents(SharedFileSystemAsyncJobExecutionActor.scala:175); 	 at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.writeScriptContents$(SharedFileSystemAsyncJobExecutionActor.scala:174); 	 at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.writeScriptContents(ConfigAsyncJobExecutionActor.scala:215); 	 at cromwell.backend.sfs.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6757:5667,Config,ConfigAsyncJobExecutionActor,5667,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6757,1,['Config'],['ConfigAsyncJobExecutionActor']
Modifiability,Actor.scala:211); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.processArgs(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.makeProcessRunner(SharedFileSystemAsyncJobExecutionActor.scala:174); at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.makeProcessRunner$(SharedFileSystemAsyncJobExecutionActor.scala:171); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.makeProcessRunner(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.$anonfun$execute$2(SharedFileSystemAsyncJobExecutionActor.scala:145); at scala.util.Either.fold(Either.scala:188); at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.execute(SharedFileSystemAsyncJobExecutionActor.scala:144); at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.execute$(SharedFileSystemAsyncJobExecutionActor.scala:139); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.execute(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$executeAsync$1(StandardAsyncExecutionActor.scala:637); at scala.util.Try$.apply(Try.scala:209); at cromwell.backend.standard.StandardAsyncExecutionActor.executeAsync(StandardAsyncExecutionActor.scala:637); at cromwell.backend.standard.StandardAsyncExecutionActor.executeAsync$(StandardAsyncExecutionActor.scala:637); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.executeAsync(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover(StandardAsyncExecutionActor.scala:952); at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover$(StandardAsyncExecutionActor.scala:944); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.executeOrRecover(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.async.AsyncBack,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4659:3731,config,config,3731,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4659,1,['config'],['config']
Modifiability,Actor.writeScriptContents$(BackgroundAsyncJobExecutionActor.scala:11); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.writeScriptContents(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.execute(SharedFileSystemAsyncJobExecutionActor.scala:158); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.execute$(SharedFileSystemAsyncJobExecutionActor.scala:155); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.execute(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$executeAsync$1(StandardAsyncExecutionActor.scala:639); 	at scala.util.Try$.apply(Try.scala:209); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeAsync(StandardAsyncExecutionActor.scala:639); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeAsync$(StandardAsyncExecutionActor.scala:639); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.executeAsync(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover(StandardAsyncExecutionActor.scala:954); 	at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover$(StandardAsyncExecutionActor.scala:946); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.executeOrRecover(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustExecuteOrRecover$1(AsyncBackendJobExecutionActor.scala:65); 	at cromwell.core.retry.Retry$.withRetry(Retry.scala:38); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.withRetry(AsyncBackendJobExecutionActor.scala:61); 	at cromwell.backend.async.AsyncBackendJobExecutionActor.cromwell$backend$async$AsyncBackendJobExecutionActor$$robustExecuteOrRecover(AsyncBackendJobExecutionActor.scala:65); 	at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5066:12158,config,config,12158,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5066,1,['config'],['config']
Modifiability,Adapt engine upgrade Centaur test for horicromtal,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4786:0,Adapt,Adapt,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4786,1,['Adapt'],['Adapt']
Modifiability,Add ; > all the config options that have been added over time. From [this PR](https://github.com/broadinstitute/cromwell/pull/2950#discussion_r153978653). @mcovarr feel free to add any config options here to start tracking them,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2957:16,config,config,16,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2957,2,['config'],['config']
Modifiability,Add HSQL file persistence to default config to enable call caching on run mode and persistence of server mode,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3786:37,config,config,37,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3786,1,['config'],['config']
Modifiability,"Add `localization` field on the [Configuring#local-filesystem-options](https://cromwell.readthedocs.io/en/stable/Configuring/#local-filesystem-options) documentation page. I got confused about what options were present, and I realise the problems that I'd actually had (https://github.com/broadinstitute/cromwell/issues/5533). I think this little change (backed up by a [HPC#shared-filesystem](https://cromwell.readthedocs.io/en/stable/backends/HPC/#shared-filesystem) makes it clearer about what's expected when configuring localization options for a local filesystem.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5542:33,Config,Configuring,33,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5542,3,"['Config', 'config']","['Configuring', 'configuring']"
Modifiability,"Add a Job Store backed by _filesystem_ stuff, which receives the following commands:. ```; registerJobComplete(jobKey: JobKey, jobResults: JobResults); isJobAlreadyCompleted(jobKey: JobKey): JobCompletedYetStatus; notifyWorkflowComplete(workflowId: WorkflowId); ```. with JobCompletedYetStatus being one of:. ```; case class JobCompletedAlready(jobResults: JobResults) extends JobCompletedYetStatus; case object JobNotCompletedYet extends JobCompletedYetStatus; ```. `registerJobComplete` adds to the database.; `notifyWorkflowComplete` removes all appropriate jobs from the database. (all class names given above are **not** final!)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1115:369,extend,extends,369,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1115,2,['extend'],['extends']
Modifiability,Add a `pull-docker` hook for the config file,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4673:33,config,config,33,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4673,1,['config'],['config']
Modifiability,Add a config option to ignore the noAddress runtime attribute [BA-5739],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5569:6,config,config,6,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5569,1,['config'],['config']
Modifiability,"Add a configuration option to deal with nested scatters in WDL. Currently, the inner scatter is converted into a subworkflow. This behavior is now controlled by the `inner-outer-scatter` option defined in `wom/src/main/resources/reference.conf` configuration file.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5061:6,config,configuration,6,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5061,2,['config'],['configuration']
Modifiability,Add a means to turn off sha256 Docker image name rewrites,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2044:49,rewrite,rewrites,49,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2044,1,['rewrite'],['rewrites']
Modifiability,"Add ability to cripple local via the configuration file, for hot-fix 25.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2073:37,config,configuration,37,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2073,1,['config'],['configuration']
Modifiability,Add akka http request-timeout idle-timeout examples in the config; To allow users to get metadata results from large workflows. Also delete the now duplicated cromwell.examples.conf file; And delete the backends section which has been split into; separate files. https://gatkforums.broadinstitute.org/wdl/discussion/10209/retrieving-metadata-for-large-workflows. https://github.com/broadinstitute/cromwell/issues/2519,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4776:59,config,config,59,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4776,1,['config'],['config']
Modifiability,Add authenticated LDAP to proxy config,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/381:32,config,config,32,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/381,1,['config'],['config']
Modifiability,Add basic backend validation for JES PBE config,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/812:41,config,config,41,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/812,1,['config'],['config']
Modifiability,Add basic backend validation for Local PBE config,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/811:43,config,config,43,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/811,1,['config'],['config']
Modifiability,Add commented out configuration for increasing the number of threads …,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/442:18,config,configuration,18,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/442,1,['config'],['configuration']
Modifiability,"Add common config, including mysql, to aws ci conf.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4201:11,config,config,11,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4201,1,['config'],['config']
Modifiability,Add config for disabling sam submit whitelist.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4580:4,config,config,4,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4580,1,['config'],['config']
Modifiability,Add config option to shutdown cromwell when unable to write heartbeats.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4785:4,config,config,4,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4785,1,['config'],['config']
Modifiability,Add configurable docker command and soft links for dockerized jobs,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1433:4,config,configurable,4,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1433,1,['config'],['configurable']
Modifiability,Add configurable docker command and soft links for dockerized jobs. Closes #1433.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1432:4,config,configurable,4,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1432,1,['config'],['configurable']
Modifiability,"Add configuration for volcano, a batch system on k8s. [BA-6011]",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5184:4,config,configuration,4,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5184,1,['config'],['configuration']
Modifiability,Add example akka config to avoid metadata timeout issue,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4776:17,config,config,17,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4776,1,['config'],['config']
Modifiability,Add localization doc for Configuring#local-filesystem-options,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5542:25,Config,Configuring,25,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5542,1,['Config'],['Configuring']
Modifiability,Add missing config header,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4207:12,config,config,12,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4207,1,['config'],['config']
Modifiability,"Add the `logsGroup` and `resourceTags` config option to the `default-runtime-attributes` section of the AWS Batch configuration. This enables you to send the logs to a custom log group name and tag the jobs that Cromwell submits. Sample usage:; ```; default-runtime-attributes {; queueArn: ""arn:aws:batch:us-east-1:111222333444:job-queue/job-queue""; logsGroup: ""/Cromwell/job/""; resourceTags {; projectid: ""project1""; }; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7219:39,config,config,39,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7219,2,['config'],"['config', 'configuration']"
Modifiability,"Added a new Shared File System (SFS) Backend package as a base for any/most backends wanting to execute cromwell calls on an SFS.; Added SGE and LSF configs (commented out) to the main `application.conf`, plus other small tweaks.; Non-main `application.conf` files only set the keys that they need to add or override from the main.; More of the config is defaulted across the board.; A number of classes moved/refactored from other backends for use by the SFS backend.; New trait `RuntimeAttributesValidation[ValidatedType]` for proccessing runtime attributes.; First pass at a `WorkflowFileSystemProvider` that combines a config and workflow options to create a filesystem. Only implemented for local and GCS files.; Added a Config backend that implements the SFS backend by reading wdl-lite command strings and `job-id-regex`.; Currently extending SFS backend to create the SGE backend until one can specify runtime attributes via the Config backend.; Added a ""shadow"" local backend, extending the SFS backend, that will be evaluated for a while before hopefully usurping the original.; Fixed integration tests that were attempting to mock the gcs file system.; Gave `MetadataDatabaseAccessSpec` a little bit more time the non-split up ""create and query a workflow"".; Fixed the `SprayDockerRegistryApiClientSpec` for v1 registries by switching from the `ubuntu` repo to the `registry` repo (we query the registry for a repo hosting images of the docker registry-- inception).",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1202:149,config,configs,149,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1202,8,"['Config', 'config', 'extend', 'refactor']","['Config', 'config', 'configs', 'extending', 'refactored']"
Modifiability,Added an undocumented config option to tweak this value if we need to adjust it for further testing.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/728:22,config,config,22,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/728,2,['config'],['config']
Modifiability,Added another latch plus patience to EnhancedRhinoSandboxSpec.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4313:37,Enhance,EnhancedRhinoSandboxSpec,37,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4313,1,['Enhance'],['EnhancedRhinoSandboxSpec']
Modifiability,Added config option 'api.routeUnwrapped' to optionally allow still serving '/workflows'.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/250:6,config,config,6,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/250,1,['config'],['config']
Modifiability,Added dispatcher for slow/blocking actors. Refactored JobPreparationA…,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/833:43,Refactor,Refactored,43,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/833,1,['Refactor'],['Refactored']
Modifiability,Added heartbeats to swr and refactor kills BA-5983,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5165:28,refactor,refactor,28,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5165,1,['refactor'],['refactor']
Modifiability,"Adding the following features:; - Optional parameters; - Expressions in output strings (e.g. an output file that's named as some function of the inputs); - Command line variable quantifiers (`*`, `?`, `+`); - Command line variable attributes (e.g. `${sep="", "" String stuff+}`), also default values for parameters.; - Command line variable prefixes (e.g. `${""-maxdepth "" maxdepth?}`); - `tsv()` function; - Declarations at the workflow and task level; - Array and Map data types",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/51:169,variab,variable,169,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/51,3,['variab'],['variable']
Modifiability,"Addresses [WX-1306](https://broadworkbench.atlassian.net/browse/WX-1306). PR adds a Python script that automates the submission of a basic workflow to a CoA instance. PR is an offshoot of [WX-983](https://broadworkbench.atlassian.net/browse/WX-983). As such the PR is carrying the GHA infrastructure as well as commented out code that pertains to the App provisioning steps via Rawls and Leo, both of which are not needed for the script review. In order to test the script locally you'll need to set env variables for the CoA base url and a Bearer Token. Both can be obtained by reviewing the network data when visiting your Workspace on Terra. Once that's done, navigate to `server/src/test/python/cromwell-az-e2e-test`. Run `poetry install` to install dependencies and then run `poetry run start` to run the script. [WX-1306]: https://broadworkbench.atlassian.net/browse/WX-1306?atlOrigin=eyJpIjoiNWRkNTljNzYxNjVmNDY3MDlhMDU5Y2ZhYzA5YTRkZjUiLCJwIjoiZ2l0aHViLWNvbS1KU1cifQ; [WX-983]: https://broadworkbench.atlassian.net/browse/WX-983?atlOrigin=eyJpIjoiNWRkNTljNzYxNjVmNDY3MDlhMDU5Y2ZhYzA5YTRkZjUiLCJwIjoiZ2l0aHViLWNvbS1KU1cifQ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7230:504,variab,variables,504,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7230,1,['variab'],['variables']
Modifiability,Adds an event handler for a backend job that failed with a retry able failure. The engine attempts to restart the failed job again on the same backend for a `max` number of times (where that number is configurable and controlled by the engine),MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/795:201,config,configurable,201,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/795,1,['config'],['configurable']
Modifiability,After careful perusal of the code it appears that this should be in `services.MetadataService.config` but since the code which uses it does an end run around the service config it wound up in `services.MetadataService` proper.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1835:94,config,config,94,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1835,2,['config'],['config']
Modifiability,"After running a job that completed (or so it seems by the files generated ... Cromwell labels it as failed), I tried to retrieve the metadata but I got this error message instead:; ```; {; ""status"": ""error"",; ""message"": ""Metadata for workflow xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx exists in database but cannot be served because row count of 1249471 exceeds configured limit of 1000000.""; }; ```; I have tried to understand what configuration variable holds this 1000000 row limits, but I could not figure it out. :-( I think it would save users valuable time if they were directed to what to do when these type of very specific errors are recognized. I know this is a little bit more work on the developer side but I would certainly be very grateful ... and I would also stop asking questions. :-)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6236:357,config,configured,357,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6236,3,"['config', 'variab']","['configuration', 'configured', 'variable']"
Modifiability,"After running a large workflow on GCS with ~2,500 tasks, rather than the workflow transitioning from running to success, I received the following error:; ```; ""status"": ""Failed"",; ""failures"": [; {; ""message"": ""Workflow is making no progress but has the following unstarted job keys: \nScatterCollectorKey_PortBasedGraphOutputNode_xxx.yyy:-1:1\nConditionalCollectorKey_PortBasedGraphOutputNode_xxx.yyy:-1:1"",; ""causedBy"": []; }; ],; ```. The `xxx.yyy` output variable is from a task being scattered and defined as follows:; ```; task xxx {; ...; output {; ...; File? yyy = if defined(zzz) then ... else None; }; }; ```; With `zzz` not defined. Despite the error, the job seemed to have completed successfully. However the files were not moved into the `final_workflow_outputs_dir` as they were supposed to, causing an unwelcome inconvenience. This [problem](https://support.terra.bio/hc/en-us/community/posts/360073398892-Workflow-failure-Workflow-is-making-no-progress-but-has-the-following-unstarted-job-keys-) has also been reported about six months ago in the Terra forum. The job run with CallCaching activated but no entries in the cache were present before the job started. The only event of notice was that at some point Cromwell crashed due to high memory demand (while trying to retrieve the metadata for the workflow) but, after I restarted it, the workflow proceeded without issues. The workflow is a `version development` WDL, as can be evinced from the use of the `None` keyword.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6238:458,variab,variable,458,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6238,1,['variab'],['variable']
Modifiability,"After updating docker container to the latest cromwell:dev from cromwell:37 I started noticing multiple file not found exception for my https://github.com/antonkulaga/rna-seq/blob/master/pipelines/bs-seq/bs_extract_run.wdl pipeline ( sample input is https://github.com/antonkulaga/rna-seq/blob/master/pipelines/bs-seq/inputs/extract_run/bs_extract_SRR948855.json ).I think it has something to do with the fact that my cromwell configuration in docker-swarm uses /data/cromwell-executions as root instead of default /cromwell-executions (my config is here https://github.com/antonkulaga/cromwell-client/blob/master/services/cromwell/app-config/application.conf ), however, there may be other reasons.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4698:427,config,configuration,427,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4698,3,['config'],"['config', 'configuration']"
Modifiability,"Akka HTTP is effectively the next version of Spray. Spray is for all intents and purposes a dead technology. Considering that's been the case for over a year now, we should update at some point just because eventually we'll run into a problem that won't be resolved by developers. Also, Akka HTTP is now hitting a point in its development cycle where not only is it deemed ""Better"" :tm: but they've switched to ease of use and performance and it's eclipsing Spray in those categories now as well. I've labeled this as developers choice as it certainly doesn't _need_ to happen any time soon, although if a someone wearing a PO hat thought it was otherwise important it could certainly be pushed in elsewhere (since it likely _would_ include performance enhancements and such)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1243:753,enhance,enhancements,753,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1243,1,['enhance'],['enhancements']
Modifiability,"All the tests that pass on the Local backend currently pass on PAPI with the hackery documented below. This does not attempt to run tests that fail on Local because there's no realistic reason to believe a conformance test that fails Local would succeed on PAPI and the PAPI conformance test run would take hours. On the topic of slowness, the PAPI conformance run will probably have to be converted to a cron job once more conformance tests start passing. The hacks:; - Cromwell now allows for a default Docker image to be specified in config. This is required for those conformance tests that don't specify a `DockerRequirement`.; - Cromwell allows for a ""GCS default input prefix"" of any input files when using the JES backend. This allows for the conformance input JSONs to be used as-is. It also works to hack the input JSONs to specify the GCS paths where input files are staged and not bother with the ""GCS default input prefix"".; - I had to turn off call caching since the hashing actor was looking at the non-GCS paths of files. It's possible this could be worked around if anyone felt it was worth the effort, but I didn't.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3086:537,config,config,537,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3086,1,['config'],['config']
Modifiability,"All$1(ActorCell.scala:523) ; at akka.actor.ActorCell.systemInvoke(ActorCell.scala:545) ; at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:283) ; at akka.dispatch.Mailbox.run(Mailbox.scala:224) ; at akka.dispatch.Mailbox.exec(Mailbox.scala:235) ; at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) ; at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) ; at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) ; at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) ; Caused by: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'services' ; at com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:156) ; at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:174) ; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:188) ; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:193) ; at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:268) ; at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:41) ; at cromwell.services.ServiceRegistryActor$.serviceNameToPropsMap(ServiceRegistryActor.scala:35) ; at cromwell.services.ServiceRegistryActor.serviceProps(ServiceRegistryActor.scala:63) ; at cromwell.services.ServiceRegistryActor.<init>(ServiceRegistryActor.scala:65) ; at cromwell.services.ServiceRegistryActor$.$anonfun$props$1(ServiceRegistryActor.scala:25) ; at akka.actor.TypedCreatorFunctionConsumer.produce(IndirectActorProducer.scala:87) ; at akka.actor.Props.newActor(Props.scala:212) ; at akka.actor.ActorCell.newActor(ActorCell.scala:624) ; at akka.actor.ActorCell.create(ActorCell.scala:650) ; ... 9 more ; ```. If I add in a `services` stanza, though, it asks me to define the class of each service, even though they should probably have default values:; ```; [ERROR] [01/24/2019 11:09:59.741] [cromwell-system-akka.dispatchers.service-dispatcher-10] [akka:/",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4577:1790,config,config,1790,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4577,1,['config'],['config']
Modifiability,Allow 'version' as a variable name,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3954:21,variab,variable,21,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3954,1,['variab'],['variable']
Modifiability,"Allow Cromwell system administrators to restrict WDL HTTP imports to specific, trusted hosts/domains. This prevents the import mechanism from being used to inappropriately access resources that the Cromwell instance has access to on its internal LAN, but which are not exposed to the end users. Terra configuration here: https://github.com/broadinstitute/firecloud-develop/pull/3138",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6938:301,config,configuration,301,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6938,1,['config'],['configuration']
Modifiability,Allow GCP global pipeline timeout to be configurable,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5273:40,config,configurable,40,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5273,1,['config'],['configurable']
Modifiability,Allow GCP global pipeline timeout to be configurable [CI clone],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5315:40,config,configurable,40,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5315,1,['config'],['configurable']
Modifiability,Allow default zones to be set in the config. Closes #1795,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1797:37,config,config,37,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1797,1,['config'],['config']
Modifiability,Allow overriding system-level `hog-factor` setting in individual backend configurations [BA-6584],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5911:73,config,configurations,73,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5911,1,['config'],['configurations']
Modifiability,Also a few variable renames. Sorry!. Fixes the first half of #2901,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2931:11,variab,variable,11,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2931,1,['variab'],['variable']
Modifiability,Also adds an env variable to filter by tag in Jenkins which makes it easier to only run a test or set of tests.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4492:17,variab,variable,17,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4492,1,['variab'],['variable']
Modifiability,Also updated the sbt assembly plugin.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7123:30,plugin,plugin,30,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7123,1,['plugin'],['plugin']
Modifiability,"Also:; Splitting the database sql and migration, plus other cleanup.; Bits of call caching business logic refactored out of `database`.; Moved all simpleton conversion out of the `database`.; PK columns that cannot be filled in by business logic are defaulted to `None`.; Renamed `Database` to `ServicesStore`.; Renamed `CromwellDatabase` to `SingletonServicesStore`.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1366:106,refactor,refactored,106,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1366,1,['refactor'],['refactored']
Modifiability,"An early look at the hog factor:. Adds:; - A hog factor in the configuration file representing ""how many greedy users would it take to use up all our resources""; - Higher values protect Cromwell's resources to keep them available for small-scale users; - Lower values let power users get their stuff done as fast as possible; - 1 is equivalent to ""no hog factor"" (and is the default); - Idea: it would be awesome to be able to dynamically scale this up and down based on ""we need to run a workflow"" or ""person X really needs to run their stuff at *full* speed for the next 4 hours""; - The ability to identify a workflow option as indicating hog group ; - A hog group is assigned to every `BackendWorkflowDescriptor` (using the specified workflow option if possible, or 'root workflow ID' if the specified option is not provided); - An update to the `TokenPool` to make it hog-group aware. TODOs:; - [x] Enhance `RoundRobinQueueIteratorSpec` with hog-limit tests; - [x] Enhance `TokenQueueSpec` with hog-limit tests; - [ ] Add full-system tests demonstrating the hog limit in action",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4013:63,config,configuration,63,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4013,3,"['Enhance', 'config']","['Enhance', 'configuration']"
Modifiability,Anyone trying to set up cromwell in a non-default configuration (i.e. one that requires a custom `application.conf`) has to find all relevant stanzas within the documentation (and these are not all together). We should provide a default template that works with the latest release. Then a user can simply modify that default template and get up-and-running.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1590:50,config,configuration,50,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1590,1,['config'],['configuration']
Modifiability,Apparantly mkdocs does not like the `+` sign for list items. https://cromwell.readthedocs.io/en/develop/Configuring/#database. So this fixes that.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5323:104,Config,Configuring,104,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5323,1,['Config'],['Configuring']
Modifiability,Aribtrary WDL in runtime attributes of provider configuration,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4700:48,config,configuration,48,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4700,1,['config'],['configuration']
Modifiability,"As a Site Reliability Engineer (SRE) , I would like to have Cromwell support Sentry (https://sentry.io) to capture and report exceptions. This will allow me to better support our runtime operations and know when the system is functioning properly. This could be as simple as a document detailing how to deploy cromwell with the appropriate configuration, or it may involve code changes. @ansingh7115 is working on this in workbench at the moment and should be able to provide more information. @davidbernick can also provide configuration details.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2120:340,config,configuration,340,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2120,2,['config'],['configuration']
Modifiability,"As a part of supporting sub-workflows, workflow outputs need to behave similarly to task outputs. Task outputs are defined as typed variable declarations (e.g. File myout = ""${foo}.bam""). Currently workflow outputs just ""expose"" the outputs of tasks, and operate more like a whitelist or filter. You can not fabricate a workflow output based on a task output (like the about myout example). However, this should still be backwards compatible with the current definitions. For example you can write:. `output {; task.value; }`. However, we should be able to allow this as syntactic sugar by inferring the type of this from the task definition. For example if this was a File, the above would be the same as `File task.value = task.value`. `output {; File task.value = task.value; }`",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1473:132,variab,variable,132,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1473,1,['variab'],['variable']
Modifiability,"As a side effect to enable abort support in HtCondor, this PR makes the polling (for checking job status) asynchronous, and the polling interval to be configurable.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1403:151,config,configurable,151,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1403,1,['config'],['configurable']
Modifiability,"As an outside developer who would like to develop new functionality for Cromwell, I would like to have a developers guide that can get me going. The developer's guide can assume a high level of technical proficiency, but I need help in understand the architecture and concepts that are relevant. The areas that are important to me (in rough order) are:; - creating a new backend; - extending an existing backend; - replacing ""pluggable"" components with new implementations (e.g. the Metadata Store)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2327:382,extend,extending,382,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2327,1,['extend'],['extending']
Modifiability,"As discussed in #4759, including migration changes and workarounds for auto-incremented columns and large objects. I started modifying the travis-ci config but I'm probably going to need an assist there. Note: I have been testing this with Postgresql 9.6.1, because that's what we're using here. Other versions are TODO, it's looking like I'll have time to check v10 at least this week.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4919:149,config,config,149,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4919,1,['config'],['config']
Modifiability,"As discussed in https://github.com/broadinstitute/cromwell/issues/6235, developers of workflows for GCP who store their images in Google Container Repositories can be exposed to large Google GCS egress charges when users attempt to run workflows in different continental regions, resulting in many trans-continental container pulls. There currently does not seem to be a satisfactory way to guard against this:. - We can't make our image repositories private because we want to make the workflows available to the public via Terra.; - We can't make the repositories requester-pays because the pipelines API does not support pulling images from requester-pays repositories.; - We can mirror our repositories to different regions, but we are still dependent on our users to configure their workflows to point to the right region and take good-faith extra steps to help us avoid these charges. Some possible ideas were suggested by @freeseek in https://github.com/broadinstitute/cromwell/issues/6235:. - Convince Google to support requester-pays buckets for container pulls in PAPI.; - Modify some combination of Cromwell/PAPI to cache images rather than pulling them for each task that is run.; - Develop infrastructure within Cromwell to know what region the workflow is running in and automatically select the right GCR mirror to pull from.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6442:772,config,configure,772,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6442,1,['config'],['configure']
Modifiability,"As far as I remember, in the Past it was possible to reference global workflow variables inside a task. But now I get wdl validation errors like this:; ```; ERROR: Variable genome does not reference any declaration in the task (line 36, col 27):. curl -z ${folder}""/""${genome} --max-time 10 --retry 3 --retry-delay 1 ${genomeURL}; ^. Task defined here (line 26, col 6):. task download_genome {; ```; Here is the wdl; ```wdl; workflow indexes {. File genomesFolder; String version #release version; String species #species and also name of the index/. String releaseURL #path to releseas. String transcriptome #relative file name (.fa.gz); String genome #relative file name (.fa.gz); String annotation #relative annotation file name (.gtf). call download_genome {; input:; genomeURL = releaseURL + ""/"" + genome,; transcriptomeURL = releaseURL + ""/"" + transcriptome,; annotationURL = releaseURL + ""/"" + annotation,; folder = genomesFolder + ""/"" + species + ""/"" + version; }. }. task download_genome {. String genomeURL; String transcriptomeURL; String annotationURL; String folder. command {; mkdir -p ${folder}; curl -z ${folder}""/""${genome} --max-time 10 --retry 3 --retry-delay 1 ${genomeURL}; curl -z ${folder}""/""${transcriptome} --max-time 10 --retry 3 --retry-delay 1 ${transcriptomeURL}; curl -z ${folder}""/""${annotation} --max-time 10 --retry 3 --retry-delay 1 ${annotationURL}; }. }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2504:79,variab,variables,79,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2504,2,"['Variab', 'variab']","['Variable', 'variables']"
Modifiability,As of recently-- some of the nightly integration tests have been failing with issues evaluating the contents of the RC file. . This is a transient failure that should already be retried -- and a part of the problem here is the inability to confirm if the operation was retried as expected. So there were two discussed solutions:; 1. Log the number of attempts to read a file as a part of the failure message for a job.; 2. There is a Cromwell configuration for the number of times an IO operation should be retried -- raise that number as a way to retry cloud hiccups.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4069:443,config,configuration,443,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4069,1,['config'],['configuration']
Modifiability,"As per @geoffjentry in a side conversation, I'm taking out this ticket. There's a service account in Cromwell FC (mounted in /etc/cromwell-account.json - https://github.com/broadinstitute/firecloud-develop/blob/dev/base-configs/cromwell/cromwell.conf.ctmpl#L134). This account has permissions it probably doesn't need (project editor). Can we be sure to find out EXACTLY what Google permissions it'll need?. I'd say I'd like to see this list before EoY.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4428:220,config,configs,220,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4428,1,['config'],['configs']
Modifiability,As per the test case in https://github.com/broadinstitute/centaur/pull/123. If you assign an alias to a subworkflow call (e.g. `call subwf as subwfA`) variable resolution is not working for providing the inputs.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1785:151,variab,variable,151,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1785,1,['variab'],['variable']
Modifiability,"As pointed out by @davidbernick, there are some vulnerabilities in Cromwell's docker image. Beyond that, it's a good idea to periodically update the underlying image. This is not deemed to be a critical issue (yet) from a security perspective, but we should make sure to clear this up when we get a chance. $ docker run -it --rm -e CLAIR_ADDR=http://clair.bits-infosec.broadinstitute.org:6060 -e CLAIR_OUTPUT=High -e CLAIR_THRESHOLD=10 -e DOCKER_USER=davidbernick -e DOCKER_PASSWORD='xxxxx' broadinstitute/klar broadinstitute/cromwell:dev; clair timeout 1m0s; docker timeout: 1m0s; no whitelist file; Analysing 10 layers; Got results from Clair API v1; Found 139 vulnerabilities; Unknown: 3; Negligible: 47; Low: 38; Medium: 44; High: 7. CVE-2017-12424: [High] ; Found in: shadow [1:4.4-4.1]; Fixed By: ; In shadow before 4.5, the newusers tool could be made to manipulate internal data structures in ways unintended by the authors. Malformed input may lead to crashes (with a buffer overflow or other memory corruption) or other unspecified behaviors. This crosses a privilege boundary in, for example, certain web-hosting environments in which a Control Panel allows an unprivileged user account to create subaccounts.; https://security-tracker.debian.org/tracker/CVE-2017-12424; -----------------------------------------; CVE-2018-13347: [High] ; Found in: mercurial [4.0-1+deb9u1]; Fixed By: ; mpatch.c in Mercurial before 4.6.1 mishandles integer addition and subtraction, aka OVE-20180430-0002.; https://security-tracker.debian.org/tracker/CVE-2018-13347; -----------------------------------------; CVE-2017-17458: [High] ; Found in: mercurial [4.0-1+deb9u1]; Fixed By: ; In Mercurial before 4.4.1, it is possible that a specially malformed repository can cause Git subrepositories to run arbitrary code in the form of a .git/hooks/post-update script checked into the repository. Typical use of Mercurial prevents construction of such repositories, but they can be created programmatically.; htt",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4979:614,layers,layers,614,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4979,1,['layers'],['layers']
Modifiability,AsyncJobExecutionActor.execute$(SharedFileSystemAsyncJobExecutionActor.scala:155); 	 at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.execute(ConfigAsyncJobExecutionActor.scala:215); 	 at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$executeAsync$1(StandardAsyncExecutionActor.scala:749); 	 at scala.util.Try$.apply(Try.scala:213); 	 at cromwell.backend.standard.StandardAsyncExecutionActor.executeAsync(StandardAsyncExecutionActor.scala:749); 	 at cromwell.backend.standard.StandardAsyncExecutionActor.executeAsync$(StandardAsyncExecutionActor.scala:749); 	 at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.executeAsync(ConfigAsyncJobExecutionActor.scala:215); 	 at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover(StandardAsyncExecutionActor.scala:1139); 	 at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover$(StandardAsyncExecutionActor.scala:1131); 	 at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.executeOrRecover(ConfigAsyncJobExecutionActor.scala:215); 	 at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustExecuteOrRecover$1(AsyncBackendJobExecutionActor.scala:65); 	 at cromwell.core.retry.Retry$.withRetry(Retry.scala:46); 	 at cromwell.backend.async.AsyncBackendJobExecutionActor.withRetry(AsyncBackendJobExecutionActor.scala:61); 	 at cromwell.backend.async.AsyncBackendJobExecutionActor.cromwell$backend$async$AsyncBackendJobExecutionActor$$robustExecuteOrRecover(AsyncBackendJobExecutionActor.scala:65); 	 at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$receive$1.applyOrElse(AsyncBackendJobExecutionActor.scala:88); 	 at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176); 	 at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176); 	 at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176); 	 at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6757:7803,config,config,7803,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6757,1,['config'],['config']
Modifiability,At least a dozen Cromwell configuration links broken (not a copy of #6329),MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6797:26,config,configuration,26,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6797,1,['config'],['configuration']
Modifiability,At the moment the HTTP File input support isn't particularly useful as many real world workflows will use workflow level engine functions (e.g. `size`) on these inputs. Enhance the support for HTTP(s) inputs to allow for these,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4200:169,Enhance,Enhance,169,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4200,1,['Enhance'],['Enhance']
Modifiability,At the moment the PAPI v2 backend uses hardcoded public docker images to localize and delocalize files / directories.; This is not desirable for several reasons:. 1) Dependency on external images; 2) Lack of flexibility; 3) Potentially unoptimized or oversized images. Infrastructure should be put in place so that we can have control over those images while ensuring they can be accessed by all Cromwell users.; Those images (along with the command they run maybe ?) should be configurable.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3680:478,config,configurable,478,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3680,1,['config'],['configurable']
Modifiability,"Authentication configuration has been coded but not properly tested for the ability to assume roles, etc. Integration tests should exist for this.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3747:15,config,configuration,15,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3747,1,['config'],['configuration']
Modifiability,Available system variables accessible from Cromwell configuration,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6005:17,variab,variables,17,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6005,2,"['config', 'variab']","['configuration', 'variables']"
Modifiability,Avoid ConfigFactory.load all over the place,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/796:6,Config,ConfigFactory,6,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/796,1,['Config'],['ConfigFactory']
Modifiability,BT-710 Add configs for BlobPathBuilderFactory,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6817:11,config,configs,11,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6817,1,['config'],['configs']
Modifiability,Backend configuration for SLURM added in beta state. #1750,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2158:8,config,configuration,8,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2158,1,['config'],['configuration']
Modifiability,"Backend: AWS Batch; Cromwell version: 45.1; ----; I am building a WDL pipeline using the CloudFormation set up provided in https://github.com/aws-samples/aws-genomics-workflows/blob/master/src/templates/cromwell/cromwell-aio.template.yaml. ; In summary, the set up is a EC2 instance running `java -jar cromwell.jar server` and calling AWS Batch to run WDL workflow using an attached EC2 instance profile. . I have no issue posting workflows and getting results. However, after a certain period of time, I will get `The security token included in the request is expired` error message logged by the cromwell server when I try to post a job. ; - I have checked that `~/.aws` and the AWS_ACCESS_KEY_ID and AWS_SECRET_ACCESS_KEY environment variable don't exist. ; - If I kill the server and restart it again, the server seem to pick up the new security token and I can post workflow again. ; - Checking `cromwell.config` (pasted below), all authentication methods are set to `default` which is documented to mean it is using `DefaultCredentialProvider` in the AWS Java SDK. That should be refreshing the security token? . Is this unexpected behaviour or did I configure something wrongly? . Thanks for your help!. ----. Config file for the cromwell serve:; ```; include required(classpath(""application"")). webservice {; interface = localhost; port = 8000; }. system {; job-rate-control {; jobs = 1; per = 2 second; }; }. aws {; application-name = ""cromwell""; auths = [{; name = ""default""; scheme = ""default""; }]; region = ""ap-southeast-2""; }. engine { filesystems { s3 { auth = ""default"" } } }. backend {; default = ""AWSBATCH""; providers {; AWSBATCH {; actor-factory = ""cromwell.backend.impl.aws.AwsBatchBackendLifecycleActorFactory""; config {; numSubmitAttempts = 10; numCreateDefinitionAttempts = 10; root = ""XXXX""; auth = ""default""; default-runtime-attributes { queueArn = ""XXXXX"" }; filesystems { s3 { auth = ""default"" } }; }; }; }; }; workflow-options {; workflow-log-dir = ""cromwell-workflow-logs"";",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5162:737,variab,variable,737,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5162,2,"['config', 'variab']","['config', 'variable']"
Modifiability,"Based on configuration (`shadowExecutionEnabled`), initialize the appropriate WorkflowManagerActor for both the CromwellServer mode and for command line execution.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/730:9,config,configuration,9,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/730,1,['config'],['configuration']
Modifiability,Bash and WDL have overlapping syntax for variable definitions: `${VARNAME}` is valid in both. This is a problem if you need to do variable manipulation in bash (e.g. get the length of a variable via `${#VARNAME}`). Cromwell should support escaping this statement so that it can be passed through and interpreted in bash.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3111:41,variab,variable,41,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3111,3,['variab'],['variable']
Modifiability,"Basic Expectations: ; Run a bunch of workflows (call caching turned off) → mid-way to completion, Upgrade → ; a) All running workflows succeed; b) Cromwell can connect to pre-existing operation ids (aka it completed within attempt 1). Run a bunch of workflows → Run them again to see they successfully cached once → upgrade → run them again to ensure they’re still caching. “Upgrade” consists of a new Cromwell Jar, and also a new Cromwell config (with the latest additions being used). Key features that shouldn’t break:; Log names (detritus files) don’t change (before and after), and if yes, then print a warning; Streaming logs (before and after), else error; Caching (before and after), else error; Job success (before and after), else error",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4101:440,config,config,440,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4101,1,['config'],['config']
Modifiability,"Basic Expectations:; Run a bunch of workflows (call caching turned off) → mid-way to completion, Upgrade →; a) All running workflows succeed; b) Cromwell can connect to pre-existing operation ids (aka it completed within attempt 1). Run a bunch of workflows → Run them again to see they successfully cached once → upgrade → run them again to ensure they’re still caching. “Upgrade” consists of a new Cromwell Jar, and also a new Cromwell config (with the latest additions being used). Key features that shouldn’t break:; - ~Log names (detritus files) don’t change (before and after), and if yes, then print a warning~ Split into Issue: #4188; - ~Streaming logs (before and after), else error~ Split into Issue: #4187; - ~Caching (before and after), else error~ PR merged: #4178; - ~Job success (before and after), else error~ PR merged: #4132",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4099:438,config,config,438,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4099,1,['config'],['config']
Modifiability,"Better error message for ""Upgrade Config from C26""",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2186:34,Config,Config,34,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2186,1,['Config'],['Config']
Modifiability,"Briefest of discussions with Jose. NOTE: All naming up in the air. Enable a runtime attribute such as `retryOnStderrPattern` that populates a value `retryAttempt`/`retry`/`retryCount`/`retry_count`/etc. This will enable tasks such as:. ```; task mytask {; command {; mycommand.sh; }; runtime {; retryOnStderrPattern = ""(OutOfMemoryError|disk quota exceeded)""; memory = (6 * retryAttempt) + ""GB""; disk = ""local-disk "" + (100 * retryAttempt) + "" SSD""; docker = ""myrepo/myimage""; }; }; ```. When the stderr contains the specified regular expression pattern, the job should be retried with the counter incremented. Not discussed afaik, how to limit the number of attempts: another runtime attribute, a backend config value, both, other?",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1991:706,config,config,706,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1991,1,['config'],['config']
Modifiability,Bring sanity to Config backend docs,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2166:16,Config,Config,16,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2166,1,['Config'],['Config']
Modifiability,"Bringing in BackendConfiguration, beginning changes to config file. Closes #580",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/627:55,config,config,55,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/627,1,['config'],['config']
Modifiability,By default all cromwell task containers submitted by Google Cloud backend doesn't allow user to mount any filesystems within a container. It happens because containers are launched without specific linux capabilities being enabled. . Nevertheless filesystem mounts can be of help in some workflows because it doesn't require all the task resources to be localized or to be embedded in docker images. Google pipelines api allows to set `ENABLE_FUSE` flag for all submitted action. Once specified it forces Google pipelines engine to launch action containers with additional linux capabilities such as `CAP_SYS_ADMIN` being enabled. The pull request adds support for launching cromwell task containers with an enabled support for fuses in Google Cloud. Fuses support can be enabled via a workflow option `enable_fuse` or via a Google Cloud backend configuration attribute `backend.providers.Papiv2.config.genomics.enable-fuse`.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5343:846,config,configuration,846,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5343,2,['config'],"['config', 'configuration']"
Modifiability,CRON Job: https://travis-ci.org/broadinstitute/cromwell/jobs/344821732. TIL: The Mutect2 workflow contains a task where the WDL author had defined the `HOME` variable upon Docker image creation and used it inside the command block. Cromwell seems to be setting its own `HOME` variable in the exec.sh and thus caused the task to fail.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3313:158,variab,variable,158,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3313,2,['variab'],['variable']
Modifiability,CWL: Workflow requirements not inheriting to as required by specification,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4544:31,inherit,inheriting,31,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4544,1,['inherit'],['inheriting']
Modifiability,"Cache commit end; [2022-12-15 21:14:52,49] [info] checkpointClose end; [2022-12-15 21:14:52,50] [info] Checkpoint end - txts: 102090; [2022-12-15 21:14:52,81] [info] Slf4jLogger started; [2022-12-15 21:14:53,15] [info] Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-b254006"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""failureShutdownDuration"" : ""5 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; [2022-12-15 21:14:53,38] [info] KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; [2022-12-15 21:14:53,44] [info] WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; [2022-12-15 21:14:53,44] [info] CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; [2022-12-15 21:14:53,44] [info] Metadata summary refreshing every 1 second.; [2022-12-15 21:14:53,44] [info] No metadata archiver defined in config; [2022-12-15 21:14:53,44] [info] No metadata deleter defined in config; [2022-12-15 21:14:53,55] [info] JobRestartCheckTokenDispenser - Distribution rate: 50 per 1 seconds.; [2022-12-15 21:14:53,66] [info] JobExecutionTokenDispenser - Distribution rate: 20 per 10 seconds.; [2022-12-15 21:14:53,78] [info] SingleWorkflowRunnerActor: Version 84; [2022-12-15 21:14:53,82] [info] SingleWorkflowRunnerActor: Submitting workflow; [2022-12-15 21:14:53,93] [info] Unspecified type (Unspecified version) workflow 9e4f5894-f7e6-4e2f-be4b-f547d6de7fff submitted; [2022-12-15 21:14:53,94] [info] SingleWorkflowRunnerActor: Workflow submitted 9e4f5894-f7e6-4e2f-be4b-f547d6de7fff; [2022-12-15 21:14:53,96] [info] 1 new workflows fetched by cromid-b254006: 9e4f5894-f7e6-4e2f-be4b-f547d6de7fff; [2022-12-15 21:14:53,96] [info] WorkflowManagerActor: Starting workflow 9e4f5894-f7e6-4e2f-be4b-f547d6de7fff; [2022-12-15 21:14:53,98] [info] WorkflowManagerActor: Successfully started WorkflowActor-9e4f5894-f7e6-4e2f-be4b-f547d6de7fff; [2022-12-15 21:14:53,98] [info]",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6971:13241,config,config,13241,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6971,2,['config'],['config']
Modifiability,Call Caching Configuration (Cromwell + Workflow),MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/292:13,Config,Configuration,13,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/292,1,['Config'],['Configuration']
Modifiability,"Can be reproduced using the following workflow. ```wdl; version 1.0. task crash {; command <<<; kill -9 $$; >>>; }. workflow crash {; call crash ; }. ```; We use a configuration with the following values:; ```HOCON; backend {; default=""SGE""; providers {; SGE {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; exit-code-timeout-seconds = 120; default-runtime-attributes {; maxRetries: 2; }; }; }; }; }; workflow-options {; workflow-failure-mode = ""ContinueWhilePossible""; }; ```; On Cromwell 37 the workflow will be run. Jobs will be killed and retried.; On Cromwell 39, the retries will not happen any more.; This is very annoying, as our cluster kills jobs that exceed the memory limit, and some java based jobs seem to have random memory spikes. Having only 1 try means basically that a workflow with 50-100 jobs will usually fail, unless we give some jobs an insane memory parameter. This is probably caused by the refactoring in:; https://github.com/broadinstitute/cromwell/pull/4654/files; EDIT: This statement was not meant to put a blame on someone. I understand that code needs to be refactored at times and that bugs can creep in. I will look if I can fix the issue myself but maybe @cjllanwarne can also have a quick look? That would be much appreciated!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4998:164,config,configuration,164,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4998,6,"['Config', 'config', 'refactor']","['ConfigBackendLifecycleActorFactory', 'config', 'configuration', 'refactored', 'refactoring']"
Modifiability,Can time zone be configurable?,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/771:17,config,configurable,17,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/771,1,['config'],['configurable']
Modifiability,"Can you add a REST API endpoint to return the value of a given configuration key, from the configuration of this Cromwell server?; I'm writing a script to run a workflow on a specified backend, automatically putting the inputs into the right filesystem; but there is no way to get the filesystem configured for given backend.; Thanks!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4317:63,config,configuration,63,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4317,3,['config'],"['configuration', 'configured']"
Modifiability,Cannot configure optional runtime-attributes for SFS backend on SLURM,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7455:7,config,configure,7,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7455,1,['config'],['configure']
Modifiability,Cannot perform operation: String + womLong(x) in config,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4659:49,config,config,49,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4659,1,['config'],['config']
Modifiability,Cannot provide task variables when part of subworkflow through json,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6841:20,variab,variables,20,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6841,1,['variab'],['variables']
Modifiability,Carbonite reading: configurable bucket read limit [BA-6489],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5555:19,config,configurable,19,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5555,1,['config'],['configurable']
Modifiability,Carbonite reading: configurable bucket read limit [BA-6489][51 hotfix],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5557:19,config,configurable,19,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5557,1,['config'],['configurable']
Modifiability,"Centaur has its own timeouts before it gives up. So does `test.inc.sh`. Setting the value in `test.inc.sh` should also set the value for centaur. https://github.com/broadinstitute/cromwell/blob/5156b786ac5fcf9db3c6c146ab9f78658a29274a/centaur/src/main/resources/reference.conf#L37-L38. https://github.com/broadinstitute/cromwell/blob/5156b786ac5fcf9db3c6c146ab9f78658a29274a/src/ci/bin/test.inc.sh#L130-L136. Currently values for centaur are set through multiple `-Dkey=value` settings inside `test_cromwel.sh`. https://github.com/broadinstitute/cromwell/blob/5156b786ac5fcf9db3c6c146ab9f78658a29274a/centaur/test_cromwell.sh#L127-L134. A couple options among others:; - This can be another `getopts` argument wired into `test_cromwell.sh`; - This could be an environment variable that overrides a default, as is currently used for setting database connection info; https://github.com/broadinstitute/cromwell/blob/5156b786ac5fcf9db3c6c146ab9f78658a29274a/src/ci/resources/build_application.inc.conf#L15-L28. A/C:; - Tests timeout at approximately the same duration in the centaur executable and the heartbeat generated by `test.inc.sh`.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3874:772,variab,variable,772,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3874,1,['variab'],['variable']
Modifiability,"Certain error messages that Cromwell receives are longer than the default limit, which is a big pain when debugging. Going from 64 to 1024 characters (1kb) doesn't seem unreasonable and solves this issue. For context, the error message below is 364 characters. . [Relevant Akka Doc](https://doc.akka.io/docs/akka-http/10.0/configuration.html). . Before:; ```; 2024-04-12 14:58:18 cromwell-system-akka.actor.default-dispatcher-26 ERROR - Error in stage [akka.http.impl.engine.client.OutgoingConnectionBlueprint$PrepareResponse@71a2a20e]: Response reason phrase exceeds the configured limit of 64 characters; akka.http.scaladsl.model.IllegalResponseException: Response reason phrase exceeds the configured limit of 64 characters; 	at akka.http.impl.engine.client.OutgoingConnectionBlueprint$PrepareResponse$$anon$3.onPush(OutgoingConnectionBlueprint.scala:191); 	at akka.stream.impl.fusing.GraphInterpreter.processPush(GraphInterpreter.scala:523); 	at akka.stream.impl.fusing.GraphInterpreter.execute(GraphInterpreter.scala:409); 	at akka.stream.impl.fusing.GraphInterpreterShell.runBatch(ActorGraphInterpreter.scala:606); 	at akka.stream.impl.fusing.ActorGraphInterpreter$SimpleBoundaryEvent.execute(ActorGraphInterpreter.scala:47); 	at akka.stream.impl.fusing.ActorGraphInterpreter$SimpleBoundaryEvent.execute$(ActorGraphInterpreter.scala:43); 	at akka.stream.impl.fusing.ActorGraphInterpreter$BatchingActorInputBoundary$OnNext.execute(ActorGraphInterpreter.scala:85); 	at akka.stream.impl.fusing.GraphInterpreterShell.processEvent(ActorGraphInterpreter.scala:581); 	at ; ...; ```. After: ; ```; <!DOCTYPE HTML PUBLIC ""-//IETF//DTD HTML 2.0//EN"">; <html><head>; <title>401 Unauthorized</title>; </head><body>; <h1>Unauthorized</h1>; <p>This server could not verify that you; are authorized to access the document; requested. Either you supplied the wrong; credentials (e.g., bad password), or your; browser doesn't understand how to supply; the credentials required.</p>; </body></html>; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7406:323,config,configuration,323,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7406,3,['config'],"['configuration', 'configured']"
Modifiability,"Changes are related only to the Shadow world. The expectations of this PR is to extend the current state of things in Workflow Execution (i.e currently we only run a single call workflow) to allow arbitrarily sized workflows (i.e. an N-call workflow). The intention is _not_ to support scatters in this PR, but allow it to be extensible for scatters (or Inception-esque nested scatters, which I hope to take up as my next ticket). ~~The original WA used Data Access and symbol store to pass around information between tasks. I am not quite sure how that would work with the shadow world, also considering we don't (yet) have engine functions at that level. So I have used a little different algorithm to orchestrate the calls in a workflow (preparing a small call graph and sorting that graph to obtain the logical ordering among tasks, and then orchestrate that via information in the FSM state data).~~. ~~I might wait for @Horneth for getting the engine functions in and have thoughts from you guys on plugging in outputs of a task to it's dependent task.~~. ~~I talked with Thibault about this and I honestly don't mind if this PR does't get merged at all if we see a problem with this, just need a fresh pair of eyes to look through it.~~. ~~Currently, I'm adding tests for all this new code.~~",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/743:80,extend,extend,80,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/743,1,['extend'],['extend']
Modifiability,"Changes from `cjl_dummyWireThrough` were overwritten by Miguel's BackendConfig branch probably during a rebase. Bringing that functionality back here. This will enable to submit a Workflow using the Cromwell Server and execute it via the new execution route if the `shadowExecutionEnabled` config property is set to true. . `SingleWorkflowRunnerActor` (and hence a submission via command line route) hasn't been modified, since it requires a whole other set of commands / responses to track / emit output for a particular WF, possibly in all of the Shadow series actors.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/732:290,config,config,290,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/732,1,['config'],['config']
Modifiability,"Closed the previous Pull Request (#841) since I ended up moving things to a new branch, but I'll address previous comments here:. Q: ""Is the system section [of application.conf] mandatory? It looks like this would throw if it's missing"" ; A: I don't think the section is mandatory in 0.19_hotfix, but looking back, it is mandatory in develop, something that needs a patch surely. Q: ""How can this [val serverMode = CromwellServer.isServerMode] be false ?"" ; A: You're right, it wasn't wired to be false ever in my previous PR. I've since changed it, please review it!. Documentation for this config change has also been updated and ready for review. Question for the reviewers: I arbitrarily moved the config to the backend stanza of the config file, since the system stanza doesn't exist anymore and the ""abortJobsOnTerminate"" config is also within the backends stanza. Is there a better place for it?. **MainSpec tests failing--it must be my changes, checking that out now, but hopefully the remaining changes can be examined in parallel**",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/889:592,config,config,592,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/889,4,['config'],['config']
Modifiability,"Closes #3214. Top level view:; - Totally split `draft2` from a fresh copy of WDL code in `draft3`.; - They now inhabit separate and unconnected sbt projects.; - Any existing code references to `wdl.` are now references to `wdl.draft2.`; - Please review my `build.sbt` file, the rest is just moving, shuffling and fixing up intellij's failures to refactor packages.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3229:346,refactor,refactor,346,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3229,1,['refactor'],['refactor']
Modifiability,Closes #4433 . The changes to `MaterializeWorkflowDescriptorActor.scala` and `CromwellApiService.scala` are basically just refactoring out reusable code into a shared place. It is a known issue (#4119) that Womtool cannot validate CWL; this limitation applies to the endpoint as well.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4467:123,refactor,refactoring,123,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4467,1,['refactor'],['refactoring']
Modifiability,Closes #4436 which was made for [this forum post](https://gatkforums.broadinstitute.org/wdl/discussion/13716/could-not-find-job-id-from-stdout-file-cromwell-with-an-unusual-backend#latest). A majority of this PR is just me shuffling content around in ConfigAsyncJobExecutionActor.scala to allow me to test the `getJob` function easily.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4437:251,Config,ConfigAsyncJobExecutionActor,251,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4437,1,['Config'],['ConfigAsyncJobExecutionActor']
Modifiability,"Closes #4557 . - Adds a configurable value `token-log-interval-seconds` in the `hog-safety` stanza.; - Logs when a hog group is at its limit (no more than once per `token-log-interval-seconds` seconds per hog group); - Logs when a backend has used all tokens (no more than once per `token-log-interval-seconds` seconds per backend); - Logs the current status of the Cromwell token queues (no more than once per `token-log-interval-seconds` seconds). Sample log message:; ```; Token Dispenser: The backend Local is starting too many jobs. New jobs are being limited.; ```. Sample queue status output:; ```; ""Token Dispenser state"": {; ""queues"": [{; ""token type"": ""BACKEND=Local/TOKENLIMIT=Some(10)/HOGFACTOR=5"",; ""queue state"": {; ""queue"": [{; ""name"": ""4a458483"",; ""queue size"": 2; }, {; ""name"": ""b106f1f4"",; ""queue size"": 2; }],; ""pool"": {; ""hog groups"": [{; ""hog group"": ""4a458483"",; ""used"": 2,; ""available"": false; }, {; ""hog group"": ""b106f1f4"",; ""used"": 2,; ""available"": false; }],; ""hog limit"": 2,; ""capacity"": 10,; ""leased"": 4; }; }; }],; ""pointer"": 0,; ""total token assignments"": 4; }; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4567:24,config,configurable,24,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4567,1,['config'],['configurable']
Modifiability,Cloudtool location needs to be configurable to VPC Service Perimeter be usable.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5585:31,config,configurable,31,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5585,2,['config'],['configurable']
Modifiability,Command line configuration documentation.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5560:13,config,configuration,13,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5560,1,['config'],['configuration']
Modifiability,Command variable expansion masks bash variable interpretation with ${...},MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3111:8,variab,variable,8,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3111,2,['variab'],['variable']
Modifiability,"Command:; ```bash; $ java -jar jars/cromwell-34.jar run hello_world/hello_world_0.wdl; ```; Output:; ```; [2018-08-30 17:53:11,17] [info] Running with database db.url = jdbc:hsqldb:mem:4fbaa426-09e6-4c70-9a1a-15469c4d77a0;shutdown=false;hsqldb.tx=mvcc; [2018-08-30 17:53:19,24] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2018-08-30 17:53:19,26] [info] [RenameWorkflowOptionsInMetadata] 100%; [2018-08-30 17:53:19,39] [info] Running with database db.url = jdbc:hsqldb:mem:146c8707-d56e-4f58-a2de-df327f328109;shutdown=false;hsqldb.tx=mvcc; [2018-08-30 17:53:20,13] [info] Slf4jLogger started; [2018-08-30 17:53:20,68] [info] Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-232861f"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; [2018-08-30 17:53:20,92] [info] Metadata summary refreshing every 2 seconds.; [2018-08-30 17:53:21,02] [info] CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; [2018-08-30 17:53:21,03] [info] KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; [2018-08-30 17:53:21,03] [info] WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; [2018-08-30 17:53:21,89] [info] JobExecutionTokenDispenser - Distribution rate: 50 per 1 seconds.; [2018-08-30 17:53:21,95] [info] SingleWorkflowRunnerActor: Version 34; [2018-08-30 17:53:21,97] [info] SingleWorkflowRunnerActor: Submitting workflow; [2018-08-30 17:53:22,05] [info] Unspecified type (Unspecified version) workflow 4dbd7d1c-e7e8-4f83-9750-5c638d1567bc submitted; [2018-08-30 17:53:22,16] [info] SingleWorkflowRunnerActor: Workflow submitted 4dbd7d1c-e7e8-4f83-9750-5c638d1567bc; [2018-08-30 17:53:22,16] [info] 1 new workflows fetched; [2018-08-30 17:53:22,16] [info] WorkflowManagerActor Starting workflow 4dbd7d1c-e7e8-4f83-9750-5c638d1567bc; [2018-08-30 17:",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4062:725,config,configuration,725,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4062,1,['config'],['configuration']
Modifiability,Comment out engine gcs filesystem in config Closes #705,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1135:37,config,config,37,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1135,1,['config'],['config']
Modifiability,Config Backend configuration: job-id-regex vs multiline output,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4436:0,Config,Config,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4436,2,"['Config', 'config']","['Config', 'configuration']"
Modifiability,Config backend runtime attributes. Closes #1315,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1327:0,Config,Config,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1327,1,['Config'],['Config']
Modifiability,Config backend wasn't dockerizing script paths.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2028:0,Config,Config,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2028,1,['Config'],['Config']
Modifiability,Config backend: runtime attributes,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1315:0,Config,Config,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1315,1,['Config'],['Config']
Modifiability,"Config only and no automated tests. Confirmed working in v2alpha1, code is in place for v2beta but may not be working there yet if the changes have not yet been promoted to beta.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5416:0,Config,Config,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5416,1,['Config'],['Config']
Modifiability,Config option to disable copying of outputs on cache hit for JES,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2347:0,Config,Config,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2347,1,['Config'],['Config']
Modifiability,Config parameter for 'system.workflow-restart' doesn't work,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1706:0,Config,Config,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1706,1,['Config'],['Config']
Modifiability,Config refactor,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6960:0,Config,Config,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6960,2,"['Config', 'refactor']","['Config', 'refactor']"
Modifiability,Config-specified Default runtime attributes,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2121:0,Config,Config-specified,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2121,1,['Config'],['Config-specified']
Modifiability,Configurable Carbonite freeze scanning parameters [BA-6109],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5272:0,Config,Configurable,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5272,1,['Config'],['Configurable']
Modifiability,Configurable Google Cloud SDK location [BA-6330],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5585:0,Config,Configurable,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5585,2,['Config'],['Configurable']
Modifiability,Configurable backend: Optional runtime attributes broke in 23,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1737:0,Config,Configurable,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1737,1,['Config'],['Configurable']
Modifiability,Configurable call caching file batch size,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4087:0,Config,Configurable,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4087,1,['Config'],['Configurable']
Modifiability,Configurable job shell.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3561:0,Config,Configurable,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3561,1,['Config'],['Configurable']
Modifiability,Configurable junk metadata stream (for throughput testing!) [BA-6417],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5506:0,Config,Configurable,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5506,1,['Config'],['Configurable']
Modifiability,Configurable value for service account Google Pipelines API uses for GCE nodes,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1656:0,Config,Configurable,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1656,1,['Config'],['Configurable']
Modifiability,Configure looking up of docker hash,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/336:0,Config,Configure,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/336,1,['Config'],['Configure']
Modifiability,Consider refactoring the Demo DOS configuration,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3858:9,refactor,refactoring,9,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3858,2,"['config', 'refactor']","['configuration', 'refactoring']"
Modifiability,Consistent failure to delocalize file referenced by variable,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4901:52,variab,variable,52,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4901,1,['variab'],['variable']
Modifiability,ContinueWhilePossible not working via Config,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1380:38,Config,Config,38,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1380,1,['Config'],['Config']
Modifiability,Convert util cruft to enhanced implicit classes,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/97:22,enhance,enhanced,22,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/97,1,['enhance'],['enhanced']
Modifiability,Correct HPC tutorial config error,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3488:21,config,config,21,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3488,1,['config'],['config']
Modifiability,"Create 2 new dispatchers: `api-dispatcher` and `engine-dispatcher`.; `api-dispatcher` isolates all actors / futures to ensure that every request will be using resources in this thread pool.; `engine-dispatcher` isolates engine actors from the rest of the system (specifically the backends that can run an arbitrary amount of blocking/slow code out of the control of the engine). ; `slow-actor-dispatcher` has been renamed to `io-dispatcher` and is used for io / blocking operations (copying outputs / logs / uploading files to gcs etc..). Other side quests:; - Re-use the WorkflowManagerSystem created in Main in `CromwellServer`, instead of extending `CromwellServer` with `WorkflowManagerSystem` which duplicates everything a second time.; - Add an `afterAll` on `CromwellTestKitSpec` to shutdown the test actor system at the end of the spec.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1152:642,extend,extending,642,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1152,1,['extend'],['extending']
Modifiability,Create Backend Factory (depends on completion of Backend Configs),MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/649:57,Config,Configs,57,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/649,1,['Config'],['Configs']
Modifiability,Create FC-develop configs,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4750:18,config,configs,18,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4750,1,['config'],['configs']
Modifiability,Create a configuration file suitable for WAAS. Outcomes:; * A PR in firecloud-develop with the new configuration; * Documentation on how to configure for WAAS; * [Optional] An example `.conf` file?,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4738:9,config,configuration,9,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4738,3,['config'],"['configuration', 'configure']"
Modifiability,Create config scheme for pluggable language support,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2346:7,config,config,7,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2346,1,['config'],['config']
Modifiability,Create folder with configuration (backends) examples,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4696:19,config,configuration,19,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4696,1,['config'],['configuration']
Modifiability,"Creates hashes for the following:; - command; - backend name; - output expression; - non-file inputs (as simpletons); - file input paths (according to config). Not included in this PR:; - backend specific hashes (runtime attributes, docker, file contents). Note that if you want anything to actually be written you'll want the following options (to avoid a hashing failure); - `lookup-docker-hash=false`; - `hash-docker-names=false`; - `hash-file-paths=true` -- actually you could leave this false but... then you'd always cache hit regardless of what files you're using!; - `hash-file-contents=false`",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1290:151,config,config,151,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1290,1,['config'],['config']
Modifiability,CromIAM deployment configuration in fc-develop repo,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4545:19,config,configuration,19,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4545,1,['config'],['configuration']
Modifiability,"Cromwell (38, in this case) is saturating the available connections to our managed MySQL database. Our DBAs increased the limit and Cromwell proceeded to fill up these slots. How can we limit the number of concurrent connections to a MySQL database? There doesn't seem to be any configuration option for this.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4777:279,config,configuration,279,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4777,1,['config'],['configuration']
Modifiability,"Cromwell 37 errors when the backend submit configuration contains an expression like:; `${""-l h_vmem="" + memory + ""G""}`: ; <details>; <summary> error message </summary>; <pre><code>; cromwell.core.CromwellFatalException: common.exception.AggregatedMessageException: Error(s):; Could not evaluate expression: ""-l h_vmem="" + memory + ""G"": Cannot perform operation: -l h_vmem= + WomLong(4); at cromwell.core.retry.Retry$$anonfun$withRetry$1.applyOrElse(Retry.scala:47); at cromwell.core.retry.Retry$$anonfun$withRetry$1.applyOrElse(Retry.scala:38); at scala.concurrent.Future.$anonfun$recoverWith$1(Future.scala:413); at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:37); at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:60); at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); at akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:91); at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:81); at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:91); at akka.dispatch.TaskInvocation.run(AbstractDispatcher.scala:40); at akka.dispatch.ForkJoinExecutorConfigurator$AkkaForkJoinTask.exec(ForkJoinExecutorConfigurator.scala:44); at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: common.exception.AggregatedMessageException: Error(s):; Could not evaluate expression: ""-l h_vmem="" + memory + ""G"": Cannot perform operation: -l h_vmem= + WomLong(4); at common.validation.Validation$ValidationTry$.toTry$extension1(Validation.scala:77); at common.validation.Validation$ValidationTry$.toTry$extension0(Validation.scala:73);",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4659:43,config,configuration,43,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4659,1,['config'],['configuration']
Modifiability,"Cromwell Appears to be setting the HOME Override in a really really wonky way that completely breaks several tools. Additionally the initial `$HOME` value is being set to `/root` as opposed to the `/cromwell_root`. I am not sure if that is by design or if that is a slight oversight. This bug however effectually renders GenomicsDBImport useless unless the user once again overrides the `$HOME` variable. the offending line in the `exec.sh` looks like the following:; ```bash; chmod 777 ""$tmpDir""; export _JAVA_OPTIONS=-Djava.io.tmpdir=""$tmpDir""; export TMPDIR=""$tmpDir""; export HOME=""$HOME$HOME$HOME$HOME$HOME$HOME$HOME$HOME$HOME$HOME$HOME$HOME$HOME$HOME$HOME$HOME$HOME$HOME$HOME$HOME$HOME$HOME$HOME$HOME$HOME"". ```. IN previous versions of cromwell (v29) this Home override did not exist. ```bash; tmpDir=$(mktemp -d /cromwell_root/tmp.XXXXXX); chmod 777 $tmpDir; export _JAVA_OPTIONS=-Djava.io.tmpdir=$tmpDir; export TMPDIR=$tmpDir; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3656:395,variab,variable,395,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3656,1,['variab'],['variable']
Modifiability,Cromwell CI refactoring.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3642:12,refactor,refactoring,12,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3642,1,['refactor'],['refactoring']
Modifiability,"Cromwell Version: 77. Hi Guys,. Im not sure if this is a bug but I recently noticed this behaviour. Im trying to write a task that registers task S3 outputs at the end of a workflow in a third-party system and copy it to another S3 bucket. This task itself does not generate any files locally but at the end of its execution I expect a new S3 object to appear in the destination bucket. The inputs and outputs are marshalled using a struct with a ""File"" variable for the S3 path of the objects. After the task executes Cromwell throws an error scala.MatchError - it recognises that the output is a `cromwell.filesystems.s3.S3Path` but dosn't appear to know what to do with it. Im wondering if it is because the ""file"" is created outside of the workflow workspace?. My work around is to use the `String` type in place of `File` type for ""path"" and cast back to `File` later in the workflow but this feels inelegant. Input:. {; ""main.bucket"" : ""my_bucket_2"" ,; ""main.file_list"":[; { ""path"": ""s3://my_bucket_1/a2c193f0-8f08-11ec-8c2a-0a58a9feac02/bob.html""}; ]; }. Expected Output:. [; {; ""id"": ""123""; ""path"": ""s3://my_bucket_2/a2c193f0-8f08-11ec-8c2a-0a58a9feac02/bob.html""; }; ]. Code:. struct file_thing {; String? id; File path; }. task copy_file_list{; input{; String bucket; Array[file_thing] file_list; }. command <<<; copy_files \; --bucket ~{bucket} \; --json_in ~{write_json(file_list)} \; --json_out outputs.json; >>>. output {; Array[file_thing] outputs = read_json(""outputs.json""); }. runtime {; docker: ""my_copy_tool:latest""; }; }. Error:. WorkflowManagerActor: Workflow e7a60e4b-8dc4-471b-aec6-b8cc1481f889 failed (during ExecutingWorkflowState): ; scala.MatchError: s3://my_bucket_2/a2c193f0-8f08-11ec-8c2a-0a58a9feac02/bob.html (of class ; cromwell.filesystems.s3.S3Path); 	at cromwell.backend.sfs.SharedFileSystem.hostAbsoluteFilePath(SharedFileSystem.scala:239); 	at cromwell.backend.sfs.SharedFileSystem.hostAbsoluteFilePath$(SharedFileSystem.scala:237); 	at cromwell.backend.sfs.Shar",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6716:454,variab,variable,454,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6716,1,['variab'],['variable']
Modifiability,"Cromwell apparently behaves badly in single-workflow mode when two instances are run in parallel (with a shared config and persistent DB). Since this is an untested operational mode, we could simply prevent the second instance from starting up?",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1498:112,config,config,112,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1498,1,['config'],['config']
Modifiability,Cromwell can fallback to configured default runtime attributes. The current implementation leverages the fact that `WdlExpression` extends `WdlValue`. This is not true anymore with WomExpressions. Find a way to fix this preferably without having WomExpression extend WdlValue.; This breaks runtime attribute validation in the `BackendWorkflowInitializationActor` and default runtime attributes.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2606:25,config,configured,25,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2606,3,"['config', 'extend']","['configured', 'extend', 'extends']"
Modifiability,Cromwell configuration to use reference disk for localization [BA-6390],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5596:9,config,configuration,9,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5596,1,['config'],['configuration']
Modifiability,"Cromwell seems to erroneously treat private/internal variables with File type as input files and attempts to localize them:. ```; version 1.0. task mytask {; 	input {; 		String mystr = ""Hello World!""; 	}. 	File myfile = ""myfile"". 	command <<<; 		echo ~{mystr} > ~{myfile}; 	>>>. 	output {; 		String file_contents = read_string(myfile); 	}; }. workflow wf {; 	call mytask; }; ```. ```; Could not localize myfile -> /home/jared/projects/gambit/data/misc/211031-apollo_illumina_pe-miniwdl/test-cromwell/cromwell-executions/wf/51d2f863-0e91-45b6-9e7b-f2365c259144/call-mytask/inputs/1979661608/myfile:; 	myfile doesn't exist; 	File not found /home/jared/projects/gambit/data/misc/211031-apollo_illumina_pe-miniwdl/test-cromwell/cromwell-executions/wf/51d2f863-0e91-45b6-9e7b-f2365c259144/call-mytask/inputs/1979661608/myfile -> /home/jared/projects/gambit/data/misc/211031-apollo_illumina_pe-miniwdl/test-cromwell/myfile; 	File not found myfile; 	File not found /home/jared/projects/gambit/data/misc/211031-apollo_illumina_pe-miniwdl/test-cromwell/myfile; 	at common.validation.Validation$ValidationTry$.toTry$extension1(Validation.scala:94); 	at common.validation.Validation$ValidationTry$.toTry$extension0(Validation.scala:90); 	at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand(StandardAsyncExecutionActor.scala:669); 	... 35 common frames omitted; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6562:53,variab,variables,53,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6562,1,['variab'],['variables']
Modifiability,"Cromwell seems to love `hard-links`:; * No matter what configuration I feed it, it will always tries `hard-links` first.; * When this fails. It does not try anything else. Given the config file `test.config`; run with `java -Dconfig.file=test.config -jar cromwell-30.1.jar run -i inputs.json test.wdl` ; ```HOCON; include required(classpath(""application"")). backend {; default=""Local""; providers {; Local {; config {; filesystems {; local {; localization: [; ""soft-link"", ""copy"", ""hard-link""; ]; caching {; duplication-strategy: [; ""soft-link"", ""copy"", ""hard-link""; ]; }; }; }; }; }; }; }; ```. ## Expected behavior:; Crommwell will prefer to use `ln -s`. If that fails it will copy. ## Actual behavior:; Cromwell output:; ```; ln: failed to create hard link '/home/ruben/IdeaProjects/construct-centrifuge-index/cromwell-executions/ConstructCentrifugeIndex/3e1afa55-3234-4fa9-b7e8-63d143846b9f/call-download/shard-0/execution/glob-0bd9f0edef72448a92c8f9e79babdc8d/GCF_000889155.1_ViralProj51245_genomic.fna' => '/tmp/test/centrifuge/data/libraries/53abeac3037f9afe08309700c99f725f/viral/GCF_000889155.1_ViralProj51245_genomic.fna': Invalid cross-device link; ln: failed to create hard link '/home/ruben/IdeaProjects/construct-centrifuge-index/cromwell-executions/ConstructCentrifugeIndex/3e1afa55-3234-4fa9-b7e8-63d143846b9f/call-download/shard-0/execution/glob-0bd9f0edef72448a92c8f9e79babdc8d/GCF_001343785.1_ViralMultiSegProj274766_genomic.fna' => '/tmp/test/centrifuge/data/libraries/53abeac3037f9afe08309700c99f725f/viral/GCF_001343785.1_ViralMultiSegProj274766_genomic.fna': Invalid cross-device link; ```; It tries only `hard-links` if this fails. It just continues, not even trying soft links, failing to record my globbed files and crashing the pipeline down the line.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3109:55,config,configuration,55,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3109,5,['config'],"['config', 'configuration']"
Modifiability,Cromwell should complain about unrecognized config keys,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1598:44,config,config,44,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1598,1,['config'],['config']
Modifiability,Cromwell should issue warnings when it encounters config it doesn't recognize,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7109:50,config,config,50,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7109,1,['config'],['config']
Modifiability,"Cromwell tests have an application.conf file... and the main source code has a default application.conf file. The test application.conf overwrites values in the main one, but this has caused confusion in the past. It'd be nicer if only one configuration file were used during tests.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/768:240,config,configuration,240,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/768,1,['config'],['configuration']
Modifiability,Cromwell tries to define undefined variables causing bizarre errors,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7201:35,variab,variables,35,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7201,1,['variab'],['variables']
Modifiability,"Cromwell: 36. I had the following config file, missing a brace:. ```; backend {; default = spartan. providers {; spartan {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; runtime-attributes = """"""; Int runtime_minutes = 600; Int cpus = 2; Int requested_memory_mb_per_core = 8000; String queue = ""short""; """""". submit = """"""; sbatch -J ${job_name} -D ${cwd} -o ${out} -e ${err} -t ${runtime_minutes} -p ${queue} \; ${""-c "" + cpus} \; --mem-per-cpu=${requested_memory_mb_per_core} \; --wrap ""/bin/bash ${script}""; """"""; kill = ""scancel ${job_id}""; check-alive = ""squeue -j ${job_id}""; job-id-regex = ""Submitted batch job (\\d+).*""; ; }; }; }; ```. When I ran `java -Dconfig.file=$(realpath spartan.conf) -jar cromwell-36.jar`, the error it printed was:. ```; Exception in thread ""main"" java.lang.ExceptionInInitializerError; 	at cromwell.CromwellApp$.runCromwell(CromwellApp.scala:14); 	at cromwell.CromwellApp$.delayedEndpoint$cromwell$CromwellApp$1(CromwellApp.scala:25); 	at cromwell.CromwellApp$delayedInit$body.apply(CromwellApp.scala:3); 	at scala.Function0.apply$mcV$sp(Function0.scala:34); 	at scala.Function0.apply$mcV$sp$(Function0.scala:34); 	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:12); 	at scala.App.$anonfun$main$1$adapted(App.scala:76); 	at scala.collection.immutable.List.foreach(List.scala:389); 	at scala.App.main(App.scala:76); 	at scala.App.main$(App.scala:74); 	at cromwell.CromwellApp$.main(CromwellApp.scala:3); 	at cromwell.CromwellApp.main(CromwellApp.scala); Caused by: com.typesafe.config.ConfigException$Parse: /data/cephfs/punim0751/spartan.conf: 27: expecting a close parentheses ')' here, not: end of file; 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseError(ConfigDocumentParser.java:201); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseError(ConfigDocumentParser.java:197); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseKey(Con",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4549:34,config,config,34,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4549,4,"['Config', 'config']","['ConfigBackendLifecycleActorFactory', 'config']"
Modifiability,"Cromwell: Development (`37-3b2affa`); Backend: HPC (`ConfigBackendLifecycleActorFactory`). I wanted access to a recently merged pull request (#4437), so I built a development version of Cromwell. However, when I run it with the same configuration file as I used for Cromwell 36, I get this error:; ```; [ERROR] [01/24/2019 11:10:24.126] [cromwell-system-akka.actor.default-dispatcher-4] [akka://cromwell-system/user/SingleWorkflowRunnerActor] No configuration setting found for key 'services' ; akka.actor.ActorInitializationException: akka://cromwell-system/user/SingleWorkflowRunnerActor/ServiceRegistryActor: exception during creation ; at akka.actor.ActorInitializationException$.apply(Actor.scala:193) ; at akka.actor.ActorCell.create(ActorCell.scala:669) ; at akka.actor.ActorCell.invokeAll$1(ActorCell.scala:523) ; at akka.actor.ActorCell.systemInvoke(ActorCell.scala:545) ; at akka.dispatch.Mailbox.processAllSystemMessages(Mailbox.scala:283) ; at akka.dispatch.Mailbox.run(Mailbox.scala:224) ; at akka.dispatch.Mailbox.exec(Mailbox.scala:235) ; at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) ; at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) ; at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) ; at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) ; Caused by: com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'services' ; at com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:156) ; at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:174) ; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:188) ; at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:193) ; at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:268) ; at com.typesafe.config.impl.SimpleConfig.getObject(SimpleConfig.java:41) ; at cromwell.services.ServiceRegistryActor$.serviceNameToPropsMap(ServiceRegi",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4577:53,Config,ConfigBackendLifecycleActorFactory,53,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4577,3,"['Config', 'config']","['ConfigBackendLifecycleActorFactory', 'configuration']"
Modifiability,"CromwellApp$.main(CromwellApp.scala:3); 	at cromwell.CromwellApp.main(CromwellApp.scala); Caused by: com.typesafe.config.ConfigException$Parse: /data/cephfs/punim0751/spartan.conf: 27: expecting a close parentheses ')' here, not: end of file; 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseError(ConfigDocumentParser.java:201); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseError(ConfigDocumentParser.java:197); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseKey(ConfigDocumentParser.java:279); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseObject(ConfigDocumentParser.java:450); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseValue(ConfigDocumentParser.java:247); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseObject(ConfigDocumentParser.java:458); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parse(ConfigDocumentParser.java:648); 	at com.typesafe.config.impl.ConfigDocumentParser.parse(ConfigDocumentParser.java:14); 	at com.typesafe.config.impl.Parseable.rawParseValue(Parseable.java:260); 	at com.typesafe.config.impl.Parseable.rawParseValue(Parseable.java:248); 	at com.typesafe.config.impl.Parseable.parseValue(Parseable.java:180); 	at com.typesafe.config.impl.Parseable.parseValue(Parseable.java:174); 	at com.typesafe.config.impl.Parseable.parse(Parseable.java:299); 	at com.typesafe.config.ConfigFactory.parseFile(ConfigFactory.java:689); 	at com.typesafe.config.DefaultConfigLoadingStrategy.parseApplicationConfig(DefaultConfigLoadingStrategy.java:51); 	at com.typesafe.config.ConfigFactory.defaultApplication(ConfigFactory.java:473); 	at com.typesafe.config.ConfigFactory$1.call(ConfigFactory.java:259); 	at com.typesafe.config.ConfigFactory$1.call(ConfigFactory.java:256); 	at com.typesafe.config.impl.ConfigImpl$LoaderCache.getOrElseUpdate(ConfigImpl.java:65); 	at com.typesafe.config.impl.ConfigImpl.computeCachedConfig(ConfigImpl.java:92)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4549:2468,config,config,2468,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4549,1,['config'],['config']
Modifiability,"Currently -- the Cromwell (and other?) service logs on the alpha env are around for upto 5 days. . It would be great to have their availability extended to a longer life line, if feasible. . Being investigated by David Bernick.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3894:144,extend,extended,144,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3894,1,['extend'],['extended']
Modifiability,"Currently Centaur is configured with a URL for a live Cromwell server. Leave this capability but also allow for Centaur to manage its own Cromwell such that it can start/stop it at will. Note that there's currently a bash script that does a lot of this, that script should be refactored as necessary once the functionality is in Centaur proper.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2350:21,config,configured,21,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2350,2,"['config', 'refactor']","['configured', 'refactored']"
Modifiability,"Currently we have docs for the SGE backend which is a bit of a hodgepodge between describing the historical SGE backend and the flexibility of the Config backend. There's also doc for the HTCondor backend which as of #2141 is also using the Config backend. . Change all of this to demonstrate how one can use the Config backend, primarily from the lens of an HPC user. Make it clear that it can handle most use cases and provide a couple of generic examples (e.g. SGE)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2166:147,Config,Config,147,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2166,3,['Config'],['Config']
Modifiability,"Currently when an external user attempts to access our cloud accounts, Travis does not hand out the encryption keys. This is desired behavior, as we do not want to run up bills on unknown code from outside users. However, currently our test scripts are not checking the variable [`TRAVIS_SECURE_ENV_VARS`](https://docs.travis-ci.com/user/environment-variables/#Default-Environment-Variables), and are instead trying to access encrypted variables that are not and never will be present. This leads to false negatives where the tests are marked as failed, when instead they should best case be marked as ignored, worst case be marked as implicitly passed.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1717:270,variab,variable,270,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1717,4,"['Variab', 'variab']","['Variables', 'variable', 'variables']"
Modifiability,"Currently, the configuration file should be passed as `java -Dconfig.file=/path/to/your.conf cromwell.jar`; neverhteless, if installed with the formula from homebrew-core, the wrapper script does not allow that configuration:. ```; #!/bin/bash; exec java -jar /usr/local/Cellar/cromwell/30.2/libexec/cromwell-30.2.jar ""$@""; ```. Could it be possible to add a way to provide the config file in this case? Something like an environmental variable can be useful (e.g., `export CROMWELL_CONFIG_FILE=/path/to/your.conf` will pick up directly this in every run).",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3262:15,config,configuration,15,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3262,4,"['config', 'variab']","['config', 'configuration', 'variable']"
Modifiability,"Currently, the file systems available to the engine for functions like read_\* are statically defined. GCS, Local, etc. This issue is to make that driven by the config file. The reason this is important is because if you are running a cromwell server and can not disable the ""Local Shared Filesystem"" from the engine... someone could write a WDL that does a read_ on any file that the cromwell server has access to (e.g. read_lines(""./cromwell.conf"")... which is bad",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/821:161,config,config,161,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/821,1,['config'],['config']
Modifiability,"Currently, we have a number of ignored tests that are part of the default 'sbt test' configuration which we are not planning on re-enabling for MVP. By excluding these we (a) don't lose them and (b) should be able to drive the ignored tests to 0 (yay!)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/996:85,config,configuration,85,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/996,1,['config'],['configuration']
Modifiability,"Currently, when trying to query for labels, one is required to provide the label key & value. Make the query endpoint more flexible so that it's possible to support querying by key.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3719:123,flexible,flexible,123,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3719,1,['flexible'],['flexible']
Modifiability,"DO NOT MERGE YET!. Hopefully a final-ish version of the DataAccess API to unblock its implementation in Slick. . RIP StoreActor, SymbolStore, and ExecutionStore. The spirit of ExecutionStore lives on in WorkflowActor, and maybe SymbolStore might find a place there too to rid us of some Await.result()s. StoreActor is dead for real. . Known issues:. FIXED ~~1) The Docker test is broken because the backend-specific initialization was accidentally refactored away. Shouldn't be a big deal to restore that.~~; 2) All other tests pass, but that might just be because the restart test stinks. There are worrisome messages being emitted from that test which need to be tracked down and have assertions put on them. It might also be a good idea to test restarting a workflow more complex than ""Hello World"".; 3) No persistence of BackendInfo yet, shouldn't be tough but that needs a bit of discussion.; 4) More Await.results() in WorkflowActor than I would like or are probably necessary. This could be a separate Tech Debt issue. At least DataAccess is fully async.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/64:448,refactor,refactored,448,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/64,1,['refactor'],['refactored']
Modifiability,"DatabaseDef$$anonfun$runInContext$1.apply(DatabaseComponent.scala:146) ~[cromwell.jar:0.19];   at slick.backend.DatabaseComponent$DatabaseDef$$anonfun$runInContext$1.apply(DatabaseComponent.scala:146) ~[cromwell.jar:0.19];   at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:251) ~[cromwell.jar:0.19];   at scala.concurrent.Future$$anonfun$flatMap$1.apply(Future.scala:249) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable.run_aroundBody0(Promise.scala:32) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable$AjcClosure1.run(Promise.scala:1) ~[cromwell.jar:0.19];   at org.aspectj.runtime.reflect.JoinPointImpl.proceed(JoinPointImpl.java:149) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation$$anonfun$aroundExecution$1.apply(FutureInstrumentation.scala:44) ~[cromwell.jar:0.19];   at kamon.trace.Tracer$.withContext(TracerModule.scala:53) ~[cromwell.jar:0.19];   at kamon.scala.instrumentation.FutureInstrumentation.aroundExecution(FutureInstrumentation.scala:43) ~[cromwell.jar:0.19];   at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:31) ~[cromwell.jar:0.19];   at scala.concurrent.impl.ExecutionContextImpl$AdaptedForkJoinTask.exec(ExecutionContextImpl.scala:121) ~[cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) [cromwell.jar:0.19];   at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) [cromwell.jar:0.19]; 2016-05-10 11:38:08,737 cromwell-system-akka.actor.default-dispatcher-3 INFO  - WorkflowActor [UUID(972b838f)]: persisting status of CollectUnsortedReadgroupBamQualityMetrics:10 to Failed.; 2016-05-10 11:38:08,738 cromwell-system-akka.actor.default-dispatcher-3 ERROR - WorkflowActor [UUID(972b838f)]: Read timed out",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/826:8003,Adapt,AdaptedForkJoinTask,8003,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/826,1,['Adapt'],['AdaptedForkJoinTask']
Modifiability,"Dear Cromwell Team,; I am trying to run a workflow written in WDL using Cromwell v.65. The workflow reports the following error in the stdout:; ```[2023-08-11 14:21:11,58] [error] SingleWorkflowRunnerActor received Failure message: Metadata for workflow <UUID> exists in database but cannot be served because row count of 3138431 exceeds configured limit of 1000000.; cromwell.services.MetadataTooLargeNumberOfRowsException: Metadata for workflow <UUID> exists in database but cannot be served because row count of 3138431 exceeds configured limit of 1000000.```; This is after having edited the `cromwell.conf` as suggested in [this thread](https://github.com/broadinstitute/cromwell/issues/2519). The configuration file used is as follows (edited to remove the main script):; ```; include required(classpath(""application"")); backend {; default = LSF; providers {; LSF {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; exit-code-timeout-seconds = 300; runtime-attributes = """"""; Int cpu; Int memory_mb; String? lsf_queue; String? lsf_project; String? docker; """""". submit = """"""; bsub \; -q ${lsf_queue} \; -P ${lsf_project} \; -J ${job_name} \; -cwd ${cwd} \; -o ${out} \; -e ${err} \; -n ${cpu} \; -R 'rusage[mem=${memory_mb}] span[hosts=1]' \; -M ${memory_mb} \; /usr/bin/env bash ${script}; """""". submit-docker = """"""; module load tools/singularity/3.8.3; SINGULARITY_MOUNTS='<redacted>'; export SINGULARITY_CACHEDIR=$HOME/.singularity/cache; LOCK_FILE=$SINGULARITY_CACHEDIR/singularity_pull_flock. export SINGULARITY_DOCKER_USERNAME=<redacted>; export SINGULARITY_DOCKER_PASSWORD=<redacted>. flock --exclusive --timeout 900 $LOCK_FILE \; singularity exec docker://${docker} \; echo ""Sucessfully pulled ${docker}"". bsub \; -q ${lsf_queue} \; -P ${lsf_project} \; -J ${job_name} \; -cwd ${cwd} \; -o ${out} \; -e ${err} \; -n ${cpu} \; -R 'rusage[mem=${memory_mb}] span[hosts=1]' \; -M ${memory_mb} \; singularity exec --containall $SINGULARITY_MOUNTS ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7203:338,config,configured,338,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7203,4,['config'],"['config', 'configuration', 'configured']"
Modifiability,"Dear Cromwell dev team,. In an attempt to use cromwell for running genomics pipeline(s) I encountered a few issues that prevent me from using these otherwise wonderful tools. Specific to my case, I would like to use Google Life Sciences v2beta in the region `europe-west4` due to data localisation needs. I mention this because of another recent Hellow World related issue #6462 where the demo did seem to work. 1) The documentation for the [Hello World](https://cromwell.readthedocs.io/en/stable/tutorials/PipelinesApi101/#lets-get-started) example is out of date. In `google.conf` it still lists the configuration for ""JES"" backend. 2) In the same tutorial ([Setting up PAPIv2](https://cromwell.readthedocs.io/en/stable/tutorials/PipelinesApi101/#setting-up-papiv2)), the instructions for which roles to assign to the GCP service account are outdated. 3) Once the user puzzles together which parts to replace, the execution is still failing (for me at least).; I run the following command ` java -Dconfig.file=cromwell.BROADexamples.v4.conf -jar cromwell-66.jar run hello.wdl -i hello.inputs`, which results in the following `Request contains an invalid argument.` error (abbreviated to the relevant section):; ```; [2021-08-13 10:44:39,31] [info] Running with database db.url = jdbc:hsqldb:mem: ...; ...; [2021-08-13 10:44:54,04] [info] Reference disks feature for PAPIv2 backend is not configured.; [2021-08-13 10:44:54,46] [info] Slf4jLogger started; [2021-08-13 10:44:54,73] [info] Workflow heartbeat configuration:; ...; [2021-08-13 10:44:55,42] [info] Running with 3 PAPI request workers; ...; [2021-08-13 10:44:55,79] [info] Unspecified type (Unspecified version) workflow a15c46b7-5f93-46d6-94a2-28f656914866 submitted; ...; [2021-08-13 10:44:56,46] [info] Request manager PAPIQueryManager created new PAPI request worker PAPIQueryWorker-58e6b395-916e-4ba4-965a-0ec8f1c0760d with batch interval of 3333 milliseconds; ...; [2021-08-13 10:44:56,67] [info] MaterializeWorkflowDescriptorActor [a",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6469:602,config,configuration,602,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6469,1,['config'],['configuration']
Modifiability,"Dear Cromwell dev team,. This is an enhancement suggestion. . When using the google backend for resources allocation, one can specify `gpuCount` and `gpuType` to request for specific resources. I am currently trying to design a task that optionally needs to access a GPU (function of input/parameters). I tried different approach to dynamically schedule GPUs, but `gpuCount` seems constrain to a non-null positive integer. https://github.com/broadinstitute/cromwell/blob/bfef756ca35b46570dff3fda57f77dd4b2b0d25c/supportedBackends/google/pipelines/common/src/main/scala/cromwell/backend/google/pipelines/common/PipelinesApiRuntimeAttributes.scala#L190 . https://github.com/broadinstitute/cromwell/blob/bfef756ca35b46570dff3fda57f77dd4b2b0d25c/supportedBackends/google/pipelines/common/src/main/scala/cromwell/backend/google/pipelines/common/GpuValidation.scala#L28-L40. To allow for dynamic access to GPUs, I propose to extend `gpuCount` type to allow for a null value, and to check for a non-null value for resource allocation. https://github.com/broadinstitute/cromwell/blob/bfef756ca35b46570dff3fda57f77dd4b2b0d25c/supportedBackends/google/pipelines/common/src/main/scala/cromwell/backend/google/pipelines/common/PipelinesApiRuntimeAttributes.scala#L193. Please let me know if such a feature is not desired for any reason. . \* I tried accessing the Jira tracker but `doesn't have access to Jira on broadworkbench.atlassian.net.`",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6679:36,enhance,enhancement,36,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6679,2,"['enhance', 'extend']","['enhancement', 'extend']"
Modifiability,"Dear WDL team,. I am using joint-discovery-gatk4.wdl for running jointcalling on 6000 plus samples using LSF as scheduler. I have lsf configuration file which was working with small set of samples. When I tried running Jointcalling on 6000+ samples using WDL, it is giving the below error.; ; **[2019-12-04 10:59:03,89] [ESC[38;5;220mwarnESC[0m] JobExecutionTokenDispenser - High load alert. Freeze token distribution.**; ; And I changed the concurrent-job-limit = 5000 in lsf configuration, now it is giving; ; **[2019-12-01 07:08:46,91] [info] WorkflowExecutionActor-b2c84d70-611d-4dad-bb18-78a6648e4113 [^[[38;5;2mb2c84d70^[[0m]: Starting JointGenotyping.ImportGVCFs (195 shards); [2019-12-01 07:15:32,84] [^[[38;5;1merror^[[0m] Failed to summarize metadata; java.sql.SQLException: java.lang.OutOfMemoryError: GC overhead limit exceeded**. Could you please help me to proceed further. Thanks In Advance; Fazulur Rehaman",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5305:134,config,configuration,134,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5305,2,['config'],['configuration']
Modifiability,"Dear all,. **Issue**; It appears that it is currently not possible to provide task variables in the input json when they are called in a subworkflow. In the example below the goal to overwrite SubTask optional value: overwrite_given_value. **Example**; _For this examples I use womtool 84 and WDL 1.0. I also tried with womtool 53.1 and 83 which showed the same issue_; The following files are used to show case the issue.; The main workflow:; ```; version 1.0. import ""SubWorkflow.wdl"" as SubWorkflow. workflow MainWorkflow {; input {; String value_2_give = ""default value""; }; call MainTask {; input:; given_value = value_2_give; }. call SubWorkflow.SubWorkflow {; input:; value_2_give = value_2_give; }; }. task MainTask {; input {; String given_value; String? overwrite_given_value; }; command <<<; echo ~{select_first([overwrite_given_value, given_value])};; >>>; }; ```. The subworkflow:; ```; version 1.0. workflow SubWorkflow {; input {; String value_2_give = ""default value""; String? overwrite_value_2_give; }; call SubTask {; input:; given_value = select_first([overwrite_value_2_give, value_2_give]); }; }. task SubTask {; input {; String given_value; String? overwrite_given_value; }; command <<<; echo ~{select_first([overwrite_given_value, given_value])};; >>>; }; ```. To be sure I ran the validation mode of womtools:; ```; $ java -jar womtool-84.jar validate MainWorkflow.wdl; Success!; $ java -jar womtool-84.jar validate SubWorkflow.wdl; Success!; ```. After creating these files, I ran womtool with the ""inputs"" option getting the following output:; ```; $ java -jar womtool-84.jar inputs MainWorkflow.wdl; {; ""MainWorkflow.SubWorkflow.overwrite_value_2_give"": ""String? (optional)"",; ""MainWorkflow.MainTask.overwrite_given_value"": ""String? (optional)"",; ""MainWorkflow.value_2_give"": ""String (optional, default = \""default value\"")""; }; ```; This output json shows which variables you can (or must) provide in order to be able to run in this case the main workflow. here we see that",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6841:83,variab,variables,83,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6841,1,['variab'],['variables']
Modifiability,"Dear cromwell developers, ; I assume that it is possbile to configure cromwell use the podman instead of docker as a backend via configuration file? (https://cromwell.readthedocs.io/en/stable/tutorials/Containers/#configuration-in-detail) So far I have not manage to accomplish it starting by modifying the https://github.com/broadinstitute/cromwell/blob/develop/cromwell.example.backends/cromwell.examples.conf backend section maybe someone can provide a template for thish? . Best, Eugene",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6660:60,config,configure,60,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6660,3,['config'],"['configuration', 'configuration-in-detail', 'configure']"
Modifiability,"Dear cromwell team,. We are trying to setup a test environment with GATK4 and cromwell for our local users. I tested the helloHaplotypeCaller.wdl in the data bundle but it is giving the following error:. ```; java -jar $cromwell run storage/WDLdata/WDLscripts/helloHaplotypeCaller.wdl -i storage/WDLdata/WDLscripts/helloHaplotypeCaller_inputs.json; [2017-10-04 06:06:48,43] [info] Running with database db.url = jdbc:hsqldb:mem:2812db5e-e9cc-48b0-bc67-62fd2c7887f9;shutdown=false;hsqldb.tx=mvcc; [2017-10-04 06:06:53,48] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2017-10-04 06:06:53,49] [info] [RenameWorkflowOptionsInMetadata] 100%; [2017-10-04 06:06:53,83] [info] Slf4jLogger started; [2017-10-04 06:06:54,01] [info] Metadata summary refreshing every 2 seconds.; [2017-10-04 06:06:54,02] [info] WriteMetadataActor configured to write to the database with batch size 200 and flush rate 5 seconds.; [2017-10-04 06:06:54,32] [info] CallCacheWriteActor configured to write to the database with batch size 100 and flush rate 3 seconds.; [2017-10-04 06:06:55,29] [info] SingleWorkflowRunnerActor: Submitting workflow; [2017-10-04 06:06:55,36] [info] Workflow bf90a37b-6ffa-4122-a12c-24aced32f3b6 submitted.; [2017-10-04 06:06:55,36] [info] SingleWorkflowRunnerActor: Workflow submitted bf90a37b-6ffa-4122-a12c-24aced32f3b6; [2017-10-04 06:06:55,36] [info] 1 new workflows fetched; [2017-10-04 06:06:55,37] [info] WorkflowManagerActor Starting workflow bf90a37b-6ffa-4122-a12c-24aced32f3b6; [2017-10-04 06:06:55,37] [info] WorkflowManagerActor Successfully started WorkflowActor-bf90a37b-6ffa-4122-a12c-24aced32f3b6; [2017-10-04 06:06:55,37] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2017-10-04 06:06:55,63] [info] MaterializeWorkflowDescriptorActor [bf90a37b]: Call-to-Backend assignments: helloHaplotypeCaller.haplotypeCaller -> Local; [2017-10-04 06:06:56,98] [info] WorkflowExecutionActor-bf90a37b-6ffa",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2673:899,config,configured,899,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2673,1,['config'],['configured']
Modifiability,"Dear developers,. During testing I ran into the problem that the `HashPathStrategy` does not include the last modified date of the file. It assumes: ""if the path is there, it is the same file"". This is not necessarily the case. Files can be modified or replaced.Therefore the current `HashPathStrategy` is a big liability when trying to get reproducible results. By adding a ""last modified date"" to the `HashPathStrategy` this will ensure that nothing has happened to the file from the user or system side. This of course is not as safe as the `HashFileStrategy` since it does not protect against filesystem or hardware errors, but it provides a lot more safety compared to the current `HashPathStrategy`. ; This is also how Snakemake checks if files are the same and it works quite well. Alternatively there could be an option in the Configfile that allows you to set this behaviour. Please let me know what you think of this.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4405:835,Config,Configfile,835,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4405,1,['Config'],['Configfile']
Modifiability,"Debugging or profiling a running Cromwell has always been extremely painful due to the need to `apt install` all the tools manually. This is particularly infeasible when working with an unstable instance that is restarting and continually erasing those modifications (this was me yesterday). All of the image changes are in limited in scope to `installDebugFacilities` function. The rest of the diff is rationalizing our build system. Previously, we had `isSnapshot`, `isRelease`, and ""neither of those"". The logic was confusing around which took precedence. I replaced the bag o' booleans with a type system representing the types. The ""neither of those"" now has a name `Standard`. And finally I augmented it with `Debug`. No external interface is changing, as mentioned in the Markdown running with no parameters still gets you a `Snapshot` build. There is a stowaway enhancement to add the `develop` tag to merged commits. We used to set this tag <a long time ago> and I meant to fix it in https://github.com/broadinstitute/cromwell/pull/7362, but forgot. Product of running all of the commands documented in Markdown:. ![Screenshot 2024-05-01 at 17 23 16](https://github.com/broadinstitute/cromwell/assets/1087943/79f9e8c0-f33f-4e75-a686-067830945584)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7417:870,enhance,enhancement,870,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7417,1,['enhance'],['enhancement']
Modifiability,Declare variable Array[File] of output from task in scatter,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1513:8,variab,variable,8,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1513,1,['variab'],['variable']
Modifiability,"Decode cwl into a temporary sub-directory so that unzipping doesn't collide under top level `/tmp`; BUG/TODO: cannot delete the cwl sub-directory to clean up files until after the workflow finishes.; Fixed passing cromwell inputs via `-i`.; Passing centaur google config via new environment variables listed in reference.conf instead of on command line.; Limit conformance tests to -Xmx1g per java process by default, and 2g for the cromwells running the conformance tests.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3187:264,config,config,264,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3187,2,"['config', 'variab']","['config', 'variables']"
Modifiability,Default workflow type is now configurable.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2586:29,config,configurable,29,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2586,1,['config'],['configurable']
Modifiability,"Define a `WomExpression` `trait` or `abstract class`; It should have an abstract `evaluate` method taking WOM I/O functions as well as some kind of ""variable context"" containing values for the variable referenced in the expression (likely a `Map[String, WomValue]` of some sort).The values should be accurate. E.g: correct shard index if inside the same scatter, array of all shards if outside etc... It should also expose a Set of variables referenced in the expression. Other methods might reveal themselves useful / needed as this is built. WDL and CWL will implement this abstract class and provide their own implementation of the abstract methods.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2522:149,variab,variable,149,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2522,3,['variab'],"['variable', 'variables']"
Modifiability,"Defining inputs in a call overwrites/affects inputs to other calls when these inputs have the same name. This happens in cromwell 34, as well as the develop version (9bee537). It happens for WDL version 1.0 and Biscayne, but not for draft-2. example:; ```; version 1.0; workflow test {; String out = ""hello""; call echo1 { #Should run `echo hello1`, but runs `echo21` if run second; input:; out = out + ""1""; }; call echo2 { #should run `echo hello2`, but runs `echo 12` if run second; input:; out = out + ""2""; }; }; task echo1 {; input {; String out; }; command {; echo ~{out}; }; }; task echo2 {; input {; String out; }; command {; echo ~{out}; }; }; ```; I added the echo task twice to check if it might be caused by running the same task multiple times, but this also happens when it's two different tasks with equally named inputs. Defining one or both inputs as variables before passing them to the call seems works as expected:; ```; workflow test {; String out = ""hello""; call echo1 { # runs `echo hello1`; input:; out = out + ""1""; }; String out2 = out + ""2""; call echo2 { # runs `echo hello2`; input:; out = out2; }; }; ```. <!--; Hi! Thanks for taking the time to report feedback. Before posting an issue here, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're in the right place. -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3999:866,variab,variables,866,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3999,2,"['config', 'variab']","['configuration', 'variables']"
Modifiability,Defining variables declared in a task level where the task has multiple aliases.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2914:9,variab,variables,9,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2914,1,['variab'],['variables']
Modifiability,Deprecation errors for DB configs. Closes #2186,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2200:26,config,configs,26,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2200,1,['config'],['configs']
Modifiability,"Description:; * Adds a statistics recorder into the WriteMetadataActor to count rows being sent per workflow. If the counter goes about a given limit, we get an alert back which the write actor converts into a log message. . Food for reviewers' thoughts:. * Does the set of configuration options make sense?; * And what might be sensible default values?; * I'm not a huge fan of how subworkflows' parents are detected here. Is there a more direct way to find out a parent?",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6641:274,config,configuration,274,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6641,1,['config'],['configuration']
Modifiability,Design a way for Cromwell to pass language specific configuration to the various bindings.; The use case for this is read_*** bytes limitation that are different for different WDL functions which Cromwell has no knowledge of anymore.; CWL also requires the same type of limitation.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2611:52,config,configuration,52,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2611,1,['config'],['configuration']
Modifiability,DigestUtils.java:794); Mar 09 00:55:25 web start-cromwell.sh[110916]: at org.apache.commons.codec.digest.DigestUtils.digest(DigestUtils.java:50); Mar 09 00:55:25 web start-cromwell.sh[110916]: at org.apache.commons.codec.digest.DigestUtils.md5(DigestUtils.java:274); Mar 09 00:55:25 web start-cromwell.sh[110916]: at org.apache.commons.codec.digest.DigestUtils.md5Hex(DigestUtils.java:310); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.backend.impl.sfs.config.HashFileStrategy.$anonfun$hash$3(ConfigHashingStrategy.scala:82); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.util.TryWithResource$.$anonfun$tryWithResource$1(TryWithResource.scala:16); Mar 09 00:55:25 web start-cromwell.sh[110916]: at scala.util.Try$.apply(Try.scala:209); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.util.TryWithResource$.tryWithResource(TryWithResource.scala:10); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.backend.impl.sfs.config.HashFileStrategy.hash(ConfigHashingStrategy.scala:82); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.backend.impl.sfs.config.ConfigHashingStrategy.usingStandardInitData$1(ConfigHashingStrategy.scala:52); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.backend.impl.sfs.config.ConfigHashingStrategy.getHash(ConfigHashingStrategy.scala:57); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.backend.impl.sfs.config.ConfigBackendFileHashingActor.customHashStrategy(ConfigBackendFileHashingActor.scala:26); Mar 09 00:55:25 web start-cromwell.sh[110916]: at cromwell.backend.standard.callcaching.StandardFileHashingActor$$anonfun$fileHashingReceive$1.applyOrElse(StandardFileHashingActor.scala:73); Mar 09 00:55:25 web start-cromwell.sh[110916]: at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); Mar 09 00:55:25 web start-cromwell.sh[110916]: at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:172); Mar 09 00:55:25 web start-cromwell.sh[110916]: at akka.actor.Actor,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3383:2653,Config,ConfigHashingStrategy,2653,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3383,1,['Config'],['ConfigHashingStrategy']
Modifiability,Disable metadata summary refresh via config,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1378:37,config,config,37,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1378,1,['config'],['config']
Modifiability,"Discussed at standup 2019-02-04. Right now, bcbio uses:; - pinned CWL (checked in); - floating docker; - floating data (not controlled by us). As such, it breaks pretty frequently due to external factors, negating its usefulness as a regression test. For this ticket, update our bcbio configuration to be two separate jobs - one fully floating to test compatibility at the cutting edge, one fully pinned to serve as a stable regression test. Floating job:; - pull CWL from Brad's repo; - floating docker [same as now]; - floating data [same as now]. Pinned job:; - pinned CWL [same as now]; - our own stable copy of the data; - our own stable copy of the dockers",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4613:285,config,configuration,285,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4613,1,['config'],['configuration']
Modifiability,Do not mix script/backend RC + refactor setStatus DB method,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/449:31,refactor,refactor,31,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/449,1,['refactor'],['refactor']
Modifiability,"Do the following:. - [x] Rename the `Preempted` `ExecutionStatus` to be `RetryableFailure`.; - [x] Change the `WorkflowExecutionActor` to blindly honor `JobFailedRetryableResponse`s. Currently it is deciding whether or not to retry when it receives these. Now it will assume the determination was already made.; - [x] Remove the `system.max-retries` config option; - [x] Change the JABJEA to track both preemptions and non-preemption retries via the KV store; - [x] For any failure from JES determine if the job is to be retried, either using the preemption count supplied by the user or a max non-preemption retry count of 2. If the job is retryable ensure a `JobFailedRetryableResponse` finds its way back to the WEA; - [x] Modify `BackendStatus` such that we can see that the job was either a) preempted or b) retried due to ReasonX",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1925:350,config,config,350,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1925,1,['config'],['config']
Modifiability,"Docker Hub is incredibly slow when accessed directly from Hangzhou or any other location within China. There is no known Alibaba Cloud provided CDN or cache for docker images on BCS. To significantly speed up docker pulls users are able to upload docker images to their own private docker registry hosted within one of their OSS buckets. This uses a plugin contributed to the docker codebase that stores and retrieves docker images via an OSS client. Currently the BCS backend allows users to specify the private OSS registry within the `docker` runtime attribute. For portability, the `docker` runtime attribute should only specify the image, and a separate `dockerRegistry` runtime attribute should optionally specify a private OSS registry. Ideally there should be a way for a user to cache docker images on their own private OSS registry while still using contributed by others WDLs. One particular issue for call caching may be that the docker image hashes are probably registry specific. Cromwell's call caching code requires WDL to specify a hash that may only be available on docker hub, and may not be available on an OSS mirror, even if the image contains the exact same content. Also it should be decided if the BCS backend should behave like the JES/PAPI backend and only allow jobs that specify a `docker` runtime attribute, or if the behavior should continue to be like the `Local`/`SFS` backends and allow running jobs on the bare VM without a docker container. Links regarding BCS/OSS and docker:; - ([EN translation](https://translate.google.com/translate?hl=en&sl=zh-CN&tl=en&u=https%3A%2F%2Fhelp.aliyun.com%2Fdocument_detail%2F28022.html)) https://help.aliyun.com/document_detail/28022.html; - ([EN translation](https://translate.google.com/translate?hl=en&sl=zh-CN&tl=en&u=https%3A%2F%2Fhelp.aliyun.com%2Fdocument_detail%2F42402.html)) https://help.aliyun.com/document_detail/42402.html; - https://docs.docker.com/registry/storage-drivers/; - https://github.com/docker/distribution",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3518:350,plugin,plugin,350,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3518,2,"['plugin', 'portab']","['plugin', 'portability']"
Modifiability,Docker private registry configuration,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3574:24,config,configuration,24,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3574,1,['config'],['configuration']
Modifiability,"Docs:; - Fixed a bunch of broken links; - I think the Scala Steward updates gave us a new version of doc generation that is more strict; - There are more broken links than just these, did not attempt to be comprehensive; - IntelliJ's markdown validation is helpful:. ![Screen Shot 2020-08-19 at 12 15 43 PM](https://user-images.githubusercontent.com/1087943/90661978-d2613d00-e215-11ea-8c1d-5ae4c842213e.png). Error messages:; - Attempted to make them more concise and consistent; - Sometimes we didn't make it obvious that a limit is configurable; - Did not attempt to be comprehensive",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5779:535,config,configurable,535,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5779,1,['config'],['configurable']
Modifiability,Document HybridMetadataServiceActor existence and config [BA-6013],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5384:50,config,config,50,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5384,1,['config'],['config']
Modifiability,Documentation Request: Passing inputs to workflow level variables,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3592:56,variab,variables,56,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3592,1,['variab'],['variables']
Modifiability,"Documentation issue regarding timing variables in ""executionEvents"" of workflows in cromwell metadata",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5579:37,variab,variables,37,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5579,1,['variab'],['variables']
Modifiability,"Does the config file https://github.com/broadinstitute/cromwell/blob/develop/scripts/docker-compose-mysql/compose/cromwell/app-config/application.conf#L1; need the header; include required(classpath(""application"")); at the top?",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4204:9,config,config,9,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4204,2,['config'],['config']
Modifiability,Dos Script: Martha url can be passed as environment variable,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3924:52,variab,variable,52,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3924,1,['variab'],['variable']
Modifiability,"Draft PR TODOs:; - [x] Add some unit tests; - [X] ImportResolver; - [X] GithubAuthVendingSupport; - [x] Find a better way to do the await result; - [x] Remove from standard config and allow the system to work in the absence of a github auth vending service OR allow it to be configured OFF in config and make that the default 🤔 ; - [x] Move the auth vending message and helper classes out of `impl`. To test this - ; - Go to github and create a limited scope personal access token; - Scope to a single repo; - Add readonly access for Content, and no other permissions; - Update the config of a running instance with the raw token under `GithubAuthVending.config.access-token`. NB don't include the `Bearer` before the token in the config file.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7365:173,config,config,173,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7365,6,['config'],"['config', 'configured']"
Modifiability,"During the testing hackathon, we discovered a number of problems caused by the eventual consistency of the metadata service. One specific case of this is the granularity of the events. . On one side, we have a publisher who has a whole collection of events that they would like to push. They push them one event at a time to the MD service. Because even things like array elements are pushed one update at a time because of MD format, we run into the situation where a consumer can see half of an array. Taken to the extreme, we could push every char of a string as a separate event. The fundamental problem with these partial updates is that a downstream consumer can not tell if an update is complete. Do they wait? How long? Can they check if the data is done?. While this touches on a larger problem in distributed computing, I think we are shooting ourselves in the foot by making every piece of a single update an async, isolated event. Taken to the extreme, we could push every char of a string as a separate event. The proposal is to extend the PutMetadataAction to take in a Seq/Varargs of MetadataEvents with the contract that these will be made available atomically (e.g. in a single Slick transaction for our implementation). Then in places where we basically unrolling a bundle of events to publish, we should use this API (e.g. WorkflowExecutionActor) to do that atomically. . In theory, this should also help with the scalability as the MD service can persist things with batchinserts in single transaction. For larger workflows, currently this would be hundreds or thousands of transactions.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/930:1042,extend,extend,1042,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/930,1,['extend'],['extend']
Modifiability,"EDIT: Changed A/C to use default sentry style configuration, instead of wiring custom HOCON configs. **Issue:**; Whenever Cromwell generates a warning or error message an additional message is emitted from `raven-logback` about a ""suitable DSN"". ```; [2018-05-18 21:17:10,79] [warn] SingleWorkflowRunnerActor: received unexpected message: Done in state RunningSwraData; [2018-05-18 21:17:10,80] [warn] Couldn't find a suitable DSN, defaulting to a Noop one.; ```. This appears to be because `raven-logback` is activated in logback.xml but is not configured by default in Cromwell. **Background:**; [Sentry](https://sentry.io/) describes itself as:. > Open-source error tracking that helps developers monitor and fix crashes in real time. Cromwell is using an deprecated version of the Sentry java bindings for logback called `raven-logback`. The current bindings are called `sentry-logback`. Additionally, the cromwell docs currently mention that sentry can be setup via the ""configuration value"" `sentry.dsn`. https://github.com/broadinstitute/cromwell/blob/b8d3d2fd4a583d3e46394efb104005c12cdf182d/docs/Logging.md#L48. https://github.com/broadinstitute/cromwell/blob/b8d3d2fd4a583d3e46394efb104005c12cdf182d/docs/Configuring.md#L345-L355. This is not correct as `raven-logback` nor its underlying library `raven` use Typesafe Config. Instead for `raven` the value must be set as a system property, or alternatively as a different environment variable. However the latest `sentry` library (and transitively `sentry-logback`) do allow code configuration via `Sentry.init`. **A/C:**; - Replace `raven-logback` dependency with `sentry-logback`; - ~Allow setting a `cromwell.sentry.*` stanza with Cromwell specific sentry configuration. Alternative namespaces could be `sentry.*` or `system.sentry.*`, but both namespaces may collide with other library/application configurations in the future!~; - ~Wire the `cromwell.sentry.*` HOCON fields into `Sentry.init`~; - ~Default the sentry DSN in `reference.c",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3657:46,config,configuration,46,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3657,4,['config'],"['configs', 'configuration', 'configured']"
Modifiability,ERROR - Scopes not configured for service account,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3690:19,config,configured,19,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3690,1,['config'],['configured']
Modifiability,"Early access MVP version of the extractor script, to make sure the extractor, digester and comparer can all be singing from the same hymn sheet as soon as possible. Also to course correct as soon as possible if I've gone in completely the wrong direction, I guess. Featuring:; * Extraction and upload of:; * Workflow metadata; * Operations metadata (PAPI v2alpha1). Not yet implemented; coming soon in part 2 (or 3 (or ...)):; * Subworkflows; * Other operations metadata flavors; * Cromwell code dump upload; * Config dump upload. Especially interested in early feedback on:; * Coding styles (if we want to standardize on one for these scripts); * User interface (eg if you try to use it, is it intuitive?); * If I got the directory structure completely wrong. Changes I suspect might happen in subsequent PRs but I'm reluctant to make in this one-script MVP:; * This function could be re-used, can we extract it to a shared location?; * Could we use a data structure to store this type of information between scripts",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5485:511,Config,Config,511,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5485,1,['Config'],['Config']
Modifiability,"Enable Cromwell to emit statsd messages to a configurable host. It'd be awesome if this whole thing could be configurable on/off but if that's a pain it's not a big deal. The default host could be a non-existent UDP thing or something. The main key for this is the infrastructure, but some initial things to instrument. Things with lifetime counts are for creating a time series, e.g. ""how many of X happened in the last N time units"". - Lifetime count of submitted workflows; - Lifetime count of completed workflows; - Lifetime count of aborted workflows; - Current count of both pending & running workflows; - Lifetime count of retry events, e.g. GCS & PAPI; - Probably best broken up so GCS & PAPI separate if possible",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2467:45,config,configurable,45,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2467,2,['config'],['configurable']
Modifiability,Enable configuration of the temporary directory.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2657:7,config,configuration,7,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2657,1,['config'],['configuration']
Modifiability,Enable global workflow variables inside tasks,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2504:23,variab,variables,23,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2504,1,['variab'],['variables']
Modifiability,Enforce git secrets are configured before allowing development [BA-5810],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5060:24,config,configured,24,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5060,1,['config'],['configured']
Modifiability,Enhance Centaur to call outputs API,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2890:0,Enhance,Enhance,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2890,1,['Enhance'],['Enhance']
Modifiability,Enhance Cromwell reporting of Martha errors [WA-340],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5845:0,Enhance,Enhance,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5845,1,['Enhance'],['Enhance']
Modifiability,Enhance map errors,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4661:0,Enhance,Enhance,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4661,1,['Enhance'],['Enhance']
Modifiability,Enhance release WDL to create firecloud-develop PR,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4779:0,Enhance,Enhance,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4779,1,['Enhance'],['Enhance']
Modifiability,Enhanced logging around IO actions [BW-413],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5999:0,Enhance,Enhanced,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5999,1,['Enhance'],['Enhanced']
Modifiability,"Ensure GCS file systems use custom configuration.; When an exception/timeout occurs during asyncHashing, report it as a failure.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2512:35,config,configuration,35,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2512,1,['config'],['configuration']
Modifiability,Error handling when Service Registry fails to initialize (e.g. bad config),MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/896:67,config,config,67,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/896,1,['config'],['config']
Modifiability,"ExceptionInInitializerError; 	at cromwell.CromwellApp$.runCromwell(CromwellApp.scala:14); 	at cromwell.CromwellApp$.delayedEndpoint$cromwell$CromwellApp$1(CromwellApp.scala:25); 	at cromwell.CromwellApp$delayedInit$body.apply(CromwellApp.scala:3); 	at scala.Function0.apply$mcV$sp(Function0.scala:34); 	at scala.Function0.apply$mcV$sp$(Function0.scala:34); 	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:12); 	at scala.App.$anonfun$main$1$adapted(App.scala:76); 	at scala.collection.immutable.List.foreach(List.scala:389); 	at scala.App.main(App.scala:76); 	at scala.App.main$(App.scala:74); 	at cromwell.CromwellApp$.main(CromwellApp.scala:3); 	at cromwell.CromwellApp.main(CromwellApp.scala); Caused by: com.typesafe.config.ConfigException$Parse: /data/cephfs/punim0751/spartan.conf: 27: expecting a close parentheses ')' here, not: end of file; 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseError(ConfigDocumentParser.java:201); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseError(ConfigDocumentParser.java:197); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseKey(ConfigDocumentParser.java:279); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseObject(ConfigDocumentParser.java:450); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseValue(ConfigDocumentParser.java:247); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseObject(ConfigDocumentParser.java:458); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parse(ConfigDocumentParser.java:648); 	at com.typesafe.config.impl.ConfigDocumentParser.parse(ConfigDocumentParser.java:14); 	at com.typesafe.config.impl.Parseable.rawParseValue(Parseable.java:260); 	at com.typesafe.config.impl.Parseable.rawParseValue(Parseable.java:248); 	at com.typesafe.config.impl.Parseable.parseValue(Parseable.java:180); 	at com.typesafe.config.impl.Parseable.parseValue(Parseable.java:174); 	at com.types",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4549:1837,config,config,1837,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4549,1,['config'],['config']
Modifiability,Execution directory variable name,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7254:20,variab,variable,20,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7254,1,['variab'],['variable']
Modifiability,ExecutionActor.writeScriptContents$(BackgroundAsyncJobExecutionActor.scala:11); at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.writeScriptContents(ConfigAsyncJobExecutionActor.scala:200); at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.execute(SharedFileSystemAsyncJobExecutionActor.scala:158); at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.execute$(SharedFileSystemAsyncJobExecutionActor.scala:155); at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.execute(ConfigAsyncJobExecutionActor.scala:200); at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$executeAsync$1(StandardAsyncExecutionActor.scala:639); at scala.util.Try$.apply(Try.scala:209); at cromwell.backend.standard.StandardAsyncExecutionActor.executeAsync(StandardAsyncExecutionActor.scala:639); at cromwell.backend.standard.StandardAsyncExecutionActor.executeAsync$(StandardAsyncExecutionActor.scala:639); at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.executeAsync(ConfigAsyncJobExecutionActor.scala:200); at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover(StandardAsyncExecutionActor.scala:954); at cromwell.backend.standard.StandardAsyncExecutionActor.executeOrRecover$(StandardAsyncExecutionActor.scala:946); at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.executeOrRecover(ConfigAsyncJobExecutionActor.scala:200); at cromwell.backend.async.AsyncBackendJobExecutionActor.$anonfun$robustExecuteOrRecover$1(AsyncBackendJobExecutionActor.scala:65); at cromwell.core.retry.Retry$.withRetry(Retry.scala:38); at cromwell.core.retry.Retry$$anonfun$withRetry$1.$anonfun$applyOrElse$3(Retry.scala:45); at akka.pattern.FutureTimeoutSupport.liftedTree1$1(FutureTimeoutSupport.scala:26); at akka.pattern.FutureTimeoutSupport.$anonfun$after$1(FutureTimeoutSupport.scala:26); at akka.actor.Scheduler$$anon$4.run(Scheduler.scala:205); ... 6 more; Caused by: common.excepti,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5092:4927,config,config,4927,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5092,1,['config'],['config']
Modifiability,"Expand the ""docs-only"" matcher to include mkdocs.yml [BA-6138 enhancement]",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5394:62,enhance,enhancement,62,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5394,1,['enhance'],['enhancement']
Modifiability,Expression evaluator refactoring,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/174:21,refactor,refactoring,21,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/174,1,['refactor'],['refactoring']
Modifiability,Extend Array functionality to maps,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1962:0,Extend,Extend,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1962,1,['Extend'],['Extend']
Modifiability,Extend Lifecycle of Alpha Logs,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3894:0,Extend,Extend,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3894,1,['Extend'],['Extend']
Modifiability,Extend localization_optional to complex types (for least surprise),MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3771:0,Extend,Extend,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3771,1,['Extend'],['Extend']
Modifiability,Extend single call workflow execution to N-step execution. Closes #652.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/743:0,Extend,Extend,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/743,1,['Extend'],['Extend']
Modifiability,"Extending mcovarr's work in #6366 . Big shoutout to mcovarr!!!. [Per @mbookman]; This pull request is an initial update to address:. CROM-6718: FR: Add flag for minimizing chance of GCP cross-region network egress charges being incurred. This PR specifically focuses on the risks of egress charges incurred due to call caching. The framing of the approach here, which is a bit broader than originally noted in CROM-6718, is:; Make call caching location-aware, prioritizing copies that minimize egress charges.; Add a workflow option enabling control of what egress charges can be incurred for call cache copying.; The new workflow option would be:. call_cache_egress: [none, continental, global]. where the values affect whether call cache copies can incur egress charges:; none: only within-region copies are allowed, which generate no egress charges; continental: within content copies are allowed; within-content copies have reduced costs, such as $0.01 / GB in the US; global: copies across all regions are allowed. Cross-content egress charges can be much higher (ranging from $0.08 / GB up to $0.23 / GB). ### CURRENT STATUS OF PR:; With the changes in this PR, Cromwell successfully checks the location of the source and destination file to be copied, compares the location, and makes a decision of whether or not it should be copied based on the call_cache_egress option. If it should be copied, the files are copied as normal. If it should not be copied, the cache attempt fails and the workflow runs instead.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6369:0,Extend,Extending,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6369,2,['Extend'],['Extending']
Modifiability,Extractor uploads local Cromwell checkout and config to GCS [BA-6382],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5500:46,config,config,46,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5500,1,['config'],['config']
Modifiability,"FSM$class.akka$actor$FSM$$processMsg(FSM.scala:657); 	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:651); 	at akka.actor.Actor$class.aroundReceive(Actor.scala:496); 	at cromwell.engine.workflow.lifecycle.MaterializeWorkflowDescriptorActor.aroundReceive(MaterializeWorkflowDescriptorActor.scala:116); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:526); 	at akka.actor.ActorCell.invoke(ActorCell.scala:495); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257); 	at akka.dispatch.Mailbox.run(Mailbox.scala:224); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:234); 	at scala.concurrent.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107). [2017-05-25 12:18:24,94] [info] WorkflowManagerActor WorkflowActor-e52409b4-c85a-4285-9453-f47c6b0ae86c is in a terminal state: WorkflowFailedState; [2017-05-25 12:18:24,94] [info] Message [cromwell.subworkflowstore.SubWorkflowStoreActor$SubWorkflowStoreCompleteSuccess] from Actor[akka://cromwell-system/user/SingleWorkflowRunnerActor/$c#-297741123] to Actor[akka://cromwell-system/user/SingleWorkflowRunnerActor/WorkflowManagerActor/WorkflowActor-e52409b4-c85a-4285-9453-f47c6b0ae86c#772660809] was not delivered. [1] dead letters encountered. This logging can be turned off or adjusted with configuration settings 'akka.log-dead-letters' and 'akka.log-dead-letters-during-shutdown'.; [2017-05-25 12:18:26,88] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; Workflow e52409b4-c85a-4285-9453-f47c6b0ae86c transitioned to state Failed. I recognize the brackets are the problem, but the tutorial doesn't seem to offer suggestions on removing those. When I did remove them it seemed the key values in the json were the problem. Any help is greatly appreciated!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2296:3370,config,configuration,3370,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2296,1,['config'],['configuration']
Modifiability,"F_PREFIX,; in_cores=CORES,; in_disk=DISK,; in_mem=MEM; }. output {; File sample = reads_extraction_and_merging.fastq_file; File genotype = genome_inference.vcf_file; }; }. task reads_extraction_and_merging {; input {; String in_container_pangenie; File in_forward_fastq; File in_reverse_fastq; String in_label; Int in_cores; Int in_disk; Int in_mem; }; command <<<; cat ~{in_forward_fastq} ~{in_reverse_fastq} | pigz -dcp ~{in_cores} > ~{in_label}.fastq; >>>; output {; File fastq_file = ""~{in_label}.fastq""; }; runtime {; docker: in_container_pangenie; memory: in_mem + "" GB""; cpu: in_cores; disks: ""local-disk "" + in_disk + "" SSD""; }; }. task genome_inference {; input {; String in_container_pangenie; File in_reference_genome; File in_pangenome_vcf; String in_executable; File in_fastq_file; String prefix_vcf; Int in_cores; Int in_disk; Int in_mem; }; command <<<; echo ""vcf: ~{in_pangenome_vcf}"" > /app/pangenie/pipelines/run-from-callset/config.yaml; echo ""reference: ~{in_reference_genome}"" >> /app/pangenie/pipelines/run-from-callset/config.yaml; echo $'reads:\n sample: ~{in_fastq_file}' >> /app/pangenie/pipelines/run-from-callset/config.yaml; echo ""pangenie: ~{in_executable}"" >> /app/pangenie/pipelines/run-from-callset/config.yaml; echo ""outdir: /app/pangenie"" >> /app/pangenie/pipelines/run-from-callset/config.yaml; cd /app/pangenie/pipelines/run-from-callset; snakemake --cores ~{in_cores}; >>>; output {; File vcf_file = ""~{prefix_vcf}.vcf""; }; runtime {; docker: in_container_pangenie; memory: in_mem + "" GB""; cpu: in_cores; disks: ""local-disk "" + in_disk + "" SSD""; preemptible: 1 # can be useful for tools which execute sequential steps in a pipeline generating intermediate outputs; }; }; ```; **_Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL:_**; ![Screenshot from 2022-12-09 10-52-16](https://user-images.githubusercontent.com/98895614/206773588-2e8dbf89-03a9-4021-9495-42f2bc0b801d.png). Please help me out on how to set",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6966:3139,config,config,3139,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6966,1,['config'],['config']
Modifiability,Factory.java:1083); at com.typesafe.config.impl.SimpleIncluder.includeResourceWithoutFallback(SimpleIncluder.java:123); at com.typesafe.config.impl.SimpleIncluder.includeResources(SimpleIncluder.java:109); at com.typesafe.config.impl.ConfigParser$ParseContext.parseInclude(ConfigParser.java:181); at com.typesafe.config.impl.ConfigParser$ParseContext.parseObject(ConfigParser.java:237); at com.typesafe.config.impl.ConfigParser$ParseContext.parseValue(ConfigParser.java:103); at com.typesafe.config.impl.ConfigParser$ParseContext.parse(ConfigParser.java:415); at com.typesafe.config.impl.ConfigParser.parse(ConfigParser.java:25); at com.typesafe.config.impl.Parseable.rawParseValue(Parseable.java:263); at com.typesafe.config.impl.Parseable.rawParseValue(Parseable.java:250); at com.typesafe.config.impl.Parseable.parseValue(Parseable.java:180); at com.typesafe.config.impl.Parseable.parseValue(Parseable.java:174); at com.typesafe.config.impl.Parseable.parse(Parseable.java:301); at com.typesafe.config.ConfigFactory.parseFile(ConfigFactory.java:793); at com.typesafe.config.ConfigFactory.parseApplicationReplacement(ConfigFactory.java:1166); at com.typesafe.config.DefaultConfigLoadingStrategy.parseApplicationConfig(DefaultConfigLoadingStrategy.java:11); at com.typesafe.config.ConfigFactory.defaultApplication(ConfigFactory.java:532); at com.typesafe.config.ConfigFactory$1.call(ConfigFactory.java:264); at com.typesafe.config.ConfigFactory$1.call(ConfigFactory.java:261); at com.typesafe.config.impl.ConfigImpl$LoaderCache.getOrElseUpdate(ConfigImpl.java:66); at com.typesafe.config.impl.ConfigImpl.computeCachedConfig(ConfigImpl.java:93); at com.typesafe.config.ConfigFactory.load(ConfigFactory.java:261); at com.typesafe.config.ConfigFactory.load(ConfigFactory.java:237); at cromwell.languages.util.ImportResolver$HttpResolver$.apply(ImportResolver.scala:237); at womtool.input.WomGraphMaker$.importResolvers$lzycompute$1(WomGraphMaker.scala:28); at womtool.input.WomGraphMaker$.importResolvers,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7255:2288,config,config,2288,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7255,1,['config'],['config']
Modifiability,Failure to recognize variable declared in task call,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4048:21,variab,variable,21,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4048,1,['variab'],['variable']
Modifiability,Feature enhancements for AWS Backend,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3809:8,enhance,enhancements,8,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3809,1,['enhance'],['enhancements']
Modifiability,"Feedback from today's workshop: `womtool validate` uselessly prints a few newlines on successful exit. Various workshop participants thought:; 1. It should exit with no output to harmonize with Unix CLI tool conventions; 2. It should confirm success in a way that is obvious to users who are e.g. biologists first, programmers second. Either would be an improvement over the current state. cc @rmeffan @ndbolliger ; <!--; Hi! Thanks for taking the time to report feedback. Before posting an issue here, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're in the right place. -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4040:1125,config,configuration,1125,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4040,1,['config'],['configuration']
Modifiability,FileSystems available to the Engine for expression evaluation should be configurable,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/821:72,config,configurable,72,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/821,1,['config'],['configurable']
Modifiability,"Find the original post [here](http://gatkforums.broadinstitute.org/wdl/discussion/7690/running-in-server-mode-jobs-that-have-localization-error-become-immortal#latest). ---. **User Report**. Running cromwell in server mode, with default configuration in each case, I can reproduce the following behaviour in 0.18, 0.19 and 0.19_hotfix (HEAD):. Submit a workflow that has non-existent file as input to a task, e.g.:. ```; task BillyBob {; File bbInput; command { echo ""done"" }; }; workflow badLocalization {; call BillyBob { input: bbInput=""/foo/bar/baz"" }; }; ```. The server log shows ""Failures during localization"" error (below) - as expected initially, I guess - but then _repeats_ the error every 30 seconds or so, forever, and hitting the API `<workflowId>/status` endpoint shows the job in a ""Running"" state, forever. I would expect this error to cause the task, and then the workflow, to die. example of a single block of the server log error: . ```; 2016-05-27 11:08:57,269 cromwell-system-akka.actor.default-dispatcher-5 ERROR - Failures during localization; java.lang.UnsupportedOperationException: Could not localize /foo/bar/baz -> /home/conradL/cromwell-executions/badLocalization/8c7774be-7917-4c6a-88c4-55e495bbb9ec/call-BillyBob/foo/bar/baz; at cromwell.engine.backend.local.SharedFileSystem$$anonfun$localize$1$3.apply(SharedFileSystem.scala:243) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$$anonfun$localize$1$3.apply(SharedFileSystem.scala:243) ~[cromwell-0.19.jar:0.19]; at scala.Option.getOrElse(Option.scala:121) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.localize$1(SharedFileSystem.scala:242) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.adjustFile$1(SharedFileSystem.scala:264) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local.SharedFileSystem$class.localizeWdlValue(SharedFileSystem.scala:271) ~[cromwell-0.19.jar:0.19]; at cromwell.engine.backend.local",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/922:237,config,configuration,237,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/922,1,['config'],['configuration']
Modifiability,"Fix $Home variable, hotfix version",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3429:10,variab,variable,10,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3429,1,['variab'],['variable']
Modifiability,Fix Home environment variable,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3428:21,variab,variable,21,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3428,1,['variab'],['variable']
Modifiability,Fix PAPI v2 USA auth handling in config,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4566:33,config,config,33,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4566,1,['config'],['config']
Modifiability,Fix TES backend to load preemptible setting from configuration [BA-6004],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5270:49,config,configuration,49,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5270,1,['config'],['configuration']
Modifiability,Fix TES backend to load preemptible setting from configuration [BA-6004] [CI clone],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5314:49,config,configuration,49,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5314,1,['config'],['configuration']
Modifiability,Fix flakey test: EnhancedRhinoSandboxSpec,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4306:17,Enhance,EnhancedRhinoSandboxSpec,17,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4306,1,['Enhance'],['EnhancedRhinoSandboxSpec']
Modifiability,Fix member access on scatter variables,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3763:29,variab,variables,29,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3763,1,['variab'],['variables']
Modifiability,Fix nested ifs that use the same variable in their expressions,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3003:33,variab,variable,33,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3003,1,['variab'],['variable']
Modifiability,Fix papi config fix,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3730:9,config,config,9,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3730,1,['config'],['config']
Modifiability,Fix submit-docker to point to the right script in example configuration [BA-5689],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5015:58,config,configuration,58,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5015,1,['config'],['configuration']
Modifiability,Fix variable resolution to call outputs. Fixes #3176,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3181:4,variab,variable,4,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3181,1,['variab'],['variable']
Modifiability,Fixed PostgreSQL variable names BA-5764,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5046:17,variab,variable,17,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5046,1,['variab'],['variable']
Modifiability,Fixed `batch-size` config parameter name in `metadata-deletion` stanza for Carboniting [CROM-6229],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5969:19,config,config,19,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5969,1,['config'],['config']
Modifiability,"Fixes #4084 ; For singularity users it is nice that `dockerRoot` can be set, as they do not have control over which paths are available in the image and `/cromwell-executions` cannot be automatically created. Other paths could be used, BioContainers for example have a `/data` folder meant specifically for these use cases. But this requires dockerRoot to be configurable. The fallback value is still `/cromwell-executions` so nothing changes if the value is not specified in the config.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4088:359,config,configurable,359,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4088,2,['config'],"['config', 'configurable']"
Modifiability,"Fixes #4998. A bit of context: We have a cluster that works using SGE and it kills jobs that use too much VMEM. This means that any java jobs get sometimes randomly killed by the cluster. These jobs do not get a proper RC file because the cluster killed them. This meant that Cromwell would be waiting eternally for the RC file. Then my former colleague ffinfo created a new feature that assumed an externall kill of no RC file was found and the cluster reported the job as finished. #4112 . This code creates the exit file and reports the job as failed in this scenario. The comments implied he meant to put `137` in the RC file, as that is the exit code for SIGKILL (`kill -9`) but instead the code put the exit code `9` in there. This code was refactored by @cjllanwarne, and 9 was changed to a variable for the exit code: SIGTERM. Which made perfect sense. Unfortunately this broke some functionality. Jobs that are externally killed are no longer retried. This is because cromwell assumes that jobs with an exit code SIGINT(`130`), SIGKILL(`137`) or SIGTERM(`143`) are killed by cromwell, and should therefore not be restarted. This makes perfect sense. . This PR does not change the retry behaviour of cromwell. It does change the exit code for externally (not killed by cromwell!) jobs so these can be retried.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5003:747,refactor,refactored,747,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5003,2,"['refactor', 'variab']","['refactored', 'variable']"
Modifiability,Fixing https://github.com/broadinstitute/cromwell/issues/4050. While doing this I notice that this check alive command is not used at all. First did a restructure of the statuses and now there is also a status Running. - [x] Add timeout on `WaitingForReturnCode` step; - [x] Make timeout a config value. Meanwhile please give already feed on this of course ;),MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4112:290,config,config,290,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4112,1,['config'],['config']
Modifiability,Fixup perf configuration around statsd instrumentation [BA-4788 follow-up],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5024:11,config,configuration,11,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5024,1,['config'],['configuration']
Modifiability,"Flexible date times no longer work in the cromwell 0.20. (e.g. ""2016-06-20"" is no longer a valid date). Either update the README and notify customers of this change or revert to the flexible date time parser. On behalf of green team, Vivek votes for keeping the stricter date time parser.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1064:0,Flexible,Flexible,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1064,2,"['Flexible', 'flexible']","['Flexible', 'flexible']"
Modifiability,"Following on from the conversation at #4039, I've started a ""Getting started with Containers"" on the Cromwell docs. My thoughts are it might be a good place to put thoughts about containers, how they can be used and any caveats about them. This tutorial follows the [user goal](https://github.com/broadinstitute/cromwell/issues/2177#issuecomment-330341279) (from #2177):; > As a **user with images in Singularity**, I want **Cromwell to support using Singularity images (either via Singularity Hub and the command line, or connecting via API)**, so that I can **use Singularity images and not have to duplicate them in Docker**. However, without any code changes, just purely through configuration. . I think it's worth touching on using these container technologies with job schedulers, so I've included the ConfigurationFile and the HPCIntro tutorials as prerequisites.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4635:684,config,configuration,684,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4635,2,"['Config', 'config']","['ConfigurationFile', 'configuration']"
Modifiability,"Following the docs at https://github.com/broadinstitute/cromwell#runtime-attributes, I'd like to be able to pass runtime attributes as the inputs to a task, for example:; ```; task iRun {; String runtimeMemory; Int runtimeCpu; command {; echo ""so far away""; }; output {; String out = read_string(stdout()); }; runtime {; memory: runtimeMemory; #cpu: runtimeCpu; }; }; ```; When using a configurable backend, I can confirm this works for the String type attribute `memory` but not the Int type `cpu`: running the above with the cpu runtime attribute uncommented I get this in the logs:; ```; [ERROR] [11/24/2016 10:49:13.299] [cromwell-system-akka.dispatchers.engine-dispatcher-22] [akka://cromwell-system/user/cromwell-service/WorkflowManagerActor] WorkflowManagerActor Workflow beb03899-5f22-4f2c-8a85-d619a2d8a969 failed (during InitializingWorkflowState): java.lang.IllegalArgumentException: Task iRun has an invalid runtime attribute cpu = runtimeCpu; ```. My custom backend application.conf section: ; ```; PBS { ; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config { ; runtime-attributes = """"""; Int cpu = 1 ; Int memory_mb = 1000; String? pbs_email; String? pbs_queue; String pbs_walltime = ""1:00:00""; """"""; ...; }; }; ```. I thought it might be because of the special nature of the `cpu` runtime attribute, but I tested with a different custom runtime attribute `Int pbs_cpu` and got the same result, so my guess is that it's the Int type that is the problem. I am working around this by defining `String pbs_cpu` which is then interpreted as an expression in the runtime block, as documented, but it feels wrong because the value should really be validated as an Int.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1702:386,config,configurable,386,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1702,4,"['Config', 'config']","['ConfigBackendLifecycleActorFactory', 'config', 'configurable']"
Modifiability,"Following the pattern of the GCP metadata actor, these actors will send Cromwell metadata to both the metadata database as well as to AWS SNS pubsub service. By sending to SNS users can setup custom accessory behavior without needing to modify Cromwell by creating subscribers to the SNS topic. Example use cases are alerting users when jobs succeed (or fail), updating slack channels, tagging workflow output S3 objects with workflow metadata. By creating AWS Lambda function subscribers, very flexible event driven actions can be taken.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5748:495,flexible,flexible,495,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5748,1,['flexible'],['flexible']
Modifiability,"For `Object`s, `Map`s and `Pair`s, and perhaps `Array`s. Eg We need to be able to distinguish between `p.left`, accessing the left hand side of a pair, and `p.left` accessing the `left` output of a task called `p`. Make sure member access works for:; - [X] Maps; - [X] Arrays; - [x] Pairs; - ~~Objects~~ Not Supported (but it's no longer the member access bit holding us back)!. Then reinstate tests:; - [x] `scatter_chain`; - ~~`if_then_else_expressions`~~ Punted to #2860 ; - [X] `array_and_map_indexing` (enhanced!)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2861:508,enhance,enhanced,508,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2861,1,['enhance'],['enhanced']
Modifiability,"For any AWS backend config using temporary credentials (fargate, assume-roles, ec2 instances?) - obtaining the actual credentials needs to be delayed as long as possible so that long running tasks will use the providers ability to refresh. This PR just converts AwsAuthModes to hand out AwsCredentialProviders rather than AwsCredentials. . All the AWS Java SDK builders take credential providers as the basis for their client anyhow (builder.credentialsProvider(xxx)) . Unresolved in this PR is the use of 'options' as a parameter to the auth modes credentials() call - I could not work out what they were intended for. In general they were just passed in as (_ => """") but there may be some loss of functionality?",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5229:20,config,config,20,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5229,1,['config'],['config']
Modifiability,"For now at least, the implementation isn’t that big of a deal as long as it’s pushbutton GCP stuff. The goal is to store the JSON events coming out of PubSub as-is in a fashion that we can access them in the future as necessary. We don’t need efficient querying of these events but we do need the ability to easily get all the events associated with a workflow. Cloud Datastore seems like it’d work (for instance, kind being workflow ID and entity being the metadatum) but I don’t really know. We could also just do something like store these in a google bucket. Let’s not get too complicated here, the idea is to find something simple and verify that it’s feasible over time. Once this is squared away, enhance the application from #3244 to also dump the events **as-is** into this event store w/o modification.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3246:704,enhance,enhance,704,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3246,1,['enhance'],['enhance']
Modifiability,"For our CI testing we want to be able to set the location of the `cromwell-executions` folder. This can already be done by messing with the config file, but this is not ideal. The `root` setting is nested within `backend -> providers -> the-used-backend -> config -> root`. This is very hard to set using the command-line with the `-D` option. . Is there a possibility to set an option that is agnostic of background? `-Dbackends.default_root` for example? Or just on option to set it on the command-line `run --root my_preferred_root my_workflow.wdl`?",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3889:140,config,config,140,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3889,2,['config'],['config']
Modifiability,"For some reason Cromwell now makes jars for every subproject every time the `run` command is issued:. ```; computer:cromwell me$ sbt ""project server"" ""run server""; [info] Loading settings from plugins.sbt,swagger2markup.sbt ...; [info] Loading project definition from /Users/me/gitrepos/cromwell/project; [info] Loading settings from build.sbt ...; [info] Resolving key references (31064 settings) ...; [info] Set current project to root (in build file:/Users/me/gitrepos/cromwell/); [info] Set current project to cromwell (in build file:/Users/me/gitrepos/cromwell/); [info] Packaging /Users/me/gitrepos/cromwell/database/sql/target/scala-2.12/cromwell-database-sql_2.12-32-92c91d9-SNAP.jar ...; [info] Packaging /Users/me/gitrepos/cromwell/cromwellApiClient/target/scala-2.12/cromwell-api-client_2.12-32-92c91d9-SNAP.jar ...; [info] Done packaging.; [info] Packaging /Users/me/gitrepos/cromwell/common/target/scala-2.12/cromwell-common_2.12-32-92c91d9-SNAP.jar ...; ...; ```. This certainly isn't making the run launch any faster and clutters up the build directory with jars that makes it tough to find the Centaur CWL runner and Cromwell server jars needed for conformance testing.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3624:193,plugin,plugins,193,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3624,1,['plugin'],['plugins']
Modifiability,For those of us who like to use the centaur configs when running Cromwell locally,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5025:44,config,configs,44,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5025,1,['config'],['configs']
Modifiability,"For users just getting started with Cromwell, the documentation here:. https://github.com/broadinstitute/cromwell#getting-started-with-wdl. Points the user here:. https://github.com/broadinstitute/wdl#getting-started-with-wdl. and when you run your first workflow, you'll see in the output:. ```; [2016-04-14 16:21:12,82] [warn] Failed to get application default credentials; java.io.IOException: The Application Default Credentials are not available. They are available if running in Google Compute Engine. Otherwise, the environment variable GOOGLE_APPLICATION_CREDENTIALS must be defined pointing to a file defining the credentials. See https://developers.google.com/accounts/docs/application-default-credentials for more information.; at com.google.api.client.googleapis.auth.oauth2.DefaultCredentialProvider.getDefaultCredential(DefaultCredentialProvider.java:93); at com.google.api.client.googleapis.auth.oauth2.GoogleCredential.getApplicationDefault(GoogleCredential.java:213); at com.google.api.client.googleapis.auth.oauth2.GoogleCredential.getApplicationDefault(GoogleCredential.java:191); at cromwell.util.google.GoogleCredentialFactory.forApplicationDefaultCredentials(GoogleCredentialFactory.scala:125); at cromwell.util.google.GoogleCredentialFactory.fromCromwellAuthScheme$lzycompute(GoogleCredentialFactory.scala:64); at cromwell.util.google.GoogleCredentialFactory.fromCromwellAuthScheme(GoogleCredentialFactory.scala:61); at cromwell.engine.backend.io.filesystem.gcs.StorageFactory$$anonfun$cromwellAuthenticated$1.apply(StorageFactory.scala:20); at cromwell.engine.backend.io.filesystem.gcs.StorageFactory$$anonfun$cromwellAuthenticated$1.apply(StorageFactory.scala:20); at scala.util.Try$.apply(Try.scala:192); at cromwell.engine.backend.io.filesystem.gcs.StorageFactory$.cromwellAuthenticated$lzycompute(StorageFactory.scala:20); at cromwell.engine.backend.io.filesystem.gcs.StorageFactory$.cromwellAuthenticated(StorageFactory.scala:18); at cromwell.engine.backend.local.LocalBac",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/705:535,variab,variable,535,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/705,1,['variab'],['variable']
Modifiability,From investigation of https://broadinstitute.atlassian.net/browse/DSDEEPB-2736. We decided to have these values in the configuration but to keep them commented out so GotC can optionally tune these.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/442:119,config,configuration,119,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/442,1,['config'],['configuration']
Modifiability,"From looking at the behaviour of cromwell, I think it traverses the execution graph (is that what it's called, the order in which tasks are run?) breadth-first, (e.g. first perform trimming for all samples, then mapping for all samples, then genotyping, etc). For most workflows, different tasks will have different performance characteristics (trimming and mapping is read/write heavy, genotyping is mostly read/CPU intensive). Would it then not make sense to do a depth first traversal of the execution graph? That way, we will have the most diversity in performance characteristics for all running tasks, which should speed up the overall runtime (e.g. no fighting over harddisk time between two trimming tasks). As a secondary bonus, depth first will mean that all different tasks are run as soon as possible, so when there is an error in one of the later tasks this is revealed to the user much more quickly.; The drawback is that cromwell will then also stop running the early tasks that do not give an error, but IIRC that behaviour is configurable in the settings file.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2736:1043,config,configurable,1043,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2736,1,['config'],['configurable']
Modifiability,"Functionality is needed to stage data files to/from S3 on a per-task level. For the example WDL file:; ```; task copy_file {; String output_file; File input_file. command {; cp ${input_file} ${output_file}; }; runtime {; docker: ""ubuntu:latest""; }; }. workflow wf_copy_file {; call copy_file; }; ```; and corresponding `inputs.json`. ```json; {; ""wf_cop_file.copy_file.input_file"": ""s3://myBucket/hello.txt"",; ""wf_cop_file.copy_file.output_file"": ""greetings.txt""; }; ```. The workflow execution should be able to copy the input file from S3 to the working task directory, and copy the output file ""greetings.txt"" to the configured S3 bucket for writing logs and outputs. An example of files written to the output S3 bucket would be:. ```; # $WF_ID is the workflow identifier (e.g. ""E6D5143C-89BC-4823-AED7-2A6AE00A1C2B""); s3://cromwell-output-bucket/$WF_ID/copy_file/outputs/greetings.txt; s3://cromwell-output-bucket/$WF_ID/copy_file/wf_copy_file-rc.txt; s3://cromwell-output-bucket/$WF_ID/copy_file/wf_copy_file-stdout.txt; s3://cromwell-output-bucket/$WF_ID/copy_file/wf_copy_file-stderr.txt; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3804:620,config,configured,620,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3804,1,['config'],['configured']
Modifiability,"GOTC was running the test for staging PAPI (Pipelines API). This test is launching 50 Single Sample workflows at once and 4 of our workflows failed with this error.; ```; ""message"": ""429 Too Many Requests\n{\n \""code\"" : 429,\n \""errors\"" : [ {\n \""domain\"" : \""global\"",\n \""message\"" : \""Insufficient tokens for quota group and limit 'defaultUSER-100s' of service 'staging-genomics.sandbox.googleapis.com', using the limit by ID '628662467800@1088569555438'.\"",\n \""reason\"" : \""rateLimitExceeded\""\n } ],\n \""message\"" : \""Insufficient tokens for quota group and limit 'defaultUSER-100s' of service 'staging-genomics.sandbox.googleapis.com', using the limit by ID '628662467800@1088569555438'.\"",\n \""status\"" : \""RESOURCE_EXHAUSTED\""\n}""; ```. All 4 of the jobs that failed were non-premptible whereas there are preemptible jobs that ran into this error and just went from attempt 1 to attempt 2 or w/e. . I don't think we would want this error to count towards our attempt count and we definitely don't want it to fail non preemptible tasks. @kcibul for prioritization",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1763:384,sandbox,sandbox,384,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1763,2,['sandbox'],['sandbox']
Modifiability,"Generated from [this forum post](https://gatkforums.broadinstitute.org/wdl/discussion/13716/could-not-find-job-id-from-stdout-file-cromwell-with-an-unusual-backend#latest). It appears that the regex provided must match the entire stdout string in order to find the Job ID (from [CromwellAsyncJobExecutionActor.scala](https://github.com/broadinstitute/cromwell/blob/develop/supportedBackends/sfs/src/main/scala/cromwell/backend/impl/sfs/config/ConfigAsyncJobExecutionActor.scala#L223)):; ```scala; val jobIdRegex = configurationDescriptor.backendConfig.getString(JobIdRegexConfig).r; val output = stdout.contentAsString.stripLineEnd; output match {; case jobIdRegex(jobId) => StandardAsyncJob(jobId); ```. But per the forum post, sometimes the output is multi-line:; ```; #> cat /.../cromwell-executions/myWorkflow/33ee300a-782d-47ae-a1e9-35a494e8bf11/call-myTask/execution/stdout.submit; mxq_group_id=...; mxq_group_name=...; mxq_job_id=16988030; ```. This fails using what is, in my opinion, a correct regex in their configuration file: `job-id-regex = ""mxq_job_id=(\\d+)""`",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4436:436,config,config,436,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4436,4,"['Config', 'config']","['ConfigAsyncJobExecutionActor', 'config', 'configuration', 'configurationDescriptor']"
Modifiability,Get languages to come in from the configuration file rather than be statically known.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3195:34,config,configuration,34,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3195,1,['config'],['configuration']
Modifiability,"Give Centaur-managed Cromwell more time to restart and a custom exit code.; Publish artifacts again on each build tag.; Login to docker before trying to push images.; Functions using secure variables ensure that xtrace is not enabled, thus no longer need a subshell, thus do not need to be exported.; Artifactory and Docker Hub credentials added to vault.; Docker login can use environment variables or vault once dsde-toolbox is public.; Split setup_secure_environment into setup_common_environment and setup_secure_resources.; Sbt environment variables prefixed as CROMWELL_SBT_*.; Print out a warning instead of exiting when vault resources cannot be rendered when testing locally.; Minor updates for more consistent shell variable usage.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3661:190,variab,variables,190,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3661,4,['variab'],"['variable', 'variables']"
Modifiability,Global ftp config + doc,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4074:11,config,config,11,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4074,1,['config'],['config']
Modifiability,Goals of these changes:; 1. Support configurable default docker container working dir for cases where dockerWorkingDir is not defined in runtime attributes.; 2. Support configurable default docker container output dir for cases where dockerOutputDir is not defined in runtime attributes.; 3. Be able to mount working directories for cases where a tool creates intermediate results (big files) in order to produce final output in the node FS and this is not capable to handle those file sizes.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1471:36,config,configurable,36,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1471,2,['config'],['configurable']
Modifiability,"Google configuration; google {. application-name = ""cromwell-demo"". auths = [; {; name = ""application-default""; scheme = ""application_default""; },; {; name = ""service-account""; scheme = ""service_account""; service-account-id = ""***@***.gserviceaccount.com""; json-file = ""/***/***.json""; }; ]; }. # Here is where you can define the backend providers that Cromwell understands.; # The default is a local provider.; # To add additional backend providers, you should copy paste additional backends; # of interest that you can find in the cromwell.example.backends folder; # folder at https://www.github.com/broadinstitute/cromwell; # Other backend providers include SGE, SLURM, Docker, udocker, Singularity. etc.; # Don't forget you will need to customize them for your particular use case.; backend {; # Override the default backend.; default = ""PAPIv2"". # The list of providers.; providers {; PAPIv2 {; actor-factory = ""cromwell.backend.google.pipelines.v2beta.PipelinesApiLifecycleActorFactory""; config {; # Google project; project = ""***-***"". # Base bucket for workflow executions; root = ""gs://*****/cromwell-execution"". # Make the name of the backend used for call caching purposes insensitive to the PAPI version.; name-for-call-caching-purposes: PAPI. # Emit a warning if jobs last longer than this amount of time. This might indicate that something got stuck in PAPI.; slow-job-warning-time: 24 hours. # Set this to the lower of the two values ""Queries per 100 seconds"" and ""Queries per 100 seconds per user"" for; # your project.; #; # Used to help determine maximum throughput to the Google Genomics API. Setting this value too low will; # cause a drop in performance. Setting this value too high will cause QPS based locks from Google.; # 1000 is the default ""Queries per 100 seconds per user"", 50000 is the default ""Queries per 100 seconds""; # See https://cloud.google.com/genomics/quotas for more information; genomics-api-queries-per-100-seconds = 10000. # Polling for completion backs-off ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6469:10588,config,config,10588,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6469,1,['config'],['config']
Modifiability,"Green team is seeing many errors detailed [here](https://partnerissuetracker.corp.google.com/issues/122571609):. The workaround is:. >... cromwell should migrate to pipelines-io, but in the meantime, if you want to make a quick fix for this you can do:. ` rm -f $HOME/.config/gcloud/gce`. > immediately before invoking gsutil inside your retry loop. This would save approximately 10% of the failures being seen in Green Team efforts per @tbl3rd and the bug",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4641:269,config,config,269,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4641,1,['config'],['config']
Modifiability,"Gull away. There are things here that need discussion, in particular `WdlTask#instantiateCommand` that is called only by tests and ""example"" code. Also I'm not sure how to properly honor initialized optionals for the config backend; I'm currently forcing in `none` defaults since if I don't expression evaluation with uninitialized optionals blows up.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2942:217,config,config,217,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2942,1,['config'],['config']
Modifiability,"HANGELOG.markdown) - [Changelog](https://bitbucket.org/asomov/snakeyaml/src/master/CHANGELOG.rst) - [Changelog](https://bitbucket.org/asomov/snakeyaml/src/master/Changelog.md) - [Changelog](https://bitbucket.org/asomov/snakeyaml/src/master/Changelog.markdown) - [Changelog](https://bitbucket.org/asomov/snakeyaml/src/master/Changelog.rst) - [Changelog](https://bitbucket.org/asomov/snakeyaml/src/master/changelog.md) - [Changelog](https://bitbucket.org/asomov/snakeyaml/src/master/changelog.markdown) - [Changelog](https://bitbucket.org/asomov/snakeyaml/src/master/changelog.rst) - [Changelog](https://bitbucket.org/asomov/snakeyaml/src/master/CHANGES.md) - [Changelog](https://bitbucket.org/asomov/snakeyaml/src/master/CHANGES.markdown) - [Changelog](https://bitbucket.org/asomov/snakeyaml/src/master/CHANGES.rst). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/b48aba70ec793405c98788a322d160987ba51d3e/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Files still referring to the old version number</summary>. The following files still refer to the old version number (1.27).; You might want to review and update them manually.; ```; dockerHashing/src/main/scala/cromwell/docker/local/DockerCliClient.scala; docs/developers/bitesize/ci/CaaS_DEV_CD.svg; scripts/metadata_comparison/test/resources/comparer/version3_comparison_good.csv; ```; </details>; <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""org.yaml"", artifactId = ""snakeyaml"" } ]; ```; </details>. labels: test-library-update, old-version-remains",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6281:2287,Config,Configure,2287,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6281,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,Have our config instructions match what we tell people,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2058:9,config,config,9,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2058,1,['config'],['config']
Modifiability,"Having default runtime attributes in jes config caused faulty WARN messages about ""Unrecognized configuration key(s) for Jes"". This PR should fix those.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3662:41,config,config,41,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3662,2,['config'],"['config', 'configuration']"
Modifiability,Heads up on the job store database refactor [BA-6199],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5397:35,refactor,refactor,35,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5397,1,['refactor'],['refactor']
Modifiability,"Hello Cromwell People, . Currently I believe Cromwell has retry logic for I/O issues or preemptible VMs issues for Google Cloud,. However, when Cromwell jobs that are executed via GridEngine dispatcher will fail with no re-try if the return code is deemed as a error code,. I am submitting a potential patch where Cromwell can retry failed jobs running on GridEngine with user specified retries (""backend.max-job-retries""), . I'm not sure how the configurations should be organized but here is my starting point; let me know what you guys think. Thanks,; Paul",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2176:447,config,configurations,447,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2176,1,['config'],['configurations']
Modifiability,"Hello I am trying to re-use an existing workflow for Mutect2 available here: https://app.terra.bio/#workspaces/terra-outreach/CHIP-Detection-Mutect2 to run on SLURM with Singularity configuration. There are multiple steps similar to Mutect2 public workflow available here: https://github.com/broadinstitute/gatk/blob/master/scripts/mutect2_wdl/mutect2.wdl , but still attaching the modified WDL with additional steps. . So when we run this with the given configuration using the following; export SINGULARITY_CACHEDIR=$PWD/singularity_cache; export SINGULARITY_TMPDIR=$PWD/tmpdir; module load singularity; rm -rf nohup.out && nohup java -Dconfig.file=$PWD/cromwell_singularity.conf -jar $PWD/cromwell-84.jar run $PWD/mutect2_modified.wdl --inputs $PWD/inputs.json &. The issue is that the first step of splitting intervals runs fine, but as it starts mutect2, it starts copying of the complete execution directory making here is the directory structure. cromwell-executions/; └── Mutect2; └── e5769b79-5e02-44a5-a4f8-38745e152beb; ├── call-M2; │ └── shard-0; │ ├── execution; │ └── inputs; │ ├── -1816294717; │ ├── 1855713868; │ │ └── run_cromwell_only.tmp; │ │ └── cromwell-executions; │ │ └── Mutect2; │ │ └── e5769b79-5e02-44a5-a4f8-38745e152beb; │ ├── 2035192126; │ └── 891763929; └── call-SplitIntervals; ├── execution; │ ├── glob-0fc990c5ca95eebc97c4c204e3e303e1; │ └── interval-files; ├── inputs; │ └── -1816294717; └── tmp.c9d96672. As you can see that run_cromwell_only.tmp is being made and that happens to fall in an endless loop and eventually, it errors stating the file name is too long to copy. Can you help me how to avoid this behavior of making circular paths when copying files for execution? Also, note it does not happen in the first step of SplitIntervals but happens in the Mutect2 call. [mutect2_gatk.wdl.txt](https://github.com/broadinstitute/cromwell/files/9813528/mutect2_gatk.wdl.txt); [cromwell_singularity.conf.txt](https://github.com/broadinstitute/cromwell/files/981352",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6934:182,config,configuration,182,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6934,2,['config'],['configuration']
Modifiability,"Hello cromwell dev team,. I'm currently working with the reference-disks option using GCPBatch as my backend. I executed the create_images.sh script from the documentation (https://cromwell.readthedocs.io/en/develop/backends/GCPBatch/) to generate my reference-disk-localization-manifests. I'm also using Cromwell v87, as specified in the same documentation. I also tested with the current `develop` build. While the manifest is correctly configured in the Cromwell config, and the reference disk appears to be mounting successfully, I’m encountering a failure with the umount command. I’m not sure why this command is being invoked in the first place. Mount Image; <img width=""573"" alt=""Screenshot 2024-09-26 at 16 07 46"" src=""https://github.com/user-attachments/assets/ce43be4a-132b-4c87-a27d-718a376171f7"">. **Error Message:**; ```; severity: ""DEFAULT""; textPayload: ""umount: /mnt/2d49bcb009113835140d638a10b535af: no mount point specified.""; timestamp: ""2024-09-26T14:07:54.88114; ```. Below is an example of what I have included in my Cromwell configuration (cromwell.conf). . ```; reference-disk-localization-manifests = [; {; ""imageIdentifier"" : ""projects/private-test-cromwell/global/images/omics-reference-disk-image"",; ""diskSizeGb"" : 10,; ""files"" : [ ; {; ""path"" : ""test-cromwell-references/hg38/v0/Homo_sapiens_assembly38.dict"",; ""crc32c"" : 2158779318; },; {; ""path"" : ""test-cromwell-references/hg38/v0/Homo_sapiens_assembly38.fasta"",; ""crc32c"" : 420322484; },; {; ""path"" : ""test-cromwell-references/hg38/v0/Homo_sapiens_assembly38.fasta.fai"",; ""crc32c"" : 1970999569; }; ]; }; ]; ```. @mcovarr and @aednichols, I have seen issue [#7502](https://github.com/broadinstitute/cromwell/pull/7502)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7548:439,config,configured,439,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7548,3,['config'],"['config', 'configuration', 'configured']"
Modifiability,"Hello! I am trying to create a submit-docker block for use with docker containers, according to instructions from [here](https://cromwell.readthedocs.io/en/stable/tutorials/Containers/). This is the how my config block looks:. ```; SLURM {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; runtime-attributes = """"""; Int runtime_minutes = 600; Int cpu = 1; Int requested_memory_mb_per_core = 8000; Int memory_mb = 4000; String queue = ""short""; String? docker; """""". submit = """"""; sbatch -J ${job_name} -D ${cwd} -o ${out} -e ${err} -t ${runtime_minutes} -p ${queue} \; ${""-c "" + cpu} \; --mem ${memory_mb} \; --wrap ""/bin/bash ${script}""; """"""; ; submit-docker = """"""; docker pull ${docker}. sbatch -J ${job_name} -D ${cwd} -o ${cwd}/execution/stdout -e ${cwd}/execution/stderr -t ${runtime_minutes} -p ${queue} \; ${""-c "" + cpu} \; --mem ${memory_mb} \; --wrap ""docker run -v ${cwd}:${docker_cwd} ${docker} ${job_shell} ${script}""; """""". kill = ""scancel ${job_id}""; check-alive = ""squeue -j ${job_id}""; job-id-regex = ""Submitted batch job (\\d+).*""; }; ```; But, I get an error from each node:. /bin/bash: /data/og/wgs/cromwell-executions/HaplotypeCallerGvcf_GATK4/98c2fe18-92b7-49d4-b490-623ed61e3dfc/call-HaplotypeCaller/shard-41/execution/script: No such file or directory. As far as I can tell, it is trying to reach the script local on the main machine, and not in the docker container. Is this expected behavior, or am I missing something? I know I can replace ${script} with ${docker_cwd}/execution/script but I am unsure why I need this change that is not according to your documentation. Thanks!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5768:206,config,config,206,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5768,4,"['Config', 'config']","['ConfigBackendLifecycleActorFactory', 'config']"
Modifiability,"Hello, I am running Cromwell 36 configured with the GCS/JES backend to run jobs on GCP. When running massive batches of workflows, I frequently encounter the IP-address quota from Google. To avoid this, I've reconfigured my default VPC to allow private google access (see #1325). I've added the following to my Cromwell configuration (other unrelated configuration entries removed):; ```; backend {; default = ""JES""; providers {; JES {; actor-factory = ""cromwell.backend.google.pipelines.v2alpha1.PipelinesApiLifecycleActorFactory""; config {; default-runtime-attributes {; noAddress: true; }; }; }; }; }; ```. This appears to have the desired effect, as my instances are now launching without an external IP, however, the jobs end up failing because docker cannot fetch the image `stedolan/jq` (as it resides on docker hub). Is there a way to configure Cromwell to use a different image for that pipeline action?. I could reconfigure the VPC to allow access to docker(hub), but that would require connecting a NAT instance which would increase the cost of using Cromwell. ---. Edit: Cromwell 36. Sorry!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4676:32,config,configured,32,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4676,5,['config'],"['config', 'configuration', 'configure', 'configured']"
Modifiability,"Hello, I am trying to deploy and use cromwell as a docker swarm stack and I have some serious problems with it. ; My configuration that I have in production is [https://github.com/antonkulaga/cromwell-client/blob/master/services/pipelines.yml](https://github.com/antonkulaga/cromwell-client/blob/master/services/pipelines.yml) where I have /pipelines folder (with cromwell-executions and data/mysql folders inside of it); As current broad container does not have docker inside (and thus cannot spawn tasks with docker runtimes) I had to:; * make a custom cromwell container that inherits from the official one and contains docker ( https://github.com/antonkulaga/cromwell-client/tree/master/services/cromwell ); * use ; ```yml; volumes:; - /var/run/docker.sock:/var/run/docker.sock; ```; trick, to spawn docker containers as sibling to cromwell container.; Unfortunately when running this setup I discovered that when I configure cromwell execution directory to an absolute path, like ""/pipelines/cromwell-executions"" the the script file that was generated by cromwell for each task still used /cromwell-executions I had to mount an extra volume to /cromwell-executions to trick it.; The other problem is that it constantly having errors like this:; ```; Workflow failed. WorkflowFailure(Unable to determine that 190 is alive, and /pipelines/cromwell-executions/vsearch/1ab35317-b0ae-4e7b-8b09-3403cdaff125/call-global_search/execution/rc does not exist.,List()); ```; while rc file does exist (checked it both on host system and volume). My bet is that it is somehow related with having cromwell inside docker.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3910:117,config,configuration,117,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3910,3,"['config', 'inherit']","['configuration', 'configure', 'inherits']"
Modifiability,"Hello, and apologies if this is not the correct place for this query. Cromwell engine version 46. We are currently looking at a Proof of Concept with Cromwell and AWS batch.; We trying to understand the **CallCaching** trigger(s), as we require this if the next step in a multi-step workflow breaks. Currently, we have set up the in-memory version and are not using any form of database. We have added the following to the configuration file:; `call-caching {; enabled = true; invalidate-bad-cache-results = true; }`. **Question 1.**. Can call caching be initiated if there is only the in-memory database, as below is not clear regarding this?; _""Cromwell's call cache is maintained in its database. In order for call caching to be used on any previously run jobs, it is best to configure Cromwell to point to a MySQL database instead of the default in-memory database. This way any invocation of Cromwell (either with run or server subcommands) will be able to utilize results from all calls that are in that database.""_. Secondly, if this can. **Question 2.**. Can call caching be initiated if a scatter, wraps a workflow, which then wraps tools.; Or will the entire workflow need to be in one script? (I have attached an example as zip); And, the options file.; [DsTrim - Broken.zip](https://github.com/broadinstitute/cromwell/files/3842334/DsTrim.-.Broken.zip). **Question 3.**. What exactly triggers callcaching to change from ""CallCachingOff"" to on, in the following result?; `; ""callCaching"": {; ""effectiveCallCachingMode"": ""CallCachingOff"",; ""allowResultReuse"": false,; ""hit"": false,; ""result"": ""Cache Miss""; },`. **If the in-memory is the issue, then please close and we will set-up a UAT correctly.; If not any additional assistance or comments will be most apprecitated.** . ###; ### IMPORTANT: Please file new issues over in our Jira issue tracker!; ###; ### https://broadworkbench.atlassian.net/projects/BA/issues; ###; ### You may need to create an account before you can view/create iss",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5280:423,config,configuration,423,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5280,2,['config'],"['configuration', 'configure']"
Modifiability,"Hello,. I am new to cromwell and trying to run a test workflow on GPC. I am using the PAPIv2 backend and here is my config:; ```; $ cat genomics.conf | grep -v '#' | sed '/^$/d'; include required(classpath(""application"")); google {; application-name = ""cromwell""; auths = [; {; name = ""application-default""; scheme = ""application_default""; }; ]; }; engine {; filesystems {; gcs {; auth = ""application-default""; project = ""xxxxx""; }; }; }; backend {; default = PAPIv2; providers {; PAPIv2 {; actor-factory = ""cromwell.backend.google.pipelines.v2alpha1.PipelinesApiLifecycleActorFactory""; config {; project = ""xxxxx""; root = ""gs://xxxx/cromwell_execution""; virtual-private-cloud {; network-label-key = ""xxx""; subnetwork-label-key = ""xxx""; auth = ""application-default""; }; name-for-call-caching-purposes: PAPI; slow-job-warning-time: ""24 hours""; genomics-api-queries-per-100-seconds = 1000; maximum-polling-interval = 600; request-workers = 3; genomics {; auth = ""application-default""; endpoint-url = ""https://genomics.googleapis.com/""; location = ""us-west1""; restrict-metadata-access = false; localization-attempts = 3; parallel-composite-upload-threshold=""150M""; }; filesystems {; gcs {; auth = ""application-default""; project = ""xxxx""; caching {; duplication-strategy = ""copy""; }; }; http { }; }; default-runtime-attributes {; cpu: 1; failOnStderr: false; continueOnReturnCode: 0; memory: ""2048 MB""; bootDiskSizeGb: 10; disks: ""local-disk 10 SSD""; noAddress: false; preemptible: 0; zones: [""us-west1-a"", ""us-west1-b""]; }; include ""papi_v2_reference_image_manifest.conf""; }; }; }; }; ```; When I run with the above config using:; ```; java -Dconfig.file=genomics.conf -jar cromwell-66.jar run cumulus.wdl -i cumulus_inputs.json; ```; I am getting the following error message:; ```; [2021-08-24 22:05:33,60] [info] WorkflowManagerActor: Workflow 6cc303b4-295d-49fa-a996-b5cf7ec9beea failed (during ExecutingWorkflowState): java.lang.Exception: Task cumulus.cluster:NA:1 failed. The job was stopped before",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6477:116,config,config,116,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6477,2,['config'],['config']
Modifiability,"Hello,. I am trying to use our on premise cromwell instance to submit jobs to GCP via the genomics api. I seem to have everything working except the VPC network name. We have a naming convention for the VPC network names configured in our GCP project and don't have the flexibility to change the name. However, cromwell seems to expect the VPC network name to be ""default"" and this does not seem to be configurable. Here is the error I am receiving when trying to submit the workflow:. [error] WorkflowManagerActor Workflow 8f55bf4d-9389-40e6-a469-dbd434394dd8 failed (during ExecutingWorkflowState): java.lang.Exception: Task wf_hello.hello:NA:1 failed. The job was stopped before the command finished. PAPI error code 3. Invalid value for field 'resource.networkInterfaces[0].network': 'https://www.googleapis.com/compute/v1/projects/projectxyz/global/networks/default'. The referenced network resource cannot be found. Is there a way for me to pass a different network name? If not, where can I request this feature be added to a future version?. Thanks!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4005:221,config,configured,221,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4005,2,['config'],"['configurable', 'configured']"
Modifiability,"Hello,. I wonder if it is possible to specify the GCP Batch task scheduling policy via Cromwell configuration. In specific, can I set `taskCountPerNode` to be `1` to enforce one job per VM (as in https://cloud.google.com/batch/docs/reference/rest/v1/projects.locations.jobs#taskgroup)?. Sincerely,; Yiming. <!--; Hi! Thanks for taking the time to report feedback. Please check whether your question is already answered in our:; Documentation http://cromwell.readthedocs.io/en/develop/; Bioinformatics Stack Exchange https://bioinformatics.stackexchange.com/search?q=cromwell; Slack https://join.slack.com/t/cromwellhq/shared_invite/zt-dxmmrtye-JHxwKE53rfKE_ZWdOHIB4g; -->. <!-- Are you seeing something that looks like a bug? Please attach as much information as possible. -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7521:96,config,configuration,96,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7521,2,['config'],['configuration']
Modifiability,"Hello,. I'm running a Cromwell service as Google Cloud VM instance. The Cromwell's version is 68, with the following conf:. ```; include required(classpath(""application"")). webservice {; interface = xx.xxx.xxx.xx; port = xxxx; }. google {; application-name = ""cromwell""; auths = [; {; name = ""application-default""; scheme = ""application_default""; }; ]; }. engine {; filesystems {; gcs {; auth = ""application-default""; project = ""gred-cumulus-sb-01-991a49c4""; }. }; }. workflow-options {; workflow-log-temporary = false; }. call-caching {; enabled = true; invalidate-bad-cache-results = true; }. database {; profile = ""slick.jdbc.MySQLProfile$""; db {; driver = ""com.mysql.cj.jdbc.Driver""; 	url = ""jdbc:mysql://localhost/cromwell?rewriteBatchedStatements=true""; 	user = ""root""; 	password = ""cromwell""; 	connectionTimeout = 5000; }; }. backend {; default = PAPIv2. providers {; PAPIv2 {; actor-factory = ""cromwell.backend.google.pipelines.v2alpha1.PipelinesApiLifecycleActorFactory""; config {; # Google project; project = ""gred-cumulus-sb-01-991a49c4"". # Base bucket for workflow executions; root = ""gs://gred-cumulus-output/cromwell_execution"". virtual-private-cloud {; network-label-key = ""my-private-network""; subnetwork-label-key = ""my-private-subnetwork""; auth = ""application-default""; }. # Make the name of the backend used for call caching purposes insensitive to the PAPI version.; name-for-call-caching-purposes: PAPI. # Emit a warning if jobs last longer than this amount of time. This might indicate that something got stuck in PAPI.; slow-job-warning-time: ""24 hours"". # Set this to the lower of the two values ""Queries per 100 seconds"" and ""Queries per 100 seconds per user"" for; # your project.; #; # Used to help determine maximum throughput to the Google Genomics API. Setting this value too low will; # cause a drop in performance. Setting this value too high will cause QPS based locks from Google.; # 1000 is the default ""Queries per 100 seconds per user"", 50000 is the default ""Querie",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6506:728,rewrite,rewriteBatchedStatements,728,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6506,2,"['config', 'rewrite']","['config', 'rewriteBatchedStatements']"
Modifiability,"Hello,. I'm seeing this error with glob. Looks like the glob-xxx.list file is not create for some reason. The file it's looking for has a couple commas (,) in them, could that be the issue?. wdl: /humgen/gsa-hpprojects/dev/tsato/palantir/Analysis/451_MedicallyRelevantCoverageWorkflow/medically-relevant-coverage.wdl.copy; json: /humgen/gsa-hpprojects/dev/tsato/palantir/Analysis/451_MedicallyRelevantCoverageWorkflow/medically-relevant-coverage.json; cromwell server: gsa5:8003 (configured for SGE); metadata: http://gsa5:8003/api/workflows/v2/e97e55f5-f0e0-42dd-9a7d-ae4edd66dc19/metadata?expandSubWorkflows=false. ""message"": ""Failed to evaluate outputs.: Could not evaluate GetHSMetrics.per_target_coverage = glob(\""*.per_target_coverage\"")[0]\n\tFile not found /humgen/gsa-hpprojects/dev/tsato/wdl/cromwell-executions/MedicallyRelevantCoverage/e97e55f5-f0e0-42dd-9a7d-ae4edd66dc19/call-GetHSMetrics/shard-1/execution/glob-66c7ddc0219653b72a61bd2dae8bb454.list""",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1980:480,config,configured,480,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1980,1,['config'],['configured']
Modifiability,"Hello,. I'm trying to connect cromwell with Gloud life science (v2beta) everything works as it should except for the problem that it takes almost 3 minutes to complete a simple hello world task. I am using the config file recommended by the documentation to run. . I would like to ask for advice on how to solve this problem. ; Thank you a lot. config file:. ```; google {. application-name = ""xxxxx-xxxxx"". auths = [; {; name = ""application-default""; scheme = ""application_default""; },; {; name = ""xxxxx-xxxxx""; scheme = ""service_account""; service-account-id = ""xxxxx@xxxxx-xxxxx.iam.gserviceaccount.com""; pem-file = ""/xxxxx/xxxxx.pem""; },; {; name = ""user-service-account""; scheme = ""user_service_account""; }; ]; }. backend {; default = PAPIv2. providers {; PAPIv2 {; actor-factory = ""cromwell.backend.google.pipelines.v2beta.PipelinesApiLifecycleActorFactory""; config {; # Google project; project = ""xxxxx-cromwell"". # Base bucket for workflow executions; root = ""gs://xxxxx-cromwell_bucket"". # Make the name of the backend used for call caching purposes insensitive to the PAPI version.; name-for-call-caching-purposes: PAPI. # Emit a warning if jobs last longer than this amount of time. This might indicate that something got stuck in PAPI.; slow-job-warning-time: 24 hours. # Set this to the lower of the two values ""Queries per 100 seconds"" and ""Queries per 100 seconds per user"" for; # your project.; #; # Used to help determine maximum throughput to the Google Genomics API. Setting this value too low will; # cause a drop in performance. Setting this value too high will cause QPS based locks from Google.; # 1000 is the default ""Queries per 100 seconds per user"", 50000 is the default ""Queries per 100 seconds""; # See https://cloud.google.com/genomics/quotas for more information; genomics-api-queries-per-100-seconds = 25000. # Polling for completion backs-off gradually for slower-running jobs.; # This is the maximum polling interval (in seconds):; maximum-polling-interval = 600. # Opt",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6462:210,config,config,210,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6462,3,['config'],['config']
Modifiability,"Hello,. I'm wondering if cromwell has support for loading environment modules somehow? I need to port the same workflow between AWS (so, the docker runtime attribute is handy) and a slurm cluster (which uses module environment). Can they be specified as a runtime parameter for example? Can they be part of the configuration file to cromwell? If yes, any suggestions as to how?. Thank you, ; Azza",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4997:311,config,configuration,311,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4997,1,['config'],['configuration']
Modifiability,"Hello,. It seems to me that cromwell (at least `cromwell-37.jar`) can run `version 1.0` WDL scripts. Would you confirm this? It would also be helpful if you had this info readily on the ReadTheDocs page (https://github.com/broadinstitute/cromwell/blob/develop/docs/LanguageSupport.md). Thank you,; Azza . <!--; Hi! Thanks for taking the time to report feedback. Before posting an issue here, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're in the right place. -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4678:1014,config,configuration,1014,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4678,1,['config'],['configuration']
Modifiability,"Hello,. when I try to run my workflow using a config file using. `$ java -Dconfig.file=../config/LSF.conf cromwell.jar cromwell run ../pipelines/bismark_pid.wdl -i ../pipelines/bismark_wgbs_pid.json`. I get the following message; ```; Error: Could not find or load main class cromwell.jar; Caused by: java.lang.ClassNotFoundException: cromwell.jar; ```. Without specifying a config file, the pipeline runs without any problems. ; I installed Cromwell (version 79) using conda. I also tried the following:. `$ java -Dconfig.file=../config/LSF.conf cromwell-79.jar run ../pipelines/bismark_pid.wdl -i ../pipelines/bismark_wgbs_pid.json `. ```; Error: Could not find or load main class cromwell-79.jar; Caused by: java.lang.ClassNotFoundException: cromwell-79.jar; ```. I also checked where the cromwell.jar file is saved in my conda environment and tried the following:. `; java -Dconfig.file=./LSF.conf /path/to/env/share/cromwell/cromwell.jar cromwell run ../pipelines/bismark_pid.wdl -i ../pipelines/bismark_wgbs_pid.json `. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->. This is the config file LSF.config:; ```; include required(classpath(""application"")). backend {. # Override the default backend.; default = LSF. # The list of providers. Copy paste the contents of a backend provider in this section; providers {; LSF {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; 	submit = ""bsub -J ${job_name} -cwd ${cwd} -o ${out} -e ${err} /usr/bin/env bash ${script}""; kill = ""bkill ${job_id}""; check-alive = ""bjobs ${job_id}""; job-id-regex = ""Job <(\\d+)>.*""; }; }; # Second backend provider would be copy pasted here!. }; }; ```. I have not much experienced with cromwell and would be very grateful for help. Thank you,; Johannes",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6796:46,config,config,46,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6796,10,"['Config', 'config']","['ConfigBackendLifecycleActorFactory', 'config', 'configuration']"
Modifiability,"Hello. Here is the simple example of workflow with optional input: . ```; workflow wf {; String? inn; call tsk_grep { input: input_381012639=inn }; }. task tsk_grep {; String? input_381012639; command { ps aux | grep j${""a"" + input_381012639}; }; }; ```. When i do not specify any input for workflow(json file below):. ```; {; }; ```. i get an the error:; `wdl4s.WdlExpressionException: Could not resolve inn as a scatter variable, namespace, call, or declaration`. But when my workflow looks like this:. ```; workflow wf {; call tsk_grep; }. task tsk_grep {; String? input_381012639; command { ps aux | grep j${""a"" + input_381012639}; }; }; ```. Cromwell works as expected executing `ps aux | grep j`.; Is this a bug or i can only use optional variables inside of **task scope**?",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1176:422,variab,variable,422,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1176,2,['variab'],"['variable', 'variables']"
Modifiability,Help configuring system portion config file to optimally use google cloud,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5352:5,config,configuring,5,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5352,2,['config'],"['config', 'configuring']"
Modifiability,"Here is how I've configured GCP:. ```; backend {; default = ""PAPIv2""; providers {; PAPIv2 {; actor-factory = ""cromwell.backend.google.pipelines.v2beta.PipelinesApiLifecycleActorFactory""; config {; project = ""***""; root = ""***""; genomics {; auth = ""application-default""; endpoint-url = ""https://us-west2-lifesciences.googleapis.com/""; location = ""us-west2""; }; filesystems {; gcs {; auth = ""application-default""; project = ""***""; }; }; }; }; }; }; ```. And yet the worker instances are running on us-central1. Which also means it's copying data across regions (because my data is in us-west2). <img width=""2017"" alt=""image"" src=""https://user-images.githubusercontent.com/125854/171462418-63cdc51b-1f9e-4a9c-90c6-479a36946628.png"">",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6774:17,config,configured,17,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6774,2,['config'],"['config', 'configured']"
Modifiability,"Hey develop team, thank you for develop this good software.; I have built a cromwell by using docker-compose.; here is my docker-compose.yml; ```version: '2'; services:; cromwell:; build: ; context: ./compose/cromwell; volumes:; - ./cromwell-executions:/cromwell-working-dir/cromwell-executions; - /data1:/data1; command: [""/wait-for-it/wait-for-it.sh mysql-db:3306 -t 120 -- java -Dconfig.file=/app-config/cromwell-application.conf -jar /app/cromwell.jar server""]; links:; - mysql-db; ports:; - ""80:8000""; mysql-db:; image: ""mysql:5.7""; environment:; - MYSQL_ROOT_PASSWORD=cromwell; - MYSQL_DATABASE=cromwell_db; volumes:; - ./compose/mysql/init:/docker-entrypoint-initdb.d; - ./compose/mysql/data:/var/lib/mysql; ports:; - ""3307:3306""; ```. and here is my crowell config file:. ```include required(classpath(""application"")). # Note: If you spot a mistake in this configuration sample, please let us know by making an issue at:; # https://github.com/broadinstitute/cromwell/issues. call-caching {; enabled = false; }. backend {; default = ""Local""; providers {; Local {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; run-in-background = true; runtime-attributes = ""String? docker Int? max_runtime = 2""; submit = ""/bin/bash ${script}""; submit-docker = ""docker run --rm -v ${cwd}:${docker_cwd} -i ${docker} /bin/bash < ${script}"". # Root directory where Cromwell writes job results. This directory must be; # visible and writeable by the Cromwell process as well as the jobs that Cromwell; # launches.; root: ""cromwell-executions"". filesystems {; local {; localization: [; ""soft-link"", ""hard-link"", ""copy""; ]. caching {; duplication-strategy: [; ""soft-link""; ]. # Possible values: file, path; # ""file"" will compute an md5 hash of the file content.; # ""path"" will compute an md5 hash of the file path. This strategy will only be effective if the duplication-strategy (above) is set to ""soft-link"",; # in order to allow for the original file path to be h",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7006:400,config,config,400,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7006,3,['config'],"['config', 'configuration']"
Modifiability,"Hi , ; When submitting jobs requiring GPU, we specified in the runtime session: ; gpuCount: 2; gpuType: ""nvidia-tesla-k80""; the jobs failed with following errors:; 2019/05/03 14:40:50 E: command failed: nvidia-docker | 2019/05/03 14:40:50 Error: Could not load UVM kernel module. Is nvidia-modprobe installed?. The same WDL file (with same docker and runtime attributes) used to work before. Please help!. Thanks!. <!--; Hi! Thanks for taking the time to report feedback. Before posting an issue here, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're in the right place. -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4935:1124,config,configuration,1124,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4935,1,['config'],['configuration']
Modifiability,"Hi , I'm new to cromwell/wdl. I tried to run a workflow using a SGE backend. wget -O SGE.conf ""https://raw.githubusercontent.com/broadinstitute/cromwell/develop/cromwell.example.backends/SGE.conf"". ```; $ java -Dconfig.file=${PWD}/SGE.conf -jar ${CROMWELL_JAR} run test.wdl --inputs input.json ; Exception in thread ""main"" java.lang.ExceptionInInitializerError; 	at cromwell.CromwellApp$.runCromwell(CromwellApp.scala:14); 	at cromwell.CromwellApp$.delayedEndpoint$cromwell$CromwellApp$1(CromwellApp.scala:25); 	at cromwell.CromwellApp$delayedInit$body.apply(CromwellApp.scala:3); 	at scala.Function0.apply$mcV$sp(Function0.scala:39); 	at scala.Function0.apply$mcV$sp$(Function0.scala:39); 	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:17); 	at scala.App.$anonfun$main$1(App.scala:76); 	at scala.App.$anonfun$main$1$adapted(App.scala:76); 	at scala.collection.IterableOnceOps.foreach(IterableOnce.scala:563); 	at scala.collection.IterableOnceOps.foreach$(IterableOnce.scala:561); 	at scala.collection.AbstractIterable.foreach(Iterable.scala:926); 	at scala.App.main(App.scala:76); 	at scala.App.main$(App.scala:74); 	at cromwell.CromwellApp$.main(CromwellApp.scala:3); 	at cromwell.CromwellApp.main(CromwellApp.scala); Caused by: com.typesafe.config.ConfigException$Parse: /home/lindenbaum-p/notebook/2023/20230208.wdl/SGE.conf: 60: expecting a close parentheses ')' here, not: end of file; 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseError(ConfigDocumentParser.java:201); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseError(ConfigDocumentParser.java:197); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseKey(ConfigDocumentParser.java:279); ```. adding an extra `}` at the end of SGE.conf fixed the problem. I'll submit a PR if I'm not wrong.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7007:843,adapt,adapted,843,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7007,12,"['Config', 'adapt', 'config']","['ConfigDocumentParser', 'ConfigException', 'adapted', 'config']"
Modifiability,"Hi ,; Im running the GATK [warp joint genotyping pipeline ](https://github.com/broadinstitute/warp/blob/develop/pipelines/broad/dna_seq/germline/joint_genotyping/JointGenotyping.wdl)cromwell on GCP backend . The pipeline fails because cromwell cannot localize files with certain data types like ` Array[Array[String]]`. This issue was reported on the [terra website](https://support.terra.bio/hc/en-us/community/posts/4409388371611-How-do-I-pass-an-array-array-file-to-another-task-) too and the workaround was to write a task to read file into an array, I have performed the workaround but are there plans to fix this issue in any upcoming releases. **Cromwell version tested :** 85. **Are you seeing something that looks like a bug? Please attach as much information as possible.** ; `""Failed to evaluate 'sample_name_map_lines' (reason 1 of 1): Evaluating read_tsv(sample_name_map) failed: Failed to read_tsv(\""gs://wgs/test/sample_map.txt\"") (reason 1 of 1): java.lang.IllegalArgumentException: Could not build the path \""gs://wgs/test/sample_map.txt\"". It may refer to a filesystem not supported by this instance of Cromwell. Supported filesystems are: HTTP, LinuxFileSystem. Failures: \nHTTP: gs://wgs/test/sample_map.txt does not have an http or https scheme (IllegalArgumentException)\nLinuxFileSystem: Cannot build a local path from gs://wgs/test/sample_map.txt (RuntimeException)\n Please refer to the documentation for more information on how to configure filesystems: http://cromwell.readthedocs.io/en/develop/backends/HPC/#filesystems""`. **Which backend are you running?** ; GCP. **Link to the workflow if possible**; https://github.com/broadinstitute/warp/blob/develop/pipelines/broad/dna_seq/germline/joint_genotyping/JointGenotyping.wdl",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7364:1457,config,configure,1457,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7364,1,['config'],['configure']
Modifiability,"Hi Cromwell Team; ; I am writing in respect to an issue that I am having with using AWS + Cromwell + MySQL server. Not sure if this is the best place to ask because I’m not sure if the issue is Cromwell specific. It might be related to AWS backend configuration. But I couldn’t figure out the problem and I figured you might be able to provide some insight.; ; I have a docker image that has MySQL server installed. I’m using percorna-server-5.6 specifically because I need to use MySQL5.6. There is a Cromwell task which does the following:; 1. Start mysql server. The first line of the WDL task is literally `service mysql start`; 2. Initialize the database and load Vcf files into the database.; 3. Run some SQL query and perform some analysis; ; And the above Cromwell task need to be run for multiple samples. ; ; So, first I did step 1-3 manually without using WDL just to make sure that I can run multiple MySQL docker container just fine. And it worked. So then the next step is test the whole WDL using LOCAL backend. And it ran fine. But when I submit the same WDL script to AWS Batch, the first task will always succeed and the subsequent tasks will always fail with port connection error because all the containers are connecting to port 3306 and port 3306 is already used. Do you know why it is trying to connect to port 3306? My issue was that it worked when running locally. So, I’m wondering if there’s something with how the docker run command was submitted to AWS Batch or EC2 is configured?",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4688:248,config,configuration,248,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4688,2,['config'],"['configuration', 'configured']"
Modifiability,"Hi Cromwell team, . I am opening this issue on behalf of an AWS customer. Customer reached out to AWS Support asking for documentation on how to configure Batch job retries via Cromwell. . In AWS Batch, retries can be specified in the job definition as described below-; Automated Job Retries - https://docs.aws.amazon.com/batch/latest/userguide/job_retries.html; Creating a Job Definition - https://docs.aws.amazon.com/batch/latest/userguide/create-job-definition.html. Is this supported in Cromwell? Could you please share information on how to do this? ; Adding the Jira issue I opened for reference-; https://broadworkbench.atlassian.net/browse/CROM-6675. Thank you!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6114:145,config,configure,145,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6114,1,['config'],['configure']
Modifiability,"Hi Everyone,; We have updated Cromwell from version 51 to 82 recently, and changed the following line in Dockerfile:. -----------------------------------------------------------------------; FROM broadinstitute/cromwell:51 --> FROM broadinstitute/cromwell:82; -----------------------------------------------------------------------. Then we had an issue with the parameter scriptBucketName in aws.conf which seems to be a new parameter introduced. So we modified the aws.conf file as follows:. aws.conf; -----------------------------------------------------------------------; backend {; default = ""AWSBATCH""; providers {; AWSBATCH {; actor-factory = ""cromwell.backend.impl.aws.AwsBatchBackendLifecycleActorFactory""; config {. concurrent-job-limit = 10000. numSubmitAttempts = 6; numCreateDefinitionAttempts = 6. // Base bucket for workflow executions; root = ${EXECUTION_BUCKET_ROOT_URL}. // A reference to an auth defined in the `aws` stanza at the top. This auth is used to create; // Jobs and manipulate auth JSONs.; auth = ""xxxxxx"". default-runtime-attributes {; queueArn: ${AWS_BATCH_QUEUE}; scriptBucketName: ""${SCRIPT_BUCKET_NAME}""; }. filesystems {; s3 {; // A reference to a potentially different auth for manipulating files via engine functions.; auth = ""default""; }; }. # Emit a warning if jobs last longer than this amount of time. This might indicate that something got stuck in the cloud.; slow-job-warning-time: 3 hours; }; },; -------------------------------------------------------------------------; Q1. What is scriptBucketName ? I know it says in the documentation that it is where the scripts are stored/written by Cromwell.; For example, if our root bucket is s3://1234-bla-bla-executor/cromwell-execution, should scriptBucketName be ""1234-bla-bla-executor"" ? I understand that we are giving the full path in the root bucket, but is it related or completely unrelated to scriptBucketName ?. It looks like Cromwell is able to create script and reconfigured-script.sh files in the",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6832:717,config,config,717,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6832,1,['config'],['config']
Modifiability,"Hi Want to run my pipeline in gcp with nvidia-tesla-a100. Get errors for insert machine. Trake into the code since cromwell set n2-custom machine meanwhile a100 require a2-highgpu-1g. I guess it is not a big change but can extend capbilities. runtime {bootDiskSizeGb: 100; disks: ""/mnt 3000 HDD""; gpuType: ""nvidia-tesla-a100""; gpuCount: 1; nvidiaDriverVersion: ""418.87.00""; zones: [""us-central1-c""]; } (edited) . ###; ### IMPORTANT: Please file new issues over in our Jira issue tracker!; ###; ### https://broadworkbench.atlassian.net/projects/BA/issues; ###; ### You may need to create an account before you can view/create issues.; ###. <!--; Hi! Thanks for taking the time to report feedback. Before posting an issue over in Jira tracker, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're almost in the right place. -->. <!-- You'll want to go to https://broadworkbench.atlassian.net/projects/BA/issues and then tell us: -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6558:223,extend,extend,223,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6558,2,"['config', 'extend']","['configuration', 'extend']"
Modifiability,"Hi all,. As discussed with @TimothyTickle, @ruchim, @benjamincarlin, @gsaksena, @abaumann, @kshakir, @geoffjentry, and others at the Broad retreat and DSP holiday hackathon, we're putting a proposal for a new feature that reports task call resource utilization metrics to Stackdriver Monitoring API. This serves 2 important goals:. 1) Users can easily plot real-time resource usage statistics across all tasks in a workflow, or for a single task call across many workflow runs, etc. This can be very powerful to quickly determine outlier tasks that could use optimization, without the need for any configuration or code (or any changes to the workflow). It's also much easier than the current state-of-the-art, i.e. parsing task-level monitoring logs. 2) Scripts can easily get aggregate statistics on resource utilization and could produce suggestions based on those. This could provide a path towards automatic runtime configuration based on the models trained with historical data. One could also detect situations like out-of-memory calls and automatically adjust resources according to those. It would also be pretty easy to add logic for estimation of task call-level cost based on the pricing of associated resources. This could provide a long-sought feature of real-time cost monitoring/control (thanks to @TimothyTickle for the suggestion). Monitoring is done using the new ""monitoring action"" for PAPIv2, which currently uses the hard-coded [quay.io/broadinstitute/cromwell-monitor](https://quay.io/repository/broadinstitute/cromwell-monitor) image, built from https://github.com/broadinstitute/cromwell-monitor (I wasn't sure if that code belonged here or in a separate repo). This is advantageous to just using it as a _monitoring_script_, because it removes all assumptions on the ""user"" Docker image (for the task itself). For example, we don't have to assume a particular distribution or presence of Python and its libraries. So it should work exactly the same for any task. Per @geoffj",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4510:598,config,configuration,598,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4510,2,['config'],['configuration']
Modifiability,"Hi all,; I am confused by Example 4 in the doc:; ```; task bwa_mem_tool {; Int threads; Int min_seed_length; Int min_std_max_min; File reference; File reads. command {; bwa mem -t ${threads} \; -k ${min_seed_length} \; -I ${sep=',' min_std_max_min+} \; ${reference} \; ${sep=' ' reads+} > output.sam; }; output {; File sam = ""output.sam""; }; runtime {; docker: ""broadinstitute/baseimg""; }; }; ```; ```; Notable pieces in this example is ${sep=',' min_std_max_min+} which specifies that min_std_max_min can be one or more integers (the + after the variable name indicates that it can be one or more). If an Array[Int] is passed into this parameter, then it's flattened by combining the elements with the separator character (sep=',').; ```; But here is also a claim that:; ```; + applies only to Array types and it represents a constraint that the Array value must contain one-or-more elements.; ```; Why can + be used with min_std_max_min which type is Int and you can even pass a Array[Int] to that variable?; I tried a lot of times and none worked.; Can someone help? Thanks!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4417:547,variab,variable,547,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4417,2,['variab'],['variable']
Modifiability,"Hi all,; I wonder if there is a mechanism of global variables setting and importing like workflow importing or application conf including. I just tried to ways:; 1. setting global variables in customized conf which can be used as conf option with cromwell cmd but I don't know how to reference them in the WDL file; 2. put all global variables in a separated workflow WDL file using workflow variables and import them in other WDL files, while it looks like only imported tasks can be called and no way to just use the variables; My purpose is that we have many pipelines and there are some shared variables (a.k.a global variables) and I prefer to reference them in some separated WDL/conf rather than repeat them again and again, and let individual pipeline developer not to modify them by accident and only focus on his pipeline specific variables and reference them by importing. How can I do that in an elegant way? Thanks!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4416:52,variab,variables,52,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4416,8,['variab'],['variables']
Modifiability,"Hi all. I've been playing the CWL ResourceRequirement with cromwell under SLURM env.; https://www.commonwl.org/v1.0/CommandLineTool.html#ResourceRequirement. So, if I submit a CWL with; ```; - class: ResourceRequirement; coresMin: 1; coresMax: 1; ramMin: 2000; ramMax: 2000; ```; The cromwell will send the command to SLURM with a ridiculously high value of memory; ```; executing: sbatch --nodes 1 --ntasks 1 \; --cpus-per-task=1 --mem-per-cpu=2097152000 \; ```; And most likely it will fail because we do not have such a beefy flavor node, since SLURM reads the memory in MB.; ```; sbatch: error: Batch job submission failed: Requested node configuration is not available; ```; More tests like using different units or numbers will lead to similar errors:; Submit; ```; - class: ResourceRequirement; coresMin: 1; coresMax: 1; ramMin: 2GB; ramMax: 2GB; ```; will give me; ```; executing: sbatch --nodes 1 --ntasks 1 \; --cpus-per-task=1 --mem-per-cpu=2000000000 \; ```; and; ```; - class: ResourceRequirement; coresMin: 1; coresMax: 1; ramMin: 2; ramMax: 2; ```; gives me; ```; executing: sbatch --nodes 1 --ntasks 1 \; --cpus-per-task=1 --mem-per-cpu=2097152 \; ```; more for; ``` - class: ResourceRequirement; coresMin: 1; coresMax: 1; ramMin: 2000MB; ramMax: 2000MB; ```; it will give; ```; executing: sbatch --nodes 1 --ntasks 1 \; --cpus-per-task=1 --mem-per-cpu=2000000000 \; ```. So, it seems cromwell will read the numbers in MB and transfer it in bytes to SLURM. However, SLURM probably needs memory in MB as well. (I assume it is a bug when mapping CWL resource key to WDL). Currently, I manage to use an expression in the config `memoryMin/1000000` to circumvent the issue.; I don't think it is a very major issue nor a complex one, so feel free to fix it whenever. The cromwell version is the latest release, cromwell-34, and please find my working config if necessary. [cromwell.slurm.conf.gz](https://github.com/broadinstitute/cromwell/files/2368103/cromwell.slurm.conf.gz)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4080:643,config,configuration,643,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4080,3,['config'],"['config', 'configuration']"
Modifiability,"Hi cromwell developers,. I'm having persistent errors similar to those in #2034 : stderr shows a line like this.; ; bash: path/to/my/cwd/cromwell-executions/my_workflow_name/some_hexadecimal_garbage/call-my_task_name/execution/script: Permission denied. Can you suggest a diagnosis or a workaround for this problem? I've tried to configure cromwell with LSF, and I suspect that's where the issue lies. Here's my complete configuration file. Thanks for your help!. include required(classpath(""application"")); backend {; default = LSF; providers {; LSF {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; concurrent-job-limit = 16; ; runtime-attributes = """"""; Int cpu; Int nthreads; Float? memory_kb; """"""; ; submit = """"""; bsub \; -J ${job_name} \; -cwd ${cwd} \; -R rusage[mem=${memory_kb}] \; -n ${nthreads} \; -W ${cpu} \; -o ${out} \; -e ${err} \; ""${script} ""; """"""; ; kill = ""bkill ${job_id}""; check-alive = ""bjobs ${job_id}""; job-id-regex = ""Job <(\\d+)>.*""; }; }; }; }",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3185:330,config,configure,330,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3185,5,"['Config', 'config']","['ConfigBackendLifecycleActorFactory', 'config', 'configuration', 'configure']"
Modifiability,"Hi folks,; I am running cromwell 36 with AWS batch. Doing the hello world example from the following:. https://aws.amazon.com/blogs/compute/using-cromwell-with-aws-batch/. I am able to submit from the swagger UI and am getting the following erro:. `2018-10-30 00:39:25,929 INFO - jobQueueArn: arn:aws:batch:us-east-2:365166883642:job-queue/GenomicsHighPriorityQue-0c2108973103ca2; 2018-10-30 00:39:25,929 INFO - taskId: wf_hello.hello-None-1; 2018-10-30 00:39:25,929 INFO - hostpath root: wf_hello/hello/bcc91ab0-fd91-41a8-b3e6-cbf091cb511d/None/1; 2018-10-30 00:39:25,965 cromwell-system-akka.dispatchers.backend-dispatcher-229 ERROR - AwsBatchAsyncBackendJobExecutionActor [UUID(bcc91ab0)wf_hello.hello:NA:1]: Error attempting to Execute; software.amazon.awssdk.core.exception.SdkClientException: Unable to execute HTTP request: batch.default.amazonaws.com: Name or service not known`. Any idea the source of this error?; <!--; Hi! Thanks for taking the time to report feedback. Before posting an issue here, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're in the right place. -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4334:1633,config,configuration,1633,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4334,1,['config'],['configuration']
Modifiability,"Hi team,. I try to configure cromwell to run ExomeGermlineSingleSample_v3.1.9.wdl on Slurm, and I follow your guide, but I have an error that ${docker_script} : No such file or directory; /cromwell-executions/ExomeGermlineSingleSample/118135f5-ce0e-437b-9fd2-332dd614bded/call-GenerateSubsettedContaminationResources/execution/script : No such file or directory; I attached the run file; #!/bin/bash; #SBATCH --nodes=1; #SBATCH --time=2:00:00. module load jdk. java -Dconfig.file=/mainfs/wrgl/broadinstitute_warp_development/tutorials/cromwell-slurm_5.config \; -jar /mainfs/wrgl/broadinstitute_warp_development/tutorials/cromwell-85.jar \; run /mainfs/wrgl/broadinstitute_warp_development/warp/ExomeGermlineSingleSample_v3.1.9.wdl \; -i /mainfs/wrgl/broadinstitute_warp_development/tutorials/Exom_test.json. #### Configuration file ###. include required(classpath(""application"")). system {; # If 'true', a SIGINT will trigger Cromwell to attempt to abort all currently running jobs before exiting; abort-jobs-on-terminate = false; }. backend {; default = SLURM. providers {; SLURM {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory"". config {; temporary-directory = ""$(mktemp -d /tmp/tmp.XXXXXX)"". runtime-attributes = """"""; Int runtime_minutes = 60; Int cpu = 1; Int memory_mb = 3900; String? docker; """""". submit = """""" \; 'sbatch \; --wait \; -J ${job_name} \; -D ${cwd} \; -o ${out} \; -e ${err} \; -t ${runtime_minutes} \; -p batch,scavenger \; -c ${cpu} \; --mem $(( (${memory_mb} >= ${cpu} * 3900) ? ${memory_mb} : $(( ${cpu} * 3900 )) )) \; -N 1 \; --exclusive \; --wrap ""/bin/bash ${script}""'; """""". submit-docker = """""" \. # Make sure the SINGULARITY_CACHEDIR variable is set. If not use a default; # based on the users home.; module load apptainer; if [ -z $APPTAINER_CACHEDIR ];; then CACHE_DIR=$HOME/.apptainer/cache; else CACHE_DIR=$APPTAINER_CACHEDIR; fi; # Make sure cache dir exists so lock file can be created by flock; mkdir -p $CACHE_DIR; LOCK_FILE",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7086:19,config,configure,19,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7086,3,"['Config', 'config']","['Configuration', 'config', 'configure']"
Modifiability,"Hi there,. I'm new to both WDL and Cromwell and am trying to get an analysis pipeline up and running. I'm using call-caching to speed up my development, so that I don't have to repeat multi-hour steps. However, I'm currently seeing ~8 minute delays for processing cache hits. With multiple steps in serial, this means that nothing in my pipeline starts running till 14 minutes after I start the run. Can you help me fix that?. Thank you for the help!. Happy to provide any more info than the below if that's helpful. I'm running with cromwell 84. Here's the command I'm running `java -Dconfig.file=workflow/cromwell.conf -jar utilities/cromwell-84.jar run workflow/expanse_workflow.wdl`. Here's my configuration (ignore the SLURM part, I'm not using it yet). Potentially important bits:; * I'm running with the local backend.; * I'm using symlink caching so that should be fast, with path+timestamp hash codes so the whole file doesn't need to be read; * I'm using the file based Hsql database. I don't see why that should matter, but maybe it does.; ```; # See https://cromwell.readthedocs.io/en/stable/Configuring/; # only use double quotes!; include required(classpath(""application"")). system {; abort-jobs-on-terminate = true; io {; number-of-requests = 30; per = 1 second; }; }. ## file based persistent database; database {; profile = ""slick.jdbc.HsqldbProfile$""; db {; driver = ""org.hsqldb.jdbcDriver""; url = """"""; jdbc:hsqldb:file:cromwell-executions/cromwell-db/cromwell-db;; shutdown=false;; hsqldb.default_table_type=cached;hsqldb.tx=mvcc;; hsqldb.result_max_memory_rows=10000;; hsqldb.large_data=true;; hsqldb.applog=1;; hsqldb.lob_compressed=true;; hsqldb.script_format=3; """"""; connectionTimeout = 120000; numThreads = 1; }; }. call-caching {; enabled = true; }. backend {; default = ""Local""; providers { ; Local {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; concurrent-job-limit = 10; run-in-background = true; submit = ""/usr/bin/env ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6971:698,config,configuration,698,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6971,1,['config'],['configuration']
Modifiability,"Hi! A task-level caching control has been introduced recently in the Cromwell 49. That's cool, thanks for the feature!. https://cromwell.readthedocs.io/en/stable/optimizations/VolatileTasks/; The example is using wdl specification 1.0 and it differs from draft-2 when tackling the meta section:. - draft-2 waits for a $string as a metadata value; - 1.0 waits for $meta_value = $string | $number | $boolean | 'null' | $meta_object | $meta_array. https://github.com/openwdl/wdl/blob/master/versions/1.0/SPEC.md#metadata-section; https://github.com/openwdl/wdl/blob/master/versions/draft-2/SPEC.md#metadata-section. Hence, a `volatile: true` is not valid for draft-2, because a boolean is not a string. Is it possible to adapt the meta section for draft-2 specification too? In example: `volatile: ""true""`. The majority of our workflows still stick to the draft-2 and their translation to 1.0 will be painful. The issue is related to https://github.com/broadinstitute/cromwell/issues/1695",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5476:718,adapt,adapt,718,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5476,1,['adapt'],['adapt']
Modifiability,"Hi!. I have been trying to make memory retry work on our system without sucess. ; Read all docs and previous issues I could find, but it still doesn't work for us. I have written a test wdl with two tasks, both write ""Killed"" to stderr, and supposed to get retried with more memory. The first task, **TestBadCommandRetry** is designed to fail regularly with rc 127, due to a bad command.; The purpose of this task is to prove the memory-retry mechanism is configured correctly in our system. Result of TestBadCommandRetry:; The memory-error-key is caught and memory is increased as defined in memory-retry-multiplier.; I also see this failure message in metadata.json:; _""message"": ""stderr for job `MemoryRetryTest.TestBadCommandRetry:NA:1` contained one of the `memory-retry-error-keys: [Killed]` specified in the Cromwell config. Job might have run out of memory.""_. Grepping metadata for memory of this job, I see the expected behaviour:; ""memory"": ""1 GB"",; ""memory"": ""2 GB"",. The second task, **TestOutOfMemoryRetry** is designed to fail do to real out of memory error.; The purpose of this task is to shoe that memory-retry mechanism is not working when a task runs out of memory, even if ""Killed"" is written to stderr. Result of TestOutOfMemoryRetry:; When this task is run, it fails but **the job is retried with the same amount of memory**.; This time I see the following failure message:; _""message"": ""Task MemoryRetryTest.TestOutOfMemoryRetry:NA:1 failed. The job was stopped before the command finished. PAPI error code 9. Execution failed: generic::failed_precondition: while running \""/cromwell_root/script\"": unexpected exit status 137 was not ignored\n[UserAction] Unexpected exit status 137 while running \""/cromwell_root/script\"": Killed\n"",_. Grepping metadata for memory of this job, I see the memory expension is not working:; ""memory"": ""1 GB"",; ""memory"": ""1 GB"",; ; I have verified ""Killed"" is written correctly to stderr :; ```; gsutil cat gs://<out_bucket>/cromwell-execution/Me",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7205:456,config,configured,456,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7205,2,['config'],"['config', 'configured']"
Modifiability,"Hi, . I wonder is it possible to increase frequency of check for rc file? Sometimes I see a gap of several minutes (3-5) between the time of rc generation in one task and the start of subsequent (dependent) task. I would like to increase the frequency of that check to at least 1 min or 30sec. . If I understand that thread correctly (https://github.com/broadinstitute/cromwell/issues/4877) there is no simple configuration option for that setting. . Best, Eugene",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7144:410,config,configuration,410,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7144,1,['config'],['configuration']
Modifiability,"Hi, . I would like to be able to override something like:. ```; runtime {; docker: ""mydockerimagename""; }; ```; at runtime. Is this possible already? I know people have been using workarounds by making the docker image name to be an input variable. I would like to have it separate from workflow input variables though.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5855:239,variab,variable,239,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5855,2,['variab'],"['variable', 'variables']"
Modifiability,"Hi, we allow users to run jobs with different workflow options and our users would like to know what options were used for given workflow run. I was searching a bit but I cannot find how to retrieve workflow options for given run. I can retrieve files that were uploaded (that's fine) from metadata but I would need also options listed if there were defaults set in the config file. Eg. user can change `read_from_cache=true` but if she does not supply any file the default option would not be listed in the metadata (nor in the `WORKFLOW_STORE_ENTRY` as far as I could check.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5246:370,config,config,370,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5246,1,['config'],['config']
Modifiability,"Hi,. I am a novice BI trying to implement cromwell via GATK exomesinglesample.wdl on a slurm HPC.; I notice the Haplotype Caller stage tries to use all available memory on the system -1024 with:; available_memory_mb=$(free -m | awk '/^Mem/ {print $2}'); let java_memory_size_mb=available_memory_mb-1024. which is causing problems.; Is there a way of setting the maximum memory that this rule can grab in the config file?",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7335:408,config,config,408,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7335,1,['config'],['config']
Modifiability,"Hi,. I got a timeout exception during cache copying on AWS S3. The cache file size is 133GB. Given the file size, more time should be allowed for cache copying. Is there any config option that can tune this? Thank you in advance for any suggestions. Backend: AWS Batch; Cromwell version: 51; Error log:. Failure copying cache results for job BackendJobDescriptorKey_CommandCallNode_PreProcessingForVariantDiscovery_GATK4.SamTo; FastqAndBwaMem:0:1 (TimeoutException: The Cache hit copying actor timed out waiting for a response to copy s3://xxxxx/cromwell-execution/Germ; line_Somatic_Calling/441619a4-7ca8-490b-bd04-2f9981d3db0f/call-Tumor_Bam/PreProcessingForVariantDiscovery_GATK4/95aed08f-3045-45e4-94c9-ba0230851136; /call-SamToFastqAndBwaMem/shard-0/39T_R.unmerged.bam to s3://xxxxx/cromwell-execution/Germline_Somatic_Calling/c25a8561-808f-4b46-9bd2-ef0488; 8c0031/call-Tumor_Bam/PreProcessingForVariantDiscovery_GATK4/8df24f46-2f4f-4557-a662-d630ac443736/call-SamToFastqAndBwaMem/shard-0/cacheCopy/39T_R.u; nmerged.bam)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5977:174,config,config,174,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5977,1,['config'],['config']
Modifiability,"Hi,. I have built a WDL workflow which works well with SLURM but now I am trying to get it to be able to be run on a standalone server. . I have Slurm as my provider and have created one for Local. ` Local {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {. run-in-background = true; exit-code-timeout-seconds = 300; workflow-reset = true; read_from_cache = true; write_to_cache = true; system.file-hash-cache=true; concurrent-job-limit = 2. runtime-attributes = """"""; String head_directory = ""/data/MGP""; String singularity_image = ""/data/MGP/sing/metaGenPipe.simg""; """""". submit = ""singularity run -B ${head_directory}:${head_directory} ${singularity_image} /bin/bash ${script}"". filesystems {; local {; localization: [; ""soft-link"", ""hard-link"", ""copy""; ]; } ## end local; } ## end file systems; } ## end config; } ## End Local`. Oddly, when running the workflow I get a submit docker error. ie. as per below. I have no idea why it's looking for docker as I'm not knowingly using it. I'm not using docker in my run time parameters. I have been able to get standalone working on another workflow by passing a singularity container to each task command output but I was wondering if there was a more elegant solution I could use such as just changing to a pre-made provider. I have searched Google and through here but not found anything. I did find one issue here but they seemed to want to use docker where as I don't. . Thanks for the help!. `task submit {. String job_id; String job_name; String cwd; String out; String err; String script; String job_shell. String head_directory = ""/data/MGP""; String singularity_image = ""/data/MGP/sing/metaGenPipe.simg"". command {; singularity run -B ${head_directory}:${head_directory} ${singularity_image} /bin/bash ${script}; }; }. task submit_docker {. String job_id; String job_name; String cwd; String out; String err; String script; String job_shell. String docker_cwd; String docker_cid; String docker_scri",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5862:252,config,config,252,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5862,4,"['Config', 'config']","['ConfigBackendLifecycleActorFactory', 'config']"
Modifiability,"Hi,. I just moved to a new cluster (no sudo) and try to run a WDL script with Cromwell-31.; Everything worked fine on my previous cluster (same Cromwell / WDL / Java versions and same script). After creating the wdl script, I validated it and generated a JSON file (with wdl-0.14), no problem. After running `java -jar cromwell-31.jar run my_script.wdl -i my_script.JSON` the workflow stops, outputting `Permission denied` for the program I call in my .wdl script (which is called from the 'cromwell_executions' folder during the process). I changed the permission to 777 for this program located in my `/usr/bin`, but still the same issue. The program, once located in the 'cromwell_executions' folder, loses the execution permission for the owner.; Same issue no matter if I submit a PBS job or run it interactively. Is there anything to mention in a cromwell configuration file or something to tune in the cluster?. Thanks !",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3500:862,config,configuration,862,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3500,1,['config'],['configuration']
Modifiability,"Hi,. I'm finding that Cromwell is using too many resources in a shared environment. It's spawning other threads and using up to 400% CPU, which I can't see why when the logs just show it's watching for jobs (maybe it's trying to hash files for call-caching?). I'd love a way to limit it, even at the expense of speed of the program, it would also be great if there was tooling (maybe an endpoint) to gauge the resource usage, and see what Cromwell's actually doing. For context, I'm running Cromwell on a (shared) login node, submitting jobs to Slurm (custom SFS config). The workflow is scattering a subworkflow 25 times, each with 4 steps. All of those have actually executed prior and it's taking a long time (sometimes > 30 minutes) to look up a call result. I am using call-caching with a mysql database.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4945:563,config,config,563,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4945,1,['config'],['config']
Modifiability,"Hi,. Sorry for submitting an issue here but I'm consistently getting a ""Something has gone wrong"" error trying to log in to your Jira. I'm hoping someone can offer some guidance for an issue I'm having running a CWL workflow with Cromwell on GCP. I'm using bcbio to generate CWL to do joint calling. This worked fine when I tested it with a single sample to shake out any issues with the pipeline. However when scaling up to a 20 sample batch there's an issue with the get_parallel_regions_jointvc step. This step appears to be localizing multiple copies of the reference genome data (one for each sample) to the same disk. This really blows up the storage requirements as the number of samples increase and ends up exhausting the storage allocated to the worker instance. Is this expected behaviour or is there some kind of configuration I'm missing that would avoid this?",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5131:825,config,configuration,825,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5131,1,['config'],['configuration']
Modifiability,"Hi,. Switching from version 51 to 52/53 I get the error:. ```; Task XYZ has an invalid runtime attribute memory = !! NOT FOUND !!; ```. I could not find any docs describing the change in required runtime attributes. I cannot add it to config as it raises another error. Thanks",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5817:235,config,config,235,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5817,1,['config'],['config']
Modifiability,"Hi,. _I'll manually synchronise this issue with Jira, I've raised it here as I think it has better exposure, might be useful as a reference and I'm going to reference it from a different issue: https://broadworkbench.atlassian.net/browse/BA-6172_. I'm trying to get call-caching working for my workflows, and having some trouble identifying a config that will work for the following requirements:. - Using containers (both Singularity and Docker); - Initial localisation strategy: `[hard-link, cached-copy]`; - Local SFS environment; - My input files can be fairly large (~250GB per Bam with up to 16 Bams). . If I can get this working, I'll happily document and update the CallCaching documentation page with what I've found. ## Background information. Version: Cromwell-47. Documentation:; - https://cromwell.readthedocs.io/en/stable/cromwell_features/CallCaching/; - https://cromwell.readthedocs.io/en/stable/Configuring/#local-filesystem-options; - https://cromwell.readthedocs.io/en/stable/backends/HPC/#shared-filesystem. Cache duplication strategies:; - `hard-link`; - `soft-link` - This strategy is not applicable for tasks which specify a Docker image and will be ignored.; - `copy`; - ~`cached-copy`~ - This is non-cache duplication strategy. Cache hashing strategies:; - `file` - (default) computes an md5 hash of the file content. [Code: `tryWithResource(() => file.newInputStream) { DigestUtils.md5Hex }`]; - `path` - computes an md5 hash of the file path. This strategy will only be effective if the duplication-strategy (above) is set to ""soft-link"".; - `path+modtime` - compute an md5 hash of the file path and the last modified time. The same conditions as for ""path"" apply here. [Code: `md5Hex(file.toAbsolutePath.pathAsString + file.lastModifiedTime.toString)`]. Other caching options:. - `system.file-hash-cache` - Prevent repeatedly requesting the hashes of the same files multiple times. - `backend.providers.Local.caching.check-sibling-md5` - will check if a sibling file with t",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5346:343,config,config,343,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5346,2,"['Config', 'config']","['Configuring', 'config']"
Modifiability,"Hi,; ### TL;DR. **Cromwell should allow for the configuration of Docker resource / environment flags at run-time.**. ---. I have a use-case where I'd like to run Cromwell jobs in a cluster environment via Docker Swarm. Since Swarm doesn't require any additional configuration outside of standard `docker run` commands, it's trivial to distribute Cromwell jobs across Swarm nodes. However, Swarm provides a series of [filters](https://github.com/docker/swarm/tree/master/scheduler/filter) and constrains that control how the scheduler distributes containers to nodes. For example, I might be interested in limiting the execution of a Cromwell job to a specific region / datacenter. This requires you to specify filters in the `docker run` command with the environment flag, `-e`. For example, to run a container on Swarm nodes that run in the `us-east` region:. ```; › docker run -d --name my_image -e constraint:region!=us-east* my_container; ```. Obviously, this configuration should _not_ be managed in the WDL document. Instead, it would be great for the Cromwell command-line tool and REST API to support additional runtime options for specifying Docker environment variables. For example:. ```; › cromwell run --docker-env ""constraint:region!=us-east*"" my_workflow.wdl -; ```. > Hint: Docker supports daemon labels. In the above case, the workflow would; > execute on a Swarm node whose Docker daemon that was started with:; > ; > ```; > docker daemon --label region=us-east; > ```. As for the API, the POST action to `/api/workflows/:version` would allow for multiple Docker env strings. The other feature I would like to request is translating `memory` and `cpu` configuration options (at the task level) to Docker via `--memory` and `--cpuset-cpus` `docker run` flags, respectively. These options are currently only used for the JES backend, but it seems as though they can also be used for the Local backend if Docker is specified. So, to summarize:; 1. Allow Docker `-e` flags to be specifie",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/375:48,config,configuration,48,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/375,3,['config'],['configuration']
Modifiability,"Hi,; I am trying to run a workflow on AWS Batch using the genomics-ami.; The ami was built following the instructions in the relevant pages and i have confirmed that it contains a /cromwell-root mount point and has rw access to the bucket we use.; The AWS batch backpoint was tested with the hello.wdl workflow and it went through. When running the workflow on the local filesystem it completes without errors but when running it using the AWS Batch backend the first step fails with the following error:. ```; 2019-01-11 20:27:06,80] [error] WorkflowManagerActor Workflow 8fa7a9e4-f30d-4c19-b8cb-68be6442f317 failed (during ExecutingWorkflowState): cromwell.engine.io.IoAttempts$EnhancedCromwellIoException: [Attempted 1 time(s)] - IOException: Could not read from s3://bucket/cwl_temp_file_8fa7a9e4-f30d-4c19-b8cb-68be6442f317.cwl/8fa7a9e4-f30d-4c19-b8cb-68be6442f317/call-bbmap/bbmap-rc.txt: s3://s3.amazonaws.com/bucket/cwl_temp_file_8fa7a9e4-f30d-4c19-b8cb-68be6442f317.cwl/8fa7a9e4-f30d-4c19-b8cb-68be6442f317/call-bbmap/bbmap-rc.txt; Caused by: java.io.IOException: Could not read from s3://bucket/cwl_temp_file_8fa7a9e4-f30d-4c19-b8cb-68be6442f317.cwl/8fa7a9e4-f30d-4c19-b8cb-68be6442f317/call-bbmap/bbmap-rc.txt: s3://s3.amazonaws.com/bucket/cwl_temp_file_8fa7a9e4-f30d-4c19-b8cb-68be6442f317.cwl/8fa7a9e4-f30d-4c19-b8cb-68be6442f317/call-bbmap/bbmap-rc.txt; 	at cromwell.engine.io.nio.NioFlow$$anonfun$withReader$2.applyOrElse(NioFlow.scala:146); 	at cromwell.engine.io.nio.NioFlow$$anonfun$withReader$2.applyOrElse(NioFlow.scala:145); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34); 	at scala.util.Failure.recoverWith(Try.scala:232); 	at cromwell.engine.io.nio.NioFlow.withReader(NioFlow.scala:145); 	at cromwell.engine.io.nio.NioFlow.limitFileContent(NioFlow.scala:154); 	at cromwell.engine.io.nio.NioFlow.$anonfun$readAsString$1(NioFlow.scala:98); 	at cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:85); 	at cats.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4542:680,Enhance,EnhancedCromwellIoException,680,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4542,1,['Enhance'],['EnhancedCromwellIoException']
Modifiability,"Hi,; I have a local Singularity mirror file named qc.sif. I did not find any examples of configuring the local .sif file into the cromwell.example.conf file in the documentation you gave me. I checked some configurations and failed. I would like you to give an example of the configuration and a short runtime section of the.wDL file. Thank you very much!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6685:89,config,configuring,89,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6685,3,['config'],"['configuration', 'configurations', 'configuring']"
Modifiability,"Hi. I have a workflow named `main_wf.wdl` which imports a subworkflow named `sub_wf.wdl` like the following:; ```; import ""sub_wf.wdl"" as sub; ```; I am able to run `main_wf.wdl` in run mode. But when I run a cromwell server and uses the swagger UI to commit the above workflow, I get the following error:. ```; 2018-12-17 11:47:12,214 cromwell-system-akka.dispatchers.engine-dispatcher-28 INFO - Retrieved 1 workflows from the WorkflowStoreActor; 2018-12-17 11:47:12,235 cromwell-system-akka.dispatchers.engine-dispatcher-34 INFO - WorkflowStoreHeartbeatWriteActor configured to flush with batch size 10000 and process rate 2 minutes.; 2018-12-17 11:47:13,348 cromwell-system-akka.dispatchers.engine-dispatcher-28 ERROR - WorkflowManagerActor Workflow 3bd35e44-d8a7-41ed-8271-c773949e8c5c failed (during MaterializingWorkflowDescriptorState): cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anon$1: Workflow input processing failed:; error in opening zip file; 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.cromwell$engine$workflow$lifecycle$materialization$MaterializeWorkflowDescriptorActor$$workflowInitializationFailed(MaterializeWorkflowDescriptorActor.scala:214); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:184); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anonfun$2.applyOrElse(MaterializeWorkflowDescriptorActor.scala:179); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34); 	at akka.actor.FSM.processEvent(FSM.scala:684); 	at akka.actor.FSM.processEvent$(FSM.scala:681); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.akka$actor$LoggingFSM$$super$processEvent(MaterializeWorkflowDescriptorActor.scala:135); ```; I put the `sub_wf.wdl` into a `workflow.zip` file like below:; ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4509:566,config,configured,566,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4509,1,['config'],['configured']
Modifiability,"Hi. I'm trying to enable call caching using a local file database and I can't seem to get it to work. Everything that I try does not seem to make a difference, and each run always starts from the first task. I'm running cromwell in run mode from the command line, and I am testing on both cromwell 43 and cromwell 47. I also have write-to-cache and read-from-cache set to true in my options.json (although I understand that is the default behaviour). I am unable to use a mySQL or postgres database at this current time. Is there something that I'm missing? Is there any additional information that is needed to help diagnose this?. My cromwell.conf is as follows:. backend {; default = LSF; providers {; LSF {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; exit-code-timeout-seconds = 600. runtime-attributes = """"""; Int cpus; Float memory_mb; String lsf_queue; String lsf_project; """""". submit = """"""; bsub \; -q ${lsf_queue} \; -P ${lsf_project} \; -J ${job_name} \; -cwd ${cwd} \; -o ${out} \; -e ${err} \; -n ${cpus} \; -R rusage[mem=${memory_mb}] \; /usr/bin/env bash ${script}; """""". job-id-regex = ""Job <(\\d+)>.*"". kill = ""bkill ${job_id}""; check-alive = ""bjobs ${job_id}"". filesystems {; local {; localization: [; ""soft-link"", ""copy"", ""hard-link""; ]; caching {; duplication-strategy: [; ""soft-link"", ""copy"", ""hard-link""; ]; hashing-strategy: ""path""; }; }; }; }; }; }; }; call-caching {; enabled = true; invalidate-bad-cache-results = true; }; database {; profile = ""slick.jdbc.HsqldbProfile$""; db {; driver = ""org.hsqldb.jdbcDriver""; url = """"""; jdbc:hsqldb:file:cromwell-executions/cromwell-db/cromwell-db;; shutdown=false;; hsqldb.default_table_type=cached;hsqldb.tx=mvcc;; hsqldb.result_max_memory_rows=100000;; hsqldb.large_data=true;; hsqldb.applog=1;; hsqldb.lob_compressed=true;; hsqldb.script_format=3; """"""; connectionTimeout = 86400000; numThreads = 1; }; }",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5370:755,config,config,755,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5370,3,"['Config', 'config']","['ConfigBackendLifecycleActorFactory', 'config']"
Modifiability,"Hi; We are trying to setup the cromwell + wdl for genomic analyses at the [National Computational Infrastructure HPC facility](https://nci.org.au/systems-services/peak-system/raijin/) in Australia. This HPC runs bespoke configured PBSPro. I have successfully managed to run ""hello world"" example workflow using the following configuration for the backend. However, I am unable to modify certain parameters as errors are thrown. . My current configuration is as follows:. ```; runtime-attributes = """"""; Int cpu = 1; Int memory = 1; String raijin_queue = ""express""; String walltime = ""01:00:00""; String jobfs = ""1GB""; String raijin_project_id = ""myproject""; """"""; #Submit string when there is no ""docker"" runtime attribute.; submit = """"""; qsub \; -V \; -N ${job_name} \; -o ${out}.qsub \; -e ${err}.qsub \; -l ncpus=${cpu} \; -l mem=${memory}""GB"" \; -l walltime=${walltime} \; -l jobfs=${jobfs} \; ${""-q "" + raijin_queue} \; -P ${raijin_project_id} \; ${script}; """"""; ```. My specific questions:. 1. I have tried `Float memory_gb = 1.0` as the runtime attribute and `${""-l mem="" + memory_gb + ""GB""}` as the submit string but this fails with `qsub: Illegal attribute or resource value Resource_List.mem` error. Could you please help me with the correct formatting of this attribute? I have copied structure of this from [SGE.conf](https://github.com/broadinstitute/cromwell/blob/787943c0eda793fcc407a3e748b56805f4a2795b/cromwell.example.backends/SGE.conf).; 2. I would like to use `$PROJECT` environment variable as the default value for `raijin_project_id` runtime attribute so that each user can run the same workflow without modification within their allocated project. Is there a way to use environment variable in the config file? I tried ${?PROJECT} and ${PROJECT} as per the recommendations for HOCON but to no avail. I am yet to understand the syntax of HOCON completely to solve this but your help at this time would be much appreciated.; 3. `jobfs` is a parameter used to control scratch space l",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4967:220,config,configured,220,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4967,3,['config'],"['configuration', 'configured']"
Modifiability,"Hi;; I'm running Cromwell 34 and hitting an issue when reading from a cache. The problematic CWL step uses a variable, `min_allele_fraction` that is initially an array of longs:. https://github.com/bcbio/test_bcbio_cwl/blob/eae685b8023126b7f159d3048f4ab4dd1a1833d6/prealign/prealign-workflow/steps/batch_for_variantcall.cwl#L101. and then gets converted into a record with individual long elements:. https://github.com/bcbio/test_bcbio_cwl/blob/eae685b8023126b7f159d3048f4ab4dd1a1833d6/prealign/prealign-workflow/steps/batch_for_variantcall.cwl#L309. This all works fine on the first run of a pipeline, but when reading the step from the cache we get an error about not supporting `Long`:; ```; [2018-08-21 10:26:40,02] [info] WorkflowExecutionActor-3e76006c-870a-4c34-9f21-949eee1a5b33 [3e76006c]: Starting batch_for_variantcall; [2018-08-21 10:26:41,10] [error] unrecognized simpleton WOM type: Long; java.lang.RuntimeException: unrecognized simpleton WOM type: Long; at cromwell.Simpletons$.toSimpleton(Simpletons.scala:30); at cromwell.Simpletons$.toSimpleton(Simpletons.scala:16); at cromwell.engine.workflow.lifecycle.execution.callcaching.FetchCachedResultsActor.$anonfun$new$2(FetchCachedResultsActor.scala:32); at scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:234); at scala.collection.Iterator.foreach(Iterator.scala:944); at scala.collection.Iterator.foreach$(Iterator.scala:944); at scala.collection.AbstractIterator.foreach(Iterator.scala:1432); at scala.collection.IterableLike.foreach(IterableLike.scala:71); at scala.collection.IterableLike.foreach$(IterableLike.scala:70); at scala.collection.AbstractIterable.foreach(Iterable.scala:54); at scala.collection.TraversableLike.map(TraversableLike.scala:234); at scala.collection.TraversableLike.map$(TraversableLike.scala:227); at scala.collection.AbstractTraversable.map(Traversable.scala:104); at cromwell.engine.workflow.lifecycle.execution.callcaching.FetchCachedResultsActor.$anonfun$new$1(FetchCachedResults",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4023:109,variab,variable,109,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4023,1,['variab'],['variable']
Modifiability,"Horicromtal wants, please see also (and give preference to) the issue for our [existing configuration](https://github.com/broadinstitute/cromwell/issues/4780).",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4781:88,config,configuration,88,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4781,1,['config'],['configuration']
Modifiability,Hotfix -- configuring *optional* WF restarts,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/889:10,config,configuring,10,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/889,1,['config'],['configuring']
Modifiability,Hotfix -- configuring restarts,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/841:10,config,configuring,10,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/841,1,['config'],['configuring']
Modifiability,How to configure proxies?,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5006:7,config,configure,7,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5006,1,['config'],['configure']
Modifiability,How to set and import global variables,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4416:29,variab,variables,29,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4416,1,['variab'],['variables']
Modifiability,How will The Great Horizontaling happen? Will we release Cromwell 4X and then sometime later change the configuration of that same version to be horizontal? Or will we release Cromwell 4X leaping into horizontal for the first time? Or different scenarios for different environments?. Whichever paths to horizontal are supported should have integration tests.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4800:104,config,configuration,104,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4800,1,['config'],['configuration']
Modifiability,I actually changed a lot less than git seems to think judging by the diffs... 😵‍💫 . * Added a little more text and a two-item bullet list at the top; * Flipped the order of the literal and label subsections since external users are more likely to use literals; * Fixed confusingly erratic whitespace in the sample config snippets,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6554:314,config,config,314,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6554,1,['config'],['config']
Modifiability,"I am aiming to run several thousand samples using Cromwell server on AWS. In testing, when submitting more than a few jobs to batch, I see many errors like:. ```; Caused by: software.amazon.awssdk.services.batch.model.BatchException: Too Many Requests (Service: null; Status Code: 429; Request ID: b8d3f02a-deee-11e8-8f12-b5957ed5827f); ```. I think this has to do with AWS batch limits. The recommendation, it appears, is to set the concurrent-job-limit in cromwell config to some number like 16. (Setting to 100 results in the errors above). While that fixes the errors, it seems to limit the scale of what can be done on AWS. So, a few questions:. 1. Does the job submission mechanism (batch vs single) affect this behavior?; 2. Would the use of scatter-gather over large batches of otherwise independent samples help?; 3. Are there limit increases that can or should be requested from AWS to make batch more amenable to large numbers of workflows?; 4. Are the best practices for AWS different than for GCP with respect to workflow authoring and submission?. Thanks for any thoughts and sorry if I missed something obvious in the docs.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4355:467,config,config,467,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4355,1,['config'],['config']
Modifiability,"I am constantly having issues when I run docker-compose of cromwell (I use https://github.com/broadinstitute/cromwell/tree/develop/scripts/docker-compose-mysql where I provide my configutation). Even though I do not have docker-user in my application.conf file when I run my pipelines, I get:; ```; cromwell_1 | [ERROR] [05/20/2017 12:57:46.015] [cromwell-system-akka.dispatchers.engine-dispatcher-22] [akka://cromwell-system/user/cromwell-service/WorkflowManagerActor/WorkflowActor-f7fdd305-d137-4128-bf68-7c39fd6c834b/WorkflowInitializationActor-f7fdd305-d137-4128-bf68-7c39fd6c834b/Local] Error parsing generated wdl:; cromwell_1 | task submit {; cromwell_1 | ; cromwell_1 | String job_id; cromwell_1 | String job_name; cromwell_1 | String cwd; cromwell_1 | String out; cromwell_1 | String err; cromwell_1 | String script; cromwell_1 | String? docker Int? max_runtime = 2; cromwell_1 | command {; cromwell_1 | /bin/bash ${script}; cromwell_1 | }; cromwell_1 | }; cromwell_1 | ; cromwell_1 | ; cromwell_1 | task submit_docker {; cromwell_1 | ; cromwell_1 | String job_id; cromwell_1 | String job_name; cromwell_1 | String cwd; cromwell_1 | String out; cromwell_1 | String err; cromwell_1 | String script; cromwell_1 | ; cromwell_1 | String docker_cwd; cromwell_1 | String? docker Int? max_runtime = 2; cromwell_1 | command {; cromwell_1 | ; cromwell_1 | docker run \; cromwell_1 | --rm -i \; cromwell_1 | ${""--user "" + docker_user} \; cromwell_1 | --entrypoint /bin/bash \; cromwell_1 | -v ${cwd}:${docker_cwd} \; cromwell_1 | ${docker} ${script}; cromwell_1 | ; cromwell_1 | }; cromwell_1 | }; cromwell_1 | java.lang.RuntimeException: Error parsing generated wdl:; cromwell_1 | task submit {; cromwell_1 | ; cromwell_1 | String job_id; cromwell_1 | String job_name; cromwell_1 | String cwd; cromwell_1 | String out; cromwell_1 | String err; cromwell_1 | String script; cromwell_1 | String? docker Int? max_runtime = 2; cromwell_1 | command {; cromwell_1 | /bin/bash ${script}; cromwell_1 | }; cromw",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2284:179,config,configutation,179,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2284,1,['config'],['configutation']
Modifiability,"I am currently running cromwell standalone **run** mode for running jobs. However, when I try to run two jobs at the same time, I get a connection time out(*see stack trace below). List of things I tried are:. - increasing the time limit but didn't work; - clearing db because db might have grown big but didn't work; - increasing max number of connections by increasing size of db but didn't work. Is it not possible to start two runs at the same time since cromwell db gets locked by the previous run until it is finished? If yes, is there any other way to do it?. PS: I understand that cromwell provides `server` mode where we can submit runs via REST API end points. However, we are working on HPC cluster where we don't have admin privileges to start server and submit requests to api. Backend: `slurm`; Workflow: [Link](https://github.com/biowdl/RNA-seq/blob/develop/RNA-seq.wdl). <details>; <summary>Config</summary>. ```; backend {. default = slurm. providers {; slurm {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; runtime-attributes = """"""; Int time_minutes = 600; Int cpu = 4; #Int memory = 500; String queue = ""short""; String map_path = ""/shared/rna-seq""; String partition = ""compute""; String root = ""/shared/rna-seq/cromwell-executions""; """""". # If an 'exit-code-timeout-seconds' value is specified:; # - check-alive will be run at this interval for every job; # - if a job is found to be not alive, and no RC file appears after this interval; # - Then it will be marked as Failed.; # Warning: If set, Cromwell will run 'check-alive' for every job at this interval. # exit-code-timeout-seconds = 120. submit = """"""; task=`echo ${job_name}|cut -d'_' -f3`; echo $task; image=`grep ""\b$task\b"" ${map_path}/map.txt |cut -d',' -f2`; echo $PWD; echo $image; if [ ! -z $image ]; then \; echo ""Inside Singularity exec""; \; echo ""CPU count: "" ${cpu}; \; echo ""time_minutes: "" ${time_minutes}; \; sbatch -J ${job_name} -D ${cwd} -c ${cpu} -o ${out}",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6208:907,Config,Config,907,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6208,1,['Config'],['Config']
Modifiability,"I am running on a local backend (laptop) and have noticed that the number of tasks running simultaneously appears to be unlimited? If this is the case, would it be possible to add config parameters to local backends to limit cpu and memory usage to that available?",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2365:180,config,config,180,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2365,1,['config'],['config']
Modifiability,"I am testing the cromwell workflow on NAVER Cloud Platform (NCP). I tried setting using custom configuration of your documentation in github (https://github.com/broadinstitute/cromwell/tree/develop/cromwell.example.backends), but I failed. I would like to set configuration of backend including docker container and object storage (comparable with AWS S3) to the same level as AWS or GCP configuration in cromwell documentation. How can I do this?. <!--; Hi! Thanks for taking the time to report feedback. Before posting an issue over in Jira tracker, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're almost in the right place. -->. <!-- You'll want to go to https://broadworkbench.atlassian.net/projects/BA/issues and then tell us: -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6548:95,config,configuration,95,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6548,4,['config'],['configuration']
Modifiability,"I am trying to adapt a WDL workflow originally developed for DNAnexus, to work in AWS Batch. I am running from ""develop"" branch on Mac, server mode. The workflow seems to run on AWS, but then fails when checking for output logs in S3... inputs: [demux_plus_inputs.json.txt](https://github.com/broadinstitute/cromwell/files/2099495/demux_plus_inputs.json.txt); workflow: [demux_only.wdl.txt](https://github.com/broadinstitute/cromwell/files/2099496/demux_only.wdl.txt); resource file: [workflows.zip](https://github.com/broadinstitute/cromwell/files/2099470/workflows.zip); config file, which shows some attempts to add the local filesystem, since I get an error about that: ; [aws.conf.txt](https://github.com/broadinstitute/cromwell/files/2099528/aws.conf.txt). ```; 2018-06-13 14:29:27,796 cromwell-system-akka.dispatchers.api-dispatcher-72 INFO - Unspecified type (Unspecified version) workflow a67833cb-b894-4790-872f-9f3104cab60c submitted; 2018-06-13 14:29:44,760 cromwell-system-akka.dispatchers.engine-dispatcher-5 INFO - 1 new workflows fetched; 2018-06-13 14:29:44,761 cromwell-system-akka.dispatchers.engine-dispatcher-5 INFO - WorkflowManagerActor Starting workflow UUID(a67833cb-b894-4790-872f-9f3104cab60c); 2018-06-13 14:29:44,765 cromwell-system-akka.dispatchers.engine-dispatcher-5 INFO - WorkflowManagerActor Successfully started WorkflowActor-a67833cb-b894-4790-872f-9f3104cab60c; 2018-06-13 14:29:44,765 cromwell-system-akka.dispatchers.engine-dispatcher-5 INFO - Retrieved 1 workflows from the WorkflowStoreActor; 2018-06-13 14:29:44,774 cromwell-system-akka.dispatchers.engine-dispatcher-32 INFO - WorkflowStoreHeartbeatWriteActor configured to flush with batch size 10000 and process rate 2 minutes.; 2018-06-13 14:29:45,255 cromwell-system-akka.dispatchers.engine-dispatcher-32 INFO - MaterializeWorkflowDescriptorActor [UUID(a67833cb)]: Parsing workflow as WDL draft-2; 2018-06-13 14:29:46,004 cromwell-system-akka.dispatchers.engine-dispatcher-32 INFO - MaterializeWorkflowDe",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3774:15,adapt,adapt,15,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3774,2,"['adapt', 'config']","['adapt', 'config']"
Modifiability,"I am trying to run Cromwell with docker images that were loaded with `docker load`. This means that the digests are unavailable (i.e. `<none>`). Unforutnately, this means that when looking up the image locally (i.e. when the config `docker.hash-lookup.method=""local""` is used), the image is not found. The offending lines of code are:; https://github.com/broadinstitute/cromwell/blob/1898d8103a06d160dc721d464862313e78ee7a2c/dockerHashing/src/main/scala/cromwell/docker/local/DockerCliClient.scala#L26; https://github.com/broadinstitute/cromwell/blob/1898d8103a06d160dc721d464862313e78ee7a2c/dockerHashing/src/main/scala/cromwell/docker/local/DockerCliClient.scala#L78-L92. Can we instead use the image ID instead of the digest when using local images?. <details>. <summary>log output</summary>. ```; [INFO] [09/16/2019 11:07:14.821] [cromwell-system-akka.dispatchers.engine-dispatcher-40] [akka://cromwell-system/user/SingleWorkflowRunnerActor/JobExecutionTokenDispenser] Not triggering log of token queue status. Effective log interval = None; [INFO] [09/16/2019 11:07:14.830] [cromwell-system-akka.dispatchers.engine-dispatcher-76] [akka://cromwell-system/user/SingleWorkflowRunnerActor/JobExecutionTokenDispenser] Assigned new job execution tokens to the following groups: 2b766fe6: 1; [2019-09-16 11:07:16,20] [error] Docker pull failed; java.lang.RuntimeException: Error running: docker pull <image>; Exit code: 1; Error response from daemon: pull access denied for <image> repository does not exist or may require 'docker login': denied: requested access to the resource is denied. 	at cromwell.docker.local.DockerCliClient.$anonfun$forRun$1(DockerCliClient.scala:58); 	at scala.util.Try$.apply(Try.scala:213); 	at cromwell.docker.local.DockerCliClient.forRun(DockerCliClient.scala:50); 	at cromwell.docker.local.DockerCliClient.pull(DockerCliClient.scala:37); 	at cromwell.docker.local.DockerCliClient.pull$(DockerCliClient.scala:36); 	at cromwell.docker.local.DockerCliClient$.pull(DockerCliC",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5178:225,config,config,225,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5178,1,['config'],['config']
Modifiability,"I am trying to run a simple WDL file under SGE. The documentation tells me to take the [application.conf](https://raw.githubusercontent.com/broadinstitute/cromwell/develop/core/src/main/resources/application.conf) file and uncomment the SGE section. . Cromwell will very quickly raise an exception:. ```; Exception in thread ""main"" com.typesafe.config.ConfigException$Missing: No configuration setting found for key 'backendsAllowed'; at com.typesafe.config.impl.SimpleConfig.findKeyOrNull(SimpleConfig.java:152); at com.typesafe.config.impl.SimpleConfig.findOrNull(SimpleConfig.java:170); at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:184); at com.typesafe.config.impl.SimpleConfig.find(SimpleConfig.java:189); at com.typesafe.config.impl.SimpleConfig.getList(SimpleConfig.java:252); at com.typesafe.config.impl.SimpleConfig.getHomogeneousUnwrappedList(SimpleConfig.java:323); at com.typesafe.config.impl.SimpleConfig.getStringList(SimpleConfig.java:381); at cromwell.server.WorkflowManagerSystem$class.allowedBackends(WorkflowManagerSystem.scala:24); at cromwell.Main$$anon$1.allowedBackends(Main.scala:97); at cromwell.server.WorkflowManagerSystem$class.$init$(WorkflowManagerSystem.scala:27); at cromwell.Main$$anon$1.<init>(Main.scala:97); at cromwell.Main.<init>(Main.scala:97); at cromwell.Main$.delayedEndpoint$cromwell$Main$1(Main.scala:49); at cromwell.Main$delayedInit$body.apply(Main.scala:31); at scala.Function0$class.apply$mcV$sp(Function0.scala:34); at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:12); at scala.App$$anonfun$main$1.apply(App.scala:76); at scala.App$$anonfun$main$1.apply(App.scala:76); at scala.collection.immutable.List.foreach(List.scala:381); at scala.collection.generic.TraversableForwarder$class.foreach(TraversableForwarder.scala:35); at scala.App$class.main(App.scala:76); at cromwell.Main$.main(Main.scala:31); at cromwell.Main.main(Main.scala); ```. I managed to fix _this_ exception by changing the configuration fil",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1406:345,config,config,345,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1406,10,"['Config', 'config']","['ConfigException', 'config', 'configuration']"
Modifiability,"I am trying to run the GATK4 workflow on Cromwell using the Spark backend. The WDL is from the Broad's GitHub repo:; https://github.com/broadinstitute/gatk4-data-processing/blob/master/processing-for-variant-discovery-gatk4.wdl. The following is my cromwell conf file where cromwell is running on the namenode of the spark cluster:; ```json; include required(classpath(""application"")). backend {; default = ""Spark""; providers {; Spark {; actor-factory = ""cromwell.backend.impl.spark.SparkBackendFactory""; config {; root: ""/mnt/data/cromwell"". filesystems {; local {; localization: [; ""hard-link"", ""soft-link"", ""copy""; ]; caching {; duplication-strategy: [; ""hard-link"", ""soft-link"", ""copy""; ]; }; }; }; master: ""yarn""; deployMode: ""cilent""; }; }; }; }; ```. It looks like the shell script cromwell is generating to submit the job to spark using spark-submit has a syntax error in it, so the workflow fails immediately. ```bash; [ec2-user@ip-10-66-51-33 execution]$ pwd; /mnt/data/cromwell/PreProcessingForVariantDiscovery_GATK4/a46f0127-f6e8-4887-ae7d-c3fc08f834e4/call-GetBwaVersion/execution; ```. ```bash; [ec2-user@ip-10-66-51-33 execution]$ ls -l; total 8; -rwxr--r-- 1 root root 1182 Feb 4 19:37 script; -rw-r--r-- 1 root root 296 Feb 4 19:37 stderr; -rw-r--r-- 1 root root 0 Feb 4 19:37 stdout; ```. ```bash; [ec2-user@ip-10-66-51-33 execution]$ cat stderr; /mnt/data/cromwell/PreProcessingForVariantDiscovery_GATK4/a46f0127-f6e8-4887-ae7d-c3fc08f834e4/call-GetBwaVersion/execution/script: 3: /mnt/data/cromwell/PreProcessingForVariantDiscovery_GATK4/a46f0127-f6e8-4887-ae7d-c3fc08f834e4/call-GetBwaVersion/execution/script: Syntax error: ""("" unexpected; ```. ```; [ec2-user@ip-10-66-51-33 execution]$ cat script ; #!/bin/sh; cd /mnt/data/cromwell/PreProcessingForVariantDiscovery_GATK4/a46f0127-f6e8-4887-ae7d-c3fc08f834e4/call-GetBwaVersion/execution; spark-submit --master yarn --total-executor-cores 1 --deploy-mode cilent --class GATK4 --executor-memory 1gb InstantiatedCommand(# Not setti",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4611:505,config,config,505,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4611,1,['config'],['config']
Modifiability,"I am using Cromwell version 86 to run my workflow localy, but I encountered an issue. After the workflow completes, a warning appears, and it has been bothering me for a long time. Can you please provide guidance on how to resolve this?. ![image](https://github.com/broadinstitute/cromwell/assets/41176704/bb754226-83e6-4058-ad57-cf6da9333473). I have also checked my WDL file and found no issues. And I am not using a configuration file. Thanks!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7349:419,config,configuration,419,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7349,1,['config'],['configuration']
Modifiability,"I am using latest cromwell develop docker container. When I run ""abort"" command it internall executes docker.kill script that looks like:; ""; #!/bin/bash ; docker kill `cat /pipelines/cromwell-executions/vsearch/81c51e4e-756c-47f7-8dd6\; -57b9c2981162/call-global_search/execution/docker_cid`; ""; However, docker_cid is never created. So, all the abort commands that I do stop the cromwell tasks but never stop docker containers that were started by it. My docker-stack configuration is https://github.com/antonkulaga/cromwell-client/blob/master/services/pipelines.yml. It uses slightly modified cromwell:develop container https://github.com/antonkulaga/cromwell-client/blob/master/services/cromwell/Dockerfile. I also share docker sockets there and everything functions well with the exception of abort.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4011:470,config,configuration,470,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4011,1,['config'],['configuration']
Modifiability,"I assume this error has to do with my config, but not particularly clear what is going on... Here is the workflow, inputs, and config; I am running from swagger:; [myWorkflow_awsbatch.wdl.txt](https://github.com/broadinstitute/cromwell/files/2077985/myWorkflow_awsbatch.wdl.txt). [aws.conf.txt](https://github.com/broadinstitute/cromwell/files/2077989/aws.conf.txt). [hello.inputs.txt](https://github.com/broadinstitute/cromwell/files/2078033/hello.inputs.txt). ```; 2018-06-06 16:18:30,442 cromwell-system-akka.dispatchers.api-dispatcher-215 INFO - WDL (Unspecified version) workflow 948bf608-f91b-46a7-b892-86454be067fd submitted; 2018-06-06 16:18:47,222 cromwell-system-akka.dispatchers.engine-dispatcher-32 INFO - 1 new workflows fetched; 2018-06-06 16:18:47,222 cromwell-system-akka.dispatchers.engine-dispatcher-32 INFO - WorkflowManagerActor Starting workflow UUID(948bf608-f91b-46a7-b892-86454be067fd); 2018-06-06 16:18:47,223 cromwell-system-akka.dispatchers.engine-dispatcher-32 INFO - WorkflowManagerActor Successfully started WorkflowActor-948bf608-f91b-46a7-b892-86454be067fd; 2018-06-06 16:18:47,223 cromwell-system-akka.dispatchers.engine-dispatcher-32 INFO - Retrieved 1 workflows from the WorkflowStoreActor; 2018-06-06 16:18:47,229 cromwell-system-akka.dispatchers.engine-dispatcher-32 INFO - MaterializeWorkflowDescriptorActor [UUID(948bf608)]: Parsing workflow as WDL draft-2; 2018-06-06 16:18:47,232 cromwell-system-akka.dispatchers.engine-dispatcher-32 ERROR - WorkflowManagerActor Workflow 948bf608-f91b-46a7-b892-86454be067fd failed (during MaterializingWorkflowDescriptorState): cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor$$anon$1: Workflow input processing failed:; Boxed Error; scala.concurrent.impl.Promise$.resolver(Promise.scala:83); scala.concurrent.impl.Promise$.scala$concurrent$impl$Promise$$resolveTry(Promise.scala:75); scala.concurrent.impl.Promise$DefaultPromise.tryComplete(Promise.scala:280); scala.concurrent.Promise.c",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3736:38,config,config,38,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736,2,['config'],['config']
Modifiability,I believe the deletion of $HOME/.config/gcloud/gce file before each gsutil invocation was intended to be a workaround for a gsutil issue. The issue was believed to be fixed in gcloud 275 but since the hanging issues appear to persist I added back in the deletion of this file everywhere I could find.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5361:33,config,config,33,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5361,1,['config'],['config']
Modifiability,"I believe this is working. Travis successfully writes the Vault token to the file, and Vault is aware of it, but the old auth method (via the `VAULT_TOKEN` env var) supersedes this one, so we're not actually using the new token yet. This warning is printed in the build logs (no token is printed):. ```; WARNING! The VAULT_TOKEN environment variable is set! This takes precedence; over the value set by this command. To use the value set by this command,; unset the VAULT_TOKEN environment variable or set it to the token displayed; below.; ```. Before merging this I'll remove the `VAULT_TOKEN` env var and retry the build. If it succeeds, I'll merge this ticket. If not, I'll get `VAULT_TOKEN` added back in and keep trying.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6669:341,variab,variable,341,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6669,2,['variab'],['variable']
Modifiability,"I cannot mutate any variables outside of the loop. I cannot even rewrite an array by its index if array is declared outside of while loop. Why the hell do we need loops then?; ```wdl; Array[Int] array = [""one"", ""two"", ""three""]; Int i = 0; Int len = length(array); while(i < len){; i = i +1 #does not work; array[i] = ""other value"" #does not work; #some other stuff; }; ```. I also tried to do the same with scatters, same problems (I cannot change variables outside of the loop). That means that both while and scatter loops are half-functional in Cromwell.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3305:20,variab,variables,20,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3305,3,"['rewrite', 'variab']","['rewrite', 'variables']"
Modifiability,I cannot test this change as I do not have the build environment set up. Is is intentional that this 'cloud' feature is inherited by the SGE backend? I am fixing an issue caused by a feature I do not need. I wonder if it could be placed in the epilogue for user configurations. Isn't that the purpose of epilogue and configuration?,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3864:120,inherit,inherited,120,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3864,3,"['config', 'inherit']","['configuration', 'configurations', 'inherited']"
Modifiability,"I cant get the sra filesystem to work. Here is the error:. ```; [2020-08-21 11:08:59,62] [info] WorkflowManagerActor Workflow dbd5cdc0-c79a-42cd-b929-56ddb1115467 failed (during InitializingWorkflowState): common.exception.AggregatedMessageException: Failed to instantiate backend filesystem:; Cannot find a filesystem with name sra in the configuration. Available filesystems: ftp, s3, gcs, oss, drs, http; 	at common.validation.Validation$ValidationChecked$.$anonfun$unsafe$2(Validation.scala:98); 	at cats.syntax.EitherOps$.valueOr$extension(either.scala:66); 	at common.validation.Validation$ValidationChecked$.unsafe$extension(Validation.scala:98); 	at cromwell.backend.BackendConfigurationDescriptor.configuredPathBuilderFactories$lzycompute(backend.scala:109); 	at cromwell.backend.BackendConfigurationDescriptor.configuredPathBuilderFactories(backend.scala:108); 	at cromwell.backend.BackendConfigurationDescriptor.pathBuilders(backend.scala:120); 	at cromwell.backend.standard.StandardInitializationActor.pathBuilders$lzycompute(StandardInitializationActor.scala:62); 	at cromwell.backend.standard.StandardInitializationActor.pathBuilders(StandardInitializationActor.scala:62); 	at cromwell.backend.google.pipelines.common.PipelinesApiInitializationActor.$anonfun$workflowPaths$2(PipelinesApiInitializationActor.scala:137); 	at scala.concurrent.Future.$anonfun$flatMap$1(Future.scala:307); 	at scala.concurrent.impl.Promise.$anonfun$transformWith$1(Promise.scala:41); 	at scala.concurrent.impl.CallbackRunnable.run(Promise.scala:64); 	at akka.dispatch.BatchingExecutor$AbstractBatch.processBatch(BatchingExecutor.scala:55); 	at akka.dispatch.BatchingExecutor$BlockableBatch.$anonfun$run$1(BatchingExecutor.scala:92); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); 	at scala.concurrent.BlockContext$.withBlockContext(BlockContext.scala:85); 	at akka.dispatch.BatchingExecutor$BlockableBatch.run(BatchingExecutor.scala:92); 	at akka.dispatch.TaskInvocation.run(Abst",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5793:340,config,configuration,340,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5793,3,['config'],"['configuration', 'configuredPathBuilderFactories']"
Modifiability,"I do not really know how to give you more relevant information, but IntelliJ is complaining that the WDL plugin has an error ... ```; Cyclic TextAttributesKey dependency found: BAD_CHARACTER->BAD_CHARACTER; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2276:105,plugin,plugin,105,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2276,1,['plugin'],['plugin']
Modifiability,"I get an `ArrayIndexOutOfBoundsException` error when starting the latest `develop` branch in server mode with a mysql (`mariadb-10.3.12-5.fc30.x86_64`) backend.; ```; [jeremiah@localhost cromwell]$ java -Dconfig.file=/home/jeremiah/cromwell.mysql.conf -jar server/target/scala-2.12/cromwell-37-56b0390-SNAP.jar server; 2019-01-31 18:29:28,169 INFO - Running with database db.url = jdbc:mysql://localhost/cromwell?rewriteBatchedStatements=true; 2019-01-31 18:29:32,763 INFO - SELECT COUNT(*) FROM cromwell.DATABASECHANGELOGLOCK; 2019-01-31 18:29:32,786 INFO - CREATE TABLE cromwell.DATABASECHANGELOGLOCK (ID INT NOT NULL, `LOCKED` BIT(1) NOT NULL, LOCKGRANTED datetime NULL, LOCKEDBY VARCHAR(255) NULL, CONSTRAINT PK_DATABASECHANGELOGLOCK PRIMARY KEY (ID)); 2019-01-31 18:29:32,845 INFO - SELECT COUNT(*) FROM cromwell.DATABASECHANGELOGLOCK; 2019-01-31 18:29:32,853 INFO - DELETE FROM cromwell.DATABASECHANGELOGLOCK; 2019-01-31 18:29:32,854 INFO - INSERT INTO cromwell.DATABASECHANGELOGLOCK (ID, `LOCKED`) VALUES (1, 0); 2019-01-31 18:29:32,869 INFO - SELECT `LOCKED` FROM cromwell.DATABASECHANGELOGLOCK WHERE ID=1; 2019-01-31 18:29:32,888 INFO - Successfully acquired change log lock; 2019-01-31 18:29:35,077 INFO - Creating database history table with name: cromwell.DATABASECHANGELOG; 2019-01-31 18:29:35,078 INFO - CREATE TABLE cromwell.DATABASECHANGELOG (ID VARCHAR(255) NOT NULL, AUTHOR VARCHAR(255) NOT NULL, FILENAME VARCHAR(255) NOT NULL, DATEEXECUTED datetime NOT NULL, ORDEREXECUTED INT NOT NULL, EXECTYPE VARCHAR(10) NOT NULL, MD5SUM VARCHAR(35) NULL, `DESCRIPTION` VARCHAR(255) NULL, COMMENTS VARCHAR(255) NULL, TAG VARCHAR(255) NULL, LIQUIBASE VARCHAR(20) NULL, CONTEXTS VARCHAR(255) NULL, LABELS VARCHAR(255) NULL, DEPLOYMENT_ID VARCHAR(10) NULL); 2019-01-31 18:29:35,271 INFO - SELECT COUNT(*) FROM cromwell.DATABASECHANGELOG; 2019-01-31 18:29:35,279 INFO - Reading from cromwell.DATABASECHANGELOG; 2019-01-31 18:29:35,280 INFO - SELECT * FROM cromwell.DATABASECHANGELOG ORDER BY DATEEX",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4605:413,rewrite,rewriteBatchedStatements,413,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4605,1,['rewrite'],['rewriteBatchedStatements']
Modifiability,"I had `hasing-strategy` instead of `hashing-strategy` in my config and lost loads of hours trying to debug the unbearably slow caching I was experiencing, and it turns out that the entire time Cromwell was simply ignoring the config I had written because of the typo. Cromwell should emit warnings when it sees config it doesn't recognize instead of silently ignoring them.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7109:60,config,config,60,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7109,3,['config'],['config']
Modifiability,"I have a [CWL workflow](https://gist.github.com/ruchim/df038401cc68383b75310422ece8e088) with a docker requirement. When I run it against a Config backend that doesn't have docker support ([backend config](https://gist.github.com/ruchim/4228058d39e6306f0a3e12cd92e5123c)), I expect the workflow to fail -- yet it simply succeeds by running the submit command without using docker. AC: When a workflow requires docker and a backend doesn't support docker, fail the workflow.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3579:140,Config,Config,140,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3579,2,"['Config', 'config']","['Config', 'config']"
Modifiability,"I have a task that depends on files generated by a dependent job, e.g. job A generates A.out and job B needs A.out in the current working directory. The applications expect to see them in the current working directory, so I think I need to copy them over. However, is there a WDL variable that stores the execution directory so I can copy those files over? Or is there another way to achieve this?. Regards,",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7254:280,variab,variable,280,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7254,1,['variab'],['variable']
Modifiability,"I have a working cromwell/AWS batch configuration.; I have a simple workflow called three_task_sequence.wdl which I am able to run on AWS backend, and see the outputs in s3. However, submitting this job to my cromwell server:; `curl -X POST ""http://172.20.1.67:8001/api/workflows/v1"" -H ""accept: application/json"" -F ""workflowSource=@three_task_sequence.wdl"" -F ""workflowOptions=@workflow_options.json""; `; Where workflow_options.json content is:; ```; {; ""final_workflow_outputs_dir"": ""s3://nrglab-cromwell-genomics/cromwell-execution/out_bin_test""; }. ```. I'm getting the following error at the end of the workflow cromwell log:. ````; 2019-02-28 08:30:32,167 cromwell-system-akka.dispatchers.engine-dispatcher-30 ERROR - Access Denied (Service: S3Client; Status Code: 403; Request ID: FA1C7E97A7A33EDC); software.amazon.awssdk.services.s3.model.S3Exception: Access Denied (Service: S3Client; Status Code: 403; Request ID: FA1C7E97A7A33EDC); 	at software.amazon.awssdk.core.http.pipeline.stages.HandleResponseStage.handleErrorResponse(HandleResponseStage.java:114); 	at software.amazon.awssdk.core.http.pipeline.stages.HandleResponseStage.handleResponse(HandleResponseStage.java:72); 	at software.amazon.awssdk.core.http.pipeline.stages.HandleResponseStage.execute(HandleResponseStage.java:57); 	at software.amazon.awssdk.core.http.pipeline.stages.HandleResponseStage.execute(HandleResponseStage.java:40); 	at software.amazon.awssdk.core.http.pipeline.RequestPipelineBuilder$ComposingRequestPipelineStage.execute(RequestPipelineBuilder.java:239); 	at software.amazon.awssdk.core.http.pipeline.stages.TimerExceptionHandlingStage.execute(TimerExceptionHandlingStage.java:40); 	at software.amazon.awssdk.core.http.pipeline.stages.TimerExceptionHandlingStage.execute(TimerExceptionHandlingStage.java:30); 	at software.amazon.awssdk.core.http.pipeline.stages.RetryableStage$RetryExecutor.doExecute(RetryableStage.java:139); 	at software.amazon.awssdk.core.http.pipeline.stages.RetryableStage$RetryExecut",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4686:36,config,configuration,36,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4686,1,['config'],['configuration']
Modifiability,"I have been experimenting some random failures due to docker containers being killed for some reason on my system (not only https://github.com/broadinstitute/cromwell/issues/3370), but if I re-run the workflow with caching enabled then this calls end without failure and the pipeline can continue and work. Nevertheless, it is tedious to re-run a whole pipeline due to random failures and rely on caching for avoid re-computation. This is something that can be avoided by providing a configuration option for retry jobs (cromwell level) or add to some tasks a runtime attribute (WDL level) to set the number of retries that can be done per-task. Do you think that this is possible in the near future to avoid re-running a whole pipeline due to a random failure in a concrete task(s)?",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3417:484,config,configuration,484,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3417,1,['config'],['configuration']
Modifiability,"I have configured a SLURM backend for Cromwell and have encountered unusual behavior while trying to configure memory as a runtime attribute. . I define a runtime attribute Int with default value in my Cromwell configuration file and attempt to override this in my task WDL. Whether the override succeeds seems to depend on the variable name used! This is very confusing behavior; I expect to either receive a message that a variable name is not allowed, or the override should succeed. . Fails: ""memory_mb""; Succeeds: ""requested_memory_per_core"". I am verifying whether the override succeeds by checking the Cromwell output [task]/execution/script.submit. . ```; SLURM {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; runtime-attributes = """"""; Int runtime_minutes = 600; Int bsub_cpu = 1; Int memory_mb = 1000; String queue; """"""; ; submit = """"""; 			sbatch -J ${job_name} -D ${cwd} -o ${out} -e ${err} -t ${runtime_minutes} -p ${queue} \; 			${""-n "" + bsub_cpu} \; 			--mem-per-cpu=${memory_mb} \; 			--wrap ""/bin/bash ${script}""; 		""""""; kill = ""scancel ${job_id}""; check-alive = ""squeue -j ${job_id}""; job-id-regex = ""Submitted batch job (\\d+).*""; }; }; ```. ```; workflow tutorialWorkflow{; 	call task_A { input : in=""testing"" }; 	call task_B { input : in=task_A.out }; 	call task_C { input : in=task_A.out }; }. task task_A{; 	String in. 	command{; 		echo 'This is task A ${in}.'; 	}	; 	output{; 		String out='This is task A ${in}'; 	}; 	runtime{; 		bsub_cpu: 1; 		runtime_minutes: 10; 		memory_mb: 100; 		queue: ""short""; 	}; }. task task_B{; 	String in; 	command{; 		echo 'This is task B ${in}.'; 	}; 	runtime{; 		bsub_cpu: 2; 		runtime_minutes: 15; 		memory_mb: 110; 		queue: ""short""; 	}; }. task task_C{; 	String in; 	command{; 		echo 'This is task C ${in}.'; 	}; 	runtime{; 		runtime_minutes: 25; 		memory_mb: 210; 		queue: ""short""; 	}; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2068:7,config,configured,7,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2068,8,"['Config', 'config', 'variab']","['ConfigBackendLifecycleActorFactory', 'config', 'configuration', 'configure', 'configured', 'variable']"
Modifiability,"I have configured localstack in Docker with S3, IAM and EC2 services on localhosts(AWS Batch is not supported). I would like to understand how Cromwell can be configured to interact with existing file systems instead of AWS. I found this option, but I do not really understand how it can be used correctly and whether it will work at least with S3:. **### Configuration**. _Cromwell's default configuration defines an instance of the HTTP filesystem named `http`. There is no additional configuration; required for the HTTP filesystem itself so adding HTTP filesystem support to a backend is a simple as; adding a reference to this filesystem within the backend's `filesystems` stanza. e.g. Cromwell's default `Local` shared filesystem; backend is configured like this (a PAPI version 2 backend would be configured in a similar way):_. ```; backend {; default = ""Local""; providers {; Local {; ...; config {; filesystems {; local {; ...; }; http { }; }; }; ...; }; ...; }; }; ```. Can I solve this problem without touching the source code?",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5055:7,config,configured,7,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5055,8,"['Config', 'config']","['Configuration', 'config', 'configuration', 'configured']"
Modifiability,"I have locally configured mariaDB my.cnf as follows：. > [mysqld]; max_connections=5024; thread_cache_size=1000; datadir=/zfsyt1/B2C_RD_P2/USER/fuxiangke/Cromwell/Data/; socket=/zfsyt1/B2C_RD_P2/USER/fuxiangke/Cromwell/socket/cromwell.sock; default-time-zone='+8:00'; port=3310; skip-character-set-client-handshake; init_connect='SET collation_connection = utf8mb4_unicode_ci'; init_connect='SET NAMES utf8mb4'; character-set-server=utf8mb4; collation-server=utf8mb4_unicode_ci; #open slow query logging; slow_query_log = ON; slow_query_log_file = /zfsyt1/B2C_RD_P2/USER/fuxiangke/Cromwell/log-files/slow_cromwell.log; long_query_time = 1; [mysqld_safe]; log-error=/zfsyt1/B2C_RD_P2/USER/fuxiangke/Cromwell/log-files/error.log; pid-file=/zfsyt1/B2C_RD_P2/USER/fuxiangke/Cromwell/pid/mysqld_cromwell.pid; [client]; default-character-set=utf8mb4; > . Then I configured the flow. The following error was reported when scatter 478 tasks were needed in one step：. > 2021-12-06 17:03:51,401 cromwell-system-akka.dispatchers.service-dispatcher-9 ERROR - Failed to summarize metadata. java.sql.SQLException: null; at com.mysql.cj.jdbc.exceptions.SQLError.createSQLException(SQLError.java:129); at com.mysql.cj.jdbc.exceptions.SQLExceptionsMapping.translateException(SQLExceptionsMapping.java:122); at com.mysql.cj.jdbc.ConnectionImpl.setAutoCommit(ConnectionImpl.java:2045); at com.zaxxer.hikari.pool.ProxyConnection.setAutoCommit(ProxyConnection.java:388); at com.zaxxer.hikari.pool.HikariProxyConnection.setAutoCommit(HikariProxyConnection.java); at slick.jdbc.JdbcBackend$BaseSession.startInTransaction(JdbcBackend.scala:511); at slick.jdbc.JdbcActionComponent$StartTransaction$.run(JdbcActionComponent.scala:37); at slick.jdbc.JdbcActionComponent$StartTransaction$.run(JdbcActionComponent.scala:34); at slick.basic.BasicBackend$DatabaseDef$$anon$3.liftedTree1$1(BasicBackend.scala:276); at slick.basic.BasicBackend$DatabaseDef$$anon$3.run(BasicBackend.scala:276); at java.base/java.util.concurrent.ThreadPo",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6583:15,config,configured,15,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6583,2,['config'],['configured']
Modifiability,"I have tried the [tutorial](https://cromwell.readthedocs.io/en/stable/tutorials/PipelinesApi101/) to run Cromwell on Google Cloud. I did not get very far. I have followed the long set of instructions. I have logged in with my `<google-user-id>`, I have set my own `<google-project-id>`. I have created my own bucket. I have generate my service account key with the command:; ```; gcloud iam service-accounts keys create sa.json --iam-account ""$EMAIL""; ```. Then I run the hello.wdl with the command:; ```; GOOGLE_APPLICATION_CREDENTIALS=sa.json; java -Dconfig.file=google.conf -jar cromwell-52.jar run hello.wdl -i hello.inputs; ```. But I get the following error:; ```; [2020-07-27 18:34:00,37] [error] PipelinesApiAsyncBackendJobExecutionActor [3d2d7a27wf_hello.hello:NA:1]: Error attempting to Execute; cromwell.engine.io.IoAttempts$EnhancedCromwellIoException: [Attempted 1 time(s)] - StorageException: xxx@xxx.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project.; Caused by: com.google.cloud.storage.StorageException: xxx@xxx.iam.gserviceaccount.com does not have serviceusage.services.use access to the Google Cloud project.; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:227); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.create(HttpStorageRpc.java:308); 	at com.google.cloud.storage.StorageImpl$3.call(StorageImpl.java:213); 	at com.google.cloud.storage.StorageImpl$3.call(StorageImpl.java:210); 	at com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:105); 	at com.google.cloud.RetryHelper.run(RetryHelper.java:76); 	at com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:50); 	at com.google.cloud.storage.StorageImpl.internalCreate(StorageImpl.java:209); 	at com.google.cloud.storage.StorageImpl.create(StorageImpl.java:171); 	at cromwell.filesystems.gcs.GcsPath.request$1(GcsPathBuilder.scala:196); 	at cromwell.filesystems.gcs.GcsPath.$anonfun$writeContent$2",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5594:836,Enhance,EnhancedCromwellIoException,836,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5594,1,['Enhance'],['EnhancedCromwellIoException']
Modifiability,"I have zero idea whether this is the correct place to post an issue. The gatk forums [say to post here](https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team). There are messages here saying post on Jira?. I am attempting to set cromwell up to run with singularity. This is in an HPC environment with a brand new install of cromwell, where I don't have the ability to access or overwrite any global files, i.e. the application.conf file with all the defaults in it. It's a documentation issue rather than a problem with cromwell, which runs fine on the default configuration. . Documentation [here](https://cromwell.readthedocs.io/en/develop/tutorials/Containers/#singularity) suggests that I need to add code similar to that found [here](https://github.com/broadinstitute/cromwell/blob/develop/cromwell.example.backends/singularity.conf) to a config block of the backend.providers section in a configuration file similar to the file [cromwell.examples.conf](https://www.github.com/broadinstitute/cromwell/tree/develop/cromwell.examples.conf). Which, if you click that link, you'll see is broken. It might possibly be linked to [this issue](https://broadworkbench.atlassian.net/browse/BA-4810) on Jira?. As a result I have no idea what the conf file is supposed to look like, nor to be honest where it goes or how it's meant to be referenced. There's an issue [here](https://gatkforums.broadinstitute.org/wdl/discussion/12789/cromwell-configuration-on-slurm) which tells me I have to have ""include required(classpath(""application""))"" in the first line of the conf file, but apart from that I can't find anything on what the file should look like. . The documentation [here](https://cromwell.readthedocs.io/en/stable/tutorials/ConfigurationFiles/) and [here](https://cromwell.readthedocs.io/en/stable/Configuring/#overview) both suggest that the configuration files are for a server version of cromwell, whereas I have to run it from the command line, i.e. . ```; cromwell run <-o confi",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5560:577,config,configuration,577,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5560,3,['config'],"['config', 'configuration']"
Modifiability,I haven't been able to discern from the documentation if specifying GCE zones in the application config is possible. I see that it is listed as runtime config. Sorry if I am misunderstanding.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1795:97,config,config,97,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1795,2,['config'],['config']
Modifiability,"I know the I/O actor is not very trendy these days, but even if it ends up going away I thought this was a small change that could help with handling IO pressure in a better way.; Currently if an actor receives a backpressure message it waits more or less 5 seconds and retries. This uses configurable exponential backoff instead with a higher randomization of waiting times to avoid spikes as much as possible.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4043:289,config,configurable,289,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4043,1,['config'],['configurable']
Modifiability,"I labeled ""do not merge"" since I would like discussion first and there are one or two items that I need to figure out a good way to test. Once merged and in image one would update JAVA_OPTS similar to below to enable and modify the defaults. JAVA_OPTS=""-DLOG_MODE=FILEROLLER -DFILEROLLER_NAMEPATTERN=%d{yyyyMMddHHmm} -DFILEROLLER_NAME=crom -DFILEROLLER_DIR=/local/cromwell -DFILEROLLER_MAXHISTORY=3"". To try it out prior a full build I did the following. 1. Copy the logback.xml from this branch into some directory. make a logs subdirectory; 2. from that directory run the following. docker run -it --rm -p 8000:8000 -v ${PWD}:/working -v ${PWD}/logs:/local/cromwell -e JAVA_OPTS=""-Dlogback.configurationFile=/working/logback.xml -DLOG_MODE=FILEROLLER -DFILEROLLER_NAMEPATTERN=%d{yyyyMMddHHmm} -DFILEROLLER_NAME=crom -DFILEROLLER_DIR=/local/cromwell -DFILEROLLER_MAXHISTORY=3"" broadinstitute/cromwell:0.22-881e7b7 server. after running for several minutes logs directory should end up looking like:. 201611182054-crom; 201611182056-crom; crom. NOTE: FileRoller rotation seems to only happen when logs are generated. So IF your cromwell is not generating any log messages the logfile won't be rotated. So in my example above the logfile ""crom"" may have messages from several minutes ago (in my case). But when the next message comes in - crom will be rotated prior to the new log message being written. I think the rotated logfile will get the timestamp based on the date of the last log message in that file. Which is why in the list above there is a gap.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1692:692,config,configurationFile,692,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1692,1,['config'],['configurationFile']
Modifiability,I noticed an error in your tutorial:; https://cromwell.readthedocs.io/en/jg_add_http_doc/tutorials/AwsBatch101/. The aws.config you supply is missing:; numSubmitAttempts = 6; numCreateDefinitionAttempts = 6; from the config portion:. It was generating a confusing error and should be updated.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4278:121,config,config,121,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4278,2,['config'],['config']
Modifiability,"I offer for your consideration a PBSPro/Torque backend that we are using here at QIMR Berghofer (based on SGE one), if you think it might be useful to encourage external user uptake in the short term. I was going to hold off until you had finished the PBE work to refactor this functionality to work with that but I see that you've accepted a PR for LSF backend using the current structure and I don't know what your broader priorities are. If you don't think it's worth your time to review then that's ok too :)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1106:264,refactor,refactor,264,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1106,1,['refactor'],['refactor']
Modifiability,"I ran it using json ways and after configuring mysql and Call Caching it is still create a new project. here is my commands and config file. ```; java -jar -Dconfig.file=/work/share/ac7m4df1o5/bin/cromwell/3_config/udocker_slum.conf ../cromwell-84.jar run /work/share/ac7m4df1o5/bin/cromwell/1_pipeline/Exome_Germline_Single_Sample/ExomeGermlineSingleSample_v3.1.5.wdl -i D5327.NA12878.json -o ../options.json; ```. conf is. ```; include required(classpath(""application"")). docker {; hash-lookup {; enable = false; }; }; call-caching {; enabled = true; invalidate-bad-cache-results = true; }. backend {; default = slurm. providers {; slurm {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory"" ; config {; 	concurrent-job-limit = 5; runtime-attributes = """"""; Int runtime_minutes = 600; Int cpus = 2; Int requested_memory_mb_per_core = 8000; String? docker; """""". submit = """"""; sbatch \; --wait \; -J ${job_name} \; -D ${cwd} \; -t ${runtime_minutes} \; 	 -p wzhcexclu06 \; ${""-c "" + cpus} \; --mem-per-cpu=${requested_memory_mb_per_core} \; --wrap ""/bin/bash ${script}""; """""". submit-docker = """"""; # Pull the image using the head node, in case our workers don't have network access; # udocker pull ${docker}. sbatch \; -J ${job_name} \; -D ${cwd} \; -t ${runtime_minutes} \; 	 -p wzhcexclu06 \; ${""-c "" + cpus} \; --mem-per-cpu=${requested_memory_mb_per_core} \; --wrap ""udocker run -v ${cwd}:${docker_cwd} ${docker} ${job_shell} ${docker_script}""; """""". kill = ""scancel ${job_id}""; check-alive = ""squeue -j ${job_id}""; job-id-regex = ""Submitted batch job (\\d+).*""; }; }; }; }. ```. help pleas",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6920:35,config,configuring,35,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6920,5,"['Config', 'config']","['ConfigBackendLifecycleActorFactory', 'config', 'configuring']"
Modifiability,"I recently got into a trouble because of wrong caching in cromwell. In most of my pipelines I copy the results of last tasks to some folder which I define in the variable (unfortunately the option.json feature of cromwell to kind'of ""copy workflow results"" is useless for us as it copies all the nested trash, like ""id/execution"" instead of just resulting files). ; Unfortunately, my task that does the copying was cached even if the task on which it depends had different inputs (and was not cached). That means that we have a false positive caching and the copying task copies the same file from cache all over again.; Here is an example of my WDL. However, it fails in all WDLs where I use the copy-task for results; ```wdl; workflow Diamond_Blast {. Int threads; File db; File query; String result_name; String results_folder; String mode = ""blastx"". call diamond_blast {; input:; threads = threads,; database = db,; name = result_name,; query = query,; mode = mode. }. call copy as copy_results {; input:; files = [diamond_blast.out],; destination = results_folder; }. output {; File out = copy_results.out[0]; }. }. task diamond_blast {. Int threads; File database; File query; String name; String mode. command {; diamond ${mode} -d ${database} -q ${query} \; --more-sensitive -o ${name}.m8 \; -f 6 sseqid qseq score pident stitle qcovhsp qtitle \; }. runtime {; docker: ""quay.io/comp-bio-aging/diamond:latest""; }. output {; File out = name + "".m8""; }. }. task copy {; Array[File] files; String destination. command {; mkdir -p ${destination}; cp -L -R -u ${sep=' ' files} ${destination}; }. output {; Array[File] out = files; }; }; ```; and here is an example of the input:; ```json. Diamond_Blast.mode = ""blastp""; Diamond_Blast.query = ""/pipelines/indexes/GRAY_WHALE/NTJE01P.1.fasta""; Diamond_Blast.threads = 8; Diamond_Blast.result_name = ""graywhale_in_minkywhale_blastp""; Diamond_Blast.db = ""/pipelines/indexes/diamond/MINKY_WHALE_GCF_000493695.1.dmnd""; Diamond_Blast.results_folder = ""/pip",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3044:162,variab,variable,162,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3044,1,['variab'],['variable']
Modifiability,I see that in readme. ```; Configuring Spark Project; When using Spark backend uncomment the following Spark configuration in the application.conf file; ```. But I do not see it in application.conf Looks like this is outdated.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2033:27,Config,Configuring,27,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2033,2,"['Config', 'config']","['Configuring', 'configuration']"
Modifiability,"I set up a heavily scattered (~1000x) workflow to run overnight on my local machine (Mac OS Catalina, Intel hardware). The machine is set up to never sleep and was connected to AC power. My Cromwell config is set to only run one task at a time, ie, only one shard of a scattered task runs at a time. The workflow stopped processing on shard 885, which was the 233rd shard to start (shards appear to start in a random order, that's not an issue). It looks like the Docker container in question is getting created, but not used. The container is not running according to Docker Desktop and the Docker CLI tools (see output below). ### Workflow; I've seen this happen with a few workflows, but this time around it's this one (failure is occurring on second task): https://github.com/aofarrel/SRANWRP/blob/bioproject_stuff/workflows/is_this_tuberculosis.wdl. ### Ruled out; * Running tasks concurrently/Cromwell config not being respected: The workflow would have either hung Docker or tasks would have returned 137; * Docker application (not the container, the entire application) hanging, like what happens when trying to run tasks concurrently on a local machine: `docker run -it` works in a new terminal window; * IP getting blocked: This would cause error output, and I can still ping SRA from the same IP without issue; * Loss of internet: This would cause error output (`curl command failed`); * Control-S: Control-Q doesn't unfreeze it; * No more disk space: There's about 50 GB free and each instance of the scattered task uses less than a GB. ### Docker container logs; `docker logs cf6f4828adc61eacf06337ce3caf2c110df6cc04937530a90bbfb0843acbb528` gives no output. ### Entering the container; `docker exec -it cf6f4828adc61eacf06337ce3caf2c110df6cc04937530a90bbfb0843acbb528 /bin/sh` returns; `Error response from daemon: Container cf6f4828adc61eacf06337ce3caf2c110df6cc04937530a90bbfb0843acbb528 is not running`. ### Docker inspect; ```; >docker inspect cf6f4828adc61eacf06337ce3caf2c110df6cc0",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6946:199,config,config,199,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6946,1,['config'],['config']
Modifiability,"I think I am experiencing a bug in cromwell version 37. The problem occurs when I submit a job to SLURM. The job gets submitted but cromwell crashes without waiting for the job to finish. Cromwell works fine when run locally or when I use version 36. . ## my command ; java is v1.8; ```; java -Dconfig.file=cori.conf -jar cromwell-37.jar run test.wdl ; ```. ## wdl ; ```; workflow jgi_dap_leo {. call doSomething { }. }. task doSomething {; runtime {; mem: ""8G""; cpu: 1; time: ""0:60:0""; backend: ""SLURM""; }; command {; free; }; }; ```. ## config ; ```; include required(classpath(""application"")). system {; job-rate-control {; jobs = 1; per = 1 second; }; }. backend {; default=""Local""; providers {; SLURM {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; runtime-attributes = """"""; String time; Int cpu; String mem; """""". submit = """"""; sbatch -J leo_dap -t ${time} -c ${cpu} --mem=${mem} -C haswell -q regular -A m342 --wrap ""/bin/bash ${script}""; """"""; kill = ""scancel ${job_id}""; check-alive = ""squeue -j ${job_id}""; job-id-regex = ""Submitted batch job (\\d+).*""; }; }; }; }; ```. ## system I'm running on . NERSC's cori machines:; Cray XC40, comprised of Intel Xeon ""Haswell"" processor nodes. ## cromwell logs; [cromwellError.txt](https://github.com/broadinstitute/cromwell/files/2866540/cromwellError.txt)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4651:539,config,config,539,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4651,4,"['Config', 'config']","['ConfigBackendLifecycleActorFactory', 'config']"
Modifiability,"I think this is what most people mean when they write declarations in WDL. Some are a bit different from how they're currently interpreted but I think it should make things easier and safer (eg. if it's an optional that has a default, don't force a `select_first`...). ## Example; ```; workflow foo {; Int a ; Int b = 5 ; Int c = b ; Int? d ; Int? e = 6; Int? f = d ; }; ```. |Declaration | Type | *Must* be supplied | **Can** be supplied | Notes | ; |-------|-----------|-------|-|-|; | `Int a` | Int | Yes | Yes | |; | `Int b = 5` | Int | No | Yes | |; | `Int c = b` | Int | No | ~~Yes~~ **No** | Intermediate value. Shouldn't be overridden because it has variable references. |; | `Int? d` | Int? | No | Yes | |; | `Int? e = 5` | ~~Int?~~ **Int** | No | Yes | Can be treated as an `Int` because it has a default |; | `Int? f = d` | Int? | No | ~~Yes~~ **No** | Intermediate value. Shouldn't be overridden because it has variable references. |",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2565:658,variab,variable,658,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2565,2,['variab'],['variable']
Modifiability,"I tried to ask this on the broad forums but got an error.""You need the Garden.Community.Manage permission to do that."", ""Class"": ""Gdn_UserException"" . I have been using a . backend.default = SGE. Line in my config file. This has been working until now, with my jobs submitted using my defined SGE backend. Today I changed some other parts of the server, unrelated and numerous. Now SOME jobs are being submitted on the SGE backend, and some on the Local backend. (I did not configure a local backend, but I assume one is built in to cromwell. How is the backend to run on chosen by cromwell? (I know of backend.default, and I beleive there is a wdl.task.runtime.backend parameter also (undocumented from what I can tell)). How can I prevent any task ever running on the local backend? I want this to be a hard error, and not overload my sge login node. . Thanks",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3533:207,config,config,207,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3533,2,['config'],"['config', 'configure']"
Modifiability,"I want the choice to specify runtime attribute `backend` per task. Right now we are able to set backends either by hardcoding or setting defaults in workflow options. I want to be able to pass in a variable to dynamically change the backend I am using. . An example of a pattern I can see working is: ; ```; task test1 {; input {; String? backend_ = ""some_backend""; }; runtime {; backend: backend_; }; }; ```. Is there a reason why we can't set this now? This dynamic runtime attributes exist now for memory, cpu, docker, etc. but not for backend.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6584:198,variab,variable,198,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6584,1,['variab'],['variable']
Modifiability,"I was trying to label all GCP batch resources using `-o` in the CLI. (according to [this doc](https://github.com/broadinstitute/cromwell/blob/master/docs/wf_options/Google.md) and [this doc](https://github.com/broadinstitute/cromwell/blob/develop/docs/backends/GCPBatch.md) ); My content of options.json is ; ```; {""google_labels"":{""workflow-run-execution-id"":""97fed6c4-6442-4efe-9e73-7b3592a33480""}} ; ```; and my command is `java -Dconfig.file=config -jar /app/cromwell.jar run wf.wdl -i input.json -o options.json`. The error I am getting:; <img width=""1409"" alt=""Screen Shot 2024-01-04 at 9 58 25 AM"" src=""https://github.com/broadinstitute/cromwell/assets/1992953/e559bccf-dd96-4dea-a48a-6649e448a26f"">. After adding string prefix to my own uuid as label value, the error was gone and my workflow ran smoothly. However, I do need to pass in the uuid so downstream analysis pipeline can still work. . Related code reporting error is [here](https://github.com/broadinstitute/cromwell/blob/dbd8a2aca7253cecd852b5b44ff199e35cdb81cd/supportedBackends/google/batch/src/main/scala/cromwell/backend/google/batch/models/GcpLabel.scala#L65) and error is produce [here](https://github.com/broadinstitute/cromwell/blob/dbd8a2aca7253cecd852b5b44ff199e35cdb81cd/supportedBackends/google/batch/src/main/scala/cromwell/backend/google/batch/models/GcpLabel.scala#L77) and [this is the regex definition](https://github.com/broadinstitute/cromwell/blob/dbd8a2aca7253cecd852b5b44ff199e35cdb81cd/supportedBackends/google/batch/src/main/scala/cromwell/backend/google/batch/models/GcpLabel.scala#L21). I am wondering can the [code](https://github.com/broadinstitute/cromwell/blob/dbd8a2aca7253cecd852b5b44ff199e35cdb81cd/supportedBackends/google/batch/src/main/scala/cromwell/backend/google/batch/models/GcpLabel.scala#L77) be updated to only check the key of a label so it aligns with GCP which does not have this restriction on label values? Or use another regex `""[a-z0-9]([-a-z0-9]*[a-z0-9])?""` for label value check",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7351:446,config,config,446,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7351,1,['config'],['config']
Modifiability,I was trying to restart a cromwell instance on server mode after modified config file. but the log was:; `2023-07-05 08:21:07 cromwell-system-akka.actor.default-dispatcher-25 ERROR - Bind failed for TCP channel on endpoint [/10.10.200.221:8000]`; Is there any way to stop an exist instance or restart it by API or something can automate by script.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7170:74,config,config,74,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7170,1,['config'],['config']
Modifiability,"I was trying to use an invalid options file for cromwell 24 methods, through swagger, and the error message returned was: . ```; {; ""status"": ""error"",; ""message"": ""The server was not able to produce a timely response to your request.""; }; ```; The cromwell logs had more information, I was using the wrong variable format for defaultRuntimeOptions.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2041:306,variab,variable,306,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2041,1,['variab'],['variable']
Modifiability,"I would like to specify an optional array of strings as a runtime attribute. As such, I tried this in my provider configuration:. runtime-attributes = """"""; Array[String]? mounts = []; """""". Unfortunately, this fails horribly:. ```; [2019-02-27 16:26:09,15] [error] Unsupported config runtime attribute WomMaybeEmptyArrayType(WomStringType) mounts; java.lang.RuntimeException: Unsupported config runtime attribute WomMaybeEmptyArrayType(WomStringType) mounts; ```. The error clearly indicates that this type is unsupported. What is the reasoning behind that, or am I just doing it wrong?. (This is with Cromwell 36.1)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4685:114,config,configuration,114,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4685,3,['config'],"['config', 'configuration']"
Modifiability,I would like to track the cost of each job that Cromwell runs with AWS Batch. Can I configure Cromwell to tag jobs with the ID from Cromwell when the jobs are launched?,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7113:84,config,configure,84,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7113,1,['config'],['configure']
Modifiability,"I'm getting an error from Cromwell `Failed to coerce one or more keys or values for creating a Map[String, Int?]` when defining an object as an input to a task that consists of a string, file and int. I would expect the Int to get converted into a string, but the error makes it seem as if Cromwell is trying to convert all of the values into integers. Here is the part of the WDL that's throwing the error: https://github.com/HumanCellAtlas/pipeline-tools/blob/c949cb5ffa2df8f2a7fc7d7a4c34478e8eadbf34/adapter_pipelines/cellranger/adapter.wdl#L222",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4131:532,adapt,adapter,532,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4131,1,['adapt'],['adapter']
Modifiability,"I'm getting an error when trying to run the following WDL, which is using an `Object` type for the output of one of the tasks: https://github.com/HumanCellAtlas/pipeline-tools/blob/master/adapter_pipelines/smart_seq2/adapter.wdl#L46. This WDL previously worked in Cromwell 29. The WDL fails immediately on validation with this error:; ```; ""failures"": [; {; ""causedBy"": [; {; ""causedBy"": [],; ""message"": ""Some([Declaration type=Object name=prep.inputs expr=Some(prep.inputs)]) (of class scala.Some)""; }; ],; ""message"": ""Workflow input processing failed""; }; ]; ```. We're relying on objects in our HCA pipelines so it would be great if this could get fixed soon!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3060:217,adapt,adapter,217,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3060,1,['adapt'],['adapter']
Modifiability,"I'm having some problems running the AWSBatch examples from the aws opendata page - https://docs.opendata.aws/genomics-workflows/aws-batch/configure-aws-batch-start/ - as far as I can tell I have correctly set the permissions, however when I try running the examples I get the error below. It looks like the output files aren't being written the S3 bucket. . I'm probably missing something obvious, but I can't work out what I'm doing wrong. Would anyone have any suggestions for where might be good to look for errors?. ```[2018-10-31 10:24:09,16] [[38;5;1merror[0m] WorkflowManagerActor Workflow b7e4cdce-ff14-4509-aec3-b226ed31043c failed (during ExecutingWorkflowState): cromwell.engine.io.IoAttempts$EnhancedCromwellIoException: [Attempted 1 time(s)] - IOException: Could not read from s3://concr-genomics-results/cromwell-execution/wf_hello/b7e4cdce-ff14-4509-aec3-b226ed31043c/call-hello/hello-rc.txt: s3://s3.amazonaws.com/concr-genomics-results/cromwell-execution/wf_hello/b7e4cdce-ff14-4509-aec3-b226ed31043c/call-hello/hello-rc.txt; Caused by: java.io.IOException: Could not read from s3://concr-genomics-results/cromwell-execution/wf_hello/b7e4cdce-ff14-4509-aec3-b226ed31043c/call-hello/hello-rc.txt: s3://s3.amazonaws.com/concr-genomics-results/cromwell-execution/wf_hello/b7e4cdce-ff14-4509-aec3-b226ed31043c/call-hello/hello-rc.txt; 	at cromwell.engine.io.nio.NioFlow$$anonfun$withReader$2.applyOrElse(NioFlow.scala:146); 	at cromwell.engine.io.nio.NioFlow$$anonfun$withReader$2.applyOrElse(NioFlow.scala:145); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:34); 	at scala.util.Failure.recoverWith(Try.scala:232); 	at cromwell.engine.io.nio.NioFlow.withReader(NioFlow.scala:145); 	at cromwell.engine.io.nio.NioFlow.limitFileContent(NioFlow.scala:154); 	at cromwell.engine.io.nio.NioFlow.$anonfun$readAsString$1(NioFlow.scala:98); 	at cats.effect.internals.IORunLoop$.cats$effect$internals$IORunLoop$$loop(IORunLoop.scala:85); 	at cats.effect.internals.IO",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4341:139,config,configure-aws-batch-start,139,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4341,2,"['Enhance', 'config']","['EnhancedCromwellIoException', 'configure-aws-batch-start']"
Modifiability,"I'm having trouble getting call caching to work with Singularity and SGE, and I'm wondering if anyone has a working example config or some pointers. My config is below, minus passwords and specific paths/urls, which I've replaced with a label encased in <>. I've tried switching to slower hashing strategies finagling with the command construction to no avail. If there's not an obvious solution, is there an easy way to debug this? There are no network issues preventing connections to dockerhub - pulling images and converting to .sif works fine. It's only call caching that's broken. Even when I see, in the metadata, identical hashes for the docker image and all inputs and outputs, I see a ""Cache Miss"" as the result, every time. . The call caching stanza in my metadata looks like this, for example. Am I missing something? ; ```; ""callCaching"": {; ""allowResultReuse"": true,; ""hashes"": {; ""output count"": ""C4CA4238A0B923820DCC509A6F75849B"",; ""runtime attribute"": {; ""docker"": ""4B2AB7B9EA875BF5290210F27BB9654D"",; ""continueOnReturnCode"": ""CFCD208495D565EF66E7DFF9F98764DA"",; ""failOnStderr"": ""68934A3E9455FA72420237EB05902327""; },; ""output expression"": {; ""File output_greeting"": ""DFC652723D8EBD4BB25CAC21431BB6C0""; },; ""input count"": ""CFCD208495D565EF66E7DFF9F98764DA"",; ""backend name"": ""2A2AB400D355AC301859E4ABB5432138"",; ""command template"": ""AFAC58B849BD67585A857F538B8E92F6""; },; ""effectiveCallCachingMode"": ""ReadAndWriteCache"",; ""hit"": false,; ""result"": ""Cache Miss""; },; ```. ```; # simple sge apptainer conf (modified from the slurm one); #; workflow-options; {; workflow-log-dir: ""cromwell-workflow-logs""; workflow-log-temporary: false; workflow-failure-mode: ""ContinueWhilePossible""; default; {; workflow-type: WDL; workflow-type-version: ""draft-2""; }; }. database {; # Store metadata in a file on disk that can grow much larger than RAM limits.; metadata {; profile = ""slick.jdbc.MySQLProfile$""; db {; url = ""jdbc:mysql:<dburl>?rewriteBatchedStatements=true""; driver = ""com.mysql.cj.jdb",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7480:124,config,config,124,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7480,2,['config'],['config']
Modifiability,"I'm not even sure if this is feasible (maybe it's a crazy idea at all), but it will be really useful to drop the metadata of a workflow/subworkflow/task into its execution bucket. An use-case could be: right now, if we want to get information of another subworkflow, from within another workflow, we have to include the credentials(service-account keys/HTTPBasic Auth u/p info) for talking to Cromwell(Cromwell-as-a-service) in the latter workflow's docker image and make the docker image private, which is really tricky (if you have a variety of environments) and makes the workflows less portable. Having an external broker reduces the overhead of managing credentials to some extent, but introduces another external dependency for the workflows. So in this particular case what would be appreciated is a way to get the metadata(even parts of it) of previous workflows from another workflow, where all workflows are living under the same ""parent workflow umbrella"". . I realize that a handful teams are doing similar things like us(querying Cromwell(which in this case, is an external service to the workflow) to get the workflow metadata from another workflow), so having this feature could make a lot of lives easier :)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4236:590,portab,portable,590,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4236,1,['portab'],['portable']
Modifiability,"I'm playing around with my first WDLs, and I realized that the QuickStart tutorial guides a user on how to assign task-level inputs, but not workflow-level. I used the womtool to generate a JSON and figured it out from there. Granted, it's what you'd expect (just omit the task name so it's ""workflow.variable"" rather than ""workflow.task.variable""), but I think this should be explicitly stated in the tutorial. It would only take a couple of lines, but it's important. Thanks!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3592:301,variab,variable,301,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3592,2,['variab'],['variable']
Modifiability,I'm proposing here the configuration I use for [TORQUE](https://www.adaptivecomputing.com/products/torque/).,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5082:23,config,configuration,23,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5082,2,"['adapt', 'config']","['adaptivecomputing', 'configuration']"
Modifiability,"I'm running Ubuntu 18.04 on a local server and backend, on docker containers, using Cromwell release 52, and WDL ""version development"". I'm using the development ""Directory"" type to provide the path to the BLAST database directory to a Docker container running NCBI BLAST. The task definition below executes successfully, but the localization via soft/hard link fails, and all the blast database files (>100GB) get copied multiple times over, as this task is called by a scatter function. Other steps in the pipeline are able to successfully use caching and get localized via soft/hard links, which rules out a configuration issue, and issues are only found right when using the ""Directory"" Type. To help in understanding my setup, I've included:. **inputs:**; ```; {; ""good_donor_good_recipient.blastdb"": ""../../data/blast/blastdb"",; ""good_donor_good_recipient.fasta"": ""../../data/ref_genomes/pseudomonas.fasta"",; }; ```. **task definition:**; ```; version development; task n {; input {; File fasta ; Directory blastdb; String out_file = ""~{basename(fasta)}.blast""; }; command <<<; export BLASTDB=~{blastdb} ; blastn \; -query ~{fasta} -db nt -num_threads 24 -evalue 1 -outfmt '6' -out ~{out_file}; >>>; output { File out = out_file }; runtime { docker: ""ncbi/blast:2.10.1"" }; }; ```. **confiuration snippet - localization only:**; ```; filesystems {; local {; localization: [; ""hard-link"", ""soft-link"", ""copy""; ]; # Call caching strategies; caching {; duplication-strategy: [; ""hard-link"", ""soft-link"", ""copy""; ]; hashing-strategy: ""md5""; check-sibling-md5: false; }; }; }; ```. **logs:**; ```; [2020-08-08 19:20:00,49] [error] Failed to hash ""../../data/blast/blastdb"": Is a directory; [2020-08-08 19:20:00,49] [warn] Localization via hard link has failed: /workflows/cromwell-executions/good_donor_good_recipient/f7947643-2729-483f-b987-44ef932f88bd/call-blaster/main/6e4fa8a1-0d72-486e-a9ae-254319c4915d/call-blaster/shard-20/inputs/2058596876/blastdb -> /data/blast/blastdb: Operation not permi",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5737:611,config,configuration,611,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5737,1,['config'],['configuration']
Modifiability,"I'm running cromwell 46 with AWS, and having problems with call caching ... 2019-09-30 15:37:20,124 cromwell-system-akka.dispatchers.engine-dispatcher-30 ERROR - Failed to hash ""s3://bdtx-scratch/Andrei/bdtx_dataset_1.00_anno_column_description.txt"": [Attempted 1 time(s)] - S3Exception: null (Service: S3, Status Code: 301, Request ID: null); 2019-09-30 15:37:20,125 cromwell-system-akka.dispatchers.engine-dispatcher-30 ERROR - 66419bab:count_lines.countLines:-1:1: Hash error ([Attempted 1 time(s)] - S3Exception: null (Service: S3, Status Code: 301, Request ID: null)), disabling call caching for this job. call caching settings:; call-caching {; enabled = true; invalidate-bad-cache-results = false; }. Thanks. ###; ### IMPORTANT: Please file new issues over in our Jira issue tracker!; ###; ### https://broadworkbench.atlassian.net/projects/BA/issues; ###; ### You may need to create an account before you can view/create issues.; ###. <!--; Hi! Thanks for taking the time to report feedback. Before posting an issue over in Jira tracker, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're almost in the right place. -->. <!-- You'll want to go to https://broadworkbench.atlassian.net/projects/BA/issues and then tell us: -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5204:1779,config,configuration,1779,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5204,1,['config'],['configuration']
Modifiability,"I'm running the ENCODE ATAC SEQ pipeline [https://github.com/ENCODE-DCC/atac-seq-pipeline.git](url) on a SGE cluster.; We don't allow hard-links in my facility (beegfs filesystem). Therefore I've been trying to use the localization parameters in the cromwell configuration file but to no avail. The backend file is being used since I can get errors message by putting non supported keyword in the localization array. I've been trying it with different version of CROMWELL (30.2, 31, 32, 32). Here is the script generated by cromwell based on my WDL file :. ```cd /sandbox/users/foucal-a/test_atac-pipe/cromwell-executions/atac/f4fd93fa-6f3a-42a6-94f2-459901d245c4/call-trim_adapter/shard-0/execution; # make the directory which will keep the matching files; mkdir /sandbox/users/foucal-a/test_atac-pipe/cromwell-executions/atac/f4fd93fa-6f3a-42a6-94f2-459901d245c4/call-trim_adapter/shard-0/execution/glob-4f26c666d13d1cb48973da7f646a7de2. # symlink all the files into the glob directory; ( ln -L merge_fastqs_R?_*.fastq.gz /sandbox/users/foucal-a/test_atac-pipe/cromwell-executions/atac/f4fd93fa-6f3a-42a6-94f2-459901d245c4/call-trim_adapter/shard-0/execution/glob-4f26c666d13d1cb48973da7f646a7de2 2> /dev/null ) || ( ln merge_fastqs_R?_*.fastq.gz /sandbox/users/foucal-a/test_atac-pipe/cromwell-executions/atac/f4fd93fa-6f3a-42a6-94f2-459901d245c4/call-trim_adapter/shard-0/execution/glob-4f26c666d13d1cb48973da7f646a7de2 ). # list all the files that match the glob into a file called glob-[md5 of glob].list; ls -1 /sandbox/users/foucal-a/test_atac-pipe/cromwell-executions/atac/f4fd93fa-6f3a-42a6-94f2-459901d245c4/call-trim_adapter/shard-0/execution/glob-4f26c666d13d1cb48973da7f646a7de2 > /sandbox/users/foucal-a/test_atac-pipe/cromwell-executions/atac/f4fd93fa-6f3a-42a6-94f2-459901d245c4/call-trim_adapter/shard-0/execution/glob-4f26c666d13d1cb48973da7f646a7de2.list; ```; I have the error when the script tries to symlink all the files into the glob directory.; Here is the WDL code : ; ```; ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3876:259,config,configuration,259,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3876,3,"['config', 'sandbox']","['configuration', 'sandbox']"
Modifiability,"I'm specifically thinking of an environment variable - I don't see anything that looks like it might meet these criteria. The goal would be to alter the program behavior slightly depending on whether it is run in a workflow (in which case additional output may be helpful) or on its own (in which case the user probably doesn't want random machine-readable output files appearing in the run dir). (And yes, I am volunteering to add this if it does not exist, because it's a major obstacle to integrating Cromwell with other systems.)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5235:44,variab,variable,44,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5235,1,['variab'],['variable']
Modifiability,"I'm throwing in some nice-to-haves here:. * deleted unused ""mungeId"" artifact before FullyQualifiedName was born; * added ""sbt-pack"" SBT plugin which makes nice run scripts and doesn't assemble fat jar (slow)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2777:137,plugin,plugin,137,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2777,2,['plugin'],['plugin']
Modifiability,"I'm trying to pass default-runtime-attributes as following:; ```; default-runtime-attributes {; failOnStderr: false; continueOnReturnCode: 0; resource_queue_id: ""q-20230616171245-5j76z""; credential: {; accessKey: ""<secret>"",; secretKey: ""<secret>""; }; }; ```. however, when Cromwell trying to convert the map into womValue, it just turn into BadDefaultAttribute().; ![image](https://github.com/broadinstitute/cromwell/assets/32162780/0030d819-3f94-43a4-bca8-63bca01ff2b5); it seems like the; ```; val value = config.getValue(key).unwrapped(); ```; here it will return a java hashMap, but when it comes to coercion function of WomMapType, It will only works for Scala immutable Map.; ```; case class WomMapType(keyType: WomType, valueType: WomType) extends WomType {; val stableName: String = s""Map[${keyType.stableName}, ${valueType.stableName}]"". override protected def coercion = {; case m: Map[_, _] if m.nonEmpty => WomMap.coerceMap(m, this); case m: util.HashMap[_,_] if !m.isEmpty => WomMap coerceMap(m.asScala.toMap,this)// I add this ; case m: Map[_, _] if m.isEmpty => WomMap(WomMapType(keyType, valueType), Map()); case js: JsObject if js.fields.nonEmpty => WomMap.coerceMap(js.fields, this); case womMap: WomMap => WomMap.coerceMap(womMap.value, this); case o: WomObjectLike => WomMap.coerceMap(o.values, this); }; ```; I add a transformation here and it works. Not sure it's a bug or this is intended",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7174:509,config,config,509,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7174,2,"['config', 'extend']","['config', 'extends']"
Modifiability,"I'm trying to pass the `memory` attribute to various backends, including both AWS and SGE (using a modified config where I added `String? memory` in place of `Float? memory_gb`). Passing values like ""4G"" as the manual suggests works fine on AWS, but on SGE I get this:; ```; cromwell.core.CromwellFatalException: java.lang.RuntimeException: Unsupported wdl type for memory: WomStringType; ```; Am I missing something or is the type inconsistent between backends? That's going to make it a lot more work to set up.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5530:108,config,config,108,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5530,1,['config'],['config']
Modifiability,"I'm trying to run a WDL file which specifies a Docker container in the runtime attributes of a task. I'm trying to do so on an SGE HPC with a shared file system. Running this with docker is not an option because I don't have root rights/access. Instead, I'm trying to run it using Singularity. This works fine when using a custom runtime attribute to define the container and using the `submit` configuration. However, if the `docker` attribute and `submit-docker` configuration are used I run into a problem:; Cromwell will use `docker_cwd` (instead of `cwd`) in the call's script. `docker_cwd` however does not exist in the container and can therefore not be mounted (due to a lack of sudo rights), like you would normally do when using Docker. The result is that the job will fail because it can't find a folder that is referenced in the script. Is there some way for me to override the `docker_cwd` value in my backend configuration? I would prefer not to use the `submit` configuration, as not all tasks currently list a container, so I need the `submit` configuration for those tasks. <!--; Hi! Thanks for taking the time to report feedback. Before posting an issue here, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're in the right place. -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4084:395,config,configuration,395,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4084,6,['config'],['configuration']
Modifiability,"I've been working on testing the AWS Batch Cromwell support, following documentation from @wleepang (https://docs.opendata.aws/genomics-workflows) in the CWL hackathon with @cjllanwarne and @aednichols. The workflow is a small test with everything in an S3 bucket:; ; https://github.com/bcbio/test_bcbio_cwl/tree/master/aws. I'm happy to report that I made good progress and have bcbio-vm using CloudFormation templates to setup the Cromwell batch ready AMI and AWS Batch requirements. I can then generate the right Cromwell AWS configuration and launch jobs to AWS batch. I see them get submitted, EC2 resources get spun up and jobs get queued and run. Awesome. When they're all ready and prepped to run, the instances fail with not finding the `cwl.inputs.json` file staged into the working directory:; ```; [2019-01-25 13:53:43,03] [info] AwsBatchAsyncBackendJobExecutionActor [2c2e5a10prep_samples_to_rec:NA:1]: Status change from Initializing to Running; [2019-01-25 13:53:59,61] [info] AwsBatchAsyncBackendJobExecutionActor [2c2e5a10alignment_to_rec:NA:1]: Status change from Initializing to Running; [2019-01-25 13:58:25,58] [info] AwsBatchAsyncBackendJobExecutionActor [2c2e5a10alignment_to_rec:NA:1]: Status change from Running to Failed; [2019-01-25 13:58:39,11] [info] AwsBatchAsyncBackendJobExecutionActor [2c2e5a10prep_samples_to_rec:NA:1]: Status change from Running to Failed; [2019-01-25 13:58:40,06] [error] WorkflowManagerActor Workflow 2c2e5a10-8c57-4f9f-8d80-c2fccacbb452 failed (during ExecutingWorkflowState): Job alignment_to_rec:NA:1 exited with return code 1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.; Check the content of stderr for potential additional information: s3://bcbio-batch-cromwell-test/cromwell-execution/main-somatic.cwl/2c2e5a10-8c57-4f9f-8d80-c2fccacbb452/call-alignment_to_rec/alignment_to_rec-stderr.log.; Traceback (most recent call last):; File ""/usr/local/bin/bcbio_nextgen.py"", lin",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4586:529,config,configuration,529,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4586,1,['config'],['configuration']
Modifiability,"INTO cromwell.SQLMETADATADATABASECHANGELOG (ID, AUTHOR, FILENAME, DATEEXECUTED, ORDEREXECUTED, MD5SUM, `DESCRIPTION`, COMMENTS, EXECTYPE, CONTEXTS, LABELS, LIQUIBASE, DEPLOYMENT_ID) VALUES ('metadata_index_removals', 'mcovarr', 'metadata_changesets/metadata_index_removals.xml', NOW(), 8, '8:b32b63103dfbe3664806be3eccf78b09', 'dropIndex indexName=METADATA_JOB_AND_KEY_IDX, tableName=METADATA_ENTRY; dropIndex indexName=METADATA_JOB_IDX, tableName=METADATA_ENTRY', '', 'EXECUTED', NULL, NULL, '3.6.3', '3752074629'); 2019-07-21 23:34:35,956 INFO - Successfully released change log lock; 2019-07-21 23:34:36,224 WARN - Unrecognized configuration key(s) for Jes: filesystems.gcs.project, name-for-call-caching-purposes, slow-job-warning-time; 2019-07-21 23:34:36,976 INFO - Slf4jLogger started; 2019-07-21 23:34:37,408 cromwell-system-akka.dispatchers.engine-dispatcher-7 INFO - Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-673c553"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""failureShutdownDuration"" : ""5 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; 2019-07-21 23:34:37,771 cromwell-system-akka.actor.default-dispatcher-3 INFO - KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; 2019-07-21 23:34:37,918 cromwell-system-akka.dispatchers.service-dispatcher-14 INFO - Metadata summary refreshing every 1 second.; 2019-07-21 23:34:38,046 WARN - 'docker.hash-lookup.gcr-api-queries-per-100-seconds' is being deprecated, use 'docker.hash-lookup.gcr.throttle' instead (see reference.conf); 2019-07-21 23:34:38,160 cromwell-system-akka.dispatchers.service-dispatcher-13 INFO - WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; 2019-07-21 23:34:38,160 cromwell-system-akka.dispatchers.engine-dispatcher-26 INFO - JobStoreWriterActor configured to flush with batch size 1000 and process rate 1 second.; 2019-07-21 23:34:38,594 cromwell-system-akka.dispatchers.engine-dispatcher-28 INFO",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5084:1633,config,configuration,1633,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5084,1,['config'],['configuration']
Modifiability,"If I could wave a magic wand and refactor the Cromwell support playbook, I would aim for it to have the following properties:. * Make it obvious where the starting point is; * A document which starts by listing links to 20 other documents is hard to get started with; * Make it indexed by problem; * 99% of the time, I've come to the playbook with a specific problem. What I'd really like to find as quickly as possible is a simple debugging flowchart for that problem.; * An ""am I ready"" and/or ""troubleshooting my permissions"" section; * Could even be structured like any other problem? Eg ; * Q: I can't connect to the Cromwell database; * A: try these 4 steps, in this order; * Eg 2:; * Q: I just started, how do I get ready to be on user liaison support?; * A: run through these 4 steps, in this order; * [Nice to have]: clear distinction between ""on call"" and ""user liaison"" types of issues because the audience for each is very different (Cromwell expert vs non-expert. Able to investigate vs getting back to operational as fast as possible); * Maybe even two separate documents? Maybe a tree of connected documents?",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4987:33,refactor,refactor,33,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4987,1,['refactor'],['refactor']
Modifiability,"If a timeout is not provided, GCP defaults to [setting a timeout of 7 days](https://developers.google.com/resources/api-libraries/documentation/genomics/v2alpha1/java/latest/com/google/api/services/genomics/v2alpha1/model/Pipeline.html), after which the pipeline will abort. Occasionally pipelines genuinely need to run >7 days. These changes allow this value to be user-configured.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5273:371,config,configured,371,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5273,1,['config'],['configured']
Modifiability,"If output of task A is read by task B, and both tasks support streaming, then they can be run in parallel, rather than sequentially, using a named pipe to stream A's output to B's input (or a socket if run on different machines). Streamable file params would be designated via param_metadata, as in dxWDL: https://github.com/dnanexus/dxWDL/blob/master/doc/ExpertOptions.md#extensions; Then chains of tasks could effectively become one task, reducing the overall workflow runtime.; This could also be implemented by a standalone WDL-to-WDL rewriter, which would identify chains of mergeable tasks in a workflow and auto-generate a new task that runs the original tasks in parallel.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3454:539,rewrite,rewriter,539,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3454,1,['rewrite'],['rewriter']
Modifiability,"If someone wants to see these kinds messages, they can change the configuration of akka (see http://doc.akka.io/docs/akka/current/java/logging.html#Auxiliary_logging_options), instead. - went through the `whenUnhandled` handlers and removed logging calls that had no or very little info; - removed one test that was associated with one of those logs",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4260:66,config,configuration,66,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4260,1,['config'],['configuration']
Modifiability,"If you use the example in the docs at https://github.com/broadinstitute/cromwell#database. you'll get a warning:. `Move the configuration directly under the 'database' element, and remove the key 'database.config'.`. The docs should be updated. Below is the config given in the readme. database {; config = main.mysql. main {; mysql {; db.url = ""jdbc:mysql://localhost:3306/cromwell""; db.user = ""root""; db.password = """"; db.driver = ""com.mysql.jdbc.Driver""; db.connectionTimeout = 5000 # NOTE: The default 1000ms is often too short for production mysql use; driver = ""slick.driver.MySQLDriver$""; }; }. test {; ...; }; }",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1730:124,config,configuration,124,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1730,4,['config'],"['config', 'configuration']"
Modifiability,"If your service configuration is missing or invalid, Cromwell should fail to start up. Currently, nothing is seen until workflows are submitted and immediately fail",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/871:16,config,configuration,16,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/871,1,['config'],['configuration']
Modifiability,"Im testing moving LSAPI runs to Batch with v86, and I keep getting the following error:. textPayload: ""docker: invalid spec: /mnt/disks/cromwell_root:/mnt/disks/cromwell_root:: empty section between colons."". for this command:; Executing runnable container:{image_uri:""gcr.io/google.com/cloudsdktool/cloud-sdk:434.0.0-alpine"" commands:""-c"" commands:""printf '%s %s\\n' \""$(date -u '+%Y/%m/%d %H:%M:%S')\"" Starting\\ container\\ setup."" entrypoint:""/bin/sh"" volumes:""/mnt/disks/cromwell_root:/mnt/disks/cromwell_root:""} timeout:{seconds:300} labels:{key:""logging"" value:""ContainerSetup""} for Task task/job-49cc8a88-722b-43067ba4-ab34-48bc00-group0-0/0/0 in TaskGroup group0 of Job job-49cc8a88-722b-43067ba4-ab34-48bc00. The docker volumes are defined as:; volumes:""/mnt/disks/cromwell_root:/mnt/disks/cromwell_root:""}. Shouldn't there be a rw permissions entry after the last colon? As far as I know, there is no way for users to modify the docker launch config to fix this. Is there something I have malformed or missing in my conf file?",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7408:954,config,config,954,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7408,1,['config'],['config']
Modifiability,Impact of runtime params on versioning of method configuration,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2268:49,config,configuration,49,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2268,1,['config'],['configuration']
Modifiability,"Implement any necessary logic to calculate hashes. Follow the pattern of the FileHasherActor: The EJHA creates an actor which can make the hash. This actor sends each hash result back to the EngineJobHashingActor individually and lets it do the magic of combining everything together.; - [x] command string (one of the initial hashes in `EJHA`); - [x] all outputs expressions (one of the initial hashes in `EJHA`); - [x] all non-file inputs (included in the set of initial hashes in `EJHA`); - [x] dockerhub/GCR hash (`EngineDockerHashingActor`) or docker name (tuple3 of (namespace, repository, tag, one of the initial hashes in `EJHA`) depending on configuration; - [x] runtime attributes (`BackendRuntimeAttributeHashingActor`); - [x] file inputs (`FileHasherActor`, and onwards to GCS, SFS specific `XYZFileHasherActor`s)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1230:651,config,configuration,651,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1230,1,['config'],['configuration']
Modifiability,"Implement the `/describe` endpoint as described in the doc and discussed with @ruchim. <!--; Hi! Thanks for taking the time to report feedback. Before posting an issue here, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're in the right place. -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4333:796,config,configuration,796,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4333,1,['config'],['configuration']
Modifiability,"Important note: I believe this PR improves correctness when `includeSubworkflows=false` is set but at the cost of query-expense. . Because none of the indexed tables include some `""isASubworkflow""` field, if `includeSubworkflows=false` is set we have to cross reference against the metadata table for each potential query result *before* pagination. Ouch!. Regarding the change in result-order, none of the options feel great. Choose your poison:. 1. ""FTFY"" the query return order for people, making it ""newest first"" rather than ""oldest first""; 2. Add another parameter to the query endpoint; 3. Add a config option . I chose option (1) for this PR, but I'm quite happy to change that.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3903:603,config,config,603,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3903,1,['config'],['config']
Modifiability,"Improves our ""munge this NIO path string into what Cromwell expects"" logic to handle paths that were initially passed into the Azure NIO library as full `http://` paths. I also added a config path (unpublished, intended for devs only) for passing a token through to TES requests. This enables us to locally submit work to a TES server in a (modified to expose TES) instance of the Azure app.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7138:185,config,config,185,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7138,1,['config'],['config']
Modifiability,"In #4406, we added a cleanup routine that deletes unzipped imports when we're done with them. It would be nice to handle imports without touching the disk at all - see [this branch](https://github.com/broadinstitute/cromwell/tree/aen_4406_zipfs) for a mostly-working implementation. That implementation is 99% complete but seems to suffer from a [Scala bug](https://github.com/scala/bug/issues/10247) in certain packaging/deployment configurations - such as the one used in Travis!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4648:433,config,configurations,433,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4648,1,['config'],['configurations']
Modifiability,"In 0.22 you could have something like this in config backend:; ```; runtime_attributes = """"""; String? pbs_email; """"""; ```; And then reference `pbs_email` inside an expression in the `submit` definition like so:; ```; submit = """"""; qsub ${""-me ea -M"" + pbs_email}; """"""; ```; so that if `pbs_email` isn't supplied, neither are the preceding option flags (as documented in `Optional Parameters and Type Constraints -> Prepending a String to an Optional Parameter` at https://software.broadinstitute.org/wdl/devzone.php). This doesn't work anymore in 23:; ```; [ERROR] [12/09/2016 11:09:29.763] [cromwell-system-akka.dispatchers.backend-dispatcher-19] [akka://cromwell-system/user/SingleWorkflowRunnerActor/WorkflowManagerActor/WorkflowActor-71ccb54a-f88c-49b2-aeee-1af92749e337/WorkflowExecutionActor-71ccb54a-f88c-49b2-aeee-1af92749e337/71ccb54a-f88c-49b2-aeee-1af92749e337-EngineJobExecutionActor-testMe.worker:NA:1/71ccb54a-f88c-49b2-aeee-1af92749e337-BackendJobExecutionActor-71ccb54a:testMe.worker:-1:1/SharedFileSystemAsyncJobExecutionActor] SharedFileSystemAsyncJobExecutionActor [UUID(71ccb54a)testMe.worker:NA:1]: Error attempting to Execute the script; java.lang.UnsupportedOperationException: Could not evaluate expression: ""-m ea -M "" + pbs_email; 	at wdl4s.command.ParameterCommandPart.instantiate(ParameterCommandPart.scala:49); 	at wdl4s.Task$$anonfun$instantiateCommand$1$$anonfun$apply$2.apply(Task.scala:107); 	at wdl4s.Task$$anonfun$instantiateCommand$1$$anonfun$apply$2.apply(Task.scala:107); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72); 	at scala.collection.AbstractIterable.foreach(Iterable.scala:54); 	at scala.collection.TraversableLike$class.map(T",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1765:46,config,config,46,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1765,1,['config'],['config']
Modifiability,"In DSDE methods, there are four backend configurations we would like to support.; - local w/ docker; - local w/o docker; - SGE (req: no docker); - JES (req: docker). But we would like to support these without having to change the WDL file itself. Currently, this is done with complex scripts that choose default options and application configurations. But perhaps there is an easier way... by parameterizing runtime attributes. I hear cromwell already supports that, except for the case where we do not want to run in docker at all (e.g. local w/o docker backends). Assuming that you can specify runtime parameters as part of a workflow. In other words, assuming that the following is valid:. ```wdl. workflow yo {; String msg; String docker_image. call task1 {; input:; msg=msg,; docker_image=docker_image; }; }. # Run a message in an arbitrary docker container (e.g. ""broadinstitute/eval-gatk-protected:crsp_validation_latest""); task task1 {; String msg; String docker_image; ; command {; echo ${msg}; } ; ; runtime {; docker: ""${docker_image}""; memory: ""1GB""; }; }; ```; ```; {; ""yo.msg"": ""foo""; ""yo.docker_image"": ""broadinstitute/eval-gatk-protected:crsp_validation_latest""; }; ```; The above WDL+json should work for JES and ""local w/ docker"" backends. However, to support local w/o docker, we need to be able to specify a ""null"" value, which cromwell will interpret as, ""do not use docker"" or ""docker was never specified"". For example:; ```; {; ""yo.msg"": ""foo""; ""yo.docker_image"": """"; }; ```; My understanding of cromwell is that this json + WDL above will cause a failure in cromwell. If this functionality already exists, please close this issue. This would make our WDLs more complicated, but it would increase flexibility and move runtime specification into the json file (which is easier than juggling default options).",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1804:40,config,configurations,40,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1804,3,"['config', 'parameteriz']","['configurations', 'parameterizing']"
Modifiability,"In Google Compute Engine, one can create custom networks and even delete the default network. ; Docs: https://cloud.google.com/vpc/docs/using-vpc; List of networks: https://console.cloud.google.com/networking/networks/list. This is commonly done for projects that have high security requirements to enforce firewalls etc. The ability to specify a network where operations are created is supported in v2alpha1, but there is no place to specify it in Cromwell (which always uses the ""default"" network). AC: Add an option to Cromwell's global config where a user can specify the VPC network name, for the PAPI v2 backend. This would override the current ""default"" network used by Cromwell. Testing Criteria:; - Confirm that Cromwell honors using a non-default network when specified via the config.; - If the network name specified doesn't exist, the error returned to the user contains information about 1) a link to documentation on how to create a network and 2) how to confirm a network exists through the cloud console.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4017:540,config,config,540,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4017,2,['config'],['config']
Modifiability,"In WDL 1.0, variables defined in nested if-statements are ""doubly optional"" (`Int??`) and break `select_first()`. Note that the degree of optionality maxes out at two, regardless of how deep the nesting is. This workflow is fine; ```; workflow Test {. Int a = 5. if (true) {; if (true) {; if (true) {; Int b = 5; }; }; }. Int c = select_first([a, b]); }; ```; but this one fails; ```; version 1.0. workflow Test {. Int a = 5. if (true) {; if (true) {; if (true) {; Int b = 5; }; }; }. Int c = select_first([a, b]); }; ```; with error; ```; Failed to process workflow definition 'Test' (reason 1 of 1):; Failed to process declaration 'Int c = select_first([a, b])' (reason 1 of 1):; Cannot coerce expression of type 'Int??' to 'Int'; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3766:12,variab,variables,12,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3766,1,['variab'],['variables']
Modifiability,"In a Cromwell configured with multiple backends, be able to dynamically determine which backend to send a job based on where the input files live. . 1. If there are no files, use the default backend; 2. If all of the files are on the same filesystem, use the backend associated w/ that filesystem (see below); 3. If the files are not all on the same filesystem, error. This will require moving backend determination (at least for many tasks) out of materialization and closer to the runtime dispatch. Note that the 2nd stage really only works right now because there's (mostly) a 1-1 mapping of backend to filesystem. If you can find a way to do this slickly in a world where a backend might support multiple filesystems, so much the better. Note also that this relates to #1312 (ideally this is done after that, but shouldn't matter too much either way). The workflow option should always override dynamic dispatch determination.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2584:14,config,configured,14,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2584,1,['config'],['configured']
Modifiability,"In a configuration like. ```wdl; workflow ifs_in_scatters {; call hello. scatter (n in range(5)) {; if (true) {; call goodbye { input: i = hello.out }; }; }; }; ```; When the conditional graph is created, all nodes outside of the scatter get ""wrapped"" in an `OuterGraphInputNode` that gets passed into the inner conditional graph so that nodes in the inner graph can reference nodes outside of the scatter.; The issue is that those OGINs are created with `preserveScatterIndex = true` even though the node they're pointing to is outside of the scatter. This was preventing the `ExecutionStore` from detecting the `i = hello.out` expression as being runnable because it was looking for a `hello.out` node in `Done` state at index `n`, which doesn't exist since `call hello` is outside the scatter.; This PR changes that to use the `preserveIndexForOuterLookups ` value of the conditional / scatter instead, which in this case will be `false`, because the scatter node does set `preserveScatterIndex = false` to build its inner graph (in this case the if).",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3158:5,config,configuration,5,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3158,1,['config'],['configuration']
Modifiability,"In cases where call caching is not being used (as is the case for Genomes On the Cloud for the time being), the ability to have workflows ""fail fast"" is desired. Fail fast in this case mean, once a task has failed no new tasks should be started (currently running tasks can finish) and then the workflow should be set to failed. This is important because when running a workflow, and you can't reuse the non-failed work, you want to know the workflow will fail as soon as possible. With a long running workflow, an early failure with few downstream dependencies you have to wait a long time (24 hours for GOTC) to realize it's actually failed. This should be specifyable as a workflow option, e.g. failure-strategy = fast where the current behavior is 'slow'. If it's easy to also have this as a server config setting for the default that would be a nice to have but not critical.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/587:803,config,config,803,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/587,1,['config'],['config']
Modifiability,"In https://github.com/broadinstitute/cromwell/pull/4502 I ignored three tests related to the refresh token functionality because they were blocking all other merges and I had no idea how to fix them. My rationale for doing so is my impression the feature is unused/end-of-life. @ruchim to decide whether we; 1. Fix the tests; or; 2. Delete the feature . <!--; Hi! Thanks for taking the time to report feedback. Before posting an issue here, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're in the right place. -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4504:1063,config,configuration,1063,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4504,1,['config'],['configuration']
Modifiability,"In order to deploy CromIAM, we need to add the deployment configurations to `firecloud-develop`. This means, at a minimum:; * a consul-template-ized `docker-compose.yml` for environments `live`, `fiab`, and `local`; * consul-template-ized `cromiam.conf` file ; * A stable-versioned, published docker image of cromiam. This should be submitted as a PR to `dev` branch, whereupon it makes its way through QA to the production environment. I've submitted my initial work(a skeleton) to the `db_add_cromiam` branch in the firecloud-develop repo.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4545:58,config,configurations,58,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4545,1,['config'],['configurations']
Modifiability,"In order to discern if a workflow is **really** running instead of having been picked up to be run but abandoned, running workflows should send a heartbeat ping to the workflow store. After some configurable time limit, if a workflow has not sent in a heartbeat, move it to a state (see below) such that it'll again be pick-upable. I think it'd be good to have a new state (e.g. `LostContact`) vs resetting it to `Submitted`",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3341:195,config,configurable,195,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3341,1,['config'],['configurable']
Modifiability,"In the example configuration, the submit-docker tries to run. docker run ... ${docker} ${script}. but ${script} will not be accessible from the docker image unless, by coincidence, the location where we are running from in the local filesystem is the same as the dockerRoot. What we want to run instead is . docker run .... ${docker} ${docker_script}. Since this is the default configuration, it has the potential to cause a lot of unnecessary confusion (eg for me)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5015:15,config,configuration,15,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5015,2,['config'],['configuration']
Modifiability,"In the following code snippet:; ```WDL; scatter(centrifuge in centrifugeList){; call centrifugeDownload {; input:; centrifugeOutput= centrifuge.outputDir,; domain=centrifuge.domain,; database=if defined(centrifuge.database) then centrifuge.database else ""refseq""; }; }; }; ```; The `centrifugeList` is a list of dictionaries. The resulting `centrifuge` `object` may or may not have a key database. . ## Expected behaviour:; `database` defaults to `""refseq""` if no `database` key is present in the dictionary. It will use the database key if it exists. ## Observed behaviour:; ```; java.lang.RuntimeException: Evaluating if defined(centrifuge.database) then centrifuge.database else ""refseq"" failed: Could not find key database in WdlObject; at cromwell.engine.workflow.lifecycle.execution.keys.ExpressionKey.$anonfun$processRunnable$2(ExpressionKey.scala:36); at cromwell.engine.workflow.lifecycle.execution.keys.ExpressionKey.$anonfun$processRunnable$2$adapted(ExpressionKey.scala:31); at scala.Function1.$anonfun$andThen$1(Function1.scala:52); at cats.data.Validated.fold(Validated.scala:14); at cats.data.Validated.bimap(Validated.scala:109); at cats.data.Validated.map(Validated.scala:152); at cromwell.engine.workflow.lifecycle.execution.keys.ExpressionKey.processRunnable(ExpressionKey.scala:31); at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActor.$anonfun$processRunnableTaskCallInputExpression$4(WorkflowExecutionActor.scala:452); at scala.util.Either.flatMap(Either.scala:338); at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActor.$anonfun$processRunnableTaskCallInputExpression$2(WorkflowExecutionActor.scala:449); at scala.util.Either.flatMap(Either.scala:338); at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActor.$anonfun$processRunnableTaskCallInputExpression$1(WorkflowExecutionActor.scala:448); at scala.util.Either.flatMap(Either.scala:338); at cromwell.engine.workflow.lifecycle.execution.WorkflowExecutionActor.processRunnable",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3093:954,adapt,adapted,954,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3093,1,['adapt'],['adapted']
Modifiability,"In the latest releases of Cromwell (28+), the tmpDir variable is set to be created under the [current working directory of the workflow task](https://github.com/broadinstitute/cromwell/blob/master/backend/src/main/scala/cromwell/backend/standard/StandardAsyncExecutionActor.scala#L186) by default. In a cluster environment, we have observed that this limits how quickly a task can execute when using a shared file system (NFS/Lustre/etc.) because these filesystems perform poorly with small reads and writes. In earlier versions of Cromwell, we worked around this by setting tmpDir within each task of the WDL to a path mounted on a local disk, but now the tmpDir variable seems to be set globally resulting in the local tmpDir variable getting overwritten. . We can modify the tmpDir path in StandardAsyncExecutionActor, but this requires recompiling Cromwell for each environment where Cromwell is deployed. Would it be possible to make the tmpDir variable configurable within reference.conf? That way a site admin can deploy Cromwell without needing to recompile, and quickly choose the tmpDir path that is optimal for their environment.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2655:53,variab,variable,53,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2655,5,"['config', 'variab']","['configurable', 'variable']"
Modifiability,"In the workflow store, also record the identity of the Cromwell who has been assigned a workflow. . Without thinking about it deeply, having it be a configurable name seems the best path. Another option would be to use the hostname. Both have issues - config could be misconfigured, but could be running multiple cromwells on the same host. Another thought would be a UUID generated by the Cromwell.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3340:149,config,configurable,149,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3340,2,['config'],"['config', 'configurable']"
Modifiability,"In version 31 I had in my configuration: ; ```temporary-directory = ""$(mkdir -p $TMPDIR && echo $TMPDIR)""```. Which resulted in:; ```; tmpDir=$(; set -e; cd /share/ScratchGeneral/evaben/cromwell/cromwell-executions/Happy_Workflow/f7b9ac1e-994c-46bd-bad5-e11ac6696165/call-happy/execution; tmpDir=""$(mkdir -p $TMPDIR && echo $TMPDIR)""; echo ""$tmpDir""; ); chmod 777 ""$tmpDir""; ```. In version 32 the same config results in:; ```; cd /share/ScratchGeneral/evaben/cromwell/cromwell-executions/Happy/356aa17f-6276-44e0-9859-391c6c58cf49/call-happy/execution; tmpDir=`$(mkdir -p $TMPDIR && echo $TMPDIR)`; chmod 777 ""$tmpDir""; ```. which executes using my $() as well as the cromwell provided ``, causing an error (which is no longer caught by set -e). Then many subsequent errors as the script tries to write to / (lucky I did not rm -r!). I thought there was documentation on readthedocs but I cannot find it with the inbuilt search or google. If I just remove my $(), it should work, but as the change was not announced and there does not seem to be documentation, I wanted to check what the actual contract is. I would also prefer cromwell did not chmod my tmpdir, but that is a separate issue.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3784:26,config,configuration,26,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3784,2,['config'],"['config', 'configuration']"
Modifiability,"Init$body.apply(CromwellApp.scala:3); 	at scala.Function0.apply$mcV$sp(Function0.scala:34); 	at scala.Function0.apply$mcV$sp$(Function0.scala:34); 	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:12); 	at scala.App.$anonfun$main$1$adapted(App.scala:76); 	at scala.collection.immutable.List.foreach(List.scala:389); 	at scala.App.main(App.scala:76); 	at scala.App.main$(App.scala:74); 	at cromwell.CromwellApp$.main(CromwellApp.scala:3); 	at cromwell.CromwellApp.main(CromwellApp.scala); Caused by: com.typesafe.config.ConfigException$Parse: /data/cephfs/punim0751/spartan.conf: 27: expecting a close parentheses ')' here, not: end of file; 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseError(ConfigDocumentParser.java:201); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseError(ConfigDocumentParser.java:197); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseKey(ConfigDocumentParser.java:279); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseObject(ConfigDocumentParser.java:450); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseValue(ConfigDocumentParser.java:247); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parseObject(ConfigDocumentParser.java:458); 	at com.typesafe.config.impl.ConfigDocumentParser$ParseContext.parse(ConfigDocumentParser.java:648); 	at com.typesafe.config.impl.ConfigDocumentParser.parse(ConfigDocumentParser.java:14); 	at com.typesafe.config.impl.Parseable.rawParseValue(Parseable.java:260); 	at com.typesafe.config.impl.Parseable.rawParseValue(Parseable.java:248); 	at com.typesafe.config.impl.Parseable.parseValue(Parseable.java:180); 	at com.typesafe.config.impl.Parseable.parseValue(Parseable.java:174); 	at com.typesafe.config.impl.Parseable.parse(Parseable.java:299); 	at com.typesafe.config.ConfigFactory.parseFile(ConfigFactory.java:689); 	at com.typesafe.config.DefaultConfigLoadingStrategy.parseApplicationConfig(DefaultC",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4549:2047,config,config,2047,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4549,1,['config'],['config']
Modifiability,"Initiated by conversation on http://gatkforums.broadinstitute.org/wdl/discussion/8546/using-different-service-account-on-compute-instance#latest . Currently, we are supplying 'default' to the RunPipelineArgs service_account email. This means the Pipelines API node will spin up using the default compute service account for the project. However (a) that account can be removed and (b) users may want to use a different service account. This should be configurable at both the cromwell server level (ie applies to all workflows) as well as by the workflow options (so it can vary by workflow). This new capability should also be documented in the README (or whever @katevoss says!)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1656:451,config,configurable,451,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1656,1,['config'],['configurable']
Modifiability,Inline reference image configuration [BT-122],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6176:23,config,configuration,23,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6176,1,['config'],['configuration']
Modifiability,"Input:. 1. Cromwell commit [`53c4693a0508518e9a6f957fbba2b1afc7dc90b5`](https://github.com/broadinstitute/cromwell/pull/6739/commits/53c4693a0508518e9a6f957fbba2b1afc7dc90b5); - I ran the job on my own branch for testing, but I updated the job to point to `develop` by PR time. Outputs:. 1. Commit to `main` in Cromwhelm: https://github.com/broadinstitute/cromwhelm/commit/0218cf0ccad9a7e9a74c785c2101ecb77ec56a13. 2. [Image in Docker Hub](https://hub.docker.com/layers/cromwell/broadinstitute/cromwell/79-cba6c97-SNAP/images/sha256-9cd6b3e404efbd1a8610b45ae606dde056dd172e6f1a83fbae36e340fb0103ea?context=explore). 3. [Complete log output of action.](https://github.com/broadinstitute/cromwell/runs/6097432895?check_suite_focus=true). ---. The action runs on self-hosted instances created by devops (`runs-on: self-hosted`) which are 2x as powerful as Travis. The whole build takes ~7 minutes, including `sbt server/docker`. My high spec Broad laptop is just a little faster at ~5 minutes. ~There is a prequisite PR https://github.com/broadinstitute/terraform-ap-deployments/pull/616 that is very close pending a naming discussion.~ Merged. ---. Now we are cool like the other repos that deploy continuously. This is near and dear to my heart:. <img width=""1159"" alt=""Screen Shot 2022-04-20 at 11 58 40 AM"" src=""https://user-images.githubusercontent.com/1087943/164273206-134f1b88-d1bb-447e-b56e-7d01c2e1cada.png"">",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6739:463,layers,layers,463,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6739,1,['layers'],['layers']
Modifiability,"Instead of the regular `${script}` variable from, this would close #5768. . Pinging @rhpvorderman and @TMiguelT as container / batch system users I know of.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5784:35,variab,variable,35,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5784,1,['variab'],['variable']
Modifiability,IntelliJ automatically locates this file in the repo and shows it as a run configuration. More convenient to clone that template & modify than to fill in all these fields manually based on prose documentation. Tested by sending to Bec and it was recognized.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6304:75,config,configuration,75,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6304,1,['config'],['configuration']
Modifiability,IntelliJ plugin throwing exceptions,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2276:9,plugin,plugin,9,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2276,1,['plugin'],['plugin']
Modifiability,Introduced configurable delay between workflow completion and metadata deletion [BA-6128],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5339:11,config,configurable,11,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5339,1,['config'],['configurable']
Modifiability,"Introduces a `RuntimeEnvironment` type in order to provide CWL expressions the proper values for the `runtime` ECMAscript variable. . See spec for explicit detail: http://www.commonwl.org/v1.0/CommandLineTool.html#Runtime_environment. Also introduce `MinimumRuntimeSettings` as the spec says ; > ""if an implementation can't provide the actual number of reserved cores during the expression evaluation time, it should report back the minimal requested amount."". I've made a few tradeoffs which I intend to document as tickets unless there are objections. To be clear the tradeoff is these compromises for speed, as I'm trying to ""spike"" on 1st-workflow and get it working :. * MinimumRuntimeSettings should come from the config. I see a major dependency tree coming all the way down from `RootCromwellActor` and I'm trying to think of a better way. In this PR I've taken the shortcut of instantiating MinimumRuntimeSettings with default values hardcoded.; * The values of `outdirSize` and `tmpdirSize` are specified in CWL but I haven't yet figured out how to provide those values accurately. I will likely create an issue to do this effectively as I doubt this is regularly used.; * I think we could constrain the types of `RuntimeEnvironment` better than the `String` and `Int` we are using currently, e.g. using `Path` and `MemorySize`. This requires moving these types up to the `wom` package.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2810:122,variab,variable,122,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2810,2,"['config', 'variab']","['config', 'variable']"
Modifiability,"Introducing the concept of a ""lord"" into the config, with the responsibilities:. * Summarize; * Liquibase. To complement this effort, these functions should be turned *off* in worker & reader Cromwells",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4750:45,config,config,45,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4750,1,['config'],['config']
Modifiability,Is it possible to configure frequency of rc check?,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7144:18,config,configure,18,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7144,1,['config'],['configure']
Modifiability,"Is it possible to use a S3 service other than Amazon S3, e.g. RADOS or MinIO? Cromwell seems to use only AWS hostnames for the S3 filesystem and I can't find a way to configure this.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6301:167,config,configure,167,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6301,1,['config'],['configure']
Modifiability,"It is very inconvenient to provide a lot of separate files via cromwell REST or console and it often leads to many mistakes when one has to run many pipelines.; It would be much better to be able just zip whole folder with cromwell project and give one json config file that gives all pathes inside zip (where is subworkflows folder, where are options and where is the main workflow).",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2410:258,config,config,258,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2410,1,['config'],['config']
Modifiability,"It looks like cromwell doesn't properly handle optional variables in tasks. If they are undefined this error occurs: ""Optional value was not set and no 'default' attribute was provided"". Setting a default (either in the input block or like so: `~{default="""" optionalValue}`) will cause the workflow to run, but this seems to me to go entirely against the reason for having an optional datatype to begin with. It also looks like setting an optional with default to `null` in the input JSON is ignored, which is in conflict with the SPECs [here](https://github.com/openwdl/wdl/blob/master/versions/1.0/SPEC.md#optional-inputs-with-defaults). I'm getting this error when using WDL version 1.0 (draft-3). The error occurs in both cromwell version 33 and 34. Full stacktrace:; ```; 2018-07-24 09:54:27,543 cromwell-system-akka.dispatchers.backend-dispatcher-53 ERROR - DispatchedConfigAsyncJobExecutionActor [UUID(514f031f)AlignStar.star:NA:1]: Error attempting to Execute; java.lang.Exception: Failed command instantiation; at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand(StandardAsyncExecutionActor.scala:536); at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand$(StandardAsyncExecutionActor.scala:471); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.instantiatedCommand$lzycompute(ConfigAsyncJobExecutionActor.scala:208); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.instantiatedCommand(ConfigAsyncJobExecutionActor.scala:208); at cromwell.backend.standard.StandardAsyncExecutionActor.commandScriptContents(StandardAsyncExecutionActor.scala:265); at cromwell.backend.standard.StandardAsyncExecutionActor.commandScriptContents$(StandardAsyncExecutionActor.scala:264); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.commandScriptContents(ConfigAsyncJobExecutionActor.scala:208); at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.writeScriptContents(Sha",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3927:56,variab,variables,56,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3927,1,['variab'],['variables']
Modifiability,It seems the sentry configuration is generating too much log from log.error due to log level set to WARN or above. So removing this configuration altogether from logback.xml.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5065:20,config,configuration,20,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5065,2,['config'],['configuration']
Modifiability,It will be great to be able to configure Access-Control-Allow-Origin * for cromwell to be able to call it via AJAX,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2824:31,config,configure,31,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2824,1,['config'],['configure']
Modifiability,"It works with the standard backend. <!-- Which backend are you running? -->; SLURM. <!-- Paste/Attach your workflow if possible: -->; cwlVersion: v1.0; class: Workflow. requirements:; SubworkflowFeatureRequirement: {}. inputs:; fastqc_output_dir:; type: string; fastqc_input_files:; type: string[]; fastqc_thread_count:; type: int; multiqc_output_dir:; type: string; outputs: []. steps:; fastqc_mkdir:; run: mkdir-cmd.cwl; in:; directory: fastqc_output_dir; out: [created_directory]; fastqc_execute:; run: fastqc-step.cwl; in:; input_files: fastqc_input_files; output_dir: fastqc_mkdir/created_directory; thread_count: fastqc_thread_count; out: [output_directory]; multiqc_mkdir:; run: mkdir-cmd.cwl; in:; directory: multiqc_output_dir; out: [created_directory]; multiqc_execute:; run: multiqc-cmd.cwl; in:; output_dir: multiqc_mkdir/created_directory; input_dir: fastqc_execute/output_directory; out: [output_directory]; <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->. at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: scala.NotImplementedError: This should not happen, please report this; at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:281); at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.pollStatus(ConfigAsyncJobExecutionActor.scala:211); at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$pollStatusAsync$1(StandardAsyncExecutionActor.scala:691); at scala.util.Try$.apply(Try.scala:209); ... 25 more. <!-- SLURM backend configuration -->; include required(classpath(""application"")). backend {; default = SLURM. providers {; SLURM {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFac",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4560:938,config,configuration,938,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4560,1,['config'],['configuration']
Modifiability,"It would be great to be able to declare variables based on output from tasks. In this example WDL I want to use an array of all the shards from TaskA as input to TaskB even though TaskB is in the same scatter. ```; task TaskA {; File single_input_file. command {; #Something happens that takes a single file and returns a single file; }; output {; File output_single_file = ""some.file""; }; }. task TaskB {; Array[File] array_of_files; File single_input_file. command {; #Something happens that takes an array of files and a single file; }; }. workflow inputsFromScatter {; Array[File] list_of_files = [""a.file"", ""b.file"", ""c.file""]. scatter(file in list_of_files) {; call TaskA {; input:; single_input_file = file; }. call TaskB {; input:; single_input_file = file,; array_of_files = variable_declared_outside_of_scatter; }; }. Array[File] variable_declared_outside_of_scatter = TaskA.output_single_file; }; ```. This workflow currently results in this error: `Workflow input processing failed.; Workflow has invalid declarations: Could not find a value for TaskA`. I may have oversimplified this example because TaskB could be in a separate scatter. If you'd like a real example with actual tasks I'd be happy to provide it.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1513:40,variab,variables,40,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1513,1,['variab'],['variables']
Modifiability,"It would be nice if cromwell would have the option to incrementally increase the memory attribute for a job, based on the retries. This is related to #1991, but the conclusion there (if I'm understanding it correctly) seems to be adding a feature to the WDL specs. I feel that these types of features might be more appropriate as a backend configuration, since whether this is something you want to do or not will depend on the infrastucture your workflow is running on. One potential way to configure this, might be to add multipliers for certain runtime attributes in the backend configuration:; ```; [...]; config {; runtime-attributes = """"""; Int? cpu = 1; Int? memory = 4; """"""; runtime-attribute-retry-multipliers = {; memory: 1.5; }; [...]; }; [...]; ```. This would, for example, cause the memory attribute to be multiplied by `1.5` with each retry. For the first attempt it would be `4`, for the the second `6`, the third `9` etc. Another option might be that the values here indicate a fraction of the original attribute which it should be increased it by each retry, so in the above example it would be: `4` -> `10` -> `16` etc. You would probably want set a lower value in that case, though. Another option would be to supply a list of numbers with each indicating a multiplier for a certain attempt. A value of `[1.5, 2]` (or maybe `[1, 1.5, 2]`) would cause the value to be multiplied by `1.5` on the second attempt and `2` on the third, repeating the last multiplier if neccesary. (ie. `4` -> `6` -> `8` -> `8`). <!--; Hi! Thanks for taking the time to report feedback. Before posting an issue here, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL ht",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4346:340,config,configuration,340,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4346,4,['config'],"['config', 'configuration', 'configure']"
Modifiability,JES backend does not seem to be properly configured in reference.conf,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1748:41,config,configured,41,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1748,1,['config'],['configured']
Modifiability,JES backend not honoring the `default-zones` configuration parameter,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2527:45,config,configuration,45,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2527,1,['config'],['configuration']
Modifiability,Job w/ docker Requirement should fail to run against a no-docker Config Backend,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3579:65,Config,Config,65,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3579,1,['Config'],['Config']
Modifiability,"JsArray is the simplest... but do you think JsObject with keys ""left"" and ""right"", or ""0"" and ""1"" would be better?; ""left"" and ""right"" would be consistent with the wdl4s code, but not extend very well to larger tuple types if you ever decide to go there.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1704:184,extend,extend,184,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1704,1,['extend'],['extend']
Modifiability,"Just some lessons learned while trying to run tests on the Local backend using a non-CI config, though the main lesson learned was to just use the CI config if possible.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4748:88,config,config,88,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4748,2,['config'],['config']
Modifiability,"L "" sequence_group_interval}; }; runtime {; docker: ""us.gcr.io/broad-gotc-prod/genomes-in-the-cloud:2.3.2-1510681135""; memory: ""6 GB""; disks: ""local-disk "" + disk_size + "" HDD""; preemptible: preemptible_tries; }; output {; File recalibration_report = ""${recalibration_report_filename}""; }; }; ```. And here is my cromwell server config:. ```scala; include required(classpath(""application"")). webservice {; port = 8000; }. system {; workflow-restart = true; }. engine {; filesystems {. gcs {; auth = ""service-account""; }. http {}. local {; localization: [; ""hard-link"", ""soft-link"", ""copy""; ]; }; }; }. backend {; default = ""Local""; providers {. Local {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; max-concurrent-workflows = 1; concurrent-job-limit = 1; }; }. PAPIv2 {; actor-factory = ""cromwell.backend.google.pipelines.v2alpha1.PipelinesApiLifecycleActorFactory""; config {; project = ""bioinfo-XXXXXXX""; root = ""gs://XXXXXXXX""; genomics-api-queries-per-100-seconds = 1000; max-concurrent-workflows = 80; concurrent-job-limit = 200; maximum-polling-interval = 600. genomics {; # Config from google stanza; auth = ""service-account"". ; # Endpoint for APIs, no reason to change this unless directed by Google.; endpoint-url = ""https://genomics.googleapis.com/""; localization-attempts = 3; }. filesystems {; gcs {; # A reference to a potentially different auth for manipulating files via engine functions.; auth = ""service-account""; }; }; }; }; }; }. # Google authentication; google {; application-name = ""cromwell""; auths = [; {; name = ""application-default""; scheme = ""application_default""; },; {; name = ""service-account""; scheme = ""service_account""; service-account-id = ""XXXXXXXXXXXXXX@XXXXXXXXXXXX.gserviceaccount.com""; json-file = ""/var/secrets/google/key.json""; }; ]; }. # database connection; database {; profile = ""slick.jdbc.MySQLProfile$""; db {; driver = ""com.mysql.jdbc.Driver""; url = ""jdbc:mysql://cromwell-db/cromwell?rewriteBatchedStat",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4336:2206,config,config,2206,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4336,1,['config'],['config']
Modifiability,Language specific configuration (not enforcing read_X limits),MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2611:18,config,configuration,18,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2611,1,['config'],['configuration']
Modifiability,"Localization via hard link has failed: /data/PROJECTS/2019_01_28_scMeth/scripts/Automated_Pipeline/cromwell/example_wdl/cromwell-executions/scMeth/41d3eecf-c5a9-42e4-8a29-8be9c252b7f5/call-trimAdapters/inputs/13016223/fastq -> /data/PROJECTS/2019_01_28_scMeth/scripts/Automated_Pipeline/cromwell/example_wdl/fastq; [2019-07-10 14:33:01,23] [warn] Localization via copy has failed: /data/PROJECTS/2019_01_28_scMeth/scripts/Automated_Pipeline/cromwell/example_wdl/fastq; [2019-07-10 14:33:01,24] [error] BackgroundConfigAsyncJobExecutionActor [41d3eecfscMeth.trimAdapters:NA:1]: Error attempting to Execute; java.lang.Exception: Failed command instantiation; 	at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand(StandardAsyncExecutionActor.scala:576); 	at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand$(StandardAsyncExecutionActor.scala:511); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.instantiatedCommand$lzycompute(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.instantiatedCommand(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.standard.StandardAsyncExecutionActor.commandScriptContents(StandardAsyncExecutionActor.scala:319); 	at cromwell.backend.standard.StandardAsyncExecutionActor.commandScriptContents$(StandardAsyncExecutionActor.scala:318); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.commandScriptContents(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.writeScriptContents(SharedFileSystemAsyncJobExecutionActor.scala:175); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.writeScriptContents$(SharedFileSystemAsyncJobExecutionActor.scala:174); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.cromwell$backend$sfs$BackgroundAsyncJobExecutionActor$$super$writeScriptContents(ConfigAsyncJo",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5066:9960,Config,ConfigAsyncJobExecutionActor,9960,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5066,1,['Config'],['ConfigAsyncJobExecutionActor']
Modifiability,Log configured batch size and max flush intervals.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2543:4,config,configured,4,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2543,1,['config'],['configured']
Modifiability,"Look at code in existing but closed PRs in cromwell-backend/cromwell. This will need to be greatly adapted for develop, but should be doable.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/487:99,adapt,adapted,99,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/487,1,['adapt'],['adapted']
Modifiability,Look for failure mode option in the right place in the config. Closes #1380,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1381:55,config,config,55,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1381,1,['config'],['config']
Modifiability,"M. Example pipeline:. ```; version 1.0. # WORKFLOW DEFINITION; workflow WholeGenomeGermlineSingleSample {; call SumFloats; output {; Float out = SumFloats.total_size; }; }. task SumFloats {; input {; Array[Float] sizes = [1,2,3,4,5.0]; Int preemptible_tries=3; }. command <<<; python -c ""print ~{sep=""+"" sizes}""; >>>; output {; Float total_size = read_float(stdout()); }; runtime {; docker: ""us.gcr.io/broad-gotc-prod/python:2.7""; preemptible: preemptible_tries; }; }; ```. The error raised with cromwell-53 is:; Failed to read_float(""/data/og/ted/cromwell-executions/WholeGenomeGermlineSingleSample/00090ef9-5211-4f18-9de9-daf3de791408/call-SumFloats/execution/stdout"") (reason 1 of 1): For input string: ""15.0; 15.0""; The stdout file truly contains this. Running with local backend returns no error.; Contents of conf file:. ```; backend {; default = ""SLURM""; providers {; Local {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; include required(classpath(""reference_local_provider_config.inc.conf"")); concurrent-job-limit = 30; }; }; SLURM {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; runtime-attributes = """"""; Int runtime_minutes = 600; Int cpu = 1; Int requested_memory_mb_per_core = 8000; Int memory_mb = 4000; String queue = ""short""; String? docker; """""". submit = """"""; sbatch -J ${job_name} -D ${cwd} -o ${out} -e ${err} -t ${runtime_minutes} -p ${queue} \; ${""-c "" + cpu} \; --mem ${memory_mb} \; --wrap ""/bin/bash ${script}""; """"""; submit-docker = """"""; docker pull ${docker}. sbatch -J ${job_name} -D ${cwd} -o ${cwd}/execution/stdout -e ${cwd}/execution/stderr -t ${runtime_minutes} -p ${queue} \; ${""-c "" + cpu} \; --mem ${memory_mb} \; --wrap ""docker run -v ${cwd}:${docker_cwd} ${docker} ${job_shell} ${docker_cwd}/execution/script""; """""". kill = ""scancel ${job_id}""; check-alive = ""scontrol show job ${job_id}""; job-id-regex = ""Submitted batch job (\\d+).*""; }; }; ```. Any thoughts?",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5932:1239,config,config,1239,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5932,3,"['Config', 'config']","['ConfigBackendLifecycleActorFactory', 'config']"
Modifiability,"Made a small change to the preStart method of WFMA, it only tries to re-start incomplete workflows when the config ""workflow-restart"" is set to true. I don't know if I loved how I named that field, and I'm open to suggestions. . Since we don't have restarts configured right now, I didn't have a chance to test this change. I didn't update the Readme yet either, since this is not a change users can use yet, I'm realizing now we do need some way to keep track of all the documentation changes we'll need to make.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/823:108,config,config,108,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/823,2,['config'],"['config', 'configured']"
Modifiability,Make PAPIv2 batch request timeouts configurable,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4973:35,config,configurable,35,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4973,1,['config'],['configurable']
Modifiability,Make backends default values configurable,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/724:29,config,configurable,29,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/724,2,['config'],['configurable']
Modifiability,Make carboniter 'enabled' config value name/location better [BA-6372],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5484:26,config,config,26,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5484,1,['config'],['config']
Modifiability,Make dockerRoot a configurable value,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4088:18,config,configurable,18,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4088,1,['config'],['configurable']
Modifiability,Make gsutil retries configurable,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3854:20,config,configurable,20,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3854,1,['config'],['configurable']
Modifiability,Make localization retries configurable,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3856:26,config,configurable,26,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3856,1,['config'],['configurable']
Modifiability,Make restarting old workflows configurable,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/755:30,config,configurable,30,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/755,1,['config'],['configurable']
Modifiability,Make sure that w/ the configuration from #2142 that one can run the new JG WDL w/ 3 samples. Fix any issues which might come up in this process,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2143:22,config,configuration,22,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2143,1,['config'],['configuration']
Modifiability,Make sure the test configs can cascade through,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/534:19,config,configs,19,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/534,1,['config'],['configs']
Modifiability,Make tmpDir configurable in reference.conf,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2655:12,config,configurable,12,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2655,1,['config'],['configurable']
Modifiability,Make use of the new lookup / variable resolution schema,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1579:29,variab,variable,29,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1579,1,['variab'],['variable']
Modifiability,"Makes a common `BatchingDbWriter` object to hold types for batched writers. For the time being at least I've refrained from a deeper refactor to pull commonality up to an abstract parent FSM, though that does mean a fair amount of repetition in the implementation classes.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2224:133,refactor,refactor,133,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2224,1,['refactor'],['refactor']
Modifiability,Makes ~ 2 * &lt;base&gt;^2 rows of metadata (~80000 as currently configured) in one burst. I Intentionally did not write a .test for this as I doubt Travis would survive. Not sure where this should live.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5504:65,config,configured,65,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5504,1,['config'],['configured']
Modifiability,Mandatory service configuration in current development branch,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4577:18,config,configuration,18,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4577,1,['config'],['configuration']
Modifiability,Many tools have thread/cores as parameter. It does not influence the end results but its change in inputs may be considered as cache invalidation by cromwell. It would be nice to have a way to tell cromwell to ignore some variables (like threads) in the caching process.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2927:222,variab,variables,222,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2927,1,['variab'],['variables']
Modifiability,Mapper.scala:24); 	 at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$mapOrNoResolve$2(StandardAsyncExecutionActor.scala:163); 	 at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$commandLineValueMapper$1(StandardAsyncExecutionActor.scala:206); 	 at mouse.AnyOps$.$bar$greater$extension(any.scala:8); 	 at cromwell.backend.standard.StandardAsyncExecutionActor.localize$1(StandardAsyncExecutionActor.scala:474); 	 at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$runtimeEnvironmentPathMapper$2(StandardAsyncExecutionActor.scala:475); 	 at mouse.AnyOps$.$bar$greater$extension(any.scala:8); 	 at cromwell.backend.standard.StandardAsyncExecutionActor.runtimeEnvironmentPathMapper(StandardAsyncExecutionActor.scala:475); 	 at cromwell.backend.standard.StandardAsyncExecutionActor.runtimeEnvironmentPathMapper$(StandardAsyncExecutionActor.scala:473); 	 at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.runtimeEnvironmentPathMapper(ConfigAsyncJobExecutionActor.scala:215); 	 at cromwell.backend.standard.StandardAsyncExecutionActor.$anonfun$runtimeEnvironment$1(StandardAsyncExecutionActor.scala:479); 	 at mouse.AnyOps$.$bar$greater$extension(any.scala:8); 	 at cromwell.backend.standard.StandardAsyncExecutionActor.runtimeEnvironment(StandardAsyncExecutionActor.scala:479); 	 at cromwell.backend.standard.StandardAsyncExecutionActor.runtimeEnvironment$(StandardAsyncExecutionActor.scala:479); 	 at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.runtimeEnvironment$lzycompute(ConfigAsyncJobExecutionActor.scala:215); 	 at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.runtimeEnvironment(ConfigAsyncJobExecutionActor.scala:215); 	 at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand(StandardAsyncExecutionActor.scala:637); 	 at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand$(StandardAsyncExecutionActor.scala:607); 	 at cromwell,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6757:4572,Config,ConfigAsyncJobExecutionActor,4572,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6757,1,['Config'],['ConfigAsyncJobExecutionActor']
Modifiability,Mark workflow TooLargeToArchive if carbonited json exceeds the configured bucket-read-limit-bytes value [BT-6],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6084:63,config,configured,63,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6084,1,['config'],['configured']
Modifiability,MaterializeWorkflowDescriptorActor: Use passed-in config,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1075:50,config,config,50,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1075,1,['config'],['config']
Modifiability,"MemoryRetryTest {; 	String message = ""Killed""; 	; 	call TestOutOfMemoryRetry {}; 	call TestBadCommandRetry {}; }. task TestOutOfMemoryRetry {; 	command <<<; 		free -h; 		df -h; 		cat /proc/cpuinfo. 		echo ""Killed"" >&2; 		tail /dev/zero; 	>>>; 	; 	runtime {; 		cpu: ""1""; 		memory: ""1 GB""; 		maxRetries: 4; 		continueOnReturnCode: 0; 	}; 	; }. task TestBadCommandRetry {; 	command <<<; free -h; df -h; cat /proc/cpuinfo. 		echo ""Killed"" >&2; 		bedtools intersect nothing with nothing; 	>>>; 	; 	runtime {; 		cpu: ""1""; 		memory: ""1 GB""; 		maxRetries: 4; 		continueOnReturnCode: 0; 	}; }. My.conf:. include required(classpath(""application"")). system {; memory-retry-error-keys = [""OutOfMemory"", ""Killed"", ""Error:""]; }. backend {; default = PAPIv2. providers {; PAPIv2 {; actor-factory = ""cromwell.backend.google.pipelines.v2beta.PipelinesApiLifecycleActorFactory"". system {; memory-retry-error-keys = [""OutOfMemory"", ""Killed"", ""Error:""]; }; config {; project = ""$my_project""; root = ""$my_bucket""; name-for-call-caching-purposes: PAPI; slow-job-warning-time: 24 hours; genomics-api-queries-per-100-seconds = 1000; maximum-polling-interval = 600. # Setup GCP to give more memory with each retry; system {; memory-retry-error-keys = [""OutOfMemory"", ""Killed"", ""Error:""]; }; system.memory-retry-error-keys = [""OutOfMemory"", ""Killed"", ""Error:""]; memory_retry_multiplier = 4; ; # Number of workers to assign to PAPI requests; request-workers = 3. virtual-private-cloud {; network-label-key = ""network-key""; network-name = ""network-name""; subnetwork-name = ""subnetwork-name""; auth = ""auth""; }; pipeline-timeout = 7 days; genomics {; auth = ""auth""; compute-service-account = ""$my_account""; endpoint-url = ""https://lifesciences.googleapis.com/""; location = ""us-central1""; restrict-metadata-access = false; localization-attempts = 3; parallel-composite-upload-threshold=""150M""; }; filesystems {; gcs {; auth = ""auth""; project = ""$my_project""; caching {; duplication-strategy = ""copy""; }; }; }; system {; memory-retr",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7451:1298,config,config,1298,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7451,1,['config'],['config']
Modifiability,Metadata Endpoint Enhancement,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4340:18,Enhance,Enhancement,18,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4340,1,['Enhance'],['Enhancement']
Modifiability,"MetadataValue.apply was throwing an NPE exception when passed null, even though it had a call to .getOrElse("""").; Consolidated standard backend runtimeAttributeDefinitions implementation.; Added a GoogleAuthModeSpec.assumeHasApplicationDefaultCredentials in tests that use application default credentials.; Refactored away JesBackendLifecycleActorFactory's toJes, only used in one place where a similar standard method now exists.; Refactored away JesBackendLifecycleActorFactory's staticRuntimeAttributeDefinitions, only used in specs.; CromwellServer no longer hard codes the binding timeout.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1823:307,Refactor,Refactored,307,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1823,2,['Refactor'],['Refactored']
Modifiability,"Meth/41d3eecf-c5a9-42e4-8a29-8be9c252b7f5/call-trimAdapters/inputs/13016223/fastq -> /data/PROJECTS/2019_01_28_scMeth/scripts/Automated_Pipeline/cromwell/example_wdl/fastq; [2019-07-10 14:33:01,23] [warn] Localization via copy has failed: /data/PROJECTS/2019_01_28_scMeth/scripts/Automated_Pipeline/cromwell/example_wdl/fastq; [2019-07-10 14:33:01,24] [error] BackgroundConfigAsyncJobExecutionActor [41d3eecfscMeth.trimAdapters:NA:1]: Error attempting to Execute; java.lang.Exception: Failed command instantiation; 	at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand(StandardAsyncExecutionActor.scala:576); 	at cromwell.backend.standard.StandardAsyncExecutionActor.instantiatedCommand$(StandardAsyncExecutionActor.scala:511); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.instantiatedCommand$lzycompute(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.instantiatedCommand(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.standard.StandardAsyncExecutionActor.commandScriptContents(StandardAsyncExecutionActor.scala:319); 	at cromwell.backend.standard.StandardAsyncExecutionActor.commandScriptContents$(StandardAsyncExecutionActor.scala:318); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.commandScriptContents(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.writeScriptContents(SharedFileSystemAsyncJobExecutionActor.scala:175); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor.writeScriptContents$(SharedFileSystemAsyncJobExecutionActor.scala:174); 	at cromwell.backend.impl.sfs.config.BackgroundConfigAsyncJobExecutionActor.cromwell$backend$sfs$BackgroundAsyncJobExecutionActor$$super$writeScriptContents(ConfigAsyncJobExecutionActor.scala:200); 	at cromwell.backend.sfs.BackgroundAsyncJobExecutionActor.writeScriptContents(BackgroundAsyncJobExecutionActor.scal",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5066:10097,Config,ConfigAsyncJobExecutionActor,10097,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5066,1,['Config'],['ConfigAsyncJobExecutionActor']
Modifiability,"Minor change to FileUtil to convert to an enhanced class pattern instead of util functions. Reviewable now, but hold off on merging until the end of the sprint.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/97:42,enhance,enhanced,42,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/97,1,['enhance'],['enhanced']
Modifiability,Minor changes in order to support:; 1. Configurable docker command in HtCondor.; 2. Allow the use of soft-links in dockerized jobs.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1432:39,Config,Configurable,39,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1432,1,['Config'],['Configurable']
Modifiability,Minor fixes to Cromwell server repo config [BT-243],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6322:36,config,config,36,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6322,1,['config'],['config']
Modifiability,Missing Service Configuration should fail Cromwell initialisation,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/871:16,Config,Configuration,16,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/871,1,['Config'],['Configuration']
Modifiability,Missing changelog message regarding Logback environment variables. Closes #345,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/530:56,variab,variables,56,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/530,1,['variab'],['variables']
Modifiability,"More details about recreating the error here: https://gatkforums.broadinstitute.org/firecloud/discussion/10740/error-the-local-copy-message-must-have-path-set. Essentially, if a task looks like ; ```; task t {; 	File x = """"; 	; 	command {; ...; 	}; 	runtime {; ...; 	}; }; ```; The job fails with: ; ```; BackendJobDescriptorKey_CommandCallNode_w.t:-1:1/CCHashingJobActor-b12fef61-w.t:NA:1] Failed to hash ; cromwell.core.path.PathParsingException: java.lang.IllegalArgumentException: Either exists on a filesystem not supported by this instance of Cromwell, or a failure occurred while building an actionable path from it. Supported filesystems are: Google Cloud Storage. Failures: Google Cloud Storage: does not have a gcs scheme (IllegalArgumentException) Please refer to the documentation for more information on how to configure filesystems: http://cromwell.readthedocs.io/en/develop/backends/HPC/#filesystems; 	at cromwell.core.path.PathFactory$.$anonfun$buildPath$4(PathFactory.scala:64); 	at scala.Option.getOrElse(Option.scala:121); 	at cromwell.core.path.PathFactory$.buildPath(PathFactory.scala:58); 	at cromwell.core.path.PathFactory.buildPath(PathFactory.scala:30); ```. AC: ; 1. In case that a user has set the value of a required File as an empty string --this error message should instead accommodate for this special case and point out that an empty string isn't valid input for a File object. ; 1b. If easy, it would also be nice to remove the link to the HPC config docs and the rest of the info about supported filesystems. ; [Optional] 2. If this doesn't hurt performance somehow, it would be nice if the error message also included the name of the input that failed to hash, not just the name of the call/value of the file.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4158:824,config,configure,824,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4158,2,['config'],"['config', 'configure']"
Modifiability,"Most of the work here is around threading Azure token acquisition through the existing Google-based DRS filesystem. Partial example config:; ```; filesystems {; drs {; global {; config {; martha {; url = ""https://us-central1-broad-dsde-dev.cloudfunctions.net/martha_v3""; }; }; }; }; }. backend {; providers {; TES {; actor-factory = ""cromwell.backend.impl.tes.TesBackendLifecycleActorFactory""; config {; filesystems {; drs {; enabled = true; auth = ""azure""; azure-keyvault-name = ""INSERT_YOUR_KEYVAULT_NAME_HERE""; azure-token-secret = ""INSERT_YOUR_SECRET_NAME_HERE""; }; }; }; }; }; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6561:132,config,config,132,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6561,3,['config'],['config']
Modifiability,Move a metadata service config option to the right location. Closes #1835,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1853:24,config,config,24,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1853,1,['config'],['config']
Modifiability,Move hardcoded default workflow options into config files,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/908:45,config,config,45,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/908,1,['config'],['config']
Modifiability,Move reference configuration for services back to reference.conf.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4589:15,config,configuration,15,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4589,1,['config'],['configuration']
Modifiability,Move reference image configuration inline with Cromwell configuration rather than using an outboard configuration file that is not subject to version control.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6176:21,config,configuration,21,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6176,3,['config'],['configuration']
Modifiability,"Moved parts of the shadow local backend into a new background executor.; Patches to tests based on changed to local: now with job id, fewer processes running in three step, using sfs config.; Replaced SGE backend with a config based version and added LSF example.; Revert: Jes's poll backoff starting at 30s up to 10 minutes is completely inappropriate for shared file system polling.; Docker Hub appears to have busted the v1 enpoint so disabling the test for now.; Sleep a second before letting the `WorkflowExecutionActorSpec` check for metadata status.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1252:183,config,config,183,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1252,2,['config'],['config']
Modifiability,"Much like our operation polling the creation of new runs in jes winds up being a problem when lots of jobs are created at once as we wind up with a ton of threads gumming up the works but still can only submit at the rate of the genomics api qps. It'd be way more fun to use those threads for things like DB access, mining bitcoins, skynet, etc. Transform the JesPollingActor & friends such that that structure manages both create and get operations (the batch API allows for heterogenous requests) are going through the same structure metered by the QPS supplied by the config file.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1798:571,config,config,571,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1798,1,['config'],['config']
Modifiability,"My WDL pipeline failed to run with Cromwell 55 configured with the `cromwell.backend.google.pipelines.v2beta.PipelinesApiLifecycleActorFactory` Google API with a long list of errors such as the following:; ```; ...; {; ""causedBy"": [; {; ""causedBy"": [; {; ""message"": ""504 Gateway Timeout\nGET https://storage.googleapis.com/download/storage/v1/b/mccarroll-mocha/o/cromwell%2Fcromwell-executions%2Fmocha%2F86d47e9a-5745-4ec0-b4eb-0164f073e5f4%2Fcall-idat2gtc%2Fshard-73%2Frc?alt=media"",; ""causedBy"": []; }; ],; ""message"": ""Could not read from gs://mccarroll-mocha/cromwell/cromwell-executions/mocha/86d47e9a-5745-4ec0-b4eb-0164f073e5f4/call-idat2gtc/shard-73/rc: 504 Gateway Timeout\nGET https://storage.googleapis.com/download/storage/v1/b/mccarroll-mocha/o/cromwell%2Fcromwell-executions%2Fmocha%2F86d47e9a-5745-4ec0-b4eb-0164f073e5f4%2Fcall-idat2gtc%2Fshard-73%2Frc?alt=media""; }; ],; ""message"": ""[Attempted 1 time(s)] - IOException: Could not read from gs://mccarroll-mocha/cromwell/cromwell-executions/mocha/86d47e9a-5745-4ec0-b4eb-0164f073e5f4/call-idat2gtc/shard-73/rc: 504 Gateway Timeout\nGET https://storage.googleapis.com/download/storage/v1/b/mccarroll-mocha/o/cromwell%2Fcromwell-executions%2Fmocha%2F86d47e9a-5745-4ec0-b4eb-0164f073e5f4%2Fcall-idat2gtc%2Fshard-73%2Frc?alt=media""; }; ],; ""message"": ""Workflow failed""; ```; I was under the expectation that this had been handled in issue #5344 and that Cromwell would retry to access the files until available (the files do indeed exist at the time of this writing).",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6154:47,config,configured,47,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6154,1,['config'],['configured']
Modifiability,"My assumption is that by using log4j + logback for our logging infrastructure, we actually offer end users quite a bit of configurability in both what is logged as well as to where (e.g. appenders). However, without example and docs users don't know how to do this. For example, rather than using a log4j rotating log appender, Henry instead piped stdout into a standalone log appender. This means he had to build his own docker rather than use our published one.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1622:122,config,configurability,122,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1622,1,['config'],['configurability']
Modifiability,"My cromwell config has two backends, local and AWSBATCH; local is the default. I submitted a workflow with workflow options setting backend to AWSBATCH. After quitting cromwell and later restarting, it is trying to resubmit jobs to the local engine, and of course failing.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4215:12,config,config,12,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4215,1,['config'],['config']
Modifiability,"NOTE: I haven't 100% confirmed that the application.conf isn't auto-included, but since we now have separated cromwell into artifacts, based on the HOCON docs it does not appear that we're using an ""application.conf"" as intended: https://github.com/typesafehub/config/blob/master/HOCON.md#conventional-configuration-files-for-jvm-apps. If someone needs to specify a backend via a new application.conf, they shouldn't need to do one of the two current workarounds:. 1) Know to include the _original_ application.conf.; 2) Copy/paste all of the previous application.conf, including things like akka dispatcher executors. The fix is to rename the core/src/main/resources/{application.conf => reference.conf}. When one then adjusts settings while running the fat-jar, one definitely doesn't need to re-include a reference.conf. The ticket says ""most of?"" because there may be some elements of the current core/.../application.conf that would be more appropriate for a fat-jar _only_, such as having the main.hsqldb and an included Local backend.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1389:261,config,config,261,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1389,2,['config'],"['config', 'configuration-files-for-jvm-apps']"
Modifiability,"NOTE: if the PAPI v2 upgrade happens in all environments before horizontaling, this ticket becomes unnecessary and should be closed as a noop. OTHERWISE:. Adapt the existing Centaur test for PAPI v1 to PAPI v2 upgrade for a horizontal Cromwell configuration.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4801:155,Adapt,Adapt,155,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4801,2,"['Adapt', 'config']","['Adapt', 'configuration']"
Modifiability,"Need ""null"" value to parameterize runtime attributes in a WDL.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1804:21,parameteriz,parameterize,21,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1804,1,['parameteriz'],['parameterize']
Modifiability,Need a HOWTO on creating a refresh token and how to modify a configuration file appropriately,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2100:61,config,configuration,61,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2100,1,['config'],['configuration']
Modifiability,New example configuration to reflect changes since v52. Signed-off-by: markjschreiber <markjschreiber@gmail.com>,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5858:12,config,configuration,12,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5858,1,['config'],['configuration']
Modifiability,"Next phase of #2835. A CWL centaur test should be added that validates expected call/workflow outputs. The famous 3-step workflow uses `ps` to generate outputs, meaning that the actual content is highly variable depending on what other processes are running at the time. Instead, a stable output should be generated, something like [`""OH NO!\nOH NO!\n1""`](https://github.com/broadinstitute/cromwell/blob/f2d1c3bdd5535d9f6a997eadaf136742d86adbe5/centaur/src/main/resources/standardTestCases/continue_on_return_code.test#L11). If the output of the task is a File (path or CWL-File), the output may be affected by #2899.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2924:203,variab,variable,203,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2924,1,['variab'],['variable']
Modifiability,"Note these fixes only apply to the config backend; JES does not currently seem to have a provision for specifying users other than root. This uses `/cromwell-executions` rather than `/root` as the execution root inside the container. Permissions of files and directories are liberalized for the users inside and outside of the container. All tests pass if I change `reference.conf` to say `String docker_user = ""nobody""`, but I've currently left `docker_user` as an unfilled (old-fashioned) `String?`.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1865:35,config,config,35,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1865,1,['config'],['config']
Modifiability,"Note to PO/scrumlords - I'm not asking for this to be prioritized. I just wanted a reminder for myself. I believe that sbt-native-publisher w/ the docker plugin could automate some of our docker-y cromwell stuff. Figure out if that's true or not, if so do it and/or write a new ticket",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/857:154,plugin,plugin,154,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/857,1,['plugin'],['plugin']
Modifiability,"Note to reviewers: it is highly recommended to ignore the 'mass renames' commit and probably the 'enter the restart check token dispenser' commit too, those are nearly all noisy mechanical refactors. In addition to the regular job ""execution"" token dispenser, these changes add a second job ""restart check"" token dispenser that can be configured with a different rate limit. Apart from that there are some fairly minor changes to the EJEA FSM to account for the new token type. As warned about above, a lot of the changes here are mechanical noise; the conceptual changes are not really that big. I'm happy to walk through this in person if it isn't clear from looking through these diffs. EJEA tests are known to be failing which isn't surprising, still grinding through some fixes for those...",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6590:189,refactor,refactors,189,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6590,2,"['config', 'refactor']","['configured', 'refactors']"
Modifiability,"Noticed that cached-copy localization strategy is broken in Cromwell-51. This test works on a cluster where `execution-dir` is some place to do execution and copy the inputs to, and `/different/file/system/` is on a different disk. Small task (`catsmallfile.wdl`):. ```wdl; version development. task CatSmallFile {; input {; File inp; }; command {; cat ${inp}; }; output {; String out = read_string(stdout()); }; }; ```. Config (`cromwell.conf`):; ```hocon; include required(classpath(""application"")). backend: {; ""default"": ""Local"",; ""providers"": {; ""Local"": {; ""actor-factory"": ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory"",; ""config"": {; ""root"": ""<execution-dir>"",; ""filesystems.local.duplication-strategy"": [; ""cached-copy""; ]; }; }; }; }; ```. Command:. ```bash; echo ""Goodbye, call-caching"" >> /different/file/system/inp.txt; echo '{""inp"": ""/different/file/system/inp.txt""}' >> inputs.json. java -Dconfig.file=cromwell.conf -jar cromwell-50.jar run catsmallfile.wdl -i inputs.json; # <execution-dir>/cached-inputs/ is empty. java -Dconfig.file=cromwell.conf -jar cromwell-50.jar run catsmallfile.wdl -i inputs.json; # <execution-dir>/cached-inputs/ is populated; ```. ----. Anecdotally, I've noticed some of the permissions of localised files have changed, I wonder if this is related to that?",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5533:421,Config,Config,421,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5533,4,"['Config', 'config']","['Config', 'ConfigBackendLifecycleActorFactory', 'config']"
Modifiability,Now setting config directly in the `database` stanza.; Deprecated `database.config`.; Database migration now just uses the key `database.migration` for configuration settings.; Moved database migration defaults into the reference.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1440:12,config,config,12,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1440,3,['config'],"['config', 'configuration']"
Modifiability,"Now that we've updated our WDLs to 1.0, we've found that `womtool graph` no longer works. It looks like it only supports draft2 and earlier WDL. `test.wdl`:; ```; version 1.0. workflow Test { }; ```. ```; $ java -jar womtool-35.jar graph /tmp/test.wdl ; Exception in thread ""main"" wdl.draft2.parser.WdlParser$SyntaxError: ERROR: Finished parsing without consuming all tokens. version 1.0; ^; ; 	at wdl.draft2.parser.WdlParser.parse(WdlParser.java:2330); 	at wdl.draft2.parser.WdlParser.parse(WdlParser.java:2335); 	at wdl.draft2.model.AstTools$.getAst(AstTools.scala:266); 	at wdl.draft2.model.WdlNamespace$.$anonfun$load$1(WdlNamespace.scala:160); 	at scala.util.Try$.apply(Try.scala:209); 	at wdl.draft2.model.WdlNamespace$.load(WdlNamespace.scala:160); 	at wdl.draft2.model.WdlNamespace$.loadUsingSource(WdlNamespace.scala:156); 	at wdl.draft2.model.WdlNamespaceWithWorkflow$.load(WdlNamespace.scala:571); 	at womtool.graph.GraphPrint$.generateWorkflowDigraph(GraphPrint.scala:19); 	at womtool.WomtoolMain$.graph(WomtoolMain.scala:94); 	at womtool.WomtoolMain$.dispatchCommand(WomtoolMain.scala:48); 	at womtool.WomtoolMain$.runWomtool(WomtoolMain.scala:125); 	at womtool.WomtoolMain$.delayedEndpoint$womtool$WomtoolMain$1(WomtoolMain.scala:130); 	at womtool.WomtoolMain$delayedInit$body.apply(WomtoolMain.scala:18); 	at scala.Function0.apply$mcV$sp(Function0.scala:34); 	at scala.Function0.apply$mcV$sp$(Function0.scala:34); 	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:12); 	at scala.App.$anonfun$main$1$adapted(App.scala:76); 	at scala.collection.immutable.List.foreach(List.scala:389); 	at scala.App.main(App.scala:76); 	at scala.App.main$(App.scala:74); 	at womtool.WomtoolMain$.main(WomtoolMain.scala:18); 	at womtool.WomtoolMain.main(WomtoolMain.scala); ```; ; The `womgraph` command still works, but the output from that command is so verbose it's unusable for viewing our workflows.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4234:1537,adapt,adapted,1537,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4234,1,['adapt'],['adapted']
Modifiability,"OK slight change of plan: execution bucket call cache hints will be opt-in for now via workflow options with no changes required in Cromwell config. This actually does not have to be PAPI specific so the proposed nomenclature would be more general:. ```json; {; call_cache_hit_path_prefixes: [ ""gs://bucket-full-o-cache-hits"", ""gs://another-bucket-o-cache-hits"" ]; }; ```. ""opt-in"" here means that for now the caller would be responsible for specifying the prefixes by which to filter cache hits. If no prefixes are specified Cromwell will do no cache hit filtering. Backends have the ability to specify a root execution path to prepend to this list. For now this root execution path would only be prepended by PAPI since that's the only backend for which a sensible root could be determined by inspection (i.e. the GCS bucket). The number of prefixes in this list would be limited, for now I'm arbitrarily choosing 3 total. @ruchim",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4019:141,config,config,141,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4019,1,['config'],['config']
Modifiability,"OR - Failed to instantiate Cromwell System. Shutting down Cromwell.; liquibase.exception.MigrationFailedException: Migration failed for change set changesets/resync_engine_schema.xml::restore_auto_increment_call_caching_hash_entry_id_postgresql::kshakir:; Reason: liquibase.exception.DatabaseException: ERROR: syntax error at or near ""as""; Position: 73 [Failed SQL: alter sequence ""CALL_CACHING_HASH_ENTRY_CALL_CACHING_HASH_ENTRY_ID_seq"" as bigint]; 	at liquibase.changelog.ChangeSet.execute(ChangeSet.java:637); 	at liquibase.changelog.visitor.UpdateVisitor.visit(UpdateVisitor.java:53); 	at liquibase.changelog.ChangeLogIterator.run(ChangeLogIterator.java:83); 	at liquibase.Liquibase.update(Liquibase.java:202); 	at liquibase.Liquibase.update(Liquibase.java:179); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:67); 	at cromwell.database.migration.liquibase.LiquibaseUtils$.updateSchema(LiquibaseUtils.scala:39); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1(ServicesStore.scala:11); 	at cromwell.services.ServicesStore$EnhancedSqlDatabase$.$anonfun$initialized$1$adapted(ServicesStore.scala:11); 	at cromwell.database.slick.SlickDatabase.$anonfun$withConnection$1(SlickDatabase.scala:156); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:70); 	at slick.jdbc.SimpleJdbcAction.run(StreamingInvokerAction.scala:69); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.liftedTree1$1(BasicBackend.scala:275); 	at slick.basic.BasicBackend$DatabaseDef$$anon$2.run(BasicBackend.scala:275); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748); Caused by: liquibase.exception.DatabaseException: ERROR: syntax error at or near ""as""; Position: 73 [Failed SQL: alter sequence ""CALL_CACHING_HASH_ENTRY_CALL_CACHING_HASH_ENTRY_ID_seq"" as bigint]; 	at liquibas",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5083:35881,Enhance,EnhancedSqlDatabase,35881,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5083,1,['Enhance'],['EnhancedSqlDatabase']
Modifiability,"OS: **Centos 7**; Cromwell version: **cromwell 86** installed from conda-forge; Backend: **SFS**. Hello,. I'm configuring Cromwell to run on my group's SLURM cluster, and struggling to make `cpu`/`memory` runtime attributes optional. I believe this is supported because the ""Getting started on HPC Clusters"" documentation shows `memory_gb` as an optional `runtime-attribute`: https://cromwell.readthedocs.io/en/develop/tutorials/HPCIntro/. ```; backend.providers.SGE.config {; runtime-attributes = """"""; Int cpu = 1; Float? memory_gb; String? sge_queue; String? sge_project; """"""; }; ```. My intent is for the user to only provide arguments for `cpu`, `memory`, `runtime_minutes`, and `partition` if they intend to override the SLURM cluster's defaults. I do not want to have cromwell supply defaults, because if these arguments are omitted from the call to `sbatch` then the cluster's defaults will be used. My understanding is that making them optional like `String? memory_mb` and then using syntax like `${""--mem "" + round(memory_mb) + ""m""} \` in the submit script means that argument will only be added if `memory` is defined, and will be omitted if `memory` is not defined. I've followed the documentation as closely as I can. However, when I try to submit a test job without `cpu` and `memory` set as a runtime attribute, I get a failure with these exceptions:; ```; cromwell.core.CromwellAggregatedException: Initialization Failure:; Runtime validation failed:; 	Task myTask has an invalid runtime attribute cpu = !! NOT FOUND !!; 	Task myTask has an invalid runtime attribute memory = !! NOT FOUND !!; 	at cromwell.engine.workflow.WorkflowActor$$anonfun$3.applyOrElse(WorkflowActor.scala:356); 	at cromwell.engine.workflow.WorkflowActor$$anonfun$3.applyOrElse(WorkflowActor.scala:339); 	at scala.runtime.AbstractPartialFunction.apply(AbstractPartialFunction.scala:35); 	at akka.actor.FSM.processEvent(FSM.scala:707); 	at akka.actor.FSM.processEvent$(FSM.scala:704); ```. Here is the test WDL I'",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7455:110,config,configuring,110,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7455,2,['config'],"['config', 'configuring']"
Modifiability,Occasionally run `check-alive` in config backend,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2315:34,config,config,34,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2315,1,['config'],['config']
Modifiability,"Often we call a bash command in a task, read in the stdout, and set a variable to the string read in. When a cromwell job is submitted to SGE, however, cromwell prints the SGE job id to the stdout (don't know when or how often). When we then read from the stdout, the job id gets read in addition to the real output we are interested in. . The example test wdl can be found in /humgen/gsa-hpprojects/dev/tsato/wdl/testSGE.wdl. The output of `GetBamFileName` starts with the job-id + newline character. We don't want them. The same workflow runs as expected on a GSAx server.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1512:70,variab,variable,70,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1512,1,['variab'],['variable']
Modifiability,"Ok, so validation fails because I had a typo in my input variable name, fine. But TELL ME WHICH VARIABLE IT WAS!!!. The rest of this description is an example:. ```; workflow foo {; 	call bar; 	# Oops, bar didn't have an output called b:; 	call baz as bad_output_name { input: b = bar.b }; 	# Oops, baz doesn't have an input called a:; 	call baz as bad_input_name { input: a = bar.a }; }. task bar {; 	command {; 		# noop; 	}; 	output {; 		String a = ""a""; 	}; 	runtime {; 		docker: ""ubuntu:latest""; 	}; }. task baz {; 	String b; 	command {; 		# noop; 	}; 	runtime {; 		docker: ""ubuntu:latest""; 	}; }; ```. The messages I actually get:; ```; Unable to load namespace from workflow: ERROR: Expression references input on call that doesn't exist (line 4, col 47):. 	call baz as bad_output_name { input: b = bar.b }; ^; Unable to load namespace from workflow: ERROR: Call references an input on task 'baz' that doesn't exist (line 6, col 38). 	call baz as bad_input_name { input: a = bar.a }; ^; ```. The message I want:; ```; Unable to load namespace from workflow: ERROR: Cannot use 'bar.b' as an input. That variable was never created. (line 4, col 47):. 	call baz as bad_output_name { input: b = bar.b }; ^; Unable to load namespace from workflow: ERROR: Call supplies an input 'a' that isn't declared in the 'baz' task (line 6, col 38). 	call baz as bad_input_name { input: a = bar.a }; ^; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2211:57,variab,variable,57,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2211,3,"['VARIAB', 'variab']","['VARIABLE', 'variable']"
Modifiability,"Okay. So initially, I was passing the `ServiceRegistryActor` reference via props down the chain of actors, and each of the actors needed to follow a pattern of steps to insert into the metadata (e.g. create a `MetadataEvent` with a `MetadataPutAction` within which the `Metadata[Key, Value]` resided, send this message over to the the service registry, and handle failures, if any. It did not look good by any stretch IMO. All the metadata generating entities needed to be aware of the `MetadataService` (the erstwhile dataAcess). **Edit:** Using the above design in-fact now. ~~Currently, what I've done below is create a single instance of the `ServiceRegistryActor` in the `WorkflowManagerActor`and then create a `WorkflowProfilerActor` (one per workflow) which is supposed to handle all the metadata information coming from the engine side for a particular workflow. The way it happens is based on the presumption that almost all the information that we needed was present in the `StateName` and `StateData` of our FSMs. Unfortunately, with Akka's `SubscribeTransitionalCallback` we can only monitor the FSM states, and not the data. So I've created a trait (which the Engine's FSMs can extend from) which provide the semantics of wrapping up the state and data of the FSM in a message, and publish it into Akka's event stream. The ProfilerActor is the listener of these events and handles them appropriately. With this, I was able to make the FSMs unaware of the MetadataServices, and simply publish it's state and data in the event stream while performing any transitions.~~. ~~Let me know if you guys have any (other?) ideas / suggestions.~~. Contents added to metadata with this PR:; - [x] workflowName; - [ ] calls (To come from the backends); - [x] outputs ; - [x] id; - [x] inputs; - [x] submission; - [x] status; - [x] end; - [x] start",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/829:1191,extend,extend,1191,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/829,1,['extend'],['extend']
Modifiability,"Okay. So initially, I was passing the `ServiceRegistryActor` reference via props down the chain of actors, and each of the actors needed to follow a pattern of steps to insert into the metadata (e.g. create a `MetadataEvent` with a `MetadataPutAction` within which the `Metadata[Key, Value]` resided, send this message over to the the service registry, and handle failures, if any. It did not look good by any stretch IMO. All the metadata generating entities needed to be aware of the `MetadataService` (the erstwhile dataAcess). Currently, what I've done below is create a single instance of the `ServiceRegistryActor` in the `WorkflowManagerActor`and then create a `WorkflowProfilerActor` (one per workflow) which is supposed to handle all the metadata information coming from the engine side for a particular workflow. The way it happens is based on the presumption that almost all the information that we needed was present in the `StateName` and `StateData` of our FSMs. Unfortunately, with Akka's `SubscribeTransitionalCallback` we can only monitor the FSM states, and not the data. So I've created a trait (which the Engine's FSMs can extend from) which provide the semantics of wrapping up the state and data of the FSM in a message, and publish it into Akka's event stream. The ProfilerActor is the listener of these events and handles them appropriately. With this, I was able to make the FSMs unaware of the MetadataServices, and simply publish it's state and data in the event stream while performing any transitions. . Let me know if you guys have any (other?) ideas / suggestions. Edit: Names of new actors might be pretty bad IMO. Please suggest better ones if you have any. _P.S. : Currently based out of the Chris's branch since his metadata changes were needed._; _P.P.S. : Still a WIP for improving some stuff._",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/822:1143,extend,extend,1143,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/822,1,['extend'],['extend']
Modifiability,"Once we merge PR #15, funnel is going to start respecting resource requests from tasks. The defaults in the Cromwell TES backend are 1 cpu and 2 GB of RAM. So if we want the centaur tests to finish in a reasonable timeframe we need to hard code in local resources into Funnel's config.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2070:278,config,config,278,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2070,1,['config'],['config']
Modifiability,"One new mode of backpressuring, some tweaks to the existing backpressuring, and several config value changes. The new backpressuring mode involves looking at the creation times of I/O command being dequeued from the I/O queue for processing and comparing them to a staleness threshold. If the commands are found to be stale, variable backpressure will be applied between lower and upper limits.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6460:88,config,config,88,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6460,2,"['config', 'variab']","['config', 'variable']"
Modifiability,"One of Morgan's input files was missing an md5 in its object metadata. Cromwell was dutifully falling back to our backup option, which is to read every byte of the file into memory and calculate the hash itself. This resulted in extraordinary network and CPU usage that destabilized the instance and caused a continual crash/reboot cycle. We think this is also what Lori ran into with the featured workspaces. Now, we detect & avoid this condition, print a warning, and carry on without call caching:; ```; 41183c60:ImputationBeagle.SubsetVcfToRegion:3:1:; Hash error ([Attempted 1 time(s)] - Exception:; File of type BlobPath requires hash in object metadata, not present for; https://lz8b0d07a4d28c13150a1a12.blob.core.windows.net/sc-94fd136b-4231-4e80-ab0c-76d8a2811066/hg38/inputs/palantir_merged_input_samples.liftedover.vcf.gz),; disabling call caching for this job.; ```. Obviously, we'd like to enhance this in the future so that call caching is still possible for these jobs, but we have to walk before we can run. ---. Visualization eye candy section!. Swiftly downloading a file on the datacenter multi-gigabit LAN:. ![Screenshot 2024-05-02 at 19 24 04](https://github.com/broadinstitute/cromwell/assets/1087943/46484bbd-30e0-4f88-8f6c-05b50649c557). Telltale CPU curve as we chew through one file after another:. ![Screenshot 2024-05-03 at 11 32 13](https://github.com/broadinstitute/cromwell/assets/1087943/7916ce63-8d4c-46f7-a86a-b3313edf0d77). Flame graph showing the smoking gun, `generateMd5FileHashForPath`:. ![Screenshot 2024-05-02 at 14 02 25](https://github.com/broadinstitute/cromwell/assets/1087943/0d06f3ad-8155-4b43-bef7-6d9ccce35132)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7419:903,enhance,enhance,903,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7419,1,['enhance'],['enhance']
Modifiability,"One possible solution: We should probably create a trait which loads all the configuration (once per application), and let classes mix it in to avoid doing ConfigFactory.load() at multiple places",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/796:77,config,configuration,77,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/796,2,"['Config', 'config']","['ConfigFactory', 'configuration']"
Modifiability,"Only the refresh-token mode requires new credentials to be created/validated for every workflow, all other modes can be validated only from the configuration. This ensures we don't re-create unnecessary auth modes.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1429:144,config,configuration,144,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1429,1,['config'],['configuration']
Modifiability,"Onprem and restricted environments can be really cagey about what Dockers are being run. Cromwell should be able to be configured (maybe in conf file? Maybe something more dynamic?) to restrict what Dockers are being run. Both the NIH and Broad Internal have mentioned the fact that unrestricted Dockers being run is something they're a bit cagey about. This would help them feel good, even if it eventually goes unused.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2528:119,config,configured,119,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2528,1,['config'],['configured']
Modifiability,"Originally posted this two in the JIRA issue tracker back in August. Reposting here since it didn't get a response over there: https://broadworkbench.atlassian.net/browse/BA-6548. > Hello everyone,; >; > I am attempting to use the AWS Batch backend for Cromwell to run a wdl script which runs several subjobs in parallel. I believe the correct parlance is a scatter. I noticed that in some of the jobs of the scatter, some reference files failed to download from S3 even though they existed (Connection Reset by Peer). This failure caused the overall job to fail after one hour of running.; >; > I believe this issue was reported and fixed before, around May 2019, but recently, in June 2020, it appears the AWS Batch backend was majorly overhauled (by @markjschreiber, thanks! Also, tagging you because I suspect you might be the resident expert here :) ), and the previous fix (using the ecs proxy image) was supposedly obsoleted.; > ; > I also see that the s3fs library appears to be vendored into cromwell, and after digging around, it appears that one might be able to set retries via an environment variable(?). But even then, I feel like if that were to work, it would be much nicer if it was configurable through cromwell's config file somehow.; >; > So that brings me to my final question. Is there some configuration that allows me to retry failed downloads some number of times before failing the whole job? Or, perhap there is some alternative configuraiton which I've overlooked and someone could point me to it? Thanks!. In addition, just wondering if perhaps there is a service limit I might be running into?",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5946:1105,variab,variable,1105,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5946,5,"['config', 'variab']","['config', 'configurable', 'configuraiton', 'configuration', 'variable']"
Modifiability,Our new saner TES polling defaults noticeably increased the runtime of our TES integration tests. Reverting CI to old behavior with config update.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7126:132,config,config,132,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7126,1,['config'],['config']
Modifiability,PBSPro Backend Configuration,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4967:15,Config,Configuration,15,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4967,1,['Config'],['Configuration']
Modifiability,"PR 1 of 3:; 1. Remove cromwell-core dependency from cloud-support; 2. Run jes centaur on travis; 3. Generate coverage for integration tests. ---. Instead of credentials requiring WorkflowOptions, any String => String will do, including Map[String, String].; Retrieving credentials only requires actorSystem/executionContext when retrying.; Moved logback dependencies from common library over to testing.; Added mockito to all artifact tests.; Fixed akka-stream-testkit dependency appearing in core's main instead of test.; Split confusingly named baseDependencies into configDependencies ++ catsDependencies.; Other dependency cleanup to reduce duplicates and extra transitive dependencies.; Log stderr from centaur'ed cromwell failures.; The total attempt time to connect to cromwell for a test is now longer than the timeout of a cromwell restart.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2938:569,config,configDependencies,569,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2938,1,['config'],['configDependencies']
Modifiability,"PR 2 of 3:; 1. Remove cromwell-core dependency from cloud-support; 2. Run jes centaur on travis; 3. Generate coverage for integration tests. ---. Centaur now uses configurable cloudSupport for auth, instead of always using application-default.; Refresh token is passed as a file path, then read by centaur.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2948:163,config,configurable,163,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2948,1,['config'],['configurable']
Modifiability,"PR Documentation describing the SparkBackend added to Cromwell. This PR adds support for execution of spark jobs as task in a workflow using the existing wdl format, with restrictions on the environment like having a local file system, a shared file system or a network file system when running a spark job in the spark standalone cluster mode. This implementation takes a wdl with the backend configuration specified as ""Spark"" and then generates the appropriate spark commands and monitoring process to ensure the job runs to completion. Meaning, details of the spark internals are completely abstracted from the user provided backends with different configurations containing different flavours of { master and deployMode } combinations are already set. Internally, we create a bash script containing a spark-submit (depending on the backend flavour selected at runtime) command using all the specified wdl runtime attributes which is then executed by Spark.  . Current deploy modes supported for any spark job:;   a - Client deploy mode using the spark standalone cluster manager;   b - Cluster deploy mode using the spark standalone cluster manager;   c - Client deploy mode using Yarn resource manager;   d - Cluster deploy mode using Yarn resource manager;   ; Future PR Plans:;   In this PR, the hadoop file system cannot be used as an input/output for the SBE because the Cromwell engine does not identify the protocol, and this results in the hdfs path being localized (soft-link, hard-link or copied).;   This is not a problem until the SBE tries to evaluate the output after a successful execution, and because it cannot interpret the protocol, it tries to look for an hdfs output locally which results in an error. Note: This is only the case when the spark job writes the output to an hdfs location. Then cromwell cannot find the output file for evaluation.   In the near **Future**, we plan to provide an hdfs client similar to that of the gcs to add support for the hdfs, primarily bec",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1339:394,config,configuration,394,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1339,2,['config'],"['configuration', 'configurations']"
Modifiability,Papi network config updates and tests BT-372,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6476:13,config,config,13,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6476,1,['config'],['config']
Modifiability,Parse Error when using variables prepended by if*,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6956:23,variab,variables,23,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6956,1,['variab'],['variables']
Modifiability,Parseable.rawParseValue(Parseable.java:250); at com.typesafe.config.impl.Parseable.parseValue(Parseable.java:180); at com.typesafe.config.impl.Parseable.parseValue(Parseable.java:174); at com.typesafe.config.impl.Parseable.parse(Parseable.java:301); at com.typesafe.config.ConfigFactory.parseFile(ConfigFactory.java:793); at com.typesafe.config.ConfigFactory.parseApplicationReplacement(ConfigFactory.java:1166); at com.typesafe.config.DefaultConfigLoadingStrategy.parseApplicationConfig(DefaultConfigLoadingStrategy.java:11); at com.typesafe.config.ConfigFactory.defaultApplication(ConfigFactory.java:532); at com.typesafe.config.ConfigFactory$1.call(ConfigFactory.java:264); at com.typesafe.config.ConfigFactory$1.call(ConfigFactory.java:261); at com.typesafe.config.impl.ConfigImpl$LoaderCache.getOrElseUpdate(ConfigImpl.java:66); at com.typesafe.config.impl.ConfigImpl.computeCachedConfig(ConfigImpl.java:93); at com.typesafe.config.ConfigFactory.load(ConfigFactory.java:261); at com.typesafe.config.ConfigFactory.load(ConfigFactory.java:237); at cromwell.languages.util.ImportResolver$HttpResolver$.apply(ImportResolver.scala:237); at womtool.input.WomGraphMaker$.importResolvers$lzycompute$1(WomGraphMaker.scala:28); at womtool.input.WomGraphMaker$.importResolvers$1(WomGraphMaker.scala:27); at womtool.input.WomGraphMaker$.$anonfun$getBundleAndFactory$1(WomGraphMaker.scala:39); at scala.util.Either.flatMap(Either.scala:352); at womtool.input.WomGraphMaker$.getBundleAndFactory(WomGraphMaker.scala:30); at womtool.input.WomGraphMaker$.fromFiles(WomGraphMaker.scala:46); at womtool.validate.Validate$.validate(Validate.scala:26); at womtool.WomtoolMain$.dispatchCommand(WomtoolMain.scala:54); at womtool.WomtoolMain$.runWomtool(WomtoolMain.scala:161); at womtool.WomtoolMain$.delayedEndpoint$womtool$WomtoolMain$1(WomtoolMain.scala:166); at womtool.WomtoolMain$delayedInit$body.apply(WomtoolMain.scala:27); at scala.Function0.apply$mcV$sp(Function0.scala:42); at scala.Function0.apply$mcV$sp$(F,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7255:3019,config,config,3019,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7255,1,['config'],['config']
Modifiability,"Part of the #2942 work involved converting the config backend to use the WOM API. The config backend uses WDL to define its commands but it does not have a workflow (it's a WdlNamespace with a bunch of tasks). This conversion mostly went smoothly with the exception of uninitialized task optionals like `docker_user` found in the Local backend's `submit-docker`:. ```; runtime-attributes = """"""; String? docker; String? docker_user; """"""; submit = ""/bin/bash ${script}""; submit-docker = """"""; docker run \; --cidfile ${docker_cid} \; --rm -i \; ${""--user "" + docker_user} \; --entrypoint /bin/bash \; -v ${cwd}:${docker_cwd} \; ${docker} ${script}; """"""; ```; Evaluating that `${""--user "" + docker_user}` expression currently blows up with no useful diagnostics in the absence of an explicit `docker_user` input. To hack around this I changed the config backend to force in `none` inputs for all optional declarations in a task, but this would have the effect of clobbering any initialized optionals:. ```; String? docker_user = ""mobydock""; ```. With the #2942 changes `docker_user` would be forced to `none` and `""mobydock""` would be lost (at sea). It's not clear why this is happening when using the WOM API at a task level and not at the workflow level. There may be some `none`-initialization done at the workflow level that should get pushed down to tasks.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2946:47,config,config,47,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2946,3,['config'],['config']
Modifiability,Pass additional job details and config for monitoring_image [BA-5717],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5028:32,config,config,32,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5028,1,['config'],['config']
Modifiability,"Path+modtime should guarantee that files are the same. . I have expanded the SFS test scala file so it properly tests the new `cached-inputs` strategy. I have added information on how to use the strategy in the docs, and added this PR to the changelog. ### Help still needed. There are two things that I could not figure out without cromwell developer help:. ~~* Checking whether a file exists and copying it to the cache should never be done by multiple threads simeltaneously. I have used the `synchronized` method to prevent this. I used an object for this, because I am sure it is unique within the JVM at cromwell runtime. This works fine, but I can imagine this can be solved in a nicer way using akka? However the akka documentation is an extensive jungle on its own, and requires quite some expertise to navigate. I could not find very quickly what I needed, and the `synchronization` primitive works fine. It is also **just 2 lines of extra code**. So if the akka solution is quite elegant as well I would like to learn about that. If not, well, it is not too bad having 2 lines of understandable commented code that is not ""the proper way of doing things(TM)"".~~. * I used the SFS scalatests to make sure everything worked correctly. However this did not test whether the thread safety was working correctly. I have added a test wdl in centaur: `standardTestCases/cached_copy/cached_copy.wdl`. This workflow creates 10 jobs that read the same input file. This workflow will crash if the `cached-inputs` cache is not used in a thread-safe way. I tested this manually with `java -Dbackend.providers.Local.config.filesystems.local.localization.0=""cached-copy"" -jar server/target/scala-2.12/cromwell-41-*-SNAP.jar run centaur/src/main/resources/standardTestCases/cached_copy/cached_copy.wdl` . Is there a way to integrate such a test in scalatest file? I have tried the `.par` method, but that did not quite work. I hope you will consider this PR as it solves an important issue for us. Thanks!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4900:3337,config,config,3337,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4900,1,['config'],['config']
Modifiability,"Per #4826, when Cromwell is configured with `workflow-log-temporary: false` and workflow does not specify `final_workflow_log_dir`, Cromwell server does not close the log file resulting in a file handle leak. The lack of a file close also prevents certain FUSE drivers from flushing any file contents to remote storage, making it impossible for clients to actually read the logs until the server is terminated (which may be never). . Looking at the code, there is no call to `workflowLogger.close()` or `workflowLogger.close(andDelete = false)` unless the file is being copied. This line in WorkflowActor.scala:; `case None if WorkflowLogger.isTemporary => workflowLogger.close(andDelete = true)`; should change to:; `case None => workflowLogger.close(andDelete = WorkflowLogger.isTemporary)`. At this point in the code, the log contents have been fully written and the log should be closed, regardless of whether the logs are temporary or not. . I've tested that this fix resolves the issue according to repro instructions in #4826.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5016:28,config,configured,28,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5016,1,['config'],['configured']
Modifiability,"Per discussion in https://github.com/broadinstitute/cromwell/pull/4039, it would be nice and clean to have different backend providers defined in an examples folder. The user:. - should more easily be able to inspect one backend, as it's not lost in a huge commented file; - from each backend example, a link to the docs (if they exist) should be provided; - per the files being separate, we don't ask the user to uncomment a million lines to use a backend (copy pasta, done). But given separation from the examples configuration file, we need to compensate by having really good instructions for doing this (I will write a nice README). I think this is the right way to go because it will more cleanly show the various backends that Cromwell provides, and how to use. Right now it's a bit overwhelming just looking at that file, and I can only imagine for a new user / someone not super keen on configuration files. @geoffjentry please assign me to this.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4696:516,config,configuration,516,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4696,2,['config'],['configuration']
Modifiability,"Per the CWL Specifications, section 3.3:. > Requirements are inherited. A requirement specified in a Workflow applies to all workflow steps; a requirement specified on a workflow step will apply to the process implementation of that step and any of its substeps. It appears that Cromwell does not correctly implement the above. For example, a `dockerPull` requirement specified in a workflow, does not get applied to a command in a subworkflow. Cromwell version: `cromwell-36`. `test.cwl`; ```; #!/usr/bin/env cwl-runner. cwlVersion: v1.0; class: Workflow. requirements:; - class: SubworkflowFeatureRequirement; - class: DockerRequirement; dockerPull: ubuntu. inputs: []. steps:; substep:; run: subworkflow.cwl; in: []; out: [container]; ; outputs:; container:; type: File; outputSource: substep/container; ```. `subworkflow.cwl`; ```; #!/usr/bin/env cwl-runner. cwlVersion: v1.0; class: Workflow. requirements:; - class: SubworkflowFeatureRequirement. inputs: []. steps:; substep:; run: command.cwl; in: []; out: [container]; ; outputs:; container:; type: File; outputSource: substep/container; ```. `command.cwl`; ``` ; cwlVersion: v1.0 ; class: CommandLineTool. baseCommand: ['grep', 'docker', '/proc/1/cgroup']. inputs: []; outputs:; container:; type: stdout; ```. `test.yaml`; ```; {}; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4544:61,inherit,inherited,61,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4544,1,['inherit'],['inherited']
Modifiability,"Perf testing has shown that removing this query improves CC time and reduces DB load (see last row in CC google doc); Unclear if it's worth keeping it as a configurable thing ?; This keeps storing the individual hashes, it just stops using them for ""fast"" cache miss detection.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4121:156,config,configurable,156,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4121,1,['config'],['configurable']
Modifiability,"Perhaps a config error... I am using the TES backend, which is configured to utilize my funnel server, that in turn is passing tasks to AWS Batch (nice, right?). This seems to work OK with the simplest workflow possible, but now that I have added some inputs, I am getting an error. Here is my setup and error trace from the server, and I am running on the latest from the develop branch:. [hello.inputs.txt](https://github.com/broadinstitute/cromwell/files/2081428/hello.inputs.txt); [my-cromwell.conf.txt](https://github.com/broadinstitute/cromwell/files/2081429/my-cromwell.conf.txt); [myWorkflow_awsbatch.wdl.txt](https://github.com/broadinstitute/cromwell/files/2081843/myWorkflow_awsbatch.wdl.txt). ```; 2018-06-07 13:09:05,646 cromwell-system-akka.dispatchers.api-dispatcher-119 INFO - Unspecified type (Unspecified version) workflow af282f7a-1e95-4390-8cf7-c3bbd93b10b2 submitted; 2018-06-07 13:09:15,813 cromwell-system-akka.dispatchers.engine-dispatcher-5 INFO - 1 new workflows fetched; 2018-06-07 13:09:15,813 cromwell-system-akka.dispatchers.engine-dispatcher-5 INFO - WorkflowManagerActor Starting workflow UUID(af282f7a-1e95-4390-8cf7-c3bbd93b10b2); 2018-06-07 13:09:15,814 cromwell-system-akka.dispatchers.engine-dispatcher-5 INFO - WorkflowManagerActor Successfully started WorkflowActor-af282f7a-1e95-4390-8cf7-c3bbd93b10b2; 2018-06-07 13:09:15,814 cromwell-system-akka.dispatchers.engine-dispatcher-5 INFO - Retrieved 1 workflows from the WorkflowStoreActor; 2018-06-07 13:09:15,815 cromwell-system-akka.dispatchers.engine-dispatcher-32 INFO - MaterializeWorkflowDescriptorActor [UUID(af282f7a)]: Parsing workflow as WDL draft-2; 2018-06-07 13:09:15,826 cromwell-system-akka.dispatchers.engine-dispatcher-32 INFO - MaterializeWorkflowDescriptorActor [UUID(af282f7a)]: Call-to-Backend assignments: wf_hello.hello -> TES; 2018-06-07 13:09:16,844 cromwell-system-akka.dispatchers.engine-dispatcher-32 INFO - WorkflowExecutionActor-af282f7a-1e95-4390-8cf7-c3bbd93b10b2 [UUID(af282f7a)]:",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3743:10,config,config,10,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3743,2,['config'],"['config', 'configured']"
Modifiability,Permission problem with LSF configuration,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3185:28,config,configuration,28,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3185,1,['config'],['configuration']
Modifiability,"Picking up from #1816. Setup for Centaur testing. The current TES [schema](https://github.com/ga4gh/task-execution-schemas) doesn't allow for changing the default user, so centaur fails on:; - non_root_specified_user. Is there a way to configure Centaur to skip specific tests?",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1979:236,config,configure,236,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1979,1,['config'],['configure']
Modifiability,Playbook Refactor,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4987:9,Refactor,Refactor,9,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4987,1,['Refactor'],['Refactor']
Modifiability,"Please check this issue.; When I configure the aws, I followed up this page. (https://docs.opendata.aws/genomics-workflows/; ); I did not use the all-in-one template. With 3 step configure, I setup the cromwell server (Custom AMI -> VPC..and etc -> cromwell server instance). <!-- Which backend are you running? -->; aws. <!-- Paste/Attach your workflow if possible: -->; ```; task echoHello{; command {; echo ""Hello AWS!""; }; runtime {; docker: ""ubuntu:latest""; }. }. workflow printHelloAndGoodbye {; call echoHello; }; ```. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->; [cromwell-server.log](https://github.com/broadinstitute/cromwell/files/2897001/cromwell-server.log)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4677:33,config,configure,33,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4677,3,['config'],"['configuration', 'configure']"
Modifiability,Port wdl IntelliJ plugin to pycharm,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1264:18,plugin,plugin,18,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1264,1,['plugin'],['plugin']
Modifiability,"Possible to specify runtime config (for example, zones) in application config?",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1795:28,config,config,28,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1795,2,['config'],['config']
Modifiability,Potential hotfix candidate but would be nice to know why these empty queues are appearing in the first place. An attempt to recover from (though probably not fix the underlying cause of) tokens going missing due to stack traces like:; ```; [cromwell-system-akka.actor.default-dispatcher-1158] ERROR akka.actor.OneForOneStrategy - dequeue on empty queue; java.util.NoSuchElementException: dequeue on empty queue; 	at scala.collection.immutable.Queue.dequeue(Queue.scala:155); 	at cromwell.engine.workflow.tokens.TokenQueue.recursingDequeue(TokenQueue.scala:63); 	at cromwell.engine.workflow.tokens.TokenQueue.dequeue(TokenQueue.scala:50); 	at cromwell.engine.workflow.tokens.RoundRobinQueueIterator.$anonfun$findFirst$1(RoundRobinQueueIterator.scala:46); 	at cromwell.engine.workflow.tokens.RoundRobinQueueIterator.$anonfun$findFirst$1$adapted(RoundRobinQueueIterator.scala:46); 	at scala.collection.immutable.Stream.$anonfun$map$1(Stream.scala:415); 	at scala.collection.immutable.Stream$Cons.tail(Stream.scala:1169); 	at scala.collection.immutable.Stream$Cons.tail(Stream.scala:1159); 	at scala.collection.immutable.StreamIterator.$anonfun$next$1(Stream.scala:1058); 	at scala.collection.immutable.StreamIterator$LazyCell.v$lzycompute(Stream.scala:1047); 	at scala.collection.immutable.StreamIterator$LazyCell.v(Stream.scala:1047); 	at scala.collection.immutable.StreamIterator.hasNext(Stream.scala:1052); 	at scala.collection.TraversableOnce.collectFirst(TraversableOnce.scala:144); 	at scala.collection.TraversableOnce.collectFirst$(TraversableOnce.scala:132); 	at scala.collection.AbstractTraversable.collectFirst(Traversable.scala:104); 	at cromwell.engine.workflow.tokens.RoundRobinQueueIterator.findFirst(RoundRobinQueueIterator.scala:48); 	at cromwell.engine.workflow.tokens.RoundRobinQueueIterator.next(RoundRobinQueueIterator.scala:32); 	at cromwell.engine.workflow.tokens.RoundRobinQueueIterator.next(RoundRobinQueueIterator.scala:10); 	at scala.collection.Iterator$SliceIterator.next(Itera,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4909:835,adapt,adapted,835,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4909,1,['adapt'],['adapted']
Modifiability,Private File variables should not be localized,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6562:13,variab,variables,13,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6562,1,['variab'],['variables']
Modifiability,"Probably mixed up the name while refactoring, the log path needs to be a file path (ie gs://balblabl/jes.log) for JES to use it as a filename when delocalizing its logs.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/303:33,refactor,refactoring,33,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/303,1,['refactor'],['refactoring']
Modifiability,Problem with + and optional variable,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5694:28,variab,variable,28,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5694,1,['variab'],['variable']
Modifiability,"Proposed in the [PR for HTTPS imports](https://github.com/broadinstitute/cromwell/pull/2758) by @kcibul:. As a **user configuring Cromwell**, I want **the option to disable HTTPs imports**, so that **I can protect my system from possible security risks**. - Effort: Small; - Risk: Small; - Business value: Medium",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2773:118,config,configuring,118,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2773,1,['config'],['configuring']
Modifiability,Prose copy/paste/edited from the earlier `CALL_CACHING_HASH_ENTRY` refactoring.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5397:67,refactor,refactoring,67,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5397,1,['refactor'],['refactoring']
Modifiability,Provide MinimumRuntimeSettings from Config,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2817:36,Config,Config,36,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2817,1,['Config'],['Config']
Modifiability,"Provide a configurable knob which will limit the number of in flight calls per workflow. This includes scatters, e.g. if the limit is 5 and there's a 6-way scatter, at most 5 shards may be processed at once. This will likely be requested to be in place prior to or shortly after the GATK launch in early january. Edit: Some clarifications. As mentioned below this needs to be robust to the entirety of the root workflow, including all subworkflows. It also needs to be robust to restart, IOW on a restart of Cromwell if there were N jobs restarted the counter should start at MAX - N.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2846:10,config,configurable,10,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2846,1,['config'],['configurable']
Modifiability,Provide better documentation/examples for logging configuration,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1622:50,config,configuration,50,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1622,1,['config'],['configuration']
Modifiability,"Pull request for https://github.com/broadinstitute/cromwell/issues/4982 issue.; Changes:; - Implemented file transferring via TransferManager; - Removed assertions that caused `copying directories is not yet supported` exception; - Fixed incorrect work of `use_relative_output_paths` option; - Fixed logs and output files copying (tested manually on following backends: local, AWS, GCP).; - Added support for `AWS` filesystem in centaur's `fileSystemCheck` ; - Refactored `CheckFiles`; - Added an integration tests checking that workflow execution results and logs are correctly copied",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5110:461,Refactor,Refactored,461,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5110,1,['Refactor'],['Refactored']
Modifiability,"Question on using the default authentication for AWS. Basically I have a credentials file saved to *~/.aws/credentials* and it is looked up by cromwell for authentication to use the AWS batch service. For scalability I wanted to include a few different profiles to look up. *~/.aws/credentials*; ```; [service1]; aws_access_key_id = key1; aws_secret_access_key = pw1. [service2]; aws_access_key_id = key2; aws_secret_access_key = pw2; ```. However, I cannot seem to get cromwell config to set a profile name for `service2` as the expected authentication. The only profile it will look for is `default`. From my config it is set up as follows:. ```; aws {; application-name = ""CROMWELL-SERVER""; auths = [{; name = ""service2""; scheme = ""default""; }]. region = ""us-east-1""; }; ```. The error when I try to run a job is below which shows I am using a `profileName=default`. Looked through the code a bit but couldn't find where I can add that profilename to the config. If there is a way to change the profile name I would definitely use it, if not then I can set things up differently. Thanks. `cromwell_1 | Caused by: software.amazon.awssdk.core.exception.SdkClientException: Unable to load credentials from any of the providers in the chain AwsCredentialsProviderChain(credentialsProviders=[SystemPropertyCredentialsProvider(), EnvironmentVariableCredentialsProvider(), ProfileCredentialsProvider(profileName=default, profileFile=ProfileFile(profiles=[Profile(name=service1, properties=[aws_access_key_id, aws_secret_access_key]), Profile(name=service2, properties=[aws_access_key_id, aws_secret_access_key])])), ContainerCredentialsProvider(), InstanceProfileCredentialsProvider()]) : [SystemPropertyCredentialsProvider(): Unable to load credentials from system settings. Access key must be specified either via environment variable (AWS_ACCESS_KEY_ID) or system property (aws.accessKeyId)., EnvironmentVariableCredentialsProvider(): Unable to load credentials from system settings. Access key must be",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5452:479,config,config,479,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5452,3,['config'],['config']
Modifiability,"Quick spike to explore if a `join` rewrite of `includeSubworkflows` might provide a performance boost analogous to the `join` rewrite for `labels`. . - ~write a `join` formulation of `includeSubworkflows`~; - ~clone dev Cloud SQL~; - harvest ""before"" and ""after"" versions of a sample `includeSubworkflows` query from Cromwell debug sessions (careful not to restart jobs in the dev clone); - compare performance of these queries between cold restarts of the dev clone",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4684:35,rewrite,rewrite,35,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4684,2,['rewrite'],['rewrite']
Modifiability,"Quoth the CHANGELOG.md:. >You can now limit the number of concurrent jobs for a backend by specifying the following option in the backend's config stanza:; ```; backend {; ...; providers {; BackendName {; actor-factory = ...; config {; concurrent-job-limit = 5; ```. But this is not generally true. The implementation in `BackendLifecycleActorFactory` defaults to an infinitely large job limit and does not look for this `concurrent-job-limit` configuration setting. `ConfigBackendLifecycleActorFactory` overrides this behavior to be consistent with CHANGELOG.md, but no other backend factory does.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1751:140,config,config,140,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1751,4,"['Config', 'config']","['ConfigBackendLifecycleActorFactory', 'config', 'configuration']"
Modifiability,"Rather than putting up with this error because their config is out of date:; ```; [ERROR] [04/19/2017 18:14:32.636] [cromwell-system-akka.actor.default-dispatcher-4] [akka://cromwell-system/user/cromwell-service/ServiceRegistryActor/MetadataService] Error summarizing metadata; com.mysql.jdbc.exceptions.jdbc4.MySQLSyntaxErrorException: You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '""SUMMARY_STATUS_ENTRY"" where (""SUMMARY_TABLE_NAME"" = 'WORKFLOW_METADATA_SUMMARY_' at line 1; ```. We should have a nice error message that tells people what to do about it",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2186:53,config,config,53,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2186,1,['config'],['config']
Modifiability,Re-added kind-projector compiler plugin to backend.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2989:33,plugin,plugin,33,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2989,1,['plugin'],['plugin']
Modifiability,Re-armor the Rhino in a way that plays nice with real world CWLs like Wash U rnaseq and doesn't do this:. ```; Caused by: java.lang.IllegalStateException; at org.mozilla.javascript.ContextFactory.initGlobal(ContextFactory.java:177); at cwl.internal.EnhancedRhinoSandbox.assertContextFactory(EnhancedRhinoSandbox.scala:94); at cwl.internal.EnhancedRhinoSandbox.eval(EnhancedRhinoSandbox.scala:42); at cwl.internal.EcmaScriptUtil$.evalRaw(EcmaScriptUtil.scala:71); ```,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3410:249,Enhance,EnhancedRhinoSandbox,249,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3410,4,['Enhance'],['EnhancedRhinoSandbox']
Modifiability,Re-lazied the `SlickDataAccessSpec` database configs.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/961:45,config,configs,45,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/961,1,['config'],['configs']
Modifiability,Reading object of same name as variable kills Cromwell,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1946:31,variab,variable,31,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1946,1,['variab'],['variable']
Modifiability,Refactor CAJEA pollStatus logic,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4654:0,Refactor,Refactor,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4654,1,['Refactor'],['Refactor']
Modifiability,Refactor CC states into an EJEA subactor,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1374:0,Refactor,Refactor,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1374,1,['Refactor'],['Refactor']
Modifiability,Refactor EngineFunctions / GCS / IO and enable cross FS localization,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/305:0,Refactor,Refactor,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/305,1,['Refactor'],['Refactor']
Modifiability,Refactor Google Credentials ahead of adding BigQuery.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4054:0,Refactor,Refactor,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4054,1,['Refactor'],['Refactor']
Modifiability,Refactor Metadata Read Interface [BA-5842],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5146:0,Refactor,Refactor,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5146,1,['Refactor'],['Refactor']
Modifiability,"Refactor WDL parsing in draft-2 and re-use in WDL 1.0, 2.0 [BA-5664]",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5134:0,Refactor,Refactor,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5134,1,['Refactor'],['Refactor']
Modifiability,Refactor backoffs + retries,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/396:0,Refactor,Refactor,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/396,1,['Refactor'],['Refactor']
Modifiability,Refactor job aborts via EJEA,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1504:0,Refactor,Refactor,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1504,1,['Refactor'],['Refactor']
Modifiability,Refactor metadata builder inside the metadata service [BA-5842],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5150:0,Refactor,Refactor,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5150,1,['Refactor'],['Refactor']
Modifiability,Refactor metadata facing routes into separate trait,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4246:0,Refactor,Refactor,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4246,1,['Refactor'],['Refactor']
Modifiability,Refactor perf tests and support horicromtal [BA-4842],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5077:0,Refactor,Refactor,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5077,1,['Refactor'],['Refactor']
Modifiability,"Refactor perf tests from ""all-in-one"" to ""modular"" [BA-4842 part 1]",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5075:0,Refactor,Refactor,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5075,1,['Refactor'],['Refactor']
Modifiability,Refactor publish/release graphs,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4962:0,Refactor,Refactor,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4962,1,['Refactor'],['Refactor']
Modifiability,Refactor run mode tests [BA-5963],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5147:0,Refactor,Refactor,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5147,1,['Refactor'],['Refactor']
Modifiability,"Refactor, Rebase, Merge + Test WDL4S PR",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1522:0,Refactor,Refactor,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1522,1,['Refactor'],['Refactor']
Modifiability,Refactored DataAccess retries.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/690:0,Refactor,Refactored,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/690,1,['Refactor'],['Refactored']
Modifiability,Refactored IO command creation to return errors instead of throw BT-8,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6019:0,Refactor,Refactored,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6019,1,['Refactor'],['Refactored']
Modifiability,"Refactored from its original version, this creates the structure to support multiple access token strategies but does not bring in the logic from BT-426 to actually get an access token for Azure. That latter bit is now the subject of a separate ticket BT-436.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6553:0,Refactor,Refactored,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6553,1,['Refactor'],['Refactored']
Modifiability,Refactored token dispenser to accommodate for rate limiting,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3332:0,Refactor,Refactored,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3332,1,['Refactor'],['Refactored']
Modifiability,Refactoring WdlValue into a trait with subclasses,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/13:0,Refactor,Refactoring,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/13,1,['Refactor'],['Refactoring']
Modifiability,Refactoring actors for FinalCalls,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/390:0,Refactor,Refactoring,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/390,1,['Refactor'],['Refactoring']
Modifiability,Refactoring of Jes configuration validation,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/201:0,Refactor,Refactoring,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/201,2,"['Refactor', 'config']","['Refactoring', 'configuration']"
Modifiability,Refactoring of Jes configuration validation V2 (Rebranched from develop),MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/208:0,Refactor,Refactoring,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/208,2,"['Refactor', 'config']","['Refactoring', 'configuration']"
Modifiability,Refactoring of backends / SGE Backend,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/145:0,Refactor,Refactoring,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/145,1,['Refactor'],['Refactoring']
Modifiability,Refactoring restarts... move globalDataAccess away from backends. closes #581,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/704:0,Refactor,Refactoring,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/704,1,['Refactor'],['Refactoring']
Modifiability,Refactorings to pass data access into the backend.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/199:0,Refactor,Refactorings,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/199,1,['Refactor'],['Refactorings']
Modifiability,"Refactors `ParameterContext` to allow values of various types. See the scaladoc for more info, generally speaking an internal untyped map is being used instead of the old `WomValue`.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3097:0,Refactor,Refactors,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3097,1,['Refactor'],['Refactors']
Modifiability,Reference disk usage metric + refactoring [BT-20],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6145:30,refactor,refactoring,30,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6145,1,['refactor'],['refactoring']
Modifiability,Referencing a non-existent scatter variable leaves workflow in running state,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2020:35,variab,variable,35,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2020,1,['variab'],['variable']
Modifiability,"Refined as:. - One log message when a hog group begins to be limited; - One log message when a hog group is no longer being limited; - One log message at a configurable interval, listing *all* hog groups being limited (and their total jobs)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4557:156,config,configurable,156,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4557,1,['config'],['configurable']
Modifiability,Remove cromwell.binding and refactor to reflect new wdl4s binding rea…,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/365:28,refactor,refactor,28,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/365,1,['refactor'],['refactor']
Modifiability,"Remove notests config, assembly is now testless",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/560:15,config,config,15,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/560,1,['config'],['config']
Modifiability,Remove obsolete config setting [BT-216],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6307:16,config,config,16,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6307,1,['config'],['config']
Modifiability,Removed GCS configuration from HtCondor. Closes #1159.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1160:12,config,configuration,12,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1160,1,['config'],['configuration']
Modifiability,"Removed `WorkflowDescriptorSpec`. Most tests were about copying logs and outputs which lives in a different (better) place now.; The one test regarding caching config that might be useful later was moved to the backend project and left ignored, with some pre-work to prepare it for whenever it will be prioritized.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1061:160,config,config,160,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1061,1,['config'],['config']
Modifiability,Removed dead code related to configs such as the old `backend.backend`.; Updated unencrypted configuration files.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2165:29,config,configs,29,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2165,2,['config'],"['configs', 'configuration']"
Modifiability,"Removed src/main/config, which is no longer needed by FireCloud",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/611:17,config,config,17,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/611,1,['config'],['config']
Modifiability,"RenameWorkflowOptionsInMetadata] 100%; [2019-02-11 10:13:15,05] [info] Running with database db.url = jdbc:hsqldb:mem:6b5d8035-4932-4680-b912-34885765f705;shutdown=false;hsqldb.tx=mvcc; [2019-02-11 10:13:15,63] [info] Slf4jLogger started; [2019-02-11 10:13:16,02] [info] Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-1ddecb5"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; [2019-02-11 10:13:16,08] [info] Metadata summary refreshing every 2 seconds.; [2019-02-11 10:13:16,20] [info] KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; [2019-02-11 10:13:16,23] [info] WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; [2019-02-11 10:13:16,25] [warn] 'docker.hash-lookup.gcr-api-queries-per-100-seconds' is being deprecated, use 'docker.hash-lookup.gcr.throttle' instead (see reference.conf); [2019-02-11 10:13:16,26] [info] CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; [2019-02-11 10:13:16,33] [info] JobExecutionTokenDispenser - Distribution rate: 50 per 1 seconds.; [2019-02-11 10:13:17,45] [info] SingleWorkflowRunnerActor: Version 37; [2019-02-11 10:13:17,46] [info] SingleWorkflowRunnerActor: Submitting workflow; [2019-02-11 10:13:17,59] [info] Unspecified type (Unspecified version) workflow 52999e15-953f-44d6-aaae-1774c74d2910 submitted; [2019-02-11 10:13:17,65] [info] SingleWorkflowRunnerActor: Workflow submitted 52999e15-953f-44d6-aaae-1774c74d2910; [2019-02-11 10:13:17,65] [info] 1 new workflows fetched; [2019-02-11 10:13:17,66] [info] WorkflowManagerActor Starting workflow 52999e15-953f-44d6-aaae-1774c74d2910; [2019-02-11 10:13:17,67] [info] WorkflowManagerActor Successfully started WorkflowActor-52999e15-953f-44d6-aaae-1774c74d2910; [2019-02-11 10:13:17,67] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2019-02-11 10:13:17,70] [info] WorkflowStoreHeartbeatWriteActor c",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4626:2535,config,configured,2535,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4626,1,['config'],['configured']
Modifiability,"Renamed the singleton services store to the engine services store.; Added metadata services store to the system startup.; Metadata liquibase configured via a new set of xml, with the same tables.; Added jitter to MetadataServiceActorSpec to ensure order is constistent.; Removed unused SqlDatabase from WorkflowStoreActor/WorkflowStoreEngineActor.; Fixed filename of CustomLabelEntry.scala.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2572:141,config,configured,141,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2572,1,['config'],['configured']
Modifiability,"Reopening https://github.com/broadinstitute/cromwell/pull/5545 as an internal branch so tests run correctly. Changelog:. - Added config option `docker.perform-registry-lookup-if-digest-is-provided` with default True (https://github.com/broadinstitute/cromwell/pull/5545/commits/e9965d8f9a385b289f15b23b3fb923ecb8c0ea38); - Added logic to `DockerConfiguration.scala` to `sendDockerRequest` if `performRegistryLookupIfDigestIsProvided` is `true`, else just `lookupKvsOrBuildDescriptorAndStop`. . Motivation:. - Cromwell only allows call-caching when a digest is provided.; - The digest registry lookup fails because Cromwell isn't respecting the system proxy. ; - This disables call-caching, even though we've provided the digest. From original PR:. > This PR is based on a comment in the Slack, and ongoing conversation in How to configure proxies? (which stems from #5006).; >; > Essentially, I don't want Cromwell to lookup my container when I provide it as a digest, because if the request fails (because Cromwell isn't respecting the system proxy), I still want call-caching to work. The main reason Cromwell seems to want to lookup the external registry is for the docker size which gets logged to metadata and doesn't seem to be used again. Thanks @mcovarr for the initial feedback, and sorry it took so long to action your suggestions. I've moved this to an internal branch so tests run automatically (as suggested in the past). I've included some of your feedback (that the dockerSize is used in the Google Backends) to the `reference.conf` and the `DockerConfiguration.scala`. I haven't included it in the documentation, but it's documented in the `reference.conf`.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6140:129,config,config,129,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6140,2,['config'],"['config', 'configure']"
Modifiability,"Replaces #5075. For best results, review in conjunction with:. - Updated perf [documentation](https://docs.google.com/document/d/1cv338uMqTNVVYVEC78k4iMTG_zyZloon3v9e4l3TdM8) ; - NB: check whether this has been updated yet in the TODOs list below); - Refactored Jenkins scripts (see [documentation](https://docs.google.com/document/d/1cv338uMqTNVVYVEC78k4iMTG_zyZloon3v9e4l3TdM8)). TODOs:; - [x] Update perf [documentation](https://docs.google.com/document/d/1cv338uMqTNVVYVEC78k4iMTG_zyZloon3v9e4l3TdM8). TODOs (but not in this ticket):; - [ ] Come up with a test case to exercise horicromtal; - [ ] Add a load balancer in front of multiple readers? (for the api tests)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5077:251,Refactor,Refactored,251,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5077,1,['Refactor'],['Refactored']
Modifiability,Request for workflow-wide global variables,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1689:33,variab,variables,33,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1689,1,['variab'],['variables']
Modifiability,Request: make possible to configure cromwell using brew wrapper script,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3262:26,config,configure,26,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3262,1,['config'],['configure']
Modifiability,"Requester pays is now added to Cromwell. The user can set the billing project id using one of the methods listed below:. - It can be added as `'google_project':'project-id'` as part of workflow options during workflow submission; - It can be included inside configuration file as shown in Getting started on Google Pipelines API where you need to replace the <google-billing-project-id> with the project id; - If it is not mentioned using above 2 ways, Cromwell will use the default project that has been configured with gcloud. More information about Requester pays can be found [here](https://cloud.google.com/storage/docs/requester-pays)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3638:258,config,configuration,258,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3638,4,['config'],"['configuration', 'configured']"
Modifiability,"Restart tests are those that command Centaur to restart Cromwell partway through. They [run sequentially](https://github.com/broadinstitute/cromwell/blob/d60b2a225a32960970890d1253374c7e057db3b7/centaur/src/main/scala/centaur/test/standard/CentaurTestFormat.scala#L43), meaning they don't start until after all the other tests have finished. Some of them also run really long, extending completion times a lot. Technically this change means that the restart test will no longer be in a horicromtal-style suite, but the main point of those suites is to verify that workflows get distributed across runners anyway. The new [restart-only suite](https://github.com/broadinstitute/cromwell/actions/runs/7107864176/job/19350092073) ran in 36 minutes. | |Before this sprint| This PR |; | --- | ------------- | ------------- |; | Centaur Papi V2 Beta|1:08|[0:56](https://github.com/broadinstitute/cromwell/actions/runs/7107864176/job/19350091880)|; | Centaur Horicromtal PapiV2 Beta | 1:34 |[1:02](https://github.com/broadinstitute/cromwell/actions/runs/7107864176/job/19350093905)|; |Centaur Papi V2 Beta (restart)|N/A|[0:38](https://github.com/broadinstitute/cromwell/actions/runs/7107864176/job/19350092073)|. In this pre-refactor sample run, `restart_while_failing` alone bloated runtime by 24 minutes:; ```; Late finishers; +--------------------------------------+-----------------+----------------------------+----------------------------+; | name | runtime_minutes | start | END |; +--------------------------------------+-----------------+----------------------------+----------------------------+; | restart_while_failing | 27 | 2023-12-05 22:00:46.653000 | 2023-12-05 22:28:14.005000 |; | draft3_call_cache_capoeira | 38 | 2023-12-05 21:25:25.583000 | 2023-12-05 22:04:17.569000 |; | sub_workflow_abort | 6 | 2023-12-05 21:53:35.602000 | 2023-12-05 21:59:55.385000 |; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7333:377,extend,extending,377,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7333,2,"['extend', 'refactor']","['extending', 'refactor']"
Modifiability,Restore configurable tmpDir behavior,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3789:8,config,configurable,8,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3789,1,['config'],['configurable']
Modifiability,Revert: Temporary patch: Use an encrypted variable for the vault token.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4585:42,variab,variable,42,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4585,1,['variab'],['variable']
Modifiability,Rewrite (or move to wdl4s) EngineFunctionsSpec,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2618:0,Rewrite,Rewrite,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2618,1,['Rewrite'],['Rewrite']
Modifiability,Rewrite error message for type coersion,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1998:0,Rewrite,Rewrite,0,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1998,1,['Rewrite'],['Rewrite']
Modifiability,"Running locally a scatter job with 2102 jobs causes an out-of-memory error after finishing job 1427 (reproduced twice) . The command that I run was using the wrapper script from **brew**:. ```; JAVA_OPTS=""-Dconfig.file=local.conf"" cromwell run --inputs inputs.json --metadata-output metadata-output.json workflow.wdl; ```. Where the local configuration looks like this:. ```; include required(classpath(""application"")). ## keep always the workflow logs; workflow-options.workflow-log-temporary: false; workflow-options.workflow-log-dir: ""/Volumes/Temp/E43CEE02/data/freqs/haf/base-all/w100000_2.0x/workflow-logs"". # Allows re-use of existing results for jobs you've already run; call-caching.enabled: true. backend.providers.Local.config {; ## limit the number of jobs; concurrent-job-limit = 10; # set the root directory to the run; root = ""/Volumes/Temp/E43CEE02/data/freqs/haf/base-all/w100000_2.0x/execution""; filesystems.local {; ## do not allow copy (too huge files); ## prefer hard-links, to don't remove data and kept analysis intact; localization: [""hard-link"", ""soft-link""]; caching.duplication-strategy: [""hard-link"", ""soft-link""]; }; # custom submit-docker to workaround detached container due to timeout in the virtual machine; # first, we do not remove the container until it really finishes (no --rm flag); # if the docker run command fails, then it runs docker wait to wait until it finishes and store the return code; # if the docker run command fails, then it runs docker wait to return the real exit code even if detached; # once it finishes, removes the docker container with docker rm; # finally, returns the ""real return code"" stored; submit-docker = """"""; docker run \; --cidfile ${docker_cid} \; -i \; ${""--user "" + docker_user} \; --entrypoint /bin/bash \; -v ${cwd}:${docker_cwd} \; ${docker} ${script}; rc=$(docker wait `cat ${docker_cid}`); docker rm `cat ${docker_cid}`; exit $rc; """"""; }; ```. The log shows the following stack-trace:. ```; [2018-03-09 15:31:16,47] [error]",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3387:339,config,configuration,339,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3387,2,['config'],"['config', 'configuration']"
Modifiability,Runtime configuration parsing improvements.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/99:8,config,configuration,8,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/99,1,['config'],['configuration']
Modifiability,"S AND OTHER SENSITIVE MATERIAL: -->. Using default configuration. Output:; ```; [2020-02-11 10:13:03,33] [info] Running with database db.url = jdbc:hsqldb:mem:89c116e0-5bca-4467-aaff-ae492c2ebbaf;shutdown=false;hsqldb.tx=mvcc; [2019-02-11 10:13:14,71] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2019-02-11 10:13:14,75] [info] [RenameWorkflowOptionsInMetadata] 100%; [2019-02-11 10:13:15,05] [info] Running with database db.url = jdbc:hsqldb:mem:6b5d8035-4932-4680-b912-34885765f705;shutdown=false;hsqldb.tx=mvcc; [2019-02-11 10:13:15,63] [info] Slf4jLogger started; [2019-02-11 10:13:16,02] [info] Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-1ddecb5"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; [2019-02-11 10:13:16,08] [info] Metadata summary refreshing every 2 seconds.; [2019-02-11 10:13:16,20] [info] KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; [2019-02-11 10:13:16,23] [info] WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; [2019-02-11 10:13:16,25] [warn] 'docker.hash-lookup.gcr-api-queries-per-100-seconds' is being deprecated, use 'docker.hash-lookup.gcr.throttle' instead (see reference.conf); [2019-02-11 10:13:16,26] [info] CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; [2019-02-11 10:13:16,33] [info] JobExecutionTokenDispenser - Distribution rate: 50 per 1 seconds.; [2019-02-11 10:13:17,45] [info] SingleWorkflowRunnerActor: Version 37; [2019-02-11 10:13:17,46] [info] SingleWorkflowRunnerActor: Submitting workflow; [2019-02-11 10:13:17,59] [info] Unspecified type (Unspecified version) workflow 52999e15-953f-44d6-aaae-1774c74d2910 submitted; [2019-02-11 10:13:17,65] [info] SingleWorkflowRunnerActor: Workflow submitted 52999e15-953f-44d6-aaae-1774c74d2910; [2019-02-11 10:13:17,65] [info] ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4626:2120,config,configured,2120,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4626,1,['config'],['configured']
Modifiability,S3fs can currently only be configured via environment variables - see https://github.com/elerch/Amazon-S3-FileSystem-NIO2/blob/sdk2/README.md. This should be wired through Cromwell configuration and the following TODO addressed: https://github.com/broadinstitute/cromwell/blob/aws_backend/filesystems/s3/src/main/scala/cromwell/filesystems/s3/S3PathBuilder.scala#L146,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3746:27,config,configured,27,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3746,3,"['config', 'variab']","['configuration', 'configured', 'variables']"
Modifiability,SFS Config supports arbitrary runtime attributes. Closes #1217,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1252:4,Config,Config,4,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1252,1,['Config'],['Config']
Modifiability,SGE cluster configuration correction in documentation,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3100:12,config,configuration,12,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3100,1,['config'],['configuration']
Modifiability,"SGE default config redirects stdout,stderr to the same file twice",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3705:12,config,config,12,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3705,1,['config'],['config']
Modifiability,"SM.akka$actor$FSM$$processMsg(FSM.scala:678); 	at akka.actor.FSM$$anonfun$receive$1.applyOrElse(FSM.scala:672); 	at akka.actor.Actor.aroundReceive(Actor.scala:517); 	at akka.actor.Actor.aroundReceive$(Actor.scala:515); 	at cromwell.engine.workflow.lifecycle.materialization.MaterializeWorkflowDescriptorActor.aroundReceive(MaterializeWorkflowDescriptorActor.scala:138); 	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:588); 	at akka.actor.ActorCell.invoke(ActorCell.scala:557); 	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:258); 	at akka.dispatch.Mailbox.run(Mailbox.scala:225); 	at akka.dispatch.Mailbox.exec(Mailbox.scala:235); 	at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260); 	at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); ```. I'm basically using the standard aws configuration file for Cromwell:. ```hocon; include required(classpath(""application"")). aws {; application-name = ""cromwell""; auths = [{; name = ""default""; scheme = ""default""; }]; region = ""ap-southeast-2""; }. engine { filesystems { s3 { auth = ""default"" } } }. backend {; default = ""AWSBATCH""; providers {; AWSBATCH {; actor-factory = ""cromwell.backend.impl.aws.AwsBatchBackendLifecycleActorFactory""; config {; numSubmitAttempts = 3; numCreateDefinitionAttempts = 3; root = ""s3://$bucketName/cromwell-execution""; auth = ""default""; concurrent-job-limit = 16; default-runtime-attributes {; queueArn = ""arn:aws:batch:ap-southeast-2:$arn""; }; filesystems { s3 { auth = ""default"" } }; }; }; }; }; ```. I've contacted AWS Support, to find out if I could fully (region) qualify the S3 locator (something like [these examples](https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingBucket.html#access-bucket-intro): `s3://us-east-1.amazonaws.com/broad-references/.../file`. . AWS basically said no, and they",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4731:3543,config,configuration,3543,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4731,1,['config'],['configuration']
Modifiability,"Sam is now up and accessible. Complete the wiring process for CromIAM to be able to talk to a live Sam. @cjllanwarne Can you fill in the blanks on what this entails?. (EDIT below by cjllanwarne):. - Have a look at the `handleRequest` method in `SamActor`. It's called by the actor's `receive`.; - Right now, the placeholders complete `Promises` after a set time. You'll want to message SAM, wait for a response, and then complete them more appropriately.; - NB in case you're wondering, the `Promise/Future` stuff is because the CromIamApiService is not an actor and so cannot receive responses in the usual actor-y way. Feel free to make it better, I ended up doing this because the actor-y way was adding in enormous/unnecessary overheads in terms of boilerplate... YMMV.; - FWIW even if `CromIamApiService` isn't an actor, I still suspect `SamActor` will end up spinning up individual worker actors. It's just the interface back to the service which isn't messages.; - The SamActor is parameterized with the `userIdHeader`. SamActorRequests will both have a `userIdtoken` included (oops, `RegisterWorkflow` calls it `user` but it's the same thing). When you make your request to same, you'll need to add the appropriate header (called whatever the actor was parameterized with) with the user token's value.; - Success or Failure completions, everything else *should* be wired up correctly already. You might want to double check that (especially for SAM rejections). If the intrepid person picking up this ticket is not me (@cjllanwarne), I'm happy to make this make more sense in person, if required.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2469:988,parameteriz,parameterized,988,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2469,2,['parameteriz'],['parameterized']
Modifiability,Scala steward config [BA-6518],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5698:14,config,config,14,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5698,1,['config'],['config']
Modifiability,Scala-Steward: Update circe-config from 0.8.0 to 0.10.0,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7047:28,config,config,28,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7047,1,['config'],['config']
Modifiability,Scala-Steward: Update circe-config from 0.8.0 to 0.10.1,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7291:28,config,config,28,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7291,1,['config'],['config']
Modifiability,Scala-Steward: Update configs from 0.4.4 to 0.5.0,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6126:22,config,configs,22,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6126,1,['config'],['configs']
Modifiability,Scala-Steward: Update configs from 0.5.0 to 0.6.0,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6244:22,config,configs,22,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6244,1,['config'],['configs']
Modifiability,Scala-Steward: Update configs from 0.6.0 to 0.6.1,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6392:22,config,configs,22,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6392,1,['config'],['configs']
Modifiability,Scala-Steward: Update delight-rhino-sandbox from 0.0.11 to 0.0.12,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5935:36,sandbox,sandbox,36,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5935,1,['sandbox'],['sandbox']
Modifiability,Scala-Steward: Update delight-rhino-sandbox from 0.0.11 to 0.0.13,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6085:36,sandbox,sandbox,36,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6085,1,['sandbox'],['sandbox']
Modifiability,Scala-Steward: Update delight-rhino-sandbox from 0.0.12 to 0.0.15,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6269:36,sandbox,sandbox,36,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6269,1,['sandbox'],['sandbox']
Modifiability,Scala-Steward: Update typesafe:config from 1.3.4 to 1.4.0,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5754:31,config,config,31,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5754,1,['config'],['config']
Modifiability,Scala-Steward: Update typesafe:config from 1.4.0 to 1.4.1,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5972:31,config,config,31,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5972,1,['config'],['config']
Modifiability,Scala-Steward: Update typesafe:config from 1.4.1 to 1.4.2,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6868:31,config,config,31,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6868,1,['config'],['config']
Modifiability,Scala-Steward: Update typesafe:config from 1.4.2 to 1.4.3,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7286:31,config,config,31,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7286,1,['config'],['config']
Modifiability,"Searched the codebase for `request-timeout`, found that we seem to use 40 seconds not the 55 previously discussed. Copied the config stanza from `cromwell/server/src/main/resources/application.conf` to CromIAM.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4615:126,config,config,126,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4615,1,['config'],['config']
Modifiability,"Second PR for call caching diff endpoint, it's a lot but most of it was actually already reviewed in the first one.; New things are CallCacheDiffActor, CallCacheDiffActorSpec and things touching to MetadataQuery in the DB layers to be able to query a specific call using include/exclude key filters",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2363:222,layers,layers,222,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2363,1,['layers'],['layers']
Modifiability,See BT-343 for more info. The changes mostly comprise:. * I/O Commands that are more than `command-backpressure-staleness` old at the time they begin to be processed will trigger I/O backpressure.; * Several previously hardcoded configuration values have been moved out to `reference.conf`.; * `job-rate-control` is lowered to give the I/O subsystem a chance to backpressure.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6463:229,config,configuration,229,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6463,1,['config'],['configuration']
Modifiability,"See below for motivating use case WDL (now a test). The throwaways need OGINs to reference the `i`, but we weren't recording the OGINs that they were making. The upshot was that multiple usages of the same variable in a nested scope was producing multiple OGINs for the same value, and that was causing the ""duplicate FQN"" errors to trigger. ```; workflow nested_lookups {; Int i = 27; if(true) {; Int? throwaway = i # Make sure this 'i' OGIN doesn't duplicate the nested m1's 'i' OGIN; Int? throwaway2 = i # Make sure this 'i' OGIN doesn't duplicate the nested m1's 'i' OGIN; if(true) {; if(true) {; call mirror as m1 { input: i = i}; }; }; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2855:206,variab,variable,206,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2855,1,['variab'],['variable']
Modifiability,"Seems like this would currently look something like PBE, with probably a lot less configuration. In the KISS spirit, perhaps only a list of supported `workflowType` + `workflowTypeVersion`s for each language processor.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2346:82,config,configuration,82,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2346,1,['config'],['configuration']
Modifiability,"Sending JMUI style call failures to Sentry.; Wired in the ability for Centaur integration tests to get data directly from the Cromwell database.; Added a `queryJobKeyValueEntries` to return all job key/values for a workflow.; Removed deprecation exception for old database config syntax.; Flatten metadata only during comparison, passing the original internally.; Removed secure env variables that were always true in Sentry.; Refactored centaur secure config rendering.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4055:273,config,config,273,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4055,4,"['Refactor', 'config', 'variab']","['Refactored', 'config', 'variables']"
Modifiability,"Sending error info to sentry during centaur testing before retrying.; Encrypting sensitive variables using a random key during centaur tests, jic they are sent to sentry.; Rendering secure resources during _all_ tests.; When secure variables cannot be rendered, only fail when secure variables are required, otherwise producing only info/warning messages.; Disabled caches during tests that read `backendStatus` call metadata.; Allow `test_cromwell.sh` to use a centaur config file.; Enable GcsPathBuilderFactory to retry more than zero times.; Lazy load centaur `*.inputs` & `*.options` so that they aren't required to load `*.test` files.; Relatedly, so that one doesn't (try to) accidentally commit the changes, `git rm` the options file that was being rendered.; Moved logback.xml out of transitive core library and into executables, next to application.conf files.; Pin `cwltool` version.; Use a workaround to pass `--timeout` through `run_test.sh` to `cwltest`.; Using `better.files` instead of `java.nio.Path`, and passing `IO` monads further up.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4000:91,variab,variables,91,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4000,4,"['config', 'variab']","['config', 'variables']"
Modifiability,"Several pieces of this repo link to/mention `Cromwell.example.backends/Cromwell.examples.conf`, but that file appears to no longer exist. Cromwell's readthedocs is also affected. This previously happened in 2021 (https://github.com/broadinstitute/cromwell/pull/6329), so it may be worth hosting Cromwell.examples.conf somewhere more stable if this repo undergoes a lot of reorganization. Affected pages (might not be exhaustive):; * https://cromwell.readthedocs.io/en/develop/cromwell_features/HogFactors/; * https://github.com/broadinstitute/cromwell/blob/develop/docs/tutorials/ConfigurationFiles.md; * https://github.com/broadinstitute/cromwell/blob/develop/cromwell.example.backends/LocalExample.conf; * https://github.com/broadinstitute/cromwell/blob/develop/cromwell.example.backends/AWS.conf; * https://github.com/broadinstitute/cromwell/blob/develop/cromwell.example.backends/HtCondor.conf; * https://github.com/broadinstitute/cromwell/blob/develop/cromwell.example.backends/LSF.conf; * https://github.com/broadinstitute/cromwell/blob/develop/cromwell.example.backends/PAPIv2.conf; * https://github.com/broadinstitute/cromwell/blob/develop/cromwell.example.backends/README.md; * https://github.com/broadinstitute/cromwell/blob/develop/cromwell.example.backends/SGE.conf; * https://github.com/broadinstitute/cromwell/blob/develop/cromwell.example.backends/TESK.conf; * https://github.com/broadinstitute/cromwell/blob/develop/cromwell.example.backends/TESK.conf; * https://github.com/broadinstitute/cromwell/blob/develop/cromwell.example.backends/singularity.conf; * https://github.com/broadinstitute/cromwell/blob/develop/cromwell.example.backends/singularity.slurm.conf; * https://github.com/broadinstitute/cromwell/blob/develop/cromwell.example.backends/slurm.conf; * https://github.com/broadinstitute/cromwell/blob/develop/cromwell.example.backends/udocker.conf; * https://github.com/broadinstitute/cromwell/blob/develop/cromwell.example.backends/udocker.slurm.conf; * https://github.com/bro",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6797:580,Config,ConfigurationFiles,580,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6797,1,['Config'],['ConfigurationFiles']
Modifiability,Shared IntelliJ config [BW-634],MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6304:16,config,config,16,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6304,1,['config'],['config']
Modifiability,"Should help with debugging occasional failures like this in travis by replacing ""not found"" with ""this looks similar"":. ```; StatsDInstrumentationServiceActorSpec:; StatsDInstrumentationServiceActor; - should increment counters (1 second, 193 milliseconds); - should add count (1 second, 9 milliseconds); - should set gauges (1 second, 10 milliseconds); info- should set timings *** FAILED *** (3 seconds, 701 milliseconds); info Missing packet: prefix_value.cromwell.test_prefix.test.metric.bucket.timing.stddev:0.00|g (StatsDInstrumentationServiceActorSpec.scala:83); info org.scalatest.exceptions.TestFailedException:; info ...[0m[0m; info at cromwell.services.instrumentation.impl.statsd.StatsDInstrumentationServiceActorSpec.$anonfun$new$4(StatsDInstrumentationServiceActorSpec.scala:83); info at cromwell.services.instrumentation.impl.statsd.StatsDInstrumentationServiceActorSpec.$anonfun$new$4$adapted(StatsDInstrumentationServiceActorSpec.scala:83); info at scala.collection.immutable.Set$Set4.foreach(Set.scala:206); info at cromwell.services.instrumentation.impl.statsd.StatsDInstrumentationServiceActorSpec.$anonfun$new$2(StatsDInstrumentationServiceActorSpec.scala:83); info at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:12); info at org.scalatest.OutcomeOf.outcomeOf(OutcomeOf.scala:85); info at org.scalatest.OutcomeOf.outcomeOf$(OutcomeOf.scala:83); info ...; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4387:910,adapt,adapted,910,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4387,1,['adapt'],['adapted']
Modifiability,Simple pattern variables compiler flag cleanup.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2433:15,variab,variables,15,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2433,1,['variab'],['variables']
Modifiability,"So far cromwell is working great on our cluster. Thanks a lot for this splendid effort. However there is one issue we run into that other people might run into as well. Our cluster uses NFS as its filesystem backend. This means that if one node completes a job, it might take a while before the files that were created. In other workflows we can set an I/O timeout option: if the file did not appear within 3 minutes, the job failed. How do we do this in cromwell. All the settings I have available is `number-of-requests`, `per` and `number-of-attempts`. Currently we have; ```HOCON; io {; number-of-requests = 10; per = 10 seconds; number-of-attempts = 180; }; ```; This should make sure that failing files are attempted for 180 seconds, but this is not very elegant. There is a `timeout` option in I/O. But this is the timeout for the I/O operation to respond. If the file is not ""visible"" then the I/O operation will respond immediately, and the job will have failed. Is there a fix to this option in the current cromwell configuration?",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3648:1026,config,configuration,1026,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3648,1,['config'],['configuration']
Modifiability,"Some FireCloud users want to communicate to various resources in Google via Cromwell - the current use case being interacting with BigQuery. . Ideally this can be set both by a config and optionally overwritten by a workflow option. The minimum scopes that are needed should always be included, so the scopes provided should just add to that.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4638:177,config,config,177,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4638,1,['config'],['config']
Modifiability,Some builds were failing to pullapprove because the config contains a lost collaborator :(,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1558:52,config,config,52,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1558,1,['config'],['config']
Modifiability,"Some light reading for @Horneth and @kshakir. This is largely Frankensteining of ""Olde Style"" code. Known missing or broken, I need to confirm that appropriate tickets exist for the restoration of the following:; - [x] #753 Abort; - [x] #751 Recover; - [x] #749 Preemptibility; - [x] #785 Persistence of any data (note this would not be a ticket to create a KV / metadata service, but to integrate this backend with such a service); - [x] #809 Hashing (prereq for #750); - [x] #750 Caching; - [x] #806 implement Firecloud style auth upload / deletion (the code is not present here); - [x] #808 Retries were removed from command script upload and JES run creation. Lessons learned:; - [x] #811 #812 Actor Factories should be responsible for sanity-checking configs .; - [x] #813 Initialization actors should have the ability to create workflow-level resources that can be shared by the other actors collaborating in the workflow execution. e.g. GCS Filesystems need only be created once per workflow, not for every call.; - [x] It's not clear how workflow logging (or logging in general) should work.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/797:756,config,configs,756,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/797,1,['config'],['configs']
Modifiability,Some of the comments are... confusing. But they come directly from the template (https://github.com/scala-steward-org/scala-steward/blob/master/docs/repo-specific-configuration.md),MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5698:163,config,configuration,163,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5698,1,['config'],['configuration']
Modifiability,Some refactoring: . * Separated the concepts of resolving and downloading.; * `DrsLocalizerMain#resolve` now chooses the `Downloader` implementation based on the content of the Martha response.; * The two downloader implementations support access and GCS URLs respectively.; * Tests for the downloader implementations have been separated from tests for the resolver.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6312:5,refactor,refactoring,5,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6312,1,['refactor'],['refactoring']
Modifiability,Spike: explore join rewrite of include subworkflows,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4684:20,rewrite,rewrite,20,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4684,1,['rewrite'],['rewrite']
Modifiability,Standardize shebang and (maybe) make it configurable,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1384:40,config,configurable,40,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1384,1,['config'],['configurable']
Modifiability,"Starting to spider out the proofing of concept for a google-y metadata system into something which is actually storing events as well as providing a not horribly inefficient read access for the current set of metadata-y endpoints. A high level description: Stream metadata events out of Cromwell via Google PubSub, and store them in two locations. The first is a permanent event store which will be storing these events in an immutable fashion, which will allow us to be flexible with downstream presentation w/o information loss. The second will be a set of SQL tables which have been designed to provide efficient results for all of the standard Cromwell metadata endpoints such as metadata, status, outputs, etc. For Broad folks, more information is available [here](https://docs.google.com/document/d/1F5WsEAKvYx6njdF-yJZ4LHvT39KcErCdBpCOySq-NoQ/edit)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3243:471,flexible,flexible,471,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3243,1,['flexible'],['flexible']
Modifiability,"Step Inputs have the task of tying wf inputs to their `run` command. This is done via the `source` field of a `WorkflowStepInput`, and there may be multiple, hence the name of this requirement. This logic falls into two buckets:. # Type. Determing the type of the element being passed to the input is a function of:; * what type the `run` is expecting; * whether the variable appears in a scatter ; * whether there is an expression in the `valueFrom` field; * How to ""merge"" when multiple sources are declared.; * the ""default"" (On which I am punting here). # Expression . The way the expression presents the inputs to the run command is determined by that `LinkMergeMethod` field i.e. how the run step expects the value to appear. . # Assumptions. The Spec says to use `merge_nested` as default, but also says:. > If ""merge_nested"" is specified with a single link, the value from the link must be wrapped in a single-item list. Thus it seemed that all values should be wrapped in a list. this is wrong and I'm going to ask on gitter what the deal is. # What I've punted on. the `default` field.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3252:367,variab,variable,367,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3252,1,['variab'],['variable']
Modifiability,Still does not honor the read limit config for WDL but makes it possible.; For CWL it does only stream the first 64KB. - [ ] Add a centaur test ?,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3113:36,config,config,36,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3113,1,['config'],['config']
Modifiability,"Strange ""Boxed Error"", probably authorization / config",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3736:48,config,config,48,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3736,1,['config'],['config']
Modifiability,"Submitting jobs to UGER should use an array:. > You are limited to 100 job in the cluster at once. This is to encourage the use of Task Arrays. Task arrays use the variable $SGE_TASK_ID which can be called inside the job script.""qsub -t 1-1000 /path/to/jobScript"". via: https://intranet.broadinstitute.org/bits/service-catalog/research-support/job-scheduling",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1491:164,variab,variable,164,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1491,1,['variab'],['variable']
Modifiability,Such complicated. Much states. Rewrite,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1373:31,Rewrite,Rewrite,31,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1373,1,['Rewrite'],['Rewrite']
Modifiability,Suggested reading order:; - JobExecutionTokenDispenserActorSpec (to see how the TokenDispenserActor is intended to operate); - EJEA (to see how the token dispenser gets invoked); - Everything else (a lot of the more annoying wiring can probably be refactored once I add per-backend god-actors in my other ticket),MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1500:248,refactor,refactored,248,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1500,1,['refactor'],['refactored']
Modifiability,"Support AWS ""monster"" configuration",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2174:22,config,configuration,22,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2174,1,['config'],['configuration']
Modifiability,Support additional Docker configuration options.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/375:26,config,configuration,26,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/375,1,['config'],['configuration']
Modifiability,"Support for this was refactored out of the Pluggable Backend Experience, in particular from LocalRuntimeAttributes and JesRuntimeAttributes.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/819:21,refactor,refactored,21,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/819,1,['refactor'],['refactored']
Modifiability,Switch to using an off the shelf Config enhancer library,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1211:33,Config,Config,33,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1211,2,"['Config', 'enhance']","['Config', 'enhancer']"
Modifiability,Switched to using lenthall config utilities.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/237:27,config,config,27,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/237,1,['config'],['config']
Modifiability,TES 4.4 requires a new backend parameter `internal_path_prefix` so it can create task files in a correct/configurable location. This PR adds that key/value pair to our `TesTask` and friends.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7189:105,config,configurable,105,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7189,1,['config'],['configurable']
Modifiability,TES 4.4 requires a new backend parameter internal_path_prefix so it can create task files in a correct/configurable location. This PR adds that key/value pair to our TesTask and friends.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7190:103,config,configurable,103,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7190,1,['config'],['configurable']
Modifiability,"TL;DR: Boot disk size is increased automatically in Papi v2 if the (approximated) docker image size is > than what is requested (or the default one). Only works for Dockerhub and GCR at this moment because quay doesn't support yet manifest v2. - Refactor of the DockerHashActor: got rid of akka stream, replaced with fs2 streams and cats.effect.IO. Easier to read/write, modify and maintain; - Instead of just getting the digest from the manifest header response, parse the content and get the size of the layer. The sum of the sizes == compressed size of the image; - The size of the layers is only available in the version 2 of the manifest schema https://docs.docker.com/registry/spec/manifest-v2-2/; GCR and Dockerhub support it, quay.io not yet (soon according to their support); - Approximate the uncompressed size using a configurable compression factor. If the approximation is higher than the requested boot disk size, use that instead (only for Papi v2); - The refactoring allows for: no need for explicitly differentiation gcr zones, which means `gcr.io`, `us.gcr.io`, `eu.gcr.io` and `asia.gcr.io` all work; - The refactoring also isolate each registry from each other with their own thread pool. Which means if say dockerhub is having very long response time all of sudden, gcr and quay aren't impacted",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4472:246,Refactor,Refactor,246,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4472,5,"['Refactor', 'config', 'layers', 'refactor']","['Refactor', 'configurable', 'layers', 'refactoring']"
Modifiability,"Task `t` is called three times with different aliases. Is there any way to share the same string variable `a` for `t`, `t1` and `t2`?; ```; workflow test {; call t {}; call t as t1 {}; call t as t2 {}; }. task t {; String? a; command { ... }; }; ```; What I expected...; ```; input.json; {; ""test.t.a"" : ""hello world""; }; ```; But I had to use...; ```; input.json; {; ""test.t.a"" : ""hello world""; ""test.t1.a"" : ""hello world""; ""test.t2.a"" : ""hello world""; }; ```; I am developing a pipeline and it has 9 aliases for the same task. I actually don't want to define the same variable 9 times in `input.json`.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2914:97,variab,variable,97,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2914,2,['variab'],['variable']
Modifiability,"Task.java:260); 	at scala.concurrent.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339); 	at scala.concurrent.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979); 	at scala.concurrent.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107); Caused by: wdl4s.WdlExpressionException: Cannot perform operation: -m ea -M + WdlOptionalValue(WdlStringType,Some(WdlString(conrad.leonard@qimrberghofer.edu.au))); 	at wdl4s.values.WdlValue$class.invalid(WdlValue.scala:12); 	at wdl4s.values.WdlString.invalid(WdlString.scala:7); 	at wdl4s.values.WdlString.add(WdlString.scala:15); 	at wdl4s.expression.ValueEvaluator$$anonfun$evaluate$3$$anonfun$apply$1.apply(ValueEvaluator.scala:54); 	at wdl4s.expression.ValueEvaluator$$anonfun$evaluate$3$$anonfun$apply$1.apply(ValueEvaluator.scala:54); 	at scala.util.Success$$anonfun$map$1.apply(Try.scala:237); 	at scala.util.Try$.apply(Try.scala:192); 	at scala.util.Success.map(Try.scala:237); 	at wdl4s.expression.ValueEvaluator$$anonfun$evaluate$3.apply(ValueEvaluator.scala:54); 	at wdl4s.expression.ValueEvaluator$$anonfun$evaluate$3.apply(ValueEvaluator.scala:54); 	at scala.util.Success.flatMap(Try.scala:231); 	at wdl4s.expression.ValueEvaluator.evaluate(ValueEvaluator.scala:54); 	at wdl4s.WdlExpression$.evaluate(WdlExpression.scala:87); 	at wdl4s.WdlExpression.evaluate(WdlExpression.scala:163); 	at wdl4s.command.ParameterCommandPart.instantiate(ParameterCommandPart.scala:37); ```. The problem appears to be in wdl4s now that optionals are first class citizens the `evaluate` [here](https://github.com/broadinstitute/wdl4s/blob/4e236a7e6e2202cd62e2a5fee991faf9829b3e67/src/main/scala/wdl4s/command/ParameterCommandPart.scala#L38) is failing with `WdlExpressionException` because you can't add `WdlOptionalValue` to `WdlString`, rather than the `VariableNotFoundException` that is handled a couple of lines below, which usefully used to return an empty string when you tried evaluate an expression with an unsupplied ""?"" variable.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1765:7139,Variab,VariableNotFoundException,7139,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1765,2,"['Variab', 'variab']","['VariableNotFoundException', 'variable']"
Modifiability,Task.scala:107); 	at wdl4s.Task$$anonfun$instantiateCommand$1.apply(Task.scala:107); 	at scala.util.Try$.apply(Try.scala:192); 	at wdl4s.Task.instantiateCommand(Task.scala:107); 	at cromwell.backend.impl.sfs.config.ConfigAsyncJobExecutionActor$class.writeTaskScript(ConfigAsyncJobExecutionActor.scala:55); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.writeTaskScript(ConfigAsyncJobExecutionActor.scala:124); 	at cromwell.backend.impl.sfs.config.ConfigAsyncJobExecutionActor$class.processArgs(ConfigAsyncJobExecutionActor.scala:39); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.processArgs$lzycompute(ConfigAsyncJobExecutionActor.scala:124); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.processArgs(ConfigAsyncJobExecutionActor.scala:124); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor$class.executeScript(SharedFileSystemAsyncJobExecutionActor.scala:220); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.executeScript(ConfigAsyncJobExecutionActor.scala:124); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor$$anonfun$executeOrRecover$2.apply(SharedFileSystemAsyncJobExecutionActor.scala:192); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor$$anonfun$executeOrRecover$2.apply(SharedFileSystemAsyncJobExecutionActor.scala:189); 	at scala.util.Try$.apply(Try.scala:192); 	at cromwell.backend.sfs.SharedFileSystemAsyncJobExecutionActor$class.executeOrRecover(SharedFileSystemAsyncJobExecutionActor.scala:188); 	at cromwell.backend.impl.sfs.config.DispatchedConfigAsyncJobExecutionActor.executeOrRecover(ConfigAsyncJobExecutionActor.scala:124); 	at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$cromwell$backend$async$AsyncBackendJobExecutionActor$$robustExecuteOrRecover$1.apply(AsyncBackendJobExecutionActor.scala:45); 	at cromwell.backend.async.AsyncBackendJobExecutionActor$$anonfun$cromwell$backend$async$AsyncBacke,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1765:3145,config,config,3145,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1765,1,['config'],['config']
Modifiability,Temporary patch: Use an encrypted variable for the vault token.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4583:34,variab,variable,34,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4583,1,['variab'],['variable']
Modifiability,Test config overrides main config -- causes confusion,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/768:5,config,config,5,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/768,2,['config'],['config']
Modifiability,"Tested with the following workflow [1], workflow options [2], and config [3]. On `develop`, the workflow failed 20/20 times with an `IOException` [0]. On the PR branch, it succeeded 20/20 times. [0]; ```; IOException: Could not read from https://coaexternalstorage.blob.core.windows.net/inputs/test/inputFile.txt: ; /Users/anichols/Projects/cromwell/https:/coaexternalstorage.blob.core.windows.net/inputs/test/inputFile.txt; ```; [1]; ```; version 1.0. workflow my_workflow {; String s = read_string(""https://coaexternalstorage.blob.core.windows.net/inputs/test/inputFile.txt""); output {; String out = s; }; }; ```; [2]; ```; {; ""read_from_cache"": false,; ""write_to_cache"": false; }; ```; [3]; ```; filesystems {; blob {; class = ""cromwell.filesystems.blob.BlobPathBuilderFactory""; global {; class = ""cromwell.filesystems.blob.BlobFileSystemConfig""; config {; # workspace-manager-url = ""{PLACEHOLDER}""; }; }; }; http {; class = ""cromwell.filesystems.http.HttpPathBuilderFactory""; }; }. engine {; filesystems {; blob {; enabled: true; endpoint: ""https://coaexternalstorage.blob.core.windows.net""; container: ""inputs""; # sas-token: ""{PLACEHOLDER}""; # workspace-id: ""{PLACEHOLDER}""; }. http {; enabled: true; }; }; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6930:66,config,config,66,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6930,2,['config'],['config']
Modifiability,"Testing conducted with local Cromwell running against Life Sciences with the following machine shape, localizing and delocalizing a 95 GB Chromosome 2 reference file [0]. ```; runtime {; docker: ""rockylinux:9""; disks: ""local-disk 2500 SSD""; cpu: 16; memory: ""32 GB""; cpuPlatform: ""Intel Ice Lake""; }; ```. ![Screenshot 2024-01-12 at 10 41 06](https://github.com/broadinstitute/cromwell/assets/1087943/b0a1925e-a243-4832-8023-1be336103e31). The result in Life Sciences above was confirmed manually using a [similarly configured GCE VM](https://console.cloud.google.com/compute/instancesDetail/zones/us-east4-c/instances/aen-build?project=broad-dsde-cromwell-dev) via SSH. ```; > gcloud storage --billing-project=broad-dsde-cromwell-dev cp gs://genomics-public-data/1000-genomes/vcf/ALL.chr2.integrated_phase1_v3.20101123.snps_indels_svs.genotypes.vcf .; Copying gs://genomics-public-data/1000-genomes/vcf/ALL.chr2.integrated_phase1_v3.20101123.snps_indels_svs.genotypes.vcf to file://./ALL.chr2.integrated_phase1_v3.20101123.snps_indels_svs.genotypes.vcf; Completed files 1/1 | 95.4GiB/95.4GiB | 519.7MiB/s . Average throughput: 1.2GiB/s; ```. Corresponding config synchronization: https://github.com/broadinstitute/terra-helmfile/pull/4987. [0] `gs://genomics-public-data/1000-genomes/vcf/ALL.chr2.integrated_phase1_v3.20101123.snps_indels_svs.genotypes.vcf`",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7359:516,config,configured,516,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7359,2,['config'],"['config', 'configured']"
Modifiability,"Thanks for taking the time to report feedback. Before posting an issue over in Jira tracker, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're almost in the right place. -->; `s3.caching.duplication-strategy` doesn't work on AWSBatch backend. <!-- You'll want to go to https://broadworkbench.atlassian.net/projects/BA/issues and then tell us: -->; https://broadworkbench.atlassian.net/browse/CROM-6734. <!-- Which backend are you running? -->; AWSBatch. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->. ```; include required(classpath(""application"")). backend {; default = ""aws""; providers {; aws {; config {; default-runtime-attributes {; scriptBucketName = ""caper4-04-20-2021""; queueArn = ""arn:aws:batch:us-east-1:618537831167:job-queue/default-caper5""; }; filesystems {; s3 {; caching {; duplication-strategy = ""reference""; }; auth = ""default""; }; }; concurrent-job-limit = 1000; numSubmitAttempts = 6; numCreateDefinitionAttempts = 6; auth = ""default""; root = ""s3://caper4-04-20-2021/out""; }; actor-factory = ""cromwell.backend.impl.aws.AwsBatchBackendLifecycleActorFactory""; }; }; }. system {; job-rate-control {; jobs = 1; per = ""2 seconds""; }; abort-jobs-on-terminate = true; graceful-server-shutdown = true; max-concurrent-workflows = 40; }; call-caching {; invalidate-bad-cache-results = true; enabled = true; }; database {; db {; connectionTimeout = 30000; numThreads = 1; url = ""jdbc:hsqldb:file:/opt/caper/default_file_db;shutdown=fal",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6327:1196,config,configuration,1196,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6327,1,['config'],['configuration']
Modifiability,"Thanks for the AWS backend, we've been looking forward to that for a long time!. It works fine when there's no proxy between cromwell server and the outside, but from behind our institute proxy it fails (detailed log here: https://gist.github.com/delocalizer/e31e2779b906fba85d99ab9f8eb485b1). The credentials are valid, it's just that the `STSClient` connection is timing out [here](https://github.com/broadinstitute/cromwell/blob/e9f47c923ab7ec0cf6b4c6b2ae45e66d0d88e907/cloudSupport/src/main/scala/cromwell/cloudsupport/aws/auth/AwsAuthMode.scala#L86) because it seems it's not respecting proxy settings specified either with environment variables:; ```; http_proxy; https_proxy; HTTP_PROXY; HTTPS_PROXY; ```; or to java directly with system properties; ```; http.proxyHost; http.proxyPort; https.proxyHost; https.proxyPort; ```. Using the version 1 of `aws-sdk-java` you coud configure clients with [ClientConfiguration](https://docs.aws.amazon.com/AWSJavaSDK/latest/javadoc/index.html?com/amazonaws/ClientConfiguration.html) that by default picks up those settings. I don't know how (or even if you can) do that with the sdk version 2 that's being used here.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3969:641,variab,variables,641,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3969,2,"['config', 'variab']","['configure', 'variables']"
Modifiability,"Thanks to a good tip from Devops [(Slack link)](https://broadinstitute.slack.com/archives/CADM7MZ35/p1664898679060499), Cromwell and CromIAM adopt the current recommended pattern for services that go to dev on merge. [Code adapted from how Workspace Manager does it](https://github.com/DataBiosphere/terra-workspace-manager/actions/runs/3176595248/workflow#L142-L149). Also, clean up a missed `-SNAP` reference to make things consistent.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6924:223,adapt,adapted,223,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6924,1,['adapt'],['adapted']
Modifiability,The (no-longer maintained) pywdl repo has a graph building tools (from wdl) that would put the nodes that comprise a scatter block in a small rectangle labeled by the scatter variable. It would be really nice to have a similar result from the graph tool in wdlTool.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2126:175,variab,variable,175,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2126,1,['variab'],['variable']
Modifiability,"The Batch backend configuration depends on entries prefixed by ""genomics"" which is the wrong term, this entry has been renamed to ""batch-api"". Also, the usages for these configs were renamed to ""batch"". At last, there was an usage involving lifesciences which has been removed too. NOTE: This is a breaking change, existing projecs using batch backend will need to update their configuration.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7411:18,config,configuration,18,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7411,3,['config'],"['configs', 'configuration']"
Modifiability,"The CWL expression evaluation needs to know minimum settings for cpu cores, memory size, etc. These should be specified in a config and passed in to the implementation. Currently they are hardcoded.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2817:125,config,config,125,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2817,1,['config'],['config']
Modifiability,"The Config (SFS) backend trait should dynamically fill in the `runtimeAttributeDefinitions` field based on its config. This will allow the JobPreparation to correctly assign the defaults, and allow the call cache hashing to hash the attributes (if appropriate). Depends on #1307",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1315:4,Config,Config,4,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1315,2,"['Config', 'config']","['Config', 'config']"
Modifiability,"The GCP Batch PR has seen a number of seemingly unrelated failures building the DRS localizer [(Github actions link)](https://github.com/broadinstitute/cromwell/actions/runs/5580938822/jobs/10198518044?pr=7177) and I saw them locally too, both on `develop` and the Batch branch [(Slack link)](https://broadinstitute.slack.com/archives/G01D73CM63S/p1689702982488299?thread_ts=1689702892.491819&cid=G01D73CM63S). ```; W: GPG error: http://security.ubuntu.com/ubuntu jammy-security InRelease: At least one invalid signature was encountered.; E: The repository 'http://security.ubuntu.com/ubuntu jammy-security InRelease' is not signed. process ""/bin/sh -c apt-get -y update"" did not complete successfully; ```. It seems that specifying the OS explicitly instead of implicitly helps work around the problem. I confirmed that yesterday's build of the localizer uses the same base so this is not a radical change. [Nightly:](https://hub.docker.com/layers/broadinstitute/cromwell-drs-localizer/86-af9660e/images/sha256-ee39681ef7287e904fdde01874b5dfa80b045aed28b9cc4b017554bdb40015f1?context=repo); ```; docker inspect broadinstitute/cromwell-drs-localizer:86-af9660e; ""Labels"": {; ""org.opencontainers.image.ref.name"": ""ubuntu"",; ""org.opencontainers.image.version"": ""22.04""; }; ```; Local:; ```; docker inspect broadinstitute/cromwell-drs-localizer:86-813fc98-SNAP; ""Labels"": {; ""org.opencontainers.image.ref.name"": ""ubuntu"",; ""org.opencontainers.image.version"": ""22.04""; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7179:942,layers,layers,942,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7179,1,['layers'],['layers']
Modifiability,The HPC tutorial config causes the server to error.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3488:17,config,config,17,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3488,1,['config'],['config']
Modifiability,"The Horicromtal Deadlock test started failing the morning of Monday, 2/26 with Docker pull failures:; ```; Head ""https://registry-1.docker.io/v2/dockercloud/haproxy/manifests/latest"":; error parsing HTTP 429 response body:; invalid character 'S' looking for beginning of value: ; ""Server capacity exceeded.\n""; ```; I was able to pull the [`dockercloud/haproxy` image](https://hub.docker.com/r/dockercloud/haproxy) locally but found that it was last updated 6 years ago. My suspicion is that ancient images are stored in a much less hot level of cache in the bowels of Docker Hub and may be more susceptible to capacity issues and timeouts. In order to adopt a current, official HAProxy image, I had to make a very basic config and we were off to the races. This is because the `dockercloud` image was a bit customized with special sauce to automatically configure itself by detecting running Docker containers. As a bonus, the new Alpine-based image is actually smaller than the ancient one, albeit only 25 MB vs. 43 MB.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7376:721,config,config,721,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7376,2,['config'],"['config', 'configure']"
Modifiability,"The MWDA should use the configuration it is passed when determining backend assignments, not rely on the `shadowy` variables in `CromwellBackends` as it does currently. Re-enable the `""assign backends based on runtime attributes""`test in `MaterialiseWorkflowDescriptorActorSpec`",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1075:24,config,configuration,24,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1075,2,"['config', 'variab']","['configuration', 'variables']"
Modifiability,"The PAPI v2 reference disk feature validates crc32c values for every file listed in configured reference disk manifests (CI manifest [here](https://github.com/broadinstitute/cromwell/blob/77c369596a1ad1153aff3fd4c8753d8a28dd649c/src/ci/resources/papi_v2_reference_image_manifest.conf)). If a file's crc32c value in GCS does not match its crc32c value in the manifest, the file will be omitted from Cromwell's reference mapping. In this particular case`gs://gcp-public-data--broad-references/hg19/v0/README` was updated in GCS which changed its GCS crc32c, but the manifest was not similarly updated until now. Cromwell did [emit a warning for this](https://api.travis-ci.com/v3/job/543857965/log.txt#:~:text=09%3A31%2C195%20%20WARN%20%20--,The%20following%20files%20listed%20in%20references%20manifest%20have%20checksum%20mismatch%20with%20actual%20files%20in%20GCS%3A%20ReferenceFile(gcp-public-data--broad-references/hg19/v0/README%2C1479759245,-)%0A2021-10-18) but I didn't notice it until after I started debugging. As there are 1604 files in the current CI manifest and it appears the only file that has changed in 8 months is the one file we use for CI, it seems likely we didn't make the best choice of test data. Suggestion for a better alternative are welcome. 🙂",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6546:84,config,configured,84,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6546,1,['config'],['configured']
Modifiability,"The StandardBackend is caching some workflow information in the backend initialization data and then using it for things like returning the ""workflowRoot"":. https://github.com/broadinstitute/cromwell/blob/4252c85d417b727d7745d67fdec03f6f175b6e58/backend/src/main/scala/cromwell/backend/standard/StandardLifecycleActorFactory.scala#L199-L205. The problem with this is that there is only _one_ `initializationData` being passed around for a ""family"" of root and subworkflows. https://github.com/broadinstitute/cromwell/blob/4252c85d417b727d7745d67fdec03f6f175b6e58/engine/src/main/scala/cromwell/engine/workflow/lifecycle/execution/WorkflowExecutionActor.scala#L562-L583. A patch for this particular issue may be a simple as _not_ overriding `getWorkflowExecutionRootPath` to ignore the `workflowRoot` stored in the initialization data. Ultimately it's possible the `workflowRoot` doesn't belong in `initializationData` if the data is supposed to be for a root-plus-subworkflows. A/C:; - Metadata for a subworkflow returns the `workflowRoot` for the subworkflow not the root.; - Other tickets filed as necessary if there are other issues regarding `initializationData` being shared between root and subworkflows. For example:; - The initializationData.workflowRoot` may be used incorrectly in other subworkflow cases; - Other ""workflow"" variables like the `executionRoot` may need a similar fix.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3623:1335,variab,variables,1335,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3623,1,['variab'],['variables']
Modifiability,"The TES backend previously hardcoded the value of preemptible to false [[BA-6004](https://broadworkbench.atlassian.net/browse/BA-6004)]. This change reads the value in from either the backend runtime or workflow runtime config. . I manually tested that the setting gets picked up from the config (workflow runtime setting of preemptible successfully overrides backend runtime setting; absence of preemptible setting uses default of false) and gets put in the task message sent to the TES API. . I also made a few minor updates to the TES docs to describe preemptible and fix a couple broken links. . A quick test was run as follows to view the TES task submission message sent by Cromwell:. - In one window, listen on port 5000 and display anything sent to it. `ncat -l 5000 -k`. - In another window, submit workflow to Cromwell configured to talk to TES on port 5000 . `java -Dconfig.file=app.config -jar /c/git/cromwell/server/target/scala-2.12/cromwell-48-366e431-SNAP.jar run test.wdl --inputs test.json; `; - Check that proper `""resources"":{""preemptible"":<value>}}` field is contained in the TES message. . [app.config.txt](https://github.com/broadinstitute/cromwell/files/3822302/app.config.txt); [test.json.txt](https://github.com/broadinstitute/cromwell/files/3822303/test.json.txt); [test.wdl.txt](https://github.com/broadinstitute/cromwell/files/3822304/test.wdl.txt)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5270:220,config,config,220,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5270,6,['config'],"['config', 'configured']"
Modifiability,The [Google backend documentation](https://github.com/broadinstitute/cromwell/blob/f1d4209a1917f95d77443e49572f29ec45f30137/docs/backends/Google.md) mentions in multiple places that a Service Account config should use the PEM file format. This is out of date. Service accounts should be specified as JSON not PEM. A/C: Mention in docs that JSON is the preferred way to represent service accounts and that PEM files should not be used. Explain as necessary what the differences are.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3838:200,config,config,200,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3838,1,['config'],['config']
Modifiability,"The `DrsCloudNioFileSystemProvider` was wrapping the retries of the `DrsPathResolver` with another set of `CloudNioRetry` retries. The product of these two retries at the previous configuration values would wait around 35 minutes (~:20 + 10 x ~3:30) to fail for each doomed attempt. That combined with a fairly wide scatter and a typo'd DRS path for `file` in code like . ```; task size {; input {; File file; }. Int file_size = ceil(size(file)); ...; }; ```; would completely block all 10 of the `IoActor`s [NIO threads](https://github.com/broadinstitute/cromwell/blob/develop/engine/src/main/scala/cromwell/server/CromwellRootActor.scala#L108). These changes remove the nested retries in the engine and dial back the patience for retries. If we want the retries to be more patient we'll probably have to make other code that is competing for `IoActor` threads more patient as well. Utility files for reproducing this error can be cherry picked from commit `ff7bddc8830802f7a606177d0eaf19c8f47ca865`. I don't know how to programatically link Google accounts to NIH accounts in Bond to be able to include this Centaur test in CI, though maybe we don't need to be linked to make sure this negative case errors within a reasonable timeout?. Workflow`9635fbf0-00b1-4635-b482-5a782cda5cd5` induced this problem in production, its metadata shows multiple `HaplotypeCaller` shards erroring out with ; ```; Failed to evaluate input 'disk_size' (reason 1 of 1): [Attempted 1 time(s)] - RuntimeException: Unexpected response during DRS resolution: RuntimeException: Could not access object 'drs://dg4.DFC/...'. Status: 500, reason: 'Internal Server Error', Martha location: 'https://.../martha_v3', message: 'Received error while resolving DRS URL. getaddrinfo ENOTFOUND dg4.dfc'; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6439:180,config,configuration,180,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6439,1,['config'],['configuration']
Modifiability,The `concurrent-job-limit` option is in the CHANGELOG but never appears in the documentation:. ```; backend {; ...; providers {; BackendName {; actor-factory = ...; config {; concurrent-job-limit = 5; ```. It should probably also make an appearance in the reference.conf file,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1841:165,config,config,165,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1841,1,['config'],['config']
Modifiability,The `cromwell-examples.conf` file demonstrates setting default workflow options using a section in the configuration file. This section is ignored!. We should either:; - Remove this example; - Allow default workflow options,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4151:103,config,configuration,103,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4151,1,['config'],['configuration']
Modifiability,"The `database.sql` artifact should follow the ""convention over configuration"" nature of [Rails](http://guides.rubyonrails.org/active_record_basics.html#convention-over-configuration-in-active-record), [GORM](http://docs.grails.org/3.1.11/guide/GORM.html#domainClasses), [Hibernate](http://docs.jboss.org/hibernate/orm/5.2/quickstart/html_single/#tutorial_annotations), etc. Classes should be named after the table, and replacing under_scores with CapitalizedNames. We can either:; 1. Liquibase update the database to match the scala names; 2. Update the scala to match the database naming; 3. Ignore the issue and not have a naming convention. Updating the scala seems like the least intrusive, avoiding any possibly time consuming database migrations and index rebuilding at the moment. However, developers may have put more effort into naming the scala tables and less into the sql tables. Liquibase updates could follow as part of a future issue, if/when the schema needs other modifications.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1423:63,config,configuration,63,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1423,2,['config'],"['configuration', 'configuration-in-active-record']"
Modifiability,"The `graph` action in womtool works fine, but when adding the `--all` argument, it gives the error:; ```; java -jar womtool-44.jar --all graph host_workflow.wdl ; Error: Unknown option --all; ```. <!--; Hi! Thanks for taking the time to report feedback. Before posting an issue over in Jira tracker, please check whether your question is already answered in our:; forum https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; documentation http://cromwell.readthedocs.io/en/develop/. Other forums:; FireCloud https://gatkforums.broadinstitute.org/firecloud/categories/ask-the-firecloud-team; WDL https://gatkforums.broadinstitute.org/wdl/categories/ask-the-wdl-team; CWL https://www.biostars.org/; -->. <!-- Are you seeing something that looks like a bug? Then great! You're almost in the right place. -->. <!-- You'll want to go to https://broadworkbench.atlassian.net/projects/BA/issues and then tell us: -->. <!-- Which backend are you running? -->. <!-- Paste/Attach your workflow if possible: -->. <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5126:1034,config,configuration,1034,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5126,1,['config'],['configuration']
Modifiability,"The assignment of these variables into each task's descriptor naturally fits in MaterializeWorkflowDescriptorActor rather than relying on the backends to re-implement it. Re-enable test `""assign default runtime attributes""` in `MaterializeWorkflowDescriptorActorSpec`",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1076:24,variab,variables,24,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1076,1,['variab'],['variables']
Modifiability,"The code used for localizing and executing the Cromwell exec script is embedded within tar.gz file in the cromwell code base. Today, each user of cromwell must locate the worker.tar.gz from cromwell's source code repository and provide a location of the file as a runtime attribute. If the path provided in the runtime attributes is a local path then cromwell streams the bytes to the OSS `Command.packagePath`. Instead of requiring the user to access cromwell's source code cromwell should move the file into an embedded resource under the directory `src/main/resources/`. The likely package location based on the other classes is `supportedBackends/bcs/src/main/scala/cromwell/backend/impl/bcs/`. Then using `better.files.File(java.lang.Object.getClass.getResource(""worker.tar.gz"").getPath)` the bytes can still be streamed to OSS. - https://github.com/aliyun/aliyun-openapi-java-sdk/blob/77e3f7639db351ced87d13b9a62f5566645f107c/aliyun-java-sdk-batchcompute/src/main/java/com/aliyuncs/batchcompute/pojo/v20151111/Command.java#L44-L47; - https://github.com/broadinstitute/cromwell/blob/31/supportedBackends/bcs/src/main/scala/cromwell/backend/impl/bcs/BcsAsyncBackendJobExecutionActor.scala#L245-L255; - https://github.com/broadinstitute/cromwell/blob/31/supportedBackends/bcs/src/main/scala/cromwell/backend/impl/bcs/worker.tar.gz. A/C:; - A user no longer needs to specify the path to the `worker.tar.gz` as it is an embedded resource; - Remove the `worker.tar.gz` reference from the `bcs_centaur.conf.ctmpl`; - Update cromwell docs on BCS so that specifying the worker path is not mandatory; - (Optional) Allow a configuration value / runtime attribute to still override the worker path for debugging purposes",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3520:1618,config,configuration,1618,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3520,1,['config'],['configuration']
Modifiability,The commented config in cromwell.examples.conf is correct so this just looks like a cut & paste issue in the docs.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3192:14,config,config,14,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3192,1,['config'],['config']
Modifiability,"The configuration option ""final_workflow_outputs_dir"" is misleading. ; What many users commonly want to do is just to copy final results to the folder in case if the workflow succeded. Right now this option copies standard nested-trash like ""MyWorkflow/bc5f9f3e-0daf-4ee3-b0c2-35971af26772/call-hello/execution"" Although this nested structure is useful for the debugging, it is not what we expect as a final result. ; I suggest giving an option for a folder where _only_ final files will be copied without any nested folders and debugging files/logs/whatsoever.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2915:4,config,configuration,4,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2915,1,['config'],['configuration']
Modifiability,The coursier plugin is a drop-in replacement for resolution and download of ivy artifacts. Resolution and downloading are done in parallel. https://github.com/coursier/coursier,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3015:13,plugin,plugin,13,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3015,1,['plugin'],['plugin']
Modifiability,"The cromwell API currently only allows users to submit the actual workflow file when they'd like to run a workflow. Also allow for a user to submit the URL pointing to the workflow file, which will then be consumed by Cromwell. . Edit: While the end goal is to not need a zip bundle for dependencies (as they can now be worked out via relative paths - cc @cjllanwarne ) -- that work is part of [3868](https://github.com/broadinstitute/cromwell/issues/3868). NB: TBD (@ruchim ?) what should we do with `file://` URLs? Perhaps a config option defaulting to off?",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3849:527,config,config,527,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3849,1,['config'],['config']
Modifiability,"The current HTML and javascript that is returned by the `/timing` endpoint as a result of #4408 (I think) does not lend itself to be inserted into an existing page. Even if the `<html>` and other tags were removed, there are javascript calls that don't work when placed elsewhere (e.g. [here](https://github.com/broadinstitute/cromwell/pull/4408/files#diff-cfb8178ef0c8be1b52e9f9a9b7129af9L136)). For this feature to be useful, it needs to either return straight html or javascript that is more portable.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4473:495,portab,portable,495,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4473,1,['portab'],['portable']
Modifiability,"The docker attribute specified in the ""default_runtime_attributes"" in cromwell.conf does not get picked up. My workflow fails with error: . ```; 2019-12-19 03:04:56,497 cromwell-system-akka.dispatchers.engine-dispatcher-24 INFO - WorkflowManagerActor Workflow 759c0000-c343-4466-a26b-aa627785; 89b0 failed (during InitializingWorkflowState): Task gcpp has an invalid runtime attribute docker = !! NOT FOUND !!; ```; The relevant portion of cromwell.conf; ```; computecfg_00 {; actor-factory = ""cromwell.backend.impl.aws.AwsBatchBackendLifecycleActorFactory""; config {; numSubmitAttempts = 10; numCreateDefinitionAttempts = 10; root = ""xxxxxx""; auth = ""default""; default-runtime-attributes {; queueArn = ""xxxxxx""; docker = ""ubuntu:latest""; }; ...; }; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5329:559,config,config,559,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5329,1,['config'],['config']
Modifiability,"The documentation for call caching could use some additional clarity - as a new user, it's fairly confusing and non-trivial to get right. Happy to break this out into multiple issues if necessary, but wanted to 'brain dump' them while it was fresh in my mind:. 1. In the [Call Caching](https://cromwell.readthedocs.io/en/stable/cromwell_features/CallCaching/) page, the *Docker Lookup* section has detailed documentation on the modes but never mentions the actual config key used to set it, nor the config string values for the different modes.; 2. Hyperlinks from the call caching section to other sections (and possibly elsewhere in the docs) are broken as it would appear there has been a change in the URL format - for example, on that same [Call Caching](https://cromwell.readthedocs.io/en/stable/cromwell_features/CallCaching/) page, ; > Call Caching can be enabled in your [Cromwell Configuration](https://cromwell.readthedocs.io/en/stable/cromwell_features/Configuring#call-caching). links to `/en/stable/cromwell_features/Configuring#call-caching`; when the current link path is `/en/stable/Configuring/#call-caching`. This is also true for the MySQL link on the page.; 3. As a user, I would expect links within documentation for a stable release to link to only ""stable"" assets. However, the Runtime Attributes link on the [Call Caching](https://cromwell.readthedocs.io/en/stable/cromwell_features/CallCaching/) page links to the develop version of the documentation instead. Similarly, the 'Example Providers Folder' section of the [Configuration](https://cromwell.readthedocs.io/en/stable/Configuring/) page links to the `develop` branch:; > You can find a description of options and example stanzas in the [Cromwell Example Configuration](https://www.github.com/broadinstitute/cromwell/tree/develop/cromwell.examples.conf), along with backend provider examples in the [Example Providers Folder](https://www.github.com/broadinstitute/cromwell/tree/develop/cromwell.example.backends).; 4. A",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4810:464,config,config,464,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4810,4,"['Config', 'config']","['Configuration', 'Configuring', 'config']"
Modifiability,The documentation for the `AWS 101 tutorial` and backend configuration needs to be updated.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3815:57,config,configuration,57,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3815,1,['config'],['configuration']
Modifiability,"The easiest way to capture and compare metrics from performance runs is to push them into GCP Stackdriver Monitoring. We have an abstraction in the service registry for Instrumentation implementations, see the [StatsDInstrumentationServiceActor].(https://github.com/broadinstitute/cromwell/blob/develop/services/src/main/scala/cromwell/services/instrumentation/impl/statsd/StatsDInstrumentationServiceActor.scala). ## Library; `libraryDependencies += ""com.google.cloud"" % ""google-cloud-monitoring"" % ""1.66.0""`. ## Acceptance Criteria . * Metrics can be labeled from global config settings. Namely: ; * Global config setting for Role (reader, worker, summarizer); * Setting for Host name (e.g. ""gce-cromwell-perfX""); * Setting for stable identifier for the perf test (e.g. ""call-cache-whitelist"").; * Logger can be configured using Service Account from Config.; * Performance runs are visible in GCP Stackdriver graphs with all labels. # Reference. * [Configuring stackdriver agent, useful for service account creation](https://cloud.google.com/monitoring/agent/install-agent); * [v3 monitoring javadoc](https://googleapis.github.io/google-cloud-java/google-cloud-clients/apidocs/com/google/cloud/monitoring/v3/package-summary.html); * [GCP Client Libraries for monitoring](https://cloud.google.com/monitoring/docs/reference/libraries)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4788:573,config,config,573,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4788,5,"['Config', 'config']","['Config', 'Configuring', 'config', 'configured']"
Modifiability,"The first step towards having great continuous performance assertions is owning the existing performance testing. This PR brings the performance tests under the auspices of the Cromwell team with the intention that we can thereafter perform, adapt, add to and maintain these processes ourselves. EDIT: See the change as a rendered `png` here: https://github.com/broadinstitute/cromwell/tree/cjl_diy_perf_testing/processes/release_processes#performance-testing",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4996:242,adapt,adapt,242,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4996,1,['adapt'],['adapt']
Modifiability,"The following config used to work (0.22):; ```; PBS {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; runtime-attributes = """"""; Int memory_mb = 1000; String pbs_cpu = ""1""; String? pbs_email; String? pbs_queue; String pbs_walltime = ""1:00:00""; """"""; }; }; ```. Note the specification of `pbs_email` and `pbs_queue` as Optional String type. On upgrading to 23 and starting the server, the process hangs and this appears in the logs:; ```; [ERROR] [12/05/2016 13:28:57.994] [cromwell-system-akka.dispatchers.engine-dispatcher-30] [akka://cromwell-system/user/SingleWorkflowRunnerActor/WorkflowManagerActor/WorkflowActor-8def86a5-13b1-4dc4-9cdf-d0ae2eedd7c9/WorkflowInitializationActor-8def86a5-13b1-4dc4-9cdf-d0ae2eedd7c9/PBS] Unsupported config runtime attribute WdlOptionalType(WdlStringType) pbs_email; java.lang.RuntimeException: Unsupported config runtime attribute WdlOptionalType(WdlStringType) pbs_email; 	at cromwell.backend.impl.sfs.config.DeclarationValidation$.fromDeclaration(DeclarationValidation.scala:41); 	at cromwell.backend.impl.sfs.config.DeclarationValidation$$anonfun$fromDeclarations$1.apply(DeclarationValidation.scala:17); 	at cromwell.backend.impl.sfs.config.DeclarationValidation$$anonfun$fromDeclarations$1.apply(DeclarationValidation.scala:17); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.Iterator$class.foreach(Iterator.scala:893); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1336); 	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72); 	at scala.collection.AbstractIterable.foreach(Iterable.scala:54); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.AbstractTraversable.map(Traversable.scala:104); 	at cromwell.backend.impl.sfs.config.DeclarationValidation$.fromDeclarations(DeclarationValida",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1737:14,config,config,14,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1737,7,"['Config', 'config']","['ConfigBackendLifecycleActorFactory', 'config']"
Modifiability,"The following wdl has the wrong variable name in the output section of the task:. ```; workflow GenotypeGVCFsComparison {; File combined_gvcf_input = ""gs://dsde-palantir/SnapshotExperiment2015/CEUTrio/gvcfs/NA12878.d691bf66-37af-4375-9c09-6a6607f322e8.g.vcf.gz"". call IndexVCF{; input:; combined_gvcf = combined_gvcf_input,; disk_size = 200; }; }. task IndexVCF {; File combined_gvcf; Int disk_size. command {; /usr/gitc/tabix ${combined_gvcf}; }; runtime {; docker: ""broadinstitute/genomes-in-the-cloud@sha256:d7aa37fc8351074a2d6fb949932d3283cdcefdc8e53729dcf7202bee16ab660a""; memory: ""13 GB""; cpu: ""1""; disks: ""local-disk "" + disk_size + "" HDD""; }; output {; File gvcf = ""${gvcf}""; File gvcf_index = ""${gvcf}.tbi""; }; }; ```. In Version 24 of Cromwell this WDL breaks the whole cromwell server. In Version 25 the only the workflow breaks which is a big improvement, however it runs the task to completion before breaking. It would be nice to validate the WDL before running the task to make sure the variables are named correctly.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2226:32,variab,variable,32,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2226,2,['variab'],"['variable', 'variables']"
Modifiability,"The green step of red/green/refactor, but wow does this need refactoring.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/20:28,refactor,refactor,28,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/20,2,['refactor'],"['refactor', 'refactoring']"
Modifiability,"The high level overview:; 1. Rename `WdlBinding` to `WdlNamespace`; 2. Move AST specific functions into `AstTools`. In more detail:; 1. `WdlBinding` was feeling poorly named since the import statement was introduced. All of a sudden this object became recursive and started to really resemble how namespaces worked in WDL. And that's not on accident because the object structure is laid out exactly like the lexical structure of WDL. So naturally we would call ""the thing that holds workflows and tasks"" as a ""namespace"".; 2. The main entry point into the binding layer is the `WdlNamespace` object, in which users call `WdlNamespace.load(...)` with either String or File parameters. Client code now looks like this:. ``` scala; val namespace = WdlNamespace.load(new File(args(0))); namespace.workflows; namespace.namespaces; namespace.tasks; ```; 1. All `Ast => Workflow | Call | Task | ...` functions are in `class WdlNamespace`. All AST related tools are now in `AstTools` (things like `findAsts`, `terminalMap`). `object WdlNamespace` only contains various `load()` functions.; 2. Changed all variable references to 'binding' in any way to reference 'namespace' instead.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/40:1097,variab,variable,1097,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/40,1,['variab'],['variable']
Modifiability,The idea of this change is to allow the user to add custom htcondor configuration to the submit file.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1639:68,config,configuration,68,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1639,1,['config'],['configuration']
Modifiability,"The mint team ran a group of ~200 10x workflows where 18 failed due to PAPI error code 10.14. Many of the tasks were stuck waiting for quota. For example, the following non-preemptible task ran for 3h 51m before failing with this error:. `CellRanger.cellranger_count:NA:1 failed. The job was stopped before the command finished. PAPI error code 10. 14: VM ggp-16203705785274897556 stopped unexpectedly.` . It would be useful if the `max_retries` runtime parameter included retrying tasks that fail with the above error, so that the workflow does not need to be manually re-run after failing. **Configuration info**:; Cromwell version: Cromwell-as-a-Service (caas-prod) version `35-5f86a05-SNAP`; Backend: PAPI v1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4363:594,Config,Configuration,594,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4363,1,['Config'],['Configuration']
Modifiability,"The parameters available to config scripts are mostly undocumented. A list can be reverse engineered using the cromwell.examples.conf file, and by forcing the parser to crash - which prints the generated submit wdl script to the log. I could then build this config:. ```; submit-docker = """"""; /usr/bin/env ${job_shell} ${script}; echo ${job_name}; echo ${cwd}; echo ${out}; echo ${err}; echo ${script}; echo ${job_shell}; echo ${docker_cid}; echo ${docker_cwd}; """"""; submit = """"""; /usr/bin/env ${job_shell} ${script}; echo ${job_name}; echo ${cwd}; echo ${out}; echo ${err}; echo ${script}; echo ${job_shell}; """"""; ```. (note while String job_id is available in the submit task, using it causes a crash-loop). . The values of cwd and docker_cwd make sense, cwd (in both scripts) refers to the 'shared file system' path to the cromwell created directory, and docker_cwd strips everything before 'cromwell-executions'. I do not see the necessity for docker_cwd, but fair enough. However 'out', 'err' and 'script' do not follow the pattern. In 'submit' they are sfs paths, but in submit-docker they are docker paths. This kind of inconsistency, combined with lack of documentation makes cromwell extremely frustrating to use.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4212:28,config,config,28,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4212,2,['config'],['config']
Modifiability,"The plugin is really nice when developing in the IDEs. Unfortunately, pycharm is not supported and evaluation workflows will probably be majority python scripts.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1264:4,plugin,plugin,4,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1264,1,['plugin'],['plugin']
Modifiability,"The purpose of this PR is to fix issue #4586.; It turns out that Cromwell looks for the ad hoc files in the wrong location while using AWS. These files placed in the S3 bucket, while Cromwell expects them to be in the root execution directory. There were already two PRs from us ([1](https://github.com/broadinstitute/cromwell/pull/5064), [2](https://github.com/broadinstitute/cromwell/pull/5057)) aimed to solve this issue, but these were not the appropriate solutions.; This time we found what part of GCP backend handles these ad hoc files and implemented the same logic on AWS. Also, in order to reduce the amount of duplicate code, we made a small refactoring.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5097:653,refactor,refactoring,653,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5097,1,['refactor'],['refactoring']
Modifiability,"The spec allows for a workflow to be called from within another workflow. This feature would be tremendously beneficial for when we would like to run a workflow on more than a single sample, but still retain the ability to run a single sample through a single sample workflow. The real benefit would be post-workflow tasks that could be imported to further interrogate the array of single sample workflow outputs. I understand something similar could be achieved using a scatter block. Unfortunately, nested scatter blocks are not functional yet (see [#838](https://github.com/broadinstitute/cromwell/issues/838)). Additionally, a solution that integrates modular workflow definitions would be cleaner, more user friendly, maintainable etc. ```; call namespace.workflow {; input: foo=bar; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/839:723,maintainab,maintainable,723,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/839,1,['maintainab'],['maintainable']
Modifiability,"The use case here is that a user wants to pass in a dos url, with a specific docker to handle the localization of that docker. Cromwell's job is to put both those pieces together to allow for custom localization in addition to the default localization performed on the filesystems declared in the Cromwell config. Requirements:; 1) A new option that allows for one to pass in the custom localization docker (globally or per-workflow); 2) Parse and accept dos urls as task inputs; 3) Feed the dos url + the final destination for that file to the docker ; 4) Fail gracefully if any functions (read_lines, size, etc) are performed on this input type, not required for this stage.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3759:306,config,config,306,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3759,1,['config'],['config']
Modifiability,"The way this works for now is:; In JES configuration you need to specify an `authenticationMode` parameter which can take one of those 2 values: `service_account` or `refresh_token`; `service_account` works exactly the same way as it did before; `refresh_token` will require 2 fields to be passed as workflow options:; `account_name` and `refresh_token`. Depending on what is available, the JES backend will create, only if necessary and at workflow initialization time, a json file (gcloudauth.json) and upload it to the root directory of the workflow.; Currently this json file can contain 2 types of information:; - Docker credentials: These are optional and can be specified in the `jes` section in application.conf. They look like this:. ```; dockerAccount = ""my.docker@account.com""; dockerToken = ""mydockertoken""; ```. If they are specified a ""docker"" value will be added to gcloudauth.json containing those values.; This will allow using a private docker image that would not be accessible otherwise.; This functionality was mostly already there from Kristian PR, I just moved the credential location from gcs to conf.; - User credentials: These need to be added as workflow options : . ```; {; ""account_name"": ""myaccount@broadinstitute.org"",; ""refresh_token"": ""refresh_token""; }; ```. Again if in RefreshToken mode, they need to be there for every workflow call or an exception will be thrown at initialization time.; If they are there they will be added to the gcloudauth.json in the same way docker crednetials are, under a ""gcloud"" value. You should then get permission to localize input files that are only accessible to this user. So depending on what is provided (docker info, user info), you can get a gcloudauth.json with both credentials, only one, or no file at all. In any case the JES backend will try to delete this file when the workflow reaches a terminal state.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/190:39,config,configuration,39,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/190,1,['config'],['configuration']
Modifiability,The workflow; ```; version 1.0. workflow member_access {; Object myObj = object { an_int: 5 }; if (myObj.an_int == 10) {; Boolean asdf = true; }; }; ```; fails to validate with error; ```; Failed to create wom Graph (reason 1 of 1):; Failed to process workflow definition 'member_access' (reason 1 of 1):; Invalid type for condition variable: Any; ```; It appears that the type checker is not correctly evaluating the type of values reached via member access.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3790:333,variab,variable,333,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3790,1,['variab'],['variable']
Modifiability,"The workflow; ```; version 1.0. workflow scatter_chain {; Array[Pair[Int, Int]] pairs = [(1, 2), (3, 4), (5, 6)]; scatter (p in pairs) {; Int x = p.left; }; }; ```; used to fail WOM validation because expressions consisting of member access on the scatter variable were erroneously counted as being consumed within the scatter's inner graph. This PR stops this misaccounting. ( On Friday @cjllanwarne and I hypothesized that `ifElementUnlinkedValueConsumer` would need a similar adjustment, but I no longer think this is the case; an `IfElement` does not create a new variable in the scope of its graph like a `ScatterElement` does. )",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3763:256,variab,variable,256,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3763,2,['variab'],['variable']
Modifiability,"There are a few development activities that are blocked by needing Jeff's computer. It has something to with the encryption of a configuration something something... more to be filled in by Jeff. . @geoffjentry I would really like you to work on unblocking this when you have your work computer back. If there's anything across other teams or BITs etc that you need, just say the word.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2442:129,config,configuration,129,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2442,1,['config'],['configuration']
Modifiability,"There is a fairly large need to support custom container engines in Cromwell, for those HPC systems that cannot run docker. This is discussed in the PR here: #4635. . Currently the only hook we have for custom container engines is the `submit-docker` field, which is a script that runs when a task is run that specifies a docker image. This lets us download the image from docker, and convert it to a custom format (probably the Singularity SIF format) before submitting a job to the queue that runs the image. However, in the case of a scatter job, this means downloading the same Docker image N times, converting it to SIF format N times, and using up N times as much storage as we would like. This issue is discussed in my comment [here](https://github.com/broadinstitute/cromwell/pull/4635#issuecomment-463890367), and a number of preceding comments. If we had another hook for the `cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory`, called `pull-docker` that was run each time a Docker image needs to be pulled, then we could resolve this issue. The hook could run each time a new image is encountered in a given workflow, but only once each time, so that a scatter job would result in only one call to the hook. We would then have to find some way for the image built in the `pull-docker` hook to be communicated to the `submit-docker` hook. The default value of `pull-docker` would be some kind of no-op, because this is not needed using Docker itself. However, it would be invaluable for custom engines.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4673:913,config,config,913,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4673,2,"['Config', 'config']","['ConfigBackendLifecycleActorFactory', 'config']"
Modifiability,There is a need to support:; 1. Configurable docker command in HtCondor.; 2. Allow the use of soft-links in dockerized jobs.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1433:32,Config,Configurable,32,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1433,1,['Config'],['Configurable']
Modifiability,"There seems to be a failure mode where a workflow fails during centaur JES testing because the JES job can't find the auth JSON:. ```; java.lang.Exception: Task readFromCache.find:NA:1 failed. JES error code 3. Message: unable to load extra config: download from ""gs://cloud-cromwell-dev/cromwell_execution/travis/readFromCache/009bccc8-8e1b-49b3-bc7c-7d15c8255482/009bccc8-8e1b-49b3-bc7c-7d15c8255482_auth.json"" failed: exit status 1: Copying gs://cloud-cromwell-dev/cromwell_execution/travis/readFromCache/009bccc8-8e1b-49b3-bc7c-7d15c8255482/009bccc8-8e1b-49b3-bc7c-7d15c8255482_auth.json...; / [0 files][ 0.0 B/ 133.0 B] ; NotFoundException: 404 gs://cloud-cromwell-dev/cromwell_execution/travis/readFromCache/009bccc8-8e1b-49b3-bc7c-7d15c8255482/009bccc8-8e1b-49b3-bc7c-7d15c8255482_auth.json does not exist.; ```. This happened on the readFromCacheFalse JES centaur test. logs are at `gs://cloud-cromwell-dev/cromwell_execution/travis/centaur_workflow/61e52cbe-50f5-4e45-b8fb-a61c1f902426/call-centaur/cromwell_root/logs/`",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2405:241,config,config,241,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2405,1,['config'],['config']
Modifiability,"Things Changed; - added a cromwell-master, which refreshes status metadata. There can be only one.; - created a pool of cromwell_norefresh, which has status refresh turned off, these can scale; - found race condition when multiple cromwells try to create the liquibase lock table at once, configured to have master go first; - updated scripts/compose to handle the above two kinds of cromwell; - increased to 100 batches of 10 workflow each; - changed timeout script to show number of completed workflows and break when done; - delete database at start of run, so the above works; - ran heartbeats in auto-commit mode rather than in a single transaction; - dump out logs at end of run for debugging. Things I'd like to share; - Lock Ordering in SELECT...FOR UPDATE no es bueno, there are great feature in MYSQL v8 (SKIP LOCKED) but we can't use those yet; - how to configure mysql for query logging, and what it shows; - heartbeat batches were never a batched update, just a big transaction; - slick terminology can give give the wrong intuition; - impact of cleaning db before each run; - No deadlocks!",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4508:289,config,configured,289,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4508,2,['config'],"['configure', 'configured']"
Modifiability,This PR . - separates out the logic for getting the next workflow to archive and number of workflows left to archive; - adds a config option on how often we want to calculate number of workflows left to archive and schedules it ; - adds a comment for the reason behind naming convention of archived metadata files. Closes https://broadworkbench.atlassian.net/browse/BW-653; Closes https://broadworkbench.atlassian.net/browse/BW-658,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6325:127,config,config,127,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6325,1,['config'],['config']
Modifiability,"This PR add support for:; - GenericS3 servers, ie non-AWS S3 services, such as CEPH or MinIO; - Connecting S3 storage to the TES backend driver. Remaining work:; - [ ] Add support for multiple GenericS3 endpoints in config file; - [ ] Add ability to configure GenericS3 endpoint using workflow options",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6737:216,config,config,216,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6737,2,['config'],"['config', 'configure']"
Modifiability,"This PR addresses two bugs from WX-1260:; 1. An `echo` command that included asterisks wasn't wrapped in double quotes, causing an issue in some environments (the user's) but not others (the developer's). Added double quotes so this issue occurs in no environments. 2. The Script Preamble that exports the SAS token environment variable was running in a bash subshell, which means that the environment variable it populated wasn't available in the user's parent shell that is actually executing the task.; - To fix this, I added the option for script preambles to be executed in a bash subshell, or not. My thinking:; - It's generally good hygiene for scripts to run in their own subshell, and I didn't want to change anything about the GCP behavior, so I left that functionality as is.; - I didn't want to write a sas token to file in the subshell for the parent shell to read. Writing tokens to file seems not great for security.; - In order for the environment variable to be visible to the user command, I allowed the TES script to run in the parent shell. This bug revealed a gap in my testing: I had been confirming that my script could acquire the token successfully and correctly, but I hadn't actually tried to use that token inside the user command block. The concept of subshells eluded me at the time. After making this change, I've confirmed that the environment variable is indeed useable in the command block.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7326:328,variab,variable,328,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7326,4,['variab'],['variable']
Modifiability,"This PR adds 3 metrics related to metadata table size:. - cromwell.metadata.table.data_free_in_gib; - cromwell.metadata.table.data_length_in_gib; - cromwell.metadata.table.index_length_in_gib. Below is a graph from hosting Grafana locally. Since my local database is small, the numbers seen in graph are actually MiB even though it says GiB (I had tweaked the code to convert values into MiB) with metrics interval at 30 seconds:. ![Screen Shot 2021-06-28 at 2 27 56 PM](https://user-images.githubusercontent.com/16748522/123685780-0be2db80-d81d-11eb-97af-1c54fbb9431a.png). TODO: After this PR is reviewed, create a fc-develop PR to set the `metadata-table-size-metrics-interval` config for summarizer. Closes https://broadworkbench.atlassian.net/browse/BW-722",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6382:681,config,config,681,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6382,1,['config'],['config']
Modifiability,"This PR adds `WORKFLOW_NAME`, `TASK_INPUTS`, `TASK_DISKS`, and `MONITORING_CONFIG` environment variables for `MonitoringAction` in PAPIv2 backend. These variables are used to pass details about task inputs and disk mappings (both in JSON form), along with an image-specific config string (e.g. `project-id.dataset-id.table-id` for `quay.io/broadinstitute/cromwell-monitor-bigquery`), into the container specified through the existing `monitoring_image` option. It also adds `bigquery.insertdata` OAuth scope, to be used for streaming monitoring data into BigQuery (@adrazhi seems to approve scope extension).; ; This PR will enable us to:; - stream monitoring data at scale into BQ (much more so than was possible through Stackdriver),; - build detailed models for prediction of runtime resource utilization, using BQ or external tools (e.g. Looker); - easily detect runtime failure modes such as running OOM. (Please see https://github.com/broadinstitute/cromwell-task-monitor-bbq for more info on BQ use case). However, the proposed changes are not specific to BQ (apart from the scope), and could be used for other `monitoring_image` implementations in the future, thanks to the new `monitoring_config` option for PAPIv2 backend. **Please note**: this is an initial implementation that's **not yet ready for a merge**. For example, `TASK_INPUTS` are not serialized correctly yet. We intend to add more commits to implement it fully. However, we're soliciting early feedback and review. Interested parties: @kshakir, @benjamincarlin, @rexwangcc, @mohawkTrail, @ruchim, @abaumann",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5028:95,variab,variables,95,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5028,3,"['config', 'variab']","['config', 'variables']"
Modifiability,"This PR adds a config option for user defined retries. With `memory-retry` the user can specify an array of strings which when encountered in the `stderr` file by Cromwell, allows the task to be retried with a factor also mentioned in the config. JIRA issue [link](https://broadworkbench.atlassian.net/browse/BA-5933).",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5180:15,config,config,15,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5180,2,['config'],['config']
Modifiability,"This PR adds initial support for tasks to run on an AWS Batch based backend It uses a configuration similar to other backends as documented in the AWS Batch 101 documentation (included in the PR). For now, the biggest gap is the lack of S3 Filesystem support. Job output is copied to the local filesystem for integration with the rest of the workflow. I will establish a new issue for that and issue a separate PR for that in the future. There are a few warts commented in the AwsBatchAsyncBackendJobExecutionActor that are related to this copying. I'd appreciate input on this, although ultimately I expect the warty code to be removed when the S3 Filesystem support is complete.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3613:86,config,configuration,86,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3613,1,['config'],['configuration']
Modifiability,This PR adds support for fetching Github token for user from ECM to support private workflows. Testing; I have tested these changes in Workflows and Cromwell Runner apps in dev by manually editing the config as well as updating the deployment with Cromwell image containing the changes. Screenshot of a successful run of private workflow. ![image](https://github.com/broadinstitute/cromwell/assets/16748522/fcd5bf8f-df9f-42de-a431-639681371c74). Closes ; - https://broadworkbench.atlassian.net/browse/WM-2500; - https://broadworkbench.atlassian.net/browse/WM-2502,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7392:201,config,config,201,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7392,1,['config'],['config']
Modifiability,This PR enables sending metrics to Stackdriver in Cromwell Perf (and removes StatsD configuration).,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5036:84,config,configuration,84,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5036,1,['config'],['configuration']
Modifiability,This PR implements DRS file system (initial support) using `cloud-nio` framework. Currently the filesystem can only support size and fileHash functions. It also removes Demo DOS filesystem. Config changes:; The config for localization of DRS paths remain the same. But the Martha section of drs config is moved to core/...../reference.conf (as compared to demo-dos filesystem config). . Closes #4291,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4456:190,Config,Config,190,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4456,4,"['Config', 'config']","['Config', 'config']"
Modifiability,"This PR introduces two new config settings: `max-scatter-width-per-scatter` and `total-max-jobs-per-root-workflow`. Their purpose is:. - max-scatter-width-per-scatter: Maximum scatter width per scatter node. If a workflow has a scatter width more than this number, Cromwell will fail the workflow; - total-max-jobs-per-root-workflow: Total max. jobs that can be created per root workflow. If workflow tries to create jobs more than this number, Cromwell will fail the workflow by: no longer creating new jobs and let the jobs that have already been started finish, and then fail the workflow. Remaining: Update the default values of these two configurations in `reference.conf` based on threshold determined from Performance Tests.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4037:27,config,config,27,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4037,2,['config'],"['config', 'configurations']"
Modifiability,"This PR is based on a comment in the Slack, and ongoing conversation in [How to configure proxies?](https://broadworkbench.atlassian.net/browse/BA-5695) (which stems from #5006). Essentially, I don't want Cromwell to lookup my container when I provide it as a digest, because if the request fails (because Cromwell isn't respecting the system proxy), I still want call-caching to work. The main reason Cromwell seems to want to lookup the external registry is for the docker size which gets logged to metadata and doesn't seem to be used again. Disabling the digest-lookup doesn't actually stop the digest being looked up and disabled call-caching anyway.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5545:80,config,configure,80,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5545,1,['config'],['configure']
Modifiability,This PR will allow Martha's url to be passed as an environment variable during `docker run`. The variable can be set as `--env MARTHA_URL=<url>`.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3924:63,variab,variable,63,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3924,2,['variab'],['variable']
Modifiability,"This change attempts to fix the deadlock between [starting workflows](https://github.com/broadinstitute/cromwell/blob/develop/database/sql/src/main/scala/cromwell/database/slick/WorkflowStoreSlickDatabase.scala#L65) and [writing heartbeats](https://github.com/broadinstitute/cromwell/blob/develop/database/sql/src/main/scala/cromwell/database/slick/WorkflowStoreSlickDatabase.scala#L75) by removing transaction semantics from the heartbeat write query. This way, the second query no longer locks multiple rows at once. I am using Slick's [`withPinnedSession`](http://slick.lightbend.com/doc/3.2.0/dbio.html#transactions-and-pinned-sessions) to preserve the efficiency gain of having all the queries in a single session. The MySQL query log shows that `transactionally` and `withPinnedSession` both cause queries to execute in a single session, as evidenced by the setting of session variable `autocommit`:. - `database.run(action.transactionally)`:; ```; Query SET autocommit=0; Query update `WORKFLOW_STORE_ENTRY` set `HEARTBEAT_TIMESTAMP` = '2018-08-20 15:43:00.194' where `WORKFLOW_STORE_ENTRY`.`WORKFLOW_EXECUTION_UUID` = 'c8482924-ef9e-4b3f-930c-ab5f023eeb78'; Query update `WORKFLOW_STORE_ENTRY` set `HEARTBEAT_TIMESTAMP` = '2018-08-20 15:43:00.194' where `WORKFLOW_STORE_ENTRY`.`WORKFLOW_EXECUTION_UUID` = 'e79a1ee7-dd21-4a55-b52d-03f50031b75e'; Query update `WORKFLOW_STORE_ENTRY` set `HEARTBEAT_TIMESTAMP` = '2018-08-20 15:43:00.194' where `WORKFLOW_STORE_ENTRY`.`WORKFLOW_EXECUTION_UUID` = 'f0bae536-32c2-4f15-93af-f03515668faf'; Query update `WORKFLOW_STORE_ENTRY` set `HEARTBEAT_TIMESTAMP` = '2018-08-20 15:43:00.194' where `WORKFLOW_STORE_ENTRY`.`WORKFLOW_EXECUTION_UUID` = '9892d137-40b5-420c-94b4-88481c8ad249'; Query update `WORKFLOW_STORE_ENTRY` set `HEARTBEAT_TIMESTAMP` = '2018-08-20 15:43:00.194' where `WORKFLOW_STORE_ENTRY`.`WORKFLOW_EXECUTION_UUID` = '4447f78f-85d2-4c27-8d2f-ea230ca130c1'; Query update `WORKFLOW_STORE_ENTRY` set `HEARTBEAT_TIMESTAMP` = '2018-08-20 15:43:00.19",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4022:883,variab,variable,883,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4022,1,['variab'],['variable']
Modifiability,"This change set adds support for inputs in the [NCBI SRA](https://www.ncbi.nlm.nih.gov/sra) via [fusera](https://github.com/mitre/fusera). A user has to provide their NGC authentication file and a fusera Docker image in their configuration file like so:. ```; filesystems {; sra {; class = ""cromwell.filesystems.sra.SraPathBuilderFactory""; docker-image = ""<some hosted docker path>/fusera:latest""; ngc = ""bmNiaV9nYXAfiwgAAAAAAAADBcHBDYQgEADAv1XQAGYXcfErUe5x0diCiFESA0Y8/VD8zTzrlXwMDEsoII9usPT5znZSmTqUohaSg5Gay14TbxsluMGOSBuqDEKefvbwCzv3BAAKoexb5uIbjjg7dq/p9mH7A5VTImxjAAAA""; }; }; ```. The `ngc` parameter must contain the base64-encoded NGC credential file. The one provided here is an example from the NCBI site.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3950:226,config,configuration,226,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3950,1,['config'],['configuration']
Modifiability,"This changeset extends our metadata large object write strategy to the engine database. There are two pieces, both of which come into play only when using PostgreSQL and only when the relevant configuration is present:; * At the end of the liquibase migration, make all tables owned by a configured role.; * Add a `SET LOCAL ROLE` to the beginning of all transactions, to ensure the transaction runs as the right role. . Associated terra-helmfile PR: https://github.com/broadinstitute/terra-helmfile/pull/5081",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7366:15,extend,extends,15,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7366,3,"['config', 'extend']","['configuration', 'configured', 'extends']"
Modifiability,This class no longer appears to be used from production code and is in the way of CROM-6862 refactors so au revoir,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6670:92,refactor,refactors,92,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6670,1,['refactor'],['refactors']
Modifiability,"This compiler flags allows the compiler to take types of kind `F[_,_]` and infers `F[_]` by parameterizing the right most argument and fixing the other ones. This allows us to omit type args when traversing to `Either` and `ErrorOr`, because scala can now see them as shape `F[_]` instead of ""you gave me a type w/ 2 type args and I was expecting one"". **I did a find/replace on all our traverses, this may be controversial**, chime in if you disagree. [Longer explanation](https://gist.github.com/djspiewak/7a81a395c461fd3a09a6941d4cd040f2)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3580:92,parameteriz,parameterizing,92,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3580,1,['parameteriz'],['parameterizing']
Modifiability,"This enhancement allows EFS or any parallel file system that can be mounted to the computes, to be accessible to the workflow run through cromwell with AWS backend.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5070:5,enhance,enhancement,5,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5070,1,['enhance'],['enhancement']
Modifiability,This implements part of the spec change that handles inputs https://github.com/openwdl/wdl/pull/359. A rewrite from https://github.com/broadinstitute/cromwell/pull/5523 . This foregoes the restriction that the specs requires that all required inputs should be set at the top-level workflow. It does enable using bubbled up inputs when the meta flag is set. The restrictions should be enabled on biscayne. But I have no idea how to implement that in this code base. Some help is needed. For now implementing this in the new base at least implements part of the spec.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5562:103,rewrite,rewrite,103,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5562,1,['rewrite'],['rewrite']
Modifiability,"This implements the remaining pieces necessary to mount volumes from the container host to the container. I am using a runtime attibutes disk format that looks like the following:. ```disks: ""local-disk, /mount/point, /other/mount/point""```. I add a random guid ""task id"" to the host directory to allow for multiple containers on the host instance. The task id is generated at run time to disambiguate this job from any other job, and is passed through to the container in the environment variable AWS_CROMWELL_TASK_ID) to allow for tracking at a later stage of the project. The host mount scheme is designed in the following manner:. /mount/point/<taskid>. Contrary to the suggestion in issue #3744, the task id is added to the end. This is a conscious decision such that mounts that refer to external volumes can be setup such that the filesystems can properly match the type of container workloads that might be using them. Note that when these mounts have files copied to S3, this should scheme should be reversed (e.g. <taskid>/mount/point to encourage proper spread and optimal S3 performance. This will be addressed when #3804 is implemented.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3835:489,variab,variable,489,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3835,1,['variab'],['variable']
Modifiability,"This introduces a ~~`CallDescriptor`~~ `JobDescriptor` abstraction that I hope resembles what we'd want in the world of pluggable backends. Although this is a backend class, it holds a reference to a `WorkflowDescriptor` which still has tons of references to engine things which we plan to refactor out, possibly into backend. `CallDescriptor` currently interacts with `BackendCall`s because that's what Cromwell has right now. :smile: . There was one very special bit of weirdness about our backend handling exposed by `RetryableCallsSpec` where the backend passed to `WorkflowManagerActor` is not necessarily the same backend used to build `WorkflowDescriptor`s. :frowning: That could use some extra scrutiny by reviewers.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/502:290,refactor,refactor,290,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/502,1,['refactor'],['refactor']
Modifiability,"This is a PR to the already existing TESK PR to add some docs and a ""global filesystem config for ftp"". The reason is this:. - FTP servers can decide to limit how many connections they allow per IP address per user; - Cromwell Filesystems are defined as ""PathBuilderFactories"". A factory is configurable at the backend level and the engine level. Meaning there will be one instance of the factory per backend that chooses to enable a given filesystem, + one for the engine if the engine wants to support it too.; - However since we need to manage a pool of connections to the FTP server over the entire Cromwell instance, we can't create a new pool per factory.; - This introduces a ""global"" or ""singleton"" configuration object that can be defined in the root filesystem configuration (as java class path) and will be shared among all factories.; - A factory can choose to use it or not, if not then everything is as it was. If yes, a single instance of this singleton object will be created and passed to the factories when they're instantiated",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4074:87,config,config,87,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4074,4,['config'],"['config', 'configurable', 'configuration']"
Modifiability,"This is a branch off of ks_liquibase_updates (since it has the most updated metadata CallCacheSpec requires to pass). The last few commits are to testing, the remainder is Khalid's hard work. Key changes:; - altered travis cromwell config to enable call-caching; - altered centaur.wdl in a way to checkout specific centaur branch (needs to be undone)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1459:232,config,config,232,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1459,1,['config'],['config']
Modifiability,"This is a duplicate of #5478 but with a less intrusive code change. I bypass all the interfaces by setting a variable using a method. ~~It is gruesome, but much less lines need to be changed. I have some changes that it is slightly nicer. It still involves a `var` but now it is set only for the sfsBackend.~~ EDIT: It now looks quite OK. Only two lines of code in cromwell's general code. The rest of the bug is fixed specifically for the sfsBackend only. Most of the lines changed are the extra tests.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5495:109,variab,variable,109,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5495,1,['variab'],['variable']
Modifiability,"This is a prototype backend that communicates via the GA4GH task execution [schema](https://github.com/ga4gh/task-execution-schemas). The reference implementation of the task server that we have been developing against is [here](https://github.com/bmeg/task-execution-server/tree/develop). This is a work in progress and definitely could use some feedback from you with regards to how to better fit this in with your current code base and future development plans. . In the coming weeks we plan to implement unit tests, add documentation and refactor the code based on your recommendations.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1816:542,refactor,refactor,542,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1816,1,['refactor'],['refactor']
Modifiability,"This is a resubmission by the Joint Genome Institute of https://github.com/broadinstitute/cromwell/pull/6140 to provide an option to disable digest lookups to support private docker registries with private images. We have long running workflows at JGI that use private images which cannot take advantage of Cromwell's call caching feartures - this is blocking a major analysis workflow's migration to Cromwell. Given that JGI also has other Docker images which are non-public, it is only the first of what is likely to be many other production workflows that cannot be used with Cromwell, blocking our institutional goal of consolidating JGI analysis workflows on Cromwell as our workflow engine. . Changelog:. Added config option docker.perform-registry-lookup-if-digest-is-provided with default True (https://github.com/broadinstitute/cromwell/commit/e9965d8f9a385b289f15b23b3fb923ecb8c0ea38); Added logic to DockerConfiguration.scala to sendDockerRequest if performRegistryLookupIfDigestIsProvided is true, else just lookupKvsOrBuildDescriptorAndStop.; Motivation:. Cromwell only allows call-caching when a digest is provided.; The digest registry lookup fails because Cromwell isn't respecting the system proxy.; This disables call-caching, even though we've provided the digest.; From original PR:. This PR is based on a comment in the Slack, and ongoing conversation in How to configure proxies? (which stems from https://github.com/broadinstitute/cromwell/issues/5006). Essentially, I don't want Cromwell to lookup my container when I provide it as a digest, because if the request fails (because Cromwell isn't respecting the system proxy), I still want call-caching to work. The main reason Cromwell seems to want to lookup the external registry is for the docker size which gets logged to metadata and doesn't seem to be used again. Thanks @mcovarr for the initial feedback, and sorry it took so long to action your suggestions. I've moved this to an internal branch so tests run automatical",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7114:717,config,config,717,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7114,1,['config'],['config']
Modifiability,"This is a unmodified copy of the Azure NIO library that is a part of the Azure SDK, configured to be built as a package. The intent here is to be able to modify it to support some of the more Terra specific needs we have from the NIO interface without having to start from scratch.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7168:84,config,configured,84,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7168,1,['config'],['configured']
Modifiability,"This is an issue to track the same problem that @ffinfo has raised on Gitter and PR #1346. The scenario for us is an HPC cluster environment with a scheduler (SGE or PBS) that strictly enforces walltimes; having jobs be killed by the scheduler (without producing rc file) when they exceed the requested walltime is, if not exactly common, not that rare either. The hacky non-async solution I have been using (up until the nice configurable backends of release 0.21 changed everything in backend-land) was to have two check cycles, a frequent cheap one to see if rc existed and occasional expensive one to poll the scheduler itself: https://github.com/delocalizer/cromwell/blob/develop/engine/src/main/scala/cromwell/engine/backend/pbs/PbsBackend.scala#L128-L166",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1499:427,config,configurable,427,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1499,1,['config'],['configurable']
Modifiability,"This is even more vestigial than #1386, all the code was removed but for some reason the variable was left behind.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1390:89,variab,variable,89,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1390,1,['variab'],['variable']
Modifiability,"This is green and actually does appear to work with a couple of mods to the three-step workflow, one to fake the `ps` for deterministic results, another to fix a bug in the wc command. But this seriously needs refactoring:; 1. Proper concurrency handling for store updates. The current code is awful, the mutable stores are just passed around the various concurrently executing actors. Probably the stores should be behind an actor which the CallActor and WorkflowActor would `ask` for queries or updates, and then compose a `pipeTo` with the `Future` response.; 2. While the potential parallelism of the cgrep and wc calls does appear to work as intended, the current test does not assert this.; 3. The call dependency determination only works for member access expressions and is kind of gross.; 4. The connection of inputs to outputs requires member access expressions and uses logic very much like point 3. Also the way outputs are copied to inputs in the symbol store seems clunky and wasteful; if the input expressions could be truly evaluated at call invocation it wouldn't be necessary to create copies of this data.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/20:210,refactor,refactoring,210,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/20,1,['refactor'],['refactoring']
Modifiability,"This is just a subset of the metadata REST API data... as a first pass, reuse as much as possible. As a future path this could all be flavors of query (flexible filtering and column selection)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/945:152,flexible,flexible,152,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/945,2,['flexible'],['flexible']
Modifiability,"This is mainly just moving stuff around, pulling the metadata based routes into a separate trait out of CromwellApiService. . The **meat** of this was peeling out the inner bits of the metadata route logic into separate/composable functions so that I can access them via other incoming work. . Because @mcovarr are actively poking at the same areas of the code I wanted to get this more basic refactor out ASAP and can follow up with further refactoring at some later point when he's done.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4246:393,refactor,refactor,393,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4246,2,['refactor'],"['refactor', 'refactoring']"
Modifiability,"This is on PAPI side and has already been reported and acknowledged by Aaron. ```; pulling image: docker pull: running [""docker"" ""pull"" ""ubuntu@sha256:de774a3145f7ca4f0bd144c7d4ffb2931e06634f11529653b23eba85aef8e378""]: exit status 1 (standard error: ""error pulling image configuration: received unexpected HTTP status: 502 Bad Gateway...; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4258:271,config,configuration,271,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4258,1,['config'],['configuration']
Modifiability,This is the SLURM configuration I have been using for workflow development on Harvard Medical School's Orchestra 2 SLURM system. You should adjust the runtime-attributes for consistency with other platforms. (see #2068).,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2158:18,config,configuration,18,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2158,1,['config'],['configuration']
Modifiability,"This is the first iteration on the Cromwell-backend LCM design and implementation. The idea is to start commenting on this in order to get a final initial version to start the implementation/refactoring of different backends. Please, DO NOT MERGE.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/604:191,refactor,refactoring,191,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/604,1,['refactor'],['refactoring']
Modifiability,"This issue was prompted by the following thread on the forum: https://gatkforums.broadinstitute.org/wdl/discussion/10347/localization-via-hard-link-has-failed. By default, cromwell does not specify a user when running docker, which leads to two issues:. Firstly, it will run each tasks as whatever user the docker image specifies, typically 'root' as this is the default. This means that depending on how the docker image was build, a completely random user is suddenly the owner of your output files. For example, if the user inside the docker container has UID 1042, this could map to a completely unrelated user on the host system, who is suddenly the owner of your output files. Related to this issue is the fact that all output files have to be world-readable by default, or else the cromwell process will not have read access to the files it has just created (which are now owned by UID 1042). This is not desireable when cromwell is run on a system with many users, some of which should not have read access to eachothers data (for example when working with patient data). As a solution, I propose to change the default docker invocation to run the analysis as $EUID by default. This works even when the EUID is not mapped to a valid user within the docker image, and ensures that the cromwell user is the owner of all the files generated by docker. From man bash: ""EUID Expands to the effective user ID of the current user, initialized at shell startup. This variable is readonly."" , so it should be available on every system. This solution makes cromwell act more secure by default, and will also solve the issue of copying over data files as discussed on the forum and in #2620",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2658:1467,variab,variable,1467,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2658,1,['variab'],['variable']
Modifiability,"This might be related to centaur configuration, which IIRC requires specific, non-default, options for this test. NB fails on both `centaurLocal` and `centaurTest`. Once fixed, reinstate centaur test:; - [x] `invalidate_bad_caches_local`",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2905:33,config,configuration,33,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2905,1,['config'],['configuration']
Modifiability,This only makes sense for output situations and many (if not most) expressions are used to determine inputs. Could possibly create a trait that extends WomExpression and holds this def,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3256:144,extend,extends,144,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3256,1,['extend'],['extends']
Modifiability,"This prepares the next PR that will implement support for `ExpressionTool`; The first 2 commits are pure renames.; The 3rd one breaks `CommandLineTool` apart:; Put `InputParameter` and `OutputParameter` in their own file, and make them trait so they can be extended by specific CWL objects (`WorkflowInputParameter`, `CommandInputParameter`, `ExpressionInputParameter`); Some logic in `CommandLineTool` is abstracted into a `Tool` trait (that will then be extended by `ExpressionTool`); TaskDefinition is also being turned into a trait so we can have `CommandTaskDefinition` and (in the next PR) `ExpressionTaskDefinition`. The general idea is to have `ExpressionTool` behave much like a `CommandLineTool`, including in WOM, except the actual work to be done is an expression to be evaluated by the engine (at least for now ?) instead of a command line run by the backend.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3200:257,extend,extended,257,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3200,2,['extend'],['extended']
Modifiability,"This proposal should give us more flexibility regarding docker tags while keeping the call caching safety on false positive / negative. Docker runtime attributes with docker hashes do not need any additional processing. All logic in this ticket applies to docker runtime attributes with a ""floating"" tag, which will be referred as ""tag"" in this issue. In all cases, if Cromwell fails to retrieve the docker hash for a task, for any reason, the corresponding call(s) will NOT be eligible for call caching, neither read nor write, regardless of the call caching configuration in effect. **When to get the hashes and what to do with them:**. 1. Cromwell will lookup the hashes corresponding to docker tags, for all docker attributes in all tasks in a workflow and its subworkflows, at Materialization time.; If the runtime attribute value can't be determined, the task in question will be ineligible for call caching. The only case when that should be true is if the attribute is an expression with variables depending on previous tasks being run. 2. If the hash lookup succeed, Cromwell will use that hash to perform any call cache read / write according to the call caching configuration in effect. It will also provide that hash, along with the original floating tag, to the backend when the job gets dispatched. 3. Backends will choose wether to use the hash or the floating tag. They will report to the engine which one they used, so that the engine can send this information to the metadata. **How to get the hash:**. 1. How to get the hash depends on the backend. Which means, at this time, that only workflows for which the backend is known statically at workflow submission time will be supported. 2. If the task is expected to run on the **Local Backend**, Cromwell will attempt to find the hash corresponding to the tag on the machine where it's being run. This first attempt must be done without executing a `pull` to avoid overriding the current local image, if it exits, with the remote rep",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2048:560,config,configuration,560,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2048,2,"['config', 'variab']","['configuration', 'variables']"
Modifiability,"This pull request will trigger CI to run for the newly added configuration. . ## What does it do?; Specifically, this test builds and deploys a docker development container with sbt and scala to build cromwell. . ## How is it tested?; The user is instructed to bind the source code with ""sbt assembly"" in the `/code` directory in the container after binding the root of this repository to `/code`. Since we cannot have volumes in circle, we instead just test the added code to the container, also located at `/code`. Since the purpose of this container is to be a clean slate with sbt, scala to build cromwell, the primary test that is important is ensuring that `sbt assembly` runs successfully without a hitch. Any other ""docker"" tests for the actual cromwell (not building it) would not belong here, but with Docker containers meant to deploy cromwell proper. # Where does it deploy?; The container will deploy to the `CONTAINER_NAME` defined in the circle environment settings (or in the circle config at `.circleci/config.yml`. By default, it will be tagged with the commit first 10 characters, and then latest, and you can change this behavior by defining `DOCKER_TAG` either in the config or circle environment (I don't see a reason to do this). Note that deploy is ONLY set up to happen on pushes to master (and you can change this to also be develop, if you choose, or to be both and then to deploy to tags `<branch>-<commit>` or something like that. ## Background; This was first done at the repo [vsoch/cromwell](https://github.com/vsoch/cromwell/pull/1) to test since I can't set it up for the broadinstitute. The (finally) working test is at [https://circleci.com/gh/vsoch/cromwell/11](https://circleci.com/gh/vsoch/cromwell/11). I forgot that I can't have volumes, so it took me many tries to remember this, derp :P . When adding to the repository here, the following additional work will be needed for setup:. - Turn on the repository to build at circleci. The first build, since there ",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4015:61,config,configuration,61,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4015,2,['config'],"['config', 'configuration']"
Modifiability,"This question may be a single config option but I have yet to find any information on it. Currently, when a CWL workflow is loaded cromwell seems to use a cache of previous cwl files used by the workflow when they are requested from http. Is there a way to prevent this behavior if the workflow has been updated but has the same name and requirements? We have had cases where we need to stop cromwell to clear the cache and force it redownload the updated workflow files.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5213:30,config,config,30,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5213,1,['config'],['config']
Modifiability,This resolves the below error (which comes up when you run CromIAM):. `error while starting up loggers akka.ConfigurationException: Logger specified in config can't be loaded [akka.event.slf4j.Slf4jLogger] due to [java.lang.ClassNotFoundException: akka.event.slf4j.Slf4jLogger]`,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4254:108,Config,ConfigurationException,108,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4254,2,"['Config', 'config']","['ConfigurationException', 'config']"
Modifiability,This reworks the JES Authentication schema in such a way that:; - All JES calls (launching a VM) are requested using the Cromwell Service Account (CSA) passed in through the configuration.; - The upload / delete of the authentication file to GCS is also done using CSA.; - All other GCS interactions are done using the user's credentials (with refresh token coming from WF options + clientID/secrets in the conf).; - a `billing_bucket` workflow option has been added that sets the gcs path where cromwell will write the auth.json file,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/295:174,config,configuration,174,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/295,1,['config'],['configuration']
Modifiability,"This seems like a bug. In my inputs.json, I have an input file that is a URL. Cromwell (v84) fails to pull it when I'm not using ""Local"" as a backend. The only difference between a working case and failed case is the name of the backend in the cromwell config. If you just change the name from ""Local"" to ""MyLocal"", it will fail. For example,. this works; ```; default = ""Local""; providers; {; Local; ```. And this fails; ```; default = ""MyLocal""; providers; {; MyLocal; ```. Command to reproduce error. export _JAVA_OPTIONS=""--add-opens=java.base/sun.security.util=ALL-UNNAMED"". java -Dconfig.file=cromwell_docker.conf \; -Dbackend.providers.Local.config.dockerRoot=$(pwd)/cromwell-executions \; -Dbackend.providers.Local.config.root=$(pwd)/cromwell-executions \; -jar ~/cromwell/cromwell-84.jar run fq_count.wdl -i fq_count.json. Error:; java.lang.IllegalArgumentException: Could not build the path ""https://portal.nersc.gov/cfs/m342/jaws/test_data/sample.fastq"". It may refer to a filesystem not supported by this instance of Cromwell. Supported filesystems are: MacOSXFileSystem. Failures: . Required files; [test-files.zip](https://github.com/broadinstitute/cromwell/files/10387814/test-files.zip)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6977:253,config,config,253,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6977,3,['config'],['config']
Modifiability,"This seems similar/related to #1575. Is it possible for Cromwell to expose metadata about its current workflow to the steps that are running? Either via injecting ENV variables into containers, or potentially as inputs (as discussed in that issue?). Our use case is wanting to add a final step to our workflows that POSTs information about the run, its output paths, etc to an external tracking service.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7137:167,variab,variables,167,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7137,1,['variab'],['variables']
Modifiability,"This sets up a mechanism to:; 1) Collect information about ""load"" from various part of the system; 2) Summarize this information and calculate a global load; 3) Notify parts of the system of changes in the global load. Current implementation is simple:; Only 2 load levels: `NormalLoad` and `HighLoad`; Actors reporting their load are:; - WriteMetadataActor; - JobStoreReadActor; - JobStoreWriteActor; - CallCacheWriteActor; - CallCacheReadActor; - KeyValueReadActor; - KeyValueWriteActor; - IoActor; - JesAPIQueryManagerActor. Additionally free memory is also being monitored and will go to `HighLoad` if going below a certain threshold. Global load == max(all load levels). So if one actor or more say their load is high, the global load will be high, otherwise normal.; The only actor listening to changes on the global load is the job token dispenser. It will stop dispensing tokens when load is high and start again when load is back to normal. At the exception of the IoActor, all the above mentioned actors have a queue in which they store work to be done. Their load is determined by comparing the size of this queue to a threshold.; The IoActor's queue is not easily accessible because hidden in the stream implementation and its size cannot easily be known. However we know when its full because we can't add to it anymore (this is when backpressure messages are sent). When that happens the IO actor reports its load to be `High`. When it hasn't had to backpressure for 10 seconds, the load returns to normal. There are many ways this could be made smarter but it already yields improvements in terms of stability and robustness. TODO: . - [x] Add Changelog; - [x] Configuration ? Lots of thresholds and values in this PR that could be configurable, how much and how do we want to configure ?",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3366:1676,Config,Configuration,1676,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3366,3,"['Config', 'config']","['Configuration', 'configurable', 'configure']"
Modifiability,"This started more as a POC that I had in mind but it ended up being a lot less refactoring than I anticipated so I'm making a PR for it.; Following the way we can plug services and languages this allows to plug in filesystems. All you need is a `PathBuilderFactory`.; How to make a `PathBuilderFactory` could still be made simpler but that's a separate issue.; This has the advantage that a filesystem can automatically be added to Cromwell engine or standard backend without code changes.; Available filesystems are defined in the config with their corresponding class, and the engine and backends can pick which ones they want to enable.; It removes some dependency of `engine` over the individual filesystem sub projects but it's not all the way there yet.; Thinking about PAPI2 this possibly opens the door to automatically support new filesystems for (de)localization as well if we were to go down that road.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3496:79,refactor,refactoring,79,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3496,2,"['config', 'refactor']","['config', 'refactoring']"
Modifiability,"This sucked up a few hours of time with the debugger, we need a better error message/handling. If you misconfigure Cromwell (in my case using a service account) whereby the auth specified in JES.filesystems.gcs.auth is unable to write to the bucket specified in JES.config.root. Specifically, I found that the uploadCommandScript was dying silently in the JABJEA and my workflow just stopped running",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1669:266,config,config,266,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1669,1,['config'],['config']
Modifiability,This was already fixed in [cromwell.examples.conf](https://github.com/broadinstitute/cromwell/blob/develop/cromwell.example.backends/cromwell.examples.conf) in https://github.com/broadinstitute/cromwell/commit/f0ae471331922b7302bffeeb2b01effe264973eb. It should also be fixed in this config.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6931:284,config,config,284,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6931,1,['config'],['config']
Modifiability,This was requested by @patmagee - I agree that it's a good idea. Find a way to detect if a liquibase migration is pending if Cromwell starts. Add a config option (defaulting to a safe mode) such that if this option is enabled and a liquibase migration is required that the process will exit with an error message stating:. - That a migration is necessary; - Encouragement to the user to backup their database and/or do further testing if in a production environment; - Describe how to override (including via command line) the setting to allow Cromwell to start properly.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2429:148,config,config,148,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2429,1,['config'],['config']
Modifiability,"This wasn't as simple as just a one line ""add singularity to the list"" of cacheable attributes, because `singularity` is a user-generated attribute specified in the Config backend's configuration. So the change ended up being:. * Allow additional config allowing users to specify which runtime attributes are call-cacheable; * Wiring that through the runtime attribute validators to include the correct call-cacheable-ness; * Unit and centaur tests.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5543:165,Config,Config,165,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5543,3,"['Config', 'config']","['Config', 'config', 'configuration']"
Modifiability,"This will allow this WDL file to run:. ```; task a {; File in; String out_name = ""out"". command {; cat ${in} > ${out_name}; }; runtime {; docker: ""kcibul/picard""; }; output {; File out = ""out""; File out_interpolation = ""${out_name}""; String contents = read_string(""${out_name}""); }; }. workflow file_passing {; File f. call a {input: in=f}; call a as b {input: in=a.out}; }; ```. This also fixes a bug where static declarations weren't being honored when resolving variables in all cases. This lead to some frustrating bugs with Yossi",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/207:465,variab,variables,465,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/207,1,['variab'],['variables']
Modifiability,"This will ensure that if you use a variable declaration twice that they must be identical definitions. Not perfect, but handles the majority case easily.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/95:35,variab,variable,35,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/95,1,['variab'],['variable']
Modifiability,"This would greatly reduce my need to modify WDL scripts to start where I have data already processed. For example, if a script goes BAM-->coverage-->CNVs, if I have already collected coverage on my BAMs, I would like to be able to provide `coverage` to the same script and have Cromwell skip the tasks involving the BAM and run the remaining steps in the workflow, e.g. coverage-->CNVs. . I run WDLs using gcloud, within a VM and locally. I don't use FireCloud so my runs do not use call-caching. I want to take the boilerplate WDL scripts the GATK4 repo makes available to run processes. I am specifically looking at the latest somatic CNV workflow. If I have alreaded padded my intervals and/or collected counts on the BAMs, I'd like to still use the rest of the steps in the workflow by specifying in the INPUTS JSON an intermediate file. If the script is thus:; ```; call CNVTasks.PreprocessIntervals {; input:; intervals = intervals,; ref_fasta_dict = ref_fasta_dict,; gatk4_jar_override = gatk4_jar_override,; gatk_docker = gatk_docker; }. if (select_first([do_explicit_gc_correction, false])) {; call CNVTasks.AnnotateIntervals {; input:; intervals = PreprocessIntervals.preprocessed_intervals,; ref_fasta = ref_fasta,; ref_fasta_fai = ref_fasta_fai,; ref_fasta_dict = ref_fasta_dict,; gatk4_jar_override = gatk4_jar_override,; gatk_docker = gatk_docker; }; ```. In the inputs, instead of defining:; ```; ""CNVSomaticPanelWorkflow.intervals"": ""File"",; ```; I would like to be able to instead provide:; ```; ""CNVSomaticPanelWorkflow.PreprocessIntervals.preprocessed_intervals"": ""File"",; ```. And not have the run error due to the lack of the `CNVSomaticPanelWorkflow.intervals` file. . I would really appreciate such a feature as it saves me the time of having to rewrite WDL scripts for each tweaked subset workflow. Thanks.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2949:1769,rewrite,rewrite,1769,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2949,1,['rewrite'],['rewrite']
Modifiability,This would work if the failure mode is passed through workflow options but not if it's set in the config.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/2239:98,config,config,98,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/2239,1,['config'],['config']
Modifiability,"Thought I would check out the new GCPBATCH support in the latest cromwell. Used the [example config](https://github.com/broadinstitute/cromwell/blob/develop/cromwell.example.backends/GCPBATCH.conf) for the newly supported GCPBATCH with my projects settings added and it errored because of multiple zones were configured:. ```; default-runtime-attributes {; ...; zones: [""us-central1-a"", ""us-central1-b""]; }; ```; I changed it to just `[""us-central1-a""]` and worked fine and ran until completion so I guess it is how the parser is combining these zones into whatever underlying batch command needs to be executed. (I also tried the value ""us-central1-a us-central1-b"" as a string instead of an array cause I thought I read somewhere that was supported, but that didn't work either). Here is the error thrown by cromwell: . ![Screenshot 2023-10-04 at 13 11 01](https://github.com/broadinstitute/cromwell/assets/40811287/9c9cc8d8-8e08-44a3-826d-a0300fc95278)",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7232:93,config,config,93,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7232,2,['config'],"['config', 'configured']"
Modifiability,"Thread.java:107); cromwell_1 | ; cromwell_1 | 2024-01-11 11:09:38 cromwell-system-akka.dispatchers.engine-dispatcher-38 INFO - BT-322 0845428a:myworkflow.mytask:-1:1 is not eligible for call caching; ```; <!-- Which backend are you running? -->; Used backend: ; GCPBATCH. Callcaching works with PAPIv2, not on GCPBATCH.; <!-- Paste/Attach your workflow if possible: -->; workflow used for testing:; ```; workflow myworkflow {; call mytask; }. task mytask {; String str = ""!""; command <<<; echo ""hello world ${str}""; >>>; output {; String out = read_string(stdout()); }. runtime{; docker: ""eu.gcr.io/project/image_name:tag""; cpu: ""1""; memory: ""500 MB""; disks: ""local-disk 5 HDD""; zones: ""europe-west1-b europe-west1-c europe-west1-d""; preemptible: 2; noAddress: true; }; }; ```; <!-- Paste your configuration if possible, MAKE SURE TO OMIT PASSWORDS, TOKENS AND OTHER SENSITIVE MATERIAL: -->; We are using cromwell through broadinstitute/cromwell:87-ecd44b6 image.; cromwell configuration:; ```; include required(classpath(""application"")). system.new-workflow-poll-rate=1. // increase timeout for http requests..... getting meta-data can timeout for large workflows.; akka.http.server.request-timeout=600s. # Maximum number of input file bytes allowed in order to read each type.; # If exceeded a FileSizeTooBig exception will be thrown.; system {; 	job-rate-control {; 	 jobs = 100; 	 per = 1 second; 	}; input-read-limits {; lines = 128000000; bool = 7; int = 19; float = 50; string = 1280000; json = 12800000; tsv = 1280000000; map = 128000000; object = 128000000; }. # If 'true', a SIGTERM or SIGINT will trigger Cromwell to attempt to gracefully shutdown in server mode,; # in particular clearing up all queued database writes before letting the JVM shut down.; # The shutdown is a multi-phase process, each phase having its own configurable timeout. See the Dev Wiki for more details.; 	graceful-server-shutdown = true; max-concurrent-workflows = 5000. io {; throttle {; # # Global Throttling - T",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7356:7263,config,configuration,7263,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7356,1,['config'],['configuration']
Modifiability,ThreadEventExecutor.java:997); at io.grpc.netty.shaded.io.netty.util.internal.ThreadExecutorMap$2.run(ThreadExecutorMap.java:74); at io.grpc.netty.shaded.io.netty.util.concurrent.FastThreadLocalRunnable.run(FastThreadLocalRunnable.java:30); ... 1 common frames omitted; Caused by: sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target; at java.base/sun.security.validator.PKIXValidator.doBuild(PKIXValidator.java:388); at java.base/sun.security.validator.PKIXValidator.engineValidate(PKIXValidator.java:271); at java.base/sun.security.validator.Validator.validate(Validator.java:256); at java.base/sun.security.ssl.X509TrustManagerImpl.checkTrusted(X509TrustManagerImpl.java:284); at java.base/sun.security.ssl.X509TrustManagerImpl.checkServerTrusted(X509TrustManagerImpl.java:144); at io.grpc.netty.shaded.io.netty.handler.ssl.ReferenceCountedOpenSslClientContext$ExtendedTrustManagerVerifyCallback.verify(ReferenceCountedOpenSslClientContext.java:234); at io.grpc.netty.shaded.io.netty.handler.ssl.ReferenceCountedOpenSslContext$AbstractCertificateVerifier.verify(ReferenceCountedOpenSslContext.java:779); at io.grpc.netty.shaded.io.netty.internal.tcnative.CertificateVerifierTask.runTask(CertificateVerifierTask.java:36); at io.grpc.netty.shaded.io.netty.internal.tcnative.SSLTask.run(SSLTask.java:48); at io.grpc.netty.shaded.io.netty.internal.tcnative.SSLTask.run(SSLTask.java:42); at io.grpc.netty.shaded.io.netty.handler.ssl.ReferenceCountedOpenSslEngine.runAndResetNeedTask(ReferenceCountedOpenSslEngine.java:1496); at io.grpc.netty.shaded.io.netty.handler.ssl.ReferenceCountedOpenSslEngine.access$700(ReferenceCountedOpenSslEngine.java:94); at io.grpc.netty.shaded.io.netty.handler.ssl.ReferenceCountedOpenSslEngine$TaskDecorator.run(ReferenceCountedOpenSslEngine.java:1471); at io.grpc.netty.shaded.io.netty.handler.ssl.SslHandler$SslTasksRunner.run(SslH,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/7551:7581,Extend,ExtendedTrustManagerVerifyCallback,7581,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/7551,1,['Extend'],['ExtendedTrustManagerVerifyCallback']
Modifiability,"To follow up #1653, would it be possible to have cromwell server mode be configurable to listen on a socket file, as an option instead of a TCP listener? With correct permissions, this would allow a user to run a cromwell server that's listener is in a protected location?. This would allow regular users, who would not have access to set firewall rules on hosts, the tools they need to run their own secure listener. Cheers!; CanWood",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2637:73,config,configurable,73,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2637,1,['config'],['configurable']
Modifiability,"To reproduce: Add an invalid actor for KeyValueService in configuration. Startup should fail, but instead the service continues running",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1266:58,config,configuration,58,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1266,1,['config'],['configuration']
Modifiability,To set expectations:; - Demonstrates the ShadowWorkflowActor progressing through every lifecycle state; - Hard-codes the DummyBackend for every call; - Doesn't store anything persistently; - Will certainly need to evolve from here...,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/720:214,evolve,evolve,214,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/720,1,['evolve'],['evolve']
Modifiability,"Today, Cromwell interprets `memory: ""4 GB""` as Gigabytes (base-10) and `memory: ""4 GiB""` as Gibibytes (base-2). This is confusing as when people are trying to size their tasks to use specific resource amounts to match cloud compute requirements -- those cloud requirements are published in base-2 units *but* the most common way to declare units in WDL is to use the syntax `GB`, which will then convert the Gigabytes to Gibibytes, which is confusing for a user. Since both GCP & AWS declare memory requirements in base-2 units, it would be best to standardize both ""GB"" and ""GiB"" in Cromwell to mean base-2 units. Additionally, when memory inputs are declared for java variables, such as:; `java -xmx4g -jar ....` the units of which also default to base-2.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4481:670,variab,variables,670,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4481,1,['variab'],['variables']
Modifiability,"Today, caching is very closely tied to the backend name of any particular job. In the case where a job is run on the PAPIv1 and re-run on the PAPIv2 backends, the job can't cache to it's previous iteration, even though they were both run on GCP in a containerized environment. . This will be a common use case for all users migrating from the PAPIv1 --> PAPIv2 backend. The only workaround to this is the ""backendName"" key in the Cromwell configuration is maintained to be the same string, and class factories and switched from v1 --> v2. However, cases where a user wants both v1 & v2 backends to be usable and jobs to be cacheable between the two, there's no proper solution. AC: Create a new key (separate from backendName) which is used by the caching algorithm and can be common between two backend stanzas, so as to enable caching between two backend configurations.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4462:439,config,configuration,439,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4462,2,['config'],"['configuration', 'configurations']"
Modifiability,"Today, during Job preparation (prior to localization), when Cromwell calls Martha to get information on a dos url, there is a schema (defined in the Cromwell config) which statically extracts an element from an array, which is no longer guaranteed to be a GS url. Ideally, when Martha returns URL info, Cromwell sorts through the array of urls to *extract the first gcs url*, and when there is no GCS url, the job fails with an error message explaining how the DOS url couldn't be resolved into a GCS url. IN addition, Cromwell can also the print the dos url + actual urls associated to the dos url for a user -- so they can easily take both pieces of info for further debugging.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/4118:158,config,config,158,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/4118,1,['config'],['config']
Modifiability,"Trying to build cromwell from source, getting the following:; ```; [warn] 	::::::::::::::::::::::::::::::::::::::::::::::; [warn] 	:: UNRESOLVED DEPENDENCIES ::; [warn] 	::::::::::::::::::::::::::::::::::::::::::::::; [warn] 	:: org.apache.httpcomponents#httpclient;4.5.2: configuration not found in org.apache.httpcomponents#httpclient;4.5.2: 'compile'. It was required from org.broadinstitute#cromwell-gcsfilesystem_2.11;25-5588e73-SNAP compile. ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/2021:273,config,configuration,273,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/2021,1,['config'],['configuration']
Modifiability,"Trying to read an object that has the same name as a variable causes Cromwell to abort not just the workflow, but the entire Cromwell instance; WDL file:; ```; task TestTask {; 	; 	command {; 		echo ""Hello World!"" > hello_world.txt; 	}. 	output {; 		File exists = ""hello_world.txt""; 	}. 	runtime {; 		docker: will_fail.docker; 		memory: will_fail.memory; 		disks: ""local-disk "" + will_fail.small_disk + "" HDD""; 	}; }. workflow KillsCromwell {; 	String test_string. # This here kills Cromwell; 	Object runtime_params = read_object(runtime_params). 	call TestTask ; }; ```. Inputs File:; ```; {; 	""KillsCromwell.test_string"": ""This is a string"",; 	""KillsCromwell.runtime_params"": {; 		""genomes_cloud_image"": ""broadinstitute/genomes-in-the-cloud:2.2.4-1469632282"",; 		""small_disk"": 100,; 		""medium_disk"": 200,; 		""large_disk"": 300,; 		""x_large_disk"": 400,; 		""preemptible_tries"": 3; 	}; }; ```",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/1946:53,variab,variable,53,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/1946,1,['variab'],['variable']
Modifiability,"Turns out the batch size for write metadata was ignored (we were looking at the wrong config path); Also turns out it doesn't matter that much when load is very high.; That is mostly because when we flush the event queue, we flush all of it, not just `dbBatchSize` of it.; This added to the fact that the flushes are controlled by messages we sent to `self` that can get lost in an ocean of metadata event messages, we can end up flushing queues of several million events at once, in one transaction, which can take quite some time for slick to do. The more time it takes, the more events we accumulate before the next flush, so the next flush takes even more time etc... ; I'll have a follow up PR to re-factor this a bit, with stats to be able to compare. TODO:; - [x] Add some tests",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/3294:86,config,config,86,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/3294,1,['config'],['config']
Modifiability,"Two days ago I successfully ran my first wdl on Cromwell using the Google Pipelines API. Then I tried to change my service account and it broke. I'm not able to get it running anymore at all. Stacktrace can be seen below, the error is ""Scopes not configured for service account."". **stdout**. ```; ...; tsv_string += '\n' + ""unmapped"". with open(""sequence_grouping_with_unmapped.txt"",""w"") as tsv_file_with_unmapped:; tsv_file_with_unmapped.write(tsv_string); tsv_file_with_unmapped.close(); CODE`; 2018-05-25 12:55:24,629 cromwell-system-akka.dispatchers.backend-dispatcher-137 ERROR - Scopes not configured for service account. Scoped should be specified by calling createScoped or passing scopes to constructor.; java.io.IOException: Scopes not configured for service account. Scoped should be specified by calling createScoped or passing scopes to constructor.; 	at com.google.auth.oauth2.ServiceAccountCredentials.refreshAccessToken(ServiceAccountCredentials.java:342); 	at com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:160); 	at com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:146); 	at com.google.auth.http.HttpCredentialsAdapter.initialize(HttpCredentialsAdapter.java:96); 	at cromwell.cloudsupport.gcp.genomics.GenomicsFactory$$anon$1.initialize(GenomicsFactory.scala:18); 	at com.google.api.client.http.HttpRequestFactory.buildRequest(HttpRequestFactory.java:93); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.buildHttpRequest(AbstractGoogleClientRequest.java:300); 	at com.google.api.client.googleapis.services.AbstractGoogleClientRequest.buildHttpRequest(AbstractGoogleClientRequest.java:277); 	at cromwell.backend.impl.jes.statuspolling.JesApiQueryManager$PAPIRunCreationRequest.httpRequest$lzycompute(JesApiQueryManager.scala:293); 	at cromwell.backend.impl.jes.statuspolling.JesApiQueryManager$PAPIRunCreationRequest.httpRequest(JesApiQueryManager.scala:293); 	at cromwell.backend.impl.jes.statuspo",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/3690:247,config,configured,247,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/3690,3,['config'],['configured']
Modifiability,"Two new centaur tests (test types actually):. * Simulates the transition from PAPI v1 to PAPI v2. Start with an FC-like config where PAPI v1 is the default `Papi` backend and PAPI v2 is available in a `Papiv2` backend. Launch a workflow into this system with two sequential calls. Shut down Cromwell once the second call starts. Tweak the Cromwell config to add `name-for-call-caching-purposes = ""Papi""` to the `Papiv2` backend. Bring Cromwell back up and let the previously-running workflow finish. Then launch a second workflow identical to the first except that its options request `{ ""backend"": ""Papiv2""}`. Let this workflow finish and confirm it call cached both calls from the first workflow despite running on different versions of PAPI. * Simulates the new steady-state after the v2 transition when new workflows are submitted with `{""backend"": ""Papiv2""}`. Run a workflow, shut down Cromwell in the middle of its execution, then bring Cromwell back up. Confirm this workflow completes successfully. Launch a second copy of the workflow also requesting `{""backend"": ""Papiv2""}` and confirm it completes successfully and caches to all the calls of the first run and that both executed on PAPI v2.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/4490:120,config,config,120,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/4490,2,['config'],['config']
Modifiability,"UBERCULOSIS/7570b5dc-4714-48a7-96b2-9c62245e3618/call-get_organism_names/shard-885"",; ""Mode"": """",; ""RW"": true,; ""Propagation"": ""rprivate""; }; ],; ""Config"": {; ""Hostname"": ""cf6f4828adc6"",; ""Domainname"": """",; ""User"": """",; ""AttachStdin"": true,; ""AttachStdout"": true,; ""AttachStderr"": true,; ""Tty"": false,; ""OpenStdin"": true,; ""StdinOnce"": true,; ""Env"": [; ""PATH=/root/miniconda3/bin:/bin:/root/edirect/:/bin/sratoolkit.3.0.0-ubuntu64/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin"",; ""PERL5LIB=/perlstuff:""; ],; ""Cmd"": [; ""/bark-bark/IS_THIS_TUBERCULOSIS/7570b5dc-4714-48a7-96b2-9c62245e3618/call-get_organism_names/shard-885/execution/script""; ],; ""Image"": ""ashedpotatoes/sranwrp@sha256:15a8875a024231bd0bf3b5cfc0c4fd4cdb654e9475cd44b2ca251c75dae7fee8"",; ""Volumes"": null,; ""WorkingDir"": """",; ""Entrypoint"": [; ""/bin/bash""; ],; ""OnBuild"": null,; ""Labels"": {}; },; ""NetworkSettings"": {; ""Bridge"": """",; ""SandboxID"": """",; ""HairpinMode"": false,; ""LinkLocalIPv6Address"": """",; ""LinkLocalIPv6PrefixLen"": 0,; ""Ports"": {},; ""SandboxKey"": """",; ""SecondaryIPAddresses"": null,; ""SecondaryIPv6Addresses"": null,; ""EndpointID"": """",; ""Gateway"": """",; ""GlobalIPv6Address"": """",; ""GlobalIPv6PrefixLen"": 0,; ""IPAddress"": """",; ""IPPrefixLen"": 0,; ""IPv6Gateway"": """",; ""MacAddress"": """",; ""Networks"": {; ""bridge"": {; ""IPAMConfig"": null,; ""Links"": null,; ""Aliases"": null,; ""NetworkID"": """",; ""EndpointID"": """",; ""Gateway"": """",; ""IPAddress"": """",; ""IPPrefixLen"": 0,; ""IPv6Gateway"": """",; ""GlobalIPv6Address"": """",; ""GlobalIPv6PrefixLen"": 0,; ""MacAddress"": """",; ""DriverOpts"": null; }; }; }; }; ]; ```. ### Terminal output (first couple shards trimmed of course); ```; [2022-11-08 21:36:56,76] [info] BackgroundConfigAsyncJobExecutionActor [7570b5dcIS_THIS_TUBERCULOSIS.get_organism_names:981:1]: executing: docker run \; --rm -i \; \; --entrypoint /bin/bash \; -v /private/var/folders/vp/327wktbj3wqb65q3v3n8qpxc0000gn/T/1667969838761-0/dockstore-is-cool/IS_THIS_TUBERCULOSIS/7570b5dc-4714-48a7-96b2-9c62245e3618/call-get",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/6946:7442,Sandbox,SandboxID,7442,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/6946,2,['Sandbox'],"['SandboxID', 'SandboxKey']"
Modifiability,"Unless I configured something improperly, all output from stdout() is doubled when running with SLURM. Example pipeline:. ```; version 1.0. # WORKFLOW DEFINITION; workflow WholeGenomeGermlineSingleSample {; call SumFloats; output {; Float out = SumFloats.total_size; }; }. task SumFloats {; input {; Array[Float] sizes = [1,2,3,4,5.0]; Int preemptible_tries=3; }. command <<<; python -c ""print ~{sep=""+"" sizes}""; >>>; output {; Float total_size = read_float(stdout()); }; runtime {; docker: ""us.gcr.io/broad-gotc-prod/python:2.7""; preemptible: preemptible_tries; }; }; ```. The error raised with cromwell-53 is:; Failed to read_float(""/data/og/ted/cromwell-executions/WholeGenomeGermlineSingleSample/00090ef9-5211-4f18-9de9-daf3de791408/call-SumFloats/execution/stdout"") (reason 1 of 1): For input string: ""15.0; 15.0""; The stdout file truly contains this. Running with local backend returns no error.; Contents of conf file:. ```; backend {; default = ""SLURM""; providers {; Local {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; include required(classpath(""reference_local_provider_config.inc.conf"")); concurrent-job-limit = 30; }; }; SLURM {; actor-factory = ""cromwell.backend.impl.sfs.config.ConfigBackendLifecycleActorFactory""; config {; runtime-attributes = """"""; Int runtime_minutes = 600; Int cpu = 1; Int requested_memory_mb_per_core = 8000; Int memory_mb = 4000; String queue = ""short""; String? docker; """""". submit = """"""; sbatch -J ${job_name} -D ${cwd} -o ${out} -e ${err} -t ${runtime_minutes} -p ${queue} \; ${""-c "" + cpu} \; --mem ${memory_mb} \; --wrap ""/bin/bash ${script}""; """"""; submit-docker = """"""; docker pull ${docker}. sbatch -J ${job_name} -D ${cwd} -o ${cwd}/execution/stdout -e ${cwd}/execution/stderr -t ${runtime_minutes} -p ${queue} \; ${""-c "" + cpu} \; --mem ${memory_mb} \; --wrap ""docker run -v ${cwd}:${docker_cwd} ${docker} ${job_shell} ${docker_cwd}/execution/script""; """""". kill = ""scancel ${job_id}""; check-alive = ""sc",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/issues/5932:9,config,configured,9,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/issues/5932,1,['config'],['configured']
Modifiability,Unset variables and -o nounset do not mix.,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5306:6,variab,variables,6,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5306,1,['variab'],['variables']
Modifiability,"Unwired the `DockerHashLookupWorkerActor`.; Removed the unused docker registry client.; Cleaned up spray dependencies now that the spray-client is no longer used.; Refactored places that were sending spray classes down into the business logic.; Turned back on deprecation warnings.; Fixed scalaz flatMap deprecation warning by adding Y.A. implicit import.; Undeprecated `TerminalUtil` used by the single workflow runner's pretty printer.; Removed empty files from git.; Bumped timeout for `SharedFileSystemJobExecutionActorSpec.recoverSpec` up to 10 seconds dilated.; Increased sleep for `WorkflowExecutionActorSpec.""retry a job 2 times""` up to 3 seconds dilated.; Updated scalatest to 3.0.0.; Removed leftover bits of `DontUseMainSpecTest`.; Printing test times, minimal stack traces, and resummarizing tests failures, via http://www.scalatest.org/user_guide/running_your_tests.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/1338:164,Refactor,Refactored,164,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/1338,1,['Refactor'],['Refactored']
Modifiability,Update delight-rhino-sandbox to 0.0.11,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5666:21,sandbox,sandbox,21,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5666,1,['sandbox'],['sandbox']
Modifiability,Update dockerfile to copy the Config file into the docker image,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/42:30,Config,Config,30,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/42,1,['Config'],['Config']
Modifiability,Update typesafe:config to 1.3.4,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5633:16,config,config,16,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5633,1,['config'],['config']
Modifiability,"Updated Language Spec: https://github.com/broadinstitute/wdl/blob/spec/SPEC.md#workflow-description-language. What you'll find in here:; - Updates to the parser for the various syntax changes we decided on. Tests have also been updated and all WDL files I could find have been updated for the new syntax.; - `EngineFunctions` -> `WdlStandardLibraryFunctions` with stubs for everything that's in the specification.; - Implemented the following on `LocalEngineFunctions`: `write_map()`, `read_map()`, `write_lines()`. Tests also added for these; - Refactoring of parts of the backend to be able to accommodate the implementation of the functions described above.; - Syntax Highlighter updated for new syntax; - Map literals now allowed in WDL source. Tests included.; - Slightly better coercion semantics: Added an identity coercion ; - Remove / refactor a lot of tech debt.; - Removed the `Command` class, now consumed into `Task` class. Since the spec change, Commands needed to know more about stuff defined at the task level (specifically, Declarations).; - Exposure of workflow outputs section in the `Workflow` class, they are not honored further than that though.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/135:546,Refactor,Refactoring,546,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/135,2,"['Refactor', 'refactor']","['Refactoring', 'refactor']"
Modifiability,Updated configuration to reflect new requirements,MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5858:8,config,configuration,8,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5858,1,['config'],['configuration']
Modifiability,"Updated the travis configuration to again use copy-only localization.; As the other localizers were previously broken, travis was _only_ able to run copy.",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/727:19,config,configuration,19,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/727,1,['config'],['configuration']
Modifiability,"Updates ; * [ch.qos.logback:logback-access](https://github.com/qos-ch/logback); * [ch.qos.logback:logback-classic](https://github.com/qos-ch/logback); * [ch.qos.logback:logback-core](https://github.com/qos-ch/logback). from 1.2.11 to 1.4.5. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/9367739b48d1bae5766674e547f8cdf8a82d318a/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""ch.qos.logback"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""ch.qos.logback"" }; }]; ```; </details>. labels: library-update, early-semver-minor, semver-spec-minor, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7026:466,Config,Configure,466,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7026,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [com.dimafeng:testcontainers-scala-mariadb](https://github.com/testcontainers/testcontainers-scala); * [com.dimafeng:testcontainers-scala-mysql](https://github.com/testcontainers/testcontainers-scala); * [com.dimafeng:testcontainers-scala-postgresql](https://github.com/testcontainers/testcontainers-scala); * [com.dimafeng:testcontainers-scala-scalatest](https://github.com/testcontainers/testcontainers-scala). from 0.39.6 to 0.39.8.; [GitHub Release Notes](https://github.com/testcontainers/testcontainers-scala/releases/tag/v0.39.8) - [Version Diff](https://github.com/testcontainers/testcontainers-scala/compare/v0.39.6...v0.39.8). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/6472b97b3365f2800f4202d1bf6b1d647bd2b0cc/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.dimafeng"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6512:874,Config,Configure,874,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6512,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [com.dimafeng:testcontainers-scala-mariadb](https://github.com/testcontainers/testcontainers-scala); * [com.dimafeng:testcontainers-scala-mysql](https://github.com/testcontainers/testcontainers-scala); * [com.dimafeng:testcontainers-scala-postgresql](https://github.com/testcontainers/testcontainers-scala); * [com.dimafeng:testcontainers-scala-scalatest](https://github.com/testcontainers/testcontainers-scala). from 0.39.8 to 0.39.12. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/00809e6249b134635f71919c17c1c81603beb22d/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.dimafeng"" } ]; ```; </details>. labels: library-update, early-semver-minor, semver-spec-patch, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6603:674,Config,Configure,674,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6603,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [com.dimafeng:testcontainers-scala-mariadb](https://github.com/testcontainers/testcontainers-scala); * [com.dimafeng:testcontainers-scala-mysql](https://github.com/testcontainers/testcontainers-scala); * [com.dimafeng:testcontainers-scala-postgresql](https://github.com/testcontainers/testcontainers-scala); * [com.dimafeng:testcontainers-scala-scalatest](https://github.com/testcontainers/testcontainers-scala). from 0.40.10 to 0.40.12.; [GitHub Release Notes](https://github.com/testcontainers/testcontainers-scala/releases/tag/v0.40.12) - [Version Diff](https://github.com/testcontainers/testcontainers-scala/compare/v0.40.10...v0.40.12). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/9367739b48d1bae5766674e547f8cdf8a82d318a/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.dimafeng"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""com.dimafeng"" }; }]; ```; </details>. labels: test-library-update, early-semver-minor, semver-spec-patch, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7031:879,Config,Configure,879,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7031,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [com.dimafeng:testcontainers-scala-mariadb](https://github.com/testcontainers/testcontainers-scala); * [com.dimafeng:testcontainers-scala-mysql](https://github.com/testcontainers/testcontainers-scala); * [com.dimafeng:testcontainers-scala-postgresql](https://github.com/testcontainers/testcontainers-scala); * [com.dimafeng:testcontainers-scala-scalatest](https://github.com/testcontainers/testcontainers-scala). from 0.40.2 to 0.40.10.; [GitHub Release Notes](https://github.com/testcontainers/testcontainers-scala/releases/tag/v0.40.10) - [Version Diff](https://github.com/testcontainers/testcontainers-scala/compare/v0.40.2...v0.40.10). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/2dc2301e75aea6c2d0c49b89d6092f7d4f134b40/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.dimafeng"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""@monthly"" },; dependency = { groupId = ""com.dimafeng"" }; }]; ```; </details>. labels: test-library-update, early-semver-minor, semver-spec-patch, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6849:877,Config,Configure,877,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6849,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [com.fasterxml.jackson.core:jackson-annotations](http://github.com/FasterXML/jackson-annotations); * [com.fasterxml.jackson.core:jackson-core](http://github.com/FasterXML/jackson-core). from 2.11.3 to 2.12.0. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/88c9ae38953d94358d1e0fbf03c7f63dbd3a2281/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.fasterxml.jackson.core"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6102:446,Config,Configure,446,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6102,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [com.fasterxml.jackson.core:jackson-annotations](http://github.com/FasterXML/jackson-annotations); * [com.fasterxml.jackson.core:jackson-core](http://github.com/FasterXML/jackson-core); * [com.fasterxml.jackson.core:jackson-databind](http://github.com/FasterXML/jackson-databind). from 2.12.0 to 2.12.2. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/b48aba70ec793405c98788a322d160987ba51d3e/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.fasterxml.jackson.core"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6243:541,Config,Configure,541,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6243,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [com.fasterxml.jackson.core:jackson-annotations](http://github.com/FasterXML/jackson-annotations); * [com.fasterxml.jackson.core:jackson-core](http://github.com/FasterXML/jackson-core); * [com.fasterxml.jackson.core:jackson-databind](http://github.com/FasterXML/jackson-databind). from 2.12.2 to 2.12.3. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/92f43ce5f010fa03daeb2625a3f9c1b1be80cca5/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.fasterxml.jackson.core"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6391:541,Config,Configure,541,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6391,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [com.fasterxml.jackson.core:jackson-annotations](http://github.com/FasterXML/jackson-annotations); * [com.fasterxml.jackson.core:jackson-core](http://github.com/FasterXML/jackson-core); * [com.fasterxml.jackson.core:jackson-databind](http://github.com/FasterXML/jackson-databind). from 2.12.5 to 2.13.0. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/6472b97b3365f2800f4202d1bf6b1d647bd2b0cc/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.fasterxml.jackson.core"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6514:541,Config,Configure,541,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6514,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [com.google.api-client:google-api-client-jackson2](https://github.com/googleapis/google-api-java-client); * [com.google.api-client:google-api-client-java6](https://github.com/googleapis/google-api-java-client). from 1.30.10 to 1.30.11.; [GitHub Release Notes](https://github.com/googleapis/google-api-java-client/releases/tag/v1.30.11) - [Changelog](https://github.com/googleapis/google-api-java-client/blob/master/CHANGELOG.md) - [Version Diff](https://github.com/googleapis/google-api-java-client/compare/v1.30.10...v1.30.11). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/70862b7263be540409b11ad2c14f1fe8fbc0ff26/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.api-client"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5942:766,Config,Configure,766,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5942,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [com.google.api-client:google-api-client-jackson2](https://github.com/googleapis/google-api-java-client); * [com.google.api-client:google-api-client-java6](https://github.com/googleapis/google-api-java-client). from 1.30.11 to 1.31.3.; [GitHub Release Notes](https://github.com/googleapis/google-api-java-client/releases/tag/v1.31.3) - [Changelog](https://github.com/googleapis/google-api-java-client/blob/master/CHANGELOG.md) - [Version Diff](https://github.com/googleapis/google-api-java-client/compare/v1.30.11...v1.31.3). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/b48aba70ec793405c98788a322d160987ba51d3e/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.api-client"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6247:763,Config,Configure,763,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6247,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [com.google.api-client:google-api-client-jackson2](https://github.com/googleapis/google-api-java-client); * [com.google.api-client:google-api-client-java6](https://github.com/googleapis/google-api-java-client). from 1.30.9 to 1.30.10.; [GitHub Release Notes](https://github.com/googleapis/google-api-java-client/releases/tag/v1.30.10) - [Changelog](https://github.com/googleapis/google-api-java-client/blob/master/CHANGELOG.md) - [Version Diff](https://github.com/googleapis/google-api-java-client/compare/v1.30.9...v1.30.10). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/a2a47735b8b5ce3b0b0a9fa0a2cdf3b8405ff98d/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.api-client"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5616:764,Config,Configure,764,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5616,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [com.google.api-client:google-api-client-jackson2](https://github.com/googleapis/google-api-java-client); * [com.google.api-client:google-api-client-java6](https://github.com/googleapis/google-api-java-client). from 1.31.3 to 1.32.1.; [GitHub Release Notes](https://github.com/googleapis/google-api-java-client/releases/tag/v1.32.1) - [Changelog](https://github.com/googleapis/google-api-java-client/blob/master/CHANGELOG.md) - [Version Diff](https://github.com/googleapis/google-api-java-client/compare/v1.31.3...v1.32.1). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/92f43ce5f010fa03daeb2625a3f9c1b1be80cca5/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.api-client"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6394:761,Config,Configure,761,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6394,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [com.google.api-client:google-api-client-jackson2](https://github.com/googleapis/google-api-java-client); * [com.google.api-client:google-api-client-java6](https://github.com/googleapis/google-api-java-client). from 1.32.1 to 1.32.2.; [GitHub Release Notes](https://github.com/googleapis/google-api-java-client/releases/tag/v1.32.2) - [Version Diff](https://github.com/googleapis/google-api-java-client/compare/v1.32.1...v1.32.2). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/00809e6249b134635f71919c17c1c81603beb22d/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Files still referring to the old version number</summary>. The following files still refer to the old version number (1.32.1).; You might want to review and update them manually.; ```; project/Dependencies.scala; ```; </details>; <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.api-client"" } ]; ```; </details>. labels: library-update, early-semver-patch, semver-spec-patch, old-version-remains, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6606:668,Config,Configure,668,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6606,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [com.google.api-client:google-api-client-jackson2](https://github.com/googleapis/google-api-java-client); * [com.google.api-client:google-api-client-java6](https://github.com/googleapis/google-api-java-client). from 1.33.2 to 1.33.4.; [GitHub Release Notes](https://github.com/googleapis/google-api-java-client/releases/tag/v1.33.4) - [Version Diff](https://github.com/googleapis/google-api-java-client/compare/v1.33.2...v1.33.4). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/2dc2301e75aea6c2d0c49b89d6092f7d4f134b40/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.api-client"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""@monthly"" },; dependency = { groupId = ""com.google.api-client"" }; }]; ```; </details>. labels: library-update, early-semver-patch, semver-spec-patch, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6853:668,Config,Configure,668,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6853,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [com.typesafe.akka:akka-actor](https://github.com/akka/akka); * [com.typesafe.akka:akka-slf4j](https://github.com/akka/akka); * [com.typesafe.akka:akka-stream](https://github.com/akka/akka); * [com.typesafe.akka:akka-stream-testkit](https://github.com/akka/akka); * [com.typesafe.akka:akka-testkit](https://github.com/akka/akka). from 2.5.23 to 2.5.31.; [GitHub Release Notes](https://github.com/akka/akka/releases/tag/v2.5.31) - [Version Diff](https://github.com/akka/akka/compare/v2.5.23...v2.5.31). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/a2a47735b8b5ce3b0b0a9fa0a2cdf3b8405ff98d/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.typesafe.akka"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5634:739,Config,Configure,739,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5634,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [com.typesafe.akka:akka-actor](https://github.com/akka/akka); * [com.typesafe.akka:akka-slf4j](https://github.com/akka/akka); * [com.typesafe.akka:akka-stream](https://github.com/akka/akka); * [com.typesafe.akka:akka-stream-testkit](https://github.com/akka/akka); * [com.typesafe.akka:akka-testkit](https://github.com/akka/akka). from 2.5.31 to 2.6.8.; [GitHub Release Notes](https://github.com/akka/akka/releases/tag/v2.6.8) - [Version Diff](https://github.com/akka/akka/compare/v2.5.31...v2.6.8). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/e6e484297151f4295e46ab0ef4aeb2de13a91724/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.typesafe.akka"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5755:736,Config,Configure,736,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5755,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [com.typesafe.akka:akka-actor](https://github.com/akka/akka); * [com.typesafe.akka:akka-slf4j](https://github.com/akka/akka); * [com.typesafe.akka:akka-stream](https://github.com/akka/akka); * [com.typesafe.akka:akka-stream-testkit](https://github.com/akka/akka); * [com.typesafe.akka:akka-testkit](https://github.com/akka/akka). from 2.6.8 to 2.6.9.; [GitHub Release Notes](https://github.com/akka/akka/releases/tag/v2.6.9) - [Version Diff](https://github.com/akka/akka/compare/v2.6.8...v2.6.9). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/e243c83e9a1ecb490a2f5ee163ab6feb857bd29d/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.typesafe.akka"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5840:734,Config,Configure,734,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5840,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [com.typesafe.akka:akka-actor](https://github.com/akka/akka); * [com.typesafe.akka:akka-slf4j](https://github.com/akka/akka); * [com.typesafe.akka:akka-stream](https://github.com/akka/akka); * [com.typesafe.akka:akka-stream-testkit](https://github.com/akka/akka); * [com.typesafe.akka:akka-testkit](https://github.com/akka/akka). from 2.6.9 to 2.6.10.; [GitHub Release Notes](https://github.com/akka/akka/releases/tag/v2.6.10) - [Version Diff](https://github.com/akka/akka/compare/v2.6.9...v2.6.10). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/0484b2e331da8203ec4270291416c96540bebe35/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.typesafe.akka"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5927:737,Config,Configure,737,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5927,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [com.typesafe.akka:akka-http](https://github.com/akka/akka-http); * [com.typesafe.akka:akka-http-spray-json](https://github.com/akka/akka-http); * [com.typesafe.akka:akka-http-testkit](https://github.com/akka/akka-http). from 10.1.12 to 10.2.0.; [GitHub Release Notes](https://github.com/akka/akka-http/releases/tag/v10.2.0) - [Version Diff](https://github.com/akka/akka-http/compare/v10.1.12...v10.2.0). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/e6e484297151f4295e46ab0ef4aeb2de13a91724/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.typesafe.akka"" } ]; ```; </details>; <details>; <summary>Applied Migrations</summary>. * dependency:MigrateToServerBuilder@com.typesafe.akka:akka-http-scalafix-rules:10.2.0. Documentation:. * https://doc.akka.io/docs/akka-http/10.2/migration-guide/migration-guide-10.2.x.html#akka-http-10-1-x-10-2-0; </details>. labels: library-update, semver-minor, scalafix-migrations",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5757:642,Config,Configure,642,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5757,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [com.typesafe.akka:akka-http](https://github.com/akka/akka-http); * [com.typesafe.akka:akka-http-spray-json](https://github.com/akka/akka-http); * [com.typesafe.akka:akka-http-testkit](https://github.com/akka/akka-http). from 10.1.12 to 10.2.1.; [GitHub Release Notes](https://github.com/akka/akka-http/releases/tag/v10.2.1) - [Version Diff](https://github.com/akka/akka-http/compare/v10.1.12...v10.2.1). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/a2cea0f1f72f13b38f3b5cb01ae3cad04a58aff0/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.typesafe.akka"" } ]; ```; </details>; <details>; <summary>Applied Migrations</summary>. * dependency:MigrateToServerBuilder@com.typesafe.akka:akka-http-scalafix-rules:10.2.0. Documentation:. * https://doc.akka.io/docs/akka-http/10.2/migration-guide/migration-guide-10.2.x.html#akka-http-10-1-x-10-2-0; </details>. labels: library-update, semver-minor, scalafix-migrations",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5913:642,Config,Configure,642,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5913,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [com.typesafe.akka:akka-http](https://github.com/akka/akka-http); * [com.typesafe.akka:akka-http-spray-json](https://github.com/akka/akka-http); * [com.typesafe.akka:akka-http-testkit](https://github.com/akka/akka-http). from 10.1.15 to 10.2.9.; [GitHub Release Notes](https://github.com/akka/akka-http/releases/tag/v10.2.9) - [Version Diff](https://github.com/akka/akka-http/compare/v10.1.15...v10.2.9). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/2dc2301e75aea6c2d0c49b89d6092f7d4f134b40/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Applied Scalafix Migrations</summary>. * com.typesafe.akka:akka-http.*:10.2.0 (created no change); * dependency:MigrateToServerBuilder@com.typesafe.akka:akka-http-scalafix-rules:10.2.0; * Documentation: https://doc.akka.io/docs/akka-http/10.2/migration-guide/migration-guide-10.2.x.html#akka-http-10-1-x-10-2-0; </details>; <details>; <summary>Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.typesafe.akka"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""@monthly"" },; dependency = { groupId = ""com.typesafe.akka"" }; }]; ```; </details>. labels: library-update, early-semver-minor, semver-spec-minor, scalafix-migrations, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6869:642,Config,Configure,642,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6869,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [com.typesafe.akka:akka-http](https://github.com/akka/akka-http); * [com.typesafe.akka:akka-http-spray-json](https://github.com/akka/akka-http); * [com.typesafe.akka:akka-http-testkit](https://github.com/akka/akka-http). from 10.1.9 to 10.1.12.; [GitHub Release Notes](https://github.com/akka/akka-http/releases/tag/v10.1.12) - [Version Diff](https://github.com/akka/akka-http/compare/v10.1.9...v10.1.12). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/a2a47735b8b5ce3b0b0a9fa0a2cdf3b8405ff98d/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.typesafe.akka"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5635:643,Config,Configure,643,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5635,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [com.typesafe.slick:slick](https://github.com/slick/slick); * [com.typesafe.slick:slick-hikaricp](https://github.com/slick/slick). from 3.4.0-M1 to 3.4.0.; [GitHub Release Notes](https://github.com/slick/slick/releases/tag/v3.4.0) - [Version Diff](https://github.com/slick/slick/compare/v3.4.0-M1...v3.4.0). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/2dc2301e75aea6c2d0c49b89d6092f7d4f134b40/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.typesafe.slick"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""@monthly"" },; dependency = { groupId = ""com.typesafe.slick"" }; }]; ```; </details>. labels: library-update, early-semver-pre-release, semver-spec-pre-release, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6872:545,Config,Configure,545,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6872,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [com.typesafe.slick:slick](https://github.com/slick/slick); * [com.typesafe.slick:slick-hikaricp](https://github.com/slick/slick). from 3.4.0-M1 to 3.4.1.; [GitHub Release Notes](https://github.com/slick/slick/releases/tag/v3.4.1) - [Version Diff](https://github.com/slick/slick/compare/v3.4.0-M1...v3.4.1). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/9367739b48d1bae5766674e547f8cdf8a82d318a/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.typesafe.slick"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""com.typesafe.slick"" }; }]; ```; </details>. labels: library-update, early-semver-pre-release, semver-spec-pre-release, version-scheme:pvp, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7045:545,Config,Configure,545,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7045,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [io.circe:circe-core](https://github.com/circe/circe); * [io.circe:circe-generic](https://github.com/circe/circe); * [io.circe:circe-generic-extras](https://github.com/circe/circe-generic-extras); * [io.circe:circe-literal](https://github.com/circe/circe); * [io.circe:circe-optics](https://github.com/circe/circe-optics); * [io.circe:circe-parser](https://github.com/circe/circe); * [io.circe:circe-refined](https://github.com/circe/circe); * [io.circe:circe-shapes](https://github.com/circe/circe). from 0.13.0 to 0.14.1.; [GitHub Release Notes](https://github.com/circe/circe/releases/tag/v0.14.1) - [Version Diff](https://github.com/circe/circe/compare/v0.13.0...v0.14.1). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/92f43ce5f010fa03daeb2625a3f9c1b1be80cca5/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Files still referring to the old version number</summary>. The following files still refer to the old version number (0.13.0).; You might want to review and update them manually.; ```; centaur/src/main/resources/integrationTestCases/cwl/bcbio/gvcf-joint-workflow/steps/process_alignment.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/gvcf-joint-workflow/steps/variantcall_batch_region.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/prealign-workflow/steps/variantcall_batch_region.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/rnaseq-workflow/steps/prepare_sample.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/somatic-workflow/steps/detect_sv.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/somatic-workflow/steps/process_alignment.cw",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6410:914,Config,Configure,914,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6410,1,['Config'],['Configure']
Modifiability,"Updates ; * [io.circe:circe-core](https://github.com/circe/circe); * [io.circe:circe-generic](https://github.com/circe/circe); * [io.circe:circe-generic-extras](https://github.com/circe/circe-generic-extras); * [io.circe:circe-literal](https://github.com/circe/circe); * [io.circe:circe-parser](https://github.com/circe/circe); * [io.circe:circe-refined](https://github.com/circe/circe); * [io.circe:circe-shapes](https://github.com/circe/circe). from 0.14.1 to 0.14.2.; [GitHub Release Notes](https://github.com/circe/circe/releases/tag/v0.14.2) - [Version Diff](https://github.com/circe/circe/compare/v0.14.1...v0.14.2). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/2dc2301e75aea6c2d0c49b89d6092f7d4f134b40/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""io.circe"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""@monthly"" },; dependency = { groupId = ""io.circe"" }; }]; ```; </details>. labels: library-update, early-semver-minor, semver-spec-patch, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6874:848,Config,Configure,848,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6874,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [io.circe:circe-core](https://github.com/circe/circe); * [io.circe:circe-generic](https://github.com/circe/circe); * [io.circe:circe-literal](https://github.com/circe/circe); * [io.circe:circe-parser](https://github.com/circe/circe); * [io.circe:circe-refined](https://github.com/circe/circe); * [io.circe:circe-shapes](https://github.com/circe/circe). from 0.12.1 to 0.12.3.; [GitHub Release Notes](https://github.com/circe/circe/releases/tag/v0.12.3) - [Version Diff](https://github.com/circe/circe/compare/v0.12.1...v0.12.3). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/a2a47735b8b5ce3b0b0a9fa0a2cdf3b8405ff98d/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""io.circe"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5640:766,Config,Configure,766,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5640,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [io.circe:circe-core](https://github.com/circe/circe); * [io.circe:circe-generic](https://github.com/circe/circe); * [io.circe:circe-literal](https://github.com/circe/circe); * [io.circe:circe-parser](https://github.com/circe/circe); * [io.circe:circe-refined](https://github.com/circe/circe); * [io.circe:circe-shapes](https://github.com/circe/circe). from 0.12.3 to 0.13.0.; [GitHub Release Notes](https://github.com/circe/circe/releases/tag/v0.13.0) - [Version Diff](https://github.com/circe/circe/compare/v0.12.3...v0.13.0). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/3208ffc94f1fcd586eda4a559961d1ef013f8952/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""io.circe"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5739:766,Config,Configure,766,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5739,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [io.circe:circe-core](https://github.com/circe/circe); * [io.circe:circe-generic](https://github.com/circe/circe); * [io.circe:circe-literal](https://github.com/circe/circe); * [io.circe:circe-parser](https://github.com/circe/circe); * [io.circe:circe-refined](https://github.com/circe/circe); * [io.circe:circe-shapes](https://github.com/circe/circe). from 0.14.1 to 0.14.4.; [GitHub Release Notes](https://github.com/circe/circe/releases/tag/v0.14.4) - [Version Diff](https://github.com/circe/circe/compare/v0.14.1...v0.14.4). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/9367739b48d1bae5766674e547f8cdf8a82d318a/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""io.circe"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""io.circe"" }; }]; ```; </details>. labels: library-update, early-semver-minor, semver-spec-patch, version-scheme:early-semver, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7048:766,Config,Configure,766,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7048,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [io.github.jbwheatley:pact4s-circe](https://github.com/jbwheatley/pact4s); * [io.github.jbwheatley:pact4s-scalatest](https://github.com/jbwheatley/pact4s). from 0.7.0 to 0.8.0.; [GitHub Release Notes](https://github.com/jbwheatley/pact4s/releases/tag/v0.8.0) - [Version Diff](https://github.com/jbwheatley/pact4s/compare/v0.7.0...v0.8.0). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/9367739b48d1bae5766674e547f8cdf8a82d318a/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""io.github.jbwheatley"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""io.github.jbwheatley"" }; }]; ```; </details>. labels: library-update, early-semver-major, semver-spec-minor, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7051:576,Config,Configure,576,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7051,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [org.http4s:http4s-blaze-client](https://github.com/http4s/http4s); * [org.http4s:http4s-circe](https://github.com/http4s/http4s); * [org.http4s:http4s-dsl](https://github.com/http4s/http4s). from 0.20.0-M5 to 0.20.23.; [GitHub Release Notes](https://github.com/http4s/http4s/releases/tag/v0.20.23) - [Version Diff](https://github.com/http4s/http4s/compare/v0.20.0-M5...v0.20.23). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/a2a47735b8b5ce3b0b0a9fa0a2cdf3b8405ff98d/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""org.http4s"" } ]; ```; </details>; <details>; <summary>Applied Migrations</summary>. * github:http4s/http4s/v0_20?sha=v0.20.11. Documentation:. * https://github.com/http4s/http4s/blob/v0.20.0/docs/src/main/tut/upgrading.md; </details>. labels: library-update, semver-pre-release, scalafix-migrations",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5690:618,Config,Configure,618,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5690,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [org.http4s:http4s-blaze-client](https://github.com/http4s/http4s); * [org.http4s:http4s-circe](https://github.com/http4s/http4s); * [org.http4s:http4s-dsl](https://github.com/http4s/http4s). from 0.20.23 to 0.21.7.; [GitHub Release Notes](https://github.com/http4s/http4s/releases/tag/v0.21.7) - [Version Diff](https://github.com/http4s/http4s/compare/v0.20.23...v0.21.7). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/6fa5051c5aeeaaae7870cefd2d9908da221f2f61/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""org.http4s"" } ]; ```; </details>; <details>; <summary>Applied Migrations</summary>. * dependency:v0_21@org.http4s:http4s-scalafix:0.21.5. Documentation:. * https://github.com/http4s/http4s/releases/tag/v0.21.5; </details>. labels: library-update, semver-minor, scalafix-migrations",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5783:611,Config,Configure,611,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5783,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [org.http4s:http4s-blaze-client](https://github.com/http4s/http4s); * [org.http4s:http4s-circe](https://github.com/http4s/http4s); * [org.http4s:http4s-dsl](https://github.com/http4s/http4s). from 0.21.31 to 0.21.33.; [GitHub Release Notes](https://github.com/http4s/http4s/releases/tag/v0.21.33) - [Version Diff](https://github.com/http4s/http4s/compare/v0.21.31...v0.21.33). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/2dc2301e75aea6c2d0c49b89d6092f7d4f134b40/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""org.http4s"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""@monthly"" },; dependency = { groupId = ""org.http4s"" }; }]; ```; </details>. labels: library-update, early-semver-minor, semver-spec-patch, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6885:614,Config,Configure,614,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6885,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [org.http4s:http4s-blaze-client](https://github.com/http4s/http4s); * [org.http4s:http4s-circe](https://github.com/http4s/http4s); * [org.http4s:http4s-dsl](https://github.com/http4s/http4s). from 0.21.31 to 0.21.34.; [GitHub Release Notes](https://github.com/http4s/http4s/releases/tag/v0.21.34) - [Version Diff](https://github.com/http4s/http4s/compare/v0.21.31...v0.21.34). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/9367739b48d1bae5766674e547f8cdf8a82d318a/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""org.http4s"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""org.http4s"" }; }]; ```; </details>. labels: library-update, early-semver-minor, semver-spec-patch, version-scheme:early-semver, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7067:614,Config,Configure,614,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7067,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [org.http4s:http4s-blaze-client](https://github.com/http4s/http4s); * [org.http4s:http4s-circe](https://github.com/http4s/http4s); * [org.http4s:http4s-dsl](https://github.com/http4s/http4s). from 0.21.7 to 0.21.11.; [GitHub Release Notes](https://github.com/http4s/http4s/releases/tag/v0.21.11) - [Version Diff](https://github.com/http4s/http4s/compare/v0.21.7...v0.21.11). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/a466aae6799dfbe77f6f281b7356be94298bc263/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""org.http4s"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6077:612,Config,Configure,612,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6077,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [org.http4s:http4s-blaze-client](https://github.com/http4s/http4s); * [org.http4s:http4s-circe](https://github.com/http4s/http4s); * [org.http4s:http4s-dsl](https://github.com/http4s/http4s). from 0.21.7 to 0.21.12.; [GitHub Release Notes](https://github.com/http4s/http4s/releases/tag/v0.21.12) - [Version Diff](https://github.com/http4s/http4s/compare/v0.21.7...v0.21.12). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/655e862ba5923af5156c8eba273fecbd0574c050/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""org.http4s"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6095:612,Config,Configure,612,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6095,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [org.http4s:http4s-blaze-client](https://github.com/http4s/http4s); * [org.http4s:http4s-circe](https://github.com/http4s/http4s); * [org.http4s:http4s-dsl](https://github.com/http4s/http4s). from 0.21.7 to 0.21.13.; [GitHub Release Notes](https://github.com/http4s/http4s/releases/tag/v0.21.13) - [Version Diff](https://github.com/http4s/http4s/compare/v0.21.7...v0.21.13). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/8b865bafda2da230e526f4f89efbfab6b6387017/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""org.http4s"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6097:612,Config,Configure,612,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6097,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [org.http4s:http4s-blaze-client](https://github.com/http4s/http4s); * [org.http4s:http4s-circe](https://github.com/http4s/http4s); * [org.http4s:http4s-dsl](https://github.com/http4s/http4s). from 0.21.7 to 0.21.8.; [GitHub Release Notes](https://github.com/http4s/http4s/releases/tag/v0.21.8) - [Version Diff](https://github.com/http4s/http4s/compare/v0.21.7...v0.21.8). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/0cc8cce3e01047b30f29ddc8a860a489e42fb85c/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""org.http4s"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5950:609,Config,Configure,609,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5950,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [org.http4s:http4s-blaze-client](https://github.com/http4s/http4s); * [org.http4s:http4s-circe](https://github.com/http4s/http4s); * [org.http4s:http4s-dsl](https://github.com/http4s/http4s). from 0.21.7 to 0.21.9.; [GitHub Release Notes](https://github.com/http4s/http4s/releases/tag/v0.21.9) - [Version Diff](https://github.com/http4s/http4s/compare/v0.21.7...v0.21.9). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/85a05eee7a9df30d4fc94d5c498a96a1ba248214/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""org.http4s"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6044:609,Config,Configure,609,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6044,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [org.slf4j:log4j-over-slf4j](http://www.slf4j.org); * [org.slf4j:slf4j-api](http://www.slf4j.org). from 1.7.25 to 1.7.30. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/a2a47735b8b5ce3b0b0a9fa0a2cdf3b8405ff98d/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""org.slf4j"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5678:359,Config,Configure,359,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5678,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [org.slf4j:log4j-over-slf4j](http://www.slf4j.org); * [org.slf4j:slf4j-api](http://www.slf4j.org). from 1.7.30 to 1.7.31. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/92f43ce5f010fa03daeb2625a3f9c1b1be80cca5/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Files still referring to the old version number</summary>. The following files still refer to the old version number (1.7.30).; You might want to review and update them manually.; ```; core/src/main/scala/cromwell/core/logging/LoggerWrapper.scala; project/Dependencies.scala; ```; </details>; <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""org.slf4j"" } ]; ```; </details>. labels: library-update, semver-patch, old-version-remains",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6423:359,Config,Configure,359,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6423,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [org.typelevel:alleycats-core](https://github.com/typelevel/cats); * [org.typelevel:cats-core](https://github.com/typelevel/cats). from 2.0.0 to 2.1.1.; [GitHub Release Notes](https://github.com/typelevel/cats/releases/tag/v2.1.1) - [Changelog](https://github.com/typelevel/cats/blob/master/CHANGES.md) - [Version Diff](https://github.com/typelevel/cats/compare/v2.0.0...v2.1.1). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/a2a47735b8b5ce3b0b0a9fa0a2cdf3b8405ff98d/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""org.typelevel"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5681:617,Config,Configure,617,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5681,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [org.typelevel:alleycats-core](https://github.com/typelevel/cats); * [org.typelevel:cats-core](https://github.com/typelevel/cats). from 2.1.1 to 2.2.0.; [GitHub Release Notes](https://github.com/typelevel/cats/releases/tag/v2.2.0) - [Changelog](https://github.com/typelevel/cats/blob/master/CHANGES.md) - [Version Diff](https://github.com/typelevel/cats/compare/v2.1.1...v2.2.0). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/a7d4a20023a46ac28c61ae0f151a7f234d737251/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""org.typelevel"" } ]; ```; </details>; <details>; <summary>Applied Migrations</summary>. * github:typelevel/cats/Cats_v2_2_0. Documentation:. * https://github.com/typelevel/cats/blob/master/scalafix/README.md#migration-to-cats-v220; </details>. labels: library-update, semver-minor, scalafix-migrations",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5829:617,Config,Configure,617,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5829,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [org.typelevel:alleycats-core](https://github.com/typelevel/cats); * [org.typelevel:cats-core](https://github.com/typelevel/cats). from 2.2.0 to 2.3.0.; [GitHub Release Notes](https://github.com/typelevel/cats/releases/tag/v2.3.0) - [Changelog](https://github.com/typelevel/cats/blob/master/CHANGES.md) - [Version Diff](https://github.com/typelevel/cats/compare/v2.2.0...v2.3.0). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/5c67c65b38598b57fee29da39645bd8a5df52a9a/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""org.typelevel"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6098:617,Config,Configure,617,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6098,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [org.typelevel:alleycats-core](https://github.com/typelevel/cats); * [org.typelevel:cats-core](https://github.com/typelevel/cats). from 2.3.0 to 2.3.1.; [GitHub Release Notes](https://github.com/typelevel/cats/releases/tag/v2.3.1) - [Changelog](https://github.com/typelevel/cats/blob/master/CHANGES.md) - [Version Diff](https://github.com/typelevel/cats/compare/v2.3.0...v2.3.1). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/b48aba70ec793405c98788a322d160987ba51d3e/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Files still referring to the old version number</summary>. The following files still refer to the old version number (2.3.0).; You might want to review and update them manually.; ```; centaur/src/main/resources/integrationTestCases/germline/single-sample-workflow/processing-for-variant-discovery-gatk4.hg38.wgs.aws.inputs.json; centaur/src/main/resources/integrationTestCases/germline/single-sample-workflow/processing-for-variant-discovery-gatk4.hg38.wgs.inputs.json; ```; </details>; <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""org.typelevel"" } ]; ```; </details>. labels: library-update, semver-patch, old-version-remains",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6278:617,Config,Configure,617,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6278,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [org.typelevel:alleycats-core](https://github.com/typelevel/cats); * [org.typelevel:cats-core](https://github.com/typelevel/cats). from 2.3.1 to 2.6.1.; [GitHub Release Notes](https://github.com/typelevel/cats/releases/tag/v2.6.1) - [Changelog](https://github.com/typelevel/cats/blob/master/CHANGES.md) - [Version Diff](https://github.com/typelevel/cats/compare/v2.3.1...v2.6.1). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/92f43ce5f010fa03daeb2625a3f9c1b1be80cca5/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Files still referring to the old version number</summary>. The following files still refer to the old version number (2.3.1).; You might want to review and update them manually.; ```; centaur/src/main/resources/integrationTestCases/germline/single-sample-production-workflow/PairedEndSingleSampleWf.wdl; project/Dependencies.scala; ```; </details>; <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""org.typelevel"" } ]; ```; </details>. labels: library-update, semver-minor, old-version-remains",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6425:617,Config,Configure,617,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6425,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [org.typelevel:alleycats-core](https://github.com/typelevel/cats); * [org.typelevel:cats-core](https://github.com/typelevel/cats). from 2.6.1 to 2.7.0.; [GitHub Release Notes](https://github.com/typelevel/cats/releases/tag/v2.7.0) - [Version Diff](https://github.com/typelevel/cats/compare/v2.6.1...v2.7.0). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/00809e6249b134635f71919c17c1c81603beb22d/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""org.typelevel"" } ]; ```; </details>. labels: library-update, early-semver-minor, semver-spec-minor, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6632:545,Config,Configure,545,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6632,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [org.typelevel:alleycats-core](https://github.com/typelevel/cats); * [org.typelevel:cats-core](https://github.com/typelevel/cats). from 2.7.0 to 2.8.0.; [GitHub Release Notes](https://github.com/typelevel/cats/releases/tag/v2.8.0) - [Version Diff](https://github.com/typelevel/cats/compare/v2.7.0...v2.8.0). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/2dc2301e75aea6c2d0c49b89d6092f7d4f134b40/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Files still referring to the old version number</summary>. The following files still refer to the old version number (2.7.0).; You might want to review and update them manually.; ```; services/src/test/scala/cromwell/services/database/QueryTimeoutSpec.scala; ```; </details>; <details>; <summary>Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""org.typelevel"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""@monthly"" },; dependency = { groupId = ""org.typelevel"" }; }]; ```; </details>. labels: library-update, early-semver-minor, semver-spec-minor, old-version-remains, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6897:545,Config,Configure,545,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6897,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [org.typelevel:alleycats-core](https://github.com/typelevel/cats); * [org.typelevel:cats-core](https://github.com/typelevel/cats). from 2.7.0 to 2.9.0.; [GitHub Release Notes](https://github.com/typelevel/cats/releases/tag/v2.9.0) - [Version Diff](https://github.com/typelevel/cats/compare/v2.7.0...v2.9.0). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/9367739b48d1bae5766674e547f8cdf8a82d318a/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Files still referring to the old version number</summary>. The following files still refer to the old version number (2.7.0).; You might want to review and update them manually.; ```; services/src/test/scala/cromwell/services/database/QueryTimeoutSpec.scala; ```; </details>; <details>; <summary>Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""org.typelevel"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""org.typelevel"" }; }]; ```; </details>. labels: library-update, early-semver-minor, semver-spec-minor, version-scheme:early-semver, old-version-remains, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7077:545,Config,Configure,545,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7077,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [software.amazon.awssdk:batch](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:cloudwatchlogs](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:core](https://github.com/aws/aws-sdk-java-v2.git); * [software.amazon.awssdk:ecs](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:s3](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:sts](https://aws.amazon.com/sdkforjava). from 2.14.28 to 2.15.19. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/b1f7a98dc53b198512d5509de8ee6860fec1cc6c/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6008:684,Config,Configure,684,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6008,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [software.amazon.awssdk:batch](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:cloudwatchlogs](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:core](https://github.com/aws/aws-sdk-java-v2.git); * [software.amazon.awssdk:ecs](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:s3](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:sts](https://aws.amazon.com/sdkforjava). from 2.14.28 to 2.15.20. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/b81ddda677fdf5b341d0edd6a6b1fb511472e7f0/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6012:684,Config,Configure,684,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6012,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [software.amazon.awssdk:batch](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:cloudwatchlogs](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:core](https://github.com/aws/aws-sdk-java-v2.git); * [software.amazon.awssdk:ecs](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:s3](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:sts](https://aws.amazon.com/sdkforjava). from 2.14.28 to 2.15.21. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/241699fed34d4870884f4f086e6f107da0954d21/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6018:684,Config,Configure,684,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6018,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [software.amazon.awssdk:batch](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:cloudwatchlogs](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:core](https://github.com/aws/aws-sdk-java-v2.git); * [software.amazon.awssdk:ecs](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:s3](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:sts](https://aws.amazon.com/sdkforjava). from 2.14.28 to 2.15.22. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/8e304dec90b4fd6d16691e94f33d6c40327886d9/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6021:684,Config,Configure,684,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6021,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [software.amazon.awssdk:batch](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:cloudwatchlogs](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:core](https://github.com/aws/aws-sdk-java-v2.git); * [software.amazon.awssdk:ecs](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:s3](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:sts](https://aws.amazon.com/sdkforjava). from 2.14.28 to 2.15.23. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/b39f66e9e52c1afeea26901c5aff972e27907584/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6025:684,Config,Configure,684,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6025,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [software.amazon.awssdk:batch](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:cloudwatchlogs](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:core](https://github.com/aws/aws-sdk-java-v2.git); * [software.amazon.awssdk:ecs](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:s3](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:sts](https://aws.amazon.com/sdkforjava). from 2.14.28 to 2.15.24. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/cc6f924b2a099b9f1462efa2007aa2a8c190c877/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6036:684,Config,Configure,684,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6036,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [software.amazon.awssdk:batch](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:cloudwatchlogs](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:core](https://github.com/aws/aws-sdk-java-v2.git); * [software.amazon.awssdk:ecs](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:s3](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:sts](https://aws.amazon.com/sdkforjava). from 2.14.28 to 2.15.25. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/8103d0289c2ae3f66a24a2e3cc4ca0f2257ca28a/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6041:684,Config,Configure,684,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6041,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [software.amazon.awssdk:batch](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:cloudwatchlogs](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:core](https://github.com/aws/aws-sdk-java-v2.git); * [software.amazon.awssdk:ecs](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:s3](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:sts](https://aws.amazon.com/sdkforjava). from 2.14.28 to 2.15.26. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/d844bec33e331a8f5c572f624947b7404cc86b55/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6045:684,Config,Configure,684,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6045,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [software.amazon.awssdk:batch](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:cloudwatchlogs](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:core](https://github.com/aws/aws-sdk-java-v2.git); * [software.amazon.awssdk:ecs](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:s3](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:sts](https://aws.amazon.com/sdkforjava). from 2.14.28 to 2.15.27. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/f5296f1943ce3d75343e031aad80d0947a118e00/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6046:684,Config,Configure,684,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6046,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [software.amazon.awssdk:batch](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:cloudwatchlogs](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:core](https://github.com/aws/aws-sdk-java-v2.git); * [software.amazon.awssdk:ecs](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:s3](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:sts](https://aws.amazon.com/sdkforjava). from 2.14.28 to 2.15.28. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/5d5e47419171410e1eac2c7a05777d64ce4bbdaa/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6049:684,Config,Configure,684,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6049,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [software.amazon.awssdk:batch](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:cloudwatchlogs](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:core](https://github.com/aws/aws-sdk-java-v2.git); * [software.amazon.awssdk:ecs](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:s3](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:sts](https://aws.amazon.com/sdkforjava). from 2.14.28 to 2.15.29. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/decdb10fae28eabe90cd4382952ae2bf0956273f/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6057:684,Config,Configure,684,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6057,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [software.amazon.awssdk:batch](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:cloudwatchlogs](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:core](https://github.com/aws/aws-sdk-java-v2.git); * [software.amazon.awssdk:ecs](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:s3](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:sts](https://aws.amazon.com/sdkforjava). from 2.14.28 to 2.15.30. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/b0f7471dc9fc547e00d32ff7a800073ea1d1951d/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6064:684,Config,Configure,684,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6064,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [software.amazon.awssdk:batch](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:cloudwatchlogs](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:core](https://github.com/aws/aws-sdk-java-v2.git); * [software.amazon.awssdk:ecs](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:s3](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:sts](https://aws.amazon.com/sdkforjava). from 2.14.28 to 2.15.31. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/928dbc6c4aa0c8a6aef19af027ec7112700b8163/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6069:684,Config,Configure,684,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6069,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [software.amazon.awssdk:batch](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:cloudwatchlogs](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:core](https://github.com/aws/aws-sdk-java-v2.git); * [software.amazon.awssdk:ecs](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:s3](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:sts](https://aws.amazon.com/sdkforjava). from 2.14.28 to 2.15.32. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/e1834055a86ba97fe5a5b4120fb60f80bf8aca15/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6074:684,Config,Configure,684,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6074,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [software.amazon.awssdk:batch](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:cloudwatchlogs](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:core](https://github.com/aws/aws-sdk-java-v2.git); * [software.amazon.awssdk:ecs](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:s3](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:sts](https://aws.amazon.com/sdkforjava). from 2.14.28 to 2.15.33. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/a466aae6799dfbe77f6f281b7356be94298bc263/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6078:684,Config,Configure,684,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6078,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [software.amazon.awssdk:batch](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:cloudwatchlogs](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:core](https://github.com/aws/aws-sdk-java-v2.git); * [software.amazon.awssdk:ecs](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:s3](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:sts](https://aws.amazon.com/sdkforjava). from 2.14.28 to 2.15.34. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/04b9d423d4830f1fd86d680ecef2d6372c8ec937/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6086:684,Config,Configure,684,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6086,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [software.amazon.awssdk:batch](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:cloudwatchlogs](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:core](https://github.com/aws/aws-sdk-java-v2.git); * [software.amazon.awssdk:ecs](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:s3](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:sts](https://aws.amazon.com/sdkforjava). from 2.14.28 to 2.15.35. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/655e862ba5923af5156c8eba273fecbd0574c050/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6090:684,Config,Configure,684,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6090,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [software.amazon.awssdk:batch](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:cloudwatchlogs](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:core](https://github.com/aws/aws-sdk-java-v2.git); * [software.amazon.awssdk:ecs](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:s3](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:sts](https://aws.amazon.com/sdkforjava). from 2.14.28 to 2.15.36. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/a60fe5f8af7a9f774089ba0e16e734ade34f1137/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6109:684,Config,Configure,684,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6109,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [software.amazon.awssdk:batch](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:cloudwatchlogs](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:core](https://github.com/aws/aws-sdk-java-v2.git); * [software.amazon.awssdk:ecs](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:s3](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:sts](https://aws.amazon.com/sdkforjava). from 2.14.28 to 2.15.37. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/d1cab327f976e108b123dc39aed7d998c40fd2d1/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6111:684,Config,Configure,684,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6111,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [software.amazon.awssdk:batch](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:cloudwatchlogs](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:core](https://github.com/aws/aws-sdk-java-v2.git); * [software.amazon.awssdk:ecs](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:s3](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:sts](https://aws.amazon.com/sdkforjava). from 2.14.28 to 2.15.38. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/d1cab327f976e108b123dc39aed7d998c40fd2d1/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6113:684,Config,Configure,684,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6113,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [software.amazon.awssdk:batch](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:cloudwatchlogs](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:core](https://github.com/aws/aws-sdk-java-v2.git); * [software.amazon.awssdk:ecs](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:s3](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:sts](https://aws.amazon.com/sdkforjava). from 2.14.28 to 2.15.39. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/cdb6299c31f426ad6b103bb16665a8618ff1fb79/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6119:684,Config,Configure,684,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6119,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [software.amazon.awssdk:batch](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:cloudwatchlogs](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:core](https://github.com/aws/aws-sdk-java-v2.git); * [software.amazon.awssdk:ecs](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:s3](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:sts](https://aws.amazon.com/sdkforjava). from 2.14.28 to 2.15.40. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/1a614dffe154286ca442fe90fb079043b2c54f6b/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6124:684,Config,Configure,684,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6124,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [software.amazon.awssdk:batch](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:cloudwatchlogs](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:core](https://github.com/aws/aws-sdk-java-v2.git); * [software.amazon.awssdk:ecs](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:s3](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:sts](https://aws.amazon.com/sdkforjava). from 2.14.28 to 2.15.41. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/e5948201aaa709db09b45255a7276df2715e1800/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6129:684,Config,Configure,684,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6129,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [software.amazon.awssdk:batch](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:cloudwatchlogs](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:core](https://github.com/aws/aws-sdk-java-v2.git); * [software.amazon.awssdk:ecs](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:s3](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:sts](https://aws.amazon.com/sdkforjava). from 2.15.41 to 2.15.82. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/b48aba70ec793405c98788a322d160987ba51d3e/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6283:684,Config,Configure,684,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6283,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * [software.amazon.awssdk:batch](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:cloudwatchlogs](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:core](https://github.com/aws/aws-sdk-java-v2.git); * [software.amazon.awssdk:ecs](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:s3](https://aws.amazon.com/sdkforjava); * [software.amazon.awssdk:sts](https://aws.amazon.com/sdkforjava). from 2.17.29 to 2.17.50. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/6472b97b3365f2800f4202d1bf6b1d647bd2b0cc/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6537:684,Config,Configure,684,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6537,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * ch.qos.logback:logback-access; * ch.qos.logback:logback-classic; * ch.qos.logback:logback-core. from 1.2.10 to 1.2.11. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/2dc2301e75aea6c2d0c49b89d6092f7d4f134b40/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""ch.qos.logback"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""@monthly"" },; dependency = { groupId = ""ch.qos.logback"" }; }]; ```; </details>. labels: library-update, early-semver-patch, semver-spec-patch, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6842:356,Config,Configure,356,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6842,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * ch.qos.logback:logback-access; * ch.qos.logback:logback-classic; * ch.qos.logback:logback-core. from 1.2.5 to 1.2.6. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/6472b97b3365f2800f4202d1bf6b1d647bd2b0cc/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Files still referring to the old version number</summary>. The following files still refer to the old version number (1.2.5).; You might want to review and update them manually.; ```; cwl/src/test/resources/cwl/ontology/EDAM.owl; ```; </details>; <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""ch.qos.logback"" } ]; ```; </details>. labels: library-update, semver-patch, old-version-remains",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6511:354,Config,Configure,354,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6511,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * ch.qos.logback:logback-access; * ch.qos.logback:logback-classic; * ch.qos.logback:logback-core. from 1.2.6 to 1.2.10. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/00809e6249b134635f71919c17c1c81603beb22d/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""ch.qos.logback"" } ]; ```; </details>. labels: library-update, early-semver-patch, semver-spec-patch, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6598:355,Config,Configure,355,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6598,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * com.dimafeng:testcontainers-scala-mariadb; * com.dimafeng:testcontainers-scala-mysql; * com.dimafeng:testcontainers-scala-postgresql; * com.dimafeng:testcontainers-scala-scalatest. from 0.35.2 to 0.38.1. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/a2a47735b8b5ce3b0b0a9fa0a2cdf3b8405ff98d/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.dimafeng"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5609:441,Config,Configure,441,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5609,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * com.dimafeng:testcontainers-scala-mariadb; * com.dimafeng:testcontainers-scala-mysql; * com.dimafeng:testcontainers-scala-postgresql; * com.dimafeng:testcontainers-scala-scalatest. from 0.38.1 to 0.38.3. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/5e7fd713ca5ed5fb400c4f4a7d7194fc5905c7f0/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.dimafeng"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5835:441,Config,Configure,441,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5835,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * com.dimafeng:testcontainers-scala-mariadb; * com.dimafeng:testcontainers-scala-mysql; * com.dimafeng:testcontainers-scala-postgresql; * com.dimafeng:testcontainers-scala-scalatest. from 0.38.3 to 0.38.4. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/c2f8651b27f1d1f1a9b3fe31cff369b1aa8f38e1/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.dimafeng"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5895:441,Config,Configure,441,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5895,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * com.dimafeng:testcontainers-scala-mariadb; * com.dimafeng:testcontainers-scala-mysql; * com.dimafeng:testcontainers-scala-postgresql; * com.dimafeng:testcontainers-scala-scalatest. from 0.38.4 to 0.38.5. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/241699fed34d4870884f4f086e6f107da0954d21/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.dimafeng"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6015:441,Config,Configure,441,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6015,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * com.dimafeng:testcontainers-scala-mariadb; * com.dimafeng:testcontainers-scala-mysql; * com.dimafeng:testcontainers-scala-postgresql; * com.dimafeng:testcontainers-scala-scalatest. from 0.38.4 to 0.38.6. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/7a0d73f56c10291c30f5bb84d1bca29837247450/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.dimafeng"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6027:441,Config,Configure,441,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6027,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * com.dimafeng:testcontainers-scala-mariadb; * com.dimafeng:testcontainers-scala-mysql; * com.dimafeng:testcontainers-scala-postgresql; * com.dimafeng:testcontainers-scala-scalatest. from 0.38.4 to 0.38.7. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/b2eed9079613d597cbfc793c459df7e361ac36f0/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.dimafeng"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6079:441,Config,Configure,441,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6079,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * com.dimafeng:testcontainers-scala-mariadb; * com.dimafeng:testcontainers-scala-mysql; * com.dimafeng:testcontainers-scala-postgresql; * com.dimafeng:testcontainers-scala-scalatest. from 0.38.6 to 0.38.9. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/b48aba70ec793405c98788a322d160987ba51d3e/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.dimafeng"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6242:441,Config,Configure,441,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6242,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * com.dimafeng:testcontainers-scala-mariadb; * com.dimafeng:testcontainers-scala-mysql; * com.dimafeng:testcontainers-scala-postgresql; * com.dimafeng:testcontainers-scala-scalatest. from 0.38.9 to 0.39.5. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/92f43ce5f010fa03daeb2625a3f9c1b1be80cca5/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.dimafeng"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6389:441,Config,Configure,441,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6389,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * com.fasterxml.jackson.core:jackson-annotations; * [com.fasterxml.jackson.core:jackson-core](https://github.com/FasterXML/jackson-core); * com.fasterxml.jackson.core:jackson-databind. from 2.13.3 to 2.13.5. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/9367739b48d1bae5766674e547f8cdf8a82d318a/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.fasterxml.jackson.core"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""com.fasterxml.jackson.core"" }; }]; ```; </details>. labels: library-update, early-semver-patch, semver-spec-patch, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7033:443,Config,Configure,443,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7033,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * com.fasterxml.jackson.core:jackson-annotations; * com.fasterxml.jackson.core:jackson-core; * com.fasterxml.jackson.core:jackson-databind. from 2.10.0 to 2.10.5. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/a2a47735b8b5ce3b0b0a9fa0a2cdf3b8405ff98d/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.fasterxml.jackson.core"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5611:398,Config,Configure,398,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5611,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * com.fasterxml.jackson.core:jackson-annotations; * com.fasterxml.jackson.core:jackson-core; * com.fasterxml.jackson.core:jackson-databind. from 2.10.5 to 2.11.2. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/12cad616e6adbc68ad8487e1fcb064c6ef8f3d9c/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.fasterxml.jackson.core"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5705:398,Config,Configure,398,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5705,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * com.fasterxml.jackson.core:jackson-annotations; * com.fasterxml.jackson.core:jackson-core; * com.fasterxml.jackson.core:jackson-databind. from 2.11.2 to 2.11.3. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/a2cea0f1f72f13b38f3b5cb01ae3cad04a58aff0/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.fasterxml.jackson.core"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5909:398,Config,Configure,398,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5909,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * com.fasterxml.jackson.core:jackson-annotations; * com.fasterxml.jackson.core:jackson-core; * com.fasterxml.jackson.core:jackson-databind. from 2.13.0 to 2.13.1. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/00809e6249b134635f71919c17c1c81603beb22d/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.fasterxml.jackson.core"" } ]; ```; </details>. labels: library-update, early-semver-patch, semver-spec-patch, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6604:398,Config,Configure,398,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6604,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * com.softwaremill.sttp:async-http-client-backend-cats; * com.softwaremill.sttp:async-http-client-backend-future; * com.softwaremill.sttp:circe; * com.softwaremill.sttp:core. from 1.5.19 to 1.7.2. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/e6e484297151f4295e46ab0ef4aeb2de13a91724/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.softwaremill.sttp"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5753:432,Config,Configure,432,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5753,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * com.softwaremill.sttp:async-http-client-backend-cats; * com.softwaremill.sttp:async-http-client-backend-future; * com.softwaremill.sttp:circe; * com.softwaremill.sttp:core. from 1.5.8 to 1.5.19. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/a2a47735b8b5ce3b0b0a9fa0a2cdf3b8405ff98d/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.softwaremill.sttp"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5630:432,Config,Configure,432,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5630,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * com.typesafe.slick:slick; * com.typesafe.slick:slick-hikaricp. from 3.3.2-2076hotfix to 3.3.3. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/e243c83e9a1ecb490a2f5ee163ab6feb857bd29d/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.typesafe.slick"" } ]; ```; </details>. labels: library-update, semver-pre-release",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5837:332,Config,Configure,332,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5837,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * org.apache.httpcomponents:httpclient; * org.apache.httpcomponents:httpclient-cache. from 4.5.12 to 4.5.13. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/fb03b086093238c1ad9834ede829daf043e517e7/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""org.apache.httpcomponents"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5919:344,Config,Configure,344,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5919,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * org.apache.httpcomponents:httpclient; * org.apache.httpcomponents:httpclient-cache. from 4.5.7 to 4.5.12. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/a2a47735b8b5ce3b0b0a9fa0a2cdf3b8405ff98d/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""org.apache.httpcomponents"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5657:343,Config,Configure,343,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5657,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * org.slf4j:jcl-over-slf4j; * org.slf4j:jul-to-slf4j; * org.slf4j:log4j-over-slf4j; * org.slf4j:slf4j-api. from 1.7.32 to 1.7.36. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/2dc2301e75aea6c2d0c49b89d6092f7d4f134b40/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""org.slf4j"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""@monthly"" },; dependency = { groupId = ""org.slf4j"" }; }]; ```; </details>. labels: library-update, early-semver-patch, semver-spec-patch, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6896:365,Config,Configure,365,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6896,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * software.amazon.awssdk:batch; * software.amazon.awssdk:cloudwatchlogs; * software.amazon.awssdk:core; * software.amazon.awssdk:ecs; * software.amazon.awssdk:s3; * software.amazon.awssdk:sts. from 2.10.71 to 2.10.91. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/a2a47735b8b5ce3b0b0a9fa0a2cdf3b8405ff98d/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5689:453,Config,Configure,453,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5689,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * software.amazon.awssdk:batch; * software.amazon.awssdk:cloudwatchlogs; * software.amazon.awssdk:core; * software.amazon.awssdk:ecs; * software.amazon.awssdk:s3; * software.amazon.awssdk:sts. from 2.10.91 to 2.14.2. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/6fa5051c5aeeaaae7870cefd2d9908da221f2f61/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5782:452,Config,Configure,452,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5782,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * software.amazon.awssdk:batch; * software.amazon.awssdk:cloudwatchlogs; * software.amazon.awssdk:core; * software.amazon.awssdk:ecs; * software.amazon.awssdk:s3; * software.amazon.awssdk:sts. from 2.10.91 to 2.14.3. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/6fa5051c5aeeaaae7870cefd2d9908da221f2f61/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5789:452,Config,Configure,452,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5789,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * software.amazon.awssdk:batch; * software.amazon.awssdk:cloudwatchlogs; * software.amazon.awssdk:core; * software.amazon.awssdk:ecs; * software.amazon.awssdk:s3; * software.amazon.awssdk:sts. from 2.10.91 to 2.14.4. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/179507babd976dd9e0d9d5d9983ff43436b13e3b/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5801:452,Config,Configure,452,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5801,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * software.amazon.awssdk:batch; * software.amazon.awssdk:cloudwatchlogs; * software.amazon.awssdk:core; * software.amazon.awssdk:ecs; * software.amazon.awssdk:s3; * software.amazon.awssdk:sts. from 2.14.23 to 2.14.25. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/6525ca66f9e66047fdcc2b5f4391921a1dec5c61/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5889:453,Config,Configure,453,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5889,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * software.amazon.awssdk:batch; * software.amazon.awssdk:cloudwatchlogs; * software.amazon.awssdk:core; * software.amazon.awssdk:ecs; * software.amazon.awssdk:s3; * software.amazon.awssdk:sts. from 2.14.23 to 2.14.26. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/c2f8651b27f1d1f1a9b3fe31cff369b1aa8f38e1/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5893:453,Config,Configure,453,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5893,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * software.amazon.awssdk:batch; * software.amazon.awssdk:cloudwatchlogs; * software.amazon.awssdk:core; * software.amazon.awssdk:ecs; * software.amazon.awssdk:s3; * software.amazon.awssdk:sts. from 2.14.23 to 2.14.27. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/2ae97f1a550112ad4dc1f038d38808b546b012dd/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5898:453,Config,Configure,453,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5898,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * software.amazon.awssdk:batch; * software.amazon.awssdk:cloudwatchlogs; * software.amazon.awssdk:core; * software.amazon.awssdk:ecs; * software.amazon.awssdk:s3; * software.amazon.awssdk:sts. from 2.14.23 to 2.14.28. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/3569d798765e3b78dd6e5137daa8656746901411/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5900:453,Config,Configure,453,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5900,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * software.amazon.awssdk:batch; * software.amazon.awssdk:cloudwatchlogs; * software.amazon.awssdk:core; * software.amazon.awssdk:ecs; * software.amazon.awssdk:s3; * software.amazon.awssdk:sts. from 2.14.28 to 2.15.10. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/f73b36c43171cc50fa4140329f0c50e5c1cd2f97/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5959:453,Config,Configure,453,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5959,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * software.amazon.awssdk:batch; * software.amazon.awssdk:cloudwatchlogs; * software.amazon.awssdk:core; * software.amazon.awssdk:ecs; * software.amazon.awssdk:s3; * software.amazon.awssdk:sts. from 2.14.28 to 2.15.11. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/9b9e2132ceac83a8c7de02764605f2d01d173034/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5963:453,Config,Configure,453,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5963,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * software.amazon.awssdk:batch; * software.amazon.awssdk:cloudwatchlogs; * software.amazon.awssdk:core; * software.amazon.awssdk:ecs; * software.amazon.awssdk:s3; * software.amazon.awssdk:sts. from 2.14.28 to 2.15.12. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/34f2a22d62f874be4398bb76b5d5ddef377873ca/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5968:453,Config,Configure,453,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5968,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * software.amazon.awssdk:batch; * software.amazon.awssdk:cloudwatchlogs; * software.amazon.awssdk:core; * software.amazon.awssdk:ecs; * software.amazon.awssdk:s3; * software.amazon.awssdk:sts. from 2.14.28 to 2.15.13. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/34f2a22d62f874be4398bb76b5d5ddef377873ca/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5970:453,Config,Configure,453,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5970,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * software.amazon.awssdk:batch; * software.amazon.awssdk:cloudwatchlogs; * software.amazon.awssdk:core; * software.amazon.awssdk:ecs; * software.amazon.awssdk:s3; * software.amazon.awssdk:sts. from 2.14.28 to 2.15.14. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/e81563f56e6088610fac719dc8928eb652175877/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5973:453,Config,Configure,453,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5973,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * software.amazon.awssdk:batch; * software.amazon.awssdk:cloudwatchlogs; * software.amazon.awssdk:core; * software.amazon.awssdk:ecs; * software.amazon.awssdk:s3; * software.amazon.awssdk:sts. from 2.14.28 to 2.15.15. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/cfdefb42da43eace1bd844d26774e317d1ea7325/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5979:453,Config,Configure,453,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5979,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * software.amazon.awssdk:batch; * software.amazon.awssdk:cloudwatchlogs; * software.amazon.awssdk:core; * software.amazon.awssdk:ecs; * software.amazon.awssdk:s3; * software.amazon.awssdk:sts. from 2.14.28 to 2.15.16. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/5b6601d06f23b6bcc7dde9c65d8332ade7992a8d/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5980:453,Config,Configure,453,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5980,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * software.amazon.awssdk:batch; * software.amazon.awssdk:cloudwatchlogs; * software.amazon.awssdk:core; * software.amazon.awssdk:ecs; * software.amazon.awssdk:s3; * software.amazon.awssdk:sts. from 2.14.28 to 2.15.17. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/1abad4bea5c3f3d9a3dece02e6531a0b61e0359c/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5987:453,Config,Configure,453,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5987,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * software.amazon.awssdk:batch; * software.amazon.awssdk:cloudwatchlogs; * software.amazon.awssdk:core; * software.amazon.awssdk:ecs; * software.amazon.awssdk:s3; * software.amazon.awssdk:sts. from 2.14.28 to 2.15.18. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/df4c082eb88fd18ef8f8933887b246dd127ed557/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6000:453,Config,Configure,453,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6000,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * software.amazon.awssdk:batch; * software.amazon.awssdk:cloudwatchlogs; * software.amazon.awssdk:core; * software.amazon.awssdk:ecs; * software.amazon.awssdk:s3; * software.amazon.awssdk:sts. from 2.14.28 to 2.15.9. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/aebd11bb7190f4f9d4816cc1a52792a99afbf86e/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5955:452,Config,Configure,452,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5955,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * software.amazon.awssdk:batch; * software.amazon.awssdk:cloudwatchlogs; * software.amazon.awssdk:core; * software.amazon.awssdk:ecs; * software.amazon.awssdk:s3; * software.amazon.awssdk:sts. from 2.14.3 to 2.14.10. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/eebb7a7cb4b96a9a1000aad3eae551796bfafef5/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5827:452,Config,Configure,452,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5827,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * software.amazon.awssdk:batch; * software.amazon.awssdk:cloudwatchlogs; * software.amazon.awssdk:core; * software.amazon.awssdk:ecs; * software.amazon.awssdk:s3; * software.amazon.awssdk:sts. from 2.14.3 to 2.14.11. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/86c78a856e54b4c29ef6c5e14c8605ddffec432b/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5831:452,Config,Configure,452,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5831,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * software.amazon.awssdk:batch; * software.amazon.awssdk:cloudwatchlogs; * software.amazon.awssdk:core; * software.amazon.awssdk:ecs; * software.amazon.awssdk:s3; * software.amazon.awssdk:sts. from 2.14.3 to 2.14.12. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/edd523c4815b27e2e8fae0ff4003c29e2c945b91/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5832:452,Config,Configure,452,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5832,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * software.amazon.awssdk:batch; * software.amazon.awssdk:cloudwatchlogs; * software.amazon.awssdk:core; * software.amazon.awssdk:ecs; * software.amazon.awssdk:s3; * software.amazon.awssdk:sts. from 2.14.3 to 2.14.13. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/5e7fd713ca5ed5fb400c4f4a7d7194fc5905c7f0/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5836:452,Config,Configure,452,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5836,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * software.amazon.awssdk:batch; * software.amazon.awssdk:cloudwatchlogs; * software.amazon.awssdk:core; * software.amazon.awssdk:ecs; * software.amazon.awssdk:s3; * software.amazon.awssdk:sts. from 2.14.3 to 2.14.14. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/e243c83e9a1ecb490a2f5ee163ab6feb857bd29d/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5843:452,Config,Configure,452,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5843,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * software.amazon.awssdk:batch; * software.amazon.awssdk:cloudwatchlogs; * software.amazon.awssdk:core; * software.amazon.awssdk:ecs; * software.amazon.awssdk:s3; * software.amazon.awssdk:sts. from 2.14.3 to 2.14.15. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/4c999c871afc48b47ca01211b35bb70b849ae19a/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5846:452,Config,Configure,452,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5846,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * software.amazon.awssdk:batch; * software.amazon.awssdk:cloudwatchlogs; * software.amazon.awssdk:core; * software.amazon.awssdk:ecs; * software.amazon.awssdk:s3; * software.amazon.awssdk:sts. from 2.14.3 to 2.14.16. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/4c999c871afc48b47ca01211b35bb70b849ae19a/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5849:452,Config,Configure,452,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5849,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * software.amazon.awssdk:batch; * software.amazon.awssdk:cloudwatchlogs; * software.amazon.awssdk:core; * software.amazon.awssdk:ecs; * software.amazon.awssdk:s3; * software.amazon.awssdk:sts. from 2.14.3 to 2.14.17. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/6c503e9531b16274c8192e5f64ca1e63bf7a4a30/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5852:452,Config,Configure,452,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5852,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * software.amazon.awssdk:batch; * software.amazon.awssdk:cloudwatchlogs; * software.amazon.awssdk:core; * software.amazon.awssdk:ecs; * software.amazon.awssdk:s3; * software.amazon.awssdk:sts. from 2.14.3 to 2.14.18. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/03a8f43709eef17df64cf1d63f34f9185fc38f2a/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5856:452,Config,Configure,452,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5856,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * software.amazon.awssdk:batch; * software.amazon.awssdk:cloudwatchlogs; * software.amazon.awssdk:core; * software.amazon.awssdk:ecs; * software.amazon.awssdk:s3; * software.amazon.awssdk:sts. from 2.14.3 to 2.14.19. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/d2da723abb8119fd00bdedc46bea52a6ca7ff38c/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5860:452,Config,Configure,452,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5860,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * software.amazon.awssdk:batch; * software.amazon.awssdk:cloudwatchlogs; * software.amazon.awssdk:core; * software.amazon.awssdk:ecs; * software.amazon.awssdk:s3; * software.amazon.awssdk:sts. from 2.14.3 to 2.14.20. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/d2da723abb8119fd00bdedc46bea52a6ca7ff38c/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5865:452,Config,Configure,452,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5865,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * software.amazon.awssdk:batch; * software.amazon.awssdk:cloudwatchlogs; * software.amazon.awssdk:core; * software.amazon.awssdk:ecs; * software.amazon.awssdk:s3; * software.amazon.awssdk:sts. from 2.14.3 to 2.14.21. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/ecfbfb1558789f05b4ed6d0564d62f6c65c7831a/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5871:452,Config,Configure,452,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5871,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * software.amazon.awssdk:batch; * software.amazon.awssdk:cloudwatchlogs; * software.amazon.awssdk:core; * software.amazon.awssdk:ecs; * software.amazon.awssdk:s3; * software.amazon.awssdk:sts. from 2.14.3 to 2.14.22. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/ca0c96d784fdfddfb9f64dd3d85e933d4eb33917/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5876:452,Config,Configure,452,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5876,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * software.amazon.awssdk:batch; * software.amazon.awssdk:cloudwatchlogs; * software.amazon.awssdk:core; * software.amazon.awssdk:ecs; * software.amazon.awssdk:s3; * software.amazon.awssdk:sts. from 2.14.3 to 2.14.23. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/6525ca66f9e66047fdcc2b5f4391921a1dec5c61/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5880:452,Config,Configure,452,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5880,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * software.amazon.awssdk:batch; * software.amazon.awssdk:cloudwatchlogs; * software.amazon.awssdk:core; * software.amazon.awssdk:ecs; * software.amazon.awssdk:s3; * software.amazon.awssdk:sts. from 2.14.3 to 2.14.24. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/6525ca66f9e66047fdcc2b5f4391921a1dec5c61/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5883:452,Config,Configure,452,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5883,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * software.amazon.awssdk:batch; * software.amazon.awssdk:cloudwatchlogs; * software.amazon.awssdk:core; * software.amazon.awssdk:ecs; * software.amazon.awssdk:s3; * software.amazon.awssdk:sts. from 2.14.3 to 2.14.5. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/179507babd976dd9e0d9d5d9983ff43436b13e3b/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5806:451,Config,Configure,451,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5806,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * software.amazon.awssdk:batch; * software.amazon.awssdk:cloudwatchlogs; * software.amazon.awssdk:core; * software.amazon.awssdk:ecs; * software.amazon.awssdk:s3; * software.amazon.awssdk:sts. from 2.14.3 to 2.14.6. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/33249b1f3d16a2bad9568d5a634316e2f2379b98/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5811:451,Config,Configure,451,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5811,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * software.amazon.awssdk:batch; * software.amazon.awssdk:cloudwatchlogs; * software.amazon.awssdk:core; * software.amazon.awssdk:ecs; * software.amazon.awssdk:s3; * software.amazon.awssdk:sts. from 2.14.3 to 2.14.7. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/33249b1f3d16a2bad9568d5a634316e2f2379b98/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5814:451,Config,Configure,451,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5814,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * software.amazon.awssdk:batch; * software.amazon.awssdk:cloudwatchlogs; * software.amazon.awssdk:core; * software.amazon.awssdk:ecs; * software.amazon.awssdk:s3; * software.amazon.awssdk:sts. from 2.14.3 to 2.14.8. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/33249b1f3d16a2bad9568d5a634316e2f2379b98/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5820:451,Config,Configure,451,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5820,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * software.amazon.awssdk:batch; * software.amazon.awssdk:cloudwatchlogs; * software.amazon.awssdk:core; * software.amazon.awssdk:ecs; * software.amazon.awssdk:s3; * software.amazon.awssdk:sts. from 2.14.3 to 2.14.9. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/049f5002d8c85f7befada19ff3a4944dc354e9fb/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5824:451,Config,Configure,451,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5824,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * software.amazon.awssdk:batch; * software.amazon.awssdk:cloudwatchlogs; * software.amazon.awssdk:core; * software.amazon.awssdk:s3; * software.amazon.awssdk:sts. from 2.17.152 to 2.17.170. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/baa6050d64c419297825797b97045f2ec9d0ceee/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, early-semver-patch, semver-spec-patch, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6731:425,Config,Configure,425,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6731,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * software.amazon.awssdk:batch; * software.amazon.awssdk:cloudwatchlogs; * software.amazon.awssdk:core; * software.amazon.awssdk:s3; * software.amazon.awssdk:sts. from 2.17.194 to 2.17.265. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/2dc2301e75aea6c2d0c49b89d6092f7d4f134b40/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""@monthly"" },; dependency = { groupId = ""software.amazon.awssdk"" }; }]; ```; </details>. labels: library-update, early-semver-patch, semver-spec-patch, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6901:425,Config,Configure,425,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6901,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * software.amazon.awssdk:batch; * software.amazon.awssdk:cloudwatchlogs; * software.amazon.awssdk:core; * software.amazon.awssdk:s3; * software.amazon.awssdk:sts. from 2.17.265 to 2.17.295. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/9367739b48d1bae5766674e547f8cdf8a82d318a/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""software.amazon.awssdk"" }; }]; ```; </details>. labels: library-update, early-semver-patch, semver-spec-patch, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7082:425,Config,Configure,425,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7082,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * software.amazon.awssdk:batch; * software.amazon.awssdk:cloudwatchlogs; * software.amazon.awssdk:core; * software.amazon.awssdk:s3; * software.amazon.awssdk:sts. from 2.17.50 to 2.17.102. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/00809e6249b134635f71919c17c1c81603beb22d/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, early-semver-patch, semver-spec-patch, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6637:424,Config,Configure,424,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6637,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * software.amazon.awssdk:cloudwatchlogs; * software.amazon.awssdk:core; * software.amazon.awssdk:s3; * software.amazon.awssdk:sts. from 2.17.152 to 2.17.171. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/e3c2ae36efa7b5e442c44f92552901d7a5c4445e/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; </details>. labels: library-update, early-semver-patch, semver-spec-patch, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6733:393,Config,Configure,393,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6733,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * software.amazon.awssdk:core; * software.amazon.awssdk:s3; * software.amazon.awssdk:sts. from 2.17.152 to 2.17.172. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/e5600937e537c0b06266c2860dfad5605a4de5ef/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequest = { frequency = ""@monthly"" },; dependency = { groupId = ""software.amazon.awssdk"" }; }]; ```; </details>. labels: library-update, early-semver-patch, semver-spec-patch, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6734:352,Config,Configure,352,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6734,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates ; * software.amazon.awssdk:s3; * software.amazon.awssdk:sts. from 2.17.152 to 2.17.173. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/5ba079e5e6b075ded705306e58f3111e16796466/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""software.amazon.awssdk"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequest = { frequency = ""@monthly"" },; dependency = { groupId = ""software.amazon.awssdk"" }; }]; ```; </details>. labels: library-update, early-semver-patch, semver-spec-patch, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6738:321,Config,Configure,321,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6738,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [co.fs2:fs2-io](https://github.com/functional-streams-for-scala/fs2) from 1.0.3 to 1.0.5.; [GitHub Release Notes](https://github.com/functional-streams-for-scala/fs2/releases/tag/v1.0.5) - [Version Diff](https://github.com/functional-streams-for-scala/fs2/compare/v1.0.3...v1.0.5). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/a2a47735b8b5ce3b0b0a9fa0a2cdf3b8405ff98d/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""co.fs2"", artifactId = ""fs2-io"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5603:515,Config,Configure,515,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5603,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [co.fs2:fs2-io](https://github.com/functional-streams-for-scala/fs2) from 2.0.0 to 2.0.1.; [GitHub Release Notes](https://github.com/functional-streams-for-scala/fs2/releases/tag/v2.0.1) - [Version Diff](https://github.com/functional-streams-for-scala/fs2/compare/v2.0.0...v2.0.1). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/a2a47735b8b5ce3b0b0a9fa0a2cdf3b8405ff98d/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""co.fs2"", artifactId = ""fs2-io"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5604:515,Config,Configure,515,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5604,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [co.fs2:fs2-io](https://github.com/functional-streams-for-scala/fs2) from 2.0.1 to 2.4.2.; [GitHub Release Notes](https://github.com/functional-streams-for-scala/fs2/releases/tag/v2.4.2) - [Version Diff](https://github.com/functional-streams-for-scala/fs2/compare/v2.0.1...v2.4.2). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/12cad616e6adbc68ad8487e1fcb064c6ef8f3d9c/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""co.fs2"", artifactId = ""fs2-io"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5702:515,Config,Configure,515,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5702,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [co.fs2:fs2-io](https://github.com/functional-streams-for-scala/fs2) from 2.0.1 to 2.4.3.; [GitHub Release Notes](https://github.com/functional-streams-for-scala/fs2/releases/tag/v2.4.3) - [Version Diff](https://github.com/functional-streams-for-scala/fs2/compare/v2.0.1...v2.4.3). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/6fa5051c5aeeaaae7870cefd2d9908da221f2f61/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""co.fs2"", artifactId = ""fs2-io"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5775:515,Config,Configure,515,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5775,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [co.fs2:fs2-io](https://github.com/functional-streams-for-scala/fs2) from 2.0.1 to 2.4.5.; [GitHub Release Notes](https://github.com/functional-streams-for-scala/fs2/releases/tag/v2.4.5) - [Changelog](https://github.com/functional-streams-for-scala/fs2/blob/master/CHANGELOG.md) - [Version Diff](https://github.com/functional-streams-for-scala/fs2/compare/v2.0.1...v2.4.5). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/cc6f924b2a099b9f1462efa2007aa2a8c190c877/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""co.fs2"", artifactId = ""fs2-io"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6035:607,Config,Configure,607,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6035,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [co.fs2:fs2-io](https://github.com/typelevel/fs2) from 2.0.1 to 2.4.6.; [GitHub Release Notes](https://github.com/typelevel/fs2/releases/tag/v2.4.6) - [Changelog](https://github.com/typelevel/fs2/blob/master/CHANGELOG.md) - [Version Diff](https://github.com/typelevel/fs2/compare/v2.0.1...v2.4.6). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/04b9d423d4830f1fd86d680ecef2d6372c8ec937/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""co.fs2"", artifactId = ""fs2-io"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6088:531,Config,Configure,531,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6088,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [co.fs2:fs2-io](https://github.com/typelevel/fs2) from 2.4.6 to 2.5.4.; [GitHub Release Notes](https://github.com/typelevel/fs2/releases/tag/v2.5.4) - [Changelog](https://github.com/typelevel/fs2/blob/master/CHANGELOG.md) - [Version Diff](https://github.com/typelevel/fs2/compare/v2.4.6...v2.5.4). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/b48aba70ec793405c98788a322d160987ba51d3e/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""co.fs2"", artifactId = ""fs2-io"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6239:531,Config,Configure,531,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6239,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [co.fs2:fs2-io](https://github.com/typelevel/fs2) from 2.5.4 to 2.5.7.; [GitHub Release Notes](https://github.com/typelevel/fs2/releases/tag/v2.5.7) - [Changelog](https://github.com/typelevel/fs2/blob/master/CHANGELOG.md) - [Version Diff](https://github.com/typelevel/fs2/compare/v2.5.4...v2.5.7). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/92f43ce5f010fa03daeb2625a3f9c1b1be80cca5/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Files still referring to the old version number</summary>. The following files still refer to the old version number (2.5.4).; You might want to review and update them manually.; ```; docs/execution/ExecutionTwists.md; ```; </details>; <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""co.fs2"", artifactId = ""fs2-io"" } ]; ```; </details>. labels: library-update, semver-patch, old-version-remains",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6385:531,Config,Configure,531,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6385,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.aliyun.oss:aliyun-sdk-oss](http://www.aliyun.com/product/oss) from 3.11.1 to 3.11.2. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/7ceee9b901bc64fca0e6207564ded09b03b2fe9f/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.aliyun.oss"", artifactId = ""aliyun-sdk-oss"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6122:323,Config,Configure,323,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6122,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.aliyun.oss:aliyun-sdk-oss](http://www.aliyun.com/product/oss) from 3.11.1 to 3.11.3. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/b48aba70ec793405c98788a322d160987ba51d3e/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.aliyun.oss"", artifactId = ""aliyun-sdk-oss"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6241:323,Config,Configure,323,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6241,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.aliyun.oss:aliyun-sdk-oss](http://www.aliyun.com/product/oss) from 3.11.3 to 3.13.0. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/92f43ce5f010fa03daeb2625a3f9c1b1be80cca5/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.aliyun.oss"", artifactId = ""aliyun-sdk-oss"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6387:323,Config,Configure,323,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6387,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.aliyun:aliyun-java-sdk-core](https://github.com/aliyun/aliyun-openapi-java-sdk) from 4.3.2 to 4.3.9. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/a2a47735b8b5ce3b0b0a9fa0a2cdf3b8405ff98d/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.aliyun"", artifactId = ""aliyun-java-sdk-core"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5606:339,Config,Configure,339,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5606,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.aliyun:aliyun-java-sdk-core](https://github.com/aliyun/aliyun-openapi-java-sdk) from 4.3.9 to 4.5.6. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/03b617d9dd9148c1ba51f5d9672094eb316485f3/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.aliyun"", artifactId = ""aliyun-java-sdk-core"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5722:339,Config,Configure,339,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5722,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.aliyun:aliyun-java-sdk-core](https://github.com/aliyun/aliyun-openapi-java-sdk) from 4.3.9 to 4.5.7. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/6fa5051c5aeeaaae7870cefd2d9908da221f2f61/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.aliyun"", artifactId = ""aliyun-java-sdk-core"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5773:339,Config,Configure,339,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5773,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.aliyun:aliyun-java-sdk-core](https://github.com/aliyun/aliyun-openapi-java-sdk) from 4.5.10 to 4.5.12. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/2ae97f1a550112ad4dc1f038d38808b546b012dd/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.aliyun"", artifactId = ""aliyun-java-sdk-core"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5899:341,Config,Configure,341,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5899,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.aliyun:aliyun-java-sdk-core](https://github.com/aliyun/aliyun-openapi-java-sdk) from 4.5.10 to 4.5.13. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/70c5cce7975167543ded62798cbe74ff42b62d3a/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.aliyun"", artifactId = ""aliyun-java-sdk-core"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5936:341,Config,Configure,341,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5936,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.aliyun:aliyun-java-sdk-core](https://github.com/aliyun/aliyun-openapi-java-sdk) from 4.5.12 to 4.5.14. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/1abad4bea5c3f3d9a3dece02e6531a0b61e0359c/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.aliyun"", artifactId = ""aliyun-java-sdk-core"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5992:341,Config,Configure,341,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5992,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.aliyun:aliyun-java-sdk-core](https://github.com/aliyun/aliyun-openapi-java-sdk) from 4.5.12 to 4.5.15. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/24a3882f4c053143d28fb39e509e1152debd3565/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.aliyun"", artifactId = ""aliyun-java-sdk-core"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6032:341,Config,Configure,341,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6032,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.aliyun:aliyun-java-sdk-core](https://github.com/aliyun/aliyun-openapi-java-sdk) from 4.5.12 to 4.5.16. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/8103d0289c2ae3f66a24a2e3cc4ca0f2257ca28a/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.aliyun"", artifactId = ""aliyun-java-sdk-core"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6038:341,Config,Configure,341,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6038,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.aliyun:aliyun-java-sdk-core](https://github.com/aliyun/aliyun-openapi-java-sdk) from 4.5.12 to 4.5.17. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/77080f8514f13ff89485ba391ea115bdbafca093/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.aliyun"", artifactId = ""aliyun-java-sdk-core"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6100:341,Config,Configure,341,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6100,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.aliyun:aliyun-java-sdk-core](https://github.com/aliyun/aliyun-openapi-java-sdk) from 4.5.16 to 4.5.20. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/b48aba70ec793405c98788a322d160987ba51d3e/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.aliyun"", artifactId = ""aliyun-java-sdk-core"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6240:341,Config,Configure,341,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6240,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.aliyun:aliyun-java-sdk-core](https://github.com/aliyun/aliyun-openapi-java-sdk) from 4.5.20 to 4.5.22. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/92f43ce5f010fa03daeb2625a3f9c1b1be80cca5/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.aliyun"", artifactId = ""aliyun-java-sdk-core"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6386:341,Config,Configure,341,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6386,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.aliyun:aliyun-java-sdk-core](https://github.com/aliyun/aliyun-openapi-java-sdk) from 4.5.25 to 4.5.30. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/00809e6249b134635f71919c17c1c81603beb22d/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.aliyun"", artifactId = ""aliyun-java-sdk-core"" } ]; ```; </details>. labels: library-update, early-semver-patch, semver-spec-patch, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6599:341,Config,Configure,341,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6599,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.aliyun:aliyun-java-sdk-core](https://github.com/aliyun/aliyun-openapi-java-sdk) from 4.5.7 to 4.5.10. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/03a8f43709eef17df64cf1d63f34f9185fc38f2a/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.aliyun"", artifactId = ""aliyun-java-sdk-core"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5854:340,Config,Configure,340,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5854,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.aliyun:aliyun-java-sdk-core](https://github.com/aliyun/aliyun-openapi-java-sdk) from 4.5.7 to 4.5.11. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/6525ca66f9e66047fdcc2b5f4391921a1dec5c61/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.aliyun"", artifactId = ""aliyun-java-sdk-core"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5885:340,Config,Configure,340,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5885,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.aliyun:aliyun-java-sdk-core](https://github.com/aliyun/aliyun-openapi-java-sdk) from 4.5.7 to 4.5.8. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/33249b1f3d16a2bad9568d5a634316e2f2379b98/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.aliyun"", artifactId = ""aliyun-java-sdk-core"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5816:339,Config,Configure,339,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5816,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.aliyun:aliyun-java-sdk-core](https://github.com/aliyun/aliyun-openapi-java-sdk) from 4.5.7 to 4.5.9. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/4c999c871afc48b47ca01211b35bb70b849ae19a/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.aliyun"", artifactId = ""aliyun-java-sdk-core"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5847:339,Config,Configure,339,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5847,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.aliyun:aliyun-java-sdk-cr](https://github.com/aliyun/aliyun-openapi-java-sdk) from 3.0.0 to 3.0.1. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/a2a47735b8b5ce3b0b0a9fa0a2cdf3b8405ff98d/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.aliyun"", artifactId = ""aliyun-java-sdk-cr"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5607:337,Config,Configure,337,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5607,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.aliyun:aliyun-java-sdk-cr](https://github.com/aliyun/aliyun-openapi-java-sdk) from 3.0.1 to 4.1.1. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/03b617d9dd9148c1ba51f5d9672094eb316485f3/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.aliyun"", artifactId = ""aliyun-java-sdk-cr"" } ]; ```; </details>. labels: library-update, semver-major",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5723:337,Config,Configure,337,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5723,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.aliyun:aliyun-java-sdk-cr](https://github.com/aliyun/aliyun-openapi-java-sdk) from 4.1.1 to 4.1.2. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/7ceee9b901bc64fca0e6207564ded09b03b2fe9f/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.aliyun"", artifactId = ""aliyun-java-sdk-cr"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6121:337,Config,Configure,337,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6121,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.aliyun:aliyun-java-sdk-cr](https://github.com/aliyun/aliyun-openapi-java-sdk) from 4.1.2 to 4.1.3. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/00809e6249b134635f71919c17c1c81603beb22d/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.aliyun"", artifactId = ""aliyun-java-sdk-cr"" } ]; ```; </details>. labels: library-update, early-semver-patch, semver-spec-patch, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6600:337,Config,Configure,337,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6600,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.azure.resourcemanager:azure-resourcemanager](https://github.com/Azure/azure-sdk-for-java) from 2.17.0 to 2.18.0. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/2dc2301e75aea6c2d0c49b89d6092f7d4f134b40/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.azure.resourcemanager"", artifactId = ""azure-resourcemanager"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""@monthly"" },; dependency = { groupId = ""com.azure.resourcemanager"", artifactId = ""azure-resourcemanager"" }; }]; ```; </details>. labels: library-update, early-semver-minor, semver-spec-minor, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6847:351,Config,Configure,351,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6847,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.azure.resourcemanager:azure-resourcemanager](https://github.com/Azure/azure-sdk-for-java) from 2.18.0 to 2.24.0. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/9367739b48d1bae5766674e547f8cdf8a82d318a/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.azure.resourcemanager"", artifactId = ""azure-resourcemanager"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""com.azure.resourcemanager"", artifactId = ""azure-resourcemanager"" }; }]; ```; </details>. labels: library-update, early-semver-minor, semver-spec-minor, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7029:351,Config,Configure,351,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7029,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.azure:azure-core-management](https://github.com/Azure/azure-sdk-for-java) from 1.7.0 to 1.7.1. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/2dc2301e75aea6c2d0c49b89d6092f7d4f134b40/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.azure"", artifactId = ""azure-core-management"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""@monthly"" },; dependency = { groupId = ""com.azure"", artifactId = ""azure-core-management"" }; }]; ```; </details>. labels: library-update, early-semver-patch, semver-spec-patch, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6843:333,Config,Configure,333,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6843,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.azure:azure-core-management](https://github.com/Azure/azure-sdk-for-java) from 1.7.1 to 1.10.1. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/9367739b48d1bae5766674e547f8cdf8a82d318a/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Files still referring to the old version number</summary>. The following files still refer to the old version number (1.7.1).; You might want to review and update them manually.; ```; project/Dependencies.scala; ```; </details>; <details>; <summary>Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.azure"", artifactId = ""azure-core-management"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""com.azure"", artifactId = ""azure-core-management"" }; }]; ```; </details>. labels: library-update, early-semver-minor, semver-spec-minor, old-version-remains, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7027:334,Config,Configure,334,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7027,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.azure:azure-identity](https://github.com/Azure/azure-sdk-for-java) from 1.4.2 to 1.4.6. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/2dc2301e75aea6c2d0c49b89d6092f7d4f134b40/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.azure"", artifactId = ""azure-identity"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""@monthly"" },; dependency = { groupId = ""com.azure"", artifactId = ""azure-identity"" }; }]; ```; </details>. labels: library-update, early-semver-patch, semver-spec-patch, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6844:326,Config,Configure,326,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6844,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.azure:azure-identity](https://github.com/Azure/azure-sdk-for-java) from 1.4.6 to 1.8.0. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/9367739b48d1bae5766674e547f8cdf8a82d318a/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.azure"", artifactId = ""azure-identity"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""com.azure"", artifactId = ""azure-identity"" }; }]; ```; </details>. labels: library-update, early-semver-minor, semver-spec-minor, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7028:326,Config,Configure,326,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7028,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.azure:azure-security-keyvault-secrets](https://github.com/Azure/azure-sdk-for-java) from 4.3.4 to 4.3.5. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/00809e6249b134635f71919c17c1c81603beb22d/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.azure"", artifactId = ""azure-security-keyvault-secrets"" } ]; ```; </details>. labels: library-update, early-semver-patch, semver-spec-patch, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6602:343,Config,Configure,343,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6602,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.azure:azure-security-keyvault-secrets](https://github.com/Azure/azure-sdk-for-java) from 4.3.7 to 4.3.8. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/2dc2301e75aea6c2d0c49b89d6092f7d4f134b40/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.azure"", artifactId = ""azure-security-keyvault-secrets"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""@monthly"" },; dependency = { groupId = ""com.azure"", artifactId = ""azure-security-keyvault-secrets"" }; }]; ```; </details>. labels: library-update, early-semver-patch, semver-spec-patch, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6845:343,Config,Configure,343,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6845,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.azure:azure-storage-blob-nio](https://github.com/Azure/azure-sdk-for-java) from 12.0.0-beta.18 to 12.0.0-beta.19. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/2dc2301e75aea6c2d0c49b89d6092f7d4f134b40/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.azure"", artifactId = ""azure-storage-blob-nio"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""@monthly"" },; dependency = { groupId = ""com.azure"", artifactId = ""azure-storage-blob-nio"" }; }]; ```; </details>. labels: library-update, early-semver-pre-release, semver-spec-pre-release, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6846:352,Config,Configure,352,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6846,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.chuusai:shapeless](https://github.com/milessabin/shapeless) from 2.3.3 to 2.3.7.; [GitHub Release Notes](https://github.com/milessabin/shapeless/releases/tag/v2.3.7) - [Version Diff](https://github.com/milessabin/shapeless/compare/v2.3.3...v2.3.7). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/92f43ce5f010fa03daeb2625a3f9c1b1be80cca5/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Files still referring to the old version number</summary>. The following files still refer to the old version number (2.3.3).; You might want to review and update them manually.; ```; project/Dependencies.scala; ```; </details>; <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.chuusai"", artifactId = ""shapeless"" } ]; ```; </details>. labels: library-update, semver-patch, old-version-remains",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6388:487,Config,Configure,487,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6388,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.chuusai:shapeless](https://github.com/milessabin/shapeless) from 2.3.7 to 2.3.9.; [GitHub Release Notes](https://github.com/milessabin/shapeless/releases/tag/v2.3.9) - [Version Diff](https://github.com/milessabin/shapeless/compare/v2.3.7...v2.3.9). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/2dc2301e75aea6c2d0c49b89d6092f7d4f134b40/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.chuusai"", artifactId = ""shapeless"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""@monthly"" },; dependency = { groupId = ""com.chuusai"", artifactId = ""shapeless"" }; }]; ```; </details>. labels: library-update, early-semver-patch, semver-spec-patch, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6848:487,Config,Configure,487,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6848,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.chuusai:shapeless](https://github.com/milessabin/shapeless) from 2.3.9 to 2.3.10.; [GitHub Release Notes](https://github.com/milessabin/shapeless/releases/tag/v2.3.10) - [Version Diff](https://github.com/milessabin/shapeless/compare/v2.3.9...v2.3.10). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/9367739b48d1bae5766674e547f8cdf8a82d318a/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.chuusai"", artifactId = ""shapeless"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""com.chuusai"", artifactId = ""shapeless"" }; }]; ```; </details>. labels: library-update, early-semver-patch, semver-spec-patch, version-scheme:pvp, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7030:490,Config,Configure,490,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7030,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.eed3si9n:sbt-assembly](https://github.com/sbt/sbt-assembly) from 0.15.0 to 1.0.0.; [GitHub Release Notes](https://github.com/sbt/sbt-assembly/releases/tag/v1.0.0) - [Version Diff](https://github.com/sbt/sbt-assembly/compare/v0.15.0...v1.0.0). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/92f43ce5f010fa03daeb2625a3f9c1b1be80cca5/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.eed3si9n"", artifactId = ""sbt-assembly"" } ]; ```; </details>. labels: sbt-plugin-update, semver-major",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6390:481,Config,Configure,481,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6390,3,"['Config', 'config', 'plugin']","['Configure', 'configuration', 'plugin-update']"
Modifiability,"Updates [com.eed3si9n:sbt-assembly](https://github.com/sbt/sbt-assembly) from 1.0.0 to 1.1.0.; [GitHub Release Notes](https://github.com/sbt/sbt-assembly/releases/tag/v1.1.0) - [Version Diff](https://github.com/sbt/sbt-assembly/compare/v1.0.0...v1.1.0). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/6472b97b3365f2800f4202d1bf6b1d647bd2b0cc/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Files still referring to the old version number</summary>. The following files still refer to the old version number (1.0.0).; You might want to review and update them manually.; ```; cwl/src/test/resources/cwl/lodash.js; filesystems/drs/src/main/scala/cromwell/filesystems/drs/DrsResolver.scala; project/Dependencies.scala; scripts/perf/vm_scripts/cromwell-dashboard.json; ```; </details>; <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.eed3si9n"", artifactId = ""sbt-assembly"" } ]; ```; </details>. labels: sbt-plugin-update, semver-minor, old-version-remains",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6513:479,Config,Configure,479,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6513,3,"['Config', 'config', 'plugin']","['Configure', 'configuration', 'plugin-update']"
Modifiability,"Updates [com.eed3si9n:sbt-assembly](https://github.com/sbt/sbt-assembly) from 1.1.0 to 1.1.1.; [GitHub Release Notes](https://github.com/sbt/sbt-assembly/releases/tag/v1.1.1) - [Version Diff](https://github.com/sbt/sbt-assembly/compare/v1.1.0...v1.1.1). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/2dc2301e75aea6c2d0c49b89d6092f7d4f134b40/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Files still referring to the old version number</summary>. The following files still refer to the old version number (1.1.0).; You might want to review and update them manually.; ```; CHANGELOG.md; centaur/src/main/resources/integrationTestCases/cwl/bcbio/gvcf-joint-workflow/steps/variantcall_batch_region.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/prealign-workflow/steps/variantcall_batch_region.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/somatic-workflow/steps/variantcall_batch_region.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/svcall-workflow/steps/variantcall_batch_region.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/wes_chr21_test-workflow-gcp/steps/variantcall_batch_region.cwl; cloud-nio/cloud-nio-impl-drs/src/main/scala/cloud/nio/impl/drs/DrsCloudNioFileSystemProvider.scala; cwl/src/test/resources/cwl/lodash.js; ```; </details>; <details>; <summary>Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.eed3si9n"", artifactId = ""sbt-assembly"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pu",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6850:479,Config,Configure,479,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6850,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.eed3si9n:sbt-assembly](https://github.com/sbt/sbt-assembly) from 1.1.1 to 1.2.0.; [GitHub Release Notes](https://github.com/sbt/sbt-assembly/releases/tag/v1.2.0) - [Version Diff](https://github.com/sbt/sbt-assembly/compare/v1.1.1...v1.2.0). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/9367739b48d1bae5766674e547f8cdf8a82d318a/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Files still referring to the old version number</summary>. The following files still refer to the old version number (1.1.1).; You might want to review and update them manually.; ```; womtool/src/test/resources/validate/wdl_draft3/valid/arrays_v1/arrays_v1.inputs.json; ```; </details>; <details>; <summary>Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.eed3si9n"", artifactId = ""sbt-assembly"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""com.eed3si9n"", artifactId = ""sbt-assembly"" }; }]; ```; </details>. labels: sbt-plugin-update, early-semver-minor, semver-spec-minor, old-version-remains, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7032:479,Config,Configure,479,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7032,3,"['Config', 'config', 'plugin']","['Configure', 'configuration', 'plugin-update']"
Modifiability,"Updates [com.fasterxml.jackson.core:jackson-databind](http://github.com/FasterXML/jackson-databind) from 2.11.3 to 2.12.0. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/88c9ae38953d94358d1e0fbf03c7f63dbd3a2281/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.fasterxml.jackson.core"", artifactId = ""jackson-databind"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6103:348,Config,Configure,348,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6103,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.github.gseitz:sbt-release](https://github.com/sbt/sbt-release) from 1.0.8 to 1.0.13.; [GitHub Release Notes](https://github.com/sbt/sbt-release/releases/tag/v1.0.13) - [Version Diff](https://github.com/sbt/sbt-release/compare/v1.0.8...v1.0.13). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/a2a47735b8b5ce3b0b0a9fa0a2cdf3b8405ff98d/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.github.gseitz"", artifactId = ""sbt-release"" } ]; ```; </details>. labels: sbt-plugin-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5612:483,Config,Configure,483,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5612,3,"['Config', 'config', 'plugin']","['Configure', 'configuration', 'plugin-update']"
Modifiability,"Updates [com.github.kxbmap:configs](https://github.com/kxbmap/configs) from 0.4.4 to 0.5.0.; [GitHub Release Notes](https://github.com/kxbmap/configs/releases/tag/v0.5.0) - [Version Diff](https://github.com/kxbmap/configs/compare/v0.4.4...v0.5.0). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/1a614dffe154286ca442fe90fb079043b2c54f6b/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.github.kxbmap"", artifactId = ""configs"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6126:27,config,configs,27,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6126,7,"['Config', 'config']","['Configure', 'configs', 'configuration']"
Modifiability,"Updates [com.github.kxbmap:configs](https://github.com/kxbmap/configs) from 0.5.0 to 0.6.0.; [GitHub Release Notes](https://github.com/kxbmap/configs/releases/tag/v0.6.0) - [Version Diff](https://github.com/kxbmap/configs/compare/v0.5.0...v0.6.0). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/b48aba70ec793405c98788a322d160987ba51d3e/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Files still referring to the old version number</summary>. The following files still refer to the old version number (0.5.0).; You might want to review and update them manually.; ```; src/ci/bin/testCentaurTes.sh; ```; </details>; <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.github.kxbmap"", artifactId = ""configs"" } ]; ```; </details>. labels: library-update, semver-minor, old-version-remains",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6244:27,config,configs,27,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6244,7,"['Config', 'config']","['Configure', 'configs', 'configuration']"
Modifiability,"Updates [com.github.kxbmap:configs](https://github.com/kxbmap/configs) from 0.6.0 to 0.6.1.; [GitHub Release Notes](https://github.com/kxbmap/configs/releases/tag/v0.6.1) - [Version Diff](https://github.com/kxbmap/configs/compare/v0.6.0...v0.6.1). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/92f43ce5f010fa03daeb2625a3f9c1b1be80cca5/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Files still referring to the old version number</summary>. The following files still refer to the old version number (0.6.0).; You might want to review and update them manually.; ```; cwl/src/test/resources/cwl/lodash.js; ```; </details>; <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.github.kxbmap"", artifactId = ""configs"" } ]; ```; </details>. labels: library-update, semver-patch, old-version-remains",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6392:27,config,configs,27,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6392,7,"['Config', 'config']","['Configure', 'configs', 'configuration']"
Modifiability,"Updates [com.github.pathikrit:better-files](https://github.com/pathikrit/better-files) from 3.8.0 to 3.9.1.; [GitHub Release Notes](https://github.com/pathikrit/better-files/releases/tag/v3.9.1) - [Changelog](https://github.com/pathikrit/better-files/blob/master/CHANGES.md) - [Version Diff](https://github.com/pathikrit/better-files/compare/v3.8.0...v3.9.1). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/a2a47735b8b5ce3b0b0a9fa0a2cdf3b8405ff98d/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.github.pathikrit"", artifactId = ""better-files"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5614:585,Config,Configure,585,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5614,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.github.pathikrit:better-files](https://x-access-token@github.com/pathikrit/better-files) from 3.9.1 to 3.9.2.; [GitHub Release Notes](https://x-access-token@github.com/pathikrit/better-files/releases/tag/v3.9.2) - [Changelog](https://x-access-token@github.com/pathikrit/better-files/blob/master/CHANGES.md) - [Version Diff](https://x-access-token@github.com/pathikrit/better-files/compare/v3.9.1...v3.9.2). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/9367739b48d1bae5766674e547f8cdf8a82d318a/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.github.pathikrit"", artifactId = ""better-files"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""com.github.pathikrit"", artifactId = ""better-files"" }; }]; ```; </details>. labels: library-update, early-semver-patch, semver-spec-patch, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7034:645,Config,Configure,645,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7034,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.github.sbt:sbt-git](https://github.com/sbt/sbt-git) from 2.0.0 to 2.0.1.; [GitHub Release Notes](https://github.com/sbt/sbt-git/releases/tag/v2.0.1) - [Version Diff](https://github.com/sbt/sbt-git/compare/v2.0.0...v2.0.1). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/9367739b48d1bae5766674e547f8cdf8a82d318a/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Files still referring to the old version number</summary>. The following files still refer to the old version number (2.0.0).; You might want to review and update them manually.; ```; CromwellRefdiskManifestCreator/pom.xml; project/Dependencies.scala; ```; </details>; <details>; <summary>Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.github.sbt"", artifactId = ""sbt-git"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""com.github.sbt"", artifactId = ""sbt-git"" }; }]; ```; </details>. labels: sbt-plugin-update, early-semver-patch, semver-spec-patch, old-version-remains, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7035:461,Config,Configure,461,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7035,3,"['Config', 'config', 'plugin']","['Configure', 'configuration', 'plugin-update']"
Modifiability,"Updates [com.github.scopt:scopt](https://github.com/scopt/scopt) from 3.7.1 to 4.0.0.; [GitHub Release Notes](https://github.com/scopt/scopt/releases/tag/v4.0.0) - [Version Diff](https://github.com/scopt/scopt/compare/v3.7.1...v4.0.0). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/88c9ae38953d94358d1e0fbf03c7f63dbd3a2281/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.github.scopt"", artifactId = ""scopt"" } ]; ```; </details>. labels: library-update, semver-major",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6105:461,Config,Configure,461,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6105,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.github.scopt:scopt](https://github.com/scopt/scopt) from 4.0.0 to 4.0.1.; [GitHub Release Notes](https://github.com/scopt/scopt/releases/tag/v4.0.1) - [Version Diff](https://github.com/scopt/scopt/compare/v4.0.0...v4.0.1). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/b48aba70ec793405c98788a322d160987ba51d3e/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Files still referring to the old version number</summary>. The following files still refer to the old version number (4.0.0).; You might want to review and update them manually.; ```; CromwellRefdiskManifestCreator/pom.xml; centaur/src/main/resources/integrationTestCases/germline/haplotype-caller-workflow/HaplotypeCallerWF.aws.inputs.json; centaur/src/main/resources/integrationTestCases/germline/joint-discovery-gatk/joint-discovery-gatk4.hg38.wgs.inputs.json; centaur/src/main/resources/integrationTestCases/germline/single-sample-workflow/processing-for-variant-discovery-gatk4.hg38.wgs.aws.inputs.json; core/src/test/resources/hello_papiv2.json; project/Dependencies.scala; ```; </details>; <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.github.scopt"", artifactId = ""scopt"" } ]; ```; </details>. labels: library-update, semver-patch, old-version-remains",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6245:461,Config,Configure,461,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6245,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.github.scopt:scopt](https://github.com/scopt/scopt) from 4.0.1 to 4.1.0.; [GitHub Release Notes](https://github.com/scopt/scopt/releases/tag/v4.1.0) - [Version Diff](https://github.com/scopt/scopt/compare/v4.0.1...v4.1.0). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/2dc2301e75aea6c2d0c49b89d6092f7d4f134b40/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.github.scopt"", artifactId = ""scopt"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""@monthly"" },; dependency = { groupId = ""com.github.scopt"", artifactId = ""scopt"" }; }]; ```; </details>. labels: library-update, early-semver-minor, semver-spec-minor, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6851:461,Config,Configure,461,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6851,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.google.api:gax-grpc](https://github.com/googleapis/gax-java) from 1.57.0 to 1.57.1.; [GitHub Release Notes](https://github.com/googleapis/gax-java/releases/tag/v1.57.1) - [Changelog](https://github.com/googleapis/gax-java/blob/master/CHANGELOG.md) - [Version Diff](https://github.com/googleapis/gax-java/compare/v1.57.0...v1.57.1). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/a2a47735b8b5ce3b0b0a9fa0a2cdf3b8405ff98d/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.api"", artifactId = ""gax-grpc"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5615:570,Config,Configure,570,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5615,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.google.api:gax-grpc](https://github.com/googleapis/gax-java) from 1.57.1 to 1.58.0.; [GitHub Release Notes](https://github.com/googleapis/gax-java/releases/tag/v1.58.0) - [Changelog](https://github.com/googleapis/gax-java/blob/master/CHANGELOG.md) - [Version Diff](https://github.com/googleapis/gax-java/compare/v1.57.1...v1.58.0). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/12cad616e6adbc68ad8487e1fcb064c6ef8f3d9c/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.api"", artifactId = ""gax-grpc"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5707:570,Config,Configure,570,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5707,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.google.api:gax-grpc](https://github.com/googleapis/gax-java) from 1.57.1 to 1.58.1.; [GitHub Release Notes](https://github.com/googleapis/gax-java/releases/tag/v1.58.1) - [Changelog](https://github.com/googleapis/gax-java/blob/master/CHANGELOG.md) - [Version Diff](https://github.com/googleapis/gax-java/compare/v1.57.1...v1.58.1). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/03b617d9dd9148c1ba51f5d9672094eb316485f3/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.api"", artifactId = ""gax-grpc"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5728:570,Config,Configure,570,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5728,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.google.api:gax-grpc](https://github.com/googleapis/gax-java) from 1.57.1 to 1.58.2.; [GitHub Release Notes](https://github.com/googleapis/gax-java/releases/tag/v1.58.2) - [Changelog](https://github.com/googleapis/gax-java/blob/master/CHANGELOG.md) - [Version Diff](https://github.com/googleapis/gax-java/compare/v1.57.1...v1.58.2). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/58abe73a731f0fe337e07a07ba05cb4bbfe81bd5/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.api"", artifactId = ""gax-grpc"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5731:570,Config,Configure,570,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5731,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.google.api:gax-grpc](https://github.com/googleapis/gax-java) from 1.58.2 to 1.58.3.; [GitHub Release Notes](https://github.com/googleapis/gax-java/releases/tag/v1.58.3) - [Changelog](https://github.com/googleapis/gax-java/blob/master/CHANGELOG.md) - [Version Diff](https://github.com/googleapis/gax-java/compare/v1.58.2...v1.58.3). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/699e420f7466287c6f3c21ddb906c21b4ab27f3d/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.api"", artifactId = ""gax-grpc"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5903:570,Config,Configure,570,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5903,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.google.api:gax-grpc](https://github.com/googleapis/gax-java) from 1.58.3 to 1.59.1.; [GitHub Release Notes](https://github.com/googleapis/gax-java/releases/tag/v1.59.1) - [Changelog](https://github.com/googleapis/gax-java/blob/master/CHANGELOG.md) - [Version Diff](https://github.com/googleapis/gax-java/compare/v1.58.3...v1.59.1). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/19da014de4d7ffaaf25485ab05efa66bc7748c1f/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.api"", artifactId = ""gax-grpc"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5953:570,Config,Configure,570,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5953,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.google.api:gax-grpc](https://github.com/googleapis/gax-java) from 1.58.3 to 1.60.0.; [GitHub Release Notes](https://github.com/googleapis/gax-java/releases/tag/v1.60.0) - [Changelog](https://github.com/googleapis/gax-java/blob/master/CHANGELOG.md) - [Version Diff](https://github.com/googleapis/gax-java/compare/v1.58.3...v1.60.0). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/f73b36c43171cc50fa4140329f0c50e5c1cd2f97/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.api"", artifactId = ""gax-grpc"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5961:570,Config,Configure,570,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5961,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.google.api:gax-grpc](https://github.com/googleapis/gax-java) from 1.58.3 to 1.60.1.; [GitHub Release Notes](https://github.com/googleapis/gax-java/releases/tag/v1.60.1) - [Changelog](https://github.com/googleapis/gax-java/blob/master/CHANGELOG.md) - [Version Diff](https://github.com/googleapis/gax-java/compare/v1.58.3...v1.60.1). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/e1834055a86ba97fe5a5b4120fb60f80bf8aca15/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.api"", artifactId = ""gax-grpc"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6075:570,Config,Configure,570,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6075,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.google.api:gax-grpc](https://github.com/googleapis/gax-java) from 1.60.1 to 1.62.0.; [GitHub Release Notes](https://github.com/googleapis/gax-java/releases/tag/v1.62.0) - [Changelog](https://github.com/googleapis/gax-java/blob/master/CHANGELOG.md) - [Version Diff](https://github.com/googleapis/gax-java/compare/v1.60.1...v1.62.0). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/b48aba70ec793405c98788a322d160987ba51d3e/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.api"", artifactId = ""gax-grpc"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6246:570,Config,Configure,570,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6246,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.google.api:gax-grpc](https://github.com/googleapis/gax-java) from 1.62.0 to 1.66.0.; [GitHub Release Notes](https://github.com/googleapis/gax-java/releases/tag/v1.66.0) - [Changelog](https://github.com/googleapis/gax-java/blob/master/CHANGELOG.md) - [Version Diff](https://github.com/googleapis/gax-java/compare/v1.62.0...v1.66.0). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/92f43ce5f010fa03daeb2625a3f9c1b1be80cca5/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.api"", artifactId = ""gax-grpc"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6393:570,Config,Configure,570,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6393,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.google.api:gax-grpc](https://github.com/googleapis/gax-java) from 2.12.2 to 2.19.0.; [GitHub Release Notes](https://github.com/googleapis/gax-java/releases/tag/v2.19.0) - [Version Diff](https://github.com/googleapis/gax-java/compare/v2.12.2...v2.19.0). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/2dc2301e75aea6c2d0c49b89d6092f7d4f134b40/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.api"", artifactId = ""gax-grpc"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""@monthly"" },; dependency = { groupId = ""com.google.api"", artifactId = ""gax-grpc"" }; }]; ```; </details>. labels: library-update, early-semver-minor, semver-spec-minor, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6852:491,Config,Configure,491,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6852,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.google.api:gax-grpc](https://github.com/googleapis/gax-java) from 2.19.0 to 2.19.6.; [GitHub Release Notes](https://github.com/googleapis/gax-java/releases/tag/v2.19.6) - [Version Diff](https://github.com/googleapis/gax-java/compare/v2.19.0...v2.19.6). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/9367739b48d1bae5766674e547f8cdf8a82d318a/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.api"", artifactId = ""gax-grpc"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""com.google.api"", artifactId = ""gax-grpc"" }; }]; ```; </details>. labels: library-update, early-semver-patch, semver-spec-patch, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7036:491,Config,Configure,491,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7036,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.google.api:gax-grpc](https://github.com/googleapis/gax-java) from 2.4.0 to 2.4.1.; [GitHub Release Notes](https://github.com/googleapis/gax-java/releases/tag/v2.4.1) - [Changelog](https://github.com/googleapis/gax-java/blob/master/CHANGELOG.md) - [Version Diff](https://github.com/googleapis/gax-java/compare/v2.4.0...v2.4.1). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/6472b97b3365f2800f4202d1bf6b1d647bd2b0cc/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Files still referring to the old version number</summary>. The following files still refer to the old version number (2.4.0).; You might want to review and update them manually.; ```; cwl/src/test/resources/cwl/lodash.js; project/Dependencies.scala; ```; </details>; <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.api"", artifactId = ""gax-grpc"" } ]; ```; </details>. labels: library-update, semver-patch, old-version-remains",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6515:565,Config,Configure,565,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6515,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.google.api:gax-grpc](https://github.com/googleapis/gax-java) from 2.4.1 to 2.7.1.; [GitHub Release Notes](https://github.com/googleapis/gax-java/releases/tag/v2.7.1) - [Version Diff](https://github.com/googleapis/gax-java/compare/v2.4.1...v2.7.1). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/00809e6249b134635f71919c17c1c81603beb22d/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.api"", artifactId = ""gax-grpc"" } ]; ```; </details>. labels: library-update, early-semver-minor, semver-spec-minor, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6605:486,Config,Configure,486,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6605,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.google.auth:google-auth-library-oauth2-http](https://github.com/googleapis/google-auth-library-java) from 0.21.0 to 0.21.1.; [GitHub Release Notes](https://github.com/googleapis/google-auth-library-java/releases/tag/v0.21.1) - [Changelog](https://github.com/googleapis/google-auth-library-java/blob/master/CHANGELOG.md) - [Version Diff](https://github.com/googleapis/google-auth-library-java/compare/v0.21.0...v0.21.1). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/a2a47735b8b5ce3b0b0a9fa0a2cdf3b8405ff98d/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.auth"", artifactId = ""google-auth-library-oauth2-http"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5620:658,Config,Configure,658,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5620,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.google.auth:google-auth-library-oauth2-http](https://github.com/googleapis/google-auth-library-java) from 0.21.1 to 0.22.0.; [GitHub Release Notes](https://github.com/googleapis/google-auth-library-java/releases/tag/v0.22.0) - [Changelog](https://github.com/googleapis/google-auth-library-java/blob/master/CHANGELOG.md) - [Version Diff](https://github.com/googleapis/google-auth-library-java/compare/v0.21.1...v0.22.0). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/8853889b19d5f226b195d46df032c05250479bcc/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.auth"", artifactId = ""google-auth-library-oauth2-http"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5949:658,Config,Configure,658,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5949,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.google.auth:google-auth-library-oauth2-http](https://github.com/googleapis/google-auth-library-java) from 0.21.1 to 0.22.1.; [GitHub Release Notes](https://github.com/googleapis/google-auth-library-java/releases/tag/v0.22.1) - [Changelog](https://github.com/googleapis/google-auth-library-java/blob/master/CHANGELOG.md) - [Version Diff](https://github.com/googleapis/google-auth-library-java/compare/v0.21.1...v0.22.1). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/03af41a542c12fc54bb78e335130c7473955d6b9/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.auth"", artifactId = ""google-auth-library-oauth2-http"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6116:658,Config,Configure,658,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6116,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.google.auth:google-auth-library-oauth2-http](https://github.com/googleapis/google-auth-library-java) from 0.22.1 to 0.22.2.; [GitHub Release Notes](https://github.com/googleapis/google-auth-library-java/releases/tag/v0.22.2) - [Changelog](https://github.com/googleapis/google-auth-library-java/blob/master/CHANGELOG.md) - [Version Diff](https://github.com/googleapis/google-auth-library-java/compare/v0.22.1...v0.22.2). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/b48aba70ec793405c98788a322d160987ba51d3e/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.auth"", artifactId = ""google-auth-library-oauth2-http"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6251:658,Config,Configure,658,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6251,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.google.auth:google-auth-library-oauth2-http](https://github.com/googleapis/google-auth-library-java) from 0.22.2 to 0.26.0.; [GitHub Release Notes](https://github.com/googleapis/google-auth-library-java/releases/tag/v0.26.0) - [Changelog](https://github.com/googleapis/google-auth-library-java/blob/master/CHANGELOG.md) - [Version Diff](https://github.com/googleapis/google-auth-library-java/compare/v0.22.2...v0.26.0). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/92f43ce5f010fa03daeb2625a3f9c1b1be80cca5/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.auth"", artifactId = ""google-auth-library-oauth2-http"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6398:658,Config,Configure,658,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6398,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.google.auth:google-auth-library-oauth2-http](https://github.com/googleapis/google-auth-library-java) from 1.1.0 to 1.3.0.; [GitHub Release Notes](https://github.com/googleapis/google-auth-library-java/releases/tag/v1.3.0) - [Version Diff](https://github.com/googleapis/google-auth-library-java/compare/v1.1.0...v1.3.0). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/00809e6249b134635f71919c17c1c81603beb22d/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Files still referring to the old version number</summary>. The following files still refer to the old version number (1.1.0).; You might want to review and update them manually.; ```; CHANGELOG.md; centaur/src/main/resources/integrationTestCases/cwl/bcbio/gvcf-joint-workflow/steps/variantcall_batch_region.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/prealign-workflow/steps/variantcall_batch_region.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/somatic-workflow/steps/variantcall_batch_region.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/svcall-workflow/steps/variantcall_batch_region.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/wes_chr21_test-workflow-gcp/steps/variantcall_batch_region.cwl; cloud-nio/cloud-nio-impl-drs/src/main/scala/cloud/nio/impl/drs/DrsCloudNioFileSystemProvider.scala; cwl/src/test/resources/cwl/lodash.js; project/plugins.sbt; ```; </details>; <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.auth"", artifactId = ""google-auth-libr",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6608:558,Config,Configure,558,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6608,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.google.auth:google-auth-library-oauth2-http](https://github.com/googleapis/google-auth-library-java) from 1.5.3 to 1.10.0.; [GitHub Release Notes](https://github.com/googleapis/google-auth-library-java/releases/tag/v1.10.0) - [Version Diff](https://github.com/googleapis/google-auth-library-java/compare/v1.5.3...v1.10.0). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/2dc2301e75aea6c2d0c49b89d6092f7d4f134b40/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Files still referring to the old version number</summary>. The following files still refer to the old version number (1.5.3).; You might want to review and update them manually.; ```; cwl/src/test/resources/cwl/ontology/EDAM.owl; ```; </details>; <details>; <summary>Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.auth"", artifactId = ""google-auth-library-oauth2-http"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""@monthly"" },; dependency = { groupId = ""com.google.auth"", artifactId = ""google-auth-library-oauth2-http"" }; }]; ```; </details>. labels: library-update, early-semver-minor, semver-spec-minor, old-version-remains, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6857:561,Config,Configure,561,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6857,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.google.auth:google-auth-library-oauth2-http](https://github.com/googleapis/google-auth-library-java) from 1.5.3 to 1.16.0.; [GitHub Release Notes](https://github.com/googleapis/google-auth-library-java/releases/tag/v1.16.0) - [Version Diff](https://github.com/googleapis/google-auth-library-java/compare/v1.5.3...v1.16.0). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/9367739b48d1bae5766674e547f8cdf8a82d318a/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.auth"", artifactId = ""google-auth-library-oauth2-http"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""com.google.auth"", artifactId = ""google-auth-library-oauth2-http"" }; }]; ```; </details>. labels: library-update, early-semver-minor, semver-spec-minor, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7040:561,Config,Configure,561,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7040,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.google.cloud:google-cloud-monitoring](https://github.com/googleapis/java-monitoring) from 1.100.1 to 2.0.0.; [GitHub Release Notes](https://github.com/googleapis/java-monitoring/releases/tag/v2.0.0) - [Changelog](https://github.com/googleapis/java-monitoring/blob/master/CHANGELOG.md) - [Version Diff](https://github.com/googleapis/java-monitoring/compare/v1.100.1...v2.0.0). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/3208ffc94f1fcd586eda4a559961d1ef013f8952/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.cloud"", artifactId = ""google-cloud-monitoring"" } ]; ```; </details>. labels: library-update, semver-major",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5742:614,Config,Configure,614,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5742,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.google.cloud:google-cloud-monitoring](https://github.com/googleapis/java-monitoring) from 1.100.1 to 2.0.1.; [GitHub Release Notes](https://github.com/googleapis/java-monitoring/releases/tag/v2.0.1) - [Changelog](https://github.com/googleapis/java-monitoring/blob/master/CHANGELOG.md) - [Version Diff](https://github.com/googleapis/java-monitoring/compare/v1.100.1...v2.0.1). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/e6e484297151f4295e46ab0ef4aeb2de13a91724/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.cloud"", artifactId = ""google-cloud-monitoring"" } ]; ```; </details>. labels: library-update, semver-major",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5764:614,Config,Configure,614,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5764,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.google.cloud:google-cloud-monitoring](https://github.com/googleapis/java-monitoring) from 3.2.5 to 3.2.10.; [GitHub Release Notes](https://github.com/googleapis/java-monitoring/releases/tag/v3.2.10) - [Version Diff](https://github.com/googleapis/java-monitoring/compare/v3.2.5...v3.2.10). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/9367739b48d1bae5766674e547f8cdf8a82d318a/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.cloud"", artifactId = ""google-cloud-monitoring"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""com.google.cloud"", artifactId = ""google-cloud-monitoring"" }; }]; ```; </details>. labels: library-update, early-semver-patch, semver-spec-patch, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7041:527,Config,Configure,527,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7041,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.google.cloud:google-cloud-nio](https://github.com/googleapis/java-storage-nio) from 0.124.8 to 0.124.14.; [GitHub Release Notes](https://github.com/googleapis/java-storage-nio/releases/tag/v0.124.14) - [Version Diff](https://github.com/googleapis/java-storage-nio/compare/v0.124.8...v0.124.14). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/2dc2301e75aea6c2d0c49b89d6092f7d4f134b40/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Files still referring to the old version number</summary>. The following files still refer to the old version number (0.124.8).; You might want to review and update them manually.; ```; CHANGELOG.md; ```; </details>; <details>; <summary>Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.cloud"", artifactId = ""google-cloud-nio"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""@monthly"" },; dependency = { groupId = ""com.google.cloud"", artifactId = ""google-cloud-nio"" }; }]; ```; </details>. labels: library-update, early-semver-minor, semver-spec-patch, old-version-remains, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6860:533,Config,Configure,533,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6860,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.google.cloud:google-cloud-nio](https://github.com/googleapis/java-storage-nio) from 0.124.8 to 0.124.21.; [GitHub Release Notes](https://github.com/googleapis/java-storage-nio/releases/tag/v0.124.21) - [Version Diff](https://github.com/googleapis/java-storage-nio/compare/v0.124.8...v0.124.21). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/9367739b48d1bae5766674e547f8cdf8a82d318a/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Files still referring to the old version number</summary>. The following files still refer to the old version number (0.124.8).; You might want to review and update them manually.; ```; CHANGELOG.md; ```; </details>; <details>; <summary>Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.cloud"", artifactId = ""google-cloud-nio"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""com.google.cloud"", artifactId = ""google-cloud-nio"" }; }]; ```; </details>. labels: library-update, early-semver-minor, semver-spec-patch, old-version-remains, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7042:533,Config,Configure,533,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7042,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.google.cloud:google-cloud-resourcemanager](https://github.com/googleapis/java-resourcemanager) from 1.0.4 to 1.1.2.; [GitHub Release Notes](https://github.com/googleapis/java-resourcemanager/releases/tag/v1.1.2) - [Changelog](https://github.com/googleapis/java-resourcemanager/blob/master/CHANGELOG.md) - [Version Diff](https://github.com/googleapis/java-resourcemanager/compare/v1.0.4...v1.1.2). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/6472b97b3365f2800f4202d1bf6b1d647bd2b0cc/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Files still referring to the old version number</summary>. The following files still refer to the old version number (1.0.4).; You might want to review and update them manually.; ```; centaur/src/main/resources/integrationTestCases/cwl/bcbio/gvcf-joint-workflow/steps/variantcall_batch_region.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/prealign-workflow/steps/variantcall_batch_region.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/somatic-workflow/steps/variantcall_batch_region.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/svcall-workflow/steps/variantcall_batch_region.cwl; centaur/src/main/resources/integrationTestCases/cwl/bcbio/wes_chr21_test-workflow-gcp/steps/variantcall_batch_region.cwl; project/Dependencies.scala; ```; </details>; <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.cloud"", artifactId = ""google-cloud-resourcemanager"" } ]; ```; </details>. labels: library-update, semver-",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6519:635,Config,Configure,635,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6519,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.google.cloud:google-cloud-resourcemanager](https://github.com/googleapis/java-resourcemanager) from 1.1.2 to 1.1.4.; [GitHub Release Notes](https://github.com/googleapis/java-resourcemanager/releases/tag/v1.1.4) - [Version Diff](https://github.com/googleapis/java-resourcemanager/compare/v1.1.2...v1.1.4). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/00809e6249b134635f71919c17c1c81603beb22d/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Files still referring to the old version number</summary>. The following files still refer to the old version number (1.1.2).; You might want to review and update them manually.; ```; centaur/src/main/resources/integrationTestCases/green/arrays/arrays.inputs; ```; </details>; <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.cloud"", artifactId = ""google-cloud-resourcemanager"" } ]; ```; </details>. labels: library-update, early-semver-patch, semver-spec-patch, old-version-remains, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6611:544,Config,Configure,544,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6611,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.google.cloud:google-cloud-resourcemanager](https://github.com/googleapis/java-resourcemanager) from 1.2.5 to 1.2.11.; [GitHub Release Notes](https://github.com/googleapis/java-resourcemanager/releases/tag/v1.2.11) - [Version Diff](https://github.com/googleapis/java-resourcemanager/compare/v1.2.5...v1.2.11). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/2dc2301e75aea6c2d0c49b89d6092f7d4f134b40/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Files still referring to the old version number</summary>. The following files still refer to the old version number (1.2.5).; You might want to review and update them manually.; ```; cwl/src/test/resources/cwl/ontology/EDAM.owl; ```; </details>; <details>; <summary>Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.cloud"", artifactId = ""google-cloud-resourcemanager"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""@monthly"" },; dependency = { groupId = ""com.google.cloud"", artifactId = ""google-cloud-resourcemanager"" }; }]; ```; </details>. labels: library-update, early-semver-patch, semver-spec-patch, old-version-remains, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6861:547,Config,Configure,547,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6861,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.google.cloud:google-cloud-resourcemanager](https://github.com/googleapis/java-resourcemanager) from 1.2.5 to 1.2.12.; [GitHub Release Notes](https://github.com/googleapis/java-resourcemanager/releases/tag/v1.2.12) - [Version Diff](https://github.com/googleapis/java-resourcemanager/compare/v1.2.5...v1.2.12). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/9367739b48d1bae5766674e547f8cdf8a82d318a/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.cloud"", artifactId = ""google-cloud-resourcemanager"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""30 days"" },; dependency = { groupId = ""com.google.cloud"", artifactId = ""google-cloud-resourcemanager"" }; }]; ```; </details>. labels: library-update, early-semver-patch, semver-spec-patch, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/7043:547,Config,Configure,547,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/7043,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.google.guava:guava](https://github.com/google/guava) from 27.0.1-jre to 27.1-jre. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/a2a47735b8b5ce3b0b0a9fa0a2cdf3b8405ff98d/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.guava"", artifactId = ""guava"" } ]; ```; </details>. labels: library-update",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5624:320,Config,Configure,320,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5624,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.google.guava:guava](https://github.com/google/guava) from 27.1-jre to 29.0-jre. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/58abe73a731f0fe337e07a07ba05cb4bbfe81bd5/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.guava"", artifactId = ""guava"" } ]; ```; </details>. labels: library-update",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5732:318,Config,Configure,318,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5732,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.google.guava:guava](https://github.com/google/guava) from 29.0-jre to 30.0-jre. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/19da014de4d7ffaaf25485ab05efa66bc7748c1f/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.guava"", artifactId = ""guava"" } ]; ```; </details>. labels: library-update",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5954:318,Config,Configure,318,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5954,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.google.guava:guava](https://github.com/google/guava) from 30.0-jre to 30.1.1-jre. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/b48aba70ec793405c98788a322d160987ba51d3e/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.guava"", artifactId = ""guava"" } ]; ```; </details>. labels: library-update",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6255:320,Config,Configure,320,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6255,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.google.guava:guava](https://github.com/google/guava) from 30.1.1-jre to 31.0.1-jre. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/6472b97b3365f2800f4202d1bf6b1d647bd2b0cc/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.guava"", artifactId = ""guava"" } ]; ```; </details>. labels: library-update, semver-major",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6521:322,Config,Configure,322,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6521,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.google.guava:guava](https://github.com/google/guava) from 31.0.1-jre to 31.1-jre. I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/2dc2301e75aea6c2d0c49b89d6092f7d4f134b40/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.guava"", artifactId = ""guava"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""@monthly"" },; dependency = { groupId = ""com.google.guava"", artifactId = ""guava"" }; }]; ```; </details>. labels: library-update, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6863:320,Config,Configure,320,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6863,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.google.oauth-client:google-oauth-client](https://github.com/googleapis/google-oauth-java-client) from 1.31.0 to 1.31.1.; [GitHub Release Notes](https://github.com/googleapis/google-oauth-java-client/releases/tag/v1.31.1) - [Changelog](https://github.com/googleapis/google-oauth-java-client/blob/master/CHANGELOG.md) - [Version Diff](https://github.com/googleapis/google-oauth-java-client/compare/v1.31.0...v1.31.1). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/70862b7263be540409b11ad2c14f1fe8fbc0ff26/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.oauth-client"", artifactId = ""google-oauth-client"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5943:654,Config,Configure,654,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5943,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.google.oauth-client:google-oauth-client](https://github.com/googleapis/google-oauth-java-client) from 1.31.0 to 1.31.2.; [GitHub Release Notes](https://github.com/googleapis/google-oauth-java-client/releases/tag/v1.31.2) - [Changelog](https://github.com/googleapis/google-oauth-java-client/blob/master/CHANGELOG.md) - [Version Diff](https://github.com/googleapis/google-oauth-java-client/compare/v1.31.0...v1.31.2). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/241699fed34d4870884f4f086e6f107da0954d21/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.oauth-client"", artifactId = ""google-oauth-client"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6017:654,Config,Configure,654,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6017,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.google.oauth-client:google-oauth-client](https://github.com/googleapis/google-oauth-java-client) from 1.31.2 to 1.31.4.; [GitHub Release Notes](https://github.com/googleapis/google-oauth-java-client/releases/tag/v1.31.4) - [Changelog](https://github.com/googleapis/google-oauth-java-client/blob/master/CHANGELOG.md) - [Version Diff](https://github.com/googleapis/google-oauth-java-client/compare/v1.31.2...v1.31.4). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/b48aba70ec793405c98788a322d160987ba51d3e/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.oauth-client"", artifactId = ""google-oauth-client"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6256:654,Config,Configure,654,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6256,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.google.oauth-client:google-oauth-client](https://github.com/googleapis/google-oauth-java-client) from 1.31.4 to 1.31.5.; [GitHub Release Notes](https://github.com/googleapis/google-oauth-java-client/releases/tag/v1.31.5) - [Changelog](https://github.com/googleapis/google-oauth-java-client/blob/master/CHANGELOG.md) - [Version Diff](https://github.com/googleapis/google-oauth-java-client/compare/v1.31.4...v1.31.5). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/92f43ce5f010fa03daeb2625a3f9c1b1be80cca5/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.oauth-client"", artifactId = ""google-oauth-client"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6402:654,Config,Configure,654,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6402,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.google.oauth-client:google-oauth-client](https://github.com/googleapis/google-oauth-java-client) from 1.33.1 to 1.33.3.; [GitHub Release Notes](https://github.com/googleapis/google-oauth-java-client/releases/tag/v1.33.3) - [Version Diff](https://github.com/googleapis/google-oauth-java-client/compare/v1.33.1...v1.33.3). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/2dc2301e75aea6c2d0c49b89d6092f7d4f134b40/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.google.oauth-client"", artifactId = ""google-oauth-client"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""@monthly"" },; dependency = { groupId = ""com.google.oauth-client"", artifactId = ""google-oauth-client"" }; }]; ```; </details>. labels: library-update, early-semver-patch, semver-spec-patch, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6864:559,Config,Configure,559,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6864,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.iheart:ficus](https://github.com/iheartradio/ficus) from 1.4.4 to 1.4.7.; [GitHub Release Notes](https://github.com/iheartradio/ficus/releases/tag/v1.4.7) - [Version Diff](https://github.com/iheartradio/ficus/compare/v1.4.4...v1.4.7). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/a2a47735b8b5ce3b0b0a9fa0a2cdf3b8405ff98d/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.iheart"", artifactId = ""ficus"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5625:473,Config,Configure,473,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5625,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.iheart:ficus](https://github.com/iheartradio/ficus) from 1.4.7 to 1.5.0.; [GitHub Release Notes](https://github.com/iheartradio/ficus/releases/tag/v1.5.0) - [Version Diff](https://github.com/iheartradio/ficus/compare/v1.4.7...v1.5.0). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/fthomas/scala-steward/blob/6fa5051c5aeeaaae7870cefd2d9908da221f2f61/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.iheart"", artifactId = ""ficus"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/5777:473,Config,Configure,473,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/5777,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.iheart:ficus](https://github.com/iheartradio/ficus) from 1.5.0 to 1.5.1.; [GitHub Release Notes](https://github.com/iheartradio/ficus/releases/tag/v1.5.1) - [Version Diff](https://github.com/iheartradio/ficus/compare/v1.5.0...v1.5.1). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/6472b97b3365f2800f4202d1bf6b1d647bd2b0cc/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.iheart"", artifactId = ""ficus"" } ]; ```; </details>. labels: library-update, semver-patch",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6522:473,Config,Configure,473,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6522,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.iheart:ficus](https://github.com/iheartradio/ficus) from 1.5.1 to 1.5.2.; [GitHub Release Notes](https://github.com/iheartradio/ficus/releases/tag/v1.5.2) - [Version Diff](https://github.com/iheartradio/ficus/compare/v1.5.1...v1.5.2). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/2dc2301e75aea6c2d0c49b89d6092f7d4f134b40/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Files still referring to the old version number</summary>. The following files still refer to the old version number (1.5.1).; You might want to review and update them manually.; ```; cwl/src/test/resources/cwl/ontology/EDAM.owl; ```; </details>; <details>; <summary>Adjust future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.iheart"", artifactId = ""ficus"" } ]; ```; Or, add this to slow down future updates of this dependency:; ```; dependencyOverrides = [{; pullRequests = { frequency = ""@monthly"" },; dependency = { groupId = ""com.iheart"", artifactId = ""ficus"" }; }]; ```; </details>. labels: library-update, early-semver-patch, semver-spec-patch, old-version-remains, commit-count:1",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6865:473,Config,Configure,473,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6865,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,"Updates [com.lihaoyi:ammonite-ops](https://github.com/com-lihaoyi/Ammonite) from 2.3.8 to 2.4.0.; [GitHub Release Notes](https://github.com/com-lihaoyi/Ammonite/releases/tag/2.4.0) - [Version Diff](https://github.com/com-lihaoyi/Ammonite/compare/2.3.8...2.4.0). I'll automatically update this PR to resolve conflicts as long as you don't change it yourself. If you'd like to skip this version, you can just close this PR. If you have any feedback, just mention me in the comments below. Configure Scala Steward for your repository with a [`.scala-steward.conf`](https://github.com/scala-steward-org/scala-steward/blob/92f43ce5f010fa03daeb2625a3f9c1b1be80cca5/docs/repo-specific-configuration.md) file. Have a fantastic day writing Scala!. <details>; <summary>Ignore future updates</summary>. Add this to your `.scala-steward.conf` file to ignore future updates of this dependency:; ```; updates.ignore = [ { groupId = ""com.lihaoyi"", artifactId = ""ammonite-ops"" } ]; ```; </details>. labels: library-update, semver-minor",MatchSource.ISSUE,broadinstitute,cromwell,87,https://github.com/broadinstitute/cromwell/pull/6403:487,Config,Configure,487,https://cromwell.readthedocs.io/en/latest/,https://github.com/broadinstitute/cromwell/pull/6403,2,"['Config', 'config']","['Configure', 'configuration']"
