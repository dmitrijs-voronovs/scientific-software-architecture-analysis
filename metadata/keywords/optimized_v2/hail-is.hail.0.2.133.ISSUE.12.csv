quality_attribute,sentence,source,author,repo,version,id,keyword,matched_word,match_idx,wiki,url,total_similar,target_keywords,target_matched_words
Integrability,"ub.com/urllib3/urllib3/commit/06406c5f795e85aca1792a52010d94c54a21fbd8""><code>06406c5</code></a> [1.26] Mention pool size when discarding connections (<a href=""https://github-redirect.dependabot.com/urllib3/urllib3/issues/2497"">#2497</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/urllib3/urllib3/compare/1.26.5...1.26.8"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=urllib3&package-manager=pip&previous-version=1.26.5&new-version=1.26.8)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11532:8128,Depend,Dependabot,8128,https://hail.is,https://github.com/hail-is/hail/pull/11532,1,['Depend'],['Dependabot']
Integrability,"ub.request</code>&quot;</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/f9c89e5d8431155caa7be57d923f96004a2dd4bd""><code>f9c89e5</code></a> Switch to using <code>github.request</code></li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/52c7f66ce172f723e8227896fe02165d288cb28f""><code>52c7f66</code></a> Use the correct token minting URL for TestPyPI</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/6079f28faa2a60d00f62b02786f23cd489019cdb""><code>6079f28</code></a> Install twine in PyPI publish workflow</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/3d43b9efdb49706cad6947f0c4d877d603781fe6""><code>3d43b9e</code></a> Fix github-script syntax in create-release.yml</li>; <li>Additional commits viewable in <a href=""https://github.com/sphinx-doc/sphinx/compare/v6.2.1...v7.1.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=sphinx&package-manager=pip&previous-version=6.2.1&new-version=7.1.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13295:6852,depend,dependency-name,6852,https://hail.is,https://github.com/hail-is/hail/pull/13295,1,['depend'],['dependency-name']
Integrability,"ubernetes/kubernetes#61231 (review)) (what; the hell?), ergo Confused Deputy. ### Future Work. - Require TLS 1.3 everywhere.; - Comply with Mozilla's ""Modern"" recommendations.; - [Incoming Trust](#incoming-trust).; - Refresh certificates after deploying new ones. ### Footnotes. [1] TLS: Transport Layer Security. Preceded by Secure Sockets Layer (SSL) which; is not obsolete and insecure. After SSL version 3, a new version of SSL was; proposed in RFC 2246. This new version was backwards-incompatible and was; thus given a new name: Transport Layer Security. In common discussion, SSL; and TLS are used interchangeable. Indeed, the python TLS library is called; `ssl`. [2] Forward secrecy is a property of an encryption system. Forward secrecy means; a message cannot be decrypted in the future by an adversary who learned one; of the private keys. For example, imagine you are sending sensitive messages; to another individual. If that individual is later coerced into revealing; their secret key, forward secrecy would prevent the coercer from reading; your messages. Forward secrecy is achieved by negotiating a shared private; key between the two parties that is only used for a ""session"" and then; discarded. If the session key is securely discarded and neither key can; recreate it without cooperation from the other key, then *one* leaked key is; insufficient to reveal the messages. ---. Things for you to verify:; - does every service load *its own unqiue* ssl-config secret?; - does every service use an SSL context for serving?; - does everyone who makes http requests to internal services use an SSL client; session?; - do all TLS-secured nginx instances include their http.conf in the `http`; section and the `proxy.conf` file in any proxying sections?; - Do the SSLContext's from `ssl.py` and the nginx configurations generated by; `create_certs.py` actually ensure security?. Post-merge actions:; - deploy gateway; - deploy internal-gateway; - deploy router-resolver. Anticipated outa",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8561:12332,message,messages,12332,https://hail.is,https://github.com/hail-is/hail/pull/8561,1,['message'],['messages']
Integrability,"ubernetes/kubernetes#91748</a>, <a href=""https://github.com/apelisse""><code>@​apelisse</code></a>)</li>; <li>Scheduler: optionally check for available storage capacity before scheduling pods which have unbound volumes (alpha feature with the new <code>CSIStorageCapacity</code> feature gate, only works for CSI drivers and depends on support for the feature in a CSI driver deployment) (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/92387"">kubernetes/kubernetes#92387</a>, <a href=""https://github.com/pohly""><code>@​pohly</code></a>) [SIG API Machinery, Apps, Auth, Scheduling, Storage and Testing]</li>; <li>Seccomp support has graduated to GA. A new <code>seccompProfile</code> field is added to pod and container securityContext objects. Support for <code>seccomp.security.alpha.kubernetes.io/pod</code> and <code>container.seccomp.security.alpha.kubernetes.io/...</code> annotations is deprecated, and will be removed in v1.22. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/91381"">kubernetes/kubernetes#91381</a>, <a href=""https://github.com/pjbgf""><code>@​pjbgf</code></a>) [SIG Apps, Auth, Node, Release, Scheduling and Testing]</li>; <li>ServiceAppProtocol feature gate is now beta and enabled by default, adding new AppProtocol field to Services and Endpoints. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/90023"">kubernetes/kubernetes#90023</a>, <a href=""https://github.com/robscott""><code>@​robscott</code></a>) [SIG Apps and Network]</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/tomplus/kubernetes_asyncio/commit/bcfd4ed2ec3b2f503adc4f2e681f9404216d302c""><code>bcfd4ed</code></a> chore: update version</li>; <li><a href=""https://github.com/tomplus/kubernetes_asyncio/commit/37f5d63425976b463bb83348d592859a82f2b5af""><code>37f5d63</code></a> chore: update changelog</li>; <li><a ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11462:13630,depend,dependabot,13630,https://hail.is,https://github.com/hail-is/hail/pull/11462,1,['depend'],['dependabot']
Integrability,"ubernetes/kubernetes/pull/94986"">kubernetes/kubernetes#94986</a>, <a href=""https://github.com/tkashem""><code>@​tkashem</code></a>) [SIG API Machinery, Auth, Cloud Provider and Testing]</li>; <li>A small regression in Service updates was fixed. The circumstances are so unlikely that probably nobody would ever hit it. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/104601"">kubernetes/kubernetes#104601</a>, <a href=""https://github.com/thockin""><code>@​thockin</code></a>)</li>; <li>Added a feature gate <code>StatefulSetAutoDeletePVC</code>, which allows PVCs automatically created for StatefulSet pods to be automatically deleted. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/99728"">kubernetes/kubernetes#99728</a>, <a href=""https://github.com/mattcary""><code>@​mattcary</code></a>)</li>; <li>Client-go impersonation config can specify a UID to pass impersonated uid information through in requests. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/104483"">kubernetes/kubernetes#104483</a>, <a href=""https://github.com/margocrawf""><code>@​margocrawf</code></a>)</li>; <li>Create HPA v2 from v2beta2 with some fields changed. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/102534"">kubernetes/kubernetes#102534</a>, <a href=""https://github.com/wangyysde""><code>@​wangyysde</code></a>) [SIG API Machinery, Apps, Auth, Autoscaling and Testing]</li>; <li>Ephemeral containers graduated to beta and are now available by default. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/105405"">kubernetes/kubernetes#105405</a>, <a href=""https://github.com/verb""><code>@​verb</code></a>)</li>; <li>Fix kube-proxy regression on UDP services because the logic to detect stale connections was not considering if the endpoint was ready. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/106163"">kubernetes/kubernetes#106163</a>, <a href=""https://gith",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11957:2952,depend,dependabot,2952,https://hail.is,https://github.com/hail-is/hail/pull/11957,1,['depend'],['dependabot']
Integrability,"ubuntu:18.04' ; ...: p = pl.Pipeline(name='download_data_fail', ; ...: backend=pl.BatchBackend(billing_project='hail'), ; ...: default_image=BENCHMARK_IMAGE, ; ...: default_cpu=1) ; ...: ; ...: for i in range(1): ; ...: t = p.new_task(f'replicate_{i}') ; ...: t.command('echo ' + 'a' * 1000) ; ...: p.run(wait=False) ; aenter; aexit; submit jobs timing {'create': 264, 'total': 265}; Traceback (most recent call last):; File ""<timed exec>"", line 15, in <module>; File ""/Users/dking/projects/hail/hail/python/hailtop/pipeline/pipeline.py"", line 395, in run; self._backend._run(self, dry_run, verbose, delete_scratch_on_exit, **backend_kwargs); File ""/Users/dking/projects/hail/hail/python/hailtop/pipeline/backend.py"", line 329, in _run; batch = batch.submit(); File ""/Users/dking/projects/hail/hail/python/hailtop/batch_client/client.py"", line 164, in submit; async_batch = async_to_blocking(self._async_builder.submit()); File ""/Users/dking/projects/hail/hail/python/hailtop/batch_client/client.py"", line 7, in async_to_blocking; return asyncio.get_event_loop().run_until_complete(coro); File ""/usr/local/Cellar/python/3.7.5/Frameworks/Python.framework/Versions/3.7/lib/python3.7/asyncio/base_events.py"", line 579, in run_until_complete; return future.result(); File ""/usr/local/Cellar/python/3.7.5/Frameworks/Python.framework/Versions/3.7/lib/python3.7/asyncio/futures.py"", line 178, in result; raise self._exception; File ""/usr/local/Cellar/python/3.7.5/Frameworks/Python.framework/Versions/3.7/lib/python3.7/asyncio/tasks.py"", line 249, in __step; result = coro.send(None); File ""/Users/dking/projects/hail/hail/python/hailtop/batch_client/aioclient.py"", line 500, in submit; b = await b_resp.json(); File ""/usr/local/lib/python3.7/site-packages/aiohttp/client_reqrep.py"", line 1032, in json; headers=self.headers); ContentTypeError: 0, message='Attempt to decode JSON with unexpected mimetype: text/plain; charset=utf-8', url='https://internal.hail.is/dking/batch/api/v1alpha/batches/create. ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7839:2173,message,message,2173,https://hail.is,https://github.com/hail-is/hail/issues/7839,1,['message'],['message']
Integrability,"uctions](https://hail.is/docs/0.2/install/macosx.html) for installing Hail on a Mac. After installing Java and restarting, I created a new Conda environment and used `pip install hail` to install.; Running the import in `ipython` succeeds, but initialization (in the course of running the code in 'Your First Hail Query' [example](https://hail.is/docs/0.2/install/try.html) fails with the following traceback:. ```; Exception Traceback (most recent call last); <ipython-input-2-20bea8c9bdc1> in <module>; ----> 1 hl.init(). ~/miniconda3/envs/hail-env/lib/python3.9/site-packages/decorator.py in fun(*args, **kw); 230 if not kwsyntax:; 231 args, kw = fix(args, kw, sig); --> 232 return caller(func, *(extras + args), **kw); 233 fun.__name__ = func.__name__; 234 fun.__doc__ = func.__doc__. ~/miniconda3/envs/hail-env/lib/python3.9/site-packages/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 575 def wrapper(__original_func, *args, **kwargs):; 576 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 577 return __original_func(*args_, **kwargs_); 578; 579 return wrapper. ~/miniconda3/envs/hail-env/lib/python3.9/site-packages/hail/context.py in init(sc, app_name, master, local, log, quiet, append, min_block_size, branching_factor, tmp_dir, default_reference, idempotent, global_seed, spark_conf, skip_logging_configuration, local_tmpdir, _optimizer_iterations); 244 optimizer_iterations = get_env_or_default(_optimizer_iterations, 'HAIL_OPTIMIZER_ITERATIONS', 3); 245; --> 246 backend = SparkBackend(; 247 idempotent, sc, spark_conf, app_name, master, local, log,; 248 quiet, append, min_block_size, branching_factor, tmpdir, local_tmpdir,. ~/miniconda3/envs/hail-env/lib/python3.9/site-packages/hail/backend/spark_backend.py in __init__(self, idempotent, sc, spark_conf, app_name, master, local, log, quiet, append, min_block_size, branching_factor, tmpdir, local_tmpdir, skip_logging_configuration, optimizer_iterations); 141 conf.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/10524:1187,wrap,wrapper,1187,https://hail.is,https://github.com/hail-is/hail/issues/10524,3,['wrap'],['wrapper']
Integrability,"ue to more; frequent GC runs (<a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/9586"">#9586</a>).</li>; <li>Fix conversion of singleton classes in Ruby (<a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/9342"">#9342</a>)</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/protocolbuffers/protobuf/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=protobuf&package-manager=pip&previous-version=3.19.6&new-version=4.21.12)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12563:4447,depend,dependabot,4447,https://hail.is,https://github.com/hail-is/hail/pull/12563,1,['depend'],['dependabot']
Integrability,"ues/10112"">#10112</a>: extlinks: Add :confval:<code>extlinks_detect_hardcoded_links</code> to enable; hardcoded links detector feature</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/9494"">#9494</a>, <a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/9456"">#9456</a>: html search: Add a config variable; :confval:<code>html_show_search_summary</code> to enable/disable the search summaries</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/9337"">#9337</a>: HTML theme, add option <code>enable_search_shortcuts</code> that enables :kbd:'/' as; a Quick search shortcut and :kbd:<code>Esc</code> shortcut that; removes search highlighting.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10107"">#10107</a>: i18n: Allow to suppress translation warnings by adding <code>#noqa</code>; comment to the tail of each translation message</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10252"">#10252</a>: C++, support attributes on classes, unions, and enums.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10253"">#10253</a>: :rst:dir:<code>pep</code> role now generates URLs based on peps.python.org</li>; </ul>; <h2>Bugs fixed</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/9876"">#9876</a>: autodoc: Failed to document an imported class that is built from native; binary module</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10133"">#10133</a>: autodoc: Crashed when mocked module is used for type annotation</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10146"">#10146</a>: autodoc: :confval:<code>autodoc_default_options</code> does not support; <code>no-value</code> option</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/9971"">#9971</a>: autodoc: TypeError is ra",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11714:3059,depend,dependabot,3059,https://hail.is,https://github.com/hail-is/hail/pull/11714,2,['depend'],['dependabot']
Integrability,"ues/1547"">#1547</a>)</p>; <p>Misc Improvements; f461401e3 Silence AsciiLineReader warning when creating a FASTA sequence index (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1559"">#1559</a>); 8f82871c1 Update explain samflags script to python3 (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1585"">#1585</a>); 4ba4c0678 Update to new version of the snappy library which will work with M1 macs (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1580"">#1580</a>); e92706452 add predicate to GFF3Codec to give a chance to filter out some unused attributes (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1575"">#1575</a>); c647764b0 Some long reads tests using PacBio data. (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1564"">#1564</a>); 57c3f03eb remove hardcoded .idx (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1568"">#1568</a>); a94a32512 Add file extension to missing index error message <a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1512"">#1512</a> (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1567"">#1567</a>); 74b827b67 Improve error message in IntervalTree (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1545"">#1545</a>); 7719274fe Htsget POST request support (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1529"">#1529</a>)</p>; <p>VCF:; aac46ee6d Added GVCF mode for VariantContext type determination (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1544"">#1544</a>); d72d73b01 Add context to exception when the vcf file is invalid <a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1565"">#1565</a> (<a href=""https://github-redirect.dependabot.com/samtools/htsjdk/issues/1566"">#1566</a>); 8466c82dc Respect genotype filtering when calculating AC/AN/AF (<a href=""https://github-redirect.dependabot.com/s",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12229:4781,message,message,4781,https://hail.is,https://github.com/hail-is/hail/pull/12229,1,['message'],['message']
Integrability,"ues/2161"">#2161</a> PR by <a href=""https://github.com/schmir""><code>@​schmir</code></a>.</li>; </ul>; </li>; <li>fix <code>language: r</code> with a local renv and <code>RENV_PROJECT</code> set.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2170"">#2170</a> PR by <a href=""https://github.com/lorenzwalthert""><code>@​lorenzwalthert</code></a>.</li>; </ul>; </li>; <li>forbid overriding <code>entry</code> in <code>language: meta</code> hooks which breaks them.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2180"">#2180</a> issue by <a href=""https://github.com/DanKaplanSES""><code>@​DanKaplanSES</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2181"">#2181</a> PR by <a href=""https://github.com/asottile""><code>@​asottile</code></a>.</li>; </ul>; </li>; <li>always use <code>#!/bin/sh</code> on windows for hook script.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2182"">#2182</a> issue by <a href=""https://github.com/hushigome-visco""><code>@​hushigome-visco</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2187"">#2187</a> PR by <a href=""https://github.com/asottile""><code>@​asottile</code></a>.</li>; </ul>; </li>; </ul>; <h1>2.16.0 - 2021-11-30</h1>; <h3>Features</h3>; <ul>; <li>add warning for regexes containing <code>[\/]</code> or <code>[/\\]</code>.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2053"">#2053</a> PR by <a href=""https://github.com/radek-sprta""><code>@​radek-sprta</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2043"">#2043</a> issue by <a href=""https://github.com/asottile""><code>@​asottile</code></a>.</li>; </ul>; </li>; <li>move hook template back to <code>bash</code> resolving shebang-portability issues.; <ul>; <li><a href=""https://github-redirect.depen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11460:10098,depend,dependabot,10098,https://hail.is,https://github.com/hail-is/hail/pull/11460,2,['depend'],['dependabot']
Integrability,"ues/2161"">#2161</a> PR by <a href=""https://github.com/schmir""><code>@​schmir</code></a>.</li>; </ul>; </li>; <li>fix <code>language: r</code> with a local renv and <code>RENV_PROJECT</code> set.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2170"">#2170</a> PR by <a href=""https://github.com/lorenzwalthert""><code>@​lorenzwalthert</code></a>.</li>; </ul>; </li>; <li>forbid overriding <code>entry</code> in <code>language: meta</code> hooks which breaks them.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2180"">#2180</a> issue by <a href=""https://github.com/DanKaplanSES""><code>@​DanKaplanSES</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2181"">#2181</a> PR by <a href=""https://github.com/asottile""><code>@​asottile</code></a>.</li>; </ul>; </li>; <li>always use <code>#!/bin/sh</code> on windows for hook script.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2182"">#2182</a> issue by <a href=""https://github.com/hushigome-visco""><code>@​hushigome-visco</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2187"">#2187</a> PR by <a href=""https://github.com/asottile""><code>@​asottile</code></a>.</li>; </ul>; </li>; </ul>; <h2>pre-commit v2.16.0</h2>; <h3>Features</h3>; <ul>; <li>add warning for regexes containing <code>[\/]</code> or <code>[/\\]</code>.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2053"">#2053</a> PR by <a href=""https://github.com/radek-sprta""><code>@​radek-sprta</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2043"">#2043</a> issue by <a href=""https://github.com/asottile""><code>@​asottile</code></a>.</li>; </ul>; </li>; <li>move hook template back to <code>bash</code> resolving shebang-portability issues.; <ul>; <li><a href=""https://github-redirect.depend",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11460:3617,depend,dependabot,3617,https://hail.is,https://github.com/hail-is/hail/pull/11460,2,['depend'],['dependabot']
Integrability,"ues/248"">#248</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiorwlock/compare/v1.0.0...v1.3.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiorwlock&package-manager=pip&previous-version=1.0.0&new-version=1.3.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11514:4224,Depend,Dependabot,4224,https://hail.is,https://github.com/hail-is/hail/pull/11514,17,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability,"ues/250"">#250</a> from carterbox/no-overflow-naturaldelta</li>; <li><a href=""https://github.com/jmoiron/humanize/commit/e89c8c8e325ccb2b3ee78ef507e9d6805c47a175""><code>e89c8c8</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/jmoiron/humanize/issues/241"">#241</a> from samueljsb/remove-deprecated-private-function-ali...</li>; <li><a href=""https://github.com/jmoiron/humanize/commit/ffe4bcfaa6cfbd95ba47315f8f71a206485af6ae""><code>ffe4bcf</code></a> Remove deprecated VERSION, use <strong>version</strong> instead</li>; <li><a href=""https://github.com/jmoiron/humanize/commit/eb3e2534267714361da866109bd33ff20e63416c""><code>eb3e253</code></a> Merge branch 'master' into no-overflow-naturaldelta</li>; <li>Additional commits viewable in <a href=""https://github.com/jmoiron/humanize/compare/1.0.0...4.0.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=humanize&package-manager=pip&previous-version=1.0.0&new-version=4.0.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` wil",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11517:6831,depend,dependency-name,6831,https://hail.is,https://github.com/hail-is/hail/pull/11517,2,['depend'],['dependency-name']
Integrability,"ues/45918"">#45918</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/pandas-dev/pandas/compare/v1.3.0...v1.4.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pandas&package-manager=pip&previous-version=1.3.0&new-version=1.4.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11539:6683,Depend,Dependabot,6683,https://hail.is,https://github.com/hail-is/hail/pull/11539,17,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability,"ues/45923"">#45923</a>: DOC: add Python 3.10 to doc (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45927"">#45927</a>)</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/deea0562e1ebabc874011575293103d0ba35d0f0""><code>deea056</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45910"">#45910</a>: TST/CI: Set hypothesis deadline to None to avoid flaky fa...</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/58aebf1940b56b77279174f5413b76a5aaba465c""><code>58aebf1</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45909"">#45909</a>: BUG: DateOffset(n) not defaulting to days (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45918"">#45918</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/pandas-dev/pandas/compare/v1.3.0...v1.4.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pandas&package-manager=pip&previous-version=1.3.0&new-version=1.4.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` wil",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11539:6035,Depend,Dependabot,6035,https://hail.is,https://github.com/hail-is/hail/pull/11539,2,"['Depend', 'depend']","['Dependabot', 'dependabot-badges']"
Integrability,"ues/48571"">#48571</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/pandas-dev/pandas/compare/v1.3.5...v1.5.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pandas&package-manager=pip&previous-version=1.3.5&new-version=1.5.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12292:6546,Depend,Dependabot,6546,https://hail.is,https://github.com/hail-is/hail/pull/12292,17,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability,"ues/59"">#59</a>)</li>; <li><a href=""https://github.com/hagenw/sphinxcontrib-katex/commit/3ea5d66cc6985f4aa021c845ceeadd9a26f39a37""><code>3ea5d66</code></a> Release 0.8.3</li>; <li><a href=""https://github.com/hagenw/sphinxcontrib-katex/commit/d7636e1c52f3cc9a586171f5c9318b338acfbaaf""><code>d7636e1</code></a> Readd manifest to fix compilation of latest docs (<a href=""https://github-redirect.dependabot.com/hagenw/sphinxcontrib-katex/issues/58"">#58</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/hagenw/sphinxcontrib-katex/compare/0.5.1...v0.8.6"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=sphinxcontrib-katex&package-manager=pip&previous-version=0.5.1&new-version=0.8.6)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11458:6273,Depend,Dependabot,6273,https://hail.is,https://github.com/hail-is/hail/pull/11458,2,['Depend'],['Dependabot']
Integrability,"ues/981"">#981</a>, pr <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/987"">#987</a>).</li>; <li>Fixed the custom <code>repr</code> for <code>dateutil.parser.ParserError</code>, which was not; defined due to an indentation error. (gh issue <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/991"">#991</a>, gh pr <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/993"">#993</a>)</li>; <li>Fixed a bug that caused <code>b'</code> prefixes to appear in parse_isodate exception; messages. Reported and fixed by Paul Brown (<a href=""https://github.com/pawl""><code>@​pawl</code></a>) (gh pr <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/1122"">#1122</a>)</li>; <li>Make <code>isoparse</code> raise when trying to parse times with inconsistent use of; <code>:</code> separator. Reported and fixed by <a href=""https://github.com/mariocj89""><code>@​mariocj89</code></a> (gh pr <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/1125"">#1125</a>).</li>; <li>Fixed <code>tz.gettz()</code> not returning local time when passed an empty string.; Reported by <a href=""https://github.com/labrys""><code>@​labrys</code></a> (gh issues <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/925"">#925</a>, <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/926"">#926</a>). Fixed by <a href=""https://github.com/ffe4""><code>@​ffe4</code></a> (gh pr <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/1024"">#1024</a>)</li>; </ul>; <h2>Documentation changes</h2>; <ul>; <li>Rearranged parser documentation into &quot;Functions&quot;, &quot;Classes&quot; and &quot;Warnings and; Exceptions&quot; categories. (gh issue <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/992"">#992</a>, pr <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/994"">#994</a>).</li>; <li>Updated <code>parser.parse</code> docum",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11518:1843,depend,dependabot,1843,https://hail.is,https://github.com/hail-is/hail/pull/11518,2,['depend'],['dependabot']
Integrability,"uest <a href=""https://github-redirect.dependabot.com/pallets/click/issues/2237"">#2237</a> from pallets/param-order</li>; <li><a href=""https://github.com/pallets/click/commit/b36bf8f9b36ab7db8cf03cd8eff714dfc33f0c29""><code>b36bf8f</code></a> restore Path param order</li>; <li><a href=""https://github.com/pallets/click/commit/a66119abe973f55b4f5e28dbb0da6f3c32c21af7""><code>a66119a</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/click/issues/2236"">#2236</a> from shadchin/patch-1</li>; <li><a href=""https://github.com/pallets/click/commit/92cebe902aa7f03a89f6b261d897964dd9c5fa43""><code>92cebe9</code></a> fix readable path check error message</li>; <li><a href=""https://github.com/pallets/click/commit/456fbb6b0053fb01bedf90b64999b0a3c645a3cd""><code>456fbb6</code></a> start version 8.1.2</li>; <li>See full diff in <a href=""https://github.com/pallets/click/compare/8.1.1...8.1.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=click&package-manager=pip&previous-version=8.1.1&new-version=8.1.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11726:2886,Depend,Dependabot,2886,https://hail.is,https://github.com/hail-is/hail/pull/11726,2,"['Depend', 'depend']","['Dependabot', 'dependabot-badges']"
Integrability,"uest <a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-xdist/issues/734"">#734</a> from nicoddemus/revamp-readme</li>; <li><a href=""https://github.com/pytest-dev/pytest-xdist/commit/83bdbf4b95c914a889d1faa8fba8d506bcc2f8c7""><code>83bdbf4</code></a> Revamp README</li>; <li><a href=""https://github.com/pytest-dev/pytest-xdist/commit/630c1eb6f2c31dcb4c38c75bb62f868237cdde94""><code>630c1eb</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-xdist/issues/733"">#733</a> from baekdohyeop/feature-loadgroup</li>; <li><a href=""https://github.com/pytest-dev/pytest-xdist/commit/62e50d00977b41e175b5f119381f9db760459ddc""><code>62e50d0</code></a> Address review</li>; <li>Additional commits viewable in <a href=""https://github.com/pytest-dev/pytest-xdist/compare/v2.2.1...v2.5.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pytest-xdist&package-manager=pip&previous-version=2.2.1&new-version=2.5.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` w",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11491:5839,depend,dependency-name,5839,https://hail.is,https://github.com/hail-is/hail/pull/11491,2,['depend'],['dependency-name']
Integrability,"uest <a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10502"">#10502</a> from AA-Turner/ifconfig-fix</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/c4458e3adbcffced2248fb3d05a283e1754d3b7c""><code>c4458e3</code></a> ifconfig: Do not use a meta node for noop</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/2a50b2e5a3b76d708dfb61d46bd78847353189a7""><code>2a50b2e</code></a> Update CHANGES for PR <a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10504"">#10504</a></li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/8aacb338aa0e9e5a9823babbce90ce478eed1237""><code>8aacb33</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10504"">#10504</a> from AA-Turner/fix-kbd-findall</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/28f9ce78b0074c70a3b849c7f9eb7a4dabf6bece""><code>28f9ce7</code></a> Update CHANGES for PR <a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10493"">#10493</a></li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/cb407c4024d7d63a832b87df62d1b73fb70162dc""><code>cb407c4</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10493"">#10493</a> from AA-Turner/more-css</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/d6d2a403450e022f5b91323a367fdc5539f7c525""><code>d6d2a40</code></a> Update CHANGES for PR <a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10503"">#10503</a></li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/433c67effc12f23c5501f051d94296cbb1cd8282""><code>433c67e</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10503"">#10503</a> from AA-Turner/gettext-catalogue-fix</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/a1ecf99b9fb75bfb74d891716958666d497bd153""><code>a1ecf99</code></a> Remove warning</li>; <li>Additiona",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11885:5742,depend,dependabot,5742,https://hail.is,https://github.com/hail-is/hail/pull/11885,1,['depend'],['dependabot']
Integrability,"uf/issues/10512"">#10512</a>)</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/a826282e15efe3ae3a2aebb040fb1691b2233a1e""><code>a826282</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/10505"">#10505</a> from deannagarcia/3.20.x</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/7639a710e10beb47bfc62f363680f7b04e8b3d26""><code>7639a71</code></a> Add version file</li>; <li>Additional commits viewable in <a href=""https://github.com/protocolbuffers/protobuf/compare/v3.20.1...v3.20.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=protobuf&package-manager=pip&previous-version=3.20.1&new-version=3.20.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12223:3205,Depend,Dependabot,3205,https://hail.is,https://github.com/hail-is/hail/pull/12223,3,['Depend'],['Dependabot']
Integrability,"ug Fixes</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1447"">#1447</a>: Null-check cleanable in <code>c.s.j.Memory#close</code> - <a href=""https://github.com/dbwiddis""><code>@​dbwiddis</code></a>.</li>; </ul>; <h1>Release 5.12.0</h1>; <h2>Features</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1433"">#1433</a>: Add <code>CFEqual</code>, <code>CFDictionaryRef.ByReference</code>, <code>CFStringRef.ByReference</code> to <code>c.s.j.p.mac.CoreFoundation</code> - <a href=""https://github.com/shalupov""><code>@​shalupov</code></a></li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/978"">#978</a>: Remove use of finalizers in JNA and improve concurrency for <code>Memory</code>, <code>CallbackReference</code> and <code>NativeLibrary</code> - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1440"">#1440</a>: Support for LoongArch64 - <a href=""https://github.com/Panxuefeng-loongson""><code>@​Panxuefeng-loongson</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1444"">#1444</a>: Update embedded libffi to 1f14b3fa92d4442a60233e9596ddec428a985e3c and rebuild native libraries - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; </ul>; <h2>Bug Fixes</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/pull/1438"">#1438</a>: Handle arrays in structures with differing size - <a href=""https://github.com/matthiasblaesing""><code>@​matthiasblaesing</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1442"">#1442</a>: Handle race condition in <code>c.s.j.p.win32.PdhUtil#PdhEnumObjectItems</code> - <a href=""https://github.com/dbwiddis""><code>@​dbwiddis</code></a>.</li>; </ul>; <h2>Importan",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12438:1284,depend,dependabot,1284,https://hail.is,https://github.com/hail-is/hail/pull/12438,1,['depend'],['dependabot']
Integrability,"ugins_in...</li>; <li><a href=""https://github.com/pytest-dev/pytest/commit/843e01824c257c3190792a9df430289c3abe349d""><code>843e018</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9732"">#9732</a> from nicoddemus/9730-toml-failure</li>; <li><a href=""https://github.com/pytest-dev/pytest/commit/bc43d66b47b917d43a22e0c703ecfe4eea342263""><code>bc43d66</code></a> [automated] Update plugin list (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9733"">#9733</a>)</li>; <li><a href=""https://github.com/pytest-dev/pytest/commit/e38d1cac489e42f4bdbecbb50f9f25dc9c36c19f""><code>e38d1ca</code></a> Improve error message for malformed pyproject.toml files</li>; <li>Additional commits viewable in <a href=""https://github.com/pytest-dev/pytest/compare/6.2.5...7.1.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pytest&package-manager=pip&previous-version=6.2.5&new-version=7.1.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11571:6853,depend,dependency-name,6853,https://hail.is,https://github.com/hail-is/hail/pull/11571,2,['depend'],['dependency-name']
Integrability,"ugpy/issues/1001"">#1001</a></p>; <h2>debugpy v1.6.2</h2>; <p>Fixes unintentional breaking change in public API in debugpy 1.6.1 (<a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/975"">#975</a>).</p>; <p>Other fixes: <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/969"">#969</a></p>; <h2>debugpy v1.6.1</h2>; <p>debugpy API now has type annotations.</p>; <p>Optimizations based on frame evaluation API are re-enabled by default.</p>; <p>Other improvements: <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/743"">#743</a>, <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/774"">#774</a>, <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/893"">#893</a>, <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/945"">#945</a></p>; <p>Bug fixes: <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/705"">#705</a>, <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/731"">#731</a>, <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/861"">#861</a>, <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/865"">#865</a>, <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/882"">#882</a>, <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/889"">#889</a>, <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/896"">#896</a>, <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/915"">#915</a>, <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/921"">#921</a>, <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/928"">#928</a>, <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/934"">#934</a></p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/microsoft/debugpy/commit/8b5eeee7e0b1678e701b07d94e",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12103:1887,depend,dependabot,1887,https://hail.is,https://github.com/hail-is/hail/pull/12103,2,['depend'],['dependabot']
Integrability,"ugpy/issues/951"">#951</a>, <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/1001"">#1001</a></p>; <h2>debugpy v1.6.2</h2>; <p>Fixes unintentional breaking change in public API in debugpy 1.6.1 (<a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/975"">#975</a>).</p>; <p>Other fixes: <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/969"">#969</a></p>; <h2>debugpy v1.6.1</h2>; <p>debugpy API now has type annotations.</p>; <p>Optimizations based on frame evaluation API are re-enabled by default.</p>; <p>Other improvements: <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/743"">#743</a>, <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/774"">#774</a>, <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/893"">#893</a>, <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/945"">#945</a></p>; <p>Bug fixes: <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/705"">#705</a>, <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/731"">#731</a>, <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/861"">#861</a>, <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/865"">#865</a>, <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/882"">#882</a>, <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/889"">#889</a>, <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/896"">#896</a>, <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/915"">#915</a>, <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/921"">#921</a>, <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/928"">#928</a>, <a href=""https://github-redirect.dependabot.com/microsoft/debugpy/issues/934"">#934</a></p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12103:1799,depend,dependabot,1799,https://hail.is,https://github.com/hail-is/hail/pull/12103,2,['depend'],['dependabot']
Integrability,"ugs discovered after; the 1.23.4 release and keeps the build infrastructure current. The; Python versions supported for this release are 3.8-3.11.</p>; <h2>Contributors</h2>; <p>A total of 7 people contributed to this release. People with a &quot;+&quot; by; their names contributed a patch for the first time.</p>; <ul>; <li><a href=""https://github.com/DWesl""><code>@​DWesl</code></a></li>; <li>Aayush Agrawal +</li>; <li>Adam Knapp +</li>; <li>Charles Harris</li>; <li>Navpreet Singh +</li>; <li>Sebastian Berg</li>; <li>Tania Allard</li>; </ul>; <h2>Pull requests merged</h2>; <p>A total of 10 pull requests were merged for this release.</p>; <ul>; <li><a href=""https://github-redirect.dependabot.com/numpy/numpy/pull/22489"">#22489</a>: TST, MAINT: Replace most setup with setup_method (also teardown)</li>; <li><a href=""https://github-redirect.dependabot.com/numpy/numpy/pull/22490"">#22490</a>: MAINT, CI: Switch to cygwin/cygwin-install-action@v2</li>; <li><a href=""https://github-redirect.dependabot.com/numpy/numpy/pull/22494"">#22494</a>: TST: Make test_partial_iteration_cleanup robust but require leak...</li>; <li><a href=""https://github-redirect.dependabot.com/numpy/numpy/pull/22592"">#22592</a>: MAINT: Ensure graceful handling of large header sizes</li>; <li><a href=""https://github-redirect.dependabot.com/numpy/numpy/pull/22593"">#22593</a>: TYP: Spelling alignment for array flag literal</li>; <li><a href=""https://github-redirect.dependabot.com/numpy/numpy/pull/22594"">#22594</a>: BUG: Fix bounds checking for <code>random.logseries</code></li>; <li><a href=""https://github-redirect.dependabot.com/numpy/numpy/pull/22595"">#22595</a>: DEV: Update GH actions and Dockerfile for Gitpod</li>; <li><a href=""https://github-redirect.dependabot.com/numpy/numpy/pull/22596"">#22596</a>: CI: Only fetch in actions/checkout</li>; <li><a href=""https://github-redirect.dependabot.com/numpy/numpy/pull/22597"">#22597</a>: BUG: Decrement ref count in gentype_reduce if allocated memory...</li>; <li><a ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12515:1334,depend,dependabot,1334,https://hail.is,https://github.com/hail-is/hail/pull/12515,1,['depend'],['dependabot']
Integrability,"uh""><code>@​JLLeitschuh</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2806"">cbeust/testng#2806</a></li>; <li>GITHUB-2807 - Failsafe buildStackTrace by <a href=""https://github.com/seregamorph""><code>@​seregamorph</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2808"">cbeust/testng#2808</a></li>; <li>Prevent overlogging of debug msgs in Graph impl by <a href=""https://github.com/krmahadevan""><code>@​krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2813"">cbeust/testng#2813</a></li>; <li>Streamline dataprovider invoking in abstract classes by <a href=""https://github.com/krmahadevan""><code>@​krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2814"">cbeust/testng#2814</a></li>; <li>Streamline TestResult due to expectedExceptions by <a href=""https://github.com/krmahadevan""><code>@​krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2815"">cbeust/testng#2815</a></li>; <li>Unexpected test runs count with retry analyzer by <a href=""https://github.com/krmahadevan""><code>@​krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2816"">cbeust/testng#2816</a></li>; <li>Make PackageUtils compliant with JPMS by <a href=""https://github.com/krmahadevan""><code>@​krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2817"">cbeust/testng#2817</a></li>; <li>Ability to retry a data provider during failures by <a href=""https://github.com/krmahadevan""><code>@​krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2820"">cbeust/testng#2820</a></li>; <li>Refactoring by <a href=""https://github.com/krmahadevan""><code>@​krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2821"">cbeust/testng#2821</a></li>; <li>Fixing bug with DataProvider retry by <a href=""http",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12665:2764,depend,dependabot,2764,https://hail.is,https://github.com/hail-is/hail/pull/12665,1,['depend'],['dependabot']
Integrability,"uilder#buildOrThrow graceful (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2159"">#2159</a>)</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/a7ac773e340bd788aa38b91bb40a503fb2530212""><code>a7ac773</code></a> chore(main): release 2.26.1-SNAPSHOT (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2155"">#2155</a>)</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/e1ce76fe8c6c5d6fc0d40d5c2c64e256294c6416""><code>e1ce76f</code></a> chore(main): release 2.26.0 (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2140"">#2140</a>)</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/68ad8e7357097e3dd161c2ab5f7a42a060a3702c""><code>68ad8e7</code></a> fix: possible NPE when HttpStorageOptions deserialized (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2153"">#2153</a>)</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/eba8b6a235919a27d1f6dadf770140c7d143aa1a""><code>eba8b6a</code></a> deps: update dependency com.google.cloud:google-cloud-shared-dependencies to ...</li>; <li>Additional commits viewable in <a href=""https://github.com/googleapis/java-storage/compare/v2.17.1...v2.26.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.google.cloud:google-cloud-storage&package-manager=gradle&previous-version=2.17.1&new-version=2.26.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by com",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13605:11518,depend,dependency,11518,https://hail.is,https://github.com/hail-is/hail/pull/13605,1,['depend'],['dependency']
Integrability,"uilder.</li>; <li>Move proto wireformat parsing functionality from the private &quot;parsing; constructor&quot; to the Builder class.</li>; <li>Change the Lite runtime to prefer merging from the wireformat into mutable; messages rather than building up a new immutable object before merging. This; way results in fewer allocations and copy operations.</li>; <li>Make message-type extensions merge from wire-format instead of building up; instances and merging afterwards. This has much better performance.</li>; <li>Fix TextFormat parser to build up recurring (but supposedly not repeated); sub-messages directly from text rather than building a new sub-message and; merging the fully formed message into the existing field.</li>; <li>This release addresses a <a href=""https://github.com/protocolbuffers/protobuf/security/advisories/GHSA-h4h5-3hr4-j3g2"">Security Advisory for Java users</a></li>; </ul>; <h2>Protocol Buffers v3.20.2</h2>; <h1>C++</h1>; <ul>; <li>Reduce memory consumption of MessageSet parsing</li>; <li>This release addresses a <a href=""https://github.com/protocolbuffers/protobuf/security/advisories/GHSA-8gq9-2x98-w8hf"">Security Advisory for C++ and Python users</a></li>; </ul>; <h2>Protocol Buffers v3.20.1</h2>; <h1>PHP</h1>; <ul>; <li>Fix building packaged PHP extension (<a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/9727"">#9727</a>)</li>; <li>Fixed composer.json to only advertise compatibility with PHP 7.0+. (<a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/9819"">#9819</a>)</li>; </ul>; <h1>Ruby</h1>; <ul>; <li>Disable the aarch64 build on macOS until it can be fixed. (<a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/9816"">#9816</a>)</li>; </ul>; <h1>Other</h1>; <ul>; <li>Fix versioning issues in 3.20.0</li>; </ul>; <h2>Protocol Buffers v3.20.1-rc1</h2>; <p>#PHP</p>; <ul>; <li>Fix building packaged PHP extension (<a href=""https://github-redirect.dependabot.com/protocol",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12563:1441,Message,MessageSet,1441,https://hail.is,https://github.com/hail-is/hail/pull/12563,1,['Message'],['MessageSet']
Integrability,"ul>; <h1>2.8.0 (2019-09-17)</h1>; <ul>; <li>Make this compatible with Python 3.7+. Import from collections.abc, instead; of from collections. (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/373"">#373</a>)</li>; </ul>; <h1>2.7.0 (2018-10-13)</h1>; <ul>; <li>; <p>Reset a session if the session age &gt; max_age (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/331"">#331</a>)</p>; </li>; <li>; <p>Reset a session on TTL expiration for EncryptedCookieStorage (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/326"">#326</a>)</p>; </li>; </ul>; <h1>2.6.0 (2018-09-12)</h1>; <ul>; <li>Create a new session if <code>NaClCookieStorage</code> cannot decode a; corrupted cookie (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/317"">#317</a>)</li>; </ul>; <h1>2.5.0 (2018-05-12)</h1>; <ul>; <li>Add an API for requesting new session explicitly (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/281"">#281</a>)</li>; </ul>; <h1>2.4.0 (2018-05-04)</h1>; <ul>; <li>Fix a bug for session fixation (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/272"">#272</a>)</li>; </ul>; <h1>2.3.0 (2018-02-13)</h1>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/af0560812d3dc2043565de1108ac41b65caac7d0""><code>af05608</code></a> Release 2.11 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/673"">#673</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/16aa24292125aa59fed1ab4292c6576d800295f1""><code>16aa242</code></a> Bump pytest-mock from 3.6.1 to 3.7.0 (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp_session/issues/674"">#674</a>)</li>; <li><a href=""https://github.com/aio-libs/aiohttp-session/commit/72d199d40689cb0a83f2",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11577:2287,depend,dependabot,2287,https://hail.is,https://github.com/hail-is/hail/pull/11577,1,['depend'],['dependabot']
Integrability,"ul>; <h2>Version 0.8.2 (2021-05-18)</h2>; <ul>; <li>Fixed: PyPI package version number</li>; </ul>; <h2>Version 0.8.1 (2021-05-18)</h2>; <ul>; <li>Fixed: PyPI package had wrong version number</li>; </ul>; <h2>Version 0.8.0 (2021-05-18)</h2>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/hagenw/sphinxcontrib-katex/commit/e27a051532dee33fbe329636b042426bf3ad6e26""><code>e27a051</code></a> Release 0.9.0</li>; <li><a href=""https://github.com/hagenw/sphinxcontrib-katex/commit/01d3b3ba5e04feec8cb34bdad388dd93f4205e3e""><code>01d3b3b</code></a> DOC: fix instructions for pre-rendering (<a href=""https://github-redirect.dependabot.com/hagenw/sphinxcontrib-katex/issues/85"">#85</a>)</li>; <li><a href=""https://github.com/hagenw/sphinxcontrib-katex/commit/4fcbee9e0e105257a1e8b47d9a2e36e22cd81dd9""><code>4fcbee9</code></a> Add script to update KaTeX version (<a href=""https://github-redirect.dependabot.com/hagenw/sphinxcontrib-katex/issues/82"">#82</a>)</li>; <li><a href=""https://github.com/hagenw/sphinxcontrib-katex/commit/fea5c7a3357fbfddb91dc145d14eefb2aadc9c20""><code>fea5c7a</code></a> Use JS files provided by package in HTML page (<a href=""https://github-redirect.dependabot.com/hagenw/sphinxcontrib-katex/issues/84"">#84</a>)</li>; <li><a href=""https://github.com/hagenw/sphinxcontrib-katex/commit/99584308b9a5f76f29530db4cef2333353504830""><code>9958430</code></a> Use katex.min.js for server rendering (<a href=""https://github-redirect.dependabot.com/hagenw/sphinxcontrib-katex/issues/83"">#83</a>)</li>; <li><a href=""https://github.com/hagenw/sphinxcontrib-katex/commit/0164f90b8242f65911ac1b4c86afe09082e527bc""><code>0164f90</code></a> Server side implementation of pre rendering of Latex equations (<a href=""https://github-redirect.dependabot.com/hagenw/sphinxcontrib-katex/issues/69"">#69</a>)</li>; <li><a href=""https://github.com/hagenw/sphinxcontrib-katex/commit/7946b7d8bae7fd7dead5",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12241:4236,depend,dependabot,4236,https://hail.is,https://github.com/hail-is/hail/pull/12241,1,['depend'],['dependabot']
Integrability,"ul>; <li><a href=""https://github.com/scipy/scipy/commit/656076ca6b490f587e9bd9c4cd10cb259a687c5b""><code>656076c</code></a> MAINT: wheel push 1.9.2 [wheel build]</li>; <li><a href=""https://github.com/scipy/scipy/commit/ad0d0f907010fbc8b66cdbe8ce0af2683881a309""><code>ad0d0f9</code></a> REL: set 1.9.2 released [wheel build]</li>; <li><a href=""https://github.com/scipy/scipy/commit/d9ad9801323653a2015b4d3e80d6d3ea93b6c021""><code>d9ad980</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/scipy/scipy/issues/17150"">#17150</a> from tylerjereddy/treddy_scipy_192_more_backports</li>; <li><a href=""https://github.com/scipy/scipy/commit/6b098c25223e224ff44101f86bbc86efecffe1d9""><code>6b098c2</code></a> TST: optimize.milp: remove problematic timeout/iteration test</li>; <li><a href=""https://github.com/scipy/scipy/commit/24dce9760b87934f1be046ec817c758b0f3952dc""><code>24dce97</code></a> DOC: stats.pearsonr: typo in coeffic<em>i</em>ent (<a href=""https://github-redirect.dependabot.com/scipy/scipy/issues/17153"">#17153</a>)</li>; <li><a href=""https://github.com/scipy/scipy/commit/a6ba7cad3b54c35d2ccb55c595691689004742c1""><code>a6ba7ca</code></a> MAINT: misc 1.9.2 updates</li>; <li><a href=""https://github.com/scipy/scipy/commit/ed9760e60a28b8f13e5644494033e2dab9aafbcd""><code>ed9760e</code></a> MAINT: stats.pearson3: fix ppf for negative skew (<a href=""https://github-redirect.dependabot.com/scipy/scipy/issues/17055"">#17055</a>)</li>; <li><a href=""https://github.com/scipy/scipy/commit/6fb67007dd7105755057f3379fb7ef423eae524e""><code>6fb6700</code></a> FIX: optimize.milp: return feasible solution if available on timeout/node lim...</li>; <li><a href=""https://github.com/scipy/scipy/commit/bcfce27fc061cbde6ac6531799362e0420ea4796""><code>bcfce27</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/scipy/scipy/issues/17132"">#17132</a> from tylerjereddy/treddy_192_backports</li>; <li><a href=""https://github.com/scipy/scipy/commit/2bc973a2c28c4b",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12352:2196,depend,dependabot,2196,https://hail.is,https://github.com/hail-is/hail/pull/12352,1,['depend'],['dependabot']
Integrability,"ul>; <li>Python 2.7 and 3.5 are not supported.</li>; <li><code>connect()</code> uses keyword-only arguments. User must use keyword argument.</li>; <li><code>connect()</code> kwargs <code>db</code> and <code>passwd</code> are now deprecated; Use <code>database</code> and <code>password</code> instead.</li>; <li>old_password authentication method (used by MySQL older than 4.1) is not supported.</li>; <li>MySQL 5.5 and MariaDB 5.5 are not officially supported, although it may still works.</li>; <li>Removed <code>escape_dict</code>, <code>escape_sequence</code>, and <code>escape_string</code> from <code>pymysql</code>; module. They are still in <code>pymysql.converters</code>.</li>; </ul>; <p>Other changes:</p>; <ul>; <li>Connection supports context manager API. <code>__exit__</code> closes the connection. (<a href=""https://github-redirect.dependabot.com/PyMySQL/PyMySQL/issues/886"">#886</a>)</li>; <li>Add MySQL Connector/Python compatible TLS options (<a href=""https://github-redirect.dependabot.com/PyMySQL/PyMySQL/issues/903"">#903</a>)</li>; <li>Major code cleanup; PyMySQL now uses black and flake8.</li>; </ul>; <h2>v0.10.1</h2>; <p>Release date: 2020-09-10</p>; <ul>; <li>Fix missing import of ProgrammingError. (<a href=""https://github-redirect.dependabot.com/PyMySQL/PyMySQL/issues/878"">#878</a>)</li>; <li>Fix auth switch request handling. (<a href=""https://github-redirect.dependabot.com/PyMySQL/PyMySQL/issues/890"">#890</a>)</li>; </ul>; <h2>v0.10.0</h2>; <p>Release date: 2020-07-18</p>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/PyMySQL/PyMySQL/commit/b12efdb6c1baa55e58a4384271e33a7351d554d5""><code>b12efdb</code></a> v1.0.2</li>; <li><a href=""https://github.com/PyMySQL/PyMySQL/commit/abe83c262ea647a09e0f13587fa91d6a14a71598""><code>abe83c2</code></a> Make 4 more arguments to keyword-only. (<a href=""https://github-redirect.dependabot.com/PyMySQL/PyMySQL/issues/9",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11595:2126,depend,dependabot,2126,https://hail.is,https://github.com/hail-is/hail/pull/11595,1,['depend'],['dependabot']
Integrability,"ull request <a href=""https://github-redirect.dependabot.com/java-native-access/jna/issues/1444"">#1444</a> from matthiasblaesing/update_libffi</li>; <li><a href=""https://github.com/java-native-access/jna/commit/9e473350a5ad5e04aab8b01e4018f973976e19f8""><code>9e47335</code></a> Update CHANGES.md</li>; <li>Additional commits viewable in <a href=""https://github.com/java-native-access/jna/compare/5.6.0...5.12.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=net.java.dev.jna:jna&package-manager=gradle&previous-version=5.6.0&new-version=5.12.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12438:8383,depend,dependabot-automerge-start,8383,https://hail.is,https://github.com/hail-is/hail/pull/12438,2,['depend'],"['dependabot-automerge-end', 'dependabot-automerge-start']"
Integrability,"ull request <a href=""https://github-redirect.dependabot.com/numpy/numpy/issues/20680"">#20680</a> from charris/backport-20663</li>; <li><a href=""https://github.com/numpy/numpy/commit/794b36f7e1bf2a8c42774ab0db86a74bd32f674b""><code>794b36f</code></a> Update armccompiler.py</li>; <li><a href=""https://github.com/numpy/numpy/commit/d93b14e3d7abaa1d837825e51671f817788e120f""><code>d93b14e</code></a> Update test_public_api.py</li>; <li><a href=""https://github.com/numpy/numpy/commit/7662c0789cc6a70d5ad4d950ee2e95f3afef7df6""><code>7662c07</code></a> Update <strong>init</strong>.py</li>; <li><a href=""https://github.com/numpy/numpy/commit/311ab52488a7d096ac3bc4c2de0fdae17ecd13ef""><code>311ab52</code></a> Update armccompiler.py</li>; <li>Additional commits viewable in <a href=""https://github.com/numpy/numpy/compare/v1.21.6...v1.22.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=numpy&package-manager=pip&previous-version=1.21.6&new-version=1.22.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` wi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11939:5162,depend,dependency-name,5162,https://hail.is,https://github.com/hail-is/hail/pull/11939,2,['depend'],['dependency-name']
Integrability,"ull request <a href=""https://github-redirect.dependabot.com/psf/requests/issues/6020"">#6020</a> from nateprewitt/pypy_37</li>; <li><a href=""https://github.com/psf/requests/commit/28d537dde33b35c3b7071afd99122eff3538b42c""><code>28d537d</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/psf/requests/issues/5917"">#5917</a> from nateprewitt/proxy_scheme_unknown_fix</li>; <li>Additional commits viewable in <a href=""https://github.com/psf/requests/compare/v2.25.1...v2.27.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=requests&package-manager=pip&previous-version=2.25.1&new-version=2.27.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11528:9513,depend,dependabot,9513,https://hail.is,https://github.com/hail-is/hail/pull/11528,2,['depend'],['dependabot']
Integrability,"ull), Map(null -> Map(WrappedArray(2) -> 31, WrappedArray(0) -> 0)))); , Set(WrappedArray(Map(null -> Map()), Map(null -> null))); , Set( WrappedArray(Map()); , WrappedArray(Map(null -> Map())); , WrappedArray(Map(null -> null)); , WrappedArray(); , WrappedArray(null, Map(null -> Map(WrappedArray() -> null)))); , Set(); , Set( WrappedArray(Map(null -> Map(WrappedArray() -> null))); , WrappedArray(); , WrappedArray(Map(null -> Map())); , WrappedArray(Map(null -> Map()), Map(null -> Map(WrappedArray() -> 2)))); , Set(WrappedArray()); , Set( WrappedArray(); , WrappedArray(Map(null -> Map()))); , Set(); , Set( WrappedArray(Map(null -> null)); , WrappedArray(Map(null -> Map()))); , Set( WrappedArray(Map(null -> Map(WrappedArray(null) -> 1)), Map(null -> Map(WrappedArray(5) -> 2))); , WrappedArray(Map())); , Set(); , Set(); , Set(WrappedArray(); , WrappedArray(Map(null -> Map()))); , Set(); , Set( null; , WrappedArray()); , Set( WrappedArray(Map(null -> Map(WrappedArray(1) -> 19))); , WrappedArray(Map(null -> Map(WrappedArray(0) -> 2)), Map(null -> Map())); , WrappedArray(Map(null -> Map())); , WrappedArray(Map(null -> Map(WrappedArray(2) -> null)), Map(null -> Map(WrappedArray() -> 17)), Map(null -> Map(WrappedArray() -> 1)))); , Set(WrappedArray(Map(null -> Map(WrappedArray(null) -> 1)), Map(null -> Map(WrappedArray(2) -> 0, WrappedArray() -> null)), Map(), Map())); , Set(WrappedArray(Map(null -> Map()), Map(null -> Map()), Map(null -> Map(WrappedArray(0) -> 0)))); , Set( WrappedArray(); , WrappedArray(Map(null -> Map(WrappedArray(0) -> null)))); , Set(WrappedArray(Map())); , Set( WrappedArray(Map()); , WrappedArray(Map(null -> Map(WrappedArray() -> 0))); , WrappedArray(Map(null -> Map()))); , Set(); , Set( WrappedArray(); , WrappedArray(Map(null -> Map(WrappedArray(null) -> 2))); , WrappedArray(Map(null -> Map()))); , Set( WrappedArray(Map(null -> Map(WrappedArray() -> 0))); , WrappedArray(Map(), Map(null -> Map()), Map(), Map(null -> Map(WrappedArray(0) -> null)))); );",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1902:2354,Wrap,WrappedArray,2354,https://hail.is,https://github.com/hail-is/hail/pull/1902,1,['Wrap'],['WrappedArray']
Integrability,"ull/22490"">#22490</a>: MAINT, CI: Switch to cygwin/cygwin-install-action@v2</li>; <li><a href=""https://github-redirect.dependabot.com/numpy/numpy/pull/22494"">#22494</a>: TST: Make test_partial_iteration_cleanup robust but require leak...</li>; <li><a href=""https://github-redirect.dependabot.com/numpy/numpy/pull/22592"">#22592</a>: MAINT: Ensure graceful handling of large header sizes</li>; <li><a href=""https://github-redirect.dependabot.com/numpy/numpy/pull/22593"">#22593</a>: TYP: Spelling alignment for array flag literal</li>; <li><a href=""https://github-redirect.dependabot.com/numpy/numpy/pull/22594"">#22594</a>: BUG: Fix bounds checking for <code>random.logseries</code></li>; <li><a href=""https://github-redirect.dependabot.com/numpy/numpy/pull/22595"">#22595</a>: DEV: Update GH actions and Dockerfile for Gitpod</li>; <li><a href=""https://github-redirect.dependabot.com/numpy/numpy/pull/22596"">#22596</a>: CI: Only fetch in actions/checkout</li>; <li><a href=""https://github-redirect.dependabot.com/numpy/numpy/pull/22597"">#22597</a>: BUG: Decrement ref count in gentype_reduce if allocated memory...</li>; <li><a href=""https://github-redirect.dependabot.com/numpy/numpy/pull/22625"">#22625</a>: BUG: Histogramdd breaks on big arrays in Windows</li>; </ul>; <h2>Checksums</h2>; <h3>MD5</h3>; <pre><code>8a412b79d975199cefadb465279fd569 numpy-1.23.5-cp310-cp310-macosx_10_9_x86_64.whl; 1b56e8e6a0516c78473657abf0710538 numpy-1.23.5-cp310-cp310-macosx_11_0_arm64.whl; c787f4763c9a5876e86a17f1651ba458 numpy-1.23.5-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl; db07645022e56747ba3f00c2d742232e numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl; c63a6fb7cc16a13aabc82ec57ac6bb4d numpy-1.23.5-cp310-cp310-win32.whl; 3fea9247e1d812600015641941fa273f numpy-1.23.5-cp310-cp310-win_amd64.whl; 4222cfb36e5ac9aec348c81b075e2c05 numpy-1.23.5-cp311-cp311-macosx_10_9_x86_64.whl; 6c7102f185b310ac70a62c13d46f04e6 numpy-1.23.5-cp311-cp311-macosx_11_0_arm64.whl; 6b7319",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12515:2210,depend,dependabot,2210,https://hail.is,https://github.com/hail-is/hail/pull/12515,1,['depend'],['dependabot']
Integrability,"ull/354"">spyder-ide/qtpy#354</a></li>; </ul>; <p><strong>Full commits list between this release and the previous one</strong>: <a href=""https://github.com/spyder-ide/qtpy/compare/v2.1.0...v2.2.0"">https://github.com/spyder-ide/qtpy/compare/v2.1.0...v2.2.0</a>; <strong>Full Changelog</strong>: <a href=""https://github.com/spyder-ide/qtpy/blob/master/CHANGELOG.md#version-220-2022-08-10"">CHANGELOG.md - Version 2.2.0 (2022-08-10)</a></p>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/spyder-ide/qtpy/blob/master/CHANGELOG.md"">qtpy's changelog</a>.</em></p>; <blockquote>; <h2>Version 2.2.0 (2022-08-10)</h2>; <h3>Issues Closed</h3>; <ul>; <li><a href=""https://github-redirect.dependabot.com/spyder-ide/qtpy/issues/359"">Issue 359</a> - Release QtPy 2.2.0</li>; <li><a href=""https://github-redirect.dependabot.com/spyder-ide/qtpy/issues/352"">Issue 352</a> - Deprecation Warning for Enum Access (<a href=""https://github-redirect.dependabot.com/spyder-ide/qtpy/pull/353"">PR 353</a> by <a href=""https://github.com/CAM-Gerlach""><code>@​CAM-Gerlach</code></a>)</li>; <li><a href=""https://github-redirect.dependabot.com/spyder-ide/qtpy/issues/351"">Issue 351</a> - <code>PySide6.QtSvgWidgets</code> not exposed</li>; <li><a href=""https://github-redirect.dependabot.com/spyder-ide/qtpy/issues/302"">Issue 302</a> - Compat shiboken and sip like Qt.py (<a href=""https://github-redirect.dependabot.com/spyder-ide/qtpy/pull/354"">PR 354</a> by <a href=""https://github.com/zjp""><code>@​zjp</code></a>)</li>; <li><a href=""https://github-redirect.dependabot.com/spyder-ide/qtpy/issues/61"">Issue 61</a> - Add documentation for methods or helpers that are specific to qtpy (<a href=""https://github-redirect.dependabot.com/spyder-ide/qtpy/pull/357"">PR 357</a> by <a href=""https://github.com/dalthviz""><code>@​dalthviz</code></a>)</li>; </ul>; <p>In this release 5 issues were closed.</p>; <h3>Pull Requests Merged</h3>; <ul>; <li><a href=""https://github-",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12194:3414,depend,dependabot,3414,https://hail.is,https://github.com/hail-is/hail/pull/12194,1,['depend'],['dependabot']
Integrability,"ullability bounds (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1775"">#1775</a>) (<a href=""https://github.com/googleapis/java-storage/commit/3b8d137a113376d7dac9010b9207d435df2622f7"">3b8d137</a>)</li>; </ul>; <h2>v2.15.0</h2>; <h2><a href=""https://github.com/googleapis/java-storage/compare/v2.14.0...v2.15.0"">2.15.0</a> (2022-11-07)</h2>; <h3>Features</h3>; <ul>; <li>Add Autoclass support and sample (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1697"">#1697</a>) (<a href=""https://github.com/googleapis/java-storage/commit/82aacd7922573d6f4779f21cdc83de10616d7a08"">82aacd7</a>)</li>; <li>Update retries for Notifications (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1734"">#1734</a>) (<a href=""https://github.com/googleapis/java-storage/commit/0fb2f1823f9eff8534f15240321003f120fed3f4"">0fb2f18</a>)</li>; </ul>; <h3>Dependencies</h3>; <ul>; <li>Update dependency com.google.cloud:google-cloud-shared-dependencies to v3.0.6 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1761"">#1761</a>) (<a href=""https://github.com/googleapis/java-storage/commit/803a90b7747b8972f51d1407616c51084d97c589"">803a90b</a>)</li>; <li>Update dependency net.jqwik:jqwik to v1.7.1 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1758"">#1758</a>) (<a href=""https://github.com/googleapis/java-storage/commit/140e90911229c876de7b674dd1e61b278e8b07fd"">140e909</a>)</li>; <li>Update dependency org.graalvm.buildtools:native-maven-plugin to v0.9.17 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1759"">#1759</a>) (<a href=""https://github.com/googleapis/java-storage/commit/7e3175a56a06dac0aa0841f221a486bb69b5c9bf"">7e3175a</a>)</li>; </ul>; <h2>v2.14.0</h2>; <h2><a href=""https://github.com/googleapis/java-storage/compare/v2.13.1...v2.14.0"">2.14.0</a> (2022-10-26)</h2>; <h3>Google Cloud Storage gRPC API Preview</h3>; <p>The fir",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12529:2077,depend,dependencies,2077,https://hail.is,https://github.com/hail-is/hail/pull/12529,1,['depend'],['dependencies']
Integrability,"ullivan</code></a>.</li>; </ul>; </li>; <li>Fix a rare race condition in change stashing.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2323"">#2323</a> PR by <a href=""https://github.com/asottile""><code>@​asottile</code></a>.</li>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2287"">#2287</a> issue by <a href=""https://github.com/ian-h-chamberlain""><code>@​ian-h-chamberlain</code></a>.</li>; </ul>; </li>; </ul>; <h3>Updating</h3>; <ul>; <li>Remove python3.6 support. Note that pre-commit still supports running hooks; written in older versions, but pre-commit itself requires python 3.7+.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2215"">#2215</a> PR by <a href=""https://github.com/asottile""><code>@​asottile</code></a>.</li>; </ul>; </li>; <li>pre-commit has migrated from the <code>master</code> branch to <code>main</code>.; <ul>; <li><a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2302"">#2302</a> PR by <a href=""https://github.com/asottile""><code>@​asottile</code></a>.</li>; </ul>; </li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pre-commit/pre-commit/commit/0276e25f713ddfd66482f358d238186ca47a6eb4""><code>0276e25</code></a> v2.18.1</li>; <li><a href=""https://github.com/pre-commit/pre-commit/commit/f5af0a9ff482bab1a947764f4e3cb11ceb8409cb""><code>f5af0a9</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pre-commit/pre-commit/issues/2324"">#2324</a> from pre-commit/local-hooks-py27</li>; <li><a href=""https://github.com/pre-commit/pre-commit/commit/1722448c3b26abdeb80f403ebe5f3171249e655f""><code>1722448</code></a> fix python 2.7 <code>repo: local</code> hooks</li>; <li><a href=""https://github.com/pre-commit/pre-commit/commit/c5a39ae77e1aff1df32034b27a3a900473698d46""><code>c5a39ae</code></a> v2.18.0</li>; <li><a href=""https://github.com",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11731:10241,depend,dependabot,10241,https://hail.is,https://github.com/hail-is/hail/pull/11731,1,['depend'],['dependabot']
Integrability,"um severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **616/1000** <br/> **Why?** Proof of Concept exploit, Has a fix available, CVSS 5.9 | NULL Pointer Dereference <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6092044](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6092044) | `cryptography:` <br> `3.3.2 -> 41.0.6` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **519/1000** <br/> **Why?** Has a fix available, CVSS 6.1 | Information Exposure <br/>[SNYK-PYTHON-REQUESTS-5595532](https://snyk.io/vuln/SNYK-PYTHON-REQUESTS-5595532) | `requests:` <br> `2.27.1 -> 2.31.0` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI0Yzg3NGFkNy01NjNmLTQ5Y2QtOTc3My04YjlmMTA5NWUzNmMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjRjODc0YWQ3LTU2M2YtNDljZC05NzczLThiOWYxMDk1ZTM2YyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14148:9108,depend,dependency,9108,https://hail.is,https://github.com/hail-is/hail/pull/14148,2,['depend'],"['dependencies', 'dependency']"
Integrability,"umentation on objects</li>; <li>Additional commits viewable in <a href=""https://github.com/ipython/ipython/compare/7.34.0...8.12.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=ipython&package-manager=pip&previous-version=7.34.0&new-version=8.12.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12832:3238,Depend,Dependabot,3238,https://hail.is,https://github.com/hail-is/hail/pull/12832,34,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability,"ummary>; <p><em>Sourced from <a href=""https://github.com/jaraco/keyrings.alt/blob/main/CHANGES.rst"">keyrings-alt's changelog</a>.</em></p>; <blockquote>; <h1>v4.2.0</h1>; <p><a href=""https://github-redirect.dependabot.com/jaraco/keyrings.alt/issues/46"">#46</a>: EncryptedFileKeyring now supports both pycryptodome and; pycryptodomex (preferring the latter).</p>; <h1>v4.1.2</h1>; <p>Updated to work with keyring 23.9+ (no longer depending on properties; module).</p>; <h1>v4.1.1</h1>; <p>Refresh package metadata.</p>; <p>Enrolled with Tidelift.</p>; <h1>v4.1.0</h1>; <p><a href=""https://github-redirect.dependabot.com/jaraco/keyrings.alt/issues/44"">#44</a>: Bump upper bound on pyfs.</p>; <p>Refresh package metadata.</p>; <h1>v4.0.2</h1>; <p><a href=""https://github-redirect.dependabot.com/jaraco/keyrings.alt/issues/43"">#43</a>: Tests are no longer included in the install.</p>; <h1>v4.0.1</h1>; <p>Package refresh and minor cleanup.</p>; <h1>v4.0.0</h1>; <p><a href=""https://github-redirect.dependabot.com/jaraco/keyrings.alt/issues/41"">#41</a>: Instead of PyCrypto or PyCryptodome, the encrypting backend; now relies on PyCryptodomex.</p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/jaraco/keyrings.alt/commit/a2ef1a8e15859bb90f499e6be88c14468f246f8e""><code>a2ef1a8</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/jaraco/keyrings.alt/issues/46"">#46</a> from TheChymera/cryptodome</li>; <li><a href=""https://github.com/jaraco/keyrings.alt/commit/dfab9b2846f7a19bebe788046b167a19a579fb45""><code>dfab9b2</code></a> 👹 Feed the hobgoblins (delint).</li>; <li><a href=""https://github.com/jaraco/keyrings.alt/commit/757afb5d5f3ada3d954eff981e9279f4e348f1e9""><code>757afb5</code></a> ⚫ Fade to black.</li>; <li><a href=""https://github.com/jaraco/keyrings.alt/commit/1614724e27124672f723735ff208a59a94d5c252""><code>1614724</code></a> Update changelog</li>; <li><a href=""https://github.com/jaraco/keyrings.alt/commi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12448:1110,depend,dependabot,1110,https://hail.is,https://github.com/hail-is/hail/pull/12448,1,['depend'],['dependabot']
Integrability,"ummary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/psf/black/blob/main/CHANGES.md"">black's changelog</a>.</em></p>; <blockquote>; <h2>22.3.0</h2>; <h3>Preview style</h3>; <ul>; <li>Code cell separators <code>#%%</code> are now standardised to <code># %%</code> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2919"">#2919</a>)</li>; <li>Remove unnecessary parentheses from <code>except</code> statements (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2939"">#2939</a>)</li>; <li>Remove unnecessary parentheses from tuple unpacking in <code>for</code> loops (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2945"">#2945</a>)</li>; <li>Avoid magic-trailing-comma in single-element subscripts (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2942"">#2942</a>)</li>; </ul>; <h3>Configuration</h3>; <ul>; <li>Do not format <code>__pypackages__</code> directories by default (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2836"">#2836</a>)</li>; <li>Add support for specifying stable version with <code>--required-version</code> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2832"">#2832</a>).</li>; <li>Avoid crashing when the user has no homedir (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2814"">#2814</a>)</li>; <li>Avoid crashing when md5 is not available (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2905"">#2905</a>)</li>; <li>Fix handling of directory junctions on Windows (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2904"">#2904</a>)</li>; </ul>; <h3>Documentation</h3>; <ul>; <li>Update pylint config documentation (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2931"">#2931</a>)</li>; </ul>; <h3>Integrations</h3>; <ul>; <li>Move test to disable plugin in Vim/Neovim, which speeds up loading (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2896"">#2896</a>)</li>; </ul>;",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11696:4216,depend,dependabot,4216,https://hail.is,https://github.com/hail-is/hail/pull/11696,1,['depend'],['dependabot']
Integrability,"ump dessant/lock-threads from 3.0.0 to 4.0.1 (<a href=""https://redirect.github.com/certifi/python-certifi/issues/229"">#229</a>)</li>; <li><a href=""https://github.com/certifi/python-certifi/commit/44df761f4c09d19f32b3cc09208a739043a5e25b""><code>44df761</code></a> Hash pin Actions and enable dependabot (<a href=""https://redirect.github.com/certifi/python-certifi/issues/228"">#228</a>)</li>; <li>See full diff in <a href=""https://github.com/certifi/python-certifi/compare/2023.05.07...2023.07.22"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=certifi&package-manager=pip&previous-version=2023.5.7&new-version=2023.7.22)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13298:1692,depend,dependabot,1692,https://hail.is,https://github.com/hail-is/hail/pull/13298,6,['depend'],['dependabot']
Integrability,"ump the hardcoded version to v3.8.2.post0.dev0</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/99c8d0d7706153970bc1cbace8bdf4ab137783c7""><code>99c8d0d</code></a> Brush up the changelog wording for v3.8.2</li>; <li><a href=""https://github.com/aio-libs/aiohttp/commit/a56b31cae75506e0640808567372359a159b1f96""><code>a56b31c</code></a> Add a note about Python 3.6 in the changelog</li>; <li>Additional commits viewable in <a href=""https://github.com/aio-libs/aiohttp/compare/v3.8.1...v3.8.3"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiohttp&package-manager=pip&previous-version=3.8.1&new-version=3.8.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12296:7966,depend,dependabot,7966,https://hail.is,https://github.com/hail-is/hail/pull/12296,1,['depend'],['dependabot']
Integrability,"ump version to 1.48.1-pre1 (on v1.48.x branch) (<a href=""https://github-redirect.dependabot.com/grpc/grpc/issues/30627"">#30627</a>)</li>; <li><a href=""https://github.com/grpc/grpc/commit/a8065cb662ca35f2b57efd636b1ac193d327ed74""><code>a8065cb</code></a> Backport EventEngine Forkables (<a href=""https://github-redirect.dependabot.com/grpc/grpc/issues/30605"">#30605</a>)</li>; <li><a href=""https://github.com/grpc/grpc/commit/796a8ddcfe629c1ef7beae117efce2004886ecd9""><code>796a8dd</code></a> xDS interop: add missing image tagging to the buildscripts (<a href=""https://github-redirect.dependabot.com/grpc/grpc/issues/30520"">#30520</a>) (<a href=""https://github-redirect.dependabot.com/grpc/grpc/issues/30529"">#30529</a>)</li>; <li><a href=""https://github.com/grpc/grpc/commit/0d20b3fac16f901bd19f116b71cfec538bb57160""><code>0d20b3f</code></a> subchannel list: fix ubsan error (<a href=""https://github-redirect.dependabot.com/grpc/grpc/issues/30393"">#30393</a>) (<a href=""https://github-redirect.dependabot.com/grpc/grpc/issues/30412"">#30412</a>)</li>; <li><a href=""https://github.com/grpc/grpc/commit/9479089ac8cb99e66a71eab687b06ce220a94838""><code>9479089</code></a> xds interop: choose correct cluster in grpc_xds_k8s_lb_python.sh (1.48.x back...</li>; <li><a href=""https://github.com/grpc/grpc/commit/d2054ec6c6e8abcecf0e24b0b4ee75035d80c3cc""><code>d2054ec</code></a> Bump version to 1.48.0 (on v1.48.x branch) (<a href=""https://github-redirect.dependabot.com/grpc/grpc/issues/30326"">#30326</a>)</li>; <li><a href=""https://github.com/grpc/grpc/commit/4c51abf12053e3c43a62059c693322ea992b35ce""><code>4c51abf</code></a> Bump version to 1.48.0-pre1 (on v1.48.x branch) (<a href=""https://github-redirect.dependabot.com/grpc/grpc/issues/30194"">#30194</a>)</li>; <li><a href=""https://github.com/grpc/grpc/commit/46bd0be2c99aa8228ec5d93d8a27f20ab0c61956""><code>46bd0be</code></a> Bump core version to 26.0.0 for upcoming release (<a href=""https://github-redirect.dependabot.com/grpc/grpc/issues/30163"">#30",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12201:4951,depend,dependabot,4951,https://hail.is,https://github.com/hail-is/hail/pull/12201,1,['depend'],['dependabot']
Integrability,"umps org.ow2.asm:asm-util from 7.3.1 to 9.5. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=org.ow2.asm:asm-util&package-manager=gradle&previous-version=7.3.1&new-version=9.5)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13636:1348,depend,dependabot,1348,https://hail.is,https://github.com/hail-is/hail/pull/13636,11,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability,"umpy/numpy/commit/d93b14e3d7abaa1d837825e51671f817788e120f""><code>d93b14e</code></a> Update test_public_api.py</li>; <li><a href=""https://github.com/numpy/numpy/commit/7662c0789cc6a70d5ad4d950ee2e95f3afef7df6""><code>7662c07</code></a> Update <strong>init</strong>.py</li>; <li><a href=""https://github.com/numpy/numpy/commit/311ab52488a7d096ac3bc4c2de0fdae17ecd13ef""><code>311ab52</code></a> Update armccompiler.py</li>; <li>Additional commits viewable in <a href=""https://github.com/numpy/numpy/compare/v1.21.6...v1.22.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=numpy&package-manager=pip&previous-version=1.21.6&new-version=1.22.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). You can trigger a rebase of this PR by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12809:5395,depend,dependabot-automerge-start,5395,https://hail.is,https://github.com/hail-is/hail/pull/12809,2,['depend'],"['dependabot-automerge-end', 'dependabot-automerge-start']"
Integrability,"umpy/numpy/issues/22391"">#22391</a> from charris/backport-22372</li>; <li><a href=""https://github.com/numpy/numpy/commit/fa16a0ca51ef0654f541fcf6fa8d30f0f6263a94""><code>fa16a0c</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/numpy/numpy/issues/22390"">#22390</a> from charris/backport-22360</li>; <li>Additional commits viewable in <a href=""https://github.com/numpy/numpy/compare/v1.21.6...v1.23.4"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=numpy&package-manager=pip&previous-version=1.21.6&new-version=1.23.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12441:6364,depend,dependabot-automerge-start,6364,https://hail.is,https://github.com/hail-is/hail/pull/12441,2,['depend'],"['dependabot-automerge-end', 'dependabot-automerge-start']"
Integrability,"umpy/numpy/issues/22594"">#22594</a> from charris/backport-22450</li>; <li><a href=""https://github.com/numpy/numpy/commit/8cededdf4eeebd4f1985bd74c11fbf44f367937f""><code>8cededd</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/numpy/numpy/issues/22592"">#22592</a> from charris/backport-22393</li>; <li>Additional commits viewable in <a href=""https://github.com/numpy/numpy/compare/v1.21.6...v1.23.5"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=numpy&package-manager=pip&previous-version=1.21.6&new-version=1.23.5)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12515:6761,depend,dependabot-automerge-start,6761,https://hail.is,https://github.com/hail-is/hail/pull/12515,2,['depend'],"['dependabot-automerge-end', 'dependabot-automerge-start']"
Integrability,"umstances are so unlikely that probably nobody would ever hit it. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/104601"">kubernetes/kubernetes#104601</a>, <a href=""https://github.com/thockin""><code>@​thockin</code></a>)</li>; <li>Added a feature gate <code>StatefulSetAutoDeletePVC</code>, which allows PVCs automatically created for StatefulSet pods to be automatically deleted. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/99728"">kubernetes/kubernetes#99728</a>, <a href=""https://github.com/mattcary""><code>@​mattcary</code></a>)</li>; <li>Client-go impersonation config can specify a UID to pass impersonated uid information through in requests. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/104483"">kubernetes/kubernetes#104483</a>, <a href=""https://github.com/margocrawf""><code>@​margocrawf</code></a>)</li>; <li>Create HPA v2 from v2beta2 with some fields changed. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/102534"">kubernetes/kubernetes#102534</a>, <a href=""https://github.com/wangyysde""><code>@​wangyysde</code></a>) [SIG API Machinery, Apps, Auth, Autoscaling and Testing]</li>; <li>Ephemeral containers graduated to beta and are now available by default. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/105405"">kubernetes/kubernetes#105405</a>, <a href=""https://github.com/verb""><code>@​verb</code></a>)</li>; <li>Fix kube-proxy regression on UDP services because the logic to detect stale connections was not considering if the endpoint was ready. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/106163"">kubernetes/kubernetes#106163</a>, <a href=""https://github.com/aojea""><code>@​aojea</code></a>) [SIG API Machinery, Apps, Architecture, Auth, Autoscaling, CLI, Cloud Provider, Contributor Experience, Instrumentation, Network, Node, Release, Scalability, Scheduling, Storage, Testing and Windows]</li>; <li>If",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11957:3204,depend,dependabot,3204,https://hail.is,https://github.com/hail-is/hail/pull/11957,1,['depend'],['dependabot']
Integrability,"und behavior</li>; <li><a href=""https://github.com/scipy/scipy/commit/7ec501097b3a22569025bf0d62cb2d89474c812b""><code>7ec5010</code></a> BUG: fix handling for <code>factorial(..., exact=False)</code> for 0-dim array inputs (#...</li>; <li><a href=""https://github.com/scipy/scipy/commit/90415c6890365585576e96e42c5aeba253da0091""><code>90415c6</code></a> BUG: Fix work array construction for various weight shapes. (<a href=""https://redirect.github.com/scipy/scipy/issues/18741"">#18741</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/scipy/scipy/compare/v1.9.3...v1.11.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=scipy&package-manager=pip&previous-version=1.9.3&new-version=1.11.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). You can trigger a rebase of this PR by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13228:4922,depend,dependabot,4922,https://hail.is,https://github.com/hail-is/hail/pull/13228,1,['depend'],['dependabot']
Integrability,unts.scala:73); 	at is.hail.rvd.RVD.head(RVD.scala:526); 	at is.hail.expr.ir.TableSubset.execute(TableIR.scala:1380); 	at is.hail.expr.ir.TableSubset.execute$(TableIR.scala:1377); 	at is.hail.expr.ir.TableHead.execute(TableIR.scala:1386); 	at is.hail.expr.ir.TableMapRows.execute(TableIR.scala:1905); 	at is.hail.expr.ir.Interpret$.run(Interpret.scala:784); 	at is.hail.expr.ir.Interpret$.alreadyLowered(Interpret.scala:56); 	at is.hail.expr.ir.InterpretNonCompilable$.interpretAndCoerce$1(InterpretNonCompilable.scala:16); 	at is.hail.expr.ir.InterpretNonCompilable$.rewrite$1(InterpretNonCompilable.scala:53); 	at is.hail.expr.ir.InterpretNonCompilable$.$anonfun$apply$1(InterpretNonCompilable.scala:25); 	at scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286); 	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36); 	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33); 	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:38); 	at scala.collection.TraversableLike.map(TraversableLike.scala:286); 	at scala.collection.TraversableLike.map$(TraversableLike.scala:279); 	at scala.collection.AbstractTraversable.map(Traversable.scala:108); 	at is.hail.expr.ir.InterpretNonCompilable$.rewriteChildren$1(InterpretNonCompilable.scala:25); 	at is.hail.expr.ir.InterpretNonCompilable$.rewrite$1(InterpretNonCompilable.scala:54); 	at is.hail.expr.ir.InterpretNonCompilable$.apply(InterpretNonCompilable.scala:58); 	at is.hail.expr.ir.lowering.InterpretNonCompilablePass$.transform(LoweringPass.scala:67); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:15); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:15); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:13); 	at is.hail.expr.ir.lowering.LoweringPass.appl,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/10682:10612,Wrap,WrappedArray,10612,https://hail.is,https://github.com/hail-is/hail/issues/10682,1,['Wrap'],['WrappedArray']
Integrability,"unused-export-let</code> warning inside <code>&lt;script context=&quot;module&quot;&gt;</code> blocks (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7055"">#7055</a>)</li>; <li>Do not collapse whitespace-only CSS vars (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7152"">#7152</a>)</li>; <li>Add <code>aria-description</code> to the list of allowed ARIA attributes (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7301"">#7301</a>)</li>; <li>Fix attribute escaping during SSR (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7327"">#7327</a>)</li>; <li>Prevent <code>.innerHTML</code> optimization from being used when <code>style:</code> directive is present (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7386"">#7386</a>)</li>; </ul>; <h2>3.46.4</h2>; <ul>; <li>Avoid <code>maximum call stack size exceeded</code> errors on large components (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/4694"">#4694</a>)</li>; <li>Preserve leading space with <code>preserveWhitespace: true</code> (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/4731"">#4731</a>)</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/sveltejs/svelte/commit/52153dbce0237f0c36e4ff36377398d7f95276ef""><code>52153db</code></a> -&gt; v3.49.0</li>; <li><a href=""https://github.com/sveltejs/svelte/commit/3798808e7484b7eeee6acb2860c45bb2e59d84bd""><code>3798808</code></a> update changelog</li>; <li><a href=""https://github.com/sveltejs/svelte/commit/0fa0a38d5168a1767843fdb0a43c00aa30b8670f""><code>0fa0a38</code></a> [fix] export CompileOptions (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7658"">#7658</a>)</li>; <li><a href=""https://github.com/sveltejs/svelte/commit/a3ecb44b5346dbf116c5bec5dcf47cd7f459784d""><code>a3ecb44</code><",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12032:5944,depend,dependabot,5944,https://hail.is,https://github.com/hail-is/hail/pull/12032,3,['depend'],['dependabot']
Integrability,"uote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pytest-dev/pytest-xdist/commit/13f39349c6950a881c1fe4fcd5984af2e8b7c220""><code>13f3934</code></a> Remove unnecessary skip from test_logfinish_hook as we require pytest&gt;=6.2</li>; <li><a href=""https://github.com/pytest-dev/pytest-xdist/commit/c76d5622f17135e892965d742377870eb9b07933""><code>c76d562</code></a> Skip test_warning_captured_deprecated_in_pytest_6 in pytest&gt;=7.1</li>; <li><a href=""https://github.com/pytest-dev/pytest-xdist/commit/5f78c7155e66ab73bdc7631c4ac6bfe684b82500""><code>5f78c71</code></a> Fix CHANGELOG header</li>; <li><a href=""https://github.com/pytest-dev/pytest-xdist/commit/c8bbc03e49d5a53b5da808c7328e8f3ad6ed2d7e""><code>c8bbc03</code></a> Release 2.5.0</li>; <li><a href=""https://github.com/pytest-dev/pytest-xdist/commit/8dbf3677dc7cc26ada33cf8a27d7ac51a9be467b""><code>8dbf367</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-xdist/issues/738"">#738</a> from pytest-dev/pre-commit-ci-update-config</li>; <li><a href=""https://github.com/pytest-dev/pytest-xdist/commit/a25c14bef59ad728e39cabc64f71190aaad73b0a""><code>a25c14b</code></a> [pre-commit.ci] pre-commit autoupdate</li>; <li><a href=""https://github.com/pytest-dev/pytest-xdist/commit/110c114025202d11570737be823de158d1bb8d99""><code>110c114</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-xdist/issues/734"">#734</a> from nicoddemus/revamp-readme</li>; <li><a href=""https://github.com/pytest-dev/pytest-xdist/commit/83bdbf4b95c914a889d1faa8fba8d506bcc2f8c7""><code>83bdbf4</code></a> Revamp README</li>; <li><a href=""https://github.com/pytest-dev/pytest-xdist/commit/630c1eb6f2c31dcb4c38c75bb62f868237cdde94""><code>630c1eb</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-xdist/issues/733"">#733</a> from baekdohyeop/feature-loadgroup</li>; <li><a href",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11491:4429,depend,dependabot,4429,https://hail.is,https://github.com/hail-is/hail/pull/11491,2,['depend'],['dependabot']
Integrability,"uote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/sveltejs/svelte/commit/52153dbce0237f0c36e4ff36377398d7f95276ef""><code>52153db</code></a> -&gt; v3.49.0</li>; <li><a href=""https://github.com/sveltejs/svelte/commit/3798808e7484b7eeee6acb2860c45bb2e59d84bd""><code>3798808</code></a> update changelog</li>; <li><a href=""https://github.com/sveltejs/svelte/commit/0fa0a38d5168a1767843fdb0a43c00aa30b8670f""><code>0fa0a38</code></a> [fix] export CompileOptions (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7658"">#7658</a>)</li>; <li><a href=""https://github.com/sveltejs/svelte/commit/a3ecb44b5346dbf116c5bec5dcf47cd7f459784d""><code>a3ecb44</code></a> update changelog</li>; <li><a href=""https://github.com/sveltejs/svelte/commit/7e1691cd62df0593882480d00eb7e9a7616bb029""><code>7e1691c</code></a> [fix] support <a href=""https://github.com/layer""><code>@​layer</code></a> (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7514"">#7514</a>)</li>; <li><a href=""https://github.com/sveltejs/svelte/commit/4583b170842208bcafcbb095221c8ac12689f739""><code>4583b17</code></a> Update CHANGELOG.md</li>; <li><a href=""https://github.com/sveltejs/svelte/commit/02f60fbebf7cdb036472d1aec8dc9d9f8215cd7a""><code>02f60fb</code></a> [fix]destroy empty component (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7492"">#7492</a>)</li>; <li><a href=""https://github.com/sveltejs/svelte/commit/31e5f8b5de24e2e058cb1a70467c0092e422ee5d""><code>31e5f8b</code></a> [docs] &quot;What's new in Svelte&quot; July newsletter (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7637"">#7637</a>)</li>; <li><a href=""https://github.com/sveltejs/svelte/commit/6f575715073f4a1eb1abdd7a2d22a75ae6017cf7""><code>6f57571</code></a> [feat] add convenience types ComponentType and ComponentProps (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/6770"">#6770</a>)</li>;",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12032:7207,depend,dependabot,7207,https://hail.is,https://github.com/hail-is/hail/pull/12032,3,['depend'],['dependabot']
Integrability,"update by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/678"">jpadilla/pyjwt#678</a></li>; <li>Prefer headers['alg'] to algorithm parameter in encode(). by <a href=""https://github.com/dajiaji""><code>@​dajiaji</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/673"">jpadilla/pyjwt#673</a></li>; <li>DOC: Clarify RSA encoding and decoding depend on the cryptography package by <a href=""https://github.com/TPXP""><code>@​TPXP</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/664"">jpadilla/pyjwt#664</a></li>; <li>Make typ optional by <a href=""https://github.com/dajiaji""><code>@​dajiaji</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/644"">jpadilla/pyjwt#644</a></li>; <li>Remove arbitrary kwargs. by <a href=""https://github.com/dajiaji""><code>@​dajiaji</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/657"">jpadilla/pyjwt#657</a></li>; <li>Assume JWK is valid for signing if &quot;use&quot; is omitted by <a href=""https://github.com/Klavionik""><code>@​Klavionik</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/668"">jpadilla/pyjwt#668</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/684"">jpadilla/pyjwt#684</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/686"">jpadilla/pyjwt#686</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/689"">jpadilla/pyjwt#689</a></li>; <li>Remove upper ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11457:4173,depend,dependabot,4173,https://hail.is,https://github.com/hail-is/hail/pull/11457,1,['depend'],['dependabot']
Integrability,upgrade gradle; change dependencies around,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6248:23,depend,dependencies,23,https://hail.is,https://github.com/hail-is/hail/pull/6248,1,['depend'],['dependencies']
Integrability,"upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091621](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091621) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091622](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091622) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI1M2U3Mjk0MS01YmVjLTQ2MjYtYTY2Ny0wNzIxYjUwNjZlZjYiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjUzZTcyOTQxLTViZWMtNDYyNi1hNjY3LTA3MjFiNTA2NmVmNiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14043:2115,depend,dependency,2115,https://hail.is,https://github.com/hail-is/hail/pull/14043,2,['depend'],"['dependencies', 'dependency']"
Integrability,"upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091621](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091621) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091622](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091622) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI3M2M5M2ZlNi0yOWM3LTQ4MWMtYTBiYy1lMzFkYzc3N2QyODEiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjczYzkzZmU2LTI5YzctNDgxYy1hMGJjLWUzMWRjNzc3ZDI4MSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14041:2000,depend,dependency,2000,https://hail.is,https://github.com/hail-is/hail/pull/14041,2,['depend'],"['dependencies', 'dependency']"
Integrability,"upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091621](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091621) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091622](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091622) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI3ZTZiMDk2ZC0xYzc5LTQ2ZjctYjY5Ni0yNjFlM2QzYzU2ZmMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjdlNmIwOTZkLTFjNzktNDZmNy1iNjk2LTI2MWUzZDNjNTZmYyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/b7c31419-ec34-40f1-8bc6-ad8303fb329b?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/b7c31419-ec34-40f1-8bc6-ad8303fb329b?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14036:1742,depend,dependency,1742,https://hail.is,https://github.com/hail-is/hail/pull/14036,2,['depend'],"['dependencies', 'dependency']"
Integrability,"upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091621](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091621) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091622](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091622) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI4ZmFmZmYwNi1jOTI2LTQ5NjEtOTI4MC1iNGI0OTczNTg2MWMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjhmYWZmZjA2LWM5MjYtNDk2MS05MjgwLWI0YjQ5NzM1ODYxYyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14038:2008,depend,dependency,2008,https://hail.is,https://github.com/hail-is/hail/pull/14038,2,['depend'],"['dependencies', 'dependency']"
Integrability,"upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091621](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091621) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091622](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091622) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI5NGM3N2YwYy0xN2JkLTRkMzQtYmJhOS1iNzBiNmVhMDllMjYiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6Ijk0Yzc3ZjBjLTE3YmQtNGQzNC1iYmE5LWI3MGI2ZWEwOWUyNiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/0ba777e1-bc27-41cc-aefa-0ed1a253829e?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/0ba777e1-bc27-41cc-aefa-0ed1a253829e?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14039:1935,depend,dependency,1935,https://hail.is,https://github.com/hail-is/hail/pull/14039,2,['depend'],"['dependencies', 'dependency']"
Integrability,"upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091621](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091621) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091622](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091622) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIxZjc1YjVmNi00MjFkLTQyN2YtYTk3OC0yNTBhNTgyNTI4YmUiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjFmNzViNWY2LTQyMWQtNDI3Zi1hOTc4LTI1MGE1ODI1MjhiZSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/cbac91bd-aa95-4900-9a06-97404b268d6e?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/cbac91bd-aa95-4900-9a06-97404b268d6e?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14035:1929,depend,dependency,1929,https://hail.is,https://github.com/hail-is/hail/pull/14035,2,['depend'],"['dependencies', 'dependency']"
Integrability,"upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091621](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091621) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091622](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091622) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIzMjkzZGUwOS01NmJjLTRkNWEtYWNkZC1iMzdlMDBkMzkwOTgiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjMyOTNkZTA5LTU2YmMtNGQ1YS1hY2RkLWIzN2UwMGQzOTA5OCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/b72ce54d-5de3-48e5-a1d4-6f8967681a12?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14034:1883,depend,dependency,1883,https://hail.is,https://github.com/hail-is/hail/pull/14034,2,['depend'],"['dependencies', 'dependency']"
Integrability,"upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091621](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091621) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091622](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091622) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIzODVlZjFmNi0zYjJhLTRjZTEtOTA5MS0xMWM1YzU3NDY0OTIiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjM4NWVmMWY2LTNiMmEtNGNlMS05MDkxLTExYzVjNTc0NjQ5MiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/92d13c88-936f-40d3-b692-29e637c1a00c?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/92d13c88-936f-40d3-b692-29e637c1a00c?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14044:1860,depend,dependency,1860,https://hail.is,https://github.com/hail-is/hail/pull/14044,2,['depend'],"['dependencies', 'dependency']"
Integrability,"upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091621](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091621) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091622](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091622) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJhNGNiNTQzMi0zM2VmLTQ3ZmQtYmYzMy1lZGU2YzJlNDJiOTAiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImE0Y2I1NDMyLTMzZWYtNDdmZC1iZjMzLWVkZTZjMmU0MmI5MCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14042:2136,depend,dependency,2136,https://hail.is,https://github.com/hail-is/hail/pull/14042,2,['depend'],"['dependencies', 'dependency']"
Integrability,"upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091621](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091621) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091622](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091622) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJiOGQwNmE2Yi00MTg0LTRhMzAtOGMxYi0wYzNhZDVkZDk2OTQiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImI4ZDA2YTZiLTQxODQtNGEzMC04YzFiLTBjM2FkNWRkOTY5NCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/e7c92c7b-5282-49ea-940f-7a5797e2a45a?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/e7c92c7b-5282-49ea-940f-7a5797e2a45a?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14045:1744,depend,dependency,1744,https://hail.is,https://github.com/hail-is/hail/pull/14045,2,['depend'],"['dependencies', 'dependency']"
Integrability,"upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091621](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091621) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **663/1000** <br/> **Why?** Proof of Concept exploit, Recently disclosed, Has a fix available, CVSS 5.4 | Improper Input Validation <br/>[SNYK-PYTHON-AIOHTTP-6091622](https://snyk.io/vuln/SNYK-PYTHON-AIOHTTP-6091622) | `aiohttp:` <br> `3.8.6 -> 3.9.0` <br> | No | Proof of Concept . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJlNDEzMjhlZS0zNDg5LTQ3NDItYTc3YS01ZDZhNTQ1ZWE2ZjIiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImU0MTMyOGVlLTM0ODktNDc0Mi1hNzdhLTVkNmE1NDVlYTZmMiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/fdd23464-9a67-49b8-8d9c-08502282c5fb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/fdd23464-9a67-49b8-8d9c-08502282c5fb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14037:1869,depend,dependency,1869,https://hail.is,https://github.com/hail-is/hail/pull/14037,2,['depend'],"['dependencies', 'dependency']"
Integrability,"upport <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7234"">#7234</a> [<a href=""https://github.com/radarhere""><code>@​radarhere</code></a>]</li>; <li>Removed deleted file from codecov.yml and increased coverage threshold <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7232"">#7232</a> [<a href=""https://github.com/radarhere""><code>@​radarhere</code></a>]</li>; <li>Removed support for 32-bit <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7228"">#7228</a> [<a href=""https://github.com/radarhere""><code>@​radarhere</code></a>]</li>; <li>Use --config-settings instead of deprecated --global-option <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7171"">#7171</a> [<a href=""https://github.com/radarhere""><code>@​radarhere</code></a>]</li>; <li>Better C integer definitions <a href=""https://redirect.github.com/python-pillow/Pillow/issues/6645"">#6645</a> [<a href=""https://github.com/Yay295""><code>@​Yay295</code></a>]</li>; <li>Fixed finding dependencies on Cygwin <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7175"">#7175</a> [<a href=""https://github.com/radarhere""><code>@​radarhere</code></a>]</li>; <li>Improved checks in font_render <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7218"">#7218</a> [<a href=""https://github.com/radarhere""><code>@​radarhere</code></a>]</li>; <li>Change <code>grabclipboard()</code> to use PNG compression on macOS <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7219"">#7219</a> [<a href=""https://github.com/abey79""><code>@​abey79</code></a>]</li>; <li>Added PyPy 3.10 and removed PyPy 3.8 <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7216"">#7216</a> [<a href=""https://github.com/radarhere""><code>@​radarhere</code></a>]</li>; <li>Added in_place argument to ImageOps.exif_transpose() <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7092"">#7092</a> [<a href=""https://github.com/radarhere""><code>@​radarhere</cod",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13321:3094,depend,dependencies,3094,https://hail.is,https://github.com/hail-is/hail/pull/13321,1,['depend'],['dependencies']
Integrability,"upported because the command was deprecated since texinfo 6.8</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/2068"">#2068</a>: :confval:<code>intersphinx_disabled_reftypes</code> has changed default value; from an empty list to <code>['std:doc']</code> as avoid too surprising silent; intersphinx resolutions.; To migrate: either add an explicit inventory name to the references; intersphinx should resolve, or explicitly set the value of this configuration; variable to an empty list.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10197"">#10197</a>: html theme: Reduce <code>body_min_width</code> setting in basic theme to 360px</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/9999"">#9999</a>: LaTeX: separate terms from their definitions by a CR (refs: <a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/9985"">#9985</a>)</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10062"">#10062</a>: Change the default language to <code>'en'</code> if any language is not set in; <code>conf.py</code></li>; </ul>; <p>5.0.0 final</p>; <ul>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10474"">#10474</a>: :confval:<code>language</code> does not accept <code>None</code> as it value. The default; value of <code>language</code> becomes to <code>'en'</code> now.</li>; </ul>; <h2>Deprecated</h2>; <p>5.0.0 b1</p>; <ul>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10028"">#10028</a>: jQuery and underscore.js will no longer be automatically injected into; themes from Sphinx 6.0. If you develop a theme or extension that uses the; <code>jQuery</code>, <code>$</code>, or <code>$u</code> global objects, you need to update your; JavaScript or use the mitigation below.</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11871:3139,depend,dependabot,3139,https://hail.is,https://github.com/hail-is/hail/pull/11871,1,['depend'],['dependabot']
Integrability,"upported because the command was deprecated since texinfo 6.8</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/2068"">#2068</a>: :confval:<code>intersphinx_disabled_reftypes</code> has changed default value; from an empty list to <code>['std:doc']</code> as avoid too surprising silent; intersphinx resolutions.; To migrate: either add an explicit inventory name to the references; intersphinx should resolve, or explicitly set the value of this configuration; variable to an empty list.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10197"">#10197</a>: html theme: Reduce <code>body_min_width</code> setting in basic theme to 360px</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/9999"">#9999</a>: LaTeX: separate terms from their definitions by a CR (refs: <a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/9985"">#9985</a>)</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10062"">#10062</a>: Change the default language to <code>'en'</code> if any language is not set in; <code>conf.py</code></li>; </ul>; <p>5.0.0 final</p>; <ul>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10474"">#10474</a>: :confval:<code>language</code> does not accept <code>None</code> as it value. The default</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/8fe27991ba23268b17fad2e2fe2548074ad6cf26""><code>8fe2799</code></a> Bump to 5.0.1 final</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/ab58bbaed71293bf8f5738f386b853b17b4190eb""><code>ab58bba</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10502"">#10502</a> from AA-Turner/ifconfig-fix</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/c4458e3adb",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11885:3938,depend,dependabot,3938,https://hail.is,https://github.com/hail-is/hail/pull/11885,1,['depend'],['dependabot']
Integrability,"upyter/jupyter_client/commit/d27c8a497c6cbb1a232fbbe75cb1fd0f53faa9b0""><code>d27c8a4</code></a> [7.x] Handle Jupyter Core Warning (<a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/issues/875"">#875</a>)</li>; <li><a href=""https://github.com/jupyter/jupyter_client/commit/46f3f8c34f272629c45beba9884053680f213cfd""><code>46f3f8c</code></a> Clean up 7.x workflows (<a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/issues/865"">#865</a>)</li>; <li>See full diff in <a href=""https://github.com/jupyter/jupyter_client/compare/v7.4.4...v7.4.5"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=jupyter-client&package-manager=pip&previous-version=7.4.4&new-version=7.4.5)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12459:3744,Depend,Dependabot,3744,https://hail.is,https://github.com/hail-is/hail/pull/12459,1,['Depend'],['Dependabot']
Integrability,"upyter/jupyter_client/commit/d27c8a497c6cbb1a232fbbe75cb1fd0f53faa9b0""><code>d27c8a4</code></a> [7.x] Handle Jupyter Core Warning (<a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/issues/875"">#875</a>)</li>; <li><a href=""https://github.com/jupyter/jupyter_client/commit/46f3f8c34f272629c45beba9884053680f213cfd""><code>46f3f8c</code></a> Clean up 7.x workflows (<a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/issues/865"">#865</a>)</li>; <li>See full diff in <a href=""https://github.com/jupyter/jupyter_client/compare/v7.4.4...v7.4.6"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=jupyter-client&package-manager=pip&previous-version=7.4.4&new-version=7.4.6)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12467:5886,Depend,Dependabot,5886,https://hail.is,https://github.com/hail-is/hail/pull/12467,1,['Depend'],['Dependabot']
Integrability,"upyter/nbconvert/compare/6.5...7.0.0"">https://github.com/jupyter/nbconvert/compare/6.5...7.0.0</a></p>; <h2>7.0.0rc3</h2>; <h2>What's Changed</h2>; <ul>; <li>Pin mistune for now by <a href=""https://github.com/blink1073""><code>@​blink1073</code></a> in <a href=""https://github-redirect.dependabot.com/jupyter/nbconvert/pull/1808"">jupyter/nbconvert#1808</a></li>; </ul>; <p><strong>Full Changelog</strong>: <a href=""https://github.com/jupyter/nbconvert/compare/7.0.0rc2...7.0.0rc3"">https://github.com/jupyter/nbconvert/compare/7.0.0rc2...7.0.0rc3</a></p>; <h2>7.0.0rc2</h2>; <h2>What's Changed</h2>; <ul>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/jupyter/nbconvert/pull/1779"">jupyter/nbconvert#1779</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/jupyter/nbconvert/pull/1780"">jupyter/nbconvert#1780</a></li>; <li>switch from entrypoints to importlib-metadata by <a href=""https://github.com/konstin""><code>@​konstin</code></a> in <a href=""https://github-redirect.dependabot.com/jupyter/nbconvert/pull/1782"">jupyter/nbconvert#1782</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/jupyter/nbconvert/pull/1786"">jupyter/nbconvert#1786</a></li>; <li>Add recursive flag for glob notebook search by <a href=""https://github.com/paoloalba""><code>@​paoloalba</code></a> in <a href=""https://github-redirect.dependabot.com/jupyter/nbconvert/pull/1785"">jupyter/nbconvert#1785</a></li>; <li>Updates for sphinx 5.0 support by <a href=""https://github.com/blink1073""><code>@​blink1073</code></a> in <a href=""https://github-redirect.dependabot.com/jupyter/nbconvert/pull/1788"">jupyter/nbconvert#1788</a></li>; <li>Fixed uniq",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12126:6793,depend,dependabot,6793,https://hail.is,https://github.com/hail-is/hail/pull/12126,1,['depend'],['dependabot']
Integrability,"upyter_client/issues/919"">#919</a>)</li>; <li><a href=""https://github.com/jupyter/jupyter_client/commit/0ab0feb42fcdfe1a2528f630ca269c9fda6a2675""><code>0ab0feb</code></a> Reflect current protocol version in documentation (<a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/issues/918"">#918</a>)</li>; <li><a href=""https://github.com/jupyter/jupyter_client/commit/eded331c9f292a1838602414b6c05928917d13e8""><code>eded331</code></a> Add full api docs (<a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/issues/908"">#908</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/jupyter/jupyter_client/compare/v7.4.8...v8.0.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=jupyter-client&package-manager=pip&previous-version=7.4.8&new-version=8.0.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12656:9075,depend,dependabot-security-updates,9075,https://hail.is,https://github.com/hail-is/hail/pull/12656,1,['depend'],['dependabot-security-updates']
Integrability,"urced from <a href=""https://github.com/cbeust/testng/releases"">org.testng:testng's releases</a>.</em></p>; <blockquote>; <h2>TestNG v7.7.1</h2>; <h2>What's Changed</h2>; <ul>; <li>Streamline overloaded assertion methods for Groovy by <a href=""https://github.com/krmahadevan""><code>@​krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2858"">cbeust/testng#2858</a></li>; </ul>; <p><strong>Full Changelog</strong>: <a href=""https://github.com/cbeust/testng/compare/7.7.0...7.7.1"">https://github.com/cbeust/testng/compare/7.7.0...7.7.1</a></p>; <h2>TestNG v7.7.0</h2>; <h2>What's Changed</h2>; <ul>; <li>Replace FindBugs by SpotBugs by <a href=""https://github.com/gruenich""><code>@​gruenich</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2781"">cbeust/testng#2781</a></li>; <li>Gradle: Drop forUseAtConfigurationTime() by <a href=""https://github.com/gruenich""><code>@​gruenich</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2783"">cbeust/testng#2783</a></li>; <li>Added ability to provide custom message to assertThrows\expectThrows methods by <a href=""https://github.com/anatolyuzhakov""><code>@​anatolyuzhakov</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2793"">cbeust/testng#2793</a></li>; <li>Fix issue 2801 - Only resolve hostname once by <a href=""https://github.com/spkrka""><code>@​spkrka</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2802"">cbeust/testng#2802</a></li>; <li>[SECURITY] Fix Zip Slip Vulnerability; by <a href=""https://github.com/JLLeitschuh""><code>@​JLLeitschuh</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2806"">cbeust/testng#2806</a></li>; <li>GITHUB-2807 - Failsafe buildStackTrace by <a href=""https://github.com/seregamorph""><code>@​seregamorph</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2808"">cbeust/testng#2808</a></li>; <li>Pr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12665:1132,depend,dependabot,1132,https://hail.is,https://github.com/hail-is/hail/pull/12665,1,['depend'],['dependabot']
Integrability,"ure storage. Basic summary of the changes:; 	- Update `AzureAsyncFS` url parsing function to look for and separate out a SAS-token-like query string. Note: made fairly specific to SAS tokens - generic detection of query string syntax interferes with glob support and '?' characters in file names; 	- Added `generate_sas_token` convenience function to `AzureAsyncFS`. Adds new `azure-mgmt-storage` package requirement.; 	- Updated `AzureAsyncFS` to use `(account, credential)` tuple as internal `BlobServiceClient` cache key; 	- Updated `AzureAsyncFSURL` and `AzureFileListEntry` to track the token separately from the name, and extend the base classes to allow returning url with or without a token ; 	- Update `RouterFS.ls` function and associated `listfiles` function to allow for trailing query strings during path traversal ; 	- Change to existing behavior: `LocalAsyncFSURL.__str__`no longer returns 'file:' prefix. Done to make `str()` output be appropriate for input to `fs` functions across all subclasses; 	- Updated `inter_cloud/test_fs.py` to generically use query-string-friendly file path building functions; - Updated InputResource to not include the SAS token as part of the destination file name . `test_fs.py` has been updated to respect the new model, where it is no longer safe to extend URLs by just appending new segments with + ""/"" because there may be a query string. But actually running those tests for the SAS case will require some new test variables to allow the test code to generate SAS tokens (`build.yaml/test_hail_python_fs`): ; ```; export HAIL_TEST_AZURE_ACCOUNT=hailtest; export HAIL_TEST_AZURE_CONTAINER=hail-test-4nxei; # Required for SAS testing on Azure; export HAIL_TEST_AZURE_RESGRP=hailms02; export HAIL_TEST_AZURE_SUBID=12ab51c6-da79-4a99-8dec-3d2decc97343; ```; So the SAS case is disabled for now (`test_fs.py`):; ```; @pytest.fixture(params=['file', 'gs', 's3', 'hail-az', 'router/file', 'router/gs', 'router/s3', 'router/hail-az']) # 'sas/hail-az'; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12877:2036,rout,router,2036,https://hail.is,https://github.com/hail-is/hail/pull/12877,4,['rout'],['router']
Integrability,"ure-sdk-for-python/commit/7b9490a5dec1a3979d1837b5eabbc9d025d60cde""><code>7b9490a</code></a> Increment version for identity releases (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/22968"">#22968</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/e7e9a75a355bc4800e129f6a471ba3561f6257ab""><code>e7e9a75</code></a> cleanup changelog (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/22965"">#22965</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/0f302dc6c299df2ee637457c8f165c7bdb4ec2af""><code>0f302dc</code></a> added ClientAssertionCredential and resource_id support (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/22887"">#22887</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/5b17097d555d32df51e58b75ee12a48a5b60df88""><code>5b17097</code></a> add validate_authority support (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/22786"">#22786</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/9acb1882379dab5e910e2a5e3ef6c4a6ac08aadf""><code>9acb188</code></a> fix cspell issues (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/22774"">#22774</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/a497e5aba391075ebbbd42c2df4937c2d11185a4""><code>a497e5a</code></a> rename troubleshooting (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/22771"">#22771</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/9791fb5bc4cb6001768e6e1fb986b8d8f8326c43""><code>9791fb5</code></a> [core] add error body to HttpResponseError str (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/22302"">#22302</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/772054c9cf24e860cf08563ac33caab50e904dd5""><code>772054c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11493:3562,depend,dependabot,3562,https://hail.is,https://github.com/hail-is/hail/pull/11493,2,['depend'],['dependabot']
Integrability,"ure/azure-sdk-for-python/commit/a497e5aba391075ebbbd42c2df4937c2d11185a4""><code>a497e5a</code></a> rename troubleshooting (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/22771"">#22771</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/9791fb5bc4cb6001768e6e1fb986b8d8f8326c43""><code>9791fb5</code></a> [core] add error body to HttpResponseError str (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/22302"">#22302</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/772054c9cf24e860cf08563ac33caab50e904dd5""><code>772054c</code></a> drop py27 support (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/22531"">#22531</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/Azure/azure-sdk-for-python/compare/azure-identity_1.6.0...azure-identity_1.8.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=azure-identity&package-manager=pip&previous-version=1.6.0&new-version=1.8.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel me",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11493:4902,Depend,Dependabot,4902,https://hail.is,https://github.com/hail-is/hail/pull/11493,4,"['Depend', 'depend']","['Dependabot', 'dependabot-badges']"
Integrability,"ure_medians': dict<str, struct {; variant_type: str, ; n_alt_alleles: int32, ; qd: float64, ; pab_max: float64, ; info_MQRankSum: float64, ; info_SOR: float64, ; info_InbreedingCoeff: float64, ; info_ReadPosRankSum: float64, ; info_FS: float64, ; info_QD: float64, ; info_MQ: float64, ; info_DP: int32; }> ; 'test_intervals': array<interval<locus<GRCh37>>> ; ----------------------------------------; Row fields:; 'locus': locus<GRCh37> ; 'alleles': array<str> ; 'variant_type': str ; 'allele_type': str ; 'n_alt_alleles': int32 ; 'was_mixed': bool ; 'has_star': bool ; 'qd': float64 ; 'pab_max': float64 ; 'info_MQRankSum': float64 ; 'info_SOR': float64 ; 'info_InbreedingCoeff': float64 ; 'info_ReadPosRankSum': float64 ; 'info_FS': float64 ; 'info_QD': float64 ; 'info_MQ': float64 ; 'info_DP': int32 ; 'transmitted_singleton': bool ; 'fail_hard_filters': bool ; 'info_POSITIVE_TRAIN_SITE': bool ; 'info_NEGATIVE_TRAIN_SITE': bool ; 'omni': bool ; 'mills': bool ; 'feature_imputed': struct {; n_alt_alleles: bool, ; qd: bool, ; pab_max: bool, ; info_MQRankSum: bool, ; info_SOR: bool, ; info_InbreedingCoeff: bool, ; info_ReadPosRankSum: bool, ; info_FS: bool, ; info_QD: bool, ; info_MQ: bool, ; info_DP: bool; } ; 'tp': bool; ----------------------------------------; Key: ['locus', 'alleles']; ----------------------------------------; ```. ### What went wrong (all error messages here, including the full java stack trace):. When run on our data with 30023341 rows where `tp` = `True`, `rand_bool` seems to be run twice as it only returns 4.2M rows where `tp` = `True`, `fp` = `False` and `train_expr` = `True` instead of 11M. If the expression is split as follows, I get the expected 11M rows:; ```; ht = ht.annotate(**{train_col: hl.cond(hl.or_else(ht[fp_col], False), hl.or_else(~ht[tp_col], True), ht[tp_col])}); train_expr = hl.cond(ht[tp_col] & hl.or_else(~ht[fp_col], True), hl.rand_bool(prob_tp), ht[train_col]); ht = ht.annotate(**{label_col: label_expr,; train_col: train_expr}); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3969:2007,message,messages,2007,https://hail.is,https://github.com/hail-is/hail/issues/3969,1,['message'],['messages']
Integrability,"urllib3/commit/b8c5d457fc42821b951ea58bec4ad685a0183c02""><code>b8c5d45</code></a> [1.26] Deprecate HTTPResponse.getheaders() and .getheader() methods</li>; <li><a href=""https://github.com/urllib3/urllib3/commit/8b8e4b5a148d0eb706daf5ac48b4423b434495f5""><code>8b8e4b5</code></a> Temporary fix for SLSA generator</li>; <li><a href=""https://github.com/urllib3/urllib3/commit/cc9b0dc10eaf83b1242d710222525edd73555b6d""><code>cc9b0dc</code></a> [1.26] Fix logo URL in README</li>; <li><a href=""https://github.com/urllib3/urllib3/commit/eb47444a9dfaa045cc4753e4d77c57fbdccaa619""><code>eb47444</code></a> [1.26] Fix CI by switching to macOS 11</li>; <li><a href=""https://github.com/urllib3/urllib3/commit/34d7348bb96eca390c2115aeeee31d1147830844""><code>34d7348</code></a> Remove &quot;&lt;4&quot; upper bound from python_requires</li>; <li>See full diff in <a href=""https://github.com/urllib3/urllib3/compare/1.26.12...1.26.13"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=urllib3&package-manager=pip&previous-version=1.26.12&new-version=1.26.13)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12506:3306,Depend,Dependabot,3306,https://hail.is,https://github.com/hail-is/hail/pull/12506,2,"['Depend', 'depend']","['Dependabot', 'dependabot-badges']"
Integrability,"us"": 200, ""response_size"": 158, ""request_header"": {""Referer"": ""-"", ""User-Agent"": ""Python/3.6 aiohttp/3.5.4""}}; {""levelname"": ""INFO"", ""asctime"": ""2019-07-11 14:19:34,967"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""update_job_with_pod:1145"", ""message"": ""update job (9, 1, 'main') with pod batch-9-job-1-c8b9b2""}; {""levelname"": ""INFO"", ""asctime"": ""2019-07-11 14:19:34,969"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""set_state:501"", ""message"": ""job (9, 1, 'main') changed state: Ready -> Cancelled""}; {""levelname"": ""INFO"", ""asctime"": ""2019-07-11 14:19:34,974"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""_delete_pvc:251"", ""message"": ""deleting persistent volume claim batch-9-job-1-c8b9b2""}; {""levelname"": ""INFO"", ""asctime"": ""2019-07-11 14:19:34,976"", ""filename"": ""batch.py"", ""funcNameAndLine"": ""update_job_with_pod:1145"", ""message"": ""update job (9, 1, 'main') with pod batch-9-job-1-c8b9b2""}; {""levelname"": ""INFO"", ""asctime"": ""2019-07-11 14:19:34,977"", ""filename"": ""web_log.py"", ""funcNameAndLine"": ""log:233"", ""message"": ""10.32.4.199 [11/Jul/2019:14:19:34 +0000] \""GET /api/v1alpha/batches/9 HTTP/1.1\"" 200 279 \""-\"" \""Python/3.6 aiohttp/3.5.4\"""", ""remote_address"": ""10.32.4.199"", ""request_start_time"": ""[11/Jul/2019:14:19:34 +0000]"", ""first_request_line"": ""GET /api/v1alpha/batches/9 HTTP/1.1"", ""response_status"": 200, ""response_size"": 279, ""request_header"": {""Referer"": ""-"", ""User-Agent"": ""Python/3.6 aiohttp/3.5.4""}}; {""levelname"": ""INFO"", ""asctime"": ""2019-07-11 14:19:34,985"", ""filename"": ""web_log.py"", ""funcNameAndLine"": ""log:233"", ""message"": ""10.32.4.199 [11/Jul/2019:14:19:34 +0000] \""GET /api/v1alpha/batches/9 HTTP/1.1\"" 200 279 \""-\"" \""Python/3.6 aiohttp/3.5.4\"""", ""remote_address"": ""10.32.4.199"", ""request_start_time"": ""[11/Jul/2019:14:19:34 +0000]"", ""first_request_line"": ""GET /api/v1alpha/batches/9 HTTP/1.1"", ""response_status"": 200, ""response_size"": 279, ""request_header"": {""Referer"": ""-"", ""User-Agent"": ""Python/3.6 aiohttp/3.5.4""}}; {""levelname"": ""INFO"", ""asctime"": ""2019-07-11 14:19:3",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6617:3485,message,message,3485,https://hail.is,https://github.com/hail-is/hail/issues/6617,1,['message'],['message']
Integrability,"us's releases</a>.</em></p>; <blockquote>; <h2>janus 1.0.0 release</h2>; <ul>; <li>Dropped Python 3.6 support</li>; <li>Janus is marked as stable, no API changes was made for years</li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/janus/blob/master/CHANGES.rst"">janus's changelog</a>.</em></p>; <blockquote>; <h2>1.0.0 (2021-12-17)</h2>; <ul>; <li>Drop Python 3.6 support</li>; </ul>; <h2>0.7.0 (2021-11-24)</h2>; <ul>; <li>Add SyncQueue and AsyncQueue Protocols to provide type hints for sync and async queues <a href=""https://github-redirect.dependabot.com/aio-libs/janus/issues/374"">#374</a></li>; </ul>; <h2>0.6.2 (2021-10-24)</h2>; <ul>; <li>Fix Python 3.10 compatibility <a href=""https://github-redirect.dependabot.com/aio-libs/janus/issues/358"">#358</a></li>; </ul>; <h2>0.6.1 (2020-10-26)</h2>; <ul>; <li>; <p>Raise RuntimeError on queue.join() after queue closing. <a href=""https://github-redirect.dependabot.com/aio-libs/janus/issues/295"">#295</a></p>; </li>; <li>; <p>Replace <code>timeout</code> type from <code>Optional[int]</code> to <code>Optional[float]</code> <a href=""https://github-redirect.dependabot.com/aio-libs/janus/issues/267"">#267</a></p>; </li>; </ul>; <h2>0.6.0 (2020-10-10)</h2>; <ul>; <li>; <p>Drop Python 3.5, the minimal supported version is Python 3.6</p>; </li>; <li>; <p>Support Python 3.9</p>; </li>; <li>; <p>Refomat with <code>black</code></p>; </li>; </ul>; <h2>0.5.0 (2020-04-23)</h2>; <ul>; <li>Remove explicit loop arguments and forbid creating queues outside event loops <a href=""https://github-redirect.dependabot.com/aio-libs/janus/issues/246"">#246</a></li>; </ul>; <h2>0.4.0 (2018-07-28)</h2>; <ul>; <li>; <p>Add <code>py.typed</code> macro <a href=""https://github-redirect.dependabot.com/aio-libs/janus/issues/89"">#89</a></p>; </li>; <li>; <p>Drop python 3.4 support and fix minimal version python3.5.3 <a href=""https://github-redirect.dependabot.com/aio-libs/janus/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11466:1218,depend,dependabot,1218,https://hail.is,https://github.com/hail-is/hail/pull/11466,1,['depend'],['dependabot']
Integrability,"use Table interface in RichTable.{forall, exists}",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3739:10,interface,interface,10,https://hail.is,https://github.com/hail-is/hail/pull/3739,1,['interface'],['interface']
Integrability,use new AggSignature to better reflect new aggregator interface,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6686:54,interface,interface,54,https://hail.is,https://github.com/hail-is/hail/pull/6686,1,['interface'],['interface']
Integrability,use varargs instead of lists in python interface,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1925:39,interface,interface,39,https://hail.is,https://github.com/hail-is/hail/issues/1925,1,['interface'],['interface']
Integrability,use wrapToMethod to control method size on InsertFields and SelectFields,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4307:4,wrap,wrapToMethod,4,https://hail.is,https://github.com/hail-is/hail/pull/4307,1,['wrap'],['wrapToMethod']
Integrability,"users to work on hail at the same time using the same shared filesystem. My design was to use a central code and library repository where there is a $CODE_HOME/hail/ and a $CODE_HOME/miniconda/ python installation, which all users PATHs are pointing to. This worked fine for both interactive and spark-submit uses with a single user, but today when I was testing with multiple users the HailContext would fail to form intermittently on a call to hc = HailContext() with either one of two errors. Note, each user today was ssh'ed into a different node and we were all using different jupyter notebooks simultaneously. There were five of us, and everytime we would all try to start HailContext at least one of us would fail out with these errors. Most of the time all five of us would fail out. Also note that concurrent calls to python only would be fine, with from hail import * working fine. Any help at all would be wonderful, as we would really like to work collaboratively on the cluster at the same time and all be referencing the same hail and python installations so we can keep our code synchronized. The first error that we would get would be. ---------; OSError Traceback (most recent call last); <ipython-input-11-2841f1963bb0> in <module>(); ----> 1 hc_rav = HailContext(). /scratch/PI/dpwall/computeEnvironments/hail/python/hail/context.pyc in __init__(self, sc, appName, master, local, log, quiet, append, parquet_compression, min_block_size, branching_factor, tmp_dir); 45; 46 from pyspark import SparkContext; ---> 47 SparkContext._ensure_initialized(); 48; 49 self._gateway = SparkContext._gateway. /share/sw/free/spark.2.1.0/spark-2.1.0-bin-hadoop2.7/python/pyspark/context.py in _ensure_initialized(cls, instance, gateway, conf); 254 with SparkContext._lock:; 255 if not SparkContext._gateway:; --> 256 SparkContext._gateway = gateway or launch_gateway(conf); 257 SparkContext._jvm = SparkContext._gateway.jvm; 258. /share/sw/free/spark.2.1.0/spark-2.1.0-bin-hadoop2.7/python/pyspa",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1525:1194,synchroniz,synchronized,1194,https://hail.is,https://github.com/hail-is/hail/issues/1525,1,['synchroniz'],['synchronized']
Integrability,"using ""chromosome"" when unexpected or leaving it out produces terrible error messages.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2537:77,message,messages,77,https://hail.is,https://github.com/hail-is/hail/issues/2537,1,['message'],['messages']
Integrability,"using builtin-java classes where applicable; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel). ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); Input In [2], in <cell line: 6>(); 3 sc = spark._sc; 5 import hail as hl; ----> 6 hl.init(sc=sc). File <decorator-gen-1703>:2, in init(sc, app_name, master, local, log, quiet, append, min_block_size, branching_factor, tmp_dir, default_reference, idempotent, global_seed, spark_conf, skip_logging_configuration, local_tmpdir, _optimizer_iterations, backend, driver_cores, driver_memory). File ~/miniforge3/envs/hail/lib/python3.9/site-packages/hail/typecheck/check.py:577, in _make_dec.<locals>.wrapper(__original_func, *args, **kwargs); 574 @decorator; 575 def wrapper(__original_func, *args, **kwargs):; 576 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 577 return __original_func(*args_, **kwargs_). File ~/miniforge3/envs/hail/lib/python3.9/site-packages/hail/context.py:312, in init(sc, app_name, master, local, log, quiet, append, min_block_size, branching_factor, tmp_dir, default_reference, idempotent, global_seed, spark_conf, skip_logging_configuration, local_tmpdir, _optimizer_iterations, backend, driver_cores, driver_memory); 299 return asyncio.get_event_loop().run_until_complete(init_batch(; 300 log=log,; 301 quiet=quiet,; (...); 309 name_prefix=app_name; 310 )); 311 if backend == 'spark':; --> 312 return init_spark(; 313 app_name=app_name,; 314 master=master,; 315 local=local,; 316 min_block_size=min_block_size,; 317 branching_factor=branching_factor,; 318 spark_conf=spark_conf,; 319 _optimizer_iterations=_optimizer_iterations,; 320 log=log,; 321 quiet=quiet,; 322 append=append,; 323 tmp_dir=tmp_dir,; 324 local_tmpdir=local_tmpdir,; 325 default_refe",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11827:2637,wrap,wrapper,2637,https://hail.is,https://github.com/hail-is/hail/issues/11827,2,['wrap'],['wrapper']
Integrability,"using the; generalized cross-validation (GCV) criterion to find the tradeoff between; smoothness and proximity to data points.</li>; <li><code>scipy.stats</code> has three new distributions, two new hypothesis tests, three; new sample statistics, a class for greater control over calculations; involving covariance matrices, and many other enhancements.</li>; </ul>; <h1>New features</h1>; <h1><code>scipy.datasets</code> introduction</h1>; <ul>; <li>A new dedicated <code>datasets</code> submodule has been added. The submodules; is meant for datasets that are relevant to other SciPy submodules ands; content (tutorials, examples, tests), as well as contain a curated; set of datasets that are of wider interest. As of this release, all; the datasets from <code>scipy.misc</code> have been added to <code>scipy.datasets</code>; (and deprecated in <code>scipy.misc</code>).</li>; <li>The submodule is based on <a href=""https://www.fatiando.org/pooch/latest/"">Pooch</a>; (a new optional dependency for SciPy), a Python package to simplify fetching; data files. This move will, in a subsequent release, facilitate SciPy; to trim down the sdist/wheel sizes, by decoupling the data files and; moving them out of the SciPy repository, hosting them externally and</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/scipy/scipy/commit/dde50595862a4f9cede24b5d1c86935c30f1f88a""><code>dde5059</code></a> REL: 1.10.0 final [wheel build]</li>; <li><a href=""https://github.com/scipy/scipy/commit/7856f281b016c585b82d03723c4494bcdbdcd4a5""><code>7856f28</code></a> Merge pull request <a href=""https://redirect.github.com/scipy/scipy/issues/17696"">#17696</a> from tylerjereddy/treddy_110_final_prep</li>; <li><a href=""https://github.com/scipy/scipy/commit/205b6243c6d075d05695e7ac6d007e0f03bfbf42""><code>205b624</code></a> DOC: add missing author</li>; <li><a href=""https://github.com/scipy/scipy/c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13227:2547,depend,dependency,2547,https://hail.is,https://github.com/hail-is/hail/pull/13227,1,['depend'],['dependency']
Integrability,"using; problems with dependency pins when upgrading. :doc:<code>aiohttp &lt;index&gt;</code> v3.8.3; fixes that by recovering the original boundary of <code>&lt; 7</code>.; (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/6950"">#6950</a>)</p>; </li>; </ul>; <hr />; <h1>3.8.2 (2022-09-20, subsequently yanked on 2022-09-21)</h1>; <p>.. note::</p>; <p>This release has some compatibility fixes for Python 3.11 but it may; still have some quirks. Some tests are still flaky in the CI.</p>; <p>.. caution::</p>; <p>This release has been yanked from PyPI. Modern pip will not pick it; up automatically. The reason is that is has <code>multidict &lt; 6</code> set in; the distribution package metadata (see :pr:<code>6950</code>). Please, use; <code>aiohttp ~= 3.8.3, != 3.8.1</code> instead, if you can.</p>; <h2>Bugfixes</h2>; <ul>; <li>Added support for registering :rfc:<code>OPTIONS &lt;9110#OPTIONS&gt;</code>; HTTP method handlers via :py:class:<code>~aiohttp.web.RouteTableDef</code>.; (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/4663"">#4663</a>)</li>; <li>Started supporting :rfc:<code>authority-form &lt;9112#authority-form&gt;</code> and; :rfc:<code>absolute-form &lt;9112#absolute-form&gt;</code> URLs on the server-side.; (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/6227"">#6227</a>)</li>; <li>Fixed Python 3.11 incompatibilities by using Cython 0.29.25.; (<a href=""https://github-redirect.dependabot.com/aio-libs/aiohttp/issues/6396"">#6396</a>)</li>; <li>Extended the <code>sock</code> argument typing declaration of the</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/aiohttp/blob/master/CHANGES.rst"">aiohttp's changelog</a>.</em></p>; <blockquote>; <h1>3.8.3 (2022-09-21)</h1>; <p>.. attention::</p>; <p>This is the last :doc:<code>aiohttp &lt;index&gt;</code> release",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12296:1804,Rout,RouteTableDef,1804,https://hail.is,https://github.com/hail-is/hail/pull/12296,1,['Rout'],['RouteTableDef']
Integrability,"ust/testng/compare/7.7.0...7.7.1"">https://github.com/cbeust/testng/compare/7.7.0...7.7.1</a></p>; <h2>TestNG v7.7.0</h2>; <h2>What's Changed</h2>; <ul>; <li>Replace FindBugs by SpotBugs by <a href=""https://github.com/gruenich""><code>@​gruenich</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2781"">cbeust/testng#2781</a></li>; <li>Gradle: Drop forUseAtConfigurationTime() by <a href=""https://github.com/gruenich""><code>@​gruenich</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2783"">cbeust/testng#2783</a></li>; <li>Added ability to provide custom message to assertThrows\expectThrows methods by <a href=""https://github.com/anatolyuzhakov""><code>@​anatolyuzhakov</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2793"">cbeust/testng#2793</a></li>; <li>Fix issue 2801 - Only resolve hostname once by <a href=""https://github.com/spkrka""><code>@​spkrka</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2802"">cbeust/testng#2802</a></li>; <li>[SECURITY] Fix Zip Slip Vulnerability; by <a href=""https://github.com/JLLeitschuh""><code>@​JLLeitschuh</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2806"">cbeust/testng#2806</a></li>; <li>GITHUB-2807 - Failsafe buildStackTrace by <a href=""https://github.com/seregamorph""><code>@​seregamorph</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2808"">cbeust/testng#2808</a></li>; <li>Prevent overlogging of debug msgs in Graph impl by <a href=""https://github.com/krmahadevan""><code>@​krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2813"">cbeust/testng#2813</a></li>; <li>Streamline dataprovider invoking in abstract classes by <a href=""https://github.com/krmahadevan""><code>@​krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2814"">cbeust/testng#2814</a></li>; <li>Streamline TestRes",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12665:1617,depend,dependabot,1617,https://hail.is,https://github.com/hail-is/hail/pull/12665,1,['depend'],['dependabot']
Integrability,"ut does not respect trailing semicolon (<a href=""https://redirect.github.com/ipython/ipython/issues/13940"">#13940</a>)</li>; <li><a href=""https://github.com/ipython/ipython/commit/3edbe3bd10c434af6458bdbe02269880b10b9adf""><code>3edbe3b</code></a> Resurrect fast (non-highlighted) traceback code for long files. (<a href=""https://redirect.github.com/ipython/ipython/issues/13947"">#13947</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/ipython/ipython/compare/7.34.0...8.11.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=ipython&package-manager=pip&previous-version=7.34.0&new-version=8.11.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12807:2628,depend,dependabot,2628,https://hail.is,https://github.com/hail-is/hail/pull/12807,1,['depend'],['dependabot']
Integrability,"ut. ```shell; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.128-17247d8990c6; LOGGING: writing to /home/edmund/.local/src/hail/hail-20240508-1553-0.2.128-17247d8990c6.log; Traceback (most recent call last):; File ""/home/edmund/.local/share/pyenv/versions/3.9.18/lib/python3.9/runpy.py"", line 197, in _run_module_as_main; return _run_code(code, main_globals, None,; File ""/home/edmund/.local/share/pyenv/versions/3.9.18/lib/python3.9/runpy.py"", line 87, in _run_code; exec(code, run_globals); File ""/home/edmund/.vscode/extensions/ms-python.debugpy-2024.6.0-linux-x64/bundled/libs/debugpy/adapter/../../debugpy/launcher/../../debugpy/__main__.py"", line 39, in <module>; cli.main(); File ""/home/edmund/.vscode/extensions/ms-python.debugpy-2024.6.0-linux-x64/bundled/libs/debugpy/adapter/../../debugpy/launcher/../../debugpy/../debugpy/server/cli.py"", line 430, in main; run(); File ""/home/edmund/.vscode/extensions/ms-python.debugpy-2024.6.0-linux-x64/bundled/libs/debugpy/adapter/../../debugpy/launcher/../../debugpy/../debugpy/server/cli.py"", line 284, in run_file; runpy.run_path(target, run_name=""__main__""); File ""/home/edmund/.vscode/extensions/ms-python.debugpy-2024.6.0-linux-x64/bundled/libs/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_runpy.py"", line 321, in run_path; return _run_module_code(code, init_globals, run_name,; File ""/home/edmund/.vscode/extensions/ms-python.debugpy-2024.6.0-linux-x64/bundled/libs/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_runpy.py"", line 135, in _run_module_code; _run_code(code, mod_globals, init_globals,; File ""/home/edmund/.vscode/extensions/ms-python.debugpy-2024.6.0-linux-x64/bundled/libs/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_runpy.py"", line 124, in _run_code; exec(code, run_globals); File ""/home/edmund/.local/src/hail/test.py"", line 34, in <module>; main(); File ""/home/edmund/.local/src/hail/test.py"", line 28, in main; r2_adj = r2_adj.checkpoint(f'{tmp}/adj', overwrite=args.overwrite); Fi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14537:2317,adapter,adapter,2317,https://hail.is,https://github.com/hail-is/hail/issues/14537,1,['adapter'],['adapter']
Integrability,"utch, Estonian, French, German, Italian,; Lithuanian, Persian, Polish, Portuguese, Russian, Spanish, Swedish, and; Turkish locales</li>; </ul>; <p>A number of accessibility features were added in this release:</p>; <ul>; <li>Allow keyboard to toggle menu expansion (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1167"">#1167</a>)</li>; <li>Allow keyboard to activate permalink (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1162"">#1162</a>)</li>; <li>Show keyboard focus on buttons (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1161"">#1161</a>)</li>; <li>Maintain aria-expanded along with .current in menu (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1151"">#1151</a>)</li>; <li>Respect tab order for prev/next buttons (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1051"">#1051</a>)</li>; </ul>; <h2>Fixes</h2>; <ul>; <li>Updated Google analytics integration (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1129"">#1129</a>)</li>; <li>Add classifier separation on Sphinx 2+ HTML4 writer (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1192"">#1192</a>)</li>; <li>Added missing space char in footer (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1188"">#1188</a>)</li>; <li>Fix navigation right padding on level2+ elements (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1068"">#1068</a>)</li>; <li>Fix navigation expansion button sizes (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1067"">#1067</a>)</li>; <li>Wrap inline literals (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_rtd_theme/issues/1050"">#1050</a>)</li>; <li>Fix aria labels (<a href=""https://github-redirect.dependabot.com/readthedocs/sphinx_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11464:3018,integrat,integration,3018,https://hail.is,https://github.com/hail-is/hail/pull/11464,2,['integrat'],['integration']
Integrability,"uthlib/pull/803"">oauthlib/oauthlib#803</a></li>; <li>chore: fix typo in test by <a href=""https://github.com/tamanobi""><code>@​tamanobi</code></a> in <a href=""https://github-redirect.dependabot.com/oauthlib/oauthlib/pull/816"">oauthlib/oauthlib#816</a></li>; <li>Fix typo in server.rst by <a href=""https://github.com/NemanjaT""><code>@​NemanjaT</code></a> in <a href=""https://github-redirect.dependabot.com/oauthlib/oauthlib/pull/819"">oauthlib/oauthlib#819</a></li>; <li>Fixed isort imports by <a href=""https://github.com/dasm""><code>@​dasm</code></a> in <a href=""https://github-redirect.dependabot.com/oauthlib/oauthlib/pull/820"">oauthlib/oauthlib#820</a></li>; <li>docs: Fix a few typos by <a href=""https://github.com/timgates42""><code>@​timgates42</code></a> in <a href=""https://github-redirect.dependabot.com/oauthlib/oauthlib/pull/822"">oauthlib/oauthlib#822</a></li>; <li>docs: fix typos by <a href=""https://github.com/kianmeng""><code>@​kianmeng</code></a> in <a href=""https://github-redirect.dependabot.com/oauthlib/oauthlib/pull/823"">oauthlib/oauthlib#823</a></li>; </ul>; <h2>New Contributors</h2>; <ul>; <li><a href=""https://github.com/ariebovenberg""><code>@​ariebovenberg</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/oauthlib/oauthlib/pull/804"">oauthlib/oauthlib#804</a></li>; <li><a href=""https://github.com/tamanobi""><code>@​tamanobi</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/oauthlib/oauthlib/pull/816"">oauthlib/oauthlib#816</a></li>; <li><a href=""https://github.com/NemanjaT""><code>@​NemanjaT</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/oauthlib/oauthlib/pull/819"">oauthlib/oauthlib#819</a></li>; <li><a href=""https://github.com/kianmeng""><code>@​kianmeng</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/oauthlib/oauthlib/pull/823"">oauthlib/oauthlib#823</a></li>; </ul>; <p><strong>Full Changelog</str",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12197:2898,depend,dependabot,2898,https://hail.is,https://github.com/hail-is/hail/pull/12197,2,['depend'],['dependabot']
Integrability,"uthlib/releases"">oauthlib's releases</a>.</em></p>; <blockquote>; <h2>3.2.1</h2>; <h2>In short</h2>; <p>OAuth2.0 Provider:</p>; <ul>; <li><a href=""https://github-redirect.dependabot.com/oauthlib/oauthlib/issues/803"">#803</a> : Metadata endpoint support of non-HTTPS</li>; <li>CVE-2022-36087</li>; </ul>; <p>OAuth1.0:</p>; <ul>; <li><a href=""https://github-redirect.dependabot.com/oauthlib/oauthlib/issues/818"">#818</a> : Allow IPv6 being parsed by signature</li>; </ul>; <p>General:</p>; <ul>; <li>Improved and fixed documentation warnings.</li>; <li>Cosmetic changes based on isort</li>; </ul>; <h2>What's Changed</h2>; <ul>; <li>add missing slots to TokenBase by <a href=""https://github.com/ariebovenberg""><code>@​ariebovenberg</code></a> in <a href=""https://github-redirect.dependabot.com/oauthlib/oauthlib/pull/804"">oauthlib/oauthlib#804</a></li>; <li>Add CORS support for Refresh Token Grant. by <a href=""https://github.com/luhn""><code>@​luhn</code></a> in <a href=""https://github-redirect.dependabot.com/oauthlib/oauthlib/pull/806"">oauthlib/oauthlib#806</a></li>; <li>GitHub Action to lint Python code by <a href=""https://github.com/cclauss""><code>@​cclauss</code></a> in <a href=""https://github-redirect.dependabot.com/oauthlib/oauthlib/pull/797"">oauthlib/oauthlib#797</a></li>; <li>Docs: fix Sphinx warnings for better ReadTheDocs generation by <a href=""https://github.com/JonathanHuot""><code>@​JonathanHuot</code></a> in <a href=""https://github-redirect.dependabot.com/oauthlib/oauthlib/pull/807"">oauthlib/oauthlib#807</a></li>; <li>Allow non-HTTPS issuer when OAUTHLIB_INSECURE_TRANSPORT. by <a href=""https://github.com/luhn""><code>@​luhn</code></a> in <a href=""https://github-redirect.dependabot.com/oauthlib/oauthlib/pull/803"">oauthlib/oauthlib#803</a></li>; <li>chore: fix typo in test by <a href=""https://github.com/tamanobi""><code>@​tamanobi</code></a> in <a href=""https://github-redirect.dependabot.com/oauthlib/oauthlib/pull/816"">oauthlib/oauthlib#816</a></li>; <li>Fix typo in server",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12197:1176,depend,dependabot,1176,https://hail.is,https://github.com/hail-is/hail/pull/12197,2,['depend'],['dependabot']
Integrability,"util/blob/master/HISTORY.rst"">psutil's changelog</a>.</em></p>; <blockquote>; <h1>5.9.0</h1>; <p>2021-12-29</p>; <p><strong>Enhancements</strong></p>; <ul>; <li>1851_, [Linux]: <code>cpu_freq()</code>_ is slow on systems with many CPUs. Read current; frequency values for all CPUs from <code>/proc/cpuinfo</code> instead of opening many; files in <code>/sys</code> fs. (patch by marxin)</li>; <li>1992_: <code>NoSuchProcess</code>_ message now specifies if the PID has been reused.</li>; <li>1992_: error classes (<code>NoSuchProcess</code><em>, <code>AccessDenied</code></em>, etc.) now have a better; formatted and separated <code>__repr__</code> and <code>__str__</code> implementations.</li>; <li>1996_, [BSD]: add support for MidnightBSD. (patch by Saeed Rasooli)</li>; <li>1999_, [Linux]: <code>disk_partitions()</code>_: convert <code>/dev/root</code> device (an alias; used on some Linux distros) to real root device path.</li>; <li>2005_: <code>PSUTIL_DEBUG</code> mode now prints file name and line number of the debug; messages coming from C extension modules.</li>; <li>2042_: rewrite HISTORY.rst to use hyperlinks pointing to psutil API doc.</li>; </ul>; <p><strong>Bug fixes</strong></p>; <ul>; <li>1456_, [macOS], <strong>[critical]</strong>: <code>cpu_freq()</code>_ <code>min</code> and <code>max</code> are set to; 0 if can't be determined (instead of crashing).</li>; <li>1512_, [macOS]: sometimes <code>Process.connections()</code>_ will crash with; <code>EOPNOTSUPP</code> for one connection; this is now ignored.</li>; <li>1598_, [Windows]: <code>disk_partitions()</code>_ only returns mountpoints on drives; where it first finds one.</li>; <li>1874_, [SunOS]: swap output error due to incorrect range.</li>; <li>1892_, [macOS]: <code>cpu_freq()</code>_ broken on Apple M1.</li>; <li>1901_, [macOS]: different functions, especially <code>Process.open_files()</code>_ and; <code>Process.connections()</code><em>, could randomly raise <code>AccessDenied</code></em> because the; in",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11459:1205,message,messages,1205,https://hail.is,https://github.com/hail-is/hail/pull/11459,1,['message'],['messages']
Integrability,"utodoc-typehints/commit/a9b90238f74f1c5f69d7dcafb83c9775504f9b3b""><code>a9b9023</code></a> Fix typos (<a href=""https://github-redirect.dependabot.com/tox-dev/sphinx-autodoc-typehints/issues/224"">#224</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/tox-dev/sphinx-autodoc-typehints/compare/1.11.1...1.18.3"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=sphinx-autodoc-typehints&package-manager=pip&previous-version=1.11.1&new-version=1.18.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11909:7917,Depend,Dependabot,7917,https://hail.is,https://github.com/hail-is/hail/pull/11909,1,['Depend'],['Dependabot']
Integrability,"v [ WrappedArray( Set( WrappedArray(null); , WrappedArray(); , WrappedArray(Map(null -> Map(WrappedArray(2) -> 2)), Map(null -> Map(WrappedArray() -> 1)), Map(null -> Map(WrappedArray(1) -> 2))); ); , Set(WrappedArray(Map(null -> null), Map(null -> Map(WrappedArray(2) -> 31, WrappedArray(0) -> 0)))); , Set(WrappedArray(Map(null -> Map()), Map(null -> null))); , Set( WrappedArray(Map()); , WrappedArray(Map(null -> Map())); , WrappedArray(Map(null -> null)); , WrappedArray(); , WrappedArray(null, Map(null -> Map(WrappedArray() -> null)))); , Set(); , Set( WrappedArray(Map(null -> Map(WrappedArray() -> null))); , WrappedArray(); , WrappedArray(Map(null -> Map())); , WrappedArray(Map(null -> Map()), Map(null -> Map(WrappedArray() -> 2)))); , Set(WrappedArray()); , Set( WrappedArray(); , WrappedArray(Map(null -> Map()))); , Set(); , Set( WrappedArray(Map(null -> null)); , WrappedArray(Map(null -> Map()))); , Set( WrappedArray(Map(null -> Map(WrappedArray(null) -> 1)), Map(null -> Map(WrappedArray(5) -> 2))); , WrappedArray(Map())); , Set(); , Set(); , Set(WrappedArray(); , WrappedArray(Map(null -> Map()))); , Set(); , Set( null; , WrappedArray()); , Set( WrappedArray(Map(null -> Map(WrappedArray(1) -> 19))); , WrappedArray(Map(null -> Map(WrappedArray(0) -> 2)), Map(null -> Map())); , WrappedArray(Map(null -> Map())); , WrappedArray(Map(null -> Map(WrappedArray(2) -> null)), Map(null -> Map(WrappedArray() -> 17)), Map(null -> Map(WrappedArray() -> 1)))); , Set(WrappedArray(Map(null -> Map(WrappedArray(null) -> 1)), Map(null -> Map(WrappedArray(2) -> 0, WrappedArray() -> null)), Map(), Map())); , Set(WrappedArray(Map(null -> Map()), Map(null -> Map()), Map(null -> Map(WrappedArray(0) -> 0)))); , Set( WrappedArray(); , WrappedArray(Map(null -> Map(WrappedArray(0) -> null)))); , Set(WrappedArray(Map())); , Set( WrappedArray(Map()); , WrappedArray(Map(null -> Map(WrappedArray() -> 0))); , WrappedArray(Map(null -> Map()))); , Set(); , Set( WrappedArray(); , WrappedArray(Map(nu",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1902:2123,Wrap,WrappedArray,2123,https://hail.is,https://github.com/hail-is/hail/pull/1902,1,['Wrap'],['WrappedArray']
Integrability,"v.alt on a multi-allelic variant currently crashed with the following error:; java.lang.IllegalArgumentException: requirement failed: called altAllele on a non-biallelic variant. The error message could be improved (""called alt / altAllele on a ...""). Or maybe v.alt on a multi-allelic variant could return a comma-delimited string of alt alleles?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/978:189,message,message,189,https://hail.is,https://github.com/hail-is/hail/issues/978,1,['message'],['message']
Integrability,"v/codecov-action action to v4 by <a href=""https://github.com/renovate""><code>@​renovate</code></a> in <a href=""https://redirect.github.com/PyMySQL/PyMySQL/pull/1137"">PyMySQL/PyMySQL#1137</a></li>; <li>ci: use codecov@v3 by <a href=""https://github.com/methane""><code>@​methane</code></a> in <a href=""https://redirect.github.com/PyMySQL/PyMySQL/pull/1142"">PyMySQL/PyMySQL#1142</a></li>; <li>chore(deps): update dessant/lock-threads action to v5 by <a href=""https://github.com/renovate""><code>@​renovate</code></a> in <a href=""https://redirect.github.com/PyMySQL/PyMySQL/pull/1141"">PyMySQL/PyMySQL#1141</a></li>; <li>doc: use rtd theme by <a href=""https://github.com/methane""><code>@​methane</code></a> in <a href=""https://redirect.github.com/PyMySQL/PyMySQL/pull/1143"">PyMySQL/PyMySQL#1143</a></li>; <li>use Ruff as formatter by <a href=""https://github.com/methane""><code>@​methane</code></a> in <a href=""https://redirect.github.com/PyMySQL/PyMySQL/pull/1144"">PyMySQL/PyMySQL#1144</a></li>; <li>chore(deps): update dependency sphinx-rtd-theme to v2 by <a href=""https://github.com/renovate""><code>@​renovate</code></a> in <a href=""https://redirect.github.com/PyMySQL/PyMySQL/pull/1147"">PyMySQL/PyMySQL#1147</a></li>; <li>chore(deps): update actions/setup-python action to v5 by <a href=""https://github.com/renovate""><code>@​renovate</code></a> in <a href=""https://redirect.github.com/PyMySQL/PyMySQL/pull/1152"">PyMySQL/PyMySQL#1152</a></li>; <li>chore(deps): update github/codeql-action action to v3 by <a href=""https://github.com/renovate""><code>@​renovate</code></a> in <a href=""https://redirect.github.com/PyMySQL/PyMySQL/pull/1154"">PyMySQL/PyMySQL#1154</a></li>; <li>chore(deps): update codecov/codecov-action action to v4 by <a href=""https://github.com/renovate""><code>@​renovate</code></a> in <a href=""https://redirect.github.com/PyMySQL/PyMySQL/pull/1158"">PyMySQL/PyMySQL#1158</a></li>; <li>Support error packet without sqlstate by <a href=""https://github.com/methane""><code>@​methane</code></a> i",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14556:2435,depend,dependency,2435,https://hail.is,https://github.com/hail-is/hail/pull/14556,1,['depend'],['dependency']
Integrability,"v/pandas/issues/45922"">#45922</a>)</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/ebf024eb886a8e81922250a386c8d1c8bfa13b2a""><code>ebf024e</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45923"">#45923</a>: DOC: add Python 3.10 to doc (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45927"">#45927</a>)</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/deea0562e1ebabc874011575293103d0ba35d0f0""><code>deea056</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45910"">#45910</a>: TST/CI: Set hypothesis deadline to None to avoid flaky fa...</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/58aebf1940b56b77279174f5413b76a5aaba465c""><code>58aebf1</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45909"">#45909</a>: BUG: DateOffset(n) not defaulting to days (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45918"">#45918</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/pandas-dev/pandas/compare/v1.3.0...v1.4.1"">compare view</a></li>; </ul>; </details>; <br />. Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11521:4293,depend,dependabot,4293,https://hail.is,https://github.com/hail-is/hail/pull/11521,1,['depend'],['dependabot']
Integrability,"v/pandas/issues/45922"">#45922</a>)</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/ebf024eb886a8e81922250a386c8d1c8bfa13b2a""><code>ebf024e</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45923"">#45923</a>: DOC: add Python 3.10 to doc (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45927"">#45927</a>)</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/deea0562e1ebabc874011575293103d0ba35d0f0""><code>deea056</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45910"">#45910</a>: TST/CI: Set hypothesis deadline to None to avoid flaky fa...</li>; <li><a href=""https://github.com/pandas-dev/pandas/commit/58aebf1940b56b77279174f5413b76a5aaba465c""><code>58aebf1</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45909"">#45909</a>: BUG: DateOffset(n) not defaulting to days (<a href=""https://github-redirect.dependabot.com/pandas-dev/pandas/issues/45918"">#45918</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/pandas-dev/pandas/compare/v1.3.0...v1.4.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pandas&package-manager=pip&previous-version=1.3.0&new-version=1.4.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11539:5811,depend,dependabot,5811,https://hail.is,https://github.com/hail-is/hail/pull/11539,1,['depend'],['dependabot']
Integrability,"v/pytest-asyncio/commit/726c6e0f3c185f10d8a842bcd1d781de32a3b2f5""><code>726c6e0</code></a> Build(deps): Bump coverage from 7.4.3 to 7.4.4 in /dependencies/default</li>; <li><a href=""https://github.com/pytest-dev/pytest-asyncio/commit/8bd8288709717165b352c7f2f207c8e4ef624a01""><code>8bd8288</code></a> Build(deps): Bump pytest from 8.0.2 to 8.1.1 in /dependencies/default</li>; <li><a href=""https://github.com/pytest-dev/pytest-asyncio/commit/ef3b3477070d6a270e1bb2c1d438c64dba42724c""><code>ef3b347</code></a> Build(deps): Bump packaging from 23.2 to 24.0 in /dependencies/default</li>; <li><a href=""https://github.com/pytest-dev/pytest-asyncio/commit/b22d84e1f0d53920352be4c66d1b6c7f7a9ce005""><code>b22d84e</code></a> [docs] Fixes the example showing how to run all tests in a session-scoped loop.</li>; <li>Additional commits viewable in <a href=""https://github.com/pytest-dev/pytest-asyncio/compare/v0.21.1...v0.23.6"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pytest-asyncio&package-manager=pip&previous-version=0.21.1&new-version=0.23.6)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14507:9200,Depend,Dependabot,9200,https://hail.is,https://github.com/hail-is/hail/pull/14507,2,"['Depend', 'depend']","['Dependabot', 'dependabot-badges']"
Integrability,"v1.21.6...v1.22.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=numpy&package-manager=pip&previous-version=1.21.6&new-version=1.22.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/hail-is/hail/netw",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11939:5712,Depend,Dependabot,5712,https://hail.is,https://github.com/hail-is/hail/pull/11939,27,"['Depend', 'depend']","['Dependabot', 'dependabot']"
Integrability,"v1561977819/icon/m.png ""medium severity"") | **581/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.9 | Uncontrolled Resource Consumption (&#x27;Resource Exhaustion&#x27;) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6157248](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6157248) | `cryptography:` <br> `41.0.7 -> 42.0.2` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **451/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.3 | NULL Pointer Dereference <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6210214](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6210214) | `cryptography:` <br> `41.0.7 -> 42.0.2` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIyN2MzNWY4NC0yNDIyLTRmNzUtYWMxYy1mODQxOGJmNzRlMzciLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjI3YzM1Zjg0LTI0MjItNGY3NS1hYzFjLWY4NDE4YmY3NGUzNyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/5ecb4152-94d0-44ff-86c6-21e542bb123d?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14234:2412,depend,dependency,2412,https://hail.is,https://github.com/hail-is/hail/pull/14234,2,['depend'],"['dependencies', 'dependency']"
Integrability,"v1561977819/icon/m.png ""medium severity"") | **581/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.9 | Uncontrolled Resource Consumption (&#x27;Resource Exhaustion&#x27;) <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6157248](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6157248) | `cryptography:` <br> `41.0.7 -> 42.0.2` <br> | No | No Known Exploit ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | **451/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 3.3 | NULL Pointer Dereference <br/>[SNYK-PYTHON-CRYPTOGRAPHY-6210214](https://snyk.io/vuln/SNYK-PYTHON-CRYPTOGRAPHY-6210214) | `cryptography:` <br> `41.0.7 -> 42.0.2` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJjMjFkYTE5Ny1lMDgzLTRiNzEtODc1Yi0xZmY0MjNhZWZmOWEiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImMyMWRhMTk3LWUwODMtNGI3MS04NzViLTFmZjQyM2FlZmY5YSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14236:2146,depend,dependency,2146,https://hail.is,https://github.com/hail-is/hail/pull/14236,2,['depend'],"['dependencies', 'dependency']"
Integrability,"v1561977819/icon/m.png ""medium severity"") | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-5840803](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5840803) | `tornado:` <br> `5.1.1 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-6041512](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-6041512) | `tornado:` <br> `5.1.1 -> 6.3.3` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-WHEEL-3180413](https://snyk.io/vuln/SNYK-PYTHON-WHEEL-3180413) | `wheel:` <br> `0.30.0 -> 0.38.0` <br> | No | No Known Exploit . Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI0ZGE0MDY2My1hNjY3LTRhNzktOWE2NS0zMWE5NzQxMGZhZjEiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjRkYTQwNjYzLWE2NjctNGE3OS05YTY1LTMxYTk3NDEwZmFmMSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14257:8598,depend,dependency,8598,https://hail.is,https://github.com/hail-is/hail/pull/14257,2,['depend'],"['dependencies', 'dependency']"
Integrability,"v1561977819/icon/m.png ""medium severity"") | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-5840803](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5840803) | `tornado:` <br> `5.1.1 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-6041512](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-6041512) | `tornado:` <br> `5.1.1 -> 6.3.3` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-WHEEL-3180413](https://snyk.io/vuln/SNYK-PYTHON-WHEEL-3180413) | `wheel:` <br> `0.30.0 -> 0.38.0` <br> | No | No Known Exploit . Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJhMmM5NWY4MC0wNmQyLTRkNWYtODk4NS00MzBmOTdiOGY2NDMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImEyYzk1ZjgwLTA2ZDItNGQ1Zi04OTg1LTQzMGY5N2I4ZjY0MyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14024:8005,depend,dependency,8005,https://hail.is,https://github.com/hail-is/hail/pull/14024,2,['depend'],"['dependencies', 'dependency']"
Integrability,"v1561977819/icon/m.png ""medium severity"") | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-5840803](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5840803) | `tornado:` <br> `5.1.1 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-6041512](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-6041512) | `tornado:` <br> `5.1.1 -> 6.3.3` <br> | No | No Known Exploit ; ![high severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/h.png ""high severity"") | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-WHEEL-3180413](https://snyk.io/vuln/SNYK-PYTHON-WHEEL-3180413) | `wheel:` <br> `0.32.2 -> 0.38.0` <br> | No | No Known Exploit . Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJiMTFhNTg5Ny0yYzUzLTQ3MmEtOWY1NS1kMjcwNjYxNWNkMjgiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImIxMWE1ODk3LTJjNTMtNDcyYS05ZjU1LWQyNzA2NjE1Y2QyOCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14364:8951,depend,dependency,8951,https://hail.is,https://github.com/hail-is/hail/pull/14364,2,['depend'],"['dependencies', 'dependency']"
Integrability,"v2.3.0 by <a href=""https://github.com/jpadilla""><code>@​jpadilla</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/703"">jpadilla/pyjwt#703</a></li>; </ul>; <h2>New Contributors</h2>; <ul>; <li><a href=""https://github.com/ehdgua01""><code>@​ehdgua01</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/702"">jpadilla/pyjwt#702</a></li>; <li><a href=""https://github.com/auvipy""><code>@​auvipy</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/701"">jpadilla/pyjwt#701</a></li>; </ul>; <p><strong>Full Changelog</strong>: <a href=""https://github.com/jpadilla/pyjwt/compare/2.2.0...2.3.0"">https://github.com/jpadilla/pyjwt/compare/2.2.0...2.3.0</a></p>; <h2>2.2.0</h2>; <h2>What's Changed</h2>; <ul>; <li>Complete <code>jwt</code> documentation by <a href=""https://github.com/johachi""><code>@​johachi</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/654"">jpadilla/pyjwt#654</a></li>; <li>Ignore coverage files generated during test runs by <a href=""https://github.com/makusu2""><code>@​makusu2</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/617"">jpadilla/pyjwt#617</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/656"">jpadilla/pyjwt#656</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/658"">jpadilla/pyjwt#658</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/667"">jpadilla/pyjwt#667</a></li>; <li>Fix aud validation to support ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11457:1945,depend,dependabot,1945,https://hail.is,https://github.com/hail-is/hail/pull/11457,1,['depend'],['dependabot']
Integrability,"v3.49.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=svelte&package-manager=npm_and_yarn&previous-version=3.38.2&new-version=3.49.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/hail-is/hail/netw",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12032:9291,Depend,Dependabot,9291,https://hail.is,https://github.com/hail-is/hail/pull/12032,27,"['Depend', 'depend']","['Dependabot', 'dependabot']"
Integrability,"v6 scoped addresses</li>; <li>Additional commits viewable in <a href=""https://github.com/urllib3/urllib3/compare/1.26.9...1.26.11"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=urllib3&package-manager=pip&previous-version=1.26.9&new-version=1.26.11)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12104:4862,Depend,Dependabot,4862,https://hail.is,https://github.com/hail-is/hail/pull/12104,17,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability,"va</h1>; <ul>; <li>Refactoring java full runtime to reuse sub-message builders and prepare to; migrate parsing logic from parse constructor to builder.</li>; <li>Move proto wireformat parsing functionality from the private &quot;parsing; constructor&quot; to the Builder class.</li>; <li>Change the Lite runtime to prefer merging from the wireformat into mutable; messages rather than building up a new immutable object before merging. This; way results in fewer allocations and copy operations.</li>; <li>Make message-type extensions merge from wire-format instead of building up; instances and merging afterwards. This has much better performance.</li>; <li>Fix TextFormat parser to build up recurring (but supposedly not repeated); sub-messages directly from text rather than building a new sub-message and; merging the fully formed message into the existing field.</li>; <li>This release addresses a <a href=""https://github.com/protocolbuffers/protobuf/security/advisories/GHSA-h4h5-3hr4-j3g2"">Security Advisory for Java users</a></li>; </ul>; <h2>Protocol Buffers v3.20.2</h2>; <h1>C++</h1>; <ul>; <li>Reduce memory consumption of MessageSet parsing</li>; <li>This release addresses a <a href=""https://github.com/protocolbuffers/protobuf/security/advisories/GHSA-8gq9-2x98-w8hf"">Security Advisory for C++ and Python users</a></li>; </ul>; <h2>Protocol Buffers v3.20.1</h2>; <h1>PHP</h1>; <ul>; <li>Fix building packaged PHP extension (<a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/9727"">#9727</a>)</li>; <li>Fixed composer.json to only advertise compatibility with PHP 7.0+. (<a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/9819"">#9819</a>)</li>; </ul>; <h1>Ruby</h1>; <ul>; <li>Disable the aarch64 build on macOS until it can be fixed. (<a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/9816"">#9816</a>)</li>; </ul>; <h1>Other</h1>; <ul>; <li>Fix versioning issues in 3.20.0</li>; </ul>; <h2>Protoc",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12563:1237,protocol,protocolbuffers,1237,https://hail.is,https://github.com/hail-is/hail/pull/12563,2,"['Protocol', 'protocol']","['Protocol', 'protocolbuffers']"
Integrability,valFilters.scala:201); 	at is.hail.expr.ir.ExtractIntervalFilters$.extractAndRewrite(ExtractIntervalFilters.scala:151); 	at is.hail.expr.ir.ExtractIntervalFilters$.extractPartitionFilters(ExtractIntervalFilters.scala:249); 	at is.hail.expr.ir.ExtractIntervalFilters$$anonfun$apply$2.apply(ExtractIntervalFilters.scala:266); 	at is.hail.expr.ir.ExtractIntervalFilters$$anonfun$apply$2.apply(ExtractIntervalFilters.scala:254); 	at is.hail.expr.ir.RewriteBottomUp$.is$hail$expr$ir$RewriteBottomUp$$rewrite$1(RewriteBottomUp.scala:15); 	at is.hail.expr.ir.RewriteBottomUp$$anonfun$1.apply(RewriteBottomUp.scala:6); 	at is.hail.expr.ir.RewriteBottomUp$$anonfun$1.apply(RewriteBottomUp.scala:6); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); 	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.AbstractTraversable.map(Traversable.scala:104); 	at is.hail.expr.ir.RewriteBottomUp$.is$hail$expr$ir$RewriteBottomUp$$rewrite$1(RewriteBottomUp.scala:6); 	at is.hail.expr.ir.RewriteBottomUp$$anonfun$1.apply(RewriteBottomUp.scala:6); 	at is.hail.expr.ir.RewriteBottomUp$$anonfun$1.apply(RewriteBottomUp.scala:6); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); 	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.AbstractTraversable.map(Traversable.scala:104); 	at is.hail.expr.ir.RewriteBottomUp$.is$hail$expr$ir$RewriteBottomUp$$rewrite$1(RewriteBottomUp,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6458:4192,Wrap,WrappedArray,4192,https://hail.is,https://github.com/hail-is/hail/issues/6458,1,['Wrap'],['WrappedArray']
Integrability,"variable <code>BLACK_CACHE_DIR</code> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2739"">#2739</a>).</li>; <li>Enable Python 3.10+ by default, without any extra need to specify -<code>-target-version=py310</code>. (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2758"">#2758</a>)</li>; <li>Make passing <code>SRC</code> or <code>--code</code> mandatory and mutually exclusive (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2804"">#2804</a>)</li>; </ul>; <h3>Output</h3>; <ul>; <li>Improve error message for invalid regular expression (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2678"">#2678</a>)</li>; <li>Improve error message when parsing fails during AST safety check by embedding the underlying SyntaxError (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2693"">#2693</a>)</li>; <li>No longer color diff headers white as it's unreadable in light themed terminals (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2691"">#2691</a>)</li>; <li>Text coloring added in the final statistics (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2712"">#2712</a>)</li>; <li>Verbose mode also now describes how a project root was discovered and which paths will be formatted. (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2526"">#2526</a>)</li>; </ul>; <h3>Packaging</h3>; <ul>; <li>All upper version bounds on dependencies have been removed (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2718"">#2718</a>)</li>; <li><code>typing-extensions</code> is no longer a required dependency in Python 3.10+ (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2772"">#2772</a>)</li>; <li>Set <code>click</code> lower bound to <code>8.0.0</code> as <em>Black</em> crashes on <code>7.1.2</code> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2791"">#2791</a>)</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (trunc",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11468:6001,depend,dependabot,6001,https://hail.is,https://github.com/hail-is/hail/pull/11468,1,['depend'],['dependabot']
Integrability,"ve deprecated VERSION, use <strong>version</strong> instead</li>; <li><a href=""https://github.com/jmoiron/humanize/commit/eb3e2534267714361da866109bd33ff20e63416c""><code>eb3e253</code></a> Merge branch 'master' into no-overflow-naturaldelta</li>; <li>Additional commits viewable in <a href=""https://github.com/jmoiron/humanize/compare/1.0.0...4.0.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=humanize&package-manager=pip&previous-version=1.0.0&new-version=4.0.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11517:7315,Depend,Dependabot,7315,https://hail.is,https://github.com/hail-is/hail/pull/11517,2,['Depend'],['Dependabot']
Integrability,"ved the code). - `.strip()` the GitHub token in case there are newlines. - print the SHA being deployed in the log statement. - add `hail-ci-build.sh` to CI, which just invokes `make test-in-cluster`(which in turn runs `test-in-cluster.sh`. - `test-in-cluster.sh` copies the secrets for testing to the expected locations and exposes the pod in which it is running with an internal service, recent changes to `site` [redirect sub URLs of ci.test.is to services named using this scheme](https://github.com/hail-is/hail/blob/master/site/hail.nginx.conf#L38-L41). GitHub uses these URLs to send updates to the CI under test about the watched repositories. - `test-locally.sh` now installs `../batch` into the currently running `pip` before testing (NB: if you edit batch and run the tests without committing the changes you've made to batch, this will pass tests but fail when pushed to a PR!). - `test-locally.sh` activates the `hail-ci` conda environment itself because it was not being propagated from the `Makefile`. I don't know why, but this is a simple fix. - `test-locally.sh` starts the ci after the repository is created. CI will print error messages if a watched repository doesn't exist. - `test/test-ci.py` now uses access tokens for all interaction with GitHub, previously it relied on the latent privileges that I and Cotton had in our environments. - `test/test-ci.py` uses a temporary, but not automatically deleted, directory when the environment variable `IN_CLUSTER` is set to `true` (to which it is set by `test-in-cluster.sh`). I noticed that, when running in a batch job pod, if an error occurred, `pytest` failed to print any error information and instead failed because the current working directory no longer existed. I found very little information on Google about this. It seems safe to not clean up temporary directories created in the batch job pod because pods are ephemeral. cc: @cseed. Assigning to @tpoterba since he has the most context on this stuff other than Cotton.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4474:1616,message,messages,1616,https://hail.is,https://github.com/hail-is/hail/pull/4474,1,['message'],['messages']
Integrability,"veltejs/svelte/issues/7494"">#7495</a>)</li>; </ul>; <h2>3.47.0</h2>; <ul>; <li>Add support for dynamic elements through <code>&lt;svelte:element&gt;</code> (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/2324"">#2324</a>)</li>; <li>Miscellaneous variable context fixes in <code>{@const}</code> (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/pull/7222"">#7222</a>)</li>; <li>Fix <code>{#key}</code> block not being reactive when the key variable is not otherwise used (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7408"">#7408</a>)</li>; <li>Add <code>Symbol</code> as a known global (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7418"">#7418</a>)</li>; </ul>; <h2>3.46.6</h2>; <ul>; <li>Actually include action TypeScript interface in published package (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/pull/7407"">#7407</a>)</li>; </ul>; <h2>3.46.5</h2>; <ul>; <li>Add TypeScript interfaces for typing actions (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/6538"">#6538</a>)</li>; <li>Do not generate <code>unused-export-let</code> warning inside <code>&lt;script context=&quot;module&quot;&gt;</code> blocks (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7055"">#7055</a>)</li>; <li>Do not collapse whitespace-only CSS vars (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7152"">#7152</a>)</li>; <li>Add <code>aria-description</code> to the list of allowed ARIA attributes (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7301"">#7301</a>)</li>; <li>Fix attribute escaping during SSR (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7327"">#7327</a>)</li>; <li>Prevent <code>.innerHTML</code> optimization from being used when <code>style:</code> directive is present (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7386"">#7386</a>)</li>; </ul>; <h2>3.46.4",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12032:4798,interface,interfaces,4798,https://hail.is,https://github.com/hail-is/hail/pull/12032,3,['interface'],['interfaces']
Integrability,"veniosoftware/dictdiffer/issues/133"">#133</a> <a href=""https://github-redirect.dependabot.com/inveniosoftware/dictdiffer/issues/134"">#134</a>)</li>; </ul>; <p>Version 0.8.0 (released 2019-03-17)</p>; <ul>; <li>Respect <code>dot_notation</code> flag in ignore argument (<a href=""https://github.com/yoyonel""><code>@​yoyonel</code></a>) (<a href=""https://github-redirect.dependabot.com/inveniosoftware/dictdiffer/issues/107"">#107</a>)</li>; <li>Adds argument for toggling dot notation in diff. (<a href=""https://github.com/robinchew""><code>@​robinchew</code></a>)</li>; </ul>; <p>Version 0.7.2 (released 2019-02-22)</p>; <ul>; <li>Two NaN values are considered the same, hence they are not shown in <code>diff</code>; output. (<a href=""https://github-redirect.dependabot.com/inveniosoftware/dictdiffer/issues/114"">#114</a>) (<a href=""https://github.com/t-b""><code>@​t-b</code></a>)</li>; <li>Refactors <code>diff</code> method to reduce recursive call stack size. (<a href=""https://github-redirect.dependabot.com/inveniosoftware/dictdiffer/issues/112"">#112</a>); (<a href=""https://github.com/yoyonel""><code>@​yoyonel</code></a>)</li>; <li>Python porting best practice use feature detection instead; of version detection to save an import and pass both PyLint; and Flake8 tests with neither 'pragma' nor 'noqa'. (<a href=""https://github.com/cclauss""><code>@​cclauss</code></a>)</li>; </ul>; <p>Version 0.7.1 (released 2018-05-04)</p>; <ul>; <li>Resolves issue with keys containing dots. (<a href=""https://github-redirect.dependabot.com/inveniosoftware/dictdiffer/issues/101"">#101</a>)</li>; </ul>; <p>Version 0.7.0 (released 2017-10-16)</p>; <ul>; <li>Fixes problem with diff results that reference the original structure by; introduction of <code>deepcopy</code> for all possibly unhashable items. Thus the diff; does not change later when the diffed structures change.</li>; <li>Adds new option for patching and reverting patches in-place.</li>; <li>Adds Python 3.6 to test matrix.</li>; <li>Fixes the <",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11485:4035,depend,dependabot,4035,https://hail.is,https://github.com/hail-is/hail/pull/11485,1,['depend'],['dependabot']
Integrability,"version numbers to: 20.2</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/806d7e4ce6f1fd0545cae226b94cb0249ea495c7""><code>806d7e4</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/10544"">#10544</a> from deannagarcia/3.20.x</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/ae718b39020ae6e6f8f5568e357d6893fd0fd29c""><code>ae718b3</code></a> Add missing includes</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/b4c395aaedfacb32e2414d361fa85968c0991b34""><code>b4c395a</code></a> Apply patch</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/6439c5c01349e74d4deb57c844a7ad4b7b13a302""><code>6439c5c</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/10531"">#10531</a> from protocolbuffers/deannagarcia-patch-7</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/22c79e6e4ca8be2bc2f700b2cdddca84d84659ce""><code>22c79e6</code></a> Update version.json</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/c1a2d2ec29314975e725021ffe4334926dbaa56c""><code>c1a2d2e</code></a> Fix python release on macos (<a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/10512"">#10512</a>)</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/a826282e15efe3ae3a2aebb040fb1691b2233a1e""><code>a826282</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/10505"">#10505</a> from deannagarcia/3.20.x</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/7639a710e10beb47bfc62f363680f7b04e8b3d26""><code>7639a71</code></a> Add version file</li>; <li>Additional commits viewable in <a href=""https://github.com/protocolbuffers/protobuf/compare/v3.20.1...v3.20.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.github",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12223:1894,protocol,protocolbuffers,1894,https://hail.is,https://github.com/hail-is/hail/pull/12223,3,['protocol'],['protocolbuffers']
Integrability,"version to 3.0.0</li>; <li><a href=""https://github.com/saghul/aiodns/commit/5d94ab0b9f81ee1feabee6a222d9352d244d76f2""><code>5d94ab0</code></a> Fix TXT CHAOS test</li>; <li><a href=""https://github.com/saghul/aiodns/commit/7bb002ea8eee1a8c1651f21d5ae0350857f00233""><code>7bb002e</code></a> Add support for CAA queries</li>; <li><a href=""https://github.com/saghul/aiodns/commit/c81387fd26d2e1c9bdcb85f7d12a13cda1c389d4""><code>c81387f</code></a> Support Python &gt;= 3.6</li>; <li>Additional commits viewable in <a href=""https://github.com/saghul/aiodns/compare/aiodns-2.0.0...aiodns-3.0.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=aiodns&package-manager=pip&previous-version=2.0.0&new-version=3.0.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11570:4199,Depend,Dependabot,4199,https://hail.is,https://github.com/hail-is/hail/pull/11570,1,['Depend'],['Dependabot']
Integrability,"version.json</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/c1a2d2ec29314975e725021ffe4334926dbaa56c""><code>c1a2d2e</code></a> Fix python release on macos (<a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/10512"">#10512</a>)</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/a826282e15efe3ae3a2aebb040fb1691b2233a1e""><code>a826282</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/10505"">#10505</a> from deannagarcia/3.20.x</li>; <li><a href=""https://github.com/protocolbuffers/protobuf/commit/7639a710e10beb47bfc62f363680f7b04e8b3d26""><code>7639a71</code></a> Add version file</li>; <li>Additional commits viewable in <a href=""https://github.com/protocolbuffers/protobuf/compare/v3.20.1...v3.20.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=protobuf&package-manager=pip&previous-version=3.20.1&new-version=3.20.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` w",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12223:2984,depend,dependency-name,2984,https://hail.is,https://github.com/hail-is/hail/pull/12223,3,['depend'],['dependency-name']
Integrability,"version: bfea6715901c2db13654f11bbc750e2fc037f831 (recent master branch). Ran:. ```; import hail as hl; hl.init(). t = hl.utils.range_table(1000); t = t.annotate(x = hl.rand_unif(0, 1)); t = t.key_by('x'); t.write('foo.ht', overwrite=True); ```. and got:. ```; Traceback (most recent call last):; File ""foo.py"", line 7, in <module>; t.write('foo.ht', overwrite=True); File ""/Users/cseed/hail/python/hail/typecheck/check.py"", line 547, in wrapper; return f(*args_, **kwargs_); File ""/Users/cseed/hail/python/hail/table.py"", line 1183, in write; self._jt.write(output, overwrite, stage_locally, _codec_spec); File ""/Users/cseed/py4j/java_gateway.py"", line 1133, in __call__; answer, self.gateway_client, self.target_id, self.name); File ""/Users/cseed/hail/python/hail/utils/java.py"", line 200, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: HailException: OrderedRVD error! Unexpected key in partition 7; Range bounds for partition 7: ([0.8599223493342859]-[0.9976076885349009]]; Key should be in partition 7: ([0.8599223493342859]-[0.9976076885349009]]; Invalid key: [0.9986274705095608]. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 7 in stage 2.0 failed 1 times, most recent failure: Lost task 7.0 in stage 2.0 (TID 23, localhost, executor driver): is.hail.utils.HailException: OrderedRVD error! Unexpected key in partition 7; Range bounds for partition 7: ([0.8599223493342859]-[0.9976076885349009]]; Key should be in partition 7: ([0.8599223493342859]-[0.9976076885349009]]; Invalid key: [0.9986274705095608]; 	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:9); 	at is.hail.utils.package$.fatal(package.scala:26); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$21$$anon$3.next(OrderedRVD.scala:1031); 	at is.hail.rvd.OrderedRVD$$anonfun$apply$21$$anon$3.next(OrderedRVD.scala:1011); 	at scala.collection.Iterator$$anon$12.next(Iterator.scala:444); 	at scala.collection.Itera",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4096:438,wrap,wrapper,438,https://hail.is,https://github.com/hail-is/hail/issues/4096,1,['wrap'],['wrapper']
Integrability,"vert preserve ordering in bulk (<a href=""https://redirect.github.com/Azure/azure-sdk-for-java/issues/36638"">#36638</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/18e193399fd48d029f326cc54e036c994084c190""><code>18e1933</code></a> Migrate KeyVault Secrets to Autorest and stream-style serialization (<a href=""https://redirect.github.com/Azure/azure-sdk-for-java/issues/36461"">#36461</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/910c88d6e85ba55d62062bf502055dfefa109530""><code>910c88d</code></a> mgmt compute, support convenience API listVmByVmss (<a href=""https://redirect.github.com/Azure/azure-sdk-for-java/issues/36631"">#36631</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/Azure/azure-sdk-for-java/compare/azure-core-http-netty_1.13.3...azure-core-http-netty_1.13.7"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.azure:azure-core-http-netty&package-manager=gradle&previous-version=1.13.3&new-version=1.13.7)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13597:3653,depend,dependency-name,3653,https://hail.is,https://github.com/hail-is/hail/pull/13597,1,['depend'],['dependency-name']
Integrability,very helpful when executing tests locally. Most of the lines here are noise because I added a function that wraps `client.create_batch` so needed to replace usages everywhere.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12884:108,wrap,wraps,108,https://hail.is,https://github.com/hail-is/hail/pull/12884,1,['wrap'],['wraps']
Integrability,"view for March release (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23294"">#23294</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/eeb2f3b8c7c115337f9d71166aca91db732c931e""><code>eeb2f3b</code></a> [Storage] Add missing SAS permissions to Storage packages (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23179"">#23179</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/038b35f890d2363edc1254ac2ee61918b2b84b66""><code>038b35f</code></a> [Storage] Fix bug with <code>ignore_read_only</code> in <code>start_copy_from_url()</code> (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23141"">#23141</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/5166ee94acdb80f2217a1ce694e169ea2b33219d""><code>5166ee9</code></a> [Storage] Fix <code>upload_blob()</code> from an OS pipe on Linux (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23211"">#23211</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/84cbec033ed8e4df87f44a82dcebb96aa19deac0""><code>84cbec0</code></a> [Storage] Adjust some file-datalake test recordings (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23147"">#23147</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/Azure/azure-sdk-for-python/compare/azure-storage-blob_12.8.1...azure-storage-blob_12.10.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=azure-storage-blob&package-manager=pip&previous-version=12.8.1&new-version=12.10.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can al",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11610:5255,depend,dependabot,5255,https://hail.is,https://github.com/hail-is/hail/pull/11610,1,['depend'],['dependabot']
Integrability,"view for March release (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23294"">#23294</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/eeb2f3b8c7c115337f9d71166aca91db732c931e""><code>eeb2f3b</code></a> [Storage] Add missing SAS permissions to Storage packages (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23179"">#23179</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/038b35f890d2363edc1254ac2ee61918b2b84b66""><code>038b35f</code></a> [Storage] Fix bug with <code>ignore_read_only</code> in <code>start_copy_from_url()</code> (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23141"">#23141</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/5166ee94acdb80f2217a1ce694e169ea2b33219d""><code>5166ee9</code></a> [Storage] Fix <code>upload_blob()</code> from an OS pipe on Linux (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23211"">#23211</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/Azure/azure-sdk-for-python/compare/azure-storage-blob_12.8.1...azure-storage-blob_12.11.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=azure-storage-blob&package-manager=pip&previous-version=12.8.1&new-version=12.11.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot r",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11703:6026,depend,dependabot,6026,https://hail.is,https://github.com/hail-is/hail/pull/11703,1,['depend'],['dependabot']
Integrability,"view</code> flag (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2752"">#2752</a>)</li>; </ul>; <h3>Style</h3>; <ul>; <li>Deprecate <code>--experimental-string-processing</code> and move the functionality under; <code>--preview</code> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2789"">#2789</a>)</li>; <li>For stubs, one blank line between class attributes and methods is now kept if there's; at least one pre-existing blank line (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2736"">#2736</a>)</li>; <li>Black now normalizes string prefix order (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2297"">#2297</a>)</li>; <li>Remove spaces around power operators if both operands are simple (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2726"">#2726</a>)</li>; <li>Work around bug that causes unstable formatting in some cases in the presence of the; magic trailing comma (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2807"">#2807</a>)</li>; <li>Use parentheses for attribute access on decimal float and int literals (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2799"">#2799</a>)</li>; <li>Don't add whitespace for attribute access on hexadecimal, binary, octal, and complex; literals (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2799"">#2799</a>)</li>; <li>Treat blank lines in stubs the same inside top-level <code>if</code> statements (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2820"">#2820</a>)</li>; <li>Fix unstable formatting with semicolons and arithmetic expressions (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2817"">#2817</a>)</li>; <li>Fix unstable formatting around magic trailing comma (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2572"">#2572</a>)</li>; </ul>; <h3>Parser</h3>; <ul>; <li>Fix mapping cases that contain as-expressions, like <code>case {&quot;key&quot;: 1 | 2 ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11468:8664,depend,dependabot,8664,https://hail.is,https://github.com/hail-is/hail/pull/11468,1,['depend'],['dependabot']
Integrability,"w stability policy</a>.</p>; <h3>Highlights</h3>; <ul>; <li>Remove Python 2 support (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2740"">#2740</a>)</li>; <li>Introduce the <code>--preview</code> flag (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2752"">#2752</a>)</li>; </ul>; <h3>Style</h3>; <ul>; <li>Deprecate <code>--experimental-string-processing</code> and move the functionality under <code>--preview</code> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2789"">#2789</a>)</li>; <li>For stubs, one blank line between class attributes and methods is now kept if there's at least one pre-existing blank line (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2736"">#2736</a>)</li>; <li>Black now normalizes string prefix order (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2297"">#2297</a>)</li>; <li>Remove spaces around power operators if both operands are simple (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2726"">#2726</a>)</li>; <li>Work around bug that causes unstable formatting in some cases in the presence of the magic trailing comma (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2807"">#2807</a>)</li>; <li>Use parentheses for attribute access on decimal float and int literals (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2799"">#2799</a>)</li>; <li>Don't add whitespace for attribute access on hexadecimal, binary, octal, and complex literals (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2799"">#2799</a>)</li>; <li>Treat blank lines in stubs the same inside top-level if statements (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2820"">#2820</a>)</li>; <li>Fix unstable formatting with semicolons and arithmetic expressions (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2817"">#2817</a>)</li>; <li>Fix unstable formatting around magic trailing comma (<a href=""https://github-",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11468:1463,depend,dependabot,1463,https://hail.is,https://github.com/hail-is/hail/pull/11468,1,['depend'],['dependabot']
Integrability,"w.nuget.org/packages/Apache.Avro/1.11.0"">https://www.nuget.org/packages/Apache.Avro/1.11.0</a></li>; <li>Java: from Maven Central,</li>; <li>Javascript: <a href=""https://www.npmjs.com/package/avro-js/v/1.11.0"">https://www.npmjs.com/package/avro-js/v/1.11.0</a></li>; <li>Perl: <a href=""https://metacpan.org/release/Avro"">https://metacpan.org/release/Avro</a></li>; <li>Python 3: <a href=""https://pypi.org/project/avro/1.11.0"">https://pypi.org/project/avro/1.11.0</a></li>; <li>Ruby: <a href=""https://rubygems.org/gems/avro/versions/1.11.0"">https://rubygems.org/gems/avro/versions/1.11.0</a></li>; </ul>; <p>Thanks to everyone for contributing!</p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/apache/avro/compare/release-1.10.0...release-1.11.0"">compare view</a></li>; </ul>; </details>; <br />. Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11475:3144,depend,dependabot,3144,https://hail.is,https://github.com/hail-is/hail/pull/11475,1,['depend'],['dependabot']
Integrability,"w.sphinx-doc.org/en/master/changes.html</a></p>; <h2>v4.4.0</h2>; <p>Changelog: <a href=""https://www.sphinx-doc.org/en/master/changes.html"">https://www.sphinx-doc.org/en/master/changes.html</a></p>; <h2>v4.3.1</h2>; <p>No release notes provided.</p>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/sphinx-doc/sphinx/blob/5.x/CHANGES"">sphinx's changelog</a>.</em></p>; <blockquote>; <h1>Release 5.0.0 (released May 30, 2022)</h1>; <h2>Dependencies</h2>; <p>5.0.0 b1</p>; <ul>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10164"">#10164</a>: Support <code>Docutils 0.18</code>_. Patch by Adam Turner.</li>; </ul>; <p>.. _Docutils 0.18: <a href=""https://docutils.sourceforge.io/RELEASE-NOTES.html#release-0-18-2021-10-26"">https://docutils.sourceforge.io/RELEASE-NOTES.html#release-0-18-2021-10-26</a></p>; <h2>Incompatible changes</h2>; <p>5.0.0 b1</p>; <ul>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10031"">#10031</a>: autosummary: <code>sphinx.ext.autosummary.import_by_name()</code> now raises; <code>ImportExceptionGroup</code> instead of <code>ImportError</code> when it failed to import; target object. Please handle the exception if your extension uses the; function to import Python object. As a workaround, you can disable the; behavior via <code>grouped_exception=False</code> keyword argument until v7.0.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/9962"">#9962</a>: texinfo: Customizing styles of emphasized text via <code>@definfoenclose</code>; command was not supported because the command was deprecated since texinfo 6.8</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/2068"">#2068</a>: :confval:<code>intersphinx_disabled_reftypes</code> has changed default value; from an empty list to <code>['std:doc']</code> as avoid too surprising silent; intersphinx resolutions.; To migr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11871:1491,depend,dependabot,1491,https://hail.is,https://github.com/hail-is/hail/pull/11871,1,['depend'],['dependabot']
Integrability,"w</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=certifi&package-manager=pip&previous-version=2023.5.7&new-version=2023.7.22)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/hail-is/hail/network/alerts). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13298:2514,depend,dependabot,2514,https://hail.is,https://github.com/hail-is/hail/pull/13298,48,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability,"w</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=cryptography&package-manager=pip&previous-version=38.0.4&new-version=39.0.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/hail-is/hail/network/alerts). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12668:7434,depend,dependabot,7434,https://hail.is,https://github.com/hail-is/hail/pull/12668,32,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability,"w</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=cryptography&package-manager=pip&previous-version=40.0.2&new-version=41.0.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/hail-is/hail/network/alerts). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13141:5689,depend,dependabot,5689,https://hail.is,https://github.com/hail-is/hail/pull/13141,24,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability,"w</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=cryptography&package-manager=pip&previous-version=41.0.1&new-version=41.0.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/hail-is/hail/network/alerts). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13244:2973,depend,dependabot,2973,https://hail.is,https://github.com/hail-is/hail/pull/13244,24,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability,"w</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=cryptography&package-manager=pip&previous-version=41.0.2&new-version=41.0.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself); You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/hail-is/hail/network/alerts). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13357:3231,depend,dependabot,3231,https://hail.is,https://github.com/hail-is/hail/pull/13357,24,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability,"w</li>; <li><a href=""https://github.com/PyCQA/mccabe/commit/e864119dca577a38552b0d32c66d0ef3dc7779e0""><code>e864119</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pycqa/mccabe/issues/86"">#86</a> from cclauss/patch-1</li>; <li>Additional commits viewable in <a href=""https://github.com/pycqa/mccabe/compare/0.6.1...0.7.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=mccabe&package-manager=pip&previous-version=0.6.1&new-version=0.7.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12449:2788,Depend,Dependabot,2788,https://hail.is,https://github.com/hail-is/hail/pull/12449,1,['Depend'],['Dependabot']
Integrability,"w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SPHINX-5812109](https://snyk.io/vuln/SNYK-PYTHON-SPHINX-5812109) | `sphinx:` <br> `1.8.6 -> 3.3.0` <br> | No | Proof of Concept ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | Open Redirect <br/>[SNYK-PYTHON-TORNADO-5537286](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5537286) | `tornado:` <br> `5.1.1 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-5840803](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5840803) | `tornado:` <br> `5.1.1 -> 6.3.3` <br> | No | No Known Exploit . Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI4OGE5ZjRlMS0yNGNjLTQ5NDYtYWYwYy03OWJlZTNkNTg3YzUiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6Ijg4YTlmNGUxLTI0Y2MtNDk0Ni1hZjBjLTc5YmVlM2Q1ODdjNSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/20159ae6-a5aa-42fa-845a-c89f5bcbf999?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13835:7440,depend,dependency,7440,https://hail.is,https://github.com/hail-is/hail/pull/13835,2,['depend'],"['dependencies', 'dependency']"
Integrability,"w_20,h_20/v1561977819/icon/m.png ""medium severity"") | Regular Expression Denial of Service (ReDoS) <br/>[SNYK-PYTHON-SPHINX-5812109](https://snyk.io/vuln/SNYK-PYTHON-SPHINX-5812109) | `sphinx:` <br> `1.8.6 -> 3.3.0` <br> | No | Proof of Concept ; ![low severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/l.png ""low severity"") | Open Redirect <br/>[SNYK-PYTHON-TORNADO-5537286](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5537286) | `tornado:` <br> `5.1.1 -> 6.3.3` <br> | No | No Known Exploit ; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | HTTP Request Smuggling <br/>[SNYK-PYTHON-TORNADO-5840803](https://snyk.io/vuln/SNYK-PYTHON-TORNADO-5840803) | `tornado:` <br> `5.1.1 -> 6.3.3` <br> | No | No Known Exploit . Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiJmY2JlODM3Mi04NzYwLTQyYjEtOGU0ZS1jZDZlNGZkNjNhYzYiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6ImZjYmU4MzcyLTg3NjAtNDJiMS04ZTRlLWNkNmU0ZmQ2M2FjNiJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/fa47fca0-549b-41a3-8bf7-bcda4ca9a617?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13866:7466,depend,dependency,7466,https://hail.is,https://github.com/hail-is/hail/pull/13866,2,['depend'],"['dependencies', 'dependency']"
Integrability,"wable in <a href=""https://github.com/elastic/elasticsearch-hadoop/compare/v7.17.1...v8.4.3"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=org.elasticsearch:elasticsearch-spark-20_2.12&package-manager=gradle&previous-version=7.17.1&new-version=8.4.3)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12358:8128,Depend,Dependabot,8128,https://hail.is,https://github.com/hail-is/hail/pull/12358,17,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability,"was not passing the kwsyntax argument.</li>; </ul>; <h2>5.0.9 (2021-05-16)</h2>; <p>Fixed a test breaking PyPy. Restored support for Sphinx.</p>; <h2>5.0.8 (2021-05-15)</h2>; <p>Made the decorator module more robust when decorating builtin functions; lacking dunder attributes, like <code>dict.__setitem__</code>.</p>; <h2>5.0.7 (2021-04-14)</h2>; <p>The decorator module was not passing correctly the defaults inside the; <code>*args</code> tuple, thanks to Dan Shult for the fix. Also fixed some mispellings; in the documentation and integrated codespell in the CI, thanks to; Christian Clauss.</p>; <h2>5.0.6 (2021-04-08)</h2>; <p>The decorator module was not copying the <strong>module</strong> attribute anymore.; Thanks to Nikolay Markov for the notice.</p>; <h2>5.0.5 (2021-04-04)</h2>; <p>Dropped support for Python &lt; 3.5 with a substantial simplification of; the code base (now building a decorator does not require calling &quot;exec&quot;).; Added a way to mimic functools.wraps-generated decorators.; Ported the Continuous Integration from Travis to GitHub.</p>; <h2>4.4.2 (2020-02-29)</h2>; <p>Sylvan Mosberger (<a href=""https://github.com/Infinisil"">https://github.com/Infinisil</a>) contributed a patch to; some doctests that were breaking on NixOS.; John Vandenberg (<a href=""https://github.com/jayvdb"">https://github.com/jayvdb</a>) made a case for removing the usage</p>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/micheles/decorator/commit/ad013a2c1ad7969963acf3dea948632be387f5a0""><code>ad013a2</code></a> Updated changelog and bumped version to 5.1.1</li>; <li><a href=""https://github.com/micheles/decorator/commit/5a2023203948ff297cc2e482aa66f84d75d1d1f8""><code>5a20232</code></a> Fixed implementation of decorator_apply</li>; <li><a href=""https://github.com/micheles/decorator/commit/9cf8151de8fd26551cb43288b2010965ad346839""><code>9cf8151</code></a> Merge pull r",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11490:2109,wrap,wraps-generated,2109,https://hail.is,https://github.com/hail-is/hail/pull/11490,1,['wrap'],['wraps-generated']
Integrability,"was not passing the kwsyntax argument.</li>; </ul>; <h2>5.0.9 (2021-05-16)</h2>; <p>Fixed a test breaking PyPy. Restored support for Sphinx.</p>; <h2>5.0.8 (2021-05-15)</h2>; <p>Made the decorator module more robust when decorating builtin functions; lacking dunder attributes, like <code>dict.__setitem__</code>.</p>; <h2>5.0.7 (2021-04-14)</h2>; <p>The decorator module was not passing correctly the defaults inside the; <code>*args</code> tuple, thanks to Dan Shult for the fix. Also fixed some mispellings; in the documentation and integrated codespell in the CI, thanks to; Christian Clauss.</p>; <h2>5.0.6 (2021-04-08)</h2>; <p>The decorator module was not copying the <strong>module</strong> attribute anymore.; Thanks to Nikolay Markov for the notice.</p>; <h2>5.0.5 (2021-04-04)</h2>; <p>Dropped support for Python &lt; 3.5 with a substantial simplification of; the code base (now building a decorator does not require calling &quot;exec&quot;).; Added a way to mimic functools.wraps-generated decorators.; Ported the Continuous Integration from Travis to GitHub.</p>; <h2>4.4.2 (2020-02-29)</h2>; <p>Sylvan Mosberger (<a href=""https://github.com/Infinisil"">https://github.com/Infinisil</a>) contributed a patch to; some doctests that were breaking on NixOS.; John Vandenberg (<a href=""https://github.com/jayvdb"">https://github.com/jayvdb</a>) made a case for removing the usage</p>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/micheles/decorator/commits/5.1.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=decorator&package-manager=pip&previous-version=4.4.0&new-version=5.1.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any co",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11799:2078,wrap,wraps-generated,2078,https://hail.is,https://github.com/hail-is/hail/pull/11799,1,['wrap'],['wraps-generated']
Integrability,"we merge; however, this flexibility was; useful during development. The JVMEntryway will eventually be useful because we will keep a ClassLoader full of a bunch of; JIT-optimized Hail classes. I did not include that in this PR because we need to finish eliminating; global state used by Hail. Currently, two executions would try to re-use compiled class names for; different code, leading to very weird errors. # Changes to File Systems. Hail has three four file system interfaces:. | File System Interface | Public | Language | Async |; | ----------------------- | ------ | -------- | ----- |; | hail.utils.hadoop_utils | Yes | Python | no |; | hail.fs | Yes | Python | no |; | hailtop.aiotools.fs | No | Python | yes |; | is.hail.io.fs | No | Scala | no |. `hail.fs` is technically in the public API (via `hl.current_backend().fs`), but I doubt anyone uses; it. `hail.utils.hadoop_utils` is a shim over `hail.fs`, there are no direct concrete implementations of; it. This PR adds `hail.fs.RouterFS` to `hail.fs`, a synchronous wrapper around; `hailtop.aiotools.fs.AsyncRouterFS`. A ""router"" file system is one which operates on URLs instead of; paths. It uses the URL's protocol to determine which concrete file system to use. For example, a; router fs can `open` both `gs://danking/abc` and `s3a://danking/abc`. Each Hail Query Python Backend is associated with one file system class. This PR associates the; ServiceBackend with `RouterFS`, enabling `hl.current_backend().fs.open`, `hl.hadoop_open`, etc. to; read from S3, GCS, ABS, and the local file system. We should deprecate `hail.utils.hadoop_utils`; because it is not Hadoop-specific. We should instead advertise the class-based `hail.fs` or create a; new function-based interface (e.g. `hl.fs.open(...)`. # Test Clean-up. The Hail Query local and spark tests should now work in Azure. I moved all the `hail.fs` and; `hailtop.aiotools.fs` tests into two build.yaml steps: `test_hail_python_fs` and; `test_hail_scala_fs`. These tests are exha",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11194:4823,Rout,RouterFS,4823,https://hail.is,https://github.com/hail-is/hail/pull/11194,1,['Rout'],['RouterFS']
Integrability,"we; timeout substantially more frequently. I have observed this myself on my laptop. Just this; morning I saw it happen to Daniel. 2. When using an `aiohttp.AsyncIterablePayload`, it is *critical* to always check if the coroutine; which actually writes to GCS (which is stashed in the variable `request_task`) is still; alive. In the current `main`, we do not do this which causes hangs (in particular the timeout; exceptions are never thrown ergo we never retry). To understand the second problem, you must first recall how writing works in aiogoogle. There are; two Tasks and an `asyncio.Queue`. The terms ""writer"" and ""reader"" are somewhat confusing, so let's; use left and right. The left Task has the owning reference to both the source ""file"" and the; destination ""file"". In particular, it is the *left* Task which closes both ""files"". Moreover, the; left Task reads chunks from the source file and places those chunks on the `asyncio.Queue`. The; right Task takes chunks off the queue and writes those chunks to the destination file. This situation can go awry in two ways. First, if the right Task encounters any kind of failure, it will stop taking chunks off of the; queue. When the queue (which has a size limit of one) is full, the left Task will hang. The system; is stuck. The left Task will wait forever for the right Task to empty the queue. The second scenario is exactly the same except that the left Task is trying to add the ""stop""; message to the queue rather than a chunk. In either case, it is critical that the left Task waits simultaneously on the queue operation *and*; on the right Task completing. If the right Task has died, no further writes can occur and the left; Task must raise an exception. In the first scenario, we do not observe the right Task's exception; because that will be done when we close the `InsertObjectStream` (which represents the destination; ""file""). ---. I also added several types, assertions, and a few missing `async with ... as resp:` blocks.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11830:1672,message,message,1672,https://hail.is,https://github.com/hail-is/hail/pull/11830,1,['message'],['message']
Integrability,wering.LowerOrInterpretNonCompilablePass$.transform(LoweringPass.scala:69); at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:16); at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:16); at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:14); at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:13); at is.hail.expr.ir.lowering.LowerOrInterpretNonCompilablePass$.apply(LoweringPass.scala:64); at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:15); at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:13); at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36); at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:38); at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:13); at is.hail.expr.ir.CompileAndEvaluate$._apply(CompileAndEvaluate.scala:47); at is.hail.backend.spark.SparkBackend._execute(SparkBackend.scala:416); at is.hail.backend.spark.SparkBackend.$anonfun$executeEncode$2(SparkBackend.scala:452); at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:70); at is.hail.utils.package$.using(package.scala:646); at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:70); at is.hail.utils.package$.using(package.scala:646); at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:17); at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:59); at is.hail.backend.spark.SparkBackend.withExecuteContext(SparkBackend.scala:310); at is.hail.backend.spark.SparkBackend.$anonfun$executeEncode$1(SparkBackend.scala:449); at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:52); at is.hail.backend.spark.SparkBacken,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12280:4451,Wrap,WrappedArray,4451,https://hail.is,https://github.com/hail-is/hail/issues/12280,1,['Wrap'],['WrappedArray']
Integrability,"when <em>Black</em> is using user-level config (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2861"">#2861</a>)</li>; </ul>; <h3>Packaging</h3>; <ul>; <li>Fix Black to work with Click 8.1.0 (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2966"">#2966</a>)</li>; <li>On Python 3.11 and newer, use the standard library's <code>tomllib</code> instead of <code>tomli</code>; (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2903"">#2903</a>)</li>; <li><code>black-primer</code>, the deprecated internal devtool, has been removed and copied to a; <a href=""https://github.com/cooperlees/black-primer"">separate repository</a> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2924"">#2924</a>)</li>; </ul>; <h3>Parser</h3>; <ul>; <li>Black can now parse starred expressions in the target of <code>for</code> and <code>async for</code>; statements, e.g <code>for item in *items_1, *items_2: pass</code> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2879"">#2879</a>).</li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/psf/black/blob/main/CHANGES.md"">black's changelog</a>.</em></p>; <blockquote>; <h2>22.3.0</h2>; <h3>Preview style</h3>; <ul>; <li>Code cell separators <code>#%%</code> are now standardised to <code># %%</code> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2919"">#2919</a>)</li>; <li>Remove unnecessary parentheses from <code>except</code> statements (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2939"">#2939</a>)</li>; <li>Remove unnecessary parentheses from tuple unpacking in <code>for</code> loops (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2945"">#2945</a>)</li>; <li>Avoid magic-trailing-comma in single-element subscripts (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2942"">#2942</a>)</li>; </ul>; <h3>Configuration</h3>; <ul>; <li>Do not ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11696:3118,depend,dependabot,3118,https://hail.is,https://github.com/hail-is/hail/pull/11696,1,['depend'],['dependabot']
Integrability,"when <em>Black</em> is using user-level config (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2861"">#2861</a>)</li>; </ul>; <h3>Packaging</h3>; <ul>; <li>Fix Black to work with Click 8.1.0 (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2966"">#2966</a>)</li>; <li>On Python 3.11 and newer, use the standard library's <code>tomllib</code> instead of <code>tomli</code>; (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2903"">#2903</a>)</li>; <li><code>black-primer</code>, the deprecated internal devtool, has been removed and copied to a; <a href=""https://github.com/cooperlees/black-primer"">separate repository</a> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2924"">#2924</a>)</li>; </ul>; <h3>Parser</h3>; <ul>; <li>Black can now parse starred expressions in the target of <code>for</code> and <code>async for</code>; statements, e.g <code>for item in *items_1, *items_2: pass</code> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2879"">#2879</a>).</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/psf/black/commit/ae2c0758c9e61a385df9700dc9c231bf54887041""><code>ae2c075</code></a> Prepare release 22.3.0 (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2968"">#2968</a>)</li>; <li><a href=""https://github.com/psf/black/commit/e9681a40dcb3d38b56b301d811bb1c55201fd97e""><code>e9681a4</code></a> Fix _unicodefun patch code for Click 8.1.0 (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2966"">#2966</a>)</li>; <li><a href=""https://github.com/psf/black/commit/ac7402cbf6a0deb5c74e9abcffc5bd7b1148fda5""><code>ac7402c</code></a> Bump sphinx from 4.4.0 to 4.5.0 in /docs (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2959"">GH-2959</a>)</li>; <li><a href=""https://github.com/psf/black/commit/f239d227c003c52126239e1b9a37c36c2b2b8305""><code>f239d22</code></a> Enforce no formatting changes f",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11696:6267,depend,dependabot,6267,https://hail.is,https://github.com/hail-is/hail/pull/11696,1,['depend'],['dependabot']
Integrability,"when requires.txt is empty. Ref <a href=""https://github-redirect.dependabot.com/python/importlib_metadata/issues/367"">#367</a>.</li>; <li><a href=""https://github.com/python/importlib_metadata/commit/f22eb5b60adbe158e458614ea0380a9071c39347""><code>f22eb5b</code></a> Ignore flake8/black warnings with pytest 7.0.1 (jaraco/skeleton#58)</li>; <li><a href=""https://github.com/python/importlib_metadata/commit/a9ea801a43fc62a569cf60e1c28e477ba510d8a0""><code>a9ea801</code></a> Require jaraco.packaging 9 adding compatibility for projects with no setup.py...</li>; <li>Additional commits viewable in <a href=""https://github.com/python/importlib_metadata/compare/0.1...v4.11.2"">compare view</a></li>; </ul>; </details>; <br />. Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11525:5114,Depend,Dependabot,5114,https://hail.is,https://github.com/hail-is/hail/pull/11525,1,['Depend'],['Dependabot']
Integrability,"which need fixing.</li>; <li><a href=""https://github.com/python-jsonschema/jsonschema/commit/095a009acc1938caf9596085d5581e7196021f66""><code>095a009</code></a> Squashed 'json/' changes from cf78d97d0..f0f619d19</li>; <li><a href=""https://github.com/python-jsonschema/jsonschema/commit/76b2e597d691e4cf5e9ebb7f3d1cff4f5da0115a""><code>76b2e59</code></a> Merge commit '095a009acc1938caf9596085d5581e7196021f66'</li>; <li><a href=""https://github.com/python-jsonschema/jsonschema/commit/aeecae37b17b430c328d3c3e15bec90d30c8848b""><code>aeecae3</code></a> Squashed 'json/' changes from d40b3e62f..cf78d97d0</li>; <li><a href=""https://github.com/python-jsonschema/jsonschema/commit/2f3a79c61176f60c9244d07fa8afb728218270ff""><code>2f3a79c</code></a> Merge commit 'aeecae37b17b430c328d3c3e15bec90d30c8848b'</li>; <li>Additional commits viewable in <a href=""https://github.com/python-jsonschema/jsonschema/compare/v4.6.0...v4.6.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=jsonschema&package-manager=pip&previous-version=4.6.0&new-version=4.6.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge`",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11981:3967,Depend,Dependabot,3967,https://hail.is,https://github.com/hail-is/hail/pull/11981,2,"['Depend', 'depend']","['Dependabot', 'dependabot-badges']"
Integrability,"which will retry transient errors. router-resolver is part of the infrastructure, so I will hand-deploy once you're happy with this.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7859:35,rout,router-resolver,35,https://hail.is,https://github.com/hail-is/hail/pull/7859,1,['rout'],['router-resolver']
Integrability,"wit/nest_asyncio/commit/616d9a5e15d8d75e3343422778e49af2e9ac80ea""><code>616d9a5</code></a> Patch asyncio.get_event_loop to not require a running loop, fixes <a href=""https://github-redirect.dependabot.com/erdewit/nest_asyncio/issues/70"">#70</a></li>; <li>See full diff in <a href=""https://github.com/erdewit/nest_asyncio/compare/v1.5.4...v1.5.5"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=nest-asyncio&package-manager=pip&previous-version=1.5.4&new-version=1.5.5)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12209:1396,Depend,Dependabot,1396,https://hail.is,https://github.com/hail-is/hail/pull/12209,1,['Depend'],['Dependabot']
Integrability,"wit/nest_asyncio/commit/616d9a5e15d8d75e3343422778e49af2e9ac80ea""><code>616d9a5</code></a> Patch asyncio.get_event_loop to not require a running loop, fixes <a href=""https://github-redirect.dependabot.com/erdewit/nest_asyncio/issues/70"">#70</a></li>; <li>See full diff in <a href=""https://github.com/erdewit/nest_asyncio/compare/v1.5.4...v1.5.6"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=nest-asyncio&package-manager=pip&previous-version=1.5.4&new-version=1.5.6)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12303:2324,Depend,Dependabot,2324,https://hail.is,https://github.com/hail-is/hail/pull/12303,1,['Depend'],['Dependabot']
Integrability,"with `eq`. That way `freshName` becomes just `new Name()`, with stronger guarantees that the new name doesn't occur anywhere in the current IR, without needing to maintain global state as we do now.; * get rid of `NormalizeNames`, instead enforcing the global uniqueness of names as a basic invariant of the IR (typecheck could also check this invariant); * keep a string in the `Name`, but no longer require it to be unique. Instead it's just a suggestion for how to show the name in printouts, adding a uniqueifying suffix as needed. With `NormalizeNames` gone, this would let us preserve meaningful variable names further in the lowering pipeline.; * possibly keep other state in the `Name`, for example to allow a more efficient implementation of environments, similar to the `mark` state on `BaseIR`. This is obviously a large change, but there are only a few conceptual pieces (appologies for not managing to separate these out):; * attempt to minimize the number of locations in which the `Name` constructor is called, to make future refactorings easier; * add `freshName()`, which just wraps `genUID()`, returning a `Name`; * convert IR construction to use the convenience methods in `ir.package`, which take scala lambdas to represent blocks with bound variables, instead of manually creating new variable names; * replace uses of the magic constant variable names (`row`, `va`, `sa`, `g`, `global`) with constants (`TableIR.{rowName, globalName}`, `MatrixIR.{rowName, colName, entryName, globalName}`); * the above changes modified the names we use for bound variables in many places. That shouldn't matter, but it cought a couple bugs where it did.; * `NormalizeNames` optionally allows the IR to contain free variables. But it didn't do anything to ensure the newly generated variable names are distinct from any contained free variables. Thus it was possible to rename a bound variable to mistakenly capture a contained free variable. I've fixed that.; * `SimplifySuite` compared simplifi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14547:1425,wrap,wraps,1425,https://hail.is,https://github.com/hail-is/hail/pull/14547,1,['wrap'],['wraps']
Integrability,"with early feedback</li>; <li>Additional commits viewable in <a href=""https://github.com/urllib3/urllib3/compare/1.26.9...1.26.12"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=urllib3&package-manager=pip&previous-version=1.26.9&new-version=1.26.12)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12140:5481,Depend,Dependabot,5481,https://hail.is,https://github.com/hail-is/hail/pull/12140,17,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability,"with the proxy.</p>; <p>In cases where Requests receives a redirect response, it previously reattached; the <code>Proxy-Authorization</code> header incorrectly, resulting in the value being; sent through the tunneled connection to the destination server. Users who rely on; defining their proxy credentials in the URL are <em>strongly</em> encouraged to upgrade; to Requests 2.31.0+ to prevent unintentional leakage and rotate their proxy; credentials once the change has been fully deployed.</p>; <p>Users who do not use a proxy or do not supply their proxy credentials through; the user information portion of their proxy URL are not subject to this; vulnerability.</p>; <p>Full details can be read in our <a href=""https://github.com/psf/requests/security/advisories/GHSA-j8r2-6x86-q33q"">Github Security Advisory</a>; and <a href=""https://nvd.nist.gov/vuln/detail/CVE-2023-32681"">CVE-2023-32681</a>.</p>; </li>; </ul>; <h2>v2.30.0</h2>; <h2>2.30.0 (2023-05-03)</h2>; <p><strong>Dependencies</strong></p>; <ul>; <li>; <p>⚠️ Added support for urllib3 2.0. ⚠️</p>; <p>This may contain minor breaking changes so we advise careful testing and; reviewing <a href=""https://urllib3.readthedocs.io/en/latest/v2-migration-guide.html"">https://urllib3.readthedocs.io/en/latest/v2-migration-guide.html</a>; prior to upgrading.</p>; <p>Users who wish to stay on urllib3 1.x can pin to <code>urllib3&lt;2</code>.</p>; </li>; </ul>; <h2>v2.29.0</h2>; <h2>2.29.0 (2023-04-26)</h2>; <p><strong>Improvements</strong></p>; <ul>; <li>Requests now defers chunked requests to the urllib3 implementation to improve; standardization. (<a href=""https://redirect.github.com/psf/requests/issues/6226"">#6226</a>)</li>; <li>Requests relaxes header component requirements to support bytes/str subclasses. (<a href=""https://redirect.github.com/psf/requests/issues/6356"">#6356</a>)</li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/psf/requests/blob/mai",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13091:1743,Depend,Dependencies,1743,https://hail.is,https://github.com/hail-is/hail/pull/13091,6,['Depend'],['Dependencies']
Integrability,"wnload-task/commit/4ff0ff0e63e0dd45f231990d0dcebffde6e6b709""><code>4ff0ff0</code></a> Update dependencies</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/a1858b494b5f3a51ccef7580c243c6dfdf520731""><code>a1858b4</code></a> Merge pull request <a href=""https://redirect.github.com/michel-kraemer/gradle-download-task/issues/295"">#295</a> from michel-kraemer/dependabot/npm_and_yarn/screencas...</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/c1e212c0fb41b3ea9185a9ea463fb1ea7142f748""><code>c1e212c</code></a> Add integration tests for Gradle 8.0 and 8.0.1</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/304f68e25f53633a92a4d2d6ce003a4986929503""><code>304f68e</code></a> Fix type inference issue</li>; <li>Additional commits viewable in <a href=""https://github.com/michel-kraemer/gradle-download-task/compare/5.3.1...5.4.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=de.undercouch.download&package-manager=gradle&previous-version=5.3.1&new-version=5.4.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12893:2799,Depend,Dependabot,2799,https://hail.is,https://github.com/hail-is/hail/pull/12893,2,"['Depend', 'depend']","['Dependabot', 'dependabot-badges']"
Integrability,"wnloads/hadoop"">https://elastic.co/downloads/hadoop</a>; Release notes: <a href=""https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.0.html"">https://www.elastic.co/guide/en/elasticsearch/hadoop/8.5/eshadoop-8.5.0.html</a></p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/da4f3c3f209aea47d69c4faf90029a6933bd3a60""><code>da4f3c3</code></a> [DOCS] Add 8.5.3 release notes (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2045"">#2045</a>) (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2050"">#2050</a>)</li>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/79d592abdce1cd90845d153afab8b66069e2a172""><code>79d592a</code></a> [DOCS] Add 8.5.2 release notes (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2042"">#2042</a>) (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2049"">#2049</a>)</li>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/712f518822ff281abdd6f83c2e0ea97857dbf6ba""><code>712f518</code></a> [DOCS] Add 8.5.1 release notes (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2040"">#2040</a>)</li>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/0a8e0bca839408ba7cdd4e1e4ef669894f29e96f""><code>0a8e0bc</code></a> [DOCS] Add 8.5.0 release notes (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2032"">#2032</a>)</li>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/4d09926f840998a20d4f45380723d2d77b46544a""><code>4d09926</code></a> [DOCS] Add 8.4.3 release notes (<a href=""https://github-redirect.dependabot.com/elastic/elasticsearch-hadoop/issues/2028"">#2028</a>)</li>; <li><a href=""https://github.com/elastic/elasticsearch-hadoop/commit/d498aa068ef552aef9de3325e9d105611e5adbba"">",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12601:2687,depend,dependabot,2687,https://hail.is,https://github.com/hail-is/hail/pull/12601,1,['depend'],['dependabot']
Integrability,"work properly on asyncio!</p>; </li>; <li>; <p>Fixed race condition in <code>Lock</code> and <code>Semaphore</code> classes when a task waiting on <code>acquire()</code>; is cancelled while another task is waiting to acquire the same primitive; (<code>[#387](https://github.com/agronholm/anyio/issues/387) &lt;https://github.com/agronholm/anyio/issues/387&gt;</code>_)</p>; </li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/agronholm/anyio/commit/787cb0c2e53c2a3307873d202fbd49dc5eac4e96""><code>787cb0c</code></a> Pinned trio to &lt; 0.22 on AnyIO 3.x</li>; <li><a href=""https://github.com/agronholm/anyio/commit/7cc3cf8cdb58f3b6df6c4fe21e9daa11537c1844""><code>7cc3cf8</code></a> Updated pre-commit modules</li>; <li>See full diff in <a href=""https://github.com/agronholm/anyio/compare/3.6.1...3.6.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=anyio&package-manager=pip&previous-version=3.6.1&new-version=3.6.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12362:3779,Depend,Dependabot,3779,https://hail.is,https://github.com/hail-is/hail/pull/12362,2,"['Depend', 'depend']","['Dependabot', 'dependabot-badges']"
Integrability,"workflows</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/b546879539200ec4128bcc6d0ed911ebf28bb3cb""><code>b546879</code></a> Bump version</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/d568b2f4f7cca743fcbf70814d15602d8129b790""><code>d568b2f</code></a> Bump to 7.0.0 final</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/ff79edf353f5cc6e02036f58e0295dc704c5e681""><code>ff79edf</code></a> Remove <code>jsdump</code> references post removal</li>; <li>Additional commits viewable in <a href=""https://github.com/sphinx-doc/sphinx/compare/v6.2.1...v7.0.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=sphinx&package-manager=pip&previous-version=6.2.1&new-version=7.0.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). You can trigger a rebase of this PR by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13054:7072,depend,dependabot,7072,https://hail.is,https://github.com/hail-is/hail/pull/13054,1,['depend'],['dependabot']
Integrability,wrap ApplyIR when emitting,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3847:0,wrap,wrap,0,https://hail.is,https://github.com/hail-is/hail/pull/3847,1,['wrap'],['wrap']
Integrability,wrap more things in their own methods to get around function size limits,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3308:0,wrap,wrap,0,https://hail.is,https://github.com/hail-is/hail/pull/3308,1,['wrap'],['wrap']
Integrability,wrap pop operations,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2532:0,wrap,wrap,0,https://hail.is,https://github.com/hail-is/hail/pull/2532,1,['wrap'],['wrap']
Integrability,wrap vep error,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4405:0,wrap,wrap,0,https://hail.is,https://github.com/hail-is/hail/pull/4405,1,['wrap'],['wrap']
Integrability,"ws(); ```. ### What went wrong (all error messages here, including the full java stack trace):. So I was distracted and used `annotate_rows` instead of `annotate_cols` and I got what seems to be an 0.1 error message:. ```; ---------------------------------------------------------------------------; AssertionError Traceback (most recent call last); <ipython-input-44-7491b514f674> in <module>; 3 gq_stats=hl.agg.group_by(qc_mt.qc_platform, hl.agg.stats(qc_mt.GQ)),; 4 callstats=hl.agg.group_by(qc_mt.qc_platform, hl.agg.call_stats(qc_mt.GT, qc_mt.alleles)),; ----> 5 call_rate=hl.agg.group_by(qc_mt.qc_platform, hl.agg.fraction(hl.is_defined(qc_mt.GQ))); 6 ).rows(); 7 # qc_ht = qc_ht.key_by('locus','alleles'). </opt/conda/lib/python3.6/site-packages/decorator.py:decorator-gen-976> in annotate_cols(self, **named_exprs). /home/hail/hail.zip/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 559 def wrapper(__original_func, *args, **kwargs):; 560 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 561 return __original_func(*args_, **kwargs_); 562 ; 563 return wrapper. /home/hail/hail.zip/hail/matrixtable.py in annotate_cols(self, **named_exprs); 995 caller = ""MatrixTable.annotate_cols""; 996 check_annotate_exprs(caller, named_exprs, self._col_indices); --> 997 return self._select_cols(caller, self.col.annotate(**named_exprs)); 998 ; 999 @typecheck_method(named_exprs=expr_any). </opt/conda/lib/python3.6/site-packages/decorator.py:decorator-gen-1038> in _select_cols(self, caller, col, new_key). /home/hail/hail.zip/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 559 def wrapper(__original_func, *args, **kwargs):; 560 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 561 return __original_func(*args_, **kwargs_); 562 ; 563 return wrapper. /home/hail/hail.zip/hail/matrixtable.py in _select_cols(self, caller, col, new_key); 3055 analyze(caller, col, self._co",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5415:1522,wrap,wrapper,1522,https://hail.is,https://github.com/hail-is/hail/issues/5415,3,['wrap'],['wrapper']
Integrability,"wstest-warning</li>; <li><a href=""https://github.com/tornadoweb/tornado/commit/f5a1d5c7e235ad8860a4c2c5f259a43692bcbaab""><code>f5a1d5c</code></a> ci: Only run pypi actions from the main repo</li>; <li><a href=""https://github.com/tornadoweb/tornado/commit/1849ef6c48415ef8f5fecbd47d9f68225588507c""><code>1849ef6</code></a> test: Close a websocket client that causes occasional test failures</li>; <li><a href=""https://github.com/tornadoweb/tornado/commit/fcb09eba4bd45c2ebfb6356a38acdb3b4450c0d8""><code>fcb09eb</code></a> Merge pull request <a href=""https://redirect.github.com/tornadoweb/tornado/issues/3256"">#3256</a> from bdarnell/build-workflow-qemu</li>; <li><a href=""https://github.com/tornadoweb/tornado/commit/c3d50f41a29cda5f76031c60cf7902b175b79479""><code>c3d50f4</code></a> ci: Update setup-qemu-action version</li>; <li>See full diff in <a href=""https://github.com/tornadoweb/tornado/compare/v6.3.1...v6.3.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=tornado&package-manager=pip&previous-version=6.3.1&new-version=6.3.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` wi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13120:2750,Depend,Dependabot,2750,https://hail.is,https://github.com/hail-is/hail/pull/13120,4,"['Depend', 'depend']","['Dependabot', 'dependabot-badges']"
Integrability,"wt/issues/697"">#697</a>)</li>; <li><a href=""https://github.com/jpadilla/pyjwt/commit/258d7bab0ecb86be91738ac1e23744429280acd1""><code>258d7ba</code></a> Use timezone package as Python 3.5+ is required (<a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/issues/694"">#694</a>)</li>; <li><a href=""https://github.com/jpadilla/pyjwt/commit/a988e1a11e5abb5869dd641f3f4f6a5bb4e70fdf""><code>a988e1a</code></a> Chore: inline Variables that immediately Returned (<a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/issues/690"">#690</a>)</li>; <li><a href=""https://github.com/jpadilla/pyjwt/commit/e7a6c022f3f2e5ba329cbadd242c788014926a7e""><code>e7a6c02</code></a> Add support for Ed448/EdDSA. (<a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/issues/675"">#675</a>)</li>; <li><a href=""https://github.com/jpadilla/pyjwt/commit/19ce9c5ec7947428d35aaffd302eb2629210a697""><code>19ce9c5</code></a> Remove upper bound on cryptography version (<a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/issues/693"">#693</a>)</li>; <li><a href=""https://github.com/jpadilla/pyjwt/commit/9249fc70b5aede04c3dcb86e4b6560ab7e032563""><code>9249fc7</code></a> [pre-commit.ci] pre-commit autoupdate (<a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/issues/689"">#689</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/jpadilla/pyjwt/compare/1.7.1...2.3.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pyjwt&package-manager=pip&previous-version=1.7.1&new-version=2.3.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-auto",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11457:13277,depend,dependabot,13277,https://hail.is,https://github.com/hail-is/hail/pull/11457,1,['depend'],['dependabot']
Integrability,"x changelog header to consistent size (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-core/issues/394"">#394</a>) (<a href=""https://github.com/googleapis/python-api-core/commit/ac266e935bc4e7c6dff250384407e7a60d8dba90"">ac266e9</a>)</li>; <li>Fix typo in the BackgroundConsumer docstring (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-core/issues/395"">#395</a>) (<a href=""https://github.com/googleapis/python-api-core/commit/0eb727f92314db3c4383754514f75a49ba02e27b"">0eb727f</a>)</li>; </ul>; <h2>v2.8.1</h2>; <h3><a href=""https://github.com/googleapis/python-api-core/compare/v2.8.0...v2.8.1"">2.8.1</a> (2022-05-26)</h3>; <h3>Bug Fixes</h3>; <ul>; <li><strong>deps:</strong> require googleapis-common-protos &gt;= 1.56.2 (<a href=""https://github.com/googleapis/python-api-core/commit/d84d66c2a4107f5f9a20c53e870a27fb1250ea3d"">d84d66c</a>)</li>; <li><strong>deps:</strong> require protobuf&gt;= 3.15.0, &lt;4.0.0dev (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-core/issues/385"">#385</a>) (<a href=""https://github.com/googleapis/python-api-core/commit/d84d66c2a4107f5f9a20c53e870a27fb1250ea3d"">d84d66c</a>)</li>; </ul>; <h2>v2.8.0</h2>; <h2><a href=""https://github.com/googleapis/python-api-core/compare/v2.7.3...v2.8.0"">2.8.0</a> (2022-05-18)</h2>; <h3>Features</h3>; <ul>; <li>adds support for audience in client_options (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-core/issues/379"">#379</a>) (<a href=""https://github.com/googleapis/python-api-core/commit/c97c4980125a86f384cdf12720df7bb1a2adf9d2"">c97c498</a>)</li>; <li>adds support for audience in client_options. (<a href=""https://github.com/googleapis/python-api-core/commit/c97c4980125a86f384cdf12720df7bb1a2adf9d2"">c97c498</a>)</li>; </ul>; <h2>v2.7.3</h2>; <h3><a href=""https://github.com/googleapis/python-api-core/compare/v2.7.2...v2.7.3"">2.7.3</a> (2022-04-29)</h3>; <h3>Bug Fixes</h3>; <ul>; <li>Avoid AttributeError if grpcio-status is not i",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11970:2013,depend,dependabot,2013,https://hail.is,https://github.com/hail-is/hail/pull/11970,1,['depend'],['dependabot']
Integrability,"x crash in match statement if class name is undefined (<a href=""https://github-redirect.dependabot.com/python/mypy/issues/12417"">#12417</a>)</li>; <li><a href=""https://github.com/python/mypy/commit/6606dbe98d09170d3ad810bc791a16d99ceb2281""><code>6606dbe</code></a> Allow non-final <strong>match_args</strong> and overriding (<a href=""https://github-redirect.dependabot.com/python/mypy/issues/12415"">#12415</a>)</li>; <li><a href=""https://github.com/python/mypy/commit/626147a761891362dbf6e845c99031e2e043d0f4""><code>626147a</code></a> Fix small conditional overload regression (<a href=""https://github-redirect.dependabot.com/python/mypy/issues/12336"">#12336</a>)</li>; <li><a href=""https://github.com/python/mypy/commit/8e9ac1576b2d9b93bfe67dcf3a553e479f9af971""><code>8e9ac15</code></a> Bump version to 0.942+dev</li>; <li>Additional commits viewable in <a href=""https://github.com/python/mypy/compare/v0.780...v0.942"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=mypy&package-manager=pip&previous-version=0.780&new-version=0.942)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11667:2661,Depend,Dependabot,2661,https://hail.is,https://github.com/hail-is/hail/pull/11667,4,"['Depend', 'depend']","['Dependabot', 'dependabot-badges']"
Integrability,"x for rendering unified hover labels in classic Jupyter Notebooks</li>; </ul>; </li>; </ul>; <h2>[5.3.0] - 2021-08-29</h2>; <h3>Updated</h3>; <ul>; <li>Updated Plotly.js to from version 2.3.1 to version 2.4.1. See the <a href=""https://github.com/plotly/plotly.js/blob/master/CHANGELOG.md#240----2021-08-27"">plotly.js CHANGELOG</a> for more information. These changes are reflected in the auto-generated <code>plotly.graph_objects</code> module. Notable changes include:; <ul>; <li>Added <code>legend.groupclick</code> options</li>; </ul>; </li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/plotly/plotly.py/commit/c6026e67628cb8b9b379e71b36d1372b0e787f20""><code>c6026e6</code></a> release v5.6.0</li>; <li><a href=""https://github.com/plotly/plotly.py/commit/5825349d88ac8e0d23115faab78a1e747e52277a""><code>5825349</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/plotly/plotly.py/issues/3590"">#3590</a> from plotly/pjs29</li>; <li><a href=""https://github.com/plotly/plotly.py/commit/bb1bc95b3225f577871c8ca35ea970787355f97c""><code>bb1bc95</code></a> bump Plotly.js to 2.9.0</li>; <li><a href=""https://github.com/plotly/plotly.py/commit/cfad7862594b35965c0e000813bd7805e8494a5b""><code>cfad786</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/plotly/plotly.py/issues/3524"">#3524</a> from plotly/release_5.5</li>; <li><a href=""https://github.com/plotly/plotly.py/commit/b7ae20514e18c5e428a08aee5547666ae005d903""><code>b7ae205</code></a> bump doc reqs</li>; <li>See full diff in <a href=""https://github.com/plotly/plotly.py/compare/v5.5.0...v5.6.0"">compare view</a></li>; </ul>; </details>; <br />. Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-autome",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11535:5279,depend,dependabot,5279,https://hail.is,https://github.com/hail-is/hail/pull/11535,1,['depend'],['dependabot']
Integrability,x$.$anonfun$exportAnnotation$5(AnnotationImpex.scala:129); at is.hail.expr.JSONAnnotationImpex$.$anonfun$exportAnnotation$5$adapted(AnnotationImpex.scala:128); at scala.collection.generic.GenTraversableFactory.tabulate(GenTraversableFactory.scala:150); at is.hail.expr.JSONAnnotationImpex$.exportAnnotation(AnnotationImpex.scala:128); at is.hail.types.virtual.Type.toJSON(Type.scala:184); at is.hail.expr.JSONAnnotationImpex$.$anonfun$exportAnnotation$4(AnnotationImpex.scala:125); at is.hail.utils.Interval.toJSON(Interval.scala:103); at is.hail.expr.JSONAnnotationImpex$.exportAnnotation(AnnotationImpex.scala:125); at is.hail.expr.JSONAnnotationImpex$.$anonfun$exportAnnotation$1(AnnotationImpex.scala:113); at scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:238); at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36); at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:38); at scala.collection.TraversableLike.map(TraversableLike.scala:238); at scala.collection.TraversableLike.map$(TraversableLike.scala:231); at scala.collection.AbstractTraversable.map(Traversable.scala:108); at is.hail.expr.JSONAnnotationImpex$.exportAnnotation(AnnotationImpex.scala:113); at is.hail.expr.ir.Pretty.header(Pretty.scala:405); at is.hail.expr.ir.Pretty.pretty$1(Pretty.scala:463); at is.hail.expr.ir.Pretty.$anonfun$sexprStyle$4(Pretty.scala:453); at scala.collection.Iterator$$anon$10.next(Iterator.scala:459); at scala.collection.Iterator$ConcatIterator.next(Iterator.scala:230); at is.hail.utils.richUtils.RichIterator$$anon$3.next(RichIterator.scala:67); at is.hail.utils.prettyPrint.Doc$.advance$1(PrettyPrintWriter.scala:68); at is.hail.utils.prettyPrint.Doc$.render(PrettyPrintWriter.scala:139); at is.hail.utils.prettyPrint.Doc.render(PrettyPrintWriter.scala:163); at is.hail.utils.prettyPrint.Doc.render(PrettyPrintWriter.scala:167); at is.hail.expr.ir.Prett,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13046:1597,Wrap,WrappedArray,1597,https://hail.is,https://github.com/hail-is/hail/issues/13046,1,['Wrap'],['WrappedArray']
Integrability,"x-dev/py-filelock/compare/3.7.1...3.8.0"">https://github.com/tox-dev/py-filelock/compare/3.7.1...3.8.0</a></p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/tox-dev/py-filelock/commit/24b26b6be356de80d7212a9f7621d81c6d3eec8d""><code>24b26b6</code></a> Delete main.pdf</li>; <li><a href=""https://github.com/tox-dev/py-filelock/commit/f7e72dd59b230b2751b10023851b01655d60bac6""><code>f7e72dd</code></a> [pre-commit.ci] pre-commit autoupdate (<a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/issues/162"">#162</a>)</li>; <li><a href=""https://github.com/tox-dev/py-filelock/commit/81bd5a3666c863c665acfdaf9ace6c6c964e0ad5""><code>81bd5a3</code></a> Update check.yml</li>; <li><a href=""https://github.com/tox-dev/py-filelock/commit/558c67f85a6f23b22831e81d792bb21471c12393""><code>558c67f</code></a> Bump build dependencies</li>; <li><a href=""https://github.com/tox-dev/py-filelock/commit/fc2edee8ecf5d4eae99e6e7502671a094e9d60d2""><code>fc2edee</code></a> Bump dependencies</li>; <li><a href=""https://github.com/tox-dev/py-filelock/commit/3b3f562be03ae963dadd1360a04b430e37b4bfd9""><code>3b3f562</code></a> [pre-commit.ci] pre-commit autoupdate (<a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/issues/159"">#159</a>)</li>; <li><a href=""https://github.com/tox-dev/py-filelock/commit/e3894f669319c4371cd398f39fe99c57c8395212""><code>e3894f6</code></a> Check 3.11 support (<a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/issues/158"">#158</a>)</li>; <li><a href=""https://github.com/tox-dev/py-filelock/commit/1957538dea683fda4cca8650efd35b97ccab04ab""><code>1957538</code></a> [pre-commit.ci] pre-commit autoupdate (<a href=""https://github-redirect.dependabot.com/tox-dev/py-filelock/issues/157"">#157</a>)</li>; <li><a href=""https://github.com/tox-dev/py-filelock/commit/e6c1a64d24eb9f1524cc0464bf6acd87a82b08fd""><code>e6c1a64</code></a> [pre-commit.ci] pre-commit autoupdate (<a href=""https://github-",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12157:5282,depend,dependencies,5282,https://hail.is,https://github.com/hail-is/hail/pull/12157,1,['depend'],['dependencies']
Integrability,"x-dev/sphinx-autodoc-typehints/commit/aa345ca0475dbe8f4da7f4c7c56832c8d8e6884a""><code>aa345ca</code></a> Add <code>typehints_use_rtype</code> option (<a href=""https://github-redirect.dependabot.com/tox-dev/sphinx-autodoc-typehints/issues/218"">#218</a>)</li>; <li><a href=""https://github.com/tox-dev/sphinx-autodoc-typehints/commit/a022d1a430db886decf2221b712bc3bd881f5e86""><code>a022d1a</code></a> inspect.getsource can raise TypeError (<a href=""https://github-redirect.dependabot.com/tox-dev/sphinx-autodoc-typehints/issues/210"">#210</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/tox-dev/sphinx-autodoc-typehints/compare/1.11.1...1.18.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=sphinx-autodoc-typehints&package-manager=pip&previous-version=1.11.1&new-version=1.18.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11773:5397,depend,dependabot-security-updates,5397,https://hail.is,https://github.com/hail-is/hail/pull/11773,1,['depend'],['dependabot-security-updates']
Integrability,"x-dev/sphinx-autodoc-typehints/issues/224"">#224</a>)</li>; <li><a href=""https://github.com/tox-dev/sphinx-autodoc-typehints/commit/1ef84886873b80ff62ed1ea76e111dd9e96dbf18""><code>1ef8488</code></a> Release 1.17.0</li>; <li><a href=""https://github.com/tox-dev/sphinx-autodoc-typehints/commit/aa345ca0475dbe8f4da7f4c7c56832c8d8e6884a""><code>aa345ca</code></a> Add <code>typehints_use_rtype</code> option (<a href=""https://github-redirect.dependabot.com/tox-dev/sphinx-autodoc-typehints/issues/218"">#218</a>)</li>; <li><a href=""https://github.com/tox-dev/sphinx-autodoc-typehints/commit/a022d1a430db886decf2221b712bc3bd881f5e86""><code>a022d1a</code></a> inspect.getsource can raise TypeError (<a href=""https://github-redirect.dependabot.com/tox-dev/sphinx-autodoc-typehints/issues/210"">#210</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/tox-dev/sphinx-autodoc-typehints/compare/1.11.1...1.18.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=sphinx-autodoc-typehints&package-manager=pip&previous-version=1.11.1&new-version=1.18.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependab",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11773:5118,Depend,Dependabot,5118,https://hail.is,https://github.com/hail-is/hail/pull/11773,2,"['Depend', 'depend']","['Dependabot', 'dependabot-badges']"
Integrability,"x-doc/sphinx/commit/78c478a579b9d3f57091544d1717ee7f1c507ff1""><code>78c478a</code></a> Merge remote-tracking branch 'upstream/5.0.x' into lang-none-en</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/479e48266c025c99025787a8004a82b2afda8e6c""><code>479e482</code></a> Update warning, revert my original warning patch</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/fb6db30c1024ce5838dcf330f275cdf2adbd94b6""><code>fb6db30</code></a> Update comment</li>; <li>Additional commits viewable in <a href=""https://github.com/sphinx-doc/sphinx/compare/v3.5.4...v5.0.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=sphinx&package-manager=pip&previous-version=3.5.4&new-version=5.0.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11871:6613,Depend,Dependabot,6613,https://hail.is,https://github.com/hail-is/hail/pull/11871,1,['Depend'],['Dependabot']
Integrability,"x-doc/sphinx/commit/a001bf47d66ae804a9a6e5d754de9b5eda4d0eb9""><code>a001bf4</code></a> Update CHANGES for PR <a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10107"">#10107</a></li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/b20e04968e73234da9fff7d19b12dfbeebebe944""><code>b20e049</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10107"">#10107</a> from Jean-Abou-Samra/intl-warnings</li>; <li>Additional commits viewable in <a href=""https://github.com/sphinx-doc/sphinx/compare/v3.5.4...v4.5.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=sphinx&package-manager=pip&previous-version=3.5.4&new-version=4.5.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11714:7867,Depend,Dependabot,7867,https://hail.is,https://github.com/hail-is/hail/pull/11714,2,['Depend'],['Dependabot']
Integrability,"x-doc/sphinx/issues/10439"">#10439</a>: std domain: Use the repr of some variables when displaying warnings,; making whitespace issues easier to identify.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10571"">#10571</a>: quickstart: Reduce content in the generated <code>conf.py</code> file. Patch by; Pradyun Gedam.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10648"">#10648</a>: LaTeX: CSS-named-alike additional :ref:<code>'sphinxsetup' &lt;latexsphinxsetup&gt;</code>; keys allow to configure four separate border-widths, four paddings, four; corner radii, a shadow (possibly inset), colours for border, background, shadow; for each of the code-block, topic, attention, caution, danger, error and warning; directives.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10655"">#10655</a>: LaTeX: Explain non-standard encoding in LatinRules.xdy</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10599"">#10599</a>: HTML Theme: Wrap consecutive footnotes in an <code>&lt;aside&gt;</code> element when; using Docutils 0.18 or later, to allow for easier styling. This matches the; behaviour introduced in Docutils 0.19. Patch by Adam Turner.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10518"">#10518</a>: config: Add <code>include_patterns</code> as the opposite of <code>exclude_patterns</code>.; Patch by Adam Turner.</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/e712eae382d213ce3f4866ad6f5b3c84ce4f4409""><code>e712eae</code></a> Bump to 5.1.1 final</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/0555345ad715b1e5ec83bce2e4a993441ffb8f29""><code>0555345</code></a> Fix ValueError popping out in <code>sphinx.ext.napoleon</code> (<a href=""https://github-redirect",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12165:4539,depend,dependabot,4539,https://hail.is,https://github.com/hail-is/hail/pull/12165,1,['depend'],['dependabot']
Integrability,"x/changes/#version-8-1-3</a></li>; <li>Milestone: <a href=""https://github.com/pallets/click/milestone/18?closed=1"">https://github.com/pallets/click/milestone/18?closed=1</a></li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/pallets/click/blob/main/CHANGES.rst"">click's changelog</a>.</em></p>; <blockquote>; <h2>Version 8.1.3</h2>; <p>Released 2022-04-28</p>; <ul>; <li>Use verbose form of <code>typing.Callable</code> for <code>@command</code> and; <code>@group</code>. :issue:<code>2255</code></li>; <li>Show error when attempting to create an option with; <code>multiple=True, is_flag=True</code>. Use <code>count</code> instead.; :issue:<code>2246</code></li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pallets/click/commit/9c6f4c8e1bb8670ce827c98559f57f6ee5935cd0""><code>9c6f4c8</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/click/issues/2262"">#2262</a> from pallets/release-8.1.3</li>; <li><a href=""https://github.com/pallets/click/commit/5ec77494bdf2c294d3b082bed429ebce78321431""><code>5ec7749</code></a> release version 8.1.3</li>; <li><a href=""https://github.com/pallets/click/commit/2ac3211cb79a63bae8e6f0441136b432ec2126bc""><code>2ac3211</code></a> update requirements</li>; <li><a href=""https://github.com/pallets/click/commit/5fd87bdf80ed450334b37344f6c99890c217d3db""><code>5fd87bd</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/click/issues/2248"">#2248</a> from jreese/8.1.x</li>; <li><a href=""https://github.com/pallets/click/commit/daa2d8e44332f66f09be83a9872218fde318bb8d""><code>daa2d8e</code></a> disallow use of is_flag and multiple in option</li>; <li><a href=""https://github.com/pallets/click/commit/afdfb120fff5cb5f8d0184d411369f5dddaed5b3""><code>afdfb12</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/click/issue",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11973:1507,depend,dependabot,1507,https://hail.is,https://github.com/hail-is/hail/pull/11973,1,['depend'],['dependabot']
Integrability,"x/issues/10702"">#10702</a>: Restore compatability with third-party builders.</li>; </ul>; <h1>Release 5.1.0 (released Jul 24, 2022)</h1>; <h2>Dependencies</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10656"">#10656</a>: Support <code>Docutils 0.19</code>_. Patch by Adam Turner.</li>; </ul>; <p>.. _Docutils 0.19: <a href=""https://docutils.sourceforge.io/RELEASE-NOTES.html#release-0-19-2022-07-05"">https://docutils.sourceforge.io/RELEASE-NOTES.html#release-0-19-2022-07-05</a></p>; <h2>Deprecated</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10467"">#10467</a>: Deprecated <code>sphinx.util.stemmer</code> in favour of <code>snowballstemmer</code>.; Patch by Adam Turner.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/9856"">#9856</a>: Deprecated <code>sphinx.ext.napoleon.iterators</code>.</li>; </ul>; <h2>Features added</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10444"">#10444</a>: html theme: Allow specifying multiple CSS files through the <code>stylesheet</code>; setting in <code>theme.conf</code> or by setting <code>html_style</code> to an iterable of strings.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10366"">#10366</a>: std domain: Add support for emphasising placeholders in :rst:dir:<code>option</code>; directives through a new :confval:<code>option_emphasise_placeholders</code> configuration; option.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10439"">#10439</a>: std domain: Use the repr of some variables when displaying warnings,; making whitespace issues easier to identify.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10571"">#10571</a>: quickstart: Reduce content in the generated <code>conf.py</code> file. Patch by; Pradyun Gedam.</li>; <li><a href=""https://github-redirect.dependabot.com/s",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12165:2949,depend,dependabot,2949,https://hail.is,https://github.com/hail-is/hail/pull/12165,1,['depend'],['dependabot']
Integrability,"xcept BaseException as e:; 446 # Remove the TypeError from the exception chain in; 447 # Python 3 (including for exceptions like SystemExit).; 448 # Otherwise it looks like a bug in the code. File /opt/conda/lib/python3.10/http/client.py:1375, in HTTPConnection.getresponse(self); 1374 try:; -> 1375 response.begin(); 1376 except ConnectionError:. File /opt/conda/lib/python3.10/http/client.py:318, in HTTPResponse.begin(self); 317 while True:; --> 318 version, status, reason = self._read_status(); 319 if status != CONTINUE:. File /opt/conda/lib/python3.10/http/client.py:287, in HTTPResponse._read_status(self); 284 if not line:; 285 # Presumably, the server closed the connection before; 286 # sending a valid response.; --> 287 raise RemoteDisconnected(""Remote end closed connection without""; 288 "" response""); 289 try:. RemoteDisconnected: Remote end closed connection without response. During handling of the above exception, another exception occurred:. ProtocolError Traceback (most recent call last); File /opt/conda/lib/python3.10/site-packages/requests/adapters.py:487, in HTTPAdapter.send(self, request, stream, timeout, verify, cert, proxies); 486 try:; --> 487 resp = conn.urlopen(; 488 method=request.method,; 489 url=url,; 490 body=request.body,; 491 headers=request.headers,; 492 redirect=False,; 493 assert_same_host=False,; 494 preload_content=False,; 495 decode_content=False,; 496 retries=self.max_retries,; 497 timeout=timeout,; 498 chunked=chunked,; 499 ); 501 except (ProtocolError, OSError) as err:. File /opt/conda/lib/python3.10/site-packages/urllib3/connectionpool.py:787, in HTTPConnectionPool.urlopen(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw); 785 e = ProtocolError(""Connection aborted."", e); --> 787 retries = retries.increment(; 788 method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]; 789 ); 790 retries.sleep(). File /opt/conda/lib/python3.10/site-packa",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13960:6170,Protocol,ProtocolError,6170,https://hail.is,https://github.com/hail-is/hail/issues/13960,1,['Protocol'],['ProtocolError']
Integrability,"xecute(MatrixIR.scala:1352); 	at is.hail.expr.ir.MatrixMapGlobals.execute(MatrixIR.scala:1832); 	at is.hail.expr.ir.MatrixKeyRowsBy.execute(MatrixIR.scala:1317); 	at is.hail.expr.ir.MatrixMapGlobals.execute(MatrixIR.scala:1832); 	at is.hail.expr.ir.MatrixMapRows.execute(MatrixIR.scala:1352); 	at is.hail.expr.ir.MatrixMapGlobals.execute(MatrixIR.scala:1832); 	at is.hail.expr.ir.MatrixMapGlobals.execute(MatrixIR.scala:1832); 	at is.hail.expr.ir.MatrixMapEntries.execute(MatrixIR.scala:1257); 	at is.hail.expr.ir.MatrixMapGlobals.execute(MatrixIR.scala:1832); 	at is.hail.expr.ir.MatrixMapGlobals.execute(MatrixIR.scala:1832); 	at is.hail.expr.ir.Interpret$.apply(Interpret.scala:728); 	at is.hail.expr.ir.Interpret$.apply(Interpret.scala:57); 	at is.hail.expr.ir.Interpret$.apply(Interpret.scala:32); 	at is.hail.variant.MatrixTable.aggregateEntries(MatrixTable.scala:891); 	at is.hail.variant.MatrixTable.aggregateEntriesJSON(MatrixTable.scala:884); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.lang.Thread.run(Thread.java:748); ERROR:root:Exception while sending command.; Traceback (most recent call last):; File ""/homes/nber/barronk-dua51929/local/anaconda3/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1159, in send_command; raise Py4JNetworkError(""Answer from Java side is empty""); py4j.protocol.Py4JNetworkError: Answer from Java side is empty; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4733:4158,protocol,protocol,4158,https://hail.is,https://github.com/hail-is/hail/issues/4733,1,['protocol'],['protocol']
Integrability,"xecution_count=10&line=1) (; [2](vscode-notebook-cell:?execution_count=10&line=2) mt.filter_rows(selected_variants.contains(mt.rsid)); [3](vscode-notebook-cell:?execution_count=10&line=3) .select_rows('rsid'); [4](vscode-notebook-cell:?execution_count=10&line=4) .select_entries('GT'); ----> [5](vscode-notebook-cell:?execution_count=10&line=5) ).make_table().take(1). File .../python3.10/site-packages/decorator.py:232, in decorate.<locals>.fun(*args, **kw); [230](.../python3.10/site-packages/decorator.py:230) if not kwsyntax:; [231](.../python3.10/site-packages/decorator.py:231) args, kw = fix(args, kw, sig); --> [232](.../python3.10/site-packages/decorator.py:232) return caller(func, *(extras + args), **kw). File .../python3.10/site-packages/hail/typecheck/check.py:584, in _make_dec.<locals>.wrapper(__original_func, *args, **kwargs); [581](.../python3.10/site-packages/hail/typecheck/check.py:581) @decorator; [582](.../python3.10/site-packages/hail/typecheck/check.py:582) def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; [583](.../python3.10/site-packages/hail/typecheck/check.py:583) args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> [584](.../python3.10/site-packages/hail/typecheck/check.py:584) return __original_func(*args_, **kwargs_). File .../python3.10/site-packages/hail/table.py:2426, in Table.take(self, n, _localize); [2392](.../python3.10/site-packages/hail/table.py:2392) @typecheck_method(n=int, _localize=bool); [2393](.../python3.10/site-packages/hail/table.py:2393) def take(self, n, _localize=True):; [2394](.../python3.10/site-packages/hail/table.py:2394) """"""Collect the first `n` rows of the table into a local list.; [2395](.../python3.10/site-packages/hail/table.py:2395) ; [2396](.../python3.10/site-packages/hail/table.py:2396) Examples; (...); [2423](.../python3.10/site-packages/hail/table.py:2423) List of row structs.; [2424](.../python3.10/site-packages/hail/table.py:2424) """"""; -> [2426](..",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14362:2613,wrap,wrapper,2613,https://hail.is,https://github.com/hail-is/hail/issues/14362,1,['wrap'],['wrapper']
Integrability,"xed download_blob_to_file example (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/704"">#704</a>) (<a href=""https://github.com/googleapis/python-storage/commit/2c94d98ed21cc768cfa54fac3d734254fc4d8480"">2c94d98</a>)</li>; </ul>; <h2><a href=""https://github.com/googleapis/python-storage/compare/v2.0.0...v2.1.0"">2.1.0</a> (2022-01-19)</h2>; <h3>Features</h3>; <ul>; <li>add turbo replication support and samples (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/622"">#622</a>) (<a href=""https://github.com/googleapis/python-storage/commit/4dafc815470480ce9de7f0357e331d3fbd0ae9b7"">4dafc81</a>)</li>; <li>avoid authentication with storage emulator (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/679"">#679</a>) (<a href=""https://github.com/googleapis/python-storage/commit/8789afaaa1b2bd6f03fae72e3d87ce004ec10129"">8789afa</a>)</li>; <li>remove python 3.6 support (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/689"">#689</a>) (<a href=""https://github.com/googleapis/python-storage/commit/8aa4130ee068a1922161c8ca54a53a4a51d65ce0"">8aa4130</a>)</li>; </ul>; <h2><a href=""https://github.com/googleapis/python-storage/compare/v1.44.0...v2.0.0"">2.0.0</a> (2022-01-12)</h2>; <h3>⚠ BREAKING CHANGES</h3>; <ul>; <li>Remove Python 2 support (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/657"">#657</a>)</li>; </ul>; <h3>Features</h3>; <ul>; <li>Remove Python 2 support (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/657"">#657</a>) (<a href=""https://github.com/googleapis/python-storage/commit/b6116700a4a32d28404c39018138e545f3f7910e"">b611670</a>)</li>; </ul>; <h2><a href=""https://www.github.com/googleapis/python-storage/compare/v1.43.0...v1.44.0"">1.44.0</a> (2022-01-05)</h2>; <h3>Features</h3>; <ul>; <li>add raw_download kwarg to BlobReader (<a href=""https://github-redirect.dependabot.com/googleapis/py",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11578:4851,depend,dependabot,4851,https://hail.is,https://github.com/hail-is/hail/pull/11578,1,['depend'],['dependabot']
Integrability,"xed version:; - ci/pinned-requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **496/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 4.2 | Information Exposure Through Sent Data <br/>[SNYK-PYTHON-URLLIB3-6002459](https://snyk.io/vuln/SNYK-PYTHON-URLLIB3-6002459) | `urllib3:` <br> `1.26.17 -> 1.26.18` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIyNWE2ZGYzMi1kYmEzLTQzOTctYmIyNC0zNjdlMzhmZWQ3ZmUiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjI1YTZkZjMyLWRiYTMtNDM5Ny1iYjI0LTM2N2UzOGZlZDdmZSJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13848:1324,depend,dependency,1324,https://hail.is,https://github.com/hail-is/hail/pull/13848,2,['depend'],"['dependencies', 'dependency']"
Integrability,"xed version:; - ci/pinned-requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **581/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 5.9 | Information Exposure Through Sent Data <br/>[SNYK-PYTHON-URLLIB3-5926907](https://snyk.io/vuln/SNYK-PYTHON-URLLIB3-5926907) | `urllib3:` <br> `1.26.16 -> 1.26.17` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI3ZGVlZGFlMy1mZmE3LTQxYmUtOGY4MS1lNmYwZTA5YTczOTMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjdkZWVkYWUzLWZmYTctNDFiZS04ZjgxLWU2ZjBlMDlhNzM5MyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/701495b8-b53d-48af-82fe-1a6c57aa56cb?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13770:1324,depend,dependency,1324,https://hail.is,https://github.com/hail-is/hail/pull/13770,2,['depend'],"['dependencies', 'dependency']"
Integrability,"xed version:; - hail/python/hailtop/pinned-requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **591/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 6.1 | Information Exposure <br/>[SNYK-PYTHON-REQUESTS-5595532](https://snyk.io/vuln/SNYK-PYTHON-REQUESTS-5595532) | `requests:` <br> `2.28.2 -> 2.31.0` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI2YzU3NmY1Yi1lNGM5LTQ4ZjctYmYxNy04YjEzOTIxODlmZDQiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjZjNTc2ZjViLWU0YzktNDhmNy1iZjE3LThiMTM5MjE4OWZkNCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13097:1232,depend,dependency,1232,https://hail.is,https://github.com/hail-is/hail/pull/13097,2,['depend'],"['dependencies', 'dependency']"
Integrability,"xed version:; - hail/python/hailtop/pinned-requirements.txt. #### Vulnerabilities that will be fixed. ##### By pinning:; Severity | Priority Score (*) | Issue | Upgrade | Breaking Change | Exploit Maturity; :-------------------------:|-------------------------|:-------------------------|:-------------------------|:-------------------------|:-------------------------; ![medium severity](https://res.cloudinary.com/snyk/image/upload/w_20,h_20/v1561977819/icon/m.png ""medium severity"") | **591/1000** <br/> **Why?** Recently disclosed, Has a fix available, CVSS 6.1 | Information Exposure <br/>[SNYK-PYTHON-REQUESTS-5595532](https://snyk.io/vuln/SNYK-PYTHON-REQUESTS-5595532) | `requests:` <br> `2.28.2 -> 2.31.0` <br> | No | No Known Exploit . (*) Note that the real score may have changed since the PR was raised. Some vulnerabilities couldn't be fully fixed and so Snyk will still find them when the project is tested again. This may be because the vulnerability existed within more than one direct dependency, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiIwMzdiOGRmZS1hZDA4LTRmZjUtYTFkOC1hNGM4Nzg2N2NkYjAiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjAzN2I4ZGZlLWFkMDgtNGZmNS1hMWQ4LWE0Yzg3ODY3Y2RiMCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13159:1324,depend,dependency,1324,https://hail.is,https://github.com/hail-is/hail/pull/13159,2,['depend'],"['dependencies', 'dependency']"
Integrability,"xpressions/base_expression.py"", line 786, in value; return hl.eval_expr(self); File ""/Users/laurent/tools/hail/python/hail/typecheck/check.py"", line 547, in wrapper; return f(*args_, **kwargs_); File ""/Users/laurent/tools/hail/python/hail/expr/expressions/expression_utils.py"", line 137, in eval_expr; return eval_expr_typed(expression)[0]; File ""/Users/laurent/tools/hail/python/hail/typecheck/check.py"", line 547, in wrapper; return f(*args_, **kwargs_); File ""/Users/laurent/tools/hail/python/hail/expr/expressions/expression_utils.py"", line 171, in eval_expr_typed; return expression.collect()[0], expression.dtype; File ""/Users/laurent/tools/hail/python/hail/expr/expressions/base_expression.py"", line 768, in collect; t = self._to_table(uid); File ""/Users/laurent/tools/hail/python/hail/expr/expressions/base_expression.py"", line 591, in _to_table; df = df.select(**{name: self}); File ""/Users/laurent/tools/hail/python/hail/typecheck/check.py"", line 547, in wrapper; return f(*args_, **kwargs_); File ""/Users/laurent/tools/hail/python/hail/table.py"", line 893, in select; return self._select('Table.select', value_struct=hl.struct(**row)); File ""/Users/laurent/tools/hail/python/hail/typecheck/check.py"", line 547, in wrapper; return f(*args_, **kwargs_); File ""/Users/laurent/tools/hail/python/hail/table.py"", line 402, in _select; base, cleanup = self._process_joins(row); File ""/Users/laurent/tools/hail/python/hail/table.py"", line 1495, in _process_joins; return process_joins(self, exprs, broadcast_f); File ""/Users/laurent/tools/hail/python/hail/utils/misc.py"", line 365, in process_joins; data_json = t._to_json(data); File ""/Users/laurent/tools/hail/python/hail/expr/types.py"", line 185, in _to_json; converted = self._convert_to_json_na(x); File ""/Users/laurent/tools/hail/python/hail/expr/types.py"", line 192, in _convert_to_json_na; return self._convert_to_json(x); File ""/Users/laurent/tools/hail/python/hail/expr/types.py"", line 802, in _convert_to_json; return {f: t._convert_to_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4078:1843,wrap,wrapper,1843,https://hail.is,https://github.com/hail-is/hail/issues/4078,1,['wrap'],['wrapper']
Integrability,"xtensions to be created on demand in custom tasks, so these tasks can be made compatible with Gradle's configuration cache (see <a href=""https://github-redirect.dependabot.com/michel-kraemer/gradle-download-task/issues/284"">#284</a>). Thanks to <a href=""https://github.com/liblit""><code>@​liblit</code></a> for testing!</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Update dependencies</li>; <li>Improve documentation</li>; <li>Add integration tests for Gradle 6.9.3 and 7.6</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/a0374fc7c895ae53309ea351e989571204e0ea5f""><code>a0374fc</code></a> Bump up version number to 5.3.1</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/612f57a382b8640cc730dc5e75d1c809e3e772bd""><code>612f57a</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/michel-kraemer/gradle-download-task/issues/291"">#291</a> from michel-kraemer/dependabot/npm_and_yarn/screencas...</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/53af1049f5514afe58e884d487d7c57dae47759d""><code>53af104</code></a> Bump http-cache-semantics from 4.1.0 to 4.1.1 in /screencast</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/398c14c05c6448b380ac35c6095598299c5e23c5""><code>398c14c</code></a> Update dependencies</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/15cf7eecfbc17d2466143828b9b69494c6cb6f2b""><code>15cf7ee</code></a> Bump up version number to 5.3.1-SNAPSHOT</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/e3c65ffcb49b9c5a33fde5f31fb63043dbf21134""><code>e3c65ff</code></a> Allow extensions to be created from tasks</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/34e2dd41477f18b1ae3d6d5a71dca5449d6cd1e0""><code>34e2dd4</code></a> Downgrade slf4j to fix warning on co",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12707:1514,depend,dependabot,1514,https://hail.is,https://github.com/hail-is/hail/pull/12707,1,['depend'],['dependabot']
Integrability,"xtensions/commit/db79268673ac10412b4aad19efea03948869b7db""><code>db79268</code></a> Silence a <code>flake8-bugbear</code> warning (<a href=""https://github-redirect.dependabot.com/python/typing_extensions/issues/72"">#72</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/python/typing_extensions/compare/4.3.0...4.4.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=typing-extensions&package-manager=pip&previous-version=4.3.0&new-version=4.4.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12288:4756,Depend,Dependabot,4756,https://hail.is,https://github.com/hail-is/hail/pull/12288,1,['Depend'],['Dependabot']
Integrability,"xtensions</code> is no longer a required dependency in Python 3.10+ (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2772"">#2772</a>)</li>; <li>Set <code>click</code> lower bound to <code>8.0.0</code> as <em>Black</em> crashes on <code>7.1.2</code> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2791"">#2791</a>)</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/psf/black/blob/main/CHANGES.md"">black's changelog</a>.</em></p>; <blockquote>; <h2>22.1.0</h2>; <p>At long last, <em>Black</em> is no longer a beta product! This is the first non-beta release; and the first release covered by our new; <a href=""https://black.readthedocs.io/en/stable/the_black_code_style/index.html#stability-policy"">stability policy</a>.</p>; <h3>Highlights</h3>; <ul>; <li><strong>Remove Python 2 support</strong> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2740"">#2740</a>)</li>; <li>Introduce the <code>--preview</code> flag (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2752"">#2752</a>)</li>; </ul>; <h3>Style</h3>; <ul>; <li>Deprecate <code>--experimental-string-processing</code> and move the functionality under; <code>--preview</code> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2789"">#2789</a>)</li>; <li>For stubs, one blank line between class attributes and methods is now kept if there's; at least one pre-existing blank line (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2736"">#2736</a>)</li>; <li>Black now normalizes string prefix order (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2297"">#2297</a>)</li>; <li>Remove spaces around power operators if both operands are simple (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2726"">#2726</a>)</li>; <li>Work around bug that causes unstable formatting in some cases in the",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11468:7585,depend,dependabot,7585,https://hail.is,https://github.com/hail-is/hail/pull/11468,1,['depend'],['dependabot']
Integrability,"xtualize/rich/commit/27a5a370edbac8e0fd8d6462587a080de6ba3823""><code>27a5a37</code></a> Merge pull request <a href=""https://redirect.github.com/Textualize/rich/issues/3069"">#3069</a> from Textualize/willmcgugan-patch-1</li>; <li><a href=""https://github.com/Textualize/rich/commit/2d035d116e5e91df3b0992c494b5bc6957e57f50""><code>2d035d1</code></a> Merge pull request <a href=""https://redirect.github.com/Textualize/rich/issues/3067"">#3067</a> from LukeSavefrogs/master</li>; <li><a href=""https://github.com/Textualize/rich/commit/33fcafe6ec28c541203ada9a85bf73e31786f61d""><code>33fcafe</code></a> Format <code>test_highlighter.py</code> using <code>black</code></li>; <li><a href=""https://github.com/Textualize/rich/commit/5633a672795e73d6262a4e7fb02b4807bf74c038""><code>5633a67</code></a> Update FUNDING.yml</li>; <li>Additional commits viewable in <a href=""https://github.com/Textualize/rich/compare/v12.6.0...v13.5.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=rich&package-manager=pip&previous-version=12.6.0&new-version=13.5.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` wil",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13575:6778,Depend,Dependabot,6778,https://hail.is,https://github.com/hail-is/hail/pull/13575,2,"['Depend', 'depend']","['Dependabot', 'dependabot-badges']"
Integrability,"xtualize/rich/commit/27a5a370edbac8e0fd8d6462587a080de6ba3823""><code>27a5a37</code></a> Merge pull request <a href=""https://redirect.github.com/Textualize/rich/issues/3069"">#3069</a> from Textualize/willmcgugan-patch-1</li>; <li><a href=""https://github.com/Textualize/rich/commit/2d035d116e5e91df3b0992c494b5bc6957e57f50""><code>2d035d1</code></a> Merge pull request <a href=""https://redirect.github.com/Textualize/rich/issues/3067"">#3067</a> from LukeSavefrogs/master</li>; <li><a href=""https://github.com/Textualize/rich/commit/33fcafe6ec28c541203ada9a85bf73e31786f61d""><code>33fcafe</code></a> Format <code>test_highlighter.py</code> using <code>black</code></li>; <li><a href=""https://github.com/Textualize/rich/commit/5633a672795e73d6262a4e7fb02b4807bf74c038""><code>5633a67</code></a> Update FUNDING.yml</li>; <li>Additional commits viewable in <a href=""https://github.com/Textualize/rich/compare/v12.6.0...v13.5.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=rich&package-manager=pip&previous-version=12.6.0&new-version=13.5.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). You can trigger a rebase of this PR by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reope",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13380:6778,Depend,Dependabot,6778,https://hail.is,https://github.com/hail-is/hail/pull/13380,2,"['Depend', 'depend']","['Dependabot', 'dependabot-badges']"
Integrability,"xy is configured to use HTTPS but the proxy itself appears to only use HTTP.</li>; <li>Added a mention of the size of the connection pool when discarding a connection due to the pool being full.</li>; <li>Added explicit support for Python 3.11.</li>; <li>Deprecated the <code>Retry.MAX_BACKOFF</code> class property in favor of <code>Retry.DEFAULT_MAX_BACKOFF</code>; to better match the rest of the default parameter names. <code>Retry.MAX_BACKOFF</code> is removed in v2.0.</li>; <li>Changed location of the vendored <code>ssl.match_hostname</code> function from <code>urllib3.packages.ssl_match_hostname</code>; to <code>urllib3.util.ssl_match_hostname</code> to ensure Python 3.10+ compatibility after being repackaged; by downstream distributors.</li>; <li>Fixed absolute imports, all imports are now relative.</li>; </ul>; <h1>1.26.7 (2021-09-22)</h1>; <ul>; <li>Fixed a bug with HTTPS hostname verification involving IP addresses and lack; of SNI. (Issue <a href=""https://github-redirect.dependabot.com/urllib3/urllib3/issues/2400"">#2400</a>)</li>; <li>Fixed a bug where IPv6 braces weren't stripped during certificate hostname; matching. (Issue <a href=""https://github-redirect.dependabot.com/urllib3/urllib3/issues/2240"">#2240</a>)</li>; </ul>; <h1>1.26.6 (2021-06-25)</h1>; <ul>; <li>Deprecated the <code>urllib3.contrib.ntlmpool</code> module. urllib3 is not able to support; it properly due to <code>reasons listed in this issue &lt;https://github.com/urllib3/urllib3/issues/2282&gt;</code>_.; If you are a user of this module please leave a comment.</li>; <li>Changed <code>HTTPConnection.request_chunked()</code> to not erroneously emit multiple; <code>Transfer-Encoding</code> headers in the case that one is already specified.</li>; <li>Fixed typo in deprecation message to recommend <code>Retry.DEFAULT_ALLOWED_METHODS</code>.</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/urllib3/urllib3/commit/b1f60e44d43b13e52",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11532:4538,depend,dependabot,4538,https://hail.is,https://github.com/hail-is/hail/pull/11532,1,['depend'],['dependabot']
Integrability,"xy_scheme_unknown_fix</li>; <li>Additional commits viewable in <a href=""https://github.com/psf/requests/compare/v2.25.1...v2.27.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=requests&package-manager=pip&previous-version=2.25.1&new-version=2.27.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11528:9699,Depend,Dependabot,9699,https://hail.is,https://github.com/hail-is/hail/pull/11528,34,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability,"y <a href=""https://github.com/dajiaji""><code>@​dajiaji</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/675"">jpadilla/pyjwt#675</a></li>; <li>Chore: inline Variables that immediately Returned by <a href=""https://github.com/yezz123""><code>@​yezz123</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/690"">jpadilla/pyjwt#690</a></li>; <li>Use timezone package as Python 3.5+ is required by <a href=""https://github.com/kkirsche""><code>@​kkirsche</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/694"">jpadilla/pyjwt#694</a></li>; <li>Bump up version to v2.2.0 by <a href=""https://github.com/jpadilla""><code>@​jpadilla</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/697"">jpadilla/pyjwt#697</a></li>; </ul>; <h2>New Contributors</h2>; <ul>; <li><a href=""https://github.com/TPXP""><code>@​TPXP</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/664"">jpadilla/pyjwt#664</a></li>; <li><a href=""https://github.com/Klavionik""><code>@​Klavionik</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/668"">jpadilla/pyjwt#668</a></li>; <li><a href=""https://github.com/riconnon""><code>@​riconnon</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/693"">jpadilla/pyjwt#693</a></li>; <li><a href=""https://github.com/yezz123""><code>@​yezz123</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/690"">jpadilla/pyjwt#690</a></li>; <li><a href=""https://github.com/kkirsche""><code>@​kkirsche</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/694"">jpadilla/pyjwt#694</a></li>; </ul>; <p><strong>Full Changelog</strong>: <a href=""https://github.com/jpadilla/pyjwt/compare/2.1.0...2.2.0"">https://",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11457:6412,depend,dependabot,6412,https://hail.is,https://github.com/hail-is/hail/pull/11457,1,['depend'],['dependabot']
Integrability,"y <a href=""https://github.com/ffe4""><code>@​ffe4</code></a> (gh pr <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/1024"">#1024</a>)</li>; </ul>; <h2>Documentation changes</h2>; <ul>; <li>Rearranged parser documentation into &quot;Functions&quot;, &quot;Classes&quot; and &quot;Warnings and; Exceptions&quot; categories. (gh issue <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/992"">#992</a>, pr <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/994"">#994</a>).</li>; <li>Updated <code>parser.parse</code> documentation to reflect the switch from; <code>ValueError</code> to <code>ParserError</code>. (gh issue <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/992"">#992</a>, pr <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/994"">#994</a>).</li>; <li>Fixed methods in the <code>rrule</code> module not being displayed in the docs. (gh pr; <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/1025"">#1025</a>)</li>; <li>Changed some relative links in the exercise documentation to refer to the; document locations in the input tree, rather than the generated HTML files in; the HTML output tree (which presumably will not exist in non-HTML output; formats). (gh pr <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/1078"">#1078</a>).</li>; </ul>; <h2>Misc</h2>; <ul>; <li>Moved <code>test_imports.py</code>, <code>test_internals.py</code> and <code>test_utils.py</code> to; pytest. Reported and fixed by <a href=""https://github.com/jpurviance""><code>@​jpurviance</code></a> (gh pr <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/978"">#978</a>)</li>; <li>Added project_urls for documentation and source. Patch by <a href=""https://github.com/andriyor""><code>@​andriyor</code></a> (gh pr; <a href=""https://github-redirect.dependabot.com/dateutil/dateutil/issues/975"">#975</a>).</li>; <li>Simplified handling of byte",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11518:3260,depend,dependabot,3260,https://hail.is,https://github.com/hail-is/hail/pull/11518,2,['depend'],['dependabot']
Integrability,"y dict. Use 'hl.empty_dict' to create an empty dict.""); ---> 74 kts = {impute_type(element) for element in x.keys()}; 75 vts = {impute_type(element) for element in x.values()}. /home/hail/hail.zip/hail/expr/expressions/base_expression.py in impute_type(x); 85 elif x is None:; ---> 86 raise ExpressionException(""Hail cannot impute the type of 'None'""); 87 elif isinstance(x, (hl.expr.builders.CaseBuilder, hl.expr.builders.SwitchBuilder)):. ExpressionException: Hail cannot impute the type of 'None'. The above exception was the direct cause of the following exception:. TypecheckFailure Traceback (most recent call last); /home/hail/hail.zip/hail/typecheck/check.py in check_all(f, args, kwargs, checks, is_method); 487 arg = args[i]; --> 488 args_.append(checker.check(arg, name, arg_name)); 489 # passed as keyword. /home/hail/hail.zip/hail/expr/expressions/expression_typecheck.py in check(self, x, caller, param); 75 except ExpressionException as e:; ---> 76 raise TypecheckFailure from e; 77 . TypecheckFailure: . The above exception was the direct cause of the following exception:. TypeError Traceback (most recent call last); <ipython-input-76-5be38e2a21ef> in <module>; ----> 1 hl.eval({'a':2, None: 1}). </opt/conda/lib/python3.6/site-packages/decorator.py:decorator-gen-583> in eval(expression). /home/hail/hail.zip/hail/typecheck/check.py in wrapper(__original_func, *args, **kwargs); 558 @decorator; 559 def wrapper(__original_func, *args, **kwargs):; --> 560 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); 561 return __original_func(*args_, **kwargs_); 562 . /home/hail/hail.zip/hail/typecheck/check.py in check_all(f, args, kwargs, checks, is_method); 512 expected=checker.expects(),; 513 found=checker.format(arg); --> 514 )) from e; 515 elif param.kind == param.VAR_POSITIONAL:; 516 # consume the rest of the positional arguments. TypeError: eval: parameter 'expression': expected expression of type any, found dict: {'a': 2, None: 1}; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5700:2702,wrap,wrapper,2702,https://hail.is,https://github.com/hail-is/hail/issues/5700,2,['wrap'],['wrapper']
Integrability,"y for ECAlgorithm by <a href=""https://github.com/estin""><code>@​estin</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/713"">jpadilla/pyjwt#713</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/720"">jpadilla/pyjwt#720</a></li>; <li>api_jwk: Add PyJWKSet.<strong>getitem</strong> by <a href=""https://github.com/woodruffw""><code>@​woodruffw</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/725"">jpadilla/pyjwt#725</a></li>; <li>Update usage.rst by <a href=""https://github.com/guneybilen""><code>@​guneybilen</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/727"">jpadilla/pyjwt#727</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/728"">jpadilla/pyjwt#728</a></li>; <li>fix: Update copyright information by <a href=""https://github.com/kkirsche""><code>@​kkirsche</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/729"">jpadilla/pyjwt#729</a></li>; <li>Docs: mention performance reasons for reusing RSAPrivateKey when encoding by <a href=""https://github.com/dmahr1""><code>@​dmahr1</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/734"">jpadilla/pyjwt#734</a></li>; <li>Fixed typo in usage.rst by <a href=""https://github.com/israelabraham""><code>@​israelabraham</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/738"">jpadilla/pyjwt#738</a></li>; <li>Add detached payload support for JWS encoding and decoding by <a href=""https://github.com/fviard""><code>@​fviard</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/723"">jpadilla/pyjwt#723</a></li>; <li>[pre-commit.ci] pre-commit a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11866:3370,depend,dependabot,3370,https://hail.is,https://github.com/hail-is/hail/pull/11866,1,['depend'],['dependabot']
Integrability,"y leak (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1216"">#1216</a>)</li>; <li>fix <code>contrib.concurrent</code> with generators (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1233"">#1233</a> &lt;- <a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1231"">#1231</a>)</li>; </ul>; <h2>tqdm v4.62.1 stable</h2>; <ul>; <li><code>contrib.logging</code>: inherit existing handler output stream (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1191"">#1191</a>)</li>; <li>fix <code>PermissionError</code> by using <code>weakref</code> in <code>DisableOnWriteError</code> (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1207"">#1207</a>)</li>; <li>fix <code>contrib.telegram</code> creation rate limit handling (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1223"">#1223</a>, <a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1221"">#1221</a> &lt;- <a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1220"">#1220</a>, <a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1076"">#1076</a>)</li>; <li>tests: fix py27 <code>keras</code> dependencies (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1222"">#1222</a>)</li>; <li>misc tidy: use relative imports (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1222"">#1222</a>)</li>; <li>minor documentation updates (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1222"">#1222</a>)</li>; </ul>; <h2>tqdm v4.62.0 stable</h2>; <ul>; <li><code>asyncio.gather</code> API consistency with stdlib (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1212"">#1212</a>)</li>; <li>fix shutdown exception (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1209"">#1209</a> &lt;- <a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1198"">#1198</a>)</li>; <li>misc build framework updates (<a href=""https://github-redirect.dependabot.com/tqdm/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11587:2974,depend,dependabot,2974,https://hail.is,https://github.com/hail-is/hail/pull/11587,1,['depend'],['dependabot']
Integrability,"y list of the variant start positions. This is a fair bit of data. Chromosome 1 has about 250 million bases, so in the worst case this is 250 * 8 million bytes = 2 GB. It occurs to me that this is actually way to much data to load on the master node in general (since I just try to open the indexes for every file). I should switch this to a disk-based index.~ Made it disk-based, called it `OnDiskBTreeIndexToValue` #3794. - each hadoop `FileSplit` now contains a possibly null (indicating no filter) list of variants (by index) to keep, in practice this should be quite small. - ~I changed several asserts to `if`'s with fatals, so as not to allocate strings~ Moved to #3771. - ~We no longer copy the genotype data into a buffer in the block reader. This was forcing the `fastKeys` to do an unnecessary data copy~ Moved to #3783 (with some substantial refactoring so it doesn't look much like this PR anymore). - ~I changed the contract on BgenRecord to require that `getValue` is called to ""consume"" the record before the next record is taken~ Irrelevant thanks to #3783 's refactoring. - ~`getValue(null)` just skips bytes (no copy, no decompression)~ Irrelevant thanks to #3783 's refactoring. - ~I added `RegionValueBuilder.unsafeAdvance` which can be used when you're creating an array of empty structs but don't want to do all the unnecessary RVB bookkeeping work.~ Moved to #3773. - ~I use `RegionValueBuilder.unsafeAdvance` to make loading a BGEN without entry fields very fast.~ Rolled into #3783. - ~I fixed `Table.index` to not trigger a partition key info gathering~ Moved to #3774. I had to ship the arrays of filtered variant indices to the workers somehow, so I shipped them as base64 encoded arrays of bytes. It's pretty groady (and that's why I added the commons-codec library). I don't know how else to initialize record readers with hadoop. Generally, I think the BGEN loading code could use a clean up, and I haven't done that here, if anything I've made it more complicated. I a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3727:2308,contract,contract,2308,https://hail.is,https://github.com/hail-is/hail/pull/3727,1,['contract'],['contract']
Integrability,"y, Dict[Array[Call], Call]]]]],; dA0IS78I: Set[Empty],; VeGLA3v: Array[Array[Struct {; C: Empty,; sHjMXnj: Boolean,; G: Call; }]],; Ni: Struct {; HCrSI: Empty,; nJt7: Boolean; },; nxb8CkLI: Int,; y4mYv_DvH: Dict[Array[Genotype], Variant]; }; v [ WrappedArray( Set( WrappedArray(null); , WrappedArray(); , WrappedArray(Map(null -> Map(WrappedArray(2) -> 2)), Map(null -> Map(WrappedArray() -> 1)), Map(null -> Map(WrappedArray(1) -> 2))); ); , Set(WrappedArray(Map(null -> null), Map(null -> Map(WrappedArray(2) -> 31, WrappedArray(0) -> 0)))); , Set(WrappedArray(Map(null -> Map()), Map(null -> null))); , Set( WrappedArray(Map()); , WrappedArray(Map(null -> Map())); , WrappedArray(Map(null -> null)); , WrappedArray(); , WrappedArray(null, Map(null -> Map(WrappedArray() -> null)))); , Set(); , Set( WrappedArray(Map(null -> Map(WrappedArray() -> null))); , WrappedArray(); , WrappedArray(Map(null -> Map())); , WrappedArray(Map(null -> Map()), Map(null -> Map(WrappedArray() -> 2)))); , Set(WrappedArray()); , Set( WrappedArray(); , WrappedArray(Map(null -> Map()))); , Set(); , Set( WrappedArray(Map(null -> null)); , WrappedArray(Map(null -> Map()))); , Set( WrappedArray(Map(null -> Map(WrappedArray(null) -> 1)), Map(null -> Map(WrappedArray(5) -> 2))); , WrappedArray(Map())); , Set(); , Set(); , Set(WrappedArray(); , WrappedArray(Map(null -> Map()))); , Set(); , Set( null; , WrappedArray()); , Set( WrappedArray(Map(null -> Map(WrappedArray(1) -> 19))); , WrappedArray(Map(null -> Map(WrappedArray(0) -> 2)), Map(null -> Map())); , WrappedArray(Map(null -> Map())); , WrappedArray(Map(null -> Map(WrappedArray(2) -> null)), Map(null -> Map(WrappedArray() -> 17)), Map(null -> Map(WrappedArray() -> 1)))); , Set(WrappedArray(Map(null -> Map(WrappedArray(null) -> 1)), Map(null -> Map(WrappedArray(2) -> 0, WrappedArray() -> null)), Map(), Map())); , Set(WrappedArray(Map(null -> Map()), Map(null -> Map()), Map(null -> Map(WrappedArray(0) -> 0)))); , Set( WrappedArray(); , WrappedArray(Map(",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1902:1881,Wrap,WrappedArray,1881,https://hail.is,https://github.com/hail-is/hail/pull/1902,1,['Wrap'],['WrappedArray']
Integrability,"y, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI0Y2E5NmE2ZC02MjMxLTQ1YTctYmQyOS1kYTA0ZmZhNTliYzQiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjRjYTk2YTZkLTYyMzEtNDVhNy1iZDI5LWRhMDRmZmE1OWJjNCJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""4ca96a6d-6231-45a7-bd29-da04ffa59bc4"",""prPublicId"":""4ca96a6d-6231-45a7-bd29-da04ffa59bc4"",""dependencies"":[{""name"":""cryptography"",""from"":""41.0.7"",""to"":""42.0.2""}],""packageManager"":""pip"",""projectPublicId"":""c1c98f6a-57c6-4ecc-a329-3b744cab74bd"",""projectUrl"":""https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CRYPTOGRAPHY-6210214""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[451],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [NULL Pointer Dereference](https://learn.snyk.io/lesson/null-dereference/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14238:2872,depend,dependencies,2872,https://hail.is,https://github.com/hail-is/hail/pull/14238,1,['depend'],['dependencies']
Integrability,"y, but not all of the affected dependencies could be upgraded. Check the changes in this PR to ensure they won't cause issues with your project. ------------. **Note:** *You are seeing this because you or someone else with access to this repository has authorized Snyk to open fix PRs.*. For more information: <img src=""https://api.segment.io/v1/pixel/track?data=eyJ3cml0ZUtleSI6InJyWmxZcEdHY2RyTHZsb0lYd0dUcVg4WkFRTnNCOUEwIiwiYW5vbnltb3VzSWQiOiI1MzAxOWZkZC04YjQwLTQ5NmUtYjRmYS0wMzA5MTAxOTBkZWMiLCJldmVudCI6IlBSIHZpZXdlZCIsInByb3BlcnRpZXMiOnsicHJJZCI6IjUzMDE5ZmRkLThiNDAtNDk2ZS1iNGZhLTAzMDkxMDE5MGRlYyJ9fQ=="" width=""0"" height=""0""/>; 🧐 [View latest project report](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr). 🛠 [Adjust project settings](https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source&#x3D;github&amp;utm_medium&#x3D;referral&amp;page&#x3D;fix-pr/settings). 📚 [Read more about Snyk's upgrade and patch logic](https://support.snyk.io/hc/en-us/articles/360003891078-Snyk-patches-to-fix-vulnerabilities). [//]: # (snyk:metadata:{""prId"":""53019fdd-8b40-496e-b4fa-030910190dec"",""prPublicId"":""53019fdd-8b40-496e-b4fa-030910190dec"",""dependencies"":[{""name"":""cryptography"",""from"":""42.0.2"",""to"":""42.0.4""}],""packageManager"":""pip"",""projectPublicId"":""c1c98f6a-57c6-4ecc-a329-3b744cab74bd"",""projectUrl"":""https://app.snyk.io/org/danking/project/c1c98f6a-57c6-4ecc-a329-3b744cab74bd?utm_source=github&utm_medium=referral&page=fix-pr"",""type"":""auto"",""patch"":[],""vulns"":[""SNYK-PYTHON-CRYPTOGRAPHY-6261585""],""upgrade"":[],""isBreakingChange"":false,""env"":""prod"",""prType"":""fix"",""templateVariants"":[""updated-fix-title"",""pr-warning-shown"",""priorityScore""],""priorityScoreList"":[581],""remediationStrategy"":""vuln""}). ---. **Learn how to fix vulnerabilities with free interactive lessons:**. 🦉 [NULL Pointer Dereference](https://learn.snyk.io/lesson/null-dereference/?loc&#x3D;fix-pr)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14344:2878,depend,dependencies,2878,https://hail.is,https://github.com/hail-is/hail/pull/14344,1,['depend'],['dependencies']
Integrability,"y-core Windows machines (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7035"">#7035</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/b379ef3acc2a983140994c93a2ea2c99e260c9c1""><code>b379ef3</code></a> Fix handling of quoted <code>init-hook</code> (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7010"">#7010</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/c15902462af9100b5f7301f0cc978f2296e5d42f""><code>c159024</code></a> Fix differing param doc false positive (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/6980"">#6980</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/680edebc686cad664bbed934a490aeafa775f163""><code>680edeb</code></a> Bump pylint to 2.14.3, update changelog</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/b05ac51ad2e3785b6b9b071b8cb241993c914105""><code>b05ac51</code></a> Pin <code>colorama</code> to lowest supported version (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/6970"">#6970</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/PyCQA/pylint/compare/v2.13.5...v2.14.4"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pylint&package-manager=pip&previous-version=2.13.5&new-version=2.14.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, over",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11980:2605,depend,dependabot,2605,https://hail.is,https://github.com/hail-is/hail/pull/11980,1,['depend'],['dependabot']
Integrability,"y-python/commit/c8b5cae3da5eb9d40067d38dac51a4a8c1e0763e"">c8b5cae</a>)</li>; </ul>; <h2>v2.4.0</h2>; <h3>Features</h3>; <ul>; <li>add 'py.typed' declaration (<a href=""https://github-redirect.dependabot.com/googleapis/google-auth-library-python/issues/919"">#919</a>) (<a href=""https://github.com/googleapis/google-auth-library-python/commit/c99350455d0f7fd3aab950ac47b43000c73dd312"">c993504</a>)</li>; <li>add api key support (<a href=""https://github-redirect.dependabot.com/googleapis/google-auth-library-python/issues/826"">#826</a>) (<a href=""https://github.com/googleapis/google-auth-library-python/commit/3b15092b3461278400e4683060f64a96d50587c4"">3b15092</a>)</li>; </ul>; <h3>Bug Fixes</h3>; <ul>; <li><strong>deps:</strong> allow cachetools 5.0 for python 3.7+ (<a href=""https://github-redirect.dependabot.com/googleapis/google-auth-library-python/issues/937"">#937</a>) (<a href=""https://github.com/googleapis/google-auth-library-python/commit/1eae37db7f6fceb32d6ef0041962ce1755d2116c"">1eae37d</a>)</li>; <li>fix the message format for metadata server exception (<a href=""https://github-redirect.dependabot.com/googleapis/google-auth-library-python/issues/916"">#916</a>) (<a href=""https://github.com/googleapis/google-auth-library-python/commit/e756f08dc78616040ab8fbd7db20903137ccf0c7"">e756f08</a>)</li>; </ul>; <h3>Documentation</h3>; <ul>; <li>fix intersphinx link for 'requests-oauthlib' (<a href=""https://github-redirect.dependabot.com/googleapis/google-auth-library-python/issues/921"">#921</a>) (<a href=""https://github.com/googleapis/google-auth-library-python/commit/967be4f4e2a43ba7e240d7acb01b6b992d40e6ec"">967be4f</a>)</li>; <li>note ValueError in <code>verify_oauth2_token</code> (<a href=""https://github-redirect.dependabot.com/googleapis/google-auth-library-python/issues/928"">#928</a>) (<a href=""https://github.com/googleapis/google-auth-library-python/commit/82bc5f08111de78a2b475b0310d3f35470680dbe"">82bc5f0</a>)</li>; </ul>; <h2>v2.3.3</h2>; <h3>Bug Fixes</h3>; <ul>; <li>add fe",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11546:2690,message,message,2690,https://hail.is,https://github.com/hail-is/hail/pull/11546,1,['message'],['message']
Integrability,"y. - [x] No SQL; store user / svc / token labels (all things that need to be validated before redirect); - [x] Websockets; - [x] Service, pod definitions, makefile updates => notebook-v2 service name; - [x] Deploy notebook service, Deploy web service ( say web service name, mapping to web.hail.is ); - [x] Direct modification of gateway: check site service for breaks after each change to prevent user ; - [x] Test in cluster; - [x] Make sure Notebook v1 still works; - [ ] Stretch, and only in v3 so Feb 5 entropy minimized: asynchttp + uvloop; - [ ] Stretch ?: route by pod ip instead of svc name: DNS propagation latency significantly longer than pod instantiation time, which sucks for users, both because notebook instances will look broken when they're not, and because if we mask that the apparent latency to first useful operation is multiples of that needed. new: ; Cotton is right, mysql is adding too much complexity for the minimal use case, esp. with gevent conflicting with PyMySQL, necessitating per route handler connection. old:; Not ready to be merged, would like to improve SQL connection handling. 6a4599df5dfe0affdb5e367dd9cdc70cca59fd17 onward dependent on this. MySQL use is unoptimized because PyMySQL doesn't play well with gevent in the following way: initial impression from reading was that monkey.patch_all() before creation of global connection should result in connection spawned for each new request, or to at least private to a greenlet. Doesn't appear to be the case, plenty of connection errors. So establishing connection within each request, which is slow. . Python C library also out, because it does not play well with Python threading/greenlet/monkey patch implementations. MySQL Connector is an option, provides thread pools, but is also slowest option, by up to 10x, for small requests, like our are likely to be. However, that will be next implementation, for velocity/documentation reasons. . A better, third, more unwieldy solution is to use the C librar",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5215:1162,rout,route,1162,https://hail.is,https://github.com/hail-is/hail/pull/5215,1,['rout'],['route']
Integrability,"y.</li>; <li><a href=""https://github.com/mrabarnett/mrab-regex/commit/16bcce0d56e84367f61c24b369e23e73a3e9ad9e""><code>16bcce0</code></a> Add changelog.txt.</li>; <li><a href=""https://github.com/mrabarnett/mrab-regex/commit/d235c2c17f2335dd7699f3c29a6ae6db6dbe6dab""><code>d235c2c</code></a> pyproject.toml was missing.</li>; <li><a href=""https://github.com/mrabarnett/mrab-regex/commit/78460dc755b09966ee6e87d04c8dcfca7212256b""><code>78460dc</code></a> Added pyproject.toml.</li>; <li>See full diff in <a href=""https://github.com/mrabarnett/mrab-regex/compare/2023.3.23...2023.5.5"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=regex&package-manager=pip&previous-version=2023.3.23&new-version=2023.5.5)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12989:3269,Depend,Dependabot,3269,https://hail.is,https://github.com/hail-is/hail/pull/12989,1,['Depend'],['Dependabot']
Integrability,"y/commit/d6951dca25de45abd52da51b608055371fbcde4e""><code>d6951dc</code></a> changelog + security fix backport (<a href=""https://github-redirect.dependabot.com/pyca/cryptography/issues/8231"">#8231</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/138da90c8450446b19619e3faa77b9da54c34be3""><code>138da90</code></a> workaround scapy bug in downstream tests (<a href=""https://github-redirect.dependabot.com/pyca/cryptography/issues/8218"">#8218</a>) (<a href=""https://github-redirect.dependabot.com/pyca/cryptography/issues/8228"">#8228</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/69527bc79095c9646d7e839121f0783477892ecc""><code>69527bc</code></a> bookworm is py311 now (<a href=""https://github-redirect.dependabot.com/pyca/cryptography/issues/8200"">#8200</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/111deefb659b8d73c56d3ce89458f2df973d60e4""><code>111deef</code></a> backport main branch CI to 39.0.x (<a href=""https://github-redirect.dependabot.com/pyca/cryptography/issues/8153"">#8153</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/338a65a7df74e189f6b5d1d3a6315ffa911b21c2""><code>338a65a</code></a> 39.0.0 version bump (<a href=""https://github-redirect.dependabot.com/pyca/cryptography/issues/7954"">#7954</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/84a3cd7abb16f594d8c315e8aedb4be02583bf6a""><code>84a3cd7</code></a> automatically download and upload circleci wheels (<a href=""https://github-redirect.dependabot.com/pyca/cryptography/issues/7949"">#7949</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/525c0b3d5d89eab7f953be5de5d2b75da1c816f8""><code>525c0b3</code></a> Type annotate release.py (<a href=""https://github-redirect.dependabot.com/pyca/cryptography/issues/7951"">#7951</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/46d2a94d1b574abf5b9e88f84fa7400a138c4edb""><code>46d2a94</code></a> Use the latest 3.10 release when wheel building (<a href=""htt",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12668:4395,depend,dependabot,4395,https://hail.is,https://github.com/hail-is/hail/pull/12668,4,['depend'],['dependabot']
Integrability,"y/issues/1101"">#1101</a>)</li>; <li>Synchronized reading the responses from a connection; (see <a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1106"">#1106</a>)</li>; </ul>; <h3>Fixes</h3>; <ul>; <li>Remove <strong>del</strong> from Redis (Fixes <a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1115"">#1115</a>); (see <a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1227"">#1227</a>)</li>; <li>fix socket.error raises (see <a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1129"">#1129</a>)</li>; <li>Fix buffer is closed error when using PythonParser class; (see <a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1213"">#1213</a>)</li>; </ul>; <h2>2.0.0 - (2021-03-18)</h2>; <h3>Features</h3>; <ul>; <li>; <p>Port redis-py's client implementation to aioredis.<br />; (see <a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/891"">#891</a>)</p>; </li>; <li>; <p>Make hiredis an optional dependency.<br />; (see <a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/917"">#917</a>)</p>; </li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/aio-libs/aioredis-py/commit/224f843bd4b33d657770bded6f86ce33b881257c""><code>224f843</code></a> Release version 2.0.1 (<a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1247"">#1247</a>)</li>; <li><a href=""https://github.com/aio-libs/aioredis-py/commit/a9825c2ac35939b9ad8928e9468335d8efab963f""><code>a9825c2</code></a> Bump py-actions/py-dependency-install from 2.1.0 to 3 (<a href=""https://github-redirect.dependabot.com/aio-libs/aioredis-py/issues/1239"">#1239</a>)</li>; <li><a href=""https://github.com/aio-libs/aioredis-py/commit/7f65c4ccb0e954c17f2a3e1ecc665c62e4a1aaeb""><code>7f65c4c</code></a> Remove <strong>del</strong> from Redis (Fixes <a href=""https://github-redirect.dependabot.com/ai",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11569:3491,depend,dependency,3491,https://hail.is,https://github.com/hail-is/hail/pull/11569,1,['depend'],['dependency']
Integrability,"y/issues/3029"">#3029</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/docker/docker-py/compare/5.0.3...6.0.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=docker&package-manager=pip&previous-version=5.0.3&new-version=6.0.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12475:7830,Depend,Dependabot,7830,https://hail.is,https://github.com/hail-is/hail/pull/12475,17,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability,"y=...&lt;/li&gt;; &lt;li&gt;&lt;a href=&quot;https://github.com/jpadilla/pyjwt/commit/35fa28e59d99b99c6a780d2a029a74d6bbba8b1e&quot;&gt;&lt;code&gt;35fa28e&lt;/code&gt;&lt;/a&gt; [pre-commit.ci] pre-commit autoupdate (&lt;a href=&quot;https://github-redirect.dependabot.com/jpadilla/pyjwt/issues/740&quot;&gt;#740&lt;/a&gt;)&lt;/li&gt;; &lt;li&gt;Additional commits viewable in &lt;a href=&quot;https://github.com/jpadilla/pyjwt/compare/1.7.1...2.4.0&quot;&gt;compare view&lt;/a&gt;&lt;/li&gt;; &lt;/ul&gt;; &lt;/details&gt;. &lt;br /&gt;; </code></pre>. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pyjwt&package-manager=pip&previous-version=1.7.1&new-version=2.4.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11866:15095,depend,dependabot,15095,https://hail.is,https://github.com/hail-is/hail/pull/11866,1,['depend'],['dependabot']
Integrability,"y>Commits</summary>; <ul>; <li><a href=""https://github.com/pyca/cryptography/commit/f09c261ca10a31fe41b1262306db7f8f1da0e48a""><code>f09c261</code></a> 41.0.6 release (<a href=""https://redirect.github.com/pyca/cryptography/issues/9927"">#9927</a>)</li>; <li>See full diff in <a href=""https://github.com/pyca/cryptography/compare/41.0.5...41.0.6"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=cryptography&package-manager=pip&previous-version=41.0.5&new-version=41.0.6)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14046:1558,Depend,Dependabot,1558,https://hail.is,https://github.com/hail-is/hail/pull/14046,3,['Depend'],['Dependabot']
Integrability,"yCQA/astroid) from 2.11.5 to 2.12.9.; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/PyCQA/astroid/blob/main/ChangeLog"">astroid's changelog</a>.</em></p>; <blockquote>; <h1>What's New in astroid 2.12.9?</h1>; <p>Release date: 2022-09-07</p>; <ul>; <li>; <p>Fixed creation of the <code>__init__</code> of <code>dataclassess</code> with multiple inheritance.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7427"">PyCQA/pylint#7427</a></p>; </li>; <li>; <p>Fixed a crash on <code>namedtuples</code> that use <code>typename</code> to specify their name.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7429"">PyCQA/pylint#7429</a></p>; </li>; </ul>; <h1>What's New in astroid 2.12.8?</h1>; <p>Release date: 2022-09-06</p>; <ul>; <li>; <p>Fixed a crash in the <code>dataclass</code> brain for <code>InitVars</code> without subscript typing.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7422"">PyCQA/pylint#7422</a></p>; </li>; <li>; <p>Fixed parsing of default values in <code>dataclass</code> attributes.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7425"">PyCQA/pylint#7425</a></p>; </li>; </ul>; <h1>What's New in astroid 2.12.7?</h1>; <p>Release date: 2022-09-06</p>; <ul>; <li>; <p>Fixed a crash in the <code>dataclass</code> brain for uninferable bases.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7418"">PyCQA/pylint#7418</a></p>; </li>; </ul>; <h1>What's New in astroid 2.12.6?</h1>; <p>Release date: 2022-09-05</p>; <ul>; <li>; <p>Fix a crash involving <code>Uninferable</code> arguments to <code>namedtuple()</code>.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7375"">PyCQA/pylint#7375</a></p>; </li>; <li>; <p>The <code>dataclass</code> brain now understands the <code>kw_only</code> keyword in dataclass decorators.</p>; <p>Closes <a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12161:1031,depend,dependabot,1031,https://hail.is,https://github.com/hail-is/hail/pull/12161,1,['depend'],['dependabot']
Integrability,"yCQA/pycodestyle/commit/10a4427c75740717b43448339fcf71f11bc33d1a""><code>10a4427</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/PyCQA/pycodestyle/issues/1092"">#1092</a> from PyCQA/2_9_1</li>; <li><a href=""https://github.com/PyCQA/pycodestyle/commit/c33e852a5938b823b04dd981260bd1664c643385""><code>c33e852</code></a> Release 2.9.1</li>; <li><a href=""https://github.com/PyCQA/pycodestyle/commit/c97e4f86bd60e449a64be6c0de5b5ec5bb28b8e9""><code>c97e4f8</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/PyCQA/pycodestyle/issues/1091"">#1091</a> from asottile/E275-yield-expression</li>; <li><a href=""https://github.com/PyCQA/pycodestyle/commit/43c5afaeef44a01b512ade340030ff4d7b0ba78e""><code>43c5afa</code></a> allow parenthesized yield (generator-coroutines)</li>; <li><a href=""https://github.com/PyCQA/pycodestyle/commit/9e6e820b269cbe39da854ae2835bd797028d22db""><code>9e6e820</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/PyCQA/pycodestyle/issues/1089"">#1089</a> from PyCQA/pre-commit-ci-update-config</li>; <li><a href=""https://github.com/PyCQA/pycodestyle/commit/9851cb692a2f824495f6bbdded03059116bb46bb""><code>9851cb6</code></a> [pre-commit.ci] pre-commit autoupdate</li>; <li><a href=""https://github.com/PyCQA/pycodestyle/commit/44b3d2895b39b1eff8cb5048ae3464a033b4ede8""><code>44b3d28</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/PyCQA/pycodestyle/issues/1087"">#1087</a> from PyCQA/2_9_0</li>; <li><a href=""https://github.com/PyCQA/pycodestyle/commit/57e39fa4f66707c305ead679e62d7ce1b7af9362""><code>57e39fa</code></a> Release 2.9.0</li>; <li><a href=""https://github.com/PyCQA/pycodestyle/commit/ab806f3f9133ca24366b6254e499f0363f6bf5ec""><code>ab806f3</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/PyCQA/pycodestyle/issues/1085"">#1085</a> from PyCQA/revert-1041</li>; <li><a href=""https://github.com/PyCQA/pycodestyle/commit/c14bd2aac8e370bc8404",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12476:2352,depend,dependabot,2352,https://hail.is,https://github.com/hail-is/hail/pull/12476,1,['depend'],['dependabot']
Integrability,"yCQA/pylint#7422</a></p>; </li>; <li>; <p>Fixed parsing of default values in <code>dataclass</code> attributes.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7425"">PyCQA/pylint#7425</a></p>; </li>; </ul>; <h1>What's New in astroid 2.12.7?</h1>; <p>Release date: 2022-09-06</p>; <ul>; <li>; <p>Fixed a crash in the <code>dataclass</code> brain for uninferable bases.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7418"">PyCQA/pylint#7418</a></p>; </li>; </ul>; <h1>What's New in astroid 2.12.6?</h1>; <p>Release date: 2022-09-05</p>; <ul>; <li>; <p>Fix a crash involving <code>Uninferable</code> arguments to <code>namedtuple()</code>.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7375"">PyCQA/pylint#7375</a></p>; </li>; <li>; <p>The <code>dataclass</code> brain now understands the <code>kw_only</code> keyword in dataclass decorators.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7290"">PyCQA/pylint#7290</a></p>; </li>; </ul>; <h1>What's New in astroid 2.12.5?</h1>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/PyCQA/astroid/commit/7352e947bdf9b9c5ea51e601bbed7a063e98316d""><code>7352e94</code></a> Bump astroid to 2.12.9, update changelog</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/449a95b08e39dd2d6f3a6c3cbf4ace3055340b46""><code>449a95b</code></a> Fixed the <code>__init__</code> of <code>dataclassess</code> with multiple inheritance (<a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1774"">#1774</a>)</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/d15466685643b47f3b8b42ae5c0ba14a429a5293""><code>d154666</code></a> Fix a crash on <code>namedtuples</code> that use <code>typename</code> (<a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1773"">#1773</a>)</li>; <li><a hre",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12161:2068,depend,dependabot,2068,https://hail.is,https://github.com/hail-is/hail/pull/12161,1,['depend'],['dependabot']
Integrability,"yCQA/pylint#7422</a></p>; </li>; <li>; <p>Fixed parsing of default values in <code>dataclass</code> attributes.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7425"">PyCQA/pylint#7425</a></p>; </li>; </ul>; <h1>What's New in astroid 2.12.7?</h1>; <p>Release date: 2022-09-06</p>; <ul>; <li>; <p>Fixed a crash in the <code>dataclass</code> brain for uninferable bases.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7418"">PyCQA/pylint#7418</a></p>; </li>; </ul>; <h1>What's New in astroid 2.12.6?</h1>; <p>Release date: 2022-09-05</p>; <ul>; <li>; <p>Fix a crash involving <code>Uninferable</code> arguments to <code>namedtuple()</code>.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7375"">PyCQA/pylint#7375</a></p>; </li>; <li>; <p>The <code>dataclass</code> brain now understands the <code>kw_only</code> keyword in dataclass decorators.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7290"">PyCQA/pylint#7290</a></p>; </li>; </ul>; <h1>What's New in astroid 2.12.5?</h1>; <p>Release date: 2022-08-29</p>; <ul>; <li>; <p>Prevent first-party imports from being resolved to <code>site-packages</code>.</p>; <p>Refs <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7365"">PyCQA/pylint#7365</a></p>; </li>; <li>; <p>Fix <code>astroid.interpreter._import.util.is_namespace()</code> incorrectly; returning <code>True</code> for frozen stdlib modules on PyPy.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1755"">#1755</a></p>; </li>; </ul>; <h1>What's New in astroid 2.12.4?</h1>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/PyCQA/astroid/commit/65bca39bbf254bc760ac9d388e5a09333eaf5c87""><code>65bca39</code></a> Bump astroid to 2.12.8, update changelog</li>; <li><a href=""https://github.com/PyCQA",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12158:1522,depend,dependabot,1522,https://hail.is,https://github.com/hail-is/hail/pull/12158,1,['depend'],['dependabot']
Integrability,"yCQA/pylint/commit/e8202000e046e286816375f5887110cacda4d11b""><code>e820200</code></a> Normalize path before checking if path should be ignored (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7080"">#7080</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/c82d08c8433de92433b9b555dd2eb50a7987060f""><code>c82d08c</code></a> Don't report <code>import-private-name</code> for relative imports (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7079"">#7079</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/f8f05f12522c0036668f9a0da86fa0d3456ed795""><code>f8f05f1</code></a> Don't emit <code>modified-iterating-dict</code> when updating existing keys (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7037"">#7037</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/bee24cd55af4f1231e787aed5a1cc072492adee6""><code>bee24cd</code></a> Avoid hangs on many-core Windows machines (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7035"">#7035</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/b379ef3acc2a983140994c93a2ea2c99e260c9c1""><code>b379ef3</code></a> Fix handling of quoted <code>init-hook</code> (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7010"">#7010</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/c15902462af9100b5f7301f0cc978f2296e5d42f""><code>c159024</code></a> Fix differing param doc false positive (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/6980"">#6980</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/680edebc686cad664bbed934a490aeafa775f163""><code>680edeb</code></a> Bump pylint to 2.14.3, update changelog</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/b05ac51ad2e3785b6b9b071b8cb241993c914105""><code>b05ac51</code></a> Pin <code>colorama</code> to lowest supported version (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/6970"">#6970</a>)</li>; <li>Additio",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11980:1668,depend,dependabot,1668,https://hail.is,https://github.com/hail-is/hail/pull/11980,1,['depend'],['dependabot']
Integrability,"yCQA/pylint/issues/6089"">#6089</a></p>; </li>; <li>; <p>Narrow the scope of the <code>unnecessary-ellipsis</code> checker to:</p>; <ul>; <li>functions &amp; classes which contain both a docstring and an ellipsis.</li>; <li>A body which contains an ellipsis <code>nodes.Expr</code> node &amp; at least one other statement.</li>; </ul>; </li>; <li>; <p>Fix false positive for <code>used-before-assignment</code> for assignments taking place via; nonlocal declarations after an earlier type annotation.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5394"">#5394</a></p>; </li>; <li>; <p>Fix crash for <code>redefined-slots-in-subclass</code> when the type of the slot is not a const or a string.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/6100"">#6100</a></p>; </li>; <li>; <p>Only raise <code>not-callable</code> when all the inferred values of a property are not callable.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5931"">#5931</a></p>; </li>; <li>; <p>Fix a false negative for <code>subclassed-final-class</code> when a set of other messages were disabled.</p>; </li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/PyCQA/pylint/commit/95cbd2bd14576cb5d9eade4798e73e8601c884de""><code>95cbd2b</code></a> Bump pylint to 2.13.5, update changelog</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/2e9b33b13264a3cc229e879e7c03b36acd523554""><code>2e9b33b</code></a> Bump black from 22.1.0 to 22.3.0 (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/6176"">#6176</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/f251131eaf88c0a6b30983b9ccd8d2924e28fe38""><code>f251131</code></a> Add <code>subclassed-final-class</code> message to the <code>check_messages</code> decorator (#...</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/a03b6e77bef920a7c72be9f3e2c2babddecd2fd2""><code>a03b6",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11739:2224,depend,dependabot,2224,https://hail.is,https://github.com/hail-is/hail/pull/11739,1,['depend'],['dependabot']
Integrability,"yCQA/pylint/issues/6100"">#6100</a></p>; </li>; <li>; <p>Only raise <code>not-callable</code> when all the inferred values of a property are not callable.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5931"">#5931</a></p>; </li>; <li>; <p>Fix a false negative for <code>subclassed-final-class</code> when a set of other messages were disabled.</p>; </li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/PyCQA/pylint/commit/95cbd2bd14576cb5d9eade4798e73e8601c884de""><code>95cbd2b</code></a> Bump pylint to 2.13.5, update changelog</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/2e9b33b13264a3cc229e879e7c03b36acd523554""><code>2e9b33b</code></a> Bump black from 22.1.0 to 22.3.0 (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/6176"">#6176</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/f251131eaf88c0a6b30983b9ccd8d2924e28fe38""><code>f251131</code></a> Add <code>subclassed-final-class</code> message to the <code>check_messages</code> decorator (#...</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/a03b6e77bef920a7c72be9f3e2c2babddecd2fd2""><code>a03b6e7</code></a> Prevent <code>used-before-assignment</code> for assignment via nonlocal after type annot...</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/074131312977fbd423fe4faff004d4fa8dbba4e5""><code>0741313</code></a> Only emit <code>lru-cache-decorating-method</code> when <code>maxsize</code> is <code>None</code> (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/6181"">#6181</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/702474327d7c756b61b82a1805efdd32c2d78ca8""><code>7024743</code></a> Fix false positive for <code>unused-import</code> when disabling both ``used-before-as...</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/4213b3c9a1d4ea7213636b67954dfbd95e290e91""><code>4213b3c</code></a> Fix handling of &quot;for x in x&quot;",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11739:3060,message,message,3060,https://hail.is,https://github.com/hail-is/hail/pull/11739,1,['message'],['message']
Integrability,"yMySQL/PyMySQL/issues/941"">#941</a>)</li>; <li><a href=""https://github.com/PyMySQL/PyMySQL/commit/5c6f8bcb741c32719a07e8c95eb8050cb9249511""><code>5c6f8bc</code></a> v1.0.1</li>; <li><a href=""https://github.com/PyMySQL/PyMySQL/commit/2d36a195060b46e12f16d8b776468bab53ea6919""><code>2d36a19</code></a> Remove warning for db and passwd. (<a href=""https://github-redirect.dependabot.com/PyMySQL/PyMySQL/issues/940"">#940</a>)</li>; <li><a href=""https://github.com/PyMySQL/PyMySQL/commit/0acaa7f4fa4e2a9a30c835fc1be0b74eec3aaf87""><code>0acaa7f</code></a> Use built-in unittest.mock (<a href=""https://github-redirect.dependabot.com/PyMySQL/PyMySQL/issues/938"">#938</a>)</li>; <li><a href=""https://github.com/PyMySQL/PyMySQL/commit/7c4700bd66b36e6e50e7f8c7df57635f0dafb006""><code>7c4700b</code></a> Remove tox</li>; <li><a href=""https://github.com/PyMySQL/PyMySQL/commit/5d1e27de3f35a936f7baf63036098d44f4a41a58""><code>5d1e27d</code></a> Set python_requires='&gt;=3.6' (<a href=""https://github-redirect.dependabot.com/PyMySQL/PyMySQL/issues/936"">#936</a>)</li>; <li><a href=""https://github.com/PyMySQL/PyMySQL/commit/5a02e5780f615ac7793373d63c407b979c33cd1c""><code>5a02e57</code></a> remove badges</li>; <li><a href=""https://github.com/PyMySQL/PyMySQL/commit/f65351b1bd6c02eab07f20cbedada6ebfbf6d56d""><code>f65351b</code></a> Do not create universal wheel</li>; <li><a href=""https://github.com/PyMySQL/PyMySQL/commit/6e5d5bd94af056c66a1ed05de754a83f8628faea""><code>6e5d5bd</code></a> v1.0.0</li>; <li>Additional commits viewable in <a href=""https://github.com/PyMySQL/PyMySQL/compare/v0.9.2...v1.0.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pymysql&package-manager=pip&previous-version=0.9.2&new-version=1.0.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11595:4104,depend,dependabot,4104,https://hail.is,https://github.com/hail-is/hail/pull/11595,1,['depend'],['dependabot']
Integrability,"ySimpleGUI</code></a>; thanks a lot! ;)</li>; <li><a href=""https://github.com/giampaolo/psutil/commit/ff2f4d4c4986bffbc5348a197396e11bef057346""><code>ff2f4d4</code></a> assert scripts have +x bit</li>; <li><a href=""https://github.com/giampaolo/psutil/commit/ebbaae8d1f42f051282af79d60f19cb1161088a5""><code>ebbaae8</code></a> git pre commit hook: use shlex.split()</li>; <li><a href=""https://github.com/giampaolo/psutil/commit/39dc44bfa5fbb9500166b3480295379602e5bbc5""><code>39dc44b</code></a> Automatically sort imports (isort CLI tool) (<a href=""https://github-redirect.dependabot.com/giampaolo/psutil/issues/2033"">#2033</a>)</li>; <li><a href=""https://github.com/giampaolo/psutil/commit/b490b5d51af6ed29709c357a00fcdb6bda26df78""><code>b490b5d</code></a> fix missing arg passed to C psutil_debug()</li>; <li><a href=""https://github.com/giampaolo/psutil/commit/eb2f74c153987b4e0d03aa16931d97e8137d9257""><code>eb2f74c</code></a> Fix CI tests / wheels / workflow (<a href=""https://github-redirect.dependabot.com/giampaolo/psutil/issues/2024"">#2024</a>)</li>; <li><a href=""https://github.com/giampaolo/psutil/commit/a1ae994cabff37eb86c6ca4564b4f193a73a7b0d""><code>a1ae994</code></a> fix <a href=""https://github-redirect.dependabot.com/giampaolo/psutil/issues/2023"">#2023</a> [Linux] cpu_freq() return order is wrong on systems with &gt; 9 CPUs.</li>; <li><a href=""https://github.com/giampaolo/psutil/commit/875d2195fc8efa642c7bca714d468551d1805c6c""><code>875d219</code></a> Handle missing dependencies on MidnightBSD (<a href=""https://github-redirect.dependabot.com/giampaolo/psutil/issues/2019"">#2019</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/giampaolo/psutil/compare/release-5.8.0...release-5.9.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=psutil&package-manager=pip&previous-version=5.8.0&new-version=5.9.0)](https://docs.github.com/en/github/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11459:5454,depend,dependabot,5454,https://hail.is,https://github.com/hail-is/hail/pull/11459,1,['depend'],['dependabot']
Integrability,yUnbufferedWritableByteChannel.writeAndClose(ApiaryUnbufferedWritableByteChannel.java:65) ~[gs:__hail-query-ger0g_jars_13536b531342a263b24a7165bfeec7bd02723e4b.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.UnbufferedWritableByteChannelSession$UnbufferedWritableByteChannel.writeAndClose(UnbufferedWritableByteChannelSession.java:40) ~[gs:__hail-query-ger0g_jars_13536b531342a263b24a7165bfeec7bd02723e4b.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.DefaultBufferedWritableByteChannel.close(DefaultBufferedWritableByteChannel.java:166) ~[gs:__hail-query-ger0g_jars_13536b531342a263b24a7165bfeec7bd02723e4b.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.StorageByteChannels$SynchronizedBufferedWritableByteChannel.close(StorageByteChannels.java:119) ~[gs:__hail-query-ger0g_jars_13536b531342a263b24a7165bfeec7bd02723e4b.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.StorageException.wrapIOException(StorageException.java:179) ~[gs:__hail-query-ger0g_jars_13536b531342a263b24a7165bfeec7bd02723e4b.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.BaseStorageWriteChannel.close(BaseStorageWriteChannel.java:84) ~[gs:__hail-query-ger0g_jars_13536b531342a263b24a7165bfeec7bd02723e4b.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.GoogleStorageFS$$anon$2.$anonfun$close$2(GoogleStorageFS.scala:326) ~[gs:__hail-query-ger0g_jars_13536b531342a263b24a7165bfeec7bd02723e4b.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.GoogleStorageFS$$anon$2.doHandlingRequesterPays(GoogleStorageFS.scala:296) ~[gs:__hail-query-ger0g_jars_13536b531342a263b24a7165bfeec7bd02723e4b.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.GoogleStorageFS$$anon$2.$anonfun$close$1(GoogleStorageFS.scala:326) ~[gs:__hail-query-ger0g_jars_13536b531342a263b24a7165bfeec7bd02723e4b.jar.jar:0.0.1-SNAPSHOT]; 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.15.jar:?]; 	at is.hail.servi,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13721:9253,wrap,wrapIOException,9253,https://hail.is,https://github.com/hail-is/hail/issues/13721,1,['wrap'],['wrapIOException']
Integrability,"yca/cryptography/commit/88e8c288975709228005e70301644034463d9823""><code>88e8c28</code></a> Bump BoringSSL and/or OpenSSL in CI (<a href=""https://redirect.github.com/pyca/cryptography/issues/8983"">#8983</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/3e24e44527a69884ca0c3247e1b5e9c8bbf590c9""><code>3e24e44</code></a> Bump once_cell from 1.17.1 to 1.17.2 in /src/rust (<a href=""https://redirect.github.com/pyca/cryptography/issues/8982"">#8982</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/pyca/cryptography/compare/40.0.2...41.0.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=cryptography&package-manager=pip&previous-version=40.0.2&new-version=41.0.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13141:4721,Depend,Dependabot,4721,https://hail.is,https://github.com/hail-is/hail/pull/13141,3,['Depend'],['Dependabot']
Integrability,"yca/cryptography/issues/7951"">#7951</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/46d2a94d1b574abf5b9e88f84fa7400a138c4edb""><code>46d2a94</code></a> Use the latest 3.10 release when wheel building (<a href=""https://github-redirect.dependabot.com/pyca/cryptography/issues/7953"">#7953</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/f150dc15582c05b1b94cf08ed3b1fbc9c4f52267""><code>f150dc1</code></a> fix CI to work with ubuntu 22.04 (<a href=""https://github-redirect.dependabot.com/pyca/cryptography/issues/7950"">#7950</a>)</li>; <li><a href=""https://github.com/pyca/cryptography/commit/8867724b2b6db528d2900414ef86c122a1f5602a""><code>8867724</code></a> fix README for python3 (<a href=""https://github-redirect.dependabot.com/pyca/cryptography/issues/7947"">#7947</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/pyca/cryptography/compare/38.0.4...39.0.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=cryptography&package-manager=pip&previous-version=38.0.4&new-version=39.0.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel me",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12668:6142,Depend,Dependabot,6142,https://hail.is,https://github.com/hail-is/hail/pull/12668,8,"['Depend', 'depend']","['Dependabot', 'dependabot-badges']"
Integrability,"ycares/commit/22a37d760349787704f8901c19e149915a7f1b26""><code>22a37d7</code></a> Update c-ares submodule to 1.18.1</li>; <li><a href=""https://github.com/saghul/pycares/commit/b5165834724340d27da642f554431514fd62ccb4""><code>b516583</code></a> Improve test compatibility with pytest</li>; <li><a href=""https://github.com/saghul/pycares/commit/356118f2985de1fdb09d2db8951f592fc6418fda""><code>356118f</code></a> Drop tox</li>; <li><a href=""https://github.com/saghul/pycares/commit/baad65cd4088f7a7108e3b2e3d5c1f4b97fc6a7e""><code>baad65c</code></a> Drop CPython 3.6</li>; <li><a href=""https://github.com/saghul/pycares/commit/24fea0ce9988c3985892104f55c4ad256e28a78f""><code>24fea0c</code></a> Run tests on Python 3.11</li>; <li><a href=""https://github.com/saghul/pycares/commit/0e970c4b27bcdc940d972eaf3c57a3c93e79be78""><code>0e970c4</code></a> Add Python 3.11 classifier to setup.py</li>; <li><a href=""https://github.com/saghul/pycares/commit/05c74ef9e4f302ba433368f3c5c714abcadec40c""><code>05c74ef</code></a> Fix some tests that depended on external sites</li>; <li><a href=""https://github.com/saghul/pycares/commit/06d1ecdd57d4da4ddbe751463c576dcaf0f3baf8""><code>06d1ecd</code></a> build: bump cibuildwheel to build for Python 3.11 + CI total time speedups</li>; <li>See full diff in <a href=""https://github.com/saghul/pycares/compare/pycares-4.2.2...pycares-4.3.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pycares&package-manager=pip&previous-version=4.2.2&new-version=4.3.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>D",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12559:3074,depend,depended,3074,https://hail.is,https://github.com/hail-is/hail/pull/12559,1,['depend'],['depended']
Integrability,"yer</code></a> (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7514"">#7514</a>)</li>; <li><a href=""https://github.com/sveltejs/svelte/commit/4583b170842208bcafcbb095221c8ac12689f739""><code>4583b17</code></a> Update CHANGELOG.md</li>; <li><a href=""https://github.com/sveltejs/svelte/commit/02f60fbebf7cdb036472d1aec8dc9d9f8215cd7a""><code>02f60fb</code></a> [fix]destroy empty component (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7492"">#7492</a>)</li>; <li><a href=""https://github.com/sveltejs/svelte/commit/31e5f8b5de24e2e058cb1a70467c0092e422ee5d""><code>31e5f8b</code></a> [docs] &quot;What's new in Svelte&quot; July newsletter (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7637"">#7637</a>)</li>; <li><a href=""https://github.com/sveltejs/svelte/commit/6f575715073f4a1eb1abdd7a2d22a75ae6017cf7""><code>6f57571</code></a> [feat] add convenience types ComponentType and ComponentProps (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/6770"">#6770</a>)</li>; <li><a href=""https://github.com/sveltejs/svelte/commit/2f562d9e2817d911d0eec437d2b0e45074ec8291""><code>2f562d9</code></a> [docs] use npm create instead of npm init (<a href=""https://github-redirect.dependabot.com/sveltejs/svelte/issues/7641"">#7641</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/sveltejs/svelte/compare/v3.38.2...v3.49.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=svelte&package-manager=npm_and_yarn&previous-version=3.38.2&new-version=3.49.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-star",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12032:8153,depend,dependabot,8153,https://hail.is,https://github.com/hail-is/hail/pull/12032,3,['depend'],['dependabot']
Integrability,"yiii/henryiii/fix/commandtype</li>; <li>Additional commits viewable in <a href=""https://github.com/pallets/click/compare/8.0.4...8.1.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=click&package-manager=pip&previous-version=8.0.4&new-version=8.1.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11801:7409,Depend,Dependabot,7409,https://hail.is,https://github.com/hail-is/hail/pull/11801,17,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability,"ylint/issues/49"">#49</a>, <a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/pull/50"">#50</a>). Thanks to <a href=""https://github.com/jayvdb""><code>@​jayvdb</code></a>.</li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/thibaudcolas/curlylint/blob/main/CHANGELOG.md"">curlylint's changelog</a>.</em></p>; <blockquote>; <h2><a href=""https://github.com/thibaudcolas/curlylint/releases/tag/v0.13.0"">v0.13.0</a> 2021-04-25</h2>; <p>This release comes with a blog post! Read on <a href=""https://www.curlylint.org/blog/quality-of-life-improvements"">Quality-of-life improvements</a>.</p>; <h3>Added</h3>; <ul>; <li>Implement --template-tags CLI flag (<a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/issues/25"">#25</a>, <a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/pull/77"">#77</a>).</li>; </ul>; <h3>Changed</h3>; <ul>; <li>Add more descriptive error message for missing whitespace between HTML attributes (<a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/issues/23#issuecomment-700622837"">#23 (comment)</a>, <a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/pull/68"">#68</a>).</li>; <li>Move development dependencies from extras to separate <code>requirements.txt</code> (<a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/pull/68"">#68</a>).</li>; <li>Declare support for Python 3.9.</li>; <li>Tentatively declare support for Python 3.10 (tested with <code>Python 3.10.0a6+</code>).</li>; </ul>; <h3>Fixed</h3>; <ul>; <li>Fix Python 3.10 deprecation warning by importing Iterable from collections.abc (<a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/pull/68"">#68</a>).</li>; </ul>; <h2><a href=""https://github.com/thibaudcolas/curlylint/releases/tag/v0.12.2"">v0.12.2</a> 2021-03-06</h2>; <h3>Fixed</h3>; <ul>; <li>The <code>image_alt</code> rule no longer crashes when encou",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11494:3433,message,message,3433,https://hail.is,https://github.com/hail-is/hail/pull/11494,2,['message'],['message']
Integrability,"ylint/issues/5459"">#5459</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/35813de38ed58855f1b89fb492dc141d24bf2661""><code>35813de</code></a> Move various tests from <code>TestTypeChecker</code> to functional tests (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5455"">#5455</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/PyCQA/pylint/compare/pylint-2.6.0...v2.12.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pylint&package-manager=pip&previous-version=2.6.0&new-version=2.12.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11461:8958,depend,dependabot-automerge-start,8958,https://hail.is,https://github.com/hail-is/hail/pull/11461,4,['depend'],"['dependabot-automerge-end', 'dependabot-automerge-start']"
Integrability,"ylint/releases"">curlylint's releases</a>.</em></p>; <blockquote>; <h2>v0.13.0 – Quality-of-life improvements</h2>; <h2><a href=""https://github.com/thibaudcolas/curlylint/releases/tag/v0.13.0"">v0.13.0</a> 2021-04-24</h2>; <p>This release comes with a blog post! Read on <a href=""https://www.curlylint.org/blog/quality-of-life-improvements"">Quality-of-life improvements</a>.</p>; <h3>Added</h3>; <ul>; <li>Implement --template-tags CLI flag (<a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/issues/25"">#25</a>, <a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/pull/77"">#77</a>).</li>; </ul>; <h3>Changed</h3>; <ul>; <li>Add more descriptive error message for missing whitespace between HTML attributes (<a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/issues/23#issuecomment-700622837"">#23 (comment)</a>, <a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/pull/68"">#68</a>).</li>; <li>Move development dependencies from extras to separate <code>requirements.txt</code> (<a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/pull/68"">#68</a>).</li>; <li>Declare support for Python 3.9.</li>; <li>Tentatively declare support for Python 3.10 (tested with <code>Python 3.10.0a6+</code>).</li>; </ul>; <h3>Fixed</h3>; <ul>; <li>Fix Python 3.10 deprecation warning by importing Iterable from collections.abc (<a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/pull/68"">#68</a>).</li>; </ul>; <h2>v0.12.2</h2>; <h2><a href=""https://github.com/thibaudcolas/curlylint/releases/tag/v0.12.2"">v0.12.2</a> 2021-03-06</h2>; <h3>Fixed</h3>; <ul>; <li>The <code>image_alt</code> rule no longer crashes when encountering template conditionals in img attributes (<a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/pull/57"">#57</a>). Thanks to <a href=""https://github.com/adrien-delhorme""><code>@​adrien-delhorme</code></a>.</li>; </ul>; <h2>v0.12.1</h2>; <h2><a href=""https://g",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11494:1181,depend,dependencies,1181,https://hail.is,https://github.com/hail-is/hail/pull/11494,2,['depend'],['dependencies']
Integrability,"ylint/releases/tag/v0.12.1"">v0.12.1</a> 2021-03-06</h2>; <h3>Fixed</h3>; <ul>; <li>The project’s sdist now includes all needed files to run the test suite (<a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/issues/49"">#49</a>, <a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/pull/50"">#50</a>). Thanks to <a href=""https://github.com/jayvdb""><code>@​jayvdb</code></a>.</li>; </ul>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/thibaudcolas/curlylint/blob/main/CHANGELOG.md"">curlylint's changelog</a>.</em></p>; <blockquote>; <h2><a href=""https://github.com/thibaudcolas/curlylint/releases/tag/v0.13.0"">v0.13.0</a> 2021-04-25</h2>; <p>This release comes with a blog post! Read on <a href=""https://www.curlylint.org/blog/quality-of-life-improvements"">Quality-of-life improvements</a>.</p>; <h3>Added</h3>; <ul>; <li>Implement --template-tags CLI flag (<a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/issues/25"">#25</a>, <a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/pull/77"">#77</a>).</li>; </ul>; <h3>Changed</h3>; <ul>; <li>Add more descriptive error message for missing whitespace between HTML attributes (<a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/issues/23#issuecomment-700622837"">#23 (comment)</a>, <a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/pull/68"">#68</a>).</li>; <li>Move development dependencies from extras to separate <code>requirements.txt</code> (<a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/pull/68"">#68</a>).</li>; <li>Declare support for Python 3.9.</li>; <li>Tentatively declare support for Python 3.10 (tested with <code>Python 3.10.0a6+</code>).</li>; </ul>; <h3>Fixed</h3>; <ul>; <li>Fix Python 3.10 deprecation warning by importing Iterable from collections.abc (<a href=""https://github-redirect.dependabot.com/thibaudcolas/curlylint/pull",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11494:3217,depend,dependabot,3217,https://hail.is,https://github.com/hail-is/hail/pull/11494,2,['depend'],['dependabot']
Integrability,"ylint](https://github.com/PyCQA/pylint) from 2.12.2 to 2.13.0.; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/PyCQA/pylint/blob/main/ChangeLog"">pylint's changelog</a>.</em></p>; <blockquote>; <h1>What's New in Pylint 2.13.0?</h1>; <p>Release date: 2022-03-24</p>; <ul>; <li>; <p>Add missing dunder methods to <code>unexpected-special-method-signature</code> check.</p>; </li>; <li>; <p>No longer emit <code>no-member</code> in for loops that reference <code>self</code> if the binary operation that; started the for loop uses a <code>self</code> that is encapsulated in tuples or lists.</p>; <p>Ref <a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1360"">PyCQA/astroid#1360</a>; Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/4826"">#4826</a></p>; </li>; <li>; <p>Output better error message if unsupported file formats are used with <code>pyreverse</code>.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5950"">#5950</a></p>; </li>; <li>; <p>Fix pyreverse diagrams type hinting for classmethods and staticmethods.</p>; </li>; <li>; <p>Fix pyreverse diagrams type hinting for methods returning None.</p>; </li>; <li>; <p>Fix matching <code>--notes</code> options that end in a non-word character.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5840"">#5840</a></p>; </li>; <li>; <p>Updated the position of messages for class and function defintions to no longer cover; the complete definition. Only the <code>def</code> or <code>class</code> + the name of the class/function; are covered.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5466"">#5466</a></p>; </li>; <li>; <p><code>using-f-string-in-unsupported-version</code> and <code>using-final-decorator-in-unsupported-version</code> msgids; were renamed from <code>W1601</code> and <code>W1602</code> to <code>W2601</code> and <code>W2602</code>. Disabl",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11674:1003,depend,dependabot,1003,https://hail.is,https://github.com/hail-is/hail/pull/11674,1,['depend'],['dependabot']
Integrability,"yload); 216 path = action_routes[action]; 217 port = self._backend_server_port; → 218 resp = self._requests_session.post(f’http://localhost:{port}{path}', data=data); 219 if resp.status_code >= 400:; 220 error_json = orjson.loads(resp.content). File ~/Library/Python/3.9/lib/python/site-packages/requests/sessions.py:637, in Session.post(self, url, data, json, **kwargs); 626 def post(self, url, data=None, json=None, **kwargs):; 627 r""""“Sends a POST request. Returns :class:Response object.; 628; 629 :param url: URL for the new :class:Request object.; (…); 634 :rtype: requests.Response; 635 “””; → 637 return self.request(“POST”, url, data=data, json=json, **kwargs). File ~/Library/Python/3.9/lib/python/site-packages/requests/sessions.py:589, in Session.request(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json); 584 send_kwargs = {; 585 “timeout”: timeout,; 586 “allow_redirects”: allow_redirects,; 587 }; 588 send_kwargs.update(settings); → 589 resp = self.send(prep, **send_kwargs); 591 return resp. File ~/Library/Python/3.9/lib/python/site-packages/requests/sessions.py:703, in Session.send(self, request, **kwargs); 700 start = preferred_clock(); 702 # Send the request; → 703 r = adapter.send(request, **kwargs); 705 # Total elapsed time of the request (approximately); 706 elapsed = preferred_clock() - start. File ~/Library/Python/3.9/lib/python/site-packages/requests/adapters.py:501, in HTTPAdapter.send(self, request, stream, timeout, verify, cert, proxies); 486 resp = conn.urlopen(; 487 method=request.method,; 488 url=url,; (…); 497 chunked=chunked,; 498 ); 500 except (ProtocolError, OSError) as err:; → 501 raise ConnectionError(err, request=request); 503 except MaxRetryError as e:; 504 if isinstance(e.reason, ConnectTimeoutError):; 505 # TODO: Remove this in 3.0.0: see #2811. ConnectionError: (‘Connection aborted.’, RemoteDisconnected(‘Remote end closed connection without response’)); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14557:2579,adapter,adapter,2579,https://hail.is,https://github.com/hail-is/hail/issues/14557,3,"['Protocol', 'adapter']","['ProtocolError', 'adapter', 'adapters']"
Integrability,"ync to new server) ...</li>; <li>Additional commits viewable in <a href=""https://github.com/pandas-dev/pandas/compare/v1.3.5...v1.5.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pandas&package-manager=pip&previous-version=1.3.5&new-version=1.5.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself). </details>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12564:6358,Depend,Dependabot,6358,https://hail.is,https://github.com/hail-is/hail/pull/12564,17,"['Depend', 'depend']","['Dependabot', 'dependabot', 'dependency']"
Integrability,"yout via CSS</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/9827"">#9827</a>: i18n: Sort items in glossary by translated terms</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/9899"">#9899</a>: py domain: Allows to specify cross-reference specifier (<code>.</code> and; <code>~</code>) as <code>:type:</code> option</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/9894"">#9894</a>: linkcheck: add option <code>linkcheck_exclude_documents</code> to disable link; checking in matched documents.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/9793"">#9793</a>: sphinx-build: Allow to use the parallel build feature in macOS on macOS; and Python3.8+</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10055"">#10055</a>: sphinx-build: Create directories when <code>-w</code> option given</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/9993"">#9993</a>: std domain: Allow to refer an inline target (ex. ``_<code>target name```) via :rst:role:</code>ref` role</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/9981"">#9981</a>: std domain: Strip value part of the option directive from general index</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/9391"">#9391</a>: texinfo: improve variable in <code>samp</code> role</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/9578"">#9578</a>: texinfo: Add :confval:<code>texinfo_cross_references</code> to disable cross; references for readability with standalone readers</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/9822"">#9822</a> (and <a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/9062"">#9062</a>), add new Intersphinx role :rst:role:<code>external</code> for explict; lookup in the external pro",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11522:3929,depend,dependabot,3929,https://hail.is,https://github.com/hail-is/hail/pull/11522,2,['depend'],['dependabot']
Integrability,"ype extensions merge from wire-format instead of building up; instances and merging afterwards. This has much better performance.</li>; <li>Fix TextFormat parser to build up recurring (but supposedly not repeated); sub-messages directly from text rather than building a new sub-message and; merging the fully formed message into the existing field.</li>; <li>This release addresses a <a href=""https://github.com/protocolbuffers/protobuf/security/advisories/GHSA-h4h5-3hr4-j3g2"">Security Advisory for Java users</a></li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/protocolbuffers/protobuf/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=protobuf&package-manager=pip&previous-version=3.20.2&new-version=4.21.9)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12518:1823,depend,dependabot-security-updates,1823,https://hail.is,https://github.com/hail-is/hail/pull/12518,1,['depend'],['dependabot-security-updates']
Integrability,"ype=Issues""><code>@​blink1073</code></a></p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/jupyter/jupyter_client/commit/f71daff259071f3077810d9a4256876b441f5ab5""><code>f71daff</code></a> Publish 7.4.6</li>; <li><a href=""https://github.com/jupyter/jupyter_client/commit/3394591f161be4a19f9e61c66ba510d7e29afd59""><code>3394591</code></a> Backport PR <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/issues/879"">#879</a> on branch 7.x (Reconcile connection information) (<a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/issues/881"">#881</a>)</li>; <li><a href=""https://github.com/jupyter/jupyter_client/commit/763ff5f8c1132d3da913bf05e19b87efa8e35bf6""><code>763ff5f</code></a> Publish 7.4.5</li>; <li><a href=""https://github.com/jupyter/jupyter_client/commit/d27c8a497c6cbb1a232fbbe75cb1fd0f53faa9b0""><code>d27c8a4</code></a> [7.x] Handle Jupyter Core Warning (<a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/issues/875"">#875</a>)</li>; <li><a href=""https://github.com/jupyter/jupyter_client/commit/46f3f8c34f272629c45beba9884053680f213cfd""><code>46f3f8c</code></a> Clean up 7.x workflows (<a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/issues/865"">#865</a>)</li>; <li>See full diff in <a href=""https://github.com/jupyter/jupyter_client/compare/v7.4.4...v7.4.6"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=jupyter-client&package-manager=pip&previous-version=7.4.4&new-version=7.4.6)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (d",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12467:5094,depend,dependabot,5094,https://hail.is,https://github.com/hail-is/hail/pull/12467,1,['depend'],['dependabot']
Integrability,"ypecheck/check.py:585, in _make_dec.<locals>.wrapper(__original_func, *args, **kwargs); 582 @decorator; 583 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 584 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 585 return __original_func(*args_, **kwargs_). File ~/hail/hail/python/hail/table.py:1963, in Table.checkpoint(self, output, overwrite, stage_locally, _codec_spec, _read_if_exists, _intervals, _filter_intervals); 1960 hl.current_backend().validate_file(output); 1962 if not _read_if_exists or not hl.hadoop_exists(f'{output}/_SUCCESS'):; -> 1963 self.write(output=output, overwrite=overwrite, stage_locally=stage_locally, _codec_spec=_codec_spec); 1964 _assert_type = self._type; 1965 _load_refs = False. File <decorator-gen-1236>:2, in write(self, output, overwrite, stage_locally, _codec_spec). File ~/hail/hail/python/hail/typecheck/check.py:585, in _make_dec.<locals>.wrapper(__original_func, *args, **kwargs); 582 @decorator; 583 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 584 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 585 return __original_func(*args_, **kwargs_). File ~/hail/hail/python/hail/table.py:2005, in Table.write(self, output, overwrite, stage_locally, _codec_spec); 1979 """"""Write to disk.; 1980; 1981 Examples; (...); 2000 If ``True``, overwrite an existing file at the destination.; 2001 """"""; 2003 hl.current_backend().validate_file(output); -> 2005 Env.backend().execute(; 2006 ir.TableWrite(self._tir, ir.TableNativeWriter(output, overwrite, stage_locally, _codec_spec)); 2007 ). File ~/hail/hail/python/hail/backend/spark_backend.py:227, in SparkBackend.execute(self, ir, timed); 224 except Exception as fatal:; 225 raise err from fatal; --> 227 raise err. File ~/hail/hail/python/hail/backend/spark_backend.py:219, in SparkBackend.execute(self, ir, timed); 217 def execute(self, ir: BaseIR, timed: bool = False) -> Any:;",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14594:2718,wrap,wrapper,2718,https://hail.is,https://github.com/hail-is/hail/issues/14594,2,['wrap'],['wrapper']
Integrability,"ypehints/commit/a9b90238f74f1c5f69d7dcafb83c9775504f9b3b""><code>a9b9023</code></a> Fix typos (<a href=""https://github-redirect.dependabot.com/tox-dev/sphinx-autodoc-typehints/issues/224"">#224</a>)</li>; <li><a href=""https://github.com/tox-dev/sphinx-autodoc-typehints/commit/1ef84886873b80ff62ed1ea76e111dd9e96dbf18""><code>1ef8488</code></a> Release 1.17.0</li>; <li>Additional commits viewable in <a href=""https://github.com/tox-dev/sphinx-autodoc-typehints/compare/1.11.1...1.18.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=sphinx-autodoc-typehints&package-manager=pip&previous-version=1.11.1&new-version=1.18.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11893:7407,depend,dependabot,7407,https://hail.is,https://github.com/hail-is/hail/pull/11893,1,['depend'],['dependabot']
Integrability,"ypes are the classes that manage in-memory representations of Hail Types (Virtual Types), for both staged and unstaged code. # Motivation:. - Improve performance by building specialized memory representations for data; - Make it easier for developers to work with in memory representations of Hail types. # Project technical goals:. - Remove requiredness from virtual types; - Implement at least one non-canonical physical type. # Relation to regions. The methods that take regions are those that construct a new in-memory representation (are either `def allocate` or convenience methods that wrap `allocate` and may perform some complex operations before calling `allocate`, e.g `copyFromType`). Allocated addresses may be read using static Region methods (e.g `Region.loadAddress`), because they are absolute memory addresses rather than relative to some region offset. Long-term, methods besides `allocate` and wrapping methods, which need to allocate (for instance lazy-loading BGEN data) will be given the ability to do so without taking region as an argument (values will be associated with the regions that allocated them). Namely, regions may be placed on the values that own them. # Physical Type organization. ## Constructible types. Every PType has a ""fundamentalType"", which is the is the constructible representation for that type. It is, by default equal to the PType itself, but this may not always be the case (e.g [ComplexPType](#complex-ptypes)). ## Collection PTypes. [PArray](#parray). - Concrete implementations (canonical/non). [PSet](#pset). - Concrete implementations (canonical/non). [PDict](#pdict). - Concrete implementations (canonical/non). [PNDArray](#pndict). - Concrete implementations (canonical/non). [PTuple](#ptuple). - Concrete implementations (canonical/non). PStruct. - Concrete implementations (canonical/non). PString. - Concrete implementations (canonical/non). PBinary. - Concrete implementations (canonical/non). ## <a name=""complex-ptypes""></a> Complex PTy",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7988:1120,wrap,wrapping,1120,https://hail.is,https://github.com/hail-is/hail/issues/7988,1,['wrap'],['wrapping']
Integrability,"ypescript-2-8-82990c516935. ### NextJS; https://nextjs.org/docs/; Next has 4 deviations from normal react:; 1) _app.js: Can be omitted. Wraps all other components. Is useful for global functions, because it is not reloaded when you change pages. Good place to place a header component, a footer, global data stores, or handle page transitions.; it has this shape:; ```js; <Container>; <Header />; <Component {...pageProps} />; <Footer />; </Container>; ```. 2) _document.js: Optional. Rendered only on the server, exactly one time. Wraps _app. Good place to define external resource you want to load, such as some external stylesheet, font, whatever. . 3) `getInitialProps`: a lifecycle method that is only available to components in the `pages/` folder. `getInitialProps ` runs once during server-side rendering, and again if you navigate to the page that defines it. Only components in pages can specify this property. This is because it is effectively a function triggered during routing and:; * `getInitialProps` is of course only available if you define a stateful component. See [functional components (just JSX wrapped in a function, rather than a class)](https://reactjs.org/docs/components-and-props.html). 4) NextJS includes a light, fast router. Routes are matched based on the names of files in `pages/`, with index.js mapping to `/`. For instance, to navigate to `domain.com/scorecard/users`, you'd make the folder structure:. pages/; * scorecard.tsx; * scorecard/; * users.tsx. These 'pages' components are just like normal react components, except they expose `getInitialProps`, described above. Each page file must export 1 default component:. ```js; #Page file; import React from 'react';. const index = () => <div>Hello World</div>; export default index;; ```. There is nothing else to do to get routing to work, a quite nice solution. ### JS pragma; 1. `this` is different than in most (every?) other language. scope of this is bound to caller, not object containing the method; * ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5162:12021,rout,routing,12021,https://hail.is,https://github.com/hail-is/hail/pull/5162,1,['rout'],['routing']
Integrability,"yptography==41.0.7|decorator==4.4.2|deprecated==1.2.14|dill==0.3.7|frozenlist==1.4.0|google-auth==2.23.4|google-auth-oauthlib==0.8.0|humanize==1.1.0|idna==3.6|isodate==0.6.1|janus==1.0.0|jinja2==3.1.2|jmespath==1.0.1|jproperties==2.1.1|markupsafe==2.1.3|msal==1.25.0|msal-extensions==1.0.0|msrest==0.7.1|multidict==6.0.4|nest-asyncio==1.5.8|numpy==1.26.2|oauthlib==3.2.2|orjson==3.9.10|packaging==23.2|pandas==2.1.3|parsimonious==0.10.0|pillow==10.1.0|plotly==5.18.0|portalocker==2.8.2|protobuf==3.20.2|py4j==0.10.9.5|pyasn1==0.5.1|pyasn1-modules==0.3.0|pycares==4.4.0|pycparser==2.21|pygments==2.17.2|pyjwt[crypto]==2.8.0|python-dateutil==2.8.2|python-json-logger==2.0.7|pytz==2023.3.post1|pyyaml==6.0.1|regex==2023.10.3|requests==2.31.0|requests-oauthlib==1.3.1|rich==12.6.0|rsa==4.9|s3transfer==0.8.0|scipy==1.11.4|six==1.16.0|sortedcontainers==2.4.0|tabulate==0.9.0|tenacity==8.2.3|tornado==6.3.3|typer==0.9.0|typing-extensions==4.8.0|tzdata==2023.3|urllib3==1.26.18|uvloop==0.19.0;sys_platform!=""win32""|wrapt==1.16.0|xyzservices==2023.10.1|yarl==1.9.3 \; ---; > '--metadata=^|||^WHEEL=gs://hail-30-day/hailctl/dataproc/dking-dev/0.2.126-a51eabd65859/hail-0.2.126-py3-none-any.whl|||PKGS=aiodns==2.0.0|aiohttp==3.9.1|aiosignal==1.3.1|async-timeout==4.0.3|attrs==23.1.0|avro==1.11.3|azure-common==1.1.28|azure-core==1.29.5|azure-identity==1.15.0|azure-mgmt-core==1.4.0|azure-mgmt-storage==20.1.0|azure-storage-blob==12.19.0|bokeh==3.3.1|boto3==1.33.1|botocore==1.33.1|cachetools==5.3.2|certifi==2023.11.17|cffi==1.16.0|charset-normalizer==3.3.2|click==8.1.7|commonmark==0.9.1|contourpy==1.2.0|cryptography==41.0.7|decorator==4.4.2|deprecated==1.2.14|dill==0.3.7|frozenlist==1.4.0|google-auth==2.23.4|google-auth-oauthlib==0.8.0|humanize==1.1.0|idna==3.6|isodate==0.6.1|janus==1.0.0|jinja2==3.1.2|jmespath==1.0.1|jproperties==2.1.1|markupsafe==2.1.3|msal==1.25.0|msal-extensions==1.0.0|msrest==0.7.1|multidict==6.0.4|nest-asyncio==1.5.8|numpy==1.26.2|oauthlib==3.2.2|orjson==3.9.10|packaging==23.2|p",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14127:3230,wrap,wrapt,3230,https://hail.is,https://github.com/hail-is/hail/pull/14127,1,['wrap'],['wrapt']
Integrability,"ypy/issues/13656"">#13656</a>) (<a href=""https://github-redirect.dependabot.com/python/mypy/issues/13658"">#13658</a>)</li>; <li><a href=""https://github.com/python/mypy/commit/70bc34837ecbafc528e511a46219262736781d43""><code>70bc348</code></a> [0.980 backport] Allow unpacking from TypeVars with iterable bounds (<a href=""https://github-redirect.dependabot.com/python/mypy/issues/13425"">#13425</a>) ...</li>; <li>Additional commits viewable in <a href=""https://github.com/python/mypy/compare/v0.950...v0.982"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=mypy&package-manager=pip&previous-version=0.950&new-version=0.982)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12291:3205,depend,dependabot,3205,https://hail.is,https://github.com/hail-is/hail/pull/12291,1,['depend'],['dependabot']
Integrability,"yright notice year.</li>; <li><a href=""https://github.com/GrahamDumpleton/wrapt/commit/9668bbd7c7314d81b7cf8ce4293d04212ae1edee""><code>9668bbd</code></a> Update version in preparation for 1.14.1 release.</li>; <li><a href=""https://github.com/GrahamDumpleton/wrapt/commit/c86a4d37fa61494957153f76b1d6bbdacfd83205""><code>c86a4d3</code></a> Add classifier for Python 3.11.</li>; <li><a href=""https://github.com/GrahamDumpleton/wrapt/commit/07239ac21a68ced86860cf3bb52ee0c60faf0915""><code>07239ac</code></a> Document fix for module importers using deprecated APIs.</li>; <li><a href=""https://github.com/GrahamDumpleton/wrapt/commit/df0e62c2740143cceb6cafea4c306dae1c559ef8""><code>df0e62c</code></a> Deal with module importers that don't implement newer API.</li>; <li><a href=""https://github.com/GrahamDumpleton/wrapt/commit/72627592324bee1a197925d0e600142bc8719a3e""><code>7262759</code></a> Fix change notes formatting.</li>; <li>Additional commits viewable in <a href=""https://github.com/GrahamDumpleton/wrapt/compare/1.13.3...1.14.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=wrapt&package-manager=pip&previous-version=1.13.3&new-version=1.14.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@depen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12102:4095,wrap,wrapt,4095,https://hail.is,https://github.com/hail-is/hail/pull/12102,1,['wrap'],['wrapt']
Integrability,"yter/jupyter_core/commit/18cc67e2f32d32ae3cebc6725251a597a4971851""><code>18cc67e</code></a> Publish 5.7.2</li>; <li><a href=""https://github.com/jupyter/jupyter_core/commit/1264a81fc834f18db2b41e136ec4ac9d1a4ad993""><code>1264a81</code></a> Update Release Scripts (<a href=""https://redirect.github.com/jupyter/jupyter_core/issues/396"">#396</a>)</li>; <li><a href=""https://github.com/jupyter/jupyter_core/commit/1c5fa3720d3d6da1b5188072c24bac095082903b""><code>1c5fa37</code></a> Enforce pytest 7 (<a href=""https://redirect.github.com/jupyter/jupyter_core/issues/393"">#393</a>)</li>; <li><a href=""https://github.com/jupyter/jupyter_core/commit/dfed905e5ce3550e1bdae60e9e9242f0d0d2faae""><code>dfed905</code></a> chore: update pre-commit hooks (<a href=""https://redirect.github.com/jupyter/jupyter_core/issues/392"">#392</a>)</li>; <li>See full diff in <a href=""https://github.com/jupyter/jupyter_core/compare/v5.7.1...v5.7.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=jupyter-core&package-manager=pip&previous-version=5.7.1&new-version=5.7.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merg",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14484:4248,Depend,Dependabot,4248,https://hail.is,https://github.com/hail-is/hail/pull/14484,2,"['Depend', 'depend']","['Dependabot', 'dependabot-badges']"
Integrability,"ytest-asyncio's changelog</a>.</em></p>; <blockquote>; <h1>0.20.2 (22-11-11)</h1>; <ul>; <li>Fixes an issue with async fixtures that are defined as methods on a test class not being rebound to the actual test instance. <code>[#197](https://github.com/pytest-dev/pytest-asyncio/issues/197) &lt;https://github.com/pytest-dev/pytest-asyncio/issues/197&gt;</code>_</li>; <li>Replaced usage of deprecated <code>@pytest.mark.tryfirst</code> with <code>@pytest.hookimpl(tryfirst=True)</code> <code>[#438](https://github.com/pytest-dev/pytest-asyncio/issues/438) &lt;https://github.com/pytest-dev/pytest-asyncio/pull/438&gt;</code>_</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pytest-dev/pytest-asyncio/commit/07a1416c2fe15d85fc149b3caa35b057de0b3d6e""><code>07a1416</code></a> Prepare release of v0.20.2.</li>; <li><a href=""https://github.com/pytest-dev/pytest-asyncio/commit/dc3ad211d160006b4a30996c0a2a2c29754ef1fc""><code>dc3ad21</code></a> Build(deps): Bump pytest-trio in /dependencies/default (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-asyncio/issues/441"">#441</a>)</li>; <li><a href=""https://github.com/pytest-dev/pytest-asyncio/commit/d9faba85890334f0548732d35f1b1d54a850a69f""><code>d9faba8</code></a> Build(deps): Bump mypy from 0.982 to 0.990 in /dependencies/default (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-asyncio/issues/440"">#440</a>)</li>; <li><a href=""https://github.com/pytest-dev/pytest-asyncio/commit/fe63e346154b61bbfe767e585b0b3b55fb37463e""><code>fe63e34</code></a> Handle bound fixture methods correctly (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-asyncio/issues/439"">#439</a>)</li>; <li><a href=""https://github.com/pytest-dev/pytest-asyncio/commit/38fc0320c39e24a473240303fbc780213354e64d""><code>38fc032</code></a> Bump to pytest 7.2.0 (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-asyncio/issues/438"">#438</a>)</li>; <l",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12453:3767,depend,dependencies,3767,https://hail.is,https://github.com/hail-is/hail/pull/12453,1,['depend'],['dependencies']
Integrability,"ytest-asyncio/commit/9246f5825f589ff01f1c67620ce34bdc416c5af3""><code>9246f58</code></a> Fix asyncio auto mode not marking static methods (closes pytest-dev/pytest-as...</li>; <li><a href=""https://github.com/pytest-dev/pytest-asyncio/commit/34436cd6653b1dd8e1836a99ca1412b850167f52""><code>34436cd</code></a> Release 0.18.1</li>; <li><a href=""https://github.com/pytest-dev/pytest-asyncio/commit/f7c8226af1d207650c11b203649759d2051d3a8d""><code>f7c8226</code></a> fix: Fixed a regression that prevented async fixtures from working in sync te...</li>; <li><a href=""https://github.com/pytest-dev/pytest-asyncio/commit/bf3d32cf0d1e2c546406ba53b96d40d10a1e6fbd""><code>bf3d32c</code></a> Fix typos in README (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-asyncio/issues/289"">#289</a>)</li>; <li><a href=""https://github.com/pytest-dev/pytest-asyncio/commit/07e9922f1dc9cb84f0948e6c84ad9921c3662969""><code>07e9922</code></a> Prepare release of v0.18.0 (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-asyncio/issues/282"">#282</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/pytest-dev/pytest-asyncio/compare/v0.14.0...v0.18.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pytest-asyncio&package-manager=pip&previous-version=0.14.0&new-version=0.18.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recre",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11510:4935,depend,dependabot,4935,https://hail.is,https://github.com/hail-is/hail/pull/11510,1,['depend'],['dependabot']
Integrability,"ytest-parallel (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/723"">#723</a>)</li>; <li><a href=""https://github.com/googleapis/python-storage/commit/dbfe520008a25c4e6f5b94e332129affa0f0d869""><code>dbfe520</code></a> chore(deps): update dependency google-cloud-pubsub to v2.10.0 (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/724"">#724</a>)</li>; <li><a href=""https://github.com/googleapis/python-storage/commit/e9aab389f868799d4425133954bad4f1cbb85786""><code>e9aab38</code></a> fix(deps): require google-api-core&gt;=1.31.5, &gt;=2.3.2 (<a href=""https://github-redirect.dependabot.com/googleapis/python-storage/issues/722"">#722</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/googleapis/python-storage/compare/v1.25.0...v2.2.0"">compare view</a></li>; </ul>; </details>; <br />. Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11578:9376,depend,dependabot,9376,https://hail.is,https://github.com/hail-is/hail/pull/11578,1,['depend'],['dependabot']
Integrability,"ython-api-core/commit/eed844f211ad8c6ab2c4cb0d6f089e1f11999f71""><code>eed844f</code></a> chore(main): release 2.8.0 (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-core/issues/381"">#381</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/googleapis/python-api-core/compare/v1.31.6...v2.8.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=google-api-core[grpc]&package-manager=pip&previous-version=1.31.6&new-version=2.8.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11970:11573,Depend,Dependabot,11573,https://hail.is,https://github.com/hail-is/hail/pull/11970,1,['Depend'],['Dependabot']
Integrability,"ython-cloud-core/commit/6014db08ca2078a1c8ebb37ee46c53dae381e7d5""><code>6014db0</code></a> chore(main): release 2.3.0 (<a href=""https://github-redirect.dependabot.com/googleapis/python-cloud-core/issues/185"">#185</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/googleapis/python-cloud-core/compare/v1.7.2...v2.3.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=google-cloud-core&package-manager=pip&previous-version=1.7.2&new-version=2.3.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12175:10628,Depend,Dependabot,10628,https://hail.is,https://github.com/hail-is/hail/pull/12175,1,['Depend'],['Dependabot']
Integrability,"ython-humanize/humanize/issues/53"">#53</a> from Luflosi/implement-decimal-sep-i18n</li>; <li><a href=""https://github.com/python-humanize/humanize/commit/862748a7acd3db1257418101eec626688e0d3c78""><code>862748a</code></a> Internationalise the decimal separator in intcomma()</li>; <li><a href=""https://github.com/python-humanize/humanize/commit/d8e27393dbf4ed3645ffc3464c9c44f4d8e47534""><code>d8e2739</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/python-humanize/humanize/issues/52"">#52</a> from Luflosi/fix-intcomma-with-str-and-ndigits</li>; <li>Additional commits viewable in <a href=""https://github.com/python-humanize/humanize/compare/1.1.0...4.4.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=humanize&package-manager=pip&previous-version=1.1.0&new-version=4.4.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12329:7500,depend,dependabot-security-updates,7500,https://hail.is,https://github.com/hail-is/hail/pull/12329,1,['depend'],['dependabot-security-updates']
Integrability,"ython/PHP/Objective-C/C#/Ruby/JavaScript)</p>; <h1>Ruby</h1>; <ul>; <li>Dropped Ruby 2.3 and 2.4 support for CI and releases. (<a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/9311"">#9311</a>)</li>; <li>Added Ruby 3.1 support for CI and releases (<a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/9566"">#9566</a>).</li>; <li>Message.decode/encode: Add recursion_limit option (<a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/9218"">#9218</a>/<a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/9486"">#9486</a>)</li>; <li>Allocate with xrealloc()/xfree() so message allocation is visible to the; Ruby GC. In certain tests this leads to much lower memory usage due to more; frequent GC runs (<a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/9586"">#9586</a>).</li>; <li>Fix conversion of singleton classes in Ruby (<a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/9342"">#9342</a>)</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/protocolbuffers/protobuf/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=protobuf&package-manager=pip&previous-version=3.19.6&new-version=4.21.12)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot action",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12563:3644,depend,dependabot,3644,https://hail.is,https://github.com/hail-is/hail/pull/12563,1,['depend'],['dependabot']
Integrability,"ython/ipython/commit/4a065015a1b987ac6f30fff9180efbd93cffbed6""><code>4a06501</code></a> Remove opening/at-exit closing of devnull.</li>; <li><a href=""https://github.com/ipython/ipython/commit/9d0419bed36bae7228b2ad48296e58b918b1a9b8""><code>9d0419b</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/ipython/ipython/issues/13900"">#13900</a> from Carreau/doc-autosugg</li>; <li>Additional commits viewable in <a href=""https://github.com/ipython/ipython/compare/7.34.0...8.9.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=ipython&package-manager=pip&previous-version=7.34.0&new-version=8.9.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12664:2744,depend,dependabot,2744,https://hail.is,https://github.com/hail-is/hail/pull/12664,1,['depend'],['dependabot']
Integrability,"ython/issues/20491"">#20491</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/e572c97e53510572b0a515547bb711a9c7282ae5""><code>e572c97</code></a> [Storage]fix live test (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/20463"">#20463</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/d3d7e3e719a079415b0d955112b7e185791b5f0c""><code>d3d7e3e</code></a> Fix type annotation in azure.storage.blob (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/20084"">#20084</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/7e7f55233be72e999ffee255697665921df14f76""><code>7e7f552</code></a> keyvault and storage have a conflict between mindependency and what local azu...</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/a152bfbd45103013f6ca27dbbded03913cd43dc0""><code>a152bfb</code></a> [Storage]fix live test (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/20217"">#20217</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/Azure/azure-sdk-for-python/compare/azure-storage-blob_12.8.1...azure-storage-blob_12.9.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=azure-storage-blob&package-manager=pip&previous-version=12.8.1&new-version=12.9.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot reb",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11484:2848,depend,dependabot,2848,https://hail.is,https://github.com/hail-is/hail/pull/11484,2,['depend'],['dependabot']
Integrability,"ython/issues/23203"">#23203</a>)</li>; </ul>; <h3>Breaking Changes</h3>; <ul>; <li><code>validate_authority</code> support is not available in 1.9.0.</li>; </ul>; <h3>Bugs Fixed</h3>; <ul>; <li>Added check on <code>content</code> from msal response. (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23483"">#23483</a>)</li>; <li>Fixed the issue that async OBO credential does not refresh correctly. (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/21981"">#21981</a>)</li>; </ul>; <h3>Other Changes</h3>; <ul>; <li>Removed <code>resource_id</code>, please use <code>identity_config</code> instead.</li>; <li>Renamed argument name <code>get_assertion</code> to <code>func</code> for <code>ClientAssertionCredential</code>.</li>; </ul>; <h2>azure-identity_1.9.0b1</h2>; <h2>1.9.0b1 (2022-03-08)</h2>; <h3>Features Added</h3>; <ul>; <li>Added <code>validate_authority</code> support for msal client (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/22625"">#22625</a>)</li>; <li>Added <code>resource_id</code> support for user-assigned managed identity (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/22329"">#22329</a>)</li>; <li>Added <code>ClientAssertionCredential</code> support (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/22328"">#22328</a>)</li>; <li>Updated App service API version to &quot;2019-08-01&quot; (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23034"">#23034</a>)</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/e650a8ca8b4cf01ec7a2961f4a50187d1528a122""><code>e650a8c</code></a> update troubleshooting (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23681"">#23681</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/58",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11752:1484,depend,dependabot,1484,https://hail.is,https://github.com/hail-is/hail/pull/11752,1,['depend'],['dependabot']
Integrability,"ython/issues/403"">#403</a> from sass/pre-commit-ci-update-config</li>; <li><a href=""https://github.com/sass/libsass-python/commit/40be5dc3e2c326006fc7f4f1ffcc3cada877c701""><code>40be5dc</code></a> [pre-commit.ci] pre-commit autoupdate</li>; <li>Additional commits viewable in <a href=""https://github.com/sass/libsass-python/compare/0.21.0...0.22.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=libsass&package-manager=pip&previous-version=0.21.0&new-version=0.22.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12482:3802,Depend,Dependabot,3802,https://hail.is,https://github.com/hail-is/hail/pull/12482,1,['Depend'],['Dependabot']
Integrability,"ython/releases"">prometheus-client's releases</a>.</em></p>; <blockquote>; <h2>0.13.1 / 2022-01-28</h2>; <p>[BUGFIX] Relax some type constraints that were too strict. <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/754"">#754</a>, <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/755"">#755</a>, <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/756"">#756</a>, <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/758"">#758</a>; [BUGFIX] Explicitly export functions with <code>__all__</code>. <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/757"">#757</a></p>; <h2>0.13.0 / 2022-01-25</h2>; <p>[CHANGE] Drop support for Python versions 2.7, 3.4, and 3.5. <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/718"">#718</a>; [FEATURE] Support adding labels when using <code>.time()</code> <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/730"">#730</a>; [ENHANCEMENT] Begin to add type hints to functions. <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/705"">#705</a>; [ENHANCEMENT] Improved go-to-declaration behavior for editors. <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/747"">#747</a>; [BUGFIX] Remove trailing slashes from pushgateway URLS. <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/722"">#722</a>; [BUGFIX] Catch non-integer bucket/count values. <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/726"">#726</a></p>; <h2>0.12.0 / 2021-10-29</h2>; <p>[FEATURE] Exemplar support (excludes multiprocess) <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/669"">#669</a>; [ENHANCEMENT] Add support for Python 3.10 <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/706"">#706</a>; [ENHANCEMENT] Restricted ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11515:1202,depend,dependabot,1202,https://hail.is,https://github.com/hail-is/hail/pull/11515,1,['depend'],['dependabot']
Integrability,"ze check was missing (Adam Kaczmarek); Fixed: GITHUB-2709: Testnames not working together with suites in suite (Martin Aldrin); Fixed: GITHUB-2704: IHookable and IConfigurable callback discrepancy (Krishnan Mahadevan); Fixed: GITHUB-2637: Upgrade to JDK11 as the minimum JDK requirements (Krishnan Mahadevan); Fixed: GITHUB-2734: Keep the initial order of listeners (Andrei Solntsev); Fixed: GITHUB-2359: Testng <a href=""https://github.com/BeforeGroups""><code>@​BeforeGroups</code></a> is running in parallel with testcases in the group (Anton Velma); Fixed: Possible StringIndexOutOfBoundsException in XmlReporter (Anton Velma); Fixed: GITHUB-2754: <a href=""https://github.com/AfterGroups""><code>@​AfterGroups</code></a> is executed for each &quot;finished&quot; group when it has multiple groups defined (Anton Velma)</p>; <p>7.5; Fixed: GITHUB-2701: Bump gradle version to 7.3.3 to support java17 build (ZhangJian He); Fixed: GITHUB-2646: Streamline Logging Across TestNG (Krishnan Mahadevan); Fixed: GITHUB-2658: Inheritance + dependsOnMethods (Krishnan Mahadevan)</p>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/cbeust/testng/commit/b94395dea479308ea3fe825269730b960f44d805""><code>b94395d</code></a> Bump version to 7.7.1 for release</li>; <li><a href=""https://github.com/cbeust/testng/commit/89dc5845fcb46c26af187e50ea907a7382d06e72""><code>89dc584</code></a> Streamline overloaded assertion methods for Groovy</li>; <li><a href=""https://github.com/cbeust/testng/commit/5ac0021d14f7eb00804fe235aaefc5c2fbce57d1""><code>5ac0021</code></a> Adding release notes</li>; <li><a href=""https://github.com/cbeust/testng/commit/c0e1e772f1fc0ab2142f3a4114a2b8cfe60fa7e1""><code>c0e1e77</code></a> Adjust version reference in deprecation msgs.</li>; <li><a href=""https://github.com/cbeust/testng/commit/011527d9bf0f91a40539f5e5467cc106888810d9""><code>011527d</code></a> Bump version to 7.7.0 for r",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12665:14607,depend,dependsOnMethods,14607,https://hail.is,https://github.com/hail-is/hail/pull/12665,1,['depend'],['dependsOnMethods']
Integrability,"zure/azure-sdk-for-java/commit/46759562feb14a16da80295135ce79556639e460""><code>4675956</code></a> target newest version of proxy tool (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/31925"">#31925</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/2c6ab741fa96a78c8b6dd607986cdbe645860747""><code>2c6ab74</code></a> updated CHANGELOG.md (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/31922"">#31922</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-java/commit/117395c4d526151c7c5faf7059285de6cd9f1c1b""><code>117395c</code></a> healthCheckImprovement[transitTimeout] (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-java/issues/31544"">#31544</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/Azure/azure-sdk-for-java/compare/azure-core_1.10.0...azure-core-http-netty_1.12.7"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.azure:azure-core-http-netty&package-manager=gradle&previous-version=1.10.0&new-version=1.12.7)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12460:3747,Depend,Dependabot,3747,https://hail.is,https://github.com/hail-is/hail/pull/12460,2,"['Depend', 'depend']","['Dependabot', 'dependabot-badges']"
Integrability,"zure/azure-sdk-for-python/commit/58613a167a5383a459a57b34c6208d7762b90264""><code>58613a1</code></a> enable pii logging (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23658"">#23658</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/ab4c52ce05bb3fda401a834cbf669c32d6d83b90""><code>ab4c52c</code></a> add doc string for authority setting (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23659"">#23659</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/68dda72cab22a13014012c6b88137684180e941b""><code>68dda72</code></a> add app service api 2017 backward compatibility support (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23626"">#23626</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/1b23cab27114193fa8c19bfd47627093052d8212""><code>1b23cab</code></a> remove validate_authority (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23625"">#23625</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/a6a41458f5d15d47fe508629056b7c90185d4060""><code>a6a4145</code></a> refresh async oob (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23551"">#23551</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/95139f477dcda4de7f6fab56c17e7081f035595d""><code>95139f4</code></a> address arch board review feedback (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23539"">#23539</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/c344afe25cd36875d0fc0c7e4c03a942d2c19bf7""><code>c344afe</code></a> Add Azure Account extension version requirement to Identity README (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23518"">#23518</a>)</li>; <li><a href=""https://github.com/Azure/azure-sdk-for-python/commit/075e68abfb5d4ebe596c8e9",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11752:3450,depend,dependabot,3450,https://hail.is,https://github.com/hail-is/hail/pull/11752,1,['depend'],['dependabot']
Integrability,"zure/azure-sdk-for-python/commit/84cbec033ed8e4df87f44a82dcebb96aa19deac0""><code>84cbec0</code></a> [Storage] Adjust some file-datalake test recordings (<a href=""https://github-redirect.dependabot.com/Azure/azure-sdk-for-python/issues/23147"">#23147</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/Azure/azure-sdk-for-python/compare/azure-storage-blob_12.8.1...azure-storage-blob_12.10.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=azure-storage-blob&package-manager=pip&previous-version=12.8.1&new-version=12.10.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and block automerging; - `@dependabot reopen` will reopen this PR if it is closed; - `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually; - `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself); - `@dependabot ignore this minor version` will close this PR a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11610:6335,depend,dependabot-automerge-start,6335,https://hail.is,https://github.com/hail-is/hail/pull/11610,2,['depend'],"['dependabot-automerge-end', 'dependabot-automerge-start']"
Integrability,"{};&quot;); </code></pre>; <p>You can now write:</p>; <pre><code>LPAR, RPAR, LBRACE, RBRACE, SEMI = Suppress.using_each(&quot;(){};&quot;); </code></pre>; <p><code>using_each</code> will also accept optional keyword args, which it will pass through to the class initializer. Here is an expression for single-letter variable names that might be used in an algebraic expression:</p>; <pre><code>algebra_var = MatchFirst(; Char.using_each(string.ascii_lowercase, as_keyword=True); ); </code></pre>; </li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/pyparsing/pyparsing/blob/master/CHANGES"">pyparsing's changelog</a>.</em></p>; <blockquote>; <h2>Version 3.1.1 - July, 2023</h2>; <ul>; <li>; <p>Fixed regression in Word(min), reported by Ricardo Coccioli, good catch! (Issue <a href=""https://redirect.github.com/pyparsing/pyparsing/issues/502"">#502</a>)</p>; </li>; <li>; <p>Fixed bug in bad exception messages raised by Forward expressions. PR submitted; by Kyle Sunden, thanks for your patience and collaboration on this (<a href=""https://redirect.github.com/pyparsing/pyparsing/issues/493"">#493</a>).</p>; </li>; <li>; <p>Fixed regression in SkipTo, where ignored expressions were not checked when looking; for the target expression. Reported by catcombo, Issue <a href=""https://redirect.github.com/pyparsing/pyparsing/issues/500"">#500</a>.</p>; </li>; <li>; <p>Fixed type annotation for enable_packrat, PR submitted by Mike Urbach, thanks! (Issue <a href=""https://redirect.github.com/pyparsing/pyparsing/issues/498"">#498</a>)</p>; </li>; <li>; <p>Some general internal code cleanup. (Instigated by Michal Čihař, Issue <a href=""https://redirect.github.com/pyparsing/pyparsing/issues/488"">#488</a>)</p>; </li>; </ul>; <h2>Version 3.1.0 - June, 2023</h2>; <ul>; <li>Added <code>tag_emitter.py</code> to examples. This example demonstrates how to insert; tags into your parse",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13345:4271,message,messages,4271,https://hail.is,https://github.com/hail-is/hail/pull/13345,1,['message'],['messages']
Integrability,"|; | is.hail.io.fs | No | Scala | no |. `hail.fs` is technically in the public API (via `hl.current_backend().fs`), but I doubt anyone uses; it. `hail.utils.hadoop_utils` is a shim over `hail.fs`, there are no direct concrete implementations of; it. This PR adds `hail.fs.RouterFS` to `hail.fs`, a synchronous wrapper around; `hailtop.aiotools.fs.AsyncRouterFS`. A ""router"" file system is one which operates on URLs instead of; paths. It uses the URL's protocol to determine which concrete file system to use. For example, a; router fs can `open` both `gs://danking/abc` and `s3a://danking/abc`. Each Hail Query Python Backend is associated with one file system class. This PR associates the; ServiceBackend with `RouterFS`, enabling `hl.current_backend().fs.open`, `hl.hadoop_open`, etc. to; read from S3, GCS, ABS, and the local file system. We should deprecate `hail.utils.hadoop_utils`; because it is not Hadoop-specific. We should instead advertise the class-based `hail.fs` or create a; new function-based interface (e.g. `hl.fs.open(...)`. # Test Clean-up. The Hail Query local and spark tests should now work in Azure. I moved all the `hail.fs` and; `hailtop.aiotools.fs` tests into two build.yaml steps: `test_hail_python_fs` and; `test_hail_scala_fs`. These tests are exhaustive: they test every file system: S3, ABS, and GCS. The only file system tests that remain in the Hail Query tests are the tests of; `hail.utils.hadoop_utils`. The hadoop tests are not exhaustive: they only test the *current* file; system. In Azure, they test ABS. In Google, they test GCS. I have not decided yet if we should enable the hail python tests in Azure. It seems mostly wasteful. # Local Cache. I added a local cache directory. It defaults to `$XDG_CONFIG_HOME/hail/cache` or; `~/.config/hail/cache` if `XDG_CONFIG_HOME` is not set. I store Python reference genome metadata; here. # Batch Attributes. The ServiceBackend `batch_attributes` attribute specifies the attributes for any batch created by; the ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11194:5563,interface,interface,5563,https://hail.is,https://github.com/hail-is/hail/pull/11194,1,['interface'],['interface']
Integrability,"}{Class, Method, Function}Builder now takes a type parameter that represents (a supertype) of the class being built: e.g. MethodBuilder[C] is a builder for a method on a class of type C. Note, we can't have a type parameter that represents the actual class type because that doesn't exist yet.; - {Emit}FunctionBuilder all but gone: {Emit}FunctionBuilder is now just a {Emit}MethodBuilder is an apply method. Most functionality moved to {Emit}ClassBuilder.; - Added EmitClassBuilder.; - It is convenient to have e.g. MethodBuilder support the ClassBuilder interface: this is what the Wrapped traits are for: MethodBuilder extends WrappedClassBuilder and ClassBuilder extends WrappedModuleBuilder. So MethodBuilder has the ClassBuilder interface, but is not actually a ClassBuilder. I tried a bunch of variants for the design of this, and while I don't think this is quite perfect, it seems workable.; - EmitMethodBuilder extends WrappedMethodBuilder, etc. Rather than overloading, the two interfaces are distinct: genMethod vs genEmitMethod, etc.; - Pushed ""new vs gen"" into more places e.g. newMethod vs genMethod. newMethod takes a name and creates a method of that name (e.g. apply). genMethod takes a baseName and creates a unique name based on the baseName.; - MethodBuilder newField => genFieldThisRef to distinguish it from ClassBuilder.newField. The former returns a Settable[T] referencing `this.<field>`, the latter just returns a Field.; - All methods supporting code generation for IR take EmitMethodBuilder rather than MethodBuilder (PType routines, aggregators, etc.). Summarizing the new class structure:. ```; class ModuleBuilder; trait WrappedModuleBuilder; def modb: ModuleBuilder; class ClassBuilder[C] extends WrappedModuleBuilder; trait WrappedClassBuilder[C]; def cb: ClassBuilder[C]; class MethodBuilder[C] extends WrappedClassBuilder[C]; trait WrappedMethodBuilder[C]; def mb: MethodBuilder; class FunctionBuilder[F] extends WrappedMethodBuilder[F]; def apply_method: MethodBui",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8335:1328,interface,interfaces,1328,https://hail.is,https://github.com/hail-is/hail/pull/8335,1,['interface'],['interfaces']
Integrability,"~Stacked on #10770~; ~Stacked on #10791~. This PR attempts to allow linear algebra codegen methods, like the LAPACK wrappers and the local whitening methods I'm working on, to defensively assert shape compatibility preconditions, without generating redundant runtime checks. (I always hate when we're pushed to avoid using code generation abstractions (in this case, just factoring code into smaller functions), because they generate worse code.). The method is pretty simple. SNDArray shapes are now arrays of `SizeValue`, which is a sum type with cases `SizeValueDyn(Value[Long])` and `SizeValueStatic(Long)`. I don't think static sizes occur very often, but it was a simple addition. `SizeValue`s can be compared statically with `==`, or at runtime with `ceq`: the former is true only if we can prove statically that the two sizes must be equal, while the latter emits code to check equality at runtime, using static knowledge to elide dynamic checks where possible. The way we encode static knowledge that two sizes are equal is by using the same local variable to store both. The primary interface to introduce that static knowledge (other than using the same set of sizes to construct multiple SNDArrays), is the method `coerceToShape(cb: CodeBuilder, newShape: Seq[SizeValue]): SNDArrayValue`, which emits code to dynamically assert that `this.shape` agrees with `newShape`, then returns `this` with shape replaced by `newShape`. Thus, `a.coerceToShape(cb, newShape).shape == newShape` will always be true, preserving the static knowledge about the shape of `a`. As a simple example, `gemm` verifies its inputs with (simplifying to the case with no transposes); ```; val Seq(m, n) = C.shapes; val k = A.shapes(1); A.assertHasShape(cb, FastIndexedSeq(m, k), errMsg); B.assertHasShape(cb, FastIndexedSeq(k, n), errMsg); ```; If we call this with; ```; val m, n, k = \\ compute expected dim sizes. \\ emit dynamic size checks once; val A_ = A.coerceToShape(cb, IndexedSeq(m, k)); val B_ = B.coerce",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10783:116,wrap,wrappers,116,https://hail.is,https://github.com/hail-is/hail/pull/10783,1,['wrap'],['wrappers']
Integrability,"~Stacked on #10791~. A few high level changes got mixed up in this PR, since I couldn't predict where a thread would lead once I started pulling. If you would like, I can try to disentangle them. Here are the conceptual changes:; * add a CodeBuilder argument to `getEmitParam`, so that parameters which are pointers to region values can be loaded into `SValue`s with multiple locals; * make `EmitValue` a concrete class, consisting of an optional boolean value and an `SValue`; * add `valueTuple` to both `SValue` and `EmitValue`; * copy the `SCode` interface onto `SValue`, to make it easier to replace `SCode`s with `SValues` ; * add `loadToSValue` to `SingleCodeType`; * add `SStreamValue`. This loses the single use assertion, but that doesn't seem like it asserts much, since the stream producer can be freely accessed without memoizing the `SStreamCode`",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10797:550,interface,interface,550,https://hail.is,https://github.com/hail-is/hail/pull/10797,1,['interface'],['interface']
Integrability,"~Stacked on #10905~. This PR refactors; * BinarySearch; * BLAS/LAPACK wrapper methods; * CodeBuilder.assign (the SSettable overload); * SSettable.store - Most uses now call with an SValue, but the SCode overload is still used in SCode subclasses.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10906:70,wrap,wrapper,70,https://hail.is,https://github.com/hail-is/hail/pull/10906,1,['wrap'],['wrapper']
Integrability,"~Stacked on #10906~. This PR refactors `MethodBuilder.invoke` and `EmitCodeBuilder.invoke(S)Code` to take/return values. * `invoke` now takes a `CodeBuilderLike`. It is used in places where there is only access to a `CodeBuilder` (not an `EmitCodeBuilder`), so I had to use the generic interface, and had to move a couple methods on `EmitCodeBuilder` to `CodeBuilderLike`. I have never understood this Emit/non-Emit split; would be a great simplification if we could collapse it.; * This change pushed some (S)Code->(S)Value refactorings inside some aggregator implementations, which generate and invoke internal methods.; * I had to keep a version of `MethodBuilder.invoke` that doesn't take a CodeBuilder, for use in `ThisLazyFieldRef.get`. Will have to think more about how this should work when Code is (mostly) gone. Maybe lazy fields should not subclass Value, and to access a lazy field requires an explicit `load(cb: CodeBuilder): Value[T]`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10907:286,interface,interface,286,https://hail.is,https://github.com/hail-is/hail/pull/10907,1,['interface'],['interface']
Integrability,"~Stacked on #8874, not by necessity, but because the following PR lowering TableJoin depends on both this and that.~. * Before, `TableStage` defined it's per-partition behavior in an abstract method `def partition(ctxRef: Ref): IR`. This makes defining a new `TableStage` a bit heavy syntactically, and means we can't inspect the type of the partition IR without apply the function to something. This PR replaces the abstract method with two fields `ctxRefName: String` and `partitionIR: IR`. It defines a method `def partition(ctx: IR): IR` using these, which is more ergonomic to use because the context isn't forced to be a `Ref`. * With the type of the partition result accessible, this PR requires that type to be a `TStream<TStruct>`. Without this requirement, there is no clear connection between the partitioner and the rest of the `TableStage`. The only violation of this requirement was mapping to some other type right before collecting; this use is accommodated by a `mapCollect` method which combines the steps. * The binding structure of `TableStage` has been slightly reorganized. The `letBindings`, which are used on the master, and the `broadcastVals` which are used on the driver (previously, they had to also be usable on master), have been teased apart. In the new structure:; * `letBindings` are as before: a sequence of bindings which are evaluated in sequence on the master, whose bindings are visible in the `contexts` expression and in the `broadcastVals`; * `broadcastVals` are now a separate sequence of bindings, which are evaluated on the master in parallel (each broadcast binding sees only the `letBindings`, no previous `broadcastVals`), and whose bindings are visible only in the `partitionIR`; * `globals` is now required to be a `Ref`, which is defined in `letBindings` and redefined in `broadcastVals`, so that the `Ref` is valid in later `letBindings`, in `contexts`, as well as in the `partitionIR`. This does mean that `globals` is always broadcast, even when it",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8917:85,depend,depends,85,https://hail.is,https://github.com/hail-is/hail/pull/8917,1,['depend'],['depends']
Integrability,"~~Stacked on #9177~~. These are tricky because of the overlapping lifetimes of the accumulator values. The solution implemented here is to keep two regions. When running the fold body, one region is empty, and the other holds just the previous accumulator. Then we deep copy the new accumulator to the empty region, clear the other one, then swap the two regions before moving to the next iteration. This required expanding the StagedRegion API a bit. First, it now strictly tracks the parent StagedRegion, even in the non-allocating case where the parent wraps the same run-time region. Second, in addition to copying a value to the parent, we can now copy a value to a sibling. It enforces at compile time that the two regions have the same parent. It follows that either both are actually separate regions, or both are just wrappers around the parent region. In the latter case, copying to a sibling is a no-op.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9178:556,wrap,wraps,556,https://hail.is,https://github.com/hail-is/hail/pull/9178,2,['wrap'],"['wrappers', 'wraps']"
Integrability,"~~stacked on #7386~~. * implements `.tail` method on `MatrixTable`. ```python; def tail(self, n: Optional[int], n_cols: Optional[int] = None) -> 'MatrixTable':; """"""Subset matrix to last `n` rows. .... Parameters; ----------; n : :obj:`int`; Number of rows to include (all rows included if ``None``).; n_cols : :obj:`int`, optional; Number of cols to include (all cols included if ``None``).; Returns; -------; :class:`.MatrixTable`; Matrix including the last `n` rows and last `n_cols` cols.; """"""; ```. question: should the interface have the same backwards compatibility naming issue as `.head`, to preserve consistency? or should the keyword arguments be `n_cols` and `n_rows`?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7394:524,interface,interface,524,https://hail.is,https://github.com/hail-is/hail/pull/7394,1,['interface'],['interface']
Integrability,"​BeyondEvil</code></a></li>; <li>Remove unused and undocumented markers (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/224"">#224</a>) <a href=""https://github.com/BeyondEvil""><code>@​BeyondEvil</code></a></li>; <li>Append a line break after captured log sections (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/217"">#217</a>) <a href=""https://github.com/borntyping""><code>@​borntyping</code></a></li>; <li>Handle when report title is stored as an environment variable (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/203"">#203</a>) <a href=""https://github.com/BeyondEvil""><code>@​BeyondEvil</code></a></li>; <li>Removed extraneous space from anchor tag (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/192"">#192</a>) <a href=""https://github.com/chardbury""><code>@​chardbury</code></a></li>; <li>Stop filtering out falsy environment values (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/180"">#180</a>) <a href=""https://github.com/crazymerlyn""><code>@​crazymerlyn</code></a></li>; <li>Always define <strong>version</strong> even if get_distribution() fails (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/178"">#178</a>) <a href=""https://github.com/nicoddemus""><code>@​nicoddemus</code></a></li>; <li>Disable sort on environment table when metadata is ordered (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-html/issues/162"">#162</a>) <a href=""https://github.com/jacebrowning""><code>@​jacebrowning</code></a></li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/pytest-dev/pytest-html/blob/master/docs/changelog.rst"">pytest-html's changelog</a>.</em></p>; <blockquote>; <p>3.1.1 (2020-12-13)</p>; <pre><code>; * Fix issue with reporting of missing CSS files. (`[#388](https",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11524:7702,depend,dependabot,7702,https://hail.is,https://github.com/hail-is/hail/pull/11524,1,['depend'],['dependabot']
Integrability,"…urces. TJ has raised a bunch of very legitimate concerns about the expressivity of; hailtop.batch. In this PR, I basically rebuilt hailtop.batch from scratch as; a learning exercise. Once I understood how it worked, I added two valuable; features:. 1. `hb.remote` creates a ""remote"" resource which is never localized but still; creates dependency relationships. 2. `ResourceToStringPickler` which pickles resources appropriately even if; they are nested within other structures.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11378:337,depend,dependency,337,https://hail.is,https://github.com/hail-is/hail/pull/11378,1,['depend'],['dependency']
Integrability,"─╮; │ /Users/cvittal/src/hail/hail/python/hailtop/hailctl/describe.py:104 in describe │; │ │; │ 101 │ ''' │; │ 102 │ Describe the MatrixTable or Table at path FILE. │; │ 103 │ ''' │; │ ❱ 104 │ asyncio.get_event_loop().run_until_complete(async_describe(file, requester_pays_proj │; │ 105 │; │ 106 │; │ 107 async def async_describe( │; │ │; │ /opt/homebrew/Cellar/python@3.10/3.10.13/Frameworks/Python.framework/Versions/3.10/lib/python3.1 │; │ 0/asyncio/base_events.py:649 in run_until_complete │; │ │; │ 646 │ │ if not future.done(): │; │ 647 │ │ │ raise RuntimeError('Event loop stopped before Future completed.') │; │ 648 │ │ │; │ ❱ 649 │ │ return future.result() │; │ 650 │ │; │ 651 │ def stop(self): │; │ 652 │ │ """"""Stop running the event loop. │; │ │; │ /Users/cvittal/src/hail/hail/python/hailtop/hailctl/describe.py:119 in async_describe │; │ │; │ 116 │ │ gcs_kwargs['project'] = requester_pays_project_id │; │ 117 │ │; │ 118 │ async with aio_contextlib.closing(RouterAsyncFS(gcs_kwargs=gcs_kwargs)) as fs: │; │ ❱ 119 │ │ j = orjson.loads(decompress(await fs.read(path.join(file, 'metadata.json.gz')), │; │ 120 │ │ │; │ 121 │ │ # Get the file schema │; │ 122 │ │ file_schema = parse_schema(j[next(k for k in j.keys() if k.endswith('type'))]) │; │ │; │ /Users/cvittal/src/hail/hail/python/hailtop/aiotools/fs/fs.py:281 in read │; │ │; │ 278 │ │ │ pass │; │ 279 │ │; │ 280 │ async def read(self, url: str) -> bytes: │; │ ❱ 281 │ │ async with await self.open(url) as f: │; │ 282 │ │ │ return await f.read() │; │ 283 │ │; │ 284 │ async def read_from(self, url: str, start: int) -> bytes: │; │ │; │ /Users/cvittal/src/hail/hail/python/hailtop/aiotools/router_fs.py:75 in open │; │ │; │ 72 │ │ return self._load_fs(uri) │; │ 73 │ │; │ 74 │ async def open(self, url: str) -> ReadableStream: │; │ ❱ 75 │ │ fs = self._get_fs(url) │; │ 76 │ │ return await fs.open(url) │; │ 77 │ │; │ 78 │ async def _open_from(self, url: str, start: int, *, length: Optional[int] = None) -> │; │ │; │ /Users/cvittal/src/h",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13793:1471,Rout,RouterAsyncFS,1471,https://hail.is,https://github.com/hail-is/hail/issues/13793,1,['Rout'],['RouterAsyncFS']
Modifiability,	at is.hail.expr.ir.ExtractIntervalFilters$.openInterval(ExtractIntervalFilters.scala:94); 	at is.hail.expr.ir.ExtractIntervalFilters$$anonfun$extractAndRewrite$6.apply(ExtractIntervalFilters.scala:205); 	at is.hail.expr.ir.ExtractIntervalFilters$$anonfun$extractAndRewrite$6.apply(ExtractIntervalFilters.scala:201); 	at scala.Option.flatMap(Option.scala:171); 	at is.hail.expr.ir.ExtractIntervalFilters$.extractAndRewrite(ExtractIntervalFilters.scala:201); 	at is.hail.expr.ir.ExtractIntervalFilters$.extractAndRewrite(ExtractIntervalFilters.scala:151); 	at is.hail.expr.ir.ExtractIntervalFilters$.extractPartitionFilters(ExtractIntervalFilters.scala:249); 	at is.hail.expr.ir.ExtractIntervalFilters$$anonfun$apply$2.apply(ExtractIntervalFilters.scala:266); 	at is.hail.expr.ir.ExtractIntervalFilters$$anonfun$apply$2.apply(ExtractIntervalFilters.scala:254); 	at is.hail.expr.ir.RewriteBottomUp$.is$hail$expr$ir$RewriteBottomUp$$rewrite$1(RewriteBottomUp.scala:15); 	at is.hail.expr.ir.RewriteBottomUp$$anonfun$1.apply(RewriteBottomUp.scala:6); 	at is.hail.expr.ir.RewriteBottomUp$$anonfun$1.apply(RewriteBottomUp.scala:6); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); 	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.AbstractTraversable.map(Traversable.scala:104); 	at is.hail.expr.ir.RewriteBottomUp$.is$hail$expr$ir$RewriteBottomUp$$rewrite$1(RewriteBottomUp.scala:6); 	at is.hail.expr.ir.RewriteBottomUp$$anonfun$1.apply(RewriteBottomUp.scala:6); 	at is.hail.expr.ir.RewriteBottomUp$$anonfun$1.apply(RewriteBottomUp.scala:6); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6458:3746,Rewrite,RewriteBottomUp,3746,https://hail.is,https://github.com/hail-is/hail/issues/6458,1,['Rewrite'],['RewriteBottomUp']
Modifiability, 	at __C214collect_distributed_array_matrix_native_writer.apply_region41_62(Unknown Source); 	at __C214collect_distributed_array_matrix_native_writer.apply_region2_229(Unknown Source); 	at __C214collect_distributed_array_matrix_native_writer.apply(Unknown Source); 	at __C214collect_distributed_array_matrix_native_writer.apply(Unknown Source); 	at is.hail.backend.BackendUtils.$anonfun$collectDArray$2(BackendUtils.scala:38); 	at is.hail.utils.package$.using(package.scala:635); 	at is.hail.backend.BackendUtils.$anonfun$collectDArray$1(BackendUtils.scala:37); 	at is.hail.utils.package$.using(package.scala:635); 	at is.hail.backend.BackendUtils.collectDArray(BackendUtils.scala:36); 	at __C19Compiled.__m23split_WriteMetadata_region27_79(Emit.scala); 	at __C19Compiled.__m23split_WriteMetadata(Emit.scala); 	at __C19Compiled.apply(Emit.scala); 	at is.hail.backend.service.ServiceBackend.$anonfun$execute$1(ServiceBackend.scala:321); 	at is.hail.backend.service.ServiceBackend.$anonfun$execute$1$adapted(ServiceBackend.scala:321); 	at is.hail.backend.ExecuteContext.$anonfun$scopedExecution$1(ExecuteContext.scala:140); 	at is.hail.utils.package$.using(package.scala:635); 	at is.hail.backend.ExecuteContext.scopedExecution(ExecuteContext.scala:140); 	at is.hail.backend.service.ServiceBackend.execute(ServiceBackend.scala:321); 	at is.hail.backend.service.ServiceBackend.execute(ServiceBackend.scala:348); 	at is.hail.backend.service.ServiceBackendSocketAPI2.$anonfun$executeOneCommand$12(ServiceBackend.scala:700); 	at is.hail.backend.service.ServiceBackendSocketAPI2.withIRFunctionsReadFromInput(ServiceBackend.scala:803); 	at is.hail.backend.service.ServiceBackendSocketAPI2.$anonfun$executeOneCommand$11(ServiceBackend.scala:698); 	at is.hail.backend.service.ServiceBackendSocketAPI2.$anonfun$executeOneCommand$2(ServiceBackend.scala:656); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:75); 	at is.hail.utils.package$.using(package.scala:635); 	at is.hail.backend.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12982:10563,adapt,adapted,10563,https://hail.is,https://github.com/hail-is/hail/issues/12982,2,['adapt'],['adapted']
Modifiability, 	at is.hail.relocated.com.google.cloud.storage.StorageImpl.writer(StorageImpl.java:674) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.relocated.com.google.cloud.storage.StorageImpl.writer(StorageImpl.java:95) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.GoogleStorageFS$$anon$2.$anonfun$doHandlingRequesterPays$2(GoogleStorageFS.scala:300) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.services.package$.retryTransientErrors(package.scala:182) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.GoogleStorageFS$$anon$2.$anonfun$doHandlingRequesterPays$1(GoogleStorageFS.scala:300) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.GoogleStorageFS$$anon$2.$anonfun$doHandlingRequesterPays$1$adapted(GoogleStorageFS.scala:299) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.GoogleStorageFS.is$hail$io$fs$GoogleStorageFS$$handleRequesterPays(GoogleStorageFS.scala:181) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.GoogleStorageFS$$anon$2.doHandlingRequesterPays(GoogleStorageFS.scala:304) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.io.fs.GoogleStorageFS$$anon$2.flush(GoogleStorageFS.scala:314) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at java.io.DataOutputStream.flush(DataOutputStream.java:123) ~[?:1.8.0_382]; 	at java.io.FilterOutputStream.close(FilterOutputStream.java:158) ~[?:1.8.0_382]; 	at is.hail.utils.richUtils.ByteTrackingOutputStream.close(ByteTrackingOutputStream.scala:23) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13697:13855,adapt,adapted,13855,https://hail.is,https://github.com/hail-is/hail/issues/13697,2,['adapt'],['adapted']
Modifiability," ""/hail/python/hail/ir/base_ir.py"", line 303, in typ; self._compute_type(); File ""/hail/python/hail/ir/table_ir.py"", line 215, in _compute_type; self._type = Env.backend().table_type(self); File ""/hail/python/hail/backend/backend.py"", line 121, in table_type; jir = self._to_java_ir(tir); File ""/hail/python/hail/backend/backend.py"", line 105, in _to_java_ir; ir._jir = ir.parse(r(ir), ir_map=r.jirs); File ""/hail/python/hail/ir/base_ir.py"", line 311, in parse; return Env.hail().expr.ir.IRParser.parse_table_ir(code, ref_map, ir_map); File ""/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py"", line 1257, in __call__; File ""/hail/python/hail/utils/java.py"", line 225, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: NoSuchMethodError: org.apache.hadoop.conf.Configuration.getPropsWithPrefix(Ljava/lang/String;)Ljava/util/Map;. Java stack trace:; java.lang.NoSuchMethodError: org.apache.hadoop.conf.Configuration.getPropsWithPrefix(Ljava/lang/String;)Ljava/util/Map;; at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.HadoopConfigurationProperty.lambda$getPropsWithPrefix$3(HadoopConfigurationProperty.java:106); at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.HadoopConfigurationProperty.getLookupKey(HadoopConfigurationProperty.java:120); at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.HadoopConfigurationProperty.getPropsWithPrefix(HadoopConfigurationProperty.java:106); at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemConfiguration.getGcsOptionsBuilder(GoogleHadoopFileSystemConfiguration.java:421); at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemConfiguration.getGcsFsOptionsBuilder(GoogleHadoopFileSystemConfiguration.java:383); at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.createGcsFs(GoogleHadoopFileSystemBase.java:1516); at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.configure(Goo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8343:2438,Config,Configuration,2438,https://hail.is,https://github.com/hail-is/hail/issues/8343,1,['Config'],['Configuration']
Modifiability," &{map[""apiVersion"":""v1"" ""kind"":""Namespace"" ""metadata"":map[""annotations"":map[""kubectl.kubernetes.io/last-applied-configuration"":""""] ""name"":""batch-pods"" ""namespace"":""""]]}; from server for: ""deployment.yaml"": namespaces ""batch-pods"" is forbidden: User ""system:serviceaccount:batch-pods:deploy-svc"" cannot get namespaces in the namespace ""batch-pods"": Unknown user ""system:serviceaccount:batch-pods:deploy-svc""; Error from server (Forbidden): error when retrieving current configuration of:; Resource: ""/v1, Resource=serviceaccounts"", GroupVersionKind: ""/v1, Kind=ServiceAccount""; Name: ""batch-svc"", Namespace: ""batch-pods""; Object: &{map[""kind"":""ServiceAccount"" ""metadata"":map[""name"":""batch-svc"" ""namespace"":""batch-pods"" ""annotations"":map[""kubectl.kubernetes.io/last-applied-configuration"":""""]] ""apiVersion"":""v1""]}; from server for: ""deployment.yaml"": serviceaccounts ""batch-svc"" is forbidden: User ""system:serviceaccount:batch-pods:deploy-svc"" cannot get serviceaccounts in the namespace ""batch-pods"": Unknown user ""system:serviceaccount:batch-pods:deploy-svc""; Error from server (Forbidden): error when retrieving current configuration of:; Resource: ""rbac.authorization.k8s.io/v1, Resource=roles"", GroupVersionKind: ""rbac.authorization.k8s.io/v1, Kind=Role""; Name: ""batch-pods-admin"", Namespace: ""batch-pods""; Object: &{map[""apiVersion"":""rbac.authorization.k8s.io/v1"" ""kind"":""Role"" ""metadata"":map[""name"":""batch-pods-admin"" ""namespace"":""batch-pods"" ""annotations"":map[""kubectl.kubernetes.io/last-applied-configuration"":""""]] ""rules"":[map[""apiGroups"":[""""] ""resources"":[""pods""] ""verbs"":[""get"" ""list"" ""watch"" ""create"" ""update"" ""patch"" ""delete""]] map[""apiGroups"":[""""] ""resources"":[""pods/log""] ""verbs"":[""get""]]]]}; from server for: ""deployment.yaml"": roles.rbac.authorization.k8s.io ""batch-pods-admin"" is forbidden: User ""system:serviceaccount:batch-pods:deploy-svc"" cannot get roles.rbac.authorization.k8s.io in the namespace ""batch-pods"": Unknown user ""system:serviceaccount:batch-pods:deploy-svc""; Error ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4609:1362,config,configuration,1362,https://hail.is,https://github.com/hail-is/hail/issues/4609,1,['config'],['configuration']
Modifiability, 'hailtop/aiotools/fs/stream.py'; adding 'hailtop/auth/__init__.py'; adding 'hailtop/auth/auth.py'; adding 'hailtop/auth/sql_config.py'; adding 'hailtop/auth/tokens.py'; adding 'hailtop/batch/__init__.py'; adding 'hailtop/batch/backend.py'; adding 'hailtop/batch/batch.py'; adding 'hailtop/batch/batch_pool_executor.py'; adding 'hailtop/batch/conftest.py'; adding 'hailtop/batch/docker.py'; adding 'hailtop/batch/exceptions.py'; adding 'hailtop/batch/globals.py'; adding 'hailtop/batch/hail_genetics_images.py'; adding 'hailtop/batch/job.py'; adding 'hailtop/batch/resource.py'; adding 'hailtop/batch/utils.py'; adding 'hailtop/batch_client/__init__.py'; adding 'hailtop/batch_client/aioclient.py'; adding 'hailtop/batch_client/client.py'; adding 'hailtop/batch_client/globals.py'; adding 'hailtop/batch_client/parse.py'; adding 'hailtop/cleanup_gcr/__init__.py'; adding 'hailtop/cleanup_gcr/__main__.py'; adding 'hailtop/config/__init__.py'; adding 'hailtop/config/deploy_config.py'; adding 'hailtop/config/user_config.py'; adding 'hailtop/fs/__init__.py'; adding 'hailtop/fs/fs.py'; adding 'hailtop/fs/fs_utils.py'; adding 'hailtop/fs/router_fs.py'; adding 'hailtop/fs/stat_result.py'; adding 'hailtop/hailctl/__init__.py'; adding 'hailtop/hailctl/__main__.py'; adding 'hailtop/hailctl/deploy.yaml'; adding 'hailtop/hailctl/describe.py'; adding 'hailtop/hailctl/auth/__init__.py'; adding 'hailtop/hailctl/auth/cli.py'; adding 'hailtop/hailctl/auth/create_user.py'; adding 'hailtop/hailctl/auth/delete_user.py'; adding 'hailtop/hailctl/auth/login.py'; adding 'hailtop/hailctl/batch/__init__.py'; adding 'hailtop/hailctl/batch/batch_cli_utils.py'; adding 'hailtop/hailctl/batch/cli.py'; adding 'hailtop/hailctl/batch/list_batches.py'; adding 'hailtop/hailctl/batch/submit.py'; adding 'hailtop/hailctl/batch/billing/__init__.py'; adding 'hailtop/hailctl/batch/billing/cli.py'; adding 'hailtop/hailctl/config/__init__.py'; adding 'hailtop/hailctl/config/cli.py'; adding 'hailtop/hailctl/dataproc/__init,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13445:10887,config,config,10887,https://hail.is,https://github.com/hail-is/hail/issues/13445,1,['config'],['config']
Modifiability," (released 2023-03-16)</h2>; <ul>; <li>[varLib] Fixed regression introduced in 4.39.1 whereby an incomplete 'STAT' table; would be built even though a DesignSpace v5 did contain 'STAT' definitions (<a href=""https://redirect.github.com/fonttools/fonttools/issues/3045"">#3045</a>, <a href=""https://redirect.github.com/fonttools/fonttools/issues/3046"">#3046</a>).</li>; </ul>; <h2>4.39.1 (released 2023-03-16)</h2>; <ul>; <li>[avar2] Added experimental support for reading/writing avar version 2 as specified in; this draft proposal: <a href=""https://github.com/harfbuzz/boring-expansion-spec/blob/main/avar2.md"">https://github.com/harfbuzz/boring-expansion-spec/blob/main/avar2.md</a></li>; <li>[glifLib] Wrap underlying XML library exceptions with GlifLibError when parsing GLIFs,; and also print the name and path of the glyph that fails to be parsed (<a href=""https://redirect.github.com/fonttools/fonttools/issues/3042"">#3042</a>).</li>; <li>[feaLib] Consult avar for normalizing user-space values in ConditionSets and in; VariableScalars (<a href=""https://redirect.github.com/fonttools/fonttools/issues/3042"">#3042</a>, <a href=""https://redirect.github.com/fonttools/fonttools/issues/3043"">#3043</a>).</li>; <li>[ttProgram] Handle string input to Program.fromAssembly() (<a href=""https://redirect.github.com/fonttools/fonttools/issues/3038"">#3038</a>).</li>; <li>[otlLib] Added a config option to emit GPOS 7 lookups, currently disabled by default; because of a macOS bug (<a href=""https://redirect.github.com/fonttools/fonttools/issues/3034"">#3034</a>).</li>; <li>[COLRv1] Added method to automatically compute ClipBoxes (<a href=""https://redirect.github.com/fonttools/fonttools/issues/3027"">#3027</a>).</li>; <li>[ttFont] Fixed getGlyphID to raise KeyError on missing glyphs instead of returning; None. The regression was introduced in v4.27.0 (<a href=""https://redirect.github.com/fonttools/fonttools/issues/3032"">#3032</a>).</li>; <li>[sbix] Fixed UnboundLocalError: cannot access local variabl",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12910:11900,Variab,VariableScalars,11900,https://hail.is,https://github.com/hail-is/hail/pull/12910,1,['Variab'],['VariableScalars']
Modifiability," 1511, in import_table; t = Table(TableRead(tr)); File ""/hail/python/hail/table.py"", line 334, in __init__; self._type = self._tir.typ; File ""/hail/python/hail/ir/base_ir.py"", line 303, in typ; self._compute_type(); File ""/hail/python/hail/ir/table_ir.py"", line 215, in _compute_type; self._type = Env.backend().table_type(self); File ""/hail/python/hail/backend/backend.py"", line 121, in table_type; jir = self._to_java_ir(tir); File ""/hail/python/hail/backend/backend.py"", line 105, in _to_java_ir; ir._jir = ir.parse(r(ir), ir_map=r.jirs); File ""/hail/python/hail/ir/base_ir.py"", line 311, in parse; return Env.hail().expr.ir.IRParser.parse_table_ir(code, ref_map, ir_map); File ""/spark-2.4.0-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py"", line 1257, in __call__; File ""/hail/python/hail/utils/java.py"", line 225, in deco; 'Error summary: %s' % (deepest, full, hail.__version__, deepest)) from None; hail.utils.java.FatalError: NoSuchMethodError: org.apache.hadoop.conf.Configuration.getPropsWithPrefix(Ljava/lang/String;)Ljava/util/Map;. Java stack trace:; java.lang.NoSuchMethodError: org.apache.hadoop.conf.Configuration.getPropsWithPrefix(Ljava/lang/String;)Ljava/util/Map;; at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.HadoopConfigurationProperty.lambda$getPropsWithPrefix$3(HadoopConfigurationProperty.java:106); at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.HadoopConfigurationProperty.getLookupKey(HadoopConfigurationProperty.java:120); at com.google.cloud.hadoop.repackaged.gcs.com.google.cloud.hadoop.util.HadoopConfigurationProperty.getPropsWithPrefix(HadoopConfigurationProperty.java:106); at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemConfiguration.getGcsOptionsBuilder(GoogleHadoopFileSystemConfiguration.java:421); at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemConfiguration.getGcsFsOptionsBuilder(GoogleHadoopFileSystemConfiguration.java:383); at com.google.cloud.hadoop.fs.gcs.GoogleHadoop",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8343:2298,Config,Configuration,2298,https://hail.is,https://github.com/hail-is/hail/issues/8343,1,['Config'],['Configuration']
Modifiability," 2.13.5.; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/PyCQA/pylint/blob/main/ChangeLog"">pylint's changelog</a>.</em></p>; <blockquote>; <h1>What's New in Pylint 2.13.5?</h1>; <p>Release date: 2022-04-06</p>; <ul>; <li>; <p>Fix false positive regression in 2.13.0 for <code>used-before-assignment</code> for; homonyms between variable assignments in try/except blocks and variables in; subscripts in comprehensions.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/6069"">#6069</a>; Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/6136"">#6136</a></p>; </li>; <li>; <p><code>lru-cache-decorating-method</code> has been renamed to <code>cache-max-size-none</code> and; will only be emitted when <code>maxsize</code> is <code>None</code>.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/6180"">#6180</a></p>; </li>; <li>; <p>Fix false positive for <code>unused-import</code> when disabling both <code>used-before-assignment</code> and <code>undefined-variable</code>.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/6089"">#6089</a></p>; </li>; <li>; <p>Narrow the scope of the <code>unnecessary-ellipsis</code> checker to:</p>; <ul>; <li>functions &amp; classes which contain both a docstring and an ellipsis.</li>; <li>A body which contains an ellipsis <code>nodes.Expr</code> node &amp; at least one other statement.</li>; </ul>; </li>; <li>; <p>Fix false positive for <code>used-before-assignment</code> for assignments taking place via; nonlocal declarations after an earlier type annotation.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5394"">#5394</a></p>; </li>; <li>; <p>Fix crash for <code>redefined-slots-in-subclass</code> when the type of the slot is not a const or a string.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/6100"">#6100</a></p>; <",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11739:1148,variab,variable,1148,https://hail.is,https://github.com/hail-is/hail/pull/11739,1,['variab'],['variable']
Modifiability," 3.7+</li>; <li>When installing with pip, the <code>docker[tls]</code> extra is deprecated and a no-op,; use <code>docker</code> for same functionality (TLS support is always available now)</li>; <li>Native Python SSH client (used by default / <code>use_ssh_client=False</code>) will now; reject unknown host keys with <code>paramiko.ssh_exception.SSHException</code></li>; <li>Short IDs are now 12 characters instead of 10 characters (same as Docker CLI)</li>; <li>Version metadata is now exposed as <code>__version__</code></li>; </ul>; <h3>✨ Features</h3>; <ul>; <li>Python 3.10 support</li>; <li>Automatically negotiate most secure TLS version</li>; <li>Add <code>platform</code> (e.g. <code>linux/amd64</code>, <code>darwin/arm64</code>) to container create &amp; run</li>; <li>Add support for <code>GlobalJob</code> and <code>ReplicatedJobs</code> for Swarm</li>; <li>Add <code>remove()</code> method on <code>Image</code></li>; <li>Add <code>force</code> param to <code>disable()</code> on <code>Plugin</code></li>; </ul>; <h3>🐛 Bugfixes</h3>; <ul>; <li>Fix install issues on Windows related to <code>pywin32</code></li>; <li>Do not accept unknown SSH host keys in native Python SSH mode</li>; <li>Use 12 character short IDs for consistency with Docker CLI</li>; <li>Ignore trailing whitespace in <code>.dockerignore</code> files</li>; <li>Fix IPv6 host parsing when explicit port specified</li>; <li>Fix <code>ProxyCommand</code> option for SSH connections</li>; <li>Do not spawn extra subshell when launching external SSH client</li>; <li>Improve exception semantics to preserve context</li>; <li>Documentation improvements (formatting, examples, typos, missing params)</li>; </ul>; <h3>🔧 Miscellaneous</h3>; <ul>; <li>Upgrade dependencies in <code>requirements.txt</code> to latest versions</li>; <li>Remove extraneous transitive dependencies</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12475:3548,Plugin,Plugin,3548,https://hail.is,https://github.com/hail-is/hail/pull/12475,1,['Plugin'],['Plugin']
Modifiability," 8 million bytes = 2 GB. It occurs to me that this is actually way to much data to load on the master node in general (since I just try to open the indexes for every file). I should switch this to a disk-based index.~ Made it disk-based, called it `OnDiskBTreeIndexToValue` #3794. - each hadoop `FileSplit` now contains a possibly null (indicating no filter) list of variants (by index) to keep, in practice this should be quite small. - ~I changed several asserts to `if`'s with fatals, so as not to allocate strings~ Moved to #3771. - ~We no longer copy the genotype data into a buffer in the block reader. This was forcing the `fastKeys` to do an unnecessary data copy~ Moved to #3783 (with some substantial refactoring so it doesn't look much like this PR anymore). - ~I changed the contract on BgenRecord to require that `getValue` is called to ""consume"" the record before the next record is taken~ Irrelevant thanks to #3783 's refactoring. - ~`getValue(null)` just skips bytes (no copy, no decompression)~ Irrelevant thanks to #3783 's refactoring. - ~I added `RegionValueBuilder.unsafeAdvance` which can be used when you're creating an array of empty structs but don't want to do all the unnecessary RVB bookkeeping work.~ Moved to #3773. - ~I use `RegionValueBuilder.unsafeAdvance` to make loading a BGEN without entry fields very fast.~ Rolled into #3783. - ~I fixed `Table.index` to not trigger a partition key info gathering~ Moved to #3774. I had to ship the arrays of filtered variant indices to the workers somehow, so I shipped them as base64 encoded arrays of bytes. It's pretty groady (and that's why I added the commons-codec library). I don't know how else to initialize record readers with hadoop. Generally, I think the BGEN loading code could use a clean up, and I haven't done that here, if anything I've made it more complicated. I also need to check that there are tests for or write tests for:. - indexing tables doesn't cause an extra shuffle; - ~the include lid and includ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3727:2564,refactor,refactoring,2564,https://hail.is,https://github.com/hail-is/hail/pull/3727,1,['refactor'],['refactoring']
Modifiability," <li>; <p>increases the weight of user specifiable priorities.; The weights of following priority plugins are increased</p>; <ul>; <li><code>TaintTolerations</code> to 3 - as leveraging node tainting to group nodes in the cluster is becoming a widely-adopted practice</li>; <li><code>NodeAffinity</code> to 2</li>; <li><code>InterPodAffinity</code> to 2</li>; </ul>; </li>; <li>; <p>Won't have <code>HealthzBindAddress</code>, <code>MetricsBindAddress</code> fields (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/104251"">kubernetes/kubernetes#104251</a>, <a href=""https://github.com/ravisantoshgudimetla""><code>@​ravisantoshgudimetla</code></a>)</p>; </li>; </ul>; </li>; <li>Introduce v1beta2 for Priority and Fairness with no changes in API spec. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/104399"">kubernetes/kubernetes#104399</a>, <a href=""https://github.com/tkashem""><code>@​tkashem</code></a>)</li>; <li>JSON log output is configurable and now supports writing info messages to stdout and error messages to stderr. Info messages can be buffered in memory. The default is to write both to stdout without buffering, as before. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/104873"">kubernetes/kubernetes#104873</a>, <a href=""https://github.com/pohly""><code>@​pohly</code></a>)</li>; <li>JobTrackingWithFinalizers graduates to beta. Feature is enabled by default. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/105687"">kubernetes/kubernetes#105687</a>, <a href=""https://github.com/alculquicondor""><code>@​alculquicondor</code></a>)</li>; <li>Kube-apiserver: Fixes handling of CRD schemas containing literal null values in enums. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/104969"">kubernetes/kubernetes#104969</a>, <a href=""https://github.com/liggitt""><code>@​liggitt</code></a>)</li>; <li>Kube-apiserver: The <code>rbac.authorization.k8s.io/v1alp",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11957:6901,config,configurable,6901,https://hail.is,https://github.com/hail-is/hail/pull/11957,1,['config'],['configurable']
Modifiability," <li><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/10190"">#10190</a>: Invalid XML characters in setup or teardown error messages are now properly escaped for JUnit XML reports.</li>; <li><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/10230"">#10230</a>: Ignore <code>.py</code> files created by <code>pyproject.toml</code>-based editable builds introduced in <a href=""https://pip.pypa.io/en/stable/news/#v21-3"">pip 21.3</a>.</li>; <li><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/3396"">#3396</a>: Doctests now respect the <code>--import-mode</code> flag.</li>; <li><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9514"">#9514</a>: Type-annotate <code>FixtureRequest.param</code> as <code>Any</code> as a stop gap measure until <code>8073</code>{.interpreted-text role=&quot;issue&quot;} is fixed.</li>; <li><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9791"">#9791</a>: Fixed a path handling code in <code>rewrite.py</code> that seems to work fine, but was incorrect and fails in some systems.</li>; <li><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9917"">#9917</a>: Fixed string representation for <code>pytest.approx</code>{.interpreted-text role=&quot;func&quot;} when used to compare tuples.</li>; </ul>; <h2>Improved Documentation</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9937"">#9937</a>: Explicit note that <code>tmpdir</code>{.interpreted-text role=&quot;fixture&quot;} fixture is discouraged in favour of <code>tmp_path</code>{.interpreted-text role=&quot;fixture&quot;}.</li>; </ul>; <h2>Trivial/Internal Changes</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/10114"">#10114</a>: Replace <a href=""https://github.com/untitaker/python-atomicwrites"">atomicwrites</a> dependency on windows with [os.replace]{.title-ref}.</li>; </ul>; <h2>7.1.2</h2>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12187:1664,rewrite,rewrite,1664,https://hail.is,https://github.com/hail-is/hail/pull/12187,1,['rewrite'],['rewrite']
Modifiability," <li><a href=""https://github.com/tqdm/tqdm/commit/05e3d32a5fc8559e133e6d627d44afda93018637""><code>05e3d32</code></a> fix jupyterlab display</li>; <li><a href=""https://github.com/tqdm/tqdm/commit/4f208e72552c4d916aa4fe6a955349ee8b2ed353""><code>4f208e7</code></a> bump version, merge branch 'slack'</li>; <li><a href=""https://github.com/tqdm/tqdm/commit/1d29dec4b07de3dab34d3557baa9520cd9d46e38""><code>1d29dec</code></a> add <code>[slack]</code> extra dependency</li>; <li><a href=""https://github.com/tqdm/tqdm/commit/4a1d10e19fdca00db47fd50725715dc5e4aa68e6""><code>4a1d10e</code></a> consistent ordering</li>; <li><a href=""https://github.com/tqdm/tqdm/commit/bf6c960f60f8a390b47ac55d2ece3ffc419e5dcd""><code>bf6c960</code></a> emoji bars</li>; <li><a href=""https://github.com/tqdm/tqdm/commit/7994aa8285743b351cf1a3b36275335d8d0730b7""><code>7994aa8</code></a> warn once on error</li>; <li><a href=""https://github.com/tqdm/tqdm/commit/a1d4401f186dc5a79b4ad452f38cae75e1f2e6da""><code>a1d4401</code></a> remove unneeded variable</li>; <li>Additional commits viewable in <a href=""https://github.com/tqdm/tqdm/compare/v4.42.1...v4.64.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=tqdm&package-manager=pip&previous-version=4.42.1&new-version=4.64.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12260:5568,variab,variable,5568,https://hail.is,https://github.com/hail-is/hail/pull/12260,1,['variab'],['variable']
Modifiability," <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/tqdm/tqdm/releases"">tqdm's releases</a>.</em></p>; <blockquote>; <h2>tqdm v4.63.0 stable</h2>; <ul>; <li>add <code>__reversed__()</code></li>; <li>add efficient <code>__contains__()</code></li>; <li>improve CLI startup time (replace <code>pkg_resources</code> =&gt; <code>importlib</code>)</li>; <li><code>tqdm.autonotebook</code> warning &amp; <code>std</code> fallback on missing <code>ipywidgets</code> (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1218"">#1218</a> &lt;- <a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1082"">#1082</a>, <a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1217"">#1217</a>)</li>; <li>warn on positional CLI arguments</li>; <li>misc build/test framework updates; <ul>; <li>enable <code>py3.10</code> tests</li>; <li>add <code>conda</code> dependencies</li>; <li>update pre-commit hooks</li>; <li>fix <code>pytest</code> config (<code>nbval</code>, <code>asyncio</code>)</li>; <li>fix dependencies &amp; tests</li>; <li>fix site deployment</li>; </ul>; </li>; </ul>; <h2>tqdm v4.62.3 stable</h2>; <ul>; <li>fix minor typo (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1246"">#1246</a>)</li>; <li>minor example fix (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1246"">#1246</a>)</li>; <li>misc tidying &amp; refactoring</li>; <li>misc build/dev framework updates; <ul>; <li>update dependencies</li>; <li>update linters</li>; <li>update docs deployment branches</li>; </ul>; </li>; <li>misc test/ci updates; <ul>; <li>test forks</li>; <li>tidy OS &amp; Python version tests</li>; <li>bump primary python version 3.7 =&gt; 3.8</li>; <li>beta py3.10 testing</li>; <li>fix py2.7 tests</li>; <li>better timeout handling</li>; </ul>; </li>; </ul>; <h2>tqdm v4.62.2 stable</h2>; <ul>; <li>fix notebook memory leak (<a href=""https://github-redirect.dependabot.com/tqdm/tqdm/issues/1216"">#1216</a>)</li>; <l",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11587:1063,config,config,1063,https://hail.is,https://github.com/hail-is/hail/pull/11587,1,['config'],['config']
Modifiability," File ""/opt/conda/envs/hail/lib/python3.6/site-packages/notebook/notebook/handlers.py"", line 59, in get; get_custom_frontend_exporters=get_custom_frontend_exporters; File ""/opt/conda/envs/hail/lib/python3.6/site-packages/notebook/base/handlers.py"", line 519, in render_template; return template.render(**ns); File ""/opt/conda/envs/hail/lib/python3.6/site-packages/jinja2/asyncsupport.py"", line 76, in render; return original_render(self, *args, **kwargs); File ""/opt/conda/envs/hail/lib/python3.6/site-packages/jinja2/environment.py"", line 1008, in render; return self.environment.handle_exception(exc_info, True); File ""/opt/conda/envs/hail/lib/python3.6/site-packages/jinja2/environment.py"", line 780, in handle_exception; reraise(exc_type, exc_value, tb); File ""/opt/conda/envs/hail/lib/python3.6/site-packages/jinja2/_compat.py"", line 37, in reraise; raise value.with_traceback(tb); File ""/opt/conda/envs/hail/lib/python3.6/site-packages/notebook/templates/notebook.html"", line 1, in top-level template code; {% extends ""page.html"" %}; File ""/opt/conda/envs/hail/lib/python3.6/site-packages/notebook/templates/page.html"", line 154, in top-level template code; {% block header %}; File ""/opt/conda/envs/hail/lib/python3.6/site-packages/notebook/templates/notebook.html"", line 120, in block ""header""; {% for exporter in get_custom_frontend_exporters() %}; File ""/opt/conda/envs/hail/lib/python3.6/site-packages/notebook/notebook/handlers.py"", line 19, in get_custom_frontend_exporters; from nbconvert.exporters.base import get_export_names, get_exporter; File ""/opt/conda/envs/hail/lib/python3.6/site-packages/nbconvert/__init__.py"", line 7, in <module>; from . import postprocessors; File ""/opt/conda/envs/hail/lib/python3.6/site-packages/nbconvert/postprocessors/__init__.py"", line 5, in <module>; from .serve import ServePostProcessor; File ""/opt/conda/envs/hail/lib/python3.6/site-packages/nbconvert/postprocessors/serve.py"", line 19, in <module>; class ProxyHandler(web.RequestHandler):; File ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5591:1840,extend,extends,1840,https://hail.is,https://github.com/hail-is/hail/issues/5591,1,['extend'],['extends']
Modifiability, FileNotFoundException: File not found: gs://danking/chr*.vcf. Java stack trace:; java.io.FileNotFoundException: File not found: gs://danking/chr*.vcf; 	at com.google.cloud.hadoop.fs.gcs.GoogleHadoopFileSystemBase.getFileStatus(GoogleHadoopFileSystemBase.java:984); 	at is.hail.io.fs.HadoopFS.fileListEntry(HadoopFS.scala:175); 	at is.hail.io.fs.HadoopFS.fileListEntry(HadoopFS.scala:87); 	at is.hail.io.fs.FS.fileListEntry(FS.scala:417); 	at is.hail.io.fs.FS.fileListEntry$(FS.scala:417); 	at is.hail.io.fs.HadoopFS.fileListEntry(HadoopFS.scala:87); 	at is.hail.expr.ir.analyses.SemanticHash$.getFileHash(SemanticHash.scala:373); 	at is.hail.expr.ir.analyses.SemanticHash$.$anonfun$encode$18(SemanticHash.scala:198); 	at scala.collection.immutable.List.foreach(List.scala:431); 	at is.hail.expr.ir.analyses.SemanticHash$.encode(SemanticHash.scala:198); 	at is.hail.expr.ir.analyses.SemanticHash$.$anonfun$apply$6(SemanticHash.scala:42); 	at is.hail.expr.ir.analyses.SemanticHash$.$anonfun$apply$6$adapted(SemanticHash.scala:41); 	at scala.collection.Iterator.foreach(Iterator.scala:943); 	at scala.collection.Iterator.foreach$(Iterator.scala:943); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431); 	at is.hail.expr.ir.analyses.SemanticHash$.go$1(SemanticHash.scala:41); 	at is.hail.expr.ir.analyses.SemanticHash$.$anonfun$apply$4(SemanticHash.scala:54); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.analyses.SemanticHash$.$anonfun$apply$1(SemanticHash.scala:34); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.analyses.SemanticHash$.apply(SemanticHash.scala:26); 	at is.hail.backend.spark.SparkBackend._execute(SparkBackend.scala:509); 	at is.hail.backend.spark.SparkBackend.$anonfun$execute$4(SparkBackend.scala:546); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.backend.spark.SparkBackend.$anonfun$execute$3(SparkBackend.scala:542); 	at is.hail.backend.spark.SparkBackend.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13915:5183,adapt,adapted,5183,https://hail.is,https://github.com/hail-is/hail/issues/13915,1,['adapt'],['adapted']
Modifiability," Hail (inside the terra container) is parsing information from the lines. I was not capable of running older versions of the Terra container (1.0.x) because the versions of Hail implemented there are not compatible with the current version of Spark on Terra. . I hope you may have a solution to this irritating problem. I have added the scripts and logs below. . Thanks in advance,; Sean Jurgens. ### Version. 0.2.126-ee77707f4fab. ### Relevant log output. ```shell; ## PLEASE NOTE: to protect privacy as much as possible, I have removed almost all entries shown by the code, and for the few line entries that remain I have changed/randomized the numeric values. The order and structure is preserved for enrtries nonetheless. `#import libraries; import os; import hail as hl; from pprint import pprint. #### Start hail; hl.init(); hl.spark_context()`. /opt/conda/lib/python3.10/site-packages/hailtop/aiocloud/aiogoogle/user_config.py:44: UserWarning:. Reading spark-defaults.conf to determine GCS requester pays configuration. This is deprecated. Please use `hailctl config set gcs_requester_pays/project` and `hailctl config set gcs_requester_pays/buckets`. SLF4J: No SLF4J providers were found.; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See https://www.slf4j.org/codes.html#noProviders for further details.; SLF4J: Class path contains SLF4J bindings targeting slf4j-api versions 1.7.x or earlier.; SLF4J: Ignoring binding found at [jar:file:/usr/lib/spark/jars/log4j-slf4j-impl-2.18.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: See https://www.slf4j.org/codes.html#ignoredBindings for an explanation.; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Running on Apache Spark version 3.3.0; SparkUI available at http://saturn-3f2d119c-05e5-496d-97b9-8f40efff98a3-m.c.terra-db12d060.internal:36235/; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ ver",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14102:1861,config,configuration,1861,https://hail.is,https://github.com/hail-is/hail/issues/14102,1,['config'],['configuration']
Modifiability," KiB/ 11.5 KiB] ; Operation completed over 1 objects/11.5 KiB. ; (base) dking@wm28c-761 hail % gsutil cp ./src/test/resources/ldprune2.vcf gs://danking/chr2.vcf; Copying file://./src/test/resources/ldprune2.vcf [Content-Type=text/x-vcard]...; / [1 files][ 11.5 KiB/ 11.5 KiB] ; Operation completed over 1 objects/11.5 KiB. ; (base) dking@wm28c-761 hail % ipython ; Python 3.10.9 (main, Jan 11 2023, 09:18:18) [Clang 14.0.6 ]; Type 'copyright', 'credits' or 'license' for more information; IPython 8.16.1 -- An enhanced Interactive Python. Type '?' for help. In [1]: import hail as hl; ...: hl.import_vcf('gs://danking/chr*.vcf').count(); Initializing Hail with default parameters...; /Users/dking/miniconda3/lib/python3.10/site-packages/hailtop/aiocloud/aiogoogle/user_config.py:29: UserWarning: You have specified the GCS requester pays configuration in both your spark-defaults.conf (/Users/dking/miniconda3/lib/python3.10/site-packages/pyspark/conf/spark-defaults.conf) and either an explicit argument or through `hailctl config`. For GCS requester pays configuration, Hail first checks explicit arguments, then `hailctl config`, then spark-defaults.conf.; warnings.warn(; SLF4J: No SLF4J providers were found.; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See https://www.slf4j.org/codes.html#noProviders for further details.; SLF4J: Class path contains SLF4J bindings targeting slf4j-api versions 1.7.x or earlier.; SLF4J: Ignoring binding found at [jar:file:/Users/dking/miniconda3/lib/python3.10/site-packages/pyspark/jars/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: See https://www.slf4j.org/codes.html#ignoredBindings for an explanation.; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Running on Apache Spark version 3.3.3; SparkUI available at http://192.168.1.142:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13915:1484,config,config,1484,https://hail.is,https://github.com/hail-is/hail/issues/13915,1,['config'],['config']
Modifiability," NotebookApp] Writing notebook server cookie secret to /root/.local/share/jupyter/runtime/notebook_cookie_secret; Mar 01 19:59:04 dk-m python[5149]: [W 19:59:04.796 NotebookApp] All authentication is disabled. Anyone who can connect to this server will be able to run code.; Mar 01 19:59:04 dk-m python[5149]: [D 19:59:04.802 NotebookApp] Paths used for configuration of jupyter_notebook_config:; Mar 01 19:59:04 dk-m python[5149]: /etc/jupyter/jupyter_notebook_config.json; Mar 01 19:59:04 dk-m python[5149]: [D 19:59:04.803 NotebookApp] Paths used for configuration of jupyter_notebook_config:; Mar 01 19:59:04 dk-m python[5149]: /usr/local/etc/jupyter/jupyter_notebook_config.json; Mar 01 19:59:04 dk-m python[5149]: [D 19:59:04.804 NotebookApp] Paths used for configuration of jupyter_notebook_config:; Mar 01 19:59:04 dk-m python[5149]: /opt/conda/etc/jupyter/jupyter_notebook_config.json; Mar 01 19:59:04 dk-m python[5149]: [D 19:59:04.804 NotebookApp] Paths used for configuration of jupyter_notebook_config:; Mar 01 19:59:04 dk-m python[5149]: /root/.jupyter/jupyter_notebook_config.json; Mar 01 19:59:04 dk-m python[5149]: [W 19:59:04.904 NotebookApp] Error loading server extension jupyter_spark; Mar 01 19:59:04 dk-m python[5149]: Traceback (most recent call last):; Mar 01 19:59:04 dk-m python[5149]: File ""/opt/conda/lib/python3.6/site-packages/notebook/notebookapp.py"", line 1575, in init_server_extensions; Mar 01 19:59:04 dk-m python[5149]: func(self); Mar 01 19:59:04 dk-m python[5149]: File ""/opt/conda/lib/python3.6/site-packages/jupyter_spark/__init__.py"", line 30, in load_jupyter_server_extension; Mar 01 19:59:04 dk-m python[5149]: from .handlers import SparkHandler; Mar 01 19:59:04 dk-m python[5149]: File ""/opt/conda/lib/python3.6/site-packages/jupyter_spark/handlers.py"", line 8, in <module>; Mar 01 19:59:04 dk-m python[5149]: class SparkHandler(IPythonHandler):; Mar 01 19:59:04 dk-m python[5149]: File ""/opt/conda/lib/python3.6/site-packages/jupyter_spark/handlers.py"", l",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5505:1595,config,configuration,1595,https://hail.is,https://github.com/hail-is/hail/issues/5505,1,['config'],['configuration']
Modifiability," When we declare a Service for say, batch in default, Kubernetes adds a DNS record for `batch.default` that resolves to a single IP pointing at kube-proxy. When a new TCP connection is established with kube-proxy for that IP, it rolls the dice (using `iptables`) and assigns that connection to a particular pod to which it will forward all subsequent packets. From the load-balancer's perspective, there is only one IP address, and only one place to open connections. The load-balancer doesn't have the information to actually load-balance once we have a functioning connection pool. This can lead to really unbalanced scenarios when preemptible pods come and go. This leads to our second goal: instead of routing all requests through kube-proxy, use Kubernetes Headless Services to expose all pod IPs underlying a Service so that our proxies can properly load-balance across persistent connections. ## Solution. This PR addresses the two goals outlined above and does so through using Envoy, a load-balancer/proxy that is well-suited to this sort of highly-dynamic cluster configuration. Envoy does not have the constraint that all upstream services must be available at start-time, and has a very convenient API for updating the cluster configuration without the need for restarting the process or dropping traffic. This makes regularly updating the cluster configuration whenever new test namespaces are created relatively straightforward and non-disruptive to traffic in other namespaces. The high-level approach is as follows:. 1. Envoy-based gateways and internal-gateways will load their routing configuration from a Kubernetes ConfigMap, which they watch for changes and reconcile their configuration when the ConfigMap changes. The ConfigMap can be populated with a manual deploy and is populated from the beginning with production routes (i.e. batch.hail.is gets routed to batch.default); 2. When running CI, CI will regularly update the ConfigMap with additional routes based on which inte",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12095:3704,config,configuration,3704,https://hail.is,https://github.com/hail-is/hail/pull/12095,1,['config'],['configuration']
Modifiability," [<code>botocore</code>] This release includes a new feature for customers to calculate the position of their devices by adding three new APIs: UpdateResourcePosition, GetResourcePosition, and GetPositionEstimate.</li>; <li>api-change:<code>kendra</code>: [<code>botocore</code>] Amazon Kendra now supports preview of table information from HTML tables in the search results. The most relevant cells with their corresponding rows, columns are displayed as a preview in the search result. The most relevant table cell or cells are also highlighted in table preview.</li>; <li>api-change:<code>logs</code>: [<code>botocore</code>] Updates to support CloudWatch Logs data protection and CloudWatch cross-account observability</li>; <li>api-change:<code>mgn</code>: [<code>botocore</code>] This release adds support for Application and Wave management. We also now support custom post-launch actions.</li>; <li>api-change:<code>oam</code>: [<code>botocore</code>] Amazon CloudWatch Observability Access Manager is a new service that allows configuration of the CloudWatch cross-account observability feature.</li>; <li>api-change:<code>organizations</code>: [<code>botocore</code>] This release introduces delegated administrator for AWS Organizations, a new feature to help you delegate the management of your Organizations policies, enabling you to govern your AWS organization in a decentralized way. You can now allow member accounts to manage Organizations policies.</li>; <li>api-change:<code>rds</code>: [<code>botocore</code>] This release enables new Aurora and RDS feature called Blue/Green Deployments that makes updates to databases safer, simpler and faster.</li>; <li>api-change:<code>textract</code>: [<code>botocore</code>] This release adds support for classifying and splitting lending documents by type, and extracting information by using the Analyze Lending APIs. This release also includes support for summarized information of the processed lending document package, in addition to",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12507:2895,config,configuration,2895,https://hail.is,https://github.com/hail-is/hail/pull/12507,1,['config'],['configuration']
Modifiability," a long or tuple of longs which is guaranteed to be distinct on every execution of `child`.; * Uids are typically created at the leaves of pipelines (`TableRead`, `StreamRange`, etc.), and propagated upwards. There was a phase-ordering conflict that had to be worked around:; * IRs must be given explict rng state and uid semantics as early as possible, to ensure determinism.; * The transformation to explicitly pass rng states and uids must happen during IR construction. If it happened later, it would create new IR objects, which would defeat the python CSE pass (which only recognizes equivalent subexpressions when they are represented by the same python object).; * The rng explication requires some type information.; * Types on the python IR are assigned after the IR is fully constructed. To fix this:; * `Ref`'s must be given a type at construction; * `TopLevelReference`s are the only case that needs to be constructed before a type is known. But they are always constructed wrapped in a `SelectFields` or `GetField`, whose type is known at construction. I added new IR classes `SelectedTopLevelReference` and `ProjectedTopLevelReference` for these two cases, which are thin wrappers which don't appear in the rendered IR.; * `construct_expr` always assigns a type to the ir. Bottom-up type construction will later assert equality with the assigned type. This caught some existing bugs, where expression type and ir type didn't agree.; * At construction of the root node of a stream/table/matrixtable pipeline (i.e. a non-stream value ir with at least one stream/table/matrixtable child), recursively rewrite the contained pipeline(s) to make rng states and uids explicit. This is safe, since stream/table/matrixtable IRs won't be CSE'd, because they may only be evaluated once. Contained value IRs are not rewritten, only wrapped with bindings which define the rng state. These are currently non-functional changes, as `ApplySeeded` still uses the old rng, and will ignore the rng state.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11847:2080,rewrite,rewrite,2080,https://hail.is,https://github.com/hail-is/hail/pull/11847,1,['rewrite'],['rewrite']
Modifiability," and providing my AWS credentials in the spark config. So these changes should (hopefully) work fine on an EMR cluster with the s3:// client. Everything worked as expected on GCP. Overview of changes:; - Added missing type hints to `load_dataset()` function and methods in `db.py`.; - In `datasets.json`:; - Added AWS urls so now for each version of a dataset in dataset[""versions""], the url entry looks like:; ```; ""url"": {; ""aws"": {; ""us"": ""s3://hail-datasets-us-east-1/...""; },; ""gcp"": {; ""eu"": ""gs://hail-datasets-eu/..."",; ""us"": ""gs://hail-datasets-us/...; }; ```; - In `load_dataset()` function:; - Added `cloud` parameter, set default values to `region='us'` and `cloud='gcp`.; - In `DB` class:; - Added `cloud` parameter to constructor, set default values to `region='us'` and `cloud='gcp`.; - All datasets in `datasets.json` currently end up in the `_DB__by_name` dictionary, even if not annotation datasets. Added line 279 in `db.py` to fix this and filter out datasets that are not annotation datasets (datasets missing ""annotation_db"" key).; - In `Dataset` class:; - Added `cloud` and `custom_config` parameters to `Dataset.from_name_and_json()` to pass to `DatasetVersion.from_json()` to grab correct urls for platform.; - Refactored `Dataset.from_name_and_json()`. Will require users passing a custom config to be of same format as what is in `datasets.json` for now. So each key: value pair in a user provided config should be as below:; ```; ""dataset_name"": {; ""annotation_db"": {""key_properties"": [""...""]},; ""description"": ""..."",; ""url"": ""..."",; ""versions"": [; {; ""reference_genome"": ""..."",; ""url"": {""aws"": {""eu"": ""..."", ""us"": ""...""},; ""gcp"": {""eu"": ""..."", ""us"": ""...""}},; ""version"": ""...""; }]}; ```; - In `DatasetVersion` class:; - Added `reference_genome` attribute, now that the version and reference genome are two separate fields in `datasets.json`.; - Modified `DatasetVersion.from_json()` to handle cloud parameter to grab correct version url when using checked-in config file.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9605:1996,Refactor,Refactored,1996,https://hail.is,https://github.com/hail-is/hail/pull/9605,4,"['Refactor', 'config']","['Refactored', 'config']"
Modifiability," and revert the unnecessary; <code>pylint.version</code> breaking change.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/4399"">#4399</a></p>; </li>; </ul>; <h2>pylint-2.8.0</h2>; <ul>; <li>; <p>New refactoring message <code>consider-using-with</code>. This message is emitted if resource-allocating functions or methods of the; standard library (like <code>open()</code> or <code>threading.Lock.acquire()</code>) that can be used as a context manager are called without; a <code>with</code> block.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/3413"">#3413</a></p>; </li>; <li>; <p>Resolve false positives on unused variables in decorator functions</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/4252"">#4252</a></p>; </li>; <li>; <p>Add new extension <code>ConfusingConsecutiveElifChecker</code>. This optional checker emits a refactoring message (R5601 <code>confusing-consecutive-elif</code>); if if/elif statements with different indentation levels follow directly one after the other.</p>; </li>; <li>; <p>New option <code>--output=&lt;file&gt;</code> to output result to a file rather than printing to stdout.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/1070"">#1070</a></p>; </li>; <li>; <p>Use a prescriptive message for <code>unidiomatic-typecheck</code></p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/3891"">#3891</a></p>; </li>; <li>; <p>Apply <code>const-naming-style</code> to module constants annotated with; <code>typing.Final</code></p>; </li>; <li>; <p>The packaging is now done via setuptools exclusively. <code>doc</code>, <code>tests</code>, <code>man</code>, <code>elisp</code> and <code>Changelog</code> are; not packaged anymore - reducing the size of the package by 75%.</p>; </li>; <li>; <p>Debian packaging is now (officially) done in <a href=""https://salsa.debian.org/python-team/packages/pyli",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11461:1292,refactor,refactoring,1292,https://hail.is,https://github.com/hail-is/hail/pull/11461,2,['refactor'],['refactoring']
Modifiability, at is.hail.expr.ir.GenericTableValue.getLTVCoercer(GenericTableValue.scala:137); at is.hail.expr.ir.GenericTableValue.toTableStage(GenericTableValue.scala:162); at is.hail.io.vcf.MatrixVCFReader.lower(LoadVCF.scala:1798); at is.hail.expr.ir.lowering.LowerTableIR$.applyTable(LowerTableIR.scala:717); at is.hail.expr.ir.lowering.LowerTableIR$.lower$2(LowerTableIR.scala:697); at is.hail.expr.ir.lowering.LowerTableIR$.applyTable(LowerTableIR.scala:903); at is.hail.expr.ir.lowering.LowerTableIR$.lower$1(LowerTableIR.scala:467); at is.hail.expr.ir.lowering.LowerTableIR$.apply(LowerTableIR.scala:472); at is.hail.expr.ir.lowering.LowerToCDA$.lower(LowerToCDA.scala:73); at is.hail.expr.ir.lowering.LowerToCDA$.apply(LowerToCDA.scala:18); at is.hail.expr.ir.lowering.LowerToDistributedArrayPass.transform(LoweringPass.scala:77); at is.hail.expr.ir.LowerOrInterpretNonCompilable$.evaluate$1(LowerOrInterpretNonCompilable.scala:27); at is.hail.expr.ir.LowerOrInterpretNonCompilable$.rewrite$1(LowerOrInterpretNonCompilable.scala:67); at is.hail.expr.ir.LowerOrInterpretNonCompilable$.rewrite$1(LowerOrInterpretNonCompilable.scala:53); at is.hail.expr.ir.LowerOrInterpretNonCompilable$.apply(LowerOrInterpretNonCompilable.scala:72); at is.hail.expr.ir.lowering.LowerOrInterpretNonCompilablePass$.transform(LoweringPass.scala:69); at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:16); at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:16); at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:14); at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:13); at is.hail.expr.ir.lowering.LowerOrInterpretNonCompilablePass$.apply(LoweringPass.scala:64); at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:15); at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$appl,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12280:3183,rewrite,rewrite,3183,https://hail.is,https://github.com/hail-is/hail/issues/12280,1,['rewrite'],['rewrite']
Modifiability," available. <code>+k8s:conversion-gen</code> tags can be used with the <code>k8s.io/code-generator</code> component to generate conversions. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/90018"">kubernetes/kubernetes#90018</a>, <a href=""https://github.com/wojtek-t""><code>@​wojtek-t</code></a>) [SIG API Machinery, Apps and Testing]</li>; <li>Kube-proxy: add <code>--bind-address-hard-fail</code> flag to treat failure to bind to a port as fatal (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/89350"">kubernetes/kubernetes#89350</a>, <a href=""https://github.com/SataQiu""><code>@​SataQiu</code></a>) [SIG Cluster Lifecycle and Network]</li>; <li>Kubebuilder validation tags are set on metav1.Condition for CRD generation (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/92660"">kubernetes/kubernetes#92660</a>, <a href=""https://github.com/damemi""><code>@​damemi</code></a>) [SIG API Machinery]</li>; <li>Kubelet's --runonce option is now also available in Kubelet's config file as <code>runOnce</code>. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/89128"">kubernetes/kubernetes#89128</a>, <a href=""https://github.com/vincent178""><code>@​vincent178</code></a>) [SIG Node]</li>; <li>Kubelet: add '--logging-format' flag to support structured logging (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/91532"">kubernetes/kubernetes#91532</a>, <a href=""https://github.com/afrouzMashaykhi""><code>@​afrouzMashaykhi</code></a>) [SIG API Machinery, Cluster Lifecycle, Instrumentation and Node]</li>; <li>Kubernetes is now built with golang 1.15.0-rc.1.; <ul>; <li>The deprecated, legacy behavior of treating the CommonName field on X.509 serving certificates as a host name when no Subject Alternative Names are present is now disabled by default. It can be temporarily re-enabled by adding the value x509ignoreCN=0 to the GODEBUG environment variable. (<a href=""https://gi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11462:9843,config,config,9843,https://hail.is,https://github.com/hail-is/hail/pull/11462,1,['config'],['config']
Modifiability," can be run from the command line like any pytest.; This change removes the `benchmark-hail` (or `hailbench`) utility. Benchmarks are marked by `pytest.mark.benchmark` (via the `@benchmark` decorator).; By convention, benchmarks are python tests whose names are prefixed by `benchmark_` and are located in files with the same prefix.; Nothing enforces this, however, so you could name your benchmarks `test_*` and put them in files named `test_*.py`.; Benchmarks may import and use any test code or utilities defined in `test/`.; The results of each benchmark are outputted as json lines (`.jsonl`) to the file specified by the `--output` pytest arg or stdout. The folder structure should be familiar, resembling our `test/` directory.; I believe this is flexible enough to add `hailtop` benchmarks should we so wish:; ```; pytest.ini - hoisted from `test/` to include benchmark marks; benchmark/; - conftest.py for custom pytest command line args ; - hail/; - confest.py for custom plugin that runs hail benchmarks; - benchmark_*.py hail query benchmark code; - tools/; - shared utilites, including the `@benchmark`; ```; Supporting pytest fixtures required writing a custom plugin to run benchmarks, as using off-the-shelf; solutions like `pytest-benchmark` would forbid method level fixtures like `tmp_path` etc.; The plugin is designed to run ""macro-benchmarks"" (ie long-running tests) and fully supports pytest parameterisation.; For each benchmark, the plugin initialises hail and then repeats (for a number of iterations defined by the pytest mark); acquiring fixtures, timing invocation and tearing-down fixtures, finally stopping hail. It is therefore unsuitable for; microbenchmarks, for which we currenly have none in python. If we add them we'd need to tweak this so support them.; Perhaps an inner loop or something. The process of submitting benchmarks to batch is greatly simplified as the old `Makefile` infrastructure for ; building wheels and docker images etc has been replaced wit",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14565:1207,plugin,plugin,1207,https://hail.is,https://github.com/hail-is/hail/pull/14565,1,['plugin'],['plugin']
Modifiability," can be set via <code>Retry.remove_headers_on_redirect</code>. (<code>[#3139](https://github.com/urllib3/urllib3/issues/3139) &lt;https://github.com/urllib3/urllib3/pull/3139&gt;</code>_)</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/urllib3/urllib3/commit/c9016bf464751a02b7e46f8b86504f47d4238784""><code>c9016bf</code></a> Release 1.26.17</li>; <li><a href=""https://github.com/urllib3/urllib3/commit/01220354d389cd05474713f8c982d05c9b17aafb""><code>0122035</code></a> Backport GHSA-v845-jxx5-vc9f (<a href=""https://redirect.github.com/urllib3/urllib3/issues/3139"">#3139</a>)</li>; <li><a href=""https://github.com/urllib3/urllib3/commit/e63989f97d206e839ab9170c8a76e3e097cc60e8""><code>e63989f</code></a> Fix installing <code>brotli</code> extra on Python 2.7</li>; <li><a href=""https://github.com/urllib3/urllib3/commit/2e7a24d08713a0131f0b3c7197889466d645cc49""><code>2e7a24d</code></a> [1.26] Configure OS for RTD to fix building docs</li>; <li><a href=""https://github.com/urllib3/urllib3/commit/57181d6ea910ac7cb2ff83345d9e5e0eb816a0d0""><code>57181d6</code></a> [1.26] Improve error message when calling urllib3.request() (<a href=""https://redirect.github.com/urllib3/urllib3/issues/3058"">#3058</a>)</li>; <li><a href=""https://github.com/urllib3/urllib3/commit/3c0148048a523325819377b23fc67f8d46afc3aa""><code>3c01480</code></a> [1.26] Run coverage even with failed jobs</li>; <li>See full diff in <a href=""https://github.com/urllib3/urllib3/compare/1.26.16...1.26.17"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=urllib3&package-manager=pip&previous-version=1.26.16&new-version=1.26.17)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yours",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13762:1878,Config,Configure,1878,https://hail.is,https://github.com/hail-is/hail/pull/13762,5,['Config'],['Configure']
Modifiability," constructor `optional<T>`, i.e. base types don't encode missingness. Emits a single bit in the encoding. Can invert this bit to control whether missing values come first or last in the ordering. If missing, nothing is emitted after.; - sort-order; - treat reversing the default ordering as a type constructor `reverse<T>`; - simply inverts the encoding bitwise; - primitive types; - same as in datafusion, encoding has same size as original type; - signed integers - flip the sign bit; - floating point numbers - if sign bit is set, invert all bits, otherwise only flip the sign bit; - arrays; - before each element and after last element, emit continuation bit (0 if no more elements); - pad before each element. This prevents a variable number of missing bits packing into a byte; - strings and byte-arrays; - simply use null-terminated strings (being careful to do this in a unicode-safe way); - structs; - simply concatenate element encodings. safe because codes are prefix-free; - key structs; - support variable length ""interval endpoints""; - e.g. for a key type `struct<t1, t2>`, the interval `[{a}, {a, b})` contains all keys with first field `a` and second field less than `b`. We break it into two ""interval endpoints"", `({a}, -1)` and `({a, b}, -1)`, which consist of a struct value which is a prefix of the key struct type, and a ""sign"". In this case, both endpoints ""lean left"".; - needed for working with partitioners at runtime; - like an array with fixed but heterogenous types and a max length; - before each element and after last element, emit two continuation bits; - `00` - end of key, leans left (less than all longer keys with this prefix); - `01` - continue, or after last key field of actual key value (not interval endpoint); - unambiguous because key value can't terminate early, and can't continue past last key field (max length); - `11` - end of key, leans right (greater than all longer keys with this prefix); - after each element, pad. # Implementation sketch; Concr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14396:2315,variab,variable,2315,https://hail.is,https://github.com/hail-is/hail/issues/14396,1,['variab'],['variable']
Modifiability," creating a managed identity to run terraform through (instead of the current service principal), to creating a VM to run the bootstrap process off of, through all following steps until running bootstrap.py; - Adds the root CA certificate that azure uses to sign the MySQL server certificates so that we can connect to the database with `VERIFY_CA`. Unlike gcp, however, this still doesn't allow us to use mTLS since it doesn't look like we can request a client cert/key for our database. Still this is not so bad for now.; - Creates a separate k8s module for terraform. This currently just holds the global-config and sql-config resources, but establishes a boundary between the cloud-specific terraform and purely k8s terraform. Later on I'll refactor the GCP terraform to use the k8s module so that different clouds can use the same k8s configuration.; - Adds a pool of spot instances to the AKS cluster and adds the required toleration to all of our preemptible deployments. Part of the node selection process for a pod requires that exist a toleration on the pod for every taint on the node. In other words, it is ok for a pod to have redundant tolerations, so it's fine to have azure-specific tolerations even if we're running in gcp.; - Refactor the az-create-worker-image.sh script to complete the entire batch worker image creation process from start to finish. This involved sending a command over ssh that previously had to be executed by hand. This meant we could combine the two-script process into one shell script. This fully matches the google setup we have currently up until running `bootstrap.py`, which is still google-specific, mainly w.r.t. gcp service accounts. The next step is to adapt this to azure, but I think we need to come to a decision about exactly how we're representing application credentials (just service principals vs managed identities?). Once we have that figured out the rest of the terraform/bootstrap process should follow pretty quickly. Stacked on #10911",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10919:1339,Refactor,Refactor,1339,https://hail.is,https://github.com/hail-is/hail/pull/10919,2,"['Refactor', 'adapt']","['Refactor', 'adapt']"
Modifiability," debugging of JVM crashing in production until the JVM logs are shown on a per-worker page. 2. JVMEntryway is now a real gradle project. I need to compile against log4j, and I didn't want to do that by hand with `javac`. Ignore gradlew, gradlew.bat, and gradle/wrapper, they're programmatically generated by gradle. 3. Add logging to JVMEntryway. JVMEntryway now logs its arguments into the QoB job log. I also log exceptions from the main thread or the cancel thread into the job log. We also flush the logs after the main thread completes, the cancel thread completes, and when the try-catch exits. This should ensure that regardless of what goes wrong (even if both threads fail to start) we at least see the arguments that the JVMEntryway received. 4. Use log4j2 programmatic reconfiguration after every job. This restores log4j2 to well enough working order that, *if you do not try to reconfigure it using log4j1 programmatic configuration*, logs will work. All old versions of Hail use log4j1 programmatic configuration. As a result, **all old versions of Hail will still have no logs**. However, new versions of Hail will log correctly even if an old version of Hail used the JVM before it. 5. `QoBAppender`. This is how we always should have done logging. A custom appender which we can flush and then redirect to a new file at our whim. I followed the log4j2 best practices for creating a new appender. All these annotations, factory methods, and managers are The Right Way, for better or worse. If we ever ban old versions of Hail from the cluster, then we can also eliminate the log4j2 reconfiguration. New versions of Hail work fine without any runtime log configuration (thanks to `QoBAppender`). I would like to eliminate reconfiguration because log4j2 reconfiguration leaves around oprhaned appenders and appender managers. Maybe I'm implementing the Appender or Appender Manager interfaces wrong, but I've read over that code a bunch of times and I cannot sort out what I am missing.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12941:2015,config,configuration,2015,https://hail.is,https://github.com/hail-is/hail/pull/12941,1,['config'],['configuration']
Modifiability," determine which concrete file system to use. For example, a; router fs can `open` both `gs://danking/abc` and `s3a://danking/abc`. Each Hail Query Python Backend is associated with one file system class. This PR associates the; ServiceBackend with `RouterFS`, enabling `hl.current_backend().fs.open`, `hl.hadoop_open`, etc. to; read from S3, GCS, ABS, and the local file system. We should deprecate `hail.utils.hadoop_utils`; because it is not Hadoop-specific. We should instead advertise the class-based `hail.fs` or create a; new function-based interface (e.g. `hl.fs.open(...)`. # Test Clean-up. The Hail Query local and spark tests should now work in Azure. I moved all the `hail.fs` and; `hailtop.aiotools.fs` tests into two build.yaml steps: `test_hail_python_fs` and; `test_hail_scala_fs`. These tests are exhaustive: they test every file system: S3, ABS, and GCS. The only file system tests that remain in the Hail Query tests are the tests of; `hail.utils.hadoop_utils`. The hadoop tests are not exhaustive: they only test the *current* file; system. In Azure, they test ABS. In Google, they test GCS. I have not decided yet if we should enable the hail python tests in Azure. It seems mostly wasteful. # Local Cache. I added a local cache directory. It defaults to `$XDG_CONFIG_HOME/hail/cache` or; `~/.config/hail/cache` if `XDG_CONFIG_HOME` is not set. I store Python reference genome metadata; here. # Batch Attributes. The ServiceBackend `batch_attributes` attribute specifies the attributes for any batch created by; the ServiceBackend. I modified the tests so that the test function name is use the ""name"" of the; batch. When a Hail Query driver job executes `parallelizeAndComputeWithIndex`, it uses its name with; a unique suffix as the name of the batch of worker jobs. # Changes to Hail Scala. I think the only changes outside of `is.hail.backend.service` and `is.hail.services` are:. 1. More retries in GoogleStorageFS. 2. Make MatrixSpecHelper and TableSpecHelper serializable.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11194:6329,config,config,6329,https://hail.is,https://github.com/hail-is/hail/pull/11194,1,['config'],['config']
Modifiability," directory provided; as parameter to pylint.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/352"">#352</a></p>; </li>; <li>; <p>Add <code>modified-iterating-list</code>, <code>modified-iterating-dict</code> and <code>modified-iterating-set</code>,; emitted when items are added to or removed from respectively a list, dictionary or; set being iterated through.</p>; </li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/PyCQA/pylint/commit/fd0eb6c2af0e3e98350e24047c4df7d5b8aad89a""><code>fd0eb6c</code></a> Bump pylint to 2.13.0, update changelog</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/1c509edc4ee2dbf1bbe8822e91e0b7df02ce463d""><code>1c509ed</code></a> [cleanup] Remove unused code in pylint.checker.base following refactor</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/1e7d3fa6219934028d2539ad290fe16ce8ea78e2""><code>1e7d3fa</code></a> [refactor] Create a file for the BasicChecker in pylint.checker.base</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/c0b8b32592f8d5d34ff37250adbda6b65269a0af""><code>c0b8b32</code></a> [refactor] Create a file for the BasicErrorChecker in pylint.checker.base</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/3f11fe629a7b89d2a3b92dce09ac5818f3904cee""><code>3f11fe6</code></a> [refactor] Create a package for the NameChecker in pylint.checker.base</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/6940715ba15f81fbd7d9e8685c0a714a8b612f24""><code>6940715</code></a> [refactor] Create a file for the DocstringChecker in pylint.checker.base</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/84d22cf24202bf6006fc179541e1853d145d33e0""><code>84d22cf</code></a> [refactor] Create a file for the PassChecker in pylint.checker.base</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/977b08d160e81aaecebf871d2b8ba2f9a96ef9d6""><code>977b08d</code></a> [re",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11674:3892,refactor,refactor,3892,https://hail.is,https://github.com/hail-is/hail/pull/11674,1,['refactor'],['refactor']
Modifiability," for the the other chromosomes with less variants but same samples, such as chr13, it worked well in Terra. Since we will convert multiple plink files to hailmatrix table using Terra platform in future, I need to figure the problem out. Any advise would be appreciated. ### Version. 0.2.127. ### Relevant log output. ```shell; 2024/01/17 20:20:25 Starting container setup.; 2024/01/17 20:20:26 Done container setup.; 2024/01/17 20:20:27 Starting localization.; 2024/01/17 20:20:34 Localization script execution started...; 2024/01/17 20:20:34 Localizing input gs://fc-5a8938eb-1299-4afc-957f-afb53ef602b9/submissions/e8747e74-47d1-4f52-acfc-1ac7f81d79ba/VUMCBed2HailMatrix/683447d9-9342-4058-bcfc-ba21422d3121/call-Bed2HailMatrix/script -> /cromwell_root/script; 2024/01/17 20:20:36 Localizing input gs://hui-sandbox/ICA-AGD/plink1/chr12.bed -> /cromwell_root/hui-sandbox/ICA-AGD/plink1/chr12.bed; 2024/01/17 20:59:18 Localizing input gs://hui-sandbox/ICA-AGD/plink1/chr12.fam -> /cromwell_root/hui-sandbox/ICA-AGD/plink1/chr12.fam; 2024/01/17 20:59:18 Localizing input gs://hui-sandbox/ICA-AGD/plink1/chr12.bim -> /cromwell_root/hui-sandbox/ICA-AGD/plink1/chr12.bim; Copying gs://hui-sandbox/ICA-AGD/plink1/chr12.fam...; / [0 files][ 0.0 B/910.3 KiB] / [1 files][910.3 KiB/910.3 KiB] Copying gs://hui-sandbox/ICA-AGD/plink1/chr12.bim...; / [1 files][910.3 KiB/369.7 MiB] - - [1 files][ 51.9 MiB/369.7 MiB] \ | | [1 files][107.6 MiB/369.7 MiB] / - - [1 files][162.3 MiB/369.7 MiB] \ \ [1 files][213.9 MiB/369.7 MiB] | / / [1 files][286.6 MiB/369.7 MiB] - \ \ [1 files][342.1 MiB/369.7 MiB] |; Operation completed over 2 objects/369.7 MiB.; | [2 files][369.7 MiB/369.7 MiB] 2024/01/17 20:59:27 Localization script execution complete.; 2024/01/17 20:59:38 Done localization.; 2024/01/17 20:59:39 Running user action: docker run -v /mnt/local-disk:/cromwell_root --entrypoint=/bin/bash hailgenetics/hail@sha256:3f22576793ce3161893aed2bd40949b1fc822d2b7e6517dc0ac993b62badaff8 /cromwell_root/script; Picke",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14168:9838,sandbox,sandbox,9838,https://hail.is,https://github.com/hail-is/hail/issues/14168,1,['sandbox'],['sandbox']
Modifiability," for; ```; GET http://localhost:8123/spark/api/v1/applications; ```; which happened repeatedly if you try to evaluate a cell. On the leader node of the spark cluster, `journalctl -u jupyter` shows:; ```; -- Logs begin at Fri 2019-03-01 19:54:49 UTC, end at Fri 2019-03-01 20:11:51 UTC. --; Mar 01 19:59:03 dk-m systemd[1]: Started Jupyter Notebook.; Mar 01 19:59:04 dk-m python[5149]: [I 19:59:04.630 NotebookApp] Writing notebook server cookie secret to /root/.local/share/jupyter/runtime/notebook_cookie_secret; Mar 01 19:59:04 dk-m python[5149]: [W 19:59:04.796 NotebookApp] All authentication is disabled. Anyone who can connect to this server will be able to run code.; Mar 01 19:59:04 dk-m python[5149]: [D 19:59:04.802 NotebookApp] Paths used for configuration of jupyter_notebook_config:; Mar 01 19:59:04 dk-m python[5149]: /etc/jupyter/jupyter_notebook_config.json; Mar 01 19:59:04 dk-m python[5149]: [D 19:59:04.803 NotebookApp] Paths used for configuration of jupyter_notebook_config:; Mar 01 19:59:04 dk-m python[5149]: /usr/local/etc/jupyter/jupyter_notebook_config.json; Mar 01 19:59:04 dk-m python[5149]: [D 19:59:04.804 NotebookApp] Paths used for configuration of jupyter_notebook_config:; Mar 01 19:59:04 dk-m python[5149]: /opt/conda/etc/jupyter/jupyter_notebook_config.json; Mar 01 19:59:04 dk-m python[5149]: [D 19:59:04.804 NotebookApp] Paths used for configuration of jupyter_notebook_config:; Mar 01 19:59:04 dk-m python[5149]: /root/.jupyter/jupyter_notebook_config.json; Mar 01 19:59:04 dk-m python[5149]: [W 19:59:04.904 NotebookApp] Error loading server extension jupyter_spark; Mar 01 19:59:04 dk-m python[5149]: Traceback (most recent call last):; Mar 01 19:59:04 dk-m python[5149]: File ""/opt/conda/lib/python3.6/site-packages/notebook/notebookapp.py"", line 1575, in init_server_extensions; Mar 01 19:59:04 dk-m python[5149]: func(self); Mar 01 19:59:04 dk-m python[5149]: File ""/opt/conda/lib/python3.6/site-packages/jupyter_spark/__init__.py"", line 30, in load_jupyter",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5505:1175,config,configuration,1175,https://hail.is,https://github.com/hail-is/hail/issues/5505,1,['config'],['configuration']
Modifiability," frame <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7521"">#7521</a> [<a href=""https://github.com/radarhere""><code>@​radarhere</code></a>]</li>; <li>Handle disposing GIF background from outside palette <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7515"">#7515</a> [<a href=""https://github.com/radarhere""><code>@​radarhere</code></a>]</li>; <li>Seek past the data when skipping a PSD layer <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7483"">#7483</a> [<a href=""https://github.com/radarhere""><code>@​radarhere</code></a>]</li>; <li>ImageMath: Inline <code>isinstance</code> check <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7623"">#7623</a> [<a href=""https://github.com/hugovk""><code>@​hugovk</code></a>]</li>; <li>Update actions/upload-artifact action to v4 <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7619"">#7619</a> [<a href=""https://github.com/radarhere""><code>@​radarhere</code></a>]</li>; <li>Import plugins relative to the module <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7576"">#7576</a> [<a href=""https://github.com/deliangyang""><code>@​deliangyang</code></a>]</li>; <li>Translate encoder error codes to strings; deprecate <code>ImageFile.raise_oserror()</code> <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7609"">#7609</a> [<a href=""https://github.com/bgilbert""><code>@​bgilbert</code></a>]</li>; <li>Updated readthedocs to latest version of Python <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7611"">#7611</a> [<a href=""https://github.com/radarhere""><code>@​radarhere</code></a>]</li>; <li>Support reading BC4U and DX10 BC1 images <a href=""https://redirect.github.com/python-pillow/Pillow/issues/6486"">#6486</a> [<a href=""https://github.com/REDxEYE""><code>@​REDxEYE</code></a>]</li>; <li>Optimize ImageStat.Stat.extrema <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7593"">#7593</a> [<a href=""https://github.com/flo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14191:6355,plugin,plugins,6355,https://hail.is,https://github.com/hail-is/hail/pull/14191,3,['plugin'],['plugins']
Modifiability," from <a href=""https://github.com/pytest-dev/pytest-metadata/blob/master/CHANGES.rst"">pytest-metadata's changelog</a>.</em></p>; <blockquote>; <h2>2.0.2 (2022-07-15)</h2>; <ul>; <li>Allow all python versions above 3.7</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pytest-dev/pytest-metadata/commit/6688a6f21c7bef1aaea5f8ac171be4a5df2eb527""><code>6688a6f</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-metadata/issues/50"">#50</a> from BeyondEvil/release-v2.0.2</li>; <li><a href=""https://github.com/pytest-dev/pytest-metadata/commit/f0b5503452f922a84faa213224a4970c57d8a654""><code>f0b5503</code></a> Release v2.0.2</li>; <li><a href=""https://github.com/pytest-dev/pytest-metadata/commit/ff493afce81b1bbe7a2f866cd27510e5d9b8feef""><code>ff493af</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-metadata/issues/47"">#47</a> from pytest-dev/pre-commit-ci-update-config</li>; <li><a href=""https://github.com/pytest-dev/pytest-metadata/commit/4591db1fa5546ff372ae95155caed99ce8dc4842""><code>4591db1</code></a> [pre-commit.ci] pre-commit autoupdate</li>; <li><a href=""https://github.com/pytest-dev/pytest-metadata/commit/0414bb9f81cc1856ea021504eecd22d202462f1d""><code>0414bb9</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-metadata/issues/46"">#46</a> from pytest-dev/pre-commit-ci-update-config</li>; <li><a href=""https://github.com/pytest-dev/pytest-metadata/commit/025be8999a22ae395b0e2b8ae4e7c9fa2334f874""><code>025be89</code></a> [pre-commit.ci] pre-commit autoupdate</li>; <li><a href=""https://github.com/pytest-dev/pytest-metadata/commit/429840f4de26276560961929f21aab79ed305875""><code>429840f</code></a> Avoid running nightly on forks</li>; <li><a href=""https://github.com/pytest-dev/pytest-metadata/commit/c1968f39609978ec9c6a4bcf91c37c6164483f04""><code>c1968f3</code></a> Fix nightly",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12188:1171,config,config,1171,https://hail.is,https://github.com/hail-is/hail/pull/12188,1,['config'],['config']
Modifiability," from <a href=""https://github.com/sass/libsass-python/blob/main/docs/changes.rst"">libsass's changelog</a>.</em></p>; <blockquote>; <h2>Version 0.22.0</h2>; <p>Released on November 12, 2022.</p>; <ul>; <li>Remove python 2.x support [:issue:<code>373</code> by anthony sottile].</li>; <li>Remove deprecated <code>sassc</code> cli [:issue:<code>379</code> by anthony sottile].</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/sass/libsass-python/commit/b18db090672676d7c58fcd52e6ae0eb505993886""><code>b18db09</code></a> 0.22.0</li>; <li><a href=""https://github.com/sass/libsass-python/commit/22adb66fac69d058e8dccc0014563cd76e78349e""><code>22adb66</code></a> correct version number</li>; <li><a href=""https://github.com/sass/libsass-python/commit/b2436e282ae19ccb7be9318f3ddd0eb6cdb48be3""><code>b2436e2</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/sass/libsass-python/issues/406"">#406</a> from sass/pre-commit-ci-update-config</li>; <li><a href=""https://github.com/sass/libsass-python/commit/980b41f462ae07939515993781e72654b117bdce""><code>980b41f</code></a> [pre-commit.ci] pre-commit autoupdate</li>; <li><a href=""https://github.com/sass/libsass-python/commit/cfffd417e56b7fd3aaf6034fa49083185714f6b7""><code>cfffd41</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/sass/libsass-python/issues/405"">#405</a> from sass/pre-commit-ci-update-config</li>; <li><a href=""https://github.com/sass/libsass-python/commit/20b3cdade8a199e832521d0e44a2507bc75315e0""><code>20b3cda</code></a> [pre-commit.ci] pre-commit autoupdate</li>; <li><a href=""https://github.com/sass/libsass-python/commit/940ef2e9f9dd4143d642a29156c94d0a3133a691""><code>940ef2e</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/sass/libsass-python/issues/404"">#404</a> from sass/pre-commit-ci-update-config</li>; <li><a href=""https://github.com/sass/libsass-python/commit/5f8470b48cb576f",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12482:1530,config,config,1530,https://hail.is,https://github.com/hail-is/hail/pull/12482,1,['config'],['config']
Modifiability," help debugging of JVM crashing in production until the JVM logs are shown on a per-worker page. 2. JVMEntryway is now a real gradle project. I need to compile against log4j, and I didn't want to do that by hand with `javac`. Ignore gradlew, gradlew.bat, and gradle/wrapper, they're programmatically generated by gradle. 3. Add logging to JVMEntryway. JVMEntryway now logs its arguments into the QoB job log. I also log exceptions from the main thread or the cancel thread into the job log. We also flush the logs after the main thread completes, the cancel thread completes, and when the try-catch exits. This should ensure that regardless of what goes wrong (even if both threads fail to start) we at least see the arguments that the JVMEntryway received. 4. Use log4j2 programmatic reconfiguration after every job. This restores log4j2 to well enough working order that, *if you do not try to reconfigure it using log4j1 programmatic configuration*, logs will work. All old versions of Hail use log4j1 programmatic configuration. As a result, **all old versions of Hail will still have no logs**. However, new versions of Hail will log correctly even if an old version of Hail used the JVM before it. 5. `QoBAppender`. This is how we always should have done logging. A custom appender which we can flush and then redirect to a new file at our whim. I followed the log4j2 best practices for creating a new appender. All these annotations, factory methods, and managers are The Right Way, for better or worse. If we ever ban old versions of Hail from the cluster, then we can also eliminate the log4j2 reconfiguration. New versions of Hail work fine without any runtime log configuration (thanks to `QoBAppender`). I would like to eliminate reconfiguration because log4j2 reconfiguration leaves around oprhaned appenders and appender managers. Maybe I'm implementing the Appender or Appender Manager interfaces wrong, but I've read over that code a bunch of times and I cannot sort out what I am mis",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12941:1358,config,configuration,1358,https://hail.is,https://github.com/hail-is/hail/pull/12941,1,['config'],['configuration']
Modifiability," href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2837"">cbeust/testng#2837</a></li>; <li>Support getting dependencies info for a test by <a href=""https://github.com/krmahadevan""><code>@​krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2839"">cbeust/testng#2839</a></li>; <li>Honour regex in dependsOnMethods by <a href=""https://github.com/krmahadevan""><code>@​krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2838"">cbeust/testng#2838</a></li>; <li>Ensure All tests run all the time by <a href=""https://github.com/krmahadevan""><code>@​krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2842"">cbeust/testng#2842</a></li>; <li>Deprecate support for running Spock Tests by <a href=""https://github.com/krmahadevan""><code>@​krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2846"">cbeust/testng#2846</a></li>; <li>Streamline dependsOnMethods for configurations by <a href=""https://github.com/krmahadevan""><code>@​krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2845"">cbeust/testng#2845</a></li>; <li>Ensure ITestContext available for JUnit4 tests by <a href=""https://github.com/krmahadevan""><code>@​krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2848"">cbeust/testng#2848</a></li>; <li>Deprecate support for running JUnit tests by <a href=""https://github.com/krmahadevan""><code>@​krmahadevan</code></a> in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2849"">cbeust/testng#2849</a></li>; </ul>; <h2>New Contributors</h2>; <ul>; <li><a href=""https://github.com/gruenich""><code>@​gruenich</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/cbeust/testng/pull/2781"">cbeust/testng#2781</a></li>; <li><a href=""https://github.com/anatolyuzhakov""><code>@​anatolyuzhakov</code>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12665:7376,config,configurations,7376,https://hail.is,https://github.com/hail-is/hail/pull/12665,1,['config'],['configurations']
Modifiability," in RFC 2246. This new version was backwards-incompatible and was; thus given a new name: Transport Layer Security. In common discussion, SSL; and TLS are used interchangeable. Indeed, the python TLS library is called; `ssl`. [2] Forward secrecy is a property of an encryption system. Forward secrecy means; a message cannot be decrypted in the future by an adversary who learned one; of the private keys. For example, imagine you are sending sensitive messages; to another individual. If that individual is later coerced into revealing; their secret key, forward secrecy would prevent the coercer from reading; your messages. Forward secrecy is achieved by negotiating a shared private; key between the two parties that is only used for a ""session"" and then; discarded. If the session key is securely discarded and neither key can; recreate it without cooperation from the other key, then *one* leaked key is; insufficient to reveal the messages. ---. Things for you to verify:; - does every service load *its own unqiue* ssl-config secret?; - does every service use an SSL context for serving?; - does everyone who makes http requests to internal services use an SSL client; session?; - do all TLS-secured nginx instances include their http.conf in the `http`; section and the `proxy.conf` file in any proxying sections?; - Do the SSLContext's from `ssl.py` and the nginx configurations generated by; `create_certs.py` actually ensure security?. Post-merge actions:; - deploy gateway; - deploy internal-gateway; - deploy router-resolver. Anticipated outages:. - Before a service is redeployed it will be inaccessible from the outside; because the router will try to speak to it on HTTPS. Services that speak to; one another (ci<->batch, everyone<->auth) will lose connections while the; deploy is happening. Deploy should move smoothly because CI will completely; transmit the deploy batch to batch before batch goes dark.; - dev namespaces will be broken until the owner redeploys the router, etc.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8561:12742,config,config,12742,https://hail.is,https://github.com/hail-is/hail/pull/8561,2,['config'],"['config', 'configurations']"
Modifiability," in the terraform does not exist in hail-vdc. If you approve of the approach I can add it in manually. . ## Terraform changes; This adds a new CI terraform module that adds a CI bucket, sets some permissions for the CI service account and adds some K8s secrets like github tokens and the zulip config. This allows the terraform deployment to optionally include resources needed for CI. This was the best way I could think to introduce this infra with the least changes, but it's not what I want in the long term. Right now we have one monolithic root module that includes all the resources necessary to run batch, with the option for tacking on CI. I would rather extract most of our root module into a `batch` module (and while we're break down the innards into modules like vdc, db, etc.) and have the root module be something that can be easily pieced together from the library of modules. This would be a decently big refactor and more importantly would require existing deployments to manually overhaul their terraform state, so it's something I want to do carefully but also sooner is better than later. Given how terraform state is indexed, I believe more modularity will be easier to manage in the long term. ## CI changes; This adds the following features to CI; - Watched branches can be marked as `mergeable`. `mergeable=true` should be the default behavior and `false` prevents CI from merging a PR on GitHub. This allows multiple CI's to run tests in different environments without stepping on each others' toes. This *does not*, however, consider statuses from multiple CIs when making the decision to merge a PR. That is currently based on the build status, and later should be changed to consider the collection of statuses on GitHub.; - Custom Deploy Steps: This is a collection of build.yaml steps that CI should run on `deploy`. This allows a deployment to only deploy a subset of the infrastructure to default, though it will run the entire test suite. Based on the semantics, `req",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11053:1133,refactor,refactor,1133,https://hail.is,https://github.com/hail-is/hail/pull/11053,1,['refactor'],['refactor']
Modifiability," in this release, <code>delimited_list</code> changes from a function to a synonym for <code>DelimitedList</code>. <code>delimited_list</code> and the older <code>delimitedList</code> method will be deprecated in a future release, in favor of <code>DelimitedList</code>.</p>; </li>; <li>; <p>Added new class method <code>ParserElement.using_each</code>, to simplify code that creates a sequence of <code>Literals</code>, <code>Keywords</code>, or other <code>ParserElement</code> subclasses.</p>; <p>For instance, to define suppressable punctuation, you would previously write:</p>; <pre><code>LPAR, RPAR, LBRACE, RBRACE, SEMI = map(Suppress, &quot;(){};&quot;); </code></pre>; <p>You can now write:</p>; <pre><code>LPAR, RPAR, LBRACE, RBRACE, SEMI = Suppress.using_each(&quot;(){};&quot;); </code></pre>; <p><code>using_each</code> will also accept optional keyword args, which it will pass through to the class initializer. Here is an expression for single-letter variable names that might be used in an algebraic expression:</p>; <pre><code>algebra_var = MatchFirst(; Char.using_each(string.ascii_lowercase, as_keyword=True); ); </code></pre>; </li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/pyparsing/pyparsing/blob/master/CHANGES"">pyparsing's changelog</a>.</em></p>; <blockquote>; <h2>Version 3.1.0 - June, 2023</h2>; <ul>; <li>Added <code>tag_emitter.py</code> to examples. This example demonstrates how to insert; tags into your parsed results that are not part of the original parsed text.</li>; </ul>; <h2>Version 3.1.0b2 - May, 2023</h2>; <ul>; <li>; <p>Updated <code>create_diagram()</code> code to be compatible with railroad-diagrams package; version 3.0. Fixes Issue <a href=""https://redirect.github.com/pyparsing/pyparsing/issues/477"">#477</a> (railroad diagrams generated with black bars),; reported by Sam Morley-Short.</p>; </li>; <li>; <p>Fixed bug",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13334:3558,variab,variable,3558,https://hail.is,https://github.com/hail-is/hail/pull/13334,1,['variab'],['variable']
Modifiability," in this release, <code>delimited_list</code> changes from a function to a synonym for <code>DelimitedList</code>. <code>delimited_list</code> and the older <code>delimitedList</code> method will be deprecated in a future release, in favor of <code>DelimitedList</code>.</p>; </li>; <li>; <p>Added new class method <code>ParserElement.using_each</code>, to simplify code that creates a sequence of <code>Literals</code>, <code>Keywords</code>, or other <code>ParserElement</code> subclasses.</p>; <p>For instance, to define suppressable punctuation, you would previously write:</p>; <pre><code>LPAR, RPAR, LBRACE, RBRACE, SEMI = map(Suppress, &quot;(){};&quot;); </code></pre>; <p>You can now write:</p>; <pre><code>LPAR, RPAR, LBRACE, RBRACE, SEMI = Suppress.using_each(&quot;(){};&quot;); </code></pre>; <p><code>using_each</code> will also accept optional keyword args, which it will pass through to the class initializer. Here is an expression for single-letter variable names that might be used in an algebraic expression:</p>; <pre><code>algebra_var = MatchFirst(; Char.using_each(string.ascii_lowercase, as_keyword=True); ); </code></pre>; </li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/pyparsing/pyparsing/blob/master/CHANGES"">pyparsing's changelog</a>.</em></p>; <blockquote>; <h2>Version 3.1.1 - July, 2023</h2>; <ul>; <li>; <p>Fixed regression in Word(min), reported by Ricardo Coccioli, good catch! (Issue <a href=""https://redirect.github.com/pyparsing/pyparsing/issues/502"">#502</a>)</p>; </li>; <li>; <p>Fixed bug in bad exception messages raised by Forward expressions. PR submitted; by Kyle Sunden, thanks for your patience and collaboration on this (<a href=""https://redirect.github.com/pyparsing/pyparsing/issues/493"">#493</a>).</p>; </li>; <li>; <p>Fixed regression in SkipTo, where ignored expressions were not checked when looking; for the target",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13345:3558,variab,variable,3558,https://hail.is,https://github.com/hail-is/hail/pull/13345,1,['variab'],['variable']
Modifiability," independent normally distributed variables and is used by `hl.skat` to generate p-values. The simplest formulation I know for it is this:. w : R^n; k : Z^n; lam : R^n; mu : R; sigma : R. x ~ N(mu, sigma^2); y_i ~ NonCentralChiSquared(k_i, lam_i). Z = x + w y^T; = x + sum_i{ w_i y_i }; Z ~ GeneralizedNonCentralChiSquared(w, k, lam, mu, sigma). The non-central chi-squared distribution arises from a sum of independent normally distributed variables with non-zero mean and unit variance. The non-centrality parameter, lambda, is defined as the sum of the squares of the means of each component normal random variable. Although the non-central chi-squared distribution has a closed form implementation (indeed, Hail implements this CDF: `hl.pchisqtail`), the generalized chi-squared distribution does not have a closed form. There are at least four distinct algorithms for evaluating the CDF. To my knowledge, the oldest one is by Robert Davies:. Davies, Robert. ""The distribution of a linear combination of chi-squared; random variables."" Applied Statistics 29 323-333. 1980. The [original publication](http://www.robertnz.net/pdf/lc_chisq.pdf) includes a Fortran implementation in the publication. Davies' [website](http://www.robertnz.net/QF.htm) also includes a C version. Hail includes a copy of the C version as `davies.cpp`. I suspect this code contains undefined behavior. Moreover, it is not supported on Apple M1 machines because we don't ship binaries for that platform. It seemed to me that the simplest solution is to port this algorithm to Scala. This PR is that port. I tested against the 39 test cases provided Davies with the source code. I also added some doctests based on the CDF plots from Wikipedia. The same 39 test cases are tested in Scala and in Python. I am open to suggestions for the name. `pgenchisq` seems to strike a balance between clarity and brevity. I believe this is the first CDF which can fail to converge. I included some relevant debugging information. I thin",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12605:1299,variab,variables,1299,https://hail.is,https://github.com/hail-is/hail/pull/12605,1,['variab'],['variables']
Modifiability," intervals.contains(key)` implies `cond`). This means it is safe to replace the `TableFilter(t, cond)` with `TableFilter(TableFilterIntervals(t, intervals), cond2)`. A common example is when `cond` can be completely captured by the interval filter, i.e. `cond` is equivant to `intervals.contains(key)`, in which case we can take `cond2 = True`, and the `TableFilter` can be optimized away. This all happens in the function; ```scala; def extractPartitionFilters(ctx: ExecuteContext, cond: IR, ref: Ref, key: IndexedSeq[String]): Option[(IR, IndexedSeq[Interval])] = {; if (key.isEmpty) None; else {; val extract = new ExtractIntervalFilters(ctx, ref.typ.asInstanceOf[TStruct].typeAfterSelectNames(key)); val trueSet = extract.analyze(cond, ref.name); if (trueSet == extract.KeySetLattice.top); None; else {; val rw = extract.Rewrites(mutable.Set.empty, mutable.Set.empty); extract.analyze(cond, ref.name, Some(rw), trueSet); Some((extract.rewrite(cond, rw), trueSet)); }; }; }; ```; `trueSet` is the set of intervals which contains all rows where `cond` is true. This set is passed back into `analyze` in a second pass, which asks it to rewrite `cond` to something equivalent, under the assumption that all keys are contained in `trueSet`. The abstraction of runtime values tracks two types of information:; * Is this value a reference to / copy of one of the key fields of this row? We need to know this to be able to recognize comparisons with key values, which we want to extract to interval filters.; * For boolean values (including, ultimately, the filter predicate itself), we track three sets of intervals of the key type: overapproximations of when the bool is true, false, and missing. Overapproximation here means, for example, if the boolean evaluates to true in some row with key `k`, then `k` must be contained in the ""true"" set of intervals. But it's completely fine if the set of intervals contains keys of rows where the bool is not true. In particular, a boolean about which we know n",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13355:2335,rewrite,rewrite,2335,https://hail.is,https://github.com/hail-is/hail/pull/13355,1,['rewrite'],['rewrite']
Modifiability," is surprising given that the database is a mere 31 GB:. ```; Filesystem Size Used Available Use% Mounted on; overlay 94.3G 46.4G 47.9G 49% /; tmpfs 64.0M 0 64.0M 0% /dev; tmpfs 14.7G 0 14.7G 0% /sys/fs/cgroup; /dev/sdd 49.0G 31.2G 17.8G 64% /prometheus; /dev/sda1 94.3G 46.4G 47.9G 49% /etc/prometheus; /dev/sda1 94.3G 46.4G 47.9G 49% /dev/termination-log; /dev/sda1 94.3G 46.4G 47.9G 49% /etc/resolv.conf; /dev/sda1 94.3G 46.4G 47.9G 49% /etc/hostname; /dev/sda1 94.3G 46.4G 47.9G 49% /etc/hosts; shm 64.0M 0 64.0M 0% /dev/shm; tmpfs 14.7G 12.0K 14.7G 0% /var/run/secrets/kubernetes.io/serviceaccount; tmpfs 14.7G 0 14.7G 0% /proc/acpi; tmpfs 64.0M 0 64.0M 0% /proc/kcore; tmpfs 64.0M 0 64.0M 0% /proc/keys; tmpfs 64.0M 0 64.0M 0% /proc/timer_list; tmpfs 14.7G 0 14.7G 0% /proc/scsi; tmpfs 14.7G 0 14.7G 0% /sys/firmware; ```. Which isn't much larger than it was before the scaling tests. It appears to slowly increase the amount of memory it needs:; ```; 1 0 nobody S 30.9g103.7 1 11.5 /bin/prometheus --config.file=/etc/prometheus/prometheus.yml --storage.tsdb.path=/prometheus --web.console.libraries=/usr/share/prometheus/console_libraries --web.console.templates=/usr/share/prometheus/consoles --web.external; ```. caping out at 31.5 GB (the disk is 31.2 GB). Now, it is presumably trying to recover. It's been up for about 7 minutes. Still unavailable:; ```; /prometheus $ wget localhost:9090/monitoring/prometheus; Connecting to localhost:9090 (127.0.0.1:9090); wget: server returned error: HTTP/1.1 503 Service Unavailable; /prometheus $ ; ```. https://github.com/prometheus/prometheus/issues/5727#issuecomment-510818825; https://github.com/prometheus/prometheus/issues/4324#issuecomment-460243182. ```; # k logs -n monitoring prometheus-0 ; level=info ts=2019-07-31T15:45:51.990Z caller=main.go:286 msg=""no time or size retention was set so using the default time retention"" duration=15d; level=info ts=2019-07-31T15:45:51.991Z caller=main.go:322 msg=""Starting Prometheus"" version=""(version",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6773:1576,config,config,1576,https://hail.is,https://github.com/hail-is/hail/issues/6773,1,['config'],['config']
Modifiability, is.hail.expr.ir.CompileAndEvaluate$._apply(CompileAndEvaluate.scala:74); E 	at is.hail.expr.ir.CompileAndEvaluate$.$anonfun$apply$1(CompileAndEvaluate.scala:19); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.CompileAndEvaluate$.apply(CompileAndEvaluate.scala:19); E 	at is.hail.expr.ir.lowering.LowerDistributedSort$.distributedSort(LowerDistributedSort.scala:163); E 	at is.hail.backend.service.ServiceBackend.lowerDistributedSort(ServiceBackend.scala:354); E 	at is.hail.backend.Backend.lowerDistributedSort(Backend.scala:100); E 	at is.hail.expr.ir.lowering.LowerAndExecuteShuffles$.$anonfun$apply$1(LowerAndExecuteShuffles.scala:23); E 	at is.hail.expr.ir.RewriteBottomUp$.$anonfun$apply$4(RewriteBottomUp.scala:26); E 	at is.hail.utils.StackSafe$More.advance(StackSafe.scala:60); E 	at is.hail.utils.StackSafe$.run(StackSafe.scala:16); E 	at is.hail.utils.StackSafe$StackFrame.run(StackSafe.scala:32); E 	at is.hail.expr.ir.RewriteBottomUp$.apply(RewriteBottomUp.scala:36); E 	at is.hail.expr.ir.lowering.LowerAndExecuteShuffles$.apply(LowerAndExecuteShuffles.scala:20); E 	at is.hail.expr.ir.lowering.LowerAndExecuteShufflesPass.transform(LoweringPass.scala:157); E 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:16); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:16); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:14); E 	at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:13); E 	at is.hail.expr.ir.lowering.LowerAndExecuteShufflesPass.apply(LoweringPass.scala:151); E 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:22); E 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:20); E 	at scala.collection.mutable.ResizableArray.foreac,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12976:1889,Rewrite,RewriteBottomUp,1889,https://hail.is,https://github.com/hail-is/hail/issues/12976,2,['Rewrite'],['RewriteBottomUp']
Modifiability, is.hail.expr.ir.TypeCheck$.apply(TypeCheck.scala:15); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:29); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:19); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:19); 	at is.hail.backend.local.LocalBackend._jvmLowerAndExecute(LocalBackend.scala:205); 	at is.hail.backend.local.LocalBackend._execute(LocalBackend.scala:249); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$2(LocalBackend.scala:314); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1(LocalBackend.scala:309); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1$adapted(LocalBackend.scala:308); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:78); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:78); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:13); 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:65); 	at is.hail.backend.local.LocalBackend.$anonfun$withExecuteContext$2(LocalBackend.scala:144); 	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:55); 	at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:62); 	at is.hail.backend.local.LocalBackend.withExecuteContext(LocalBackend.scala:130); 	at is.hail.backend.local.LocalBackend.execute(LocalBackend.scala:308); 	at is.hail.backend.BackendHttpHandler.handle(BackendServer.scala:88); 	at com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:79); 	at sun.net.httpserver.AuthFilter.doFilter(AuthFi,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14245:20212,adapt,adapted,20212,https://hail.is,https://github.com/hail-is/hail/issues/14245,1,['adapt'],['adapted']
Modifiability, is.hail.expr.ir.TypeCheck$.apply(TypeCheck.scala:17); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:29); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:19); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:19); 	at is.hail.backend.local.LocalBackend._jvmLowerAndExecute(LocalBackend.scala:205); 	at is.hail.backend.local.LocalBackend._execute(LocalBackend.scala:249); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$2(LocalBackend.scala:314); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1(LocalBackend.scala:309); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1$adapted(LocalBackend.scala:308); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:78); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:78); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:13); 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:65); 	at is.hail.backend.local.LocalBackend.$anonfun$withExecuteContext$2(LocalBackend.scala:144); 	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:55); 	at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:62); 	at is.hail.backend.local.LocalBackend.withExecuteContext(LocalBackend.scala:130); 	at is.hail.backend.local.LocalBackend.execute(LocalBackend.scala:308); 	at is.hail.backend.BackendHttpHandler.handle(BackendServer.scala:88); 	at com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:79); 	at sun.net.httpserver.AuthFilter.doFilter(AuthFi,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14245:16744,adapt,adapted,16744,https://hail.is,https://github.com/hail-is/hail/issues/14245,1,['adapt'],['adapted']
Modifiability, is.hail.rvd.RVD$.$anonfun$getKeyInfo$2$adapted(RVD.scala:1233); 	at is.hail.sparkextras.ContextRDD.$anonfun$crunJobWithIndex$1(ContextRDD.scala:242); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:131); 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:498); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:501); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:750). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2304); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2253); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2252); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2252); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1124); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1124); 	at scala.Option.foreach(Option.scala:407); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1124); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2491); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2433); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2422); 	at org.apache.spark.u,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12532:5969,adapt,adapted,5969,https://hail.is,https://github.com/hail-is/hail/issues/12532,1,['adapt'],['adapted']
Modifiability, is.hail.sparkextras.ContextRDD.$anonfun$runJob$1(ContextRDD.scala:365); 	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2242); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:131); 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2254); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2203); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2202); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2202); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1078); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1078); 	at scala.Option.foreach(Option.scala:407); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1078); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2441); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2383); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2372); 	at org.apache.spark.u,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/10682:8101,adapt,adapted,8101,https://hail.is,https://github.com/hail-is/hail/issues/10682,1,['adapt'],['adapted']
Modifiability, log output. ```shell; 2024/01/17 20:20:25 Starting container setup.; 2024/01/17 20:20:26 Done container setup.; 2024/01/17 20:20:27 Starting localization.; 2024/01/17 20:20:34 Localization script execution started...; 2024/01/17 20:20:34 Localizing input gs://fc-5a8938eb-1299-4afc-957f-afb53ef602b9/submissions/e8747e74-47d1-4f52-acfc-1ac7f81d79ba/VUMCBed2HailMatrix/683447d9-9342-4058-bcfc-ba21422d3121/call-Bed2HailMatrix/script -> /cromwell_root/script; 2024/01/17 20:20:36 Localizing input gs://hui-sandbox/ICA-AGD/plink1/chr12.bed -> /cromwell_root/hui-sandbox/ICA-AGD/plink1/chr12.bed; 2024/01/17 20:59:18 Localizing input gs://hui-sandbox/ICA-AGD/plink1/chr12.fam -> /cromwell_root/hui-sandbox/ICA-AGD/plink1/chr12.fam; 2024/01/17 20:59:18 Localizing input gs://hui-sandbox/ICA-AGD/plink1/chr12.bim -> /cromwell_root/hui-sandbox/ICA-AGD/plink1/chr12.bim; Copying gs://hui-sandbox/ICA-AGD/plink1/chr12.fam...; / [0 files][ 0.0 B/910.3 KiB] / [1 files][910.3 KiB/910.3 KiB] Copying gs://hui-sandbox/ICA-AGD/plink1/chr12.bim...; / [1 files][910.3 KiB/369.7 MiB] - - [1 files][ 51.9 MiB/369.7 MiB] \ | | [1 files][107.6 MiB/369.7 MiB] / - - [1 files][162.3 MiB/369.7 MiB] \ \ [1 files][213.9 MiB/369.7 MiB] | / / [1 files][286.6 MiB/369.7 MiB] - \ \ [1 files][342.1 MiB/369.7 MiB] |; Operation completed over 2 objects/369.7 MiB.; | [2 files][369.7 MiB/369.7 MiB] 2024/01/17 20:59:27 Localization script execution complete.; 2024/01/17 20:59:38 Done localization.; 2024/01/17 20:59:39 Running user action: docker run -v /mnt/local-disk:/cromwell_root --entrypoint=/bin/bash hailgenetics/hail@sha256:3f22576793ce3161893aed2bd40949b1fc822d2b7e6517dc0ac993b62badaff8 /cromwell_root/script; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp.81879b1c; Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/cromwell_root/tmp.81879b1c; 24/01/17 20:59:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; Setting default log lev,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14168:10141,sandbox,sandbox,10141,https://hail.is,https://github.com/hail-is/hail/issues/14168,1,['sandbox'],['sandbox']
Modifiability," metion (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/2637"">#2637</a>)</li>; <li>Adding new axios documentation website link (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3681"">#3681</a>, <a href=""https://github-redirect.dependabot.com/axios/axios/pull/3707"">#3707</a>)</li>; <li>Updating documentation around dispatching requests (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3772"">#3772</a>)</li>; <li>Adding documentation for the type guard isAxiosError (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3767"">#3767</a>)</li>; <li>Adding explanation of cancel token (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3803"">#3803</a>)</li>; <li>Updating CI status badge (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3953"">#3953</a>)</li>; <li>Fixing errors with JSON documentation (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3936"">#3936</a>)</li>; <li>Fixing README typo under Request Config (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3825"">#3825</a>)</li>; <li>Adding axios-multi-api to the ecosystem file (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3817"">#3817</a>)</li>; <li>Adding SECURITY.md to properly disclose security vulnerabilities (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3981"">#3981</a>)</li>; </ul>; <p>Huge thanks to everyone who contributed to this release via code (authors listed below) or via reviews and triaging on GitHub:</p>; <ul>; <li><a href=""https://github.com/SashaKoro"">Sasha Korotkov</a></li>; <li><a href=""https://github.com/timemachine3030"">Daniel Lopretto</a></li>; <li><a href=""https://github.com/MikeBishop"">Mike Bishop</a></li>; <li><a href=""https://github.com/DigitalBrainJS"">Dmitriy Mozgovoy</a></li>; <li><a href=""https://github.com/bimbiltu"">Mark</a></li>; <li><a href=""https://github.com/piiih"">Philipe Gouveia Paixão</a></li>; </ul>; <!-- raw HTML omitte",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11080:4562,Config,Config,4562,https://hail.is,https://github.com/hail-is/hail/pull/11080,2,['Config'],['Config']
Modifiability," metion (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/2637"">#2637</a>)</li>; <li>Adding new axios documentation website link (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3681"">#3681</a>, <a href=""https://github-redirect.dependabot.com/axios/axios/pull/3707"">#3707</a>)</li>; <li>Updating documentation around dispatching requests (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3772"">#3772</a>)</li>; <li>Adding documentation for the type guard isAxiosError (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3767"">#3767</a>)</li>; <li>Adding explanation of cancel token (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3803"">#3803</a>)</li>; <li>Updating CI status badge (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3953"">#3953</a>)</li>; <li>Fixing errors with JSON documentation (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3936"">#3936</a>)</li>; <li>Fixing README typo under Request Config (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3825"">#3825</a>)</li>; <li>Adding axios-multi-api to the ecosystem file (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3817"">#3817</a>)</li>; <li>Adding SECURITY.md to properly disclose security vulnerabilities (<a href=""https://github-redirect.dependabot.com/axios/axios/pull/3981"">#3981</a>)</li>; </ul>; <p>Huge thanks to everyone who contributed to this release via code (authors listed below) or via reviews and triaging on GitHub:</p>; <ul>; <li><a href=""https://github.com/axios/axios/blob/master/mailto:jasonsaayman@gmail.com"">Jay</a></li>; <li><a href=""https://github.com/SashaKoro"">Sasha Korotkov</a></li>; <li><a href=""https://github.com/timemachine3030"">Daniel Lopretto</a></li>; <li><a href=""https://github.com/MikeBishop"">Mike Bishop</a></li>; <li><a href=""https://github.com/DigitalBrainJS"">Dmitriy Mozgovoy</a></li>; <li><a href=""https://github.com/bimbiltu"">Mark</a></li>",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11080:10087,Config,Config,10087,https://hail.is,https://github.com/hail-is/hail/pull/11080,2,['Config'],['Config']
Modifiability," not merge PRs unless all those statuses were also green. The original GCP status, however, is still `ci-test`. This is awkward for a number of reasons:. - Inconsistent naming; - ci.azure.hail.is does not report the GCP status; - As a result of the above, Azure CI might not always make the same decisions as to who the merge candidate should be. The last is the most bothersome and the reason for this change. An example of how this can deadlock the current CI system is the following:. | |GCP |Azure |; |----|--------|----------|; |1 |Fail |Success |; |2 |Success|Pending |. GCP will see PR 2 as the merge candidate because out of the 2 it has no failing checks, and will wait for Azure to post a status. Azure, on the other hand, does not see GCP's status, and so views PR 1 as ready to merge and has no need to run any other PRs. Azure does not issue merge requests to Github as it is not the primary CI. This stalls both CIs until someone manually retries PR 2 on Azure or otherwise changes the system. The way in which we decide the merge priority should not be different on different CI instances, so long as each instance has the same view of the PRs. This PR is a step toward fixing that. I want to just change the GCP CI's status to `hail-ci-gcp` instead of the legacy `ci-test`. However, I don't want all the existing PR statuses to go to waste. So, this change picks up `ci-test` statuses in addition to `hail-ci-*` statuses, and mirrors any `ci-test` status as `hail-ci-gcp`. This way, if I change GCP's status to `hail-ci-gcp`, it will see existing statuses as its own and not try to re-compute statuses for all existing PRs. Once a PR has a real `hail-ci-gcp` status, I can go and delete the `ci-test` status without disturbing the system. Once all `ci-test` statuses are gone, we can just delete any mention of `ci-test` in the code block below. The `GITHUB_STATUS_CONTEXT` is set through the ci-config secret, which in GCP is managed manually. I can edit that once this PR is merged.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11958:2063,config,config,2063,https://hail.is,https://github.com/hail-is/hail/pull/11958,1,['config'],['config']
Modifiability," older versions of the Terra container (1.0.x) because the versions of Hail implemented there are not compatible with the current version of Spark on Terra. . I hope you may have a solution to this irritating problem. I have added the scripts and logs below. . Thanks in advance,; Sean Jurgens. ### Version. 0.2.126-ee77707f4fab. ### Relevant log output. ```shell; ## PLEASE NOTE: to protect privacy as much as possible, I have removed almost all entries shown by the code, and for the few line entries that remain I have changed/randomized the numeric values. The order and structure is preserved for enrtries nonetheless. `#import libraries; import os; import hail as hl; from pprint import pprint. #### Start hail; hl.init(); hl.spark_context()`. /opt/conda/lib/python3.10/site-packages/hailtop/aiocloud/aiogoogle/user_config.py:44: UserWarning:. Reading spark-defaults.conf to determine GCS requester pays configuration. This is deprecated. Please use `hailctl config set gcs_requester_pays/project` and `hailctl config set gcs_requester_pays/buckets`. SLF4J: No SLF4J providers were found.; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See https://www.slf4j.org/codes.html#noProviders for further details.; SLF4J: Class path contains SLF4J bindings targeting slf4j-api versions 1.7.x or earlier.; SLF4J: Ignoring binding found at [jar:file:/usr/lib/spark/jars/log4j-slf4j-impl-2.18.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: See https://www.slf4j.org/codes.html#ignoredBindings for an explanation.; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Running on Apache Spark version 3.3.0; SparkUI available at http://saturn-3f2d119c-05e5-496d-97b9-8f40efff98a3-m.c.terra-db12d060.internal:36235/; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.126-ee77707f4fab; LOGGING: writing to /home/jupyter/Ellinor_Lubitz_PHB_Joint_Analyses/edit/h",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14102:1916,config,config,1916,https://hail.is,https://github.com/hail-is/hail/issues/14102,2,['config'],['config']
Modifiability," own `config` or `url`. `Dataset.from_name_and_json()` now calls `DatasetVersion.get_region()` method to retrieve the dataset from the bucket in the selected region if `custom_config` is `False`. ; - The `DatasetVersion.get_region()` method takes the dataset `name`, a list of `DatasetVersion` objects, and a `region`, and returns a list of the versions that are available for that region. This method calls the instance method `in_region()` to check if the dataset is available in the requested region.; - If `in_region()` determines the desired region is not available for some dataset that otherwise is available in another region, it will raise a warning. If user still tries to call `db.annotate_rows_db()` using a dataset unavailable in their region, then it will get caught by the `_check_availability` instance method in the `DB` class and raise a `ValueError`.; - Started to add documentation to the classes and methods, still a work in progress. Changes to datasets and datasets API site:; - Added the `ldsc_baselineLD_annotations`, `ldsc_baselineLD_ldscores`, and `ldsc_baseline_ldscores` datasets to the `annotation_db.json` configuration file. Now accessible via `load_dataset()` and `db.annotate_rows_db()` (for the annotations at least).; - New `.rst` files in `hail/python/hail/docs/datasets` have been generated to reflect the available datasets in the config file, and `hail/python/hail/docs/datasets.rst` has been updated with the new files as well. Future updates:; - In next PR can add the functionality to automatically determine the users region.; - Also considering modifying the `load_datasets()` function a bit to only require one `version` parameter, to be consistent with the way the version strings are formatted in `annotation_db.json`, and to avoid having to check if the version and reference genome are available separately. Something like this:. ```; mt_1kg = hl.experimental.load_dataset(name='1000_Genomes_autosomes',; version='phase_3-GRCh37', ; region='us'); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9496:2287,config,configuration,2287,https://hail.is,https://github.com/hail-is/hail/pull/9496,2,['config'],"['config', 'configuration']"
Modifiability," pod IPs underlying a Service so that our proxies can properly load-balance across persistent connections. ## Solution. This PR addresses the two goals outlined above and does so through using Envoy, a load-balancer/proxy that is well-suited to this sort of highly-dynamic cluster configuration. Envoy does not have the constraint that all upstream services must be available at start-time, and has a very convenient API for updating the cluster configuration without the need for restarting the process or dropping traffic. This makes regularly updating the cluster configuration whenever new test namespaces are created relatively straightforward and non-disruptive to traffic in other namespaces. The high-level approach is as follows:. 1. Envoy-based gateways and internal-gateways will load their routing configuration from a Kubernetes ConfigMap, which they watch for changes and reconcile their configuration when the ConfigMap changes. The ConfigMap can be populated with a manual deploy and is populated from the beginning with production routes (i.e. batch.hail.is gets routed to batch.default); 2. When running CI, CI will regularly update the ConfigMap with additional routes based on which internal namespaces (dev and PR) are currently active. This requires relatively small changes to CI to track active namespaces but overall is a pretty small change. Note that this does not introduce a dependency on CI to support production traffic, only development traffic.; 3. Deployments that run more than 1 replica (but really can be all of them) are run behind Headless Services, which expose the underlying pod IPs so Envoy can handle load-balancing instead of kube-proxy. This allows Envoy to make smart load-balancing decisions and correctly enforce rate-limiting when using connection pools. The namespace tracking in CI in Point 2 is possible before we make any changes to our networking, so that comes first in #12093. Point 3 is taken care of in #12094, and the rest of Point 2 and Poi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12095:4371,Config,ConfigMap,4371,https://hail.is,https://github.com/hail-is/hail/pull/12095,1,['Config'],['ConfigMap']
Modifiability," signal; .; Driver stacktrace:. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.4 in stage 1.0 (TID 10) (all-of-us-1774-w-0.c.terra-vpc-sc-23dfb1a3.internal executor 7): ExecutorLostFailure (executor 7 exited caused by one of the running tasks) Reason: Container from a bad node: container_e01_1690206305672_0001_01_000007 on host: all-of-us-1774-w-0.c.terra-vpc-sc-23dfb1a3.internal. Exit status: 137. Diagnostics: [2023-07-24 13:52:49.515]Container killed on request. Exit code is 137; [2023-07-24 13:52:49.517]Container exited with a non-zero exit code 137. ; [2023-07-24 13:52:49.518]Killed by external signal; .; Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2304); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2253); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2252); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2252); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1124); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1124); 	at scala.Option.foreach(Option.scala:407); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1124); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2491); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2433); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2422); 	at org.apache.spark.u",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13287:6632,adapt,adapted,6632,https://hail.is,https://github.com/hail-is/hail/issues/13287,1,['adapt'],['adapted']
Modifiability," the class itself.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5408"">PyCQA/pylint#5408</a></p>; </li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/PyCQA/astroid/commit/07c0f60ffc1017d0a9a2bb605a5c645781a8c088""><code>07c0f60</code></a> Bump astroid to 2.10.0, update changelog</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/e6dc5ef0f8c2d28bc9d2ffa226fbb5e4e58d88f3""><code>e6dc5ef</code></a> Fix some typoes in the Changelog</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/b6d17107f2e02df4ce5080536bb783a25273b33f""><code>b6d1710</code></a> Changed NodeNG.tolineno to use end_lineno when it is available (<a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1351"">#1351</a>)</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/0acb961d7375131c3d1e7a3580f974b6e8c5ef94""><code>0acb961</code></a> Refactor: Stop adding arbitrary attributes to module obj when building (<a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1215"">#1215</a>)</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/62aa3bb63c3ca0cda19a1bb294a6b052c2346189""><code>62aa3bb</code></a> Restore custom distutils handling for resolving paths to submodules. (<a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1386"">#1386</a>)</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/8f7f07898720b875cfbf447a7106875db4a904b3""><code>8f7f078</code></a> Limit expensive decorator function (<a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1407"">#1407</a>)</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/98280b57b5ed3db8a4d431cb60e21f136f6c70de""><code>98280b5</code></a> Add Position to the nodes.<strong>init</strong> (<a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1408"">#1408</a>)</li>; <li><a href=""https://github.com/PyCQA/astroid/commit",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11463:3947,Refactor,Refactor,3947,https://hail.is,https://github.com/hail-is/hail/pull/11463,2,['Refactor'],['Refactor']
Modifiability," the non-central chi-squared distribution has a closed form implementation (indeed, Hail implements this CDF: `hl.pchisqtail`), the generalized chi-squared distribution does not have a closed form. There are at least four distinct algorithms for evaluating the CDF. To my knowledge, the oldest one is by Robert Davies:. Davies, Robert. ""The distribution of a linear combination of chi-squared; random variables."" Applied Statistics 29 323-333. 1980. The [original publication](http://www.robertnz.net/pdf/lc_chisq.pdf) includes a Fortran implementation in the publication. Davies' [website](http://www.robertnz.net/QF.htm) also includes a C version. Hail includes a copy of the C version as `davies.cpp`. I suspect this code contains undefined behavior. Moreover, it is not supported on Apple M1 machines because we don't ship binaries for that platform. It seemed to me that the simplest solution is to port this algorithm to Scala. This PR is that port. I tested against the 39 test cases provided Davies with the source code. I also added some doctests based on the CDF plots from Wikipedia. The same 39 test cases are tested in Scala and in Python. I am open to suggestions for the name. `pgenchisq` seems to strike a balance between clarity and brevity. I believe this is the first CDF which can fail to converge. I included some relevant debugging information. I think we should standardize on a schema, but I need more examples before I am certain of the right standard. I am open to critique of `GeneralizedChiSquaredDistribution.scala` but I will strongly argue against significant refactoring. I worry that we will subtly break this algorithm. I directly reached out to Robert Davies to clarify the licensing of this algorithm. It appears to have been released at least under both GPL2 and MIT by unaffiliated third parties (who, really, have no right to apply a license to it). Do not remove WIP until I resolve this. With this PR in place, `hl.skat` can be implemented entirely in Python.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12605:2489,refactor,refactoring,2489,https://hail.is,https://github.com/hail-is/hail/pull/12605,1,['refactor'],['refactoring']
Modifiability," to <code>*string</code>. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/104624"">kubernetes/kubernetes#104624</a>, <a href=""https://github.com/Haleygo""><code>@​Haleygo</code></a>)</li>; <li>Kubernetes is now built using go 1.17. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/103692"">kubernetes/kubernetes#103692</a>, <a href=""https://github.com/justaugustus""><code>@​justaugustus</code></a>)</li>; <li>Performs strict server side schema validation requests via the <code>fieldValidation=[Strict,Warn,Ignore]</code>. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/105916"">kubernetes/kubernetes#105916</a>, <a href=""https://github.com/kevindelgado""><code>@​kevindelgado</code></a>)</li>; <li>Promote <code>IPv6DualStack</code> feature to stable.; Controller Manager flags for the node IPAM controller have slightly changed:; <ol>; <li>When configuring a dual-stack cluster, the user must specify both <code>--node-cidr-mask-size-ipv4</code> and <code>--node-cidr-mask-size-ipv6</code> to set the per-node IP mask sizes, instead of the previous <code>--node-cidr-mask-size</code> flag.</li>; <li>The <code>--node-cidr-mask-size</code> flag is mutually exclusive with <code>--node-cidr-mask-size-ipv4</code> and <code>--node-cidr-mask-size-ipv6</code>.</li>; <li>Single-stack clusters do not need to change, but may choose to use the more specific flags. Users can use either the older <code>--node-cidr-mask-size</code> flag or one of the newer <code>--node-cidr-mask-size-ipv4</code> or <code>--node-cidr-mask-size-ipv6</code> flags to configure the per-node IP mask size, provided that the flag's IP family matches the cluster's IP family (--cluster-cidr). (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/104691"">kubernetes/kubernetes#104691</a>, <a href=""https://github.com/khenidak""><code>@​khenidak</code></a>)</li>; </ol>; </li>; <li>Remove <code>NodeLease</code> feature gate that ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11957:10533,config,configuring,10533,https://hail.is,https://github.com/hail-is/hail/pull/11957,1,['config'],['configuring']
Modifiability," was ready at about 19:05:33 worker time because that's when we see the; image cleanup loop start running. The worker times out and kills itself before; the driver initiates another scheduling loop. This PR ensures that aiohttp is; already initialized and that the only work we need to do before we can; accept a job is parse the JSON response for our token. ```; 2022-03-02 19:06:21,325	ACCEPTABLE_QUERY_JAR_URL_PREFIX hail-az://haildevtest/test/iy40biv5rl1j/jars; 2022-03-02 19:06:30,168	JVM-0: trying to open socket; 2022-03-02 19:06:30,169	JVM-1: trying to open socket; 2022-03-02 19:06:30,169	JVM-2: trying to open socket; 2022-03-02 19:06:30,169	JVM-3: trying to open socket; 2022-03-02 19:06:30,170	JVM-4: trying to open socket; 2022-03-02 19:06:30,170	JVM-5: trying to open socket; 2022-03-02 19:06:30,170	JVM-6: trying to open socket; 2022-03-02 19:06:30,171	JVM-7: trying to open socket; 2022-03-02 19:06:30,171	JVM-8: trying to open socket; 2022-03-02 19:06:30,171	JVM-9: trying to open socket; 2022-03-02 19:06:30,172	JVM-10: trying to open socket; 2022-03-02 19:06:30,172	JVM-11: trying to open socket; 2022-03-02 19:06:30,173	JVM-12: trying to open socket; 2022-03-02 19:06:30,173	JVM-13: trying to open socket; 2022-03-02 19:06:30,173	JVM-14: trying to open socket; 2022-03-02 19:06:30,173	JVM-15: trying to open socket; 2022-03-02 19:06:30,203	BATCH_LOGS_ROOT hail-az://haildevtest/test/batch/logs/4piCT5NOAh9FghF7VjKqZh/batch; 2022-03-02 19:06:30,204	EXAMPLE BATCH_JOB_LOGS_PATH hail-az://haildevtest/test/batch/logs/4piCT5NOAh9FghF7VjKqZh/batch/1/1/abc123/main/log; 2022-03-02 19:06:30,204	No environment configuration found.; 2022-03-02 19:06:30,205	ManagedIdentityCredential will use IMDS; 2022-03-02 19:06:30,419	JVM-0: trying to open socket; 2022-03-02 19:06:30,420	JVM-1: trying to open socket; 2022-03-02 19:06:30,421	JVM-2: trying to open socket; 2022-03-02 19:06:30,421	JVM-3: trying to open socket; 2022-03-02 19:06:30,422	JVM-4: trying to open socket; 2022-03-02 19:06:30,4",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:28066,config,configuration,28066,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['config'],['configuration']
Modifiability,"""*""]; ---; kind: RoleBinding; apiVersion: rbac.authorization.k8s.io/v1; metadata:; namespace: default; name: notebook-create-services-and-pods; subjects:; - kind: ServiceAccount; name: notebook; namespace: default; roleRef:; kind: Role; name: create-services #this was causing the error, and of course the create-services role is superseded by the the create-services-and-pods role; apiGroup: """"; ---; ```. After:; ```yaml; kind: Role; apiVersion: rbac.authorization.k8s.io/v1; metadata:; namespace: default; name: create-services-and-pods; rules:; - apiGroups: [""""]; resources: [""services""]; verbs: [""*""]; - apiGroups: [""""]; resources: [""pods""]; verbs: [""*""]; ---; kind: RoleBinding; apiVersion: rbac.authorization.k8s.io/v1; metadata:; namespace: default; name: notebook-create-services-and-pods; subjects:; - kind: ServiceAccount; name: notebook; namespace: default; roleRef:; kind: Role; name: create-services-and-pods; apiGroup: """"; ---; ```. ### Results of test runs. Before:. ```sh; kubectl apply -f k8s-config.yaml; ERROR: (gcloud.compute.addresses.describe) Could not fetch resource:; - Required 'compute.addresses.get' permission for 'projects/hail-vdc-staging/regions/us-central1/addresses/site'. namespace/batch-pods unchanged; ...; The RoleBinding ""notebook-create-services-and-pods"" is invalid: roleRef: Invalid value: rbac.RoleRef{APIGroup:""rbac.authorization.k8s.io"", Kind:""Role"", Name:""create-services""}: cannot change roleRef; make: *** [k8s-config] Error 1; ```. After:; ```sh; ERROR: (gcloud.compute.addresses.describe) Could not fetch resource:; - Required 'compute.addresses.get' permission for 'projects/hail-vdc-staging/regions/us-central1/addresses/site'. ...; role.rbac.authorization.k8s.io/create-services-and-pods unchanged; rolebinding.rbac.authorization.k8s.io/notebook-create-services-and-pods configured; role.rbac.authorization.k8s.io/read-get-user-secret unchanged; rolebinding.rbac.authorization.k8s.io/notebook-read-get-users-secret configured; ```. I think the er",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5746:2396,config,config,2396,https://hail.is,https://github.com/hail-is/hail/pull/5746,1,['config'],['config']
Modifiability,"""><code>@​damemi</code></a>) [SIG API Machinery]</li>; <li>Kubelet's --runonce option is now also available in Kubelet's config file as <code>runOnce</code>. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/89128"">kubernetes/kubernetes#89128</a>, <a href=""https://github.com/vincent178""><code>@​vincent178</code></a>) [SIG Node]</li>; <li>Kubelet: add '--logging-format' flag to support structured logging (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/91532"">kubernetes/kubernetes#91532</a>, <a href=""https://github.com/afrouzMashaykhi""><code>@​afrouzMashaykhi</code></a>) [SIG API Machinery, Cluster Lifecycle, Instrumentation and Node]</li>; <li>Kubernetes is now built with golang 1.15.0-rc.1.; <ul>; <li>The deprecated, legacy behavior of treating the CommonName field on X.509 serving certificates as a host name when no Subject Alternative Names are present is now disabled by default. It can be temporarily re-enabled by adding the value x509ignoreCN=0 to the GODEBUG environment variable. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/93264"">kubernetes/kubernetes#93264</a>, <a href=""https://github.com/justaugustus""><code>@​justaugustus</code></a>) [SIG API Machinery, Auth, CLI, Cloud Provider, Cluster Lifecycle, Instrumentation, Network, Node, Release, Scalability, Storage and Testing]</li>; </ul>; </li>; <li>Promote Immutable Secrets/ConfigMaps feature to Beta and enable the feature by default.; This allows to set <code>Immutable</code> field in Secrets or ConfigMap object to mark their contents as immutable. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/89594"">kubernetes/kubernetes#89594</a>, <a href=""https://github.com/wojtek-t""><code>@​wojtek-t</code></a>) [SIG Apps and Testing]</li>; <li>Remove <code>BindTimeoutSeconds</code> from schedule configuration <code>KubeSchedulerConfiguration</code> (<a href=""https://github-redirect.dependabot.com/kubernetes/kub",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11462:10766,variab,variable,10766,https://hail.is,https://github.com/hail-is/hail/pull/11462,1,['variab'],['variable']
Modifiability,"""https://github.com/BenWhitehead""><code>@​BenWhitehead</code></a>, <a href=""https://github.com/frankyn""><code>@​frankyn</code></a>, <a href=""https://github.com/jesselovelace""><code>@​jesselovelace</code></a> and <a href=""https://github.com/sydney-munro""><code>@​sydney-munro</code></a> for their hard work on this effort.</p>; <h4>Notable Improvements</h4>; <ol>; <li>; <p>For all gRPC media related operations (upload/download) we are now more resource courteous then the corresponding HTTP counterpart. Buffers are fixed to their specified size (can't arbitrarily grow without bounds), are allocated lazily and only if necessary.</p>; <ol>; <li>Investigation into the possibility of backporting these improvements to the HTTP counterparts is ongoing</li>; </ol>; </li>; <li>; <p>Preview support for Accessing GCS via gRPC</p>; <ol>; <li>Set the environment variable <code>GOOGLE_CLOUD_ENABLE_DIRECT_PATH_XDS=true</code>, then run your program.</li>; <li>When configuring your <code>StorageOptions</code> mimic the following:; <pre><code> StorageOptions.grpc(); .setAttemptDirectPath(true); .build(); </code></pre>; </li>; <li>Internally the default host endpoint <code>https://storage.googleapis.com:443</code> will be transformed to the applicable <code>google-c2p-experimental:///storage.googleapis.com</code></li>; </ol>; </li>; <li>; <p>Support for <code>java.time</code> types on model classes</p>; <ol>; <li>Points in time are now represented with <code>java.time.OffsetDateTime</code>, while durations are represented with <code>java.time.Duration</code></li>; <li>All existing <code>Long</code> centric methods are still present, but have been deprecated in favor of their corresponding <code>java.time</code> variant</li>; <li>At the next major version, these deprecated methods will be replaced with types from <code>java.time</code> and the <code>java.time</code> variant methods will be deprecated</li>; </ol>; </li>; <li>; <p><code>com.google.cloud.storage.Storage</code> now extends <",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12456:4385,config,configuring,4385,https://hail.is,https://github.com/hail-is/hail/pull/12456,2,['config'],['configuring']
Modifiability,"""https://github.com/BenWhitehead""><code>@​BenWhitehead</code></a>, <a href=""https://github.com/frankyn""><code>@​frankyn</code></a>, <a href=""https://github.com/jesselovelace""><code>@​jesselovelace</code></a> and <a href=""https://github.com/sydney-munro""><code>@​sydney-munro</code></a> for their hard work on this effort.</p>; <h4>Notable Improvements</h4>; <ol>; <li>; <p>For all gRPC media related operations (upload/download) we are now more resource courteous then the corresponding HTTP counterpart. Buffers are fixed to their specified size (can't arbitrarily grow without bounds), are allocated lazily and only if necessary.</p>; <ol>; <li>Investigation into the possibility of backporting these improvements to the HTTP counterparts is ongoing</li>; </ol>; </li>; <li>; <p>Preview support for Accessing GCS via gRPC</p>; <ol>; <li>Set the environment variable <code>GOOGLE_CLOUD_ENABLE_DIRECT_PATH_XDS=true</code>, then run your program.</li>; <li>When configuring your <code>StorageOptions</code> mimic the following:; <pre><code> StorageOptions.grpc(); </code></pre>; </li>; </ol>; </li>; </ol>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/googleapis/java-storage/commit/bfd48a1b5542ff28ffa337eba883c4ca6c3b0aad""><code>bfd48a1</code></a> chore(main): release 2.15.1 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1765"">#1765</a>)</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/3b8d137a113376d7dac9010b9207d435df2622f7""><code>3b8d137</code></a> docs: annotate all Option factory methods with their Nullability bounds (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1775"">#1775</a>)</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/ba49f9d903d1c68f2a67ea56489fc64907d7d31d""><code>ba49f9d</code></a> test(deps): update kms.version to v0.100.0 (<a href=""https://github-redirec",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12529:10779,config,configuring,10779,https://hail.is,https://github.com/hail-is/hail/pull/12529,1,['config'],['configuring']
Modifiability,"""https://github.com/justaugustus""><code>@​justaugustus</code></a>) [SIG API Machinery, Auth, CLI, Cloud Provider, Cluster Lifecycle, Instrumentation, Network, Node, Release, Scalability, Storage and Testing]</li>; </ul>; </li>; <li>Promote Immutable Secrets/ConfigMaps feature to Beta and enable the feature by default.; This allows to set <code>Immutable</code> field in Secrets or ConfigMap object to mark their contents as immutable. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/89594"">kubernetes/kubernetes#89594</a>, <a href=""https://github.com/wojtek-t""><code>@​wojtek-t</code></a>) [SIG Apps and Testing]</li>; <li>Remove <code>BindTimeoutSeconds</code> from schedule configuration <code>KubeSchedulerConfiguration</code> (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/91580"">kubernetes/kubernetes#91580</a>, <a href=""https://github.com/cofyc""><code>@​cofyc</code></a>) [SIG Scheduling and Testing]</li>; <li>Remove kubescheduler.config.k8s.io/v1alpha1 (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/89298"">kubernetes/kubernetes#89298</a>, <a href=""https://github.com/gavinfish""><code>@​gavinfish</code></a>) [SIG Scheduling]</li>; <li>Reserve plugins that fail to reserve will trigger the unreserve extension point (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/92391"">kubernetes/kubernetes#92391</a>, <a href=""https://github.com/adtac""><code>@​adtac</code></a>) [SIG Scheduling and Testing]</li>; <li>Resolve regression in <code>metadata.managedFields</code> handling in update/patch requests submitted by older API clients (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/91748"">kubernetes/kubernetes#91748</a>, <a href=""https://github.com/apelisse""><code>@​apelisse</code></a>)</li>; <li>Scheduler: optionally check for available storage capacity before scheduling pods which have unbound volumes (alpha feature with the new <code>CSIStorageCapa",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11462:11897,config,config,11897,https://hail.is,https://github.com/hail-is/hail/pull/11462,1,['config'],['config']
Modifiability,"# --- DRAFT ---. # People. @hail-is/tensors . # Scope of Document; Python API, types, IR, optimizer, compiler. # Notation. e[[x/v]] means substitute occurrences of the variable v with the expression x in; the expression e. f[[ e ]] is just application of the function `f` but with the advantage that it doesn't look like any python or Scala syntax (so it's obviously referring to the meta-language rather than the languages we're building here). I'm going to consistently use ""distributed"" to talk about BlockMatrix-y things and ""small"" to refer to things that live in the ""value"" IR. # DistributedTensorIR. Some thoughts on TensorIR (fruits of discussion among the group):. TensorIR ::= TensorLiteral(); | TensorContract(TensorIR, TensorIR, Int, Int, body: IR); | TensorMap2(TensorIR, TensorIR, body: IR); | TensorMap(TensorIR, body: IR); | TensorSelectGlobals(TensorIR, body: IR). In the body of TensorContract and TensorMap2, four refs are free: `l`, `r`, `i`, and `j`. In the body of TensorMap, three refs are free: `e`, `i`, `j`. In the body of TensorContract, all four refs are aggregables. In the TensorMap and TensorMap2, they are scalar values. No aggregations are allowed in the body of TensorSelectGlobals. It is just `SparkContext.broadcast`. ## From Python. C[[ u @ v ]] := TensorContract(; C[[ u ]],; C[[ v ]],; 1,; 0,; hl.agg.sum(l * r)). C[[ u + v ]] := TensorMap2(; C[[ u ]],; C[[ v ]],; l + r). C[[ u + 1 ]] := TensorMap(; C[[ u ]],; e + I32(1)). C[[ u + hl.ndarray(...) ]] := TensorMap(; TensorSelectGlobals(; C[[ u ]],; uuid1,; C[[ hl.ndarray(...) ]]); e + NDArrayIndex(GetField(""globals"", uuid1), i, j)). ## Transformations. This representation admits elegant transformations:. TensorMap2(TensorMap(u, x), v, body); <=>; TensorMap2(u, v, Let(uuid1, x[l/e], body[Ref(uuid1)/l])). TensorMap(TensorMap(u, x), y); <=>; TensorMap(u, Let(uuid1, x, y[Ref(uuid1)/e])). TensorContraction(TensorMap(u, x), v, body); <=>; TensorContraction(u, v, Let(uuid1, x[l/e], body[Ref(uuid1)/l])). the ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5195:168,variab,variable,168,https://hail.is,https://github.com/hail-is/hail/issues/5195,1,['variab'],['variable']
Modifiability,"# Overview. Query on Batch fundamentally eliminates Spark in favor of Hail Batch. Each Hail pipeline starts a; single job batch which acts as the ""driver"" or ""compiler"". The driver executes new batches whenever; it encounters a parallelizeAndComputeWithIndex. You can try this branch out in your developer; namespace by executing this:. ```; hailctl dev config set default_namespace default; hailctl dev deploy --branch danking/hail:nqs-copy --steps delete_batch_tables,deploy_batch; make -C query ipython; ```. The last command compiles and uploads a JAR to GCS. These JARs are deleted in 24 hours. If you have; already uploaded a JAR for theee current SHA in the last 24 hours, you can use `make -C query; ipython-no-deps` to start a new session without uploading a new JAR. You can interact at ipython like this:. ```; In [1]: import hail as hl; ...: hl.utils.range_table(10).collect(); Initializing Hail with default parameters...; /Users/dking/projects/hail/hail/python/hail/utils/java.py:54: UserWarning: When using the query service backend, use `await Env._async_hc()'; warnings.warn('When using the query service backend, use `await Env._async_hc()\''); Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.81-edcde5c1b324; LOGGING: writing to /Users/dking/projects/hail/query/hail-20220113-1844-0.2.81-edcde5c1b324.log; Out[1]: ; [Struct(idx=0),; Struct(idx=1),; Struct(idx=2),; Struct(idx=3),; Struct(idx=4),; Struct(idx=5),; Struct(idx=6),; Struct(idx=7),; Struct(idx=8),; Struct(idx=9)]; ```. The very first time you execute this comand, it will run four batches to generate the four default; reference genomes and download those to your local machine. Those four reference genomes are cached; per-SHA on your local machine, so future Hail pipelines will have lower latency. If you have the ""standing working"" enabled, you should expect a latency of ~8s for the above job. I; think we can approximately halve this by re-using classloaders. Ask me more ab",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11194:354,config,config,354,https://hail.is,https://github.com/hail-is/hail/pull/11194,1,['config'],['config']
Modifiability,"# SRE; - The Google SRE Books https://landing.google.com/sre/books/; - Distributed Systems Observability https://www.oreilly.com/library/view/distributed-systems-observability/9781492033431/; - ""Learning to Build Distributed Systems"" http://brooker.co.za/blog/2019/04/03/learning.html; - Increment's On-Call issue https://increment.com/on-call/; # SWE; - ""Designing Data-Intensive Systems"" by Kleppman https://www.amazon.com/gp/product/1449373321/; # SEC; - ""The Confused Deputy"" http://zoo.cs.yale.edu/classes/cs422/2010/bib/hardy88confused.pdf; - ""Blueprint fo a science of cybersecurity"" http://www.cs.cornell.edu/fbs/publications/SoS.blueprint.pdf; - ""Macaroons: Cookies with Contextual Caveats for Decentralized Authorization in the Cloud"" https://ai.google/research/pubs/pub41892; - ""Native Client: A Sandbox for Portable, Untrusted x86 Native Code"" https://ai.google/research/pubs/pub34913; - What is CSRF https://www.owasp.org/index.php/Cross-Site_Request_Forgery_(CSRF); - What is XSS https://www.owasp.org/index.php/Cross-site_Scripting_(XSS); ## Containers; - gVisor Architecture Guide https://gvisor.dev/docs/architecture_guide/; - ""cgroups"" https://www.kernel.org/doc/Documentation/cgroup-v1/cgroups.txt; - ""cgroups v2"" https://github.com/torvalds/linux/blob/master/Documentation/admin-guide/cgroup-v2.rst; - ""Docker Security"" https://docs.docker.com/engine/security/security/; - ""On the security of containers"" https://medium.com/@ewindisch/on-the-security-of-containers-2c60ffe25a9e; - ""User namespaces might not be enough"" https://medium.com/@ewindisch/linux-user-namespaces-might-not-be-secure-enough-a-k-a-subverting-posix-capabilities-f1c4ae19cad; - ""OS-level virtualization"" https://en.wikipedia.org/wiki/OS-level_virtualisation; - ""Sandbox (computer security)"" https://en.wikipedia.org/wiki/Sandbox_(computer_security); - ""Making Containers More Isolated: An Overview of Sandboxed Container Technologies"" https://unit42.paloaltonetworks.com/making-containers-more-isolated-an-over",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6720:807,Sandbox,Sandbox,807,https://hail.is,https://github.com/hail-is/hail/issues/6720,2,"['Portab', 'Sandbox']","['Portable', 'Sandbox']"
Modifiability,"## Bug fixes to enable Azure deployment. Most of these bugs were discovered in deploying the MySQL server from scratch, specifically deploying version 8.0. ; Some were encountered when we hit certificate issues in trying to run the `./bootstrap.sh deploy_unmanaged` step multiple times within 24hrs. Documentation was clarified in order to resolve this issue. - build.yaml; - Step one fails on rerun since the /repo directory exists, -p to fix; - ci/create_database.py; - In MySQL 8 a new error was introduced [4006](https://dev.mysql.com/doc/mysql-errors/8.0/en/server-error-reference.html#error_er_cannot_user_referenced_as_definer); - This error gets triggered on the CREATE USER IF NOT EXISTS commands for both user and admin if the user was previously created and set a a definer on any events/triggers.; - Really this statement should be a no-op given that the user exists, but for some reason the error triggers anyway.; - To get around this I added a manual check if the user/admin exists and if they do simply skip the create user command. This fixes the bug and allows the MySQL db deploy to finish properly. - dev-docs/letsencrypt.md; - Debugging was confusing since the revoke command addressed ids we were unable to find.; - After extensive searching I added to the documentation how to find your existing cert IDs if you need to revoke them. - infra/azure/README.md; - Added clarity to the Azure deployment documentation. - infra/azure/bootstrap.sh; - Added the passing of additional flag arguments to terraform; - In our case the passing of the `-upgrade` flag to the terraform init step was required in order to continue. - infra/azure/main.tf, infra/azure/modules/batch/main.tf, infra/azure/modules/batch/variables.tf infra/azure/variables.tf; - Add additional argument for the az_storage_account.; - The name must be globally unique in Azure, so the original argument failed on our deployment since it shared the name with the Hail team's Azure deployment",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12065:1722,variab,variables,1722,https://hail.is,https://github.com/hail-is/hail/pull/12065,2,['variab'],['variables']
Modifiability,"## Change Description. Config and records relating to the appsec deployment instance. Necessary for future maintenance and management of the appsec instance. ## Security Assessment. - This change has no security impact. ### Impact Description. No impact because this relates only to the parallel appsec instance, not the main production instance. (Reviewers: please confirm the security impact before approving)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14726:23,Config,Config,23,https://hail.is,https://github.com/hail-is/hail/pull/14726,1,['Config'],['Config']
Modifiability,"## Change Description. Fixes #14597. ## Security Assessment. Delete all except the correct answer:; - This change has a high security impact; - [ ] Required: The impact has been assessed and approved by appsec; - This change has a medium security impact; - This change has a low security impact; - This change has no security impact. ### Impact Description. For none/low impact: a quick one/two sentence justification of the rating.; - Example: ""Docs only"", ""Low-level refactoring of non-security code"", etc.; For medium/high impact: provide a description of the impact and the mitigations in place.; - Example: ""New UI text field added in analogy to existing elements, with input strings escaped and validated against code injection"". (Reviewers: please confirm the security impact before approving)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14745:469,refactor,refactoring,469,https://hail.is,https://github.com/hail-is/hail/pull/14745,1,['refactor'],['refactoring']
Modifiability,"## Change Description. Fixes #<issue_number> (delete if N/A). Brief description and justification of what this PR is doing. ## Security Assessment. Delete all except the correct answer:; - This change has a high security impact; - [ ] Required: The impact has been assessed and approved by appsec; - This change has a medium security impact; - This change has a low security impact; - This change has no security impact. ### Impact Description. For none/low impact: a quick one/two sentence justification of the rating.; - Example: ""Docs only"", ""Low-level refactoring of non-security code"", etc.; For medium/high impact: provide a description of the impact and the mitigations in place.; - Example: ""New UI text field added in analogy to existing elements, with input strings escaped and validated against code injection"". (Reviewers: please confirm the security impact before approving)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14732:556,refactor,refactoring,556,https://hail.is,https://github.com/hail-is/hail/pull/14732,2,['refactor'],['refactoring']
Modifiability,## Change Description. This PR updates the tutorial instructions for running Hail on Dataproc to clarify that the Google Cloud SDK must be installed and configured before Hail can be run. I made this change to prevent future users from also needing to Google these setup instructions. ## Security Assessment. - This change has no security impact. ### Impact Description. This change only updates documentation and has no immediate end user impact. The updated documentation does not leak any proprietary / confidential / sensitive information about Hail or any related systems.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14737:153,config,configured,153,https://hail.is,https://github.com/hail-is/hail/pull/14737,1,['config'],['configured']
Modifiability,"### Background. In the world of low-level container runtimes there exists the term ""bundle"", which basically means the pair of a root filesystem and a `config.json` file containing all of the other necessary information to run the container. If you invoke `crun` or `runc` with `--bundle /path/to/bundle`, the runtime assumes the following:. - The configuration file for the container is located at `/path/to/bundle/config.json`; - That `config.json` contains a field [`root.path`](https://github.com/opencontainers/runtime-spec/blob/main/config.md#root) that specifies the location of the root filesystem, most commonly as a path relative to `/path/to/bundle`. `crun` offers a way to explicitly reference the location of `config.json` through its `--config` flag. This seems fairly innocuous, but specifying a custom `--config` path can have some unfortunate unintended consequences because it invalidates the assumption in the specification that the configuration resides at `/path/to/bundle/config.json`. Specifically, it breaks [Hooks](https://github.com/opencontainers/runtime-spec/blob/main/config.md#posix-platform-hooks). When a hook is run, the runtime (crun) feeds it the [container state](https://github.com/opencontainers/runtime-spec/blob/main/runtime.md#state), a JSON of information about the container including the `bundle` path. Any hook that attempts to load the `config.json`, like for example, the `nvidia-container-runtime-hook`, will crash. ### Change. This change stops using the `--config` flag for crun and instead does the following to create a well-formed bundle:. - Instead of the bundle being the merged directory of the container overlay, it is the container's scratch directory; - `root.path` is adjusted inside of `config.json` to now point to the merged directory of the container overlay. I've opted to use an absolute path here because why use a relative path.; - Move `config.json` into the container scratch directory so that it is inside the root of the bundle d",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13438:152,config,config,152,https://hail.is,https://github.com/hail-is/hail/pull/13438,10,['config'],"['config', 'configuration']"
Modifiability,"### Change Description. This change exists as part of larger refactoring work. Herein, I've exchanged; hard-coded contextual strings passed to `ExecutionTimer.time` with implict; contexts, drawing inspiration from scalatest. These contexts are now supplied after entering functions like `Compile` and; `Emit` instead of before (see `ExecuteContext.time`). By sprinking calls to ; `time` throughout the codebase after entering functions, we obtain a nice trace; of the timings with `sourcecode.Enclosing`, minus the previous verbosity. See [1] for more information about what pre-built macros are available. We can; always build our own later. See comments in [pull request id] for example output.; Note that `ExectionTimer.time` still accepts a string to support uses like; `Optimise` and `LoweringPass` where those contexts are provided already.; It is also exception-safe now. This change exposed many similarities between the implementations of query; execution across all three backends. I've stopped short of full unification; which is a greater work, I've instead simplified and moved duplicated result; encoding into the various backend api implementations. More interesting changes are to `ExecuteContext`, which now supports; - `time`, as discussed above; - `local`, a generalisation for temporarily overriding properties of an ; `ExecuteContext` (inspired by [2]). While I've long wanted this for testing,; we were doing some questionable things when reporting timings back to python,; for which locally overriding the `timer` of a `ctx` has been very useful.; We also follow this pattern for local regions. [1] https://github.com/com-lihaoyi/sourcecode; [2] https://hackage.haskell.org/package/mtl-2.3.1/docs/Control-Monad-Reader.html#v:local. ### Security Assessment. This change has no security impact as it's confined to refactoring of existing non-security-related code.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14683:61,refactor,refactoring,61,https://hail.is,https://github.com/hail-is/hail/pull/14683,2,['refactor'],['refactoring']
Modifiability,"### Description. In this pull request, I add a convenience method to dummy-code categorical variables in a matrix table. See the [dummy variable Wikipedia article](https://en.m.wikipedia.org/wiki/Dummy_variable_(statistics)) for background. This pull request closes #13601. ### Testing. I add a unit test. For the documentation changes, I built the documentation locally and manually inspected the output to confirm that the documentation appears as expected.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14269:92,variab,variables,92,https://hail.is,https://github.com/hail-is/hail/pull/14269,2,['variab'],"['variable', 'variables']"
Modifiability,"### Description. In this pull request, I add a function to perform a Cochran-Mantel-Haenszel statistical test for association. This pull request closes #13481. ### Testing. I add unit tests. Since I have not used R before (the [associated GitHub issue](https://github.com/hail-is/hail/issues/13481) suggests using R to create test cases), I created the unit tests from examples that I found on the internet. I linked these sources in the code for the unit tests. I built the documentation locally and inspected it to confirm that it matches my expectations. I am having trouble testing the docstring examples locally. When I run `make -C hail doctest-query`, the tests error due to a checksum exception. ### Discussion. ~I have not added an example to the documentation that uses a matrix table yet. (This is an acceptance criteria in #13481.) I wanted to get some advice about the best way to do this. I think ideally, the example would have a binary phenotype, an allele to test for association, and some stratifying variable. I tried to search through the existing code to find suitable example matrix tables in the docstrings, but I didn't find anything promising. I would appreciate help here.~. Update: thanks to @patrick-schultz's recommendation, I have added an example using a matrix table.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14255:1019,variab,variable,1019,https://hail.is,https://github.com/hail-is/hail/pull/14255,1,['variab'],['variable']
Modifiability,"### Description. In this pull request, I change the implementation of the `MatrixTable.show` method. Previously, `show` would create a table and then show the table by reusing the table implementation of `show`. The problem with the existing implementation is that it creates row fields in the table for all of the entries in the matrix table. This new implementation directly shows the matrix table by creating a table and displaying the information in the table. I make some refactoring changes in this pull request as well that helped me understand the code and will hopefully help others as well. ### Testing. I add some unit tests.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14250:477,refactor,refactoring,477,https://hail.is,https://github.com/hail-is/hail/pull/14250,1,['refactor'],['refactoring']
Modifiability,"### Hail version: ; 0.1-74bf1eb. ### What you did: ; Export vcf to local file:// path. ### What went wrong (all error messages here, including the full java stack trace): ; When exporting vcf to path that begins with 'file://', I get the error: `ClassNotFoundException: Class org.apache.hadoop.mapred.DirectFileOutputCommitter not found`. I am using Spark 2.2.1 (prebuilt with hadoop2.7) with AWS-Hadoop 2.7.4. I have the following settings in spark config and am using a custom directParquetOutputCommitter. Standard writes to 'file://' of Spark dataframes work without issue. Thanks for any help!. ```; spark.sql.parquet.output.committer.class org.apache.spark.sql.parquet.DirectParquetOutputCommitter; spark.hadoop.mapred.output.committer.class org.apache.hadoop.mapred.DirectFileOutputCommitter; spark.hadoop.mapreduce.use.directfileoutputcommitter true; spark.hadoop.spark.sql.parquet.output.committer.class org.apache.spark.sql.parquet.DirectParquetOutputCommitter; ```. Code and stack trace:; ```; ================================================================================================== FAILURES ===================================================================================================; __________________________________________________________________________________________ TestHAIL.test_export_vcf ___________________________________________________________________________________________. self = <test_hail.TestHAIL testMethod=test_export_vcf>. def test_export_vcf(self):; # define files; bgen_file = os.path.join(self.testdir, 'example.10bits.bgen'); sample_file = os.path.join(self.testdir, 'example.sample'); # make index; self.hc.index_bgen(bgen_file); # load to vds; bgen_vds = self.hc.import_bgen(bgen_file, sample_file=sample_file); # export vcf; out_path = 'file://' + os.path.join(self.tmpdir, 'test_vcf_export.vcf.bgz'); > bgen_vds.export_vcf(out_path, export_pp=False, parallel=False). tests/hail/test_hail.py:55:; _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3946:450,config,config,450,https://hail.is,https://github.com/hail-is/hail/issues/3946,1,['config'],['config']
Modifiability,"### Hail version:; 0.1 only - this already works in 0.2. ### What you did:; I'm calling kt.export_elasticsearch(..) on this keytable schema:. ```; ...; aIndex: Int,; alt: String,; codingGeneIds: Set[String],; contig: String,; docId: String,; domains: Set[String],; end: Int,; filters: Set[String],; geneIds: Set[String],; pos: Int,; ref: String,; rsid: String,; start: Int,; variantId: String,; vep: Array[Struct{; gene_id: String,; gene_symbol: String,; protein_id: String,; transcript_id: String,; hgvs: String,; major_consequence: String,; major_consequence_rank: Int,; category: String; }],; wasSplit: Boolean,; ```. ### What went wrong (all error messages here, including the full java stack trace):. Having `vep: Array[Struct..]` in the schema leads to . ```; 2018-09-02 07:06:06,821 INFO ==> exporting data to elasticasearch. Write mode: upsert, blocksize: 1000; Config Map(es.batch.size.entries -> 1000, es.index.auto.create -> true, es.mapping.id -> docId, es.write.operation -> upsert, es.port -> 9200, es.nodes -> 10.56.10.4); [Stage 3:> (0 + 100) / 1000]Traceback (most recent call last):; File ""/tmp/ffc9fb0b99f64080b674ab7a07962df9/load_dataset_to_es.py"", line 734, in <module>; run_pipeline(); File ""/tmp/ffc9fb0b99f64080b674ab7a07962df9/load_dataset_to_es.py"", line 726, in run_pipeline; hc, vds = step2_export_to_elasticsearch(hc, vds, args); File ""/tmp/ffc9fb0b99f64080b674ab7a07962df9/load_dataset_to_es.py"", line 565, in step2_export_to_elasticsearch; disable_index_for_fields=(""sortedTranscriptConsequences"", ),; File ""/tmp/ffc9fb0b99f64080b674ab7a07962df9/load_dataset_to_es.py"", line 358, in export_to_elasticsearch; verbose=True,; File ""/tmp/ffc9fb0b99f64080b674ab7a07962df9/hail_scripts.zip/hail_scripts/v01/utils/elasticsearch_client.py"", line 140, in export_vds_to_elasticsearch; File ""/tmp/ffc9fb0b99f64080b674ab7a07962df9/hail_scripts.zip/hail_scripts/v01/utils/elasticsearch_client.py"", line 287, in export_kt_to_elasticsearch; File ""<decorator-gen-143>"", line 2, in expo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4250:870,Config,Config,870,https://hail.is,https://github.com/hail-is/hail/issues/4250,1,['Config'],['Config']
Modifiability,"### Stacked PR; Stacks on #5429, adding the scss that was excluded from that PR. I separated them to make the story a bit cleaner. When #5429 is approved, this PR will contain 3 lines of change to index.html, 5 to notebook.py (to compile scss css), 1 to environment.yml (to include libsass), 1 to gitignore (to ignore the compiled css). The remaining 437 lines are the top-scope styles (margins, buttons that are frequently re-used, etc), the header styles, and styles for the login and notebook pages. We can exclude login page in this PR, but it only adds ~ 12 lines. Some of the global SCSS we will be able to removed later this week, once we understand which pieces we truly don't need. I can also remove them now if needed, but we won't have a single ""styles"" PR. ### SCSS vs CSS; I find SCSS preferable to CSS because it makes style scoping and re-use easier. For instance, we may define a variable $margin, to standardize spacing across all pages, and $color to define a font color for all text. SCSS can be written identically to css if the developer is totally unfamiliar or doesn't have time to learn. My style scoping solution is reminiscent of [BEM](http://getbem.com/introduction/). Each page defines an ID, and any styles that are private to that page are scope that way `#page { ...styles }` in the corresponding `pages/page.scss`. It is lightweight (no additional tooling needed), and should be easy to follow. cc @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5430:896,variab,variable,896,https://hail.is,https://github.com/hail-is/hail/pull/5430,1,['variab'],['variable']
Modifiability,"### What happened?. # Problem. A user submitted a Hail Batch batch which read from a bucket whose storage class was ""Archive"". This produced a large unexpected spend because Archive class objects cost 0.05 USD per GB whereas Standard class objects are free. # Solution. Hail Batch and Hail Query should collect the set of buckets which were used as reads, imports, input files, or temporary intermediates and assert that the bucket default storage class is the standard class / hot tier. In Google this is called the [Standard storage class](https://cloud.google.com/storage/docs/storage-classes#standard). In Azure, this is called the [Hot tier](https://learn.microsoft.com/en-us/azure/storage/blobs/access-tiers-overview?tabs=azure-portal). A user should be able to explicitly override this setting with an allowlist. The allowlist should be initialized using Hail's [standard configuration system](https://github.com/hail-is/hail/blob/48d7b5cfbf9a2231d72dd0a1a682da28422fde4b/hail/python/hailtop/config/user_config.py#L42). In Hail Query, this allowlist should be a setting on `hl.init`. In Hail Batch, it should be a setting on `ServiceBackend`. ### Version. 0.2.115. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13003:879,config,configuration,879,https://hail.is,https://github.com/hail-is/hail/issues/13003,2,['config'],"['config', 'configuration']"
Modifiability,"### What happened?. > In regards to the https vs hail-az, I get an error for https:; > hailctl config set batch/remote_tmpdir https://kahlquisrefsa.blob.core.windows.net/test; > Error: bad value 'https://kahlquisrefsa.blob.core.windows.net/test' for parameter 'batch/remote_tmpdir' should be valid cloud storage URI such as gs://my-bucket/batch-tmp/. ### Version. 0.2.116. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13049:95,config,config,95,https://hail.is,https://github.com/hail-is/hail/issues/13049,1,['config'],['config']
Modifiability,"### What happened?. @jkgoodrich requested this. It appears to be a fairly straightforward manipulation of the four variables. Hail already has the chi-squared CDF. I think we can implement this entirely in Python. Acceptance criteria:; - Tests comparing the results to results from R. Ensure we have tests for small, intermediate, and large p-values.; - Method should accept at least the four parameters and they should be named a, b, c, and d.; - Method should return the test statistics as well as its p-value (i.e. the value of the chi-squared CDF at the test statistic); - Docs should include concrete examples with explicit values.; - Docs should include an example of using it in a Hail table.; - . References:; - http://www.biostathandbook.com/cmh.html; - https://en.wikipedia.org/wiki/Cochran–Mantel–Haenszel_statistics; - https://cran.r-project.org/web/packages/samplesizeCMH/vignettes/samplesizeCMH-introduction.html. ### Version. 0.2.120. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13481:115,variab,variables,115,https://hail.is,https://github.com/hail-is/hail/issues/13481,1,['variab'],['variables']
Modifiability,"### What happened?. After #13440 lands, we should be guaranteed that `ubuntu:22.04` exists inside the internal docker registry. Then, we need to update the `docker_root_image` field in the `global-config` to use `ubuntu:22.04` instead of `ubuntu:20.04`. Doing so requires the following:. 1. A PR that updates the terraform in `infra/azure` and `infra/gcp` to use `ubuntu:22.04` in the global-config. The azure terraform should be applied against `haildev`.; 2. Manually editing the `global-config` in `hail-vdc` to switch `docker_root_image` to `ubuntu:22.04`.; 3. A follow up PR once the global-configs are updated that removes `ubuntu:20.04` from `docker/third-party/images.txt`. ### Version. 0.2.120. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13545:197,config,config,197,https://hail.is,https://github.com/hail-is/hail/issues/13545,4,['config'],"['config', 'configs']"
Modifiability,"### What happened?. After I ran the ""make install-on-cluster HAIL_COMPILE_NATIVES=1 SCALA_VERSION=2.12.18 SPARK_VERSION=3.5.0"", I get the following error. > Configure project :; WARNING: Hail primarily tested with Spark 3.3.2, use other versions at your own risk. > Task :compileScala; [Error] /gpfs/fs1/home/jl/Hail2/hail/hail/src/main/scala/is/hail/HailContext.scala:127:21: value implOpMulMatrix_DMD_DVD_eq_DVD is not a member of object breeze.linalg.DenseMatrix; one error found. > Task :compileScala FAILED. FAILURE: Build failed with an exception. * What went wrong:; Execution failed for task ':compileScala'.; > Compilation failed. * Try:; > Run with --info option to get more log output.; > Run with --scan to get full insights. BUILD FAILED in 4m 52s; 2 actionable tasks: 2 executed; make: *** [build/libs/hail-all-spark.jar] Error 1. ### Version. Hail 0.2.13. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14235:157,Config,Configure,157,https://hail.is,https://github.com/hail-is/hail/issues/14235,1,['Config'],['Configure']
Modifiability,"### What happened?. After sorting our costs into ""cost of goods"", ""operating expenses"", and ""capital expenses"", I realized there are four ""operating expenses"" that are not tracked and reported with the other expenses. I regressed these costs against the core-hours to estimate the cost per core-hour. resource | intercept (USD) | cost (USD/core-hour); -- | -- | --; GCP Support Variable fee | 3.46403 +- 0.49155 | 0.00123 +- 0.00007; System logs costs SKU#1 | 13.09991 +- 3.13991 | 0.00093 +- 0.00039; System logs costs SKU#2 | 7.87838 +- 0.81695 | 0.00027 +- 0.00012; Job specifications | 5.41150 +- 0.36608 | 0.00025 +- 0.00005; Firewall policy | 0.51216 +- 0.03185 | 0.00012 +- 0.00000. To fully recover the operating expenses at our current revenue, we need an additional 0.005 USD per core-hour (which is 0.002 more than the sum of intercepts). This issue is complete after we add a new product:. resource | cost (USD/core-hour); -- | --; support-logs-specs-and-firewall-fees/1 | 0.005. ### Version. 0.2.120. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13526:378,Variab,Variable,378,https://hail.is,https://github.com/hail-is/hail/issues/13526,1,['Variab'],['Variable']
Modifiability,"### What happened?. Although it is not possible to avoid all cross-region access (and thus costs), there are some obvious preventable misuses. For example, the following pipeline should error:. ```; b = hb.Batch(regions=['us-east1']); x = b.read_input('gs://bucket-in-central1/'); b.new_job(f'cat {x}'); b.run(); ```; But the following pipeline should not error:; ```; b = hb.Batch(regions=['us-east1']); x = b.read_input('gs://bucket-in-central1/'); j = b.new_job(f'cat {x}'); j.regions(['us-central1']); ```; The following should error because the job *could* be in us-east1:; ```; b = hb.Batch(regions=['us-east1', 'us-central1']); x = b.read_input('gs://bucket-in-central1/'); b.new_job(f'cat {x}'); b.run(); ```; The following should error:; ```; b = hb.Batch(regions=['us-east1']) # remote_tmpdir is set in config file as a us-centra1 bucket; j = b.new_job(f'echo hi > {j.f}'); j2 = b.new_job(f'cat {j.f}'); b.run(); ```. ### Version. 0.2.119. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13232:813,config,config,813,https://hail.is,https://github.com/hail-is/hail/issues/13232,1,['config'],['config']
Modifiability,"### What happened?. At time of writing, building hail with `SPARK_VERSION=3.4.0` errors with the following message:. ```; hail/src/main/scala/is/hail/HailContext.scala:119:21: value implOpMulMatrix_DMD_DVD_eq_DVD is not a member of object breeze.linalg.DenseMatrix; ```. This is due to a major version upgrade and breaking change in the Breeze library on which spark and hail depend. The exact error is a rename and refactor. The method `DenseMatrix.implOpMulMatrix_DMD_DVD_eq_DVD` is now `HasOps.impl_OpMulMatrix_DMD_DVD_eq_DVD`. Notice the method name change and the fact that `HasOps` does not exist in the version of Breeze (1.x) that is used in Spark 3.3. Hail should build with Spark 3.4, but since we only officially support one version of Spark (whichever Dataproc currently is running), it would be reasonable to wait to fully upgrade to Spark 3.4 when [Dataproc 2.2](https://cloud.google.com/dataproc/docs/concepts/versioning/dataproc-release-2.2) is GA instead of trying to do something hacky to support both versions of Breeze. ### Version. 0.2.126. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13971:416,refactor,refactor,416,https://hail.is,https://github.com/hail-is/hail/issues/13971,1,['refactor'],['refactor']
Modifiability,"### What happened?. CI records during heal loops which PR is the current merge candidate. However, this stashed variable does not ultimately govern merge order (it uses `prs_in_merge_priority_order`). If someone applies `prio:high` this can cause a mismatch between who is actually going to be merged next and who was the first line during the last heal. Instead of storing the merge candidate, it would be more informative if the CI page could instead display the first mergeable PR in `prs_in_merge_priority_order` (basically the first one that `try_to_merge` *would* select). ### Version. 0.2.124. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13746:112,variab,variable,112,https://hail.is,https://github.com/hail-is/hail/issues/13746,1,['variab'],['variable']
Modifiability,"### What happened?. Categorical data requires the user to preprocess their data. The subtle distinctions between dummy coding and one-hot encoding are not obvious to all users. We should provide a simple method, clear docs, and clear examples to ease the analysis of categorical variables. Here's a prototype implementation; ```python3; def dummy_code(mt: hl.MatrixTable, *fields: str) -> DummyCode:; field_categories = mt.aggregate_cols(**{; field: hl.agg.collect_as_set(mt[field]) for field in fields; }). dummy_codes = {; f'{field}_{category}': mt[field] == c; for field in field_categories; for category in field_categories[field]; }. mt = mt.annotate_cols(**dummy_codes). dummy_code_fields = list(dummy_codes). return field_categories, dummy_code_fields, mt. # Example. _, dummy_code_fields, mt = hl.dummy_code(mt, 'breed', 'color'); mt = hl.linear_regression_rows(; x=mt.GT.n_alt_alleles(),; y=[1.0, *dc.dummy_code_fields]; ). ```. References; - How to handle categorical manually in Hail. https://discuss.hail.is/t/how-do-i-include-a-categorical-variable-as-a-covariate-in-my-logistic-or-linear-regression/1362; - Dummy coding vs one-hot encoding. https://stats.stackexchange.com/questions/224051/one-hot-vs-dummy-encoding-in-scikit-learn; - A recent user request for this feature. https://hail.zulipchat.com/#narrow/stream/123010-Hail-Query-0.2E2-support/topic/categorical.20covariates.20in.20regression. ### Version. 0.2.122. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13601:279,variab,variables,279,https://hail.is,https://github.com/hail-is/hail/issues/13601,2,['variab'],"['variable-as-a-covariate-in-my-logistic-or-linear-regression', 'variables']"
Modifiability,"### What happened?. Consider adding support for GPUs. This requires changes to the frontend, the driver, and the worker. In particular, getting the worker configuration correct is tricky. We could develop faster if we had a fully local version of Batch development. For example, consider starting a linux VM which had separate containers running: auth, batch, batch-driver, mysql, and a single worker. Each container could live update changes to the source code. Such a system should also work on OS X, although the networking may be more complicated due to the Linux VM. It might be easier to just expect developers to have a separately managed Linux VM on their Mac?. ### Version. 0.2.122. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13630:155,config,configuration,155,https://hail.is,https://github.com/hail-is/hail/issues/13630,1,['config'],['configuration']
Modifiability,"### What happened?. Currently, if you try to pass `--project` to `hailctl dataproc submit`, it still tries to use the project configured via `gcloud config`, and passes through the value specified for `--project` in the `pass_through_args`. An example command where the project is ignored on `main` is:. ```bash; hailctl dataproc submit test.py --region us-central1 --project broad-ctsa; ```. ### Version. 0.2.132. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14647:126,config,configured,126,https://hail.is,https://github.com/hail-is/hail/issues/14647,2,['config'],"['config', 'configured']"
Modifiability,"### What happened?. Currently, in order to change the rate limit in `internal-gateway`, one has to manually edit `envoy.py` and redeploy CI. This is non-standard, time intensive and can be accidentally reverted if CI merges a new commit to `main`. CI already regularly updates the envoy configuration `internal-gateway` uses to account for services in new namespaces, so making the rate limit configurable should be a simple CRUD task that would greatly ease operation of batch under high load. One gotcha to keep in mind is that while we run CI as a control plane for our ""dynamic cluster topology"", it should still be possible to manually deploy `internal-gateway` in a standalone Batch cluster (see `internal-gateway/Makefile`), so `envoy.py` should still be runnable as a standalone script. ### Version. 0.2.128. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14399:287,config,configuration,287,https://hail.is,https://github.com/hail-is/hail/issues/14399,2,['config'],"['configurable', 'configuration']"
Modifiability,### What happened?. Details here: https://discuss.hail.is/t/subset-matrix-table-to-a-medium-sized-list-of-variants/3362/5. ```; Java stack trace:; java.lang.ClassCastException: class org.apache.spark.sql.catalyst.expressions.GenericRow cannot be cast to class is.hail.variant.Locus (org.apache.spark.sql.catalyst.expressions.GenericRow is in unnamed module of loader 'app'; is.hail.variant.Locus is in unnamed module of loader org.apache.spark.util.MutableURLClassLoader @62435e70); at is.hail.expr.JSONAnnotationImpex$.exportAnnotation(AnnotationImpex.scala:124); at is.hail.expr.JSONAnnotationImpex$.$anonfun$exportAnnotation$5(AnnotationImpex.scala:129); at is.hail.expr.JSONAnnotationImpex$.$anonfun$exportAnnotation$5$adapted(AnnotationImpex.scala:128); at scala.collection.generic.GenTraversableFactory.tabulate(GenTraversableFactory.scala:150); at is.hail.expr.JSONAnnotationImpex$.exportAnnotation(AnnotationImpex.scala:128); at is.hail.types.virtual.Type.toJSON(Type.scala:184); at is.hail.expr.JSONAnnotationImpex$.$anonfun$exportAnnotation$4(AnnotationImpex.scala:125); at is.hail.utils.Interval.toJSON(Interval.scala:103); at is.hail.expr.JSONAnnotationImpex$.exportAnnotation(AnnotationImpex.scala:125); at is.hail.expr.JSONAnnotationImpex$.$anonfun$exportAnnotation$1(AnnotationImpex.scala:113); at scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:238); at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36); at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:38); at scala.collection.TraversableLike.map(TraversableLike.scala:238); at scala.collection.TraversableLike.map$(TraversableLike.scala:231); at scala.collection.AbstractTraversable.map(Traversable.scala:108); at is.hail.expr.JSONAnnotationImpex$.exportAnnotation(AnnotationImpex.scala:113); at is.hail.expr.ir.Pretty.header(Pretty.scala:405); at is.hail.expr.ir.Pretty.pretty$1(Pretty,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13046:723,adapt,adapted,723,https://hail.is,https://github.com/hail-is/hail/issues/13046,1,['adapt'],['adapted']
Modifiability,"### What happened?. Follow up on #13445 - I almost succeed to install hail on AWS but still have some environment issue:. * I am trying to install Hail v0.2.124; * on AWS EMR v6.9.1 (latest version with Spark 3.3.0 suggested on hail doc); * I upgrade to python 3.9.18; ```sh; $ python --version; Python 3.9.18; ```; I activate java 11.0.20.1; ```sh; $ java -version; openjdk version ""11.0.20.1"" 2023-08-22 LTS; OpenJDK Runtime Environment Corretto-11.0.20.9.1 (build 11.0.20.1+9-LTS); OpenJDK 64-Bit Server VM Corretto-11.0.20.9.1 (build 11.0.20.1+9-LTS, mixed mode); ```; * I clone hail; ```sh; $ cd /tmp; $ git clone --branch 0.2.124 --depth 1 https://github.com/broadinstitute/hail.git; ```; * I build hail; ```sh; $ cd hail/hail/; $ make install-on-cluster HAIL_COMPILE_NATIVES=1 SCALA_VERSION=2.12.15 SPARK_VERSION=3.3.0; [...]; Successfully installed hail-0.2.124; hailctl config set query/backend spark; ```; * At this point Hail seems correcly installed; ```sh; $ pip show hail; Name: hail; Version: 0.2.124; Summary: Scalable library for exploring and analyzing genomic data.; Home-page: https://hail.is; Author: Hail Team; Author-email: hail@broadinstitute.org; License: UNKNOWN; Location: /home/hadoop/.local/lib/python3.9/site-packages; ```; * For sake of configuration I create a symlink of the hail backend; ```sh; sudo ln -sf /home/hadoop/.local/lib/python3.9/site-packages/hail/backend /opt/hail/backend; ```; * Confident of the. installation I try to run spark shell; ```sh; $ spark-shell; [...]; Exception in thread ""main"" java.lang.NoSuchMethodError: 'scala.reflect.internal.settings.MutableSettings ; ```. I am out of idea on how to solve the current situation. ; Thanks. ### Version. 0.2.124. ### Relevant log output. ```shell; $ spark-shell; SLF4J: No SLF4J providers were found.; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See https://www.slf4j.org/codes.html#noProviders for further details.; SLF4J: Class path contains SLF4J bindings targeting slf4j",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13837:879,config,config,879,https://hail.is,https://github.com/hail-is/hail/issues/13837,1,['config'],['config']
Modifiability,"### What happened?. From [zulip](https://hail.zulipchat.com/#narrow/channel/123010-Hail-Query-0.2E2-support/topic/StreamConstraintsException.20issue.20persisting.20in.200.2E2.2E133/near/480572744). When initializing a QoB job, we parse the input json (as it contains the `rpcConfig`) before initializing a `ServiceBackend`, however as of #14651 we are setting this limit in the `Backend` constructor itself. This represents a regression from #14567. https://github.com/hail-is/hail/blob/3fa74f091fe0eb8c0f0a24c2a0bad124f5d54da6/hail/src/main/scala/is/hail/backend/service/ServiceBackend.scala#L458-L472. The solution is probably to restore this override in `ServiceBackendAPI.main`, or alternatively, refactor so that we create the `ServiceBackend` instance earlier. ### Version. 0.2.133. ### Relevant log output. ```shell; 2024-11-05 02:43:37.202 JVMEntryway: INFO: is.hail.JVMEntryway received arguments:; 2024-11-05 02:43:37.202 JVMEntryway: INFO: 0: /hail-jars/gs:__hail-query-daaf463550_jars_4c60fddb171a52c21f41a81995c53a28e375c26b.jar.jar; 2024-11-05 02:43:37.202 JVMEntryway: INFO: 1: is.hail.backend.service.Main; 2024-11-05 02:43:37.202 JVMEntryway: INFO: 2: /batch/990e17d5209d429196c84ce010acab9d; 2024-11-05 02:43:37.202 JVMEntryway: INFO: 3: /batch/990e17d5209d429196c84ce010acab9d/log; 2024-11-05 02:43:37.202 JVMEntryway: INFO: 4: gs://hail-query-daaf463550/jars/4c60fddb171a52c21f41a81995c53a28e375c26b.jar; 2024-11-05 02:43:37.202 JVMEntryway: INFO: 5: driver; 2024-11-05 02:43:37.202 JVMEntryway: INFO: 6: execute(...); 2024-11-05 02:43:37.202 JVMEntryway: INFO: 7: gs://cpg-bioheart-hail/batch-tmp/tmp/hail/sRjJqvkZ3l9nmKuUErfNZv/jHpWQ6lemx/in; 2024-11-05 02:43:37.202 JVMEntryway: INFO: 8: gs://cpg-bioheart-hail/batch-tmp/tmp/hail/sRjJqvkZ3l9nmKuUErfNZv/jHpWQ6lemx/out; 2024-11-05 02:43:37.202 JVMEntryway: INFO: Yielding control to the QoB Job.; 2024-11-05 02:43:37.206 ServiceBackendAPI$: INFO: BatchClient allocated.; 2024-11-05 02:43:37.207 ServiceBackendAPI$: INFO: BatchCon",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14749:701,refactor,refactor,701,https://hail.is,https://github.com/hail-is/hail/issues/14749,1,['refactor'],['refactor']
Modifiability,### What happened?. I've been waiting to delete temporary files used for swapping the VEP reference files to ones that are indexed. These shouldn't be needed any longer. I wanted to wait until the new indexed VEP files have gotten more use and we have confirmation there are no issues in case we need to quickly swap anything back to the original configuration. The files to be deleted are:. ```; gs://hail-qob-vep-grch38-us-central1/95_GRCh38_indexed.tar # this is just a backup for the new indexed dataproc files. This file is in all of the dataproc VEP buckets already; gs://hail-qob-vep-grch38-us-central1/homo_sapiens_backup/ # these are the original unindexed reference files; gs://hail-qob-vep-grch38-us-central1-test/ # this was just used for staging. should be okay to just delete; ```. ### Version. 0.2.128. ### Relevant log output. _No response_,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14414:347,config,configuration,347,https://hail.is,https://github.com/hail-is/hail/issues/14414,1,['config'],['configuration']
Modifiability,"### What happened?. In broad-gcp/main.tf, we explicitly list the regions which have VPC networks. This is wrong. We should use the `batch_gcp_regions` terraform variable. This was an oversight on my part when I first created this. ### Version. 0.2.124. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13790:161,variab,variable,161,https://hail.is,https://github.com/hail-is/hail/issues/13790,1,['variab'],['variable']
Modifiability,"### What happened?. In older versions of hail (tested with 0.2.115), when starting a dataproc cluster with VEP, e.g.; ```{bash}; hailctl dataproc start hail-test --region australia-southeast1 --project my-project --vep GRCh38 --packages gnomad --num-workers 2; ```; the dataproc cluster command would be provided the following environment variable through the `--metadata` flag: `VEP_REPLICATE=aus-sydney`. This variable is used within the script `gs://hail-common/hailctl/dataproc/0.2.115/vep-GRCh38.sh` to determine which bucket to pull the VEP cache data from. In more recent versions (tested with 0.2.130), this `VEP_REPLICATE` variable has been changed to `VEP_REPLICATE=australia-southeast1`, however the Australian bucket containing the VEP cache data is still `aus-sydney`, meaning that the VEP data is not copied into the dataproc cluster, and when trying to run VEP I get the error `No cache found for homo_sapiens, version 95`. ### Version. 0.2.130. ### Relevant log output. ```shell; FatalError: HailException: VEP command '/vep --format vcf --json --everything --allele_number --no_stats --cache --offline --minimal --assembly GRCh38 --fasta /opt/vep/.vep/homo_sapiens/95_GRCh38/Homo_sapiens.GRCh38.dna.toplevel.fa.gz --plugin LoF,loftee_path:/opt/vep/Plugins/,gerp_bigwig:/opt/vep/.vep/gerp_conservation_scores.homo_sapiens.GRCh38.bw,human_ancestor_fa:/opt/vep/.vep/human_ancestor.fa.gz,conservation_file:/opt/vep/.vep/loftee.sql --dir_plugins /opt/vep/Plugins/ -o STDOUT' failed with non-zero exit status 2; VEP Error output:; Smartmatch is experimental at /opt/vep/Plugins/de_novo_donor.pl line 175.; Smartmatch is experimental at /opt/vep/Plugins/de_novo_donor.pl line 214.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 191.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 194.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 238.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 241",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14513:339,variab,variable,339,https://hail.is,https://github.com/hail-is/hail/issues/14513,3,['variab'],['variable']
Modifiability,"### What happened?. It seems like the event loop policy has changed again. ### Version. 0.2.126. ### Relevant log output. ```shell; (base) dking@wm28c-761 hail % HAIL_QUERY_BACKEND=service ipython; Python 3.10.9 (main, Jan 11 2023, 09:18:18) [Clang 14.0.6 ]; Type 'copyright', 'credits' or 'license' for more information; IPython 8.18.1 -- An enhanced Interactive Python. Type '?' for help. In [1]: import hail as hl. In [2]: hl.init(); /Users/dking/miniconda3/lib/python3.10/site-packages/hail/context.py:350: UserWarning: The ""service"" backend is now called the ""batch"" backend. Support for ""service"" will be removed in a future release.; warnings.warn(; ---------------------------------------------------------------------------; RuntimeError Traceback (most recent call last); File ~/miniconda3/lib/python3.10/site-packages/hailtop/hail_event_loop.py:12, in hail_event_loop(); 11 try:; ---> 12 asyncio.get_running_loop(); 13 nest_asyncio.apply(). RuntimeError: no running event loop. During handling of the above exception, another exception occurred:. RuntimeError Traceback (most recent call last); Cell In[2], line 1; ----> 1 hl.init(). File <decorator-gen-1760>:2, in init(sc, app_name, master, local, log, quiet, append, min_block_size, branching_factor, tmp_dir, default_reference, idempotent, global_seed, spark_conf, skip_logging_configuration, local_tmpdir, _optimizer_iterations, backend, driver_cores, driver_memory, worker_cores, worker_memory, gcs_requester_pays_configuration, regions, gcs_bucket_allow_list). File ~/miniconda3/lib/python3.10/site-packages/hail/typecheck/check.py:587, in _make_dec.<locals>.wrapper(__original_func, *args, **kwargs); 584 @decorator; 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_). File ~/miniconda3/lib/python3.10/site-packages/hail/context.py:357, in init(sc, app_name, maste",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14099:343,enhance,enhanced,343,https://hail.is,https://github.com/hail-is/hail/issues/14099,1,['enhance'],['enhanced']
Modifiability,"### What happened?. Julia Sealock reported this https://hail.zulipchat.com/#narrow/stream/123010-Hail-Query-0.2E2-support/topic/vep.20issue/near/352790173. We also saw it in test_dataproc. Cal also reported it.; ```; org.apache.spark.SparkException: Job aborted due to stage failure: Task 56 in stage 4.0 failed 20 times, most recent failure: Lost task 56.19 in stage 4.0 (TID 48622) (jsealock-schema-sw-43bq.c.daly-neale-sczmeta.internal executor 3): is.hail.utils.HailException: VEP command '/vep --format vcf --json --everything --allele_number --no_stats --cache --offline --minimal --assembly GRCh38 --fasta /opt/vep/.vep/homo_sapiens/95_GRCh38/Homo_sapiens.GRCh38.dna.toplevel.fa.gz --plugin LoF,loftee_path:/opt/vep/Plugins/,gerp_bigwig:/opt/vep/.vep/gerp_conservation_scores.homo_sapiens.GRCh38.bw,human_ancestor_fa:/opt/vep/.vep/human_ancestor.fa.gz,conservation_file:/opt/vep/.vep/loftee.sql --dir_plugins /opt/vep/Plugins/ -o STDOUT' failed with non-zero exit status 125; VEP Error output:; docker: Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?.; See 'docker run --help'. 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:17); 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:17); 	at is.hail.utils.package$.fatal(package.scala:78); 	at is.hail.methods.VEP$.waitFor(VEP.scala:73); 	at is.hail.methods.VEP.$anonfun$execute$5(VEP.scala:231); 	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490); 	at is.hail.utils.richUtils.RichContextRDD$$anon$1.hasNext(RichContextRDD.scala:69); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490); 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490); 	at scala.collectio",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12936:691,plugin,plugin,691,https://hail.is,https://github.com/hail-is/hail/issues/12936,3,"['Plugin', 'plugin']","['Plugins', 'plugin']"
Modifiability,"### What happened?. Motivated by: https://hail.zulipchat.com/#narrow/stream/128581-Cloud-support/topic/bucket.20regions.20and.20hail.20batch. New users or users in new environments (such as a new laptop) may have not yet configured their batch/regions. This can lead to unexpected egress if jobs land in a region different from their data. Forcing the user to make an explicit choice might alleviate this issue a bit. On the other hand, a user might make one explicit choice and then forget to modify that choice later when a new project begins with data in a new location. This ticket is considered complete when we've listed a few of the scenarios and evaluate the effect of making region configuration explicit. . See also: https://github.com/hail-is/hail/issues/13232. ### Version. 0.2.119. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13234:221,config,configured,221,https://hail.is,https://github.com/hail-is/hail/issues/13234,2,['config'],"['configuration', 'configured']"
Modifiability,"### What happened?. No hail log file is available. > On 0.2.109: 5k samples and 8 interval lists -- WORKED; > 5k samples and 1 interval list -- WORKED; > On 0.2.120: 2k samples and 1 interval list -- WORKED; > On 0.2.120: 2k samples and 2 interval lists -- WORKED; > On 0.2.120: 2k samples and 4 interval list -- ERROR; > On 0.2.120: 2k samples and 8 interval list -- ERROR (edited); > ; > All of these runs were on driver: 96 CPU/684G RAM; > Workers 4 CPU and 8GB RAM; > Spark configuration allocated 512GB for driver; > ; > I have tried the above in various configurations... Maybe a specific interval list is problematic, but that does not seem to be the case; > ; > The interval lists are the same across runs.; > ; > And lastly, the error is the usual Py4J Error. Usually I address this w/ more driver RAM, but I can't go any higher and this used to work fine in Hail 0.2.109.; > ; > I tried downgrading from 120-->109, but I don't believe that I can in Terra, due to Spark incompatibilities. > filtered_mt is a MatrixTable that has already been split and filtered (to drop irrelevant variants). By the time the [following] code blocks are run, `filtered_mt = hl.read_matrix_table(filtered_mt_url)` has been executed.; > Some more information: The code after this (not shown [in the below code blocks]) does additional filtering. If I skip the step `variant_data.export(f""{variant_stat_file_path_stem}_FULL.tsv"")`, I can complete successfully. The issue is that we need the `*_FULL.tsv` output. So, I believe that this is likely a RAM issue on the driver, but this used to work. ```; variant_mt = generate_variant_stats(filtered_mt, interval_names, interval_table_dict). # Main loop to compute variant stats and save to files. # File path stem to use for saving variant stats over different interval lists; variant_stat_file_path_stem = f""{bucket}/batchE/{workflow_nickname}/variant_stats"". variant_data = variant_mt.cols(); variant_data.describe(); #variant_data.to_pandas().to_csv(f""{variant_st",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13960:478,config,configuration,478,https://hail.is,https://github.com/hail-is/hail/issues/13960,2,['config'],"['configuration', 'configurations']"
Modifiability,### What happened?. See: https://hail.zulipchat.com/#narrow/stream/128581-Cloud-support/topic/requester.20pays.20in.20batch. We need a way to configure the RouterFS in a Python file. Maybe `hfs.init`? I'm not sure. ### Version. 0.2.120. ### Relevant log output. _No response_,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13567:142,config,configure,142,https://hail.is,https://github.com/hail-is/hail/issues/13567,1,['config'],['configure']
Modifiability,"### What happened?. Semantic hash assumes the params.files is a list of concrete file paths but it is a list of file paths with glob expressions. Consider the following example. Part of this ticket must also determine why this was not caught by `test_glob`.; ```; (base) dking@wm28c-761 hail % gsutil cp ./src/test/resources/ldprune2.vcf gs://danking/chr1.vcf; Copying file://./src/test/resources/ldprune2.vcf [Content-Type=text/x-vcard]...; / [1 files][ 11.5 KiB/ 11.5 KiB] ; Operation completed over 1 objects/11.5 KiB. ; (base) dking@wm28c-761 hail % gsutil cp ./src/test/resources/ldprune2.vcf gs://danking/chr2.vcf; Copying file://./src/test/resources/ldprune2.vcf [Content-Type=text/x-vcard]...; / [1 files][ 11.5 KiB/ 11.5 KiB] ; Operation completed over 1 objects/11.5 KiB. ; (base) dking@wm28c-761 hail % ipython ; Python 3.10.9 (main, Jan 11 2023, 09:18:18) [Clang 14.0.6 ]; Type 'copyright', 'credits' or 'license' for more information; IPython 8.16.1 -- An enhanced Interactive Python. Type '?' for help. In [1]: import hail as hl; ...: hl.import_vcf('gs://danking/chr*.vcf').count(); Initializing Hail with default parameters...; /Users/dking/miniconda3/lib/python3.10/site-packages/hailtop/aiocloud/aiogoogle/user_config.py:29: UserWarning: You have specified the GCS requester pays configuration in both your spark-defaults.conf (/Users/dking/miniconda3/lib/python3.10/site-packages/pyspark/conf/spark-defaults.conf) and either an explicit argument or through `hailctl config`. For GCS requester pays configuration, Hail first checks explicit arguments, then `hailctl config`, then spark-defaults.conf.; warnings.warn(; SLF4J: No SLF4J providers were found.; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See https://www.slf4j.org/codes.html#noProviders for further details.; SLF4J: Class path contains SLF4J bindings targeting slf4j-api versions 1.7.x or earlier.; SLF4J: Ignoring binding found at [jar:file:/Users/dking/miniconda3/lib/python3.10/site-packages/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13915:969,enhance,enhanced,969,https://hail.is,https://github.com/hail-is/hail/issues/13915,1,['enhance'],['enhanced']
Modifiability,"### What happened?. Suppose you're working with the [Wheat genome](https://hail.zulipchat.com/#narrow/stream/123010-Hail-Query-0.2E2-support/topic/Other.20genome/near/397467764). The following is seemingly correct code but it doesn't work:; ```python3; import hail as hl. rgwheat = hl.ReferenceGenome('Wheat', ...). hl.init(default_reference=rgwheat); ```; The first problem is that the `@typecheck` on `hl.init`, `hl.init_spark`, etc. only allows a built-in reference genome. . Even if we relax that requirement, we encounter a deeper problem: creating the reference genome initializes Hail. In particular, [we call `Env.backend()`](https://github.com/hail-is/hail/blob/main/hail/python/hail/genetics/reference_genome.py#L117-L118) (which calls `Env.hc()`, which forces initialization) so that we can call `add_reference`. What does initialization mean? Historically, it meant connection to or starting a JVM/Spark process. In QoB/ServiceBackend, initialization just loads configurations, it doesn't really do anything irreversible. Regardless of what it does, we only allow initialization *once*. OK, so, there's two possible routes to fix this problem:; 1. Rewrite `ReferenceGenome.__init__` such that it does not initialize Hail. You have to decide how reference genomes are ultimately communicated to the backend. Do you hang a list of all created reference genomes off of the `ReferenceGenome` class? Do you require explicit registering a la `hl.register_reference`? The latter seems a bit silly. The former seems OK, but you could also ...; 2. Allow modification of the default reference after initialization. The default reference genome is just a field on the HailContext: `_default_ref` which is accessed through `hl.default_reference()`. Just modify `hl.default_reference` to *return* the reference with no arguments and *set* the reference with one argument. Now this works:. ```python3; import hail as hl; rgwheat = hl.ReferenceGenome('Wheat', ...); hl.default_reference(rgwheat); mt = hl",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13856:974,config,configurations,974,https://hail.is,https://github.com/hail-is/hail/issues/13856,1,['config'],['configurations']
Modifiability,"### What happened?. The CloudSQL backups of the database are backed up into a multi-regional bucket. These need to be switched to regional. There's a setting in the backups part of the cloud console. We should make sure this doesn't mess up the Terraform configuration. The current database size is 1TB.; <img width=""1171"" alt=""Screenshot 2024-03-22 at 4 57 07 PM"" src=""https://github.com/hail-is/hail/assets/1693348/3bfc6d72-f7ab-4083-a2f5-c7053ae021b8"">. ### Version. 0.2.128. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14422:255,config,configuration,255,https://hail.is,https://github.com/hail-is/hail/issues/14422,1,['config'],['configuration']
Modifiability,"### What happened?. The NDArrayNumericExpression currently lacks a max method that allows users to compute the maximum value along a specified axis of the NDArray, akin to numpy's max method. Implementing this feature would enhance the functionality and user-friendliness of the Hail library. # Expected Behavior with Examples:. ## Basic Usage:. The max method can be called on an NDArrayNumericExpression object to return the maximum value along a specified axis.; If no axis is specified, it should return the maximum value in the entire NDArray.; Example:. ```python; import hail as hl. # Creating an NDArrayNumericExpression object; nd = hl.nd.array([[1, 2, 3], [4, 5, 6]]). # Getting the maximum value along axis 0; max_along_axis0 = nd.max(axis=0). # Getting the maximum value along axis 1; max_along_axis1 = nd.max(axis=1). # Getting the maximum value in the entire array; overall_max = nd.max(). # Expected outputs; # max_along_axis0: [4, 5, 6]; # max_along_axis1: [3, 6]; # overall_max: 6; ```. ## Handling of NaN Values:; The method should be able to handle NaN values, similar to numpy, where an optional parameter can be provided to ignore NaN values.; Example:. ```python; import hail as hl; import numpy as np. # Creating an NDArrayNumericExpression object with NaN values; nd = hl.nd.array([[1, np.nan, 3], [4, 5, np.nan]]). # Getting the maximum value while ignoring NaN values; max_ignore_nan = nd.max(axis=1, ignore_nan=True). # Expected output: [3, 5] instead of [nan, nan]; ```. ## Errors and Exceptions:; Appropriate errors and exceptions should be raised for invalid inputs, such as non-integer or out-of-bound axis values. ### Version. 0.2.124. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13781:224,enhance,enhance,224,https://hail.is,https://github.com/hail-is/hail/issues/13781,1,['enhance'],['enhance']
Modifiability,"### What happened?. The following should not hang, but it does. ```python3; (base) dking@wm28c-761 hail % HAIL_QUERY_BACKEND=local ipython; Python 3.10.9 (main, Jan 11 2023, 09:18:18) [Clang 14.0.6 ]; Type 'copyright', 'credits' or 'license' for more information; IPython 8.16.1 -- An enhanced Interactive Python. Type '?' for help. In [1]: import hail as hl; ...: import os; ...: hl.utils.range_table(1).write('gs://danking/test_hail_in_notebook.ht'); ```. Writing to a local file path causes no issue. ### Version. 0.2.124. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13904:285,enhance,enhanced,285,https://hail.is,https://github.com/hail-is/hail/issues/13904,1,['enhance'],['enhanced']
Modifiability,"### What happened?. The infrastructure necessary to run a Hail Batch deployment (network, buckets, DB, Kubernetes cluster) are managed through Terraform in `infra/gcp` and `infra/azure`. In order to migrate terraform resources, the terraform module need to be given input variables specific to our deployment provided through a `global.tfvars` file. Since this file contains secrets, in GCP we encrypt the file with [SOPS](https://github.com/getsops/sops) and check it into the repo so that any developer with the credentials to our deployment can run the terraform. This is not the case in Azure, so if a developer wants to run the Azure terraform they have to obtain the `global.tfvars` from myself. We should use the same strategy for communicating this file as we do in GCP. ### Version. 0.2.129. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14457:272,variab,variables,272,https://hail.is,https://github.com/hail-is/hail/issues/14457,1,['variab'],['variables']
Modifiability,"### What happened?. Using this image https://hub.docker.com/layers/gneak123/guide_browser/latest/images/sha256-8ca2a921828cd147e86519051a0da68522983b7b49f22e1280c83ab9c56b3129?context=explore, deploy a 1 pod deployment into a fresh namespace and serve it at guide-analysis.hail.is. It need not be in build.yaml nor in the infrastructure (just like Duncan's stuff isn't). We're just hosting it as a service to the lab. ### Version. 0.2.126. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14067:60,layers,layers,60,https://hail.is,https://github.com/hail-is/hail/issues/14067,1,['layers'],['layers']
Modifiability,### What happened?. We are leaving tasks alive when workers shut down and we do not know which tasks they are. This issue has two parts:. 1. Fix `dump_all_stacktraces` to actually show all the outstanding tasks. Perhaps `log.debug` isn't generating output b/c of our logging configuration.; 2. Figure out why these tasks are running and prevent them from staying running. Several examples [here](https://cloudlogging.app.goo.gl/aMfqzLB4FBa864WJ7). ### Version. 0.2.124. ### Relevant log output. _No response_,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13908:275,config,configuration,275,https://hail.is,https://github.com/hail-is/hail/issues/13908,1,['config'],['configuration']
Modifiability,"### What happened?. We tried to copy and symlink the directory file `..` when trying to use the `--files` argument with a directory. ### Version. 0.2.123. ### Relevant log output. ```shell; ""input_files"": [; {; ""from"": ""gs://my_bucket//jwTsgaP9Q7zbQJVgO20Z84/sample_qc.py"",; ""to"": ""/io/batch/7d4f36/inputs/xzMZj/sample_qc.py""; },; {; ""from"": ""gs://my_bucket//jwTsgaP9Q7zbQJVgO20Z84/.."",; ""to"": ""/io/batch/7d4f36/inputs/bukrz/..""; },; {; ""from"": ""gs://my_bucket//jwTsgaP9Q7zbQJVgO20Z84//Users/me/.config/hail/config.ini"",; ""to"": ""/io/batch/7d4f36/inputs/Rjsy0/config.ini""; }; ],; ```. ```; ln: failed to create symbolic link '../..': File exists; ```; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13785:496,config,config,496,https://hail.is,https://github.com/hail-is/hail/issues/13785,3,['config'],['config']
Modifiability,"### What happened?. When the QoB client on a user's laptop sends a request to create a QoB job, it sends a `jar_spec` parameter as part of the job spec that is either:; - `git_revision`: the git SHA that the hail was built with. The Batch front end takes this and resolves a URL for the published JAR that was created when that commit was merged to `main`.; - `jar_url`: A blob storage URL that points directly to the JAR to use. The Batch front end ensures that this URL is trusted. The `jar_url` setting is mainly for development and debugging purposes, allowing a dev or user to set a URL to a development JAR instead of using a merged commit. In normal configuration fashion, it is possible to set `jar_url` in `hailctl config`. This is an enormous footgun, as users may forget to unset this configuration and continue using the dev jar *even after they install a different hail wheel*. We must do two things:; 1. Remove the ability to set the jar_url through `hailctl` so as to avoid this footgun. Batch should also fully remove support for `jar_url`s so that any users who might be inadvertently using it are loudly alerted (though I suspect there are few if any such users now).; 2. Remove entirely the ability to specify a JAR other than that which was built along with the installed wheel. The proposed plan is to always send `git_revision` for QoB jobs. In order to enable development JARs, Batch should be augmented to search first for production JARs matching a certain revision, and then if that fails search a specified `dev/` subdirectory for the requested revision. These development JARs should not be cached on workers so as to enable debugging development without constant committing. ### Version. 0.2.130. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14539:657,config,configuration,657,https://hail.is,https://github.com/hail-is/hail/issues/14539,3,['config'],"['config', 'configuration']"
Modifiability,"### What happened?. [cc8d364](https://github.com/hail-is/hail/commit/cc8d36408b3603237dd856802eadad562b114256) refactored the plumbing around (un)persist for `Table`, `MatrixTable` and `BlockMatrix`.; It had the slightly undesirable effect of breaking persist on `BlockMatrix`. ### Version. 0.2.114. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14689:111,refactor,refactored,111,https://hail.is,https://github.com/hail-is/hail/issues/14689,1,['refactor'],['refactored']
Modifiability,"### What happened?. `hail-0.2.129-py3-none-any.whl` bundled a version of `hailtop/hailctl/deploy.yaml` that was intended for internal testing only. This file provides configuration variables for `hailctl`. The file in [0.2.129](https://github.com/hail-is/hail/releases/tag/0.2.129) pointed to cloud resources in `gs://hail-30-day/` that cause commands like `hailctl dataproc start` to fail due to one of the following:; - the user does not have access to `gs://hail-30-day`, or; - the resources have been deleted according to the bucket's 30-day lifecycle policy. ### Version. 0.2.129. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14452:167,config,configuration,167,https://hail.is,https://github.com/hail-is/hail/issues/14452,2,"['config', 'variab']","['configuration', 'variables']"
Modifiability,"### What happened?. `hailctl dataproc start` fails with an error message like the one below because [in Dataproc 2.2](https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/network#:~:text=Internal%20addresses%20only%20(no%2Daddress)%20is%20set%20by%20default%20when%20creating%20a%20Dataproc%202.2%20image%20version%20cluster.%20You%20can%20use%20the%20gcloud%20dataproc%20clusters%20create%20%2D%2Dpublic%2Dip%2Daddress%20flag%20to%20enable%20public%20IP%20addresses.), clusters are created without public internet access by default. A workaround is to pass the `--public-ip-address` flag to the command. Error message:. ```python; pip packages are ['setuptools', 'mkl<2020', 'lxml<5', 'https://github.com/hail-is/jgscm/archive/v0.1.13+hail.zip', 'ipykernel==6.22.0', 'ipywidgets==8.0.6', 'jupyter-console==6.6.3', 'nbconvert==7.3.1', 'notebook==6.5.6', 'qtconsole==5.4.2', 'aiodns==2.0.0', 'aiohttp==3.9.5', 'aiosignal==1.3.1', 'async-timeout==4.0.3', 'attrs==23.2.0', 'avro==1.11.3', 'azure-common==1.1.28', 'azure-core==1.30.2', 'azure-identity==1.17.1', 'azure-mgmt-core==1.4.0', 'azure-mgmt-storage==20.1.0', 'azure-storage-blob==12.20.0', 'bokeh==3.3.4', 'boto3==1.34.138', 'botocore==1.34.138', 'cachetools==5.3.3', 'certifi==2024.6.2', 'cffi==1.16.0', 'charset-normalizer==3.3.2', 'click==8.1.7', 'commonmark==0.9.1', 'contourpy==1.2.1', 'cryptography==42.0.8', 'decorator==4.4.2', 'deprecated==1.2.14', 'dill==0.3.8', 'frozenlist==1.4.1', 'google-auth==2.31.0', 'google-auth-oauthlib==0.8.0', 'humanize==1.1.0', 'idna==3.7', 'isodate==0.6.1', 'janus==1.0.0', 'jinja2==3.1.4', 'jmespath==1.0.1', 'jproperties==2.1.1', 'markupsafe==2.1.5', 'msal==1.29.0', 'msal-extensions==1.2.0', 'msrest==0.7.1', 'multidict==6.0.5', 'nest-asyncio==1.6.0', 'numpy==1.26.4', 'oauthlib==3.2.2', 'orjson==3.10.6', 'packaging==24.1', 'pandas==2.2.2', 'parsimonious==0.10.0', 'pillow==10.4.0', 'plotly==5.22.0', 'portalocker==2.10.0', 'protobuf==3.20.2', 'py4j==0.10.9.7', 'pyasn1==0.6.0', 'pyasn1-",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14652:166,config,configuring-clusters,166,https://hail.is,https://github.com/hail-is/hail/issues/14652,1,['config'],['configuring-clusters']
Modifiability,"### What happened?. https://batch.hail.is/batches/8083756/jobs/72. `test_hail_in_notebook` just executed `jupyter` on `test_hail_in_notebook.ipynb`. The notebook contains one cell:. ```python3; import hail as hl; import os; hl.utils.range_table(1).write(f'{os.environ[""HAIL_TEST_STORAGE_URI""]}/test_hail_in_notebook.ht'); from helpers import resource; hl.read_table(resource('backward_compatability/1.7.0/table/9.ht')).count(); ```. This is not idempotent because `HAIL_TEST_STORAGE_URI` is randomly generated once per job not once per attempt. In particular, the job specification itself has this as an environment variable. In the [this PR test job](https://batch.hail.is/batches/8083756/jobs/72), the test job gets preempted and rescheduled. Upon rescheduling, the hail table already exists, causing the test to fail. The fix is simple: add a random string to the written Hail table file. ### Version. 0.2.126. ### Relevant log output. _No response_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13994:616,variab,variable,616,https://hail.is,https://github.com/hail-is/hail/issues/13994,1,['variab'],['variable']
Modifiability,### What happened?. https://hail.zulipchat.com/#narrow/stream/223457-Hail-Batch-support/topic/How.20to.20use.20hailctl.20batch.20submit.3F/near/385496357. Solution: I think the issue is we're missing this configuration in `hailctl batch submit` https://typer.tiangolo.com/tutorial/commands/context/#configuring-the-context. ### Version. 0.2.120. ### Relevant log output. _No response_,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13446:205,config,configuration,205,https://hail.is,https://github.com/hail-is/hail/issues/13446,2,['config'],"['configuration', 'configuring-the-context']"
Modifiability,"### What happened?. while trying to run the following code I get the error mention in the title (Invalid maximum heap size: -Xmx0m). import hail as hl; hl.init(default_reference=""GRCh38""). However I tried to resolve the issue with overloading the default setting with new values for spark configuration (command below), unfortunately the error still exists; hl.init(driver_memory='1024m’). ### Version. latest version used in allOfUs research workbench platform. ### Relevant log output. ```shell; Invalid maximum heap size: -Xmx0m; Error: Could not create the Java Virtual Machine.; Error: A fatal exception has occurred. Program will exit.; ---------------------------------------------------------------------------; RuntimeError Traceback (most recent call last); Cell In[14], line 2; 1 #hl.init(default_reference=""GRCh38""); ----> 2 hl.init(driver_memory='1024m'). File <decorator-gen-1756>:2, in init(sc, app_name, master, local, log, quiet, append, min_block_size, branching_factor, tmp_dir, default_reference, idempotent, global_seed, spark_conf, skip_logging_configuration, local_tmpdir, _optimizer_iterations, backend, driver_cores, driver_memory, worker_cores, worker_memory, gcs_requester_pays_configuration, regions, gcs_bucket_allow_list). File /opt/conda/lib/python3.10/site-packages/hail/typecheck/check.py:587, in _make_dec.<locals>.wrapper(__original_func, *args, **kwargs); 584 @decorator; 585 def wrapper(__original_func: Callable[..., T], *args, **kwargs) -> T:; 586 args_, kwargs_ = check_all(__original_func, args, kwargs, checkers, is_method=is_method); --> 587 return __original_func(*args_, **kwargs_). File /opt/conda/lib/python3.10/site-packages/hail/context.py:364, in init(sc, app_name, master, local, log, quiet, append, min_block_size, branching_factor, tmp_dir, default_reference, idempotent, global_seed, spark_conf, skip_logging_configuration, local_tmpdir, _optimizer_iterations, backend, driver_cores, driver_memory, worker_cores, worker_memory, gcs_requester_pays_",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14489:289,config,configuration,289,https://hail.is,https://github.com/hail-is/hail/issues/14489,1,['config'],['configuration']
Modifiability,#10957 introduced loading GCP-specific configuration from the global-config instead of environment variables. The auth-driver uses this but doesn't have a global-config mounted.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10962:39,config,configuration,39,https://hail.is,https://github.com/hail-is/hail/pull/10962,4,"['config', 'variab']","['config', 'configuration', 'variables']"
Modifiability,"#11005 Added support for the BuildImage job in build.py to work with `GOOGLE_APPLICATION_CREDENTIALS` or `AZURE_APPLICATION_CREDENTIALS`, but that doesn't mean that the backing secret behind those environment variables has to be different in each case. Ultimately, we would like the same k8s terraform to generate secrets for both clouds, so this changes both `gcr-push-service-account-key` and `acr-push-credentials` to just be `registry-push-credentials`. I have copied the `gcr-push-service-account-key` into a new secret with the appropriate name in `hail-vdc`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11033:209,variab,variables,209,https://hail.is,https://github.com/hail-is/hail/pull/11033,1,['variab'],['variables']
Modifiability,#13890 removed an optional argument to `docker-build.sh`. Now that there are no optional arguments I think it is cleaner to claim any additional arguments as docker args instead of stuffing docker args into an environment variable.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13910:222,variab,variable,222,https://hail.is,https://github.com/hail-is/hail/pull/13910,1,['variab'],['variable']
Modifiability,"#14056 added a new optional field to the deploy config, `base_path` which is intended to phase out `default_namespace`. But for backwards compatibility reasons we cannot yet remove `default_namespace`. This should all work fine without breaking any workflows like switching back and forth between namespaces so long as `base_path` is not explicitly set in a developer's deploy config. But `hailctl dev config set <property> <value>` does not just set a single property, it loads the deploy config, sets the property, and then writes the whole deploy config back. If the deploy config does anything with default values, which it now does with `base_path`, this round trip does not work. Another simpler example is that currently in main, the following will make two changes to a deploy config not one:. ```; # deploy config of {'location': 'external', 'domain': 'hail.is', 'default_namespace': 'default'}; HAIL_DOMAIN=foo hailctl dev config set location gce. # deploy config will now read {'location': 'gce', 'domain': 'foo', 'default_namespace': 'default'}; ```. This PR should change `hailctl dev config set` so that the only changes that are made to the deploy config are the single property/value change described in the command.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14169:48,config,config,48,https://hail.is,https://github.com/hail-is/hail/pull/14169,12,['config'],['config']
Modifiability,"#14609 broke the routing for https://hail.is. The `domains` variable here indicates to `gateway` which domains in incoming requests should be routed to the given service. Since #14609 changed the `service` parameter from `str` to `Service`, it silently broke this branch. This wasn't covered by the envoy config generation tests because we didn't have a `www` service in the test configuration. I've added it so that this branch is covered. Fixes #14616",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14617:60,variab,variable,60,https://hail.is,https://github.com/hail-is/hail/pull/14617,3,"['config', 'variab']","['config', 'configuration', 'variable']"
Modifiability,"#313 : changed the Interval created from BED file so [Start, End) in BED file becomes [Start + 1, End] in Hail. See updated docs.; #257 : added annotatesamples list which creates a new boolean annotation based on whether a sample id is in the input file or not; #319 : changed regular expression parsing to handle contig\tstart\tend in addition to config:start-end",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/398:348,config,config,348,https://hail.is,https://github.com/hail-is/hail/pull/398,1,['config'],['config']
Modifiability,"#9634 Introduced a large performance regression in the `linear_regression_rows_nd` benchmark (making it about 4x slower). This PR fixes that by doing two things:. 1. Move all the global into one single `annotate_globals` expression, so that CSE can work properly. This required fixing a bug in some ndarray expressions that were not correctly tracking their source tables. To make sure I was only referencing the global versions of this computed things, rather accidentally recomputing, I wrapped the global setup in a function to scope the variables. This improvement was minor, didn't hit the real root of the problem. 2. Much more significantly, and not 100% clear why: `process_y_group` is now a function that returns a python dictionary, instead of a hail struct. I can guess that the allocation required by making a struct was wasteful, but it seems crazy that it was ""make the benchmark 4x slower"" amounts of wasteful. . While this is not user facing yet, would be good to get this in before an eventual 0.2.60 release if we want to avoid benchmarks regressing between versions.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9666:541,variab,variables,541,https://hail.is,https://github.com/hail-is/hail/pull/9666,1,['variab'],['variables']
Modifiability,"$100(URLClassLoader.java:71); at java.net.URLClassLoader$1.run(URLClassLoader.java:361); at java.net.URLClassLoader$1.run(URLClassLoader.java:355); at java.security.AccessController.doPrivileged(Native Method); at java.net.URLClassLoader.findClass(URLClassLoader.java:354); at java.lang.ClassLoader.loadClass(ClassLoader.java:425); at java.lang.ClassLoader.loadClass(ClassLoader.java:358); at org.broadinstitute.hail.driver.ToplevelCommands$.<init>(Command.scala:62); at org.broadinstitute.hail.driver.ToplevelCommands$.<clinit>(Command.scala); at org.broadinstitute.hail.driver.Main$.main(Main.scala:205); at org.broadinstitute.hail.driver.Main.main(Main.scala); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:606); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:731); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:181); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala). I think this may relate to java version, so I re-configured java,but the error still appear, How can I solve it ?. --------------------My java version and path; [root@***-3 opt]# java -version; java version ""1.8.0_91""; Java(TM) SE Runtime Environment (build 1.8.0_91-b14); Java HotSpot(TM) 64-Bit Server VM (build 25.91-b14, mixed mode). [root@***-3 opt]# echo $JAVA_HOME; /opt/BioDir/jdk/jdk1.8.0_91. [root@bio-x-3 opt]# echo $PATH; /opt/BioDir/plink_1.9:/opt/BioDir/jdk/jdk1.8.0_91/bin:/opt/BioDir/gradle/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin. My OS is CentOS7; [root@***-3 opt]# uname -a; Linux bio-x-3 3.10.0-229.14.1.el7.x86_64",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/825:2158,config,configured,2158,https://hail.is,https://github.com/hail-is/hail/issues/825,1,['config'],['configured']
Modifiability,$_jvmLowerAndExecute$3(LocalBackend.scala:186); E 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3$adapted(LocalBackend.scala:186); E 	at is.hail.backend.ExecuteContext.$anonfun$scopedExecution$1(ExecuteContext.scala:144); E 	at is.hail.utils.package$.using(package.scala:673); E 	at is.hail.backend.ExecuteContext.scopedExecution(ExecuteContext.scala:144); E 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$2(LocalBackend.scala:186); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); E 	at is.hail.backend.local.LocalBackend._jvmLowerAndExecute(LocalBackend.scala:186); E 	at is.hail.backend.local.LocalBackend._execute(LocalBackend.scala:212); E 	at is.hail.backend.local.LocalBackend.$anonfun$execute$2(LocalBackend.scala:277); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); E 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1(LocalBackend.scala:272); E 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1$adapted(LocalBackend.scala:271); E 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:78); E 	at is.hail.utils.package$.using(package.scala:673); E 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:78); E 	at is.hail.utils.package$.using(package.scala:673); E 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:13); E 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:65); E 	at is.hail.backend.local.LocalBackend.$anonfun$withExecuteContext$2(LocalBackend.scala:120); E 	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:55); E 	at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:62); E 	at is.hail.backend.local.LocalBackend.withExecuteContext(LocalBackend.scala:105); E 	at is.hail.backend.local.LocalBackend.execute(LocalBackend.scala:271); E 	at is.hail.backend.BackendHttpHandler.handle(BackendServer.scala:88); E 	at jdk.httpserver/com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:77); E 	at jd,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14705:6764,adapt,adapted,6764,https://hail.is,https://github.com/hail-is/hail/issues/14705,1,['adapt'],['adapted']
Modifiability,"% gsutil cp ./src/test/resources/ldprune2.vcf gs://danking/chr2.vcf; Copying file://./src/test/resources/ldprune2.vcf [Content-Type=text/x-vcard]...; / [1 files][ 11.5 KiB/ 11.5 KiB] ; Operation completed over 1 objects/11.5 KiB. ; (base) dking@wm28c-761 hail % ipython ; Python 3.10.9 (main, Jan 11 2023, 09:18:18) [Clang 14.0.6 ]; Type 'copyright', 'credits' or 'license' for more information; IPython 8.16.1 -- An enhanced Interactive Python. Type '?' for help. In [1]: import hail as hl; ...: hl.import_vcf('gs://danking/chr*.vcf').count(); Initializing Hail with default parameters...; /Users/dking/miniconda3/lib/python3.10/site-packages/hailtop/aiocloud/aiogoogle/user_config.py:29: UserWarning: You have specified the GCS requester pays configuration in both your spark-defaults.conf (/Users/dking/miniconda3/lib/python3.10/site-packages/pyspark/conf/spark-defaults.conf) and either an explicit argument or through `hailctl config`. For GCS requester pays configuration, Hail first checks explicit arguments, then `hailctl config`, then spark-defaults.conf.; warnings.warn(; SLF4J: No SLF4J providers were found.; SLF4J: Defaulting to no-operation (NOP) logger implementation; SLF4J: See https://www.slf4j.org/codes.html#noProviders for further details.; SLF4J: Class path contains SLF4J bindings targeting slf4j-api versions 1.7.x or earlier.; SLF4J: Ignoring binding found at [jar:file:/Users/dking/miniconda3/lib/python3.10/site-packages/pyspark/jars/log4j-slf4j-impl-2.17.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]; SLF4J: See https://www.slf4j.org/codes.html#ignoredBindings for an explanation.; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Running on Apache Spark version 3.3.3; SparkUI available at http://192.168.1.142:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.125-c4e2880b3279; LOGGING: writing to /Users/dking/projects/hail/hail/hail-20231",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13915:1516,config,configuration,1516,https://hail.is,https://github.com/hail-is/hail/issues/13915,2,['config'],"['config', 'configuration']"
Modifiability,'app'). Java stack trace:; java.lang.ClassCastException: class is.hail.types.physical.stypes.concrete.SIndexablePointer cannot be cast to class is.hail.types.physical.stypes.concrete.SJavaArrayString (is.hail.types.physical.stypes.concrete.SIndexablePointer and is.hail.types.physical.stypes.concrete.SJavaArrayString are in unnamed module of loader 'app'); 	at is.hail.expr.ir.functions.RegistryFunctions.unwrapReturn(Functions.scala:364); 	at is.hail.expr.ir.Emit.$anonfun$emitI$85(Emit.scala:1173); 	at is.hail.expr.ir.IEmitCodeGen.map(Emit.scala:352); 	at is.hail.expr.ir.Emit.emitI(Emit.scala:1153); 	at is.hail.expr.ir.streams.EmitStream$.is$hail$expr$ir$streams$EmitStream$$emit$1(EmitStream.scala:148); 	at is.hail.expr.ir.streams.EmitStream$.produce(EmitStream.scala:321); 	at is.hail.expr.ir.Emit.emitStream$2(Emit.scala:821); 	at is.hail.expr.ir.Emit.emitI(Emit.scala:1177); 	at is.hail.expr.ir.Emit.$anonfun$emitSplitMethod$1(Emit.scala:607); 	at is.hail.expr.ir.Emit.$anonfun$emitSplitMethod$1$adapted(Emit.scala:605); 	at is.hail.expr.ir.EmitCodeBuilder$.scoped(EmitCodeBuilder.scala:19); 	at is.hail.expr.ir.EmitCodeBuilder$.scopedVoid(EmitCodeBuilder.scala:29); 	at is.hail.expr.ir.EmitMethodBuilder.voidWithBuilder(EmitClassBuilder.scala:1086); 	at is.hail.expr.ir.Emit.emitSplitMethod(Emit.scala:605); 	at is.hail.expr.ir.Emit.emitInSeparateMethod(Emit.scala:622); 	at is.hail.expr.ir.Emit.emitI(Emit.scala:809); 	at is.hail.expr.ir.Emit.emitInNewBuilder$1(Emit.scala:818); 	at is.hail.expr.ir.Emit.$anonfun$emitI$33(Emit.scala:979); 	at is.hail.expr.ir.EmitCode$.fromI(Emit.scala:461); 	at is.hail.expr.ir.Emit.$anonfun$emitI$32(Emit.scala:979); 	at scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at scala.collection.Trave,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13633:5134,adapt,adapted,5134,https://hail.is,https://github.com/hail-is/hail/issues/13633,1,['adapt'],['adapted']
Modifiability,"'locus1', 'alleles1'). mt = mt.annotate_rows(v1=hl.is_defined(vp_mt[(mt.locus, mt.alleles), :])); ```. ### What went wrong (all error messages here, including the full java stack trace):; ```; In [49]: mt = mt.annotate_rows(v1=hl.is_defined(vp_mt[(mt.locus, mt.alleles),:])); ---------------------------------------------------------------------------; FatalError Traceback (most recent call last); <ipython-input-49-5ea2fe942ada> in <module>(); ----> 1 mt = mt.annotate_rows(v1=hl.is_defined(vp_mt[(mt.locus, mt.alleles),:])). /home/hail/hail.zip/hail/matrixtable.py in annotate_rows(self, **named_exprs); 894 exprs = []; 895 named_exprs = {k: to_expr(v) for k, v in named_exprs.items()}; --> 896 base, cleanup = self._process_joins(*named_exprs.values()); 897; 898 for k, v in named_exprs.items():. /home/hail/hail.zip/hail/matrixtable.py in _process_joins(self, *exprs); 2205 for j in list(e._joins)[::-1]:; 2206 if j.uid not in used_uids:; -> 2207 left = j.join_function(left); 2208 all_uids.extend(j.temp_vars); 2209 used_uids.add(j.uid). /home/hail/hail.zip/hail/matrixtable.py in <lambda>(left); 2157 prefix = 'va'; 2158 joiner = lambda left: (; -> 2159 MatrixTable(left._jvds.annotateRowsVDS(right._jvds, uid))); 2160 else:; 2161 return self.rows().index(*exprs). /usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(self, *args); 1131 answer = self.gateway_client.send_command(command); 1132 return_value = get_return_value(; -> 1133 answer, self.gateway_client, self.target_id, self.name); 1134; 1135 for temp_arg in temp_args:. /home/hail/hail.zip/hail/utils/java.py in deco(*args, **kwargs); 236 # this is a hack to suppress the original error's stack trace; 237 if _exception:; --> 238 raise _exception; 239; 240 return deco. FatalError: AssertionError: assertion failed. Java stack trace:; java.lang.AssertionError: assertion failed; 	at scala.Predef$.assert(Predef.scala:156); 	at is.hail.variant.MatrixTable.orderedRVDLeftJoinDistinctAndInsert(MatrixTable.sca",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3119:1539,extend,extend,1539,https://hail.is,https://github.com/hail-is/hail/issues/3119,1,['extend'],['extend']
Modifiability,"'s New in astroid 2.12.6?</h1>; <p>Release date: 2022-09-05</p>; <ul>; <li>; <p>Fix a crash involving <code>Uninferable</code> arguments to <code>namedtuple()</code>.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7375"">PyCQA/pylint#7375</a></p>; </li>; <li>; <p>The <code>dataclass</code> brain now understands the <code>kw_only</code> keyword in dataclass decorators.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7290"">PyCQA/pylint#7290</a></p>; </li>; </ul>; <h1>What's New in astroid 2.12.5?</h1>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/PyCQA/astroid/commit/7352e947bdf9b9c5ea51e601bbed7a063e98316d""><code>7352e94</code></a> Bump astroid to 2.12.9, update changelog</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/449a95b08e39dd2d6f3a6c3cbf4ace3055340b46""><code>449a95b</code></a> Fixed the <code>__init__</code> of <code>dataclassess</code> with multiple inheritance (<a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1774"">#1774</a>)</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/d15466685643b47f3b8b42ae5c0ba14a429a5293""><code>d154666</code></a> Fix a crash on <code>namedtuples</code> that use <code>typename</code> (<a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1773"">#1773</a>)</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/65bca39bbf254bc760ac9d388e5a09333eaf5c87""><code>65bca39</code></a> Bump astroid to 2.12.8, update changelog</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/fab511c1477d13262e9e33b015906d4bca683953""><code>fab511c</code></a> Fix crash in <code>dataclass</code> brain (<a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1770"">#1770</a>)</li>; <li><a href=""https://github.com/PyCQA/astroid/commit/0720cbcd05a3938bdf8141328a1ceed1e2f38bed""><code>0720cbc</code></a> Parse def",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12161:2675,inherit,inheritance,2675,https://hail.is,https://github.com/hail-is/hail/pull/12161,1,['inherit'],['inheritance']
Modifiability,"'s changelog</a>.</em></p>; <blockquote>; <h2>Version 2.2.3</h2>; <p>Released 2023-02-14</p>; <ul>; <li>Ensure that URL rules using path converters will redirect with strict slashes when; the trailing slash is missing. :issue:<code>2533</code></li>; <li>Type signature for <code>get_json</code> specifies that return type is not optional when; <code>silent=False</code>. :issue:<code>2508</code></li>; <li><code>parse_content_range_header</code> returns <code>None</code> for a value like <code>bytes */-1</code>; where the length is invalid, instead of raising an <code>AssertionError</code>. :issue:<code>2531</code></li>; <li>Address remaining <code>ResourceWarning</code> related to the socket used by <code>run_simple</code>.; Remove <code>prepare_socket</code>, which now happens when creating the server. :issue:<code>2421</code></li>; <li>Update pre-existing headers for <code>multipart/form-data</code> requests with the test; client. :issue:<code>2549</code></li>; <li>Fix handling of header extended parameters such that they are no longer quoted.; :issue:<code>2529</code></li>; <li><code>LimitedStream.read</code> works correctly when wrapping a stream that may not return; the requested size in one <code>read</code> call. :issue:<code>2558</code></li>; <li>A cookie header that starts with <code>=</code> is treated as an empty key and discarded,; rather than stripping the leading <code>==</code>.</li>; <li>Specify a maximum number of multipart parts, default 1000, after which a; <code>RequestEntityTooLarge</code> exception is raised on parsing. This mitigates a DoS; attack where a larger number of form/file parts would result in disproportionate; resource use.</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pallets/werkzeug/commit/22a254fca2ad0130adbbcbd11d3de51bcb04a08b""><code>22a254f</code></a> release version 2.2.3</li>; <li><a href=""https://github.com/pallets/werkzeug/commit/517cac5a804e8c4dc4ed038bb2",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12703:2237,extend,extended,2237,https://hail.is,https://github.com/hail-is/hail/pull/12703,1,['extend'],['extended']
Modifiability,"'s releases</a>.</em></p>; <blockquote>; <h2>v4.4.0</h2>; <p>Changelog: <a href=""https://www.sphinx-doc.org/en/master/changes.html"">https://www.sphinx-doc.org/en/master/changes.html</a></p>; <h2>v4.3.1</h2>; <p>No release notes provided.</p>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/sphinx-doc/sphinx/blob/4.x/CHANGES"">sphinx's changelog</a>.</em></p>; <blockquote>; <h1>Release 4.4.0 (released Jan 17, 2022)</h1>; <h2>Dependencies</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10007"">#10007</a>: Use <code>importlib_metadata</code> for python-3.9 or older</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10007"">#10007</a>: Drop <code>setuptools</code></li>; </ul>; <h2>Features added</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/9075"">#9075</a>: autodoc: Add a config variable :confval:<code>autodoc_typehints_format</code>; to suppress the leading module names of typehints of function signatures (ex.; <code>io.StringIO</code> -&gt; <code>StringIO</code>)</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/9831"">#9831</a>: Autosummary now documents only the members specified in a module's; <code>__all__</code> attribute if :confval:<code>autosummary_ignore_module_all</code> is set to; <code>False</code>. The default behaviour is unchanged. Autogen also now supports; this behavior with the <code>--respect-module-all</code> switch.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/9555"">#9555</a>: autosummary: Improve error messages on failure to load target object</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/9800"">#9800</a>: extlinks: Emit warning if a hardcoded link is replaceable; by an extlink, suggesting a replacement.</li>; <li><a href=""https://github-redirect.dependabot.com/sph",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11522:1162,config,config,1162,https://hail.is,https://github.com/hail-is/hail/pull/11522,4,"['config', 'variab']","['config', 'variable']"
Modifiability,"'s the only event loop that will exist forever. Pytest (and newer version of IPython, afaict) violate this pretty liberally. ~~pytest_asyncio has [explicit instructions on how to run every test in the same event loop](https://pytest-asyncio.readthedocs.io/en/latest/how-to-guides/run_session_tests_in_same_loop.html). I've implemented those here.~~ [These instructions don't work](https://github.com/pytest-dev/pytest-asyncio/issues/744). It seems that the reliable way to ensure we're using one event loop everywhere is to use pytest-asyncio < 0.23 and to define an event_loop fixture with scope `'session'`. I also switched test_batch.py into pytest-only style. This allows me to use session-scoped fixtures so that they exist exactly once for the entire test suite execution. Also:; - `RouterAsyncFS` methods must either be a static method or an async method. We must not create an FS in a sync method. Both `parse_url` and `copy_part_size` now both do not allocate an FS.; - `httpx.py` now eagerly errors if the running event loop in `request` differs from that at allocation time. Annoying but much better error message than this nonsense about timeout context managers.; - `hail_event_loop` either gets the current thread's event loop (running or not, doesn't matter to us) or creates a fresh event loop and sets it as the current thread's event loop. The previous code didn't guarantee we'd get an event loop b/c `get_event_loop` fails if `set_event_loop` was previously called.; - `conftest.py` is inherited downward, so I lifted fixtures out of test_copy.py and friends and into a common `hailtop/conftest.py`; - I added `make -C hail pytest-inter-cloud` for testing the inter cloud directory. You still need appropriate permissions and authn.; - I removed extraneous pytest.mark.asyncio since we use auto mode everywhere.; - `FailureInjectingClientSession` creates an `aiohttp.ClientSession` and therefore must be used while an event loop is running. Easiest fix was to make the test async.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14097:1690,inherit,inherited,1690,https://hail.is,https://github.com/hail-is/hail/pull/14097,1,['inherit'],['inherited']
Modifiability,"(99 + 1) / 100]2018-03-08 02:54:37 Hail: INFO: vep: annotated 243477 variants; ---------------------------------------------------------------------------; FatalError Traceback (most recent call last); <ipython-input-6-a229f1f9de81> in <module>(); ----> 1 clinvar_vep = hl.vep(clinvar_mt, vep_config). <decorator-gen-843> in vep(dataset, config, block_size, name, csq). /hadoop_gcs_connector_metadata_cache/hail/hail-devel-0c961806173f.zip/hail/typecheck/check.py in _typecheck(__orig_func__, *args, **kwargs); 491 def _typecheck(__orig_func__, *args, **kwargs):; 492 args_, kwargs_ = check_all(__orig_func__, args, kwargs, checkers, is_method=False); --> 493 return __orig_func__(*args_, **kwargs_); 494; 495 return decorator(_typecheck). /hadoop_gcs_connector_metadata_cache/hail/hail-devel-0c961806173f.zip/hail/methods/qc.py in vep(dataset, config, block_size, name, csq); 545; 546 require_row_key_variant(dataset, 'vep'); --> 547 return MatrixTable(Env.hail().methods.VEP.apply(dataset._jvds, config, 'va.`{}`'.format(name), csq, block_size)); 548; 549. /usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py in __call__(self, *args); 1131 answer = self.gateway_client.send_command(command); 1132 return_value = get_return_value(; -> 1133 answer, self.gateway_client, self.target_id, self.name); 1134; 1135 for temp_arg in temp_args:. /hadoop_gcs_connector_metadata_cache/hail/hail-devel-0c961806173f.zip/hail/utils/java.py in deco(*args, **kwargs); 236 # this is a hack to suppress the original error's stack trace; 237 if _exception:; --> 238 raise _exception; 239; 240 return deco. FatalError: AssertionError: assertion failed. Java stack trace:; java.lang.AssertionError: assertion failed; 	at scala.Predef$.assert(Predef.scala:156); 	at is.hail.variant.MatrixTable.orderedRVDLeftJoinDistinctAndInsert(MatrixTable.scala:982); 	at is.hail.methods.VEP$.annotate(VEP.scala:429); 	at is.hail.methods.VEP$.apply(VEP.scala:434); 	at is.hail.methods.VEP.apply(VEP.scala); 	at sun.reflect",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3099:2188,config,config,2188,https://hail.is,https://github.com/hail-is/hail/issues/3099,1,['config'],['config']
Modifiability,"(<a href=""https://github.com/googleapis/java-storage/commit/8c59c64ccf0dd7753467b4c0f0bcf5f4b49c5bf0"">8c59c64</a>)</li>; </ul>; <h3>Documentation</h3>; <ul>; <li>Annotate all Option factory methods with their Nullability bounds (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1775"">#1775</a>) (<a href=""https://github.com/googleapis/java-storage/commit/3b8d137a113376d7dac9010b9207d435df2622f7"">3b8d137</a>)</li>; </ul>; <h2>v2.15.0</h2>; <h2><a href=""https://github.com/googleapis/java-storage/compare/v2.14.0...v2.15.0"">2.15.0</a> (2022-11-07)</h2>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/googleapis/java-storage/blob/main/CHANGELOG.md"">google-cloud-storage's changelog</a>.</em></p>; <blockquote>; <h2><a href=""https://github.com/googleapis/java-storage/compare/v2.15.1...v2.16.0"">2.16.0</a> (2022-12-06)</h2>; <h3>Features</h3>; <ul>; <li>Add {Compose,Rewrite,StartResumableWrite}Request.object_checksums and Bucket.RetentionPolicy.retention_duration (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1790"">#1790</a>) (<a href=""https://github.com/googleapis/java-storage/commit/31c1b18acc3c118e39eb613a82ee292f3e246b8f"">31c1b18</a>)</li>; <li>Added a new retention_duration field of Duration type (<a href=""https://github.com/googleapis/java-storage/commit/31c1b18acc3c118e39eb613a82ee292f3e246b8f"">31c1b18</a>)</li>; <li>Added object_checksums for compose/rewrite/startResumableWrite request (<a href=""https://github.com/googleapis/java-storage/commit/31c1b18acc3c118e39eb613a82ee292f3e246b8f"">31c1b18</a>)</li>; </ul>; <h3>Bug Fixes</h3>; <ul>; <li>Removed WriteObject routing annotations (<a href=""https://github.com/googleapis/java-storage/commit/31c1b18acc3c118e39eb613a82ee292f3e246b8f"">31c1b18</a>)</li>; </ul>; <h3>Documentation</h3>; <ul>; <li>Clarified relative resource names in gRPC IAM RPCs (<a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12545:5310,Rewrite,Rewrite,5310,https://hail.is,https://github.com/hail-is/hail/pull/12545,1,['Rewrite'],['Rewrite']
Modifiability,(Compile.scala:74); 	at is.hail.backend.BackendWithCodeCache.lookupOrCompileCachedFunction(Backend.scala:125); 	at is.hail.backend.BackendWithCodeCache.lookupOrCompileCachedFunction$(Backend.scala:121); 	at is.hail.backend.spark.SparkBackend.lookupOrCompileCachedFunction(SparkBackend.scala:273); 	at is.hail.expr.ir.Compile$.apply(Compile.scala:40); 	at is.hail.expr.ir.lowering.TableStageToRVD$.apply(RVDToTableStage.scala:112); 	at is.hail.backend.spark.SparkBackend.lowerDistributedSort(SparkBackend.scala:689); 	at is.hail.backend.Backend.lowerDistributedSort(Backend.scala:110); 	at is.hail.expr.ir.lowering.LowerAndExecuteShuffles$.$anonfun$apply$1(LowerAndExecuteShuffles.scala:23); 	at is.hail.expr.ir.RewriteBottomUp$.$anonfun$apply$2(RewriteBottomUp.scala:11); 	at is.hail.utils.StackSafe$More.advance(StackSafe.scala:60); 	at is.hail.utils.StackSafe$.run(StackSafe.scala:16); 	at is.hail.utils.StackSafe$StackFrame.run(StackSafe.scala:32); 	at is.hail.expr.ir.RewriteBottomUp$.apply(RewriteBottomUp.scala:21); 	at is.hail.expr.ir.lowering.LowerAndExecuteShuffles$.apply(LowerAndExecuteShuffles.scala:20); 	at is.hail.expr.ir.lowering.LowerAndExecuteShufflesPass.transform(LoweringPass.scala:157); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:16); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:16); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:14); 	at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:13); 	at is.hail.expr.ir.lowering.LowerAndExecuteShufflesPass.apply(LoweringPass.scala:151); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:22); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:20); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:6,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13633:9112,Rewrite,RewriteBottomUp,9112,https://hail.is,https://github.com/hail-is/hail/issues/13633,1,['Rewrite'],['RewriteBottomUp']
Modifiability,(DAGScheduler.scala:868); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2202); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2223); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2242); 	at is.hail.sparkextras.ContextRDD.runJob(ContextRDD.scala:362); 	at is.hail.rvd.RVD.$anonfun$head$1(RVD.scala:526); 	at is.hail.utils.PartitionCounts$.incrementalPCSubsetOffset(PartitionCounts.scala:73); 	at is.hail.rvd.RVD.head(RVD.scala:526); 	at is.hail.expr.ir.TableSubset.execute(TableIR.scala:1380); 	at is.hail.expr.ir.TableSubset.execute$(TableIR.scala:1377); 	at is.hail.expr.ir.TableHead.execute(TableIR.scala:1386); 	at is.hail.expr.ir.TableMapRows.execute(TableIR.scala:1905); 	at is.hail.expr.ir.Interpret$.run(Interpret.scala:784); 	at is.hail.expr.ir.Interpret$.alreadyLowered(Interpret.scala:56); 	at is.hail.expr.ir.InterpretNonCompilable$.interpretAndCoerce$1(InterpretNonCompilable.scala:16); 	at is.hail.expr.ir.InterpretNonCompilable$.rewrite$1(InterpretNonCompilable.scala:53); 	at is.hail.expr.ir.InterpretNonCompilable$.$anonfun$apply$1(InterpretNonCompilable.scala:25); 	at scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286); 	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36); 	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33); 	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:38); 	at scala.collection.TraversableLike.map(TraversableLike.scala:286); 	at scala.collection.TraversableLike.map$(TraversableLike.scala:279); 	at scala.collection.AbstractTraversable.map(Traversable.scala:108); 	at is.hail.expr.ir.InterpretNonCompilable$.rewriteChildren$1(InterpretNonCompilable.scala:25); 	at is.hail.expr.ir.InterpretNonCompilable$.rewrite$1(InterpretNonCompilable.scala:54); 	at is.hail.expr.ir.InterpretNonCompilable$.apply(InterpretNonCompilable.scala:58); 	at is.hail.expr.ir.lowering.InterpretNonCompilablePass$.transform(LoweringPass.scala:6,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/10682:10182,rewrite,rewrite,10182,https://hail.is,https://github.com/hail-is/hail/issues/10682,1,['rewrite'],['rewrite']
Modifiability,"(https://github.com/pytest-dev/pytest) from 6.2.5 to 7.0.1.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/pytest-dev/pytest/releases"">pytest's releases</a>.</em></p>; <blockquote>; <h2>7.0.1</h2>; <h1>pytest 7.0.1 (2022-02-11)</h1>; <h2>Bug Fixes</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9608"">#9608</a>: Fix invalid importing of <code>importlib.readers</code> in Python 3.9.</li>; <li><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9610"">#9610</a>: Restore [UnitTestFunction.obj]{.title-ref} to return unbound rather than bound method.; Fixes a crash during a failed teardown in unittest TestCases with non-default [__init__]{.title-ref}.; Regressed in pytest 7.0.0.</li>; <li><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9636"">#9636</a>: The <code>pythonpath</code> plugin was renamed to <code>python_path</code>. This avoids a conflict with the <code>pytest-pythonpath</code> plugin.</li>; <li><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9642"">#9642</a>: Fix running tests by id with <code>::</code> in the parametrize portion.</li>; <li><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9643"">#9643</a>: Delay issuing a <code>~pytest.PytestWarning</code>{.interpreted-text role=&quot;class&quot;} about diamond inheritance involving <code>~pytest.Item</code>{.interpreted-text role=&quot;class&quot;} and; <code>~pytest.Collector</code>{.interpreted-text role=&quot;class&quot;} so it can be filtered using <code>standard warning filters &lt;warnings&gt;</code>{.interpreted-text role=&quot;ref&quot;}.</li>; </ul>; <h2>7.0.0</h2>; <h1>pytest 7.0.0 (2022-02-03)</h1>; <p>(<strong>Please see the full set of changes for this release also in the 7.0.0rc1 notes below</strong>)</p>; <h2>Deprecations</h2>; <ul>; <li>; <p><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9488",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11516:1043,plugin,plugin,1043,https://hail.is,https://github.com/hail-is/hail/pull/11516,3,['plugin'],['plugin']
Modifiability,"(or maybe in a new design doc for regions). Observations:. Methods like loadElement (PContainer and inheritors) and loadField (PBaseStruct and inheritors) have region-taking parameterizations, but these methods are always wrappers for non-region parameterization (e.g loadElement(region, offset, idx) = loadElement(offset, idx)), which makes sense since our ""offsets"" are now memory addresses in these cases (can be read without knowledge of the region that allocated that memory). I believe historically these were really offsets into a region, requiring that region to load it. I believe the remaining use case, now that these offsets are absolute, is to allow for off-heap allocation. This seems slightly odd for a load operation/getter, but I am probably not seeing the intention. Thanks!. daniel king: The history is correct. daniel king: You may want a load to do allocation if you're loading from a lazy datastructure, like a lazily decoded BGEN genotype row. Alex Kotlar: ok, thanks Dan, will keep that parameterization as is. daniel king: You should check-in with Tim though, not clear that load is the place to do this. Tim Poterba: Yep, agree with Dan here. This was the reason I pushed back on your pr to remove the region args in December. Patrick Schultz: How would a lazily decoded datastructure work? Would it mutate to record the fact that some lazy value has already been computed? Or would it recompute every time that value is accessed?. Patrick Schultz: We probably want the former for performance, but we should figure out what the memory management for that looks like. Patrick Schultz: It might be that the lazy datastructure should really own the region(s) it uses for on-demand computation, rather than getting them from its callers. Tim Poterba: hmmm, you're right. Passing the region on load is not sufficient -- that region needs to be the owning region for the original data. Alex Kotlar: Would we want to associate an instance of a PType with a single region?. Patrick ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7826:1418,parameteriz,parameterization,1418,https://hail.is,https://github.com/hail-is/hail/issues/7826,1,['parameteriz'],['parameterization']
Modifiability,(since doesn't use any constructor arguments or other instance state). Should cost a bit less memory per region instance. Part of upcoming larger refactor that removes region instances where possible,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7599:146,refactor,refactor,146,https://hail.is,https://github.com/hail-is/hail/pull/7599,1,['refactor'],['refactor']
Modifiability,"(verbose event binding, DOM modification, needs polyfills since browser incompatibilities). JQuery makes this easier, but is 1) very slow, 2) provides no structure. Vanilla JS and JQuery tend to devolve to soup of global state-modifying code, with a lot of time spent on figuring out how to update values in DOM elements. . React/Next make DOM modification declarative, and very very easy. They provide a great deal of structure (especially with Next handling tooling), and thanks to the virtual dom / reconciliation process, performs, in many cases, much faster than directly modifying the DOM (HTML) (i.e plain JS). React also handles necessities like properly escaping all inputs, for XSS attack prevention. All of this in a bundle size that isn't significantly bigger than JQuery, without all of those benefits (and React is rapidly shrinking). It's possible to avoid Javascript. One can simulate interactivity by issuing a server GET request for a new page, i.e click on a link with a GET variable ?someVar=val and get a new page. This is slow (full round trip cost), and puts much more load on the server (since it not only needs to make the db call, but interpret PHP/Python to render the view). . There is a good reason why JS and monolithic single page applications became popular, with all of the initial-load (bundle size) downsides: client-side rendering allows perceived performance on the order of native mobile or desktop applications. Achieving interactive UI's without JS or Web Assembly, by using server-rendered pages, is ~impossible. We will achieve this interactivity without suffering the bundle-size-before-first-render cost, at minor developer costs vs server-side-only rendering. Lastly, it is possible to abuse any technology. Javascript brings to mind ""bloated""; this is an implementation issue. PHP/Python/Perl websites also used to be slow and ugly (Geocities).; * NodeJS/Javascript/V8 JIT is consistently faster than PHP, Python, and ~Java: https://www.techempower.com/b",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4931:2001,variab,variable,2001,https://hail.is,https://github.com/hail-is/hail/pull/4931,1,['variab'],['variable']
Modifiability,") from None. File ~/projects/hail/hail/python/hail/backend/py4j_backend.py:223, in Py4JBackend._rpc(self, action, payload); 221 if resp.status_code >= 400:; 222 error_json = orjson.loads(resp.content); --> 223 raise fatal_error_from_java_error_triplet(; 224 error_json['short'], error_json['expanded'], error_json['error_id']; 225 ); 226 return resp.content, resp.headers.get('X-Hail-Timings', ''). FatalError: NoSuchElementException: Ref with name __iruid_1834 could not be resolved in env BindingEnv((__iruid_1832 -> struct{},__iruid_2157 -> struct{}),None,None,()). Java stack trace:; is.hail.utils.HailException: error after applying LowerToDistributedArray; 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:23); 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:23); 	at is.hail.utils.package$.fatal(package.scala:89); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:32); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:19); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:19); 	at is.hail.backend.local.LocalBackend._jvmLowerAndExecute(LocalBackend.scala:205); 	at is.hail.backend.local.LocalBackend._execute(LocalBackend.scala:249); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$2(LocalBackend.scala:314); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1(LocalBackend.scala:309); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1$adapted(LocalBackend.scala:308); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:78); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.backend.ExecuteContext$.$anonfun$sco",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14245:3718,adapt,adapted,3718,https://hail.is,https://github.com/hail-is/hail/issues/14245,1,['adapt'],['adapted']
Modifiability,); 	at is.hail.expr.ir.EmitClassBuilder.resultWithIndex(EmitClassBuilder.scala:959); 	at is.hail.expr.ir.WrappedEmitClassBuilder.resultWithIndex(EmitClassBuilder.scala:272); 	at is.hail.expr.ir.WrappedEmitClassBuilder.resultWithIndex$(EmitClassBuilder.scala:270); 	at is.hail.expr.ir.EmitFunctionBuilder.resultWithIndex(EmitClassBuilder.scala:1489); 	at is.hail.expr.ir.Emit.$anonfun$emitI$282(Emit.scala:3275); 	at is.hail.expr.ir.IEmitCodeGen.map(Emit.scala:423); 	at is.hail.expr.ir.Emit.emitI(Emit.scala:3180); 	at is.hail.expr.ir.streams.EmitStream$.is$hail$expr$ir$streams$EmitStream$$emit$1(EmitStream.scala:166); 	at is.hail.expr.ir.streams.EmitStream$.produce(EmitStream.scala:390); 	at is.hail.expr.ir.streams.EmitStream$.produce$1(EmitStream.scala:313); 	at is.hail.expr.ir.streams.EmitStream$.produce(EmitStream.scala:1582); 	at is.hail.expr.ir.Emit.emitI(Emit.scala:2820); 	at is.hail.expr.ir.Emit.$anonfun$emitSplitMethod$1(Emit.scala:720); 	at is.hail.expr.ir.Emit.$anonfun$emitSplitMethod$1$adapted(Emit.scala:718); 	at is.hail.expr.ir.EmitCodeBuilder$.scoped(EmitCodeBuilder.scala:17); 	at is.hail.expr.ir.EmitCodeBuilder$.scopedVoid(EmitCodeBuilder.scala:27); 	at is.hail.expr.ir.EmitMethodBuilder.voidWithBuilder(EmitClassBuilder.scala:1422); 	at is.hail.expr.ir.Emit.emitSplitMethod(Emit.scala:718); 	at is.hail.expr.ir.Emit.emitInSeparateMethod(Emit.scala:743); 	at is.hail.expr.ir.Emit.emitI(Emit.scala:1008); 	at is.hail.expr.ir.Emit.emitInNewBuilder$1(Emit.scala:1031); 	at is.hail.expr.ir.Emit.$anonfun$emitI$39(Emit.scala:1221); 	at is.hail.expr.ir.EmitCode$.fromI(Emit.scala:545); 	at is.hail.expr.ir.Emit.$anonfun$emitI$38(Emit.scala:1221); 	at scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at scala.collection.T,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14362:11411,adapt,adapted,11411,https://hail.is,https://github.com/hail-is/hail/issues/14362,1,['adapt'],['adapted']
Modifiability,); 	at is.hail.utils.package$.fatal(package.scala:89); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:32); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:19); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:19); 	at is.hail.backend.local.LocalBackend._jvmLowerAndExecute(LocalBackend.scala:205); 	at is.hail.backend.local.LocalBackend._execute(LocalBackend.scala:249); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$2(LocalBackend.scala:314); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1(LocalBackend.scala:309); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1$adapted(LocalBackend.scala:308); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:78); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:78); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:13); 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:65); 	at is.hail.backend.local.LocalBackend.$anonfun$withExecuteContext$2(LocalBackend.scala:144); 	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:55); 	at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:62); 	at is.hail.backend.local.LocalBackend.withExecuteContext(LocalBackend.scala:130); 	at is.hail.backend.local.LocalBackend.execute(LocalBackend.scala:308); 	at is.hail.backend.BackendHttpHandler.handle(BackendServer.scala:88); 	at com.sun.net.httpserver.Filter$Chain.doFilter(Filter.java:79); 	at sun.net.httpserver.AuthFilter.doFilter(AuthFi,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14245:4508,adapt,adapted,4508,https://hail.is,https://github.com/hail-is/hail/issues/14245,1,['adapt'],['adapted']
Modifiability,")</li>; </ul>; <h3>Configuration</h3>; <ul>; <li>Do not format <code>__pypackages__</code> directories by default (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2836"">#2836</a>)</li>; <li>Add support for specifying stable version with <code>--required-version</code> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2832"">#2832</a>).</li>; <li>Avoid crashing when the user has no homedir (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2814"">#2814</a>)</li>; <li>Avoid crashing when md5 is not available (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2905"">#2905</a>)</li>; <li>Fix handling of directory junctions on Windows (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2904"">#2904</a>)</li>; </ul>; <h3>Documentation</h3>; <ul>; <li>Update pylint config documentation (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2931"">#2931</a>)</li>; </ul>; <h3>Integrations</h3>; <ul>; <li>Move test to disable plugin in Vim/Neovim, which speeds up loading (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2896"">#2896</a>)</li>; </ul>; <h3>Output</h3>; <ul>; <li>In verbose, mode, log when <em>Black</em> is using user-level config (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2861"">#2861</a>)</li>; </ul>; <h3>Packaging</h3>; <ul>; <li>Fix Black to work with Click 8.1.0 (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2966"">#2966</a>)</li>; <li>On Python 3.11 and newer, use the standard library's <code>tomllib</code> instead of <code>tomli</code>; (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2903"">#2903</a>)</li>; <li><code>black-primer</code>, the deprecated internal devtool, has been removed and copied to a; <a href=""https://github.com/cooperlees/black-primer"">separate repository</a> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2924"">#2924</a>)</li>; </ul>; <h3>Parser</h3>; <ul>; <li>Blac",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11696:1932,plugin,plugin,1932,https://hail.is,https://github.com/hail-is/hail/pull/11696,2,['plugin'],['plugin']
Modifiability,"* Primary goal is to rewrite TableMapRows to conform to new semantics: TableMapRows cannot change key fields. It can rename key fields, but can't change their values.; * While bugfixing, I changed a few places that were producing unsorted tables. In the end I'm not sure those changes are necessary to get tests to pass, but they need to be made anyways.; * Fix the places in python that were making assumptions about tables not sorting by key (always tables coming from columns of a matrixtable.; * Make `Table.keyBy` take `keys` as an `IndexedSeq` rather than an `Array`, consistent with previous changes.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4242:21,rewrite,rewrite,21,https://hail.is,https://github.com/hail-is/hail/pull/4242,1,['rewrite'],['rewrite']
Modifiability,"* Require AbstractRVDSpec to take a makeEncoder.; * Add a struct to hold all the encoders needed to write matrix columns and globals.; * Make MatrixValue.{writeGlobals,writeCols} methods take encoders and AbstractTypedCodecSpecs. Basically, where possible try to separate 'compile something' from 'use that compiled code'. Finalize write is currently not parallelize-able. This is a problem for; `write_matrix_tables` as it creates a large portion of work that is; single threaded. The reason for this is twofold. First, finalizeWrite; compiles encoders for columns, globals, and the globals' globals.; Second, MatrixValue is not serializable, and I don't think it can be.; This is a little trickier as it will require the exploding/broadcasting; of the globals/columns. This refactoring removes compiling encoders from; this logic.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8081:776,refactor,refactoring,776,https://hail.is,https://github.com/hail-is/hail/pull/8081,1,['refactor'],['refactoring']
Modifiability,"* Rewrite `MatrixTable.same` to not use `OrderedRVDPartitioner.enlargeToRange`; * Rewrite `MatrixTable.windowVariants` to not use `ContextRDD.adjustPartitions`. With those changes made, a bunch of code is no longer used, replaced by the new partitioner infrastructure:; * `OrderedRVD.adjustBoundsAndShuffle`; * `OrderedRVDPartitioner.enlargeToRange`; * `AdjustedPartitionsRDD`; * `ContextRDD.adjustPartitions`. `enlargeToRange` was no longer correct anyways, now that we allow gaps between partitions.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4298:2,Rewrite,Rewrite,2,https://hail.is,https://github.com/hail-is/hail/pull/4298,2,['Rewrite'],['Rewrite']
Modifiability,"* don't inherit from BaseType, which doesn't really fit.; * remove pyString methods; * remove _toPretty. Stacked on #7744, don't review until that goes in.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7868:8,inherit,inherit,8,https://hail.is,https://github.com/hail-is/hail/pull/7868,1,['inherit'],['inherit']
Modifiability,"**User-facing Changes:**; - Added preemptible and machine_type to resources configuration in addition to existing worker_type (will get removed at some point in the future).; - machine_type and preemptible are hidden options in hailtop.batch (I put them in for testing purposes); - Can only specify one of worker_type and machine_type; - Preemptible is only valid for machine_type; - If you specify the machine_type, your storage gets rounded up to the nearest Gi with 10 Gi being the minimum (this is because we use a persistent-SSD as the worker data disk and the min for this is 10 Gi. **Billing Changes:**; - The list of possible machine types we currently support is in the globals -- we only support the n1 family. I insert new resource rates into the Resources SQL table to account for the new nonpreemptible resources.; - If you have a job private instance, you are billed for that instance at the time of the instance's creation (not when it's activated). This is done by modifying the trigger for the attempts table to take the minimum attempt start time rather than the maximum. I'm not sure why we needed the maximum to begin with as the attempt start time was always the same. This is probably a place to double check before merging. **Job State Changes:**; - We now support a new state ""Creating"" which represents an instance has been spun up for a job, but it has not been activated yet; - The SQL user resources table and cancellable resources table needed to be changed to add the n_creating_jobs, n_cancellable_creating_jobs, and the n_cancelled_creating_jobs; - Added a new SQL function `mark_job_creating` that is only called by the job private instance creator.; - A lot of the existing SQL functions had to change to account for the fact that an instance in the pending state can have job-specific operations done such as mark_job_complete if the job is cancelled. In addition, the ""Creating"" state is like ""Running"" for some operations in that an attempt has been created and ac",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9972:76,config,configuration,76,https://hail.is,https://github.com/hail-is/hail/pull/9972,1,['config'],['configuration']
Modifiability,"- (1.0 / (n - 2.0)); starts_and_stops = hl.linalg.utils.locus_windows(ht.locus, args.radius, _localize=False); r2_adj = r2_adj._sparsify_row_intervals_expr(starts_and_stops, blocks_only=False); r2_adj = r2_adj.sparsify_triangle(); r2_adj = r2_adj.checkpoint(f'{tmp}/adj', overwrite=args.overwrite). if __name__ == '__main__':; main(); ```. ### Version. 0.2.128. ### Relevant log output. ```shell; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.128-17247d8990c6; LOGGING: writing to /home/edmund/.local/src/hail/hail-20240508-1553-0.2.128-17247d8990c6.log; Traceback (most recent call last):; File ""/home/edmund/.local/share/pyenv/versions/3.9.18/lib/python3.9/runpy.py"", line 197, in _run_module_as_main; return _run_code(code, main_globals, None,; File ""/home/edmund/.local/share/pyenv/versions/3.9.18/lib/python3.9/runpy.py"", line 87, in _run_code; exec(code, run_globals); File ""/home/edmund/.vscode/extensions/ms-python.debugpy-2024.6.0-linux-x64/bundled/libs/debugpy/adapter/../../debugpy/launcher/../../debugpy/__main__.py"", line 39, in <module>; cli.main(); File ""/home/edmund/.vscode/extensions/ms-python.debugpy-2024.6.0-linux-x64/bundled/libs/debugpy/adapter/../../debugpy/launcher/../../debugpy/../debugpy/server/cli.py"", line 430, in main; run(); File ""/home/edmund/.vscode/extensions/ms-python.debugpy-2024.6.0-linux-x64/bundled/libs/debugpy/adapter/../../debugpy/launcher/../../debugpy/../debugpy/server/cli.py"", line 284, in run_file; runpy.run_path(target, run_name=""__main__""); File ""/home/edmund/.vscode/extensions/ms-python.debugpy-2024.6.0-linux-x64/bundled/libs/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_runpy.py"", line 321, in run_path; return _run_module_code(code, init_globals, run_name,; File ""/home/edmund/.vscode/extensions/ms-python.debugpy-2024.6.0-linux-x64/bundled/libs/debugpy/_vendored/pydevd/_pydevd_bundle/pydevd_runpy.py"", line 135, in _run_module_code; _run_code(code, mod_globals, init_globals,; File ""/home/edmund/.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14537:1934,adapt,adapter,1934,https://hail.is,https://github.com/hail-is/hail/issues/14537,1,['adapt'],['adapter']
Modifiability,"- Add Hadoop config as additional parameter to c++ compiled function; - Add C++ `HadoopConfig` wrapper and method to create an output stream; - Implement `NDArrayWrite` node and emit on backend. ### Notes; - `RichHadoopConfiguration` is an `AnyVal`, which is not implemented as a Java `Object`. In order to use it with JNI (and our `ObjectArray` pattern), I had to cast it to an `AnyRef` and allocate it as an object. There might be a way to call `AnyVal` methods and not do the allocation but haven't found one yet.; - Our current system doesn't support compiled functions that don't return values. I made it support void-type IRs but for now enforced that they will return an int (returned 0 after a successful write).; - All our bufferspecs are blocking which won't work for a numpy-compatible encoding. Going to follow-up on this PR with a simple non-blocking spec. cc: @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5837:13,config,config,13,https://hail.is,https://github.com/hail-is/hail/pull/5837,1,['config'],['config']
Modifiability,"- Add `terminationGracePeriodSeconds` to query kubernetes deployment; - Implement `app.on_shutdown` signal handler to wait for all asyncio tasks to complete before returning.; - Upgrade `aiohttp == 0.7.3` to address tasks being cancelled before the on_shutdown method is called: https://github.com/aio-libs/aiohttp/issues/3593. ## Testing. - Adding a ""wait `n` seconds"" method that slept for n seconds, and returned the value of an environment variable. This environment variable meant I could track which version of the deployment my script ran against.; - Taking the `deploy.yaml` from the `deploy query` step of the dev deploy, adding the `TEST_VALUE` environment variable with some value and saving it as `new-deploy.yaml`; - Issuing the first wait request (for 50 seconds) (`https://internal.hail.populationgenomics.org.au/$NAMESPACE/query/api/v1alpha/wait?duration=50`); - Issuing the new deploy with:; ```bash; kubectl -n $NAMESPACE apply -f new-deploy.yaml; kubectl -n $NAMESPACE rollout status --timeout=10m deployment query; ```; - When the new pod is created (seen with `kubectl --namespace $NAMESPACE get pod`), issue the second request to the wait method.; - If all goes well, you should have:; - termination logs like those below,; - the first request successfully fulfilled with the response of env value being None (filled by the first pod); - The second request successfully filled, but has the value of the environment value, the one you set in the deploy.yaml (it got scheduled to the new node). Termination logs:. ```; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:22:40,472"", ""filename"": ""query.py"", ""funcNameAndLine"": ""on_shutdown:253"", ""message"": ""On shutdown request received, with 2 tasks left"", ""hail_log"": 1}; ++ term; ++ kill -TERM 7; + true; + '[' no == yes ']'; + trap - SIGTERM SIGINT; + wait 7; {""severity"": ""INFO"", ""levelname"": ""INFO"", ""asctime"": ""2021-02-24 23:23:26,004"", ""filename"": ""hail_logging.py"", ""funcNameAndLine"": ""log:40"", ""message"": """,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10106:444,variab,variable,444,https://hail.is,https://github.com/hail-is/hail/pull/10106,3,['variab'],['variable']
Modifiability,"- Add make_formatter (in batch_cli_utils.py) options for csv, tsv, grid, and orgtbl; - Refactor list_batches.py to always use result of make_formatter; - Changed default format for `hailctl batch list` to grid",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11215:87,Refactor,Refactor,87,https://hail.is,https://github.com/hail-is/hail/pull/11215,1,['Refactor'],['Refactor']
Modifiability,"- Added a new build step `test_pipeline_docs` that runs doctest for the pipeline module; - Added pipeline docs to the hail/Makefile with a new target `pipeline-docs`. I also changed the `make-docs` target to be `base-docs` and `hail-docs`. `pipeline-docs` and `hail-docs` depend on `base-docs` and `upload-docs` depends on `hail-docs` and `pipeline-docs`; - Fixed a bunch of places in the documentation for clarity and to make the doctests work.; - Note, some examples are skipped because we can't run docker within docker in local mode. We can consider at another time point running all of the examples with the BatchBackend; - There's a bunch of Sphinx stuff I had to do to get the docs to render how I wanted them to with regards to inherited members (it was including all string methods by default even though). It's possible I can clean that up a bit, but I think it's fine for now.; - Added a link to the docs to the batch dropdown menu.; - Docs will appear at hail.is/docs/pipeline for now. Eventually everything will be renamed to batch, but I elected not to do that now.; - I checked the dropdown works correctly.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8086:736,inherit,inherited,736,https://hail.is,https://github.com/hail-is/hail/pull/8086,1,['inherit'],['inherited']
Modifiability,"- Added a shared image gallery to terraform; - Added a managed identity `batch-worker` to terraform; - Gave `batch-worker` ""acrpull"" privileges for the resource group; - Added new config variables in config.mk that are specific to Azure; - Added commands to batch/Makefile to create a boot disk image; - Added an Azure-specific startup script that installs Docker and the CLI and then authenticates and pulls the base image. The disk image we create is specialized. This means it has credentials in there after publishing it. I think this is okay and I specifically used the batch-worker managed identity to login for this. I can try and double check this assumption if you think I'm not correct after reading these docs: https://docs.microsoft.com/en-us/cli/azure/vm?view=azure-cli-latest#az_vm_create. > Accept system or user assigned identities separated by spaces. Use '[system]' to refer system assigned identity, or a resource id to refer user assigned identity. Check out help for more examples. I had to give the batch-worker managed identity in the resource group we want permissions to be an identity for a VM in the build-batch-worker-image resource group.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10834:180,config,config,180,https://hail.is,https://github.com/hail-is/hail/pull/10834,3,"['config', 'variab']","['config', 'variables']"
Modifiability,- Added a single `BlockMatrixFilter` IR node for filtering a subset of rows and columns.; - I don't really have a great way of talking about filtering on some dimensions and not others. Filter takes a list of list of indices (one list per dimension) and if the list is empty that dimension is not filtered on. While there's no other meaningful interpretation of an empty list it feels like you're saying you don't want to keep any of the indices. Could use optionals for each dimension but `None` seems just as confusing and would require some small refactoring of the parser. The more consistent thing to do is pass along something like `range(n_rows)` but that just seems wasteful.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5491:550,refactor,refactoring,550,https://hail.is,https://github.com/hail-is/hail/pull/5491,1,['refactor'],['refactoring']
Modifiability,"- Added idea of two types of outputs: internal and external. Internal outputs are copied between tasks and external outputs are user specified copies of files.; - Added `valid` and `mentioned` which are sets of resources tasks keep track of. `valid` checks whether the resources were properly declared. `mentioned` keeps a record of the resources used in the command for variables that need to be declared.; - Changed when outputs are copied for external outputs. TaskResourceFiles are copied when the task finishes rather than at the end of the pipeline. InputResourceFiles are copied at the beginning of the pipeline as one job.; - `inputs`, `internal_outputs`, and `external_outputs` only contain resource files (not resource groups) which simplified the code quite a bit!",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5962:371,variab,variables,371,https://hail.is,https://github.com/hail-is/hail/pull/5962,1,['variab'],['variables']
Modifiability,"- Added support for blobfuse, which is Azure's equivalent of gcsfuse.; - Renamed operations/variables to cloudfuse to be generic; - The validator is slightly more complicated because there is a double renaming of gcsfuse to cloud fuse to gcsfuse for old clients. This is to maintain backwards compatibility with old instances. Once v21 instances die, then we can remove the extra backwards compatibility step.; - renamed instance_env.py files to worker_api.py files. @daniel-goldstein @danking Can you decide amongst yourselves who should review this? Maybe Dan takes a first glance and then Daniel reads it in more detail?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11211:92,variab,variables,92,https://hail.is,https://github.com/hail-is/hail/pull/11211,1,['variab'],['variables']
Modifiability,- Added the AzureGraphClient which creates applications and service principals; - Modified Auth to create service principals and delete them; - Added two fields to the auth database that optionally store the application ID and the credentials secret name; - Had to modify AzureCredentials a bit to account for a different scope (one of the Azure Credentials types cannot take multiple scopes for some reason); - There's an auth database migration here!; - I tried to figure out what API calls result in the same result in the portal. It's possible the exact calls are not quite right (ex: addPassword on the application versus the service principal). TODO:; - Figure out how to use the global config in auth/Makefile to template global.cloud; - Double check the service principal creation is correct (I know the appID and password end up working to create resources at least). cc: @danking,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10986:693,config,config,693,https://hail.is,https://github.com/hail-is/hail/pull/10986,1,['config'],['config']
Modifiability,"- Aggregate along a set of dimensions of an NDArray; - As a first pass I made it only sum, but intend on extending the body to generic hail aggregators",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6049:105,extend,extending,105,https://hail.is,https://github.com/hail-is/hail/pull/6049,1,['extend'],['extending']
Modifiability,- Allow ci-related secrets in azure; - remove `create_ci_test_repo.token` in `ci/Makefile` since that is not retrieved from the `ci-config` secret; - Use `standard` memory in the test build.yaml,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11119:132,config,config,132,https://hail.is,https://github.com/hail-is/hail/pull/11119,1,['config'],['config']
Modifiability,"- Array: append, extend; - Set: add, union, difference, intersection, issubset",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1491:17,extend,extend,17,https://hail.is,https://github.com/hail-is/hail/pull/1491,1,['extend'],['extend']
Modifiability,"- Changed NDArrayRef node to take a _sequence_ of IR for the indices as opposed to a single IR. This will make operations like slicing much easier, simplifies IR emission and allows us to typecheck that you have enough index variables; - Refactored `linearizeIndices`, a function that takes a Scala sequence of index variables for a ndarray and emits the single array index, so that it actually checks now that each index is within the shape length bounds of that dimension.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5876:225,variab,variables,225,https://hail.is,https://github.com/hail-is/hail/pull/5876,3,"['Refactor', 'variab']","['Refactored', 'variables']"
Modifiability,"- Expand variables at definition; - Fix pip definition, allow it to be overwritten; - Copy hail_version and hail_pip_version into hailctl to not break; local PYTHON_PATH settings.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6322:9,variab,variables,9,https://hail.is,https://github.com/hail-is/hail/pull/6322,1,['variab'],['variables']
Modifiability,- Fixes #3691 ; - I also refactored the python tests to move all of the import/export tests to test_io.py,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3695:25,refactor,refactored,25,https://hail.is,https://github.com/hail-is/hail/pull/3695,1,['refactor'],['refactored']
Modifiability,"- Implement broadcasting of NDArrays. This essentially just gives NDArrays additional dimensions of length one, which changes the view onto the NDArray but not the underlying data. This allows us to promote smaller-dimensional NDArrays before a Map2 so both NDArrays have the same number of dimensions. The loops for the map will loop through the _unified shape_ of both child NDArrays with the same semantics as numpy (if corresponding dimensions are not equal, they are still compatible if one is 1 in which case you would take the larger one). Dimensions of length 1 have a stride of 0, so indexing into the array as if it were broadcast works and is totally free. The only additional benefit deforesting would actually give you is putting fewer loop variables into the calculation of the index.; - Restructured emit for NDArrays with stub-like emit method for deforesting so deforesting will be very easy to implement, but not currently deforesting anything. Thought this was necessary for `NDArrayReindex`. Ultimately it wasn't but is what we'll want to do next with maps anyway.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5922:754,variab,variables,754,https://hail.is,https://github.com/hail-is/hail/pull/5922,1,['variab'],['variables']
Modifiability,"- Incorporated navbar into Sphinx output; - Refactored CSS; - Added some formatting of Sphinx output. To-Do:; Once this branch is merged, we need to modify the Discourse copy of navbar.html",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1100:44,Refactor,Refactored,44,https://hail.is,https://github.com/hail-is/hail/pull/1100,1,['Refactor'],['Refactored']
Modifiability,- Intervals cannot be in GenomeReference constructor because intervals; are parameterized by reference with Ordering[Locus],MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2533:76,parameteriz,parameterized,76,https://hail.is,https://github.com/hail-is/hail/pull/2533,1,['parameteriz'],['parameterized']
Modifiability,- Intervals cannot be in GenomeReference constructor because intervals; are parameterized by reference; - Made python genome reference operations lazy,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2530:76,parameteriz,parameterized,76,https://hail.is,https://github.com/hail-is/hail/pull/2530,1,['parameteriz'],['parameterized']
Modifiability,"- Most of the code is actually the same, but I was intentionally not deforesting until now to get some benchmarks.; - Basically all you need to do is compose the `outputElement`s of your children (the body of the loops) and compute what the ultimate bounds (shape) of the nested loops should be.; - For Reindex, we statically reorder the loop variables used to index into the NDArray instead of permuting the shape/strides at runtime. Not a huge performance improvement but in the broadcasting case (adding dimensions) it's at least fewer multiplications at runtime in the loop body to compute the index.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6026:343,variab,variables,343,https://hail.is,https://github.com/hail-is/hail/pull/6026,1,['variab'],['variables']
Modifiability,"- Need to install npm on build server; - Install following node packages: jsdom, jquery, mathjax-node; - Set the Global Environment Variable for where Node packages are: $NODE_PATH",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/800:132,Variab,Variable,132,https://hail.is,https://github.com/hail-is/hail/pull/800,1,['Variab'],['Variable']
Modifiability,- Refactored `exportRectangles` on BlockMatrix from a static function with an input and output file to an instance function with an output file that writes the instance.; - Added `BlockMatrixRectanglesWriter` so exporting rectangles happens through the IR.; - Updated tests and deleted parts of tests that dealt with invalid inputs that aren't applicable when exporting from an already loaded BlockMatrix.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5478:2,Refactor,Refactored,2,https://hail.is,https://github.com/hail-is/hail/pull/5478,1,['Refactor'],['Refactored']
Modifiability,"- Register arithmetic functions for NDArray w/ NDArray, value w/ NDArray and NDArray w/ value both in Scala and Python; - Add natural number and natural number variable to both Scala and Python and make NDArray's `nDim` a `NatBase`. This allows specifying function signatures that work on NDArrays of any (but matching) dimensionality.; - Add `NDArrayNumericExpression` and arithmetic methods on it. ### Notes; - In Scala, I directly register the same numeric operations for arrays on ndarrays for reuse and so they don't diverge. However, the IRs generated for `%` and `**` are not supported in C++ yet. I removed the front-end methods for them on `NDArrayNumericExpression` but left the rest of the infrastructure in.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5737:160,variab,variable,160,https://hail.is,https://github.com/hail-is/hail/pull/5737,1,['variab'],['variable']
Modifiability,"- Using the full domain name instead of the shorthand `<service>.<namespace>` isn't strictly necessary but just made me nervous and I opted for the full unambiguous domain for in-cluster services (what if we had a namespace named `com`?? I feel like that would break some things); - I got the configuration wrong on how to tell envoy *not* to worry about certs of internal namespaces (I'd recommend using the `split` view for the diff because otherwise it's pretty hard to read); - For internal namespaces, using the `prefix` parameter for matching a route allowed `/foo/batch` to match a route like `/foo/batch-driver` which is obviously not great. the `path_separated_prefix` parameter actually does what we want; - Fixed the batch tests not to look at the HTTP 1.1 reason phrase and instead look at the response body to determine the error",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12392:293,config,configuration,293,https://hail.is,https://github.com/hail-is/hail/pull/12392,1,['config'],['configuration']
Modifiability,"- [ ] (@tpoterba) caf1e1e673 add fails_service_backend; - [ ] (@tpoterba, @cseed) a979dfba58 [hail] introduce and use mktemp and mktempd; - [ ] (@tpoterba) dcf026b01c [hail] make is.hail.expr.ir.functions threadsafe; - [ ] (@tpoterba) 807f38c20e [hail] fix use of row requiredness in lowerDistributedSort; - [ ] (@catoverdrive) 12df8eb456 [query-service] handle void-typed IRs in query-service; - [ ] (@catoverdrive) 03357ee83d [query-service] make user cache thread-safe; - [ ] (@tpoterba) 6c6734bc71 [query-service] bugfix: preserve globals through a shuffle; - [ ] (@catoverdrive) a3d2572ce7 [shuffler] log ShuffleCodecSpec anytime it is created; - [ ] (@daniel-goldstein) 8949dfec3c [scala-lsm] bugfix: least key may equal greatest key; - [ ] (@daniel-goldstein) 6067bd8e51 [services] discovered new transient error; - [ ] (@daniel-goldstein) c8356d30bb [shuffler] more assertions in ShuffleClient; - [ ] (@daniel-goldstein) 9991da90f0 [shuffler] bugfix: shuffler needs a HailContext to decode loci; - [ ] (@daniel-goldstein) bc0140ab6f [query-service] move hail.jar earlier in Dockerfile; - [ ] (@daniel-goldstein) f96c28174d [query-service] permit pod scaling and remove cpu limit; - [ ] (@catoverdrive) 6ae26339fe [query-service] simplify socket handling; - [ ] (@jigold) f3db30e23f [batch] teach JVMJob where to find the hail configuration files; - [ ] (@daniel-goldstein) b5c6d85554 [query-service] switch to services team approved logging; - [ ] (@tpoterba) 35a306c066 [query-service] query workers need a hail context; - [ ] (@daniel-goldstein, @catoverdrive) 051c89b8e7 [query-service] use a UNIX Domain Socket for Py-Scala communication; - [ ] (@daniel-goldstein, @catoverdrive) ad9ea73d7a [query-service] run tests against query service",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10072:1334,config,configuration,1334,https://hail.is,https://github.com/hail-is/hail/pull/10072,1,['config'],['configuration']
Modifiability,- `CreateNamespaceStep.public` was entirely unused; - `adminServiceAccount` is not used in `build.yaml` so `CreateNamespaceStep.admin_service_account` is always `None` meaning it has no effect.; - The three environment variables that I deleted from the `deployment.yaml` are as far as I can tell entirely unused (they are now grabbed from the global config),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13967:219,variab,variables,219,https://hail.is,https://github.com/hail-is/hail/pull/13967,2,"['config', 'variab']","['config', 'variables']"
Modifiability,"- `geom_point` did not correctly include color in the legend when the color was a continuous variable that had been mapped to a discrete one, e.g. an integer that the user specified as the color. - `geom_bar` and `geom_col` suffered the same issue but additionally lacked the ability to name each color group in the legend.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12768:93,variab,variable,93,https://hail.is,https://github.com/hail-is/hail/pull/12768,1,['variab'],['variable']
Modifiability,- added sort on Arrays in expr; - extended sort and sortBy to take an optional Boolean parameter for ascending; - modifed behavior to always place null values at the end; - updated HailExpressionLanguage.md; - added tests for sort and sortBy to ExprSuite,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/511:34,extend,extended,34,https://hail.is,https://github.com/hail-is/hail/pull/511,1,['extend'],['extended']
Modifiability,- added tests for scans; - added tests for binding variables from outside aggregators; - fixed bugs caught by aforementioned tests; - removed some unused code in CodeAggregator.scala; - swapped ordering of args in ApplyAggOp/ApplySeqOp to match ordering in AggSignature; - added parser + IR tests for AggFilter/AggExplode/AggGroupBy in Scala,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4565:51,variab,variables,51,https://hail.is,https://github.com/hail-is/hail/pull/4565,1,['variab'],['variables']
Modifiability,"- automatically download catch.hpp from GitHub if it's missing; - remove builtin rules and suffix based rules to improve performance and ease debugging; - change Makefile variable definitions to match our standard `FOO OP VAL` (note: two spaces); - rely on `clang -MM` (see: [Clang command line reference](https://clang.llvm.org/docs/ClangCommandLineReference.html) and below explanation) to generate precise dependencies for object files (including source and header files); - explicitly specify which files depend on `NUMBER_OF_GENOTYPES_PER_ROW` to be set (namely the dependency file and the object file associated with `ibs.cpp`); - break `TEST_OBJECTS` into two steps so that we can have `_test.cpp` files which do not have corresponding `.cpp` files (consider, for example, a header-only file, which ApproximateQuantiles will be); - eliminate `$(BUILD)/headers` in favor of precise dependency tracking described above; - remove the target `$(BUILD)`, directories don't work the way you think in Make, it's better to have individual rules create the containing directories when necessary; - remove `wget` nonsense, standardize on `curl -sSL` (which produces useful error messages). ---. # clang -MM. This argument to clang allows us to generate ""depfile"" or ""dependency files"" which are valid `Makefile`s describing how object files depend on `c`, `cpp`, `h`, and `hpp` files. `clang -MM foo.cpp` writes to stdout a Makefile that indicates how `foo.o` depends on preprocessor includes of other *user* files. For example,. ```; # cat foo.cpp; #include<stdio.h>; #include ""bar.h""; # clang -MM foo.cpp; foo.o: foo.cpp bar.h; ```. The `-MT target` allows us to specify the target's name:; ```; # clang -MM foo.cpp -MT fiddle; fiddle: foo.cpp bar.h; ```. The `-MQ` argument asks `clang` to quote the variable before make sees it, so (nb, I first quote it for the shell so it doesn't get seen as an env var):; ```; # clang -MM foo.cpp -MQ '$fiddle'; $$fiddle: foo.cpp bar.h; ```. The `-MG` argument tel",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5331:171,variab,variable,171,https://hail.is,https://github.com/hail-is/hail/pull/5331,1,['variab'],['variable']
Modifiability,"- but don't enable; - add back deployable to watched branches; - add deploy flag to build configuration; - added Code option that represents a version of code (but not quite a sha, because it might do a merge that produces a new sha) and can check itself out. I think this gets us pretty close. Working on ci2 tests now.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5938:90,config,configuration,90,https://hail.is,https://github.com/hail-is/hail/pull/5938,1,['config'],['configuration']
Modifiability,"- convert the VEP configuration file to JSON; - let the conf file fully specify the command line, environment and output schema. This is breaking change. I updated the VEP config files on the cloud:. ```; $ gsutil ls gs://hail-common/vep/vep/*.json; gs://hail-common/vep/vep/vep81-gcloud.json; gs://hail-common/vep/vep/vep85-gcloud.json; gs://hail-common/vep/vep/vep92-GRCm38-gcloud.json; ```. But pipelines will have to change to use them. I tested GRCm38, but not the other ones. @konradjk, would you be up for testing the standard usage? (We really need to add automated VEP tests.)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3872:18,config,configuration,18,https://hail.is,https://github.com/hail-is/hail/pull/3872,2,['config'],"['config', 'configuration']"
Modifiability,- copied files from hail.is repository to www/; - added navbar; - added bootstrap and jquery to repository; - added Tutorial; - added Overview page; - split docs into Introduction and Commands Reference; - moved Getting Started to it's own page; - modified gradle build step from `createDocs` to `createWebsite` (maintained `createDocs` for backwards compatibility); - website is assembled in `build/docs/`; - refactored Node code so one node script compiles all 4 docs pages; - iPython notebook is automatically compiled with R images using `notedown`,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/875:410,refactor,refactored,410,https://hail.is,https://github.com/hail-is/hail/pull/875,1,['refactor'],['refactored']
Modifiability,- fixed structure of docs + links (hail/* -> docs/stable/*); - Added Hail version + supported spark versions + git hash as gradle variables; - Used these versions in Sphinx.; - Changed path of distribution links in getting started to point at current hash.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2034:130,variab,variables,130,https://hail.is,https://github.com/hail-is/hail/pull/2034,1,['variab'],['variables']
Modifiability,"- front_end returns 200 OK if a bunch is already inserted for an open batch; - add a test that inserts failures on every third http request made by a batch builder; - add `MultipleExceptions` which can be raised and have many causes; - set minimum log level of aioclient to WARNING, so users see `log.warn` messages; - increase bunch byte size to 8MiB (was 8MB), increase bunch size to 8 * 1024 (was 1000, which, for typical Konrad jobs (1kB) prevents fully filling the HTTP request); - make the previous two parameters configurable (primarily for testing purposes); - souped up AsyncThrottledGather to bail out after a configurable number of exceptions. For the restartable client we:; 1. create the batch, if that succeeds we never try to create again; 2. create the json-encoded job_spec bunches, this only fails on user error; 3. submit 50-way parallel bunch, with a maximum of (by default) 10 individual request failures; 4. if any request fails, raise an exception, which is caught by outer `submit`, which retries a configurable number of times, logging a configurable number of errors",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7875:520,config,configurable,520,https://hail.is,https://github.com/hail-is/hail/pull/7875,4,['config'],['configurable']
Modifiability,"- move environment.yml files out of the packaged directory so they don't get shipped to end users. - add `make test-pip-deploy` which pip deploys to the next available `devN` version (you have to wait a bit before you can `pip install` it, so I didn't include that in the test, but you can do that manually, or a motivated person can write a polling script). - add `build/dev-conda` which ensures that if the dev-environment file changes since you last ran `make build/dev-conda`, your conda environment is updated. - pedantically use the correct conda environment _everywhere_. - use python to determine cpu count instead of fixing it at 2. - add `jq` as an `env-setup.sh` dependency. - add `make build/credentials.json` which `scp`s a new JSON file containing credentials to the local machine, moreover there are two rules for automatically extracting the credentials for PYPI from this JSON file. - use `ENV_VAR`, a make macro, to ensure we rebuild the appropriate targets (but no more) when a relevant environment variable is changed since last build. - added several missing breeze versions, now we can easily test against new spark versions, just run `SPARK_VERSION=4.0.0 make test`. - fold doctests in with regular tests under `test-python` which uses pytest, no more unnecessary copying as well. - fix build-info. - delete two unused python files in hail root. - correct LIBSIMDPP dependency in C makefile. # Not Doing Yet. - incorporate native lib into this Makefile. Instead, if anything changed in src/main/c since we last built, we rebuild. - fix the directory structure to be compliant with pytests recommended structure",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5194:1018,variab,variable,1018,https://hail.is,https://github.com/hail-is/hail/pull/5194,1,['variab'],['variable']
Modifiability,"- moved k8s accounts, roles and bindings to vdc/k8s-config.yaml (applied to current cluster); - created deploy service account with privileges on default (should lock down to minimal set); - added batch service account option, use to launch deploy job with deploy-svc; - give batch-svc default-deploy binding so it can launch the deploy pod with suitable privileges",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4596:52,config,config,52,https://hail.is,https://github.com/hail-is/hail/pull/4596,1,['config'],['config']
Modifiability,"- put_on_ready should never be in an ensure_future, but I had to keep it there when used in Pod.create() because I didn't want to block the create/delete pool waiting for the pods to be on the ready queue; otherwise, it should be fixed everywhere else. - I added `Binds: None` in the Docker config as the default because if we specify a HostConfig, then I believe Docker uses a default of {} which might be allocating a volume unnecessarily. I can't find where I read that before. I can double check the performance of the change if you want. I'm pretty sure it helps.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7347:291,config,config,291,https://hail.is,https://github.com/hail-is/hail/pull/7347,1,['config'],['config']
Modifiability,"- remove shadowJar dependency of makeDocsNoTest; - cleanup markdown conversion, make general: any pair of .md and .xslt file defines a new top-level page; - harmonize naming to enable the above, landing.md becomes index.md; - ctrl-c actually kills the site docker container now; - `(cd site && make test)` tests the site image with the contents of `hail/build/www` (we need a top-level makefile to manage that dependency properly); - added a 404 page; ![screen shot 2018-12-07 at 3 33 13 pm](https://user-images.githubusercontent.com/106194/49671603-72713580-fa36-11e8-91cf-b24936257628.png); - fixed redirect rules for /docs and /hail see note below. Resolves #4919 . ---; ### On NGINX Redirects; The internet seems to think that `rewrite` for redirects is ""bad"", ergo, I ignore the deleted rule and explain the additions. ```; location = /docs/ {; return 307 $scheme://$http_host/docs/0.2;; }; location ~ ^/hail(|/.*)$ {; return 301 $scheme://$http_host/docs/0.1$1;; }; ```. The [location](http://nginx.org/en/docs/http/ngx_http_core_module.html#location) directive can match `=` exactly, `~` by regex, `~*` by case insensitive regex, and `^~` which I do not understand. Question one: does this redirect `hail.is/docs` to `/docs/0.2`? Yes, the last paragraph of the location docs:. > If a location is defined by a prefix string that ends with the slash character, and requests are processed by one of proxy_pass, fastcgi_pass, uwsgi_pass, scgi_pass, memcached_pass, or grpc_pass, then the special processing is performed. In response to a request with URI equal to this string, but without the trailing slash, a permanent redirect with the code 301 will be returned to the requested URI with the slash appended. The docs appear incomplete, though, because this is a `return` rule, but it gets the 301. Question two: does this redirect `hail.is/docs/foo` to `/docs/0.2/foo`. No, the docs redirect is an `=` or exact match so `hail.is/docs/foo` is a 404. Question three: does this redirect `/hail/over",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4929:732,rewrite,rewrite,732,https://hail.is,https://github.com/hail-is/hail/pull/4929,1,['rewrite'],['rewrite']
Modifiability,"- removed nullFit function entirely, simplifying code; - null model variables are first rather than last, simplifying code; - logreg fit now only computes margins of score and firth on first iteration; - score and fisher are Options in LogisticRegressionFit (not computed by Firth); - added Firth test to logreg; - added R test of Firth test; - added Firth to EPACTS test; - added Firth to logreg documentation; - added TriSolve for solving triangular systems (LAPACK dtrtrs), used in fitFirth; - added TriSolve test",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1375:68,variab,variables,68,https://hail.is,https://github.com/hail-is/hail/pull/1375,1,['variab'],['variables']
Modifiability,"- removes everything related to ci1, pr-builder, hail-ci-*, etc.; - adds build.yaml ci2 build configuration; - makes master deployable (will probably fail)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5974:94,config,configuration,94,https://hail.is,https://github.com/hail-is/hail/pull/5974,1,['config'],['configuration']
Modifiability,"- retry every deadlock in two deadlock prone SQL operations; - add prometheus metrics for cores; - fix prometheus when you're not in the default namespace; - retry every docker 500 error, it's 500, not our fault, just retry, right?; - create a billing account for the dev deploying user; - rewrite a couple queries to harmonize table locking a bit; - add globals to delete tables script; - fix list_batches, which was broken by the query language changes; - include primary services developers' namespaces in prometheus monitoring. Fixes #7756",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7783:290,rewrite,rewrite,290,https://hail.is,https://github.com/hail-is/hail/pull/7783,1,['rewrite'],['rewrite']
Modifiability,"- rewrite ArrayElements.initOp to take nested initOps as arguments directly; - pass in EmitTriplet instead of RVAVariable; get rid of RVAVariable; - StagedRegionValueAggregator -> StagedAggregator, since doesn't always use RVs; - refactor tests to be more extensible for new aggregators",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6687:2,rewrite,rewrite,2,https://hail.is,https://github.com/hail-is/hail/pull/6687,2,"['refactor', 'rewrite']","['refactor', 'rewrite']"
Modifiability,"- rewrite Python broadcasts as Literal nodes; - Add LiftLiterals IR transformation, which adds to globals. This is necessary to start working on functionality to allow `Table.aggregate` to return an expression instead of a value to Python.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4116:2,rewrite,rewrite,2,https://hail.is,https://github.com/hail-is/hail/pull/4116,1,['rewrite'],['rewrite']
Modifiability,"---------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-1-e24d842d2b9a> in <module>; ----> 1 import hail. ~/sandbox/hail/venv/3.8/lib/python3.8/site-packages/hail/__init__.py in <module>; 32 # F401 '.expr.*' imported but unused; 33 # E402 module level import not at top of file; ---> 34 from .table import Table, GroupedTable, asc, desc # noqa: E402; 35 from .matrixtable import MatrixTable, GroupedMatrixTable # noqa: E402; 36 from .expr import * # noqa: F401,F403,E402. ~/sandbox/hail/venv/3.8/lib/python3.8/site-packages/hail/table.py in <module>; 2 import itertools; 3 import pandas; ----> 4 import pyspark; 5 from typing import Optional, Dict, Callable; 6 . ~/sandbox/hail/venv/3.8/lib/python3.8/site-packages/pyspark/__init__.py in <module>; 49 ; 50 from pyspark.conf import SparkConf; ---> 51 from pyspark.context import SparkContext; 52 from pyspark.rdd import RDD, RDDBarrier; 53 from pyspark.files import SparkFiles. ~/sandbox/hail/venv/3.8/lib/python3.8/site-packages/pyspark/context.py in <module>; 29 from py4j.protocol import Py4JError; 30 ; ---> 31 from pyspark import accumulators; 32 from pyspark.accumulators import Accumulator; 33 from pyspark.broadcast import Broadcast, BroadcastPickleRegistry. ~/sandbox/hail/venv/3.8/lib/python3.8/site-packages/pyspark/accumulators.py in <module>; 95 import socketserver as SocketServer; 96 import threading; ---> 97 from pyspark.serializers import read_int, PickleSerializer; 98 ; 99 . ~/sandbox/hail/venv/3.8/lib/python3.8/site-packages/pyspark/serializers.py in <module>; 69 xrange = range; 70 ; ---> 71 from pyspark import cloudpickle; 72 from pyspark.util import _exception_message; 73 . ~/sandbox/hail/venv/3.8/lib/python3.8/site-packages/pyspark/cloudpickle.py in <module>; 143 ; 144 ; --> 145 _cell_set_template_code = _make_cell_set_template_code(); 146 ; 147 . ~/sandbox/hail/venv/3.8/lib/python3.8/site-packages/pyspark/cloudpickle.py in _make_cell_set_template_code(); ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/10197:10701,sandbox,sandbox,10701,https://hail.is,https://github.com/hail-is/hail/issues/10197,1,['sandbox'],['sandbox']
Modifiability,"----------. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 8 in stage 1.0 failed 20 times, most recent failure: Lost task 8.19 in stage 1.0 (TID 2899) (hail-test-w-1.australia-southeast1-a.c.pb-dev-312200.internal executor 3): is.hail.utils.HailException: VEP command '/vep --format vcf --json --everything --allele_number --no_stats --cache --offline --minimal --assembly GRCh38 --fasta /opt/vep/.vep/homo_sapiens/95_GRCh38/Homo_sapiens.GRCh38.dna.toplevel.fa.gz --plugin LoF,loftee_path:/opt/vep/Plugins/,gerp_bigwig:/opt/vep/.vep/gerp_conservation_scores.homo_sapiens.GRCh38.bw,human_ancestor_fa:/opt/vep/.vep/human_ancestor.fa.gz,conservation_file:/opt/vep/.vep/loftee.sql --dir_plugins /opt/vep/Plugins/ -o STDOUT' failed with non-zero exit status 2; VEP Error output:; Smartmatch is experimental at /opt/vep/Plugins/de_novo_donor.pl line 175.; Smartmatch is experimental at /opt/vep/Plugins/de_novo_donor.pl line 214.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 191.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 194.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 238.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 241.; DBI connect('dbname=/opt/vep/.vep/loftee.sql','',...) failed: unable to open database file at /opt/vep/Plugins/LoF.pm line 126. -------------------- EXCEPTION --------------------; MSG: ERROR: No cache found for homo_sapiens, version 95. STACK Bio::EnsEMBL::VEP::CacheDir::dir /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/CacheDir.pm:328; STACK Bio::EnsEMBL::VEP::CacheDir::init /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/CacheDir.pm:227; STACK Bio::EnsEMBL::VEP::CacheDir::new /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/CacheDir.pm:111; STACK Bio::EnsEMBL::VEP::AnnotationSourceAdaptor::get_all_from_cache /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/AnnotationSourceAdaptor.pm:115; STACK Bio::EnsE",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14513:4349,Plugin,Plugins,4349,https://hail.is,https://github.com/hail-is/hail/issues/14513,1,['Plugin'],['Plugins']
Modifiability,"-mask-size-ipv4</code> and <code>--node-cidr-mask-size-ipv6</code>.</li>; <li>Single-stack clusters do not need to change, but may choose to use the more specific flags. Users can use either the older <code>--node-cidr-mask-size</code> flag or one of the newer <code>--node-cidr-mask-size-ipv4</code> or <code>--node-cidr-mask-size-ipv6</code> flags to configure the per-node IP mask size, provided that the flag's IP family matches the cluster's IP family (--cluster-cidr). (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/104691"">kubernetes/kubernetes#104691</a>, <a href=""https://github.com/khenidak""><code>@​khenidak</code></a>)</li>; </ol>; </li>; <li>Remove <code>NodeLease</code> feature gate that was graduated and locked to stable in 1.17 release. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/105222"">kubernetes/kubernetes#105222</a>, <a href=""https://github.com/cyclinder""><code>@​cyclinder</code></a>)</li>; <li>Removed deprecated <code>--seccomp-profile-root</code>/<code>seccompProfileRoot</code> config. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/103941"">kubernetes/kubernetes#103941</a>, <a href=""https://github.com/saschagrunert""><code>@​saschagrunert</code></a>)</li>; <li>Since golang 1.17 both net.ParseIP and net.ParseCIDR rejects leading zeros in the dot-decimal notation of IPv4 addresses,; Kubernetes will keep allowing leading zeros on IPv4 address to not break the compatibility.; IMPORTANT: Kubernetes interprets leading zeros on IPv4 addresses as decimal, users must not rely on parser alignment to not being impacted by the associated security advisory:; CVE-2021-29923 golang standard library &quot;net&quot; - Improper Input Validation of octal literals in golang 1.16.2 and below standard library &quot;net&quot; results in indeterminate SSRF &amp; RFI vulnerabilities.</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summar",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11957:11944,config,config,11944,https://hail.is,https://github.com/hail-is/hail/pull/11957,1,['config'],['config']
Modifiability,". (<a href=""https://redirect.github.com/ipython/ipython/issues/13975"">#13975</a>)</li>; <li><a href=""https://github.com/ipython/ipython/commit/3a9419dce7d6ccf7de39be606eec2fc212ef4445""><code>3a9419d</code></a> Update completer documentation (<a href=""https://redirect.github.com/ipython/ipython/issues/13999"">#13999</a>)</li>; <li><a href=""https://github.com/ipython/ipython/commit/a7d8defdecca3cfa54eada171181e0880c8b6b5f""><code>a7d8def</code></a> Expose <code>auto_suggest.resume_hinting</code>, fix resume on backspace (<a href=""https://redirect.github.com/ipython/ipython/issues/13994"">#13994</a>)</li>; <li><a href=""https://github.com/ipython/ipython/commit/4e7b9408a0b35cabbdc973f131257f4e97a3ddcf""><code>4e7b940</code></a> Fix autosuggestions in multi-line mode, vi command mode delay (<a href=""https://redirect.github.com/ipython/ipython/issues/13991"">#13991</a>)</li>; <li><a href=""https://github.com/ipython/ipython/commit/ad452c1d8bb25e742caa152fb301e0e6626b6faa""><code>ad452c1</code></a> Improve API documentation around configuration of embedded IPython (<a href=""https://redirect.github.com/ipython/ipython/issues/13989"">#13989</a>)</li>; <li><a href=""https://github.com/ipython/ipython/commit/92027083ab69186db3f104fe38651086bcf4e760""><code>9202708</code></a> Handle OSError cases where traceback frames occur from built files (<a href=""https://redirect.github.com/ipython/ipython/issues/13964"">#13964</a>)</li>; <li><a href=""https://github.com/ipython/ipython/commit/fc872d6cfab48d861c43c766d583edde73370836""><code>fc872d6</code></a> Allow to dispatch getting documentation on objects</li>; <li>Additional commits viewable in <a href=""https://github.com/ipython/ipython/compare/7.34.0...8.12.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=ipython&package-manager=pip&previous-version=7.34.0&new-version=8.12.0)](https://docs.github.com/en/github/managing-secur",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12832:1856,config,configuration,1856,https://hail.is,https://github.com/hail-is/hail/pull/12832,2,['config'],['configuration']
Modifiability,.$anonfun$scoped$3(ExecuteContext.scala:75); E 	at is.hail.utils.package$.using(package.scala:635); E 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:75); E 	at is.hail.utils.package$.using(package.scala:635); E 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:17); E 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:63); E 	at is.hail.backend.service.ServiceBackendSocketAPI2.$anonfun$executeOneCommand$1(ServiceBackend.scala:644); E 	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:52); E 	at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:59); E 	at is.hail.backend.service.ServiceBackendSocketAPI2.withExecuteContext$1(ServiceBackend.scala:631); E 	at is.hail.backend.service.ServiceBackendSocketAPI2.executeOneCommand(ServiceBackend.scala:693); E 	at is.hail.backend.service.ServiceBackendSocketAPI2$.$anonfun$main$6(ServiceBackend.scala:459); E 	at is.hail.backend.service.ServiceBackendSocketAPI2$.$anonfun$main$6$adapted(ServiceBackend.scala:458); E 	at is.hail.utils.package$.using(package.scala:635); E 	at is.hail.backend.service.ServiceBackendSocketAPI2$.$anonfun$main$5(ServiceBackend.scala:458); E 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); E 	at is.hail.services.package$.retryTransientErrors(package.scala:124); E 	at is.hail.backend.service.ServiceBackendSocketAPI2$.$anonfun$main$4(ServiceBackend.scala:458); E 	at is.hail.backend.service.ServiceBackendSocketAPI2$.$anonfun$main$4$adapted(ServiceBackend.scala:456); E 	at is.hail.utils.package$.using(package.scala:635); E 	at is.hail.backend.service.ServiceBackendSocketAPI2$.$anonfun$main$3(ServiceBackend.scala:456); E 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); E 	at is.hail.services.package$.retryTransientErrors(package.scala:124); E 	at is.hail.backend.service.ServiceBackendSocketAPI2$.main(ServiceBackend.scala:456); E 	at is.hail.backend.service.Main$.main(Main.scala:15); E 	at is,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12976:6202,adapt,adapted,6202,https://hail.is,https://github.com/hail-is/hail/issues/12976,2,['adapt'],['adapted']
Modifiability,.$anonfun$scoped$3(ExecuteContext.scala:75); E 	at is.hail.utils.package$.using(package.scala:635); E 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:75); E 	at is.hail.utils.package$.using(package.scala:635); E 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:17); E 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:63); E 	at is.hail.backend.service.ServiceBackendSocketAPI2.$anonfun$executeOneCommand$1(ServiceBackend.scala:648); E 	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:52); E 	at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:59); E 	at is.hail.backend.service.ServiceBackendSocketAPI2.withExecuteContext$1(ServiceBackend.scala:634); E 	at is.hail.backend.service.ServiceBackendSocketAPI2.executeOneCommand(ServiceBackend.scala:697); E 	at is.hail.backend.service.ServiceBackendSocketAPI2$.$anonfun$main$6(ServiceBackend.scala:462); E 	at is.hail.backend.service.ServiceBackendSocketAPI2$.$anonfun$main$6$adapted(ServiceBackend.scala:461); E 	at is.hail.utils.package$.using(package.scala:635); E 	at is.hail.backend.service.ServiceBackendSocketAPI2$.$anonfun$main$5(ServiceBackend.scala:461); E 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); E 	at is.hail.services.package$.retryTransientErrors(package.scala:134); E 	at is.hail.backend.service.ServiceBackendSocketAPI2$.$anonfun$main$4(ServiceBackend.scala:460); E 	at is.hail.backend.service.ServiceBackendSocketAPI2$.$anonfun$main$4$adapted(ServiceBackend.scala:459); E 	at is.hail.utils.package$.using(package.scala:635); E 	at is.hail.backend.service.ServiceBackendSocketAPI2$.$anonfun$main$3(ServiceBackend.scala:459); E 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); E 	at is.hail.services.package$.retryTransientErrors(package.scala:134); E 	at is.hail.backend.service.ServiceBackendSocketAPI2$.main(ServiceBackend.scala:458); E 	at is.hail.backend.service.Main$.main(Main.scala:15); E 	at is,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13074:5916,adapt,adapted,5916,https://hail.is,https://github.com/hail-is/hail/issues/13074,2,['adapt'],['adapted']
Modifiability,... and use in batch instead of hard-coded regions. There a new global-config key batch_gpc_regions which is a JSON list of region names to use.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9786:71,config,config,71,https://hail.is,https://github.com/hail-is/hail/pull/9786,1,['config'],['config']
Modifiability,".3 google-cloud-core-1.6.0 google-cloud-storage-1.25.0 google-resumable-media-0.5.1 googleapis-common-protos-1.53.0 hail-0.2.64 humanize-1.0.0 hurry.filesize-0.9 idna-2.8 ipython-7.21.0 ipython-genutils-0.2.0 jedi-0.18.0 multidict-5.1.0 nest-asyncio-1.5.1 numpy-1.20.1 oauthlib-3.1.0 packaging-20.9 pandas-1.1.4 parsimonious-0.8.1 parso-0.8.1 pexpect-4.8.0 pickleshare-0.7.5 pillow-8.1.2 prompt-toolkit-3.0.17 protobuf-3.15.6 ptyprocess-0.7.0 py4j-0.10.7 pyasn1-0.4.8 pyasn1-modules-0.2.8 pygments-2.8.1 pyparsing-2.4.7 pyspark-2.4.1 python-dateutil-2.8.1 python-json-logger-0.1.11 pytz-2021.1 requests-2.22.0 requests-oauthlib-1.3.0 rsa-4.7.2 scipy-1.6.1 six-1.15.0 tabulate-0.8.3 tornado-6.1 tqdm-4.42.1 traitlets-5.0.5 typing-extensions-3.7.4.3 urllib3-1.25.11 wcwidth-0.2.5 wrapt-1.12.1 yarl-1.6.3; (3.8) ✔ ~/sandbox/hail [master|𝚫8?2]; snafu$ ipython ; Python 3.8.6 (default, Jan 27 2021, 15:42:20) ; Type 'copyright', 'credits' or 'license' for more information; IPython 7.21.0 -- An enhanced Interactive Python. Type '?' for help. In [1]: import hail; ---------------------------------------------------------------------------; TypeError Traceback (most recent call last); <ipython-input-1-e24d842d2b9a> in <module>; ----> 1 import hail. ~/sandbox/hail/venv/3.8/lib/python3.8/site-packages/hail/__init__.py in <module>; 32 # F401 '.expr.*' imported but unused; 33 # E402 module level import not at top of file; ---> 34 from .table import Table, GroupedTable, asc, desc # noqa: E402; 35 from .matrixtable import MatrixTable, GroupedMatrixTable # noqa: E402; 36 from .expr import * # noqa: F401,F403,E402. ~/sandbox/hail/venv/3.8/lib/python3.8/site-packages/hail/table.py in <module>; 2 import itertools; 3 import pandas; ----> 4 import pyspark; 5 from typing import Optional, Dict, Callable; 6 . ~/sandbox/hail/venv/3.8/lib/python3.8/site-packages/pyspark/__init__.py in <module>; 49 ; 50 from pyspark.conf import SparkConf; ---> 51 from pyspark.context import SparkContext; 52 from pyspark.rd",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/10197:9622,enhance,enhanced,9622,https://hail.is,https://github.com/hail-is/hail/issues/10197,1,['enhance'],['enhanced']
Modifiability,".</p>; </li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/PyCQA/pylint/commit/fd0eb6c2af0e3e98350e24047c4df7d5b8aad89a""><code>fd0eb6c</code></a> Bump pylint to 2.13.0, update changelog</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/1c509edc4ee2dbf1bbe8822e91e0b7df02ce463d""><code>1c509ed</code></a> [cleanup] Remove unused code in pylint.checker.base following refactor</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/1e7d3fa6219934028d2539ad290fe16ce8ea78e2""><code>1e7d3fa</code></a> [refactor] Create a file for the BasicChecker in pylint.checker.base</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/c0b8b32592f8d5d34ff37250adbda6b65269a0af""><code>c0b8b32</code></a> [refactor] Create a file for the BasicErrorChecker in pylint.checker.base</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/3f11fe629a7b89d2a3b92dce09ac5818f3904cee""><code>3f11fe6</code></a> [refactor] Create a package for the NameChecker in pylint.checker.base</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/6940715ba15f81fbd7d9e8685c0a714a8b612f24""><code>6940715</code></a> [refactor] Create a file for the DocstringChecker in pylint.checker.base</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/84d22cf24202bf6006fc179541e1853d145d33e0""><code>84d22cf</code></a> [refactor] Create a file for the PassChecker in pylint.checker.base</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/977b08d160e81aaecebf871d2b8ba2f9a96ef9d6""><code>977b08d</code></a> [refactor] Create files for comparison checker in pylint.checker.base</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/ddfca0ca884d677e4eb0e6f53553b16e7a503157""><code>ddfca0c</code></a> [refactor] Create a file for _BasicChecker in pylint.checkers</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/be4699399904654ef4107a228817b4ef176d8999""><code>be46993</code></a> [refactor] Crea",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11674:4285,refactor,refactor,4285,https://hail.is,https://github.com/hail-is/hail/pull/11674,1,['refactor'],['refactor']
Modifiability,.EvalRelationalLets$.execute$1(EvalRelationalLets.scala:10); 	at is.hail.expr.ir.lowering.EvalRelationalLets$.lower$1(EvalRelationalLets.scala:18); 	at is.hail.expr.ir.lowering.EvalRelationalLets$.apply(EvalRelationalLets.scala:32); 	at is.hail.expr.ir.lowering.EvalRelationalLetsPass.transform(LoweringPass.scala:147); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:16); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:16); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:14); 	at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:13); 	at is.hail.expr.ir.lowering.EvalRelationalLetsPass.apply(LoweringPass.scala:141); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:22); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:20); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:20); 	at is.hail.expr.ir.CompileAndEvaluate$._apply(CompileAndEvaluate.scala:50); 	at is.hail.backend.spark.SparkBackend._execute(SparkBackend.scala:462); 	at is.hail.backend.spark.SparkBackend.$anonfun$executeEncode$2(SparkBackend.scala:498); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:75); 	at is.hail.utils.package$.using(package.scala:635); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:75); 	at is.hail.utils.package$.using(package.scala:635); 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:17); 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:63); 	at is.hail.backend.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13633:11376,adapt,adapted,11376,https://hail.is,https://github.com/hail-is/hail/issues/13633,1,['adapt'],['adapted']
Modifiability,.EvalRelationalLets$.execute$1(EvalRelationalLets.scala:13); 	at is.hail.expr.ir.lowering.EvalRelationalLets$.lower$1(EvalRelationalLets.scala:21); 	at is.hail.expr.ir.lowering.EvalRelationalLets$.apply(EvalRelationalLets.scala:35); 	at is.hail.expr.ir.lowering.EvalRelationalLetsPass.transform(LoweringPass.scala:168); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:32); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:32); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:30); 	at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:29); 	at is.hail.expr.ir.lowering.EvalRelationalLetsPass.apply(LoweringPass.scala:162); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:21); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:19); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:19); 	at is.hail.expr.ir.CompileAndEvaluate$._apply(CompileAndEvaluate.scala:45); 	at is.hail.backend.spark.SparkBackend._execute(SparkBackend.scala:600); 	at is.hail.backend.spark.SparkBackend.$anonfun$execute$4(SparkBackend.scala:636); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.backend.spark.SparkBackend.$anonfun$execute$3(SparkBackend.scala:631); 	at is.hail.backend.spark.SparkBackend.$anonfun$execute$3$adapted(SparkBackend.scala:630); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:78); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(E,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14529:10449,adapt,adapted,10449,https://hail.is,https://github.com/hail-is/hail/issues/14529,1,['adapt'],['adapted']
Modifiability,.EvalRelationalLets$.execute$1(EvalRelationalLets.scala:13); 	at is.hail.expr.ir.lowering.EvalRelationalLets$.lower$1(EvalRelationalLets.scala:21); 	at is.hail.expr.ir.lowering.EvalRelationalLets$.apply(EvalRelationalLets.scala:35); 	at is.hail.expr.ir.lowering.EvalRelationalLetsPass.transform(LoweringPass.scala:170); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:32); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:32); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:30); 	at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:29); 	at is.hail.expr.ir.lowering.EvalRelationalLetsPass.apply(LoweringPass.scala:164); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:21); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:19); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:19); 	at is.hail.expr.ir.CompileAndEvaluate$._apply(CompileAndEvaluate.scala:45); 	at is.hail.backend.spark.SparkBackend._execute(SparkBackend.scala:601); 	at is.hail.backend.spark.SparkBackend.$anonfun$execute$4(SparkBackend.scala:637); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.backend.spark.SparkBackend.$anonfun$execute$3(SparkBackend.scala:632); 	at is.hail.backend.spark.SparkBackend.$anonfun$execute$3$adapted(SparkBackend.scala:631); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:77); 	at is.hail.utils.package$.using(package.scala:665); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(E,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14362:17211,adapt,adapted,17211,https://hail.is,https://github.com/hail-is/hail/issues/14362,1,['adapt'],['adapted']
Modifiability,.RichInputStream$.readRepeatedly$extension0(RichInputStream.scala:21); 	at is.hail.utils.richUtils.RichInputStream$.readFully$extension1(RichInputStream.scala:12); 	at is.hail.io.StreamBlockInputBuffer.readBlock(InputBuffers.scala:549); 	at is.hail.io.ZstdInputBlockBuffer.readBlock(InputBuffers.scala:643); 	at is.hail.io.BlockingInputBuffer.ensure(InputBuffers.scala:384); 	at is.hail.io.BlockingInputBuffer.readByte(InputBuffers.scala:402); 	at is.hail.io.LEB128InputBuffer.readByte(InputBuffers.scala:219); 	at __C372collect_distributed_array_matrix_native_writer.__m478readLeafNode(Unknown Source); 	at __C372collect_distributed_array_matrix_native_writer.apply_region16_290(Unknown Source); 	at __C372collect_distributed_array_matrix_native_writer.apply_region4_318(Unknown Source); 	at __C372collect_distributed_array_matrix_native_writer.apply_region2_501(Unknown Source); 	at __C372collect_distributed_array_matrix_native_writer.apply(Unknown Source); 	at __C372collect_distributed_array_matrix_native_writer.apply(Unknown Source); 	at is.hail.backend.BackendUtils.$anonfun$collectDArray$16(BackendUtils.scala:91); 	at is.hail.utils.package$.using(package.scala:637); 	at is.hail.annotations.RegionPool.scopedRegion(RegionPool.scala:162); 	at is.hail.backend.BackendUtils.$anonfun$collectDArray$15(BackendUtils.scala:90); 	at is.hail.backend.service.Worker$.$anonfun$main$12(Worker.scala:167); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); 	at is.hail.services.package$.retryTransientErrors(package.scala:182); 	at is.hail.backend.service.Worker$.$anonfun$main$11(Worker.scala:166); 	at is.hail.backend.service.Worker$.$anonfun$main$11$adapted(Worker.scala:164); 	at is.hail.utils.package$.using(package.scala:637); 	at is.hail.backend.service.Worker$.main(Worker.scala:164); 	at is.hail.backend.service.Main$.main(Main.scala:14); 	at is.hail.backend.service.Main.main(Main.scala); 	... 11 more. ```. ### Version. 0.2.124. ### Relevant log output. _No response_,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13704:2533,adapt,adapted,2533,https://hail.is,https://github.com/hail-is/hail/issues/13704,1,['adapt'],['adapted']
Modifiability,.SparkContext.runJob(SparkContext.scala:2126); at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:945); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); at org.apache.spark.rdd.RDD.withScope(RDD.scala:363); at org.apache.spark.rdd.RDD.collect(RDD.scala:944); at is.hail.sparkextras.ContextRDD.collect(ContextRDD.scala:166); at is.hail.rvd.RVD.writeRowsSplit(RVD.scala:954); at is.hail.expr.ir.MatrixValue.write(MatrixValue.scala:224); at is.hail.expr.ir.MatrixNativeWriter.apply(MatrixWriter.scala:41); at is.hail.expr.ir.WrappedMatrixWriter.apply(MatrixWriter.scala:25); at is.hail.expr.ir.Interpret$.run(Interpret.scala:726); at is.hail.expr.ir.Interpret$.alreadyLowered(Interpret.scala:53); at is.hail.expr.ir.InterpretNonCompilable$.interpretAndCoerce$1(InterpretNonCompilable.scala:16); at is.hail.expr.ir.InterpretNonCompilable$.is$hail$expr$ir$InterpretNonCompilable$$rewrite$1(InterpretNonCompilable.scala:53); at is.hail.expr.ir.InterpretNonCompilable$.apply(InterpretNonCompilable.scala:58); at is.hail.expr.ir.lowering.InterpretNonCompilablePass$.transform(LoweringPass.scala:50); at is.hail.expr.ir.lowering.LoweringPass$$anonfun$apply$3$$anonfun$1.apply(LoweringPass.scala:15); at is.hail.expr.ir.lowering.LoweringPass$$anonfun$apply$3$$anonfun$1.apply(LoweringPass.scala:15); at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:69); at is.hail.expr.ir.lowering.LoweringPass$$anonfun$apply$3.apply(LoweringPass.scala:15); at is.hail.expr.ir.lowering.LoweringPass$$anonfun$apply$3.apply(LoweringPass.scala:13); at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:69); at is.hail.expr.ir.lowering.LoweringPass$class.apply(LoweringPass.scala:13); at is.hail.expr.ir.lowering.InterpretNonCompilablePass$.apply(LoweringPass.scala:45); at is.hail.expr.ir.lowering.LoweringPipeline$$anonfun$apply$1.apply(LoweringPipeline.scala:20); at is.hail.expr.ir.lo,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9293:11643,rewrite,rewrite,11643,https://hail.is,https://github.com/hail-is/hail/issues/9293,1,['rewrite'],['rewrite']
Modifiability,.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); 	at java.base/java.lang.Thread.run(Thread.java:829). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2673); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2609); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2608); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2608); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1182); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1182); 	at scala.Option.foreach(Option.scala:407); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1182); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2861); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2803); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2792); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:952); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2236); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2257); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2276); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2301); 	at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1021); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOp,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12936:5786,adapt,adapted,5786,https://hail.is,https://github.com/hail-is/hail/issues/12936,1,['adapt'],['adapted']
Modifiability,.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); 	at java.base/java.lang.Thread.run(Thread.java:829). Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2717); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2653); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2652); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2652); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1189); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1189); 	at scala.Option.foreach(Option.scala:407); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1189); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2913); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2855); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2844); 	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:959); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2261); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2282); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2301); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2326); 	at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1021); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOp,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14513:8962,adapt,adapted,8962,https://hail.is,https://github.com/hail-is/hail/issues/14513,1,['adapt'],['adapted']
Modifiability,".apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551); 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); 	at java.base/java.lang.Thread.run(Thread.java:829). Hail version: 0.2.130-bea04d9c79b5; Error summary: HailException: VEP command '/vep --format vcf --json --everything --allele_number --no_stats --cache --offline --minimal --assembly GRCh38 --fasta /opt/vep/.vep/homo_sapiens/95_GRCh38/Homo_sapiens.GRCh38.dna.toplevel.fa.gz --plugin LoF,loftee_path:/opt/vep/Plugins/,gerp_bigwig:/opt/vep/.vep/gerp_conservation_scores.homo_sapiens.GRCh38.bw,human_ancestor_fa:/opt/vep/.vep/human_ancestor.fa.gz,conservation_file:/opt/vep/.vep/loftee.sql --dir_plugins /opt/vep/Plugins/ -o STDOUT' failed with non-zero exit status 2; VEP Error output:; Smartmatch is experimental at /opt/vep/Plugins/de_novo_donor.pl line 175.; Smartmatch is experimental at /opt/vep/Plugins/de_novo_donor.pl line 214.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 191.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 194.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 238.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 241.; DBI connect('dbname=/opt/vep/.vep/loftee.sql','',...) failed: unable to open database file at /opt/vep/Plugins/LoF.pm line 126. -------------------- EXCEPTION --------------------; MSG: ERROR: No cache found for homo_sapiens, version 95. STACK Bio::EnsEMBL::VEP::CacheDir::dir /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/CacheDir.pm:328; STACK Bio::EnsEMBL::VEP::CacheDir::init /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/CacheDir.pm:227; STACK Bio::EnsEMBL::VEP::CacheDir::new /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/CacheDir.pm:111; STACK Bio::EnsEMBL::VEP::AnnotationSourceAdaptor::get_all_from_cache /opt/vep/src/ensembl",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14513:20455,Plugin,Plugins,20455,https://hail.is,https://github.com/hail-is/hail/issues/14513,1,['Plugin'],['Plugins']
Modifiability,.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:75); 	at is.hail.utils.package$.using(package.scala:635); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:75); 	at is.hail.utils.package$.using(package.scala:635); 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:17); 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:63); 	at is.hail.backend.service.ServiceBackendSocketAPI2.$anonfun$executeOneCommand$1(ServiceBackend.scala:646); 	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:52); 	at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:59); 	at is.hail.backend.service.ServiceBackendSocketAPI2.withExecuteContext$1(ServiceBackend.scala:633); 	at is.hail.backend.service.ServiceBackendSocketAPI2.executeOneCommand(ServiceBackend.scala:695); 	at is.hail.backend.service.ServiceBackendSocketAPI2$.$anonfun$main$6(ServiceBackend.scala:461); 	at is.hail.backend.service.ServiceBackendSocketAPI2$.$anonfun$main$6$adapted(ServiceBackend.scala:460); 	at is.hail.utils.package$.using(package.scala:635); 	at is.hail.backend.service.ServiceBackendSocketAPI2$.$anonfun$main$5(ServiceBackend.scala:460); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); 	at is.hail.services.package$.retryTransientErrors(package.scala:124); 	at is.hail.backend.service.ServiceBackendSocketAPI2$.$anonfun$main$4(ServiceBackend.scala:460); 	at is.hail.backend.service.ServiceBackendSocketAPI2$.$anonfun$main$4$adapted(ServiceBackend.scala:458); 	at is.hail.utils.package$.using(package.scala:635); 	at is.hail.backend.service.ServiceBackendSocketAPI2$.$anonfun$main$3(ServiceBackend.scala:458); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); 	at is.hail.services.package$.retryTransientErrors(package.scala:124); 	at is.hail.backend.service.ServiceBackendSocketAPI2$.main(ServiceBackend.scala:458); 	at is.hail.backend.service.Main$.main(Main.scala:33); 	at is.hail.backend.service.Main,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12982:12420,adapt,adapted,12420,https://hail.is,https://github.com/hail-is/hail/issues/12982,6,['adapt'],['adapted']
Modifiability,".com/alculquicondor""><code>@​alculquicondor</code></a>)</li>; <li>Kube-apiserver: <code>--audit-log-version</code> and <code>--audit-webhook-version</code> now only support the default value of <code>audit.k8s.io/v1</code>. The v1alpha1 and v1beta1 audit log versions, deprecated since 1.13, have been removed. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108092"">kubernetes/kubernetes#108092</a>, <a href=""https://github.com/carlory""><code>@​carlory</code></a>)</li>; <li>Kube-apiserver: the <code>metadata.selfLink</code> field can no longer be populated by kube-apiserver; it was deprecated in 1.16 and has not been populated by default since 1.20+. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/107527"">kubernetes/kubernetes#107527</a>, <a href=""https://github.com/wojtek-t""><code>@​wojtek-t</code></a>)</li>; <li>Kubelet external Credential Provider feature is moved to Beta. Credential Provider Plugin and Credential Provider Config API's updated from v1alpha1 to v1beta1 with no API changes. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108847"">kubernetes/kubernetes#108847</a>, <a href=""https://github.com/adisky""><code>@​adisky</code></a>)</li>; <li>Make STS available replicas optional again. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/109241"">kubernetes/kubernetes#109241</a>, <a href=""https://github.com/ravisantoshgudimetla""><code>@​ravisantoshgudimetla</code></a>)</li>; <li>MaxUnavailable for StatefulSets, allows faster RollingUpdate by taking down more than 1 pod at a time. The number of pods you want to take down during a RollingUpdate is configurable using maxUnavailable parameter. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/82162"">kubernetes/kubernetes#82162</a>, <a href=""https://github.com/krmayankk""><code>@​krmayankk</code></a>)</li>; <li>Non-graceful node shutdown handling is enabled for stateful workload failove",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12196:9181,Plugin,Plugin,9181,https://hail.is,https://github.com/hail-is/hail/pull/12196,2,"['Config', 'Plugin']","['Config', 'Plugin']"
Modifiability,".com/prometheus/client_python/issues/754"">#754</a>, <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/755"">#755</a>, <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/756"">#756</a>, <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/758"">#758</a>; [BUGFIX] Explicitly export functions with <code>__all__</code>. <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/757"">#757</a></p>; <h2>0.13.0 / 2022-01-25</h2>; <p>[CHANGE] Drop support for Python versions 2.7, 3.4, and 3.5. <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/718"">#718</a>; [FEATURE] Support adding labels when using <code>.time()</code> <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/730"">#730</a>; [ENHANCEMENT] Begin to add type hints to functions. <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/705"">#705</a>; [ENHANCEMENT] Improved go-to-declaration behavior for editors. <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/747"">#747</a>; [BUGFIX] Remove trailing slashes from pushgateway URLS. <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/722"">#722</a>; [BUGFIX] Catch non-integer bucket/count values. <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/726"">#726</a></p>; <h2>0.12.0 / 2021-10-29</h2>; <p>[FEATURE] Exemplar support (excludes multiprocess) <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/669"">#669</a>; [ENHANCEMENT] Add support for Python 3.10 <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/706"">#706</a>; [ENHANCEMENT] Restricted Registry will handle metrics added after restricting <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/675"">#675</a>, <a href=""https://github-redirect.dependabot.com/prometheus/cl",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11515:1412,ENHANCE,ENHANCEMENT,1412,https://hail.is,https://github.com/hail-is/hail/pull/11515,1,['ENHANCE'],['ENHANCEMENT']
Modifiability,".com/pytest-dev/pytest/commit/e2753a2b8b55de73adcc992036d0dc52facdbab9""><code>e2753a2</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9669"">#9669</a> from hugovk/ci-only-update-plugin-list-for-upstream</li>; <li><a href=""https://github.com/pytest-dev/pytest/commit/b5a154c1d961dbc19a3c00d798de2f27aaa5ace5""><code>b5a154c</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9668"">#9668</a> from hugovk/test-me-latest-3.10</li>; <li><a href=""https://github.com/pytest-dev/pytest/commit/0fae45bb6e4ecf177afdfa3bf03738813ec7b913""><code>0fae45b</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9660"">#9660</a> from pytest-dev/backport-9646-to-7.0.x</li>; <li><a href=""https://github.com/pytest-dev/pytest/commit/37d434f5fcb5f80188b3d5b8f22d418dc191b955""><code>37d434f</code></a> [7.0.x] Delay warning about collector/item diamond inheritance</li>; <li>Additional commits viewable in <a href=""https://github.com/pytest-dev/pytest/compare/6.2.5...7.0.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pytest&package-manager=pip&previous-version=6.2.5&new-version=7.0.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@de",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11516:6396,inherit,inheritance,6396,https://hail.is,https://github.com/hail-is/hail/pull/11516,3,['inherit'],['inheritance']
Modifiability,.exportVCF(VariantDataset.scala:425); E at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); E at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); E at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); E at java.lang.reflect.Method.invoke(Method.java:498); E at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); E at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); E at py4j.Gateway.invoke(Gateway.java:280); E at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); E at py4j.commands.CallCommand.execute(CallCommand.java:79); E at py4j.GatewayConnection.run(GatewayConnection.java:214); E at java.lang.Thread.run(Thread.java:748)java.lang.RuntimeException: java.lang.ClassNotFoundException: Class org.apache.hadoop.mapred.DirectFileOutputCommitter not found; E at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2195); E at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2219); E at org.apache.hadoop.mapred.JobConf.getOutputCommitter(JobConf.java:726); E at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply$mcV$sp(PairRDDFunctions.scala:1051); E at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1035); E at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1035); E at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); E at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); E at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); E at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1035); E at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$3.apply$mcV$sp(PairRDDFunctions.scala:1016); E at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$3.apply(PairRDDFunctions.scala:1016); E at org.apache.s,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3946:7690,Config,Configuration,7690,https://hail.is,https://github.com/hail-is/hail/issues/3946,1,['Config'],['Configuration']
Modifiability,.expr.ir.Emit.emit$1(Emit.scala:621); 	at is.hail.expr.ir.Emit.emitVoid(Emit.scala:657); 	at is.hail.expr.ir.Emit.$anonfun$emitVoidInSeparateMethod$1(Emit.scala:579); 	at is.hail.expr.ir.Emit.$anonfun$emitVoidInSeparateMethod$1$adapted(Emit.scala:577); 	at is.hail.expr.ir.EmitCodeBuilder$.scoped(EmitCodeBuilder.scala:18); 	at is.hail.expr.ir.EmitCodeBuilder$.scopedVoid(EmitCodeBuilder.scala:28); 	at is.hail.expr.ir.EmitMethodBuilder.voidWithBuilder(EmitClassBuilder.scala:1011); 	at is.hail.expr.ir.Emit.emitVoidInSeparateMethod(Emit.scala:577); 	at is.hail.expr.ir.Emit.emitInSeparateMethod(Emit.scala:601); 	at is.hail.expr.ir.Emit.emitI(Emit.scala:793); 	at is.hail.expr.ir.Emit.emitI$1(Emit.scala:630); 	at is.hail.expr.ir.Emit.$anonfun$emitVoid$26(Emit.scala:748); 	at is.hail.expr.ir.RelationalWriter.writeMetadata(TableWriter.scala:463); 	at is.hail.expr.ir.Emit.emitVoid(Emit.scala:748); 	at is.hail.expr.ir.Emit$.$anonfun$apply$3(Emit.scala:70); 	at is.hail.expr.ir.Emit$.$anonfun$apply$3$adapted(Emit.scala:68); 	at is.hail.expr.ir.EmitCodeBuilder$.scoped(EmitCodeBuilder.scala:18); 	at is.hail.expr.ir.EmitCodeBuilder$.scopedVoid(EmitCodeBuilder.scala:28); 	at is.hail.expr.ir.EmitMethodBuilder.voidWithBuilder(EmitClassBuilder.scala:1011); 	at is.hail.expr.ir.Emit$.apply(Emit.scala:68); 	at is.hail.expr.ir.Compile$.apply(Compile.scala:78); 	at is.hail.expr.ir.CompileAndEvaluate$.$anonfun$_apply$1(CompileAndEvaluate.scala:50); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.CompileAndEvaluate$._apply(CompileAndEvaluate.scala:50); 	at is.hail.expr.ir.CompileAndEvaluate$.evalToIR(CompileAndEvaluate.scala:30); 	at is.hail.expr.ir.LowerOrInterpretNonCompilable$.evaluate$1(LowerOrInterpretNonCompilable.scala:30); 	at is.hail.expr.ir.LowerOrInterpretNonCompilable$.rewrite$1(LowerOrInterpretNonCompilable.scala:67); 	at is.hail.expr.ir.LowerOrInterpretNonCompilable$.apply(LowerOrInterpretNonCompilable.scala:72); 	at is.hail.expr.ir.lowering.Lo,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12533:8593,adapt,adapted,8593,https://hail.is,https://github.com/hail-is/hail/issues/12533,1,['adapt'],['adapted']
Modifiability,.expr.ir.FoldConstants$$anonfun$is$hail$expr$ir$FoldConstants$$foldConstants$1.apply(FoldConstants.scala:45); 	at is.hail.expr.ir.FoldConstants$$anonfun$is$hail$expr$ir$FoldConstants$$foldConstants$1.apply(FoldConstants.scala:13); 	at is.hail.expr.ir.RewriteBottomUp$.is$hail$expr$ir$RewriteBottomUp$$rewrite$1(RewriteBottomUp.scala:15); 	at is.hail.expr.ir.RewriteBottomUp$$anonfun$1.apply(RewriteBottomUp.scala:6); 	at is.hail.expr.ir.RewriteBottomUp$$anonfun$1.apply(RewriteBottomUp.scala:6); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); 	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.AbstractTraversable.map(Traversable.scala:104); 	at is.hail.expr.ir.RewriteBottomUp$.is$hail$expr$ir$RewriteBottomUp$$rewrite$1(RewriteBottomUp.scala:6); 	at is.hail.expr.ir.RewriteBottomUp$$anonfun$1.apply(RewriteBottomUp.scala:6); 	at is.hail.expr.ir.RewriteBottomUp$$anonfun$1.apply(RewriteBottomUp.scala:6); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); 	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.AbstractTraversable.map(Traversable.scala:104); 	at is.hail.expr.ir.RewriteBottomUp$.is$hail$expr$ir$RewriteBottomUp$$rewrite$1(RewriteBottomUp.scala:6); 	at is.hail.expr.ir.RewriteBottomUp$$anonfun$1.apply(RewriteBottomUp.scala:6); 	at is.hail.expr.ir.RewriteBottomUp$$anonfun$1.apply(RewriteBottomUp.scala:6); 	at scala.collection.Trav,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9128:1509,Rewrite,RewriteBottomUp,1509,https://hail.is,https://github.com/hail-is/hail/issues/9128,1,['Rewrite'],['RewriteBottomUp']
Modifiability,.hail.expr.ir.ExtractIntervalFilters$$anonfun$apply$2.apply(ExtractIntervalFilters.scala:254); 	at is.hail.expr.ir.RewriteBottomUp$.is$hail$expr$ir$RewriteBottomUp$$rewrite$1(RewriteBottomUp.scala:15); 	at is.hail.expr.ir.RewriteBottomUp$$anonfun$1.apply(RewriteBottomUp.scala:6); 	at is.hail.expr.ir.RewriteBottomUp$$anonfun$1.apply(RewriteBottomUp.scala:6); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); 	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.AbstractTraversable.map(Traversable.scala:104); 	at is.hail.expr.ir.RewriteBottomUp$.is$hail$expr$ir$RewriteBottomUp$$rewrite$1(RewriteBottomUp.scala:6); 	at is.hail.expr.ir.RewriteBottomUp$$anonfun$1.apply(RewriteBottomUp.scala:6); 	at is.hail.expr.ir.RewriteBottomUp$$anonfun$1.apply(RewriteBottomUp.scala:6); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); 	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.AbstractTraversable.map(Traversable.scala:104); 	at is.hail.expr.ir.RewriteBottomUp$.is$hail$expr$ir$RewriteBottomUp$$rewrite$1(RewriteBottomUp.scala:6); 	at is.hail.expr.ir.RewriteBottomUp$.apply(RewriteBottomUp.scala:25); 	at is.hail.expr.ir.ExtractIntervalFilters$.apply(ExtractIntervalFilters.scala:254); 	at is.hail.expr.ir.Optimize$.optimize(Optimize.scala:19); 	at is.hail.expr.ir.Optimize$.apply(Optimize.scala:49); 	at is.hail.expr.ir.CompileAndEvaluate$$anonfun$,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6458:4519,Rewrite,RewriteBottomUp,4519,https://hail.is,https://github.com/hail-is/hail/issues/6458,1,['Rewrite'],['RewriteBottomUp']
Modifiability,.hail.expr.ir.lowering.LowerToCDA$.lower(LowerToCDA.scala:67); E 	at is.hail.expr.ir.lowering.LowerToCDA$.lower(LowerToCDA.scala:36); E 	at is.hail.expr.ir.lowering.LowerToCDA$.apply(LowerToCDA.scala:16); E 	at is.hail.expr.ir.lowering.LowerToDistributedArrayPass.transform(LoweringPass.scala:75); E 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:15); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:15); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); E 	at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:13); E 	at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:12); E 	at is.hail.expr.ir.lowering.LowerToDistributedArrayPass.apply(LoweringPass.scala:70); E 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:14); E 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:12); E 	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36); E 	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33); E 	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:38); E 	at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:12); E 	at is.hail.backend.local.LocalBackend._jvmLowerAndExecute(LocalBackend.scala:88); E 	at is.hail.backend.local.LocalBackend._execute(LocalBackend.scala:124); E 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1(LocalBackend.scala:131); E 	at is.hail.expr.ir.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:47); E 	at is.hail.utils.package$.using(package.scala:627); E 	at is.hail.expr.ir.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:47); E 	at is.hail.utils.package$.using(package.scala:627); E 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:13); E 	at is.hail.expr.ir.ExecuteContext$.scoped(ExecuteContext,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10379:1446,adapt,adapted,1446,https://hail.is,https://github.com/hail-is/hail/pull/10379,1,['adapt'],['adapted']
Modifiability,.hail.utils.StackSafe$StackFrame.run(StackSafe.scala:32); 	at is.hail.expr.ir.RewriteBottomUp$.apply(RewriteBottomUp.scala:21); 	at is.hail.expr.ir.lowering.LowerAndExecuteShuffles$.apply(LowerAndExecuteShuffles.scala:14); 	at is.hail.expr.ir.lowering.LowerAndExecuteShufflesPass.transform(LoweringPass.scala:167); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:26); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:26); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:24); 	at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:23); 	at is.hail.expr.ir.lowering.LowerAndExecuteShufflesPass.apply(LoweringPass.scala:161); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:22); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:20); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:20); 	at is.hail.expr.ir.CompileAndEvaluate$._apply(CompileAndEvaluate.scala:50); 	at is.hail.backend.spark.SparkBackend._execute(SparkBackend.scala:517); 	at is.hail.backend.spark.SparkBackend.$anonfun$execute$4(SparkBackend.scala:546); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.backend.spark.SparkBackend.$anonfun$execute$3(SparkBackend.scala:542); 	at is.hail.backend.spark.SparkBackend.$anonfun$execute$3$adapted(SparkBackend.scala:541); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:76); 	at is.hail.utils.package$.using(package.scala:657); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(E,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14102:13223,adapt,adapted,13223,https://hail.is,https://github.com/hail-is/hail/issues/14102,1,['adapt'],['adapted']
Modifiability,.hail.utils.StackSafe$StackFrame.run(StackSafe.scala:32); 	at is.hail.expr.ir.RewriteBottomUp$.apply(RewriteBottomUp.scala:21); 	at is.hail.expr.ir.lowering.LowerAndExecuteShuffles$.apply(LowerAndExecuteShuffles.scala:20); 	at is.hail.expr.ir.lowering.LowerAndExecuteShufflesPass.transform(LoweringPass.scala:157); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:16); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:16); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:14); 	at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:13); 	at is.hail.expr.ir.lowering.LowerAndExecuteShufflesPass.apply(LoweringPass.scala:151); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:22); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:20); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:20); 	at is.hail.expr.ir.lowering.EvalRelationalLets$.execute$1(EvalRelationalLets.scala:10); 	at is.hail.expr.ir.lowering.EvalRelationalLets$.lower$1(EvalRelationalLets.scala:18); 	at is.hail.expr.ir.lowering.EvalRelationalLets$.apply(EvalRelationalLets.scala:32); 	at is.hail.expr.ir.lowering.EvalRelationalLetsPass.transform(LoweringPass.scala:147); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:16); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:16); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13633:10007,adapt,adapted,10007,https://hail.is,https://github.com/hail-is/hail/issues/13633,1,['adapt'],['adapted']
Modifiability,.hail.utils.StackSafe$StackFrame.run(StackSafe.scala:32); 	at is.hail.expr.ir.RewriteBottomUp$.apply(RewriteBottomUp.scala:36); 	at is.hail.expr.ir.lowering.LowerAndExecuteShuffles$.apply(LowerAndExecuteShuffles.scala:20); 	at is.hail.expr.ir.lowering.LowerAndExecuteShufflesPass.transform(LoweringPass.scala:157); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:16); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:16); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:14); 	at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:13); 	at is.hail.expr.ir.lowering.LowerAndExecuteShufflesPass.apply(LoweringPass.scala:151); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:22); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:20); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:20); 	at is.hail.backend.service.ServiceBackend.execute(ServiceBackend.scala:312); 	at is.hail.backend.service.ServiceBackend.execute(ServiceBackend.scala:348); 	at is.hail.backend.service.ServiceBackendSocketAPI2.$anonfun$executeOneCommand$12(ServiceBackend.scala:700); 	at is.hail.backend.service.ServiceBackendSocketAPI2.withIRFunctionsReadFromInput(ServiceBackend.scala:803); 	at is.hail.backend.service.ServiceBackendSocketAPI2.$anonfun$executeOneCommand$11(ServiceBackend.scala:698); 	at is.hail.backend.service.ServiceBackendSocketAPI2.$anonfun$executeOneCommand$2(ServiceBackend.scala:656); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteCont,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12983:8935,adapt,adapted,8935,https://hail.is,https://github.com/hail-is/hail/issues/12983,4,['adapt'],['adapted']
Modifiability,".org/en/master/changes.html</a></p>; <h2>v5.0.0</h2>; <p>No release notes provided.</p>; <h2>v5.0.0b1</h2>; <p>Changelog: <a href=""https://www.sphinx-doc.org/en/master/changes.html"">https://www.sphinx-doc.org/en/master/changes.html</a></p>; <h2>v4.5.0</h2>; <p>Changelog: <a href=""https://www.sphinx-doc.org/en/master/changes.html"">https://www.sphinx-doc.org/en/master/changes.html</a></p>; <h2>v4.4.0</h2>; <p>Changelog: <a href=""https://www.sphinx-doc.org/en/master/changes.html"">https://www.sphinx-doc.org/en/master/changes.html</a></p>; <h2>v4.3.1</h2>; <p>No release notes provided.</p>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/sphinx-doc/sphinx/blob/5.x/CHANGES"">sphinx's changelog</a>.</em></p>; <blockquote>; <h1>Release 5.0.2 (released Jun 17, 2022)</h1>; <h2>Features added</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10523"">#10523</a>: HTML Theme: Expose the Docutils's version info tuple as a template; variable, <code>docutils_version_info</code>. Patch by Adam Turner.</li>; </ul>; <h2>Bugs fixed</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10538"">#10538</a>: autodoc: Inherited class attribute having docstring is documented even; if :confval:<code>autodoc_inherit_docstring</code> is disabled</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10509"">#10509</a>: autosummary: autosummary fails with a shared library</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10497"">#10497</a>: py domain: Failed to resolve strings in Literal. Patch by Adam Turner.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10523"">#10523</a>: HTML Theme: Fix double brackets on citation references in Docutils 0.18+.; Patch by Adam Turner.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10534"">#10534</a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11925:1542,variab,variable,1542,https://hail.is,https://github.com/hail-is/hail/pull/11925,1,['variab'],['variable']
Modifiability,".pb-dev-312200.internal executor 3): is.hail.utils.HailException: VEP command '/vep --format vcf --json --everything --allele_number --no_stats --cache --offline --minimal --assembly GRCh38 --fasta /opt/vep/.vep/homo_sapiens/95_GRCh38/Homo_sapiens.GRCh38.dna.toplevel.fa.gz --plugin LoF,loftee_path:/opt/vep/Plugins/,gerp_bigwig:/opt/vep/.vep/gerp_conservation_scores.homo_sapiens.GRCh38.bw,human_ancestor_fa:/opt/vep/.vep/human_ancestor.fa.gz,conservation_file:/opt/vep/.vep/loftee.sql --dir_plugins /opt/vep/Plugins/ -o STDOUT' failed with non-zero exit status 2; VEP Error output:; Smartmatch is experimental at /opt/vep/Plugins/de_novo_donor.pl line 175.; Smartmatch is experimental at /opt/vep/Plugins/de_novo_donor.pl line 214.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 191.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 194.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 238.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 241.; DBI connect('dbname=/opt/vep/.vep/loftee.sql','',...) failed: unable to open database file at /opt/vep/Plugins/LoF.pm line 126. -------------------- EXCEPTION --------------------; MSG: ERROR: No cache found for homo_sapiens, version 95. STACK Bio::EnsEMBL::VEP::CacheDir::dir /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/CacheDir.pm:328; STACK Bio::EnsEMBL::VEP::CacheDir::init /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/CacheDir.pm:227; STACK Bio::EnsEMBL::VEP::CacheDir::new /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/CacheDir.pm:111; STACK Bio::EnsEMBL::VEP::AnnotationSourceAdaptor::get_all_from_cache /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/AnnotationSourceAdaptor.pm:115; STACK Bio::EnsEMBL::VEP::AnnotationSourceAdaptor::get_all /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/AnnotationSourceAdaptor.pm:91; STACK Bio::EnsEMBL::VEP::BaseRunner::get_all_AnnotationSources /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14513:4583,Plugin,Plugins,4583,https://hail.is,https://github.com/hail-is/hail/issues/14513,1,['Plugin'],['Plugins']
Modifiability,.rewriteChildren$1(InterpretNonCompilable.scala:25); 	at is.hail.expr.ir.InterpretNonCompilable$.rewrite$1(InterpretNonCompilable.scala:54); 	at is.hail.expr.ir.InterpretNonCompilable$.apply(InterpretNonCompilable.scala:58); 	at is.hail.expr.ir.lowering.InterpretNonCompilablePass$.transform(LoweringPass.scala:67); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:15); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:15); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:13); 	at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:12); 	at is.hail.expr.ir.lowering.InterpretNonCompilablePass$.apply(LoweringPass.scala:62); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:14); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:12); 	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36); 	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33); 	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:38); 	at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:12); 	at is.hail.expr.ir.CompileAndEvaluate$._apply(CompileAndEvaluate.scala:29); 	at is.hail.backend.spark.SparkBackend._execute(SparkBackend.scala:381); 	at is.hail.backend.spark.SparkBackend.$anonfun$execute$1(SparkBackend.scala:365); 	at is.hail.expr.ir.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:47); 	at is.hail.utils.package$.using(package.scala:627); 	at is.hail.expr.ir.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:47); 	at is.hail.utils.package$.using(package.scala:627); 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:17); 	at is.hail.expr.ir.ExecuteContext$.scoped(ExecuteContext.scala:46); 	at is.hail.backend.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/10682:11883,adapt,adapted,11883,https://hail.is,https://github.com/hail-is/hail/issues/10682,1,['adapt'],['adapted']
Modifiability,.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:750); Caused by: java.lang.reflect.InvocationTargetException; 	at sun.reflect.GeneratedMethodAccessor23.invoke(Unknown Source); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at is.hail.JVMEntryway$1.run(JVMEntryway.java:119); 	... 7 more; Caused by: is.hail.backend.service.EndOfInputException; 	at is.hail.backend.service.ServiceBackendSocketAPI2.read(ServiceBackend.scala:497); 	at is.hail.backend.service.ServiceBackendSocketAPI2.readInt(ServiceBackend.scala:510); 	at is.hail.backend.service.ServiceBackendSocketAPI2.executeOneCommand(ServiceBackend.scala:561); 	at is.hail.backend.service.ServiceBackendSocketAPI2$.$anonfun$main$6(ServiceBackend.scala:462); 	at is.hail.backend.service.ServiceBackendSocketAPI2$.$anonfun$main$6$adapted(ServiceBackend.scala:461); 	at is.hail.utils.package$.using(package.scala:635); 	at is.hail.backend.service.ServiceBackendSocketAPI2$.$anonfun$main$5(ServiceBackend.scala:461); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); 	at is.hail.services.package$.retryTransientErrors(package.scala:141); 	at is.hail.backend.service.ServiceBackendSocketAPI2$.$anonfun$main$4(ServiceBackend.scala:460); 	at is.hail.backend.service.ServiceBackendSocketAPI2$.$anonfun$main$4$adapted(ServiceBackend.scala:459); 	at is.hail.utils.package$.using(package.scala:635); 	at is.hail.backend.service.ServiceBackendSocketAPI2$.$anonfun$main$3(ServiceBackend.scala:459); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); 	at is.hail.services.package$.retryTransientErrors(package.scala:141); 	at is.hail.backend.service.ServiceBackendSocketAPI2$.main(ServiceBackend.scala:458); 	at is.hail.backend.service.Main$.main(Main.scala:15); 	at is.hail.backend.service.Main,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13160:5595,adapt,adapted,5595,https://hail.is,https://github.com/hail-is/hail/pull/13160,1,['adapt'],['adapted']
Modifiability,".scala:36); 	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33); 	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:198); 	at is.hail.asm4s.ClassesBytes.load(ClassBuilder.scala:62); 	at is.hail.expr.ir.EmitClassBuilder$$anon$1.apply(EmitClassBuilder.scala:715); 	at is.hail.expr.ir.EmitClassBuilder$$anon$1.apply(EmitClassBuilder.scala:708); 	at is.hail.expr.ir.CompileIterator$.$anonfun$forTableStageToRVD$1(Compile.scala:311); 	at is.hail.expr.ir.CompileIterator$.$anonfun$forTableStageToRVD$1$adapted(Compile.scala:310); 	at is.hail.expr.ir.lowering.TableStageToRVD$.$anonfun$apply$9(RVDToTableStage.scala:106); 	at is.hail.sparkextras.ContextRDD.$anonfun$cflatMap$2(ContextRDD.scala:211); 	at scala.collection.Iterator$$anon$11.nextCur(Iterator.scala:486); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:492); 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490); 	at is.hail.rvd.RVD$.$anonfun$getKeyInfo$2(RVD.scala:1234); 	at is.hail.rvd.RVD$.$anonfun$getKeyInfo$2$adapted(RVD.scala:1233); 	at is.hail.sparkextras.ContextRDD.$anonfun$crunJobWithIndex$1(ContextRDD.scala:242); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:131); 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:498); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:501); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:750). Hail version: 0.2.105-3f053140ad00; Error summary: ClassFormatError: Too many arguments in method signature in class file __C2866stream; ```. This used to work fine in earlier Hail versions, e.g. 0.2.85.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12532:13084,adapt,adapted,13084,https://hail.is,https://github.com/hail-is/hail/issues/12532,1,['adapt'],['adapted']
Modifiability,.scala:94); 	at is.hail.expr.ir.ExtractIntervalFilters$$anonfun$extractAndRewrite$6.apply(ExtractIntervalFilters.scala:205); 	at is.hail.expr.ir.ExtractIntervalFilters$$anonfun$extractAndRewrite$6.apply(ExtractIntervalFilters.scala:201); 	at scala.Option.flatMap(Option.scala:171); 	at is.hail.expr.ir.ExtractIntervalFilters$.extractAndRewrite(ExtractIntervalFilters.scala:201); 	at is.hail.expr.ir.ExtractIntervalFilters$.extractAndRewrite(ExtractIntervalFilters.scala:151); 	at is.hail.expr.ir.ExtractIntervalFilters$.extractPartitionFilters(ExtractIntervalFilters.scala:249); 	at is.hail.expr.ir.ExtractIntervalFilters$$anonfun$apply$2.apply(ExtractIntervalFilters.scala:266); 	at is.hail.expr.ir.ExtractIntervalFilters$$anonfun$apply$2.apply(ExtractIntervalFilters.scala:254); 	at is.hail.expr.ir.RewriteBottomUp$.is$hail$expr$ir$RewriteBottomUp$$rewrite$1(RewriteBottomUp.scala:15); 	at is.hail.expr.ir.RewriteBottomUp$$anonfun$1.apply(RewriteBottomUp.scala:6); 	at is.hail.expr.ir.RewriteBottomUp$$anonfun$1.apply(RewriteBottomUp.scala:6); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); 	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.AbstractTraversable.map(Traversable.scala:104); 	at is.hail.expr.ir.RewriteBottomUp$.is$hail$expr$ir$RewriteBottomUp$$rewrite$1(RewriteBottomUp.scala:6); 	at is.hail.expr.ir.RewriteBottomUp$$anonfun$1.apply(RewriteBottomUp.scala:6); 	at is.hail.expr.ir.RewriteBottomUp$$anonfun$1.apply(RewriteBottomUp.scala:6); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.IndexedSeqOptimized$cl,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6458:3825,Rewrite,RewriteBottomUp,3825,https://hail.is,https://github.com/hail-is/hail/issues/6458,1,['Rewrite'],['RewriteBottomUp']
Modifiability,.spark.SparkContext.runJob(SparkContext.scala:2257); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2289); 	at is.hail.sparkextras.ContextRDD.crunJobWithIndex(ContextRDD.scala:238); 	at is.hail.rvd.RVD$.getKeyInfo(RVD.scala:1029); 	at is.hail.rvd.RVD$.makeCoercer(RVD.scala:1104); 	at is.hail.rvd.RVD$.coerce(RVD.scala:1060); 	at is.hail.rvd.RVD.changeKey(RVD.scala:142); 	at is.hail.rvd.RVD.changeKey(RVD.scala:135); 	at is.hail.backend.spark.SparkBackend.lowerDistributedSort(SparkBackend.scala:716); 	at is.hail.backend.Backend.lowerDistributedSort(Backend.scala:143); 	at is.hail.expr.ir.lowering.LowerAndExecuteShuffles$.$anonfun$apply$1(LowerAndExecuteShuffles.scala:17); 	at is.hail.expr.ir.RewriteBottomUp$.$anonfun$apply$2(RewriteBottomUp.scala:11); 	at is.hail.utils.StackSafe$More.advance(StackSafe.scala:60); 	at is.hail.utils.StackSafe$.run(StackSafe.scala:16); 	at is.hail.utils.StackSafe$StackFrame.run(StackSafe.scala:32); 	at is.hail.expr.ir.RewriteBottomUp$.apply(RewriteBottomUp.scala:21); 	at is.hail.expr.ir.lowering.LowerAndExecuteShuffles$.apply(LowerAndExecuteShuffles.scala:14); 	at is.hail.expr.ir.lowering.LowerAndExecuteShufflesPass.transform(LoweringPass.scala:167); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:26); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:26); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:24); 	at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:23); 	at is.hail.expr.ir.lowering.LowerAndExecuteShufflesPass.apply(LoweringPass.scala:161); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:22); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:20); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:6,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14102:12328,Rewrite,RewriteBottomUp,12328,https://hail.is,https://github.com/hail-is/hail/issues/14102,1,['Rewrite'],['RewriteBottomUp']
Modifiability,"//github.com/PyCQA/pylint/commit/403dac602ee01e317a22800e0d63bdeb0c2faa7e""><code>403dac6</code></a> Bump pylint to 2.15.3, update changelog</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/38e278401a66218fba26308fbce56740761a2003""><code>38e2784</code></a> Bump astroid to 2.12.10</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/f5e168e867799013fb380aa9fe8a0c1516a651c8""><code>f5e168e</code></a> Fix <code>undefined-loop-variable</code> with <code>NoReturn</code> and <code>Never</code> (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7476"">#7476</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/fbc9e663473fa0416779f1d71109b4123f6c3365""><code>fbc9e66</code></a> Accept a comma-separated list of messages IDs in <code>--help-msg</code> (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7490"">#7490</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/fe3436efb0ec10677ba1539ac02e26cb3f852cbb""><code>fe3436e</code></a> False positive <code>global-variable-not-assigned</code> (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7479"">#7479</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/52cf631d732f7b39a879adf7e617e0aa7059a83a""><code>52cf631</code></a> [invalid-class-object] Fix crash when <strong>class</strong> is defined with a tuple</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/8e05ff6acf30deae5d83ea3847ec47ed0bf049a4""><code>8e05ff6</code></a> Fix a crash in the <code>modified-iterating-dict</code> checker involving instance attri...</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/9b359ad676dff97a35321976c19ca0f6c4fc44ad""><code>9b359ad</code></a> Fix <code>unhashable-member</code> crash when <code>lambda</code> used as a dict key (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7454"">#7454</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/5716ad10104a9553ef9d64404b044c04947889b2""><code>5716ad1</code></a> Bump pyli",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12240:1164,variab,variable-not-assigned,1164,https://hail.is,https://github.com/hail-is/hail/pull/12240,1,['variab'],['variable-not-assigned']
Modifiability,"//github.com/sass/libsass/releases/tag/3.6.3</a></p>; <h2>Version 0.19.3</h2>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/sass/libsass-python/commit/13c0d60e244c694dec88d8ac8370d7aae6dce4d0""><code>13c0d60</code></a> 0.21.0</li>; <li><a href=""https://github.com/sass/libsass-python/commit/5c94c2a72dab34367758e229c487de50f1430283""><code>5c94c2a</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/sass/libsass-python/issues/344"">#344</a> from sass/3_6_5</li>; <li><a href=""https://github.com/sass/libsass-python/commit/ad69f6e023a6d8fdde4428b7a497b60fb5515215""><code>ad69f6e</code></a> update libsass to 3.6.5</li>; <li><a href=""https://github.com/sass/libsass-python/commit/38735e2fdc30ecb21f6eebb253c1b7a9a45dc757""><code>38735e2</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/sass/libsass-python/issues/343"">#343</a> from sass/pre-commit-ci-update-config</li>; <li><a href=""https://github.com/sass/libsass-python/commit/7f01591fdbca66375a61d70e505a286550a1c1b1""><code>7f01591</code></a> [pre-commit.ci] pre-commit autoupdate</li>; <li><a href=""https://github.com/sass/libsass-python/commit/814d42df9787494f01474116940782ab67da083f""><code>814d42d</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/sass/libsass-python/issues/342"">#342</a> from sass/pre-commit-ci-update-config</li>; <li><a href=""https://github.com/sass/libsass-python/commit/b08f9ca307ce64867070a3ca5ee5f1a6c5742069""><code>b08f9ca</code></a> [pre-commit.ci] pre-commit autoupdate</li>; <li><a href=""https://github.com/sass/libsass-python/commit/89d6a1dda507abde79ff79b3fd95b9d013eaa02d""><code>89d6a1d</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/sass/libsass-python/issues/340"">#340</a> from sass/pre-commit-ci-update-config</li>; <li><a href=""https://github.com/sass/libsass-python/commit/93c70a9a9f350b2",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11508:4199,config,config,4199,https://hail.is,https://github.com/hail-is/hail/pull/11508,1,['config'],['config']
Modifiability,"/312"">#312</a></li>; <li><a href=""https://github.com/lepture/mistune/commit/f857f048ebb2f6f2bb7ab97dcb7a159172a20649""><code>f857f04</code></a> Trigger GitHub dependency graph</li>; <li><a href=""https://github.com/lepture/mistune/commit/3f422f1e84edae0f39756c45be453ecde534b755""><code>3f422f1</code></a> Version bump 2.0.3</li>; <li><a href=""https://github.com/lepture/mistune/commit/a6d43215132fe4f3d93f8d7e90ba83b16a0838b2""><code>a6d4321</code></a> Fix asteris emphasis regex CVE-2022-34749</li>; <li><a href=""https://github.com/lepture/mistune/commit/5638e460459cb59ceb20e4ce4716c802d4d73c53""><code>5638e46</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/lepture/mistune/issues/307"">#307</a> from jieter/patch-1</li>; <li><a href=""https://github.com/lepture/mistune/commit/0eba47196a81453bafe1f2492748a87475063dff""><code>0eba471</code></a> Fix typo in guide.rst</li>; <li><a href=""https://github.com/lepture/mistune/commit/61e9337884e20f9f8fdc0b7788d319afdd259729""><code>61e9337</code></a> Fix table plugin</li>; <li><a href=""https://github.com/lepture/mistune/commit/76dec68c4514c2612ef9263b49c6ec7f4d77bd14""><code>76dec68</code></a> Add documentation for renderer heading when TOC enabled</li>; <li>Additional commits viewable in <a href=""https://github.com/lepture/mistune/compare/v0.8.4...v2.0.4"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=mistune&package-manager=pip&previous-version=0.8.4&new-version=2.0.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12066:3608,plugin,plugin,3608,https://hail.is,https://github.com/hail-is/hail/pull/12066,2,['plugin'],['plugin']
Modifiability,"/67db4c4de60e49825c843afebd08ef0ac47e2b0d""><code>67db4c4</code></a> chore(java): update dependencies in java requirements file (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1695"">#1695</a>) (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1760"">#1760</a>)</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/803a90b7747b8972f51d1407616c51084d97c589""><code>803a90b</code></a> deps: update dependency com.google.cloud:google-cloud-shared-dependencies to ...</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/82aacd7922573d6f4779f21cdc83de10616d7a08""><code>82aacd7</code></a> feat: add Autoclass support and sample (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1697"">#1697</a>)</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/7e3175a56a06dac0aa0841f221a486bb69b5c9bf""><code>7e3175a</code></a> deps: update dependency org.graalvm.buildtools:native-maven-plugin to v0.9.17...</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/140e90911229c876de7b674dd1e61b278e8b07fd""><code>140e909</code></a> deps: update dependency net.jqwik:jqwik to v1.7.1 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1758"">#1758</a>)</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/303ba366cc706dd233d497618bb22f8b018a617b""><code>303ba36</code></a> chore: Set <code>rest_numeric_enums = False</code> for all gapic rules explicitly (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1756"">#1756</a>)</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/e2d3851e22adac0c2d3cc25a7c772de7ac9c05aa""><code>e2d3851</code></a> chore: require hashes when installing dependencies in owlbot postprocessor jo...</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/a67683558eee7590f98a391d915eb3a19fb88f95""><code>a676835</code></a> chore(deps): update dep",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12456:12803,plugin,plugin,12803,https://hail.is,https://github.com/hail-is/hail/pull/12456,1,['plugin'],['plugin']
Modifiability,"/a> Add .DS_Store to .gitignore file</li>; <li><a href=""https://github.com/brettcannon/gidgethub/commit/ef0368998fe40769f4f20a6c4b6ccfea27fe8ca9""><code>ef03689</code></a> Bump the version number</li>; <li><a href=""https://github.com/brettcannon/gidgethub/commit/1f80a51670555acda0db0e42189d00bb58bb3b45""><code>1f80a51</code></a> Release 5.2.1</li>; <li><a href=""https://github.com/brettcannon/gidgethub/commit/89ade8859539212e0663e91f0777ad8a39ecf323""><code>89ade88</code></a> Fix cgi and importlib_resources deprecations (<a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/185"">#185</a>)</li>; <li><a href=""https://github.com/brettcannon/gidgethub/commit/64888cbe83e3f11af3c6f25294adff26dc2f557a""><code>64888cb</code></a> Add support for Python 3.11 and drop EOL Python 3.6 (<a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/184"">#184</a>)</li>; <li><a href=""https://github.com/brettcannon/gidgethub/commit/8c60e56029b7e10b7be9879e64dfbf97bbeda2b8""><code>8c60e56</code></a> Add variable mapping to fix 'Session tests-3.10-dev skipped: Python interpret...</li>; <li><a href=""https://github.com/brettcannon/gidgethub/commit/07040aa3d7dc3466308e92625bb889abe53ff0a9""><code>07040aa</code></a> Update a link</li>; <li><a href=""https://github.com/brettcannon/gidgethub/commit/5f8d37f6db04d7962256d2d934b53e1cec9c0bfc""><code>5f8d37f</code></a> v5.2.0: Add changelog entry and update the version (<a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/180"">#180</a>)</li>; <li><a href=""https://github.com/brettcannon/gidgethub/commit/cf2cb85551a8aa36536dc828e830e13032e594d4""><code>cf2cb85</code></a> Bump min PyJWT v2.4.0 (<a href=""https://github-redirect.dependabot.com/brettcannon/gidgethub/issues/179"">#179</a>)</li>; <li><a href=""https://github.com/brettcannon/gidgethub/commit/9096d1b79447a3ef81b331457ea39c43f43e2f2d""><code>9096d1b</code></a> Release v5.1.0 (<a href=""https://github-redirect.dependabot.com/brettcannon/gidgeth",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12328:8241,variab,variable,8241,https://hail.is,https://github.com/hail-is/hail/pull/12328,1,['variab'],['variable']
Modifiability,"/a>)</li>; <li><a href=""https://github.com/googleapis/python-logging/commit/a760e02371a55d6262e42de9e0222fffa2c7192b""><code>a760e02</code></a> feat: add json_fields extras argument for adding to jsonPayload (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/447"">#447</a>)</li>; <li><a href=""https://github.com/googleapis/python-logging/commit/83d9ca8521fe7c470bb6755a48a97496515d7abc""><code>83d9ca8</code></a> feat!: make logging API more friendly to use (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/422"">#422</a>)</li>; <li><a href=""https://github.com/googleapis/python-logging/commit/818213e143d6a1941211a48e0b23069a426ac300""><code>818213e</code></a> feat: avoid importing grpc when explicitly disabled (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/416"">#416</a>)</li>; <li><a href=""https://github.com/googleapis/python-logging/commit/e1506fa9030776353878048ce562c53bf6ccf7bf""><code>e1506fa</code></a> fix!: api consistency between HTTP and Gapic layers (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/375"">#375</a>)</li>; <li><a href=""https://github.com/googleapis/python-logging/commit/6fa17735fe3edb45483ec5e3abd1f53c24ffa881""><code>6fa1773</code></a> feat!: support string-encoded json (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/339"">#339</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/googleapis/python-logging/compare/v1.12.1...v3.0.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=google-cloud-logging&package-manager=pip&previous-version=1.12.1&new-version=3.0.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you d",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11574:13529,layers,layers,13529,https://hail.is,https://github.com/hail-is/hail/pull/11574,1,['layers'],['layers']
Modifiability,"/a>, <a href=""https://github.com/alculquicondor""><code>@​alculquicondor</code></a>)</li>; <li>Kube-apiserver: Fixes handling of CRD schemas containing literal null values in enums. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/104969"">kubernetes/kubernetes#104969</a>, <a href=""https://github.com/liggitt""><code>@​liggitt</code></a>)</li>; <li>Kube-apiserver: The <code>rbac.authorization.k8s.io/v1alpha1</code> API version is removed; use the <code>rbac.authorization.k8s.io/v1</code> API, available since v1.8. The <code>scheduling.k8s.io/v1alpha1</code> API version is removed; use the <code>scheduling.k8s.io/v1</code> API, available since v1.14. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/104248"">kubernetes/kubernetes#104248</a>, <a href=""https://github.com/liggitt""><code>@​liggitt</code></a>)</li>; <li>Kube-scheduler: support for configuration file version <code>v1beta1</code> is removed. Update configuration files to v1beta2(xref: <a href=""https://github-redirect.dependabot.com/kubernetes/enhancements/issues/2901"">kubernetes/enhancements#2901</a>) or v1beta3 before upgrading to 1.23. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/104782"">kubernetes/kubernetes#104782</a>, <a href=""https://github.com/kerthcet""><code>@​kerthcet</code></a>)</li>; <li>KubeSchedulerConfiguration provides a new field <code>MultiPoint</code> which will register a plugin for all valid extension points (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/105611"">kubernetes/kubernetes#105611</a>, <a href=""https://github.com/damemi""><code>@​damemi</code></a>) [SIG Scheduling and Testing]</li>; <li>Kubelet should reject pods whose OS doesn't match the node's OS label. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/105292"">kubernetes/kubernetes#105292</a>, <a href=""https://github.com/ravisantoshgudimetla""><code>@​ravisantoshgudimetla</code></a>) [SIG Apps a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11957:8450,config,configuration,8450,https://hail.is,https://github.com/hail-is/hail/pull/11957,1,['config'],['configuration']
Modifiability,"/a>]</li>; <li>Removed unused INT64 definition <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7180"">#7180</a> [<a href=""https://github.com/radarhere""><code>@​radarhere</code></a>]</li>; <li>Updated xz to 5.4.3 <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7136"">#7136</a> [<a href=""https://github.com/radarhere""><code>@​radarhere</code></a>]</li>; <li>Fixed saving TIFF multiframe images with LONG8 tag types <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7078"">#7078</a> [<a href=""https://github.com/radarhere""><code>@​radarhere</code></a>]</li>; <li>Do not set size unnecessarily if image fails to open <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7056"">#7056</a> [<a href=""https://github.com/radarhere""><code>@​radarhere</code></a>]</li>; <li>Removed unused code <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7210"">#7210</a> [<a href=""https://github.com/radarhere""><code>@​radarhere</code></a>]</li>; <li>Removed unused variables <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7205"">#7205</a> [<a href=""https://github.com/radarhere""><code>@​radarhere</code></a>]</li>; <li>Fixed signedness comparison warning <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7203"">#7203</a> [<a href=""https://github.com/radarhere""><code>@​radarhere</code></a>]</li>; <li>Fixed combining single duration across duplicate APNG frames <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7146"">#7146</a> [<a href=""https://github.com/radarhere""><code>@​radarhere</code></a>]</li>; <li>Remove temporary file when error is raised <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7148"">#7148</a> [<a href=""https://github.com/radarhere""><code>@​radarhere</code></a>]</li>; <li>Do not use temporary file when grabbing clipboard on Linux <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7200"">#7200</a> [<a href=""https://github.com/radarhere""><code>@​r",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13321:5894,variab,variables,5894,https://hail.is,https://github.com/hail-is/hail/pull/13321,1,['variab'],['variables']
Modifiability,"/code>, <code>modified-iterating-dict</code> and <code>modified-iterating-set</code>,; emitted when items are added to or removed from respectively a list, dictionary or; set being iterated through.</p>; </li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/PyCQA/pylint/commit/fd0eb6c2af0e3e98350e24047c4df7d5b8aad89a""><code>fd0eb6c</code></a> Bump pylint to 2.13.0, update changelog</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/1c509edc4ee2dbf1bbe8822e91e0b7df02ce463d""><code>1c509ed</code></a> [cleanup] Remove unused code in pylint.checker.base following refactor</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/1e7d3fa6219934028d2539ad290fe16ce8ea78e2""><code>1e7d3fa</code></a> [refactor] Create a file for the BasicChecker in pylint.checker.base</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/c0b8b32592f8d5d34ff37250adbda6b65269a0af""><code>c0b8b32</code></a> [refactor] Create a file for the BasicErrorChecker in pylint.checker.base</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/3f11fe629a7b89d2a3b92dce09ac5818f3904cee""><code>3f11fe6</code></a> [refactor] Create a package for the NameChecker in pylint.checker.base</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/6940715ba15f81fbd7d9e8685c0a714a8b612f24""><code>6940715</code></a> [refactor] Create a file for the DocstringChecker in pylint.checker.base</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/84d22cf24202bf6006fc179541e1853d145d33e0""><code>84d22cf</code></a> [refactor] Create a file for the PassChecker in pylint.checker.base</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/977b08d160e81aaecebf871d2b8ba2f9a96ef9d6""><code>977b08d</code></a> [refactor] Create files for comparison checker in pylint.checker.base</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/ddfca0ca884d677e4eb0e6f53553b16e7a503157""><code>ddfca0c</code></a> [ref",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11674:4086,refactor,refactor,4086,https://hail.is,https://github.com/hail-is/hail/pull/11674,1,['refactor'],['refactor']
Modifiability,"/h1>; <p>2021-12-29</p>; <p><strong>Enhancements</strong></p>; <ul>; <li>1851_, [Linux]: <code>cpu_freq()</code>_ is slow on systems with many CPUs. Read current; frequency values for all CPUs from <code>/proc/cpuinfo</code> instead of opening many; files in <code>/sys</code> fs. (patch by marxin)</li>; <li>1992_: <code>NoSuchProcess</code>_ message now specifies if the PID has been reused.</li>; <li>1992_: error classes (<code>NoSuchProcess</code><em>, <code>AccessDenied</code></em>, etc.) now have a better; formatted and separated <code>__repr__</code> and <code>__str__</code> implementations.</li>; <li>1996_, [BSD]: add support for MidnightBSD. (patch by Saeed Rasooli)</li>; <li>1999_, [Linux]: <code>disk_partitions()</code>_: convert <code>/dev/root</code> device (an alias; used on some Linux distros) to real root device path.</li>; <li>2005_: <code>PSUTIL_DEBUG</code> mode now prints file name and line number of the debug; messages coming from C extension modules.</li>; <li>2042_: rewrite HISTORY.rst to use hyperlinks pointing to psutil API doc.</li>; </ul>; <p><strong>Bug fixes</strong></p>; <ul>; <li>1456_, [macOS], <strong>[critical]</strong>: <code>cpu_freq()</code>_ <code>min</code> and <code>max</code> are set to; 0 if can't be determined (instead of crashing).</li>; <li>1512_, [macOS]: sometimes <code>Process.connections()</code>_ will crash with; <code>EOPNOTSUPP</code> for one connection; this is now ignored.</li>; <li>1598_, [Windows]: <code>disk_partitions()</code>_ only returns mountpoints on drives; where it first finds one.</li>; <li>1874_, [SunOS]: swap output error due to incorrect range.</li>; <li>1892_, [macOS]: <code>cpu_freq()</code>_ broken on Apple M1.</li>; <li>1901_, [macOS]: different functions, especially <code>Process.open_files()</code>_ and; <code>Process.connections()</code><em>, could randomly raise <code>AccessDenied</code></em> because the; internal buffer of <code>proc_pidinfo(PROC_PIDLISTFDS)</code> syscall was not big enough.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11459:1264,rewrite,rewrite,1264,https://hail.is,https://github.com/hail-is/hail/pull/11459,1,['rewrite'],['rewrite']
Modifiability,"/h2>; <h3>Features</h3>; <ul>; <li>Add Autoclass support and sample (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1697"">#1697</a>) (<a href=""https://github.com/googleapis/java-storage/commit/82aacd7922573d6f4779f21cdc83de10616d7a08"">82aacd7</a>)</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/googleapis/java-storage/commit/bf75118939f7b76bf3cdfbcc3c530136d15cb7fd""><code>bf75118</code></a> chore(main): release 2.16.0 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1783"">#1783</a>)</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/b1d026608a5e3772e8bf77f25f1daf68b007427a""><code>b1d0266</code></a> deps: update dependency com.google.cloud:google-cloud-shared-dependencies to ...</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/31c1b18acc3c118e39eb613a82ee292f3e246b8f""><code>31c1b18</code></a> feat: add {Compose,Rewrite,StartResumableWrite}Request.object_checksums and B...</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/deb89e56754677d6fb6db2c407a21e913385e41d""><code>deb89e5</code></a> chore: build: remove obsolete branches 1.106.1, 1.106.1-patch, 1.111.3-patch</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/c9ee3ca8820531cd709bb8f8a58a736813346861""><code>c9ee3ca</code></a> deps: update dependency org.apache.httpcomponents:httpmime to v4.5.14 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1796"">#1796</a>)</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/cf900f4139f30f89e3c0784467ddc12cc00cf81c""><code>cf900f4</code></a> deps: update dependency org.apache.httpcomponents:httpclient to v4.5.14 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1795"">#1795</a>)</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/099a61",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12545:10730,Rewrite,Rewrite,10730,https://hail.is,https://github.com/hail-is/hail/pull/12545,1,['Rewrite'],['Rewrite']
Modifiability,"/java-storage/commit/cf900f4139f30f89e3c0784467ddc12cc00cf81c"">cf900f4</a>)</li>; <li>Update dependency org.apache.httpcomponents:httpcore to v4.4.16 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1786"">#1786</a>) (<a href=""https://github.com/googleapis/java-storage/commit/3bf403e94c035e6cf936e062a1ced2b5221b3912"">3bf403e</a>)</li>; <li>Update dependency org.apache.httpcomponents:httpmime to v4.5.14 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1796"">#1796</a>) (<a href=""https://github.com/googleapis/java-storage/commit/c9ee3ca8820531cd709bb8f8a58a736813346861"">c9ee3ca</a>)</li>; <li>Update dependency org.graalvm.buildtools:native-maven-plugin to v0.9.18 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1782"">#1782</a>) (<a href=""https://github.com/googleapis/java-storage/commit/5bc517623ef04bdb9a71a51666754b9f753f4c69"">5bc5176</a>)</li>; <li>Update dependency org.graalvm.buildtools:native-maven-plugin to v0.9.19 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1791"">#1791</a>) (<a href=""https://github.com/googleapis/java-storage/commit/3184d65cce1368c2f39ff85a6ed02cf536902244"">3184d65</a>)</li>; </ul>; <h2><a href=""https://github.com/googleapis/java-storage/compare/v2.15.0...v2.15.1"">2.15.1</a> (2022-11-17)</h2>; <h3>Bug Fixes</h3>; <ul>; <li>Disable REGAPIC transport in storage v2 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1762"">#1762</a>) (<a href=""https://github.com/googleapis/java-storage/commit/13d630e7ce89273c292acca7a7e048218ece4182"">13d630e</a>)</li>; <li>Update GrpcStorageImpl#get(BlobId) to return null on 404 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1772"">#1772</a>) (<a href=""https://github.com/googleapis/java-storage/commit/8c59c64ccf0dd7753467b4c0f0bcf5f4b49c5bf0"">8c59c64</a>)</li>; </ul>; <h3>Documentation</h3>; <ul>; <li>Annotate all Option factory met",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12545:8325,plugin,plugin,8325,https://hail.is,https://github.com/hail-is/hail/pull/12545,1,['plugin'],['plugin']
Modifiability,"/java-storage/commit/cf900f4139f30f89e3c0784467ddc12cc00cf81c"">cf900f4</a>)</li>; <li>Update dependency org.apache.httpcomponents:httpcore to v4.4.16 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1786"">#1786</a>) (<a href=""https://github.com/googleapis/java-storage/commit/3bf403e94c035e6cf936e062a1ced2b5221b3912"">3bf403e</a>)</li>; <li>Update dependency org.apache.httpcomponents:httpmime to v4.5.14 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1796"">#1796</a>) (<a href=""https://github.com/googleapis/java-storage/commit/c9ee3ca8820531cd709bb8f8a58a736813346861"">c9ee3ca</a>)</li>; <li>Update dependency org.graalvm.buildtools:native-maven-plugin to v0.9.18 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1782"">#1782</a>) (<a href=""https://github.com/googleapis/java-storage/commit/5bc517623ef04bdb9a71a51666754b9f753f4c69"">5bc5176</a>)</li>; <li>Update dependency org.graalvm.buildtools:native-maven-plugin to v0.9.19 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1791"">#1791</a>) (<a href=""https://github.com/googleapis/java-storage/commit/3184d65cce1368c2f39ff85a6ed02cf536902244"">3184d65</a>)</li>; </ul>; <h2>v2.15.1</h2>; <h2><a href=""https://github.com/googleapis/java-storage/compare/v2.15.0...v2.15.1"">2.15.1</a> (2022-11-17)</h2>; <h3>Bug Fixes</h3>; <ul>; <li>Disable REGAPIC transport in storage v2 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1762"">#1762</a>) (<a href=""https://github.com/googleapis/java-storage/commit/13d630e7ce89273c292acca7a7e048218ece4182"">13d630e</a>)</li>; <li>Update GrpcStorageImpl#get(BlobId) to return null on 404 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1772"">#1772</a>) (<a href=""https://github.com/googleapis/java-storage/commit/8c59c64ccf0dd7753467b4c0f0bcf5f4b49c5bf0"">8c59c64</a>)</li>; </ul>; <h3>Documentation</h3>; <ul>; <li>Annotate all ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12545:3474,plugin,plugin,3474,https://hail.is,https://github.com/hail-is/hail/pull/12545,1,['plugin'],['plugin']
Modifiability,"/lepture/mistune/releases"">mistune's releases</a>.</em></p>; <blockquote>; <h2>Version 2.0.2</h2>; <p>Fix <code>escape_url </code> via <a href=""https://github-redirect.dependabot.com/lepture/mistune/pull/295"">lepture/mistune#295</a></p>; <h2>Version 2.0.1</h2>; <p>Fix XSS for image link syntax.</p>; <h2>Version 2.0.0</h2>; <p>First release of Mistune v2.</p>; <h2>Version 2.0.0 RC1</h2>; <p>In this release, we have a <strong>Security Fix</strong> for harmful links.</p>; <h2>Version 2.0.0 Alpha 1</h2>; <p>This is the first release of v2. An alpha version for users to have a preview of the new mistune.</p>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/lepture/mistune/blob/master/docs/changes.rst"">mistune's changelog</a>.</em></p>; <blockquote>; <h2>Changelog</h2>; <p>Here is the full history of mistune v2.</p>; <p>Version 2.0.4</p>; <pre><code>; Released on Jul 15, 2022; <ul>; <li>Fix <code>url</code> plugin in <code>&amp;lt;a&amp;gt;</code> tag</li>; <li>Fix <code>*</code> formatting</li>; </ul>; <p>Version 2.0.3; </code></pre></p>; <p>Released on Jun 27, 2022</p>; <ul>; <li>Fix <code>table</code> plugin</li>; <li>Security fix for CVE-2022-34749</li>; </ul>; <p>Version 2.0.2</p>; <pre><code>; Released on Jan 14, 2022; <p>Fix <code>escape_url</code></p>; <p>Version 2.0.1; </code></pre></p>; <p>Released on Dec 30, 2021</p>; <p>XSS fix for image link syntax.</p>; <p>Version 2.0.0</p>; <pre><code>; Released on Dec 5, 2021; <p>This is the first non-alpha release of mistune v2.</p>; <p>Version 2.0.0rc1; </code></pre></p>; <p>Released on Feb 16, 2021</p>; <p>Version 2.0.0a6</p>; <pre><code>; &lt;/tr&gt;&lt;/table&gt; ; </code></pre>; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/lepture/mistune/commit/3f422f1e84edae0f39756c45be453ecde534b755""><code>3f422f1</code></a> Version bump 2.0.3</li>; <li><a href=""https://github.com/l",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12064:1149,plugin,plugin,1149,https://hail.is,https://github.com/hail-is/hail/pull/12064,1,['plugin'],['plugin']
Modifiability,"/lepture/mistune/releases"">mistune's releases</a>.</em></p>; <blockquote>; <h2>Version 2.0.2</h2>; <p>Fix <code>escape_url </code> via <a href=""https://github-redirect.dependabot.com/lepture/mistune/pull/295"">lepture/mistune#295</a></p>; <h2>Version 2.0.1</h2>; <p>Fix XSS for image link syntax.</p>; <h2>Version 2.0.0</h2>; <p>First release of Mistune v2.</p>; <h2>Version 2.0.0 RC1</h2>; <p>In this release, we have a <strong>Security Fix</strong> for harmful links.</p>; <h2>Version 2.0.0 Alpha 1</h2>; <p>This is the first release of v2. An alpha version for users to have a preview of the new mistune.</p>; </blockquote>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/lepture/mistune/blob/master/docs/changes.rst"">mistune's changelog</a>.</em></p>; <blockquote>; <h2>Changelog</h2>; <p>Here is the full history of mistune v2.</p>; <p>Version 2.0.4</p>; <pre><code>; Released on Jul 15, 2022; <ul>; <li>Fix <code>url</code> plugin in <code>&amp;lt;a&amp;gt;</code> tag</li>; <li>Fix <code>*</code> formatting</li>; </ul>; <p>Version 2.0.3; </code></pre></p>; <p>Released on Jun 27, 2022</p>; <ul>; <li>Fix <code>table</code> plugin</li>; <li>Security fix for CVE-2022-34749</li>; </ul>; <p>Version 2.0.2</p>; <pre><code>; Released on Jan 14, 2022; <p>Fix <code>escape_url</code></p>; <p>Version 2.0.1; </code></pre></p>; <p>Released on Dec 30, 2021</p>; <p>XSS fix for image link syntax.</p>; <p>Version 2.0.0</p>; <pre><code>; Released on Dec 5, 2021; <p>This is the first non-alpha release of mistune v2.</p>; <p>Version 2.0.0rc1; </code></pre></p>; <p>Released on Feb 16, 2021</p>; <p>Version 2.0.0a6</p>; <pre><code>; &lt;/tr&gt;&lt;/table&gt; ; </code></pre>; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/lepture/mistune/commit/b92a5febd4da3d7097a3d2b8d7cac6f5d57ea20c""><code>b92a5fe</code></a> Version bump 2.0.4</li>; <li><a href=""https://github.com/l",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12066:1149,plugin,plugin,1149,https://hail.is,https://github.com/hail-is/hail/pull/12066,2,['plugin'],['plugin']
Modifiability,"/p>; <p>Version 2.0.0a6</p>; <pre><code>; &lt;/tr&gt;&lt;/table&gt; ; </code></pre>; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/lepture/mistune/commit/3f422f1e84edae0f39756c45be453ecde534b755""><code>3f422f1</code></a> Version bump 2.0.3</li>; <li><a href=""https://github.com/lepture/mistune/commit/a6d43215132fe4f3d93f8d7e90ba83b16a0838b2""><code>a6d4321</code></a> Fix asteris emphasis regex CVE-2022-34749</li>; <li><a href=""https://github.com/lepture/mistune/commit/5638e460459cb59ceb20e4ce4716c802d4d73c53""><code>5638e46</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/lepture/mistune/issues/307"">#307</a> from jieter/patch-1</li>; <li><a href=""https://github.com/lepture/mistune/commit/0eba47196a81453bafe1f2492748a87475063dff""><code>0eba471</code></a> Fix typo in guide.rst</li>; <li><a href=""https://github.com/lepture/mistune/commit/61e9337884e20f9f8fdc0b7788d319afdd259729""><code>61e9337</code></a> Fix table plugin</li>; <li><a href=""https://github.com/lepture/mistune/commit/76dec68c4514c2612ef9263b49c6ec7f4d77bd14""><code>76dec68</code></a> Add documentation for renderer heading when TOC enabled</li>; <li><a href=""https://github.com/lepture/mistune/commit/799cd118cc5e664b72e98410ce1b68645f1a38c0""><code>799cd11</code></a> Version bump 2.0.2</li>; <li><a href=""https://github.com/lepture/mistune/commit/babb0cfa57a983ead615286a2b7c8f6885c46721""><code>babb0cf</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/lepture/mistune/issues/295"">#295</a> from dairiki/bug.escape_url</li>; <li><a href=""https://github.com/lepture/mistune/commit/fc2cd53d7698e432ab5b250ffac53458263a49e2""><code>fc2cd53</code></a> Make mistune.util.escape_url less aggressive</li>; <li><a href=""https://github.com/lepture/mistune/commit/3e8d35215120ac82176f300dd5e20c0bea5464ea""><code>3e8d352</code></a> Version bump 2.0.1</li>; <li>Additional commits viewable in <a href=""h",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12064:2837,plugin,plugin,2837,https://hail.is,https://github.com/hail-is/hail/pull/12064,1,['plugin'],['plugin']
Modifiability,"/utils.py"", line 35, in <lambda>; thread_pool, lambda: fun(*args, **kwargs)); File ""/usr/local/lib/python3.6/site-packages/batch/google_storage.py"", line 65, in _write_gs_file; f.upload_from_string(string, *args, **kwargs); File ""/usr/local/lib/python3.6/site-packages/google/cloud/storage/blob.py"", line 1257, in upload_from_string; predefined_acl=predefined_acl,; File ""/usr/local/lib/python3.6/site-packages/google/cloud/storage/blob.py"", line 1157, in upload_from_file; client, file_obj, content_type, size, num_retries, predefined_acl; File ""/usr/local/lib/python3.6/site-packages/google/cloud/storage/blob.py"", line 1063, in _do_upload; client, stream, content_type, size, num_retries, predefined_acl; File ""/usr/local/lib/python3.6/site-packages/google/cloud/storage/blob.py"", line 857, in _do_multipart_upload; response = upload.transmit(transport, data, object_metadata, content_type); File ""/usr/local/lib/python3.6/site-packages/google/resumable_media/requests/upload.py"", line 106, in transmit; retry_strategy=self._retry_strategy,; File ""/usr/local/lib/python3.6/site-packages/google/resumable_media/requests/_helpers.py"", line 136, in http_request; return _helpers.wait_and_retry(func, RequestsMixin._get_status_code, retry_strategy); File ""/usr/local/lib/python3.6/site-packages/google/resumable_media/_helpers.py"", line 150, in wait_and_retry; response = func(); File ""/usr/local/lib/python3.6/site-packages/google/auth/transport/requests.py"", line 317, in request; **kwargs; File ""/usr/local/lib/python3.6/site-packages/requests/sessions.py"", line 533, in request; resp = self.send(prep, **send_kwargs); File ""/usr/local/lib/python3.6/site-packages/requests/sessions.py"", line 646, in send; r = adapter.send(request, **kwargs); File ""/usr/local/lib/python3.6/site-packages/requests/adapters.py"", line 529, in send; raise ReadTimeout(e, request=request); requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='www.googleapis.com', port=443): Read timed out. (read timeout=60). ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8083:4990,adapt,adapter,4990,https://hail.is,https://github.com/hail-is/hail/issues/8083,2,['adapt'],"['adapter', 'adapters']"
Modifiability,"/utils.py"", line 35, in <lambda>; thread_pool, lambda: fun(*args, **kwargs)); File ""/usr/local/lib/python3.6/site-packages/batch/google_storage.py"", line 65, in _write_gs_file; f.upload_from_string(string, *args, **kwargs); File ""/usr/local/lib/python3.6/site-packages/google/cloud/storage/blob.py"", line 1257, in upload_from_string; predefined_acl=predefined_acl,; File ""/usr/local/lib/python3.6/site-packages/google/cloud/storage/blob.py"", line 1157, in upload_from_file; client, file_obj, content_type, size, num_retries, predefined_acl; File ""/usr/local/lib/python3.6/site-packages/google/cloud/storage/blob.py"", line 1063, in _do_upload; client, stream, content_type, size, num_retries, predefined_acl; File ""/usr/local/lib/python3.6/site-packages/google/cloud/storage/blob.py"", line 857, in _do_multipart_upload; response = upload.transmit(transport, data, object_metadata, content_type); File ""/usr/local/lib/python3.6/site-packages/google/resumable_media/requests/upload.py"", line 106, in transmit; retry_strategy=self._retry_strategy,; File ""/usr/local/lib/python3.6/site-packages/google/resumable_media/requests/_helpers.py"", line 136, in http_request; return _helpers.wait_and_retry(func, RequestsMixin._get_status_code, retry_strategy); File ""/usr/local/lib/python3.6/site-packages/google/resumable_media/_helpers.py"", line 150, in wait_and_retry; response = func(); File ""/usr/local/lib/python3.6/site-packages/google/auth/transport/requests.py"", line 317, in request; **kwargs; File ""/usr/local/lib/python3.6/site-packages/requests/sessions.py"", line 533, in request; resp = self.send(prep, **send_kwargs); File ""/usr/local/lib/python3.6/site-packages/requests/sessions.py"", line 646, in send; r = adapter.send(request, **kwargs); File ""/usr/local/lib/python3.6/site-packages/requests/adapters.py"", line 529, in send; raise ReadTimeout(e, request=request); requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='www.googleapis.com', port=443): Read timed out. (read timeout=60); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8053:5000,adapt,adapter,5000,https://hail.is,https://github.com/hail-is/hail/issues/8053,4,['adapt'],"['adapter', 'adapters']"
Modifiability,"0,0.00,0.25,0.52;AS_ReadPosRankSum=-0.200,.,0.500,-0.220;AS_SOR=2.300,.,1.600,3.000;BaseQRankSum=0.200;DP=600000;ExcessHet=0.0477;FS=0.900;MQ=55.02;MQRankSum=-0.553;QD=1.00;ReadPosRankSum=-0.162;SOR=0.792;VarDP=650	GT:AD:DP:GQ:PGT:PID:PL:PS:SB	0/0:.:21:30	0/0:.:300:20	0/0:.:30:72	0/0:.:31:98	0|1:29,3,0,0,0:33:78:0|1:113_GG_G:78,0,1100,140,1400,1200,172,1600,1200,1000,175,1100,1100,1300,1000:113:19,19,2,1	0/0:.:20:19	0/0:.:19:20	0/0:.:25:50		0|1:90,2,0,0,0:30:40:0|1:113_GG_G:40,0,600,70,650,600,90,640,900,300,60,800,400,900,900:113:2,14,2,0	0/0:.:20:10	0/0:.:9:20	0/0:.:30:40	0/0:.:37:38		0/4:5,0,0,0,1:5:33:.:.:30,40,400,50,220,220,38,270,270,270,0,200,200,200,202:.:5,0,0,1	. 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:22); 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:22); 	at is.hail.utils.package$.fatal(package.scala:81); 	at is.hail.io.vcf.MatrixVCFReader.$anonfun$executeGeneric$7(LoadVCF.scala:1921); 	at is.hail.io.vcf.MatrixVCFReader.$anonfun$executeGeneric$7$adapted(LoadVCF.scala:1909); 	at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:515); 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460); 	at __C678stream_Let.apply(Emit.scala); 	at is.hail.expr.ir.CompileIterator$$anon$2.step(Compile.scala:302); 	at is.hail.expr.ir.CompileIterator$LongIteratorWrapper.hasNext(Compile.scala:155); 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490); 	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460); 	at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:490); 	at is.hail.rvd.RVD$.$anonfun$getKeyInfo$2(RVD.scala:1030); 	at is.hail.rvd.RVD$.$anonfun$getKeyInfo$2$adapted(RVD.scala:1029); 	at is.hail.sparkextras.ContextRDD.$anonfun$crunJobWithIndex$1(ContextRDD.scala:242); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:136); 	at org.apache.spark.e",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14102:7568,adapt,adapted,7568,https://hail.is,https://github.com/hail-is/hail/issues/14102,2,['adapt'],['adapted']
Modifiability,01); 	at org.apache.spark.rdd.RDD.$anonfun$collect$1(RDD.scala:1021); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:406); 	at org.apache.spark.rdd.RDD.collect(RDD.scala:1020); 	at is.hail.sparkextras.ContextRDD.collect(ContextRDD.scala:176); 	at is.hail.utils.richUtils.RichContextRDD.writePartitions(RichContextRDD.scala:105); 	at is.hail.io.RichContextRDDLong$.writeRows$extension(RichContextRDDRegionValue.scala:234); 	at is.hail.rvd.RVD.write(RVD.scala:779); 	at is.hail.expr.ir.TableNativeWriter.apply(TableWriter.scala:128); 	at is.hail.expr.ir.Interpret$.run(Interpret.scala:865); 	at is.hail.expr.ir.Interpret$.alreadyLowered(Interpret.scala:59); 	at is.hail.expr.ir.LowerOrInterpretNonCompilable$.evaluate$1(LowerOrInterpretNonCompilable.scala:20); 	at is.hail.expr.ir.LowerOrInterpretNonCompilable$.rewrite$1(LowerOrInterpretNonCompilable.scala:67); 	at is.hail.expr.ir.LowerOrInterpretNonCompilable$.apply(LowerOrInterpretNonCompilable.scala:72); 	at is.hail.expr.ir.lowering.LowerOrInterpretNonCompilablePass$.transform(LoweringPass.scala:67); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:16); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:16); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:14); 	at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:13); 	at is.hail.expr.ir.lowering.LowerOrInterpretNonCompilablePass$.apply(LoweringPass.scala:62); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:22); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:20); 	at scala.collection.mutable.ResizableArray.foreac,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12936:7632,rewrite,rewrite,7632,https://hail.is,https://github.com/hail-is/hail/issues/12936,1,['rewrite'],['rewrite']
Modifiability,"02ce463d""><code>1c509ed</code></a> [cleanup] Remove unused code in pylint.checker.base following refactor</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/1e7d3fa6219934028d2539ad290fe16ce8ea78e2""><code>1e7d3fa</code></a> [refactor] Create a file for the BasicChecker in pylint.checker.base</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/c0b8b32592f8d5d34ff37250adbda6b65269a0af""><code>c0b8b32</code></a> [refactor] Create a file for the BasicErrorChecker in pylint.checker.base</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/3f11fe629a7b89d2a3b92dce09ac5818f3904cee""><code>3f11fe6</code></a> [refactor] Create a package for the NameChecker in pylint.checker.base</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/6940715ba15f81fbd7d9e8685c0a714a8b612f24""><code>6940715</code></a> [refactor] Create a file for the DocstringChecker in pylint.checker.base</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/84d22cf24202bf6006fc179541e1853d145d33e0""><code>84d22cf</code></a> [refactor] Create a file for the PassChecker in pylint.checker.base</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/977b08d160e81aaecebf871d2b8ba2f9a96ef9d6""><code>977b08d</code></a> [refactor] Create files for comparison checker in pylint.checker.base</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/ddfca0ca884d677e4eb0e6f53553b16e7a503157""><code>ddfca0c</code></a> [refactor] Create a file for _BasicChecker in pylint.checkers</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/be4699399904654ef4107a228817b4ef176d8999""><code>be46993</code></a> [refactor] Create a package in order to be able to burst base.py</li>; <li>Additional commits viewable in <a href=""https://github.com/PyCQA/pylint/compare/v2.12.2...v2.13.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pylint&package-manager=pip&previous-version=2.12.2&new-version=2.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11674:4679,refactor,refactor,4679,https://hail.is,https://github.com/hail-is/hail/pull/11674,1,['refactor'],['refactor']
Modifiability,"0374e9f4e4b701d7"">Full Changelog</a>)</p>; <h3>Bugs fixed</h3>; <ul>; <li>Fix json_output in kernelspec app <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/921"">#921</a> (<a href=""https://github.com/blink1073""><code>@​blink1073</code></a>)</li>; </ul>; <h3>Contributors to this release</h3>; <p>(<a href=""https://github.com/jupyter/jupyter_client/graphs/contributors?from=2023-01-26&amp;to=2023-01-26&amp;type=c"">GitHub contributors page for this release</a>)</p>; <p><a href=""https://github.com/search?q=repo%3Ajupyter%2Fjupyter_client+involves%3Ablink1073+updated%3A2023-01-26..2023-01-26&amp;type=Issues""><code>@​blink1073</code></a></p>; <h2>8.0.0</h2>; <p>(<a href=""https://github.com/jupyter/jupyter_client/compare/v7.3.5...760a7835d8b20a9daea3737759b1751d5e55dad8"">Full Changelog</a>)</p>; <p>This release is primarily focused on improving <code>asyncio</code> support, while aiming to have minimal API changes.</p>; <h3>Enhancements made</h3>; <ul>; <li>Remove nest-asyncio dependency <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/835"">#835</a> (<a href=""https://github.com/blink1073""><code>@​blink1073</code></a>)</li>; </ul>; <h3>Bugs fixed</h3>; <ul>; <li>Allow interrupt during restart of pending kernels <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/898"">#898</a> (<a href=""https://github.com/blink1073""><code>@​blink1073</code></a>)</li>; <li>Fix connection reconciliation to handle restarts <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/882"">#882</a> (<a href=""https://github.com/kevin-bates""><code>@​kevin-bates</code></a>)</li>; <li>Reconcile connection information <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/879"">#879</a> (<a href=""https://github.com/kevin-bates""><code>@​kevin-bates</code></a>)</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>;",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12656:5297,Enhance,Enhancements,5297,https://hail.is,https://github.com/hail-is/hail/pull/12656,1,['Enhance'],['Enhancements']
Modifiability,"0</a>)</li>; <li><code>from __future__ import annotations</code> statement now implies Python 3.7+ (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2690"">#2690</a>)</li>; </ul>; <h3>Performance</h3>; <ul>; <li>Speed-up the new backtracking parser about 4X in general (enabled when <code>--target-version</code> is set to 3.10 and higher). (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2728"">#2728</a>)</li>; <li>Black is now compiled with mypyc for an overall 2x speed-up. 64-bit Windows, MacOS, and Linux (not including musl) are supported. (<a href=""https://github-redirect.dependabot.com/psf/black/issues/1009"">#1009</a>, <a href=""https://github-redirect.dependabot.com/psf/black/issues/2431"">#2431</a>)</li>; </ul>; <h3>Configuration</h3>; <ul>; <li>Do not accept bare carriage return line endings in pyproject.toml (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2408"">#2408</a>)</li>; <li>Add configuration option (<code>python-cell-magics</code>) to format cells with custom magics in Jupyter Notebooks (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2744"">#2744</a>)</li>; <li>Allow setting custom cache directory on all platforms with environment variable <code>BLACK_CACHE_DIR</code> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2739"">#2739</a>).</li>; <li>Enable Python 3.10+ by default, without any extra need to specify -<code>-target-version=py310</code>. (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2758"">#2758</a>)</li>; <li>Make passing <code>SRC</code> or <code>--code</code> mandatory and mutually exclusive (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2804"">#2804</a>)</li>; </ul>; <h3>Output</h3>; <ul>; <li>Improve error message for invalid regular expression (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2678"">#2678</a>)</li>; <li>Improve error message when parsing fails during AST safety check by embedding the underly",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11468:4731,config,configuration,4731,https://hail.is,https://github.com/hail-is/hail/pull/11468,1,['config'],['configuration']
Modifiability,"1. If the user has not specified a configuration for disable_progress_bar, then only disable it if we are noninteractive. 2. Change @fails_service_backend to @skip... for a `to_spark` test. 3. Pass the path collision test by using `Validate`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12535:35,config,configuration,35,https://hail.is,https://github.com/hail-is/hail/pull/12535,1,['config'],['configuration']
Modifiability,"1. Introduce new MatrixIR types FilterColsIR and FilterRowsIR which take an IR predicate; and implement it by ir.Compile. 2. New MatrixIR rewrite rules matching these. 3. Change filterColsExpr and filterRowsExpr to attempt pred.toIR() conversion, and use; FilterColsIR/FilterRowsIR if that succeeds. 4. New PrettyAST(ast: AST) is a deep pretty-printer for AST predicates, so that it's easy to; understand a predicate which fails toIR()",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3174:138,rewrite,rewrite,138,https://hail.is,https://github.com/hail-is/hail/pull/3174,1,['rewrite'],['rewrite']
Modifiability,"1. Replace kaniko with buildkit.; 2. For any repository, the `cache` tag is a dump of layers that have been built before.; 3. Allow ci to start docker jobs that are ""unconfined"" by app armor and seccomp.; 4. Add `docker-build.sh` which enforces use of buildkit, knows about the `cache` tag, and ensures the cache is updated on each build.; 5. Remove the `gcloud` binary from Dockerfile.base. Replace uses with either the gcloud-sdk image or with ci-utils-image, which now contains the gcloud install.; 6. Move pyspark (which is huge, 100s of MB) before everything because its version rarely changes.; 7. Move requirements.txt to the end of base, since it changes more often than the rest.; 8. Move hailtop last in service-base because hailtop has a git SHA in it.; 9. Simplify make files: always use docker-build.sh, no explicit pushes (we almost always want to push), no explicit pulls (buildkit cache doesn't need it), none of this digest nonsense (it was never accurate anyway). When my namespace CI builds ci/test/resources/build.yaml, it finishes in 4 minutes. Still dominated by image building. Layer extraction (required when things change, e.g. hail top's SHA change or hello's python files) dominates our time. We might try collapsing the largely unchanging lower layers of service-base (pyspark, apt-get, gcs-connector, and catch2). That will hurt us when we *do* change one of those layers. Alternatively, we might make service-base based on hail-ubuntu instead of base. We could eliminate a bunch of build software like cmake, gcc, and the jdk. I based the create-certs image on hail-ubuntu to ensure its built early and doesn't hold up service deployment. The following is an as-cached-as-possible build. The service and hello images have to extract layers and build themselves because the SHA changed. <img width=""1920"" alt=""Screen Shot 2021-05-19 at 2 34 18 PM"" src=""https://user-images.githubusercontent.com/106194/118865766-4e74d800-b8af-11eb-8386-94a3782a2a45.png"">. I'm not even sur",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10502:86,layers,layers,86,https://hail.is,https://github.com/hail-is/hail/pull/10502,1,['layers'],['layers']
Modifiability,16(BackendUtils.scala:91) ~[gs:__hail-query-ger0g_jars_13536b531342a263b24a7165bfeec7bd02723e4b.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.utils.package$.using(package.scala:637) ~[gs:__hail-query-ger0g_jars_13536b531342a263b24a7165bfeec7bd02723e4b.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.annotations.RegionPool.scopedRegion(RegionPool.scala:162) ~[gs:__hail-query-ger0g_jars_13536b531342a263b24a7165bfeec7bd02723e4b.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.BackendUtils.$anonfun$collectDArray$15(BackendUtils.scala:90) ~[gs:__hail-query-ger0g_jars_13536b531342a263b24a7165bfeec7bd02723e4b.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$12(Worker.scala:167) ~[gs:__hail-query-ger0g_jars_13536b531342a263b24a7165bfeec7bd02723e4b.jar.jar:0.0.1-SNAPSHOT]; 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.15.jar:?]; 	at is.hail.services.package$.retryTransientErrors(package.scala:182) ~[gs:__hail-query-ger0g_jars_13536b531342a263b24a7165bfeec7bd02723e4b.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$11(Worker.scala:166) ~[gs:__hail-query-ger0g_jars_13536b531342a263b24a7165bfeec7bd02723e4b.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$11$adapted(Worker.scala:164) ~[gs:__hail-query-ger0g_jars_13536b531342a263b24a7165bfeec7bd02723e4b.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.utils.package$.using(package.scala:637) ~[gs:__hail-query-ger0g_jars_13536b531342a263b24a7165bfeec7bd02723e4b.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.main(Worker.scala:164) ~[gs:__hail-query-ger0g_jars_13536b531342a263b24a7165bfeec7bd02723e4b.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Main$.main(Main.scala:14) ~[gs:__hail-query-ger0g_jars_13536b531342a263b24a7165bfeec7bd02723e4b.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Main.main(Main.scala) ~[gs:__hail-query-ger0g_jars_13536b531342a263b24a7165bfeec7bd02723e4b.jar.jar:0.0.1-SNAPSHOT]; 	... 11 more; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13721:12159,adapt,adapted,12159,https://hail.is,https://github.com/hail-is/hail/issues/13721,1,['adapt'],['adapted']
Modifiability,"16f2a7</code></a> Fix reference in docs build.</li>; <li><a href=""https://github.com/python/importlib_metadata/commit/c8d7285af792d6851227212d4261ce7ae180a87c""><code>c8d7285</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/python/importlib_metadata/issues/391"">#391</a> from python/ghpython-93259/from-name-arg-validation-s...</li>; <li><a href=""https://github.com/python/importlib_metadata/commit/91b71494226a95251134c4fe6ea65a1dd25f495c""><code>91b7149</code></a> Update changelog</li>; <li><a href=""https://github.com/python/importlib_metadata/commit/c96dc1e77f032315bfc78f0c1d13c9a61fb68c3f""><code>c96dc1e</code></a> Merge branch 'main' into ghpython-93259/from-name-arg-validation-simple</li>; <li><a href=""https://github.com/python/importlib_metadata/commit/f52757d0c8a9a555d0591a86b334a17028e2ead9""><code>f52757d</code></a> In Distribution.from_name, re-use discover.</li>; <li><a href=""https://github.com/python/importlib_metadata/commit/344a6ffc612eec611592e7686264ced72f64da5a""><code>344a6ff</code></a> Refactor Distribution.from_name to avoid return in loop and unnecessary None ...</li>; <li><a href=""https://github.com/python/importlib_metadata/commit/eb19c647519c754dd93b42a0c421101af73cf7a4""><code>eb19c64</code></a> In Distribution.from_name, require a non-empty string. Fixes <a href=""https://github-redirect.dependabot.com/python/cpython/issues/9"">python/cpython#9</a>...</li>; <li><a href=""https://github.com/python/importlib_metadata/commit/d3fe031dbad4590896829f18ecbd8d9d8a132f53""><code>d3fe031</code></a> Add comment about the compatibility factor.</li>; <li><a href=""https://github.com/python/importlib_metadata/commit/a4ae953dca38da768bcd1786aeba84bada32efb4""><code>a4ae953</code></a> Add xfail test capturing new expectation.</li>; <li><a href=""https://github.com/python/importlib_metadata/commit/e5b7d8759214feedd0c49a7859ebb124473bcfc3""><code>e5b7d87</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/python/importli",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12000:3387,Refactor,Refactor,3387,https://hail.is,https://github.com/hail-is/hail/pull/12000,1,['Refactor'],['Refactor']
Modifiability,1905); 	at is.hail.expr.ir.Interpret$.run(Interpret.scala:784); 	at is.hail.expr.ir.Interpret$.alreadyLowered(Interpret.scala:56); 	at is.hail.expr.ir.InterpretNonCompilable$.interpretAndCoerce$1(InterpretNonCompilable.scala:16); 	at is.hail.expr.ir.InterpretNonCompilable$.rewrite$1(InterpretNonCompilable.scala:53); 	at is.hail.expr.ir.InterpretNonCompilable$.$anonfun$apply$1(InterpretNonCompilable.scala:25); 	at scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286); 	at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOptimized.scala:36); 	at scala.collection.IndexedSeqOptimized.foreach$(IndexedSeqOptimized.scala:33); 	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:38); 	at scala.collection.TraversableLike.map(TraversableLike.scala:286); 	at scala.collection.TraversableLike.map$(TraversableLike.scala:279); 	at scala.collection.AbstractTraversable.map(Traversable.scala:108); 	at is.hail.expr.ir.InterpretNonCompilable$.rewriteChildren$1(InterpretNonCompilable.scala:25); 	at is.hail.expr.ir.InterpretNonCompilable$.rewrite$1(InterpretNonCompilable.scala:54); 	at is.hail.expr.ir.InterpretNonCompilable$.apply(InterpretNonCompilable.scala:58); 	at is.hail.expr.ir.lowering.InterpretNonCompilablePass$.transform(LoweringPass.scala:67); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:15); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:15); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:13); 	at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:12); 	at is.hail.expr.ir.lowering.InterpretNonCompilablePass$.apply(LoweringPass.scala:62); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:14); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.s,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/10682:10888,rewrite,rewriteChildren,10888,https://hail.is,https://github.com/hail-is/hail/issues/10682,1,['rewrite'],['rewriteChildren']
Modifiability,"19:06:30,198	main.py	get_credentials_1:226	returning azure credentials to activating instance instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q; INFO	2022-03-02 19:06:30,199	hail_logging.py	log:40	https GET /pr-11438-default-g6cibyji6520/batch-driver/api/v1alpha/instances/credentials done in 0.005999999999858119s: 200; INFO	2022-03-02 19:06:30,226	main.py	activate_instance_1:237	activating instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q; INFO	2022-03-02 19:06:30,991	base.py	check:335	checking on instance batch-worker-pr-11438-default-g6cibyji6520-highcpu-z0idl, last updated 60.151s ago; INFO	2022-03-02 19:06:31,526	pool.py	schedule_loop_body:371	schedule pool standard: starting; INFO	2022-03-02 19:06:31,583	job.py	schedule_job:443	schedule job (94, 2) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:31,584	job.py	schedule_job:443	schedule job (95, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:31,585	job.py	schedule_job:443	schedule job (93, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:31,586	job.py	schedule_job:443	schedule job (90, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:31,586	job.py	schedule_job:443	schedule job (94, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:31,598	job.py	schedule_job:443	schedule job (97, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:31,656	job.py	schedule_job:443	schedule job (99, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:31,662	job.py	schedule_job:443	schedule job (100, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:1280,config,config,1280,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['config'],['config']
Modifiability,"1cd709bb8f8a58a736813346861""><code>c9ee3ca</code></a> deps: update dependency org.apache.httpcomponents:httpmime to v4.5.14 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1796"">#1796</a>)</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/cf900f4139f30f89e3c0784467ddc12cc00cf81c""><code>cf900f4</code></a> deps: update dependency org.apache.httpcomponents:httpclient to v4.5.14 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1795"">#1795</a>)</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/099a6165722464b46d37206af274a637d3f0461a""><code>099a616</code></a> test(deps): update cross product test dependencies (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1792"">#1792</a>)</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/3184d65cce1368c2f39ff85a6ed02cf536902244""><code>3184d65</code></a> deps: update dependency org.graalvm.buildtools:native-maven-plugin to v0.9.19...</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/7d6742115bcea6b848a289fdf5c4e4bbafc4cf18""><code>7d67421</code></a> build(deps): update dependency com.google.cloud:google-cloud-shared-config to...</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/3bf403e94c035e6cf936e062a1ced2b5221b3912""><code>3bf403e</code></a> deps: update dependency org.apache.httpcomponents:httpcore to v4.4.16 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1786"">#1786</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/googleapis/java-storage/compare/v1.106.0...v2.16.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=com.google.cloud:google-cloud-storage&package-manager=gradle&previous-version=1.106.0&new-version=2.16.0)](https://docs.github.com/en/github/managing-security-vulner",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12545:12093,plugin,plugin,12093,https://hail.is,https://github.com/hail-is/hail/pull/12545,1,['plugin'],['plugin']
Modifiability,"2 -> struct{},__iruid_2157 -> struct{}),None,None,()); 	at is.hail.expr.ir.TypeCheck$.checkSingleNode(TypeCheck.scala:110); 	at is.hail.expr.ir.TypeCheck$.$anonfun$check$4(TypeCheck.scala:37); 	at is.hail.expr.ir.TypeCheck$.$anonfun$check$4$adapted(TypeCheck.scala:29); 	at is.hail.utils.StackSafe$StackFrame.$anonfun$map$1(StackSafe.scala:30); 	at is.hail.utils.StackSafe$StackFrame.flatMap(StackSafe.scala:21); 	at is.hail.utils.StackSafe$StackFrame.map(StackSafe.scala:30); 	at is.hail.expr.ir.TypeCheck$.check(TypeCheck.scala:29); 	at is.hail.expr.ir.TypeCheck$.$anonfun$check$2(TypeCheck.scala:31); 	at is.hail.utils.StackSafe$More.advance(StackSafe.scala:64); 	at is.hail.utils.StackSafe$.run(StackSafe.scala:16); 	at is.hail.utils.StackSafe$StackFrame.run(StackSafe.scala:32); 	at is.hail.expr.ir.TypeCheck$.apply(TypeCheck.scala:15); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:29); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:19); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at is.hail.expr.ir.lowering.LoweringPipeline.apply(LoweringPipeline.scala:19); 	at is.hail.backend.local.LocalBackend._jvmLowerAndExecute(LocalBackend.scala:205); 	at is.hail.backend.local.LocalBackend._execute(LocalBackend.scala:249); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$2(LocalBackend.scala:314); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1(LocalBackend.scala:309); 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1$adapted(LocalBackend.scala:308); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:78); 	at is.hail.utils.package$.using(package.scala:664); 	at is.hail.backend.ExecuteContext$.$anonfun$sco",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14245:19422,adapt,adapted,19422,https://hail.is,https://github.com/hail-is/hail/issues/14245,1,['adapt'],['adapted']
Modifiability,"2-03-02 19:06:30,991	base.py	check:335	checking on instance batch-worker-pr-11438-default-g6cibyji6520-highcpu-z0idl, last updated 60.151s ago; INFO	2022-03-02 19:06:31,526	pool.py	schedule_loop_body:371	schedule pool standard: starting; INFO	2022-03-02 19:06:31,583	job.py	schedule_job:443	schedule job (94, 2) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:31,584	job.py	schedule_job:443	schedule job (95, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:31,585	job.py	schedule_job:443	schedule job (93, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:31,586	job.py	schedule_job:443	schedule job (90, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:31,586	job.py	schedule_job:443	schedule job (94, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:31,598	job.py	schedule_job:443	schedule job (97, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:31,656	job.py	schedule_job:443	schedule job (99, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:31,662	job.py	schedule_job:443	schedule job (100, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:31,663	job.py	schedule_job:443	schedule job (98, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:32,455	job.py	schedule_job:443	schedule job (101, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:32,455	job.py	schedule_job:443	schedule job (102, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:1766,config,config,1766,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['config'],['config']
Modifiability,"21ce02ce25ce311d"">3b71fab</a>)</li>; <li>Update dependency net.jqwik:jqwik to v1.7.2 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1833"">#1833</a>) (<a href=""https://github.com/googleapis/java-storage/commit/83bc261130e89e5994f21e32422054ef6ea2fe8e"">83bc261</a>)</li>; <li>Update dependency org.junit.vintage:junit-vintage-engine to v5.9.2 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1837"">#1837</a>) (<a href=""https://github.com/googleapis/java-storage/commit/5b381845b4f48a691aa3f0cb96599ddefc7e463f"">5b38184</a>)</li>; <li>Update junit-platform.version to v5.9.2 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1838"">#1838</a>) (<a href=""https://github.com/googleapis/java-storage/commit/372521ba80b12e52c74fae5ac766dbe6610ff0b2"">372521b</a>)</li>; </ul>; <h2><a href=""https://github.com/googleapis/java-storage/compare/v2.15.1...v2.16.0"">2.16.0</a> (2022-12-06)</h2>; <h3>Features</h3>; <ul>; <li>Add {Compose,Rewrite,StartResumableWrite}Request.object_checksums and Bucket.RetentionPolicy.retention_duration (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1790"">#1790</a>) (<a href=""https://github.com/googleapis/java-storage/commit/31c1b18acc3c118e39eb613a82ee292f3e246b8f"">31c1b18</a>)</li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/googleapis/java-storage/commit/28bd2bbe07eeb014ba63c62125371286163fbbdc""><code>28bd2bb</code></a> chore(main): release 2.17.1 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1854"">#1854</a>)</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/1425dd97cb7d4a58f0bbededeca543f1a89c7d5d""><code>1425dd9</code></a> fix: update BaseStorageReadChannel to be left open unless explicitly closed (...</li>; <li><a href=""https://github.com/googleapis/java-storage/comm",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12598:13089,Rewrite,Rewrite,13089,https://hail.is,https://github.com/hail-is/hail/pull/12598,1,['Rewrite'],['Rewrite']
Modifiability,236); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2257); 	at org.apache.spark.SparkContext.runJob(SparkContext.scala:2289); 	at is.hail.sparkextras.ContextRDD.crunJobWithIndex(ContextRDD.scala:238); 	at is.hail.rvd.RVD$.getKeyInfo(RVD.scala:1029); 	at is.hail.rvd.RVD$.makeCoercer(RVD.scala:1104); 	at is.hail.rvd.RVD$.coerce(RVD.scala:1060); 	at is.hail.rvd.RVD.changeKey(RVD.scala:142); 	at is.hail.rvd.RVD.changeKey(RVD.scala:135); 	at is.hail.backend.spark.SparkBackend.lowerDistributedSort(SparkBackend.scala:716); 	at is.hail.backend.Backend.lowerDistributedSort(Backend.scala:143); 	at is.hail.expr.ir.lowering.LowerAndExecuteShuffles$.$anonfun$apply$1(LowerAndExecuteShuffles.scala:17); 	at is.hail.expr.ir.RewriteBottomUp$.$anonfun$apply$2(RewriteBottomUp.scala:11); 	at is.hail.utils.StackSafe$More.advance(StackSafe.scala:60); 	at is.hail.utils.StackSafe$.run(StackSafe.scala:16); 	at is.hail.utils.StackSafe$StackFrame.run(StackSafe.scala:32); 	at is.hail.expr.ir.RewriteBottomUp$.apply(RewriteBottomUp.scala:21); 	at is.hail.expr.ir.lowering.LowerAndExecuteShuffles$.apply(LowerAndExecuteShuffles.scala:14); 	at is.hail.expr.ir.lowering.LowerAndExecuteShufflesPass.transform(LoweringPass.scala:167); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:26); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:26); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:24); 	at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:23); 	at is.hail.expr.ir.lowering.LowerAndExecuteShufflesPass.apply(LoweringPass.scala:161); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:22); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:20); 	at scala.collection.mutable.ResizableArray.foreach(Res,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14102:12305,Rewrite,RewriteBottomUp,12305,https://hail.is,https://github.com/hail-is/hail/issues/14102,1,['Rewrite'],['RewriteBottomUp']
Modifiability,24); 	at is.hail.expr.ir.EmitClassBuilder.newEmitMethod(EmitClassBuilder.scala:584); 	at is.hail.expr.ir.EmitClassBuilder.genEmitMethod(EmitClassBuilder.scala:754); 	at is.hail.expr.ir.EmitClassBuilder.$anonfun$getOrGenEmitMethod$1(EmitClassBuilder.scala:747); 	at scala.collection.mutable.HashMap.getOrElseUpdate(HashMap.scala:86); 	at is.hail.expr.ir.EmitClassBuilder.getOrGenEmitMethod(EmitClassBuilder.scala:746); 	at is.hail.types.encoded.EType.buildEncoderMethod(EType.scala:57); 	at is.hail.types.encoded.EType.buildEncoder(EType.scala:49); 	at is.hail.expr.ir.PartitionNativeWriter$StreamConsumer.consumeElement(TableWriter.scala:294); 	at is.hail.expr.ir.PartitionNativeWriter.$anonfun$consumeStream$1(TableWriter.scala:334); 	at is.hail.expr.ir.PartitionNativeWriter.$anonfun$consumeStream$1$adapted(TableWriter.scala:332); 	at is.hail.expr.ir.streams.StreamProducer.$anonfun$memoryManagedConsume$1(EmitStream.scala:113); 	at is.hail.expr.ir.streams.StreamProducer.$anonfun$memoryManagedConsume$1$adapted(EmitStream.scala:112); 	at is.hail.expr.ir.streams.StreamProducer.unmanagedConsume(EmitStream.scala:100); 	at is.hail.expr.ir.streams.StreamProducer.memoryManagedConsume(EmitStream.scala:112); 	at is.hail.expr.ir.PartitionNativeWriter.consumeStream(TableWriter.scala:332); 	at is.hail.expr.ir.Emit.$anonfun$emit$21(Emit.scala:2629); 	at is.hail.expr.ir.IEmitCodeGen.flatMap(Emit.scala:351); 	at is.hail.expr.ir.Emit.$anonfun$emit$20(Emit.scala:2628); 	at is.hail.expr.ir.EmitCode$.fromI(Emit.scala:445); 	at is.hail.expr.ir.Emit.emit(Emit.scala:2627); 	at is.hail.expr.ir.Emit.emitFallback$1(Emit.scala:811); 	at is.hail.expr.ir.Emit.emitI(Emit.scala:2476); 	at is.hail.expr.ir.Emit.emitI(Emit.scala:786); 	at is.hail.expr.ir.Emit.$anonfun$emitI$241(Emit.scala:2386); 	at is.hail.expr.ir.EmitCode$.fromI(Emit.scala:445); 	at is.hail.expr.ir.Emit.$anonfun$emitI$240(Emit.scala:2386); 	at is.hail.expr.ir.EmitCodeBuilder$.scoped(EmitCodeBuilder.scala:18); 	at is.hail.expr.ir.EmitCodeBuil,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12533:5813,adapt,adapted,5813,https://hail.is,https://github.com/hail-is/hail/issues/12533,1,['adapt'],['adapted']
Modifiability,"27745>; ##contig=<ID=chrUn_KI270753v1,length=62944>; ##contig=<ID=chrUn_KI270754v1,length=40191>; ##contig=<ID=chrUn_KI270755v1,length=36723>; ##contig=<ID=chrUn_KI270756v1,length=79590>; ##contig=<ID=chrUn_KI270757v1,length=71251>; ##contig=<ID=chrUn_GL000214v1,length=137718>; ##contig=<ID=chrUn_KI270742v1,length=186739>; ##contig=<ID=chrUn_GL000216v2,length=176608>; ##contig=<ID=chrUn_GL000218v1,length=161147>; ##contig=<ID=chrEBV,length=171823>; ##contig=<ID=hs38d1,length=10560522>; ##bcftools_pluginVersion=1.9+htslib-1.9; ##bcftools_pluginCommand=plugin fill-AN-AC; Date=Sat Dec 29 14:52:44 2018; ##ALT=<ID=NON_REF,Description=""Represents any possible alternative allele at this location"">; ##FORMAT=<ID=MIN_DP,Number=1,Type=Integer,Description=""Minimum DP observed within the GVCF block"">; ##FORMAT=<ID=PGT,Number=1,Type=String,Description=""Physical phasing haplotype information, describing how the alternate alleles are phased in relation to one another"">; ##FORMAT=<ID=PID,Number=1,Type=String,Description=""Physical phasing ID information, where each unique ID within a given sample (but not across samples) connects records within a phasing group"">; ##FORMAT=<ID=RGQ,Number=1,Type=Integer,Description=""Unconditional reference genotype confidence, encoded as a phred quality -10*log10 p(genotype call is wrong)"">; ##FORMAT=<ID=SB,Number=4,Type=Integer,Description=""Per-sample component statistics which comprise the Fisher's Exact Test to detect strand bias."">; ##GATKCommandLine=<ID=GenotypeGVCFs,CommandLine=""GenotypeGVCFs --output 3P5CH.new.vcf --use-new-qual-calculator true --annotation-group StandardAnnotation --annotation-group StandardHCAnnotation --dbsnp /home/fgc3/dbsnp/150/GRCh38/All_20170710.vcf.gz --variant 3P5CH.new.g.vcf.gz --reference /home/fgc3/10x/refdata-GRCh38-2.1.0/fasta/genome.fa --create-output-variant-index false --verbosity ERROR --annotate-with-num-discovered-alleles false --heterozygosity 0.001 --indel-heterozygosity 1.25E-4 --heterozygosity-stdev 0.01 ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8469:21981,plugin,plugin,21981,https://hail.is,https://github.com/hail-is/hail/issues/8469,1,['plugin'],['plugin']
Modifiability,"28a20a</code></a> Add exception chaining (<a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/issues/702"">#702</a>)</li>; <li><a href=""https://github.com/jpadilla/pyjwt/commit/cf545e4bfc087e863b7c7a2a2313d52fe8f107ca""><code>cf545e4</code></a> [pre-commit.ci] pre-commit autoupdate (<a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/issues/700"">#700</a>)</li>; <li><a href=""https://github.com/jpadilla/pyjwt/commit/6223ba13780a941a3f4c9dec62f282bdd9b5afb0""><code>6223ba1</code></a> Bump up version to v2.2.0 (<a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/issues/697"">#697</a>)</li>; <li><a href=""https://github.com/jpadilla/pyjwt/commit/258d7bab0ecb86be91738ac1e23744429280acd1""><code>258d7ba</code></a> Use timezone package as Python 3.5+ is required (<a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/issues/694"">#694</a>)</li>; <li><a href=""https://github.com/jpadilla/pyjwt/commit/a988e1a11e5abb5869dd641f3f4f6a5bb4e70fdf""><code>a988e1a</code></a> Chore: inline Variables that immediately Returned (<a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/issues/690"">#690</a>)</li>; <li><a href=""https://github.com/jpadilla/pyjwt/commit/e7a6c022f3f2e5ba329cbadd242c788014926a7e""><code>e7a6c02</code></a> Add support for Ed448/EdDSA. (<a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/issues/675"">#675</a>)</li>; <li><a href=""https://github.com/jpadilla/pyjwt/commit/19ce9c5ec7947428d35aaffd302eb2629210a697""><code>19ce9c5</code></a> Remove upper bound on cryptography version (<a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/issues/693"">#693</a>)</li>; <li><a href=""https://github.com/jpadilla/pyjwt/commit/9249fc70b5aede04c3dcb86e4b6560ab7e032563""><code>9249fc7</code></a> [pre-commit.ci] pre-commit autoupdate (<a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/issues/689"">#689</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/jpadilla/pyjwt/compare/1.7.1...2.3.0"">comp",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11457:12709,Variab,Variables,12709,https://hail.is,https://github.com/hail-is/hail/pull/11457,1,['Variab'],['Variables']
Modifiability,"2] Added experimental support for reading/writing avar version 2 as specified in; this draft proposal: <a href=""https://github.com/harfbuzz/boring-expansion-spec/blob/main/avar2.md"">https://github.com/harfbuzz/boring-expansion-spec/blob/main/avar2.md</a></li>; <li>[glifLib] Wrap underlying XML library exceptions with GlifLibError when parsing GLIFs,; and also print the name and path of the glyph that fails to be parsed (<a href=""https://redirect.github.com/fonttools/fonttools/issues/3042"">#3042</a>).</li>; <li>[feaLib] Consult avar for normalizing user-space values in ConditionSets and in; VariableScalars (<a href=""https://redirect.github.com/fonttools/fonttools/issues/3042"">#3042</a>, <a href=""https://redirect.github.com/fonttools/fonttools/issues/3043"">#3043</a>).</li>; <li>[ttProgram] Handle string input to Program.fromAssembly() (<a href=""https://redirect.github.com/fonttools/fonttools/issues/3038"">#3038</a>).</li>; <li>[otlLib] Added a config option to emit GPOS 7 lookups, currently disabled by default; because of a macOS bug (<a href=""https://redirect.github.com/fonttools/fonttools/issues/3034"">#3034</a>).</li>; <li>[COLRv1] Added method to automatically compute ClipBoxes (<a href=""https://redirect.github.com/fonttools/fonttools/issues/3027"">#3027</a>).</li>; <li>[ttFont] Fixed getGlyphID to raise KeyError on missing glyphs instead of returning; None. The regression was introduced in v4.27.0 (<a href=""https://redirect.github.com/fonttools/fonttools/issues/3032"">#3032</a>).</li>; <li>[sbix] Fixed UnboundLocalError: cannot access local variable 'rawdata' (<a href=""https://redirect.github.com/fonttools/fonttools/issues/3031"">#3031</a>).</li>; <li>[varLib] When building VF, do not overwrite a pre-existing <code>STAT</code> table that was built; with feaLib from FEA feature file. Also, added support for building multiple VFs; defined in Designspace v5 from <code>fonttools varLib</code> script (<a href=""https://redirect.github.com/fonttools/fonttools/issues/3024"">#30",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12910:12258,config,config,12258,https://hail.is,https://github.com/hail-is/hail/pull/12910,1,['config'],['config']
Modifiability,"3/userFiles-33b96853-73f9-423a-ac6a-bcdb9106012a/fetchFileTemp414690014855588879.tmp; 2018-10-09 15:04:36 Executor: INFO: Adding file:/private/var/folders/w4/9k0my8pd6113d61pq05fvqlr0000gn/T/spark-4d23a45e-e197-4f14-ac11-3973337df8a3/userFiles-33b96853-73f9-423a-ac6a-bcdb9106012a/sparklyr-2.2-2.11.jar to class loader; 2018-10-09 15:04:36 CodeGenerator: INFO: Code generated in 140.241861 ms; 2018-10-09 15:04:36 Executor: INFO: Finished task 0.0 in stage 0.0 (TID 0). 1015 bytes result sent to driver; 2018-10-09 15:04:36 TaskSetManager: INFO: Finished task 0.0 in stage 0.0 (TID 0) in 395 ms on localhost (executor driver) (1/1); 2018-10-09 15:04:36 TaskSchedulerImpl: INFO: Removed TaskSet 0.0, whose tasks have all completed, from pool ; 2018-10-09 15:04:36 DAGScheduler: INFO: ResultStage 0 (collect at utils.scala:44) finished in 0.412 s; 2018-10-09 15:04:36 DAGScheduler: INFO: Job 0 finished: collect at utils.scala:44, took 0.679005 s; 2018-10-09 15:04:36 SparkSession$Builder: WARN: Using an existing SparkSession; some configuration may not take effect.; 2018-10-09 15:04:36 SparkSqlParser: INFO: Parsing command: table8508c46074; 2018-10-09 15:04:36 SparkSession$Builder: WARN: Using an existing SparkSession; some configuration may not take effect.; 2018-10-09 15:04:36 SparkSqlParser: INFO: Parsing command: CACHE TABLE `table8508c46074`; 2018-10-09 15:04:36 SparkSqlParser: INFO: Parsing command: `table8508c46074`; 2018-10-09 15:04:37 CodeGenerator: INFO: Code generated in 15.850234 ms; 2018-10-09 15:04:37 CodeGenerator: INFO: Code generated in 9.347112 ms; 2018-10-09 15:04:37 SparkContext: INFO: Starting job: sql at NativeMethodAccessorImpl.java:0; 2018-10-09 15:04:37 DAGScheduler: INFO: Registering RDD 12 (sql at NativeMethodAccessorImpl.java:0); 2018-10-09 15:04:37 DAGScheduler: INFO: Got job 1 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions; 2018-10-09 15:04:37 DAGScheduler: INFO: Final stage: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0); 201",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4513:17991,config,configuration,17991,https://hail.is,https://github.com/hail-is/hail/issues/4513,1,['config'],['configuration']
Modifiability,"30. ### Relevant log output. ```shell; FatalError: HailException: VEP command '/vep --format vcf --json --everything --allele_number --no_stats --cache --offline --minimal --assembly GRCh38 --fasta /opt/vep/.vep/homo_sapiens/95_GRCh38/Homo_sapiens.GRCh38.dna.toplevel.fa.gz --plugin LoF,loftee_path:/opt/vep/Plugins/,gerp_bigwig:/opt/vep/.vep/gerp_conservation_scores.homo_sapiens.GRCh38.bw,human_ancestor_fa:/opt/vep/.vep/human_ancestor.fa.gz,conservation_file:/opt/vep/.vep/loftee.sql --dir_plugins /opt/vep/Plugins/ -o STDOUT' failed with non-zero exit status 2; VEP Error output:; Smartmatch is experimental at /opt/vep/Plugins/de_novo_donor.pl line 175.; Smartmatch is experimental at /opt/vep/Plugins/de_novo_donor.pl line 214.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 191.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 194.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 238.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 241.; DBI connect('dbname=/opt/vep/.vep/loftee.sql','',...) failed: unable to open database file at /opt/vep/Plugins/LoF.pm line 126. -------------------- EXCEPTION --------------------; MSG: ERROR: No cache found for homo_sapiens, version 95. STACK Bio::EnsEMBL::VEP::CacheDir::dir /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/CacheDir.pm:328; STACK Bio::EnsEMBL::VEP::CacheDir::init /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/CacheDir.pm:227; STACK Bio::EnsEMBL::VEP::CacheDir::new /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/CacheDir.pm:111; STACK Bio::EnsEMBL::VEP::AnnotationSourceAdaptor::get_all_from_cache /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/AnnotationSourceAdaptor.pm:115; STACK Bio::EnsEMBL::VEP::AnnotationSourceAdaptor::get_all /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/AnnotationSourceAdaptor.pm:91; STACK Bio::EnsEMBL::VEP::BaseRunner::get_all_AnnotationSources /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14513:1965,Plugin,Plugins,1965,https://hail.is,https://github.com/hail-is/hail/issues/14513,1,['Plugin'],['Plugins']
Modifiability,"4 (Krishnan Mahadevan); 7.6.0; Fixed: GITHUB-2741: Show fully qualified name of the test instead of just the function name for better readability of test output.(Krishnan Mahadevan); Fixed: GITHUB-2725: Honour custom attribute values in TestNG default reports (Krishnan Mahadevan); Fixed: GITHUB-2726: <a href=""https://github.com/AfterClass""><code>@​AfterClass</code></a> config method is executed for EACH <a href=""https://github.com/Test""><code>@​Test</code></a> method when parallel == methods (Krishnan Mahadevan); Fixed: GITHUB-2752: TestListener is being lost when implenting both IClassListener and ITestListener (Krishnan Mahadevan); New: GITHUB-2724: DataProvider: possibility to unload dataprovider class, when done with it (Dzmitry Sankouski); Fixed: GITHUB-217: Configure TestNG to fail when there's a failure in data provider (Krishnan Mahadevan); Fixed: GITHUB-2743: SuiteRunner could not be initial by default Configuration (Nan Liang); Fixed: GITHUB-2729: beforeConfiguration() listener method should be invoked for skipped configurations as well(Nan Liang); Fixed: assertEqualsNoOrder for Collection and Iterators size check was missing (Adam Kaczmarek); Fixed: GITHUB-2709: Testnames not working together with suites in suite (Martin Aldrin); Fixed: GITHUB-2704: IHookable and IConfigurable callback discrepancy (Krishnan Mahadevan); Fixed: GITHUB-2637: Upgrade to JDK11 as the minimum JDK requirements (Krishnan Mahadevan); Fixed: GITHUB-2734: Keep the initial order of listeners (Andrei Solntsev); Fixed: GITHUB-2359: Testng <a href=""https://github.com/BeforeGroups""><code>@​BeforeGroups</code></a> is running in parallel with testcases in the group (Anton Velma); Fixed: Possible StringIndexOutOfBoundsException in XmlReporter (Anton Velma); Fixed: GITHUB-2754: <a href=""https://github.com/AfterGroups""><code>@​AfterGroups</code></a> is executed for each &quot;finished&quot; group when it has multiple groups defined (Anton Velma)</p>; <p>7.5; Fixed: GITHUB-2701: Bump gradle ve",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12665:13217,Config,Configure,13217,https://hail.is,https://github.com/hail-is/hail/pull/12665,3,"['Config', 'config']","['Configuration', 'Configure', 'configurations']"
Modifiability,4); E 	at scala.collection.IterableLike.foreach$(IterableLike.scala:73); E 	at scala.collection.AbstractIterable.foreach(Iterable.scala:56); E 	at is.hail.utils.package$.runAll(package.scala:1038); E 	at is.hail.utils.package$.$anonfun$runAllKeepFirstError$3(package.scala:1054); E 	at is.hail.backend.local.LocalBackend.parallelizeAndComputeWithIndex(LocalBackend.scala:146); E 	at is.hail.backend.BackendUtils.collectDArray(BackendUtils.scala:85); E 	at __C22901Compiled.__m23019split_CollectDistributedArray_region3_27(Emit.scala); E 	at __C22901Compiled.__m23019split_CollectDistributedArray(Emit.scala); E 	at __C22901Compiled.__m22905begin_group_0_region15_103(Emit.scala); E 	at __C22901Compiled.__m22905begin_group_0(Emit.scala); E 	at __C22901Compiled.__m22903split_Block(Emit.scala); E 	at __C22901Compiled.apply(Emit.scala); E 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3(LocalBackend.scala:186); E 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$3$adapted(LocalBackend.scala:186); E 	at is.hail.backend.ExecuteContext.$anonfun$scopedExecution$1(ExecuteContext.scala:144); E 	at is.hail.utils.package$.using(package.scala:673); E 	at is.hail.backend.ExecuteContext.scopedExecution(ExecuteContext.scala:144); E 	at is.hail.backend.local.LocalBackend.$anonfun$_jvmLowerAndExecute$2(LocalBackend.scala:186); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); E 	at is.hail.backend.local.LocalBackend._jvmLowerAndExecute(LocalBackend.scala:186); E 	at is.hail.backend.local.LocalBackend._execute(LocalBackend.scala:212); E 	at is.hail.backend.local.LocalBackend.$anonfun$execute$2(LocalBackend.scala:277); E 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:84); E 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1(LocalBackend.scala:272); E 	at is.hail.backend.local.LocalBackend.$anonfun$execute$1$adapted(LocalBackend.scala:271); E 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:78); E,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14705:5885,adapt,adapted,5885,https://hail.is,https://github.com/hail-is/hail/issues/14705,1,['adapt'],['adapted']
Modifiability,"45404,; ""finish_time"": 1586188245457,; ""duration"": 53; },; ""runtime"": {; ""start_time"": 1586188245458,; ""finish_time"": 1586189446263,; ""duration"": 1200805; },; ""starting"": {; ""start_time"": 1586188245458,; ""finish_time"": 1586188246261,; ""duration"": 803; },; ""running"": {; ""start_time"": 1586188246262,; ""finish_time"": 1586189446263,; ""duration"": 1200001; },; ""uploading_log"": {; ""start_time"": 1586189446266,; ""finish_time"": 1586189446350,; ""duration"": 84; },; ""deleting"": {; ""start_time"": 1586189446351,; ""finish_time"": 1586189456802,; ""duration"": 10451; }; },; ""error"": ""Traceback (most recent call last):\n File \""/usr/local/lib/python3.6/site-packages/batch/worker.py\"", line 387, in run\n raise JobTimeoutError(f'timed out after {self.timeout}s')\nJobTimeoutError: timed out after 1200s\n"",; ""container_status"": {; ""state"": ""running"",; ""started_at"": ""2020-04-06T15:50:46.250931386Z"",; ""finished_at"": ""0001-01-01T00:00:00Z"",; ""out_of_memory"": false,; ""exit_code"": 0; }; }; },; ""start_time"": 1586188245458,; ""end_time"": 1586189446263; },; ""spec"": {; ""command"": [; ""bash"",; ""-c"",; ""export HAIL_DEPLOY_CONFIG_FILE=/deploy-config/deploy-config.json\nexport SCRATCH=gs://hail-test-dmk9z/o1111h6zxn1p/pipeline\npython3 -m pytest --log-cli-level=INFO -s -vv --instafail /io/test/""; ],; ""image"": ""gcr.io/hail-vdc/ci-intermediate:q7503hc818u5"",; ""job_id"": 65,; ""mount_docker_socket"": false,; ""secrets"": [; {; ""namespace"": ""pr-8470-default-dyvil12gxzyf"",; ""name"": ""gce-deploy-config"",; ""mount_path"": ""/deploy-config""; },; {; ""namespace"": ""pr-8470-batch-pods-r3e5lmgvb8dl"",; ""name"": ""test-tokens"",; ""mount_path"": ""/user-tokens""; },; {; ""namespace"": ""batch-pods"",; ""name"": ""ci-gsa-key"",; ""mount_path"": ""/gsa-key"",; ""mount_in_copy"": true; }; ],; ""timeout"": 1200,; ""input_files"": [; {; ""from"": ""gs://hail-ci-bpk3h/build/23dca3776b11f404e2d0a242697d3b5f/repo/pipeline/test"",; ""to"": ""/io/""; }; ],; ""resources"": {; ""cpu"": ""1"",; ""memory"": ""3.75G""; },; ""env"": []; },; ""attributes"": {; ""name"": ""test_pipeline""; }; }; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8473:2654,config,config,2654,https://hail.is,https://github.com/hail-is/hail/issues/8473,4,['config'],['config']
Modifiability,"4e9f4e4b701d7"">Full Changelog</a>)</p>; <h3>Bugs fixed</h3>; <ul>; <li>Fix json_output in kernelspec app <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/921"">#921</a> (<a href=""https://github.com/blink1073""><code>@​blink1073</code></a>)</li>; </ul>; <h3>Contributors to this release</h3>; <p>(<a href=""https://github.com/jupyter/jupyter_client/graphs/contributors?from=2023-01-26&amp;to=2023-01-26&amp;type=c"">GitHub contributors page for this release</a>)</p>; <p><a href=""https://github.com/search?q=repo%3Ajupyter%2Fjupyter_client+involves%3Ablink1073+updated%3A2023-01-26..2023-01-26&amp;type=Issues""><code>@​blink1073</code></a></p>; <h2>v8.0.0</h2>; <h2>8.0.0</h2>; <p>(<a href=""https://github.com/jupyter/jupyter_client/compare/v7.3.5...760a7835d8b20a9daea3737759b1751d5e55dad8"">Full Changelog</a>)</p>; <p>This release is primarily focused on improving <code>asyncio</code> support, while aiming to have minimal API changes.</p>; <h3>Enhancements made</h3>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/jupyter/jupyter_client/blob/main/CHANGELOG.md"">jupyter-client's changelog</a>.</em></p>; <blockquote>; <h2>8.0.2</h2>; <p>(<a href=""https://github.com/jupyter/jupyter_client/compare/v8.0.1...717d36edcd9ce595f727d8b5a27e270c2a6e2c46"">Full Changelog</a>)</p>; <h3>Bugs fixed</h3>; <ul>; <li>Add papermill downstream check and fix kernel client replies <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/925"">#925</a> (<a href=""https://github.com/blink1073""><code>@​blink1073</code></a>)</li>; </ul>; <h3>Maintenance and upkeep improvements</h3>; <ul>; <li>Adopt more ruff rules <a href=""https://github-redirect.dependabot.com/jupyter/jupyter_client/pull/924"">#924</a> (<a href=""https://github.com/blink1073""><code>@​blink1073</code></a>)</li>; <li>Prefer print in kernelspecapp <a href=""https://github-redirect.depen",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12656:2648,Enhance,Enhancements,2648,https://hail.is,https://github.com/hail-is/hail/pull/12656,1,['Enhance'],['Enhancements']
Modifiability,"5c94c2a</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/sass/libsass-python/issues/344"">#344</a> from sass/3_6_5</li>; <li><a href=""https://github.com/sass/libsass-python/commit/ad69f6e023a6d8fdde4428b7a497b60fb5515215""><code>ad69f6e</code></a> update libsass to 3.6.5</li>; <li><a href=""https://github.com/sass/libsass-python/commit/38735e2fdc30ecb21f6eebb253c1b7a9a45dc757""><code>38735e2</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/sass/libsass-python/issues/343"">#343</a> from sass/pre-commit-ci-update-config</li>; <li><a href=""https://github.com/sass/libsass-python/commit/7f01591fdbca66375a61d70e505a286550a1c1b1""><code>7f01591</code></a> [pre-commit.ci] pre-commit autoupdate</li>; <li><a href=""https://github.com/sass/libsass-python/commit/814d42df9787494f01474116940782ab67da083f""><code>814d42d</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/sass/libsass-python/issues/342"">#342</a> from sass/pre-commit-ci-update-config</li>; <li><a href=""https://github.com/sass/libsass-python/commit/b08f9ca307ce64867070a3ca5ee5f1a6c5742069""><code>b08f9ca</code></a> [pre-commit.ci] pre-commit autoupdate</li>; <li><a href=""https://github.com/sass/libsass-python/commit/89d6a1dda507abde79ff79b3fd95b9d013eaa02d""><code>89d6a1d</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/sass/libsass-python/issues/340"">#340</a> from sass/pre-commit-ci-update-config</li>; <li><a href=""https://github.com/sass/libsass-python/commit/93c70a9a9f350b24af796bb31d81182be4ac4b1f""><code>93c70a9</code></a> [pre-commit.ci] pre-commit autoupdate</li>; <li><a href=""https://github.com/sass/libsass-python/commit/e836a7e7c3778ac34a8bd117c2ce701209097cd5""><code>e836a7e</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/sass/libsass-python/issues/339"">#339</a> from sass/pre-commit-ci-update-config</li>; <li>Additional commits viewable in <a href=""https://github.com/sass/libsas",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11508:4647,config,config,4647,https://hail.is,https://github.com/hail-is/hail/pull/11508,1,['config'],['config']
Modifiability,"6b65269a0af""><code>c0b8b32</code></a> [refactor] Create a file for the BasicErrorChecker in pylint.checker.base</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/3f11fe629a7b89d2a3b92dce09ac5818f3904cee""><code>3f11fe6</code></a> [refactor] Create a package for the NameChecker in pylint.checker.base</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/6940715ba15f81fbd7d9e8685c0a714a8b612f24""><code>6940715</code></a> [refactor] Create a file for the DocstringChecker in pylint.checker.base</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/84d22cf24202bf6006fc179541e1853d145d33e0""><code>84d22cf</code></a> [refactor] Create a file for the PassChecker in pylint.checker.base</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/977b08d160e81aaecebf871d2b8ba2f9a96ef9d6""><code>977b08d</code></a> [refactor] Create files for comparison checker in pylint.checker.base</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/ddfca0ca884d677e4eb0e6f53553b16e7a503157""><code>ddfca0c</code></a> [refactor] Create a file for _BasicChecker in pylint.checkers</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/be4699399904654ef4107a228817b4ef176d8999""><code>be46993</code></a> [refactor] Create a package in order to be able to burst base.py</li>; <li>Additional commits viewable in <a href=""https://github.com/PyCQA/pylint/compare/v2.12.2...v2.13.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pylint&package-manager=pip&previous-version=2.12.2&new-version=2.13.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <det",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11674:5067,refactor,refactor,5067,https://hail.is,https://github.com/hail-is/hail/pull/11674,1,['refactor'],['refactor']
Modifiability,"6ce8ea78e2""><code>1e7d3fa</code></a> [refactor] Create a file for the BasicChecker in pylint.checker.base</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/c0b8b32592f8d5d34ff37250adbda6b65269a0af""><code>c0b8b32</code></a> [refactor] Create a file for the BasicErrorChecker in pylint.checker.base</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/3f11fe629a7b89d2a3b92dce09ac5818f3904cee""><code>3f11fe6</code></a> [refactor] Create a package for the NameChecker in pylint.checker.base</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/6940715ba15f81fbd7d9e8685c0a714a8b612f24""><code>6940715</code></a> [refactor] Create a file for the DocstringChecker in pylint.checker.base</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/84d22cf24202bf6006fc179541e1853d145d33e0""><code>84d22cf</code></a> [refactor] Create a file for the PassChecker in pylint.checker.base</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/977b08d160e81aaecebf871d2b8ba2f9a96ef9d6""><code>977b08d</code></a> [refactor] Create files for comparison checker in pylint.checker.base</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/ddfca0ca884d677e4eb0e6f53553b16e7a503157""><code>ddfca0c</code></a> [refactor] Create a file for _BasicChecker in pylint.checkers</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/be4699399904654ef4107a228817b4ef176d8999""><code>be46993</code></a> [refactor] Create a package in order to be able to burst base.py</li>; <li>Additional commits viewable in <a href=""https://github.com/PyCQA/pylint/compare/v2.12.2...v2.13.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pylint&package-manager=pip&previous-version=2.12.2&new-version=2.13.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as lo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11674:4872,refactor,refactor,4872,https://hail.is,https://github.com/hail-is/hail/pull/11674,1,['refactor'],['refactor']
Modifiability,6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.utils.package$.using(package.scala:637) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.annotations.RegionPool.scopedRegion(RegionPool.scala:162) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.BackendUtils.$anonfun$collectDArray$15(BackendUtils.scala:90) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$12(Worker.scala:167) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.15.jar:?]; 	at is.hail.services.package$.retryTransientErrors(package.scala:182) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$11(Worker.scala:166) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$11$adapted(Worker.scala:164) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.utils.package$.using(package.scala:637) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.main(Worker.scala:164) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Main$.main(Main.scala:14) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Main.main(Main.scala) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	... 12 more; ```. ### Version. 0.2.124. ### Relevant log output. _No response_,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13697:33205,adapt,adapted,33205,https://hail.is,https://github.com/hail-is/hail/issues/13697,1,['adapt'],['adapted']
Modifiability,"7</a> from asottile/setup-cfg-fmt</li>; <li><a href=""https://github.com/PyCQA/flake8/commit/960cf8cf2044359d5fbd3454a2a9a1d7a0586594""><code>960cf8c</code></a> rerun setup-cfg-fmt (and restore comments)</li>; <li><a href=""https://github.com/PyCQA/flake8/commit/d7baba5f14091e7975d2abb3ba9bf321b5be6102""><code>d7baba5</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pycqa/flake8/issues/1406"">#1406</a> from asottile/update-versions</li>; <li><a href=""https://github.com/PyCQA/flake8/commit/d79021aafc809d999c4cbbc0a513a5ceb473efa2""><code>d79021a</code></a> update dependency versions</li>; <li><a href=""https://github.com/PyCQA/flake8/commit/283f0c81241673221d9628beb11e2d7356826f00""><code>283f0c8</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pycqa/flake8/issues/1404"">#1404</a> from PyCQA/drop-xdg-config</li>; <li><a href=""https://github.com/PyCQA/flake8/commit/807904aebc20814ac595b0004ab526fffb5ef681""><code>807904a</code></a> Drop support for Home and XDG config files</li>; <li>Additional commits viewable in <a href=""https://github.com/pycqa/flake8/compare/3.8.3...4.0.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=flake8&package-manager=pip&previous-version=3.8.3&new-version=4.0.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11456:2065,config,config,2065,https://hail.is,https://github.com/hail-is/hail/pull/11456,2,['config'],['config']
Modifiability,"7c4e8a5c2dec8444df8f480293""><code>afd2399</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pycqa/flake8/issues/1407"">#1407</a> from asottile/setup-cfg-fmt</li>; <li><a href=""https://github.com/PyCQA/flake8/commit/960cf8cf2044359d5fbd3454a2a9a1d7a0586594""><code>960cf8c</code></a> rerun setup-cfg-fmt (and restore comments)</li>; <li><a href=""https://github.com/PyCQA/flake8/commit/d7baba5f14091e7975d2abb3ba9bf321b5be6102""><code>d7baba5</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pycqa/flake8/issues/1406"">#1406</a> from asottile/update-versions</li>; <li><a href=""https://github.com/PyCQA/flake8/commit/d79021aafc809d999c4cbbc0a513a5ceb473efa2""><code>d79021a</code></a> update dependency versions</li>; <li><a href=""https://github.com/PyCQA/flake8/commit/283f0c81241673221d9628beb11e2d7356826f00""><code>283f0c8</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pycqa/flake8/issues/1404"">#1404</a> from PyCQA/drop-xdg-config</li>; <li><a href=""https://github.com/PyCQA/flake8/commit/807904aebc20814ac595b0004ab526fffb5ef681""><code>807904a</code></a> Drop support for Home and XDG config files</li>; <li>Additional commits viewable in <a href=""https://github.com/pycqa/flake8/compare/3.8.3...4.0.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=flake8&package-manager=pip&previous-version=3.8.3&new-version=4.0.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11456:1903,config,config,1903,https://hail.is,https://github.com/hail-is/hail/pull/11456,2,['config'],['config']
Modifiability,"8); # Java VM: OpenJDK 64-Bit Server VM (25.242-b08 mixed mode linux-amd64 ); # Problematic frame:; # J 8451 C2 is.hail.annotations.Region$.loadBit(JJ)Z (33 bytes) @ 0x00007fa4b25e18cd [0x00007fa4b25e18a0+0x2d]; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /tmp/cac7924b3c14494b9702ac2689c0c52d/hs_err_pid6637.log; ```; with this pipeline:; ```; def normalize_contig(input_contig: hl.expr.StringExpression) -> hl.expr.StringExpression:; return input_contig.replace(""^chr"", """"). def downsample_matrix_table(mt: hl.MatrixTable, n_divisions: int, p_threshold: float) -> hl.Table:; ​ mt = mt.choose_cols(list(range(10))); ​; x = mt.locus.global_position(); y = -hl.log10(mt.Pvalue); ​; downsampled = mt.annotate_cols(; binned=hl.agg.filter(; mt.Pvalue > p_threshold,; hl.agg.downsample(; x,; y,; label=[; normalize_contig(mt.locus.contig),; hl.str(mt.locus.position),; hl.str(mt.Pvalue),; ],; n_divisions=n_divisions; ); ),; unbinned=hl.agg.filter(; mt.Pvalue <= p_threshold,; hl.agg.collect(hl.struct(; pval=mt.Pvalue,; chrom=normalize_contig(mt.locus.contig),; pos=mt.locus.position,; ac=mt.AC,; af=mt.AF,; an=mt.N,; alleles=mt.alleles,; beta=mt.BETA,; consequence=hl.if_else(; hl.is_defined(mt.annotation),; mt.annotation,; ""N/A""; ),; gene_name=mt.gene,; is_binned=False; ); ); ); ); ​; downsampled = downsampled.select_cols(; binned=downsampled.binned.map(; lambda a_bin: hl.struct(; pval=hl.float64(a_bin[2][2]),; chrom=a_bin[2][0],; pos=hl.int32(a_bin[2][1]),; ac=hl.literal(0.0),; af=hl.literal(0.0),; an=hl.literal(0),; alleles=hl.literal(['N', 'A']),; beta=hl.literal(0.0),; consequence=""N/A"",; gene_name=""N/A"",; is_binned=True,; ​; ); ),; unbinned=downsampled.unbinned,; ); ​; downsampled = downsampled.select_cols(; data=downsampled.binned.extend(downsampled.unbinned); ); downsampled = downsampled.cols(); ​; return downsampled; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8240:2240,extend,extend,2240,https://hail.is,https://github.com/hail-is/hail/issues/8240,1,['extend'],['extend']
Modifiability,"81b7711f4672c113636892""><code>e9af7c2</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/flask/issues/4754"">#4754</a> from pallets/werkzeug-version</li>; <li><a href=""https://github.com/pallets/flask/commit/de16718b39e3544688130339a0813997e3790c48""><code>de16718</code></a> require werkzeug &gt;= 2.2.2</li>; <li><a href=""https://github.com/pallets/flask/commit/6ab3cb8d0cb1fa28dd2e0118c07e481720bd684a""><code>6ab3cb8</code></a> fix issue number</li>; <li><a href=""https://github.com/pallets/flask/commit/e3eaafb56e3914676755fce6f67256599fb3fc64""><code>e3eaafb</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/flask/issues/4749"">#4749</a> from pallets/shell-env</li>; <li><a href=""https://github.com/pallets/flask/commit/e3df23374cdb9342a823556170c53c9d987d0d33""><code>e3df233</code></a> remove env from shell banner</li>; <li><a href=""https://github.com/pallets/flask/commit/a0458efef6c8a5669bb6e78044a290bf560f962b""><code>a0458ef</code></a> refactor or remove old docs (<a href=""https://github-redirect.dependabot.com/pallets/flask/issues/4748"">#4748</a>)</li>; <li><a href=""https://github.com/pallets/flask/commit/45b2c99c1f6a884376d54bbb25223edad65596c5""><code>45b2c99</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/pallets/flask/issues/4742"">#4742</a> from pallets/env-default</li>; <li><a href=""https://github.com/pallets/flask/commit/a6a7a57380cd8f7410753c3b819ba6d09198d8c9""><code>a6a7a57</code></a> fix default value of app.env</li>; <li>Additional commits viewable in <a href=""https://github.com/pallets/flask/compare/2.0.3...2.2.2"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=flask&package-manager=pip&previous-version=2.0.3&new-version=2.2.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12206:8867,refactor,refactor,8867,https://hail.is,https://github.com/hail-is/hail/pull/12206,1,['refactor'],['refactor']
Modifiability,"858119s: 200; INFO	2022-03-02 19:06:30,226	main.py	activate_instance_1:237	activating instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q; INFO	2022-03-02 19:06:30,991	base.py	check:335	checking on instance batch-worker-pr-11438-default-g6cibyji6520-highcpu-z0idl, last updated 60.151s ago; INFO	2022-03-02 19:06:31,526	pool.py	schedule_loop_body:371	schedule pool standard: starting; INFO	2022-03-02 19:06:31,583	job.py	schedule_job:443	schedule job (94, 2) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:31,584	job.py	schedule_job:443	schedule job (95, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:31,585	job.py	schedule_job:443	schedule job (93, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:31,586	job.py	schedule_job:443	schedule job (90, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:31,586	job.py	schedule_job:443	schedule job (94, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:31,598	job.py	schedule_job:443	schedule job (97, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:31,656	job.py	schedule_job:443	schedule job (99, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:31,662	job.py	schedule_job:443	schedule job (100, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:31,663	job.py	schedule_job:443	schedule job (98, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:32,455	job.py	schedule_job:443	schedule job (101, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9x",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:1604,config,config,1604,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['config'],['config']
Modifiability,"8pd6113d61pq05fvqlr0000gn/T/spark-02128b51-f37e-4798-84bb-d3e3819e51be/userFiles-7053b92c-9117-46b6-8c52-752fee2701e9/sparklyr-2.2-2.11.jar to class loader; 2018-10-09 14:46:41 CodeGenerator: INFO: Code generated in 142.013327 ms; 2018-10-09 14:46:41 Executor: INFO: Finished task 0.0 in stage 0.0 (TID 0). 972 bytes result sent to driver; 2018-10-09 14:46:41 TaskSetManager: INFO: Finished task 0.0 in stage 0.0 (TID 0) in 406 ms on localhost (executor driver) (1/1); 2018-10-09 14:46:41 TaskSchedulerImpl: INFO: Removed TaskSet 0.0, whose tasks have all completed, from pool ; 2018-10-09 14:46:41 DAGScheduler: INFO: ResultStage 0 (collect at utils.scala:44) finished in 0.420 s; 2018-10-09 14:46:41 DAGScheduler: INFO: Job 0 finished: collect at utils.scala:44, took 0.669318 s; 2018-10-09 14:46:41 SparkSession$Builder: WARN: Using an existing SparkSession; some configuration may not take effect.; 2018-10-09 14:46:41 SparkSqlParser: INFO: Parsing command: table7e606a8b83f4; 2018-10-09 14:46:41 SparkSession$Builder: WARN: Using an existing SparkSession; some configuration may not take effect.; 2018-10-09 14:46:41 SparkSqlParser: INFO: Parsing command: CACHE TABLE `table7e606a8b83f4`; 2018-10-09 14:46:41 SparkSqlParser: INFO: Parsing command: `table7e606a8b83f4`; 2018-10-09 14:46:41 CodeGenerator: INFO: Code generated in 17.141549 ms; 2018-10-09 14:46:41 CodeGenerator: INFO: Code generated in 10.417049 ms; 2018-10-09 14:46:41 SparkContext: INFO: Starting job: sql at NativeMethodAccessorImpl.java:0; 2018-10-09 14:46:41 DAGScheduler: INFO: Registering RDD 12 (sql at NativeMethodAccessorImpl.java:0); 2018-10-09 14:46:41 DAGScheduler: INFO: Got job 1 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions; 2018-10-09 14:46:41 DAGScheduler: INFO: Final stage: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0); 2018-10-09 14:46:41 DAGScheduler: INFO: Parents of final stage: List(ShuffleMapStage 1); 2018-10-09 14:46:41 DAGScheduler: INFO: Missing parents: List(ShuffleMa",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4513:35705,config,configuration,35705,https://hail.is,https://github.com/hail-is/hail/issues/4513,1,['config'],['configuration']
Modifiability,"8pd6113d61pq05fvqlr0000gn/T/spark-4d23a45e-e197-4f14-ac11-3973337df8a3/userFiles-33b96853-73f9-423a-ac6a-bcdb9106012a/sparklyr-2.2-2.11.jar to class loader; 2018-10-09 15:04:36 CodeGenerator: INFO: Code generated in 140.241861 ms; 2018-10-09 15:04:36 Executor: INFO: Finished task 0.0 in stage 0.0 (TID 0). 1015 bytes result sent to driver; 2018-10-09 15:04:36 TaskSetManager: INFO: Finished task 0.0 in stage 0.0 (TID 0) in 395 ms on localhost (executor driver) (1/1); 2018-10-09 15:04:36 TaskSchedulerImpl: INFO: Removed TaskSet 0.0, whose tasks have all completed, from pool ; 2018-10-09 15:04:36 DAGScheduler: INFO: ResultStage 0 (collect at utils.scala:44) finished in 0.412 s; 2018-10-09 15:04:36 DAGScheduler: INFO: Job 0 finished: collect at utils.scala:44, took 0.679005 s; 2018-10-09 15:04:36 SparkSession$Builder: WARN: Using an existing SparkSession; some configuration may not take effect.; 2018-10-09 15:04:36 SparkSqlParser: INFO: Parsing command: table8508c46074; 2018-10-09 15:04:36 SparkSession$Builder: WARN: Using an existing SparkSession; some configuration may not take effect.; 2018-10-09 15:04:36 SparkSqlParser: INFO: Parsing command: CACHE TABLE `table8508c46074`; 2018-10-09 15:04:36 SparkSqlParser: INFO: Parsing command: `table8508c46074`; 2018-10-09 15:04:37 CodeGenerator: INFO: Code generated in 15.850234 ms; 2018-10-09 15:04:37 CodeGenerator: INFO: Code generated in 9.347112 ms; 2018-10-09 15:04:37 SparkContext: INFO: Starting job: sql at NativeMethodAccessorImpl.java:0; 2018-10-09 15:04:37 DAGScheduler: INFO: Registering RDD 12 (sql at NativeMethodAccessorImpl.java:0); 2018-10-09 15:04:37 DAGScheduler: INFO: Got job 1 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions; 2018-10-09 15:04:37 DAGScheduler: INFO: Final stage: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0); 2018-10-09 15:04:37 DAGScheduler: INFO: Parents of final stage: List(ShuffleMapStage 1); 2018-10-09 15:04:37 DAGScheduler: INFO: Missing parents: List(ShuffleMapStage",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4513:18188,config,configuration,18188,https://hail.is,https://github.com/hail-is/hail/issues/4513,1,['config'],['configuration']
Modifiability,"964fcc98db1c5025e05d6495f""><code>9ea3530</code></a> fix(deps): require protobuf &gt;=3.19.5 (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-common-protos/issues/141"">#141</a>)</li>; <li><a href=""https://github.com/googleapis/python-api-common-protos/commit/5cf4e0bbfed23d061600d64099f21fcf92ef0cf2""><code>5cf4e0b</code></a> chore: update dependency protobuf &gt;= 3.20.2 (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-common-protos/issues/138"">#138</a>)</li>; <li><a href=""https://github.com/googleapis/python-api-common-protos/commit/92d9f53f5525ecb9af97c93467a594d6b92095cd""><code>92d9f53</code></a> fix(deps): require protobuf&gt;=3.20.2 (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-common-protos/issues/137"">#137</a>)</li>; <li><a href=""https://github.com/googleapis/python-api-common-protos/commit/db8a75633fd184ebf845ccc707727c419a5de435""><code>db8a756</code></a> chore(python): exclude setup.py in renovate config (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-common-protos/issues/132"">#132</a>)</li>; <li><a href=""https://github.com/googleapis/python-api-common-protos/commit/e32db2497b00e398dadb5ed2bf0c49d8d5acfecd""><code>e32db24</code></a> chore(python): update .kokoro/requirements.txt (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-common-protos/issues/131"">#131</a>)</li>; <li><a href=""https://github.com/googleapis/python-api-common-protos/commit/6026462f3b63b4df442a7f3e9214ee8ebfd7ffdb""><code>6026462</code></a> chore: fix path to requirements.txt in release script [autoapprove] (<a href=""https://github-redirect.dependabot.com/googleapis/python-api-common-protos/issues/130"">#130</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/googleapis/python-api-common-protos/compare/v1.56.4...v1.57.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibil",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12514:6752,config,config,6752,https://hail.is,https://github.com/hail-is/hail/pull/12514,1,['config'],['config']
Modifiability,"9:04 dk-m python[5149]: /etc/jupyter/jupyter_notebook_config.json; Mar 01 19:59:04 dk-m python[5149]: [D 19:59:04.803 NotebookApp] Paths used for configuration of jupyter_notebook_config:; Mar 01 19:59:04 dk-m python[5149]: /usr/local/etc/jupyter/jupyter_notebook_config.json; Mar 01 19:59:04 dk-m python[5149]: [D 19:59:04.804 NotebookApp] Paths used for configuration of jupyter_notebook_config:; Mar 01 19:59:04 dk-m python[5149]: /opt/conda/etc/jupyter/jupyter_notebook_config.json; Mar 01 19:59:04 dk-m python[5149]: [D 19:59:04.804 NotebookApp] Paths used for configuration of jupyter_notebook_config:; Mar 01 19:59:04 dk-m python[5149]: /root/.jupyter/jupyter_notebook_config.json; Mar 01 19:59:04 dk-m python[5149]: [W 19:59:04.904 NotebookApp] Error loading server extension jupyter_spark; Mar 01 19:59:04 dk-m python[5149]: Traceback (most recent call last):; Mar 01 19:59:04 dk-m python[5149]: File ""/opt/conda/lib/python3.6/site-packages/notebook/notebookapp.py"", line 1575, in init_server_extensions; Mar 01 19:59:04 dk-m python[5149]: func(self); Mar 01 19:59:04 dk-m python[5149]: File ""/opt/conda/lib/python3.6/site-packages/jupyter_spark/__init__.py"", line 30, in load_jupyter_server_extension; Mar 01 19:59:04 dk-m python[5149]: from .handlers import SparkHandler; Mar 01 19:59:04 dk-m python[5149]: File ""/opt/conda/lib/python3.6/site-packages/jupyter_spark/handlers.py"", line 8, in <module>; Mar 01 19:59:04 dk-m python[5149]: class SparkHandler(IPythonHandler):; Mar 01 19:59:04 dk-m python[5149]: File ""/opt/conda/lib/python3.6/site-packages/jupyter_spark/handlers.py"", line 13, in SparkHandler; Mar 01 19:59:04 dk-m python[5149]: @tornado.web.asynchronous; Mar 01 19:59:04 dk-m python[5149]: AttributeError: module 'tornado.web' has no attribute 'asynchronous'; ```. It appears that Jupyter starts even though one of its plugins fail. This sucks, since Jupyter doesn't actually seem to work if jupyter_spark fails. This happens even if the evaluated cell contains only `3 + 3`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5505:2873,plugin,plugins,2873,https://hail.is,https://github.com/hail-is/hail/issues/5505,1,['plugin'],['plugins']
Modifiability,": / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ff2413b8470>: Failed to establish a new connection: [Errno 113] No route to host',))\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1341, in polling_event_loop\n await refresh_k8s_state()\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1332, in refresh_k8s_state\n await refresh_k8s_pods()\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1296, in refresh_k8s_pods\n await update_job_with_pod(job, pod)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 1229, in update_job_with_pod\n await job.mark_complete(success=True, pod=pod)\n File \""/usr/local/lib/python3.6/dist-packages/batch/batch.py\"", line 594, in mark_complete\n requests.post(f'http://{pod.status.pod_ip}:5001/')\n File \""/usr/local/lib/python3.6/dist-packages/requests/api.py\"", line 116, in post\n return request('post', url, data=data, json=json, **kwargs)\n File \""/usr/local/lib/python3.6/dist-packages/requests/api.py\"", line 60, in request\n return session.request(method=method, url=url, **kwargs)\n File \""/usr/local/lib/python3.6/dist-packages/requests/sessions.py\"", line 533, in request\n resp = self.send(prep, **send_kwargs)\n File \""/usr/local/lib/python3.6/dist-packages/requests/sessions.py\"", line 646, in send\n r = adapter.send(request, **kwargs)\n File \""/usr/local/lib/python3.6/dist-packages/requests/adapters.py\"", line 516, in send\n raise ConnectionError(e, request=request)\nrequests.exceptions.ConnectionError: HTTPConnectionPool(host='10.32.16.16', port=5001): Max retries exceeded with url: / (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7ff2413b8470>: Failed to establish a new connection: [Errno 113] No route to host',))""}; ```. I think this was probably already reaped by the other loop.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6754:4427,adapt,adapter,4427,https://hail.is,https://github.com/hail-is/hail/issues/6754,2,['adapt'],"['adapter', 'adapters']"
Modifiability,": INFO: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 4726 bytes); 2018-10-09 14:46:42 Executor: INFO: Running task 0.0 in stage 2.0 (TID 2); 2018-10-09 14:46:42 ShuffleBlockFetcherIterator: INFO: Getting 1 non-empty blocks out of 1 blocks; 2018-10-09 14:46:42 ShuffleBlockFetcherIterator: INFO: Started 0 remote fetches in 4 ms; 2018-10-09 14:46:42 Executor: INFO: Finished task 0.0 in stage 2.0 (TID 2). 1539 bytes result sent to driver; 2018-10-09 14:46:42 TaskSetManager: INFO: Finished task 0.0 in stage 2.0 (TID 2) in 30 ms on localhost (executor driver) (1/1); 2018-10-09 14:46:42 TaskSchedulerImpl: INFO: Removed TaskSet 2.0, whose tasks have all completed, from pool ; 2018-10-09 14:46:42 DAGScheduler: INFO: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0) finished in 0.031 s; 2018-10-09 14:46:42 DAGScheduler: INFO: Job 1 finished: sql at NativeMethodAccessorImpl.java:0, took 0.301773 s; 2018-10-09 14:46:42 SparkSession$Builder: WARN: Using an existing SparkSession; some configuration may not take effect.; 2018-10-09 14:46:42 SparkSqlParser: INFO: Parsing command: SELECT count(*) FROM `table7e606a8b83f4`; 2018-10-09 14:46:42 SparkContext: INFO: Starting job: collect at utils.scala:197; 2018-10-09 14:46:42 DAGScheduler: INFO: Registering RDD 18 (collect at utils.scala:197); 2018-10-09 14:46:42 DAGScheduler: INFO: Got job 2 (collect at utils.scala:197) with 1 output partitions; 2018-10-09 14:46:42 DAGScheduler: INFO: Final stage: ResultStage 4 (collect at utils.scala:197); 2018-10-09 14:46:42 DAGScheduler: INFO: Parents of final stage: List(ShuffleMapStage 3); 2018-10-09 14:46:42 DAGScheduler: INFO: Missing parents: List(ShuffleMapStage 3); 2018-10-09 14:46:42 DAGScheduler: INFO: Submitting ShuffleMapStage 3 (MapPartitionsRDD[18] at collect at utils.scala:197), which has no missing parents; 2018-10-09 14:46:42 MemoryStore: INFO: Block broadcast_3 stored as values in memory (estimated size 18.7 KB, free 366.2 MB); 2018-10-09 ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4513:41334,config,configuration,41334,https://hail.is,https://github.com/hail-is/hail/issues/4513,1,['config'],['configuration']
Modifiability,": INFO: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, ANY, 4726 bytes); 2018-10-09 15:04:37 Executor: INFO: Running task 0.0 in stage 2.0 (TID 2); 2018-10-09 15:04:37 ShuffleBlockFetcherIterator: INFO: Getting 1 non-empty blocks out of 1 blocks; 2018-10-09 15:04:37 ShuffleBlockFetcherIterator: INFO: Started 0 remote fetches in 4 ms; 2018-10-09 15:04:37 Executor: INFO: Finished task 0.0 in stage 2.0 (TID 2). 1539 bytes result sent to driver; 2018-10-09 15:04:37 TaskSetManager: INFO: Finished task 0.0 in stage 2.0 (TID 2) in 31 ms on localhost (executor driver) (1/1); 2018-10-09 15:04:37 TaskSchedulerImpl: INFO: Removed TaskSet 2.0, whose tasks have all completed, from pool ; 2018-10-09 15:04:37 DAGScheduler: INFO: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0) finished in 0.032 s; 2018-10-09 15:04:37 DAGScheduler: INFO: Job 1 finished: sql at NativeMethodAccessorImpl.java:0, took 0.308114 s; 2018-10-09 15:04:37 SparkSession$Builder: WARN: Using an existing SparkSession; some configuration may not take effect.; 2018-10-09 15:04:37 SparkSqlParser: INFO: Parsing command: SELECT count(*) FROM `table8508c46074`; 2018-10-09 15:04:37 SparkContext: INFO: Starting job: collect at utils.scala:197; 2018-10-09 15:04:37 DAGScheduler: INFO: Registering RDD 18 (collect at utils.scala:197); 2018-10-09 15:04:37 DAGScheduler: INFO: Got job 2 (collect at utils.scala:197) with 1 output partitions; 2018-10-09 15:04:37 DAGScheduler: INFO: Final stage: ResultStage 4 (collect at utils.scala:197); 2018-10-09 15:04:37 DAGScheduler: INFO: Parents of final stage: List(ShuffleMapStage 3); 2018-10-09 15:04:37 DAGScheduler: INFO: Missing parents: List(ShuffleMapStage 3); 2018-10-09 15:04:37 DAGScheduler: INFO: Submitting ShuffleMapStage 3 (MapPartitionsRDD[18] at collect at utils.scala:197), which has no missing parents; 2018-10-09 15:04:37 MemoryStore: INFO: Block broadcast_3 stored as values in memory (estimated size 18.7 KB, free 366.2 MB); 2018-10-09 15",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4513:23813,config,configuration,23813,https://hail.is,https://github.com/hail-is/hail/issues/4513,1,['config'],['configuration']
Modifiability,"://github-redirect.dependabot.com/kubernetes/kubernetes/pull/105916"">kubernetes/kubernetes#105916</a>, <a href=""https://github.com/kevindelgado""><code>@​kevindelgado</code></a>)</li>; <li>Promote <code>IPv6DualStack</code> feature to stable.; Controller Manager flags for the node IPAM controller have slightly changed:; <ol>; <li>When configuring a dual-stack cluster, the user must specify both <code>--node-cidr-mask-size-ipv4</code> and <code>--node-cidr-mask-size-ipv6</code> to set the per-node IP mask sizes, instead of the previous <code>--node-cidr-mask-size</code> flag.</li>; <li>The <code>--node-cidr-mask-size</code> flag is mutually exclusive with <code>--node-cidr-mask-size-ipv4</code> and <code>--node-cidr-mask-size-ipv6</code>.</li>; <li>Single-stack clusters do not need to change, but may choose to use the more specific flags. Users can use either the older <code>--node-cidr-mask-size</code> flag or one of the newer <code>--node-cidr-mask-size-ipv4</code> or <code>--node-cidr-mask-size-ipv6</code> flags to configure the per-node IP mask size, provided that the flag's IP family matches the cluster's IP family (--cluster-cidr). (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/104691"">kubernetes/kubernetes#104691</a>, <a href=""https://github.com/khenidak""><code>@​khenidak</code></a>)</li>; </ol>; </li>; <li>Remove <code>NodeLease</code> feature gate that was graduated and locked to stable in 1.17 release. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/105222"">kubernetes/kubernetes#105222</a>, <a href=""https://github.com/cyclinder""><code>@​cyclinder</code></a>)</li>; <li>Removed deprecated <code>--seccomp-profile-root</code>/<code>seccompProfileRoot</code> config. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/103941"">kubernetes/kubernetes#103941</a>, <a href=""https://github.com/saschagrunert""><code>@​saschagrunert</code></a>)</li>; <li>Since golang 1.17 both net.ParseIP and ne",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11957:11229,config,configure,11229,https://hail.is,https://github.com/hail-is/hail/pull/11957,1,['config'],['configure']
Modifiability,"://github-redirect.dependabot.com/sass/libsass-python/issues/342"">#342</a> from sass/pre-commit-ci-update-config</li>; <li><a href=""https://github.com/sass/libsass-python/commit/b08f9ca307ce64867070a3ca5ee5f1a6c5742069""><code>b08f9ca</code></a> [pre-commit.ci] pre-commit autoupdate</li>; <li><a href=""https://github.com/sass/libsass-python/commit/89d6a1dda507abde79ff79b3fd95b9d013eaa02d""><code>89d6a1d</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/sass/libsass-python/issues/340"">#340</a> from sass/pre-commit-ci-update-config</li>; <li><a href=""https://github.com/sass/libsass-python/commit/93c70a9a9f350b24af796bb31d81182be4ac4b1f""><code>93c70a9</code></a> [pre-commit.ci] pre-commit autoupdate</li>; <li><a href=""https://github.com/sass/libsass-python/commit/e836a7e7c3778ac34a8bd117c2ce701209097cd5""><code>e836a7e</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/sass/libsass-python/issues/339"">#339</a> from sass/pre-commit-ci-update-config</li>; <li>Additional commits viewable in <a href=""https://github.com/sass/libsass-python/compare/0.19.2...0.21.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=libsass&package-manager=pip&previous-version=0.19.2&new-version=0.21.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have bee",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11508:5543,config,config,5543,https://hail.is,https://github.com/hail-is/hail/pull/11508,1,['config'],['config']
Modifiability,":06:31,526	pool.py	schedule_loop_body:371	schedule pool standard: starting; INFO	2022-03-02 19:06:31,583	job.py	schedule_job:443	schedule job (94, 2) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:31,584	job.py	schedule_job:443	schedule job (95, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:31,585	job.py	schedule_job:443	schedule job (93, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:31,586	job.py	schedule_job:443	schedule job (90, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:31,586	job.py	schedule_job:443	schedule job (94, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:31,598	job.py	schedule_job:443	schedule job (97, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:31,656	job.py	schedule_job:443	schedule job (99, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:31,662	job.py	schedule_job:443	schedule job (100, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:31,663	job.py	schedule_job:443	schedule job (98, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:32,455	job.py	schedule_job:443	schedule job (101, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:32,455	job.py	schedule_job:443	schedule job (102, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:33,456	hail_logging.py	log:40	https POST /pr-11438-default-g6cibyji6520/batch-driver/api/v1alpha/instances/activate d",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:1928,config,config,1928,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['config'],['config']
Modifiability,":1128); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); 	at java.base/java.lang.Thread.run(Thread.java:829). Hail version: 0.2.130-bea04d9c79b5; Error summary: HailException: VEP command '/vep --format vcf --json --everything --allele_number --no_stats --cache --offline --minimal --assembly GRCh38 --fasta /opt/vep/.vep/homo_sapiens/95_GRCh38/Homo_sapiens.GRCh38.dna.toplevel.fa.gz --plugin LoF,loftee_path:/opt/vep/Plugins/,gerp_bigwig:/opt/vep/.vep/gerp_conservation_scores.homo_sapiens.GRCh38.bw,human_ancestor_fa:/opt/vep/.vep/human_ancestor.fa.gz,conservation_file:/opt/vep/.vep/loftee.sql --dir_plugins /opt/vep/Plugins/ -o STDOUT' failed with non-zero exit status 2; VEP Error output:; Smartmatch is experimental at /opt/vep/Plugins/de_novo_donor.pl line 175.; Smartmatch is experimental at /opt/vep/Plugins/de_novo_donor.pl line 214.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 191.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 194.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 238.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 241.; DBI connect('dbname=/opt/vep/.vep/loftee.sql','',...) failed: unable to open database file at /opt/vep/Plugins/LoF.pm line 126. -------------------- EXCEPTION --------------------; MSG: ERROR: No cache found for homo_sapiens, version 95. STACK Bio::EnsEMBL::VEP::CacheDir::dir /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/CacheDir.pm:328; STACK Bio::EnsEMBL::VEP::CacheDir::init /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/CacheDir.pm:227; STACK Bio::EnsEMBL::VEP::CacheDir::new /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/CacheDir.pm:111; STACK Bio::EnsEMBL::VEP::AnnotationSourceAdaptor::get_all_from_cache /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/AnnotationSourceAdaptor.pm:115; STACK Bio::EnsEMBL::VEP::AnnotationSourceAdaptor::get_all /opt/vep/src/ensembl-vep/modules/Bi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14513:20608,Plugin,Plugins,20608,https://hail.is,https://github.com/hail-is/hail/issues/14513,1,['Plugin'],['Plugins']
Modifiability,:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.GatewayConnection.run(GatewayConnection.java:238); 	at java.lang.Thread.run(Thread.java:748). java.lang.NoClassDefFoundError: Could not initialize class __C147RGContainer_GRCh38; 	at __C144Compiled.applyregion0_8(Emit.scala); 	at __C144Compiled.apply(Emit.scala); 	at is.hail.expr.ir.TableMapRows.$anonfun$execute$43(TableIR.scala:1938); 	at scala.runtime.java8.JFunction1$mcJJ$sp.apply(JFunction1$mcJJ$sp.java:23); 	at scala.collection.Iterator$$anon$10.next(Iterator.scala:461); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:496); 	at is.hail.utils.richUtils.RichContextRDD$$anon$1.next(RichContextRDD.scala:79); 	at scala.collection.Iterator$$anon$11.next(Iterator.scala:496); 	at is.hail.utils.package$.getIteratorSizeWithMaxN(package.scala:415); 	at is.hail.rvd.RVD.$anonfun$head$2(RVD.scala:526); 	at is.hail.rvd.RVD.$anonfun$head$2$adapted(RVD.scala:526); 	at is.hail.sparkextras.ContextRDD.$anonfun$runJob$2(ContextRDD.scala:366); 	at is.hail.sparkextras.ContextRDD.sparkManagedContext(ContextRDD.scala:164); 	at is.hail.sparkextras.ContextRDD.$anonfun$runJob$1(ContextRDD.scala:365); 	at org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2242); 	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); 	at org.apache.spark.scheduler.Task.run(Task.scala:131); 	at org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:497); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:500); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748). Hail version: 0.2.71-f3a54b530979; Error summary: NoClassDefFoundError: Could not initialize,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/10682:14719,adapt,adapted,14719,https://hail.is,https://github.com/hail-is/hail/issues/10682,1,['adapt'],['adapted']
Modifiability,":34 2024; Ensembl API version = 95; ---------------------------------------------------. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 8 in stage 1.0 failed 20 times, most recent failure: Lost task 8.19 in stage 1.0 (TID 2899) (hail-test-w-1.australia-southeast1-a.c.pb-dev-312200.internal executor 3): is.hail.utils.HailException: VEP command '/vep --format vcf --json --everything --allele_number --no_stats --cache --offline --minimal --assembly GRCh38 --fasta /opt/vep/.vep/homo_sapiens/95_GRCh38/Homo_sapiens.GRCh38.dna.toplevel.fa.gz --plugin LoF,loftee_path:/opt/vep/Plugins/,gerp_bigwig:/opt/vep/.vep/gerp_conservation_scores.homo_sapiens.GRCh38.bw,human_ancestor_fa:/opt/vep/.vep/human_ancestor.fa.gz,conservation_file:/opt/vep/.vep/loftee.sql --dir_plugins /opt/vep/Plugins/ -o STDOUT' failed with non-zero exit status 2; VEP Error output:; Smartmatch is experimental at /opt/vep/Plugins/de_novo_donor.pl line 175.; Smartmatch is experimental at /opt/vep/Plugins/de_novo_donor.pl line 214.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 191.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 194.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 238.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 241.; DBI connect('dbname=/opt/vep/.vep/loftee.sql','',...) failed: unable to open database file at /opt/vep/Plugins/LoF.pm line 126. -------------------- EXCEPTION --------------------; MSG: ERROR: No cache found for homo_sapiens, version 95. STACK Bio::EnsEMBL::VEP::CacheDir::dir /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/CacheDir.pm:328; STACK Bio::EnsEMBL::VEP::CacheDir::init /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/CacheDir.pm:227; STACK Bio::EnsEMBL::VEP::CacheDir::new /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/CacheDir.pm:111; STACK Bio::EnsEMBL::VEP::AnnotationSourceAdaptor::get_all_from_cache /opt/vep/src/ensembl",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14513:4274,Plugin,Plugins,4274,https://hail.is,https://github.com/hail-is/hail/issues/14513,1,['Plugin'],['Plugins']
Modifiability,"; 	at is.hail.annotations.RegionPool.scopedRegion(RegionPool.scala:162) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.BackendUtils.$anonfun$collectDArray$15(BackendUtils.scala:90) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$12(Worker.scala:167) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23) ~[scala-library-2.12.15.jar:?]; 	at is.hail.services.package$.retryTransientErrors(package.scala:182) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$11(Worker.scala:166) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.$anonfun$main$11$adapted(Worker.scala:164) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.utils.package$.using(package.scala:637) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Worker$.main(Worker.scala:164) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Main$.main(Main.scala:14) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	at is.hail.backend.service.Main.main(Main.scala) ~[gs:__hail-query-ger0g_jars_b115f6a6ec23f111a4512b562b52d9f8a52ec41c.jar.jar:0.0.1-SNAPSHOT]; 	... 12 more; 	Suppressed: is.hail.relocated.com.google.cloud.storage.StorageException: 403 Forbidden; POST https://storage.googleapis.com/upload/storage/v1/b/neale-bge/o?name=foo.ht/index/part-0-c7ba7549-bf68-42db-a8ef-0f1b13721c79.idx/index&uploadType=resumable; {; ""error"": {; ""co",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13697:16554,adapt,adapted,16554,https://hail.is,https://github.com/hail-is/hail/issues/13697,1,['adapt'],['adapted']
Modifiability,"; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/googleapis/java-storage/releases"">com.google.cloud:google-cloud-storage's releases</a>.</em></p>; <blockquote>; <h2>v2.26.1</h2>; <h2><a href=""https://github.com/googleapis/java-storage/compare/v2.26.0...v2.26.1"">2.26.1</a> (2023-08-14)</h2>; <h3>Bug Fixes</h3>; <ul>; <li>Make use of ImmutableMap.Builder#buildOrThrow graceful (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2159"">#2159</a>) (<a href=""https://github.com/googleapis/java-storage/commit/e9746f856e9204c1c0ec62f19e6f71ff8a0b9750"">e9746f8</a>)</li>; <li>Update gRPC writeAndClose to only set finish_write on the last message (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2163"">#2163</a>) (<a href=""https://github.com/googleapis/java-storage/commit/95df758d6753005226556177e68a3e9c630c789b"">95df758</a>)</li>; </ul>; <h3>Dependencies</h3>; <ul>; <li>Update dependency org.graalvm.buildtools:native-maven-plugin to v0.9.24 (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2158"">#2158</a>) (<a href=""https://github.com/googleapis/java-storage/commit/4f5682a4f6d6d5372a2d382ae3e47dace490ca0d"">4f5682a</a>)</li>; </ul>; <h2>v2.26.0</h2>; <h2><a href=""https://github.com/googleapis/java-storage/compare/v2.25.0...v2.26.0"">2.26.0</a> (2023-08-03)</h2>; <h3>Features</h3>; <ul>; <li>Implement BufferToDiskThenUpload BlobWriteSessionConfig (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2139"">#2139</a>) (<a href=""https://github.com/googleapis/java-storage/commit/4dad2d5c3a81eda7190ad4f95316471e7fa30f66"">4dad2d5</a>)</li>; <li>Introduce new BlobWriteSession (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2123"">#2123</a>) (<a href=""https://github.com/googleapis/java-storage/commit/e0191b518e50a49fae0691894b50f0c5f33fc6af"">e0191b5</a>)</li>; </ul>; <h3>Bug Fixes</h3>; <ul>; <li><strong>grpc:</strong> Return error if credentials are detect",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13605:1118,plugin,plugin,1118,https://hail.is,https://github.com/hail-is/hail/pull/13605,1,['plugin'],['plugin']
Modifiability,"; Resource: ""rbac.authorization.k8s.io/v1, Resource=rolebindings"", GroupVersionKind: ""rbac.authorization.k8s.io/v1, Kind=RoleBinding""; Name: ""batch-pods-admin-binding"", Namespace: ""batch-pods""; Object: &{map[""apiVersion"":""rbac.authorization.k8s.io/v1"" ""kind"":""RoleBinding"" ""metadata"":map[""annotations"":map[""kubectl.kubernetes.io/last-applied-configuration"":""""] ""name"":""batch-pods-admin-binding"" ""namespace"":""batch-pods""] ""roleRef"":map[""apiGroup"":"""" ""kind"":""Role"" ""name"":""batch-pods-admin""] ""subjects"":[map[""kind"":""ServiceAccount"" ""name"":""batch-svc"" ""namespace"":""default""]]]}; from server for: ""deployment.yaml"": rolebindings.rbac.authorization.k8s.io ""batch-pods-admin-binding"" is forbidden: User ""system:serviceaccount:batch-pods:deploy-svc"" cannot get rolebindings.rbac.authorization.k8s.io in the namespace ""batch-pods"": Unknown user ""system:serviceaccount:batch-pods:deploy-svc""; Error from server (Forbidden): error when retrieving current configuration of:; Resource: ""apps/v1beta2, Resource=deployments"", GroupVersionKind: ""apps/v1beta2, Kind=Deployment""; Name: ""batch-deployment"", Namespace: ""batch-pods""; Object: &{map[""apiVersion"":""apps/v1beta2"" ""kind"":""Deployment"" ""metadata"":map[""labels"":map[""hail.is/sha"":""1c6dbf20333a"" ""app"":""batch""] ""name"":""batch-deployment"" ""namespace"":""batch-pods"" ""annotations"":map[""kubectl.kubernetes.io/last-applied-configuration"":""""]] ""spec"":map[""replicas"":'\x01' ""selector"":map[""matchLabels"":map[""app"":""batch""]] ""template"":map[""metadata"":map[""labels"":map[""app"":""batch"" ""hail.is/sha"":""1c6dbf20333a""]] ""spec"":map[""containers"":[map[""image"":""gcr.io/broad-ctsa/batch:4b4139c73fe9be3bee6c2895aa74059e157eb861d2bdac7d2304ba44b5421f88"" ""name"":""batch"" ""ports"":[map[""containerPort"":'\u1388']]]] ""serviceAccountName"":""batch-svc""]]]]}; from server for: ""deployment.yaml"": deployments.apps ""batch-deployment"" is forbidden: User ""system:serviceaccount:batch-pods:deploy-svc"" cannot get deployments.apps in the namespace ""batch-pods"": Unknown user ""system:serviceaccount:batch",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4609:3257,config,configuration,3257,https://hail.is,https://github.com/hail-is/hail/issues/4609,1,['config'],['configuration']
Modifiability,; at scala.collection.Iterator$class.foreach(Iterator.scala:891); at scala.collection.AbstractIterator.foreach(Iterator.scala:1334); at scala.collection.TraversableOnce$class.foldLeft(TraversableOnce.scala:157); at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1334); at scala.collection.TraversableOnce$class.fold(TraversableOnce.scala:212); at scala.collection.AbstractIterator.fold(Iterator.scala:1334); at is.hail.expr.ir.FreeVariables$.is$hail$expr$ir$FreeVariables$$compute$1(FreeVariables.scala:38); at is.hail.expr.ir.FreeVariables$.apply(FreeVariables.scala:42); at is.hail.expr.ir.Mentions$.inAggOrScan(Mentions.scala:10); at is.hail.expr.ir.Simplify$$anonfun$matrixRules$1.applyOrElse(Simplify.scala:893); at is.hail.expr.ir.Simplify$$anonfun$matrixRules$1.applyOrElse(Simplify.scala:828); at scala.PartialFunction$Lifted.apply(PartialFunction.scala:223); at scala.PartialFunction$Lifted.apply(PartialFunction.scala:219); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$rewriteMatrixNode(Simplify.scala:68); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$3.apply(Simplify.scala:50); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$3.apply(Simplify.scala:50); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$visitNode(Simplify.scala:31); at is.hail.expr.ir.Simplify$.is$hail$expr$ir$Simplify$$simplifyMatrix(Simplify.scala:52); at is.hail.expr.ir.Simplify$.apply(Simplify.scala:21); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at is.hail.expr.ir.Simplify$$anonfun$is$hail$expr$ir$Simplify$$simplifyMatrix$2.apply(Simplify.scala:49); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); at scala.collection.mutable.WrappedArray.foreach(Wrapp,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8338:7175,rewrite,rewriteMatrixNode,7175,https://hail.is,https://github.com/hail-is/hail/issues/8338,1,['rewrite'],['rewriteMatrixNode']
Modifiability,"</code></a> [SPARK-40705][SQL] Handle case of using mutable array when converting Row to ...</li>; <li><a href=""https://github.com/apache/spark/commit/9f8eef8bc7fbb5f9a0fe7a4f5c99da0b59b74c07""><code>9f8eef8</code></a> [SPARK-40682][SQL][TESTS] Set <code>spark.driver.maxResultSize</code> to 3g in `SqlBased...</li>; <li><a href=""https://github.com/apache/spark/commit/5a23f62806109425869752de9be1b4ab012f9af8""><code>5a23f62</code></a> Preparing development version 3.3.2-SNAPSHOT</li>; <li><a href=""https://github.com/apache/spark/commit/7c465bc3154cdd0d578f837c9b82e4289caf0b14""><code>7c465bc</code></a> Preparing Spark release v3.3.1-rc3</li>; <li><a href=""https://github.com/apache/spark/commit/5fe895a65a4a9d65f81d43af473b5e3a855ed8c8""><code>5fe895a</code></a> [SPARK-40660][SQL][3.3] Switch to XORShiftRandom to distribute elements</li>; <li><a href=""https://github.com/apache/spark/commit/5dc9ba0d22741173bd122afb387c54d7ca4bfb6d""><code>5dc9ba0</code></a> [SPARK-40669][SQL][TESTS] Parameterize <code>rowsNum</code> in <code>InMemoryColumnarBenchmark</code></li>; <li>Additional commits viewable in <a href=""https://github.com/apache/spark/compare/v3.1.3...v3.3.1"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=pyspark&package-manager=pip&previous-version=3.1.3&new-version=3.3.1)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreat",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12455:1972,Parameteriz,Parameterize,1972,https://hail.is,https://github.com/hail-is/hail/pull/12455,1,['Parameteriz'],['Parameterize']
Modifiability,"<a href=""https://github.com/googleapis/java-storage/commit/c80505129baa831e492a5514e937875407211595"">c805051</a>)</li>; </ul>; <h3>Documentation</h3>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/googleapis/java-storage/commit/d0b4ef7ac4a1c05658f8c6c3aac4a84e9691a732""><code>d0b4ef7</code></a> chore(main): release 2.26.1 (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2161"">#2161</a>)</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/a35d4ce1dc8492ecf2b5db76c137b3bcf5b7b0ca""><code>a35d4ce</code></a> chore(deps): update dependency com.google.cloud:libraries-bom to v26.22.0 (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2"">#2</a>...</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/4f5682a4f6d6d5372a2d382ae3e47dace490ca0d""><code>4f5682a</code></a> deps: update dependency org.graalvm.buildtools:native-maven-plugin to v0.9.24...</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/8627f7b141a53ca90a997f1f70126b1d1272784a""><code>8627f7b</code></a> chore(deps): update dependency com.google.cloud:google-cloud-storage to v2.26...</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/95df758d6753005226556177e68a3e9c630c789b""><code>95df758</code></a> fix: update gRPC writeAndClose to only set finish_write on the last message (...</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/e9746f856e9204c1c0ec62f19e6f71ff8a0b9750""><code>e9746f8</code></a> fix: make use of ImmutableMap.Builder#buildOrThrow graceful (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2159"">#2159</a>)</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/a7ac773e340bd788aa38b91bb40a503fb2530212""><code>a7ac773</code></a> chore(main): release 2.26.1-SNAPSHOT (<a href=""https://redirect.github.com/googleapis/java-storage/issues/2155"">#2155</a>)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13605:9846,plugin,plugin,9846,https://hail.is,https://github.com/hail-is/hail/pull/13605,1,['plugin'],['plugin']
Modifiability,"<blockquote>; <h2>10.2.0 (2024-01-02)</h2>; <ul>; <li>; <p>Add <code>keep_rgb</code> option when saving JPEG to prevent conversion of RGB colorspace <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7553"">#7553</a>; [bgilbert, radarhere]</p>; </li>; <li>; <p>Trim glyph size in ImageFont.getmask() <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7669"">#7669</a>, <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7672"">#7672</a>; [radarhere, nulano]</p>; </li>; <li>; <p>Deprecate IptcImagePlugin helpers <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7664"">#7664</a>; [nulano, hugovk, radarhere]</p>; </li>; <li>; <p>Allow uncompressed TIFF images to be saved in chunks <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7650"">#7650</a>; [radarhere]</p>; </li>; <li>; <p>Concatenate multiple JPEG EXIF markers <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7496"">#7496</a>; [radarhere]</p>; </li>; <li>; <p>Changed IPTC tile tuple to match other plugins <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7661"">#7661</a>; [radarhere]</p>; </li>; <li>; <p>Do not assign new fp attribute when exiting context manager <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7566"">#7566</a>; [radarhere]</p>; </li>; <li>; <p>Support arbitrary masks for uncompressed RGB DDS images <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7589"">#7589</a>; [radarhere, akx]</p>; </li>; <li>; <p>Support setting ROWSPERSTRIP tag <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7654"">#7654</a>; [radarhere]</p>; </li>; <li>; <p>Apply ImageFont.MAX_STRING_LENGTH to ImageFont.getmask() <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7662"">#7662</a>; [radarhere]</p>; </li>; <li>; <p>Optimise <code>ImageColor</code> using <code>functools.lru_cache</code> <a href=""https://redirect.github.com/python-pillow/Pillow/issues/7657"">#7657</a>; [hugovk]<",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14191:10915,plugin,plugins,10915,https://hail.is,https://github.com/hail-is/hail/pull/14191,3,['plugin'],['plugins']
Modifiability,"<blockquote>; <h2>v1.22.0</h2>; <h1>NumPy 1.22.0 Release Notes</h1>; <p>NumPy 1.22.0 is a big release featuring the work of 153 contributors; spread over 609 pull requests. There have been many improvements,; highlights are:</p>; <ul>; <li>Annotations of the main namespace are essentially complete. Upstream; is a moving target, so there will likely be further improvements,; but the major work is done. This is probably the most user visible; enhancement in this release.</li>; <li>A preliminary version of the proposed Array-API is provided. This is; a step in creating a standard collection of functions that can be; used across application such as CuPy and JAX.</li>; <li>NumPy now has a DLPack backend. DLPack provides a common interchange; format for array (tensor) data.</li>; <li>New methods for <code>quantile</code>, <code>percentile</code>, and related functions. The; new methods provide a complete set of the methods commonly found in; the literature.</li>; <li>A new configurable allocator for use by downstream projects.</li>; </ul>; <p>These are in addition to the ongoing work to provide SIMD support for; commonly used functions, improvements to F2PY, and better documentation.</p>; <p>The Python versions supported in this release are 3.8-3.10, Python 3.7; has been dropped. Note that 32 bit wheels are only provided for Python; 3.8 and 3.9 on Windows, all other wheels are 64 bits on account of; Ubuntu, Fedora, and other Linux distributions dropping 32 bit support.; All 64 bit wheels are also linked with 64 bit integer OpenBLAS, which should fix; the occasional problems encountered by folks using truly huge arrays.</p>; <h2>Expired deprecations</h2>; <h3>Deprecated numeric style dtype strings have been removed</h3>; <p>Using the strings <code>&quot;Bytes0&quot;</code>, <code>&quot;Datetime64&quot;</code>, <code>&quot;Str0&quot;</code>, <code>&quot;Uint32&quot;</code>,; and <code>&quot;Uint64&quot;</code> as a dtype will now raise a <code>TypeError</code>.</p>; <p>(<a h",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11939:1199,config,configurable,1199,https://hail.is,https://github.com/hail-is/hail/pull/11939,4,['config'],['configurable']
Modifiability,"<code>~cryptography.hazmat.primitives.asymmetric.ec.EllipticCurvePublicKey.from_encoded_point</code>; should be used instead.</li>; <li><strong>BACKWARDS INCOMPATIBLE:</strong> Support for using MD5 or SHA1 in; :class:<code>~cryptography.x509.CertificateBuilder</code>, other X.509 builders, and; PKCS7 has been removed.</li>; <li><strong>BACKWARDS INCOMPATIBLE:</strong> Dropped support for macOS 10.10 and 10.11, macOS; users must upgrade to 10.12 or newer.</li>; <li><strong>ANNOUNCEMENT:</strong> The next version of <code>cryptography</code> (40.0) will change; the way we link OpenSSL. This will only impact users who build; <code>cryptography</code> from source (i.e., not from a <code>wheel</code>), and specify their; own version of OpenSSL. For those users, the <code>CFLAGS</code>, <code>LDFLAGS</code>,; <code>INCLUDE</code>, <code>LIB</code>, and <code>CRYPTOGRAPHY_SUPPRESS_LINK_FLAGS</code> environment; variables will no longer be respected. Instead, users will need to; configure their builds <code>as documented here</code>_.</li>; <li>Added support for; :ref:<code>disabling the legacy provider in OpenSSL 3.0.x&lt;legacy-provider&gt;</code>.</li>; <li>Added support for disabling RSA key validation checks when loading RSA; keys via; :func:<code>~cryptography.hazmat.primitives.serialization.load_pem_private_key</code>,; :func:<code>~cryptography.hazmat.primitives.serialization.load_der_private_key</code>,; and; :meth:<code>~cryptography.hazmat.primitives.asymmetric.rsa.RSAPrivateNumbers.private_key</code>.; This speeds up key loading but is :term:<code>unsafe</code> if you are loading potentially; attacker supplied keys.</li>; <li>Significantly improved performance for; :class:<code>~cryptography.hazmat.primitives.ciphers.aead.ChaCha20Poly1305</code></li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/pyca/cryptography/commit/d6951dca25de45abd52da51b60",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12668:2422,config,configure,2422,https://hail.is,https://github.com/hail-is/hail/pull/12668,4,['config'],['configure']
Modifiability,"<img width=""1168"" alt=""Screen Shot 2021-05-24 at 4 54 34 PM"" src=""https://user-images.githubusercontent.com/63973811/129767519-85ab5cf1-2da6-41ee-b52f-44bdf63f7118.png"">. The goal of this progress bar is to have a visual concept that could show the progress of every job created. We added Plotly to show how long it takes for each step to complete when creating a batch job. We decided to use the container_status already created and created a new variable that would hold the new data that Plotly would produce. We use the job-status variable to obtain all of the creating pulling and posting information created. We inserted the data collected through a for-loop that test for each possible test case.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10687:448,variab,variable,448,https://hail.is,https://github.com/hail-is/hail/pull/10687,2,['variab'],['variable']
Modifiability,"=y</code> option will check all discovered <code>.py</code> files and packages found inside subtree of directory provided; as parameter to pylint.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/352"">#352</a></p>; </li>; <li>; <p>Add <code>modified-iterating-list</code>, <code>modified-iterating-dict</code> and <code>modified-iterating-set</code>,; emitted when items are added to or removed from respectively a list, dictionary or; set being iterated through.</p>; </li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/PyCQA/pylint/commit/fd0eb6c2af0e3e98350e24047c4df7d5b8aad89a""><code>fd0eb6c</code></a> Bump pylint to 2.13.0, update changelog</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/1c509edc4ee2dbf1bbe8822e91e0b7df02ce463d""><code>1c509ed</code></a> [cleanup] Remove unused code in pylint.checker.base following refactor</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/1e7d3fa6219934028d2539ad290fe16ce8ea78e2""><code>1e7d3fa</code></a> [refactor] Create a file for the BasicChecker in pylint.checker.base</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/c0b8b32592f8d5d34ff37250adbda6b65269a0af""><code>c0b8b32</code></a> [refactor] Create a file for the BasicErrorChecker in pylint.checker.base</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/3f11fe629a7b89d2a3b92dce09ac5818f3904cee""><code>3f11fe6</code></a> [refactor] Create a package for the NameChecker in pylint.checker.base</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/6940715ba15f81fbd7d9e8685c0a714a8b612f24""><code>6940715</code></a> [refactor] Create a file for the DocstringChecker in pylint.checker.base</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/84d22cf24202bf6006fc179541e1853d145d33e0""><code>84d22cf</code></a> [refactor] Create a file for the PassChecker in pylint.checker.base</li>; <li><a href=""https:",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11674:3757,refactor,refactor,3757,https://hail.is,https://github.com/hail-is/hail/pull/11674,1,['refactor'],['refactor']
Modifiability,> TMPDIR; > This variable shall represent a pathname of a directory made; > available for programs that need a place to create temporary; > files. http://pubs.opengroup.org/onlinepubs/9699919799/. Requested by the discuss user rca:. http://discuss.hail.is/t/hailcontext-tmp-dir/323,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2327:17,variab,variable,17,https://hail.is,https://github.com/hail-is/hail/pull/2327,1,['variab'],['variable']
Modifiability,"> doSomething(r) ).catch( err => throw new Error(err) ); ```. This has one problem. Chaining promises leads to a potentially hard to follow chain of `.then` `.catch`. As in many other languages, the solution to ""transforming"" async call syntax to sync ones, is to color async functions with a ""async"" and ""await"" clauses. This can be used with any functions that return promises (but not those that just return a callback). Luckily again, JS libraries have been moving towards the Promise-land (sorry) for ~5 years, before Promises were in stdlib (bluebird). ```js; async function usePromise() {; const arg = someSyncOperation();; ; let result;; try {; result = await asyncPromise(arg);; } catch(e) {; // without wrapping catch, will just throw on reject(), unwinding the call stack; doSomethingWIthError(e) ; }; ; doStuffWithResult(result);; }; ```; ### React; What is a react component? A function that returns JSX. React components accept props (HTML attributes `<Component propName={propValue} />`); Stateless vs stateful components; ```jsx; # Stateful; class Stuff extends React.Component {; static getInitialProps() {; ; }. render() {; return <div>Hello World</div>; } ; }. # Stateless; # Note that arrow syntax has an implicit return if you don't create a function block, i. => { return <div>Hello World</div> } is valid too.; () => <div> Hello World </div> ; ```. Stateless ones are typically cheaper, but not necessarily:; * See: [PureComponent](https://reactjs.org/docs/react-api.html#reactpurecomponent); * See: [shouldComponentUpdate lifecycle method](https://reactjs.org/docs/react-component.html#shouldcomponentupdate). #### JSX differences from html; 1. `className` : ""class"" is a reserved word in JSX; used to specify the component class (every HTML element is modeled as an object). [This will go away in 2019, maybe](https://github.com/facebook/react/issues/13525); 2. There should alway be one and only one non-leaf node in the component tree. Leaf siblings are allowed; note that t",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5162:6668,extend,extends,6668,https://hail.is,https://github.com/hail-is/hail/pull/5162,1,['extend'],['extends']
Modifiability,> pytest-instafail is a plugin for py.test that shows failures and errors instantly instead of waiting until the end of test session. https://github.com/pytest-dev/pytest-instafail/,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6854:24,plugin,plugin,24,https://hail.is,https://github.com/hail-is/hail/pull/6854,1,['plugin'],['plugin']
Modifiability,"> was made a bit more descriptive (<code>pattern=N,...</code> instead of <code>moduleSpec</code>). (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/106090"">kubernetes/kubernetes#106090</a>, <a href=""https://github.com/pohly""><code>@​pohly</code></a>) [SIG API Machinery, Architecture, CLI, Cluster Lifecycle, Instrumentation, Node and Scheduling]</li>; <li>Introduce <code>OS</code> field in the PodSpec (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/104693"">kubernetes/kubernetes#104693</a>, <a href=""https://github.com/ravisantoshgudimetla""><code>@​ravisantoshgudimetla</code></a>)</li>; <li>Introduce <code>v1beta3</code> API for scheduler. This version; <ul>; <li>; <p>increases the weight of user specifiable priorities.; The weights of following priority plugins are increased</p>; <ul>; <li><code>TaintTolerations</code> to 3 - as leveraging node tainting to group nodes in the cluster is becoming a widely-adopted practice</li>; <li><code>NodeAffinity</code> to 2</li>; <li><code>InterPodAffinity</code> to 2</li>; </ul>; </li>; <li>; <p>Won't have <code>HealthzBindAddress</code>, <code>MetricsBindAddress</code> fields (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/104251"">kubernetes/kubernetes#104251</a>, <a href=""https://github.com/ravisantoshgudimetla""><code>@​ravisantoshgudimetla</code></a>)</p>; </li>; </ul>; </li>; <li>Introduce v1beta2 for Priority and Fairness with no changes in API spec. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/104399"">kubernetes/kubernetes#104399</a>, <a href=""https://github.com/tkashem""><code>@​tkashem</code></a>)</li>; <li>JSON log output is configurable and now supports writing info messages to stdout and error messages to stderr. Info messages can be buffered in memory. The default is to write both to stdout without buffering, as before. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/104873"">kuber",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11957:6009,plugin,plugins,6009,https://hail.is,https://github.com/hail-is/hail/pull/11957,1,['plugin'],['plugins']
Modifiability,">)</li>; <li>Add support for specifying stable version with <code>--required-version</code> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2832"">#2832</a>).</li>; <li>Avoid crashing when the user has no homedir (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2814"">#2814</a>)</li>; <li>Avoid crashing when md5 is not available (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2905"">#2905</a>)</li>; <li>Fix handling of directory junctions on Windows (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2904"">#2904</a>)</li>; </ul>; <h3>Documentation</h3>; <ul>; <li>Update pylint config documentation (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2931"">#2931</a>)</li>; </ul>; <h3>Integrations</h3>; <ul>; <li>Move test to disable plugin in Vim/Neovim, which speeds up loading (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2896"">#2896</a>)</li>; </ul>; <h3>Output</h3>; <ul>; <li>In verbose, mode, log when <em>Black</em> is using user-level config (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2861"">#2861</a>)</li>; </ul>; <h3>Packaging</h3>; <ul>; <li>Fix Black to work with Click 8.1.0 (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2966"">#2966</a>)</li>; <li>On Python 3.11 and newer, use the standard library's <code>tomllib</code> instead of <code>tomli</code>; (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2903"">#2903</a>)</li>; <li><code>black-primer</code>, the deprecated internal devtool, has been removed and copied to a; <a href=""https://github.com/cooperlees/black-primer"">separate repository</a> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2924"">#2924</a>)</li>; </ul>; <h3>Parser</h3>; <ul>; <li>Black can now parse starred expressions in the target of <code>for</code> and <code>async for</code>; statements, e.g <code>for item in *items_1, *items_2: pass</code> (<a href=""https://github-redir",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11696:2163,config,config,2163,https://hail.is,https://github.com/hail-is/hail/pull/11696,2,['config'],['config']
Modifiability,">; <blockquote>; <h2>0.13.1 / 2022-01-28</h2>; <p>[BUGFIX] Relax some type constraints that were too strict. <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/754"">#754</a>, <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/755"">#755</a>, <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/756"">#756</a>, <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/758"">#758</a>; [BUGFIX] Explicitly export functions with <code>__all__</code>. <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/757"">#757</a></p>; <h2>0.13.0 / 2022-01-25</h2>; <p>[CHANGE] Drop support for Python versions 2.7, 3.4, and 3.5. <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/718"">#718</a>; [FEATURE] Support adding labels when using <code>.time()</code> <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/730"">#730</a>; [ENHANCEMENT] Begin to add type hints to functions. <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/705"">#705</a>; [ENHANCEMENT] Improved go-to-declaration behavior for editors. <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/747"">#747</a>; [BUGFIX] Remove trailing slashes from pushgateway URLS. <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/722"">#722</a>; [BUGFIX] Catch non-integer bucket/count values. <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/726"">#726</a></p>; <h2>0.12.0 / 2021-10-29</h2>; <p>[FEATURE] Exemplar support (excludes multiprocess) <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/669"">#669</a>; [ENHANCEMENT] Add support for Python 3.10 <a href=""https://github-redirect.dependabot.com/prometheus/client_python/issues/706"">#706</a>; [ENHANCEMENT] Restricted Registry will handle metrics added after restricting <a ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11515:1265,ENHANCE,ENHANCEMENT,1265,https://hail.is,https://github.com/hail-is/hail/pull/11515,1,['ENHANCE'],['ENHANCEMENT']
Modifiability,">; <h2>Deprecated</h2>; <ul>; <li><a href=""https://redirect.github.com/sphinx-doc/sphinx/issues/11412"">#11412</a>: Emit warnings on using a deprecated Python-specific index entry type; (namely, <code>module</code>, <code>keyword</code>, <code>operator</code>, <code>object</code>, <code>exception</code>,; <code>statement</code>, and <code>builtin</code>) in the :rst:dir:<code>index</code> directive, and; set the removal version to Sphinx 9. Patch by Adam Turner.</li>; </ul>; <h2>Features added</h2>; <ul>; <li><a href=""https://redirect.github.com/sphinx-doc/sphinx/issues/11415"">#11415</a>: Add a checksum to JavaScript and CSS asset URIs included within; generated HTML, using the CRC32 algorithm.</li>; <li>:meth:<code>~sphinx.application.Sphinx.require_sphinx</code> now allows the version; requirement to be specified as <code>(major, minor)</code>.</li>; <li><a href=""https://redirect.github.com/sphinx-doc/sphinx/issues/11011"">#11011</a>: Allow configuring a line-length limit for object signatures, via; :confval:<code>maximum_signature_line_length</code> and the domain-specific variants.; If the length of the signature (in characters) is greater than the configured; limit, each parameter in the signature will be split to its own logical line.; This behaviour may also be controlled by options on object description; directives, for example :rst:dir:<code>py:function:single-line-parameter-list</code>.; Patch by Thomas Louf, Adam Turner, and Jean-François B.</li>; <li><a href=""https://redirect.github.com/sphinx-doc/sphinx/issues/10983"">#10983</a>: Support for multiline copyright statements in the footer block.; Patch by Stefanie Molin</li>; <li><code>sphinx.util.display.status_iterator</code> now clears the current line; with ANSI control codes, rather than overprinting with space characters.</li>; <li><a href=""https://redirect.github.com/sphinx-doc/sphinx/issues/11431"">#11431</a>: linkcheck: Treat SSL failures as broken links.; Patch by Bénédikt Tran</li>; <li><a href=""http",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13295:2353,config,configuring,2353,https://hail.is,https://github.com/hail-is/hail/pull/13295,1,['config'],['configuring']
Modifiability,">; <li><a href=""https://github.com/grantjenks/python-sortedcontainers/commit/da6d0d034822f66966e4a84a3a1e2f37cc83e3b0""><code>da6d0d0</code></a> Remove unneeded &quot;update order&quot; consistency test</li>; <li><a href=""https://github.com/grantjenks/python-sortedcontainers/commit/e85d8659733cb3e28d539a28db0fdd71672ab2e4""><code>e85d865</code></a> Simplify &quot;update order&quot; consistency test</li>; <li><a href=""https://github.com/grantjenks/python-sortedcontainers/commit/7dc426c95a0c329d5514e6198d92080f1ffc1e5e""><code>7dc426c</code></a> Fix update() ordering to be more consistent with add() ordering (<a href=""https://github-redirect.dependabot.com/grantjenks/python-sortedcontainers/issues/159"">#159</a>)</li>; <li><a href=""https://github.com/grantjenks/python-sortedcontainers/commit/13d30bc654eb9e6be092282ca502967fcb7f0113""><code>13d30bc</code></a> Bump version to 2.2.2</li>; <li><a href=""https://github.com/grantjenks/python-sortedcontainers/commit/4997d0e849f2275d1931772a5432163ecc20e0b0""><code>4997d0e</code></a> Refactor small slice optimization in SortedList.<strong>getitem</strong></li>; <li><a href=""https://github.com/grantjenks/python-sortedcontainers/commit/6ee5d57fc8d691fbab4972b853a60348d0f922ef""><code>6ee5d57</code></a> improve SortedList.<strong>getitem</strong>() performance for small slices</li>; <li><a href=""https://github.com/grantjenks/python-sortedcontainers/commit/ac80254fb6a08045ced7d9704412878ff8000fa7""><code>ac80254</code></a> suppress warning in test of deprecated function (<a href=""https://github-redirect.dependabot.com/grantjenks/python-sortedcontainers/issues/118"">#118</a>)</li>; <li>Additional commits viewable in <a href=""https://github.com/grantjenks/python-sortedcontainers/compare/v2.1.0...v2.4.0"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=sortedcontainers&package-manager=pip&previous-version=2.1.0&new-version=2.4",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11476:2996,Refactor,Refactor,2996,https://hail.is,https://github.com/hail-is/hail/pull/11476,1,['Refactor'],['Refactor']
Modifiability,"></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/684"">jpadilla/pyjwt#684</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/686"">jpadilla/pyjwt#686</a></li>; <li>[pre-commit.ci] pre-commit autoupdate by <a href=""https://github.com/pre-commit-ci""><code>@​pre-commit-ci</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/689"">jpadilla/pyjwt#689</a></li>; <li>Remove upper bound on cryptography version by <a href=""https://github.com/riconnon""><code>@​riconnon</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/693"">jpadilla/pyjwt#693</a></li>; <li>Add support for Ed448/EdDSA. by <a href=""https://github.com/dajiaji""><code>@​dajiaji</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/675"">jpadilla/pyjwt#675</a></li>; <li>Chore: inline Variables that immediately Returned by <a href=""https://github.com/yezz123""><code>@​yezz123</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/690"">jpadilla/pyjwt#690</a></li>; <li>Use timezone package as Python 3.5+ is required by <a href=""https://github.com/kkirsche""><code>@​kkirsche</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/694"">jpadilla/pyjwt#694</a></li>; <li>Bump up version to v2.2.0 by <a href=""https://github.com/jpadilla""><code>@​jpadilla</code></a> in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/697"">jpadilla/pyjwt#697</a></li>; </ul>; <h2>New Contributors</h2>; <ul>; <li><a href=""https://github.com/TPXP""><code>@​TPXP</code></a> made their first contribution in <a href=""https://github-redirect.dependabot.com/jpadilla/pyjwt/pull/664"">jpadilla/pyjwt#664</a></li>; <li><a href=""https://github.com/Klavionik""><code>@​Klavionik</code></a> made their first contribution in <a href=""https",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11457:5606,Variab,Variables,5606,https://hail.is,https://github.com/hail-is/hail/pull/11457,1,['Variab'],['Variables']
Modifiability,"><a href=""https://github.com/pytest-dev/pytest-asyncio/commit/adc88090f341d9872e9e9b4d22a94cdadf60b3bc""><code>adc8809</code></a> Build(deps): Bump typing-extensions in /dependencies/default (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-asyncio/issues/425"">#425</a>)</li>; <li><a href=""https://github.com/pytest-dev/pytest-asyncio/commit/4abf9d1df228ed8b083721d7affa73e4a08d13c3""><code>4abf9d1</code></a> Build(deps): Bump zipp from 3.8.1 to 3.9.0 in /dependencies/default (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-asyncio/issues/424"">#424</a>)</li>; <li><a href=""https://github.com/pytest-dev/pytest-asyncio/commit/eb487bcb076f44dedcdb33e74972bf06c37027ee""><code>eb487bc</code></a> Build(deps): Bump hypothesis in /dependencies/default (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-asyncio/issues/423"">#423</a>)</li>; <li><a href=""https://github.com/pytest-dev/pytest-asyncio/commit/907c461f172e52159a595e2592176c7feac04a43""><code>907c461</code></a> Refactor pytest_pycollect_makeitems (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-asyncio/issues/421"">#421</a>)</li>; <li><a href=""https://github.com/pytest-dev/pytest-asyncio/commit/d45ab217c80117854b510edc6c9fdd457b6b07fc""><code>d45ab21</code></a> feat: Add deprecation warning for pytest &lt; 7. (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-asyncio/issues/420"">#420</a>)</li>; <li><a href=""https://github.com/pytest-dev/pytest-asyncio/commit/cab20f4d346e9e52e5ffc93854de3ec881e7d342""><code>cab20f4</code></a> Build(deps): Bump importlib-metadata in /dependencies/default (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-asyncio/issues/415"">#415</a>)</li>; <li><a href=""https://github.com/pytest-dev/pytest-asyncio/commit/d9f77567189c96536b39b43520f4b40895b34fb9""><code>d9f7756</code></a> Build(deps): Bump hypothesis in /dependencies/default (<a href=""https://github-redirect.dependabot.com/pytest-dev/pytest-asyncio/is",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12390:5637,Refactor,Refactor,5637,https://hail.is,https://github.com/hail-is/hail/pull/12390,1,['Refactor'],['Refactor']
Modifiability,"><a href=""https://github.com/sphinx-doc/sphinx/commit/ed6970311349e54ceebe24ede255378fcd9d94e5""><code>ed69703</code></a> Update CHANGES for PR <a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10535"">#10535</a></li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/377d8668b5c93cc224fec46f2f3c2920b25107ca""><code>377d866</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10535"">#10535</a> from AA-Turner/css-nav-contents</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/709602437df850d5538a4fe899a50625c01a0f80""><code>7096024</code></a> Update CHANGES for PR <a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10539"">#10539</a></li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/d0452276689bfb5b97ca7a3469e1afb505895cdd""><code>d045227</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10539"">#10539</a> from AA-Turner/fix-inherited-attrs</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/29edce9243046962f5f024d510315133448dd3e1""><code>29edce9</code></a> test: Add testcase for autodoc_inherit_docstring and attributes (refs: <a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10539"">#10539</a>)</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/3956cf2249d27ed63e8381c07dfde36f6c96f78f""><code>3956cf2</code></a> Fix documenting inherited attributes</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/27f05328d0369ad0db85c27935d52fdadf020f6b""><code>27f0532</code></a> Move <code>aside.topic</code> into the conditional blocks</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/5806f0af2788db40661d62e5e88c2c1560ae46b6""><code>5806f0a</code></a> Add <code>nav.contents</code> everywhere that <code>div.topic</code> is used</li>; <li><a href=""https://github.com/sphinx-doc/sphinx/commit/8da2efb1d71ab2d384ddc90cf4fdebe5d18e91cd""><code>8da2efb</c",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11925:5097,inherit,inherited-attrs,5097,https://hail.is,https://github.com/hail-is/hail/pull/11925,1,['inherit'],['inherited-attrs']
Modifiability,"><code>10a4427</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/PyCQA/pycodestyle/issues/1092"">#1092</a> from PyCQA/2_9_1</li>; <li><a href=""https://github.com/PyCQA/pycodestyle/commit/c33e852a5938b823b04dd981260bd1664c643385""><code>c33e852</code></a> Release 2.9.1</li>; <li><a href=""https://github.com/PyCQA/pycodestyle/commit/c97e4f86bd60e449a64be6c0de5b5ec5bb28b8e9""><code>c97e4f8</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/PyCQA/pycodestyle/issues/1091"">#1091</a> from asottile/E275-yield-expression</li>; <li><a href=""https://github.com/PyCQA/pycodestyle/commit/43c5afaeef44a01b512ade340030ff4d7b0ba78e""><code>43c5afa</code></a> allow parenthesized yield (generator-coroutines)</li>; <li><a href=""https://github.com/PyCQA/pycodestyle/commit/9e6e820b269cbe39da854ae2835bd797028d22db""><code>9e6e820</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/PyCQA/pycodestyle/issues/1089"">#1089</a> from PyCQA/pre-commit-ci-update-config</li>; <li><a href=""https://github.com/PyCQA/pycodestyle/commit/9851cb692a2f824495f6bbdded03059116bb46bb""><code>9851cb6</code></a> [pre-commit.ci] pre-commit autoupdate</li>; <li><a href=""https://github.com/PyCQA/pycodestyle/commit/44b3d2895b39b1eff8cb5048ae3464a033b4ede8""><code>44b3d28</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/PyCQA/pycodestyle/issues/1087"">#1087</a> from PyCQA/2_9_0</li>; <li><a href=""https://github.com/PyCQA/pycodestyle/commit/57e39fa4f66707c305ead679e62d7ce1b7af9362""><code>57e39fa</code></a> Release 2.9.0</li>; <li><a href=""https://github.com/PyCQA/pycodestyle/commit/ab806f3f9133ca24366b6254e499f0363f6bf5ec""><code>ab806f3</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/PyCQA/pycodestyle/issues/1085"">#1085</a> from PyCQA/revert-1041</li>; <li><a href=""https://github.com/PyCQA/pycodestyle/commit/c14bd2aac8e370bc84048a97f17a1ed906523bf9""><code>c14bd2a</code></a> Revert &quot;Merg",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12476:2440,config,config,2440,https://hail.is,https://github.com/hail-is/hail/pull/12476,1,['config'],['config']
Modifiability,"><code>@​akayunov</code></a></li>; </ul>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/jmoiron/humanize/commit/a1514eb521c2befe40274674d61aba4f0fbf6137""><code>a1514eb</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/jmoiron/humanize/issues/239"">#239</a> from hugovk/rm-3.6</li>; <li><a href=""https://github.com/jmoiron/humanize/commit/48506d434fd315a976bbdc058a791b80086f7e7e""><code>48506d4</code></a> pre-commit autoupdate</li>; <li><a href=""https://github.com/jmoiron/humanize/commit/8f2c8551e5e20cc6cc3bcaa241fa2c1760d07926""><code>8f2c855</code></a> Remove unused import</li>; <li><a href=""https://github.com/jmoiron/humanize/commit/04bf8872908178b3d7d9fb4b316da8ce72916209""><code>04bf887</code></a> Drop support for Python 3.6</li>; <li><a href=""https://github.com/jmoiron/humanize/commit/0f2ff42cbe632c47ddb6ac255c61890ab8a46fd4""><code>0f2ff42</code></a> Use actions/setup-python's pip cache and update other CI config</li>; <li><a href=""https://github.com/jmoiron/humanize/commit/464de5965692765d29d1c3cfde1f87c4ceece440""><code>464de59</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/jmoiron/humanize/issues/253"">#253</a> from hugovk/rm-VERSION</li>; <li><a href=""https://github.com/jmoiron/humanize/commit/66b8a6322fbda9bffb2882500c6a9b6c96271401""><code>66b8a63</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/jmoiron/humanize/issues/250"">#250</a> from carterbox/no-overflow-naturaldelta</li>; <li><a href=""https://github.com/jmoiron/humanize/commit/e89c8c8e325ccb2b3ee78ef507e9d6805c47a175""><code>e89c8c8</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/jmoiron/humanize/issues/241"">#241</a> from samueljsb/remove-deprecated-private-function-ali...</li>; <li><a href=""https://github.com/jmoiron/humanize/commit/ffe4bcfaa6cfbd95ba47315f8f71a206485af6ae""><code>ffe4bc",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11517:5367,config,config,5367,https://hail.is,https://github.com/hail-is/hail/pull/11517,2,['config'],['config']
Modifiability,">Fix handling of standalone <code>match()</code> or <code>case()</code> when there is a trailing newline or a comment inside of the parentheses. (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2760"">#2760</a>)</li>; <li><code>from __future__ import annotations</code> statement now implies Python 3.7+ (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2690"">#2690</a>)</li>; </ul>; <h3>Performance</h3>; <ul>; <li>Speed-up the new backtracking parser about 4X in general (enabled when <code>--target-version</code> is set to 3.10 and higher). (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2728"">#2728</a>)</li>; <li>Black is now compiled with mypyc for an overall 2x speed-up. 64-bit Windows, MacOS, and Linux (not including musl) are supported. (<a href=""https://github-redirect.dependabot.com/psf/black/issues/1009"">#1009</a>, <a href=""https://github-redirect.dependabot.com/psf/black/issues/2431"">#2431</a>)</li>; </ul>; <h3>Configuration</h3>; <ul>; <li>Do not accept bare carriage return line endings in pyproject.toml (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2408"">#2408</a>)</li>; <li>Add configuration option (<code>python-cell-magics</code>) to format cells with custom magics in Jupyter Notebooks (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2744"">#2744</a>)</li>; <li>Allow setting custom cache directory on all platforms with environment variable <code>BLACK_CACHE_DIR</code> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2739"">#2739</a>).</li>; <li>Enable Python 3.10+ by default, without any extra need to specify -<code>-target-version=py310</code>. (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2758"">#2758</a>)</li>; <li>Make passing <code>SRC</code> or <code>--code</code> mandatory and mutually exclusive (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2804"">#2804</a>)</li>; </ul>; <h3>Output</h3>; <ul>; <li>Improve error",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11468:4538,Config,Configuration,4538,https://hail.is,https://github.com/hail-is/hail/pull/11468,1,['Config'],['Configuration']
Modifiability,"@cseed @catoverdrive This is how we should do aggregators. I implemented several as examples. It's a bit repetitive, maybe `@specialized` can help here? I'm kind of afraid of it. Some open issues:. - if the result of an aggregator is missing, I can't write it into the region, maybe rewrite `result` in continuation-passing style with a missing and non missing continuation? (is that function call indirection worth avoiding an allocation of a `Some(offset)` per-aggrgator-result?). - how do I take a user supplied function, e.g. `takeBy`? I keep avoiding lambda-like constructs. Do I introduce a new binding form, like `ApplyUnaryFunAggOp`. I don't like this path, but I also think adding a `Lambda` IR that isn't a full-fledged lambda will make the compiler look annoying/ugly too. This issue is basically the continuation of me punting on how to handle lambdas. - How do y'all feel about me eliminating some type-specific aggregators that can be implemented in terms of other ones (see AggOp.scala). If y'all are happy with this, I want to solve the missingness issue, and then farm out the last few (non-lambda-taking) aggregators to the team.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2606:283,rewrite,rewrite,283,https://hail.is,https://github.com/hail-is/hail/pull/2606,1,['rewrite'],['rewrite']
Modifiability,"@cseed @tpoterba . There's now an option to disable the Unsafe warnings in javac. You have to `-XDenableSunApiLintControl` and then you can `@SuppressWarnings(""sunapi"")`. The changes that are not in build.gradle and build.sbt are just me fixing warnings. There were some meaningful things, like unused variables and some places we were unnecessarily allocating a tuple.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5951:302,variab,variables,302,https://hail.is,https://github.com/hail-is/hail/pull/5951,1,['variab'],['variables']
Modifiability,"@cseed @tpoterba @jigold. I think these are most of the structural changes I was planning on making to the python aggregator stuff so that the interface change can go in. I haven't changed the existing interface yet, but I figured I'd throw this up for comments if you guys wanted to take a look this morning. Some comments:; - I don't think that the IR introspection this is the correct way to do this, long term, but I think that the correct thing to do will be easier to implement correctly with the IR changes we discussed yesterday, so I'm inclined to do it this way for now since we'll have to rewrite it when we change the IR structure (assuming we still want to get the interface change in first and think about the IR rewrite next week). - I think there are some things in group_by that won't work with the current IR structure. I'll have some more thoughts on this in a bit.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4540:600,rewrite,rewrite,600,https://hail.is,https://github.com/hail-is/hail/pull/4540,2,['rewrite'],['rewrite']
Modifiability,@cseed @tpoterba I accidentally undid the caching behavior in the tests by using the name of input variables from their name in the environment instead of just using a default set of variable names. Should be much faster now.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5578:99,variab,variables,99,https://hail.is,https://github.com/hail-is/hail/pull/5578,2,['variab'],"['variable', 'variables']"
Modifiability,@cseed The part I am stuck on is the authentication for the router resolver. How does the batch2 instance in a test namespace get access to the real encryption key that the router resolver is expecting? Can you also double check the nginx configuration?,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6918:239,config,configuration,239,https://hail.is,https://github.com/hail-is/hail/pull/6918,1,['config'],['configuration']
Modifiability,"@danking I have a mostly completed draft for SAIGE in QoB. Can you take a look? I'm mainly looking for enough feedback to get a green light to actually start testing this end to end, fill in the remaining not implemented components, add documentation, add verbosity and possibly a dry run feature, and support VEP annotations natively. There are a couple of core concepts:; 1. Phenotypes - Set of phenotypes to test. I support the ability to group phenotypes together. This is in anticipation of a new version of SAIGE that Wei is going to release soon.; 2. VariantChunks - The set of variant intervals of data to test per job. If it's SAIGE-GENE, then there's also the ""groups"" to actually test within that interval.; 3. io - There's a bunch of wrappers that handle input and output files so all of that logic combined with the checkpointing logic is abstracted away from what is actually going on.; 4. steps - These are the SAIGE modules to run. They are all dataclasses with configuration options; 5. saige - There's a class that can be instantiated in Python or I started writing the framework for a CLI. This has the code that builds the DAG end to end. All configuration happens with a yaml file that can overwrite default parameters for each step such as whether to checkpoint or where the results should be written to. For the CLI, I envision you can either give a config file and/or specify `--overrides step1_null_glmm.use_checkpoint=true`. For every Saige run, I write out the configuration used to a file in the output directory as well as information about the input data and variant chunks and the batch information.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13804:978,config,configuration,978,https://hail.is,https://github.com/hail-is/hail/pull/13804,4,['config'],"['config', 'configuration']"
Modifiability,"@danking The latest version is the code in hail/methods/. I'm having trouble with all of the configs and how to instantiate that properly. After that, I need to figure out what inputs `run_saige` actually needs. Then I need to write util functions for creating the testing chunks and annotating the matrix table. Then I think after testing and cleaning it up, it will be sufficient for the workshop. To get it into main is going to be a lot more work to have helpful error messages, check MT is valid for this analysis, integrate it more carefully into QoB.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13588:93,config,configs,93,https://hail.is,https://github.com/hail-is/hail/pull/13588,1,['config'],['configs']
Modifiability,"@danking the changes in the router configuration for the blog are causing an infinite redirect loop when you try to go to https://blog.hail.is. I'd like to change them back to how they were before (I added the X-Real-IP line that was not in the original configuration, which I think is the change you were introducing in that PR, although I have no idea how that works.)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8107:35,config,configuration,35,https://hail.is,https://github.com/hail-is/hail/pull/8107,2,['config'],['configuration']
Modifiability,"@patrick-schultz your assignment was totally random!. Here is the code for TableDistinct:; ```scala; case class TableDistinct(child: TableIR) extends TableIR {. ... protected[ir] override def execute(hc: HailContext): TableValue = {; val prev = child.execute(hc); prev.copy(rvd = prev.rvd.distinctByKey()); }; }; ```. I suspect that if the RVD key is longer than the table `typ.key`, this is going to produce incorrect results.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4833:142,extend,extends,142,https://hail.is,https://github.com/hail-is/hail/issues/4833,1,['extend'],['extends']
Modifiability,"@tpoterba , can you take a look as well?. Notes:. 1. Azure uses Spark 3.0.2, so I need to build and publish a wheel for Spark 3.0.2.; 2. Azure provides Jupyter Notebooks already.; 3. hail/Makefile (for manual deploys) was missing some changes for deploy.sh, so I updated it.; 4. Azure sets the `AZURE_SPARK` environment variable inside hosted Jupyter Notebooks. 5. In Azure's Jupyter, if you set `extraClassPath` you break the extant classpath (e.g. you cannot load Scala stdlib classes). However, the JARs specified in `spark.jars` are added to the classpath properly, so, in Azure, it suffices to specify `spark.jars`. 6. Azure lacks requester pays, so I require Azure users download, untar, and upload the VEP files to their own bucket. 7. Instead of ""submit"", Azure installs Livy, a Java job-queue system. I have no idea how to set environment variables in Livy and Azure does not set AZURE_SPARK in Livy jobs; therefore, I search for `hdinsight` in the CLASSPATH.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11187:320,variab,variable,320,https://hail.is,https://github.com/hail-is/hail/pull/11187,2,['variab'],"['variable', 'variables']"
Modifiability,"@tpoterba @jbloom22 a few more things to fix for the workshop. I was using a too powerful kubernetes command to look up worker pods and services for the admin page. I now use a restricted form of it that is permitted by our security policy. We also are missing the non-preemptible node pool (!), so this adds that to our gcp-config. cc: @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4862:325,config,config,325,https://hail.is,https://github.com/hail-is/hail/pull/4862,1,['config'],['config']
Modifiability,"@tpoterba there is one minor implementation difference, wanted to check if you considered it too far afield: removed `PStringOptional` and `PStringRequired`. These are used in only 3 classes, and *Optional/Required classes are inconsistently used in the codebase anyways. By removing them we have fewer legacy constructors hanging off PArray.; * Furthermore, by adding the final class modifier to PCanonicalString, I'm not sure we can implement a case object in the same way (cannot extend PCanonicalString, which means places that expect a PType, like `StagedBlockLinkedListSuite.scala:159`, won't type check, if we simply make a PStringOptional with a constructor that calls `PCanonicalStruct()`)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7750:483,extend,extend,483,https://hail.is,https://github.com/hail-is/hail/pull/7750,1,['extend'],['extend']
Modifiability,"A `DependentFunCode` is a function that additionally depends on the particular type of its arguments, even if it is otherwise generic. This likely provides a path towards refactoring `TNumeric` as well. cc: @cseed @jigold",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2226:171,refactor,refactoring,171,https://hail.is,https://github.com/hail-is/hail/pull/2226,1,['refactor'],['refactoring']
Modifiability,"A few improvements:. 1. Show `n_partitions` in the ""Exploring Tables"" section. Fixes #7827 ; 2. Show `drop` in the ""Subset variables"" section (based on user question).; 3. Advertise `hl.plot.show` instead of `bokeh.io.show`. Fixes #7911",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7963:123,variab,variables,123,https://hail.is,https://github.com/hail-is/hail/pull/7963,1,['variab'],['variables']
Modifiability,"A forthcoming change to the hail ci system will introduce deployment. This change adds `hail-ci-deploy.sh` which replicates the [""Deploy Website""](https://ci.hail.is/admin/editRunType.html?id=buildType:HailSourceCode_HailMainline_DeployWebsite&runnerId=RUNNER_29) and [""Deploy Google Cloud""](https://ci.hail.is/admin/editRunType.html?id=buildType:HailSourceCode_HailMainline_DeployDocsAndGoogleCloudSpark220&runnerId=RUNNER_10) TeamCity jobs. My general thinking for deploy jobs from the CI is that, for the time being, we'll hardcode a mapping from GitHub repository to [Kubernetes Secret](https://kubernetes.io/docs/concepts/configuration/secret/). That's where this `/secret/ci.hail.is-web-updater-rsa-key` will come from. Moreover, the CI will always authorize a gcloud account (again with a baked in mapping from GitHub repository to GCP service account) before calling the deploy script. I did not retest the master branch here. Should we do that even though a PR is only merged to master if it passes the tests? Even after locking down merging, there's still the possibility of CI bugs. cc: @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4220:627,config,configuration,627,https://hail.is,https://github.com/hail-is/hail/pull/4220,1,['config'],['configuration']
Modifiability,"A long-standing fixme in the LocalBackend was to not rely on HadoopFS, which we use with the SparkBackend for compatibility with dataproc and hdfs urls. By default, the HadoopFS doesn't understand gs urls. Users need to install the gcs-hadoop-connector (preinstalled in dataproc) to communicate with google cloud storage. Spark handles supplying credentials to the connector. Issue #13904 is caused by failing to properly supply the gcs-hadoop-connector with credentials in the LocalBackend. In the absence of config, the connector hangs while trying to fetch a token form a non-existant metadata server. The LocalBackend was designed to be a testing ground for lowered and compiled code that would eventually be run on batch, where we use the RouterFS. I propose a pragmatic fix for #13904 that ditches the HadoopFS for all but local filesystem access in the LocalBackend instead of identifying and fixing the root cause. In doing so, I made a couple of changes to how the RouterFS is configured: In the absence of the `HAIL_CLOUD` environment variable, RouterFS can handle gs and az urls iff credentials are not supplied. If the user supplies creditials, we use `HAIL_CLOUD` to decide which cloud to route to. fixes #13904",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14407:510,config,config,510,https://hail.is,https://github.com/hail-is/hail/pull/14407,3,"['config', 'variab']","['config', 'configured', 'variable']"
Modifiability,"A lot of changes here. A summary:; - This subsumes notebook, so I deleted notebook and renamed notebook2 => notebook. Apologies, this makes the diff slightly harder to read.; - Added a simple messaging framework, stored in aiohttp session cookie, set message with `set_message`, handled by web_common by `base_context` by the default layout,; - Added notebook.hail.is/workshop-admin to manage and enable/disabled workshops. Workshops stored in the database.; - Workshop will be located at notebook.hail.is/workshop (I will move to workshop.hail.is as a later step); - Meta change: don't try to track dependencies on `make check` everywhere, it isn't really needed and it wasn't correct; - Rewrote code to monitor the spin up of notebooks: store notebook state in the database. I'm happy with how it turned out, it will be simpler and more reliable.; - I refactored the auth code to support the needs of workshops. I think it is also improved: simpler. Things left to do:; - ~~Port the load test code. And load test!~~; - The notebook link shouldn't be click-able if the notebook isn't ready. (Even better: If you click, launch the notebook when it is ready.); - ~~Didn't test the error case (when the notebook isn't actually available). This probably needs some work, and should get integrated into the message framework.~~; - The workshop header is a bit spare. Maybe add a slash (/) link. What would it link to?; - ~~Move notebook.hail.is/workshop to workshop.hail.is~~; - (low-prio) Finally, when the notebook state changes, we just refresh the page. Might be nice to just dynamically update HTML. Maybe react?; - (unrelated) The message framework should get used by the other services. @tpoterba I'm assigning this to you since you're point for the workshop. @akotlar knows this code if you want to re-assign. I gave you an account in my namespace, so you should be able to see/play with this at internal.hail.is/cseed/notebook. FYI @akotlar",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7112:854,refactor,refactored,854,https://hail.is,https://github.com/hail-is/hail/pull/7112,1,['refactor'],['refactored']
Modifiability,"A simple but powerful extension requested by @alexb-3 and Christina to allow for synthetic genotypes with very general and realistic-looking PCA plots with [redacted]. Alex pointed out that BaldingNichols is special case of PritchardStephensDonnelly in a degenerate sense, just as one-hot encoded `Categorical(p_1,...,p_k)` is the distributional limit of `Dirichlet(a * p_1,..., a * p_k)` as `a` goes to 0. So the substantive changes took about 10 lines. It's turned on by the `mixture` parameter which defaults to False and is marked as experimental. `True` means treat `pop_dist` as the parameters of Dirichlet rather than Categorical. @alexb-3 , it'd be great if you and Christina could experiment with it and extend the documentation accordingly. Once we have that, I'll add tests and remove ""experimental"". The plots below are already quite convincing. ```; import hail as hl; import matplotlib.pyplot as plt. mt = hl.balding_nichols_model(3, 500, 50, pop_dist=[0.01, 0.02, 0.05], fst=[.2, .3, .5]); _, pcs, _ = hl.hwe_normalized_pca(mt, 3); plt.scatter(pcs.PC1.collect(), pcs.PC2.collect()); ```. ![ex0](https://user-images.githubusercontent.com/3201642/37743475-a470a372-2d40-11e8-894c-5ed0d74f3d14.png). ```; mt = hl.balding_nichols_model(3, 500, 50, pop_dist=[0.01, 0.02, 0.05], fst=[.2, .3, .5], mixture=True); ```. ![ex1](https://user-images.githubusercontent.com/3201642/37743104-decf0da8-2d3e-11e8-8d43-3e36f194fa8e.png). ```; mt = hl.balding_nichols_model(3, 500, 50, pop_dist=[0.1, 0.2, 0.5], fst=[.2, .3, .5], mixture=True); ```. ![ex2](https://user-images.githubusercontent.com/3201642/37743108-e2e4cfe0-2d3e-11e8-9860-724de2c6611c.png)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3206:713,extend,extend,713,https://hail.is,https://github.com/hail-is/hail/pull/3206,1,['extend'],['extend']
Modifiability,"A small bit of refactoring. I've moved schema and math for both LinearRegression and LinearRegressionMultiPheno to the LinearRegressionModel class, and now fit returns LinearRegressionStats which in turn have toAnnotation functions. This provides better separation of data prep and annotation from core math, in line with structure of LogisticRegression(Model), and sets stage for next step of generalizing genotype field. I've left LinearRegression3 as is for now, full consolidation may wait until 0.2.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2007:15,refactor,refactoring,15,https://hail.is,https://github.com/hail-is/hail/pull/2007,1,['refactor'],['refactoring']
Modifiability,"A test timed out with this in the logs. This is some driver job. It just hangs for 2 minutes trying to talk to Azure Blob Storage presumably? Let us get some more information:. ```; 2023-06-08 20:22:28.209 JVMEntryway: INFO: Yielding control to the QoB Job.; 2023-06-08 20:22:28.210 Tokens: INFO: tokens found for namespaces {pr-12991-default-ei61x1qrplk9}; 2023-06-08 20:22:28.210 tls: INFO: ssl config file found at /batch/240df6ec091b49d8a6062b781e6700d3/secrets/ssl-config/ssl-config.json; 2023-06-08 20:24:30.873 : INFO: RegionPool: initialized for thread 10: pool-2-thread-2; 2023-06-08 20:24:31.016 ServiceBackend$: INFO: executing: iaU8w3QX6Y6hRrB9jczJds ArrayBuffer((), is.hail.utils.SerializableHadoopConfiguration@5ad5cde6); 2023-06-08 20:24:31.153 : INFO: JSON: JObject(List((name,JString(TableFilterPartitions)), (parts,JArray(List(JInt(0)))), (keep,JBool(true)))); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13157:397,config,config,397,https://hail.is,https://github.com/hail-is/hail/pull/13157,3,['config'],['config']
Modifiability,"A very small PR but here's the background and context behind this change. When talking to either GCP or Azure, hail chooses credentials in the following order from highest priority to lowest priority:. 1. An explicit `credential_file` argument passed to the relevant credentials class; 2. An environment variable containing the path to the credentials (`GOOGLE_APPLICATION_CREDENTIALS` or `AZURE_APPLICATION_CREDENTIALS`) (from this you can see why the code that was here is totally redundant); 3. The latent credentials present on the machine. This might be `gcloud` or `az` credentials, or the metadata server if you're on a cloud VM. I'm trying to rid the codebase of most explicit providing of credentials file paths, for two reasons:; - Quality of life. I'm already signed into the cloud with `gcloud` and `az`. I shouldn't need to download some file and provide `AZURE_APPLICATION_CREDENTIALS` to run this test. It should just use the latent credentials.; - We are trying to phase out credentials files altogether for security reasons. These files are long-lived secrets that you really don't want to leak and are currently exposed to users in Batch jobs, so they can be easily exfiltrated. Using the latent credentials on a cloud VM (the metadata server) has the benefit of only issuing short-lived access tokens which last for hours not months, so it's basically always better to use the latent credentials when possible.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13981:304,variab,variable,304,https://hail.is,https://github.com/hail-is/hail/pull/13981,1,['variab'],['variable']
Modifiability,"A very uninteresting PR but just to show you more bits of the codebase that are relevant to our earlier `python-dill` bug. We publish a small collection of images in DockerHub that users can use, like `python-dill` and a `hail` image that includes the whole hail pip package. You can use these like `j.image('hailgenetics/hail')`. However, DockerHub sets severe rate limits that would throttle a large batch from pulling those images on N workers for sufficiently large N. So, we mirror these images in our private image registry in GCP / Azure. If a user submits a job with one of these images, we instead pull from our own registry instead. This script does the mirroring from DockerHub -> internal registry. All I did in this PR is refactor the script. I don't honestly know why I used two lists instead of one, there was probably at one point some difference in how these images were handled that got deleted.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12231:735,refactor,refactor,735,https://hail.is,https://github.com/hail-is/hail/pull/12231,1,['refactor'],['refactor']
Modifiability,"A/pylint) from 2.6.0 to 2.12.2.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/PyCQA/pylint/releases"">pylint's releases</a>.</em></p>; <blockquote>; <h2>pylint-2.8.1</h2>; <ul>; <li>; <p>Add numversion back (temporarily) in <code>__pkginfo__</code> because it broke Pylama and revert the unnecessary; <code>pylint.version</code> breaking change.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/4399"">#4399</a></p>; </li>; </ul>; <h2>pylint-2.8.0</h2>; <ul>; <li>; <p>New refactoring message <code>consider-using-with</code>. This message is emitted if resource-allocating functions or methods of the; standard library (like <code>open()</code> or <code>threading.Lock.acquire()</code>) that can be used as a context manager are called without; a <code>with</code> block.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/3413"">#3413</a></p>; </li>; <li>; <p>Resolve false positives on unused variables in decorator functions</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/4252"">#4252</a></p>; </li>; <li>; <p>Add new extension <code>ConfusingConsecutiveElifChecker</code>. This optional checker emits a refactoring message (R5601 <code>confusing-consecutive-elif</code>); if if/elif statements with different indentation levels follow directly one after the other.</p>; </li>; <li>; <p>New option <code>--output=&lt;file&gt;</code> to output result to a file rather than printing to stdout.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/1070"">#1070</a></p>; </li>; <li>; <p>Use a prescriptive message for <code>unidiomatic-typecheck</code></p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/3891"">#3891</a></p>; </li>; <li>; <p>Apply <code>const-naming-style</code> to module constants annotated with; <code>typing.Final</code></p>; </li>; <li>; <p>The packaging is now done via s",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11461:1045,variab,variables,1045,https://hail.is,https://github.com/hail-is/hail/pull/11461,2,['variab'],['variables']
Modifiability,"AFAIK, we do not use this file and it confuses Emacs. Emacs uses this configuration; instead of the one at the root of the repository.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9465:70,config,configuration,70,https://hail.is,https://github.com/hail-is/hail/pull/9465,1,['config'],['configuration']
Modifiability,"Add `product` option to `Table.index`, and `MatrixTable.{index_rows, index_cols}`. Supports interval joins. Refactored the index methods to reduce code duplication, and make them more consistent with each other. Only case not supporting `product=True` is annotating columns of a matrix table with an interval keyed table.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5937:108,Refactor,Refactored,108,https://hail.is,https://github.com/hail-is/hail/pull/5937,1,['Refactor'],['Refactored']
Modifiability,"Add a codegen method `SNDArray.coiterate`, with signature; ```; def coiterate(cb: EmitCodeBuilder, region: Value[Region], indexVars: IndexedSeq[String], arrays: IndexedSeq[(SNDArrayCode, IndexedSeq[Int], String)], body: IndexedSeq[SSettable] => Unit, deepCopy: Boolean): Unit; ```; For example, the index expression `A[i, j] += B[j]` would be written; ```; coiterate(cb, region, Seq(""i"", ""j""), Seq((A, Seq(0, 1), ""A""), (B, Seq(1), ""B"")), {; case Seq(a, b) => cb.assign(a, SCode.add(cb, a, b)); }); ```; This generates a loop nest, with one loop per variable in `indexVars`. The inner loop is `indexVars(0)`, so that column major traversal is when index variables are increasing, as in `(A, Seq(0, 1), ""A"")`. Each index variable iterates over a dimension, with the size of the dimension inferred from its use. In the inner loop, each index variable `i0, i1, ...` has a value; `body` is run, with each of the `SSettable`s bound to an element of the corresponding input in `arrays`. For example, if the first element of `arrays` is `(A, IndexedSeq(1, 3), ""A"")`, then the `SSettable` will be the element of `A` at index `(i1, i3)`. However, it avoids computing the address of each element from the indices from scratch in the inner loop. This was motivated by the need to generate operations on ndarrays in the local whitening aggregator. I replaced a few uses of `forEachIndex` with `coiterate`, which may give a performance boost since it avoids index math in the inner loop.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10583:549,variab,variable,549,https://hail.is,https://github.com/hail-is/hail/pull/10583,4,['variab'],"['variable', 'variables']"
Modifiability,Add convenience method to dummy code categorical variables,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14269:49,variab,variables,49,https://hail.is,https://github.com/hail-is/hail/pull/14269,1,['variab'],['variables']
Modifiability,Add domain to the deploy config.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9791:25,config,config,25,https://hail.is,https://github.com/hail-is/hail/pull/9791,1,['config'],['config']
Modifiability,Add rewrite rule to combine MatrixFilterEntries nodes,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4548:4,rewrite,rewrite,4,https://hail.is,https://github.com/hail-is/hail/pull/4548,1,['rewrite'],['rewrite']
Modifiability,Add rewrite rule to optimize a common case of Literal array contains,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5660:4,rewrite,rewrite,4,https://hail.is,https://github.com/hail-is/hail/pull/5660,1,['rewrite'],['rewrite']
Modifiability,Add struct rewrite tests,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3675:11,rewrite,rewrite,11,https://hail.is,https://github.com/hail-is/hail/pull/3675,1,['rewrite'],['rewrite']
Modifiability,Added infrastructure for user-configured type printout.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2775:30,config,configured,30,https://hail.is,https://github.com/hail-is/hail/pull/2775,1,['config'],['configured']
Modifiability,Added required hail.vep.fasta VEP configuration property.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1435:34,config,configuration,34,https://hail.is,https://github.com/hail-is/hail/pull/1435,1,['config'],['configuration']
Modifiability,"Adding a new compiler pass (lowering MatrixIR to TableIR) exposed a problem in Simplify. The logic for preventing some simplifications from triggering if they would introduce non-determinism was broken, and fixing it required a pretty complete overhaul. Fortunately, I think it's now a lot simpler. Besides the rewrite of the high level Simplify architecture, I also:; * Changed `testRepartitioningSimplifyRules` to something that failed in the old version.; * Changed the `copy` signature on the IR hierarchy to be more precise (to avoid unnecessary coercions).; * Grouped the Simplify rules into IR, MatrixIR, and TableIR. After the reorganization, a couple of rule redundancies became evident.; * A couple of vals in PruneSuite required running the compiler. When I had a bug in Simplify, this was causing the test runner to fail before any tests were run, on class initialization of PruneSuite, which gives very little help in diagnosing the issue. I made them lazy vals to prevent this in the future.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4564:311,rewrite,rewrite,311,https://hail.is,https://github.com/hail-is/hail/pull/4564,1,['rewrite'],['rewrite']
Modifiability,Adding configuration flag to hailctl dataproc submit,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7586:7,config,configuration,7,https://hail.is,https://github.com/hail-is/hail/pull/7586,1,['config'],['configuration']
Modifiability,Adding doc for linreg in its current form. This doc will evolve as we add more features.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/198:57,evolve,evolve,57,https://hail.is,https://github.com/hail-is/hail/pull/198,1,['evolve'],['evolve']
Modifiability,"Addressing what we discussed in lowering meeting yesterday. I've refactored TableStage to accumulate a bunch of let bindings that can be wrapped around the IR you want to generate with `TableStage.wrapInBindings`. See `TableCollect` for an example of this. This definitely generates the IR we wanted, but I'd be very open to suggestions about how to make this more ergonomic to use (had to generate a lot of UIDs and Refs manually for `TableParallelize`). . cc @cseed @tpoterba",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8627:65,refactor,refactored,65,https://hail.is,https://github.com/hail-is/hail/pull/8627,1,['refactor'],['refactored']
Modifiability,"Adds `copy_spark_log_on_error` init configuration option. When true, driver logs are copied to the remote tmpdir if an error occurs. This is useful in support cases where users cannot copy logs off the dataproc server themselves as it has already shut down.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14447:36,config,configuration,36,https://hail.is,https://github.com/hail-is/hail/pull/14447,1,['config'],['configuration']
Modifiability,"Adds functionality for CI to track which namespaces in the cluster are currently active and which services they are running. See #12095 for more context on the motivation for this change. As an added bonus, this is one step toward more flexible internal namespace management, i.e. automatic cleanup of dev namespaces or keeping PR namespaces open for X days.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12093:236,flexible,flexible,236,https://hail.is,https://github.com/hail-is/hail/pull/12093,1,['flexible'],['flexible']
Modifiability,"Adds support for using mkl, which is needed for some of the added lapack methods. To use, install mkl, then set the environment variable `HAIL_MKL_PATH` to the directory containing the mkl dylib files. In particular, it should contain `libmkl_rt.dylib`. On my laptop, I installed mkl through conda with `conda install -c intel mkl`, then set `HAIL_MKL_PATH=~/opt/miniconda3/envs/hail/lib/`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10770:128,variab,variable,128,https://hail.is,https://github.com/hail-is/hail/pull/10770,1,['variab'],['variable']
Modifiability,Adds the `docker_root_image` to the global config in `build.py` so that #10107 can pass CI tests without manually redeploying CI.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10340:43,config,config,43,https://hail.is,https://github.com/hail-is/hail/pull/10340,1,['config'],['config']
Modifiability,"Adds the ability to rerun/retry queries from the nearest `CollectDistributedArray` (`CDA`) IR site. Computes a ""Semantic Hash"" of the top-level IR, which is split and shared among the various constituent `CDA` calls in a query. The `CDA` procedure looks in an execution cache for the results of each partition for that call and uses/updates the cache with successful partition computations. . The nature of the staged- lower and execute model means we don't know how many `CDA` calls that will be generated ahead of time. Thus we treat the ""Semantic Hash"" in a similar way to an RNG state variable and generate a key from the Semantic Hash every time every time we encounter a `CDA`. Since an `ExecutionContext` is re-used for multiple queries in tests while a `SemanticHash` is coupled to one query, the two were kept separate. To minimise the amount of manual state handling, the code was transformed to use a ""State"" monad (abstracted as `MonadLower`). Since the `ExecuteContext` is used nearly everywhere the semantic hash is required, the `ExecuteContext` was absorbed into the `MonadLower` interface. `Lower` is a simple, concrete instance of `MonadLower`, and is used to adapt statements into `MonadLower` expressions.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13194:589,variab,variable,589,https://hail.is,https://github.com/hail-is/hail/pull/13194,2,"['adapt', 'variab']","['adapt', 'variable']"
Modifiability,"Adds the ability to rerun/retry queries from the nearest `CollectDistributedArray` (`CDA`) `IR` site. Computes a ""Semantic Hash"" of the top-level `IR` which is used to generate a key for the various constituent `CDA` calls in a query. The implementation for CDA, `BackendUtils.collectDArray`, uses that key to look into an the execution cache for the results of each partition for that call and uses/updates the cache with successful partition computations. The nature of the staged- lower and execute model means we don't know how many `CDA` calls that will be generated ahead of time. Thus we treat the ""Semantic Hash"" in a similar way to an RNG state variable and generate a key from the Semantic Hash every time every time we encounter a `CDA`. The execution cache is implemented on-top of a local or remote filesystem (configurable via the `HAIL_CACHE_DIR` environment variable). This defaults to `{tmpdir}/hail/{pip-version}`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12954:654,variab,variable,654,https://hail.is,https://github.com/hail-is/hail/pull/12954,3,"['config', 'variab']","['configurable', 'variable']"
Modifiability,"After spending a few hours digging through log4j and trying a bunch of approaches, I wasn't able to fix our current approach of adding appenders to the consoleLog after log4j has already been configured. Instead, we set up log4j in initial configuration to have the appenders we want. Also moved logging config from HailContext to backend, where it should be. . Storing the StringSocketAppender on the static object is definitely a bit funky, but it's being allocated inside log4j and I don't see a simpler way to store it for retrieval later.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12783:192,config,configured,192,https://hail.is,https://github.com/hail-is/hail/pull/12783,3,['config'],"['config', 'configuration', 'configured']"
Modifiability,"After this, there are only 150ish warnings remaining, which shouldn't be too hard to fix by hand. Most are unused locals. Scalafix can delete unused locals, but I disable that, because there were too many cases where it left the rhs unnecessarily, e.g.; ```; ...; val idx = Symbol(genUID()); ...; ```; rewrites to; ```; ...; Symbol(genUID()); ...; ```; I'd rather just leave those as errors to be fixed manually. This is intended to replace #14103, which ended up mixing manual changes to fix warnings with scalafix changes.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14156:302,rewrite,rewrites,302,https://hail.is,https://github.com/hail-is/hail/pull/14156,1,['rewrite'],['rewrites']
Modifiability,"Ajupyter%2Fnotebook+involves%3Ameeseeksmachine+updated%3A2023-10-17..2024-01-19&amp;type=Issues""><code>@​meeseeksmachine</code></a></p>; <!-- raw HTML omitted -->; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/jupyter/notebook/commit/80e992e9f4cfa6cc1fcf4d84cebe09d53e769790""><code>80e992e</code></a> Publish 7.0.7</li>; <li><a href=""https://github.com/jupyter/notebook/commit/089c78c48fd00b2b0d2f33e4463eb42018e86803""><code>089c78c</code></a> Update to JupyterLab 4.0.11 (<a href=""https://redirect.github.com/jupyter/notebook/issues/7215"">#7215</a>)</li>; <li><a href=""https://github.com/jupyter/notebook/commit/109ba7578886283ad7be54d189904132bd7bb6f0""><code>109ba75</code></a> Backport PR <a href=""https://redirect.github.com/jupyter/notebook/issues/7176"">#7176</a>: Update publish-release workflow for PyPI trusted publisher...</li>; <li><a href=""https://github.com/jupyter/notebook/commit/d252423198e3bce218fd4c370a706f373dcb4c78""><code>d252423</code></a> Update ruff config and typing (<a href=""https://redirect.github.com/jupyter/notebook/issues/7145"">#7145</a>) (<a href=""https://redirect.github.com/jupyter/notebook/issues/7186"">#7186</a>)</li>; <li><a href=""https://github.com/jupyter/notebook/commit/d2ef92f0b385b7ecd11cbf0f3af181ee8e494623""><code>d2ef92f</code></a> Backport PR <a href=""https://redirect.github.com/jupyter/notebook/issues/7142"">#7142</a>: Clean up lint handling (<a href=""https://redirect.github.com/jupyter/notebook/issues/7185"">#7185</a>)</li>; <li><a href=""https://github.com/jupyter/notebook/commit/8e9390d9af903f34bb1c8414c7e9b49d2fdec32f""><code>8e9390d</code></a> Backport PR <a href=""https://redirect.github.com/jupyter/notebook/issues/7132"">#7132</a>: Adopt ruff format (<a href=""https://redirect.github.com/jupyter/notebook/issues/7184"">#7184</a>)</li>; <li><a href=""https://github.com/jupyter/notebook/commit/4d07f1ee9b6d3dca2736e2bf3a1254451add8259""><code>4d07f1e</code></a> Install stable JupyterLab 4",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14182:6653,config,config,6653,https://hail.is,https://github.com/hail-is/hail/pull/14182,1,['config'],['config']
Modifiability,All these classes inherit from `Resource` which is an `abc.ABC`.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13541:18,inherit,inherit,18,https://hail.is,https://github.com/hail-is/hail/pull/13541,1,['inherit'],['inherit']
Modifiability,"Almost every call to these methods was just casting the values to codes anyway, and using a list of values makes more sense. In the future, we are almost definitely going to want to change this so the method just directly takes in a `PTupleValue` so that we aren't making variables per dimension of the ndarray all the time.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9302:272,variab,variables,272,https://hail.is,https://github.com/hail-is/hail/pull/9302,1,['variab'],['variables']
Modifiability,"Already done:; - Made a public bucket in us-central1 with requester pays on (gs://qob-vep-grch37-us-central1); - Uploaded the configuration file for grch37 in us-central1 to gs://hail-common/qob-vep/; - Documentation. To-Do items:; - Mirror the loftee base image in our artifact registry; - Replicate the data in Azure and create an Azure configuration file (can't make this requester pays, so not sure what to do here); - Add instructions for setting up a config file in the respective infra READMEs; - Write tests; - Get GRCh38 working; - Modify the cloud run functions for ACR cleanup to cleanup the vep-grch37 and eventually vep-grch38 images",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12428:126,config,configuration,126,https://hail.is,https://github.com/hail-is/hail/pull/12428,3,['config'],"['config', 'configuration']"
Modifiability,"Alright, I snagged the PR namespace from the CI:. ```; pr-13135-default-u5tt5011yt5w; ```. Then I went to the Azure [Log Analytics workspace haildev-logs](https://portal.azure.com/#@haildev.onmicrosoft.com/resource/subscriptions/22cd45fe-f996-4c51-af67-ef329d977519/resourceGroups/haildev/providers/Microsoft.OperationalInsights/workspaces/haildev-logs/logs). I went to ""Queries"", selected ""DK's AKS Pod Logs"", modified the namespace to the aforementioned one, and added a filter for ""hail-az://"". ```; let startTimestamp = ago(2h);; KubePodInventory; | where TimeGenerated > startTimestamp; | extend PodName=Name; | where Namespace == ""pr-13135-default-u5tt5011yt5w"" and PodName startswith ""batch-driver""; | distinct ContainerID, PodName, Namespace; | join (; ContainerLog; | where TimeGenerated > startTimestamp; ) on ContainerID; | project TimeGenerated, message=parse_json(LogEntry).message, LogEntry=parse_json(LogEntry); | where message contains ""hail-az://""; | order by TimeGenerated desc; ```. That revealed the batch logs path:. ```; EXAMPLE BATCH_JOB_LOGS_PATH hail-az://haildevtest/test/batch/logs/we5a79QlczzdluUx8kT2Vh/batch/1/1/abc123/main/log; ```. In the [failing PR test job logs](https://ci.azure.hail.is/batches/3956877/jobs/152), I found the batch id:. ```; [2023-06-09 12:43:34] test/hail/methods/test_impex.py::BGENTests::test_import_bgen_row_fields; -------------------------------- live log call ---------------------------------; INFO batch_client.aioclient:aioclient.py:753 created batch 1148. INFO batch_client.aioclient:aioclient.py:770 updated batch 1148. FAILED; ```. I listed the job logs:. ```; (base) dking@wm28c-761 hail % az storage blob list --account-name haildevtest --container test --prefix batch/logs/we5a79QlczzdluUx8kT2Vh/batch/1148/ -o table; Name Blob Type Blob Tier Length Content Type Last Modified Snapshot; ----------------------------------------------------------------------------- ----------- ----------- -------- ------------------------ ---------",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13160:594,extend,extend,594,https://hail.is,https://github.com/hail-is/hail/pull/13160,1,['extend'],['extend']
Modifiability,"Alright, so the goal of this PR is to make this work:. ```; HAIL_QUERY_BACKEND=service \; python3 -c 'import hail as hl; hl.utils.range_table(10).write(""gs://foo/bar.t"")`; ```. In particular, the Hail Query JAR is stored in a well known location. If we know the desired git revision, (we do, it should be the same git revision as our wheel), then we can deduce the JAR URL for the user. Moreover, if we're pointed at a namespace, we can still determine the correct location [1]. This PR provides three escape hatches to this behavior:; 1. Specify the `jar_url` parameter to `ServiceBackend`.; 2. Specify the `HAIL_JAR_URL` environment variable.; 3. Specify a JAR url in the user config: `hailctl config set query/jar_url gs://...`. This PR is unfortunately entangled with one other minor change. In `main`, we send the git revision *and* the JAR URL to the driver and the worker as a part of the ""command string"" (the JVMEntryway passes this array of strings to the `main` method of `ServiceBackendSocketAPI2` or `Worker`. After this change, the backend does not necessarily know the git revision. That's fine. The git revision was only ever used as:; 1. a cache key for the JAR cache, and; 2. a unique name for the JAR; Both of these uses are buggy anyway! If you re-use a HAIL_SHA with a different HAIL_JAR_URL and you land on a worker that previously pulled that HAIL_SHA, you'll get the previously pulled JAR, not the newly specified one. Instead I use the JAR URL directly as a cache key and unique name. ---. [1] Odds are good that the developer has not uploaded a JAR to this location, but they can do so by dev deploying `upload_query_jar` or by running `make -C query push-jar`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11643:635,variab,variable,635,https://hail.is,https://github.com/hail-is/hail/pull/11643,3,"['config', 'variab']","['config', 'variable']"
Modifiability,"Also may need to add back annotate_global_expr. Either way include these examples which used to be un the FAQ:. **How do I access an annotation name with white-space in the Hail Expression Language?**. Put the annotation name in back ticks. ```; annotateglobal expr -c 'global.`my variable` = global.`lof count`'; ```. **How do I count the number of samples matching a phenotype annotation?**. ```; annotateglobal expr -c '; global.nMales = samples.count(sa.pheno.sex == ""Male""),; global.nFemales = samples.count(sa.pheno.sex == ""Female""),; global.nSamples = samples.count(true)'; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1349:281,variab,variable,281,https://hail.is,https://github.com/hail-is/hail/issues/1349,1,['variab'],['variable']
Modifiability,Also refactor BGEN ptype logic. stacked on #7941,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7943:5,refactor,refactor,5,https://hail.is,https://github.com/hail-is/hail/pull/7943,1,['refactor'],['refactor']
Modifiability,"Also, added hail.vep.extra_plugins for specifying additional plugins beyond the default ones (such as LoF_splice.pm for predicting variants' probability of splice junction disruption or creation)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1712:61,plugin,plugins,61,https://hail.is,https://github.com/hail-is/hail/pull/1712,1,['plugin'],['plugins']
Modifiability,Also... - fix inheriting from str so `join` will work; - fix Makefile for checking whether Batch files have been updated; - fix copying same input multiple times in LocalBackend,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5483:14,inherit,inheriting,14,https://hail.is,https://github.com/hail-is/hail/pull/5483,1,['inherit'],['inheriting']
Modifiability,An unfortunately large set of changes to enable `writeRows` on a `ContextRDD`. I took the chance to do a wee bit of refactoring between the write methods of `UnpartitionedRVD` and `OrderedRVD`.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3311:116,refactor,refactoring,116,https://hail.is,https://github.com/hail-is/hail/pull/3311,1,['refactor'],['refactoring']
Modifiability,"And `Batch`. Again, no code changes here. That's all for today. Monday I'll do one last refactor before I'm ready to start merging the DAG functionality.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4798:88,refactor,refactor,88,https://hail.is,https://github.com/hail-is/hail/pull/4798,1,['refactor'],['refactor']
Modifiability,"And use internally. This adds the bucket parameter/config setting, but doesn't require it, and falls back to getting the bucket from the user information. After this is released, I'll rip out the user bucket and make this mandatory.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8852:51,config,config,51,https://hail.is,https://github.com/hail-is/hail/pull/8852,1,['config'],['config']
Modifiability,Another small effort toward getting `gs://` out of our code. I'll follow up with a PR that puts the prod CI bucket into terraform. The `test_storage_uri` field of the global config was introduced in #11014,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11025:174,config,config,174,https://hail.is,https://github.com/hail-is/hail/pull/11025,1,['config'],['config']
Modifiability,"Another try at #10796. It's all the same excpet I've fixed the `test_cant_submit_to_default_with_other_ns_creds` test, which had been wiping the `deploy-config.json` after trying to read AND write to it. Now the test tries to change the `default_namespace` to `""default""`. This should succeed in the default namespace but is expected to fail in other namespaces.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10854:153,config,config,153,https://hail.is,https://github.com/hail-is/hail/pull/10854,1,['config'],['config']
Modifiability,"Apologies, this spiraled into a big PR. Hopefully the large set of changes actually improves everyone's understanding of this. ---. The goal of this PR is to make this work:. ```; HAIL_QUERY_BACKEND=service \; python3 -c 'import hail as hl; hl.utils.range_table(10).write(""gs://foo/bar.t"")`; ```. In particular, a normal user should not need to know the location of a Hail Query JAR. Currently, you must specify two environment variables: `HAIL_SHA` and `HAIL_JAR_URL`. This PR takes advantage of the well known location of a Hail Query JAR [1]. We use the newly introduced `hl.revision()` to determine the SHA-1 of the currently installed Hail. This PR includes the revision in the driver job spec. The front end has been modified to convert the revision into a cloud storage URL. This PR also provides three escape hatches to the aforementioned default behavior. These escape hatches should more or less only be used by developers. They're specified from highest priority to lowest.; 1. Specify the `jar_url` parameter to `ServiceBackend`.; 2. Specify the `HAIL_JAR_URL` environment variable.; 3. Specify a JAR url in the user config: `hailctl config set query/jar_url gs://...`. While writing this PR, I decided to clean up five bits of cruft I left when I first built the service backend. First, I took the JAR URL out of the ""command"" of the job spec. This ""command"" is just an array of strings. The fact that certain parts of that array *must* be the JAR URL and the SHA-1 is confusing. Instead, there are now two keys in a JVM process specification:; 1. `jar_spec`, which may be either `{""type"": ""jar_url"", ""value"": ""gs://..../abc123....jar""}` or `{""type"":""git_revision"", ""value"": ""abc123...""}`.; 2. `argv`, an opaque list of strings which are passed, by the JVMEntryway, along with a few more args, to `is.hail.backend.service.Main`. The `Main` class dispatches to either `ServiceBackendSocketAPI2` or the `Worker` based on the first element of `argv`. Each class expects different contents in",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11645:428,variab,variables,428,https://hail.is,https://github.com/hail-is/hail/pull/11645,1,['variab'],['variables']
Modifiability,"Applies the most restrictive bind and event propagation settings to job container mounts. While user jobs do not have the capabilities to create mount points, overlapping mount points in the container config can inadvertently trigger mount propagation back to the host which we just never want.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12960:201,config,config,201,https://hail.is,https://github.com/hail-is/hail/pull/12960,1,['config'],['config']
Modifiability,"Apt-get update does not use the retries parameter used by; apt-get install. In fact, I could not find any retry configuration; for apt-get update. This is a cheap hack that retries 5 times with; exponential back-off.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9722:112,config,configuration,112,https://hail.is,https://github.com/hail-is/hail/pull/9722,1,['config'],['configuration']
Modifiability,Array.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at is.hail.expr.ir.Emit.$anonfun$emitVoid$4(Emit.scala:644); 	at is.hail.expr.ir.Emit.$anonfun$emitVoid$4$adapted(Emit.scala:643); 	at is.hail.expr.ir.EmitCodeBuilder$.scoped(EmitCodeBuilder.scala:18); 	at is.hail.expr.ir.EmitCodeBuilder$.scopedVoid(EmitCodeBuilder.scala:28); 	at is.hail.expr.ir.EmitMethodBuilder.voidWithBuilder(EmitClassBuilder.scala:1011); 	at is.hail.expr.ir.Emit.$anonfun$emitVoid$3(Emit.scala:643); 	at is.hail.expr.ir.Emit.$anonfun$emitVoid$3$adapted(Emit.scala:641); 	at scala.collection.Iterator.foreach(Iterator.scala:943); 	at scala.collection.Iterator.foreach$(Iterator.scala:943); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1431); 	at is.hail.expr.ir.Emit.emitVoid(Emit.scala:641); 	at is.hail.expr.ir.Emit$.$anonfun$apply$3(Emit.scala:70); 	at is.hail.expr.ir.Emit$.$anonfun$apply$3$adapted(Emit.scala:68); 	at is.hail.expr.ir.EmitCodeBuilder$.scoped(EmitCodeBuilder.scala:18); 	at is.hail.expr.ir.EmitCodeBuilder$.scopedVoid(EmitCodeBuilder.scala:28); 	at is.hail.expr.ir.EmitMethodBuilder.voidWithBuilder(EmitClassBuilder.scala:1011); 	at is.hail.expr.ir.Emit$.apply(Emit.scala:68); 	at is.hail.expr.ir.Compile$.apply(Compile.scala:78); 	at is.hail.expr.ir.CompileAndEvaluate$.$anonfun$_apply$1(CompileAndEvaluate.scala:50); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.CompileAndEvaluate$._apply(CompileAndEvaluate.scala:50); 	at is.hail.expr.ir.CompileAndEvaluate$.evalToIR(CompileAndEvaluate.scala:30); 	at is.hail.expr.ir.LowerOrInterpretNonCompilable$.evaluate$1(LowerOrInterpretNonCompilable.scala:30); 	at is.hail.expr.ir.LowerOrInterpretNonCompilable$.rewrite$1(LowerOrInterpretNonCompilable.scala:67); 	at is.hail.expr.ir.LowerOrInterpretNonCompilable$.apply(LowerOrInterpretNonCompilable.scala:72); 	at is.hail.expr.ir.lowering.Lo,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12531:7331,adapt,adapted,7331,https://hail.is,https://github.com/hail-is/hail/issues/12531,1,['adapt'],['adapted']
Modifiability,ArrayExpression.extend doesn't do type promotion in scala,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2691:16,extend,extend,16,https://hail.is,https://github.com/hail-is/hail/issues/2691,1,['extend'],['extend']
Modifiability,"ArrayFunctions:. - [ ] extend; - [ ] argF; - [ ] uniqueIndex; - [ ] ""[]"" with negative argument; - [ ] ""[*:]""; - [ ] ""[:*]""; - [ ] ""[*:*]"". DictFunctions:. - [ ] contains; - [ ] get. SetFunctions:. - [ ] contains. StringFunctions:. - [ ] ""[*:]""; - [ ] ""[:*]""; - [ ] ""[*:*]"". UtilFunctions:. - [ ] min; - [ ] max",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4766:23,extend,extend,23,https://hail.is,https://github.com/hail-is/hail/issues/4766,1,['extend'],['extend']
Modifiability,"As a step towards coralling the specification of the binding structure of the IR into one place, this rewrites `Bindings` to use only a single method of the `GenericBindingEnv` interface, `newBlock`, which therefore captures all possibilities of how a node can modify its parent's environment in a child. Later work refactors this to return an object encoding this modification, instead of returning a modified environment, which allows the caller complete flexibility in how to maintain an environment appropriately for their use case. This PR leaves in the old `Bindings` implementation, with an assertion that they agree. The PR stacked above this, #14495, deletes the old implementation. This way CI asserts that this refactoring hasn't changed any behavior.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14475:102,rewrite,rewrites,102,https://hail.is,https://github.com/hail-is/hail/pull/14475,3,"['refactor', 'rewrite']","['refactoring', 'refactors', 'rewrites']"
Modifiability,"As currently written, if `git clone` returns a non-zero exit code, the script; should exit immediately. I am not sure why this GnuTLS recv error (pasted below); does not trigger a non-zero exit code from git clone. This change both; explicitly echoes the exit code so we can be sure of our sanity and adds a check; that I'm confident will fail if no git repository was cloned (`git status`). ```; + date; Wed Apr 29 21:15:15 UTC 2020; + rm -rf repo; + mkdir repo; + cd repo; + '[' '!' -d .git ']'; + retry clone; + clone; + set -e; ++ mktemp -d; + dir=/tmp/tmp.5R5aJAlgEm; + git clone https://github.com/hail-is/hail.git /tmp/tmp.5R5aJAlgEm; Cloning into '/tmp/tmp.5R5aJAlgEm'...; error: RPC failed; curl 56 GnuTLS recv error (-54): Error in the pull function.; fatal: The remote end hung up unexpectedly; fatal: early EOF; fatal: index-pack failed; ++ ls -A /tmp/tmp.5R5aJAlgEm. real	0m0.998s; user	0m0.008s; sys	0m0.017s; + git config user.email ci@hail.is; fatal: not in a git directory; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8667:930,config,config,930,https://hail.is,https://github.com/hail-is/hail/pull/8667,1,['config'],['config']
Modifiability,"As of #14056, there is ambiguity when referring to the configuration value `domain`. - In the `global-config`, this is the root domain of the entire hail system. This is the same across all namespaces.; - In the `deploy-config` of a namespace N, this refers to the root domain served by applications of that namespace. In production (namespace `default`), this is `hail.is`, the same as the root domain of the entire system. In other namespaces, this is `internal.hail.is`. Setting the `HAIL_DOMAIN` environment variable in the k8s deployments from the `global-config` overrides what should be `internal.hail.is` to `hail.is`, breaking any form of redirection. There's really no need to set this environment variable at all, as its value can be derived from the `deploy-config`. This PR removes that environment variable. I tested this in my development namespace.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14164:55,config,configuration,55,https://hail.is,https://github.com/hail-is/hail/pull/14164,8,"['config', 'variab']","['config', 'configuration', 'variable']"
Modifiability,"As part of our work with generating All of Us datasets, we needed to copy around a million gcs objects. Our `Copier` infrastructure 'should' be able to handle that, but it kept falling with robustness issues. What finally worked was using GCS's [rewrite](https://cloud.google.com/storage/docs/json_api/v1/objects/rewrite) api. This allowed us to copy data without reading it, allowing the copies to complete in a fraction of the time while also reducing bandwidth needs. There are two components to this:; 1. Research what specific APIs we can take advantage of; 2. Update our code to use them when we can, for the `Copier`, and the new sync tool (#14248). Here's the code I used for making the rewrite requests for merging a set of matrix tables together, the progress bar code was for visibility. ```python3; async def rewrite(; gfs: GoogleStorageAsyncFS,; src: str,; dst: str,; progress: Optional[rich.progress.Progress] = None,; file_tid: Optional[rich.progress.TaskID] = None,; requests_tid: Optional[rich.progress.TaskID] = None,; ):; assert (progress is None) == (file_tid is None) == (requests_tid is None); src_bkt, src_name = gfs.get_bucket_and_name(src); dst_bkt, dst_name = gfs.get_bucket_and_name(dst); if not src_name:; raise IsABucketError(src); if not dst_name:; raise IsABucketError(dst); client = gfs._storage_client; path = (; f'/b/{src_bkt}/o/{urllib.parse.quote(src_name, safe="""")}/rewriteTo'; f'/b/{dst_bkt}/o/{urllib.parse.quote(dst_name, safe="""")}'; ); kwargs = {'json': '', 'params': {}}; client._update_params_with_user_project(kwargs, src_bkt); response = await retry_transient_errors(client.post, path, **kwargs); if progress is not None:; progress.update(requests_tid, advance=1); while not response['done']:; kwargs['params']['rewriteToken'] = response['rewriteToken']; response = await retry_transient_errors(client.post, path, **kwargs); if progress is not None:; progress.update(requests_tid, advance=1); if progress is not None:; progress.update(file_tid, advance=1)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14601:246,rewrite,rewrite,246,https://hail.is,https://github.com/hail-is/hail/issues/14601,7,['rewrite'],"['rewrite', 'rewriteTo', 'rewriteToken']"
Modifiability,"As stated in the GNU make manual, ""Recursive make commands should always; use the variable MAKE, not the explicit command name ‘make’"". https://www.gnu.org/software/make/manual/make.html#MAKE-Variable",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9525:82,variab,variable,82,https://hail.is,https://github.com/hail-is/hail/pull/9525,2,"['Variab', 'variab']","['Variable', 'variable']"
Modifiability,"Assigning @tpoterba since he (and cotton) have the most context to review this. A few preliminaries:. 1. I noticed the proxy headers were not quite right when you're testing this without SSL or on some non-standard port. `$host` does not include the port, `$http_host` does. `$scheme` returns `http` or `https` depending on how the user connected to gateway; 2. The admin privilege check was too restrictive, if `delete_worker_pod` is called by `/new` there's no need to check admin privs; 3. I realized that the timeout logic wasn't quite right because a misconfigured gateway (I was testing with a broken gateway config) will return 5xx codes, but that doesn't mean the server is alive. We probably should error here, but I'm hesitant to add new error modes so close to a tutorial. Ok, how does this work? Basically, if the gateway cannot connect to the notebook pod, we intercept the error and redirect the user to the ""create new notebook"" webpage. That webpage deletes whatever remains of the users previous notebook pod & service. Here are the pieces:. 1. `recursive_error_pages on;` the internet suggests that without this we cannot use `error_page` with an ""internal"" rule (the `@` rules are internal rules that users cannot directly access); 2. `proxy_connect_timeout` defaults to 60s which is a shit user experience if your pod dies. Honestly, I might set this to 100ms. This is all inside a datacenter.; 3. `proxy_intercept_errors` permits us to use `error_page` with 5xx errors from failing to connect to the proxy. ---. I tested this with a pile of hacks to deploy this into an anonymous namespace in `vdc`. I'm not ready to PR those changes, they need a clean up before others use them. Sometime next week I hope to get that in. Getting it requires some restructuring of `vdc/` and `gateway/` to be more modular.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4974:615,config,config,615,https://hail.is,https://github.com/hail-is/hail/pull/4974,1,['config'],['config']
Modifiability,"Assigning to Daniel 2 because the scorecard beacon is tired. This removes the workshop login option (previously agreed upon with Cotton), which makes the login.html page totally useless; so I've converted the login link to hit the old /login POST endpoint, and converted the POST to a GET. I think this is semantically fine, because no credentials (or other data) is actually sent to that endpoint (as workshop password is kaput), making that endpoint solely issue a redirect. Since login.html is gone, I also no longer redirect to it. Instead, unauthorized users are redirected to /error, and I refactored this redirect into a function since it's now used identically in 2 places. I've also imported the jwt library, so that jwt.exceptions.InvalidTokenError is in scope, and made some minor cleanup. cc @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6078:596,refactor,refactored,596,https://hail.is,https://github.com/hail-is/hail/pull/6078,1,['refactor'],['refactored']
Modifiability,"Associate a region with each ptype, and remove region parameterizations of ptype methods, including load*, is*Missing, allocate. Reference from Zulip:. Alex Kotlar: What is our long term plan for load* methods, and do we need their region parameterizations? I would love to understand the design proposal for these methods, in part because I want to document our allocation strategy in the ptype design doc (or maybe in a new design doc for regions). Observations:. Methods like loadElement (PContainer and inheritors) and loadField (PBaseStruct and inheritors) have region-taking parameterizations, but these methods are always wrappers for non-region parameterization (e.g loadElement(region, offset, idx) = loadElement(offset, idx)), which makes sense since our ""offsets"" are now memory addresses in these cases (can be read without knowledge of the region that allocated that memory). I believe historically these were really offsets into a region, requiring that region to load it. I believe the remaining use case, now that these offsets are absolute, is to allow for off-heap allocation. This seems slightly odd for a load operation/getter, but I am probably not seeing the intention. Thanks!. daniel king: The history is correct. daniel king: You may want a load to do allocation if you're loading from a lazy datastructure, like a lazily decoded BGEN genotype row. Alex Kotlar: ok, thanks Dan, will keep that parameterization as is. daniel king: You should check-in with Tim though, not clear that load is the place to do this. Tim Poterba: Yep, agree with Dan here. This was the reason I pushed back on your pr to remove the region args in December. Patrick Schultz: How would a lazily decoded datastructure work? Would it mutate to record the fact that some lazy value has already been computed? Or would it recompute every time that value is accessed?. Patrick Schultz: We probably want the former for performance, but we should figure out what the memory management for that looks like. P",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7826:54,parameteriz,parameterizations,54,https://hail.is,https://github.com/hail-is/hail/issues/7826,6,"['inherit', 'parameteriz']","['inheritors', 'parameterization', 'parameterizations']"
Modifiability,"At some point we started optimizing the MakeStruct to a SelectFields,; which is great, but not if it breaks important optimizations like the; avoid-a-shuffle rewrite rule!",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7073:158,rewrite,rewrite,158,https://hail.is,https://github.com/hail-is/hail/pull/7073,1,['rewrite'],['rewrite']
Modifiability,"At this point, every job that needs the private network specifies; it (https://github.com/hail-is/hail/pull/9380). This change moves jobs with; unspecified `network` to the private network. I removed the gce-deploy-config because jobs should not, by default, assume they; are on the private network. The GCE Deploy Config instructs you to enter GKE; using the internal-gateway, which is on our private network.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9744:215,config,config,215,https://hail.is,https://github.com/hail-is/hail/pull/9744,4,"['Config', 'config']","['Config', 'config']"
Modifiability,Awesome InsFields rewrite rules,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4374:18,rewrite,rewrite,18,https://hail.is,https://github.com/hail-is/hail/pull/4374,1,['rewrite'],['rewrite']
Modifiability,"Azure already has a Jupyter system in place, so I worked within that. As a result, I took a very different approach from `hailctl dataproc`. I'm not sure how many of the configuration settings done in `hailctl dataproc` are necessary in Azure. I also do not plan to add special support for any special parameters from Azure. If a user wants to, for example, configure auto-scaling, they can use pass through arguments. There are three files that need to be hosted somewhere: two startup scripts and an Azure-specific wheel file. For the startup scripts, I just rely on GitHub tagged raw files. For the wheel file, I placed it in hail common and use the public HTTP endpoint. For development, you have to manually upload the files you want to override and invoke `hailctl hdinsight` like this:; ```; hailctl hdinsight; start \; clustername \; password \; password \; storageaccount \; --install-hail-uri https://raw.githubusercontent.com/danking/hail/dk-hdinsight-test/hail/python/hailtop/hailctl/hdinsight/resources/install-hail.sh \; --install-native-deps-uri https://raw.githubusercontent.com/danking/hail/dk-hdinsight-test/hail/python/hailtop/hailctl/hdinsight/resources/install-native-deps.sh \; --wheel-uri https://storage.googleapis.com/hail-common/dking/hail-0.2.79-py3-none-any.whl; ```; We could make this easier, but I'd rather spend that time on the query service. cc: @jigold",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11180:170,config,configuration,170,https://hail.is,https://github.com/hail-is/hail/pull/11180,2,['config'],"['configuration', 'configure']"
Modifiability,"Based off of discussion in #11907, this aims to avoid separate PRs from clobbering the image cache tag and sets up PR-specific cache tags per image. Note that using `ci-intermediate` was also detrimental to the image cache and I don't think different images sharing layers under the common name holds much value. I think we should ultimately get rid of `ci-intermediate` entirely and explicitly name our images so that they don't ruin each other's caches. I tested this in my namespace's CI. Here's the image build times from two consecutive dev deploys:. Before | After; :-------------------------:|:-------------------------:; ![Screen Shot 2022-07-05 at 6 14 36 PM](https://user-images.githubusercontent.com/24440116/177426924-5d5ade8c-0cee-4a0e-b477-2156d4e01e78.png) | ![Screen Shot 2022-07-05 at 6 14 45 PM](https://user-images.githubusercontent.com/24440116/177426882-c0029760-42ae-471d-b48c-daa0eadea448.png). I don't personally see the need for adding more SHAs to the cache as mentioned in #11907, a per-PR cache seems like exactly what you would want. The one drawback I can think of here is that a deploy won't make use of the cache from the PR that resulted in the commit to main. I believe the commit SHAs would be different because we squash so other than devising a way to trace the commit back to the PR I don't see how we can easily connect the two. Still, I feel like it's not a big deal since it will still use the previously deployed commit as a cache, so most deploys will still be very fast and no one's waiting on deploys in the same way as we wait on PRs and dev deploys.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11999:266,layers,layers,266,https://hail.is,https://github.com/hail-is/hail/pull/11999,1,['layers'],['layers']
Modifiability,"Based on #3822. Make sure you start looking at commits at `Keyed RV Aggregator`. Same PR as #3768, but rebased with some refactoring.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3824:121,refactor,refactoring,121,https://hail.is,https://github.com/hail-is/hail/pull/3824,1,['refactor'],['refactoring']
Modifiability,Based on #7681. I had to refactor `ParameterPack.newFields` a bit to get it to work with `ParameterPack.array`.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8028:25,refactor,refactor,25,https://hail.is,https://github.com/hail-is/hail/pull/8028,1,['refactor'],['refactor']
Modifiability,"Basically all naming, rids these test files of linting errors. We do a lot of reassigning a `BatchBuilder` variable to a `Batch` and so I consolidated around `bb` and `b`. A couple instances where I remove debug_info from an assert statement is because the associated `Batch` object would not exist, since that assert is triggered by an error that's raised before the `Batch` object is created.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12147:107,variab,variable,107,https://hail.is,https://github.com/hail-is/hail/pull/12147,1,['variab'],['variable']
Modifiability,"Batch Client:; - Added new parameter max_idle_time (seconds); - Removed BatchBuilder and fused it with Batch; - Added 2 new operations:; - Commit ; - Close; - Kept submit which is the same as close for backwards compatibility reasons; - commit, close, and submit now return the batch so these methods can be chained together; - create_batch stayed the same. Tests:; - Added 3 new tests for new functionality; - Renamed a bunch of variables in the tests and cleaned up the variables. Database:; - Added time_last_updated for determining how long a batch has been idle; - Added max_idle_time; - Added a closed field and changed the possible states for a batch to created, running, and complete (removed open); - Changed close_batch to be commit_staged_jobs. Changes were made to make sure this worked even if there were 0 jobs to actually commit. ; - Changed cancel_batch to always set cancelled = 1 and closed = 1 regardless of whether the batch is actually running. The time_completed is only set if no jobs are currently running. Otherwise, the time_completed will be set in MJC. **It also commits any jobs that are pending before cancelling the batch.** I'm not sure if we want this behavior or not. Driver:; - Runs a loop every 60 seconds to close batches with max_idle_time greater than that specified. UI:; - The UI changed the batches table to be time_created instead of time_closed as the Submitted/Created column. The duration is the time from time_complete - time_created for newer batches instead of time_complete - time_closed.; - Added a close button; - An open batch (even one just in the created state) can be cancelled or closed. **This might be confusing**. Other:; - Cancel is idempotent; - Getting the batch state and time_completed correct was tricky.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10484:430,variab,variables,430,https://hail.is,https://github.com/hail-is/hail/pull/10484,2,['variab'],['variables']
Modifiability,"Because, you know, that one is maternally inherited.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2005:42,inherit,inherited,42,https://hail.is,https://github.com/hail-is/hail/issues/2005,1,['inherit'],['inherited']
Modifiability,"Before we can simplify the binding structure, we need to stop duplicating it all over the place. This PR rewrites `FreeVariables` so that it no longer needs special logic for particular nodes, hard coding binding structure (redundantly). To do this, it takes advantage of the new `Bindings`, which operates on a `GenericBindingEnv` interface. It adds a new implementation of this interface specifically for computing free variables, then simply does a generic traversal of the IR using this custom binging environment. While I find the new implementation far simpler and more obviously correct than the old, I do expect it to further simplify once I'm able to start modifying the core binding structure.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14451:105,rewrite,rewrites,105,https://hail.is,https://github.com/hail-is/hail/pull/14451,2,"['rewrite', 'variab']","['rewrites', 'variables']"
Modifiability,"Ben came across an image in the wild with a null `Env` field in the manifest, which caused the following error:; ```; Error; Traceback (most recent call last):; File ""/usr/local/lib/python3.9/dist-packages/batch/worker/worker.py"", line 868, in _run; timed_out = await self._run_until_done_or_deleted(self._run_container); File ""/usr/local/lib/python3.9/dist-packages/batch/worker/worker.py"", line 1010, in _run_until_done_or_deleted; return await run_until_done_or_deleted(self.deleted_event, f, *args, **kwargs); File ""/usr/local/lib/python3.9/dist-packages/batch/worker/worker.py"", line 680, in run_until_done_or_deleted; return step.result(); File ""/usr/local/lib/python3.9/dist-packages/batch/worker/worker.py"", line 1066, in _run_container; await self._write_container_config(); File ""/usr/local/lib/python3.9/dist-packages/batch/worker/worker.py"", line 1106, in _write_container_config; config = await self.container_config(); File ""/usr/local/lib/python3.9/dist-packages/batch/worker/worker.py"", line 1166, in container_config; 'env': self._env(),; File ""/usr/local/lib/python3.9/dist-packages/batch/worker/worker.py"", line 1354, in _env; self.image.image_config['Config']['Env'] + self.env + CLOUD_WORKER_API.cloud_specific_env_vars_for_user_jobs; TypeError: unsupported operand type(s) for +: 'NoneType' and 'list'; ```. He fixed it by creating the following docker image:. ```docker; FROM jargene/hapice:1.0; ```. It could be that old versions of docker allowed this to be empty but have since made it `[]`, which would mean this would be unfortunately very annoying to test but nonetheless pretty trivial to fix.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13720:893,config,config,893,https://hail.is,https://github.com/hail-is/hail/pull/13720,2,"['Config', 'config']","['Config', 'config']"
Modifiability,"Bigger than I expected, but:; 1. Re-enable the FS tests and create a Gradle target for them so they can be run locally.; 2. Allow the FS tests to be easily used locally by not hardcoding a particular key file path.; 3. Skip GoogleStorageFSSuite when `CLOUD` is not `gcp`; 4. Remove irrelevant env vars from non-FS Scala tests.; 5. Eliminate the ""hail_repl"" image and deployment which was scoped dev anyway and never used.; 6. Add hail_pip_installed_image which can be used to execute `hailtop.aiotools.copy`.; 7. Use copy in two places in build.yaml.; 8. Add a command line argument for configuring the number of concurrent transfers which sets an upper bound on the number of open source files (and, additionally, open destination files). On my MacBook, I can't seem to open 100 local files simultaneously. I set the default low enough that local use should work by default.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11089:587,config,configuring,587,https://hail.is,https://github.com/hail-is/hail/pull/11089,1,['config'],['configuring']
Modifiability,"Black only supports the `pyproject.toml` configuration file. Between all our tools (mypy, flake8, black, pylint…), there's no single config file they all seem to support. I moved the black config from `.pre-commit-config.yaml` to `pyproject.toml` so black can pick up the configuration whenever it's run, so editor plugins to activate autoformatting can work by default now.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10438:41,config,configuration,41,https://hail.is,https://github.com/hail-is/hail/pull/10438,6,"['config', 'plugin']","['config', 'configuration', 'plugins']"
Modifiability,BlockMatrix.write_from_entry_expr OOM without appropriate cluster config,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8239:66,config,config,66,https://hail.is,https://github.com/hail-is/hail/issues/8239,1,['config'],['config']
Modifiability,Bootstrap render_config_mk: add missing variables,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11371:40,variab,variables,40,https://hail.is,https://github.com/hail-is/hail/pull/11371,1,['variab'],['variables']
Modifiability,BoxedArrayBuilder's type parameter needs to extend AnyRef to avoid; runtime matches on the type for all operations on the array.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10509:44,extend,extend,44,https://hail.is,https://github.com/hail-is/hail/pull/10509,1,['extend'],['extend']
Modifiability,Builds on #4094. Diff [here](https://github.com/patrick-schultz/hail/compare/RVD2-partitioner...patrick-schultz:RVD3-partitionKeys). * Remove partition keys from `OrderedRVDType` and `OrderedRVDPartitioner`; * Rewrite `TableKeyBy` to match specification in [design doc](https://docs.google.com/document/d/1Or3AeBvHB-6zDRKq0KHDBcKcoPedOxwlZMRdxWoblhE/edit?usp=sharing); * Add back explicit partition key arguments to `getKeyInfo` and `coerce` to keep support for local sorting path.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4119:210,Rewrite,Rewrite,210,https://hail.is,https://github.com/hail-is/hail/pull/4119,1,['Rewrite'],['Rewrite']
Modifiability,"Builds on: https://github.com/hail-is/hail/pull/4869. ExtendedOrdering on rows and containers now matches CodeOrdering by using lt instead of compare in lt, etc. FYI @tpoterba since this could potentially (e.g. comparing arrays with nans) cause a user-visible change in behavior.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4871:54,Extend,ExtendedOrdering,54,https://hail.is,https://github.com/hail-is/hail/pull/4871,1,['Extend'],['ExtendedOrdering']
Modifiability,"Builds on: https://github.com/hail-is/hail/pull/5004. Convert all operations in table.py to IR (if possible). Here are the things that remain in order to get rid of Table._jt in table.py. Rewrite in Python:; - expandTypes; - flatten; - collectJSON: use aggregate/collect (@tpoterba, do you feel this will be significantly slower now?); - showString: rewrite in Python in terms of collect. Add IR:; - intervalJoin; - same; - groupByKey. Should only work with SparkBackend:; - toDF. Hmm:; - forceCount: remove? add force option to TableCount that disables optimization?; - nPartitions; - filterPartitions; - persist, unpersist",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5015:188,Rewrite,Rewrite,188,https://hail.is,https://github.com/hail-is/hail/pull/5015,2,"['Rewrite', 'rewrite']","['Rewrite', 'rewrite']"
Modifiability,"Bumps [aiohttp](https://github.com/aio-libs/aiohttp) from 3.8.6 to 3.9.0.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/aio-libs/aiohttp/releases"">aiohttp's releases</a>.</em></p>; <blockquote>; <h2>3.9.0</h2>; <h2>Features</h2>; <ul>; <li>; <p>Introduced <code>AppKey</code> for static typing support of <code>Application</code> storage.; See <a href=""https://docs.aiohttp.org/en/stable/web_advanced.html#application-s-config"">https://docs.aiohttp.org/en/stable/web_advanced.html#application-s-config</a></p>; <p>(<a href=""https://redirect.github.com/aio-libs/aiohttp/issues/5864"">#5864</a>)</p>; </li>; <li>; <p>Added a graceful shutdown period which allows pending tasks to complete before the application's cleanup is called.; The period can be adjusted with the <code>shutdown_timeout</code> parameter. -- by :user:<code>Dreamsorcerer</code>.; See <a href=""https://docs.aiohttp.org/en/latest/web_advanced.html#graceful-shutdown"">https://docs.aiohttp.org/en/latest/web_advanced.html#graceful-shutdown</a></p>; <p>(<a href=""https://redirect.github.com/aio-libs/aiohttp/issues/7188"">#7188</a>)</p>; </li>; <li>; <p>Added <code>handler_cancellation &lt;https://docs.aiohttp.org/en/stable/web_advanced.html#web-handler-cancellation&gt;</code>_ parameter to cancel web handler on client disconnection. -- by :user:<code>mosquito</code>; This (optionally) reintroduces a feature removed in a previous release.; Recommended for those looking for an extra level of protection against denial-of-service attacks.</p>; <p>(<a href=""https://redirect.github.com/aio-libs/aiohttp/issues/7056"">#7056</a>)</p>; </li>; <li>; <p>Added support for setting response header parameters <code>max_line_size</code> and <code>max_field_size</code>.</p>; <p>(<a href=""https://redirect.github.com/aio-libs/aiohttp/issues/2304"">#2304</a>)</p>; </li>; <li>; <p>Added <code>auto_decompress</code> parameter to <code>ClientSession.request</code> to override <code>ClientSession._a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14027:468,config,config,468,https://hail.is,https://github.com/hail-is/hail/pull/14027,12,['config'],['config']
Modifiability,"Bumps [astroid](https://github.com/PyCQA/astroid) from 2.11.5 to 2.12.9.; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/PyCQA/astroid/blob/main/ChangeLog"">astroid's changelog</a>.</em></p>; <blockquote>; <h1>What's New in astroid 2.12.9?</h1>; <p>Release date: 2022-09-07</p>; <ul>; <li>; <p>Fixed creation of the <code>__init__</code> of <code>dataclassess</code> with multiple inheritance.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7427"">PyCQA/pylint#7427</a></p>; </li>; <li>; <p>Fixed a crash on <code>namedtuples</code> that use <code>typename</code> to specify their name.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7429"">PyCQA/pylint#7429</a></p>; </li>; </ul>; <h1>What's New in astroid 2.12.8?</h1>; <p>Release date: 2022-09-06</p>; <ul>; <li>; <p>Fixed a crash in the <code>dataclass</code> brain for <code>InitVars</code> without subscript typing.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7422"">PyCQA/pylint#7422</a></p>; </li>; <li>; <p>Fixed parsing of default values in <code>dataclass</code> attributes.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7425"">PyCQA/pylint#7425</a></p>; </li>; </ul>; <h1>What's New in astroid 2.12.7?</h1>; <p>Release date: 2022-09-06</p>; <ul>; <li>; <p>Fixed a crash in the <code>dataclass</code> brain for uninferable bases.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7418"">PyCQA/pylint#7418</a></p>; </li>; </ul>; <h1>What's New in astroid 2.12.6?</h1>; <p>Release date: 2022-09-05</p>; <ul>; <li>; <p>Fix a crash involving <code>Uninferable</code> arguments to <code>namedtuple()</code>.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7375"">PyCQA/pylint#7375</a></p>; </li>; <li>; <p>The <code>dataclass</code> brain now understands the <code>kw_only</code> keyword in dat",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12161:422,inherit,inheritance,422,https://hail.is,https://github.com/hail-is/hail/pull/12161,1,['inherit'],['inheritance']
Modifiability,"Bumps [black](https://github.com/psf/black) from 22.1.0 to 22.3.0.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/psf/black/releases"">black's releases</a>.</em></p>; <blockquote>; <h2>22.3.0</h2>; <h3>Preview style</h3>; <ul>; <li>Code cell separators <code>#%%</code> are now standardised to <code># %%</code> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2919"">#2919</a>)</li>; <li>Remove unnecessary parentheses from <code>except</code> statements (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2939"">#2939</a>)</li>; <li>Remove unnecessary parentheses from tuple unpacking in <code>for</code> loops (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2945"">#2945</a>)</li>; <li>Avoid magic-trailing-comma in single-element subscripts (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2942"">#2942</a>)</li>; </ul>; <h3>Configuration</h3>; <ul>; <li>Do not format <code>__pypackages__</code> directories by default (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2836"">#2836</a>)</li>; <li>Add support for specifying stable version with <code>--required-version</code> (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2832"">#2832</a>).</li>; <li>Avoid crashing when the user has no homedir (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2814"">#2814</a>)</li>; <li>Avoid crashing when md5 is not available (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2905"">#2905</a>)</li>; <li>Fix handling of directory junctions on Windows (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2904"">#2904</a>)</li>; </ul>; <h3>Documentation</h3>; <ul>; <li>Update pylint config documentation (<a href=""https://github-redirect.dependabot.com/psf/black/issues/2931"">#2931</a>)</li>; </ul>; <h3>Integrations</h3>; <ul>; <li>Move test to disable plugin in Vim/Neovim, which speeds up loading (<a href=""https://githu",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11696:938,Config,Configuration,938,https://hail.is,https://github.com/hail-is/hail/pull/11696,1,['Config'],['Configuration']
Modifiability,"Bumps [boto3](https://github.com/boto/boto3) from 1.26.6 to 1.26.9.; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/boto/boto3/blob/develop/CHANGELOG.rst"">boto3's changelog</a>.</em></p>; <blockquote>; <h1>1.26.9</h1>; <ul>; <li>api-change:<code>customer-profiles</code>: [<code>botocore</code>] This release enhances the SearchProfiles API by providing functionality to search for profiles using multiple keys and logical operators.</li>; <li>api-change:<code>lakeformation</code>: [<code>botocore</code>] This release adds a new parameter &quot;Parameters&quot; in the DataLakeSettings.</li>; <li>api-change:<code>managedblockchain</code>: [<code>botocore</code>] Updating the API docs data type: NetworkEthereumAttributes, and the operations DeleteNode, and CreateNode to also include the supported Goerli network.</li>; <li>api-change:<code>proton</code>: [<code>botocore</code>] Add support for CodeBuild Provisioning</li>; <li>api-change:<code>rds</code>: [<code>botocore</code>] This release adds support for restoring an RDS Multi-AZ DB cluster snapshot to a Single-AZ deployment or a Multi-AZ DB instance deployment.</li>; <li>api-change:<code>workdocs</code>: [<code>botocore</code>] Added 2 new document related operations, DeleteDocumentVersion and RestoreDocumentVersions.</li>; <li>api-change:<code>xray</code>: [<code>botocore</code>] This release enhances GetServiceGraph API to support new type of edge to represent links between SQS and Lambda in event-driven applications.</li>; </ul>; <h1>1.26.8</h1>; <ul>; <li>api-change:<code>glue</code>: [<code>botocore</code>] Added links related to enabling job bookmarks.</li>; <li>api-change:<code>iot</code>: [<code>botocore</code>] This release add new api listRelatedResourcesForAuditFinding and new member type IssuerCertificates for Iot device device defender Audit.</li>; <li>api-change:<code>license-manager</code>: [<code>botocore</code>] AWS License Manager now supports onboarded Managem",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12466:351,enhance,enhances,351,https://hail.is,https://github.com/hail-is/hail/pull/12466,1,['enhance'],['enhances']
Modifiability,"Bumps [boto3](https://github.com/boto/boto3) from 1.26.7 to 1.26.16.; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/boto/boto3/blob/develop/CHANGELOG.rst"">boto3's changelog</a>.</em></p>; <blockquote>; <h1>1.26.16</h1>; <ul>; <li>api-change:<code>grafana</code>: [<code>botocore</code>] This release includes support for configuring a Grafana workspace to connect to a datasource within a VPC as well as new APIs for configuring Grafana settings.</li>; <li>api-change:<code>rbin</code>: [<code>botocore</code>] This release adds support for Rule Lock for Recycle Bin, which allows you to lock retention rules so that they can no longer be modified or deleted.</li>; </ul>; <h1>1.26.15</h1>; <ul>; <li>bugfix:Endpoints: [<code>botocore</code>] Resolve endpoint with default partition when no region is set</li>; <li>bugfix:s3: [<code>botocore</code>] fixes missing x-amz-content-sha256 header for s3 object lambda</li>; <li>api-change:<code>appflow</code>: [<code>botocore</code>] Adding support for Amazon AppFlow to transfer the data to Amazon Redshift databases through Amazon Redshift Data API service. This feature will support the Redshift destination connector on both public and private accessible Amazon Redshift Clusters and Amazon Redshift Serverless.</li>; <li>api-change:<code>kinesisanalyticsv2</code>: [<code>botocore</code>] Support for Apache Flink 1.15 in Kinesis Data Analytics.</li>; </ul>; <h1>1.26.14</h1>; <ul>; <li>api-change:<code>route53</code>: [<code>botocore</code>] Amazon Route 53 now supports the Asia Pacific (Hyderabad) Region (ap-south-2) for latency records, geoproximity records, and private DNS for Amazon VPCs in that region.</li>; </ul>; <h1>1.26.13</h1>; <ul>; <li>api-change:<code>appflow</code>: [<code>botocore</code>] AppFlow provides a new API called UpdateConnectorRegistration to update a custom connector that customers have previously registered. With this API, customers no longer need to unregister and then",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12502:364,config,configuring,364,https://hail.is,https://github.com/hail-is/hail/pull/12502,2,['config'],['configuring']
Modifiability,"Bumps [botocore](https://github.com/boto/botocore) from 1.24.13 to 1.24.14.; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/boto/botocore/blob/develop/CHANGELOG.rst"">botocore's changelog</a>.</em></p>; <blockquote>; <h1>1.24.14</h1>; <ul>; <li>api-change:<code>chime-sdk-meetings</code>: Adds support for Transcribe language identification feature to the StartMeetingTranscription API.</li>; <li>api-change:<code>ecs</code>: Amazon ECS UpdateService API now supports additional parameters: loadBalancers, propagateTags, enableECSManagedTags, and serviceRegistries</li>; <li>api-change:<code>migration-hub-refactor-spaces</code>: AWS Migration Hub Refactor Spaces documentation update.</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/boto/botocore/commit/5c6f8c8d8e6c5ed05b05302ba9ef83cc2f0c420f""><code>5c6f8c8</code></a> Merge branch 'release-1.24.14'</li>; <li><a href=""https://github.com/boto/botocore/commit/3042265ca9488b8d73c6442f703337309d6733a4""><code>3042265</code></a> Bumping version to 1.24.14</li>; <li><a href=""https://github.com/boto/botocore/commit/ba0d095eeb62a2a293abadb54111df5fc0e2f0c8""><code>ba0d095</code></a> Update to latest models</li>; <li><a href=""https://github.com/boto/botocore/commit/a8c5cc855ecb91f5f64d73f2a15dfebc9e5e20e0""><code>a8c5cc8</code></a> Merge branch 'release-1.24.13' into develop</li>; <li>See full diff in <a href=""https://github.com/boto/botocore/compare/1.24.13...1.24.14"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=botocore&package-manager=pip&previous-version=1.24.13&new-version=1.24.14)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11534:647,refactor,refactor-spaces,647,https://hail.is,https://github.com/hail-is/hail/pull/11534,2,"['Refactor', 'refactor']","['Refactor', 'refactor-spaces']"
Modifiability,"Bumps [botocore](https://github.com/boto/botocore) from 1.29.13 to 1.29.16.; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/boto/botocore/blob/develop/CHANGELOG.rst"">botocore's changelog</a>.</em></p>; <blockquote>; <h1>1.29.16</h1>; <ul>; <li>api-change:<code>grafana</code>: This release includes support for configuring a Grafana workspace to connect to a datasource within a VPC as well as new APIs for configuring Grafana settings.</li>; <li>api-change:<code>rbin</code>: This release adds support for Rule Lock for Recycle Bin, which allows you to lock retention rules so that they can no longer be modified or deleted.</li>; </ul>; <h1>1.29.15</h1>; <ul>; <li>bugfix:Endpoints: Resolve endpoint with default partition when no region is set</li>; <li>bugfix:s3: fixes missing x-amz-content-sha256 header for s3 object lambda</li>; <li>api-change:<code>appflow</code>: Adding support for Amazon AppFlow to transfer the data to Amazon Redshift databases through Amazon Redshift Data API service. This feature will support the Redshift destination connector on both public and private accessible Amazon Redshift Clusters and Amazon Redshift Serverless.</li>; <li>api-change:<code>kinesisanalyticsv2</code>: Support for Apache Flink 1.15 in Kinesis Data Analytics.</li>; </ul>; <h1>1.29.14</h1>; <ul>; <li>api-change:<code>route53</code>: Amazon Route 53 now supports the Asia Pacific (Hyderabad) Region (ap-south-2) for latency records, geoproximity records, and private DNS for Amazon VPCs in that region.</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/boto/botocore/commit/f0dd67f9b7cc2791f301f3fd135f0c97d9c66bae""><code>f0dd67f</code></a> Merge branch 'release-1.29.16'</li>; <li><a href=""https://github.com/boto/botocore/commit/22c3cb362c0ef00c6de404140f06a14d0e195f39""><code>22c3cb3</code></a> Bumping version to 1.29.16</li>; <li><a href=""https://github.com/boto/botocore/commit/4",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12503:353,config,configuring,353,https://hail.is,https://github.com/hail-is/hail/pull/12503,2,['config'],['configuring']
Modifiability,"Bumps [de.undercouch.download](https://github.com/michel-kraemer/gradle-download-task) from 5.3.0 to 5.3.1.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/michel-kraemer/gradle-download-task/releases"">de.undercouch.download's releases</a>.</em></p>; <blockquote>; <h2>5.3.1</h2>; <p>Bug fixes:</p>; <ul>; <li>Downgrade slf4j to fix warning on console about missing slf4j provider</li>; <li>Allow <code>download</code> and <code>verify</code> extensions to be created on demand in custom tasks, so these tasks can be made compatible with Gradle's configuration cache (see <a href=""https://github-redirect.dependabot.com/michel-kraemer/gradle-download-task/issues/284"">#284</a>). Thanks to <a href=""https://github.com/liblit""><code>@​liblit</code></a> for testing!</li>; </ul>; <p>Maintenance:</p>; <ul>; <li>Update dependencies</li>; <li>Improve documentation</li>; <li>Add integration tests for Gradle 6.9.3 and 7.6</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/a0374fc7c895ae53309ea351e989571204e0ea5f""><code>a0374fc</code></a> Bump up version number to 5.3.1</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/612f57a382b8640cc730dc5e75d1c809e3e772bd""><code>612f57a</code></a> Merge pull request <a href=""https://github-redirect.dependabot.com/michel-kraemer/gradle-download-task/issues/291"">#291</a> from michel-kraemer/dependabot/npm_and_yarn/screencas...</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/53af1049f5514afe58e884d487d7c57dae47759d""><code>53af104</code></a> Bump http-cache-semantics from 4.1.0 to 4.1.1 in /screencast</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task/commit/398c14c05c6448b380ac35c6095598299c5e23c5""><code>398c14c</code></a> Update dependencies</li>; <li><a href=""https://github.com/michel-kraemer/gradle-download-task",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12707:593,config,configuration,593,https://hail.is,https://github.com/hail-is/hail/pull/12707,1,['config'],['configuration']
Modifiability,"Bumps [google-cloud-logging](https://github.com/googleapis/python-logging) from 1.12.1 to 3.0.0.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/googleapis/python-logging/releases"">google-cloud-logging's releases</a>.</em></p>; <blockquote>; <h2>v3.0.0</h2>; <h2><a href=""https://github.com/googleapis/python-logging/compare/v2.7.0...v3.0.0"">3.0.0</a> (2022-01-27)</h2>; <h3>⚠ BREAKING CHANGES</h3>; <ul>; <li>make logging API more friendly to use (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/422"">#422</a>)</li>; <li>api consistency between HTTP and Gapic layers (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/375"">#375</a>)</li>; <li>support string-encoded json (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/339"">#339</a>)</li>; <li>Infer default resource in logger (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/315"">#315</a>)</li>; <li>support json logs (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/316"">#316</a>)</li>; <li>deprecate AppEngineHandler and ContainerEngineHandler (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/310"">#310</a>)</li>; </ul>; <h3>Features</h3>; <ul>; <li>add api key support (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/472"">#472</a>) (<a href=""https://github.com/googleapis/python-logging/commit/81ca8c616acb988be1fbecfc2a0b1a5b39280149"">81ca8c6</a>)</li>; <li>add json_fields extras argument for adding to jsonPayload (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/447"">#447</a>) (<a href=""https://github.com/googleapis/python-logging/commit/a760e02371a55d6262e42de9e0222fffa2c7192b"">a760e02</a>)</li>; <li>avoid importing grpc when explicitly disabled (<a href=""https://github-redirect.dependabot.com/googleapis/python-logging/issues/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11574:640,layers,layers,640,https://hail.is,https://github.com/hail-is/hail/pull/11574,1,['layers'],['layers']
Modifiability,"Bumps [google-cloud-storage](https://github.com/googleapis/java-storage) from 1.106.0 to 2.16.0.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/googleapis/java-storage/releases"">google-cloud-storage's releases</a>.</em></p>; <blockquote>; <h2>v2.16.0</h2>; <h2><a href=""https://github.com/googleapis/java-storage/compare/v2.15.1...v2.16.0"">2.16.0</a> (2022-12-06)</h2>; <h3>Features</h3>; <ul>; <li>Add {Compose,Rewrite,StartResumableWrite}Request.object_checksums and Bucket.RetentionPolicy.retention_duration (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1790"">#1790</a>) (<a href=""https://github.com/googleapis/java-storage/commit/31c1b18acc3c118e39eb613a82ee292f3e246b8f"">31c1b18</a>)</li>; <li>Added a new retention_duration field of Duration type (<a href=""https://github.com/googleapis/java-storage/commit/31c1b18acc3c118e39eb613a82ee292f3e246b8f"">31c1b18</a>)</li>; <li>Added object_checksums for compose/rewrite/startResumableWrite request (<a href=""https://github.com/googleapis/java-storage/commit/31c1b18acc3c118e39eb613a82ee292f3e246b8f"">31c1b18</a>)</li>; </ul>; <h3>Bug Fixes</h3>; <ul>; <li>Removed WriteObject routing annotations (<a href=""https://github.com/googleapis/java-storage/commit/31c1b18acc3c118e39eb613a82ee292f3e246b8f"">31c1b18</a>)</li>; </ul>; <h3>Documentation</h3>; <ul>; <li>Clarified relative resource names in gRPC IAM RPCs (<a href=""https://github.com/googleapis/java-storage/commit/31c1b18acc3c118e39eb613a82ee292f3e246b8f"">31c1b18</a>)</li>; <li>Clarified the object can be deleted via DeleteObject (<a href=""https://github.com/googleapis/java-storage/commit/31c1b18acc3c118e39eb613a82ee292f3e246b8f"">31c1b18</a>)</li>; <li>Updated the document link for <code>Naming Guidelines</code> (<a href=""https://github.com/googleapis/java-storage/commit/31c1b18acc3c118e39eb613a82ee292f3e246b8f"">31c1b18</a>)</li>; </ul>; <h3>Dependencies</h3>; <ul>; <li>Update dependency com.google.cloud:",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12545:459,Rewrite,Rewrite,459,https://hail.is,https://github.com/hail-is/hail/pull/12545,2,"['Rewrite', 'rewrite']","['Rewrite', 'rewrite']"
Modifiability,"Bumps [jupyter-lsp](https://github.com/jupyter-lsp/jupyterlab-lsp) from 2.2.1 to 2.2.2.; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/jupyter-lsp/jupyterlab-lsp/blob/main/CHANGELOG.md"">jupyter-lsp's changelog</a>.</em></p>; <blockquote>; <h3><code>jupyter-lsp 2.2.2</code></h3>; <ul>; <li>bug fixes:; <ul>; <li>address warning about renamed <code>extension_points</code> (<a href=""https://redirect.github.com/jupyter-lsp/jupyterlab-lsp/issues/1035"">#1035</a>)</li>; <li>fix compatibility with jupyter server 1.x</li>; <li>fix an authentication-related security vulnerability (see <a href=""https://github.com/jupyter-lsp/jupyterlab-lsp/security/advisories/GHSA-4qhp-652w-c22x"">the advisory</a> for details)</li>; </ul>; </li>; <li>enhancements:; <ul>; <li>add authorization support (<code>lsp</code> resource, jupyter-server v2+ only) - this allows server operators for fine grained access control, e.g. in case if specific users (such as guest or read-only users) should not be allowed to access LSP; this is in addition to authentication fixes</li>; </ul>; </li>; </ul>; <h3><code>@jupyter-lsp/jupyterlab-lsp 5.0.1</code></h3>; <ul>; <li>bug fixes:; <ul>; <li>fix false “undefined name” in <code>%%time</code> and <code>%%capture</code> magics <a href=""https://redirect.github.com/jupyter-lsp/jupyterlab-lsp/issues/1007"">#1007</a> (thanks <a href=""https://github.com/i-aki-y""><code>@​i-aki-y</code></a>!)</li>; <li>fix completion items for paths and other long items being cut off <a href=""https://redirect.github.com/jupyter-lsp/jupyterlab-lsp/issues/1025"">#1025</a></li>; <li>workaround issue with markdown lost on edit <a href=""https://redirect.github.com/jupyter-lsp/jupyterlab-lsp/issues/1016"">#1016</a></li>; <li>fix latex/Greek letters insertion and other completions which do not match prefix (do not pre-filter completions from kernel) <a href=""https://redirect.github.com/jupyter-lsp/jupyterlab-lsp/issues/1022"">#1022</a></li>; <li>fix completion",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14171:774,enhance,enhancements,774,https://hail.is,https://github.com/hail-is/hail/pull/14171,1,['enhance'],['enhancements']
Modifiability,"Bumps [kubernetes-asyncio](https://github.com/tomplus/kubernetes_asyncio) from 19.15.1 to 24.2.2.; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/tomplus/kubernetes_asyncio/blob/master/CHANGELOG.md"">kubernetes-asyncio's changelog</a>.</em></p>; <blockquote>; <h1>v24.2.2</h1>; <ul>; <li>fix: config reader handles bool types (<a href=""https://github-redirect.dependabot.com/tomplus/kubernetes_asyncio/pull/218"">#218</a>, <a href=""https://github.com/tomplus""><code>@​tomplus</code></a>)</li>; </ul>; <h1>v24.2.1</h1>; <ul>; <li>fixed watch.stream bug of not working with apis with follow kwarg (<a href=""https://github-redirect.dependabot.com/tomplus/kubernetes_asyncio/pull/216"">#216</a>, <a href=""https://github.com/mcreng""><code>@​mcreng</code></a>)</li>; </ul>; <h1>v24.2.0</h1>; <p>Kubernetes API Version: v1.24.2</p>; <h3>API Change</h3>; <ul>; <li>Add 2 new options for kube-proxy running in winkernel mode. <code>--forward-healthcheck-vip</code>, if specified as true, health check traffic whose destination is service VIP will be forwarded to kube-proxy's healthcheck service. <code>--root-hnsendpoint-name</code> specifies the name of the hns endpoint for the root network namespace. This option enables the pass-through load balancers like Google's GCLB to correctly health check the backend services. Without this change, the health check packets is dropped, and Windows node will be considered to be unhealthy by those load balancers. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/99287"">kubernetes/kubernetes#99287</a>, <a href=""https://github.com/anfernee""><code>@​anfernee</code></a>)</li>; <li>Added CEL runtime cost calculation into CustomerResource validation. CustomerResource validation will fail if runtime cost exceeds the budget. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/108482"">kubernetes/kubernetes#108482</a>, <a href=""https://github.com/cici37""><code>@​cici37</code><",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12196:334,config,config,334,https://hail.is,https://github.com/hail-is/hail/pull/12196,1,['config'],['config']
Modifiability,"Bumps [minimist](https://github.com/substack/minimist) from 1.2.5 to 1.2.6.; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/substack/minimist/commit/7efb22a518b53b06f5b02a1038a88bd6290c2846""><code>7efb22a</code></a> 1.2.6</li>; <li><a href=""https://github.com/substack/minimist/commit/ef88b9325f77b5ee643ccfc97e2ebda577e4c4e2""><code>ef88b93</code></a> security notice for additional prototype pollution issue</li>; <li><a href=""https://github.com/substack/minimist/commit/c2b981977fa834b223b408cfb860f933c9811e4d""><code>c2b9819</code></a> isConstructorOrProto adapted from PR</li>; <li><a href=""https://github.com/substack/minimist/commit/bc8ecee43875261f4f17eb20b1243d3ed15e70eb""><code>bc8ecee</code></a> test from prototype pollution PR</li>; <li>See full diff in <a href=""https://github.com/substack/minimist/compare/1.2.5...1.2.6"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=minimist&package-manager=npm_and_yarn&previous-version=1.2.5&new-version=1.2.6)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`. [//]: # (dependabot-automerge-start); [//]: # (dependabot-automerge-end). ---. <details>; <summary>Dependabot commands and options</summary>; <br />. You can trigger Dependabot actions by commenting on this PR:; - `@dependabot rebase` will rebase this PR; - `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it; - `@dependabot merge` will merge this PR after your CI passes on it; - `@dependabot squash and merge` will squash and merge this PR after your CI passes on it; - `@dependabot cancel merge` will cancel a previously requested merge and blo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11653:590,adapt,adapted,590,https://hail.is,https://github.com/hail-is/hail/pull/11653,1,['adapt'],['adapted']
Modifiability,"Bumps [mypy](https://github.com/python/mypy) from 0.950 to 0.982.; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/python/mypy/commit/1c2b899fa9029538b9b9e6d30401901d94536202""><code>1c2b899</code></a> Bump version to 0.982</li>; <li><a href=""https://github.com/python/mypy/commit/51d9858b09c82499c79023d0a80693a71baa7bed""><code>51d9858</code></a> Restore Type vs Callable special-casing that was broken in refactoring (<a href=""https://github-redirect.dependabot.com/python/mypy/issues/13784"">#13784</a>)</li>; <li><a href=""https://github.com/python/mypy/commit/d03f201762df7138c6da157b5cbb8e634acef45f""><code>d03f201</code></a> Suggest using upper bound for unbound tvar (<a href=""https://github-redirect.dependabot.com/python/mypy/issues/13730"">#13730</a>)</li>; <li><a href=""https://github.com/python/mypy/commit/5b17cc6c393280326ed15d763e599cbaeefbc0e6""><code>5b17cc6</code></a> Fix overload overlap check for UninhabitedType (<a href=""https://github-redirect.dependabot.com/python/mypy/issues/13461"">#13461</a>)</li>; <li><a href=""https://github.com/python/mypy/commit/c7b4714e1f5e3cb8f3fec7426b6538fe1a3dcab1""><code>c7b4714</code></a> Update version to 0.981</li>; <li><a href=""https://github.com/python/mypy/commit/2bd7da21462a59643f2aec546304db1a624ba285""><code>2bd7da2</code></a> [0.980 backport] build changes (<a href=""https://github-redirect.dependabot.com/python/mypy/issues/13688"">#13688</a>)</li>; <li><a href=""https://github.com/python/mypy/commit/2b2953a1392368f623331d5168ccdfd39e37bbee""><code>2b2953a</code></a> [0.980 backport] Update pos-only unit tests for Python 3.10.7 (<a href=""https://github-redirect.dependabot.com/python/mypy/issues/13660"">#13660</a>) (<a href=""https://github-redirect.dependabot.com/python/mypy/issues/13665"">#13665</a>)</li>; <li><a href=""https://github.com/python/mypy/commit/ada007841f6a96f68d114769624a0f7b523814a7""><code>ada0078</code></a> Remove dev from version</li>; <li><a href=""https://github.com/python/mypy/commit/",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12291:435,refactor,refactoring,435,https://hail.is,https://github.com/hail-is/hail/pull/12291,1,['refactor'],['refactoring']
Modifiability,"Bumps [notebook](https://github.com/jupyter/notebook) from 7.0.6 to 7.0.7.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/jupyter/notebook/releases"">notebook's releases</a>.</em></p>; <blockquote>; <h2>v7.0.7</h2>; <h2>7.0.7</h2>; <p>(<a href=""https://github.com/jupyter/notebook/compare/@jupyter-notebook/application-extension@7.0.6...089c78c48fd00b2b0d2f33e4463eb42018e86803"">Full Changelog</a>)</p>; <h3>Enhancements made</h3>; <ul>; <li>Update to JupyterLab 4.0.11 <a href=""https://redirect.github.com/jupyter/notebook/pull/7215"">#7215</a> (<a href=""https://github.com/krassowski""><code>@​krassowski</code></a>)</li>; </ul>; <h3>Maintenance and upkeep improvements</h3>; <ul>; <li>Update ruff config and typing <a href=""https://redirect.github.com/jupyter/notebook/pull/7145"">#7145</a> (<a href=""https://github.com/blink1073""><code>@​blink1073</code></a>)</li>; <li>Clean up lint handling <a href=""https://redirect.github.com/jupyter/notebook/pull/7142"">#7142</a> (<a href=""https://github.com/blink1073""><code>@​blink1073</code></a>)</li>; <li>Adopt ruff format <a href=""https://redirect.github.com/jupyter/notebook/pull/7132"">#7132</a> (<a href=""https://github.com/blink1073""><code>@​blink1073</code></a>)</li>; <li>[7.0.x] Install stable JupyterLab 4.0 in the releaser hook <a href=""https://redirect.github.com/jupyter/notebook/pull/7183"">#7183</a> (<a href=""https://github.com/jtpio""><code>@​jtpio</code></a>)</li>; <li>Update publish-release workflow for PyPI trusted publisher <a href=""https://redirect.github.com/jupyter/notebook/pull/7176"">#7176</a> (<a href=""https://github.com/jtpio""><code>@​jtpio</code></a>)</li>; </ul>; <h3>Contributors to this release</h3>; <p>(<a href=""https://github.com/jupyter/notebook/graphs/contributors?from=2023-10-17&amp;to=2024-01-19&amp;type=c"">GitHub contributors page for this release</a>)</p>; <p><a href=""https://github.com/search?q=repo%3Ajupyter%2Fnotebook+involves%3Abrichet+updated%3A2023-10-17..2024-",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14182:454,Enhance,Enhancements,454,https://hail.is,https://github.com/hail-is/hail/pull/14182,2,"['Enhance', 'config']","['Enhancements', 'config']"
Modifiability,"Bumps [numpy](https://github.com/numpy/numpy) from 1.21.6 to 1.22.0.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/numpy/numpy/releases"">numpy's releases</a>.</em></p>; <blockquote>; <h2>v1.22.0</h2>; <h1>NumPy 1.22.0 Release Notes</h1>; <p>NumPy 1.22.0 is a big release featuring the work of 153 contributors; spread over 609 pull requests. There have been many improvements,; highlights are:</p>; <ul>; <li>Annotations of the main namespace are essentially complete. Upstream; is a moving target, so there will likely be further improvements,; but the major work is done. This is probably the most user visible; enhancement in this release.</li>; <li>A preliminary version of the proposed Array-API is provided. This is; a step in creating a standard collection of functions that can be; used across application such as CuPy and JAX.</li>; <li>NumPy now has a DLPack backend. DLPack provides a common interchange; format for array (tensor) data.</li>; <li>New methods for <code>quantile</code>, <code>percentile</code>, and related functions. The; new methods provide a complete set of the methods commonly found in; the literature.</li>; <li>A new configurable allocator for use by downstream projects.</li>; </ul>; <p>These are in addition to the ongoing work to provide SIMD support for; commonly used functions, improvements to F2PY, and better documentation.</p>; <p>The Python versions supported in this release are 3.8-3.10, Python 3.7; has been dropped. Note that 32 bit wheels are only provided for Python; 3.8 and 3.9 on Windows, all other wheels are 64 bits on account of; Ubuntu, Fedora, and other Linux distributions dropping 32 bit support.; All 64 bit wheels are also linked with 64 bit integer OpenBLAS, which should fix; the occasional problems encountered by folks using truly huge arrays.</p>; <h2>Expired deprecations</h2>; <h3>Deprecated numeric style dtype strings have been removed</h3>; <p>Using the strings <code>&quot;Bytes0&",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11939:662,enhance,enhancement,662,https://hail.is,https://github.com/hail-is/hail/pull/11939,4,['enhance'],['enhancement']
Modifiability,"Bumps [protobuf](https://github.com/protocolbuffers/protobuf) from 3.19.6 to 4.21.12.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/protocolbuffers/protobuf/releases"">protobuf's releases</a>.</em></p>; <blockquote>; <h2>Protocol Buffers v3.20.3</h2>; <h1>Java</h1>; <ul>; <li>Refactoring java full runtime to reuse sub-message builders and prepare to; migrate parsing logic from parse constructor to builder.</li>; <li>Move proto wireformat parsing functionality from the private &quot;parsing; constructor&quot; to the Builder class.</li>; <li>Change the Lite runtime to prefer merging from the wireformat into mutable; messages rather than building up a new immutable object before merging. This; way results in fewer allocations and copy operations.</li>; <li>Make message-type extensions merge from wire-format instead of building up; instances and merging afterwards. This has much better performance.</li>; <li>Fix TextFormat parser to build up recurring (but supposedly not repeated); sub-messages directly from text rather than building a new sub-message and; merging the fully formed message into the existing field.</li>; <li>This release addresses a <a href=""https://github.com/protocolbuffers/protobuf/security/advisories/GHSA-h4h5-3hr4-j3g2"">Security Advisory for Java users</a></li>; </ul>; <h2>Protocol Buffers v3.20.2</h2>; <h1>C++</h1>; <ul>; <li>Reduce memory consumption of MessageSet parsing</li>; <li>This release addresses a <a href=""https://github.com/protocolbuffers/protobuf/security/advisories/GHSA-8gq9-2x98-w8hf"">Security Advisory for C++ and Python users</a></li>; </ul>; <h2>Protocol Buffers v3.20.1</h2>; <h1>PHP</h1>; <ul>; <li>Fix building packaged PHP extension (<a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/9727"">#9727</a>)</li>; <li>Fixed composer.json to only advertise compatibility with PHP 7.0+. (<a href=""https://github-redirect.dependabot.com/protocolbuffers/protobuf/issues/9",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12563:324,Refactor,Refactoring,324,https://hail.is,https://github.com/hail-is/hail/pull/12563,1,['Refactor'],['Refactoring']
Modifiability,"Bumps [protobuf](https://github.com/protocolbuffers/protobuf) from 3.20.2 to 4.21.9.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/protocolbuffers/protobuf/releases"">protobuf's releases</a>.</em></p>; <blockquote>; <h2>Protocol Buffers v3.20.3</h2>; <h1>Java</h1>; <ul>; <li>Refactoring java full runtime to reuse sub-message builders and prepare to; migrate parsing logic from parse constructor to builder.</li>; <li>Move proto wireformat parsing functionality from the private &quot;parsing; constructor&quot; to the Builder class.</li>; <li>Change the Lite runtime to prefer merging from the wireformat into mutable; messages rather than building up a new immutable object before merging. This; way results in fewer allocations and copy operations.</li>; <li>Make message-type extensions merge from wire-format instead of building up; instances and merging afterwards. This has much better performance.</li>; <li>Fix TextFormat parser to build up recurring (but supposedly not repeated); sub-messages directly from text rather than building a new sub-message and; merging the fully formed message into the existing field.</li>; <li>This release addresses a <a href=""https://github.com/protocolbuffers/protobuf/security/advisories/GHSA-h4h5-3hr4-j3g2"">Security Advisory for Java users</a></li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li>See full diff in <a href=""https://github.com/protocolbuffers/protobuf/commits"">compare view</a></li>; </ul>; </details>; <br />. [![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=protobuf&package-manager=pip&previous-version=3.20.2&new-version=4.21.9)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores). Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12518:323,Refactor,Refactoring,323,https://hail.is,https://github.com/hail-is/hail/pull/12518,1,['Refactor'],['Refactoring']
Modifiability,"Bumps [psutil](https://github.com/giampaolo/psutil) from 5.8.0 to 5.9.0.; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/giampaolo/psutil/blob/master/HISTORY.rst"">psutil's changelog</a>.</em></p>; <blockquote>; <h1>5.9.0</h1>; <p>2021-12-29</p>; <p><strong>Enhancements</strong></p>; <ul>; <li>1851_, [Linux]: <code>cpu_freq()</code>_ is slow on systems with many CPUs. Read current; frequency values for all CPUs from <code>/proc/cpuinfo</code> instead of opening many; files in <code>/sys</code> fs. (patch by marxin)</li>; <li>1992_: <code>NoSuchProcess</code>_ message now specifies if the PID has been reused.</li>; <li>1992_: error classes (<code>NoSuchProcess</code><em>, <code>AccessDenied</code></em>, etc.) now have a better; formatted and separated <code>__repr__</code> and <code>__str__</code> implementations.</li>; <li>1996_, [BSD]: add support for MidnightBSD. (patch by Saeed Rasooli)</li>; <li>1999_, [Linux]: <code>disk_partitions()</code>_: convert <code>/dev/root</code> device (an alias; used on some Linux distros) to real root device path.</li>; <li>2005_: <code>PSUTIL_DEBUG</code> mode now prints file name and line number of the debug; messages coming from C extension modules.</li>; <li>2042_: rewrite HISTORY.rst to use hyperlinks pointing to psutil API doc.</li>; </ul>; <p><strong>Bug fixes</strong></p>; <ul>; <li>1456_, [macOS], <strong>[critical]</strong>: <code>cpu_freq()</code>_ <code>min</code> and <code>max</code> are set to; 0 if can't be determined (instead of crashing).</li>; <li>1512_, [macOS]: sometimes <code>Process.connections()</code>_ will crash with; <code>EOPNOTSUPP</code> for one connection; this is now ignored.</li>; <li>1598_, [Windows]: <code>disk_partitions()</code>_ only returns mountpoints on drives; where it first finds one.</li>; <li>1874_, [SunOS]: swap output error due to incorrect range.</li>; <li>1892_, [macOS]: <code>cpu_freq()</code>_ broken on Apple M1.</li>; <li>1901_, [macOS]: diff",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11459:299,Enhance,Enhancements,299,https://hail.is,https://github.com/hail-is/hail/pull/11459,1,['Enhance'],['Enhancements']
Modifiability,"Bumps [pylint](https://github.com/PyCQA/pylint) from 2.13.3 to 2.13.4.; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/PyCQA/pylint/blob/main/ChangeLog"">pylint's changelog</a>.</em></p>; <blockquote>; <h1>What's New in Pylint 2.13.4?</h1>; <p>Release date: 2022-03-31</p>; <ul>; <li>; <p>Fix false positive regression in 2.13.0 for <code>used-before-assignment</code> for; homonyms between variable assignments in try/except blocks and variables in; a comprehension's filter.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/6035"">#6035</a></p>; </li>; <li>; <p>Include <code>testing_pylintrc</code> in source and wheel distributions.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/6028"">#6028</a></p>; </li>; <li>; <p>Fix crash in <code>super-init-not-called</code> checker when using <code>ctypes.Union</code>.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/6027"">#6027</a></p>; </li>; <li>; <p>Fix crash for <code>unneccessary-ellipsis</code> checker when an ellipsis is used inside of a container or a lambda expression.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/6036"">#6036</a>; Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/6037"">#6037</a>; Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/6048"">#6048</a></p>; </li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/PyCQA/pylint/commit/14ae9e8985a70af1b04aa996c04a1a8c3fa8f463""><code>14ae9e8</code></a> Bump pylint to 2.13.4, update changelog</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/9009189c06dd326b7a4f5b9911d0246976f64509""><code>9009189</code></a> Fix crash in <code>super-init-not-called</code> checker (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/6043"">#6043</a>)</li>; <li><a href=""https://g",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11723:432,variab,variable,432,https://hail.is,https://github.com/hail-is/hail/pull/11723,2,['variab'],"['variable', 'variables']"
Modifiability,"Bumps [pylint](https://github.com/PyCQA/pylint) from 2.13.4 to 2.13.5.; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/PyCQA/pylint/blob/main/ChangeLog"">pylint's changelog</a>.</em></p>; <blockquote>; <h1>What's New in Pylint 2.13.5?</h1>; <p>Release date: 2022-04-06</p>; <ul>; <li>; <p>Fix false positive regression in 2.13.0 for <code>used-before-assignment</code> for; homonyms between variable assignments in try/except blocks and variables in; subscripts in comprehensions.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/6069"">#6069</a>; Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/6136"">#6136</a></p>; </li>; <li>; <p><code>lru-cache-decorating-method</code> has been renamed to <code>cache-max-size-none</code> and; will only be emitted when <code>maxsize</code> is <code>None</code>.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/6180"">#6180</a></p>; </li>; <li>; <p>Fix false positive for <code>unused-import</code> when disabling both <code>used-before-assignment</code> and <code>undefined-variable</code>.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/6089"">#6089</a></p>; </li>; <li>; <p>Narrow the scope of the <code>unnecessary-ellipsis</code> checker to:</p>; <ul>; <li>functions &amp; classes which contain both a docstring and an ellipsis.</li>; <li>A body which contains an ellipsis <code>nodes.Expr</code> node &amp; at least one other statement.</li>; </ul>; </li>; <li>; <p>Fix false positive for <code>used-before-assignment</code> for assignments taking place via; nonlocal declarations after an earlier type annotation.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5394"">#5394</a></p>; </li>; <li>; <p>Fix crash for <code>redefined-slots-in-subclass</code> when the type of the slot is not a const or a string.</p>; <p>Closes <a href=""https://github-redi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11739:432,variab,variable,432,https://hail.is,https://github.com/hail-is/hail/pull/11739,2,['variab'],"['variable', 'variables']"
Modifiability,"Bumps [pylint](https://github.com/PyCQA/pylint) from 2.13.5 to 2.14.3.; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/PyCQA/pylint/commit/680edebc686cad664bbed934a490aeafa775f163""><code>680edeb</code></a> Bump pylint to 2.14.3, update changelog</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/b05ac51ad2e3785b6b9b071b8cb241993c914105""><code>b05ac51</code></a> Pin <code>colorama</code> to lowest supported version (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/6970"">#6970</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/417e8c3560bcb733a08dbdc8a0d33d5e3cb4a1b0""><code>417e8c3</code></a> Fix <code>bad-super-call</code> for non-direct parents (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/6956"">#6956</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/fb6be5933ab270d542d80589be6fdea8abc82665""><code>fb6be59</code></a> Fix <code>undefined-variable</code> for <code>__class__</code> in inner methods (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/6957"">#6957</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/b9ecb4d70d23f7a6d05cc14e94c26fd8d3261d0f""><code>b9ecb4d</code></a> Fix false positive for <code>useless-super-delegation</code> for variadics (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/6949"">#6949</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/f881219a66deaf9cef6467ba27c3385bc98dad82""><code>f881219</code></a> Bump pylint to 2.14.2, update changelog</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/988d882b56f9eca8ba1825b86b59e92b824ca1c3""><code>988d882</code></a> Treat <code>--errors-only</code> as a disable, not a paired enable/disable (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/6937"">#6937</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/386e7782b78a6e1baf0edd57cff893f3a08fb33c""><code>386e778</code></a> Mix incorrect parsing of multi-line optio",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11971:952,variab,variable,952,https://hail.is,https://github.com/hail-is/hail/pull/11971,1,['variab'],['variable']
Modifiability,"Bumps [pylint](https://github.com/PyCQA/pylint) from 2.13.5 to 2.14.4.; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/PyCQA/pylint/commit/bf29a5520e8d0e432ca715e0614a62052b3809e2""><code>bf29a55</code></a> Bump pylint to 2.14.4, update changelog</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/15470d10f74adb8fd3fab599097a8da8c10ec515""><code>15470d1</code></a> Fix recognition of config files named <code>setup.cfg</code> (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/3630"">#3630</a>) (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/6577"">#6577</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/e8202000e046e286816375f5887110cacda4d11b""><code>e820200</code></a> Normalize path before checking if path should be ignored (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7080"">#7080</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/c82d08c8433de92433b9b555dd2eb50a7987060f""><code>c82d08c</code></a> Don't report <code>import-private-name</code> for relative imports (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7079"">#7079</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/f8f05f12522c0036668f9a0da86fa0d3456ed795""><code>f8f05f1</code></a> Don't emit <code>modified-iterating-dict</code> when updating existing keys (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7037"">#7037</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/bee24cd55af4f1231e787aed5a1cc072492adee6""><code>bee24cd</code></a> Avoid hangs on many-core Windows machines (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7035"">#7035</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/b379ef3acc2a983140994c93a2ea2c99e260c9c1""><code>b379ef3</code></a> Fix handling of quoted <code>init-hook</code> (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7010"">#7010</a>)</li>; <li><a href=""https",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11980:420,config,config,420,https://hail.is,https://github.com/hail-is/hail/pull/11980,1,['config'],['config']
Modifiability,"Bumps [pylint](https://github.com/PyCQA/pylint) from 2.13.5 to 2.15.3.; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/PyCQA/pylint/commit/403dac602ee01e317a22800e0d63bdeb0c2faa7e""><code>403dac6</code></a> Bump pylint to 2.15.3, update changelog</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/38e278401a66218fba26308fbce56740761a2003""><code>38e2784</code></a> Bump astroid to 2.12.10</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/f5e168e867799013fb380aa9fe8a0c1516a651c8""><code>f5e168e</code></a> Fix <code>undefined-loop-variable</code> with <code>NoReturn</code> and <code>Never</code> (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7476"">#7476</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/fbc9e663473fa0416779f1d71109b4123f6c3365""><code>fbc9e66</code></a> Accept a comma-separated list of messages IDs in <code>--help-msg</code> (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7490"">#7490</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/fe3436efb0ec10677ba1539ac02e26cb3f852cbb""><code>fe3436e</code></a> False positive <code>global-variable-not-assigned</code> (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7479"">#7479</a>)</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/52cf631d732f7b39a879adf7e617e0aa7059a83a""><code>52cf631</code></a> [invalid-class-object] Fix crash when <strong>class</strong> is defined with a tuple</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/8e05ff6acf30deae5d83ea3847ec47ed0bf049a4""><code>8e05ff6</code></a> Fix a crash in the <code>modified-iterating-dict</code> checker involving instance attri...</li>; <li><a href=""https://github.com/PyCQA/pylint/commit/9b359ad676dff97a35321976c19ca0f6c4fc44ad""><code>9b359ad</code></a> Fix <code>unhashable-member</code> crash when <code>lambda</code> used as a dict key (<a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/7454"">#7454</a>)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12240:575,variab,variable,575,https://hail.is,https://github.com/hail-is/hail/pull/12240,1,['variab'],['variable']
Modifiability,"Bumps [pylint](https://github.com/PyCQA/pylint) from 2.6.0 to 2.12.2.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/PyCQA/pylint/releases"">pylint's releases</a>.</em></p>; <blockquote>; <h2>pylint-2.8.1</h2>; <ul>; <li>; <p>Add numversion back (temporarily) in <code>__pkginfo__</code> because it broke Pylama and revert the unnecessary; <code>pylint.version</code> breaking change.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/4399"">#4399</a></p>; </li>; </ul>; <h2>pylint-2.8.0</h2>; <ul>; <li>; <p>New refactoring message <code>consider-using-with</code>. This message is emitted if resource-allocating functions or methods of the; standard library (like <code>open()</code> or <code>threading.Lock.acquire()</code>) that can be used as a context manager are called without; a <code>with</code> block.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/3413"">#3413</a></p>; </li>; <li>; <p>Resolve false positives on unused variables in decorator functions</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/4252"">#4252</a></p>; </li>; <li>; <p>Add new extension <code>ConfusingConsecutiveElifChecker</code>. This optional checker emits a refactoring message (R5601 <code>confusing-consecutive-elif</code>); if if/elif statements with different indentation levels follow directly one after the other.</p>; </li>; <li>; <p>New option <code>--output=&lt;file&gt;</code> to output result to a file rather than printing to stdout.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/1070"">#1070</a></p>; </li>; <li>; <p>Use a prescriptive message for <code>unidiomatic-typecheck</code></p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/3891"">#3891</a></p>; </li>; <li>; <p>Apply <code>const-naming-style</code> to module constants annotated with; <code>typing.Final</code></p>; </li>; <li",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11461:591,refactor,refactoring,591,https://hail.is,https://github.com/hail-is/hail/pull/11461,2,['refactor'],['refactoring']
Modifiability,"Bumps [pytest](https://github.com/pytest-dev/pytest) from 6.2.5 to 7.0.1.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/pytest-dev/pytest/releases"">pytest's releases</a>.</em></p>; <blockquote>; <h2>7.0.1</h2>; <h1>pytest 7.0.1 (2022-02-11)</h1>; <h2>Bug Fixes</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9608"">#9608</a>: Fix invalid importing of <code>importlib.readers</code> in Python 3.9.</li>; <li><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9610"">#9610</a>: Restore [UnitTestFunction.obj]{.title-ref} to return unbound rather than bound method.; Fixes a crash during a failed teardown in unittest TestCases with non-default [__init__]{.title-ref}.; Regressed in pytest 7.0.0.</li>; <li><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9636"">#9636</a>: The <code>pythonpath</code> plugin was renamed to <code>python_path</code>. This avoids a conflict with the <code>pytest-pythonpath</code> plugin.</li>; <li><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9642"">#9642</a>: Fix running tests by id with <code>::</code> in the parametrize portion.</li>; <li><a href=""https://github-redirect.dependabot.com/pytest-dev/pytest/issues/9643"">#9643</a>: Delay issuing a <code>~pytest.PytestWarning</code>{.interpreted-text role=&quot;class&quot;} about diamond inheritance involving <code>~pytest.Item</code>{.interpreted-text role=&quot;class&quot;} and; <code>~pytest.Collector</code>{.interpreted-text role=&quot;class&quot;} so it can be filtered using <code>standard warning filters &lt;warnings&gt;</code>{.interpreted-text role=&quot;ref&quot;}.</li>; </ul>; <h2>7.0.0</h2>; <h1>pytest 7.0.0 (2022-02-03)</h1>; <p>(<strong>Please see the full set of changes for this release also in the 7.0.0rc1 notes below</strong>)</p>; <h2>Deprecations</h2>; <ul>; <li>; <p><a href=""https://github-redirect.dependabot.com/pytest-dev/pyte",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11516:932,plugin,plugin,932,https://hail.is,https://github.com/hail-is/hail/pull/11516,3,['plugin'],['plugin']
Modifiability,"Bumps [rich](https://github.com/Textualize/rich) from 12.6.0 to 13.7.0.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/Textualize/rich/releases"">rich's releases</a>.</em></p>; <blockquote>; <h2>The &quot;It's a wrap&quot; release</h2>; <h2>[13.7.0] - 2023-11-15</h2>; <h3>Added</h3>; <ul>; <li>Adds missing parameters to Panel.fit <a href=""https://redirect.github.com/Textualize/rich/issues/3142"">Textualize/rich#3142</a></li>; </ul>; <h3>Fixed</h3>; <ul>; <li>Some text goes missing during wrapping when it contains double width characters <a href=""https://redirect.github.com/Textualize/rich/issues/3176"">Textualize/rich#3176</a></li>; <li>Ensure font is correctly inherited in exported HTML <a href=""https://redirect.github.com/Textualize/rich/issues/3104"">Textualize/rich#3104</a></li>; <li>Fixed typing for <code>FloatPrompt</code>.</li>; </ul>; <h2>The Python 3.12 release</h2>; <p>Mostly a meta update in readiness for the release of Python3.12</p>; <h2>[13.6.0] - 2023-09-30</h2>; <h3>Added</h3>; <ul>; <li>Added Python 3.12 to classifiers.</li>; </ul>; <h2>Markdown fixes</h2>; <h2>[13.5.3] - 2023-09-17</h2>; <h3>Fixed</h3>; <ul>; <li>Markdown table rendering issue with inline styles and links <a href=""https://redirect.github.com/Textualize/rich/issues/3115"">Textualize/rich#3115</a></li>; <li>Fix Markdown code blocks on a light background <a href=""https://redirect.github.com/Textualize/rich/issues/3123"">Textualize/rich#3123</a></li>; </ul>; <h2>v13.5.2</h2>; <p>Bugfix</p>; <h2>[13.5.2] - 2023-08-01</h2>; <h3>Fixed</h3>; <ul>; <li>Fixed Text.expand_tabs assertion error</li>; </ul>; <h2>v13.5.1</h2>; <p>Very minor update to URL highlighting</p>; <h2>[13.5.1] - 2023-07-31</h2>; <h3>Fixed</h3>; <ul>; <li>Fix tilde character (<code>~</code>) not included in link regex when printing to console <a href=""https://redirect.github.com/Textualize/rich/issues/3057"">Textualize/rich#3057</a></li>; </ul>; <h2>Mostly cake, one or two puppies</h2",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14012:714,inherit,inherited,714,https://hail.is,https://github.com/hail-is/hail/pull/14012,2,['inherit'],['inherited']
Modifiability,"Bumps [rich](https://github.com/Textualize/rich) from 12.6.0 to 13.7.1.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/Textualize/rich/releases"">rich's releases</a>.</em></p>; <blockquote>; <h2>v13.7.1</h2>; <p>Fixes some character widths</p>; <h2>[13.7.1] - 2023-02-28</h2>; <h3>Fixed</h3>; <ul>; <li>Updated the widths of some characters <a href=""https://redirect.github.com/Textualize/rich/pull/3289"">Textualize/rich#3289</a></li>; </ul>; <h2>The &quot;It's a wrap&quot; release</h2>; <h2>[13.7.0] - 2023-11-15</h2>; <h3>Added</h3>; <ul>; <li>Adds missing parameters to Panel.fit <a href=""https://redirect.github.com/Textualize/rich/issues/3142"">Textualize/rich#3142</a></li>; </ul>; <h3>Fixed</h3>; <ul>; <li>Some text goes missing during wrapping when it contains double width characters <a href=""https://redirect.github.com/Textualize/rich/issues/3176"">Textualize/rich#3176</a></li>; <li>Ensure font is correctly inherited in exported HTML <a href=""https://redirect.github.com/Textualize/rich/issues/3104"">Textualize/rich#3104</a></li>; <li>Fixed typing for <code>FloatPrompt</code>.</li>; </ul>; <h2>The Python 3.12 release</h2>; <p>Mostly a meta update in readiness for the release of Python3.12</p>; <h2>[13.6.0] - 2023-09-30</h2>; <h3>Added</h3>; <ul>; <li>Added Python 3.12 to classifiers.</li>; </ul>; <h2>Markdown fixes</h2>; <h2>[13.5.3] - 2023-09-17</h2>; <h3>Fixed</h3>; <ul>; <li>Markdown table rendering issue with inline styles and links <a href=""https://redirect.github.com/Textualize/rich/issues/3115"">Textualize/rich#3115</a></li>; <li>Fix Markdown code blocks on a light background <a href=""https://redirect.github.com/Textualize/rich/issues/3123"">Textualize/rich#3123</a></li>; </ul>; <h2>v13.5.2</h2>; <p>Bugfix</p>; <h2>[13.5.2] - 2023-08-01</h2>; <h3>Fixed</h3>; <ul>; <li>Fixed Text.expand_tabs assertion error</li>; </ul>; <h2>v13.5.1</h2>; <p>Very minor update to URL highlighting</p>; <!-- raw HTML omitted -->; </blockquot",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14376:966,inherit,inherited,966,https://hail.is,https://github.com/hail-is/hail/pull/14376,2,['inherit'],['inherited']
Modifiability,"Bumps [sphinx-rtd-theme](https://github.com/readthedocs/sphinx_rtd_theme) from 1.3.0 to 2.0.0.; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/readthedocs/sphinx_rtd_theme/blob/master/docs/changelog.rst"">sphinx-rtd-theme's changelog</a>.</em></p>; <blockquote>; <h1>2.0.0</h1>; <h2>Added</h2>; <ul>; <li>Support for Sphinx versions <code>6.x</code> and <code>7.x</code></li>; <li>Support for docutils <code>&lt;=0.20</code></li>; </ul>; <h2>Deprecations</h2>; <ul>; <li>The HTML4 writer is now officially deprecated. An error will be thrown if your; project configuration still uses the HTML4 writer.</li>; <li>Support for Sphinx versions &lt; 5.0 was removed.</li>; <li>In addition, our supported dependencies will match the dependencies from our; lowest supported Sphinx release, version 5.0: Python &gt;= 3.6 and docutils &gt; 0.14 and &lt; 0.19</li>; </ul>; <p>.. _release-1.3.0:</p>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/readthedocs/sphinx_rtd_theme/commit/7c9b1b5d391f6d7fae72274393eb25d1df96e546""><code>7c9b1b5</code></a> Release 2.0 final (<a href=""https://redirect.github.com/readthedocs/sphinx_rtd_theme/issues/1544"">#1544</a>)</li>; <li><a href=""https://github.com/readthedocs/sphinx_rtd_theme/commit/c1044107602faf9be43e4358bc4f8b6abff9b420""><code>c104410</code></a> Bump for next potential release, 2.0.0rc5 (<a href=""https://redirect.github.com/readthedocs/sphinx_rtd_theme/issues/1539"">#1539</a>)</li>; <li><a href=""https://github.com/readthedocs/sphinx_rtd_theme/commit/53ca116ef64123735e5e445258b8b103ad31a26e""><code>53ca116</code></a> Release 2.0.0rc4 (<a href=""https://redirect.github.com/readthedocs/sphinx_rtd_theme/issues/1538"">#1538</a>)</li>; <li><a href=""https://github.com/readthedocs/sphinx_rtd_theme/commit/4498e97b462688bac2ff3615ac1da1b867b21842""><code>4498e97</code></a> Fix AttributeError when one of <code>css_files</code> is a string (<a href=""https://redire",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14502:600,config,configuration,600,https://hail.is,https://github.com/hail-is/hail/pull/14502,1,['config'],['configuration']
Modifiability,"Bumps [urllib3](https://github.com/urllib3/urllib3) from 1.26.5 to 1.26.8.; <details>; <summary>Release notes</summary>; <p><em>Sourced from <a href=""https://github.com/urllib3/urllib3/releases"">urllib3's releases</a>.</em></p>; <blockquote>; <h2>1.26.8</h2>; <p><strong>If you or your organization rely on urllib3 consider supporting us via <a href=""https://github.com/sponsors/urllib3"">GitHub Sponsors</a>.</strong></p>; <p>:warning: <strong>urllib3 v2.0 will drop support for Python 2</strong>: <a href=""https://urllib3.readthedocs.io/en/latest/v2-roadmap.html"">Read more in the v2.0 Roadmap</a></p>; <p>:warning: <strong>This release will be the last release supporting Python 3.5. Please upgrade to a non-EOL Python version.</strong></p>; <ul>; <li>Added extra message to<code>urllib3.exceptions.ProxyError</code> when urllib3 detects that a proxy is configured to use HTTPS but the proxy itself appears to only use HTTP.</li>; <li>Added a mention of the size of the connection pool when discarding a connection due to the pool being full.</li>; <li>Added explicit support for Python 3.11.</li>; <li>Deprecated the <code>Retry.MAX_BACKOFF</code> class property in favor of <code>Retry.DEFAULT_MAX_BACKOFF</code> to better match the rest of the default parameter names. <code>Retry.MAX_BACKOFF</code> is removed in v2.0.</li>; <li>Changed location of the vendored <code>ssl.match_hostname</code> function from <code>urllib3.packages.ssl_match_hostname</code> to <code>urllib3.util.ssl_match_hostname</code> to ensure Python 3.10+ compatibility after being repackaged by downstream distributors.</li>; <li>Fixed absolute imports, all imports are now relative.</li>; </ul>; <h2>1.26.7</h2>; <p>:warning: <strong>IMPORTANT: urllib3 v2.0 will drop support for Python 2</strong>: <a href=""https://urllib3.readthedocs.io/en/latest/v2-roadmap.html"">Read more in the v2.0 Roadmap</a></p>; <ul>; <li>Fixed a bug with HTTPS hostname verification involving IP addresses and lack of SNI</li>; <li>Fixed a bug ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11532:856,config,configured,856,https://hail.is,https://github.com/hail-is/hail/pull/11532,1,['config'],['configured']
Modifiability,"Bumps [zipp](https://github.com/jaraco/zipp) from 3.17.0 to 3.18.1.; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/jaraco/zipp/blob/main/NEWS.rst"">zipp's changelog</a>.</em></p>; <blockquote>; <h1>v3.18.1</h1>; <p>No significant changes.</p>; <h1>v3.18.0</h1>; <h2>Features</h2>; <ul>; <li>Bypass ZipFile.namelist in glob for better performance. (<a href=""https://redirect.github.com/jaraco/zipp/issues/106"">#106</a>)</li>; <li>Refactored glob functionality to support a more generalized solution with support for platform-specific path separators. (<a href=""https://redirect.github.com/jaraco/zipp/issues/108"">#108</a>)</li>; </ul>; <h2>Bugfixes</h2>; <ul>; <li>Add special accounting for pypy when computing the stack level for text encoding warnings. (<a href=""https://redirect.github.com/jaraco/zipp/issues/114"">#114</a>)</li>; </ul>; </blockquote>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/jaraco/zipp/commit/bfae83474a730e8cc9b8a71027fb859b46b3875c""><code>bfae834</code></a> Finalize</li>; <li><a href=""https://github.com/jaraco/zipp/commit/487066ec9757c3c82e96014d0b30906996c6280d""><code>487066e</code></a> Merge changelog into last release.</li>; <li><a href=""https://github.com/jaraco/zipp/commit/4584ee2dcfb10d5314ad319d9d5b140c90bc2951""><code>4584ee2</code></a> Move changelog entry, saved to the wrong location :(</li>; <li><a href=""https://github.com/jaraco/zipp/commit/3c06d30b91b37a118536d9d424e0a8b893e78a6e""><code>3c06d30</code></a> Finalize</li>; <li><a href=""https://github.com/jaraco/zipp/commit/48b72b8db6ae5f7712323aca6b340744db15f576""><code>48b72b8</code></a> Merge pull request <a href=""https://redirect.github.com/jaraco/zipp/issues/113"">#113</a> from jaraco/feature/glob-perf</li>; <li><a href=""https://github.com/jaraco/zipp/commit/171fa98236a1adfc316c3bc5cdc5eaa4b9548424""><code>171fa98</code></a> Add news fragment.</li>; <li><a href=""https://github.com/jaraco/zipp/commit/ac8ea7a5",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14473:471,Refactor,Refactored,471,https://hail.is,https://github.com/hail-is/hail/pull/14473,1,['Refactor'],['Refactored']
Modifiability,C5Compiled.__m7split_Let(Emit.scala); 	at __C5Compiled.apply(Emit.scala); 	at is.hail.expr.ir.CompileAndEvaluate$.$anonfun$_apply$7(CompileAndEvaluate.scala:74); 	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.CompileAndEvaluate$._apply(CompileAndEvaluate.scala:74); 	at is.hail.expr.ir.CompileAndEvaluate$.$anonfun$apply$1(CompileAndEvaluate.scala:19); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.CompileAndEvaluate$.apply(CompileAndEvaluate.scala:19); 	at is.hail.expr.ir.lowering.LowerDistributedSort$.distributedSort(LowerDistributedSort.scala:163); 	at is.hail.backend.service.ServiceBackend.lowerDistributedSort(ServiceBackend.scala:356); 	at is.hail.backend.Backend.lowerDistributedSort(Backend.scala:100); 	at is.hail.expr.ir.lowering.LowerAndExecuteShuffles$.$anonfun$apply$1(LowerAndExecuteShuffles.scala:23); 	at is.hail.expr.ir.RewriteBottomUp$.$anonfun$apply$4(RewriteBottomUp.scala:26); 	at is.hail.utils.StackSafe$More.advance(StackSafe.scala:60); 	at is.hail.utils.StackSafe$.run(StackSafe.scala:16); 	at is.hail.utils.StackSafe$StackFrame.run(StackSafe.scala:32); 	at is.hail.expr.ir.RewriteBottomUp$.apply(RewriteBottomUp.scala:36); 	at is.hail.expr.ir.lowering.LowerAndExecuteShuffles$.apply(LowerAndExecuteShuffles.scala:20); 	at is.hail.expr.ir.lowering.LowerAndExecuteShufflesPass.transform(LoweringPass.scala:157); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:16); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:16); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:14); 	at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:13); 	at is.hail.expr.ir.lowering.LowerAndExecuteShufflesPass.apply(LoweringP,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12983:7756,Rewrite,RewriteBottomUp,7756,https://hail.is,https://github.com/hail-is/hail/issues/12983,4,['Rewrite'],['RewriteBottomUp']
Modifiability,CF$extension(VariantDataset.scala:425); E at is.hail.variant.VariantDatasetFunctions.exportVCF(VariantDataset.scala:425); E at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); E at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); E at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); E at java.lang.reflect.Method.invoke(Method.java:498); E at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); E at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); E at py4j.Gateway.invoke(Gateway.java:280); E at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); E at py4j.commands.CallCommand.execute(CallCommand.java:79); E at py4j.GatewayConnection.run(GatewayConnection.java:214); E at java.lang.Thread.run(Thread.java:748)java.lang.ClassNotFoundException: Class org.apache.hadoop.mapred.DirectFileOutputCommitter not found; E at org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:2101); E at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2193); E at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2219); E at org.apache.hadoop.mapred.JobConf.getOutputCommitter(JobConf.java:726); E at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply$mcV$sp(PairRDDFunctions.scala:1051); E at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1035); E at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1035); E at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); E at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); E at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); E at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1035); E at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$3.apply$mcV$sp(PairRDDFunctions,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3946:11546,Config,Configuration,11546,https://hail.is,https://github.com/hail-is/hail/issues/3946,1,['Config'],['Configuration']
Modifiability,"CHANGELOG: ABS blob URIs in the format of `https://<ACCOUNT_NAME>.blob.core.windows.net/<CONTAINER_NAME>/<PATH>` are now supported. The `hail-az` scheme for referencing blobs in ABS is now deprecated and will be removed in an upcoming release. This PR introduces the https addressing of blobs in ABS and phases out hail-az. The test suite converts completely to testing `https`, but both schemes are still supported. We can have confidence that this did not break completely break the `hail-az` scheme because our test bucket configuration is still using `hail-az` (and must until this PR is merged. So some of the test suite + all the service backend tests are flexing the `https` code path, and then the inter_cloud tests are flexing the `hail-az` code path. After this merges, we'll need the following PRs. - Update the azure terraform to use `https` instead of `hail-az` and apply the changes; - Remove support for the hail-az scheme. This will be a breaking change as the copy tool and batch worker will stop being able to transfer files and logs for that scheme. It seems like there is large support for dropping this scheme entirely though so I'd rather make this change while there is little use on azure.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12917:526,config,configuration,526,https://hail.is,https://github.com/hail-is/hail/pull/12917,1,['config'],['configuration']
Modifiability,"CHANGELOG: Add `hl.pgenchisq` the cumulative distribution function of the generalized chi-squared distribution. The [Generalized Chi-Squared; Distribution](https://en.wikipedia.org/wiki/Generalized_chi-squared_distribution) arises from weighted sums of sums of squares of independent normally distributed variables and is used by `hl.skat` to generate p-values. The simplest formulation I know for it is this:. w : R^n; k : Z^n; lam : R^n; mu : R; sigma : R. x ~ N(mu, sigma^2); y_i ~ NonCentralChiSquared(k_i, lam_i). Z = x + w y^T; = x + sum_i{ w_i y_i }; Z ~ GeneralizedNonCentralChiSquared(w, k, lam, mu, sigma). The non-central chi-squared distribution arises from a sum of independent normally distributed variables with non-zero mean and unit variance. The non-centrality parameter, lambda, is defined as the sum of the squares of the means of each component normal random variable. Although the non-central chi-squared distribution has a closed form implementation (indeed, Hail implements this CDF: `hl.pchisqtail`), the generalized chi-squared distribution does not have a closed form. There are at least four distinct algorithms for evaluating the CDF. To my knowledge, the oldest one is by Robert Davies:. Davies, Robert. ""The distribution of a linear combination of chi-squared; random variables."" Applied Statistics 29 323-333. 1980. The [original publication](http://www.robertnz.net/pdf/lc_chisq.pdf) includes a Fortran implementation in the publication. Davies' [website](http://www.robertnz.net/QF.htm) also includes a C version. Hail includes a copy of the C version as `davies.cpp`. I suspect this code contains undefined behavior. Moreover, it is not supported on Apple M1 machines because we don't ship binaries for that platform. It seemed to me that the simplest solution is to port this algorithm to Scala. This PR is that port. I tested against the 39 test cases provided Davies with the source code. I also added some doctests based on the CDF plots from Wikipedia. The same",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12605:305,variab,variables,305,https://hail.is,https://github.com/hail-is/hail/pull/12605,3,['variab'],"['variable', 'variables']"
Modifiability,"CHANGELOG: Added `Job.run_when()` which allows you to specify under what conditions a job should run based on the state of its parent dependencies and whether the job is cancellable. The gist of this PR is that we now have an extra variable `run_condition` which specifies under what conditions a job should run (any, all, always). The default is to maintain the current behavior that a job runs when all its parent dependencies succeeded. The semantics of `always_run` should stay the same. Can you check over the jobs_after_update trigger and make sure I'm not crazy and nothing needs to be modified there since the job state where the cancelled state matters is a Ready or Running job and the run_condition / cancelled interaction applies to Pending jobs with parent dependencies. Also, I did this crazily fast, so maybe I'm missing something and it shouldn't be this easy????",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12365:232,variab,variable,232,https://hail.is,https://github.com/hail-is/hail/pull/12365,1,['variab'],['variable']
Modifiability,"CHANGELOG: Added a new method Job.regions() as well as a configurable parameter to the ServiceBackend to specify which cloud regions a job can run in. The default value is a job can run in any available region. Stacked on #12212 . This PR threads through region requests from the user and feeds that information into the scheduler. The architecture of a pool per machine type has not changed. We explicitly chose not to have a new pool per region x machine_type. Instead, the control loop looks at the front of the job queue and tries to predict which jobs are likely to be scheduled. From those jobs, we then find which regions the jobs can run in and create the number of corresponding instances. We use the fair share calculation to estimate how many jobs per user can be scheduled in 2.5 minutes assuming the scheduling loop runs once per second. We then grab this many jobs from the queue for each user and estimate the ""scheduling iteration"" at which each iteration of the scheduler each chunk of user jobs would be scheduled. We sort the overall set of jobs that we've chosen by the ""scheduling iteration"". We also include the regions as part of the sorting queries with None (any region) being sorted last. This is to compact the free cores across jobs so as to avoid fragmentation of instances created and for jobs with no region specifications to fill in the remaining cores in any region. For the hailtop.batch client, I added a new setting in `~/.config/hail` to set the default regions for all jobs in the ServiceBackend and a new method on `Job` that sets the list of regions to run in. Things to double check once everything is working is the sort orders on the scheduling queries are correct. . Once this PR goes in, then we can merge #11840 with some minor changes. There will also be a follow-up PR that gets rid of the CI-specific code in the scheduler.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12221:57,config,configurable,57,https://hail.is,https://github.com/hail-is/hail/pull/12221,2,['config'],"['config', 'configurable']"
Modifiability,CHANGELOG: Added hailctl config setting 'batch/backend' to specify the default backend to use in batch scripts when not specified in code. This is more consistent now with `HAIL_QUERY_BACKEND` and makes it less boilerplate-y to use the service. cc: @danking,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12522:25,config,config,25,https://hail.is,https://github.com/hail-is/hail/pull/12522,1,['config'],['config']
Modifiability,"CHANGELOG: Adds close, default implementation pass, to Backend as an abstract method. This reduces the number of conditional statements needed by 1 when using variable backends. Variable backends (Local or Service) are useful when prototyping batches, or when the user will know in advance that a particular batch routine will work locally (since in future work it will be much easier to consume dockerized methods using Batch than anything else). Additionally, as provided, the only Batch tutorial, GWAS clumping will not work with LocalBackend without this. Use case:. ```python; parser.add_argument('--local', required=False, action=""store_true""); if is_local:; backend = hb.LocalBackend(); run_opts = {}; else:; backend = hb.ServiceBackend(); run_opts = {open: True, wait: True}. # do a bunch of Batch stuff to ; batch.run(**run_opts); backend.close(); ```. In a similar vein, I'd like to allow LocalBackend to ignore unused run opts. Again, GWAS tutorial would not work with LocalBackend without this (or an opts dict as above).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9191:159,variab,variable,159,https://hail.is,https://github.com/hail-is/hail/pull/9191,2,"['Variab', 'variab']","['Variable', 'variable']"
Modifiability,"CHANGELOG: Batch ServiceBackend now requires a bucket for intermediate files, either explicitly or through the batch/bucket config setting. Other changes:; - moved notebook/user to auth/user (more appropriate there); - auth no longer creates bucket during user creation",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8834:124,config,config,124,https://hail.is,https://github.com/hail-is/hail/pull/8834,1,['config'],['config']
Modifiability,CHANGELOG: Changed cost per instance from $0.02170 to $0.021935 from switching to using local SSDs. - Added 1 local SSD (375 GB) and formatted it in the worker run script.; - Changed the resource for boot-disk to just disk and modified the worker config. I figured there was no reason to have a separate boot disk in the resources as long as all disks are assumed to be fractions of the instance based on the number of cores being used.; - Changed the worker boot disk from 100 GB to 20 GB; - Changed the worker to move all docker files and batch files to the Local SSD from the boot disk. Can you double check my math for the documentation?. Is it possible it takes longer for an instance to boot up with a local SSD? One of my earlier tests had workers stuck in STAGING. This resolved itself later on so I'm assuming it was a Google error.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8844:247,config,config,247,https://hail.is,https://github.com/hail-is/hail/pull/8844,1,['config'],['config']
Modifiability,"CHANGELOG: Fixed bug where making NDArrays of non-numeric types would fail. Non-numeric ndarrays still cannot be collected to python though. . NDArrays of non numeric types are broken, have been for a while. No one seems to use them for that currently, so it hasn't been an issue, but I suspect with `dndarray` or BlockedMatrixTable experiments it's going to be desirable. . This PR starts to address that problem by doing the following:. 1. `checkedConvertFrom`, which only supported primitive arrays, is replaced with the more flexible `copyFromType`. As this was the only use of `checkedConvertFrom`, I removed it altogether. . 2. Add tests that show that it's now possible to make an ndarray of non-numeric types, so long as the only things that get returned in python are numbers. The remaining problems all involve conversions to numpy. If you never convert to numpy, things should be fine:. 1. I need to get strides out of the Java ndarray representation. Strides make no sense for non-numeric objects after converting from Java to Python. We say the size of a required tuple of 3 int32's is 12 bytes, but that's not going to be the size of the python object. 2. Strings are tricky too, since the numpy string dtype comes with a max length, so we'll have to do a pass over the strings to figure out how large the largest one is before converting.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9503:529,flexible,flexible,529,https://hail.is,https://github.com/hail-is/hail/pull/9503,1,['flexible'],['flexible']
Modifiability,"CHANGELOG: Fixed bugs in the identity by descent implementation for Query on Batch. This PR fixes #14052. There were two bugs in how we compute IBD. In addition, the tests weren't running in QoB and the test dataset we were using doesn't have enough variability to catch errors. I used Balding Nichols generated data instead. Do we need to set the seed in the tests here?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14062:250,variab,variability,250,https://hail.is,https://github.com/hail-is/hail/pull/14062,1,['variab'],['variability']
Modifiability,"CHANGELOG: Hail Query-on-Batch previously used Class A Operations for all interaction with blobs. This change ensures that QoB only uses Class A Operations when necessary. Inspired by @jigold 's file system improvement campaign, I pursued the avoidance of ""list"" operations. I anticipate this reduces flakiness in Azure (which is tracked in #13351) and cost in Azure. I enforced aiotools.fs terminology on hail.fs and Scala:. 1. `FileStatus`. Metadata about a blob or file. It does not know if a directory exists at this path. 2. `FileListEntry`. Metadata from a list operation. It knows if a directory exists at this path. Variable names were updated to reflect this distinction:. 1. `fileStatus` / `fileStatuses`. 2. `fle`/ `fles` / `fileListEntry` / `fileListEntries`, respectively. `listStatus` renamed to `listDirectory` for clarity. In both Azure and Google, `fileStatus` does not use a list operation. `fileListEntry` can be used when we must know if a directory exists. I just rewrote this from first principles because:; 1. In neither Google nor Azure did it check if the path was a directory and a file.; 2. In Google, if the directory entry wasn't in the first page, it would fail (NB: there are fifteen non-control characters in ASCII before `/`, if the page size is 15 or fewer, we'd miss the first entry with a `/` at the end).; 3. In Azure, we issued both a get and a list. There are now unit tests for this method. ---. 1. `copyMerge` and `concatenateFiles` previously used `O(N_FILES)` list operations, they now use `O(N_FILES)` get operations.; 2. Writers that used `exists` to check for a _SUCCESS file now use a get operation.; 3. Index readers, import BGEN, and import plink all now check file size with a get operation. That said, overall, the bulk of our Class A Operations are probably writes.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13885:624,Variab,Variable,624,https://hail.is,https://github.com/hail-is/hail/pull/13885,1,['Variab'],['Variable']
Modifiability,"CHANGELOG: Hail Query-on-Batch previously used Class A Operations for all interaction with blobs. This change ensures that QoB only uses Class A Operations when necessary. Inspired by @jigold 's file system improvement campaign, I pursued the avoidance of ""list"" operations. I anticipate this reduces flakiness in Azure (which is tracked in #13351) and cost in Azure. I enforced aiotools.fs terminology on hail.fs and Scala:. 1. `FileStatus`. Metadata about a blob or file. It does not know if a directory exists at this path. 2. `FileListEntry`. Metadata from a list operation. It knows if a directory exists at this path. Variable names were updated to reflect this distinction:. 1. `fileStatus` / `fileStatuses`. 2. `fle`/ `fles` / `fileListEntry` / `fileListEntries`, respectively. `listStatus` renamed to `listDirectory` for clarity. In both Azure and Google, `fileStatus` does not use a list operation. `fileListEntry` can be used when we must know if a directory exists. I just rewrote this from first principles because:; 1. In neither Google nor Azure did it check if the path was a directory and a file.; 2. In Google, if the directory entry wasn't in the first page, it would fail (NB: there are fifteen non-control characters in ASCII before `/`, if the page size is 15 or fewer, we'd miss the first entry with a `/` at the end).; 3. In Azure, we issued both a get and a list. There are now unit tests for this method. ---. 1. `copyMerge` and `concatenateFiles` previously used `O(N_FILES)` list operations, they now use `O(N_FILES)` get operations.; 2. Writers that used `exists` to check for a _SUCCESS file now use a get operation.; 3. Index readers, import BGEN, and import plink all now check file size with a get operation. That said, overall, the bulk of our Class A Operations are probably writes. fix test failures. passes tests. fixes. fix tests to not use fileStatus for folders. only file vs directory status matters. fix azure. azure dislikes %. finally get azure right. nix e",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13883:624,Variab,Variable,624,https://hail.is,https://github.com/hail-is/hail/pull/13883,1,['Variab'],['Variable']
Modifiability,"CHANGELOG: Hail Query-on-Batch previously used Class A Operations for all interaction with blobs. This change ensures that QoB only uses Class A Operations when necessary. Inspired by @jigold 's file system improvement campaign, I pursued the avoidance of ""list"" operations. I anticipate this reduces flakiness in Azure (which is tracked in #13351) and cost in Azure. I enforced aiotools.fs terminology on hail.fs and Scala:. 1. `FileStatus`. Metadata about a blob or file. It does not know if a directory exists at this path. 2. `FileListEntry`. Metadata from a list operation. It knows if a directory exists at this path. Variable names were updated to reflect this distinction:. 1. `fileStatus` / `fileStatuses`. 2. `fle`/ `fles` / `fileListEntry` / `fileListEntries`, respectively. `listStatus` renamed to `listDirectory` for clarity. In both Azure and Google, `fileStatus` does not use a list operation. `getFileListEntry` can be used when we must know if a directory exists. I just rewrote this from first principles because:; 1. In neither Google nor Azure did it check if the path was a directory and a file.; 2. In Google, if the directory entry wasn't in the first page, it would fail (NB: there are fifteen non-control characters in ASCII before `/`, if the page size is 15 or fewer, we'd miss the first entry with a `/` at the end).; 3. In Azure, we issued both a get and a list. There are now unit tests for this method. ---. 1. `copyMerge` and `concatenateFiles` previously used `O(N_FILES)` list operations, they now use `O(N_FILES)` get operations.; 2. Writers that used `exists` to check for a _SUCCESS file now use a get operation.; 3. Index readers, import BGEN, and import plink all now check file size with a get operation. That said, overall, the bulk of our Class A Operations are probably writes.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13452:624,Variab,Variable,624,https://hail.is,https://github.com/hail-is/hail/pull/13452,1,['Variab'],['Variable']
Modifiability,"CHANGELOG: Hail `frozenlist` now has an eval-able `repr`. `hailtop.hail_frozenlist.frozenlist` previously inherited the `repr` of the `frozenlist` library:. > frozenlist([1, 2, 3]); <FrozenList(frozen=True, [1, 2, 3])>. With this change, I both use the fact that `frozen=True` for Hail frozenlists and use a printed form that is actually eval-able:. > frozenlist([1, 2, 3]); frozenlist([1, 2, 3]); > eval(repr(frozenlist([1, 2, 3]))); frozenlist([1, 2, 3])",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13422:106,inherit,inherited,106,https://hail.is,https://github.com/hail-is/hail/pull/13422,1,['inherit'],['inherited']
Modifiability,"CHANGELOG: Introduce `hailtop.fs` that makes public a filesystem module that works for local fs, gs, s3 and abs. This is now used as the `Backend.fs` for hail query but can be used standalone for Hail Batch users by `import hailtop.fs as hfs`. Still have to do the docs but a couple questions remain:. I create a hidden singleton `RouterFS` object so that is used by functions in `hailtop.fs`. Should this singleton also be used by the Hail Query backends when they are initialized? How do we propagate configuration information such as `requester_pays_bucket` to the FS?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12731:503,config,configuration,503,https://hail.is,https://github.com/hail-is/hail/pull/12731,1,['config'],['configuration']
Modifiability,CHANGELOG: Introduce `hl.fs.fast_stat` and `hl.hadoop_fast_stat` which use cheaper Class B Operations in Google Cloud Storage rather than Class A Operations. Users of `hl.hadoop_stat` and `hl.fs.stat` should consider switching. This PR extends https://github.com/hail-is/hail/pull/13883 into the public API.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13884:236,extend,extends,236,https://hail.is,https://github.com/hail-is/hail/pull/13884,1,['extend'],['extends']
Modifiability,CHANGELOG: Introduce `hl.fs.fast_stat` and `hl.hadoop_fast_stat` which use cheaper Class B Operations in Google Cloud Storage rather than Class A Operations. Users of `hl.hadoop_stat` and `hl.fs.stat` should consider switching. This PR extends https://github.com/hail-is/hail/pull/13885 into the public API.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13886:236,extend,extends,236,https://hail.is,https://github.com/hail-is/hail/pull/13886,1,['extend'],['extends']
Modifiability,"CHANGELOG: Mitigate #12936 in which VEP Dataproc clusters fail to start. The root cause is complex. Docker has a bug which prevents it from cleanly starting if it is *re* installed. Whatever Google is doing in Dataproc to configure their Docker ""component"" appears to trigger this bug. See for details: https://github.com/hail-is/hail/issues/12936#issuecomment-1709120751. The basic fix is to sleep to allow the system to coalesce a bit and then to restart Docker.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13580:222,config,configure,222,https://hail.is,https://github.com/hail-is/hail/pull/13580,1,['config'],['configure']
Modifiability,CHANGELOG: Refactored VCF combiner to support other GVCF schemas.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8942:11,Refactor,Refactored,11,https://hail.is,https://github.com/hail-is/hail/pull/8942,1,['Refactor'],['Refactored']
Modifiability,"CHANGELOG: Remove memory leak in `BlockMatrix.to_matrix_table_row_major` and `BlockMatrix.to_table_row_major`. Also, make the cache size used in both methods configurable. The `ref` variable was holding entire blocks in memory for no reason. It was a; vestiage of debugging. Moreover, the configurable cache permits users to fine tune; memory usage.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9501:158,config,configurable,158,https://hail.is,https://github.com/hail-is/hail/pull/9501,3,"['config', 'variab']","['configurable', 'variable']"
Modifiability,"CHANGELOG: Requester pays buckets now work in `hailtop.fs` and `hl.hadoop_*`. This has been broken since at least 0.2.115. I first check for an explicit argument or the standard hailctl configuration. If neither of those exist, I try to parse spark-defaults.conf with lots of error handling and warning.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13089:186,config,configuration,186,https://hail.is,https://github.com/hail-is/hail/pull/13089,1,['config'],['configuration']
Modifiability,"CHANGELOG: `hailctl batch submit` now propagates configuration environment variables to the submitted job. Copying the user's config file into the job feels hacky and rude. Now that everything is guaranteed to be using the `configuration_of` mechanism we can set the entire config through environment variables. Also, if the intention is that the job's environment should magically reflect what the user set up locally, we should use `configuration_of` so that `HAIL_BILLING_PROJECT=foo hailctl batch submit` actually works.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13506:49,config,configuration,49,https://hail.is,https://github.com/hail-is/hail/pull/13506,5,"['config', 'variab']","['config', 'configuration', 'variables']"
Modifiability,"CHANGELOG: `hl.Table.parallelize` is much more flexible and now successfully imports most Hail-compatible data. I really wanted to load the hail-is/hail pull requests into Hail. I did not want to specify; the types of all 271 fields. I souped up Hail's `impute_type`:. - If an empty array, set, dict or `None` appears at any nesting level, but a ""peer"" is non-empty and; non-missing, we accept the peer's type.; - We take the union of two struct types as long as they agree on their intersection.; - If we discover a dict that cannot be imputed as a Hail dict, we try to impute it as a struct. If you like this change, I'll add tests. Note: I had to change `HailType` to include `None`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10045:47,flexible,flexible,47,https://hail.is,https://github.com/hail-is/hail/pull/10045,1,['flexible'],['flexible']
Modifiability,"CHANGELOG: `hl.import_table` is up to twice as fast for small tables. The big change is optimizing for the single file, no filters case in which; we need not scan for the first extant row, that row *must* be in the first; partition, if it exists at all. Unfortunately there is no zero-RPC way to; determine the number of partitions in a table, so I must catch an error; about the lack of a zeroth partition. I also did some refactoring:. 1. Move some functions to a utility file and add lots of indents and newlines to make them readable.; 2. Use `hl.format` for constructing strings.; 3. Make `should_filter_line` into `should_remove_line` for clarity of name.; 4. Modify `should_remove_line` to use short-circuiting and/or instead of array folds.; 5. Modify `should_remove_line` to indicate (via returning None) when there are no filters enabled.; 6. Add types.; 7. Fix a bug where we assumed that `.collect()[0]` would be `None` if there were no values in the table. (It raises an error); 8. Deduplicate `hail.utils.deduplicate` (haha: I mean, there is already code for doing field dedupe)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11782:424,refactor,refactoring,424,https://hail.is,https://github.com/hail-is/hail/pull/11782,1,['refactor'],['refactoring']
Modifiability,"CHANGELOG: `hl.logistic_regression_rows`, `hl.poisson_regression_rows`, and `hl.skat` all now support configuration of the maximum number of iterations and the tolerance. I had to make some fixes to how we count the number of iterations. It was quite screwy. Now it should reliably report the correct number of iterations regardless of failure, non-convergence, or explosion. This was requested [on Zulip](https://hail.zulipchat.com/#narrow/stream/127634-Feature-Requests/topic/Convergence.20issues.20with.20hl.2Elogistic_regression_rows).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11759:102,config,configuration,102,https://hail.is,https://github.com/hail-is/hail/pull/11759,1,['config'],['configuration']
Modifiability,"CHANGELOG: make hail's optimization rewriting filters to interval-filters smarter and more robust. Completely rewrites ExtractIntervalFilters. Instead of matching against very specific patterns, and failing completely for things that don't quite match (e.g. an input is let bound, or the fold implementing ""locus is contained in a set of intervals"" is written slightly differently), this uses a standard abstract interpretation framework, which is almost completely insensitive to the form of the IR, only depending on the semantics. It also correctly handles missing key fields, where the previous implementation often produced an unsound transformation of the IR. Also adds a much more thorough test suite than we had before. At the top level, the analysis takes a boolean typed IR `cond` in an environment where there is a reference to some `key`, and produces a set `intervals`, such that `cond` is equivalent to `cond & intervals.contains(key)` (in other words `cond` implies `intervals.contains(key)`, or `intervals` contains all rows where `cond` is true). This means for instance it is safe to replace `TableFilter(t, cond)` with `TableFilter(TableFilterIntervals(t, intervals), cond)`. Then in a second pass it rewrites `cond` to `cond2`, such that `cond & (intervals.contains(key))` is equivalent to `cond2 & intervals.contains(key)` (in other words `cond` implies `cond2`, and `cond2 & intervals.contains(key)` implies `cond`). This means it is safe to replace the `TableFilter(t, cond)` with `TableFilter(TableFilterIntervals(t, intervals), cond2)`. A common example is when `cond` can be completely captured by the interval filter, i.e. `cond` is equivant to `intervals.contains(key)`, in which case we can take `cond2 = True`, and the `TableFilter` can be optimized away. This all happens in the function; ```scala; def extractPartitionFilters(ctx: ExecuteContext, cond: IR, ref: Ref, key: IndexedSeq[String]): Option[(IR, IndexedSeq[Interval])] = {; if (key.isEmpty) None; else {; val e",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13355:110,rewrite,rewrites,110,https://hail.is,https://github.com/hail-is/hail/pull/13355,1,['rewrite'],['rewrites']
Modifiability,"CVE-2019-11245 is a vulnerability in k8s that causes some (all?); containers without a runAsUser configuration to run; as user id 0, i.e. root. Jupyter refuses to start as root.; This change enables Jupyter to start successfully.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6678:97,config,configuration,97,https://hail.is,https://github.com/hail-is/hail/pull/6678,1,['config'],['configuration']
Modifiability,Can we combine the Hail Documentation Build Configuration with the regular Hail CI configuration?,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/735:44,Config,Configuration,44,https://hail.is,https://github.com/hail-is/hail/issues/735,2,"['Config', 'config']","['Configuration', 'configuration']"
Modifiability,"Changes the first argument that Emit expects to be a SparkFunctionContext, which currently holds a region and a SparkEnv (currently a stub; will be fleshed out as we start writing code to call back into Spark.) This should let us be more flexible in our ability to pass other necessary (non-IR-value) inputs, such as a hadoop configuration, to the function without relying on function argument ordering and accounting. builds on #5457.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5459:238,flexible,flexible,238,https://hail.is,https://github.com/hail-is/hail/pull/5459,2,"['config', 'flexible']","['configuration', 'flexible']"
Modifiability,"Changes to make sure that only the annotation datasets are visible on the docs page, now that the `datasets.json` config file contains all available datasets. Overview:. - In `datasets.json`, moved ""key_properties"" inside an ""annotation_db"" field, like `""annotation_db"": {""key_properties"": []}`, so that only the datasets with the ""annotation_db"" key are shown in the annotation DB docs page. Removed ""key_properties"" from non-annotation datasets. - Minor reformatting changes to docs page, added a reference genome column to the HTML table. - Updated deploy script to reflect the filename change from `annotation_db.json` to `datasets.json`. - Modified checks for keys in dicts from `assert key in doc, doc` to `assert key in doc` in `DatasetVersion.from_json()` and `Dataset.from_name_and_json()`. Since the `doc` that is passed to these methods from the checked in JSON file is just a dict like `doc = {""annotation_db"": {""key_properties"": [...]}, ""description"": ..., ""url"": ..., ""versions"": [...]}` this seems to work fine. Let me know if `key in doc, doc` form was used for other reasons I've overlooked.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9546:114,config,config,114,https://hail.is,https://github.com/hail-is/hail/pull/9546,1,['config'],['config']
Modifiability,"Changes:; - removed unused py4jVersion from build.gradle; - pin breeze native version to version required by spark. This was not easy! I do it by creating a configuration that just depends on Spark, and then a resolution rule for all configurations that says only accept the breeze natives version corresponding to the version requested by spark.; - determine sparkMajorVersion from sparkVersion (strip patch version); - in docs, everywhere we use SPARK_VERSION, also specify SCALA_VERSION. I verified 2.4.0.cloudera is built against Scala 2.11.; - added SCALA_VERSION to hail/Makefile; - make Makefile versions match build.gradle defaults (somewhat annoying they are duplicated)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8680:157,config,configuration,157,https://hail.is,https://github.com/hail-is/hail/pull/8680,2,['config'],"['configuration', 'configurations']"
Modifiability,Ci is currently failing because this variable is not defined.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6641:37,variab,variable,37,https://hail.is,https://github.com/hail-is/hail/pull/6641,1,['variab'],['variable']
Modifiability,Closes hail-is/hail-tasks#2. @danking Can you take a look at this before I start testing? I think the query/log4j.properties file still needs to be there to configure the logs that show up for the JVM and not the user's jobs.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11471:157,config,configure,157,https://hail.is,https://github.com/hail-is/hail/pull/11471,1,['config'],['configure']
Modifiability,"Closes https://github.com/hail-is/hail/issues/14485. Tested that this works by deploying the branch to my dev namespace and pointing my dev config at it:. ```bash; hailctl dev deploy -b iris-garden/hail:batch/deprecated-apis -s deploy_batch,add_developers; hailctl dev config set default_namespace irademac; ```. And then running the following:. ```python; from hailtop.batch import ServiceBackend; batch_client = await ServiceBackend(billing_project='test', remote_tmpdir='gs://irademac/test/')._batch_client(); # one of the deprecated endpoints; await batch_client._get(""/api/v1alpha/batches/402/jobs/1/log""); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14621:140,config,config,140,https://hail.is,https://github.com/hail-is/hail/pull/14621,2,['config'],['config']
Modifiability,Configure feature flags with environment variables,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8256:0,Config,Configure,0,https://hail.is,https://github.com/hail-is/hail/pull/8256,2,"['Config', 'variab']","['Configure', 'variables']"
Modifiability,Configure git user name and email in deploy.sh,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11351:0,Config,Configure,0,https://hail.is,https://github.com/hail-is/hail/pull/11351,1,['Config'],['Configure']
Modifiability,"Configure spark version once, re-use in future builds",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1613:0,Config,Configure,0,https://hail.is,https://github.com/hail-is/hail/pull/1613,1,['Config'],['Configure']
Modifiability,"Contains one piece of a fix for #5262. This refactor was initially undertaken to resolve the above issue, which; manifested due to the nested stack frames created by the IR renderer.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5465:44,refactor,refactor,44,https://hail.is,https://github.com/hail-is/hail/pull/5465,1,['refactor'],['refactor']
Modifiability,"Context.java:343); 	at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:911); 	at io.netty.channel.nio.AbstractNioByteChannel$NioByteUnsafe.read(AbstractNioByteChannel.java:131); 	at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:643); 	at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:566); 	at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:480); 	at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:442); 	at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:131); 	at io.netty.util.concurrent.DefaultThreadFactory$DefaultRunnableDecorator.run(DefaultThreadFactory.java:144); 	at java.lang.Thread.run(Thread.java:748); </details>. <details>; <summary>Working hail.log</summary>. ```; 2018-10-09 15:04:33 Hail: INFO: SparkUI: http://10.32.119.167:4040; 2018-10-09 15:04:33 Hail: INFO: Running Hail version devel-17a988f2a628; 2018-10-09 15:04:33 SharedState: INFO: loading hive config file: file:/Users/michafla/spark/spark-2.2.0-bin-hadoop2.7/conf/hive-site.xml; 2018-10-09 15:04:33 SharedState: INFO: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/michafla/projects/R/pkg/hailr/inst/unitTests/spark-warehouse/').; 2018-10-09 15:04:33 SharedState: INFO: Warehouse path is 'file:/Users/michafla/projects/R/pkg/hailr/inst/unitTests/spark-warehouse/'.; 2018-10-09 15:04:33 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@16ba3696{/SQL,null,AVAILABLE,@Spark}; 2018-10-09 15:04:33 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@2780d0b8{/SQL/json,null,AVAILABLE,@Spark}; 2018-10-09 15:04:33 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@7cea1161{/SQL/execution,null,AVAILABLE,@Spark}; 2018-10-09 15:04:33 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@696b1f0{/SQL/execution/json,null,AVAILABLE,@Spark}; 2018-10-09 15:04:33 ContextHan",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4513:13610,config,config,13610,https://hail.is,https://github.com/hail-is/hail/issues/4513,1,['config'],['config']
Modifiability,Correct website URL in Zenodo config,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8998:30,config,config,30,https://hail.is,https://github.com/hail-is/hail/pull/8998,1,['config'],['config']
Modifiability,"Created IR nodes for reading, writing and adding BlockMatrix objects as well as a BlockMatrixLiteral node to interop with functionality that doesn't use the IR. Refactored `blockmatrix.py` to stay fully functional while methods are converted into the IR.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5148:161,Refactor,Refactored,161,https://hail.is,https://github.com/hail-is/hail/pull/5148,1,['Refactor'],['Refactored']
Modifiability,"Creating network namespaces can often take hundreds of milliseconds (and sometimes seconds with `iptables` contention), so Batch takes this off the job hot path by pre-allocating namespaces. All job namespaces are configured identically and there is a fixed number of ""slots"" on any batch worker (`CORES * 4`), so pre-allocation and asynchronous recycling of namespaces is fairly straight-forward so long as we never attempt to run more containers on a worker than the number of slots (which the scheduling system should prohibit). However, since we started running long-lived JVM containers (#11397), the number of containers running on a given worker can easily be *greater* than `N_SLOTS`. On a 16-core machine, we create 30 JVMs that sit idle waiting for JVMJobs all the while occupying a precious network namespace. I thought for the longest time that #13402 was a race condition so was trying to trigger it through a barrage of quick jobs. Turns out all it took was running >34 long-running jobs on a single 16-core worker. In a dev deploy of `main`, running a batch with 35 quarter-core `sleep 150` jobs fails with a single job timing out waiting for a network. On this branch, I am able to run the same 35 job batch as well as a batch with 64 quarter-core jobs. Unfortunately, we don't have a great way to test ""run all these jobs at once on the same worker"". Resolves #13402",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13678:214,config,configured,214,https://hail.is,https://github.com/hail-is/hail/pull/13678,1,['config'],['configured']
Modifiability,"Crosslink to dataproc docs that explain how to start a VEP cluster, mention that the config info is not necessary if you're using dataproc",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8885:85,config,config,85,https://hail.is,https://github.com/hail-is/hail/pull/8885,1,['config'],['config']
Modifiability,"Current implementation allows to specify covariates, but does not output coefficients for the covariates.; I suggest implementing a linereg, where the X variable of interest can be specified.; E.g. . linreg -y sa.pheno.height -c sa.cov.age,sa.cov.isMale -x sa.isblueEyes. In this case, it just run 1 linear regression without using the genotype data. another important addition would be to specify the link function.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/375:153,variab,variable,153,https://hail.is,https://github.com/hail-is/hail/issues/375,1,['variab'],['variable']
Modifiability,"Currently `TableRead.execute` always produces a `TableValueIntermediate`, even though almost all `TableReader`s are lowerable, so could produce a `TableStageIntermediate`. This pr refactors `TableReader` to allow producing a `TableStageIntermediate` in most cases, and to make it clearer which readers still need to be lowered (only `TableFromBlockMatrixNativeReader`, `MatrixVCFReader`, and `MatrixPLINKReader`). It also deletes some now dead code.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13229:180,refactor,refactors,180,https://hail.is,https://github.com/hail-is/hail/pull/13229,1,['refactor'],['refactors']
Modifiability,"Currently the auth service uses its own authentication decorators instead of using those that the other services do (because those make a request to auth which feels a bit circular), but now we have two sets of decorators which we want to mostly keep in step aside from where they get their `UserData` from. This PR creates a small abstraction with an `Authenticator` base class and a `AuthServiceAuthenticator` subclass that extends it and fetches userdata from the auth service. The auth service instead uses a `LocalAuthenticator` which instead of making an rpc directly fetches the userdata from its database. (I would recommend using the split diff)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13672:426,extend,extends,426,https://hail.is,https://github.com/hail-is/hail/pull/13672,1,['extend'],['extends']
Modifiability,"Currently you can't do a dev deploy that only builds an image, because the `deployed_services` method breaks if there are no `deploy_*` steps in the config. This change allows a dev deploy to work with just steps that don't transitively depend on the create namespace step.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12619:149,config,config,149,https://hail.is,https://github.com/hail-is/hail/pull/12619,1,['config'],['config']
Modifiability,"Currently, `hail.ggplot.geom_point` generates cross-product-style legends when the `shape` and `color` aesthetics each have multiple groups. This change makes that behavior consistent with `ggplot2`'s implementation, producing legends where the groups are factored out. Because the strategy used to accomplish this does not preserve the interactive features of the legends, such as toggling groups' visibility, this change also makes all plots generated via `hail.ggplot.geom_point` [static](https://plotly.com/python/configuration-options/#making-a-static-chart). For example, before this change, this code:. ```python; import hail as hl; from hail.ggplot import ggplot, aes, geom_point; ht = hl.utils.range_table(10); ht = ht.annotate(squared=ht.idx ** 2); ht = ht.annotate(even=hl.if_else(ht.idx % 2 == 0, ""yes"", ""no"")); ht = ht.annotate(threeven=hl.if_else(ht.idx % 3 == 0, ""good"", ""bad"")); fig = (; ggplot(ht, aes(x=ht.idx, y=ht.squared)); + geom_point(aes(color=ht.even, shape=ht.threeven)); ); fig.show(); ```. Generates this legend:. <img width=""107"" alt=""Screen Shot 2022-09-29 at 12 22 57"" src=""https://user-images.githubusercontent.com/84595986/193085964-e4545e78-473f-46a3-8c8c-7d6189eb7adc.png"">. After the change, this legend is generated:. <img width=""102"" alt=""Screen Shot 2022-10-03 at 13 56 01"" src=""https://user-images.githubusercontent.com/84595986/193645748-b02ec35c-37c0-400e-b4d6-5c11a5d8df8c.png"">. Custom labels can be used by updating the code like so:; ```python; ...; from hail.ggplot import ggplot, aes, geom_point, labs; ...; fig = (; ggplot(ht, aes(x=ht.idx, y=ht.squared)); + geom_point(aes(color=ht.even, shape=ht.threeven)); + labs(color=""Even"", shape=""Threeven""); ); ...; ```. Generating this legend:. <img width=""106"" alt=""Screen Shot 2022-10-03 at 13 58 34"" src=""https://user-images.githubusercontent.com/84595986/193646267-f935b880-94fe-4a1e-a8a8-b0f850b54a86.png"">. For more information on the current behavior, see #12244 and #12207.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12254:518,config,configuration-options,518,https://hail.is,https://github.com/hail-is/hail/pull/12254,1,['config'],['configuration-options']
Modifiability,"Currently, `hailctl curl` uses `external_url` instead of `url`. As a result,; if `hailctl curl` is used inside a GCE VM or on a k8s pod, the url will always; be `....hail.is` to which GCE VMs and k8s pods likely lack credentials. This was a mistake when I first wrote curl. At that time, I was only using it for; local testing. It will still work for local testing because our deploy configs are; all `external`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8584:384,config,configs,384,https://hail.is,https://github.com/hail-is/hail/pull/8584,1,['config'],['configs']
Modifiability,"Currently, attempting to start a Dataproc cluster without either a region argument or a configured `dataproc/region` results in a long error message `subprocess.CalledProcessError: Command '['gcloud', 'dataproc', 'clusters', 'create', ... ]' returned non-zero exit status 1` with the actual cause obscured above the traceback. That cause is:; ```; Failed to find attribute [region]. The attribute can be set in the following ways:; - provide the argument [--region] on the command line; - set the property [dataproc/region]; ```. There is some logic to show a nicer error message if no region is provided. However, that is only shown if `gcloud config get-value dataproc/region` fails. When `dataproc/region` is not set, that command succeeds and outputs an empty string. This change handles that case and shows the nicer error message.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8791:88,config,configured,88,https://hail.is,https://github.com/hail-is/hail/pull/8791,2,['config'],"['config', 'configured']"
Modifiability,"Currently, jobs in hail batch can only be run on n1 machines but with the rise of deep learning in bioinformatics, the ability to run jobs on g2 machines, as well as other GPU supported machines, is an important and exciting addition to hail batch. This PR highlights the steps needed to add new machine types into hail batch and could be used as a template for further development support. . The changes in this PR can broadly be divided into additions to the job crun container and insertion of g2 resources (CPU, RAM, L4 Accelerator) into the resources table for billing. This PR uses the NVIDIA Container Toolkit, which allows the creation of GPU accelerated containers. This toolkit is integrated with docker via the parameters —runtime=nvidia and the specification of GPUs is made through —gpus all. The toolkit is installed in the batch worker VM startup script and the corresponding docker parameters are configured if the machine type is g2, so there is no change to the docker configuration for n1 machines. For the toolkit to work there is a nvidia hook that needs to be injected into the crun config. These modifications are also done based on machine type. On the billing side, the existing pricing setup was expanded to include g2 machines. The g2 instance cores and RAM are inserted into the database, and the SKUs are hard coded. For future machine type incorporation or updates, [https://cloud.google.com/skus/?currency=USD&filter=](https://cloud.google.com/skus/?currency=USD&filter=) may serve as a useful resource to identify relevant SKU ids. A new resource type was also added for the accelerator, including preemptible and non-preemtible. Finally, g2 machines mount the worker data disk under the name nvme0n2 so the code is updated to reflect this. Future work may want to investigate a way to automatically detect what the proper disk name is or make the disk naming logic more robust.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13430:913,config,configured,913,https://hail.is,https://github.com/hail-is/hail/pull/13430,3,['config'],"['config', 'configuration', 'configured']"
Modifiability,"Currently, multiple users updating the pool config on the pool pages on the batch-driver website can have unexpected behavior. For instance, if two users simultaneously go to the batch-driver website and update the pool config one after the other, the net result is that the second config update will override the first with neither user knowing that two updates happened. This PR addresses this issue by ensuring that the current pool config that a client sees is consistent with what the pool config that the server has, before processing an update. - Add hidden input to pool.html to store the current client config json; - Change config-update route to get current client pool config and proposed pool config from POST request body; - Compare current client config with current server config and if they're different, then reject the proposed pool config",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11798:44,config,config,44,https://hail.is,https://github.com/hail-is/hail/pull/11798,12,['config'],"['config', 'config-update']"
Modifiability,"Currently, tasks to schedule new instances are put on the event loop inside the `Pool` and `JobPrivateInstanceManager` constructors. `Pool.create` and `JobPrivateInstanceManager.create` first instantiate an object of their respective type and then load existing instances from the database into the in-memory instance collection. This could potentially cause the create instances loop to trigger while we're drawing ""existing"" instances, which causes the assertion error in https://github.com/hail-is/hail-tasks/issues/24 when the create instances loop and load instances query race to add the instance to the in-memory data structure. This change moves the task creation from the constructor to the `create` method, so we don't start creating instances until all existing instances are accounted for. I think I would have liked to simply pass the constructor a list of instances, but we can't create an `Instance` without an `InstanceCollection`. Resolves hail-is/hail-tasks#24. I also threw in a bit of cleanup, i.e. removing some variable assignments that didn't seem very helpful and resolving a lint issue where we used `items` where we could just use `values`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11766:1033,variab,variable,1033,https://hail.is,https://github.com/hail-is/hail/pull/11766,1,['variab'],['variable']
Modifiability,"Currently, the Grafana service deployed with the Hail environment is behind two layers of authentication, since the Grafana NGINX configuration proxies requests to it through the `/auth` route, and the login screen built into Grafana also displays. This change removes the second login screen. Demo at https://internal.hail.is/irademac/grafana.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12192:80,layers,layers,80,https://hail.is,https://github.com/hail-is/hail/pull/12192,2,"['config', 'layers']","['configuration', 'layers']"
Modifiability,"Currently, the k8s namespace field is used both for routing internal requests inside kubernetes but also external requests over the internet. It also has special logic based on whether the namespace indicates a production or dev environment. For example, if `namespace == 'default'`, then we route external `batch` requests to `batch.<domain>/path`, but if `namespace == foo_dev`, we route external `batch` requests to `internal.<domain>/foo_dev/path`. This PR decouples the namespace field from routing. Aside from being overall more straightforward in my opinion, this is necessary for batch on azure terra where batch is served out of a subpath it does not control and is unrelated to whatever namespace it might reside in. The guiding principle for routing is then as follows: If the config has no subpath, use a subdomain, otherwise put everything under domain + subpath. For example:; - `{'domain': 'hail.is', 'subpath': null}` => `batch.hail.is`; - `{'domain': 'internal.hail.is', 'subpath': '/foo_dev'}` => `internal.hail.is/foo_dev/batch`. Since the CI pipeline runs on current production instances, there is a minor need to stay compatible with old deploy configs (or else hack up the CI build.yaml). It's quite a simple translation though, because if there is no subpath provided we can infer one based on the `default_namespace`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14056:788,config,config,788,https://hail.is,https://github.com/hail-is/hail/pull/14056,2,['config'],"['config', 'configs']"
Modifiability,"Currently, the test_batch fails for local users. These changes enable test_batch to work for local users with minimal configuration. The only necessary step is for a user to execute:; ```; hailctl config set batch/billing_project hail; ```; All other steps are handled by the test suite, including uploading test data if it does not already exist. I believe this obsoletes `hail-services` bucket. Is that correct?. The main change necessary to support this was a Hail configuration system. There is now a file stored in an [XDG acceptable](https://standards.freedesktop.org/basedir-spec/basedir-spec-latest.html) location to which we can read and write sectioned key-value pairs. The `ServiceBackend` looks in this configuration file if the billing_project is unspecified. The file format is defined by the INI-like configuration file library, [`configparser`](https://docs.python.org/3/library/configparser.html#). `configparser` is included in Python. cc: @cseed your thoughts on `hailctl config` appreciated. I think we'll use this for the query service as well.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8559:118,config,configuration,118,https://hail.is,https://github.com/hail-is/hail/pull/8559,9,['config'],"['config', 'configparser', 'configuration']"
Modifiability,DAGScheduler.handleTaskCompletion(DAGScheduler.scala:1495); 			at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2109); 			at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2061); 			at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2050); 			at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49); 			at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:738); 			at org.apache.spark.SparkContext.runJob(SparkContext.scala:2061); 			at org.apache.spark.SparkContext.runJob(SparkContext.scala:2158); 			at is.hail.rvd.RVD.combine(RVD.scala:688); 			at is.hail.expr.ir.Interpret$.run(Interpret.scala:804); 			at is.hail.expr.ir.Interpret$.alreadyLowered(Interpret.scala:53); 			at is.hail.expr.ir.InterpretNonCompilable$.interpretAndCoerce$1(InterpretNonCompilable.scala:16); 			at is.hail.expr.ir.InterpretNonCompilable$.is$hail$expr$ir$InterpretNonCompilable$$rewrite$1(InterpretNonCompilable.scala:53); 			at is.hail.expr.ir.InterpretNonCompilable$.is$hail$expr$ir$InterpretNonCompilable$$rewrite$1(InterpretNonCompilable.scala:39); 			at is.hail.expr.ir.InterpretNonCompilable$.apply(InterpretNonCompilable.scala:58); 			at is.hail.expr.ir.lowering.InterpretNonCompilablePass$.transform(LoweringPass.scala:50); 			at is.hail.expr.ir.lowering.LoweringPass$$anonfun$apply$3$$anonfun$1.apply(LoweringPass.scala:15); 			at is.hail.expr.ir.lowering.LoweringPass$$anonfun$apply$3$$anonfun$1.apply(LoweringPass.scala:15); 			at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:69); 			at is.hail.expr.ir.lowering.LoweringPass$$anonfun$apply$3.apply(LoweringPass.scala:15); 			at is.hail.expr.ir.lowering.LoweringPass$$anonfun$apply$3.apply(LoweringPass.scala:13); 			at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:69); 			at is.hail.expr.ir.lowering.LoweringPass$class.apply(LoweringPass.scala:13); 			at is.hail.expr.ir.lowering.InterpretNonCom,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8944:12416,rewrite,rewrite,12416,https://hail.is,https://github.com/hail-is/hail/issues/8944,1,['rewrite'],['rewrite']
Modifiability,DDOperationScope.scala:112); 	at org.apache.spark.rdd.RDD.withScope(RDD.scala:414); 	at org.apache.spark.rdd.RDD.collect(RDD.scala:1029); 	at is.hail.backend.spark.SparkBackend.parallelizeAndComputeWithIndex(SparkBackend.scala:355); 	at is.hail.backend.BackendUtils.collectDArray(BackendUtils.scala:43); 	at __C793Compiled.__m916begin_group_0(Emit.scala); 	at __C793Compiled.__m794split_Let(Emit.scala); 	at __C793Compiled.apply(Emit.scala); 	at is.hail.expr.ir.CompileAndEvaluate$.$anonfun$_apply$3(CompileAndEvaluate.scala:57); 	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.CompileAndEvaluate$._apply(CompileAndEvaluate.scala:57); 	at is.hail.expr.ir.CompileAndEvaluate$.evalToIR(CompileAndEvaluate.scala:30); 	at is.hail.expr.ir.LowerOrInterpretNonCompilable$.evaluate$1(LowerOrInterpretNonCompilable.scala:30); 	at is.hail.expr.ir.LowerOrInterpretNonCompilable$.rewrite$1(LowerOrInterpretNonCompilable.scala:67); 	at is.hail.expr.ir.LowerOrInterpretNonCompilable$.apply(LowerOrInterpretNonCompilable.scala:72); 	at is.hail.expr.ir.lowering.LowerOrInterpretNonCompilablePass$.transform(LoweringPass.scala:69); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:16); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:16); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:14); 	at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:13); 	at is.hail.expr.ir.lowering.LowerOrInterpretNonCompilablePass$.apply(LoweringPass.scala:64); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:15); 	at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:13); 	at scala.collection.IndexedSeqOptimized.foreach(I,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13287:9207,rewrite,rewrite,9207,https://hail.is,https://github.com/hail-is/hail/issues/13287,1,['rewrite'],['rewrite']
Modifiability,Dataset.scala:425); E at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); E at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); E at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); E at java.lang.reflect.Method.invoke(Method.java:498); E at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); E at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); E at py4j.Gateway.invoke(Gateway.java:280); E at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); E at py4j.commands.CallCommand.execute(CallCommand.java:79); E at py4j.GatewayConnection.run(GatewayConnection.java:214); E at java.lang.Thread.run(Thread.java:748)java.lang.RuntimeException: java.lang.ClassNotFoundException: Class org.apache.hadoop.mapred.DirectFileOutputCommitter not found; E at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2195); E at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2219); E at org.apache.hadoop.mapred.JobConf.getOutputCommitter(JobConf.java:726); E at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply$mcV$sp(PairRDDFunctions.scala:1051); E at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1035); E at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1035); E at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); E at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); E at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); E at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1035); E at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$3.apply$mcV$sp(PairRDDFunctions.scala:1016); E at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$3.apply(PairRDDFunctions.scala:1016); E at org.apache.spark.rdd.PairRDDFun,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3946:7713,Config,Configuration,7713,https://hail.is,https://github.com/hail-is/hail/issues/3946,1,['Config'],['Configuration']
Modifiability,"Defines a TStream/PStream type stub. I've omitted some number of things that other types need to define, as the purpose of the stream type is going to be to ensure that we're never fully instantiating collections where we shouldn't be, e.g. all the rows in a table partition. To that end, I've omitted definitions for ordering since I don't forsee a need for ordering on the entire stream (as opposed to on the element, or a subset thereof), as well as generators for annotations, etc. It basically otherwise mimics the PArray/TArray definitions, but I've made it extend Type/PType directly since most of the extra methods on containers seem irrelevant to streams, having mostly to do with e.g. length and loading specific elements. cc @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5610:564,extend,extend,564,https://hail.is,https://github.com/hail-is/hail/pull/5610,1,['extend'],['extend']
Modifiability,"Deleted the `gsutil cat` line, it wasn't doing anything because of that erroneous `/vep_data/Plugins.tar`. I don't think plugin needs to be included here, as it's in the docker image. . Deleted the `gsutil cp`, as the file it referenced did not exist. Grabbed the 1var.vcf from the already copied loftee_data. . It's not clear to me why we don't do the `1var.vcf` vep run stuff when using `GRCh38`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10370:93,Plugin,Plugins,93,https://hail.is,https://github.com/hail-is/hail/pull/10370,2,"['Plugin', 'plugin']","['Plugins', 'plugin']"
Modifiability,"Deploying grafana in our GKE cluster gives us instant and easy access to the stackdriver backend with the same querying capabilities of our current front-end, but without the clutter and insanely slow load times. See [here](https://internal.hail.is/dgoldste/grafana/d/TVkleyLMk/detailed-service-resource-utilization?orgId=1) for some example dashboards I set up to look at resources across our services (credentials are the default admin/admin). This alleviates the immediate pain of using the console (for metrics only, not logging), but my longer aim is that getting more regular use out of our metrics can reveal deeper pain points of our monitoring stack and if/where we need to eat up more responsibility from google monitoring. This is a StatefulSet, so configuration through the UI will persist and is done manually. If we find that our dashboards are stable and boilerplate enough, I'd like to move to a code-based dashboard configuration. Sadly, `check-yaml` does not appreciate our jinja templating in yaml, so I've removed it for now. cc: @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10013:760,config,configuration,760,https://hail.is,https://github.com/hail-is/hail/pull/10013,2,['config'],['configuration']
Modifiability,Dice came up @patrick-schultz. - Parameterize (de/en)coders by InputStream type which is either a Java input stream or an array of bytes.; - add `compileComparison` which produces the bytes of a system-specific executable for comparing two values of types `l` and `r` encoded in `codec`; - experimental python API to `compileComparison` to enable experimentation. The end goal is to run `compileComparison` and ship the bytes to the shuffle service which will use it as a comparison operation on the encoded keys.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6505:33,Parameteriz,Parameterize,33,https://hail.is,https://github.com/hail-is/hail/pull/6505,1,['Parameteriz'],['Parameterize']
Modifiability,Disable apiserver deploy for the moment. Remove everything related to Spark. Saved existing deploy configuration in apiserver/build.yaml_disabled.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6195:99,config,configuration,99,https://hail.is,https://github.com/hail-is/hail/pull/6195,1,['config'],['configuration']
Modifiability,Do not create hail/hailctl config file if it does not exist,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11671:27,config,config,27,https://hail.is,https://github.com/hail-is/hail/pull/11671,1,['config'],['config']
Modifiability,"Does not extend into modifying TableValue, as this affects the IR, relates to the boundary you spoke of I believe, and will affect much more besides IBD. Happy to start digging into that in this PR or the next PR if desired. cc @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6415:9,extend,extend,9,https://hail.is,https://github.com/hail-is/hail/pull/6415,2,['extend'],['extend']
Modifiability,Does not/should not change current behavior; I'm just refactoring some code in anticipation of future changes needing the individual pieces instead of the whole.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5457:54,refactor,refactoring,54,https://hail.is,https://github.com/hail-is/hail/pull/5457,1,['refactor'],['refactoring']
Modifiability,"Don't split variable-length encoded ints across compression blocks. Save a comparison in the inner loop. As usual, has seemingly negligible effect on performance. I'm sure it would be significant on the C side. I don't encode as signed yet. It makes the termination condition more complicated and I want to think on it a bit more.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2430:12,variab,variable-length,12,https://hail.is,https://github.com/hail-is/hail/pull/2430,1,['variab'],['variable-length']
Modifiability,"E.g., replace spaces with underscores. Use regex rewrite.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/945:49,rewrite,rewrite,49,https://hail.is,https://github.com/hail-is/hail/issues/945,1,['rewrite'],['rewrite']
Modifiability,"ES.html#release-0-19-2022-07-05"">https://docutils.sourceforge.io/RELEASE-NOTES.html#release-0-19-2022-07-05</a></p>; <h2>Deprecated</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10467"">#10467</a>: Deprecated <code>sphinx.util.stemmer</code> in favour of <code>snowballstemmer</code>.; Patch by Adam Turner.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/9856"">#9856</a>: Deprecated <code>sphinx.ext.napoleon.iterators</code>.</li>; </ul>; <h2>Features added</h2>; <ul>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10444"">#10444</a>: html theme: Allow specifying multiple CSS files through the <code>stylesheet</code>; setting in <code>theme.conf</code> or by setting <code>html_style</code> to an iterable of strings.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10366"">#10366</a>: std domain: Add support for emphasising placeholders in :rst:dir:<code>option</code>; directives through a new :confval:<code>option_emphasise_placeholders</code> configuration; option.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10439"">#10439</a>: std domain: Use the repr of some variables when displaying warnings,; making whitespace issues easier to identify.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10571"">#10571</a>: quickstart: Reduce content in the generated <code>conf.py</code> file. Patch by; Pradyun Gedam.</li>; <li><a href=""https://github-redirect.dependabot.com/sphinx-doc/sphinx/issues/10648"">#10648</a>: LaTeX: CSS-named-alike additional :ref:<code>'sphinxsetup' &lt;latexsphinxsetup&gt;</code>; keys allow to configure four separate border-widths, four paddings, four; corner radii, a shadow (possibly inset), colours for border, background, shadow; for each of the code-block, topic, attention, caution, danger, error and warning; directives.</li>; <li><a href=""https:",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12165:3458,config,configuration,3458,https://hail.is,https://github.com/hail-is/hail/pull/12165,1,['config'],['configuration']
Modifiability,Elasticsearch/Kibana/Fluentd Configuration,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6413:29,Config,Configuration,29,https://hail.is,https://github.com/hail-is/hail/pull/6413,1,['Config'],['Configuration']
Modifiability,"Emit was taking two MethodBuilder arguments, one directly and one embedded in an EmitRegion. This PR replaces the EmitRegion argument with a Value[Region]. It also makes a couple other simple refactorings that were personally helpful in understanding the structure of Emit.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8449:192,refactor,refactorings,192,https://hail.is,https://github.com/hail-is/hail/pull/8449,1,['refactor'],['refactorings']
Modifiability,Emit.scala); 	at __C5Compiled.apply(Emit.scala); 	at is.hail.expr.ir.CompileAndEvaluate$.$anonfun$_apply$7(CompileAndEvaluate.scala:74); 	at scala.runtime.java8.JFunction0$mcJ$sp.apply(JFunction0$mcJ$sp.java:23); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.CompileAndEvaluate$._apply(CompileAndEvaluate.scala:74); 	at is.hail.expr.ir.CompileAndEvaluate$.$anonfun$apply$1(CompileAndEvaluate.scala:19); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.CompileAndEvaluate$.apply(CompileAndEvaluate.scala:19); 	at is.hail.expr.ir.lowering.LowerDistributedSort$.distributedSort(LowerDistributedSort.scala:163); 	at is.hail.backend.service.ServiceBackend.lowerDistributedSort(ServiceBackend.scala:356); 	at is.hail.backend.Backend.lowerDistributedSort(Backend.scala:100); 	at is.hail.expr.ir.lowering.LowerAndExecuteShuffles$.$anonfun$apply$1(LowerAndExecuteShuffles.scala:23); 	at is.hail.expr.ir.RewriteBottomUp$.$anonfun$apply$4(RewriteBottomUp.scala:26); 	at is.hail.utils.StackSafe$More.advance(StackSafe.scala:60); 	at is.hail.utils.StackSafe$.run(StackSafe.scala:16); 	at is.hail.utils.StackSafe$StackFrame.run(StackSafe.scala:32); 	at is.hail.expr.ir.RewriteBottomUp$.apply(RewriteBottomUp.scala:36); 	at is.hail.expr.ir.lowering.LowerAndExecuteShuffles$.apply(LowerAndExecuteShuffles.scala:20); 	at is.hail.expr.ir.lowering.LowerAndExecuteShufflesPass.transform(LoweringPass.scala:157); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:16); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:16); 	at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); 	at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:14); 	at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:13); 	at is.hail.expr.ir.lowering.LowerAndExecuteShufflesPass.apply(LoweringPass.scala:151); 	at is.ha,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12983:7790,Rewrite,RewriteBottomUp,7790,https://hail.is,https://github.com/hail-is/hail/issues/12983,4,['Rewrite'],['RewriteBottomUp']
Modifiability,"Envoy by default responds with a 403 if it fails to make an authorization check. We should treat the failure to contact `auth` as a transient error, so that clients can know to retry whatever request they were trying to make instead of failing. In particular, in dev namespaces the current behavior can trigger a QoB client to cancel an ongoing pipeline while polling for completion. [status_on_error](https://www.envoyproxy.io/docs/envoy/latest/api-v3/extensions/filters/http/ext_authz/v3/ext_authz.proto#extensions-filters-http-ext-authz-v3-extauthz) allows us to configure that default behavior to return a 503 unavailable. I deployed this in Azure by running `make -C gateway deploy NAMESPACE=default`. I poked around to see that I could access my dev namespace and production pages through the browser but did not otherwise try to prove that this failure mode no longer exists.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13735:566,config,configure,566,https://hail.is,https://github.com/hail-is/hail/pull/13735,1,['config'],['configure']
Modifiability,ErrorHandling.fatal(ErrorHandling.scala:18); 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:18); 	at is.hail.utils.package$.fatal(package.scala:81); 	at is.hail.annotations.RegionValueBuilder.setMissing(RegionValueBuilder.scala:207); 	at is.hail.io.vcf.VCFLine.parseAddInfoArrayDouble(LoadVCF.scala:1034); 	at is.hail.io.vcf.VCFLine.parseAddInfoField(LoadVCF.scala:1055); 	at is.hail.io.vcf.VCFLine.addInfoField(LoadVCF.scala:1075); 	at is.hail.io.vcf.VCFLine.parseAddInfo(LoadVCF.scala:1112); 	at is.hail.io.vcf.LoadVCF$.parseLineInner(LoadVCF.scala:1541); 	at is.hail.io.vcf.LoadVCF$.parseLine(LoadVCF.scala:1409); 	at is.hail.io.vcf.MatrixVCFReader.$anonfun$executeGeneric$7(LoadVCF.scala:1916); 	... 21 more. Driver stacktrace:; 	at org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2673); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2609); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2608); 	at scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62); 	at scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55); 	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49); 	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2608); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1182); 	at org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1182); 	at scala.Option.foreach(Option.scala:407); 	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1182); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2861); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2803); 	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2792); 	at org.apache.spark.u,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14102:10129,adapt,adapted,10129,https://hail.is,https://github.com/hail-is/hail/issues/14102,1,['adapt'],['adapted']
Modifiability,Evaluation of relational lets is an explicit pass. Executing and rewriting shuffles is an explicit pass.; * lowerDistributedSort executes the shuffle and produces a TableReader. Higher-level passes that recursively lower and execute are parameterized; by the contained pipeline.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12587:237,parameteriz,parameterized,237,https://hail.is,https://github.com/hail-is/hail/pull/12587,1,['parameteriz'],['parameterized']
Modifiability,Example stack trace:; ```; 2022-02-08 18:09:30 root: ERROR: IllegalArgumentException: requirement failed; From java.lang.IllegalArgumentException: requirement failed; 	at scala.Predef$.require(Predef.scala:268); 	at is.hail.rvd.RVDPartitioner.<init>(RVDPartitioner.scala:52); 	at is.hail.rvd.RVDPartitioner.extendKeySamePartitions(RVDPartitioner.scala:141); 	at is.hail.expr.ir.LoweredTableReader$$anon$2.coerce(TableIR.scala:382); 	at is.hail.expr.ir.GenericTableValue.toTableStage(GenericTableValue.scala:162); 	at is.hail.io.vcf.MatrixVCFReader.lower(LoadVCF.scala:1790); 	at is.hail.expr.ir.lowering.LowerTableIR$.applyTable(LowerTableIR.scala:581); 	at is.hail.expr.ir.lowering.LowerTableIR$.lower$2(LowerTableIR.scala:561); 	at is.hail.expr.ir.lowering.LowerTableIR$.applyTable(LowerTableIR.scala:1304); 	at is.hail.expr.ir.lowering.LowerTableIR$.lower$2(LowerTableIR.scala:561); 	at is.hail.expr.ir.lowering.LowerTableIR$.applyTable(LowerTableIR.scala:1035); 	at is.hail.expr.ir.lowering.LowerTableIR$.lower$1(LowerTableIR.scala:394); 	at is.hail.expr.ir.lowering.LowerTableIR$.apply(LowerTableIR.scala:547); 	at is.hail.expr.ir.lowering.LowerToCDA$.lower(LowerToCDA.scala:69); 	at is.hail.expr.ir.lowering.LowerToCDA$.apply(LowerToCDA.scala:18); 	at is.hail.expr.ir.lowering.LowerToDistributedArrayPass.transform(LoweringPass.scala:77). ```. called from here:; https://github.com/hail-is/hail/blob/d2f87d81dd1af43617740309e354d4bac8c672e0/hail/src/main/scala/is/hail/expr/ir/TableIR.scala#L382,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11335:307,extend,extendKeySamePartitions,307,https://hail.is,https://github.com/hail-is/hail/issues/11335,1,['extend'],['extendKeySamePartitions']
Modifiability,"Existence of directories is filesystem dependent, and they exist on Google if there is an object with that directory name a prefix. This required a little refactoring that changed fs.listfiles to return a coroutine that gives an iterator, rather than returning an iterator directly. This is because, if you use the `async def foo ... yield ...` syntax, it is not possible to write any code that will run between calling the async genreator function `foo` and the first call to `__anext__`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9818:155,refactor,refactoring,155,https://hail.is,https://github.com/hail-is/hail/pull/9818,1,['refactor'],['refactoring']
Modifiability,Expecting this to fail since I haven't applied the terraform yet and the config values set there are still using `hail-az`. After applying terraform this should pass.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14209:73,config,config,73,https://hail.is,https://github.com/hail-is/hail/pull/14209,1,['config'],['config']
Modifiability,Expose Genome Reference as global variable,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1789:34,variab,variable,34,https://hail.is,https://github.com/hail-is/hail/pull/1789,1,['variab'],['variable']
Modifiability,Extend Let to work with BaseIR,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4905:0,Extend,Extend,0,https://hail.is,https://github.com/hail-is/hail/issues/4905,1,['Extend'],['Extend']
Modifiability,Extend PruneDeadFields to prune key fields (woohoo!),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5864:0,Extend,Extend,0,https://hail.is,https://github.com/hail-is/hail/pull/5864,1,['Extend'],['Extend']
Modifiability,Extend PruneDeadFields to prune tuples,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5851:0,Extend,Extend,0,https://hail.is,https://github.com/hail-is/hail/pull/5851,1,['Extend'],['Extend']
Modifiability,Extend Python methods that print to take arbitrary handler functions,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4303:0,Extend,Extend,0,https://hail.is,https://github.com/hail-is/hail/pull/4303,1,['Extend'],['Extend']
Modifiability,Extend Simplify to remove more operations before TableCount,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3676:0,Extend,Extend,0,https://hail.is,https://github.com/hail-is/hail/issues/3676,1,['Extend'],['Extend']
Modifiability,"Extend `FunctionChecker` to assert that at least the number of non-default parameters are specified, up to the maximum number of parameters.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12814:0,Extend,Extend,0,https://hail.is,https://github.com/hail-is/hail/pull/12814,1,['Extend'],['Extend']
Modifiability,Extend min/max functions.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2935:0,Extend,Extend,0,https://hail.is,https://github.com/hail-is/hail/pull/2935,1,['Extend'],['Extend']
Modifiability,Extend option to skip Scala tests requiring plink/Rscript executables,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5126:0,Extend,Extend,0,https://hail.is,https://github.com/hail-is/hail/pull/5126,1,['Extend'],['Extend']
Modifiability,Extending the idea of better error messages from #9398 to include `NDArrayRef`.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9444:0,Extend,Extending,0,https://hail.is,https://github.com/hail-is/hail/pull/9444,1,['Extend'],['Extending']
Modifiability,"FO: Getting 1 non-empty blocks out of 1 blocks; 2018-10-09 14:46:42 ShuffleBlockFetcherIterator: INFO: Started 0 remote fetches in 0 ms; 2018-10-09 14:46:42 Executor: INFO: Finished task 0.0 in stage 4.0 (TID 4). 1539 bytes result sent to driver; 2018-10-09 14:46:42 TaskSetManager: INFO: Finished task 0.0 in stage 4.0 (TID 4) in 7 ms on localhost (executor driver) (1/1); 2018-10-09 14:46:42 TaskSchedulerImpl: INFO: Removed TaskSet 4.0, whose tasks have all completed, from pool ; 2018-10-09 14:46:42 DAGScheduler: INFO: ResultStage 4 (collect at utils.scala:197) finished in 0.007 s; 2018-10-09 14:46:42 DAGScheduler: INFO: Job 2 finished: collect at utils.scala:197, took 0.053572 s; 2018-10-09 14:46:42 CodeGenerator: INFO: Code generated in 5.955541 ms; 2018-10-09 14:46:42 SparkSession$Builder: WARN: Using an existing SparkSession; some configuration may not take effect.; 2018-10-09 14:46:42 SparkSqlParser: INFO: Parsing command: SELECT *; FROM `table7e606a8b83f4` AS `zzz1`; WHERE (0 = 1); 2018-10-09 14:46:42 SparkSession$Builder: WARN: Using an existing SparkSession; some configuration may not take effect.; 2018-10-09 14:46:42 SparkSqlParser: INFO: Parsing command: SELECT *; FROM `table7e606a8b83f4`; 2018-10-09 14:46:43 root: INFO: optimize: before:; (TableCount; (TableKeyBy () False; (TableLiteral))); 2018-10-09 14:46:43 root: INFO: optimize: after:; (TableCount; (TableLiteral)); 2018-10-09 14:46:43 SparkContext: INFO: Starting job: fold at RVD.scala:361; 2018-10-09 14:46:43 DAGScheduler: INFO: Got job 3 (fold at RVD.scala:361) with 1 output partitions; 2018-10-09 14:46:43 DAGScheduler: INFO: Final stage: ResultStage 5 (fold at RVD.scala:361); 2018-10-09 14:46:43 DAGScheduler: INFO: Parents of final stage: List(); 2018-10-09 14:46:43 DAGScheduler: INFO: Missing parents: List(); 2018-10-09 14:46:43 DAGScheduler: INFO: Submitting ResultStage 5 (MapPartitionsRDD[28] at mapPartitions at ContextRDD.scala:137), which has no missing parents; 2018-10-09 14:46:43 MemoryStore: ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4513:46192,config,configuration,46192,https://hail.is,https://github.com/hail-is/hail/issues/4513,1,['config'],['configuration']
Modifiability,"FYI @cseed @danking: I found a bad bug in the Kubernetes deserializer that we use to deserialize the pod spec from the request from the client. Any variable with a compound name like `generate_name` or `cluster_name` was being set to None regardless of what the input was. This is because their code has a mapping from the Python style with underscores to camel case and it was using the camel case to look up the attributes instead of the underscore names. @akotlar was going to make a PR to correct it in their repo. For now, I'm including the correct code in our repo. Without it, I was getting errors trying to deserialize pod templates with metadata from the MySQL database back to Python. The other horrible behavior I found with the deserializer is if you pass `None` to the deserialize function, you get a dictionary with all attributes set to `None` instead of just `None`. Something to be aware of or we should fix it in this PR to return None instead. @akotlar: I tried to make everything just adhere to Python3, but can you make sure I did the conversions correctly?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5738:148,variab,variable,148,https://hail.is,https://github.com/hail-is/hail/pull/5738,1,['variab'],['variable']
Modifiability,"Failed to annotate a large vcf with vep. Command:; hail-new-vep read -i /user/aganna/CANCER.vds \; vep --config /psych/genetics_data/working/cseed/vep.properties \; write -o /user/aganna/CANCER.vep.vds. Error:; Exception in thread ""main"" java.lang.NoClassDefFoundError: org/broadinstitute/hail/methods/VCFReport$; at org.broadinstitute.hail.driver.Main$.runCommands(Main.scala:125); at org.broadinstitute.hail.driver.Main$.main(Main.scala:276); at org.broadinstitute.hail.driver.Main.main(Main.scala); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:497); at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672); at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180); at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.ClassNotFoundException: org.broadinstitute.hail.methods.VCFReport$; at java.net.URLClassLoader.findClass(URLClassLoader.java:381); at java.lang.ClassLoader.loadClass(ClassLoader.java:424); at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331); at java.lang.ClassLoader.loadClass(ClassLoader.java:357); ... 12 more. [hail.log.txt](https://github.com/broadinstitute/hail/files/222874/hail.log.txt)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/303:105,config,config,105,https://hail.is,https://github.com/hail-is/hail/issues/303,1,['config'],['config']
Modifiability,"Few more variables are expected to be in `config.mk` for manual bootstrap:. * `DOCKER_ROOT_IMAGE` used to build batch workers and benchmark; * `HAIL_TEST_GCS_BUCKET` used to build query; * `KUBERNETES_SERVER_URL` used to build amundsen; * `PROJECT`, `ZONE`, `REGION` are probably not need, but might make sense to add for consistency. Also match the order from `global-config`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11371:9,variab,variables,9,https://hail.is,https://github.com/hail-is/hail/pull/11371,3,"['config', 'variab']","['config', 'variables']"
Modifiability,"Finally add BGEN filtering at the level of bytes. We add a non-public, non-documented `_variants_per_file` argument that lists the variants to keep by their on-disk indices. It's a pretty groady interface, but it works with the current infrastructure and provides a _massive_ improvement. We go from decoding all the variants in the BGEN to decoding only those relevant to the computation at hand. In the case of Caitlin's PRS scoring method, that's about 1% or less of the original variant set. It's a bit janky. The file paths need to be the fully qualified ones that are seen by the hadoop reader. So `file:/full/path/to/file.bgen` or `gs://full/path/to/bgen.file`, which is annoying. I don't have any better way to generically uniquely identify files though. ---; ### Calc Depth Bug. I also had to fix a bug in the indices. Neither my `OnDiskBTreeIndexToValue` nor the existing `IndexBTree` correctly calculated the sizes of the given trees. Recall that a b-tree is a series of layers. Layer 0 is at most `branchingFactor` in size. Layer i is at most `branchingFactor ^ (i+1)` in size. The total size of the b-tree is the sum of the layer sizes. Here's a few max sizes for a branchingFactor of 1024:. - 1 layer tree: 1024; - 2 layer tree: 1024^2 + 1024; - 3 layer tree: 1024^3 + 1024^2 + 1024. If you look carefully at the old `calcDepth` method, it incorrectly concludes that fully populated 3 layer trees have four layers because they have more than 1024^3 total (internal+leaf) elements. This issue rears it's head on an exponentially small number of trees (at depth `i`, the number of leaf elements must lie in `[1024^i-1024^(i-1), 1024^i]`. This discrepancy is what lead to my confusion for the last few days. It shows up quite quickly with very small branching factors (e.g. 3) but with a large branching factor (the default of 1024 and what all the tests were written against) it's fairly rare. ---; ### Summary of Changes. - add `_variants_per_file` which is a map from absolute file paths",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3813:982,layers,layers,982,https://hail.is,https://github.com/hail-is/hail/pull/3813,1,['layers'],['layers']
Modifiability,"First step in RVD changes. Rewrites `Interval` to support endpoints that are `Row`s of different lengths. Hopefully comments and test suite are enough to make the semantics clear. If not, let me know what is unclear and I'll add documentation and/or test cases.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4072:27,Rewrite,Rewrites,27,https://hail.is,https://github.com/hail-is/hail/pull/4072,1,['Rewrite'],['Rewrites']
Modifiability,"Fix `IEmitCode.map`, Rewrite `MakeNDArray` in `CodeBuilder` style",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8516:21,Rewrite,Rewrite,21,https://hail.is,https://github.com/hail-is/hail/pull/8516,1,['Rewrite'],['Rewrite']
Modifiability,"Fix bad error message in Table.order_by, extend functionality",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4927:41,extend,extend,41,https://hail.is,https://github.com/hail-is/hail/pull/4927,1,['extend'],['extend']
Modifiability,Fix configuration,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1162:4,config,configuration,4,https://hail.is,https://github.com/hail-is/hail/pull/1162,1,['config'],['configuration']
Modifiability,Fix simplification for integer subtraction; Extend scope of simplifier to more numeric types.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12754:44,Extend,Extend,44,https://hail.is,https://github.com/hail-is/hail/pull/12754,1,['Extend'],['Extend']
Modifiability,Fix the overriding of the gcs_requester_pays/project config variable through using 'hailctl describe -u'. Closes #13793,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13826:53,config,config,53,https://hail.is,https://github.com/hail-is/hail/pull/13826,2,"['config', 'variab']","['config', 'variable']"
Modifiability,Fixed bed annotator to be more flexible,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1627:31,flexible,flexible,31,https://hail.is,https://github.com/hail-is/hail/pull/1627,1,['flexible'],['flexible']
Modifiability,Fixed getting started cloudera configuration,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2021:31,config,configuration,31,https://hail.is,https://github.com/hail-is/hail/pull/2021,1,['config'],['configuration']
Modifiability,Fixed inlining of ArrayAgg nodes without aggs in the body. Also added; simplify rule to rewrite these nodes to just the body.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7219:88,rewrite,rewrite,88,https://hail.is,https://github.com/hail-is/hail/pull/7219,1,['rewrite'],['rewrite']
Modifiability,"Fixes #11335. @tpoterba made the replicating test, with that it was easy to find the source of the bug. The error was in; ```; pkPartitioned; .strictify(); ...; .changePartitionerNoRepartition(partitioner.extendKeySamePartitions(keyType)); ```; where `pkPartitioned` is keyed by the partition key. In the test case, all rows have the same partition key, so the partitioner looks like `[x, x], [x, x], ...`. In that case, `strictify` correctly collapses all those partitions into one, but `partitioner.extendKeySamePartitions(keyType)` tries to extend the key type without changing the partitioning, which in this case creates an invalid partitioner. The fix is to use `pkPartitioned.extendKeyPreservesPartitioning(key)`, which does the `strictify` and creates the correct partitioner.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11355:205,extend,extendKeySamePartitions,205,https://hail.is,https://github.com/hail-is/hail/pull/11355,4,['extend'],"['extend', 'extendKeyPreservesPartitioning', 'extendKeySamePartitions']"
Modifiability,"Fixes #3729. The problem with the If in the array emitting logic was that the lengths were being stored in two different local variables, which were only being evaluated/stored depending on which branch was taken. Because we store that information in another local variable, `xvcond`, and check it again when we're actually consuming the array, the analyzer was checking both branches again for that step, and being unhappy that the local variable where the length is stored could have been unpopulated. I have fixed this by only having one branch and doing both the length calculation and the rest of the stuff there.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4234:127,variab,variables,127,https://hail.is,https://github.com/hail-is/hail/pull/4234,3,['variab'],"['variable', 'variables']"
Modifiability,Fixes a bug where identifiers for bound variables were not being printed by the sexpr style pretty printer.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11603:40,variab,variables,40,https://hail.is,https://github.com/hail-is/hail/pull/11603,1,['variab'],['variables']
Modifiability,"Fixes the problem where if there is a bad secret / job config fails, we didn't update the attempt id in the jobs table in the database.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8760:55,config,config,55,https://hail.is,https://github.com/hail-is/hail/pull/8760,1,['config'],['config']
Modifiability,Fixes this problem:. ```; + xargs -r gcloud -q compute instances delete --zone; ERROR: (gcloud.compute.instances.list) The required property [project] is not currently set.; You may set it for your current workspace by running:. $ gcloud config set project VALUE. or it can be set temporarily by the environment variable [CLOUDSDK_CORE_PROJECT]; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7520:238,config,config,238,https://hail.is,https://github.com/hail-is/hail/pull/7520,2,"['config', 'variab']","['config', 'variable']"
Modifiability,Fixes/enhancements to HTSGenotypeView.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2296:6,enhance,enhancements,6,https://hail.is,https://github.com/hail-is/hail/pull/2296,1,['enhance'],['enhancements']
Modifiability,"Flags now use the same user configuration machinery we use for Batch and QoB. I am not certain this is the right choice. Feedback very welcome. The configuration_of function lets us uniformly treat any configuration by checking, in order: explicit argument, envvar, config file, or a fallback. I added a bit of code to allow us to support the envvars which do not conform to the new envvar scheme. I also removed a few flags that are no longer used. I kind of think these flags should actually be under a new section like ""query_compiler"" or something. @tpoterba, thoughts?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12423:28,config,configuration,28,https://hail.is,https://github.com/hail-is/hail/pull/12423,3,['config'],"['config', 'configuration']"
Modifiability,"For linreg, logrem, lmmreg, and skat:; - changed Python implementation to annotate or select on `x` if not a field and always pass `x_field`, which must be float64 but may have missing values.; - changed Scala linreg, logrem, lmmreg, and skat to take `xField` rather than `xExpr`. Updated Scala tests with selectEntry accordingly.; - replaced RegressionUtils `inputVector` with `setMeanImputedDoubles`; - removed `dataset` parameter from Python. Now all methods that take a dataset and one or more required expressions on that dataset now only take the expressions. Updated docs, tests, tutorial accordingly.; - added `req_tstring` to linear_mixed_regression and `We plan to change the interface to this method in Hail 0.2 while maintaining its functionality.` The constraint is due to string assumption made when comparing and filtering column keys against keys on KinshipMatrix. Since the latter is going away (and marked as such), I don't think it's worth more changes to remove the constraint.; - made docs more consistent and variable names more generic (sample=>col, variant=>row, etc)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3289:1031,variab,variable,1031,https://hail.is,https://github.com/hail-is/hail/pull/3289,1,['variab'],['variable']
Modifiability,"For my SAIGE implementation, it would be nice to be able to use the `{BATCH_TMPDIR}` environment variable within a file name so that I can give user-specified file path names for output files to write that can be used downstream in globs when importing temporary files in Hail without having to localize all of the files (could be 4K+ files). I also thought this could solve Konrad's region bucket request where we copy data from a region-specific location.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14340:97,variab,variable,97,https://hail.is,https://github.com/hail-is/hail/pull/14340,1,['variab'],['variable']
Modifiability,"From Cotton:. I think the request/s and request latency metrics in Grafana are not actually the metrics for the Kubernetes service as we'd hoped. In particular, the reqs/s makes no sense. This post:. https://blog.freshtracks.io/a-deep-dive-into-kubernetes-metrics-part-4-the-kubernetes-api-server-72f1e1210770. indicates we should have an apiserver_request_count and apiserver_request_latencies_bucket which sound like what we want. They give ""the Prometheus configuration for getting metrics from the Kubernetes API server, even in environments where the masters are hosted for you"" (and I think our master is hosted for us in GKE). In particular, we have no analogous apiserver scrape config with ""role: endpoints"" in our setup. Here is the apiserver code with all the metrics they collect: https://github.com/kubernetes/apiserver/blob/master/pkg/endpoints/metrics/metrics.go",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6495:459,config,configuration,459,https://hail.is,https://github.com/hail-is/hail/issues/6495,2,['config'],"['config', 'configuration']"
Modifiability,From is.hail.utils.HailException: /data/public/prs/ex_antonk.bim:1013423: Invalid locus '11:135009883' found. Position '135009883' is not within the range [1-135006516] for reference genome 'GRCh37'.; offending line: 11	.	0	135009883	CT	C; 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:30); 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:28); 	at is.hail.utils.package$.fatal(package.scala:78); 	at is.hail.utils.Context.wrapException(Context.scala:21); 	at is.hail.utils.WithContext.foreach(Context.scala:51); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$2(LoadPlink.scala:37); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$2$adapted(LoadPlink.scala:36); 	at scala.collection.Iterator.foreach(Iterator.scala:941); 	at scala.collection.Iterator.foreach$(Iterator.scala:941); 	at scala.collection.AbstractIterator.foreach(Iterator.scala:1429); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$1(LoadPlink.scala:36); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$1$adapted(LoadPlink.scala:35); 	at is.hail.io.fs.FS.$anonfun$readLines$1(FS.scala:222); 	at is.hail.utils.package$.using(package.scala:640); 	at is.hail.io.fs.FS.readLines(FS.scala:213); 	at is.hail.io.fs.FS.readLines$(FS.scala:211); 	at is.hail.io.fs.HadoopFS.readLines(HadoopFS.scala:72); 	at is.hail.io.plink.LoadPlink$.parseBim(LoadPlink.scala:35); 	at is.hail.io.plink.MatrixPLINKReader$.fromJValue(LoadPlink.scala:179); 	at is.hail.expr.ir.MatrixReader$.fromJson(MatrixIR.scala:88); 	at is.hail.expr.ir.IRParser$.matrix_ir_1(Parser.scala:1720); 	at is.hail.expr.ir.IRParser$.$anonfun$matrix_ir$1(Parser.scala:1646); 	at is.hail.utils.StackSafe$More.advance(StackSafe.scala:64); 	at is.hail.utils.StackSafe$.run(StackSafe.scala:16); 	at is.hail.utils.StackSafe$StackFrame.run(StackSafe.scala:32); 	at is.hail.expr.ir.IRParser$.$anonfun$parse_matrix_ir$1(Parser.scala:1986); 	at is.hail.expr.ir.IRParser$.parse(Parser.scala:1973); 	at is.hail.expr.ir.IRParser$.parse_matrix_ir(Parser.scala:1986); ,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11836:2298,adapt,adapted,2298,https://hail.is,https://github.com/hail-is/hail/issues/11836,1,['adapt'],['adapted']
Modifiability,"From the man page:. ```; -t Don't run, just test the configuration file. The nginx; checks configuration for correct syntax and then tries; to open files referred in configuration.; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4429:53,config,configuration,53,https://hail.is,https://github.com/hail-is/hail/pull/4429,3,['config'],['configuration']
Modifiability,Future enhancements to batch will necessitate the proper use of modules.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4787:7,enhance,enhancements,7,https://hail.is,https://github.com/hail-is/hail/pull/4787,1,['enhance'],['enhancements']
Modifiability,"Gateway receives the user IP (thanks to #8045). However, gateway is an HTTP; proxy, so packets from gateway necessarily come from gateway's IP. Gateway; places the user IP into the HTTP header `X-Real-IP`. All downstream servers; must: log `X-Real-IP` and forward `X-Real-IP` unadulterated. This PR makes that; change for `router`. - fix router Makefile (`domain` is now in `global`); - add `proxy.conf` which configures the standard proxy headers (importantly:; forwards `X-REAL-IP`); - for non-notebook servers, `include` the `proxy.conf`; - for notebook, update to include proxy headers; - override default `access_log` (which required checking in the default; `nginx.conf`); - lift other `http` directives into `nginx.conf` now that it is checked in",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8058:410,config,configures,410,https://hail.is,https://github.com/hail-is/hail/pull/8058,1,['config'],['configures']
Modifiability,GenericTableValue.toTableStage(GenericTableValue.scala:162); at is.hail.io.vcf.MatrixVCFReader.lower(LoadVCF.scala:1798); at is.hail.expr.ir.lowering.LowerTableIR$.applyTable(LowerTableIR.scala:717); at is.hail.expr.ir.lowering.LowerTableIR$.lower$2(LowerTableIR.scala:697); at is.hail.expr.ir.lowering.LowerTableIR$.applyTable(LowerTableIR.scala:903); at is.hail.expr.ir.lowering.LowerTableIR$.lower$1(LowerTableIR.scala:467); at is.hail.expr.ir.lowering.LowerTableIR$.apply(LowerTableIR.scala:472); at is.hail.expr.ir.lowering.LowerToCDA$.lower(LowerToCDA.scala:73); at is.hail.expr.ir.lowering.LowerToCDA$.apply(LowerToCDA.scala:18); at is.hail.expr.ir.lowering.LowerToDistributedArrayPass.transform(LoweringPass.scala:77); at is.hail.expr.ir.LowerOrInterpretNonCompilable$.evaluate$1(LowerOrInterpretNonCompilable.scala:27); at is.hail.expr.ir.LowerOrInterpretNonCompilable$.rewrite$1(LowerOrInterpretNonCompilable.scala:67); at is.hail.expr.ir.LowerOrInterpretNonCompilable$.rewrite$1(LowerOrInterpretNonCompilable.scala:53); at is.hail.expr.ir.LowerOrInterpretNonCompilable$.apply(LowerOrInterpretNonCompilable.scala:72); at is.hail.expr.ir.lowering.LowerOrInterpretNonCompilablePass$.transform(LoweringPass.scala:69); at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$3(LoweringPass.scala:16); at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); at is.hail.expr.ir.lowering.LoweringPass.$anonfun$apply$1(LoweringPass.scala:16); at is.hail.utils.ExecutionTimer.time(ExecutionTimer.scala:81); at is.hail.expr.ir.lowering.LoweringPass.apply(LoweringPass.scala:14); at is.hail.expr.ir.lowering.LoweringPass.apply$(LoweringPass.scala:13); at is.hail.expr.ir.lowering.LowerOrInterpretNonCompilablePass$.apply(LoweringPass.scala:64); at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1(LoweringPipeline.scala:15); at is.hail.expr.ir.lowering.LoweringPipeline.$anonfun$apply$1$adapted(LoweringPipeline.scala:13); at scala.collection.IndexedSeqOptimized.foreach(IndexedSeqOpt,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12280:3284,rewrite,rewrite,3284,https://hail.is,https://github.com/hail-is/hail/issues/12280,1,['rewrite'],['rewrite']
Modifiability,Genome reference as global variable,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1889:27,variab,variable,27,https://hail.is,https://github.com/hail-is/hail/pull/1889,1,['variab'],['variable']
Modifiability,"Getting the following errors when compiling on a Mac. Any suggestions?. ./gradlew shadowJar ; :compileJava UP-TO-DATE; :nativeLib; (cd libsimdpp-2.0-rc2 && cmake .); -- Configuring done; -- Generating done; -- Build files have been written to: /Users/farrell/github/hail/src/main/c/libsimdpp-2.0-rc2; mkdir -p lib/darwin; c++ -fvisibility=hidden -dynamiclib -O3 -march=native -g -std=c++11 -Ilibsimdpp-2.0-rc2 ibs.cpp -o lib/darwin/libibs.dylib; /var/folders/gx/t1q6w73n4pn8jzfc4_k3lm0m0000gn/T//ccuBKQk1.s:23:no such instruction: `vmovd %xmm0, %rax'; /var/folders/gx/t1q6w73n4pn8jzfc4_k3lm0m0000gn/T//ccuBKQk1.s:38:no such instruction: `vpextrq $1, %xmm0,%rax'; /var/folders/gx/t1q6w73n4pn8jzfc4_k3lm0m0000gn/T//ccuBKQk1.s:79:no such instruction: `vpcmpeqd %xmm5, %xmm5,%xmm5'; /var/folders/gx/t1q6w73n4pn8jzfc4_k3lm0m0000gn/T//ccuBKQk1.s:96:no such instruction: `vpxor %xmm1, %xmm0,%xmm1'; /var/folders/gx/t1q6w73n4pn8jzfc4_k3lm0m0000gn/T//ccuBKQk1.s:114:no such instruction: `vpxor %xmm5, %xmm1,%xmm1'; /var/folders/gx/t1q6w73n4pn8jzfc4_k3lm0m0000gn/T//ccuBKQk1.s:135:no such instruction: `vpand %xmm3, %xmm2,%xmm3'; /var/folders/gx/t1q6w73n4pn8jzfc4_k3lm0m0000gn/T//ccuBKQk1.s:150:no such instruction: `vpsrlq $1, %xmm1,%xmm0'; /var/folders/gx/t1q6w73n4pn8jzfc4_k3lm0m0000gn/T//ccuBKQk1.s:167:no such instruction: `vpxor %xmm5, %xmm3,%xmm3'; /var/folders/gx/t1q6w73n4pn8jzfc4_k3lm0m0000gn/T//ccuBKQk1.s:193:no such instruction: `vpor LC1(%rip), %xmm3,%xmm3'; /var/folders/gx/t1q6w73n4pn8jzfc4_k3lm0m0000gn/T//ccuBKQk1.s:212:no such instruction: `vpand %xmm1, %xmm0,%xmm4'; /var/folders/gx/t1q6w73n4pn8jzfc4_k3lm0m0000gn/T//ccuBKQk1.s:225:no such instruction: `vpandn %xmm4, %xmm3,%xmm4'; /var/folders/gx/t1q6w73n4pn8jzfc4_k3lm0m0000gn/T//ccuBKQk1.s:241:no such instruction: `vmovd %xmm4, %rax'; /var/folders/gx/t1q6w73n4pn8jzfc4_k3lm0m0000gn/T//ccuBKQk1.s:255:no such instruction: `vpxor %xmm1, %xmm0,%xmm2'; /var/folders/gx/t1q6w73n4pn8jzfc4_k3lm0m0000gn/T//ccuBKQk1.s:277:no such instruction: `v",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1274:169,Config,Configuring,169,https://hail.is,https://github.com/hail-is/hail/issues/1274,1,['Config'],['Configuring']
Modifiability,"Getting this with current master on the cloud:. ```; Use of uninitialized value in hash element at /vep/ensembl-tools-release-85/scripts/variant_effect_predictor/Bio/EnsEMBL/Variation/Utils/VEP.pm line 4255, <VARS> line 1.; [Stage 18:=> (273 + 410) / 13592]Traceback (most recent call last):; File ""/tmp/7ff73b01-6ea1-4254-a49d-01e9075ab5b0/subset.py"", line 75, in <module>; main(args, pops); File ""/tmp/7ff73b01-6ea1-4254-a49d-01e9075ab5b0/subset.py"", line 51, in main; 'va.rf').write(args.output + "".autosomes.vds"", overwrite=True); File ""/tmp/7ff73b01-6ea1-4254-a49d-01e9075ab5b0/utils.py"", line 452, in post_process_vds; vds = vds.vep(config=vep_config, csq=True, root='va.info.CSQ', force=True); File ""<decorator-gen-110>"", line 2, in vep; File ""/tmp/7ff73b01-6ea1-4254-a49d-01e9075ab5b0/pyhail-attr.zip/hail/java.py"", line 93, in handle_py4j; hail.java.FatalError: NoSuchElementException: None.get; [Stage 18:=> (277 + 409) / 13592]java.util.concurrent.RejectedExecutionException: Task scala.concurrent.impl.CallbackRunnable@2a632cbb rejected from java.util.concurrent.ThreadPoolExecutor@974d518[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 2913]; ```. Lmk if you need more log.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1518:639,config,config,639,https://hail.is,https://github.com/hail-is/hail/issues/1518,1,['config'],['config']
Modifiability,"Got annoyed with the constant re-tagging of images that don't need to be rebuilt, and decided to play a little make golf along the way. cc @jigold This should dramatically reduce the number of tags for hail-ubuntu from make-deployed images, though the number of layers in the container registry should not change.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12841:262,layers,layers,262,https://hail.is,https://github.com/hail-is/hail/pull/12841,1,['layers'],['layers']
Modifiability,"Grace requested this for gnomAD purposes. In Azure, we can determine this; using the classpath or envionrment variables (the env var is only available; inside Jupyter). In GCP, I added an environment variable to our Spark env; / Jupyter env.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11230:110,variab,variables,110,https://hail.is,https://github.com/hail-is/hail/pull/11230,2,['variab'],"['variable', 'variables']"
Modifiability,"Had to refactor some things to deal with subtle importing graphs. I also left the hl.scan stuff using functools, because I'm not sure that; we can fix that as easily. fixes #4112",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4139:7,refactor,refactor,7,https://hail.is,https://github.com/hail-is/hail/pull/4139,1,['refactor'],['refactor']
Modifiability,"Hail version: 0.2.130-bea04d9c79b5; Error summary: HailException: VEP command '/vep --format vcf --json --everything --allele_number --no_stats --cache --offline --minimal --assembly GRCh38 --fasta /opt/vep/.vep/homo_sapiens/95_GRCh38/Homo_sapiens.GRCh38.dna.toplevel.fa.gz --plugin LoF,loftee_path:/opt/vep/Plugins/,gerp_bigwig:/opt/vep/.vep/gerp_conservation_scores.homo_sapiens.GRCh38.bw,human_ancestor_fa:/opt/vep/.vep/human_ancestor.fa.gz,conservation_file:/opt/vep/.vep/loftee.sql --dir_plugins /opt/vep/Plugins/ -o STDOUT' failed with non-zero exit status 2; VEP Error output:; Smartmatch is experimental at /opt/vep/Plugins/de_novo_donor.pl line 175.; Smartmatch is experimental at /opt/vep/Plugins/de_novo_donor.pl line 214.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 191.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 194.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 238.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 241.; DBI connect('dbname=/opt/vep/.vep/loftee.sql','',...) failed: unable to open database file at /opt/vep/Plugins/LoF.pm line 126. -------------------- EXCEPTION --------------------; MSG: ERROR: No cache found for homo_sapiens, version 95. STACK Bio::EnsEMBL::VEP::CacheDir::dir /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/CacheDir.pm:328; STACK Bio::EnsEMBL::VEP::CacheDir::init /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/CacheDir.pm:227; STACK Bio::EnsEMBL::VEP::CacheDir::new /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/CacheDir.pm:111; STACK Bio::EnsEMBL::VEP::AnnotationSourceAdaptor::get_all_from_cache /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/AnnotationSourceAdaptor.pm:115; STACK Bio::EnsEMBL::VEP::AnnotationSourceAdaptor::get_all /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/AnnotationSourceAdaptor.pm:91; STACK Bio::EnsEMBL::VEP::BaseRunner::get_all_AnnotationSources /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14513:20764,Plugin,Plugins,20764,https://hail.is,https://github.com/hail-is/hail/issues/14513,1,['Plugin'],['Plugins']
Modifiability,"Hail's benchmarks were kind of their own thing and a little neglected.; This change moves the benchmarks into the `hail/python` folder and updates them to use pytest with a custom plugin/set of pytest hooks.; Now, benchmarks can be run from the command line like any pytest.; This change removes the `benchmark-hail` (or `hailbench`) utility. Benchmarks are marked by `pytest.mark.benchmark` (via the `@benchmark` decorator).; By convention, benchmarks are python tests whose names are prefixed by `benchmark_` and are located in files with the same prefix.; Nothing enforces this, however, so you could name your benchmarks `test_*` and put them in files named `test_*.py`.; Benchmarks may import and use any test code or utilities defined in `test/`.; The results of each benchmark are outputted as json lines (`.jsonl`) to the file specified by the `--output` pytest arg or stdout. The folder structure should be familiar, resembling our `test/` directory.; I believe this is flexible enough to add `hailtop` benchmarks should we so wish:; ```; pytest.ini - hoisted from `test/` to include benchmark marks; benchmark/; - conftest.py for custom pytest command line args ; - hail/; - confest.py for custom plugin that runs hail benchmarks; - benchmark_*.py hail query benchmark code; - tools/; - shared utilites, including the `@benchmark`; ```; Supporting pytest fixtures required writing a custom plugin to run benchmarks, as using off-the-shelf; solutions like `pytest-benchmark` would forbid method level fixtures like `tmp_path` etc.; The plugin is designed to run ""macro-benchmarks"" (ie long-running tests) and fully supports pytest parameterisation.; For each benchmark, the plugin initialises hail and then repeats (for a number of iterations defined by the pytest mark); acquiring fixtures, timing invocation and tearing-down fixtures, finally stopping hail. It is therefore unsuitable for; microbenchmarks, for which we currenly have none in python. If we add them we'd need to tweak this s",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14565:180,plugin,plugin,180,https://hail.is,https://github.com/hail-is/hail/pull/14565,1,['plugin'],['plugin']
Modifiability,"HailContext initialization overrides any existing log4j configuration, which can lead to the logs ending up in an unexpected location. This PR adds an option to HailContext initialization to skip this configuration step. I also included two unrelated changes to this PR:; - Not bundling the transitive dependencies for `com.indeed:lsmtree-core:1.0.7`, which don't seem to be needed and can lead to classpath conflicts.; - Allowing the `quiet` option during initialization to silence the warning issued when initializing with pip-installed Hail.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8571:56,config,configuration,56,https://hail.is,https://github.com/hail-is/hail/pull/8571,2,['config'],['configuration']
Modifiability,Handling.fatal$(ErrorHandling.scala:18); 	at is.hail.utils.package$.fatal(package.scala:81); 	at is.hail.variant.ReferenceGenome.addLiftover(ReferenceGenome.scala:407); 	at is.hail.backend.spark.SparkBackend.$anonfun$pyAddLiftover$2(SparkBackend.scala:613); 	at is.hail.backend.spark.SparkBackend.$anonfun$pyAddLiftover$2$adapted(SparkBackend.scala:612); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$3(ExecuteContext.scala:76); 	at is.hail.utils.package$.using(package.scala:657); 	at is.hail.backend.ExecuteContext$.$anonfun$scoped$2(ExecuteContext.scala:76); 	at is.hail.utils.package$.using(package.scala:657); 	at is.hail.annotations.RegionPool$.scoped(RegionPool.scala:17); 	at is.hail.backend.ExecuteContext$.scoped(ExecuteContext.scala:62); 	at is.hail.backend.spark.SparkBackend.$anonfun$withExecuteContext$1(SparkBackend.scala:347); 	at is.hail.backend.spark.SparkBackend.$anonfun$pyAddLiftover$1(SparkBackend.scala:612); 	at is.hail.backend.spark.SparkBackend.$anonfun$pyAddLiftover$1$adapted(SparkBackend.scala:611); 	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:52); 	at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:59); 	at is.hail.backend.spark.SparkBackend.pyAddLiftover(SparkBackend.scala:611); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); 	at py4j.Gateway.invoke(Gateway.java:282); 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); 	at py4j.commands.CallCommand.execute(CallCommand.java:79); 	at py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13993:4488,adapt,adapted,4488,https://hail.is,https://github.com/hail-is/hail/issues/13993,1,['adapt'],['adapted']
Modifiability,"Happened on VDS with small number of partitions (18) but large number of variants (~150mio). [Stage 0:=============================> (1 + 1) / 2]hail: info: running: vep --force --config /home/users/cseed/vep.properties; [Stage 1:======================================> (12 + 6) / 18]hail: vep: caught exception: Job aborted due to stage failure: Task 17 in stage 1.0 failed 4 times, most recent failure: Lost task 17.3 in stage 1.0 (TID 22, nid00019.urika.com): java.lang.IllegalArgumentException: Size exceeds Integer.MAX_VALUE; at sun.nio.ch.FileChannelImpl.map(FileChannelImpl.java:836); at org.apache.spark.storage.DiskStore$$anonfun$getBytes$2.apply(DiskStore.scala:125); at org.apache.spark.storage.DiskStore$$anonfun$getBytes$2.apply(DiskStore.scala:113); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1206); at org.apache.spark.storage.DiskStore.getBytes(DiskStore.scala:127); at org.apache.spark.storage.DiskStore.getBytes(DiskStore.scala:134); at org.apache.spark.storage.BlockManager.doGetLocal(BlockManager.scala:512); at org.apache.spark.storage.BlockManager.getLocal(BlockManager.scala:429); at org.apache.spark.storage.BlockManager.get(BlockManager.scala:618); at org.apache.spark.CacheManager.getOrCompute(CacheManager.scala:44); at org.apache.spark.rdd.RDD.iterator(RDD.scala:262); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:300); at org.apache.spark.rdd.RDD.iterator(RDD.scala:264); at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38); at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:300); at org.apache.spark.rdd.RDD.iterator(RDD.scala:264); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66); at org.apache.spark.scheduler.Task.run(Task.scala:88); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at j",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/430:180,config,config,180,https://hail.is,https://github.com/hail-is/hail/issues/430,1,['config'],['config']
Modifiability,"Happy to hear suggestions as to better ways to do this, but I've made too many emitter typos with while loops. I keep either doing something like. ```; i := 0,; j := 0,; Code.whileLoop(i < M,; Code.whileLoop(j < N, ; ???,; j := j + 1; ); i := i + 1; ); ```; (j should be inside the outer whileLoop),; forgetting one of the increments, or forgetting to set the variables to 0 at the beginning. `Code.forLoop` is to force me to include all parts.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7587:360,variab,variables,360,https://hail.is,https://github.com/hail-is/hail/pull/7587,1,['variab'],['variables']
Modifiability,Have a new test to target that will verify correct code generation. Also refactor parameterpack a bit to be more traceable. High prio because this is blocking ptypes work.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8084:73,refactor,refactor,73,https://hail.is,https://github.com/hail-is/hail/pull/8084,1,['refactor'],['refactor']
Modifiability,"Hi!. Trying to calculate polygenic risk score with code from the [Polygenic Score Calculation](https://hail.is/docs/0.2/guides/genetics.html#polygenic-score-calculation), getting error with stacktrace:. `2022-05-14 12:09:07 Hail: INFO: Running Hail version 0.2.94-f0b38d6c436f; 2022-05-14 12:09:08 SparkContext: WARN: Using an existing SparkContext; some configuration may not take effect.; 2022-05-14 12:09:08 root: INFO: RegionPool: initialized for thread 30: Thread-4; 2022-05-14 12:09:09 MemoryStore: INFO: Block broadcast_0 stored as values in memory (estimated size 34.3 KiB, free 434.4 MiB); 2022-05-14 12:09:09 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated size 3.2 KiB, free 434.4 MiB); 2022-05-14 12:09:09 BlockManagerInfo: INFO: Added broadcast_0_piece0 in memory on 10.40.3.21:33951 (size: 3.2 KiB, free: 434.4 MiB); 2022-05-14 12:09:09 SparkContext: INFO: Created broadcast 0 from broadcast at SparkBackend.scala:311; 2022-05-14 12:09:11 root: INFO: RegionPool: FREE: 64.0K allocated (64.0K blocks / 0 chunks), regions.size = 1, 0 current java objects, thread 30: Thread-4; 2022-05-14 12:09:11 root: ERROR: HailException: Invalid locus '11:135009883' found. Position '135009883' is not within the range [1-135006516] for reference genome 'GRCh37'.; From is.hail.utils.HailException: /data/public/prs/ex_antonk.bim:1013423: Invalid locus '11:135009883' found. Position '135009883' is not within the range [1-135006516] for reference genome 'GRCh37'.; offending line: 11	.	0	135009883	CT	C; 	at is.hail.utils.ErrorHandling.fatal(ErrorHandling.scala:30); 	at is.hail.utils.ErrorHandling.fatal$(ErrorHandling.scala:28); 	at is.hail.utils.package$.fatal(package.scala:78); 	at is.hail.utils.Context.wrapException(Context.scala:21); 	at is.hail.utils.WithContext.foreach(Context.scala:51); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$2(LoadPlink.scala:37); 	at is.hail.io.plink.LoadPlink$.$anonfun$parseBim$2$adapted(LoadPlink.scala:36); 	at scala.colle",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/11836:355,config,configuration,355,https://hail.is,https://github.com/hail-is/hail/issues/11836,1,['config'],['configuration']
Modifiability,"Hi, I am using hail in spark, but encounter some problem.; I followed the ""Getting Started"" to deploy hail , and build Hail from source; (https://hail.is/docs/stable/getting_started.html). I set the environmental variables as follows:; ```; export SPARK_HOME=/opt/Software/spark/spark-2.0.2-bin-hadoop2.6; export HAIL_HOME=/opt/Software/hail; export PYTHONPATH=""$PYTHONPATH:$HAIL_HOME/python:$SPARK_HOME/python:`echo $SPARK_HOME/python/lib/py4j*-src.zip`""; export SPARK_CLASSPATH=$HAIL_HOME/build/libs/hail-all-spark.jar; ```; I put the vcf file in hadoop， as follows:; ```; [hdfs@tele-1 root]$ hdfs dfs -ls /hail/test; Found 1 items; -rw-r--r-- 3 hdfs supergroup 21194 2017-08-08 18:20 /hail/test/BRCA1.raw_indel.vcf; ```; But when I excuted the command:; ```; hc.import_vcf('/hail/test/BRCA1.raw_indel.vcf').write('/hail/test/brca1.vds'); ```; there are some errors：; ```; [hdfs@tele-1 root]$ python; Python 2.7.13 |Anaconda 4.4.0 (64-bit)| (default, Dec 20 2016, 23:09:15) ; [GCC 4.4.7 20120313 (Red Hat 4.4.7-1)] on linux2; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; Anaconda is brought to you by Continuum Analytics.; Please check out: http://continuum.io/thanks and https://anaconda.org; >>> import hail; >>> hc = hail.HailContext(); Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel).; hail: info: SparkUI: http://192.168.1.4:4041; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.1-0320a61; >>> hc.import_vcf('/hail/test/BRCA1.raw_indel.vcf').write('/hail/test/brca1.vds'); hail: warning: `/hail/test/BRCA1.raw_indel.vcf' refers to no files; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""<decorator-gen-483>"", line 2, in import_vcf; File ""/opt/Software/hail/python/hail/java.py"", line 112, in handle_py4j; 'Error summary: %s' % (deepest, full, Env.hc().version, deepest)); h",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/2076:213,variab,variables,213,https://hail.is,https://github.com/hail-is/hail/issues/2076,1,['variab'],['variables']
Modifiability,"Hi, I tried the following command , and configured the log path , but it still not worked, are there any suggestions?. spark-submit --executor-memory 16g --executor-cores 4 --class org.broadinstitute.hail.driver.Main ******/hail-all-spark.jar --master yarn-client importvcf --log-file /user/hail/hail.log /user/hail/split_test.vcf splitmulti write -o /user/hail/split_test_1_1.vds exportvcf -o /user/hail/split_test_1_1.vcf. ERROR:; WARNING: Running spark-class from user-defined location.; hail: info: running: importvcf /user/hail/sample.vcf; hail: info: Coerced sorted dataset; hail: info: running: splitmulti; hail: info: running: write -o /user/hail/sample_1008.vds; hail: write: caught exception: org.apache.spark.SparkException: Job aborted.; .........; at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 2.0 failed 4 times, most recent failure: Lost task 0.3 in stage 2.0 (TID 5, bio-x-3): java.io.IOException: The file being written is in an invalid state. Probably caused by an error thrown previously. Current state: COLUMN; ...........; at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)java.io.IOException: The file being written is in an invalid state. Probably caused by an error thrown previously. Current state: COLUMN. [splitmulti_1_1.txt](https://github.com/hail-is/hail/files/550095/splitmulti_1_1.txt)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1003:40,config,configured,40,https://hail.is,https://github.com/hail-is/hail/issues/1003,1,['config'],['configured']
Modifiability,I accidentally copy pasted the line. If you look a few lines down you can see the actual name/value pair for that environment variable.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13628:126,variab,variable,126,https://hail.is,https://github.com/hail-is/hail/pull/13628,1,['variab'],['variable']
Modifiability,"I added a `PropertySuite` and deleted the `check` business. I feel this is an improvement, but also that we can do better. You can still have an orphaned `Prop` by writing:. ```; class MyProperties extends PropertySuite {; forAll ... // no property(""name"") = ...; }; ```. I think better would be for `PropretySuite` to declare `forAll` and make `forAll` take a name. `PropertySuite` extends `SparkSuite`. I was seeing some strange behavior that I don't fully understand if I made it extend `TestNGSuite` and then mixed `PropertySuite` and `SparkSuite` in a test suite. Thoughts?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/732:198,extend,extends,198,https://hail.is,https://github.com/hail-is/hail/pull/732,3,['extend'],"['extend', 'extends']"
Modifiability,"I added a new field to the global config that is gs:// + hail_test_gcs_bucket named test_blob_storage_uri and use that wherever it doesn't matter that the backend be google storage, which is essentially everywhere except for the FS/copy tests, where we specifically want a test gcs bucket.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10960:34,config,config,34,https://hail.is,https://github.com/hail-is/hail/pull/10960,1,['config'],['config']
Modifiability,"I added the capability for the deploy config to find the domain from setting it in the config.ini file. This way users only use `hailctl config set domain` rather than `hailctl dev config set domain`. In addition, we use this new capability to make a test in Batch work on Azure. CC: @danking",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11113:38,config,config,38,https://hail.is,https://github.com/hail-is/hail/pull/11113,4,['config'],['config']
Modifiability,"I added the configuration option for the minimum number of workers that should be present at any time. I tested this in my namespace. I'd like you to double check the logic is correct for the number of workers needed as I derived it by working through examples:. ```python3; n_live_instances = self.n_instances_by_state['pending'] + self.n_instances_by_state['active']; n_standing_instances_needed = max(0, self.min_instances - self.n_instances); n_standing_instances_needed = min(; n_standing_instances_needed,; self.max_live_instances - n_live_instances,; self.max_instances - self.n_instances,; remaining_instances_per_autoscaler_loop,; # 20 queries/s; our GCE long-run quota; 300,; ); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12742:12,config,configuration,12,https://hail.is,https://github.com/hail-is/hail/pull/12742,1,['config'],['configuration']
Modifiability,"I also added factories for Google and Azure so that we only; check the global-config cloud setting once, not repeatedly; every time we create an AsyncFS.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11201:78,config,config,78,https://hail.is,https://github.com/hail-is/hail/pull/11201,1,['config'],['config']
Modifiability,"I also did a bit of refactoring in lmmreg to make this change more organic. I will add a test asap, but want to simultaneously give @alexb-3 a chance to look over the math.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1720:20,refactor,refactoring,20,https://hail.is,https://github.com/hail-is/hail/pull/1720,1,['refactor'],['refactoring']
Modifiability,I also reduced the layers and size of the notebook a bit. It's still ~8GB. I added `time` to the make command for curiosity's sake.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4976:19,layers,layers,19,https://hail.is,https://github.com/hail-is/hail/pull/4976,1,['layers'],['layers']
Modifiability,"I based this on the row store in 0.2, in order to preserve partitioning on block matrices under read / write. @danking this should adapt to HailBlockMatrix with basically no change.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2276:131,adapt,adapt,131,https://hail.is,https://github.com/hail-is/hail/pull/2276,1,['adapt'],['adapt']
Modifiability,"I broke this when I separated out the dependencies for hail into two layers:. 1. hailtop dependencies; 2. hail dependencies, which builds on top of the hailtop dependencies. This fix does two things:; - Use the full dependencies in 1 & 2; - Use fully pinned dependencies when installing on clusters which seems better than using our wide-range dependencies. I left the `install-deps` and `install-dev-deps` as the normal requirements files as those are meant for development (I think?) but am happy to take opinions on whether we should use fully pinned deps there as well. I have so far been going by the rule of thumb of fully-pinned for CI and production environments, more lax rules for dev environments. See [here](https://github.com/hail-is/hail/pull/12446#discussion_r1030986069) for additional context. cc: @tpoterba, any idea why the test dataproc test succeeded?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12510:69,layers,layers,69,https://hail.is,https://github.com/hail-is/hail/pull/12510,1,['layers'],['layers']
Modifiability,I can break this up further if you want. Big changes:. - change batch.py to support multi-line commands (use `{\n...\n}`); - change batch.py and job.py to support per-job environment variables (and add tests to test_batch.py); - add `partition` to hail top mirroring the implementation in Scala; - implement BatchPoolExecutor which attempts to faithfully implement the interface of concurrent.futures.Executor,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9035:183,variab,variables,183,https://hail.is,https://github.com/hail-is/hail/pull/9035,1,['variab'],['variables']
Modifiability,I could not get the `\d` to work for me on an Ubuntu machine. The `[0-9]`; range seems to work with extended regexps.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11568:100,extend,extended,100,https://hail.is,https://github.com/hail-is/hail/pull/11568,1,['extend'],['extended']
Modifiability,I develop accross a couple of OSes and my username isn't always the same. I'd like to expose this make variable so that I can push images to the same location.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12846:103,variab,variable,103,https://hail.is,https://github.com/hail-is/hail/pull/12846,1,['variab'],['variable']
Modifiability,"I didn't give very good names to all the introduced `memoize`s, but those will all go away as we push the refactoring through.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10848:106,refactor,refactoring,106,https://hail.is,https://github.com/hail-is/hail/pull/10848,1,['refactor'],['refactoring']
Modifiability,"I discovered [issue forms](https://github.blog/changelog/2021-06-23-issues-forms-beta-for-public-repositories/) the other day and thought it might be helpful for directing users to the discussion forum / Zulip chatroom. With this configuration, when someone opens an issue, they'll be presented with some options:; ![Screen Shot 2023-01-13 at 8 01 11 AM](https://user-images.githubusercontent.com/1156625/212326189-214fb8b2-e210-4c96-8b52-7000d5025148.png). If they choose to report a bug, they'll be presented with a form prompting for Hail version and log output.; ![Screen Shot 2023-01-13 at 8 01 46 AM](https://user-images.githubusercontent.com/1156625/212326274-affeaa80-adec-45c9-b436-73059c6fc841.png)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12595:230,config,configuration,230,https://hail.is,https://github.com/hail-is/hail/pull/12595,1,['config'],['configuration']
Modifiability,"I do not know why we do this, but we return a `Code` here, not a `Value`, so it seems silly to store in a variable. In practice, the LIR is littered with invocations that store their value in a local which is then read and stored in a different local beause we `memoize` the function call.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13777:106,variab,variable,106,https://hail.is,https://github.com/hail-is/hail/pull/13777,1,['variab'],['variable']
Modifiability,"I finally figured out how to get the authorization bearer token for the Grafana robot into Grafana automatically. The problem I'm running into right now is when we load a datasource from a configuration file, we can not edit any of the settings in the UI. We'd want to make sure all the prometheus settings we want are inside the new config file. I also don't want to accidentally overwrite any of the existing configuration.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10772:189,config,configuration,189,https://hail.is,https://github.com/hail-is/hail/pull/10772,3,['config'],"['config', 'configuration']"
Modifiability,"I fixed sql-config.cnf in the last change, not sql-config.json. I just changed everything to treat a key being `null` in JSON the; same as the key not existing. The situation now:; - sql-config.cnf will not have the string None (seems right, cnf is for MySQL); - sql-config.json might have `null` which is treated the same as a missing key",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8500:12,config,config,12,https://hail.is,https://github.com/hail-is/hail/pull/8500,4,['config'],['config']
Modifiability,I forgot to include the changes in #14056 to the scala code as well. This favors using `basePath` in the Scala deploy config over the `defaultNamespace`.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14195:118,config,config,118,https://hail.is,https://github.com/hail-is/hail/pull/14195,1,['config'],['config']
Modifiability,"I had a choice on how to implement this and I decided to add a JobTask class that takes care of a single pod and the Job changes to just be a manager of the pods. However, I could have done it all within the Job if you think that is clearer. Happy to refactor if needed. Please look and see if I have enough tests. The tests are passing, but I'm getting this error message. Is this expected or a bug in my code? . ```; INFO	| 2019-02-22 11:48:48,126 	| _internal.py 	| _log:87 | 127.0.0.1 - - [22/Feb/2019 11:48:48] ""POST /pod_changed HTTP/1.1"" 204 -; INFO	| 2019-02-22 11:48:48,210 	| _internal.py 	| _log:87 | 127.0.0.1 - - [22/Feb/2019 11:48:48] ""POST /pod_changed HTTP/1.1"" 204 -; INFO	| 2019-02-22 11:48:48,833 	| server.py 	| mark_complete:190 | wrote log for job 61, main task to logs/job-61-main.log; INFO	| 2019-02-22 11:48:48,845 	| server.py 	| set_state:272 | job 61 changed state: Created -> Complete; INFO	| 2019-02-22 11:48:48,851 	| server.py 	| parent_new_state:287 | parent 61 successfully complete for 63; INFO	| 2019-02-22 11:48:48,857 	| server.py 	| parent_new_state:292 | all parents successfully complete for 63, creating pod; INFO	| 2019-02-22 11:48:48,918 	| server.py 	| create_pod:135 | created pod name: job-63-main-qqwb2 for job 63, main task; INFO	| 2019-02-22 11:48:48,929 	| server.py 	| mark_complete:330 | job 61 complete, exit_code 0; INFO	| 2019-02-22 11:48:48,995 	| _internal.py 	| _log:87 | 127.0.0.1 - - [22/Feb/2019 11:48:48] ""POST /pod_changed HTTP/1.1"" 204 -; [2019-02-22 11:48:49,043] ERROR in app: Exception on /test [POST]; Traceback (most recent call last):; File ""//anaconda/envs/hail-batch/lib/python3.6/site-packages/flask/app.py"", line 1982, in wsgi_app; response = self.full_dispatch_request(); File ""//anaconda/envs/hail-batch/lib/python3.6/site-packages/flask/app.py"", line 1615, in full_dispatch_request; return self.finalize_request(rv); File ""//anaconda/envs/hail-batch/lib/python3.6/site-packages/flask/app.py"", line 1630, in finalize_request",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5418:251,refactor,refactor,251,https://hail.is,https://github.com/hail-is/hail/pull/5418,1,['refactor'],['refactor']
Modifiability,"I hardcoded us-central1, which is the only thing we're using right now. Otherwise, we'd have to change CI before deploy. Also, clearly a fixed global zone is naive, so I think we have to reconsider the GCP configuration going forward. FYI @danking",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8016:206,config,configuration,206,https://hail.is,https://github.com/hail-is/hail/pull/8016,1,['config'],['configuration']
Modifiability,"I have diagnosed the root cause of the issue observed by; both Patrick and Chris: incorrect spilling of method parameter variables. This patch makes the bug impossible to replicate using proper interfaces,; though does not fix the underlying issue in LIR. Here's a way to replicate:. ```; val mb = kb.genEmitMethod(""btree_foo"", FastIndexedSeq[ParamType](typeInfo[Long]), typeInfo[Unit]); mb.voidWithBuilder { cb =>; val arg = mb.getCodeParam[Long](1).asInstanceOf[Settable[Long]]. cb.assign(arg, arg + 1L). (0 until 100).foreach { i =>; cb.println(s""i=$i, arg="", arg.toS); }. }; cb.invokeVoid(mb,const( 0L)); ```. called with `0`, this prints `1` until i=84, then starts printing 0 again.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9946:121,variab,variables,121,https://hail.is,https://github.com/hail-is/hail/pull/9946,1,['variab'],['variables']
Modifiability,"I haven't tested this yet because I wanted to see if you liked the idea. Not as flexible as a python loop, but possibly the easiest way to get rid of *a lot* of yaml.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11771:80,flexible,flexible,80,https://hail.is,https://github.com/hail-is/hail/pull/11771,1,['flexible'],['flexible']
Modifiability,"I knew I was missing tests of greater than two layers. Sure enough there were more bugs lurking. I think >3 layers won't find any new bugs given that there are basically three kinds of b-trees:. - 1 layer: all leaf nodes, <=1024 elements; - 2 layers: one internal/key layer, one leaf layer [1025, 1024^2] elements; - n layers: n-1 internal/key layers, one leaf layer [1024^(n-1)+1, 1024^n] elements. The last case is the first case where we have to do two levels of internal layers. This traversal is defined inductively, so I suspect succeeding on 3 layers tests all the functionality of >3 layers.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3807:47,layers,layers,47,https://hail.is,https://github.com/hail-is/hail/pull/3807,8,['layers'],['layers']
Modifiability,"I left the changes to Query and Batch in separate commits for ease of review. I put these in the same PR because we don't really have standalone testing for JVM Jobs outside of Query-on-Batch so the FASTA use-case serves as a test here that cloudfuse is working properly for JVM Jobs. Would be great if Jackie you could review the batch commit and Tim could review the query commit. ## Hail Query; - Added support for the `FROM_FASTA_FILE` rpc and the service backend now passes sequence file information from RGs in every rpc; - Refactored the liftover handling in service_backend to not redundantly store liftover maps and just take them from the ReferenceGenome objects like I did for sequence files. This means that add/remove liftover/sequence functions on the Backend are just intended to sync up the backend with python, which is a no-op for the service backend.; - Don't localize the index file on fromFASTAFile/addSequence before creating the index object. `FastaSequenceIndex` just loads the whole file on construction so might as well stream it in from whatever storage it's in.; - FASTA caching is left alone because those files will be mounted and unmounted from the jvm container over the life of the job. JVM doesn't have to worry about disk usage because that's handled by Batch XFS quotas, so long as the service backend requests enough storage to fit the FASTA file. Batch will make sure that a given bucket (and therefore a given FASTA file) is mounted once per-user on a batch worker. ## Hail Batch; - Added support for read-only cloudfuse mounts for JVM jobs; - These mounts are shared between jobs on the same machine from the same user; - I did not change DockerJobs, but they could be very easily adapted to use this new mount-sharing code.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12736:530,Refactor,Refactored,530,https://hail.is,https://github.com/hail-is/hail/pull/12736,2,"['Refactor', 'adapt']","['Refactored', 'adapted']"
Modifiability,"I made the name change `gce-deploy-config` to `worker-deploy-config`. Feel free to change the name. Also, I'm pretty sure this name change won't break the deploy because it's created as part of the deploy process. But it has been 198 days since the secret was updated... FYI: @danking",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11002:35,config,config,35,https://hail.is,https://github.com/hail-is/hail/pull/11002,2,['config'],['config']
Modifiability,"I manually added a `hail_test_gcs_bucket` field to the k8s global config and use that value wherever we have our current test bucket hard coded. I also added the necessary terraform to make that in a new cluster, though I have not done a new terraform run in my project. Once this and a couple more refactoring PRs go in I'll be able to run ci tests in a separate cluster and validate that the terraform is working correctly. cc: @danking",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10807:66,config,config,66,https://hail.is,https://github.com/hail-is/hail/pull/10807,2,"['config', 'refactor']","['config', 'refactoring']"
Modifiability,I manually added a field to the global-config for the requester pays bucket used in batch tests. Adding it here to build.py's view of global fields so that CI can template #10866 in the future and actually test it.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10870:39,config,config,39,https://hail.is,https://github.com/hail-is/hail/pull/10870,1,['config'],['config']
Modifiability,"I manually changed the Cloud SQL automated backups storage from the `us` multi-region to `us-central1`. There's no reason to store it in a multi-region and it's more expensive. What I didn't realize is that this configuration is actually owned by the terraform that we have managing the lifecycle of the database and other infra, so we need to update the terraform to reflect the desired (and current) state.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14568:212,config,configuration,212,https://hail.is,https://github.com/hail-is/hail/pull/14568,1,['config'],['configuration']
Modifiability,"I merged these already approved, likely passing, branches together for CI efficiency. - [daniel-goldstein/drop-user-if-exists](/daniel-goldstein/hail/tree/drop-user-if-exists); - [daniel-goldstein/mysql-flexible](/daniel-goldstein/hail/tree/mysql-flexible); - [daniel-goldstein/blame-ignore-isort-pr](/daniel-goldstein/hail/tree/blame-ignore-isort-pr); - [jigold/timings](/jigold/hail/tree/timings); - [CDiaz96/find_spark_home_type](/CDiaz96/hail/tree/find_spark_home_type); - [daniel-goldstein/close-db-pool-last-batch-driver](/daniel-goldstein/hail/tree/close-db-pool-last-batch-driver); - [chrisvittal/lowering/fix-export-table-separate-header](/chrisvittal/hail/tree/lowering/fix-export-table-separate-header); - [chrisvittal/vds/n_partitions](/chrisvittal/hail/tree/vds/n_partitions). FYI @chrisvittal , @jigold, @daniel-goldstein, @CDiaz96",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11482:203,flexible,flexible,203,https://hail.is,https://github.com/hail-is/hail/pull/11482,2,['flexible'],['flexible']
Modifiability,"I misunderstood the issue originally. The exit status was set *in the sub-shell*, so; it did not affect the parent shell's environment. Instead, I run the command in; a sub-shell and update the variable in the parent shell. I also had to fix the issues that arose while the check wasn't honored.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9377:194,variab,variable,194,https://hail.is,https://github.com/hail-is/hail/pull/9377,1,['variab'],['variable']
Modifiability,"I must have broken this during a recent refactor of the decorators. When making requests to an internal namespace, the default namespace's auth token is set in the `X-Hail-Internal-Authorization` header and the dev namespace's token is in the `Authorization` header. The dev namespace needs to know *not* to pick up the `X-Hail-Internal-Authorization` header.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13515:40,refactor,refactor,40,https://hail.is,https://github.com/hail-is/hail/pull/13515,1,['refactor'],['refactor']
Modifiability,"I need to get GKE costs down further. The driver is now 3 CPU anyway. @daniel-goldstein, I am not sure how to modify the Azure terraform. It appears this; is controlled by a variable which is already set to a 4 core machine?",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11985:174,variab,variable,174,https://hail.is,https://github.com/hail-is/hail/pull/11985,1,['variab'],['variable']
Modifiability,"I observed a cluster with it set to the default idle time of 30 seconds in Azure and the workers were continuously thrashing leading up to 49 instances being created over the course of a PR. With an idle time of 120 seconds, there was no thrashing and 28 instances were created over the course of the PR (16 standard + job private etc.). The cluster nicely scaled down at the end of the PR. It looked like a couple of times the `standard-np` pool scaled up and then scaled down so I assume the `standard` pool wasn't at full capacity while that was happening. It might be worth configuring the `standard-np` pool to be 4 or 5 standing instances with 16 cores and see what happens -- that might help as well.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13314:578,config,configuring,578,https://hail.is,https://github.com/hail-is/hail/pull/13314,1,['config'],['configuring']
Modifiability,"I picked this refactor off of my terra branch and took it the last ten yards such that now you can run `make batch-db` and get a full local instance of the batch database that you can access through `mysql -h 127.0.0.1 -u root -ppw` or. ```ipython; (hail) dgoldste@wmce3-cb7 hail % HAIL_SQL_DATABASE=local-batch ipython; Python 3.9.17 (main, Jul 5 2023, 16:17:03); Type 'copyright', 'credits' or 'license' for more information; IPython 8.15.0 -- An enhanced Interactive Python. Type '?' for help. In [1]: from gear import Database; ...: db = Database(); ...: await db.async_init(); ...: await db.select_and_fetchone('SELECT * FROM globals'); ...:; ...:; Out[1]:; {'instance_id': 'XXXXXXXX',; 'internal_token': 'XXXXXXX',; 'n_tokens': 200,; 'frozen': 0}; ```. If you add a migration, just run `make batch-db` again.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13670:14,refactor,refactor,14,https://hail.is,https://github.com/hail-is/hail/pull/13670,2,"['enhance', 'refactor']","['enhanced', 'refactor']"
Modifiability,"I played with a few options. I liked this one the best. Downside to `Value[T] extends Code[T]`:; - A bunch of code (using Array) assumes Code[T] is monomorphic. Either way I fixed those here (by switching to polymorphic IndexedSeq[T]); - Can't use the analogous setup for PValue since the hierarchy is more complicated. This is why I picked this solution. Downside to this solution: ; - Scala won't apply stacked implicits, so need to add additional implicits for e.g. Value[Int] to CodeInt. I do that here. In the end, `Value[T]` is a thing that can produce multiple `Code[T]`, which can then only be emitted once. I used `Value.get: Code[T]` over `load()` and renamed a few field accessors get => getField. If we like how this goes I can rip out `load()`. I fixed some know multiple emission of Code[T] in ETypes buildEncoder. I will slowly convert over the necessary stuff to `Value[T]` in later PRs. `Code.markEmitted` (not called) can be used to find Code[T] that are emitted multiple times.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8229:78,extend,extends,78,https://hail.is,https://github.com/hail-is/hail/pull/8229,2,"['extend', 'polymorphi']","['extends', 'polymorphic']"
Modifiability,"I rage programmed here a bit. I was pretty frustrated with this class when; trying to debug some other issues in the Shuffler IR. I have two aims with this; PR:; 1. Use a clear, consistent naming scheme throughout the file; 2. Use concise definitions. In particular, I unified the terminology to use these words:; - name: the function's name; - valueParameterTypes: the type of each value-level parameter; - typeParameters: the type-level parameters, these are always type variables, I; considered calling them typeVariables, but I like the symmetry with valueParameters; - returnType and returnPType; - typeArguments and valueArguments: these refer to the concrete values to which the parameters are bound. I also simplified some anonymous class definitions by providing constructor arguments; instead of methods that are always overridden by `val`s.; Oh, and I changed `IRFunction` to `JVMFunction` because there are already ""IR"" functions; and an ""irRegistry"" and it was super confusing to not have the IRFunctions inside the; ""irRegistry"". I did not use `CodeFunction` because these are actually implemented by; a number of different JVM Bytecode building tools: `Code`, `PCode`, `EmitCode`, and; `IEmitCode`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8718:473,variab,variables,473,https://hail.is,https://github.com/hail-is/hail/pull/8718,1,['variab'],['variables']
Modifiability,"I realize this looks like a lot of code changes, but it's mostly copying and pasting two SQL procedures and changing one line in each. This adds 4 bits of metadata to requests that then can be queried as extra metadata:; - batch_id; - job_id; - batch_operation; - job_queue_time. Should be self-explanatory except job_queue time is the time in which the job is first set to ready to when it was scheduled on the worker (exact moment is when the job config is made to send to the worker). Example logging query. Note that the search on ""batch_id"" is not optimized so you definitely want to add some kind of time limit that's short on the window to search. I can add my Python script that scrapes these logs and makes a Plotly figure in a separate PR once this goes in. ```; (; resource.labels.container_name=""batch""; resource.labels.namespace_name=""{namespace}""; ) OR (; resource.labels.container_name=""batch-driver""; resource.labels.namespace_name=""{namespace}""; ) OR (; resource.type=""gce_instance""; logName:""worker.log""; labels.""compute.googleapis.com/resource_name"":""{namespace}""; ); jsonPayload.batch_id=""{batch_id}""; timestamp >= ""{start_timestamp}"" {end_timestamp}; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13219:449,config,config,449,https://hail.is,https://github.com/hail-is/hail/pull/13219,1,['config'],['config']
Modifiability,"I renamed RichProgressBar and SimpleRichProgressBar to ...CopyToolProgressBar because that is more accurate. I enhanced both to now include a count and a rate with the right units based on the description. It is a bit flaky because I need the descriptions to be exactly ""files"" or exactly ""bytes"" to pick the right units, but this seems fine for the specific case of th CopyToolProgressBar. There is probably a better way to build these UIs. I am sure we will start to figure that out as we use rich more. Before:; <img width=""830"" alt=""Screenshot 2023-10-16 at 18 28 14"" src=""https://github.com/hail-is/hail/assets/106194/95f8828e-beb3-46d2-9403-18ff7aa60256"">. After:; <img width=""830"" alt=""Screenshot 2023-10-16 at 18 27 53"" src=""https://github.com/hail-is/hail/assets/106194/01186b7c-d59f-4a0e-a1f6-9279fb50ae7e"">",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13832:111,enhance,enhanced,111,https://hail.is,https://github.com/hail-is/hail/pull/13832,1,['enhance'],['enhanced']
Modifiability,I tested the config comes through correctly in my namespace.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10839:13,config,config,13,https://hail.is,https://github.com/hail-is/hail/pull/10839,1,['config'],['config']
Modifiability,"I think prometheus got forcibly shutdown and its volume got corrupted, which caused it to fail on startup. I had to wipe the volume. Starting with a new volume introduced permissions issues, I think because that volume claim might still have been there from the original time we were running prometheus.. Either way I was able to get this up and running in default. I had wanted to extend the retention time so we can see a full month of metrics instead of just two weeks, so I'm being extra nice with the volume and moving prometheus off of preemptibles in default.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10271:382,extend,extend,382,https://hail.is,https://github.com/hail-is/hail/pull/10271,1,['extend'],['extend']
Modifiability,"I think this is a race condition with another process trying to pull the same image after the current process has pulled the image. That would mostly be solved by a per user Docker cache, but I think this solution is still needed as you could have a race condition on the cache timeout boundaries. ```; Traceback (most recent call last):; File ""/usr/local/lib/python3.6/site-packages/batch/worker.py"", line 287, in run; name=f'batch-{self.job.batch_id}-job-{self.job.job_id}-{self.name}'); File ""/usr/local/lib/python3.6/site-packages/batch/worker.py"", line 91, in docker_call_retry; return await f(*args, **kwargs); File ""/usr/local/lib/python3.6/site-packages/aiodocker/containers.py"", line 48, in create; url, method=""POST"", data=config, params=kwargs; File ""/usr/local/lib/python3.6/site-packages/aiodocker/docker.py"", line 223, in _query_json; path, method, params=params, data=data, headers=headers, timeout=timeout; File ""/usr/local/lib/python3.6/site-packages/aiodocker/docker.py"", line 291, in __aenter__; resp = await self._coro; File ""/usr/local/lib/python3.6/site-packages/aiodocker/docker.py"", line 206, in _do_query; raise DockerError(response.status, json.loads(what.decode(""utf8""))); aiodocker.exceptions.DockerError: DockerError(404, 'No such image: gcr.io/hail-vdc/ci-utils:e9pnvtf1078g'); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8193:733,config,config,733,https://hail.is,https://github.com/hail-is/hail/pull/8193,1,['config'],['config']
Modifiability,"I think this is what was wrong with the `git_make_bash_image` taking a minute each time. Since every image without a `publishAs` uses `ci-intermediate`, the `ci-intermediate:cache-PR-X` tag is left pointing to whichever anonymous image built last in the PR run. This is certainly never `git_make_bash_image`, so every time it gets rebuilt, the cache-from that it is using points to an an image whose layers do not include a layer that is `RUN apt-get update && apt-get install -y git make bash`. If this PR runs twice, hopefully we'll see the first step go super quick.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12285:400,layers,layers,400,https://hail.is,https://github.com/hail-is/hail/pull/12285,1,['layers'],['layers']
Modifiability,"I think this may help users discover `group_by` and also help users; who are comfortable with the idea of a counter but not with `group_by`. I added a new dataset for doctests and I realized a couple things:; - doctest_write_data.py is not deterministic; - if I add/change one dataset, my commit explodes with changes to all the datasets (see above); - doctest_write_data.py has to be run by *me*, it's not run by CI. I also noticed that when you specify no `row_key` to `import_matrix_table` you get a row key called `row_id`, which is annoying. Anyway now when someone asks how to count the mutations in each gene by consequence type we can point them to the `counter` docs. ---. Adding a dataset caused a bunch of docs failure that lead me to change how we do doctesting. The changes are summarized below.; - ignore `python/.eggs`; - make `PARALLELISM` configurable in `Makefile`; - fix `make pytest` (it referenced a non-extant target); - add `make doctest` (this and `pytest` use setup.py to replicate the environment the user would have after installation, I prefer this approach because I need not manually install any dependencies, setup.py handles that, it also configures spark correctly without environment variables); - harmonize `doctest` and `pytest` parameters in `build.gradle` and `Makefile`; - clean up import order in `conftest.py` to match pylint's desired ordering; - use a `temple.TemporaryDirectory` for all doctest and test output, which is automatically cleaned up (if you want to interrogate it you can `ctrl-z` a running doctest); this allows us to not copy the entire python directory into a build directory before running pytest; - *important:* re-generate all input datasets on every run of the tests. Previously, there was a file `doctest_write_data.py` which you were supposed to run when you changed the datasets, but if Hail changes then the random datasets generated by `doctest_write_data.py` might change. This means when I came along to add a new dataset, I had t",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6856:856,config,configurable,856,https://hail.is,https://github.com/hail-is/hail/pull/6856,1,['config'],['configurable']
Modifiability,"I tracked down why this is happening. The old code stored the (compressed) genotype data per variant in a buffer and decoded it in BgenRecord.getValue. The new code decodes eagerly, but only if the entries are needed. I assume the intention was to mark the entries as unneeded during the scan, but not when decoding the actual values, but this wasn't done. It isn't done easily, either, since we can't set a per-Hadoop import configuration, see: https://github.com/hail-is/hail/issues/3861. Options:. - go back to the old code that stashes the compressed value and evaluates lazily,; - have separate InputFormat/RecordReader for scan and decode,; - stop using Hadoop InputFormat to load BGEN and just code it in directly in Spark, where it is trivial to pass different parameters to scan and decode. I personally vote for the latter.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3862:426,config,configuration,426,https://hail.is,https://github.com/hail-is/hail/issues/3862,1,['config'],['configuration']
Modifiability,"I tried to run Hail with Spark 2.4.4 built for Scala 2.12, and it did not work. It does work with Spark 2.4.4 built for Scala 2.11. Here's the error I got with Scala 2.12:; > Py4JJavaError: An error occurred while calling z:is.hail.HailContext.apply.; > : java.lang.NoSuchMethodError: scala/Predef$.refArrayOps([Ljava/lang/Object;)Lscala/collection/mutable/ArrayOps; (loaded from file:/home/hammer/codebox/spark-2.4.4-bin-without-hadoop-scala-2.12/jars/scala-library-2.12.8.jar by sun.misc.Launcher$AppClassLoader@ac1080fa) called from class is.hail.HailContext$ (loaded from file:/home/hammer/anaconda3/lib/python3.7/site-packages/hail/hail-all-spark.jar by sun.misc.Launcher$AppClassLoader@ac1080fa).; > 	at is.hail.HailContext$.majorMinor$1(HailContext.scala:71); > 	at is.hail.HailContext$.checkSparkCompatibility(HailContext.scala:73); > 	at is.hail.HailContext$.createSparkConf(HailContext.scala:84); > 	at is.hail.HailContext$.configureAndCreateSparkContext(HailContext.scala:134); > 	at is.hail.HailContext$.apply(HailContext.scala:270); > 	at is.hail.HailContext.apply(HailContext.scala); > 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); > 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); > 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); > 	at java.lang.reflect.Method.invoke(Method.java:498); > 	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); > 	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); > 	at py4j.Gateway.invoke(Gateway.java:282); > 	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); > 	at py4j.commands.CallCommand.execute(CallCommand.java:79); > 	at py4j.GatewayConnection.run(GatewayConnection.java:238); > 	at java.lang.Thread.run(Thread.java:819); >",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8009:934,config,configureAndCreateSparkContext,934,https://hail.is,https://github.com/hail-is/hail/issues/8009,1,['config'],['configureAndCreateSparkContext']
Modifiability,"I updated every call site to match the new parameters. This refactoring removes some code duplication, changes a stack trace in `hailctl auth user` to a nice print message, and adds a parameter (`client_session`) which I will use in my forthcoming TCP Proxy PR.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9715:60,refactor,refactoring,60,https://hail.is,https://github.com/hail-is/hail/pull/9715,1,['refactor'],['refactoring']
Modifiability,"I updated terraform but. 1. GCP Terraform state is still local on my laptop. 2. GCP Terraform appears to not configure global-config. As such, I cannot thread the name of the bucket through to the tests the way we do with TEST_STORAGE_URI. For now, I've hardcoded the name (which is what we were doing previously). When we eventually get to testing recreation of GCP in a new project we'll have to address the global config then.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12964:109,config,configure,109,https://hail.is,https://github.com/hail-is/hail/pull/12964,3,['config'],"['config', 'configure']"
Modifiability,"I want to make ordering a val instead of a def so it doesn't have to be recreated, but that means I need a way to pass missingGreatest as a parameter in compare. Hence, ExtendedOrdering. There are variants of compare, etc. that default missingGreatest = true since that is the default. All the overrides are necessary because lt, etc. can't always be determined from compare (e.g. nan compares false with everything for all comparison operations). This is used by a future PR for generic interval comparison.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2675:169,Extend,ExtendedOrdering,169,https://hail.is,https://github.com/hail-is/hail/pull/2675,1,['Extend'],['ExtendedOrdering']
Modifiability,"I wanted `WriteValue` to be able to essentially generate filenames exactly like we currently do in crdd.writePartitions, so I added a `HailTaskContext` concept to be able to mimic that behavior. It'll currently generate files named `prefix` if run on the master, and files named `prefix-stage-partition-…` if run in a distributed setting. We may eventually want to parameterize the behavior of `WriteValue` to have it do different things with the filename, but I think this will be enough to start moving over some of the writers.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8180:365,parameteriz,parameterize,365,https://hail.is,https://github.com/hail-is/hail/pull/8180,1,['parameteriz'],['parameterize']
Modifiability,I wanted to get feedback on the code I've written thus far before I start testing everything. I'm worried it might be too complicated / brittle to maintain. I also chose to blow away the entire existing environment rather than resetting the variables with new values. Not sure if that's what we want.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13279:241,variab,variables,241,https://hail.is,https://github.com/hail-is/hail/pull/13279,1,['variab'],['variables']
Modifiability,"I was assigned:; ```; size(dict<T, U>): int32; size(set<T>): int32; isEmpty(dict<T, U>): bool; isEmpty(set<T>): bool; isEmpty(array<T>): bool; head(set<T>): T; head(array<T>): T; tail(set<T>): set<T>; tail(array<T>): array<T>; sum(set<tnum>): tnum; product(set<tnum>): tnum; map(set<T>,(T) => U): set<U>; exists(set<T>,(T) => bool): bool; forall(set<T>,(T) => bool): bool; filter(set<T>,(T) => bool): set<T>; length(array<T>): int32; sort(array<T>,bool): array<T>; sort(array<T>): array<str>; append(array<T>,T): array<T>; extend(array<T>,array<T>): array<T>; ```; I didn't do `head` or `tail`, because they weren't being used. I'm not sure how/where to test the new functions.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3554:523,extend,extend,523,https://hail.is,https://github.com/hail-is/hail/pull/3554,1,['extend'],['extend']
Modifiability,"I was hoping that a greater restructure would lead to a more elegant solution, but after so many footguns it just felt worth making this change. The main point is shelling out in the Makefiles to ask Kubernetes directly for what the global config values are instead of hard-coding them. Specifically, the changes are:. - `KUBERNETES_SERVER_URL` was simply not used anymore in the Makefiles so I deleted it.; - `DOCKER_ROOT_IMAGE`, `INTERNAL_IP`, `IP` and `CLOUD` were only used in a couple Makefiles so I moved the `kubectl` invocation into where they're used so that Makefiles that don't depend on those variables won't incur the cost of querying them; - `DOCKER_PREFIX` and `DOMAIN` were used pretty widely, so I kept them in config.mk because most Makefiles will need to query those values anyway. The added startup time for `make deploy` feels pretty insignificant.; - With this change in place, there's no need to render config.mk anymore so I deleted the shell function for doing so",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11414:240,config,config,240,https://hail.is,https://github.com/hail-is/hail/pull/11414,4,"['config', 'variab']","['config', 'variables']"
Modifiability,I wasn't sure if we should print at least one Docker config or not. I'm worried about the test for out_of_memory where that prints out a bunch of the letter 'a' in the script.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9184:53,config,config,53,https://hail.is,https://github.com/hail-is/hail/pull/9184,1,['config'],['config']
Modifiability,"I'm attempting to build hail from a clone of this repository's master branch, as a local install on my laptop, under Debian GNU/Linux version 8. The gradle script successfully downloaded and installed the various Java dependencies, but gcc chokes on the C source code. I get:; $ ./gradlew shadowJar; :compileJava UP-TO-DATE; :nativeLib; (cd libsimdpp-2.0-rc2 && cmake .); -- Configuring done; -- Generating done; -- Build files have been written to: /home/rmk/package_sources/hail/hail/src/main/c/libsimdpp-2.0-rc2; mkdir -p lib/linux-x86-64; g++ -fvisibility=hidden -rdynamic -shared -fPIC -ggdb -O3 -march=native -g -std=c++11 -Ilibsimdpp-2.0-rc2 -Wall -Werror ibs.cpp -o lib/linux-x86-64/libibs.so; In file included from ibs.cpp:1:0:; /usr/lib/gcc/x86_64-linux-gnu/4.9/include/popcntintrin.h: In function ‘uint64_t vector_popcnt(uint64vector)’:; /usr/lib/gcc/x86_64-linux-gnu/4.9/include/popcntintrin.h:42:1: error: inlining failed in call to always_inline ‘long long int _mm_popcnt_u64(long long unsigned int)’: target specific option mismatch; _mm_popcnt_u64 (unsigned long long __X); ^; ibs.cpp:14:48: error: called from here; uint64_t count = _mm_popcnt_u64(extract<0>(x));; ^; In file included from ibs.cpp:1:0:; /usr/lib/gcc/x86_64-linux-gnu/4.9/include/popcntintrin.h:42:1: error: inlining failed in call to always_inline ‘long long int _mm_popcnt_u64(long long unsigned int)’: target specific option mismatch; _mm_popcnt_u64 (unsigned long long __X); ^; ibs.cpp:16:41: error: called from here; count += _mm_popcnt_u64(extract<1>(x));; ^; make: *** [lib/linux-x86-64/libibs.so] Error 1; Makefile:52: recipe for target 'lib/linux-x86-64/libibs.so' failed; :nativeLib FAILED. Tim Poterba suggested defining `CXXFLAGS='-DHAIL_OVERRIDE_ARCH -DSIMDPP_ARCH_X86_SSE2'`, but to no avail. So, he suggested I open this issue. I'm running gcc version 4.9.2. Possibly relevant might be the processor I'm running,; $ lscpu; Architecture: x86_64; CPU op-mode(s): 32-bit, 64-bit; Byte Order: Little Endian;",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1520:375,Config,Configuring,375,https://hail.is,https://github.com/hail-is/hail/issues/1520,1,['Config'],['Configuring']
Modifiability,"I'm getting this warning:. ```; /Users/jigold/hail/src/main/scala/is/hail/io/vcf/ExportVCF.scala:199: non-variable type argument String in type pattern scala.collection.immutable.Map[String,Any] (the underlying of Map[String,Any]) is unchecked since it is eliminated by erasure; case Some(x: Map[String, Any]) => getAttributes(path.tail, Some(x)); ```. If you have suggestions on how to improve the `getAttributes` function, I'd appreciate it!",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2496:106,variab,variable,106,https://hail.is,https://github.com/hail-is/hail/pull/2496,1,['variab'],['variable']
Modifiability,I'm not sure this change is thorough enough. Is there a way for a bucket to get partially mounted but have config['mounted'] still be False?,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12975:107,config,config,107,https://hail.is,https://github.com/hail-is/hail/pull/12975,1,['config'],['config']
Modifiability,I'm pretty sure this is why the session messages were gone when trying to configure the pools pages.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11094:74,config,configure,74,https://hail.is,https://github.com/hail-is/hail/pull/11094,1,['config'],['configure']
Modifiability,"I'm thinking something like `parseExprsAtTypes`:. ```scala; def parseExprsAtTypes[A](e: String, ec: EvalContext, hole: TypeHole[A]): Array[(BaseType, A, () => Option[Any])]; ```. ```scala; // function throws Exception if type is unacceptable; trait TypeHole[A] extends Iterable[Type => A] { }; sealed case class RepeatingTypeHole[A](f: Type => A) extends TypeHole[A] {; def iterator() = repeat(f).iterator; }; sealed case class ExactTypeHole(types: Type*) extends TypeHole[Unit] {; def iterator() =; types.iterator.map(x => y => if (x == y) () else fatal(s""$x should be of type $y""); }. def repeat[A](it: Iterable[A]) = Stream.continually(it.toStream).flatten; ```. Then the new LMMReg check for covariance types would be:; ```scala; val compiledExprs = parseExprsAtTypes(options.covSA, ec, RepeatingTypeHole(toDouble)); val covSA = vds.sampleIdsAndAnnotations.map { case (s, sa) =>; ec.setAll(s, sa); compiledExprs.map { case (typ, convert, query) =>; query().map(convert); }; }; ```. And AnnotationImpex would be something like:. ```scala; val fs = Parser.parseExprs(variantFields, ec, ExactTypeHole(TString, TInt, TString, TArray(TString))); ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1113:261,extend,extends,261,https://hail.is,https://github.com/hail-is/hail/issues/1113,3,['extend'],['extends']
Modifiability,I've already applied this change to the cluster since k8s-config.yaml isn't actually auto-deployed yet.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5518:58,config,config,58,https://hail.is,https://github.com/hail-is/hail/pull/5518,1,['config'],['config']
Modifiability,"I've changed BlockMatrix.from(lm: BDM[Double]) so that each executor is transmitted only the blocks it needs (~num_blocks/num_executors) rather than all of them: ""[TorrentBroadcast](https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-TorrentBroadcast.html) uses a BitTorrent-like protocol for block distribution (that only happens when tasks access broadcast variables on executors)."". In another branch, I've verified on GCP that distributing and then localizing a 10k x 10k matrix is twice as fast (about 15s vs 30s). Distributing and then writing a 25k by 25k matrix (5GB) with 10+2 standard 8-core workers takes about 30s with the new method but fails for every partition with the old method (months ago I believe I sometimes got the old method to work at this scale using high mem. It's needed for LMM). Note the matrix only has 49 partitions at the new default blockSize so I had more cores than needed for the experiment. I've also added a method to write a local matrix as a block matrix. I use ParRange to parallelize writing from master. Writing and then reading should be the safest way to distribute a big local matrix at the beginning of complex pipelines, and I think it avoids some of the memory overhead associated with broadcast.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2848:371,variab,variables,371,https://hail.is,https://github.com/hail-is/hail/pull/2848,1,['variab'],['variables']
Modifiability,"INFO	2022-03-02 19:06:30,199	hail_logging.py	log:40	https GET /pr-11438-default-g6cibyji6520/batch-driver/api/v1alpha/instances/credentials done in 0.005999999999858119s: 200; INFO	2022-03-02 19:06:30,226	main.py	activate_instance_1:237	activating instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q; INFO	2022-03-02 19:06:30,991	base.py	check:335	checking on instance batch-worker-pr-11438-default-g6cibyji6520-highcpu-z0idl, last updated 60.151s ago; INFO	2022-03-02 19:06:31,526	pool.py	schedule_loop_body:371	schedule pool standard: starting; INFO	2022-03-02 19:06:31,583	job.py	schedule_job:443	schedule job (94, 2) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:31,584	job.py	schedule_job:443	schedule job (95, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:31,585	job.py	schedule_job:443	schedule job (93, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:31,586	job.py	schedule_job:443	schedule job (90, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:31,586	job.py	schedule_job:443	schedule job (94, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:31,598	job.py	schedule_job:443	schedule job (97, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:31,656	job.py	schedule_job:443	schedule job (99, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:31,662	job.py	schedule_job:443	schedule job (100, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy2q: made job config; INFO	2022-03-02 19:06:31,663	job.py	schedule_job:443	schedule job (98, 1) on instance batch-worker-pr-11438-default-g6cibyji6520-standard-9xy",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11451:1442,config,config,1442,https://hail.is,https://github.com/hail-is/hail/pull/11451,1,['config'],['config']
Modifiability,"IO's <code>ExceptionGroup</code> class; causing <code>AttributeError: 'NonBaseMultiError' object has no attribute '_exceptions'</code>; (AnyIO 4 is unaffected)</li>; </ul>; <p><strong>3.6.1</strong></p>; <ul>; <li>Fixed exception handler in the asyncio test runner not properly handling a context; that does not contain the <code>exception</code> key</li>; </ul>; <p><strong>3.6.0</strong></p>; <ul>; <li>; <p>Fixed <code>TypeError</code> in <code>get_current_task()</code> on asyncio when using a custom <code>Task</code> factory</p>; </li>; <li>; <p>Updated type annotations on <code>run_process()</code> and <code>open_process()</code>:</p>; <ul>; <li><code>command</code> now accepts accepts bytes and sequences of bytes</li>; <li><code>stdin</code>, <code>stdout</code> and <code>stderr</code> now accept file-like objects; (PR by John T. Wodder II)</li>; </ul>; </li>; <li>; <p>Changed the pytest plugin to run both the setup and teardown phases of asynchronous; generator fixtures within a single task to enable use cases such as cancel scopes and; task groups where a context manager straddles the <code>yield</code></p>; </li>; </ul>; <p><strong>3.5.0</strong></p>; <ul>; <li>Added <code>start_new_session</code> keyword argument to <code>run_process()</code> and <code>open_process()</code>; (PR by Jordan Speicher)</li>; <li>Fixed deadlock in synchronization primitives on asyncio which can happen if a task acquiring a; primitive is hit with a native (not AnyIO) cancellation with just the right timing, leaving the; next acquiring task waiting forever (<code>[#398](https://github.com/agronholm/anyio/issues/398) &lt;https://github.com/agronholm/anyio/issues/398&gt;</code>_)</li>; <li>Added workaround for bpo-46313_ to enable compatibility with OpenSSL 3.0</li>; </ul>; <p>.. _bpo-46313: <a href=""https://bugs.python.org/issue46313"">https://bugs.python.org/issue46313</a></p>; <p><strong>3.4.0</strong></p>; <ul>; <li>; <p>Added context propagation to/from worker threads in <code>to_t",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12362:1386,plugin,plugin,1386,https://hail.is,https://github.com/hail-is/hail/pull/12362,1,['plugin'],['plugin']
Modifiability,Ideally:; - Add a flag to state whether to force rewrite or not,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/859:49,rewrite,rewrite,49,https://hail.is,https://github.com/hail-is/hail/issues/859,1,['rewrite'],['rewrite']
Modifiability,"If the gradle.properties file doesn't exist, our gradle script errors and asks the user to run ./configure. The ./configure script queries the user for sparkVersion and generates a valid gradle.properties file. Afterwards, the user can execute gradle normally without any -D parameters. Users may still override the sparkVersion variable on the command line by specifying -PsparkVersion=2.1.1.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1613:97,config,configure,97,https://hail.is,https://github.com/hail-is/hail/pull/1613,3,"['config', 'variab']","['configure', 'variable']"
Modifiability,"If these tests are being run, I can't find them. Also, rename incorrectly named gear => config in hailtop tests.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9396:88,config,config,88,https://hail.is,https://github.com/hail-is/hail/pull/9396,1,['config'],['config']
Modifiability,"If we're binding a variable and using it in an array expression, and then transforming that array expression, we should be able to deforest the entire thing.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5667:19,variab,variable,19,https://hail.is,https://github.com/hail-is/hail/pull/5667,1,['variab'],['variable']
Modifiability,"If you follow the call path of a `org.apache.hadoop.fs.LocalFileSystem.mkdirs`,; you'll find that it's actually implemented on; `org.apache.hadoop.fs.FilterFileSystem` which implements it in terms of some; internal `fs` variable, which in `LocalFileSystem`'s case is; `org.apache.hadoop.fs.RawLocalFileSystem`. This class has `mkOneDirWithMode`,; which delegates to `java.io.File`. Now we're at ground truth. This is a well; documented Java API. It returns true if the directory was created, false; otherwise. No `IOException`s. Going back up through the callstack, we find that; `IOException`s are thrown for a variety of unusual circumstances (like if; you're creating `/foo/bar/baz` and `/foo/bar` is a file that isn't a; directory), but, ultimately, if the directory *already exists* `mkdirs`; returns `false`, it does *not* throw an `IOException`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1359:220,variab,variable,220,https://hail.is,https://github.com/hail-is/hail/pull/1359,1,['variab'],['variable']
Modifiability,"If you look in the body of create_database, you will see that I copy the; keys from an existing sql-config using `get`. This propagates the `None`s; rather than leaving the keys missing. This fix changes `write_user_config`; to filter out keys set to None. Such keys should not appear in normal; configs because we never use `null` in our configs.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8498:100,config,config,100,https://hail.is,https://github.com/hail-is/hail/pull/8498,3,['config'],"['config', 'configs']"
Modifiability,"Implemented image untagging for image cleanup steps (like is done in GCR) for Azure. Since old layers still should be used for caching, this just removes the tag used for an image in a test build. We can then do something like [here](https://docs.microsoft.com/en-us/azure/container-registry/container-registry-auto-purge#run-in-an-on-demand-task) where you can purge untagged layers that are older than some number of weeks where we believe they're no longer relevant to the layer cache. I also switched out the `registry-push-credentials` that CI uses to build images from the ACR admin login to CI's service principal and eliminated the admin login from the ACR terraform resource. I dev deployed CI and manually verified after a deploy that a tag that was cleaned up no longer showed up in acr",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11100:95,layers,layers,95,https://hail.is,https://github.com/hail-is/hail/pull/11100,2,['layers'],['layers']
Modifiability,"Implemented the transmission disequilibrium test (TDT) in hail. TDT tests for variants that are inherited more or less than what would be expected by chance (i.e., 50%).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/753:96,inherit,inherited,96,https://hail.is,https://github.com/hail-is/hail/pull/753,1,['inherit'],['inherited']
Modifiability,Importing from `batch_configuration` means that for this cache to be used you must define all environment variables that batch depends on. I severed this connection and fixed a use of the k8s cache in bootstrap.py,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11162:106,variab,variables,106,https://hail.is,https://github.com/hail-is/hail/pull/11162,1,['variab'],['variables']
Modifiability,"In R, when you load a data table, it auto-detects whether each column is a character vs. numeric type. It would be super if this could be implemented in Hail. I'm guessing it would take the form of ""if none of the fields in the column contain special characters or letters, then it's numeric, else it's character,"" (but maybe it's not so straight forward, not so sure...). . Anyways, when you have over 30 annotations that are numeric, it's a bit of a pain to have to go through writing all the -t flag options in Hail, so if it could be auto-detected, that would be super! . In the case where 'dummy' variables are used (like 1-5 for Batch), then the user should be able to say that that's a string or a ""factor"" as it is in R (or a character/string, which is essentially the same), for the purposes of analysis in linear regression.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/463:602,variab,variables,602,https://hail.is,https://github.com/hail-is/hail/issues/463,1,['variab'],['variables']
Modifiability,"In a new environment,; ```; cd hail; make install; make pytest; ```; fails with; ```; ...; ERROR: usage: setup.py [options] [file_or_dir] [file_or_dir] [...]; setup.py: error: unrecognized arguments: --instafail --self-contained-html --html=../build/reports/pytest.html; inifile: None; rootdir: /path/to/hail/hail/python; ```. because the pytest plugins in hail/python/dev-requirements.txt are not installed. This documents the need to install them before running tests.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7942:346,plugin,plugins,346,https://hail.is,https://github.com/hail-is/hail/pull/7942,1,['plugin'],['plugins']
Modifiability,"In a world without gsa keys and hail auth tokens in secrets, the only other k8s secrets that we sometimes add to the job spec are the user ssl config which I believe to be unused (will address in a separate PR) and the `worker-deploy-config` secret. I don't really get why this is in a secret though, this is information already known to the worker and we can effortlessly add this to every job. Not only that, we can write the deploy-config once and mount it as read-only in all containers.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13056:143,config,config,143,https://hail.is,https://github.com/hail-is/hail/pull/13056,3,['config'],['config']
Modifiability,"In https://github.com/hail-is/hail/pull/9113, I forced the auth driver to use; the modern, TLS-required, SQL config format. I incorrectly forgot to specify the; TLS file paths. Luckily, when I tried to create a user account for Patrick; Cummings, instead of creating a broken secret, the auth driver; error'ed. Moreover, the clean up code was broken. As a result, Patrick's account; was stuck in `creating`. This PR fixes both the clean up code issue (I set `self.namespace` in; `K8sSecretResource`) and specifies the TLS file paths (see driver.py near; line 217). In addition, this PR attempts to avoid future problems with the sql; configuration by codifying the required components as a NamedTuple, `SQLConfig`. I also; co-located all the parsing and transformation logic between JSON, dicts, and CNF; in the `SQLConfig` class. I traced back all the users of `create_secret_data_from_config` to ensure they; all now use SQLConfig. I added lots of type annotations, but those won't do; anything right now because we don't have mypy enabled for hailtop.auth. ---. There's a separate issue of us not getting notified that Patrick's account was; not being created due to an error. The relevant logs are linked below. I'm glad; we're starting work on better monitoring. Hopefully error logs like these will; trigger emails to services team. https://console.cloud.google.com/logs/query;query=resource.type%3D%22k8s_container%22%0Aresource.labels.namespace_name%3D%22default%22%0Aresource.labels.container_name%3D%22auth-driver%22;timeRange=2020-08-11T15:44:00.000Z%2F2020-08-11T23:55:00.000Z?project=hail-vdc&query=%0A. Moreover, the infinite retry of his account created tens of google service; accounts that were not cleaned up. I do not yet understand why the google; service account clean up code failed. The clean up code bug that I *do* fix in; this PR addresses the GSA secret and the tokens secret.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9259:109,config,config,109,https://hail.is,https://github.com/hail-is/hail/pull/9259,2,['config'],"['config', 'configuration']"
Modifiability,"In order to rewrite `linear_regression_rows`, I'm going to need a way to get data out of ndarray type. Need something like https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.tolist.html . I'm going to break with the numpy matching though and call it `to_array`, since hail doesn't use lists.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7979:12,rewrite,rewrite,12,https://hail.is,https://github.com/hail-is/hail/issues/7979,1,['rewrite'],['rewrite']
Modifiability,"In the spirit of consolidation, this is just translating the current nginx config that is handling TLS for the batch driver to envoy. Doesn't have any special dependencies or deployment complications. Note that this time running Envoy as root is required to listening on the same port (443) that nginx currently listens on.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12383:75,config,config,75,https://hail.is,https://github.com/hail-is/hail/pull/12383,1,['config'],['config']
Modifiability,"In this PR, I rewrite `linear_regression_rows_nd` to use `_map_partitions` instead of `_group_within_partitions`. By doing this, I've eliminated the need to do a `key_by` at the end of `linear_regression_rows_nd`. I also think this makes the code clearer. . This PR also makes a few seemingly random changes that are actually bug fixes:. 1. When emitting `Apply` nodes, we were grabbing the `Code[Region]` from the first argument to the `MethodBuilder`. However, the assumption that the first argument will always be a `Region` seems to no longer be true. As such, we just construct a `CodeParam` from the `StagedRegion` we have available. . 2. In the NDArrayEmitter, I want to make sure I call the local `emit` method that passes off to `emitWithRegion`, for the same reason as 1: (Can't trust first argument to be a `Region`). 3. In `EmitStream`, I need to use `memoizeField` instead of `memoize`, because regular `memoize` saves to a `LocalRef`, and that will get reset to 0 when `next` is called on a stream. Lesson: don't trust locals for things that must live between elements of a stream. I feel like you have a better idea of how the Stream stuff gets emitted than I do Patrick. I'm curious if what I wrote in `process_block` could be written in a way that would lead to better code getting emitted, as I still need to figure out how to squeeze more performance out of this.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9469:14,rewrite,rewrite,14,https://hail.is,https://github.com/hail-is/hail/pull/9469,1,['rewrite'],['rewrite']
Modifiability,Incorporates grafana which we did not have at the time of previous revision and removes the nginx config that is no longer used. We now use Envoy as our load balancer. I'll make a separate dev doc explaining the gateways.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14400:98,config,config,98,https://hail.is,https://github.com/hail-is/hail/pull/14400,1,['config'],['config']
Modifiability,"Initializing Spark and Hail with default parameters...; using hail jar at /home/unix/dking/.conda/envs/hail/lib/python3.7/site-packages/hail/hail-all-spark.jar; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Running on Apache Spark version 2.2.3; SparkUI available at http://10.200.100.39:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.11-cf54f08305d1; LOGGING: writing to /home/unix/dking/hail-20190307-1908-0.2.11-cf54f08305d1.log; 2019-03-07 19:08:30 Hail: INFO: balding_nichols_model: generating genotypes for 3 populations, 100 samples, and 100 variants...; ^[[A; In [3]: t = hl.linear_regression_rows(x=mt.GT.n_alt_alleles(), y=mt.pop, covariates=[1]) ; [Stage 0:============================================> (6 + 1) / 8]2019-03-07 19:08:39 Hail: INFO: Coerced sorted dataset; 2019-03-07 19:08:40 Hail: INFO: linear_regression_rows: running on 100 samples for 1 response variable y,; with input variable x, and 1 additional covariate...; /broad/software/free/Linux/redhat_7_x86_64/pkgs/jdk1.8.0_181/bin/java: symbol lookup error: /tmp/jniloader1327638724610654731netlib-native_system-linux-x86_64.so: undefined symbol: cblas_dgemm; ERROR:root:Exception while sending command.; Traceback (most recent call last):; File ""/home/unix/dking/.conda/envs/hail/lib/python3.7/site-packages/py4j/java_gateway.py"", line 1159, in send_command; raise Py4JNetworkError(""Answer from Java side is empty""); py4j.protocol.Py4JNetworkError: Answer from Java side is empty. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/home/unix/dking/.conda/envs/hail/lib/python3.7/site-packages/py4j/java_gateway.py"", line 985, in send_command; response = connection.send_command(command); File ""/home/unix/dking/.conda/envs/hail/lib/python3.7/site-pa",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5559:1361,variab,variable,1361,https://hail.is,https://github.com/hail-is/hail/issues/5559,2,['variab'],['variable']
Modifiability,"Instead of using `gsutil` we use hailtop.aiotools.copy from the new `HAILGENETICS_HAIL_IMAGE`. Previously, deploying the pip-versioned image was a manual asynchronous step that mostly happened in response to user requests. 1. Actually build and test hailgenetics/hail and hailgenetics/genetics on every build.; 2. On deploy, push the newly built hailgenetics/hail and hailgenetics/genetics images to both docker hub and gcr.io/hail-vdc/; 3. Provide the built-for-this-PR hailgenetics/hail as an env var to the tests.; 4. By default use the hailgenetics/hail image for the currently published pip version for FS operations. Allow overriding by environment variable.; 5. Remove now unnecessary publish-public-images.sh.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11091:655,variab,variable,655,https://hail.is,https://github.com/hail-is/hail/pull/11091,1,['variab'],['variable']
Modifiability,"Intention is two-fold:. - get ready to move the k8s cluster from broad-ctsa to hail-vdc; - automate as much of our infrastructure build out as possible. Ultimately, changing GCP or k8s infrastructure should involve pushing to something like vdc/. We should regularly test rebuild from scratch. Outline of changes:. - added a new project directory, vdc/; - parameterize projects by GCP project for GCR, set from gcloud project config; - parameterize site by domain name and IP address; - GCP resources are deployed using the Google Deployment Manager; - added a MySQL 5.6 instance (to be used by upload, others); - ugprades gke to latest version. Doesn't handle CI yet. I think we need a setting for CI where it runs the tests and tracks its internal state but doesn't do anything on Github.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4545:356,parameteriz,parameterize,356,https://hail.is,https://github.com/hail-is/hail/pull/4545,3,"['config', 'parameteriz']","['config', 'parameterize']"
Modifiability,"Interface change:. ``` scala; abstract class Type[T] extends BaseType {; def coerce(a: Any): T; // ...; }; ```. Note the two major changes:; - Every `Type` now must correspond to a Scala type; - Every `Type` must know how to convert appropriate values to their associated Scala type. We may then naturally modify methods like `evalCompose`:. ``` scala; def evalCompose[T](ec: EvalContext, typ: Type[T])(subexpr: AST); (g: (T) => Any): () => Any = {; val f = subexpr.eval(ec); () => {; val x = f(); if (x != null); g(typ.coerce(x)); else; null; }; }; ```. which will hopefully induce or enable downstream simplifications.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/624:53,extend,extends,53,https://hail.is,https://github.com/hail-is/hail/issues/624,1,['extend'],['extends']
Modifiability,"Issue the [rewrite] request. To save on reading and writing entire; blobs, as well as transferring data to the machine running the copy; rather than letting google storage move the data. This operation should be effectively free when copying from one location; in a bucket to a different location in the same bucket, as the linked; docs say, when source and destination have the same location and storage; class, the blob is copied in a single request and returns immediately. [rewrite]: https://cloud.google.com/storage/docs/json_api/v1/objects/rewrite",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11922:11,rewrite,rewrite,11,https://hail.is,https://github.com/hail-is/hail/pull/11922,3,['rewrite'],['rewrite']
Modifiability,"Issues to address. - [ ] Type rewriter for CastRename: https://github.com/hail-is/hail/pull/6912/files/5257ca5eead8da3c470932e61944c715a5293913#r317669438. - [x] NA, Die: https://github.com/hail-is/hail/pull/6912#discussion_r317669761, https://github.com/hail-is/hail/pull/6912/files#r317671912. - [x] MakeArray: https://github.com/hail-is/hail/pull/6912#discussion_r317670311; - [x] Literal: walk values: https://github.com/hail-is/hail/pull/6990#discussion_r323810812 ; * Literal appears done, marking completed, but lets verify @tpoterba . - [x] MakeTuple: same as MakeArray; - [x] Coalesce: https://github.com/hail-is/hail/pull/6912#discussion_r317670382; - [x] If; - [ ] Upcast pass in Emit (and Interpret). cc @tpoterba",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6952:30,rewrite,rewriter,30,https://hail.is,https://github.com/hail-is/hail/issues/6952,1,['rewrite'],['rewriter']
Modifiability,"It is possible this addresses #12950 for two reasons:; 1. In 2.25.0, they rewrote the BlobWriteChannel entirely. [commit](https://github.com/googleapis/java-storage/commit/1b52a1053130620011515060787bada10c324c0b).; 2. Also in 2.25.0, after the rewrite, they fixed in issue with tracking offsets after incremental flushes. Maybe the issue existed in the old code too?. [commit](https://github.com/googleapis/java-storage/commit/c099a2f4f8ea9afa6953270876653916b021fd9f).; 3. In 2.22.4 they modified the BlobWriteChannel to use a different retry method. [commit](https://github.com/googleapis/java-storage/commit/1b52a1053130620011515060787bada10c324c0b). Anyway, all circumstantial.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13551:245,rewrite,rewrite,245,https://hail.is,https://github.com/hail-is/hail/pull/13551,1,['rewrite'],['rewrite']
Modifiability,"It is probably sufficient to verify it runs successfully and produces an expected output. https://github.com/hail-is/hail/pull/3872 makes the VEP invocation much more flexible, including running dockerized VEP (although there's still the question of installing the data files). We should probably make similar changes to Nirvana. The Nirvana [wiki](https://github.com/Illumina/Nirvana/wiki/Getting-Started) says it runs ""in Docker"" but I a quick Google didn't turn up any images.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4021:167,flexible,flexible,167,https://hail.is,https://github.com/hail-is/hail/issues/4021,1,['flexible'],['flexible']
Modifiability,"It looks like the configuration files for `xfs_quota` serve mostly to persist mappings from project name -> project id, and project id -> filesystem path. We keep that information in the worker anyway, and `xfs_quota` (way deep in its documentation) allows you to specify a path and project id in the project-creation command and then use a project id in the command that sets limits. This avoids locking on configuration files.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10467:18,config,configuration,18,https://hail.is,https://github.com/hail-is/hail/pull/10467,2,['config'],['configuration']
Modifiability,"It turns out that Kryo serialization is extra sneaky and will often just try to serialize the parts of a class if the class itself doesn't implement the KryoSerializable interface. I made a trait, `UnKryoSerializable`, that extends KryoSerializable but throws errors on read and write to try to weed out the rest of the places where UnsafeRows are being serialized. The biggest place this popped up was with colValues. For now, they're just being broadcast as safe Annotations everywhere. This depends on a change in #3258 and I'll rebase when that goes in.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3288:224,extend,extends,224,https://hail.is,https://github.com/hail-is/hail/pull/3288,1,['extend'],['extends']
Modifiability,"It was previously called config.yaml, when it was actually a python; configparser config file, which is a subset of [ini syntax]. [ini syntax]: https://docs.python.org/3/library/configparser.html. Check to see if the .yaml file exists and the .ini file does not exist.; If so, silently rename the config file to the new name.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9493:25,config,config,25,https://hail.is,https://github.com/hail-is/hail/pull/9493,5,['config'],"['config', 'configparser']"
Modifiability,"It's always bothered me that it's `hailctl config list` and `hailctl dev config show`. I deprecated `show` here and added `list`. I'm also open to not deprecating `show` and aliasing them, but mainly I just want the same subcommand to work in both contexts.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12019:43,config,config,43,https://hail.is,https://github.com/hail-is/hail/pull/12019,2,['config'],['config']
Modifiability,"JGSCM has inconsistent handling of buckets, folders. Because of this, combined with the fact that both folder and files are blobs in the Google Cloud storage world, that Jupyter's ContentsManager class strips slashes](https://jupyter-notebook.readthedocs.io/en/stable/extending/contents.html#api-paths), and that JGSCM behaves differently in the root folder depending on whether or not `default_path` is set (where without it, the root folder is effectively a listing of buckets, and ""folders"" created within are buckets rather than folder-blobs), means that some operations fail. Currently this appears to be seen only with file moving operations, but may occur under other circumstances. cc @cseed.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5820:268,extend,extending,268,https://hail.is,https://github.com/hail-is/hail/issues/5820,1,['extend'],['extending']
Modifiability,JZJZLis/hail/io/OutputBuffer;; 	at scala.Predef$.require(Predef.scala:281); 	at is.hail.asm4s.MethodBuilder.<init>(ClassBuilder.scala:531); 	at is.hail.asm4s.ClassBuilder.newMethod(ClassBuilder.scala:324); 	at is.hail.expr.ir.EmitClassBuilder.newEmitMethod(EmitClassBuilder.scala:584); 	at is.hail.expr.ir.EmitClassBuilder.genEmitMethod(EmitClassBuilder.scala:754); 	at is.hail.expr.ir.EmitClassBuilder.$anonfun$getOrGenEmitMethod$1(EmitClassBuilder.scala:747); 	at scala.collection.mutable.HashMap.getOrElseUpdate(HashMap.scala:86); 	at is.hail.expr.ir.EmitClassBuilder.getOrGenEmitMethod(EmitClassBuilder.scala:746); 	at is.hail.types.encoded.EType.buildEncoderMethod(EType.scala:57); 	at is.hail.types.encoded.EType.buildEncoder(EType.scala:49); 	at is.hail.expr.ir.PartitionNativeWriter$StreamConsumer.consumeElement(TableWriter.scala:294); 	at is.hail.expr.ir.PartitionNativeWriter.$anonfun$consumeStream$1(TableWriter.scala:334); 	at is.hail.expr.ir.PartitionNativeWriter.$anonfun$consumeStream$1$adapted(TableWriter.scala:332); 	at is.hail.expr.ir.streams.StreamProducer.$anonfun$memoryManagedConsume$1(EmitStream.scala:113); 	at is.hail.expr.ir.streams.StreamProducer.$anonfun$memoryManagedConsume$1$adapted(EmitStream.scala:112); 	at is.hail.expr.ir.streams.StreamProducer.unmanagedConsume(EmitStream.scala:100); 	at is.hail.expr.ir.streams.StreamProducer.memoryManagedConsume(EmitStream.scala:112); 	at is.hail.expr.ir.PartitionNativeWriter.consumeStream(TableWriter.scala:332); 	at is.hail.expr.ir.Emit.$anonfun$emit$21(Emit.scala:2629); 	at is.hail.expr.ir.IEmitCodeGen.flatMap(Emit.scala:351); 	at is.hail.expr.ir.Emit.$anonfun$emit$20(Emit.scala:2628); 	at is.hail.expr.ir.EmitCode$.fromI(Emit.scala:445); 	at is.hail.expr.ir.Emit.emit(Emit.scala:2627); 	at is.hail.expr.ir.Emit.emitFallback$1(Emit.scala:811); 	at is.hail.expr.ir.Emit.emitI(Emit.scala:2476); 	at is.hail.expr.ir.Emit.emitI(Emit.scala:786); 	at is.hail.expr.ir.Emit.$anonfun$emitI$241(Emit.scala:2386); 	at is.hail.expr.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12533:5608,adapt,adapted,5608,https://hail.is,https://github.com/hail-is/hail/issues/12533,1,['adapt'],['adapted']
Modifiability,"Jobs that are configured with `mount_tokens=True` will have their Hail tokens mounted into the main container. However, now that we are using access tokens from cloud identities, the tokens are no longer used. This removes the default behavior of mounting the `tokens.json` files since they aren't used by our codebase anyway.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14059:14,config,configured,14,https://hail.is,https://github.com/hail-is/hail/pull/14059,1,['config'],['configured']
Modifiability,Johnc LD Matrix Rewrite Without Matrix Multiplies,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1884:16,Rewrite,Rewrite,16,https://hail.is,https://github.com/hail-is/hail/pull/1884,1,['Rewrite'],['Rewrite']
Modifiability,"Just a refactor, simplifies the interactions between `Worker`, `CloudWorkerAPI` and `CloudUserCredentials` and hopefully makes this code safer and easier to work with. Instead of the following occuring in worker.py:. 1. get credentials string from `CloudUserCredentials`; 2. tell `CloudWorkerAPI` to write credentials string to `path` owned by the job; 3. tell `CloudWorkerAPI` to mount cloudfuse using the credentials stored at `path`. we instead just do. 1. tell `CloudWorkerAPI` to mount cloudfuse using `CloudUserCredentials`. On its own I think this change makes the codepath simpler and easier to think about in terms of where credentials are stored, but this also gets rid of the requirement from `worker.py`'s point of view that credentials must be stored on the filesystem. This will make it easier to transition off of key files and over to metadata server tokens. In order to make the new statement sound in terms of types, we can't have `CloudWorkerAPI.mount_cloudfuse` just accept a `CloudUserCredentials` argument, because that means `GCPWorkerAPI` would need to be able to support an argument of type `AzureUserCredentials`, which would never happen and doesn't make sense. What we can do here is make `CloudWorkerAPI` generic over the subtype of `CloudUserCredentials` that it both produces and consumes. This allows us to use stricter types like `GCPUserCredentials` and `AzureUserCredentials` inside of `GCPWorkerAPI` and `AzureWorkerAPI` respectively and now the type system is happy. It also relaxes the restriction that both of the `GCPUserCredentials` and `AzureUserCredentials` need to conform to the same `cloudfuse_credentials` interface.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12962:7,refactor,refactor,7,https://hail.is,https://github.com/hail-is/hail/pull/12962,1,['refactor'],['refactor']
Modifiability,"Just refactoring. VSM is now parameterized by a `MatrixT` that has the row, column and cell types.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1851:5,refactor,refactoring,5,https://hail.is,https://github.com/hail-is/hail/pull/1851,2,"['parameteriz', 'refactor']","['parameterized', 'refactoring']"
Modifiability,Just use plugin.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1728:9,plugin,plugin,9,https://hail.is,https://github.com/hail-is/hail/issues/1728,1,['plugin'],['plugin']
Modifiability,"Key changes:. - Remove old VCF combiner; - Add StreamZipJoinProducers an IR that takes an array, and a function from array.elementType to stream and zip joins the result of calling that function on each member of the array.; - Combine Table._generate and this new stream zip operation to rewrite the gvcf merge stage of the vds combiner in O(1) IR",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13206:288,rewrite,rewrite,288,https://hail.is,https://github.com/hail-is/hail/pull/13206,1,['rewrite'],['rewrite']
Modifiability,KeyboardInterrupt inherits from BaseException and not Exception so we couldn't kill waiting on batches etc. in the terminal. I decided to not catch BaseException and instead add the separate handler case because I wasn't sure we want to actually catch BaseException rather than Exception.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12495:18,inherit,inherits,18,https://hail.is,https://github.com/hail-is/hail/pull/12495,1,['inherit'],['inherits']
Modifiability,"Large collection of interface improvements to asm4s and Emit {Emit}{Module, Class, Method, Function}Builder. The main goal here is to make generating arbitrary classes a first class activity. Here is a summary of changes:; - newLocal now has parameters: newLocal(). This is a step towards requiring names on all generated objects.; - {Emit}{Class, Method, Function}Builder now takes a type parameter that represents (a supertype) of the class being built: e.g. MethodBuilder[C] is a builder for a method on a class of type C. Note, we can't have a type parameter that represents the actual class type because that doesn't exist yet.; - {Emit}FunctionBuilder all but gone: {Emit}FunctionBuilder is now just a {Emit}MethodBuilder is an apply method. Most functionality moved to {Emit}ClassBuilder.; - Added EmitClassBuilder.; - It is convenient to have e.g. MethodBuilder support the ClassBuilder interface: this is what the Wrapped traits are for: MethodBuilder extends WrappedClassBuilder and ClassBuilder extends WrappedModuleBuilder. So MethodBuilder has the ClassBuilder interface, but is not actually a ClassBuilder. I tried a bunch of variants for the design of this, and while I don't think this is quite perfect, it seems workable.; - EmitMethodBuilder extends WrappedMethodBuilder, etc. Rather than overloading, the two interfaces are distinct: genMethod vs genEmitMethod, etc.; - Pushed ""new vs gen"" into more places e.g. newMethod vs genMethod. newMethod takes a name and creates a method of that name (e.g. apply). genMethod takes a baseName and creates a unique name based on the baseName.; - MethodBuilder newField => genFieldThisRef to distinguish it from ClassBuilder.newField. The former returns a Settable[T] referencing `this.<field>`, the latter just returns a Field.; - All methods supporting code generation for IR take EmitMethodBuilder rather than MethodBuilder (PType routines, aggregators, etc.). Summarizing the new class structure:. ```; class ModuleBuilder; trait WrappedMo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8335:961,extend,extends,961,https://hail.is,https://github.com/hail-is/hail/pull/8335,2,['extend'],['extends']
Modifiability,"Let's build it from scratch, but better, faster, ... Philosophy: Minimal magic, minimal reliance on outside work, don't use it unless we understand it. Goal: <16ms interactions, including <16ms page transitions. Should feel identical to a desktop app in terms of performance, but maintain state like a website (i.e `get` variables). TODO:; - [ ] Profile/logout should be responsive: no user icon / dropdown until narrow view; - [x] Default to redirect rather than popup; - [x] Clicking on login should clear state if auth failed; - [ ] Write test for token verification on backend; - [ ] Add profile page; - [ ] Finish auth/redirect notebook logic in gateway; - [ ] Add notebook state endpoints in gateway; - [ ] Add notebook state view in frontend; - [ ] Break this up into ~10 commits, targeting <= 200 LOC each (with first commit being checking in package-lock.json); - [ ] Deal with cross-origin tracking issues in Safari. This may require using the ""custom domains"" feature of auth0, paid. Workaround could be to poll/websocket request to api server to refresh tokens. . To run:; ```sh; cd packages/web-client; docker build . -t blah; docker run --env-file=env-example -p 3000:3000 blah npm run start; ```; then navigate to `http://localhost:3000`. \# lines: Most come from the package.json.lock files. These maintain versioning information.; * [It is recommended to check in .lock files]( https://stackoverflow.com/questions/44206782/do-i-commit-the-package-lock-json-file-created-by-npm-5); * They're huge, sorry.; # Documentation; ### JS; https://javascript.info. We use the subset termed [ES2018](https://flaviocopes.com/es2018/). Compatibility across all browsers is ensured by [transpilation using BabelJS, to some lower JS target](https://babeljs.io/docs/en/). Polyfills should not be used, except when impossible to support a browser (this is configurable). I mostly don't care about anything that isn't an evergreen browser, so I think we should support: Edge, Safari, Chrome, Firefox. A",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5162:321,variab,variables,321,https://hail.is,https://github.com/hail-is/hail/pull/5162,1,['variab'],['variables']
Modifiability,"Lines 381-390 had a real bug: we re-used the ""b1"" and ""b2"" variables for the rest of wait which is a dictionary, not a true handle to the batch. I went ahead and fixed all the mypy / pylons issues I found in this file.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11203:59,variab,variables,59,https://hail.is,https://github.com/hail-is/hail/pull/11203,1,['variab'],['variables']
Modifiability,"Long awaited, this change prompts the batch driver to only schedule jobs on workers with the most recent instance version, i.e. matches the `INSTANCE_VERSION` global variable. This way we can make backwards incompatible changes between the worker and driver without having to manually kill the whole fleet. This will allow pre-existing workers to finish gracefully, as they will just stop receiving work when the new batch driver is deployed and eventually die off. ### Scheduler changes; Just skips instances where the instance version doesn't match `INSTANCE_VERSION`. ### Autoscaler changes; Cluster stats like free mcpu and live instances are tracked per instance version. The autoscaler now only looks at instances of the latest version when deciding whether it needs more workers. This way we don't get stuck unable to schedule new jobs until the old workers die off because there technically are enough cores available to meet demand but they are from old workers.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13055:166,variab,variable,166,https://hail.is,https://github.com/hail-is/hail/pull/13055,1,['variab'],['variable']
Modifiability,"Looks like the `get_remote_tmpdir` function was made when the Query ServiceBackend needed this config and didn't want to copy code directly from the batch ServiceBackend. Howevr, the batch ServiceBackend was never changed to use the new functions so got left behind. Aside from deleting a lot of duplicate code, the only change is that now the batch ServiceBackend will pick up the following environment variables `HAIL_BATCH_REMOTE_TMPDIR` and `HAIL_BATCH_BILLING_PROJECT`",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12799:95,config,config,95,https://hail.is,https://github.com/hail-is/hail/pull/12799,2,"['config', 'variab']","['config', 'variables']"
Modifiability,"Looks like this:; ```; (py37) dking@wmb16-359 # ./install-gcs-connector.sh . To set the active account, run:; $ gcloud config set account `ACCOUNT`. created key [bd10c2da666d327144166cc71ba13075dbd7ea26] of type [json] as [/Users/dking/.hail/gcs-keys/gcs-connector-key.json] for [842871226259-compute@developer.gserviceaccount.com]; mkdir: /Users/dking/anaconda2/envs/py37/lib/python3.7/site-packages/pyspark/conf: File exists; success; ```; I tested it by running `python -c 'import hail as hl; hl.read_table(""gs://danking/gnomad-test.mt"").describe()'`",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4500:119,config,config,119,https://hail.is,https://github.com/hail-is/hail/pull/4500,1,['config'],['config']
Modifiability,"Lost task 8.19 in stage 1.0 (TID 2899) (hail-test-w-1.australia-southeast1-a.c.pb-dev-312200.internal executor 3): is.hail.utils.HailException: VEP command '/vep --format vcf --json --everything --allele_number --no_stats --cache --offline --minimal --assembly GRCh38 --fasta /opt/vep/.vep/homo_sapiens/95_GRCh38/Homo_sapiens.GRCh38.dna.toplevel.fa.gz --plugin LoF,loftee_path:/opt/vep/Plugins/,gerp_bigwig:/opt/vep/.vep/gerp_conservation_scores.homo_sapiens.GRCh38.bw,human_ancestor_fa:/opt/vep/.vep/human_ancestor.fa.gz,conservation_file:/opt/vep/.vep/loftee.sql --dir_plugins /opt/vep/Plugins/ -o STDOUT' failed with non-zero exit status 2; VEP Error output:; Smartmatch is experimental at /opt/vep/Plugins/de_novo_donor.pl line 175.; Smartmatch is experimental at /opt/vep/Plugins/de_novo_donor.pl line 214.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 191.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 194.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 238.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 241.; DBI connect('dbname=/opt/vep/.vep/loftee.sql','',...) failed: unable to open database file at /opt/vep/Plugins/LoF.pm line 126. -------------------- EXCEPTION --------------------; MSG: ERROR: No cache found for homo_sapiens, version 95. STACK Bio::EnsEMBL::VEP::CacheDir::dir /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/CacheDir.pm:328; STACK Bio::EnsEMBL::VEP::CacheDir::init /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/CacheDir.pm:227; STACK Bio::EnsEMBL::VEP::CacheDir::new /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/CacheDir.pm:111; STACK Bio::EnsEMBL::VEP::AnnotationSourceAdaptor::get_all_from_cache /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/AnnotationSourceAdaptor.pm:115; STACK Bio::EnsEMBL::VEP::AnnotationSourceAdaptor::get_all /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/AnnotationSourceAdaptor.pm:91; STACK Bio::EnsEMBL::VEP::BaseRunn",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14513:4505,Plugin,Plugins,4505,https://hail.is,https://github.com/hail-is/hail/issues/14513,1,['Plugin'],['Plugins']
Modifiability,"Made the following changes:. - Disabled dataproc tests; - Moved dataproc tests to Makefile, to be run before manual deploys; - Add back VEP cluster test script; - Removed cloudtools config files; - Removed the latest-build functionality; - Added VEP scripts to hailctl/dataproc/resources; - Changed init_notebook to pip install hail wheels, picking up; dependencies automatically; - add out-of-date check (once per day) to hailctl startup",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6250:182,config,config,182,https://hail.is,https://github.com/hail-is/hail/pull/6250,1,['config'],['config']
Modifiability,Make TabixReader take a hadoop configuration in the constructor,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5033:31,config,configuration,31,https://hail.is,https://github.com/hail-is/hail/pull/5033,1,['config'],['configuration']
Modifiability,Make split_multi_hts more flexible,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3625:26,flexible,flexible,26,https://hail.is,https://github.com/hail-is/hail/pull/3625,1,['flexible'],['flexible']
Modifiability,"Makes some further progress on simplifying the `PruneDeadFields` pass, with the primary goal of decoupling it from the details of the binding structure. The primary change is to `memoizeValueIR`. Before, it passed in only the requested type of the node, and returned and environment containing all free variables and their requested types. Any bound variables would then need to be removed, and the environments of all children then merged. This low-level manipulation of environments made it closely tied to the binding structure, essentially redundantly encoding everything in `Binds.scala`. Now we pass an environment down into the children, which maps variables to a mutable state tracking the requested type. Each `Ref` node unions the requested type at the reference with the state in the environment. This lets us use the general environment infrastructure. I didn't do an assertion directly comparing the old and new implementations, as I've done with some other pass rewrites. But `PruneDeadFields` has pretty good test coverage.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14509:303,variab,variables,303,https://hail.is,https://github.com/hail-is/hail/pull/14509,4,"['rewrite', 'variab']","['rewrites', 'variables']"
Modifiability,Memory refactor,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14536:7,refactor,refactor,7,https://hail.is,https://github.com/hail-is/hail/pull/14536,1,['refactor'],['refactor']
Modifiability,Mendel error computation need to be adapted to multi-allelic sites,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/45:36,adapt,adapted,36,https://hail.is,https://github.com/hail-is/hail/issues/45,1,['adapt'],['adapted']
Modifiability,"Minor cleanups, remove unused/unnecessary variables, force/forceBgz have; no use, all files must be bgzip compressed and tabix indexed for; import_gvcfs.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11260:42,variab,variables,42,https://hail.is,https://github.com/hail-is/hail/pull/11260,1,['variab'],['variables']
Modifiability,Modify compiler arguments to emit warnings required for scalafix.; Fix failures that arise from the new build configuration.; Run scalafix.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14103:110,config,configuration,110,https://hail.is,https://github.com/hail-is/hail/pull/14103,1,['config'],['configuration']
Modifiability,"Modify hailctl dev config to let you set the domain. Note, this is an; interface change since I changed `hailctl dev config` to act like; gcloud/kubectl `... set property value`. The hardest part of this was getting a doubly-nested subcommand to work in argprase. The existing code is wack, but I will change everything to work like hailctl dev/dev config does below.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9791:19,config,config,19,https://hail.is,https://github.com/hail-is/hail/pull/9791,3,['config'],['config']
Modifiability,Modify the [scorecard.py](https://github.com/hail-is/hail/blob/master/scorecard/scorecard/scorecard.py#L40)'s `user` variable to include Daniel Goldstein's GitHub handle so that he shows up in the random user list.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5087:117,variab,variable,117,https://hail.is,https://github.com/hail-is/hail/issues/5087,1,['variab'],['variable']
Modifiability,More details at #8058. - Include the user's IP in the site logs.; - Fix out of date Makefile. I recognize there's duplication of log format. Abstracting over that doesn't seem *that* valuable and requires putting the shared configuration into a file in the root of hail and then arranging for the shared config file to be in the docker context. It's all kind of annoying and seems low value.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8059:224,config,configuration,224,https://hail.is,https://github.com/hail-is/hail/pull/8059,2,['config'],"['config', 'configuration']"
Modifiability,"Mostly I wanted ArrayEmitter to inherit from EmitTriplet since it is a type of EmitTriplet, just deforested when allowed. Also ArrayEmitter -> EmitStream, which I feel like is a better name for what it's actually doing.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5609:32,inherit,inherit,32,https://hail.is,https://github.com/hail-is/hail/pull/5609,1,['inherit'],['inherit']
Modifiability,"Mostly code reorg. Also:. moved rewriters to ir objects; call Optimize before intepreting; removed Filter{Rows, Cols} rules (non-IR), those should get folded back into the MT methods like other AST-based rules; re-enabled Fitler{Rows, Cols}IR fusion rules since logical and/or is back",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3330:32,rewrite,rewriters,32,https://hail.is,https://github.com/hail-is/hail/pull/3330,1,['rewrite'],['rewriters']
Modifiability,"Mostly infrastructure. Added NewAST base class for Matrix and KeyTable ASTs with a primitive term rewriting engine. This should eventually be a base for AST, too (because we'll want to rewrite value expressions, too). I broke VariantMetadata into two parts: VSMMetadata (static types/metdata for VSM) and VSMLocalValue (part of MatrixValue that is computed/stored on master and broadcast). Added MatrixRead, FilterSamples and FilterVariants matrix AST nodes. Simple optimizer that pushes filters into read and some minor optimizations of filters.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1778:185,rewrite,rewrite,185,https://hail.is,https://github.com/hail-is/hail/pull/1778,1,['rewrite'],['rewrite']
Modifiability,"Mostly random bugs that didn't get flexed until trying to run CI jobs and batch tests within jobs.; - The IP addresses used for jobs immediately got out of sync with GCP and I needed to add an `internal.hail` entry to the worker and job's `/etc/hosts` so that default batch could submit to dev batch.; - GCP's metadata server and DNS nameserver are both 169.254.169.254. Azure has a separate IP address for the latter, so I added this configuration to the CloudWorkerAPI. Something that's not addressed here is that I needed to comment out the resource requirements for build image jobs to make them run on standards. The common 2 vCPU / 10 Gi storage / 7.5 Gi Mem lands on standards in GCP but highcpu on azure, which doesn't have disks implemented yet. I'm not sure what the correct step forward on that front is. Otherwise, dev deploying batch should be possible! I ran into multiple issues where my user's sql config was messed up because it was created from a buggy branch. I tried to fix these for the other dev namespaces (dan's which was made later was fine) but there may be some bits I missed. I got as far as running `test_batch_0` and the tests start (!) but fail quickly because of a blob permission issue on the dev driver.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11071:435,config,configuration,435,https://hail.is,https://github.com/hail-is/hail/pull/11071,2,['config'],"['config', 'configuration']"
Modifiability,"Motivation for this change: I want to keep the global configuration information in one place, and that's going to be the K8s default/global-config secret. In particular, I want to get rid of config.mk and just pull the relevant information from K8s. The secret currently like this:. ```; $ k get -o json secret global-config | jq '.data | map_values(@base64d)'; {; ""default_namespace"": ""..."",; ""docker_root_image"": ""..."",; ""domain"": ""..."",; ""gcp_project"": ""..."",; ""gcp_region"": ""..."",; ""gcp_zone"": ""..."",; ""gsuite_organization"": ""..."",; ""internal_ip"": ""..."",; ""ip"": ""..."",; ""kubernetes_server_url"": ""...""; }; ```. default_namespace will always be the name of the namespace the secret is in. This adds gsuite_organization which will be used by auth to restrict logins to a fixed GSuite organization, e.g. broadinstitute.org. I have created this secret on our production K8s cluster. The Terraform script will also create it. With this change, CI creates global-config in test and dev ""default"" namespaces based on the one from where CI is operating. The only field that currently needs to be updated is default_namespace. The plan is to pull from global-config in deployments instead of threading these global configuration(s) through CI. I made this change in the CI tests. FYI @lgruen. I'm going to break up the infra-1 work into a few separate PRs to keep it all clear and manageable.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9777:54,config,configuration,54,https://hail.is,https://github.com/hail-is/hail/pull/9777,7,['config'],"['config', 'configuration']"
Modifiability,"NFO: Getting 1 non-empty blocks out of 1 blocks; 2018-10-09 15:04:37 ShuffleBlockFetcherIterator: INFO: Started 0 remote fetches in 0 ms; 2018-10-09 15:04:37 Executor: INFO: Finished task 0.0 in stage 4.0 (TID 4). 1539 bytes result sent to driver; 2018-10-09 15:04:37 TaskSetManager: INFO: Finished task 0.0 in stage 4.0 (TID 4) in 7 ms on localhost (executor driver) (1/1); 2018-10-09 15:04:37 TaskSchedulerImpl: INFO: Removed TaskSet 4.0, whose tasks have all completed, from pool ; 2018-10-09 15:04:37 DAGScheduler: INFO: ResultStage 4 (collect at utils.scala:197) finished in 0.008 s; 2018-10-09 15:04:37 DAGScheduler: INFO: Job 2 finished: collect at utils.scala:197, took 0.051042 s; 2018-10-09 15:04:37 CodeGenerator: INFO: Code generated in 5.011153 ms; 2018-10-09 15:04:37 SparkSession$Builder: WARN: Using an existing SparkSession; some configuration may not take effect.; 2018-10-09 15:04:37 SparkSqlParser: INFO: Parsing command: SELECT *; FROM `table8508c46074` AS `zzz1`; WHERE (0 = 1); 2018-10-09 15:04:37 SparkSession$Builder: WARN: Using an existing SparkSession; some configuration may not take effect.; 2018-10-09 15:04:37 SparkSqlParser: INFO: Parsing command: SELECT *; FROM `table8508c46074`; 2018-10-09 15:04:38 root: INFO: optimize: before:; (TableCount; (TableKeyBy () False; (TableLiteral))); 2018-10-09 15:04:38 root: INFO: optimize: after:; (TableCount; (TableLiteral)); 2018-10-09 15:04:38 SparkContext: INFO: Starting job: fold at RVD.scala:361; 2018-10-09 15:04:38 DAGScheduler: INFO: Got job 3 (fold at RVD.scala:361) with 1 output partitions; 2018-10-09 15:04:38 DAGScheduler: INFO: Final stage: ResultStage 5 (fold at RVD.scala:361); 2018-10-09 15:04:38 DAGScheduler: INFO: Parents of final stage: List(); 2018-10-09 15:04:38 DAGScheduler: INFO: Missing parents: List(); 2018-10-09 15:04:38 DAGScheduler: INFO: Submitting ResultStage 5 (MapPartitionsRDD[28] at mapPartitions at ContextRDD.scala:137), which has no missing parents; 2018-10-09 15:04:38 MemoryStore: INF",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4513:28667,config,configuration,28667,https://hail.is,https://github.com/hail-is/hail/issues/4513,1,['config'],['configuration']
Modifiability,NativeMethodAccessorImpl.invoke0(Native Method); E at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); E at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); E at java.lang.reflect.Method.invoke(Method.java:498); E at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244); E at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357); E at py4j.Gateway.invoke(Gateway.java:280); E at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132); E at py4j.commands.CallCommand.execute(CallCommand.java:79); E at py4j.GatewayConnection.run(GatewayConnection.java:214); E at java.lang.Thread.run(Thread.java:748)java.lang.ClassNotFoundException: Class org.apache.hadoop.mapred.DirectFileOutputCommitter not found; E at org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:2101); E at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2193); E at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2219); E at org.apache.hadoop.mapred.JobConf.getOutputCommitter(JobConf.java:726); E at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply$mcV$sp(PairRDDFunctions.scala:1051); E at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1035); E at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$4.apply(PairRDDFunctions.scala:1035); E at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151); E at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112); E at org.apache.spark.rdd.RDD.withScope(RDD.scala:362); E at org.apache.spark.rdd.PairRDDFunctions.saveAsHadoopFile(PairRDDFunctions.scala:1035); E at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$3.apply$mcV$sp(PairRDDFunctions.scala:1016); E at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopFile$3.apply(PairRDDFunctions.scala:1016); E at org.apache.s,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3946:11677,Config,Configuration,11677,https://hail.is,https://github.com/hail-is/hail/issues/3946,1,['Config'],['Configuration']
Modifiability,"New Hail Concepts. Every principal in our system has a secret: `ssl-config-NAME`. These secrets are; automatically created for a particular namespace by `tls/create_certs.py`. Who; trusts who (i.e. who is allowed to talk to whom) is defined by; `tls/config.yaml`. For example, `site` is defined in `config.yaml` as follows:. ```; - name: site; domain: site; kind: nginx; incoming:; - admin-pod; - router; ```. A principal named ""site"" exists. Site's domain names are `site`,; `site.NAMESPACE`, `site.NAMESPACE.svc.cluster.local`. Site's configuration files; should be in NGINX configuration file format. Site accepts incoming requests; from the principals named admin-pod and router. Site is not permitted to make; any outgoing requests. `create_certs.py` will create a new secret named; `ssl-config-site` which contains five files:. - `site-config-http.conf`: an NGINX configuration file that configures TLS for; incoming requests.; - `site-config-proxy.conf`: an NGINX configuration file that configures TLS for; outgoing (proxy_pass) requests.; - `site-key.pem`: a private key.; - `site-cert.pem`: a certificate.; - `site-incoming.pem`: a list of certificates trusted for incoming requests.; - `site-outgoing.pem`: a list of certificates expected from outgoing requests. If site makes an HTTP request to a server and that server does not return a; certificate in `site-outgoing.pem`, it will immediately halt the connection. I; intend (though do not currently) site to also reject incoming requests that are; not accompanied by a certificate in `site-incoming.pem`. I describe the [trouble; with that later](#incoming-trust). There are two other kinds: `json` and `curl`. The former is for Hail Python; services. The later is for the admin-pod and image-fetcher. Deploy will run `create_certs` on every master deploy. Newly deployed services; will be unable to talk to not-yet-deployed services. I include the; one-deploy-ago certificates in the trust chains, but once incoming trust is; fixed, I a",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8561:7218,config,configuration,7218,https://hail.is,https://github.com/hail-is/hail/pull/8561,2,['config'],"['configuration', 'configures']"
Modifiability,"New PR for NativeModule etc. - NativeModule now has a single big_mutex, so that it is single-threaded (releasing big_mutex; only while sleeping between polling file state). - The run_shell_get_first_line() has been removed, moving almost all configuration into the; module-build makefile; ; - Simplified Makefile. - Remove some historical code",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4211:242,config,configuration,242,https://hail.is,https://github.com/hail-is/hail/pull/4211,1,['config'],['configuration']
Modifiability,No worker deploy config secret,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13211:17,config,config,17,https://hail.is,https://github.com/hail-is/hail/pull/13211,1,['config'],['config']
Modifiability,"Note this PR replaces the previous [Feature/sas token merge](https://github.com/hail-is/hail/pull/12877) because the original PR branch got jacked up beyond repair. All the comments on the earlier PR are responded to there and addressed in the code for this one. This PR is to enable `hail-az/https` Azure file references to contain SAS tokens to enable bearer-auth style file access to Azure storage. Basic summary of the changes:; - Update `AzureAsyncFS` url parsing function to look for and separate out a SAS-token-like query string. Note: made fairly specific to SAS tokens - generic detection of query string syntax interferes with glob support and '?' characters in file names; - Added `generate_sas_token` convenience function to `AzureAsyncFS`. Adds new azure-mgmt-storage package requirement.; - Updated `AzureAsyncFS` to use `(account, container, credential)` tuple as internal `BlobServiceClient` cache key; - Updated `AzureAsyncFSURL` and `AzureFileListEntry` to track the token separately from the name, and extend the base classes to allow returning url with or without a token; - Update `RouterFS.ls` function and associated listfiles function to allow for trailing query strings during path traversal; - Update `AsyncFS.open_from` function to handle query-string urls in zero-length case; - Change to existing behavior: `LocalAsyncFSURL.__str__` no longer returns 'file:' prefix. Done to make `str()` output be appropriate for input to `fs` functions across all subclasses; - Updated `InputResource` to not include the SAS token as part of the destination file name; - Updated `inter_cloud/test_fs.py` to generically use query-string-friendly file path building functions to respect the new model, where it is no longer safe to extend URLs by just appending new segments with `+ ""/""` because there may be a query string, and added `'sas/azure-https'` test case to the fixture. Running tests for the SAS case requires some new test variables to allow the test code to generate SAS toke",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13140:1022,extend,extend,1022,https://hail.is,https://github.com/hail-is/hail/pull/13140,1,['extend'],['extend']
Modifiability,"Notebook2 was _literally_ unusable (no favicon). Instead of copying and pasting the favicon link 5 times, I also extracted out the shared elements into a template, and extended it in all other views. How this works:; `layout.html`: contains all shared elements, and marks places where children can insert content (`{% block title %}{% endblock %}`, `{% block head %}{% endblock %}`, `{% block content %}{% endblock %}`). Every other file extends this. The 2 templates that weren't updated (admin-login.html, and workers.html) are placeholders from notebook1 that haven't been updated for notebook 2 yet; they should work, but don't use notebook2 styles, and therefore don't have shared elements to wrap in layout.html. This all works. cc @cseed, @jigold, @danking, @konradjk",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5827:168,extend,extended,168,https://hail.is,https://github.com/hail-is/hail/pull/5827,2,['extend'],"['extended', 'extends']"
Modifiability,"Now get:; ```; E AttributeError: ArrayStructExpression instance has no field, method, or property 'select'; E Did you mean:; E ArrayStructExpression inherited method: 'collect'; ```. instead of. ```; AttributeError: ArrayStructExpression instance has no field, method, or property 'select'; Did you mean:; ArrayStructExpression method: 'select'; ArrayStructExpression inherited method: 'collect'. ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10608:149,inherit,inherited,149,https://hail.is,https://github.com/hail-is/hail/pull/10608,2,['inherit'],['inherited']
Modifiability,"Now image fetcher asks the running notebook image what worker image its using and pulls that. Also, add a five second sleep after the service's endpoints are configured. Hopefully that prevents these intermittent gateway errors.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4690:158,config,configured,158,https://hail.is,https://github.com/hail-is/hail/pull/4690,1,['config'],['configured']
Modifiability,"Now the `HAIL_SSL_CONFIG_DIR` environment variable can point to any absolute path. It must contain a `ssl-config.json` file that contains relative paths to `HAIL_SSL_CONFIG_DIR` for the rest of the ssl config files. Also allows `HAIL_TOKENS_FILE` in python, which was already implemented in Scala.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10275:42,variab,variable,42,https://hail.is,https://github.com/hail-is/hail/pull/10275,3,"['config', 'variab']","['config', 'variable']"
Modifiability,"Now we try, in order:; ```; $XDG_CONFIG_HOME/hail; ~/.config/hail; ~/.hail; ```. The [XDG Base Directory Specification] is a freedesktop spec inteded to; define where applications should look for files they need to run. [XDG Base Directory Specification]: https://specifications.freedesktop.org/basedir-spec/basedir-spec-latest.html. If ~/.hail already exists on your system, this should not break you as; long as $XDG_CONFIG_HOME/hail or ~/.config/hail also do not exist. I have enough 💩 in my home directory for applications I don't control,; I'd like to try to keep it clean when it comes to applications I do; control.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7125:54,config,config,54,https://hail.is,https://github.com/hail-is/hail/pull/7125,2,['config'],['config']
Modifiability,"Numpy both supports this and prominently uses it in documentation. We should support this for people translating Numpy code to Hail code. Note that I don't extend this feature to Hail TupleExpressions, because Hail tuple types are distinct from Hail array types (in that the latter has a single element_type, and the former has a collection of possible types). Python tuples are distinct from lists only in their immutability. Also, we support tuples in concatenate/NDArrayConcat, which makes the constructor difference from Numpy extra confusing. Example Numpy use: ; https://numpy.org/doc/stable/reference/generated/numpy.hstack.html?highlight=hstack#numpy.hstack; `a = np.array((1,2,3))` (this is the first example, which would fail if translated to hail); https://numpy.org/doc/stable/reference/generated/numpy.array.html#numpy.array; `x = np.array([(1,2),(3,4)])`",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9117:156,extend,extend,156,https://hail.is,https://github.com/hail-is/hail/pull/9117,1,['extend'],['extend']
Modifiability,"OK, I gave you maximum spicy. I don't think it's so bad, but let me know if you want me to cut it up. Some remarks:; - This PR successfully tests (and it passes!) and then cleans up this branch: https://github.com/hail-is/hail/pull/5842. See `build.yaml`. It's a thing of beauty (I think).; - That branch has everything but Scala tests and dataproc/cloudtools tests. The latter are easy, the former are a little messy since I want to test against a test jar, and I've decided to switch to maven for that.; - No support for publish or deploy yet.; - There are synchronous calls it `git` in various places which can make the UI sluggish. I'll fix those in another PR.; - Work remains to validate build.yaml and the deploy step yaml.; - I currently run jinja2 if the file (Dockerfile or deployment yaml) ends in `.in`, but I think I'm going to make it unconditional. `.in` just seem error prone.; - In CreateDatabaseStep, I put secret credentials in the pod configuration. That's not ideal, but I don't think it is a serious problem, because nobody who isn't privileged can read the pods, and I can fix it in a later PR (the create database step should generate the passwords, not ci2).; - I disabled the fixme pylint message (on # FIXME comments), since are fixmes are longer lived than a single change sometimes.; - I'm slightly confused about runImage (which generates a batch job) and deploy of a pod spec (which runs kubectl apply as a batch job). Right now, runImage always runs in batch-pods, and a deploy job runs in whatever namespace you specify. Fixes https://github.com/hail-is/hail/issues/5903",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5891:955,config,configuration,955,https://hail.is,https://github.com/hail-is/hail/pull/5891,1,['config'],['configuration']
Modifiability,"OK, this should fix routing from internal.hail.is. The gateway routes internal.hail.is/ns/svc to router.ns with Host: svc.internal so the ns router can dispatch to the right server block off the Host. We could dispatch off the URL, but that would mean the default and private namespaces dispatch different, doubling the complexity of the router NGINX configuration. Change the host back for grafana and prometheus which generate a redirect otherwise. The monitoring and gateway changes are deployed and everything seems to be working.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6928:351,config,configuration,351,https://hail.is,https://github.com/hail-is/hail/pull/6928,1,['config'],['configuration']
Modifiability,"On Ubuntu 20.10, with Python 3.8.6 and hail 0.2.64 installed from pip, I get: ​I get `TypeError: an integer is required (got type bytes)` immediately upon importing hail. A full transcript is below. (pyve is an alias to create a python virtual env and activate it). ---. ```; snafu$ pyve; + python3.8 -m venv venv/3.8; + source venv/3.8/bin/activate; + pip install -U setuptools pip; Collecting setuptools; Using cached setuptools-54.1.2-py3-none-any.whl (785 kB); Collecting pip; Using cached pip-21.0.1-py3-none-any.whl (1.5 MB); Installing collected packages: setuptools, pip; Attempting uninstall: setuptools; Found existing installation: setuptools 44.0.0; Uninstalling setuptools-44.0.0:; Successfully uninstalled setuptools-44.0.0; Attempting uninstall: pip; Found existing installation: pip 20.1.1; Uninstalling pip-20.1.1:; Successfully uninstalled pip-20.1.1; Successfully installed pip-21.0.1 setuptools-54.1.2; (3.8) ✔ ~/sandbox/hail [master|𝚫8?2]; snafu$ pip install hail ipython; Collecting hail; Using cached hail-0.2.64-py3-none-any.whl (97.5 MB); Collecting ipython; Using cached ipython-7.21.0-py3-none-any.whl (784 kB); Collecting pandas<1.1.5,>=1.1.0; Using cached pandas-1.1.4-cp38-cp38-manylinux1_x86_64.whl (9.3 MB); Collecting python-json-logger==0.1.11; Using cached python_json_logger-0.1.11-py2.py3-none-any.whl; Collecting gcsfs==0.7.2; Using cached gcsfs-0.7.2-py2.py3-none-any.whl (22 kB); Collecting requests==2.22.0; Using cached requests-2.22.0-py2.py3-none-any.whl (57 kB); Collecting tabulate==0.8.3; Using cached tabulate-0.8.3-py3-none-any.whl; Collecting nest-asyncio; Using cached nest_asyncio-1.5.1-py3-none-any.whl (5.0 kB); Collecting parsimonious<0.9; Using cached parsimonious-0.8.1-py3-none-any.whl; Collecting pyspark<2.4.2,>=2.4; Using cached pyspark-2.4.1-py2.py3-none-any.whl; Collecting tqdm==4.42.1; Using cached tqdm-4.42.1-py2.py3-none-any.whl (59 kB); Collecting bokeh<2.0,>1.3; Using cached bokeh-1.4.0-py3-none-any.whl; Collecting Deprecated<1.3",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/10197:933,sandbox,sandbox,933,https://hail.is,https://github.com/hail-is/hail/issues/10197,1,['sandbox'],['sandbox']
Modifiability,"Once the current auth overhaul is through and we go ""keyless"", the only secret left that we mount into user jobs is the deploy config, which at that point feels kind of silly. It's also nearly always the same deploy config value that we serialize and write to a file for every job. It seems cleaner and simpler to me that we create one deploy config for the worker, and the worker readonly mounts that config into every job. Note that this is overridable so that any pre-existing jobs that specify a deploy-config secret and all the special deploy-config stuff that we do in build.yaml should not be affected",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13203:127,config,config,127,https://hail.is,https://github.com/hail-is/hail/pull/13203,6,['config'],['config']
Modifiability,Only create serializable and broadcasted HadoopConf once in HailContext and use everywhere else. I was seeing pipelines with MANY duplicate broadcasts the Hadoop configuration.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5422:162,config,configuration,162,https://hail.is,https://github.com/hail-is/hail/pull/5422,1,['config'],['configuration']
Modifiability,"Options</code> mimic the following:; <pre><code> StorageOptions.grpc(); .setAttemptDirectPath(true); .build(); </code></pre>; </li>; <li>Internally the default host endpoint <code>https://storage.googleapis.com:443</code> will be transformed to the applicable <code>google-c2p-experimental:///storage.googleapis.com</code></li>; </ol>; </li>; <li>; <p>Support for <code>java.time</code> types on model classes</p>; <ol>; <li>Points in time are now represented with <code>java.time.OffsetDateTime</code>, while durations are represented with <code>java.time.Duration</code></li>; <li>All existing <code>Long</code> centric methods are still present, but have been deprecated in favor of their corresponding <code>java.time</code> variant</li>; <li>At the next major version, these deprecated methods will be replaced with types from <code>java.time</code> and the <code>java.time</code> variant methods will be deprecated</li>; </ol>; </li>; <li>; <p><code>com.google.cloud.storage.Storage</code> now extends <code>java.lang.AutoClosable</code> thereby allowing it to be used in a try-with-resource block.</p>; </li>; </ol>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/googleapis/java-storage/blob/main/CHANGELOG.md"">google-cloud-storage's changelog</a>.</em></p>; <blockquote>; <h2><a href=""https://github.com/googleapis/java-storage/compare/v2.14.0...v2.15.0"">2.15.0</a> (2022-11-07)</h2>; <h3>Features</h3>; <ul>; <li>Add Autoclass support and sample (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1697"">#1697</a>) (<a href=""https://github.com/googleapis/java-storage/commit/82aacd7922573d6f4779f21cdc83de10616d7a08"">82aacd7</a>)</li>; <li>Update retries for Notifications (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1734"">#1734</a>) (<a href=""https://github.com/googleapis/java-storage/commit/0fb2f1823f9e",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12456:5415,extend,extends,5415,https://hail.is,https://github.com/hail-is/hail/pull/12456,1,['extend'],['extends']
Modifiability,"Options</code> mimic the following:; <pre><code> StorageOptions.grpc(); .setAttemptDirectPath(true); .build(); </code></pre>; </li>; <li>Internally the default host endpoint <code>https://storage.googleapis.com:443</code> will be transformed to the applicable <code>google-c2p-experimental:///storage.googleapis.com</code></li>; </ol>; </li>; <li>; <p>Support for <code>java.time</code> types on model classes</p>; <ol>; <li>Points in time are now represented with <code>java.time.OffsetDateTime</code>, while durations are represented with <code>java.time.Duration</code></li>; <li>All existing <code>Long</code> centric methods are still present, but have been deprecated in favor of their corresponding <code>java.time</code> variant</li>; <li>At the next major version, these deprecated methods will be replaced with types from <code>java.time</code> and the <code>java.time</code> variant methods will be deprecated</li>; </ol>; </li>; <li>; <p><code>com.google.cloud.storage.Storage</code> now extends <code>java.lang.AutoClosable</code> thereby allowing it to be used in a try-with-resource block.</p>; <ol>; <li>When using gRPC transport be sure to call <code>Storage#close()</code> when complete so it can clean up the gRPC middleware and resources.</li>; <li>When using HTTP transport calling <code>Storage#close()</code> will gracefully no-op, allowing for the same style of use regardless of transport.</li>; </ol>; </li>; </ol>; <!-- raw HTML omitted -->; </blockquote>; <p>... (truncated)</p>; </details>; <details>; <summary>Commits</summary>; <ul>; <li><a href=""https://github.com/googleapis/java-storage/commit/48bb8ae1cd1362f44a94132c4903fb185b767728""><code>48bb8ae</code></a> chore(main): release 2.15.0 (<a href=""https://github-redirect.dependabot.com/googleapis/java-storage/issues/1746"">#1746</a>)</li>; <li><a href=""https://github.com/googleapis/java-storage/commit/67db4c4de60e49825c843afebd08ef0ac47e2b0d""><code>67db4c4</code></a> chore(java): update dependencies in java req",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12456:10909,extend,extends,10909,https://hail.is,https://github.com/hail-is/hail/pull/12456,1,['extend'],['extends']
Modifiability,OrderBy => KeyBy rewrite,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4367:17,rewrite,rewrite,17,https://hail.is,https://github.com/hail-is/hail/pull/4367,1,['rewrite'],['rewrite']
Modifiability,Other changes:. - stop supporting python 2; - remove support for 0.1; - formatting. Coming soon to a PR near you:. - use google client library instead of `gsutil cat` (huge speedup); - upload configuration in deploy; include paths in hailctl package,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6136:192,config,configuration,192,https://hail.is,https://github.com/hail-is/hail/pull/6136,1,['config'],['configuration']
Modifiability,"Our CI service should really be logging a JSON format the way batch does. Easy to change, need to use configure logging in Gear.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6701:102,config,configure,102,https://hail.is,https://github.com/hail-is/hail/issues/6701,1,['config'],['configure']
Modifiability,"Our current HTML display of tables flattens the table and concatenates the field; names to produce table headers. This leads to long, unreadable headers. This change reproduces the nesting structure of the types with several table; header layers. The essential activity is to convert:. ```; bing; foo:; bar:; baz; quux; fizzle:; fazz:; fazz1; fazz2; fezz; quork; bang; ```. into. ```; foo; -------------------------------; fizzle; ----------------; bar fazz; -------- -----------; bing baz quux fazz1 fazz2 fezz quork bang; ```. The bottom layer are the names of the leaves of this tree. Working from the; bottom, a name appears when the row corresponds to that name's tree height. For; this reason `bar` appears lower than `fizzle`. This frustrates finding peer; fields. However, I prefer it. I think I have some sense of visual gravity that; wants bar to fall down. Anyway, I implement this with some html grunginess in `Table._Show` and a new; class named `PlacementTree`. We construct a `PlacementTree` from a type. It is a; tree whose internal and leaf nodes contain a name, width, and height. It has a; method `to_grid` which converts it to an HTML-table-like structure with ""spacer""; elements. Our above example looks like:. ```python3; [[(None, 1), ('foo', 6), (None, 1)],; [(None, 1), (None, 2), ('fizzle', 3), (None, 1), (None, 1)],; [(None, 1), ('bar', 2), ('fazz', 2), (None, 1) (None, 1), (None, 1)],; [('bing', 1), ('baz', 1), ('quux', 1), ('fazz1', 1), ('fazz2', 1), ('fezz', 1) ('quork', 1), ('bang', 1)]]; ```. The code in `Table._Show` converts this to HTML table rows that looks like:; ```html; <tr><td></td><td colspan=""6"">foo</td><td></td></tr>; <tr><td></td><td colspan=""2""></td><td colspan=3>fizzle</td><td></td><td></td></tr>; <tr><td></td><td colspan=""2"">bar</td><td colspan=2>fazz</td><td></td><td></td><td></td></tr>; <tr><td>bing</td><td>baz</td><td>quux</td><td>fazz1</td><td>fazz2</td><td>fezz</td><td>quork</td><td>bang</td></tr>; ```. Which looks like:. <table>; <tr><t",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8811:239,layers,layers,239,https://hail.is,https://github.com/hail-is/hail/pull/8811,1,['layers'],['layers']
Modifiability,"Our team is currently trying to run kinship analysis with [king()](https://hail.is/docs/0.2/methods/relatedness.html#hail.methods.king) on just under 110k samples. We have run this successfully in the past on 10k samples using a google cloud cluster with the following configuration. ```; hailctl dataproc start cluster --vep GRCh38 \; 	--requester-pays-allow-annotation-db \; 	--packages gnomad --requester-pays-allow-buckets gnomad-public-requester-pays \; 	--master-machine-type=n1-highmem-8 --worker-machine-type=n1-highmem-8 \; 	--num-workers=300	--num-secondary-workers=0 \; 	--worker-boot-disk-size=1000 \; 	--properties=dataproc:dataproc.logging.stackdriver.enable=true,dataproc:dataproc.monitoring.stackdriver.enable=true; ```; We are currently receiving a spark error when using this cluster for our larger dataset. ```; [Stage 10:=====> (69 + 656) / 729]; raise err; File ""/opt/conda/default/lib/python3.8/site-packages/hail/backend/py4j_backend.py"", line 98, in execute; result_tuple = self._jbackend.executeEncode(jir, stream_codec, timed); File ""/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py"", line 1304, in __call__; File ""/opt/conda/default/lib/python3.8/site-packages/hail/backend/py4j_backend.py"", line 31, in deco; raise fatal_error_from_java_error_triplet(deepest, full, error_id) from None; hail.utils.java.FatalError: SparkException: Job aborted due to stage failure: Task 582 in stage 10.0 failed 20 times, most recent failure: Lost task 582.19 in stage 10.0 (TID 461381) (cluster-w-144.c.project-.internal executor 3568): ExecutorLostFailure (executor 3568 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 128936 ms; Driver stacktrace:. Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 582 in stage 10.0 failed 20 times, most recent failure: Lost task 582.19 in stage 10.0 (TID 461381) (cluster-w-144.c.gbsc-project.internal executor 3568): ExecutorLostFailure (executor 3568 e",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/12290:269,config,configuration,269,https://hail.is,https://github.com/hail-is/hail/issues/12290,1,['config'],['configuration']
Modifiability,Overwrite ssl-config-hail-root secret for dev,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10188:14,config,config-hail-root,14,https://hail.is,https://github.com/hail-is/hail/pull/10188,1,['config'],['config-hail-root']
Modifiability,"P data is not copied into the dataproc cluster, and when trying to run VEP I get the error `No cache found for homo_sapiens, version 95`. ### Version. 0.2.130. ### Relevant log output. ```shell; FatalError: HailException: VEP command '/vep --format vcf --json --everything --allele_number --no_stats --cache --offline --minimal --assembly GRCh38 --fasta /opt/vep/.vep/homo_sapiens/95_GRCh38/Homo_sapiens.GRCh38.dna.toplevel.fa.gz --plugin LoF,loftee_path:/opt/vep/Plugins/,gerp_bigwig:/opt/vep/.vep/gerp_conservation_scores.homo_sapiens.GRCh38.bw,human_ancestor_fa:/opt/vep/.vep/human_ancestor.fa.gz,conservation_file:/opt/vep/.vep/loftee.sql --dir_plugins /opt/vep/Plugins/ -o STDOUT' failed with non-zero exit status 2; VEP Error output:; Smartmatch is experimental at /opt/vep/Plugins/de_novo_donor.pl line 175.; Smartmatch is experimental at /opt/vep/Plugins/de_novo_donor.pl line 214.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 191.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 194.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 238.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 241.; DBI connect('dbname=/opt/vep/.vep/loftee.sql','',...) failed: unable to open database file at /opt/vep/Plugins/LoF.pm line 126. -------------------- EXCEPTION --------------------; MSG: ERROR: No cache found for homo_sapiens, version 95. STACK Bio::EnsEMBL::VEP::CacheDir::dir /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/CacheDir.pm:328; STACK Bio::EnsEMBL::VEP::CacheDir::init /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/CacheDir.pm:227; STACK Bio::EnsEMBL::VEP::CacheDir::new /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/CacheDir.pm:111; STACK Bio::EnsEMBL::VEP::AnnotationSourceAdaptor::get_all_from_cache /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/AnnotationSourceAdaptor.pm:115; STACK Bio::EnsEMBL::VEP::AnnotationSourceAdaptor::get_all /opt/vep/src/ensembl-vep/modules/Bi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14513:1809,Plugin,Plugins,1809,https://hail.is,https://github.com/hail-is/hail/issues/14513,1,['Plugin'],['Plugins']
Modifiability,"PBaseStruct becomes an interface with only implementations that are re-parameterizations of its abstract methods. PStruct and PTuple inherit. PCanonicalStruct gets the PBaseStruct implementations, and PCanonicalTuple implements its concrete methods by calling PCanonicalStruct's.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7928:71,parameteriz,parameterizations,71,https://hail.is,https://github.com/hail-is/hail/issues/7928,2,"['inherit', 'parameteriz']","['inherit', 'parameterizations']"
Modifiability,PR.config has a different signature from the base class Code.config,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6142:3,config,config,3,https://hail.is,https://github.com/hail-is/hail/issues/6142,2,['config'],['config']
Modifiability,Pandas only releases [breaking changes in major versions](https://pandas.pydata.org/docs/development/policies.html). It seems safe; to be flexible on patch version. Just today I had an issue where I ran `pip install pandas` to; upgrade from an old pandas version and I landed on 1.1.5.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9819:138,flexible,flexible,138,https://hail.is,https://github.com/hail-is/hail/pull/9819,1,['flexible'],['flexible']
Modifiability,Parameterise docker registry in the kaniko config,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10444:43,config,config,43,https://hail.is,https://github.com/hail-is/hail/pull/10444,1,['config'],['config']
Modifiability,Parameterize spark version in gradle install commands,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/399:0,Parameteriz,Parameterize,0,https://hail.is,https://github.com/hail-is/hail/issues/399,1,['Parameteriz'],['Parameterize']
Modifiability,Parameterized the key type of TDict,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1323:0,Parameteriz,Parameterized,0,https://hail.is,https://github.com/hail-is/hail/pull/1323,1,['Parameteriz'],['Parameterized']
Modifiability,Part 1 of chipping away at config.mk. This puts the two make targets for building the vm image in GCP into a single script. It loads variables that used to come from config.mk from kubernetes. Added a convenience function to offer a confirmation prompt before running the script. Here's an example:. ```; (hailenv) dgoldste@wmce3-cb7 hail % $HAIL/batch/gcp-create-worker-image.sh; Building image with properties:; Version: 12; Project: hail-vdc; Zone: us-central1-a; Are you sure? [y/N] n; (hailenv) dgoldste@wmce3-cb7 hail %; ```. Tested by running with a high image version number (3010 to be precise),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11327:27,config,config,27,https://hail.is,https://github.com/hail-is/hail/pull/11327,3,"['config', 'variab']","['config', 'variables']"
Modifiability,"Part of a refactoring effort. I need to break the model that a `TNDArray` is represented by an underlying `TStruct` and `TArray`. This adds an `UnsafeNDArray` Java representation, rather than the old model which was just to use`UnsafeRow` like it was a struct. . cc @tpoterba",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9854:10,refactor,refactoring,10,https://hail.is,https://github.com/hail-is/hail/pull/9854,1,['refactor'],['refactoring']
Modifiability,Pass Spark config options through HailContext(),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1336:11,config,config,11,https://hail.is,https://github.com/hail-is/hail/issues/1336,1,['config'],['config']
Modifiability,Point vep check to new config and reference files,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5315:23,config,config,23,https://hail.is,https://github.com/hail-is/hail/pull/5315,1,['config'],['config']
Modifiability,"Pretty sure this is all dead code because we don't currently speak TLS between the worker and internal gateway. I think what's ultimately the right approach here is to start sending the hail root cert to workers and have them mount that at a well known location to all containers, not have it be part of the job spec. Then we should be able to talk https to internal gateway. I'm not exactly sure what to do in this PR specifically. I want to get rid of this hard dependency on the ssl-config because; 1. Doesn't exist in terra as everything goes through the relay listener; 2. These ssl configs aren't used anyway; but I'd need to put in a bit more work to start sending the root cert to workers and add https to internal-gateway",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13187:486,config,config,486,https://hail.is,https://github.com/hail-is/hail/pull/13187,2,['config'],"['config', 'configs']"
Modifiability,"Prevents us from being able to concatenate a bunch of NDArrays using a map over an expression. Note that np.array(hl.eval(a)) would work. ```python; >>> a = hl.literal([hl.nd.array((1,2,3)), hl.nd.array((4,5,6))]) ; >>> hl.eval(a); [array([1, 2, 3], dtype=int32), array([4, 5, 6], dtype=int32)]. >>> hl.eval(hl.nd.array(a)); Java stack trace:; java.lang.NullPointerException: null; 	at is.hail.expr.ir.Interpret$.run(Interpret.scala:305); 	at is.hail.expr.ir.Interpret$.alreadyLowered(Interpret.scala:53); 	at is.hail.expr.ir.FoldConstants$$anonfun$is$hail$expr$ir$FoldConstants$$foldConstants$1.apply(FoldConstants.scala:45); 	at is.hail.expr.ir.FoldConstants$$anonfun$is$hail$expr$ir$FoldConstants$$foldConstants$1.apply(FoldConstants.scala:13); 	at is.hail.expr.ir.RewriteBottomUp$.is$hail$expr$ir$RewriteBottomUp$$rewrite$1(RewriteBottomUp.scala:15); 	at is.hail.expr.ir.RewriteBottomUp$$anonfun$1.apply(RewriteBottomUp.scala:6); 	at is.hail.expr.ir.RewriteBottomUp$$anonfun$1.apply(RewriteBottomUp.scala:6); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33); 	at scala.collection.mutable.WrappedArray.foreach(WrappedArray.scala:35); 	at scala.collection.TraversableLike$class.map(TraversableLike.scala:234); 	at scala.collection.AbstractTraversable.map(Traversable.scala:104); 	at is.hail.expr.ir.RewriteBottomUp$.is$hail$expr$ir$RewriteBottomUp$$rewrite$1(RewriteBottomUp.scala:6); 	at is.hail.expr.ir.RewriteBottomUp$$anonfun$1.apply(RewriteBottomUp.scala:6); 	at is.hail.expr.ir.RewriteBottomUp$$anonfun$1.apply(RewriteBottomUp.scala:6); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234); 	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.s",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9128:768,Rewrite,RewriteBottomUp,768,https://hail.is,https://github.com/hail-is/hail/issues/9128,8,"['Rewrite', 'rewrite']","['RewriteBottomUp', 'rewrite']"
Modifiability,"Previously, I read the tmpdir, billingProject, and remoteTmpdir arguments; separately for each comand in its branch of the switch. Then, I called; a method for that command, passing the three aformentioned arguments. The; method then constructs an execute context. Every method constructed the; context in the exact same way. This was just naughty copy paste job on my; part. I rectify that here by abstracting over the creation of the execute; context and moving the reading of the three execute context relevant; parameters to outside of the switch. I did not change any functionality. This strictly a refactor.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11646:604,refactor,refactor,604,https://hail.is,https://github.com/hail-is/hail/pull/11646,1,['refactor'],['refactor']
Modifiability,"Previously, the BlockMatrix IR had nodes for reading and writing that only covered the BlockMatrix part file format. Implemented readers and writers for both native and binary file formats (compatible with numpy) refactored read/write nodes, and implemented `tofile` and `fromfile` BlockMatrix methods in terms of the IR. Also hardcoded the front end default block size so now tests running IO/basic algebra should be able to run on the service.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5392:213,refactor,refactored,213,https://hail.is,https://github.com/hail-is/hail/pull/5392,1,['refactor'],['refactored']
Modifiability,"Prior to this PR, when someone specified they'd like to color a plot by a discrete variable, we used a predetermined list of 10 colors to assign colors. If something used more than 10 colors, it'd wrap around. . This PR changes `scale_color_discrete` to be an alias for `scale_color_hue`, as it is in ggplot. `scale_color_hue` works by sampling evenly spaced points around a color wheel to create a set of maximally distant colors. . The old behavior is now achievable by using `scale_color_manual`, which takes in a list of colors and assigns colors based on that list.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11613:83,variab,variable,83,https://hail.is,https://github.com/hail-is/hail/pull/11613,1,['variab'],['variable']
Modifiability,Provide option to skip log4j configuration,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8571:29,config,configuration,29,https://hail.is,https://github.com/hail-is/hail/pull/8571,1,['config'],['configuration']
Modifiability,"Python CLI tools like `hailctl` suffer from slow startup times, which infuriate me. This is in part because the first thing that happens is python has to recursively load all imported packages, since imports are traditionally done at the top-level. Very conveniently, setting the `PYTHONPROFILEIMPORTTIME` environment variable will cause python to emit a profile to stderr, which you can visualize with tools like [tuna](https://github.com/nschloe/tuna). So running. ```; PYTHONPROFILEIMPORTTIME=1 hailctl dev config show 2> profile.log; tuna profile.log; ```. gave me this. <img width=""1576"" alt=""Screen Shot 2022-01-28 at 2 58 28 PM"" src=""https://user-images.githubusercontent.com/24440116/151614364-d57a4478-1516-4397-ac72-4f2b9c6c081b.png"">. showing that importing `aiohttp` is responsible for half the time it takes me to run `hailctl dev config show`, which is literally just printing a local file!! There's no reason this shouldn't be instantaneous, but reducing it to ~300ms, which this change did, is fine enough for me for now. Generally people don't care about import time because most applications are long-lived and what does a few seconds matter, so `pylint` by default wants us to put imports at the top level. I would say this is a valid exception.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11293:318,variab,variable,318,https://hail.is,https://github.com/hail-is/hail/pull/11293,3,"['config', 'variab']","['config', 'variable']"
Modifiability,"Python integration tests often fail waiting to allocate highmem instances for worker jobs.; Since we control both APIs, it seems reasonable to move the testing burdon for vm allocation onto batch and use contract testing on the query driver side. These contract tests cover:; - uploading the the ServiceBackendRPConfig to remote storage in python; - reading that config and forwarding the relevant sections to the batch service in scala. Admittedly these are fairly busy tests and make bare a lot of lower-level implementation details. While I believe these tests are good to have, they perhaps don't warrant the time investment to properly refactor for cleaner mocking. Should details of the main implementation change, these will likely break. I've made tweaks to the python unittest annotations for backend test filtering. The old system skipped tests after all required fixtures had been acquired. Using `@pytest.mark.{feature}` allows us to exclude tests before fixtures are setup as well as add additional setup/teardown code.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14512:363,config,config,363,https://hail.is,https://github.com/hail-is/hail/pull/14512,2,"['config', 'refactor']","['config', 'refactor']"
Modifiability,RR: https://github.com/hail-is/hail/issues/13045; RR: https://github.com/hail-is/hail/issues/13046 ; Support symmetric comparison of structs and struct expressions.; Provide better error messages when attempting to construct literals from expressions with free variables.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13226:261,variab,variables,261,https://hail.is,https://github.com/hail-is/hail/pull/13226,1,['variab'],['variables']
Modifiability,RR: https://github.com/hail-is/hail/issues/13261. Grouping asserts of distributed `BlockMatrix` queries via `BatchAssert` lead to repeated timeout failures during tests that used the batch-service backend.; This change removes all `BatchAssert`s from `test_linalg.py`. It uses `pytest.mark.parameterize` to gain parallelism in test execution from the test driver.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13348:290,parameteriz,parameterize,290,https://hail.is,https://github.com/hail-is/hail/pull/13348,1,['parameteriz'],['parameterize']
Modifiability,"Rather than letting Breeze throw a SingularMatrixException, we should check for dependence and give an informative error message. The most common mistakes leading to dependence are accidentally including the same covariate twice (identical columns) or encoding a categorical variable with n categories using n rather than n - 1 covariates (since the model has an intercept term, this creates linear relation. We might also consider automating this encoding).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1156:275,variab,variable,275,https://hail.is,https://github.com/hail-is/hail/issues/1156,1,['variab'],['variable']
Modifiability,"Re-implement export vcf in generated code. There is a fair amount of 'duplicated' code here between table export; and vcf export, however, I belive this to be fine. We can always; refactor VCFPartitionWriter to be a subclass of SimplePartitionWriter,; but that would require a little special casing as VCF export needs; access to the column values and SimplePartitionWriter assumes such; a thing is not necessary. As far as VCF export itself, we simply duplicate the logic present in; ExportVCF but with generated code.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11450:180,refactor,refactor,180,https://hail.is,https://github.com/hail-is/hail/pull/11450,1,['refactor'],['refactor']
Modifiability,"Ready for review. The regex is working, though not sure where to place it in our code base. To properly match against nonNumeric() with no variables, there must be no groups (logically!)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/261:139,variab,variables,139,https://hail.is,https://github.com/hail-is/hail/pull/261,1,['variab'],['variables']
Modifiability,"Ready to look at. . Abstracts file system functionality. We no longer pass around a Hadoop Configuration w/ implicit methods defined in RichHadoopConfiguration. Instead we define an abstract FS class (could be a trait as well) to serve as our file system interface, and provide one Hadoop implementation to maintain existing functionality. The PR has many lines, but should hopefully be relatively easy to follow; mostly involves renaming. . cc @cseed , thanks @tpoterba",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6083:91,Config,Configuration,91,https://hail.is,https://github.com/hail-is/hail/pull/6083,1,['Config'],['Configuration']
Modifiability,Reduce. Reuse. Refactor.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6170:15,Refactor,Refactor,15,https://hail.is,https://github.com/hail-is/hail/pull/6170,1,['Refactor'],['Refactor']
Modifiability,Refactor AggSignature,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3890:0,Refactor,Refactor,0,https://hail.is,https://github.com/hail-is/hail/pull/3890,1,['Refactor'],['Refactor']
Modifiability,Refactor Die to take a string IR child,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4845:0,Refactor,Refactor,0,https://hail.is,https://github.com/hail-is/hail/pull/4845,1,['Refactor'],['Refactor']
Modifiability,Refactor LoadVCF to use MatrixRead,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3840:0,Refactor,Refactor,0,https://hail.is,https://github.com/hail-is/hail/pull/3840,1,['Refactor'],['Refactor']
Modifiability,Refactor MatrixLiteral to delete unnecessary parameter,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3963:0,Refactor,Refactor,0,https://hail.is,https://github.com/hail-is/hail/pull/3963,1,['Refactor'],['Refactor']
Modifiability,Refactor MatrixRead and MatrixReader to be cleaner,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3926:0,Refactor,Refactor,0,https://hail.is,https://github.com/hail-is/hail/pull/3926,1,['Refactor'],['Refactor']
Modifiability,Refactor MatrixReader JSON serialization,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3880:0,Refactor,Refactor,0,https://hail.is,https://github.com/hail-is/hail/pull/3880,1,['Refactor'],['Refactor']
Modifiability,Refactor MatrixWrite and use in Python,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4864:0,Refactor,Refactor,0,https://hail.is,https://github.com/hail-is/hail/pull/4864,1,['Refactor'],['Refactor']
Modifiability,Refactor Python IR to reduce code duplication and complexity,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5465:0,Refactor,Refactor,0,https://hail.is,https://github.com/hail-is/hail/pull/5465,1,['Refactor'],['Refactor']
Modifiability,Refactor Python MatrixRead,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4918:0,Refactor,Refactor,0,https://hail.is,https://github.com/hail-is/hail/pull/4918,1,['Refactor'],['Refactor']
Modifiability,Refactor ResultOp to return a single element instead of a tuple.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10894:0,Refactor,Refactor,0,https://hail.is,https://github.com/hail-is/hail/pull/10894,1,['Refactor'],['Refactor']
Modifiability,Refactor SBaseStruct.isFieldMissing and dependent methods to `CodeBuilder => Value` style.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10893:0,Refactor,Refactor,0,https://hail.is,https://github.com/hail-is/hail/pull/10893,1,['Refactor'],['Refactor']
Modifiability,Refactor SeqOp,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3850:0,Refactor,Refactor,0,https://hail.is,https://github.com/hail-is/hail/pull/3850,1,['Refactor'],['Refactor']
Modifiability,Refactor TableWrite to take a TableWriter,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5775:0,Refactor,Refactor,0,https://hail.is,https://github.com/hail-is/hail/pull/5775,1,['Refactor'],['Refactor']
Modifiability,Refactor _select methods in python,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4042:0,Refactor,Refactor,0,https://hail.is,https://github.com/hail-is/hail/pull/4042,1,['Refactor'],['Refactor']
Modifiability,Refactor `_emitStream` to a `EmitCodeBuilder -> IEmitCode` signature.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9926:0,Refactor,Refactor,0,https://hail.is,https://github.com/hail-is/hail/pull/9926,1,['Refactor'],['Refactor']
Modifiability,Refactor annotateVariantsTable. Annotate global table. Added extra key table method. checkpoint. Checkpoint. checkpoint before tests. Some of the docs. Passing tests. Fixed tutorial. Fix tutorial styling. Finish rebase. Fix rebase errors. Fix tests,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1687:0,Refactor,Refactor,0,https://hail.is,https://github.com/hail-is/hail/pull/1687,2,['Refactor'],['Refactor']
Modifiability,Refactor code so that job private instances look up memory from a table rather than calculating from number of cores and mib memory per core,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14536:0,Refactor,Refactor,0,https://hail.is,https://github.com/hail-is/hail/pull/14536,1,['Refactor'],['Refactor']
Modifiability,Refactor export argument parser. Cleans up exportCass / exportSolr c…,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/443:0,Refactor,Refactor,0,https://hail.is,https://github.com/hail-is/hail/pull/443,1,['Refactor'],['Refactor']
Modifiability,Refactor expr code to VSM,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/932:0,Refactor,Refactor,0,https://hail.is,https://github.com/hail-is/hail/pull/932,1,['Refactor'],['Refactor']
Modifiability,Refactor genotype readers with more abstraction,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1673:0,Refactor,Refactor,0,https://hail.is,https://github.com/hail-is/hail/issues/1673,1,['Refactor'],['Refactor']
Modifiability,Refactor rDeletionInsertion to rInsertionDeletion,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/851:0,Refactor,Refactor,0,https://hail.is,https://github.com/hail-is/hail/pull/851,1,['Refactor'],['Refactor']
Modifiability,Refactor reorder_columns to choose_cols,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3228:0,Refactor,Refactor,0,https://hail.is,https://github.com/hail-is/hail/pull/3228,1,['Refactor'],['Refactor']
Modifiability,Refactor resource usage,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2103:0,Refactor,Refactor,0,https://hail.is,https://github.com/hail-is/hail/pull/2103,1,['Refactor'],['Refactor']
Modifiability,"Refactor uniqueMinIndex and uniqueMaxIndex into argmin and argmax,",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2990:0,Refactor,Refactor,0,https://hail.is,https://github.com/hail-is/hail/pull/2990,1,['Refactor'],['Refactor']
Modifiability,Refactored OrderedRDD2 to take a RegionValueRDD,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2517:0,Refactor,Refactored,0,https://hail.is,https://github.com/hail-is/hail/pull/2517,1,['Refactor'],['Refactored']
Modifiability,"Refactored RDD[(Variant, Annotation, Iterable[Genotype])] to; RDD[(Variant, (Annotation, Iterable[Genotype]))]",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/526:0,Refactor,Refactored,0,https://hail.is,https://github.com/hail-is/hail/pull/526,1,['Refactor'],['Refactored']
Modifiability,"Refactored VariantRecord to RecordDecoder, made genotype decoding; lazy. This allows us to get out fastKeys and the genotypes with the; same abstraction. Refactored multiple BGEN file handling to BgenLoader, where it should be. Added assertions that we silently relied on.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/693:0,Refactor,Refactored,0,https://hail.is,https://github.com/hail-is/hail/pull/693,2,['Refactor'],['Refactored']
Modifiability,Refactored sampleQC to run against HTSGenotypeView,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2120:0,Refactor,Refactored,0,https://hail.is,https://github.com/hail-is/hail/pull/2120,1,['Refactor'],['Refactored']
Modifiability,Refactored table reader coercion and caching mechanism. ### What changed?. - Removed `shouldCacheQueryInfo` method from `Backend` class; - Introduced `CoercerCache` in `ExecuteContext`; - Refactored `LoweredTableReader.makeCoercer` to return a function instead of a class; - Removed local caching in `GenericTableValue` and `LoweredTableReader`; - Added `NoCaching` utility . ### Why make this change?. This change aims to optimize table reader coercion by:; - Centralizing caching logic in `ExecuteContext`; - Allowing more flexible caching strategies across different backend implementations,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14696:0,Refactor,Refactored,0,https://hail.is,https://github.com/hail-is/hail/pull/14696,3,"['Refactor', 'flexible']","['Refactored', 'flexible']"
Modifiability,"Refactoring RVD interface, pt. 1",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4392:0,Refactor,Refactoring,0,https://hail.is,https://github.com/hail-is/hail/pull/4392,1,['Refactor'],['Refactoring']
Modifiability,"Refactoring RVD interface, pt. 2",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4395:0,Refactor,Refactoring,0,https://hail.is,https://github.com/hail-is/hail/pull/4395,1,['Refactor'],['Refactoring']
Modifiability,"Refactoring RVD interface, pt. 3",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4398:0,Refactor,Refactoring,0,https://hail.is,https://github.com/hail-is/hail/pull/4398,1,['Refactor'],['Refactoring']
Modifiability,"Refactoring RVD interface, pt. 4",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4407:0,Refactor,Refactoring,0,https://hail.is,https://github.com/hail-is/hail/pull/4407,1,['Refactor'],['Refactoring']
Modifiability,"Refactoring RVD interface, pt. 5",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4409:0,Refactor,Refactoring,0,https://hail.is,https://github.com/hail-is/hail/pull/4409,1,['Refactor'],['Refactoring']
Modifiability,"Refactoring RVD interface, pt. 6",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4412:0,Refactor,Refactoring,0,https://hail.is,https://github.com/hail-is/hail/pull/4412,1,['Refactor'],['Refactoring']
Modifiability,"Refactors `Bindings` to return an object encoding the change to the environment (any new bindings, whether the agg/scan env is promoted, etc). This allows the deletion of `SegregatedBindingEnv`. Follow up work will use this to replace the other specializations of `GenericBindingEnv`, and to greatly simplify compiler passes, such as `NormalizeNames` and `PruneDeadFields`, which currently need to redundantly encode the binding structure of every node.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14496:0,Refactor,Refactors,0,https://hail.is,https://github.com/hail-is/hail/pull/14496,1,['Refactor'],['Refactors']
Modifiability,"Refactors `_blanczos_pca` into reusable and composable pieces, and uses those pieces to implement spectral moments estimators. # Krylov factorization; The core iteration of `_blanczos_pca` is factored out into `_krylov_factorization`. `_krylov_factorization(A, V0, p)` takes a matrix `A` (represented as a table of ndarrays) and a starting block `V0` (a local ndarray), and computes matrices (for now local) `U`, `R`, and `V`, such that:; * `U` and `V` are orthonormal matrices (i.e. `U'U = V'V = I`); * the columns of `V` are a basis for the block Krylov subspace `K_p(A'A, V_0)`, where `K_p(X, Y) = span(Y, XY, ... X^pY)`; * `UR = AV`, and hence `U` is a basis for the block Krylov subspace `A K_p(A'A, V_0) = K_p(AA', AV_0)`; * `V` is an extension of `V_0`, i.e. `V = hcat(V_0, ...)`; * `R` is upper triangular. # Reduced SVD; From a Krylov factorization, a reduced SVD can be easily computed: If `R = U_1 S V'_1` is a full SVD of `R` (which is small and easily computable), then `(U U_1[:, :k]) S[:k, :k] (V V_1[:, :k])'` is a reduced SVD of `A`. This is implemented in `KrylovFactorization.reduced_svd`. # Spectral moments; We can also easily compute estimates of spectral moments, i.e. moments of the set of all eigenvalues of `A'A`. The estimator exploits the following key facts:; * If `v` is a random vector of independent entries with mean 0, std. dev. 1 (equivalently `E(v) = 0`, `E(vv') = I`), then `E(v'Xv) = tr(X)`; * `tr(X)` equals the sum of the eigenvalues of `X`, `∑_i 𝜆_i`. More generally, if `f` is any matrix function, `tr(f(X)) = ∑_i f(𝜆_i)`.; * If `w` is a unit-norm vector, and `UR = AV` is the factorization `_krylov_factorization(A, w, p)`, then `w' f(A'A) w` is well-approximated by `w' f(VV'A'AVV') w = w'V f(R'U'UR) V'w = w'V f(R'R) V'w`, and is exact if `f` is a degree `2p+1` polynomial. Moreover, since `w` is the first column of `V`, i.e. `w = Ve_1`, the above further simplifies `w'V f(R'R) V'w = e'_1 f(R'R) e_1`. Finally, if `R = U_1 S V'_1` is an SVD, this reduces",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11045:0,Refactor,Refactors,0,https://hail.is,https://github.com/hail-is/hail/pull/11045,1,['Refactor'],['Refactors']
Modifiability,RegionValue doesn't extend Serializable,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3305:20,extend,extend,20,https://hail.is,https://github.com/hail-is/hail/pull/3305,1,['extend'],['extend']
Modifiability,"Remaining is that found in Etypes, in the _buildSkip function. This is slightly tricky, because there is a place in the code where there is no corresponding PType, and the solution to fix that is a bit involved, or if straightforward, beyond my current understanding of ETypes. I made an issue here: https://github.com/hail-is/hail/issues/7701. Stacked on https://github.com/hail-is/hail/pull/7687. edit: I removed the ETypes issue, by creating a packBitsToBytes function on UnsafeUtils. We may not want this change however, because I think array packing may needs to be the same as the array implementation (I think readBytes fills the allocated memory with the InputBuffer's encoded missingness data, which needs same number of bytes as what is encoded), in which case that coupling becomes less clear if the utility function is on UnsafeUtils. I could move it back to PContainer, or may _buildSkip take a ptype. . There are other places where (n + 7) >>> 3 are used, so this seems pretty general, hence UnsafeUtils (where we have some other bitwise ops, happy to move elsewhere). PTuple is one.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7702:776,coupling,coupling,776,https://hail.is,https://github.com/hail-is/hail/pull/7702,1,['coupling'],['coupling']
Modifiability,Remove annotation methods from PType:. - ordering (ExtendedOrdering); - str; - typeCheck; - valuesSimilar; - query; - queryTyped; - gen,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4280:51,Extend,ExtendedOrdering,51,https://hail.is,https://github.com/hail-is/hail/pull/4280,1,['Extend'],['ExtendedOrdering']
Modifiability,"Remove some (now) unnecessary local variable initializations. newEmit{Local, Field}: don't store missingness variable for required types. Split up zip cases assert same length and extend na. Otherwise, the same length code ended up assigning a missing element to a required field.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8317:36,variab,variable,36,https://hail.is,https://github.com/hail-is/hail/pull/8317,3,"['extend', 'variab']","['extend', 'variable']"
Modifiability,"Remove the setup of Jupyter/JupyterLab from hailctl to enable use of Dataproc's [Component Gateway](https://cloud.google.com/dataproc/docs/concepts/accessing/dataproc-gateways) feature, which eliminates the need to use an ssh tunnel to reach the various web UIs on the Dataproc cluster. To test this pull request:; 1. run `hailctl dataproc start` as usual, but add parameters `--enable-component-gateway --optional-components JUPYTER --dry-run` to generate the `gcloud dataproc clusters create` command that will setup JupyterLab and eliminate the need for an ssh tunnel. For example:; ```; hailctl dataproc start my-cluster-name \; --region us-central1 \; --enable-component-gateway \; --optional-components JUPYTER \; --bucket name-of-my-staging-gcs-bucket-where-notebook-files-will-live \; --temp-bucket name-of-my-gcs-bucket-with-a-lifecycle-rule-to-autodelete-cruft-after-two-weeks \; --max-idle 60m \; --dry-run; ```; 2. In the generated `gcloud dataproc clusters create` command, replace the value of `--initialization-actions` with the path of the GCS location to the script in this pull request. Also replace the value of `--temp-bucket`, since hailctl appears to stomp on the user specified value. Then run the command to create your cluster with component gateway enabled.; 3. To obtain the URL to JupyterLab, run `gcloud dataproc clusters describe my-cluster-name --region=us-central1 --format=""yaml(config.endpointConfig.httpPorts)""`; 4. Run Hail notebooks to test the setup of JupyterLab provided by Dataproc!",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12788:1412,config,config,1412,https://hail.is,https://github.com/hail-is/hail/pull/12788,1,['config'],['config']
Modifiability,"Renamed and moved `datasets/annotation_db.json` config file to `hail/experimental/datasets.json` and modified urls in `dataset[path]` to use a region parameter to load datasets from bucket in the appropriate region. Modified `load_datasets()` function to no longer use the `config_file` parameter, and to require user to specify `region` parameter. The checked-in `hail/experimental/datasets.json` file will now be used as the config file.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9411:48,config,config,48,https://hail.is,https://github.com/hail-is/hail/pull/9411,2,['config'],['config']
Modifiability,Replaced VariantDataset ..._to_pandas with ..._keytable.; Added expand_types and flatten to KeyTable. These probably need to be more configurable but are a start.; Added KeyTable.toDF. This allows KeyTables to be easily written to Parquet.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1157:133,config,configurable,133,https://hail.is,https://github.com/hail-is/hail/pull/1157,1,['config'],['configurable']
Modifiability,"Resolves issue #763.; ### Simple Types. The Function Registry distinguishes between fields and functions because they were distinguished in the existing `AST.scala`. Moreover, for unary functions, there are registration methods for both pure functions and computations in the `Option` monad. Registration requires only a name and an implementation. Unfortunately, the Scala compiler fails to infer the type parameters from an expression like `_.isHomRef`. . ``` scala; registerOptionField(""dosage"", { (x: Genotype) => x.dosage.map(a => a: IndexedSeq[Double]) }); registerField(""isHomRef"", { (x: Genotype) => x.isHomRef }); ```. ``` scala; register(""Variant"", { (x: String) =>; val Array(chr, pos, ref, alts) = x.split("":""); Variant(chr, pos.toInt, ref, alts.split("","")); }); register(""Variant"", { (x: String, y: Int, z: String, a: String) => Variant(x, y, z, a) }); ```. The `HailRep` type class associates Scala types with Hail expression types. For example, the function registry knows that `Variant` returns a `TVariant` because of this implicit:. ``` scala; implicit object variantHr extends HailRep[Variant] {; def typ = TVariant; }; ```; ### Polymorphic Types. I don't have an answer for the various kinds of polymorphism present in the Hail expression language. There is unbounded polymorphism:. ``` scala; case (t: TArray, ""length"") => TInt; ```. as well as bounded polymorphism:. ``` scala; case (""pow"", _) => TDouble; args.map(_.`type`) match {; case Array(a: TNumeric, b: TNumeric) => TDouble; // ...; }; ```. Both of these are still handled by explicit case matching.; ### Struct Types. Functions returning structs can use `registerAnn` to specifically provide a return type. ``` scala; registerAnn(""foo"", TStruct((""bar"", TDouble)), { (x: Int) => Annotation(x / 2.0) } ; ```. In general, the `register` `HailRep` implicits can be overridden as well, but this case is common enough to merit a concise alternative.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/807:1088,extend,extends,1088,https://hail.is,https://github.com/hail-is/hail/pull/807,5,"['Polymorphi', 'extend', 'polymorphi']","['Polymorphic', 'extends', 'polymorphism']"
Modifiability,"Resource groups are permitted to use dashes, underscores, uppercase letters,; and probably other characters not permitted in storage account names. This; PR cahanges `bootstrap.sh` to:. 1. Ignore invalid characters in the resouce group. 2. Ensure (via randomness) that the generated name is unique. 3. Do not try to create a new storage account if `backend-config.tfvars` exists. I lightly tested this. Here is an example of how it sanitizes a resource group name:. ```; RESOURCE_GROUP=bu__ild-batch-worker-i32mage; possibly_invalid_storage_account_name=""$(cat /dev/urandom | LC_ALL=C tr -dc 0-9 | head -c 4)${RESOURCE_GROUP}""; STORAGE_ACCOUNT_NAME=$(LC_ALL=C tr -dc a-z0-9 <<< ""${possibly_invalid_storage_account_name}"" | head -c 24); echo $STORAGE_ACCOUNT_NAME; 7241buildbatchworkeri32m; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11313:357,config,config,357,https://hail.is,https://github.com/hail-is/hail/pull/11313,1,['config'],['config']
Modifiability,"Revert ""[batch] Mount worker deploy config instead of using k8s secret""",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13209:36,config,config,36,https://hail.is,https://github.com/hail-is/hail/pull/13209,1,['config'],['config']
Modifiability,"Revert ""[combiner] use a single variable rather than a map for merge …",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5597:32,variab,variable,32,https://hail.is,https://github.com/hail-is/hail/pull/5597,1,['variab'],['variable']
Modifiability,Rewrite IR array sorting to use scala's sortWith,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3719:0,Rewrite,Rewrite,0,https://hail.is,https://github.com/hail-is/hail/pull/3719,1,['Rewrite'],['Rewrite']
Modifiability,"Rewrite VariantQC in Python, support multiallelics",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3629:0,Rewrite,Rewrite,0,https://hail.is,https://github.com/hail-is/hail/pull/3629,1,['Rewrite'],['Rewrite']
Modifiability,"Rewrite invocations of `hl.cond()` to `hl.if_else()`, `hl.null()` to `hl.missing()`, and `hl.zip_with_index()` to `hl.enumerate()`. Very minor, but a few of these appear in our test logs (and probably yours as well), which makes for noise when you're tracking down other problems in the logs:. ```; hail/methods/misc.py:437: DeprecationWarning: Call to deprecated function (or staticmethod) cond. (Replaced by hl.if_else) -- Deprecated since version 0.2.59.; hail/vds/methods.py:79: DeprecationWarning: Call to deprecated function (or staticmethod) zip_with_index. (Replaced by hl.enumerate) -- Deprecated since version 0.2.56.; hail/vds/methods.py:75: DeprecationWarning: Call to deprecated function (or staticmethod) null. (Replaced by hl.missing) -- Deprecated since version 0.2.62.; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13349:0,Rewrite,Rewrite,0,https://hail.is,https://github.com/hail-is/hail/pull/13349,1,['Rewrite'],['Rewrite']
Modifiability,Rewrite the staged aggregator interface to:; - allow primitive values in aggregator without associated region; - create Scala Region instance once and reuse by setting different underlying native Region object to avoid overhead of object creation. Also includes some interface changes to AggregatorState (formerly RVAState) to clean up the region dependencies.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6652:0,Rewrite,Rewrite,0,https://hail.is,https://github.com/hail-is/hail/pull/6652,1,['Rewrite'],['Rewrite']
Modifiability,"Right now the Grafana is exposed as a k8s service speaking http with only the grafana auth. This puts an nginx sidecar in front of Grafana to bring TLS all the way through the the Grafana pod and perform dev authentication. This required adding an api endpoint to auth that can verify a connection based on the session and not an Authorization header. Other services like `router-resolver` have gotten away with not having this since they construct the Authorization header in python before hitting the `userinfo` endpoint, but this seems like a straightforward addition that will make it easier for internal authentication such as this case. This does another deviant thing which is using a `runImage` step to template the nginx config instead of templating inside the container at container start time (like router and site currently do). It is a little janky, because there are essentially two jinja passes, one in CI to render the shell script for the job, and then the jinja line in the job itself to render the nginx config. But this looks to be the most straightforward way I could figure out without adding another `build.py` Step type and even in that case it would have to be some sort of no-op job.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10139:730,config,config,730,https://hail.is,https://github.com/hail-is/hail/pull/10139,2,['config'],['config']
Modifiability,"Right now this spins up K8s, a database, some of the networking stuff,; and creates a default/global-config secret that includes the; information stored in $HAIL/config.mk. This isn't used yet and will; probably change.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9713:101,config,config,101,https://hail.is,https://github.com/hail-is/hail/pull/9713,2,['config'],['config']
Modifiability,Save it to a variable and pass it to standard input using a heredoc; instead of a gnarly command line argument. This still outputs the; config to the logs/job output since the variable assignment expression; will be printed with `set -x`.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9533:13,variab,variable,13,https://hail.is,https://github.com/hail-is/hail/pull/9533,3,"['config', 'variab']","['config', 'variable']"
Modifiability,Scorecard should use a readiness probe to prevent traffic from being sent to scorecard before it has fully updated itself and is ready to serve traffic. https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-probes/. An HTTP readiness probe that hits `GET /` should be sufficient.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6648:186,config,configure-pod-container,186,https://hail.is,https://github.com/hail-is/hail/issues/6648,2,['config'],"['configure-liveness-readiness-probes', 'configure-pod-container']"
Modifiability,"Security/Server_Side_TLS#Recommended_configurations). ## New Hail Concepts. Every principal in our system has a secret: `ssl-config-NAME`. These secrets are; automatically created for a particular namespace by `tls/create_certs.py`. Who; trusts who (i.e. who is allowed to talk to whom) is defined by; `tls/config.yaml`. For example, `site` is defined in `config.yaml` as follows:. ```; - name: site; domain: site; kind: nginx; incoming:; - admin-pod; - router; ```. A principal named ""site"" exists. Site's domain names are `site`,; `site.NAMESPACE`, `site.NAMESPACE.svc.cluster.local`. Site's configuration files; should be in NGINX configuration file format. Site accepts incoming requests; from the principals named admin-pod and router. Site is not permitted to make; any outgoing requests. `create_certs.py` will create a new secret named; `ssl-config-site` which contains five files:. - `site-config-http.conf`: an NGINX configuration file that configures TLS for; incoming requests.; - `site-config-proxy.conf`: an NGINX configuration file that configures TLS for; outgoing (proxy_pass) requests.; - `site-key.pem`: a private key.; - `site-cert.pem`: a certificate.; - `site-incoming.pem`: a list of certificates trusted for incoming requests.; - `site-outgoing.pem`: a list of certificates expected from outgoing requests. If site makes an HTTP request to a server and that server does not return a; certificate in `site-outgoing.pem`, it will immediately halt the connection. I; intend (though do not currently) site to also reject incoming requests that are; not accompanied by a certificate in `site-incoming.pem`. I describe the [trouble; with that later](#incoming-trust). There are two other kinds: `json` and `curl`. The former is for Hail Python; services. The later is for the admin-pod and image-fetcher. Deploy will run `create_certs` on every master deploy. Newly deployed services; will be unable to talk to not-yet-deployed services. I include the; one-deploy-ago certificates in",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8561:7189,config,config-proxy,7189,https://hail.is,https://github.com/hail-is/hail/pull/8561,1,['config'],['config-proxy']
Modifiability,"See #6370 . > Could you open an issue, to explore changing this to a header-specified token, or randomizing the name field.; > ; > https://security.stackexchange.com/questions/211352/does-owasp-recommend-to-include-a-csrf-token-in-a-header-or-to-use-it-as-a-param; > ; > Need to take care with logging in this case.; > https://github.com/OWASP/CheatSheetSeries/blob/master/cheatsheets/Cross-Site_Request_Forgery_Prevention_Cheat_Sheet.md; > ; > To further enhance the security of this proposed design, consider randomizing the CSRF token parameter name and/or value for each request. Implementing this approach results in the generation of per-request tokens as opposed to per-session tokens.; > doing both seems identical to implementing 2 CSRF tokens",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6417:456,enhance,enhance,456,https://hail.is,https://github.com/hail-is/hail/issues/6417,1,['enhance'],['enhance']
Modifiability,"See `pyproject.toml` for the isort configuration. This adds isort as a part of the `check` target for the services. To manually run isort, just run `isort .` anywhere in the hail repo. It will properly find the config file and ignore non-services code. isort has a `black` setting so it should be compatible with subsequent format checks. It doesn't immediately play well with pre-commit (ignores file excludes and runs where it shouldn't e.g. migrations) so I will separately have to look into running it there. When run, it does the following:. - Inserts line breaks to keep long imports in the desired line length; - Sorts items imported from a given module, it appears first by data type (classes before functions) and then alphabetically; - Groups and orders imports by: stdlib, third party, first party (set in pyproject.toml), and local (inferred from imports that start with `.`). I like this a lot; - Sorts imports within each group by `import`vs`from … import`, then alphabetically by module",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11231:35,config,configuration,35,https://hail.is,https://github.com/hail-is/hail/pull/11231,2,['config'],"['config', 'configuration']"
Modifiability,"See the transcript below. This is particularly confusing for users because python often elides the non-printable characters. A small wrinkle of confusion is that the UTF-8 BOM, `ef bb bf`, is converted by Java into the UTF-16 BOM, `fe ff`. This is apparently [a well known Java bug](https://stackoverflow.com/questions/1835430/byte-order-mark-screws-up-file-reading-in-java)? This looks pretty annoying to fix in Scala/Java because we'd have to muck around with Spark's `hadoopFile` infrastructure to figure out where it is actually reading from a file. ```; # hexdump /tmp/bar; 0000000 ef bb bf 73 61 6d 70 6c 65 5f 69 64 0a 66 6f 6f; 0000010 0a ; 0000011; # ipython; import hail asPython 3.7.3 (default, Mar 27 2019, 09:23:15) ; Type 'copyright', 'credits' or 'license' for more information; IPython 7.5.0 -- An enhanced Interactive Python. Type '?' for help. In [1]: import hail as hl ; hl.import_; In [2]: t = hl.import_table('/tmp/bar') ; ...: t.describe() ; ...: t = t.key_by('sample_id') ; Initializing Spark and Hail with default parameters...; using hail jar at /usr/local/lib/python3.7/site-packages/hail/hail-all-spark.jar; 19/06/13 14:08:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; Setting default log level to ""WARN"".; To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).; Running on Apache Spark version 2.4.1; SparkUI available at http://wm06b-953.broadinstitute.org:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.14-5cb00c115421; LOGGING: writing to /Users/dking/projects/hail/hail/hail-20190613-1408-0.2.14-5cb00c115421.log; 2019-06-13 14:08:15 Hail: INFO: Reading table with no type imputation; Loading column '?sample_id' as type 'str' (type not specified). ----------------------------------------; Global fields:; None; --------",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6342:814,enhance,enhanced,814,https://hail.is,https://github.com/hail-is/hail/issues/6342,1,['enhance'],['enhanced']
Modifiability,"Set and Dict used an inconsistent definition in the JVM backend, and what's more, it is different from the Scala code. This fixes that, and in particular, it is technically a breaking change. There are two orderings on types, the default coming from <, <=, etc. and a total ordering coming from `compare`. The default can compare ""strangely"", e.g. for Doubles every comparison with nan returns false. This code changes Set and Dict to use the total ordering on types for comparison of elements and keys. The representation of Set and Dict in Java are now SortedSet and SortedMap, which are implemented as TreeSet and TreeMap, which is always parameterized to take the total ordering. Note, I left the tests disabled because there's another comparison bug related to intervals I'm sorting out with @patrick-schultz.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6100:642,parameteriz,parameterized,642,https://hail.is,https://github.com/hail-is/hail/pull/6100,1,['parameteriz'],['parameterized']
Modifiability,"Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/michafla/projects/R/pkg/hailr/inst/unitTests/spark-warehouse/').; 2018-10-09 14:46:38 SharedState: INFO: Warehouse path is 'file:/Users/michafla/projects/R/pkg/hailr/inst/unitTests/spark-warehouse/'.; 2018-10-09 14:46:38 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@28f0ac7{/SQL,null,AVAILABLE,@Spark}; 2018-10-09 14:46:38 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@49a30f89{/SQL/json,null,AVAILABLE,@Spark}; 2018-10-09 14:46:38 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@4495af6e{/SQL/execution,null,AVAILABLE,@Spark}; 2018-10-09 14:46:38 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@6baf9f3b{/SQL/execution/json,null,AVAILABLE,@Spark}; 2018-10-09 14:46:38 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@562ad221{/static/sql,null,AVAILABLE,@Spark}; 2018-10-09 14:46:39 StateStoreCoordinatorRef: INFO: Registered StateStoreCoordinator endpoint; 2018-10-09 14:46:39 SparkSession$Builder: WARN: Using an existing SparkSession; some configuration may not take effect.; 2018-10-09 14:46:39 SparkSqlParser: INFO: Parsing command: SHOW TABLES; 2018-10-09 14:46:40 SparkContext: INFO: Starting job: collect at utils.scala:44; 2018-10-09 14:46:40 DAGScheduler: INFO: Got job 0 (collect at utils.scala:44) with 1 output partitions; 2018-10-09 14:46:40 DAGScheduler: INFO: Final stage: ResultStage 0 (collect at utils.scala:44); 2018-10-09 14:46:40 DAGScheduler: INFO: Parents of final stage: List(); 2018-10-09 14:46:40 DAGScheduler: INFO: Missing parents: List(); 2018-10-09 14:46:40 DAGScheduler: INFO: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41), which has no missing parents; 2018-10-09 14:46:40 MemoryStore: INFO: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 366.3 MB); 2018-10-09 14:46:41 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4513:32357,config,configuration,32357,https://hail.is,https://github.com/hail-is/hail/issues/4513,1,['config'],['configuration']
Modifiability,"Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/michafla/projects/R/pkg/hailr/inst/unitTests/spark-warehouse/').; 2018-10-09 15:04:33 SharedState: INFO: Warehouse path is 'file:/Users/michafla/projects/R/pkg/hailr/inst/unitTests/spark-warehouse/'.; 2018-10-09 15:04:33 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@16ba3696{/SQL,null,AVAILABLE,@Spark}; 2018-10-09 15:04:33 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@2780d0b8{/SQL/json,null,AVAILABLE,@Spark}; 2018-10-09 15:04:33 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@7cea1161{/SQL/execution,null,AVAILABLE,@Spark}; 2018-10-09 15:04:33 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@696b1f0{/SQL/execution/json,null,AVAILABLE,@Spark}; 2018-10-09 15:04:33 ContextHandler: INFO: Started o.s.j.s.ServletContextHandler@14d32b0c{/static/sql,null,AVAILABLE,@Spark}; 2018-10-09 15:04:34 StateStoreCoordinatorRef: INFO: Registered StateStoreCoordinator endpoint; 2018-10-09 15:04:34 SparkSession$Builder: WARN: Using an existing SparkSession; some configuration may not take effect.; 2018-10-09 15:04:34 SparkSqlParser: INFO: Parsing command: SHOW TABLES; 2018-10-09 15:04:36 SparkContext: INFO: Starting job: collect at utils.scala:44; 2018-10-09 15:04:36 DAGScheduler: INFO: Got job 0 (collect at utils.scala:44) with 1 output partitions; 2018-10-09 15:04:36 DAGScheduler: INFO: Final stage: ResultStage 0 (collect at utils.scala:44); 2018-10-09 15:04:36 DAGScheduler: INFO: Parents of final stage: List(); 2018-10-09 15:04:36 DAGScheduler: INFO: Missing parents: List(); 2018-10-09 15:04:36 DAGScheduler: INFO: Submitting ResultStage 0 (MapPartitionsRDD[4] at map at utils.scala:41), which has no missing parents; 2018-10-09 15:04:36 MemoryStore: INFO: Block broadcast_0 stored as values in memory (estimated size 6.0 KB, free 366.3 MB); 2018-10-09 15:04:36 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4513:14842,config,configuration,14842,https://hail.is,https://github.com/hail-is/hail/issues/4513,1,['config'],['configuration']
Modifiability,Should actually figure out how to unify all these variables in one file since they're at least used in both hail-ci-deploy.sh and get-deployed-sha.sh right now,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5009:50,variab,variables,50,https://hail.is,https://github.com/hail-is/hail/pull/5009,1,['variab'],['variables']
Modifiability,Should maybe use `spark.local.dir` if that variable is set.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8277:43,variab,variable,43,https://hail.is,https://github.com/hail-is/hail/issues/8277,1,['variab'],['variable']
Modifiability,"Significantly cleaned up code by refactoring; and deleting org.broadinstitute.hail.Utils:; 1. Rich classes are moved to utils.richUtils._,; and implicit conversions are held in a trait; utils.richUtils.Implicits; 2. Standalone classes in Utils have been made; independent classes under utils; 3. Miscellaneous methods have been moved to; utils package object",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/740:33,refactor,refactoring,33,https://hail.is,https://github.com/hail-is/hail/pull/740,1,['refactor'],['refactoring']
Modifiability,"SigningRequest API conditions were updated:; <ul>; <li>a <code>status</code> field was added; this field defaults to <code>True</code>, and may only be set to <code>True</code> for <code>Approved</code>, <code>Denied</code>, and <code>Failed</code> conditions</li>; <li>a <code>lastTransitionTime</code> field was added</li>; <li>a <code>Failed</code> condition type was added to allow signers to indicate permanent failure; this condition can be added via the <code>certificatesigningrequests/status</code> subresource.</li>; <li><code>Approved</code> and <code>Denied</code> conditions are mutually exclusive</li>; <li><code>Approved</code>, <code>Denied</code>, and <code>Failed</code> conditions can no longer be removed from a CSR (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/90191"">kubernetes/kubernetes#90191</a>, <a href=""https://github.com/liggitt""><code>@​liggitt</code></a>) [SIG API Machinery, Apps, Auth, CLI and Node]</li>; </ul>; </li>; <li>Cluster admins can now turn off /logs endpoint in kubelet by setting enableSystemLogHandler to false in their kubelet configuration file. enableSystemLogHandler can be set to true only when enableDebuggingHandlers is also set to true. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/87273"">kubernetes/kubernetes#87273</a>, <a href=""https://github.com/SaranBalaji90""><code>@​SaranBalaji90</code></a>) [SIG Node]</li>; <li>Custom Endpoints are now mirrored to EndpointSlices by a new EndpointSliceMirroring controller. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/91637"">kubernetes/kubernetes#91637</a>, <a href=""https://github.com/robscott""><code>@​robscott</code></a>) [SIG API Machinery, Apps, Auth, Cloud Provider, Instrumentation, Network and Testing]</li>; <li>CustomResourceDefinitions added support for marking versions as deprecated by setting <code>spec.versions[*].deprecated</code> to <code>true</code>, and for optionally overriding the defaul",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11462:5167,config,configuration,5167,https://hail.is,https://github.com/hail-is/hail/pull/11462,1,['config'],['configuration']
Modifiability,"Since #13211, all jobs by default have a deploy config mounted into the container. The `worker-deploy-config` secret is no longer necessary, so long as we properly configure the namespace that CI jobs need to talk to.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13343:48,config,config,48,https://hail.is,https://github.com/hail-is/hail/pull/13343,3,['config'],"['config', 'configure']"
Modifiability,"Since recently adding metadata server support for batch jobs in GCP, `gcloud` should now ""Just Work"" using the CI service account in CI jobs without explicitly configuring it with a key file, so we no longer need this line. I tested that this succeeds with a dev deploy.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14308:160,config,configuring,160,https://hail.is,https://github.com/hail-is/hail/pull/14308,1,['config'],['configuring']
Modifiability,"So I did:. hail-new-vep importvcf /user/satterst/DILI/DILI_controls.vcf.bgz repartition -n 100 splitmulti vep --config /psych/genetics_data/working/cseed/vep.properties write -o /user/satterst/DILI/DILI_split_vep.vds . It almost immediately advanced to the write, then it sat there having tasks fail for two hours, then it said:; [Stage 1:> (0 + 35) / 100]; hail: write: caught exception: org.apache.spark.SparkException: Job aborted. log here: /humgen/atgu1/fs03/satterst/hail.jobaborted.log",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/302:112,config,config,112,https://hail.is,https://github.com/hail-is/hail/issues/302,1,['config'],['config']
Modifiability,"Some light refactoring of TableStage to change how context/body is defined; this is pretty similar to how BlockMatrixStage currently handles contexts. I prefer this way of defining the body of a partition because I think it will make writing table joins more natural and lead to less boilerplate ref generation; I think BlockMatrixDot provides a pretty good illustration of what a join body will look like, in general. (The context handling is different, and I don't think we want to do what BlockMatrixStage does w.r.t contexts right now.) This is slightly different from the code in master; I've rewritten `blockBody` to make use of `bindIR` and (currently non-existent) `foldIR` instead of manually generating refs to better illustrate flow. ```; case x@BlockMatrixDot(leftIR, rightIR) =>; val left = lower(leftIR); val right = lower(rightIR); val newCtxType = TArray(TTuple(left.ctxType, right.ctxType)); new BlockMatrixStage(left.globalVals ++ right.globalVals, newCtxType) {; def blockContext(idx: (Int, Int)): IR = {; val (i, j) = idx; MakeArray(Array.tabulate[Option[IR]](leftIR.typ.nColBlocks) { k =>; if (leftIR.typ.hasBlock(i -> k) && rightIR.typ.hasBlock(k -> j)); Some(MakeTuple.ordered(FastSeq(; left.blockContext(i -> k), right.blockContext(k -> j)))); else None; }.flatten[IR], newCtxType); }. def blockBody(ctxRef: Ref): IR = {; def blockMultiply(elt: Ref) =; bindIR(GetTupleElement(elt, 0)) { leftElt =>; bindIR(GetTupleElement(elt, 1)) { rightElt =>; NDArrayMatMul(left.blockBody(leftElt), right.blockBody(rightElt)); }; }; foldIR(ToStream(invoke(""sliceRight"", ctxType, ctxRef, I32(1))),; bindIR(ArrayRef(ctxRef, 0))(blockMultiply)) { (sum, elt) =>; NDArrayMap2(sum, blockMultiply(elt), ""l"", ""r"",; Ref(""l"", x.typ.elementType) + Ref(""r"", x.typ.elementType)); }; }; }; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8658:11,refactor,refactoring,11,https://hail.is,https://github.com/hail-is/hail/pull/8658,1,['refactor'],['refactoring']
Modifiability,Some links:. http://findbugs.sourceforge.net/; https://docs.gradle.org/current/userguide/findbugs_plugin.html; https://github.com/sksamuel/scalac-scapegoat-plugin; https://stackoverflow.com/questions/22617713/whats-the-current-state-of-static-analysis-tools-for-scala; https://stackoverflow.com/questions/1598882/are-there-any-tools-for-performing-static-analysis-of-scala-code,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/81:156,plugin,plugin,156,https://hail.is,https://github.com/hail-is/hail/issues/81,1,['plugin'],['plugin']
Modifiability,"Soon, I will add certificates and keys to the secrets and I want; to add configuration parameters that specify the paths to those; certificates and keys. Therefore, the mount locations of the; secrets must be the same everywhere so the paths are valid.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8416:73,config,configuration,73,https://hail.is,https://github.com/hail-is/hail/pull/8416,1,['config'],['configuration']
Modifiability,Stacked on #10876. Refactors all the function registry interfaces to take/return (S)Values.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10877:19,Refactor,Refactors,19,https://hail.is,https://github.com/hail-is/hail/pull/10877,1,['Refactor'],['Refactors']
Modifiability,"Stacked on #10920 and #10965. # Summary of Changes. ## hailtop.aiocloud.aioazure; - Renamed AzureResourcesClient to AzureResourceManagementClient; - Added AzureResourcesClient that hits a different API than before; - Added `AzureBaseClient.get_next_link` and `AzureBaseClient.delete_and_wait`. ## Batch; - Added `batch.azure` which mirrors the functionality of `batch.gcp`; - Renamed `worker_local_ssd_data_disk` to `local_ssd_data_disk` in the PoolConfig; - Renamed `worker_pd_ssd_data_disk_size_gb` to `external_data_disk_size_gb` in the PoolConfig; - Added {Azure,GCP}UserCredentials to the worker to abstract away the names of environment variables and the mount paths of credentials in containers. ## Auth; - Added new fields in the auth database for `azure service principal name` and `azure_credentials_secret_name`; - Made `auth` only create `GSAResource` if CLOUD == 'gcp'. ## Gear; - Added `azure-vm` to the location options for `DeployConfig`. # Assumptions:; - Mapped `{'lowmen': 'F', 'standard': 'D', 'highmem': 'E'}` for machine types in Azure. This corresponds to 2Gi/core, 4Gi/core, and 8Gi/core.; - Spot price is set to -1 for now until we figure out a better billing strategy; - We look for existing network security groups to tell if a VM has been fully cleaned up already in the garbage collection loop. # To-Do:. ## Services. - Use global config and make an `AzureConfig` (@daniel-goldstein not sure if you're already doing this) instead of optional environment variables; - Azure user disks are not implemented; There's a maximum number of disks that can be mounted per machine type with a maximum of 32 along with figuring out the API calls. We'll need a semaphore of some sort.; - No activity logs loop. Not necessary for initial development and preemption billing is not working how intended anyways (will add to the list to fix!). We also don't track vm creation success rates per zone like we do with GCP. It might be good to look for VM deletion events to remove instances ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10970:643,variab,variables,643,https://hail.is,https://github.com/hail-is/hail/pull/10970,1,['variab'],['variables']
Modifiability,"Stacked on #11240. Rewrite all `SSettable.store` implementations to take an `SValue`. With that, `SCode` and subclasses are safe to delete.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11241:19,Rewrite,Rewrite,19,https://hail.is,https://github.com/hail-is/hail/pull/11241,1,['Rewrite'],['Rewrite']
Modifiability,Stacked on #11996. This change gets rid of the extra dummy variable and temp table used for bookkeeping the previous migration to populate the aggregated billing tables.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12006:59,variab,variable,59,https://hail.is,https://github.com/hail-is/hail/pull/12006,1,['variab'],['variable']
Modifiability,"Stacked on #12210, this alters `build.py` to push images to `docker_prefix` and to `new_docker_prefix` if present in the global config. This will make sure that when we switch `docker_prefix` to the new Artifact Registry that any in-use images are ready to go. Once we are ready to switch over, we can; 1. change `docker_prefix` to the new AR in the global-config; 2. remove `new_docker_prefix` from the global-config; 3. Revert this change",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12211:128,config,config,128,https://hail.is,https://github.com/hail-is/hail/pull/12211,3,['config'],['config']
Modifiability,"Stacked on #9769 . I tried to make the code changes as small as possible and this is just a refactoring. I split the current instance_pool into the instance_monitor and the instance_pool. The main difference is the instance pool and instance monitor are recording two exact copies of the instances by state and live total cores etc which are linked via `adjust_for_*_instance`. Eventually with multiple pools, these numbers won't be identical and one will be for all instances and the other will be pool specific.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9772:92,refactor,refactoring,92,https://hail.is,https://github.com/hail-is/hail/pull/9772,1,['refactor'],['refactoring']
Modifiability,"Stacked on #9774 . This PR leaves the system in a state that has multiple pools in the SQL code, but the instance pool is hard coded as standard and there's only one of them. The global variables of local ssd, standing worker cores, etc. are still in globals and not per pool yet. This is because I need to write the code for the instance pool manager which will be in subsequent PRs so that we can configure each pool individually. The goal of this PR is to make sure the incremental data structures are correct for supporting multiple pools.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9779:186,variab,variables,186,https://hail.is,https://github.com/hail-is/hail/pull/9779,2,"['config', 'variab']","['configure', 'variables']"
Modifiability,Stacked on: https://github.com/hail-is/hail/pull/5509. Broadcast once and reuse the same broadcast where. Never serialize (except via broadcast). Same pattern as RVDPartitioner and Hadoop configuration.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5512:188,config,configuration,188,https://hail.is,https://github.com/hail-is/hail/pull/5512,1,['config'],['configuration']
Modifiability,Stacked on: https://github.com/hail-is/hail/pull/5891. I found getting .in (or not) consistent between the configuration and the files was just error prone. I think this is just simpler.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5907:107,config,configuration,107,https://hail.is,https://github.com/hail-is/hail/pull/5907,1,['config'],['configuration']
Modifiability,"Stacked on: https://github.com/hail-is/hail/pull/7031. Changes:; - primary change was to add `Tokens.namespace_token_or_error` which prints a friendly error of the user doesn't have the necessary authentication; - added `hailctl auth list`, and made `hailctl dev config` with no options print out the current configuration; - implemented @danking's suggestion: change some natural entrypoints (BatchClient, get_userinfo, etc.) to take optional `deploy_config` argument and load the default config if not given",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7035:263,config,config,263,https://hail.is,https://github.com/hail-is/hail/pull/7035,3,['config'],"['config', 'configuration']"
Modifiability,"Stacked on: https://github.com/hail-is/hail/pull/7208. Make app, db and v1 not global variables in batch.py. I'm doing this because I want to break Batch, Job into separate files and use them in both the scheduler and the front end. To do that, they need to be parameterized by the app (or the services that are carried on the app).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7210:86,variab,variables,86,https://hail.is,https://github.com/hail-is/hail/pull/7210,2,"['parameteriz', 'variab']","['parameterized', 'variables']"
Modifiability,"Stacks on #5430. Once #5430 is in, the changes here will be limited to: 1) notebook.py: login/logout routes, the provision of authorized users, auth0 lib, 2) index.html 3) header.html: update lines 12 and 13 to read user from session. Provides basic login page. Below are a few images of it in action. Looks like app.hail.is. Handles authorized and workshop-only login. Handles login only; future PR will extend to checking, refreshing the session. cc @cseed . screenshots (notebook create button not yet PR'd , auth0 page not yet styled). <img width=""1141"" alt=""screen shot 2019-02-25 at 11 17 37 pm"" src=""https://user-images.githubusercontent.com/5543229/53387218-d62f3e80-3953-11e9-8653-e4c6b0e8294a.png"">; <img width=""1139"" alt=""screen shot 2019-02-25 at 11 18 00 pm"" src=""https://user-images.githubusercontent.com/5543229/53387219-d62f3e80-3953-11e9-8595-d7f1ea58a243.png"">; <img width=""1139"" alt=""screen shot 2019-02-25 at 11 18 18 pm"" src=""https://user-images.githubusercontent.com/5543229/53387220-d62f3e80-3953-11e9-9fba-e4a93b0374ee.png"">; <img width=""1141"" alt=""screen shot 2019-02-25 at 11 18 33 pm"" src=""https://user-images.githubusercontent.com/5543229/53387221-d62f3e80-3953-11e9-9527-7c4589846a29.png"">",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5437:405,extend,extend,405,https://hail.is,https://github.com/hail-is/hail/pull/5437,1,['extend'],['extend']
Modifiability,StagedExtractedAggregators had a lot of duplicated code from ExtractAggregators. This just parameterizes the internal functions so that we don't have two identical copies of the aggregator logic.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6161:91,parameteriz,parameterizes,91,https://hail.is,https://github.com/hail-is/hail/pull/6161,1,['parameteriz'],['parameterizes']
Modifiability,"Started playing with [typer](https://typer.tiangolo.com/) on the plane. It's a somewhat thin wrapper around `click`, and I'm not entirely sold on one vs the other, but either seems a lot neater than argparse (I remember Cotton tried this years ago but I haven't looked at that PR). Click gives us the easy composition of CLIs, function name as the command name, the use of docstring as the description, help output, and most of the core functionality you see. Typer is the one translating python type hints into click type-checking, default setting, etc. Typer also uses rich if it's installed and allows you to install shell completion which is pretty neat, not sure if you can get that through click or if you need to use a click plugin. I replaced a couple of the hailctl commands here with the typer/click version. If you like what you see I can keep going on the rest of the commands (you can look to `batch/cli.py` and `hailctl/__main__.py` as an example).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13109:732,plugin,plugin,732,https://hail.is,https://github.com/hail-is/hail/pull/13109,1,['plugin'],['plugin']
Modifiability,StatAggregator inherits NaN and Infinities from StatCounter,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1636:15,inherit,inherits,15,https://hail.is,https://github.com/hail-is/hail/issues/1636,1,['inherit'],['inherits']
Modifiability,Still need to verify the audience and probably configure our clients to specifically use the hail oauth client id as the audience.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13084:47,config,configure,47,https://hail.is,https://github.com/hail-is/hail/pull/13084,1,['config'],['configure']
Modifiability,"Summary of changes:; - Overhaul tmpdir handling. Remove most of the old code. Added local_tmpdir to `init`. tmpdir is the networked tmpdir. local_tmpdir is the tmpdir used for local files on both the driver and the executors. Added tmpdir and localTmpdir to ExecuteContext. ExecuteContext removes tmp files on close. Tmp file base is now required, try to give good base names. Tmp file names are now generated by being sufficiently random.; - Removed fs from HailContext. This involved threading ctx and fs through lots of code (most of the changes).; - Added ExecuteContext to EmitModuleBuilder and friends. This is necessary because EmitMethodBuilder gives generated code access to backend, fs, etc. which are carried by the ctx.; - Some IR (mostly readers, but also VEP, which needs to load the VEP configuration to determine its type) have overall parameters that control their behavior (e.g. the VCF reader path) but have to do IO to determine other state (like the matrix type, determined from the VCF header). This complicates pretty printing, serialization, and equality. I clarified this. In particular, I seperate the parameters (see, for example, MatrixVCFReaderParameters) which are specified on creation and used for serialization and equality from other derived state. IR no longer close over ctx or fs and they don't need to do IO after their intiial construction.; - MatrixSpec has subspecs for the marginal tables, and TableSpec has the global and rows RVD. These are now loaded on construction, so lowering no longer neesd to do IO.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8581:802,config,configuration,802,https://hail.is,https://github.com/hail-is/hail/pull/8581,1,['config'],['configuration']
Modifiability,"Summary of changes:; - add is.hail.lir, a low-level IR for emitting JVM bytecode; - lir handles local variable initialization. It uses dataflow analysis to compute which variables must be initialized. It will no longer be necessary to initialize locals to satisfy the JVM bytecode verifier.; - Modify Code[T] to use lir instead of asm directly. Code[T] can only be used once and this is now checked.; - Remove joinpoint and ParameterPack. This primarily involved making EmitStream use Labels instead of joinpoint, and specializing routines that required ParameterPack to work over EmitCode instead.; - Because Code[T] can only be used once, push Value[T], PValue and EmitValue throughout the code base. For example, the Emit environment is now an Emit[EmitValue]. This was mostly a lot of tedious changes: remove `.load()` in places, add calls to `memoize`, and change `Code[T] => Value[T]` in various places.; - EmitMetholdBuilder has newEmit{Local, Field} for creating places to store EmitCodes. I think there are two main issues to clean up before this goes in, or soon after:. This code doesn't try to optimize short-circuit boolean operations (||, &&, etc.) like the old code did, tho it seems the old code wasn't always working. Either way, this should get fixed. It is relatively easy to handle in `Code[T]`. I will fix this before the final version. I left jointpoint.Ctrl and have implicit conversions that freely convert between `Code[Unit]` and `Code[Ctrl]`. This is a bit tedious, but I guess `Code[T]` should support `Code[Nothing]` for type checking user code, although it will still treat it like a `Code[Unit]`. I will fix this later.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8312:102,variab,variable,102,https://hail.is,https://github.com/hail-is/hail/pull/8312,2,['variab'],"['variable', 'variables']"
Modifiability,"Summing a block-sparse matrix may result in a block-dense vector, in which case maybeBlocks should be None (otherwise the `bis.length < maxNBlocks` assert fails...when rebuilding BlockMatrix in Python/C++ I may change the invariants). Also extended test cases to serve as regression test.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4888:240,extend,extended,240,https://hail.is,https://github.com/hail-is/hail/pull/4888,1,['extend'],['extended']
Modifiability,"Support [Artifact Registry](https://cloud.google.com/artifact-registry) to store images. It's useful for our deployment in Australia, as GCR does not support our continent. With AR, we would save on network egress. The PR adds a `DOCKER_PREFIX` variable, which is passed along in the code together with `GCP_PROJECT` and others. To switch to AR, one would need to modify `DOCKER_PREFIX` in `config.mk`:. ```; REGION := us-central1; DOCKER_PREFIX := gcr.io/$(PROJECT); ```. ```; REGION := australia-southeast1; DOCKER_PREFIX := $(REGION)-docker.pkg.dev/$(PROJECT)/hail; ```. Also, when making an initial deployment with Terraform, there is an extra variable `use_artifact_registry = false` that controls whether to use AR or GCR.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10107:245,variab,variable,245,https://hail.is,https://github.com/hail-is/hail/pull/10107,3,"['config', 'variab']","['config', 'variable']"
Modifiability,"Suppose you have two branches with the same base commit. Neither branch has Scala changes. Consider `make shadowJar` when switching between these branches: it thinks there's nothing to do because the Scala code hasn't changed. This of course doesn't work because the python version *is* changing (note: make install-editable refreshes the version files) and Hail refuses to use an out of date jar. This adds a tiny make macro that lets make targets depend on variables that depend on the latent environment, like git SHAs. To create a target for such a variable add this line: `$(eval $(call ENV_VAR,VARIABLE_NAME))`. Any rule that depends on the value of `VARIABLE_NAME` should depend on the target `env/VARIABLE_NAME`. I also split `BUILD_INFO` into the scala parts and the python parts and moved the scala dependency down to the shadow jar rule, where it belongs. This bug was hidden because build.gradle still regenerates the build info every time shadowJar is called. cc: @tpoterba",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6867:459,variab,variables,459,https://hail.is,https://github.com/hail-is/hail/pull/6867,2,['variab'],"['variable', 'variables']"
Modifiability,Syntax: hailctl config list [section]. Output (for each value):; ```; with no section specified:; {section}/{key}={value}; with a section specified:; {key}={value}; ```,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9529:16,config,config,16,https://hail.is,https://github.com/hail-is/hail/pull/9529,1,['config'],['config']
Modifiability,"TaskRunner.$anonfun$run$3(Executor.scala:548); 	at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1504); 	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:551); 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); 	at java.base/java.lang.Thread.run(Thread.java:829). Hail version: 0.2.130-bea04d9c79b5; Error summary: HailException: VEP command '/vep --format vcf --json --everything --allele_number --no_stats --cache --offline --minimal --assembly GRCh38 --fasta /opt/vep/.vep/homo_sapiens/95_GRCh38/Homo_sapiens.GRCh38.dna.toplevel.fa.gz --plugin LoF,loftee_path:/opt/vep/Plugins/,gerp_bigwig:/opt/vep/.vep/gerp_conservation_scores.homo_sapiens.GRCh38.bw,human_ancestor_fa:/opt/vep/.vep/human_ancestor.fa.gz,conservation_file:/opt/vep/.vep/loftee.sql --dir_plugins /opt/vep/Plugins/ -o STDOUT' failed with non-zero exit status 2; VEP Error output:; Smartmatch is experimental at /opt/vep/Plugins/de_novo_donor.pl line 175.; Smartmatch is experimental at /opt/vep/Plugins/de_novo_donor.pl line 214.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 191.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 194.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 238.; Smartmatch is experimental at /opt/vep/Plugins/splice_site_scan.pl line 241.; DBI connect('dbname=/opt/vep/.vep/loftee.sql','',...) failed: unable to open database file at /opt/vep/Plugins/LoF.pm line 126. -------------------- EXCEPTION --------------------; MSG: ERROR: No cache found for homo_sapiens, version 95. STACK Bio::EnsEMBL::VEP::CacheDir::dir /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/CacheDir.pm:328; STACK Bio::EnsEMBL::VEP::CacheDir::init /opt/vep/src/ensembl-vep/modules/Bio/EnsEMBL/VEP/CacheDir.pm:227; STACK Bio::EnsEMBL::VEP::CacheDir::new /opt/vep/src/ensembl-vep/modul",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14513:20266,Plugin,Plugins,20266,https://hail.is,https://github.com/hail-is/hail/issues/14513,2,['Plugin'],['Plugins']
Modifiability,"The 'build' docs page implies that the only requirement for running hail is Gradle. However, I've just tried to build hail on Debian Jessie and Ubuntu 16.04, and both failed in different ways. On Jessie, I was able to figure out that the version of Gradle was too old. On Ubuntu 16.04, I get. ```; :compileJava UP-TO-DATE; :compileScala FAILED. FAILURE: Build failed with an exception. * What went wrong:; A problem was found with the configuration of task ':compileScala'.; > No value has been specified for property 'zincClasspath'. * Try:; Run with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output. BUILD FAILED; ```. A quick Google around doesn't reveal any obvious answers to this. What version of Gradle is needed? Is Scala a prerequisite? It would be very useful to provide detailed instructions on how to build hail from scratch on a fresh installation of some Linux distribution.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/594:435,config,configuration,435,https://hail.is,https://github.com/hail-is/hail/issues/594,1,['config'],['configuration']
Modifiability,The GCP terraform got into a bit of an invalid state during an ambitious but ultimately fragmented migration I was trying to make to modularize the terraform code. The `sql_config` module assumed by the terraform code no longer exists (!) and I've reinstated the database server config resource for the time being until the GCP terraform code is ready to use the new `infra/k8s` module. This also includes the following fixes/cleanup:. - A GSA key/secret for grafana that is required for grafana/create_accounts to work correctly; - Deleting resources related to the `gcr_pull` service account that no longer exists since it isn't used in our codebase.; - Added the cluster role/binding for batch that it needs to use to access developer/test namespaces. This will become relevant soon when I introduce the rest of the changes from #10866 that I now intend to do more gradually. I tested this by applying my changes to my own cluster and restarting auth/auth-driver to validate that the sql config works as intended and using the admin-pod to verify that the `sql-config.cnf` is also correct.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11009:279,config,config,279,https://hail.is,https://github.com/hail-is/hail/pull/11009,3,['config'],['config']
Modifiability,The PR adds support for skipping Scala `SchedulerSuite` unit tests by setting a `HAIL_TEST_SKIP_SCHEDULER` environment variable.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6768:119,variab,variable,119,https://hail.is,https://github.com/hail-is/hail/pull/6768,1,['variab'],['variable']
Modifiability,The TOKEN variable is defined in config.mk which is included into hail/Makefile.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12825:10,variab,variable,10,https://hail.is,https://github.com/hail-is/hail/pull/12825,2,"['config', 'variab']","['config', 'variable']"
Modifiability,"The `--extra-config` short option used to be `-c` and I accidentally made it `-e`, which likely shadows the previous option. This broke using `-e` for `--excluded_steps`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13182:13,config,config,13,https://hail.is,https://github.com/hail-is/hail/pull/13182,1,['config'],['config']
Modifiability,The `fails_in_azure` decorator uses the `HAIL_CLOUD` environment variable and it wasn't supplied to tests. The decorator itself looks fine.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11132:65,variab,variable,65,https://hail.is,https://github.com/hail-is/hail/pull/11132,1,['variab'],['variable']
Modifiability,The `logging_queries` variable is always *defined* but sometimes `None`.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13824:22,variab,variable,22,https://hail.is,https://github.com/hail-is/hail/pull/13824,1,['variab'],['variable']
Modifiability,"The `to_dense_mt` and `to_merged_sparse_representation` methods required; localizing into an array all of the split rows at each locus when the; variant data is on the right side of the join. We flip the order so that; the variant data are on the left and the reference data, known to be; locus-distinct, are on the right. I also fix a few stream mis-parameterizations that led to a slightly; higher (but similarly scaling) memory usage.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11755:351,parameteriz,parameterizations,351,https://hail.is,https://github.com/hail-is/hail/pull/11755,1,['parameteriz'],['parameterizations']
Modifiability,"The assumption is that the default_ns namespace has a database-server-config that has credentials for the database instance which can be used to create various databases. This is present in default. We will require this is also present for dev namespaces, database-server-config will be the user's private database. devs shouldn't have access to the root database credentials. When we create a test default_ns when running the tests, we also create a ""test_instance"" database that will be used as the database instance inside the tests. database-server-config is only used by CI. Also, there's no reason to use the credentials from batch-pods anymore, so I use the one from default. This will need to go in before I can finish https://github.com/hail-is/hail/pull/7674",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7683:70,config,config,70,https://hail.is,https://github.com/hail-is/hail/pull/7683,3,['config'],['config']
Modifiability,"The asyncio event loop only keeps weak references to tasks, so wherever we call `asyncio.create_task` we need to ensure that we keep a strong reference to its result. Specifically, `BackgroundTaskManager` needs to keep strong references not weak references to the tasks it creates. This is easy to do without accumulating garbage by using a done callback on the task to remove itself from the set. However, this felt iffy with the threadsafe futures, which were only used in sync.py anyway, so I pushed that functionality directly into sync.py and removed it from the `BackgroundTaskManager`. To simplify the ownership story for tasks, this changes `BackgroundTaskManager` to *not* return the task and instead hold onto strong references. If a client wants a reference to the task it creates, it should call `asyncio.create_task` directly and manage the lifecycle of the spawned task. This required only a few small changes in worker.py since most of the codebase does not assign the result of `task_manager.ensure_future`. The only change that gave me pause was the handling of `mjs_fut`, whose lifetime is a little tricky since it is potentially passed to yet another task. I think this shows a general weakness in the handling of ownership and lifetimes in between the Job and Worker classes and think a larger refactor can make this less error-prone but is out of scope for this fix. So I'd appreciate an especially scrutinizing look at that piece of the code.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12692:1314,refactor,refactor,1314,https://hail.is,https://github.com/hail-is/hail/pull/12692,1,['refactor'],['refactor']
Modifiability,"The conceptual change here is we want to parameterize all batch related tables to have a new job group ID that I've set to **0** for the root job group. We need to make sure all future inserts / updates into the batches table are propagated to the new job groups table. When we create a batch now, we also create the corresponding entries into the job groups and job group parents tables. I chose the root job group to be 0 as I think conceptually, the client should start numbering job groups at 1 and not know there is a hidden root job group being created under the hood. I'm not wedded to this. I tried to check for all the indices that would be needed in my prototype. It's possible I missed one or two, but it's not a big deal to add it later. I don't think we need to test this on a populated database (dev deploy main, submit jobs, then run the migration), but let me know if you think that would be helpful.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13475:41,parameteriz,parameterize,41,https://hail.is,https://github.com/hail-is/hail/pull/13475,1,['parameteriz'],['parameterize']
Modifiability,The config flag batch/tmp_dir is now batch/remote_tmpdir,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13258:4,config,config,4,https://hail.is,https://github.com/hail-is/hail/pull/13258,1,['config'],['config']
Modifiability,The contents of ssl-config are not named after the service in question. See create_certs.py,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9257:20,config,config,20,https://hail.is,https://github.com/hail-is/hail/pull/9257,1,['config'],['config']
Modifiability,The correct thing is to expose the entrypoint in pipeline/batch_client and add it to the config for a job.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7558:89,config,config,89,https://hail.is,https://github.com/hail-is/hail/issues/7558,1,['config'],['config']
Modifiability,"The current main version of the Query Service uses a fresh class loader for every query. This means each driver job and worker job starts with uncompiled classes for any class in Hail. This change uses a shared class loader for all jobs with the same SHA. This enables use of previously JIT'ed Hail classes. This noticeably improves no-op performance from ~8 seconds to ~3 seconds. Most of that remaining 3 seconds is due to Query-on-Batch and Batch, not Query. Currently, Hail generates classes using a counter. When a driver or worker re-uses an old class loader, it would mistakenly re-use classes generated by a previous Hail Query-on-Batch job because they share the same name. This PR avoids that entirely by using a fresh class loader per job for *generated* classes. This PR parameterizes the entire Hail Query system by a class loader. This class loader is passed in from the initiator of the driver or worker job. We could, eventually, re-use class loaders:; - across jobs for a single batch; - across jobs for a single user; - across jobs for a single billing project; - across all jobs. I think the first three are somewhat uncontroversial but we need to fix the class naming problem. The fourth introduces a new security risk. I think we have a lot of performance to squeeze out of QoB before we need to take that step.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11212:783,parameteriz,parameterizes,783,https://hail.is,https://github.com/hail-is/hail/pull/11212,1,['parameteriz'],['parameterizes']
Modifiability,"The date time changes added `-target:jvm-1.8` to build.gradle which quietly; broke SBT. It wasn't a problem for me because I wasn't hacking on Hail until; recently. Moreover, [Ensime](https://ensime.github.io) is dead, so I'm switching over to; bloop. This plugin is necessary for SBT to generate bloop configuration files.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8683:257,plugin,plugin,257,https://hail.is,https://github.com/hail-is/hail/pull/8683,2,"['config', 'plugin']","['configuration', 'plugin']"
Modifiability,The environment variable was getting assigned after we setup the fluentd log parameters.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13726:16,variab,variable,16,https://hail.is,https://github.com/hail-is/hail/pull/13726,1,['variab'],['variable']
Modifiability,"The environment variables should be affecting `pytest`, not `cd`. `test_import_bed` just needs to use an `open` that can speak `gs://`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12536:16,variab,variables,16,https://hail.is,https://github.com/hail-is/hail/pull/12536,1,['variab'],['variables']
Modifiability,"The first few lines of a hail log look like:; ```; 2019-12-02 13:20:36 Hail: WARN: This Hail JAR was compiled for Spark 2.4.0, running with Spark 2.4.1.; Compatibility is not guaranteed.; 2019-12-02 13:20:36 SparkContext: INFO: Running Spark version 2.4.1; 2019-12-02 13:20:36 SparkContext: INFO: Submitted application: Hail; 2019-12-02 13:20:36 SparkContext: INFO: Spark configuration:; spark.app.name=Hail; spark.driver.extraClassPath=//miniconda3/envs/hail/lib/python3.7/site-packages/hail/hail-all-spark.jar; spark.executor.extraClassPath=./hail-all-spark.jar; spark.hadoop.io.compression.codecs=org.apache.hadoop.io.compress.DefaultCodec,is.hail.io.compress.BGzipCodec,is.hail.io.compress.BGzipCodecTbi,org.apache.hadoop.io.compress.GzipCodec; spark.hadoop.mapreduce.input.fileinputformat.split.minsize=0; spark.jars=file:///miniconda3/envs/hail/lib/python3.7/site-packages/hail/hail-all-spark.jar; spark.kryo.registrator=is.hail.kryo.HailKryoRegistrator; spark.logConf=true; spark.master=local[*]; spark.repl.local.jars=file:///miniconda3/envs/hail/lib/python3.7/site-packages/hail/hail-all-spark.jar; spark.serializer=org.apache.spark.serializer.KryoSerializer; spark.submit.deployMode=client; spark.ui.showConsoleProgress=false; ```. But the hail version string isn't here! That would be helpful. The full one with the hash. Rolled the dice, came up John.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7644:372,config,configuration,372,https://hail.is,https://github.com/hail-is/hail/issues/7644,1,['config'],['configuration']
Modifiability,"The goal of this PR is to have all of the JVM container logs available where all the worker logs are. I tagged the entries with ""worker.log"" so they show up with the other worker log entries. However, it's plain text with no timestamp. We can improve the formatting as a separate project. Notice the two entries with ""*"" on the left instead of the normal ""I"". The design choice I made is to have the JVM containers write to a location that is static. We cannot easily change the fluentd configuration dynamically. It requires restarting the daemon which takes 1.5 seconds. Furthermore, the configuration for fluentd is on /etc/ on the host which the batch worker container cannot access. Hence, why I took the approach of specifying it in the startup script at known locations. . Before we merge this, I'd like to confirm that (a) we want these logs and (b) they don't contain any secrets.; <img width=""1585"" alt=""Screenshot 2023-06-16 at 4 06 43 PM"" src=""https://github.com/hail-is/hail/assets/1693348/0ce9f7dc-1188-4c66-ae6f-83fcc3744f95"">",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13190:487,config,configuration,487,https://hail.is,https://github.com/hail-is/hail/pull/13190,2,['config'],['configuration']
Modifiability,"The idea is to allow the execution on both `SparkBackend` and `ServiceBackend` without code changes, simply switching to the Query service by setting the environment variables `HAIL_QUERY_BACKEND`, `HAIL_BILLING_PROJECT`, and `HAIL_BUCKET`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10189:166,variab,variables,166,https://hail.is,https://github.com/hail-is/hail/pull/10189,1,['variab'],['variables']
Modifiability,"The json output now has ""config"" and ""benchmarks"" top level fields",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6826:25,config,config,25,https://hail.is,https://github.com/hail-is/hail/pull/6826,1,['config'],['config']
Modifiability,"The main goal of this PR was to remove some of the vector/scalar logic from the BlockMatrixMap2 node, and to support the scalar operations on BlockMatrixMap. I basically accomplished this by taking the cases that are matched on in BlockMatrixMap2 and lifting them into the Simplify rules. The only endpoint that I believe I needed to cover was the BlockMatrix.pyExecute() one; all the others will go through the usual CompileAndEvaluate. There's another part of the PR that fixes the variable bindings, which are currently hard-coded and unchecked. I needed this to construct the right expressions for the IR expressions, so I changed it to handle variable bindings with the rest of our IR.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7566:484,variab,variable,484,https://hail.is,https://github.com/hail-is/hail/pull/7566,2,['variab'],['variable']
Modifiability,The match on method identity caused mismatches between the variable; stored in loaded across splits.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9947:59,variab,variable,59,https://hail.is,https://github.com/hail-is/hail/pull/9947,1,['variab'],['variable']
Modifiability,"The old bucket did not use uniform access control and also was multi-regional (us). I created a new bucket using the random suffix ger0g which has uniform access control. I also switched the location to us-central1 (not pictured here because that is a variable). I copied all the JARs from `gs://hail-query/jars` to `gs://hail-query-ger0g/jars` using a GCE VM. Again, global-config is not present in our terraform, so I'll have to manually edit that to reflect this new location: `gs://hail-query-ger0g`. The deployment process is:. 1. Edit global-config to reflect new bucket.; 2. Delete batch and batch-driver pods.; 3. Delete old workers. The rollback process (if necessary) is the same. Since this requires wiping the workers, I'll wait for a time when no one is on the cluster to do it. Any users using explicit JAR URLs will need to switch to `gs://hail-query-ger0g/...`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12969:252,variab,variable,252,https://hail.is,https://github.com/hail-is/hail/pull/12969,3,"['config', 'variab']","['config', 'variable']"
Modifiability,"The only real bitrot in the GCP terraform was the leftover `gsuite_organization` variable. This fixes that and also makes the zuliprc secret and ukbb module optional. The extra `fileexists` in the data block for the zuliprc is janky, but functions such as `file` are evaluated before the creation of the resource, so terraform will complain that about the file not existing without that extra guard there. I don't love it but ultimately want these to come from a cloud secret vault so it might look different soon enough anyway.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11319:81,variab,variable,81,https://hail.is,https://github.com/hail-is/hail/pull/11319,1,['variab'],['variable']
Modifiability,"The picture is from asm4s:; - Value[T] is convertible to Code[T] and can be used multiple times: it is a primitive value (constant, variable ref, etc.); - Code[T] can be used once; - Settable[T] extends Value[T] and has a store operation. Changes:; - rename PValue => PCode; - add PValue which is multi-use, PSettable extends PValue; - rename EmitTriplet => EmitCode; - add EmitValue and EmitSettable; - Removed type parameter from PValue and introduced downcast operators. I'm not really happy with either option. Will revisit this again in the future. Changes that are coming:; - add EmitMethodBuilder.newEmit{Local, Field} that return EmitSettables; - Emit.E will become Env[EmitSettable]. The goal here is to rip out jointpoint and ParameterPack. EmitSettables will replace the funtionality of ParameterPack for TypedTriplets (which will go away in favor of EmitTriplet/EmitCode). Removing joinpoint will cause problems when Code[T] are reused, so the Value types must be pushed throughout the codebase. I will put out what infrastructure I can as separate PRs, but I'm having a hard time finding way to do this incrementally.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8263:132,variab,variable,132,https://hail.is,https://github.com/hail-is/hail/pull/8263,3,"['extend', 'variab']","['extends', 'variable']"
Modifiability,"The problem was query was writing the job configuration to the query bucket, but workers only get the user gsa, so they were unable to read the configuration. This worked in the tests because the query and user account are both the test service account. I can remove the query-gsa-key and the hail-query bucket after this goes in.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8937:42,config,configuration,42,https://hail.is,https://github.com/hail-is/hail/pull/8937,2,['config'],['configuration']
Modifiability,"The real change here is changing the preemptible pool config from `preemptible = true` to `spot = true`, but the `spot` config was only available in the new provider which involved a major version upgrade. The only incompatibility was the addition of an explicit `project` input to `google_project_iam_member`, as opposed to picking it up from the provider configuration. Tested just now in my own project. If one wants to apply this change without incurring downtime for preemptible deployments, they should follow the instructions outlined in the [migrating node pools dev-docs](https://github.com/hail-is/hail/blob/main/dev-docs/kubernetes-operations.md#when-using-terraform).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12127:54,config,config,54,https://hail.is,https://github.com/hail-is/hail/pull/12127,3,['config'],"['config', 'configuration']"
Modifiability,The reducer should be parameterized as a keyword-only arg. `filter_missing` should become a keyword-only arg.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7107:22,parameteriz,parameterized,22,https://hail.is,https://github.com/hail-is/hail/issues/7107,1,['parameteriz'],['parameterized']
Modifiability,"The refactor in #14524, ironically to add more testing, accidentally dropped the query arguments when production CI filters by live namespaces. I'll follow up with more testing but CI is currently borked without this",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14549:4,refactor,refactor,4,https://hail.is,https://github.com/hail-is/hail/pull/14549,1,['refactor'],['refactor']
Modifiability,"The resulting rules are more succinct and correctly rely on file-system modification dependencies. - No use of `SPARK_HOME` and `PYTHONPATH`, and limited use of `PYSPARK_SUBMIT_ARGS`. Python tests now rely on the python package directly which handles correctly handles dependencies like `pyspark`. - There are also some phony targets for convenience: `jar`, `zip`, `pip-install`, `docs`, and `docs-no-test`. - Fix configuration of Spark version for the python package. The version is written by make into `python/spark_version` and read by `python/setup.py`. Many of the tests pass against 2.3.0, but there's some floating point value changes. - add breezeVersions for all currently released Spark versions greater than 2.2.0. - For developers, require python package `py` version 1.7.0 or later to allow `pytest` to test an installed package while loading the doctest expressions from the source code. (We could also determine where hail was installed and pass that path to pytest instead of `python/src`, but using the environment variable `PY_IGNORE_IMPORTMISMATCH` seems simple and safe enough). ---. ### Explainers. #### env_var.mk. This is a Makefile that is intended to be `include`d by other Makefiles. It defines a [multi-line variable](https://www.gnu.org/software/make/manual/html_node/Multi_002dLine.html) that [takes arguments](https://www.gnu.org/software/make/manual/html_node/Call-Function.html#Call-Function) (known in any reasonable language as a ""function""). It is intended to be used like this:. ```; VERSION = 30; $(eval $(call ENV_VAR,VERSION)). build: env/VERSION; build:; ... $(VERSION) ...; ```. Each time this Makefile is executed, at Makefile parse-time, `make` evaluates the `ifneq` to compare the current value of the variable to the previously used value (if any). If they differ, a phony (ergo always needs to be rebuilt) target is dynamically generated. That target will force a execution of any dependent targets, in the example above, it will force `build` to be exec",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5130:2369,variab,variable,2369,https://hail.is,https://github.com/hail-is/hail/pull/5130,1,['variab'],['variable']
Modifiability,The return value of these functions indicates if the containing loop; should wait or if we should immediately re-call the function. This; is intended to be used to allow functions which *know* they have more; work to eagerly invoke themselves again. The use of this variable seems to have been changed to basically always; eagerly re-run during the Azure work. This change restores the original behavior:; 1. Do not wait in job private if we saw 300 records (seems likely there were; 301 or more records in the db).; 2. Do not wait in pool scheduler if we exhaust a user's share. I do not; fully follow the pool scheduler's logic. There might be something; smarter we can do. I think we should really only re-call if we believe; the db contains more ready jobs and we have available cores.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11384:266,variab,variable,266,https://hail.is,https://github.com/hail-is/hail/pull/11384,1,['variab'],['variable']
Modifiability,"The root issue here was that sometimes exc.args[0] was a string and sometimes it was a dict. When it was a string the `in` condition worked fine. When it was a dict, it was looking at the keys of the dict and not finding the error message (which is buried under a few layers). The code was unnecessarily complex. I reworked the yaml printer to be simpler and work for any multiline string. I removed the regular expression that was used to discover the worker batch when the worker jobs were in a different batch from the driver jobs. I remove all specialized debugging information in favor of the general `debug_info` methods on `Batch` and `ServiceBackend`. I also have two clear error cases: if the driver does not write its output file, then something went horribly wrong. We dump all the debug info. If we do not receive valid JSON from the driver, again, something went horribly wrong. We dump all the debug info. The only remaining exceptional case is an error purposely serialized by the QoB driver to us (with or without an error id). In particular, note that we now completely ignore the number of failing or successful jobs. That doesn't matter. If the driver sends us an output file, we use the data found there. If the driver does not send us an output file or sends us an output file without valid JSON, we dump as much debug info as possible. cc: @tpoterba for visibility on your end; cc: @iris-garden because you're in this space (albeit, the bug you're fixing is in the QoB *driver* whereas this is the *client* [nb: *client* is the Python code which starts a batch with a *driver*. A *driver* adds zero or more *worker* jobs to its batch. You're addressing an issue with how the *driver* handles errors from the *workers*. This PR simplifies the logic for how the *client* handles errors from the *driver*.]).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12470:268,layers,layers,268,https://hail.is,https://github.com/hail-is/hail/pull/12470,1,['layers'],['layers']
Modifiability,"The semantics of setting a variable in make are kinda weird, example:. ```make; FOO := foo; BAR ?= bar; .PHONY: echo; echo:; 	echo $(FOO) $(BAR); ```. ```sh; $ FOO=baz make; echo foo bar; foo bar; $ make FOO=baz; echo baz bar; baz bar; $ BAR=baz make; echo foo baz; foo baz; ```. This will fix an issue where ci wasn't actually building with spark 3.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9556:27,variab,variable,27,https://hail.is,https://github.com/hail-is/hail/pull/9556,1,['variab'],['variable']
Modifiability,"The terraform sets `gcp_project` in the global-config not `project`. A few weeks ago I did a manual copy & rename of `project -> gcp_project`, `zone -> gcp_zone` etc. This is the follow-through for that conversion.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11036:47,config,config,47,https://hail.is,https://github.com/hail-is/hail/pull/11036,1,['config'],['config']
Modifiability,"The type of this RDD is rather complicated because we prepend a String to; an RDD of a universally quantified variable. `writeTextTable` works with any subtypes of AnyRef because it only requires; that the object defines `toString`. Ergo, we don't actually need to know; anything about the type parameter of the RDD. The explicit annotation; that I've added prevents Scala from inferring a complex type that cannot; be expressed without `forSome`. Such types trigger a warning from the; Scala compiler.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2705:110,variab,variable,110,https://hail.is,https://github.com/hail-is/hail/pull/2705,1,['variab'],['variable']
Modifiability,"The values of the global config are the same across namespaces, but it does feel more correct to use the `global-config` from the namespace you're targeting than the one in production. This should also enable `make` deploying into a dev namespace without having any permissions for `default`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13338:25,config,config,25,https://hail.is,https://github.com/hail-is/hail/pull/13338,2,['config'],['config']
Modifiability,"There are many global config fields that CI needs in order to template build.yaml jobs that are threaded through to CI with environment variables. However, these variables are never actually used by CI and they introduce some needless dependencies to run CI (you need a GCP_PROJECT, for example, even though CI doesn't care at all). Instead of setting specific environment variables for each field that build.yaml steps need, I instead mount the global-config (read-only) to the CI container and read in the whole thing. This does potentially expose more variables to the build.yaml environment than there were previously, but I argue that none of those should be sensitive anyway or maybe don't belong in the global-config (which shouldn't be sensitive). This in part makes the process of adding global config fields easier, since right now you need separate PRs to 1) introduce the field to CI and then 2) use it in a new build.yaml step. It also makes the CI deployment.yaml cloud-agnostic. . cc @jigold",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10911:22,config,config,22,https://hail.is,https://github.com/hail-is/hail/pull/10911,8,"['config', 'variab']","['config', 'variables']"
Modifiability,"There are many of occurences of k8s templating of variables like GCP project or domain that never change and exist in the global config. The process of adding a field to the global config sometimes then requires adding it to `config.mk`, then the jinja of a deployment template that needs it, and then templating that in the deployment.yaml. These are nearly always environment variables (but not always), which can and sometimes are read from kubernetes secrets. This is a sweep of every such occurence I could find so that these variables are just read directly from the k8s secret. Though it adds lines to the deployments, it reduces the complexity of our Makefile process and makes adding variables to the global config much easier. This also *dramatically* reduces the dependencies on `config.mk` and most of its variables. I think I'll address config.mk specifically in another PR, but I believe keeping it from ballooning with multi-cloud configuration will be valuable in keeping the complexity of our build/deployment system in check.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10869:50,variab,variables,50,https://hail.is,https://github.com/hail-is/hail/pull/10869,12,"['config', 'variab']","['config', 'configuration', 'variables']"
Modifiability,"There are many things wrong here. The Hadoop configuration is not copied per HadoopRDD operation. Proof:. ```; >>> import hail as hl; >>> hl.init(min_block_size=0); >>> t = hl.import_table('test.tsv.bgz', impute=True, min_partitions=8); >>> t.n_partitions(); 8; >>> t = hl.import_table('test-bgz.tsv.gz', impute=True, min_partitions=8); >>> t.n_partitions(); 1; ```. where `test-bgz.tsv.gz` is a bgz in gz's clothing. This is compounded by the fact that SparkContext.hadoopFile is not invoked until TableIR.execute is run making HailContext.forceBGZ() completely ineffective. One option is turning on spark.hadoop.cloneConf, that appears to clone the Hadoop configuration (to avoid some multithreading issues) although the docs don't recommend it due to ""performance regressions"". I haven't tested it. The other option is stop using the Hadoop stuff so we can pass state into the file loaders. Doing that for text files/line splitting is a bit nasty, but it would mean we could properly fix this gz/bgz business once and for all (look at the GZ header to see if it is block gzip'ed).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/3861:45,config,configuration,45,https://hail.is,https://github.com/hail-is/hail/issues/3861,2,['config'],['configuration']
Modifiability,"There was a bug converting Call to/from Java, in this line:. if annotation:. A call is represented by a 0 integer which is False in Python. I; changed all of these to `if annotation is not None`. Also, there was a bit of confusion in the call interface inherited; from genotype. A not call is just a missing Call value (in python); and a null Call = java.lang.Integer (in Java).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2474:253,inherit,inherited,253,https://hail.is,https://github.com/hail-is/hail/pull/2474,1,['inherit'],['inherited']
Modifiability,There was an extra check in the where statement for the token matching on the jobs billing table. The jobs billing table is the only one not parameterized with a token.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12942:141,parameteriz,parameterized,141,https://hail.is,https://github.com/hail-is/hail/pull/12942,1,['parameteriz'],['parameterized']
Modifiability,"There's a few things happening here:. ### Node pool updates through terraform; I extended the node pool update documentation with how to deal with terraform-managed node pools. This is what I did on Azure and worked fine. The only real change in terraform other than changing the machine type is making the node pool name configurable to adhere to the naming guidelines and allow us to do a rolling migration. ### Updated the kubernetes and azurerm providers; I updated the azurerm provider without thinking much about it and even though it's a minor version had some breaking changes that after a half-successful `apply` made it hard to downgrade. So I decided just to appease the breaking change and leave us at the new version, which is what all the `blob_properties` changes are for. They are in no way related to the node pools. ### Troubleshooting; I added a section for a bug that I've seen a couple of times (and encountered again today) but never documented how I got around it.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11636:81,extend,extended,81,https://hail.is,https://github.com/hail-is/hail/pull/11636,2,"['config', 'extend']","['configurable', 'extended']"
Modifiability,There's a kind of unrelated thing: Fix reading of configuration information to not ignore a hailctl configuration value of `''` . The big change is to introduce 3 progress bar systems:; 1. SimpleRichProgressBar. One progress bar active at a time.; 2. RichProgressBar. More than one progress bar active at a time.; 3. BatchProgressBar. Same as RichProgressBar but with default columns good for monitoring 1 or more Hail Batch batches.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12346:50,config,configuration,50,https://hail.is,https://github.com/hail-is/hail/pull/12346,2,['config'],['configuration']
Modifiability,"These are the alterations that Jackie and I made to be able to add a developer account to a dev namespace. If the namespace isn't default then it grabs the credentials for the user from default instead of creating a new credential. I don't like that the extra config lives on the branch but this is how it is otherwise supported in bootstrap.py, and ultimately we should just use the auth account to hit the auth endpoint and delete the `create_initial_account` script entirely.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11115:260,config,config,260,https://hail.is,https://github.com/hail-is/hail/pull/11115,1,['config'],['config']
Modifiability,"These changes are a prerequisite for introducing a mysql DB pod for every test and dev namespace. The crux of such a change is any CreateDatabase steps should use the `database-server-config` from *its own namespace* (which will come in the PR that uses this step) and not from default. There's no cleanup step required because this will be used to create DBs inside the namespace for the pipeline, so resources will get cleaned up with the namespace. The other changes in this step bring the configuration for `dev` scopes closer to that of `test` scopes, because creation of test databases should really just be idempotent and there shouldn't be a difference between deploying a database in dev and test. I would have deferred making the changes to the `dev` scope except dev deploy was the most practical way for me to test this change.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13022:184,config,config,184,https://hail.is,https://github.com/hail-is/hail/pull/13022,2,['config'],"['config', 'configuration']"
Modifiability,"These changes are mostly because mypy now needs all `None` parameters to be explicit optionals, whereas before it would let something like `def foo(arg: str = None)` slide. The `type: ignore` on the azure client call is an azure library bug, I looked into the source for that function and there's a comment saying that the input is an `Optional[int]` but the type stubs that mypy is picking up say `int`. the `check_untyped_defs` config flag tells mypy to typecheck the bodies of functions that do not have a type signature, which apparently it wasn't doing on its own.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12447:430,config,config,430,https://hail.is,https://github.com/hail-is/hail/pull/12447,1,['config'],['config']
Modifiability,"These changes enable hailctl clusters to work correctly in an Broad GCP Security Best Practices configured project, with minor hail-specific set-up. See further details in team chat.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7978:96,config,configured,96,https://hail.is,https://github.com/hail-is/hail/pull/7978,1,['config'],['configured']
Modifiability,"These improvements would help for QC on trio data, and for exploring new variant quality models exploiting inheritance. .mendelI (nError per individual) should be an integer-valued sample annotation. We might also be interested in nError per trio, as sample annotation on child of trio. .mendelL (nError per locus, really variant) should be an integer-valued variant annotation. .mendel lists all errors. Each error has a unique (trio, variant). It's natural to ask for all variants where a trio has errors, and also for all trios in which a variant has an error. Perhaps the list of errors per variant should be a variant annotation from which all other annotations are derived. Note that if variants are distributed in intervals, this annotation won't be well-balanced as difficult-to-sequence regions will have far more error. .mendalF (nError per nuclear family) could be sample-keyed by the mother",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/597:107,inherit,inheritance,107,https://hail.is,https://github.com/hail-is/hail/issues/597,1,['inherit'],['inheritance']
Modifiability,"These top-shelf methods make applying the LinearMixedModel class as easy as 1-2-3:; 1: create model from matrix table expressions (and possibly kinship matrix) ; 2: fit model; 3: test each row of matrix table using fit model. E.g., using markers as random effects:; ```; mt0 = dataset.filter_rows(mt.use_as_marker); model, _ = hl.linear_mixed_model(y=mt0.height, x=[1, mt0.sex], z_t=mt0.n_alt_alleles(), p_path='p.bm'); model.fit(); mt = hl.linear_mixed_regression(mt.n_alt_alleles(), model); ```. E.g., using any ndarray kinship matrix:; ```; model, _ = hl.linear_mixed_model(y=mt0.height, x=[1, mt0.sex], k, p_path='p.bm'); model.fit(); mt = hl.linear_mixed_regression(mt.n_alt_alleles(), model); ```. This required smaller changes to LinearMixedRegression class, particularly adding `p_path` as a member variable and to all constructors. I've also modified and run `doctest_write_data.py` which rebuilt the datasets, accounting for the large binary file count (I can factor this out as it's own pre-PR if you prefer). I renamed `from_mixed_effects` to `from_random_effects` since a mixed model has fixed and random effects, and `z` is the random ones.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4191:807,variab,variable,807,https://hail.is,https://github.com/hail-is/hail/pull/4191,1,['variab'],['variable']
Modifiability,They use the deprecated AST interface. Rewrite in terms of Table interface.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3738:39,Rewrite,Rewrite,39,https://hail.is,https://github.com/hail-is/hail/pull/3738,1,['Rewrite'],['Rewrite']
Modifiability,"This PR adds `utils/StackSafe.scala`, which contains generic tools for writing stack safe code. To illustrate its use, I've converted `NormalizeNames` and `RewriteBottomUp` to be stack safe. This approach optimizes for the minimal possible change to existing code to make it stack safe. I originally expected this to have mediocre performance, and designed this to have optimization opportunities--requiring more substantial rewrites--where we found it was necessary. In a follow up PR, I converted the IR parser to be stack safe. In benchmarking that, I'm not able to see any performance penalty (if anything, the stack safe version looks slightly faster, which is probably just noise). So it's possible this will perform well enough as is, but we can keep an eye on it as we convert more passes. The basic idea is to rewrite functions that can be called recursively (directly or indirectly through a path of mutually recursive functions) from `f: (...) => A` to `f: (...) => StackFrame[A]`. Where the former evaluates, executing all recursive calls, and then returns the `A` result, the later returns a description of the work to be done before making any recursive calls. The method `StackFrame[A].run(): A` executes that description in a non-recursive loop. `StackFrame` is a monad, implementing `map` and `flatMap`, which allows the `for` syntactic sugar to be used. When a method makes several recursive calls, this can be significantly more readable. The public api is small. There are the free functions; ```scala; def done[A](result: A): StackFrame[A]; def call[A](body: => StackFrame[A]): StackFrame[A]; ```; and the methods; ```scala; abstract class StackFrame[A] {; def flatMap[B](f: A => StackFrame[B]): StackFrame[B]; def map[B](f: A => B): StackFrame[B] = flatMap(a => Done(f(a))); def run(): A; }; ```; `done` is basically the return statement. `call` is very important: it wraps a recursive call in a thunk, so that returning a `StackFrame` doesn't require descending all the way to t",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9320:156,Rewrite,RewriteBottomUp,156,https://hail.is,https://github.com/hail-is/hail/pull/9320,3,"['Rewrite', 'rewrite']","['RewriteBottomUp', 'rewrite', 'rewrites--where']"
Modifiability,"This PR adds a new column to the `resources` table (resource_id) as well as to the `attempt_resources` table. The `resource_id` represents the mapping from the string resource name to an integer identifier. To make this migration work, we first need to add the new columns to the corresponding tables along with a new trigger. The trigger makes sure any writes that occur after we start populating the older values will have the new resource_ids filled into the `attempt_resources` table. I decided to not convert the `attempt_{batch, job,billing_project}_resources` tables to have the resource_id because we'll drop them anyways in the future and it was adding 75% more time to the migration. My original script had the updates happening to all tables, hence why there's overkill for the way it's structured. I can try and refactor the code back to the way it was before if you'd like. The code to insert into the `attempt_resources` table in `job.py` needs to insert both the resource and the resource_id because we do not want to rely on the new trigger for adding the resource_id to the record so we can remove the resource column later on.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12028:824,refactor,refactor,824,https://hail.is,https://github.com/hail-is/hail/pull/12028,1,['refactor'],['refactor']
Modifiability,"This PR adds environment variable options to skip tests requiring plink/Rscript executables. - If `HAIL_TEST_SKIP_PLINK` is set, skip tests requiring the `plink` binary.; - If `HAIL_TEST_SKIP_R` is set, skip tests requiring `RScript`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5123:25,variab,variable,25,https://hail.is,https://github.com/hail-is/hail/pull/5123,1,['variab'],['variable']
Modifiability,"This PR adds the job groups functionality as described in this [RFC](https://github.com/hail-is/hail-rfcs/pull/5) to the Batch backend and `hailtop.batch_client`. This includes supporting nested job groups up to a maximum depth of 5. Note, that none of these changes are user-facing yet (hence no change log here). The PRs that came before this one:; - #13475 ; - #13487 ; - #13810 (note that this database migration required a shutdown). Subsequent PRs will need to implement the following:; - Querying job groups with the flexible query language (v2); - Implementing job groups in the Scala Client for QoB; - Using job groups in QoB with `cancel_after_n_failures=1` for all new stages of worker jobs; - UI functionality to page and sort through job groups; - A new `hailtop.batch` interface for users to define and work with Job Groups. A couple of nuances in the implementation came up that I also tried to articulate in the RFC:; 1. A root job group with ID = 0 does not belong to an update (""update_id"" IS NULL). This means that any checks that look for ""committed"" job groups need to do `(batch_updates.committed OR job_groups.job_group_id = %s)` where ""%s"" is the ROOT_JOB_GROUP_ID.; 2. When job groups are cancelled, only the specific job group that was cancelled is inserted into `job_groups_cancelled`. This table does **NOT** contain all transitive job groups that were also cancelled indirectly. The reason for this is we cannot guarantee that a user wouldn't have millions of job groups and we can't insert millions of records inside a single SQL stored procedure. Now, any query on the driver / front_end must look up the tree and see if any parent has been cancelled. This code looks similar to the code below [1].; 3. There used to be `DELETE FROM` statements in `commit_batch_update` and `commit_batch` that cleaned up old records that were no longer used in `job_group_inst_coll_cancellable_resources` and `job_groups_inst_coll_staging`. This cleanup now occurs in a periodic loop on",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14282:524,flexible,flexible,524,https://hail.is,https://github.com/hail-is/hail/pull/14282,1,['flexible'],['flexible']
Modifiability,"This PR attempts to simplify the use of TLS and HTTP(S) in Hail. The big changes; are in `hail/python/hailtop`. In particular I removed several functions with; confusingly overlapping functionality in `tls.py`. Instead, we now have three; functions:. - `internal_server_ssl_context`; - `internal_client_ssl_context`; - `external_client_ssl_context`. The client context is configured to seek certificates from its peers. Both; internal contexts load the Hail certificate chain specified in the Hail SSL; Config. The external client context does not load the hail certificate chain. I intend all Hail's HTTP(S) requests to use `httpx.py` (so named to not conflict; with modules named `http`). Again, I have simplified the landscape. We now have; two functions:. - `httpx.client_session`: The constructor for all asynchronous, HTTPS client; sessions.; - `httpx.blocking_client_session`: The constructor for all synchronous, HTTPS; client sessions. Both sessions have the exact same configuration parameters. The API is exactly; the same except the blocking client session replaces asynchronous methods with; synchronous ones. Both sessions accept the `aiohttp.ClientSession` constructor parameters. They; support one new parameter and modify the behavior of one old parameter.; - `retry_transient`: when set to `True` this parameter will retry all transient; errors in all requests made by this session. This defaults to `True`.; - `raise_for_status`: this parameter now defaults to `True` and includes the; response body text in the error message. Both; Both parameters may be overridden on a per-request basis. - `httpx.ResponseManager` and `httpx.ClientSession` work together to enable; `retry_transient` and `raise_for_status`. Aiohttp has this unusual structure where; all the request methods are synchronous but they return an object that is both; awaitable and an async context manager. I mirror their structure exactly. The; `httpx.ResponseManager` is both awaitable and an async context manager.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9554:372,config,configured,372,https://hail.is,https://github.com/hail-is/hail/pull/9554,3,"['Config', 'config']","['Config', 'configuration', 'configured']"
Modifiability,"This PR changes our vep init scripts to pull from the new `hail-us-vep` google bucket, which is requester pays. . I realized while doing this that my previous PR (#8253) really had nothing to do with supporting this, since that really just sets the configuration for the Google Cloud / Hadoop connector, which is not how we get vep data. I tried to enforce the rules from those command line arguments anyway by rejecting `--vep` flag if they don't specify they're ok with requester pays and manually checking that `hail-us-vep` was in their approved bucket list. But if a user was to specify the init scripts using `gcloud dataproc` and didn't go through `hailctl`, there'd be no catch to check if they were ok with requester pays. Perhaps there is some way we could set environment variables on the dataproc machines based on the `--requester-pays-allow....` flags and use those in the init scripts. I also expanded `make test-dataproc` to test with a GRCh38 cluster as well, as we use separate scripts to make them and I'm uncomfortable with only testing one.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8268:249,config,configuration,249,https://hail.is,https://github.com/hail-is/hail/pull/8268,2,"['config', 'variab']","['configuration', 'variables']"
Modifiability,"This PR enables shuffling in the service. It is stacked on several other PRs, so look only at the; most recent commit. Some highlights:; - Open the public network back up. We should probably make query jobs special so that they can; access the internal network. To do that, batch would need to accept a ""acting on behalf of"" user; account: Query submits the job using its account ""acting on behalf of"" the user. Batch allows; query to use the private network, but for all other purposes, the job is owned by the user. - Allow public access to some the `gcr.io/hail-vdc/query` Docker image. - Automatically rewrite uses of `hailgenetics/` Docker images to their `gcr.io` equivalents. - Move `deploy_address` above `deploy_query` so that query can depend on address (necessary for; shufles). - Fix logging configuration. Services team wants all logs all the time to go to stdout. - Implement lowerDistributedSort using the shuffler. - Allow shuffle ids to be encoded so they can be used in `Literal`.; Unified Split",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9848:606,rewrite,rewrite,606,https://hail.is,https://github.com/hail-is/hail/pull/9848,2,"['config', 'rewrite']","['configuration', 'rewrite']"
Modifiability,"This PR extends #1902, merge that one first. Now, 50% of the time a type is a Scalar type rather than a recursive one. Additionally, this PR adds a generator for pairs of types and values of that type. Here's a few samples:; ```scala; t Struct{; W: Call,; GL: Genotype,; nsfJ: Long,; tiX0pLA: Int,; B7vWAW: Call,; a6_mm: Boolean,; AGS1Eh: Interval,; tqbHQbDv: Dict[AltAllele, Long],; HUh: Set[Double],; Xgb26Wlws: Double,; qe_XlLJt7_X: Dict[Double, Int],; U: Array[Call],; j: Double; }; v [ 1; , 5/6:.:.:.:GP=0.0,0.0,6.103515625E-4,0.0,0.0,0.0,0.0,0.00286865234375,0.0,0.058441162109375,0.0,0.0,0.0,0.00567626953125,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.004730224609375,0.153839111328125,0.0,0.0,0.0,0.704742431640625,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.018402099609375,0.050689697265625,0.0,0.0,0.0,0.0,0.0,0.0,376902925948550232; , 2147483647; , 1; , true; , 15:396751431-18:1945111790; , Map(GT/C -> -9223372036854775808, GC/TGTG -> 0, GTCAC/AC -> 1, TCG/G -> -2853243060319614448, TTTG/G -> 0); , Set(0.0, 1.2590508536333097E308, -26.66700965052354, -1.0, 1.7976931348623157E308); , -44.18866673875504; , Map(4.9E-324 -> 1069254047, -29.21881886290265 -> 0, -7.511481628119398E307 -> -51783790, 78.3075905923555 -> -1679218199, -1.0 -> -1476797686, 66.69344244874847 -> -2147483648, -74.87563451361888 -> -50, 8.529797881337316E306 -> -38); , WrappedArray(2, 2, null, 2, 2, 1); , 1.7044473544408425E308; ]; ```; ```scala; t Struct{; jHUkH: Interval,; c: Struct{; EZyb77: Boolean,; qckA6k: Empty; },; K: Interval,; X: Locus,; BuujVaardN: Call,; drTH1J: Set[Locus],; DJL9uj7D: Variant,; vwuq: Set[Int],; cKAObAm1oh7: Boolean,; FqhLLOlV4p: Struct{; Ri631ZK2TiA: Empty; },; vtQ: Set[String],; HzHvw: Locus,; g: Double,; inwJHuBmLUM: Boolean,; Q: Float,; i: Genotype,; q: Float,; p_Wmn2Q: Variant,; Y6foXEa7F: Dict[Set[Float], Double],; SuXouO__uX: Int,; hrfM: Locus,; k: Variant,; V1WzY: Struct{; xWj: Struct{; bg: AltAllele; }; },; L3Ol_: Call,; Bmt: Variant,; EExpF_H: Struct{; DyAZQ1pL: Empty; },; JS",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1903:8,extend,extends,8,https://hail.is,https://github.com/hail-is/hail/pull/1903,1,['extend'],['extends']
Modifiability,This PR extends a previous PR that added g2-standard-4 machines into batch by adding the full machine family. The code adds a new Accelerator Resource that takes the number of gpus.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14519:8,extend,extends,8,https://hail.is,https://github.com/hail-is/hail/pull/14519,1,['extend'],['extends']
Modifiability,This PR extends environment variable options to skip Scala tests requiring plink/Rscript executables.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5126:8,extend,extends,8,https://hail.is,https://github.com/hail-is/hail/pull/5126,2,"['extend', 'variab']","['extends', 'variable']"
Modifiability,"This PR incorporates @cseed 's changes from #3477, brings everything up to date with master, and adds/fixes the following:; - added a test for linreg with no covariates against R, and deleted old `test_linear_regression_with_no_cov` since that still had intercept.; - extended Skat to work without covariates and added test that it runs, but it’s hard to test result against R given that the latter fails with no covariates: `Error in solve.default(t(X1) %*% X1) : 'a' is 0-diml`. The result look ""reasonable"" to me.; - added req of at least one covariate for logreg in doc and code. It's going to be painful to get logistic to take no covariates, we can always come back to it if priority goes up. Related fun breeze behavior: `a(::, *) *:* b` with `a` an `(n, 0)` matrix and `b` an `n`-vector has dimensions `(0, 0)`.; - removed default value of empty list for `covariate`, both to help signal users to consider putting in the intercept (pipelines currently using intercept only with default empty `[]` will break) and because empty is not currently valid for logreg.; - noted in docs that intercept must be included explicitly.; - added comment of R code against which linreg and logreg are testing",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4067:268,extend,extended,268,https://hail.is,https://github.com/hail-is/hail/pull/4067,1,['extend'],['extended']
Modifiability,"This PR introduces a new type `Name` for representing bound variables in the IR, replacing `String`. For now, it is just an `AnyVal` wrapper around `String`, but in the future I would like to take advantage of the new type. For example, I'd like to:; * change equality of `Name` from string comparison to comparing object identity with `eq`. That way `freshName` becomes just `new Name()`, with stronger guarantees that the new name doesn't occur anywhere in the current IR, without needing to maintain global state as we do now.; * get rid of `NormalizeNames`, instead enforcing the global uniqueness of names as a basic invariant of the IR (typecheck could also check this invariant); * keep a string in the `Name`, but no longer require it to be unique. Instead it's just a suggestion for how to show the name in printouts, adding a uniqueifying suffix as needed. With `NormalizeNames` gone, this would let us preserve meaningful variable names further in the lowering pipeline.; * possibly keep other state in the `Name`, for example to allow a more efficient implementation of environments, similar to the `mark` state on `BaseIR`. This is obviously a large change, but there are only a few conceptual pieces (appologies for not managing to separate these out):; * attempt to minimize the number of locations in which the `Name` constructor is called, to make future refactorings easier; * add `freshName()`, which just wraps `genUID()`, returning a `Name`; * convert IR construction to use the convenience methods in `ir.package`, which take scala lambdas to represent blocks with bound variables, instead of manually creating new variable names; * replace uses of the magic constant variable names (`row`, `va`, `sa`, `g`, `global`) with constants (`TableIR.{rowName, globalName}`, `MatrixIR.{rowName, colName, entryName, globalName}`); * the above changes modified the names we use for bound variables in many places. That shouldn't matter, but it cought a couple bugs where it did.; * `Normal",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14547:60,variab,variables,60,https://hail.is,https://github.com/hail-is/hail/pull/14547,2,['variab'],"['variable', 'variables']"
Modifiability,"This PR is a step towards a general picture for generating debugging information in bytecode. The general picture is to write a sequence of files, each corresponding to a certain point in the compile pipeline, where each line in each file includes a line number pointing to the line in the previous file from which this line was derived. (We may eventually want richer source information than just a single line number, like a range or list of ranges.) The top of each file has the file name of the previous printout, which is the target of all line numbers in the file. We could in the future also print a list of transformations that were applied to get from the previous printed state to this one. The idea to implement this picture is simple. Each IR node stores a line number in a mutable variable. When we want to generate a printed checkpoint, we walk the IR, printing a representation of each node, including the stored line number, and then overwriting the node's line number with the current line count of the file being written to. Some work will be required to preserve this source information in all IR transformations. This PR implements this idea in lir only. If the `HAIL_WRITE_IR_FILES` environment variable is set, it is hardcoded to print the lir after the first `SimplifyControl` (because before that is very hard to read), and after method splitting right before emitting bytecode. It also prints out the class files themselves. Longer term we'll want to be able to control which points in the compilation get printed.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9521:794,variab,variable,794,https://hail.is,https://github.com/hail-is/hail/pull/9521,2,['variab'],['variable']
Modifiability,"This PR is to enable `hail-az;` file references to contain SAS tokens to enable bearer-auth style file access to Azure storage. Basic summary of the changes:; 	- Update `AzureAsyncFS` url parsing function to look for and separate out a SAS-token-like query string. Note: made fairly specific to SAS tokens - generic detection of query string syntax interferes with glob support and '?' characters in file names; 	- Added `generate_sas_token` convenience function to `AzureAsyncFS`. Adds new `azure-mgmt-storage` package requirement.; 	- Updated `AzureAsyncFS` to use `(account, credential)` tuple as internal `BlobServiceClient` cache key; 	- Updated `AzureAsyncFSURL` and `AzureFileListEntry` to track the token separately from the name, and extend the base classes to allow returning url with or without a token ; 	- Update `RouterFS.ls` function and associated `listfiles` function to allow for trailing query strings during path traversal ; 	- Change to existing behavior: `LocalAsyncFSURL.__str__`no longer returns 'file:' prefix. Done to make `str()` output be appropriate for input to `fs` functions across all subclasses; 	- Updated `inter_cloud/test_fs.py` to generically use query-string-friendly file path building functions; - Updated InputResource to not include the SAS token as part of the destination file name . `test_fs.py` has been updated to respect the new model, where it is no longer safe to extend URLs by just appending new segments with + ""/"" because there may be a query string. But actually running those tests for the SAS case will require some new test variables to allow the test code to generate SAS tokens (`build.yaml/test_hail_python_fs`): ; ```; export HAIL_TEST_AZURE_ACCOUNT=hailtest; export HAIL_TEST_AZURE_CONTAINER=hail-test-4nxei; # Required for SAS testing on Azure; export HAIL_TEST_AZURE_RESGRP=hailms02; export HAIL_TEST_AZURE_SUBID=12ab51c6-da79-4a99-8dec-3d2decc97343; ```; So the SAS case is disabled for now (`test_fs.py`):; ```; @pytest.fixture(param",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12877:743,extend,extend,743,https://hail.is,https://github.com/hail-is/hail/pull/12877,1,['extend'],['extend']
Modifiability,"This PR makes a number of changes to reduce the overhead of the interpreted `TableAggregate` in general, plus a couple of tweaks to `ApproxCDFCombiner` to eliminate sources of boxed primitives. The main changes are:; * Make `RegionMemory` track the number of Java objects being held, and include that in the log.; * Make the combOp in `TableAggregate` interpreter operate directly on `RegionValue`s. It modifies and returns the left state, and frees the right one.; * To generate the combOp function, I had to compile a function with two agg states (instead of concatenating two `TupleAggregatorStates`, which must live in a single region). That meant not using the `CombOp` IR node. I couldn't quite get rid of the `CombOp` node completely, because I don't understand how it's being used in `Aggregators2Suite` well enough to rewrite it, but that is now the only use.; * In `TableAggregate`, work with `RDD[WrappedByteArray]` instead of `RDD[Array[Byte]]`, to allow the incoming `Array[Byte]` to be GCed as soon as we have decoded it.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8794:827,rewrite,rewrite,827,https://hail.is,https://github.com/hail-is/hail/pull/8794,1,['rewrite'],['rewrite']
Modifiability,This PR makes a small change to `build.gradle` so that the Eclipse gradle project plugin will import the project correctly.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4334:82,plugin,plugin,82,https://hail.is,https://github.com/hail-is/hail/pull/4334,1,['plugin'],['plugin']
Modifiability,"This PR makes the following changes:; * Add a `separateRegions` flag to `PStream`.; * Add a `separateRegions` flag to the stream producer nodes `MakeStream`, `StreamRange`, and `ToStream`.; * Propogate `separateRegions` through all stream nodes in `InferPType`. The intended semantics is that if a stream's type has the `separateRegions` flag set, its consumer must pass it a region which gets cleared every element. If the flag is not set, there is no requirement; depending on context, the consumer may put every element in the same region, but is also allowed to use separate regions for each element. For example, in a zip, the elements of the zipped stream are put in separate regions iff at least one child stream requires separate regions; in that case, all children will get emitted with separate regions, whether they requested it or not. In this PR, the `separateRegions` flags are left unused. Eventually, stream consumers will inspect the flag on their child streams' types, and use that information to construct the appropriate `StagedRegion` to pass to `emitStream`. In implementing that, I did some refactoring of the `StagedRegion` design, which I separated out into a follow-up PR.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9388:1114,refactor,refactoring,1114,https://hail.is,https://github.com/hail-is/hail/pull/9388,1,['refactor'],['refactoring']
Modifiability,"This PR pushes aggregators much closer to where we want; them to be with regardes to SCodes/STypes. Here are the; important conceptual changes:; 1. Aggregators are no longer parameterized by the ptypes; of seqop and initop args. Instead, the state signature; contains a sequence of VirtualTypeWithRequiredness, which; is exactly what its name says. Aggregators use ptypes; internally, but this is not in the state signature.; 2. As a consequence of 1), we no longer cast argument types; to seqop/initops. We are still able to, for instance,pass a seqop; argument of a different type than the container type to; the collect aggregator because the collect aggregator accepts; an SCode argument, and uses the appropriate PType constructor to; store that SCode (with a possible conversion if necessary, as here).; 3. We codebuilder-ify most of the aggregator package. There are some; straggling bits, but I will clean that up in a followup since the; time to get a change in will scale super-linearly with its size. Benchmarks forthcoming. Agg SCodes hopefully done",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9868:174,parameteriz,parameterized,174,https://hail.is,https://github.com/hail-is/hail/pull/9868,1,['parameteriz'],['parameterized']
Modifiability,"This PR refactors the `Binds.scala` file, which encodes the binding structure of the IR. The binding structure controls what variable bindings are in scope in each location of the IR. The encoding specifies, for each node `x` and each child `c` of `x`, how does the environment (the set of bindings which are in scope, and their types) of 'x' differ from the environment of `c`. For instance, `c`'s environment might add a new bindings (e.g. in the body of a `StreamMap`), or it might drop all bindings, isolating the child, so that it cannot refer to anything bound outside of `x` (e.g. all relational nodes). The binding structure is complicated by the separation of the environment into ""eval"", ""agg"", ""scan"", and ""relational"" scopes. The child `c`'s environment might add new bindings in any of these scopes, and it might modify the parent's environment in other ways, like replacing the ""eval"" scope with the ""agg"" scope. In `Binds.scala`, the encoding of this relationship between parent's and child's environments was split across many methods, separately encoding bindings added to each of the scopes, and a prior modification to the parent scope. This made it difficult to understand the binding behavior of any particular node. And for nodes with more complicated binding behavior, these separate encodings became confusingly entangled. In this PR, `Binds.scala` is rewritten so that the binding behavior of a node is specified in a single place. Instead of computing a list of new bindings, it simply takes the parent's environment and returns the child's. Some use cases do require knowing what new bindings are added by a node in a child's environment. To support this, I made the `BindingEnvironment` interface a trait, and added another implementor `SegregatedBindingEnv`, which wraps two separate `BindingEnvironment`s, and puts all new bindings into the second. This satisfies the invariant that for any function `f(GenericBindingEnv): GenericBindingEnv` which modifies an environment",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14404:8,refactor,refactors,8,https://hail.is,https://github.com/hail-is/hail/pull/14404,2,"['refactor', 'variab']","['refactors', 'variable']"
Modifiability,This PR refactors the aioclient to merge the functionality of Batch and BatchBuilder into just a single Batch object. The reason for making this change is to make adding job groups simpler. I will follow up with a change to Jobs after this merges. I apologize for the number of line changes. Most are just renaming `bb -> b` in the tests.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13458:8,refactor,refactors,8,https://hail.is,https://github.com/hail-is/hail/pull/13458,1,['refactor'],['refactors']
Modifiability,"This PR rewrites the hailctl command line argument parsing code. While the interface remains largely the same, a few changes were made to how options are handled. We first introduce a bit of terminology. In a shell command invocation like `$ cmd a -o c`, `a`, `-o` and `c` are called parameters. `a` and `c` which do not start with dashes, are called arguments. `-o`, which starts with a dash, is an option. This PR makes the following changes:. - For dataproc commands taking extra gcloud parameters, all parameters after a double-dash (--) are passed to gcloud.; - The actual rule is slightly more complicated, but I think the above rule is the right take away. In detail, extra parameters are passed to gcloud. Unknown options (starting with a dash) before `--` are reported as an error. So arguments (not options) before `--` and all parameters after are passed to gcloud. ; - Short options don't need a `=` when specifying a value. It is now `-p2`, not `-p=2`.; - While I was making breaking changes, I changed `dataproc submit` `--gcloud_configuration` to `--gcloud-configuration`. I am happy to undo this one.; - Group arguments must go before the next command. Write `hailctl dataproc --beta start ...` not `hailctl dataproc start --beta ...`, which is an error since `start` has no option `--beta`. This PR rewrites argument parsing to use click instead of argparse: https://click.palletsprojects.com/en/7.x/. Things you need to know about click:; - A group is a group of commands or subgroups, like `hailctl dataproc`, `hailctl batch`, etc. Groups are defined like this:; ; ```; @hailctl.group(; help=""Manage the Hail Batch service.""); def batch():; pass; ```; - A command in a group is defined like this:. ```; @batch.command(; help=""Get a particular batch's info.""); @click.argument('batch_id', type=int); @click.option('--output-format', '-o',; type=click.Choice(['yaml', 'json']),; default='yaml', show_default=True,; help=""Specify output format"",); def get(batch_id, output_format):; ..",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9842:8,rewrite,rewrites,8,https://hail.is,https://github.com/hail-is/hail/pull/9842,1,['rewrite'],['rewrites']
Modifiability,"This PR supersedes #9146, sets ndarray slicing behavior to follow ndarray/python semantics when out of bounds: upper_bound = len_dim if step > 0 else len_dim - 1, lower_bound = 0 if step > 0 else -1 (since our -1 has the effect of a slice bound that is None). The other PR doesn't clamp dimensions properly (min and max out of bounds for start and stop are identical), and missed a 2nd issue, which is that python changes clamping behavior when step is negative. I bet this polymorphism is the reason we don't allow non-1 steps for ArrayExpressions.; - @johnc1231 could you still follow up on the byte code generation issue?. I've verified this works in the boundary cases.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9152:474,polymorphi,polymorphism,474,https://hail.is,https://github.com/hail-is/hail/pull/9152,1,['polymorphi'],['polymorphism']
Modifiability,"This PR teaches gear/database.py to respect four more MySQL configuration parameters: `ssl-mode`, `ssl-ca`, `ssl-cert`, `ssl-key`. In particular, we can now turn TLS on or off and rotate keys by simply changing secrets and restarting the services. Since all sql-config secrets (except those in my namespace) currently have no certs, no keys, and no ssl parameters, after this PR merges all services will still use plaintext communications to the database. After this PR merges, I will update the root secret as well as all the service secrets (e.g. sql-auth-user-config) to have a shared client cert/key and our sql database's cert. Moreover I will set `ssl-mode` to `VERIFY_CA` which means (in our world, at least) verify the server's certificate but not the hostname (we use IPs to connect to our sql server) and present your own certificate for verification. Then I will restart all the services. Then I will ban plaintext connections to the database. Then I will PR a change that raises errors if we try to start a service with plaintext connections or unverified connections. I also:; - updated `create_database.py` so that it will propagate these TLS settings, if present, to created secrets, and; - updated CI to use `gear/database.py` and standard sql-config locations. All these parameters are defined by MySQL. We only support three options for [`ssl-mode`](https://dev.mysql.com/doc/refman/5.7/en/connection-options.html#option_general_ssl-mode), the remainder are either unnecessary or not supported (e.g. we have no hostnames so `VERIFY_IDENTITY` is irrelevant).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8433:60,config,configuration,60,https://hail.is,https://github.com/hail-is/hail/pull/8433,4,['config'],"['config', 'configuration']"
Modifiability,"This PR teaches most of our cluster how to exclusively speak HTTPS instead of; HTTP. The exceptions are:; - from batch-driver to batch workers; - from batch workers to internal-gateway; - to ukbb-rg; - from router to notebook workers; - letsencrypt (oh the irony). ## Changes from Original PR Proposal. ### Root Certificate. I added a secret to default named `ssl-config-hail-root` containing `hail-root-key.pem`, and `hail-root-cert.pem`. Every principal trusts this root. This root trusts every principal. This PR originally prevented clients from speaking to servers with certs they didn't trust. Now everyone trusts everyone. As long as the root key is not leaked this is OK. Only `create_certs` mounts this secret. The key is used to sign every certificate and the cert is included in each principal's incoming and outgoing trust lists. The root certificate and key are never re-created, so our deploys have no downtime and we avoid addressing the rotation problem. I removed all the trust specifications. A later PR will resolve rotation and mTLS. That PR will restore the trust specifications. I didn't change the structure of the secrets (they still have an incoming and outgoing trust list which only contains the root cert) because I need this structure for mTLS anyway. The original PR text follows. ---. ## HTTPS and TLS. HTTP is implemented on TCP/IP. HTTPS is also implemented on TCP/IP and differs; very mildly. After the socket is opened, a TLS [1] connection is established; over the socket. Thereafter, every HTTP message is encrypted and transported by; the TLS machinery. The HTTP protocol is unchanged. The default port fort HTTP is; 80 and the default port for HTTPS 443, however any port may be used. There are currently four versions of TLS, the latest is TLS 1.3. All versions of; SSL are considered insecure. The OpenSSL library implements TLS. There are other implementations, such as; LibreSSL, but they implement roughly the same interface as OpenSSL. The TLS protocol def",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8561:364,config,config-hail-root,364,https://hail.is,https://github.com/hail-is/hail/pull/8561,1,['config'],['config-hail-root']
Modifiability,"This PR uses BLAS `dgemm` function to multiply matrices when we are multiplying two 2 dimensional tensors of floats. I should extend this to work in the arbitrary tensor case with floats, but I have not done so yet. I'll do the extending after I've reworked the NDArray code to use column major, which I think will make it less complicated.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7773:126,extend,extend,126,https://hail.is,https://github.com/hail-is/hail/pull/7773,2,['extend'],"['extend', 'extending']"
Modifiability,"This PR:. - Introduces `StructComparisonOp`, a subclass of `ComparisonOp` that is just for comparing structs. They have an array of sort fields for this purpose.; - Extends `StreamDistribute` to take in a `ComparisonOp`, so that it doesn't just assume data sorted in ascending order.; - Updates `LowerDistributedSort.scala` to actually use the `SortFields` that get passed into it, allowing for arbitrary sort orders.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11270:165,Extend,Extends,165,https://hail.is,https://github.com/hail-is/hail/pull/11270,1,['Extend'],['Extends']
Modifiability,"This PR:. 1. Refactors `ResultOp` to just take an index and return whatever agg result is at that index. No more returning a suffix of the total aggregator tuple based on a starting index. This is necessary for me to effectively implement my Fold aggregator, which will be included in a subsequent PR. ; 2. Pushes `EmitType` through aggregators, uses them as the basis for analyzing the requiredness of aggregator results.; 3. Changes `_storeResult` on aggregators to instead just be `_result`, which directly returns an `IEmitCode`. No reason that `ResultOp` had to be so wound up in `PType`s, and for the most part this made the code simpler.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10894:13,Refactor,Refactors,13,https://hail.is,https://github.com/hail-is/hail/pull/10894,1,['Refactor'],['Refactors']
Modifiability,"This PR:. 1. Refactors `listify` to return pandas dataframes, and every geom to take in pandas dataframes. This significantly simplifies the code and should also speed things up.; 2. Refactors the `apply_to_fig` method of most of the geoms to rely on a specification dict and then just loop over that. This simplifies adding a new argument / aesthethic. In the future, it may be best to just make all of the geoms take `**kwargs` so that arguments added to that dict will immediately be used for plotting, as right now I have to add something to `geom_bar`, `GeomBar.__init__`, and that dictionary for it to start showing up in plots. ; 3. Adds `identity` as a bar position, which means to plot bars on top of each other. This is useful along with the `alpha` argument added to bars and histograms, which sets transparency of points.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11317:13,Refactor,Refactors,13,https://hail.is,https://github.com/hail-is/hail/pull/11317,2,['Refactor'],['Refactors']
Modifiability,This PR:; - Replaces Fluentd with Filebeat (Filebeat config based on the recommended kubernetes filebeat config from elastic repo); - Increases elasticsearch storage. ; - Modifies Kibana's security context so that it doesn't run as root (Kibana will print an error message if it's running as root).; - Adds the `decode_json_fields` processor to filebeat so that it parse our structured log messages as json.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6659:53,config,config,53,https://hail.is,https://github.com/hail-is/hail/pull/6659,2,['config'],['config']
Modifiability,"This adds `test_storage_uri` and `batch_logs_storage_uri` fields in the global config. In GCP, this meant just copying existing GCS bucket names and prepending `gs://`, which I've done in the terraform and manually in default. For azure, in the terraform I add two storage accounts, `batch` and `ci`, with `logs` and `test` containers, respectively. This felt like an intuitive consolidation of containers under storage accounts that would make permissioning cleaner. E.g. the batch service principal has access to the entire batch storage account, but only to the `test` container in the ci storage account. However, I've not thought about it deeper than that so it might be worth some looking into. Luckily this decision has no impact on application code. There's still more to be done in a follow-up PR to replace instances of `hail_test_gcs_bucket_name` with `test_storage_uri`, but I think this takes care of the batch deployment's dependency on GCS.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11014:79,config,config,79,https://hail.is,https://github.com/hail-is/hail/pull/11014,1,['config'],['config']
Modifiability,This adds a control to CI where an operator can adjust the rate limit on a particular service in a particular namespace. CI stores and propagates that information when it generates the Envoy configs for `gateway` and `internal-gateway`. This enables operators to shield an overwhelmed batch driver by decreasing its rate limit without needing to push a code change. Increasing the rate limit can increase throughput if workers are being rate limited but the batch driver is not fully utilized.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14609:191,config,configs,191,https://hail.is,https://github.com/hail-is/hail/pull/14609,1,['config'],['configs']
Modifiability,This adds simple unit tests to the CI functionality that generates the configs for `gateway` and `internal-gateway`. It also adds a developer-only endpoint to CI for easier inspection of what configs CI is currently generating in production. These configs do not contain any sensitive information.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14524:71,config,configs,71,https://hail.is,https://github.com/hail-is/hail/pull/14524,3,['config'],['configs']
Modifiability,"This adds some useful infrastructure for Scala-generated C++. 1. Initial support for a small number of C++-to-Scala upcalls. 2. C++ info/warn/error implemented as upcall going through is.hail.utils,{info,warn,error}. 3. Scala PrettyCode auto-indenter for Scala-generated C++, so you don't have to try to; get the indentation right while generating the C++ source. 4. src/main/c/Makefile has a variable HAIL_ENABLE_DEBUG if set as "":=1"", then libs will be; built with -O1, and the initialization in src/main/NativePtr.cpp will try to start gdb in an xterm; and attach back to the hail process, allowing gdb debugging of generated C++ called from; Scala. 5. ObjectArray is a NativeObj which can hold any number of Scala Objects, holding them in C++; as JNI global-ref jobjects. This can be used for example to hold InputBuffer or InputStream; objects, and to pass them down to a constructor for a C++ object (e.g. a decoder) which will then ; make upcalls to methods of those objects. . A subsequent commit will have the RowStore/C++ decoder using all this infrastructure (passing an; InputBuffer down to the C++ decoder, which holds it and makes upcalls to pull a block of data).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4302:393,variab,variable,393,https://hail.is,https://github.com/hail-is/hail/pull/4302,1,['variab'],['variable']
Modifiability,"This adds the Google Cloud Monitoring and Prometheus datasources to the grafana configuration. I had done this initially by hand in the UI but this is the first step toward reproducible monitoring, and I'll eventually follow up with dashboards as code. The one ""change"" I made is I exposed the prometheus port sitting behind nginx so that grafana can talk directly to prometheus. Currently, there's an nginx sitting in front of prometheus so that the prometheus UI can be exposed at prometheus.hail.is with https and dev authentication. This hasn't changed. Currently though, grafana is piggybacking on this flow by forwarding the user's session (which I set up in the UI), but I couldn't figure out an easy way to set that in the config and it seemed unnecessarily complicated. I ended up going the simpler route of just letting grafana talk to prometheus directly and not go through nginx. The 9090 endpoint is not reachable outside of the cluster. I considered namespacing the prometheus domain (`{{ default_ns.name }}` instead of `default`), but I pretty much never find it useful to spin up my own prometheus. In the rare case I run my own grafana I just point it to the data from default.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10627:80,config,configuration,80,https://hail.is,https://github.com/hail-is/hail/pull/10627,2,['config'],"['config', 'configuration']"
Modifiability,"This adds the following pieces of infrastructure:. - Fully scripted bootstrapping process, from creating a managed identity to run terraform through (instead of the current service principal), to creating a VM to run the bootstrap process off of, through all following steps until running bootstrap.py; - Adds the root CA certificate that azure uses to sign the MySQL server certificates so that we can connect to the database with `VERIFY_CA`. Unlike gcp, however, this still doesn't allow us to use mTLS since it doesn't look like we can request a client cert/key for our database. Still this is not so bad for now.; - Creates a separate k8s module for terraform. This currently just holds the global-config and sql-config resources, but establishes a boundary between the cloud-specific terraform and purely k8s terraform. Later on I'll refactor the GCP terraform to use the k8s module so that different clouds can use the same k8s configuration.; - Adds a pool of spot instances to the AKS cluster and adds the required toleration to all of our preemptible deployments. Part of the node selection process for a pod requires that exist a toleration on the pod for every taint on the node. In other words, it is ok for a pod to have redundant tolerations, so it's fine to have azure-specific tolerations even if we're running in gcp.; - Refactor the az-create-worker-image.sh script to complete the entire batch worker image creation process from start to finish. This involved sending a command over ssh that previously had to be executed by hand. This meant we could combine the two-script process into one shell script. This fully matches the google setup we have currently up until running `bootstrap.py`, which is still google-specific, mainly w.r.t. gcp service accounts. The next step is to adapt this to azure, but I think we need to come to a decision about exactly how we're representing application credentials (just service principals vs managed identities?). Once we have that figured o",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10919:703,config,config,703,https://hail.is,https://github.com/hail-is/hail/pull/10919,4,"['config', 'refactor']","['config', 'configuration', 'refactor']"
Modifiability,This adds the following terraform capabilities:; - A reserved public IP for the k8s gateway; - A container registry and pull access for the k8s cluster; - A [private link](https://azure.microsoft.com/en-us/services/private-link/) for the mysql database that makes it accessible on the k8s subnet. I haven't set up the config to use the database yet but ensured that the hostname for the database was resolvable from a pod on the cluster. I think this covers most of the azure specific resources that we need. Most of the rest of our terraform for gcp creating k8s secrets for the database config and various service accounts. I'd like to approach that in a single chunk to find out how best to abstract those into modules.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10838:318,config,config,318,https://hail.is,https://github.com/hail-is/hail/pull/10838,2,['config'],['config']
Modifiability,"This adds the function to TableReader:; ```; rowAndGlobalPTypes(ctx: ExecuteContext, requrestedType: Type): (PStruct, PStruct); ```. (The context is necessary for native readers to be able to get the filesystem in order to read the metadata.). I'm not sure if this is the best way to implement this, but it feels like TableReaders ought to be able to tell you what PType they expect to be decoding into at compile time, since we can use this information to make decisions about requiredness, etc. on IRs that contain TableReads. I rely on this to extend the requiredness analysis to TableIR nodes; I think it's probably reasonable to have one function that goes from requestedType => PType instead of separate functions for requiredness and other analyses we might want to do un the future, since I don't think we have imminent plans to decode directly into different PTypes.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8740:547,extend,extend,547,https://hail.is,https://github.com/hail-is/hail/pull/8740,1,['extend'],['extend']
Modifiability,"This adds the k8s config necessary to host the [guide browser](https://hub.docker.com/r/gneak123/guide_browser/tags) in our k8s cluster. You can see it running in dev [here](https://internal.hail.is/dgoldste/guide-analysis/). There's not much special here, a deployment with the browser app and an envoy sidecar to handle TLS. Once this merges and the `ssl-config-guide-analysis` is created in `default` I can `make -C guide deploy NAMESPACE=default` and then recreate the certs to pick up the new subdomain, after which it should be live. Resolves #14067",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14078:18,config,config,18,https://hail.is,https://github.com/hail-is/hail/pull/14078,2,['config'],"['config', 'config-guide-analysis']"
Modifiability,"This adds the minimal resources to k8s to allow us to modify the gateway's configuration to include redirects for https://notebook.hail.is. Currently, that domain will timeout, but there should otherwise be no errors introduces to the k8s system. cc: @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4645:75,config,configuration,75,https://hail.is,https://github.com/hail-is/hail/pull/4645,2,['config'],['configuration']
Modifiability,"This allows the user to specify the cloud platform ('gcp' or 'aws') they are using when accessing datasets via the datasets API and annotation DB. A user running hail on AWS would read from the s3 bucket, and a user running on GCP would read from the gs bucket (can also still read locally from gs bucket with cloud storage connector installed). Not intended for cross-platform use like running a dataproc cluster and trying to access the s3 bucket, or trying to access the gs bucket on an EMR cluster. Will assume user on AWS has their configuration set with their credentials. . Did not have permissions to set up a cluster or EC2 instance on AWS to test, but was able to access all the datasets without issue on a dataproc cluster when using s3a:// prefixes and providing my AWS credentials in the spark config. So these changes should (hopefully) work fine on an EMR cluster with the s3:// client. Everything worked as expected on GCP. Overview of changes:; - Added missing type hints to `load_dataset()` function and methods in `db.py`.; - In `datasets.json`:; - Added AWS urls so now for each version of a dataset in dataset[""versions""], the url entry looks like:; ```; ""url"": {; ""aws"": {; ""us"": ""s3://hail-datasets-us-east-1/...""; },; ""gcp"": {; ""eu"": ""gs://hail-datasets-eu/..."",; ""us"": ""gs://hail-datasets-us/...; }; ```; - In `load_dataset()` function:; - Added `cloud` parameter, set default values to `region='us'` and `cloud='gcp`.; - In `DB` class:; - Added `cloud` parameter to constructor, set default values to `region='us'` and `cloud='gcp`.; - All datasets in `datasets.json` currently end up in the `_DB__by_name` dictionary, even if not annotation datasets. Added line 279 in `db.py` to fix this and filter out datasets that are not annotation datasets (datasets missing ""annotation_db"" key).; - In `Dataset` class:; - Added `cloud` and `custom_config` parameters to `Dataset.from_name_and_json()` to pass to `DatasetVersion.from_json()` to grab correct urls for platform.; - Refac",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9605:537,config,configuration,537,https://hail.is,https://github.com/hail-is/hail/pull/9605,2,['config'],"['config', 'configuration']"
Modifiability,"This allows us to write functions for the IR that handle missingness specially, in cases where we don't necessarily want the behavior where any missing argument implies that the entire function result is considered missing. I implemented `&&` and `||` using this in order to test. I also refactored the return from Emit.emit to a case class `EmitTriplet` to make it easier to talk about them in other contexts. cc @cseed @danking",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3210:288,refactor,refactored,288,https://hail.is,https://github.com/hail-is/hail/pull/3210,1,['refactor'],['refactored']
Modifiability,"This also fixes the currently broken `delete_*_tables` steps. In the past, all dev and test databases shared the same MySQL Server (with production), so instead of each service getting its own dedicated database, there was one database per dev/test namespace with all the tables for all the services. This made it difficult to reset the database state of a particular service -- you needed to explicitly delete only the tables for that particular service. Nowadays, dev and test databases live on their own MySQL Servers, so each service gets its own database (like in production). This makes it a lot easier to reset a service's database, we just drop the MySQL database for that service. This PR makes that change, deletes all the now unused `delete-*-tables.sql` files, and adds a dev doc explaining how to reset a dev database. The reason these steps were broken is that the sql configs in dev/test namespaces use K8s DNS for the `host`, which does not work out of the box in batch jobs because they are not in the K8s network. There's code in `database.py` that uses the K8s API to resolve the database host to an IP address that the batch jobs can access. This is why I wrote a python script instead of just using `mysql`. I tested these with the following dev deploy, which scrapped everything and I was able to log in after it was done!. ```; hailctl dev deploy -b daniel-goldstein/hail:dev-ns-delete-db -s delete_auth_tables,delete_batch_tables,deploy_batch,add_developers; ```. cc: @sjparsa, @iris-garden given your recent dev namespace woes",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13456:883,config,configs,883,https://hail.is,https://github.com/hail-is/hail/pull/13456,1,['config'],['configs']
Modifiability,"This basically just pulls out the logic from the `NativeDecoder` and `NativeEncoder` stuff in RowStore.scala into their own objects, and dynamically generates a c++ class for the row type. (The only things that have changed between `NativeDecoder`/`cxx.PackDecoder` and the encoders are the `apply` functions; I'm generating an Encoder class that inherits NativeObj instead of relying on the wrapper classes in `Encoder.h` and `Decoder.h`. This mostly felt like it made things easier to reason about when I started writing the full-stage code generation stuff, but I've pulled it out here as a separate PR. cc @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4722:347,inherit,inherits,347,https://hail.is,https://github.com/hail-is/hail/pull/4722,1,['inherit'],['inherits']
Modifiability,"This builds on: https://github.com/hail-is/hail/pull/3107. We were getting absolutely murdered by serializing the partitioner on every task. I made OrderedRVDPartitioner not inherit from Spark Partitioner, non-serializable, and modified it to be broadcasted where needed. There is a good chance this will speed up OrderedRVD shuffles as well, but I haven't timed. Timing:. ```; import hail as hl. mt = hl.read_matrix_table('gnomad.exomes.vds', _drop_cols=True); mt = mt._filter_partitions(list(range(1000))); mt._force_count_rows(); ```. master: 1m15s; no_ser_ord_part: 9s. That's about 8x improvement. This includes startup time so it's actually much better.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3110:174,inherit,inherit,174,https://hail.is,https://github.com/hail-is/hail/pull/3110,1,['inherit'],['inherit']
Modifiability,"This came to mind yesterday during our pairing. This PR introduces the following properties that our image building targets do not currently have:; 1. If your intention is only to build images, you shouldn't need `kubectl`. When `DOCKER_PREFIX` is used as a docker build arg it is because we mirror some dockerhub images inside our registry (for reliability/rate limiting reasons). But for local building there's no reason you can't use the dockerhub image. Also, other people should be able to build the hail image if they want to!; 2. One should *only* need to use `kubectl` if they are intending to use an image in a kubernetes deployment. In other words, you should only need the private registry `DOCKER_PREFIX` for pushing images.; 3. One should not need to endure image pushing if the only goal is to build the image locally; 4. No intermediate tags should end up in the private registry. If we push on every image build, the private docker registry will accumulate a lot of `hail-ubuntu:dev-xxxxxx` tags that are never used again because `hail-ubuntu` is just an intermediate used to build other images. This does *not* change the number of layers that end up in the registry, but reduces a bit of the work that the registry cleanup job needs to do to untag and delete images and just seems cleaner.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13890:1149,layers,layers,1149,https://hail.is,https://github.com/hail-is/hail/pull/13890,1,['layers'],['layers']
Modifiability,"This change applies each currently-ignored `ruff` rule progressively; each commit applies one rule. The changes were applied manually to avoid known issues with the automatic fixes; for example, given the code; ```python; return (; is_container(t); or isinstance(t, tstruct); or isinstance(t, tunion); or isinstance(t, ttuple); or isinstance(t, tndarray); ); ```; the automatic fixes produce; ```python; return isinstance(t, (tndarray, tstruct, ttuple, tunion)); ```; instead of ; ```python; return is_container(t) or isinstance(t, (tstruct, tunion, ttuple, tndarray)); ```; where not only has the call to `is_container` been removed, but also the order of the `isinstance` comparisons has been changed, which has the potential to produce side effects (though in this case, I don’t think it does). Similarly, when eliminating assignments to unused variables, I left the right-hand side of the assignment intact in case of side effects, except where I myself wrote the code in question and know there are no side effects produced by it. See also https://github.com/hail-is/hail/pull/14150 and https://github.com/hail-is/hail/pull/14159.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14415:848,variab,variables,848,https://hail.is,https://github.com/hail-is/hail/pull/14415,1,['variab'],['variables']
Modifiability,"This change combines cloud auth logic that was previously duplicated; between the various `FS` implementations and the `BatchClient`. . The main refactoring is to make the interface between the `ServiceBackend` more; high-level and leave json serialisation to the `BatchClient`. To do this, I've; added a bunch of case classes that resemble the python objects the batch service ; expects (or a subset of the data). To simplify the interface, I've split batch; creation from job submission (update). For QoB, the python client creates the ; batch before handing control to the query driver; batch creation is necessary; for testing only. This change has low security impact as there are minor changes to the creation; and scoping of service account credentials. Note that for each `FS`, credentials; are scoped to the default storage oauth2 scopes for each service.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14684:145,refactor,refactoring,145,https://hail.is,https://github.com/hail-is/hail/pull/14684,1,['refactor'],['refactoring']
Modifiability,"This change creates mysql pods for test and dev namespaces, instead of sharing the CloudSQL database server. The areas of change are as follows:. ### Generation of the namespace's database-server-config; The current approach in main does a little trick. Since the current `createDatabase` step uses the `database-server-config` from default to generate admin/user sql configs, the CI pipeline creates a dummy database `test-database-instance` to create a `sql-test-instance-admin-config` that inherits the credentials from the production `database-server-config`, and then copies that within the test namespace to `database-server-config`. In this change, since we are creating the server ourselves, we can just replace these with a step that creates a `database-server-config` from scratch, and then uses that for the DB pod. Overall making these changes really gave me the heebie jeebies that the test and dev namespaces have all these credentials to the CloudSQL server. I'm glad this gets rid of that. ### Accessing the database server; We use the DB pod's service DNS name as the `host` so inside Kubernetes this Just Works. The one caveat is the CI pipeline in which we run migrations in batch jobs. Those jobs need a way to reach the DB pod. I achieve this with a NodePort and then use the job's K8s credentials to resolve the node and port that the DB is on. The code I've added to do this resolution feels a bit janky, wouldn't mind some feedback on that. In terms of security, if a user job was able to somehow resolve the address of a test db, they would still not have the credentials to access it, and this is currently also the case with the production database. Nevertheless, this does raise an action item that we should only allow traffic to the k8s and DB subnets for `network=private` jobs, but I think we should make that a separate PR. ### Database creation; In order to test this properly in a dev deploy, I needed to make some changes to `create_database.py`. In main, dev deplo",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13030:196,config,config,196,https://hail.is,https://github.com/hail-is/hail/pull/13030,8,"['config', 'inherit']","['config', 'configs', 'inherits']"
Modifiability,"This change exists as part of larger refactoring work. Herein, I've exchanged; hard-coded contextual strings passed to `ExecutionTimer.time` with implict; contexts, drawing inspiration from scalatest. These contexts are now supplied after entering functions like `Compile` and; `Emit` instead of before (see `ExecuteContext.time`). By sprinking calls to ; `time` throughout the codebase after entering functions, we obtain a nice trace; of the timings with `sourcecode.Enclosing`, minus the previous verbosity. See [1] for more information about what pre-built macros are available. We can; always build our own later. See comments in [pull request id] for example output.; Note that `ExectionTimer.time` still accepts a string to support uses like; `Optimise` and `LoweringPass` where those contexts are provided already.; It is also exception-safe now. This change exposed many similarities between the implementations of query; execution across all three backends. I've stopped short of full unification; which is a greater work, I've instead simplified and moved duplicated result; encoding into the various backend api implementations. More interesting changes are to `ExecuteContext`, which now supports; - `time`, as discussed above; - `local`, a generalisation for temporarily overriding properties of an ; `ExecuteContext` (inspired by [2]). While I've long wanted this for testing,; we were doing some questionable things when reporting timings back to python,; for which locally overriding the `timer` of a `ctx` has been very useful.; We also follow this pattern for local regions. [1] https://github.com/com-lihaoyi/sourcecode; [2] https://hackage.haskell.org/package/mtl-2.3.1/docs/Control-Monad-Reader.html#v:local",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14679:37,refactor,refactoring,37,https://hail.is,https://github.com/hail-is/hail/pull/14679,1,['refactor'],['refactoring']
Modifiability,"This change is split out from a larger refactoring effort on the various Backend ; implementations. The goals of this effort are to provide query-level ; configuration to the backend that's currently tied to the lifetime of a backend,; reduce code duplication and reduce state duplication. In this change, I'm restoring references to the execute context [1] and ; decoupling them from the backend. In a future change, they'll be lifted out of ; the backend implementations altogether. This is to reduce the surface area of ; the Backend interface to the details that are actually different. Both the Local and Spark backend have state that's manipulated from python via ; various py methods. These pollute the Backend interface [2] and so have been ; extracted into the trait Py4JBackendExtensions. In future changes, this will ; become a facade that owns state set in python. Notes; [1] ""Restoring"" old behaviour I foolishly removed in fe5ed32; [2] ""Pollute"" in that they obfuscate what's different about backend query plan ; and execution",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14686:39,refactor,refactoring,39,https://hail.is,https://github.com/hail-is/hail/pull/14686,2,"['config', 'refactor']","['configuration', 'refactoring']"
Modifiability,"This change is split out from a larger refactoring effort on the various Backend; implementations. The goals of this effort are to provide query-level; configuration to the backend that's currently tied to the lifetime of a backend,; reduce code duplication and reduce state duplication. In this change, I'm removing blockmatrix persist/unpersist from the `Backend`; interface by adding `BlockMatrixCache: mutable.Map[String, BlockMatrix]` to; `ExecuteContext`. The various reader/writer implementations simply fetch the ; block matrix from this cache. For the spark backend, this is backed by a cache; whose lifetime is tied to the spark backend. Since block matrices are not; supported in the local and service backends, the cache is an empty map. Note that block matrix persist is broken in python (#14689)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14690:39,refactor,refactoring,39,https://hail.is,https://github.com/hail-is/hail/pull/14690,2,"['config', 'refactor']","['configuration', 'refactoring']"
Modifiability,"This change makes the labels for groups of points on scatterplots created through `geom_point` configurable by the user. Consider the following sample code:. ```python; import hail as hl; from hail.ggplot import ggplot, aes, geom_point; ht = hl.utils.range_table(10); ht = ht.annotate(squared=ht.idx ** 2); ht = ht.annotate(even=hl.if_else(ht.idx % 2 == 0, ""yes"", ""no"")); ht = ht.annotate(threeven=hl.if_else(ht.idx % 3 == 0, ""good"", ""bad"")); fig = (; ggplot(ht, aes(x=ht.idx, y=ht.squared, color=ht.even, shape=ht.threeven)); + geom_point(); ); fig.show(); ```. Before this change, this code generates the following legend for the plot:. <img width=""118"" alt=""Screen Shot 2022-09-29 at 12 29 27"" src=""https://user-images.githubusercontent.com/84595986/193087326-a1bed417-b314-442c-a8a0-c2f506ca7d93.png"">. After this change, the legend looks like this (`×` is now the default group name separator):. <img width=""107"" alt=""Screen Shot 2022-09-29 at 12 22 57"" src=""https://user-images.githubusercontent.com/84595986/193085964-e4545e78-473f-46a3-8c8c-7d6189eb7adc.png"">. If `legend_format` is passed to `geom_point`, like so:. ```python; ...; + geom_point(legend_format=""{color} ({shape})""); ...; ```. the following legend will be generated, replacing the names of the aesthetics within brackets in the format string with their values:. <img width=""104"" alt=""Screen Shot 2022-09-29 at 12 25 17"" src=""https://user-images.githubusercontent.com/84595986/193086499-4ffaacac-ada1-43ea-b056-9334e26b713d.png"">. Notably, if the reverse ordering of group names (`""{shape} ({color})""`) is used, the legend will look like this:. <img width=""103"" alt=""Screen Shot 2022-09-29 at 12 26 35"" src=""https://user-images.githubusercontent.com/84595986/193086758-f7accbe4-4427-4b06-8b5c-f200a3ceec3e.png"">. The order in which the groups in the legend appear can be adjusted, if desired, by changing the order of the aesthetics when they are passed into `aes`:. ```python; ...; ggplot(ht, aes(x=ht.idx, y=ht.squared, shape=h",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12244:95,config,configurable,95,https://hail.is,https://github.com/hail-is/hail/pull/12244,1,['config'],['configurable']
Modifiability,"This change simplifies aspects of the annotation db's implementation as well as adding new features such as annotating a Table or using a custom JSON configuration file. The Annotation DB will remain experimental until we iron out the JSON configuration file's structure and we're confident in the deploy process. - Allow custom URL or JSON for configuration (enabling testing and local development).; - Support Tables.; - Restructure the annotation db JSON to reduce duplication. It now maps from dataset name to dataset metadata and dataset versions.; - Simplify JS logic based on new JSON structure.; - Check-in and implement versioned deployment of the annotation db configuration JSON.; - Add a JS file to the website that defines `hail_version` and `hail_pip_version`.; - Add `key_properties` which currently supports two properties `gene` and `unique`. Gene keyed datasets require using the `gencode` dataset to crosswalk from locus to gene before joining.; - Rudimentary test of key properties functionality. Foundational Changes Outside Annotation DB:; - Define `__pip_version__` in `hail`.; - Teach `StructExpression` and `TupleExpression` how to slice by integers, facilitating the construction of structs of a prefix of fields.; - Make `ttuple` a mapping from integers to the tuple elements.; - Implement `Table._maybe_flexindex_table_by_expr` which, given a indexer expression, finds a prefix of the expression that can index the indexee, if such an expression exists. Unrelated changes:; - Clarify Makefile error echos with `ERROR:`. ---. ## flexindex. The primary use case for this is a dataset which is `locus, allele` keyed and needs to index into a `locus` keyed or `interval<locus>` keyed dataset. Hail's normal join logic will return a key mismatch error:. ```python; import hail as hl; t = hl.utils.range_table(10); t2 = t.key_by(x=t.idx, y=t.idx); t.index(t2.key); ```; ```; Traceback (most recent call last):; File ""<ipython-input-6-3ddc90774dfe>"", line 1, in <module>; t.index(",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7178:150,config,configuration,150,https://hail.is,https://github.com/hail-is/hail/pull/7178,4,['config'],['configuration']
Modifiability,"This changes allow `hl.init()` to run against the query service without starting JVM/Spark on the client:. ```; $ python3; Python 3.7.3 (default, Oct 7 2019, 12:56:13) ; [GCC 8.3.0] on linux; Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.; >>> import hail as hl; >>> hl.init(_backend=hl.backend.ServiceBackend()); Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.34-0ef20f14e0c1; LOGGING: writing to /home/cotton/hail/hail-20200402-0120-0.2.34-0ef20f14e0c1.log; ```. Summary of changes:; - Move initialization of Java HailContext from init to SparkBackend ctor. There is no JVM or Java HailContext when using the service backend.; - Env no longer carries the gateway. (Next: jvm); - make Java HailContext.tmpDir construction lazy. It requires a fs, but HailContext will only carry an fs for the SparkBackend. This will have to get rethought.; - Make Java ServiceBackend extend Backend.; - Construct a HailContext in the query service.; - Implement /references/get in query backend which is needed by hl.init to get the builtin reference genomes on startup.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8434:932,extend,extend,932,https://hail.is,https://github.com/hail-is/hail/pull/8434,1,['extend'],['extend']
Modifiability,"This changes the Azure database from Azure database for MySQL Single Server to Azure database for MySQL Flexible Server. The major changes are:. - Fixed several small rots across the bootstrap code; - Altered the database module in terraform to use flexible server. This configuration mostly matches what we had with single server, importantly that it is only accessible on our vnet.; - Makes the client key/certificate in the SQLConfig optional (the current use of SQLConfig is a little repetitious and could probably use a refactor).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11423:104,Flexible,Flexible,104,https://hail.is,https://github.com/hail-is/hail/pull/11423,4,"['Flexible', 'config', 'flexible', 'refactor']","['Flexible', 'configuration', 'flexible', 'refactor']"
Modifiability,"This commit changes the tracking of Joins on Python expressions; in two ways:. First, joins are switched from being tracked explicitly; on Expression to being a part of the expr AST. Second, broadcasts are split off as a separate AST node, which; lets us make them significantly simpler. It also made it easy; to collapse all broadcasts for a given MT/Table operation into; one MapGlobals IR, instead of one per broadcast variable. In the future, all the metadata on Expression should be tracked; on AST (type, aggregations, indices). This is a first incremental; step in getting there.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3573:422,variab,variable,422,https://hail.is,https://github.com/hail-is/hail/pull/3573,1,['variab'],['variable']
Modifiability,"This consisted almost entirely of `region` -> `Region`. I had to rewrite some things to replace `appendBinary` and `appendString`, but there shouldn't be any other substantive changes in here.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7092:65,rewrite,rewrite,65,https://hail.is,https://github.com/hail-is/hail/pull/7092,1,['rewrite'],['rewrite']
Modifiability,"This enables Query-on-Batch pipelines to read from requester pays buckets. @tpoterba curious for your thoughts on the flag situation. I suspect this PR will induce the Australians to start including requester pays config in their pipelines. If you describe an API you like, I can implement it for this PR. Otherwise, I think this is ready. It works, it is tested. The changes to GoogleStorageFS suck, but its due to the reality of the GCS API.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12133:214,config,config,214,https://hail.is,https://github.com/hail-is/hail/pull/12133,1,['config'],['config']
Modifiability,"This fixes site to work inside PRs and dev namespaces. The main fix is to teach; site that, when the namespace is not default, all its resources are located at; `/$NAMESPACE/site`. I also use `subs_filter` to rewrite images, anchors, and; stylesheets that have absolute links (this can be `<a href=""/""` or `<a; href=""/foo/bar/baz.html""`) to include the namespace prefix. I also added a test that the website is up and returning 200 with our infrastructure. I also added `updated_host` which uses the X-Fowarded-For host if it exists (i.e. in a namespace).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8763:209,rewrite,rewrite,209,https://hail.is,https://github.com/hail-is/hail/pull/8763,1,['rewrite'],['rewrite']
Modifiability,"This illustrates one of the footguns in using CodeBuilder. When using; functionality like ifx, we must be sure to actually put the resultant; code on the CodeBuilder in the block we pass to ifx. Otherwise we won't; add any code and the behavior may be surprising. This is basically equivalent to storing some Code in a variable and then; never passing that variable into a returned Code, so it is never; executed.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8487:319,variab,variable,319,https://hail.is,https://github.com/hail-is/hail/pull/8487,2,['variab'],['variable']
Modifiability,This implements [Apache Arrow](https://arrow.apache.org/docs/format/Columnar.html#variable-size-list-layout) style nested arrays. A more detailed write up will appear here as this gets closer to being ready.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10542:82,variab,variable-size-list-layout,82,https://hail.is,https://github.com/hail-is/hail/pull/10542,1,['variab'],['variable-size-list-layout']
Modifiability,"This introduces a new version of the batch worker instance: one without `docker`. Instead we bring in `podman` to cover the functions of pulling images, extracting expanding filesystems from those images, and running the worker container. `podman` by default uses `crun` as its low-level runtime so we can get rid of the independent `crun` installation in the worker image. `podman` is daemonless and can be run rootless. For the most part you can't tell the difference, except this makes `podman` easy to run under multiple users with different caches per user. So if you ssh into a worker, be sure to `sudo` before any `podman` (or `crun`) command or else you might think nothing is running when in fact the worker is running under root's podman configuration. The podman/crun state directories are now shared between the host and the worker so `sudo crun list` on the worker should reveal the running job containers without having to exec into the worker first. For the most part, `podman` is a drop-in replacement for `docker`, but there are a handful of inconsistencies that comprise most of this PR. One notable change is that we no longer persist any GCR credentials in the worker VM image so we authenticate again on start up. cc: @jigold",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10693:748,config,configuration,748,https://hail.is,https://github.com/hail-is/hail/pull/10693,1,['config'],['configuration']
Modifiability,"This introduces the necessary pieces of infrastructure to run CI in GCP and a couple of small changes such that it can run as a secondary CI. This is currently failing because one of the secrets I introduce here in the terraform does not exist in hail-vdc. If you approve of the approach I can add it in manually. . ## Terraform changes; This adds a new CI terraform module that adds a CI bucket, sets some permissions for the CI service account and adds some K8s secrets like github tokens and the zulip config. This allows the terraform deployment to optionally include resources needed for CI. This was the best way I could think to introduce this infra with the least changes, but it's not what I want in the long term. Right now we have one monolithic root module that includes all the resources necessary to run batch, with the option for tacking on CI. I would rather extract most of our root module into a `batch` module (and while we're break down the innards into modules like vdc, db, etc.) and have the root module be something that can be easily pieced together from the library of modules. This would be a decently big refactor and more importantly would require existing deployments to manually overhaul their terraform state, so it's something I want to do carefully but also sooner is better than later. Given how terraform state is indexed, I believe more modularity will be easier to manage in the long term. ## CI changes; This adds the following features to CI; - Watched branches can be marked as `mergeable`. `mergeable=true` should be the default behavior and `false` prevents CI from merging a PR on GitHub. This allows multiple CI's to run tests in different environments without stepping on each others' toes. This *does not*, however, consider statuses from multiple CIs when making the decision to merge a PR. That is currently based on the build status, and later should be changed to consider the collection of statuses on GitHub.; - Custom Deploy Steps: This is a colle",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11053:505,config,config,505,https://hail.is,https://github.com/hail-is/hail/pull/11053,1,['config'],['config']
Modifiability,"This is a bad change to a worse problem. The right solution is to redesign the IR; so that implicit init eval scopes don't exist -- but the right solution is hard to justify; going off to do right now. This change patches the Extract.scala lowering logic to track the variables bound inside a; lowered IR and find the highest node that provides all necessary free variables. This change; still makes assumptions about the structure of the IR -- namely, it is still invalid to write; an IR like:. ```; MakeTuple; Let; initBinding1; <something>; ApplyAggOp with ref to initBinding1; Let; initBinding2; <something2>; ApplyAggOp with ref to initbinding2; ```. However, this fix resolves the case where init args reference a high single binding chain, as; in the test added.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12092:268,variab,variables,268,https://hail.is,https://github.com/hail-is/hail/pull/12092,2,['variab'],['variables']
Modifiability,"This is a bit of a mess so feel free to ask that I break it down or explain more in depth. In short, this:. - adds terraform for forgotten bits and pieces necessary for running PR tests like test buckets and the necessary permissions on those resources; - Adds a couple of flags that allow a CI `WatchedBranch` to be considered mergeable or not. This shouldn't change anything in default CI, but it allows you to specify that a secondary CI should run PRs, post statuses, and deploy new commits, but never actually commit anything to GitHub. Similarly there's a flag for turning off zulip notifications, but annoyingly the zulip config is still a required secret. I plan to make that nicer in the future.; - Fixes a lot of previously-unreached syntax errors in the batch tests. Following PRs will have relatively less functionality but probably a fair bit of cleanup and reorganization, e.g. getting rid of config.mk and generating it from terraform output, making scripts of the bootstrapping process etc.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10866:629,config,config,629,https://hail.is,https://github.com/hail-is/hail/pull/10866,2,['config'],['config']
Modifiability,"This is a long overdue description of how our K8s ingress / config is set up. I've tried to keep it as concise as possible, so ask for elaboration if there are unexplained gaps.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14488:60,config,config,60,https://hail.is,https://github.com/hail-is/hail/pull/14488,1,['config'],['config']
Modifiability,"This is a minor architectural change (cc'ing @cseed @tpoterba) that I hope will improve maintainability of `batch`. It foreshadows the DAG functionality. There may be shared data structures between the server and the client. At the very least, the client sends structured data to the server (e.g. a pod spec and metadata about the job). Often, the server parses this data into an object or series of objects which contain methods for performing the server's job (e.g. `batch/server/job.py`). I think this architecture is more or less a different way of defining the API (see `batch/api.py`). I think defining the API via data objects is appealing because; - it centralizes serialization and deserialization for each data structure in one class,; - it enables sharing (via object composition) of that basic data structure between potentially complex client and server objects that implement algorithms on that data structure (I want to do this with the forthcoming DAG stuff), and; - the client has objects representing its ideas (i.e. ""a job"") and those objects can have `__str__`'s and `__repr__`'s facilitating debugging of the client. Moreover, this change pushes the use of k8s' swagger models everywhere possible. This means it's harder for us to make code mistakes because pylint will notice when we, for example, misspell a parameter to a k8s model.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4804:88,maintainab,maintainability,88,https://hail.is,https://github.com/hail-is/hail/pull/4804,1,['maintainab'],['maintainability']
Modifiability,"This is a multi-stage overhaul of our Kubernetes load balancers / service discovery. This involves moving off of NGINX onto Envoy, but more importantly involves better control of what namespaces and services are active in our cluster at a given point in time. TL;DR Switching from NGINX to Envoy with CI acting as the ""control plane"" for our internal networking allows us to more easily dynamically configure our Kubernetes networking and achieve proper connection pooling/load-balancing over TLS, which translates to less resource consumption and lower request latencies. ## Motivation; This is primarily a performance-motivated change, and one largely based on our (ab)use of NGINX in order to work with our dynamically-generated Kubernetes test namespaces. Currently, we configure NGINX by creating server blocks that dynamically resolve and dispatch requests based on matching regular expressions on the host and path headers. This is in large part due that at gateway deploy time we do not statically know all of the namespaces and namespace-service combinations that will exist in the cluster in the future. This is true for `default`, but not test namespaces, and NGINX will refuse to start with statically-configured clusters that it cannot reach. Making the server blocks make the routing decisions dynamically circumvents this limitation. However, this prevents usage of NGINX [upstream](http://nginx.org/en/docs/http/ngx_http_upstream_module.html) blocks that provide connection pooling, at least in the community edition, and as a result the gateways will create and terminate a TCP connection per http request. This likely causes minor delays on the front-end through gateway, but this hampers performance greatly in job scheduling. The batch driver is forced to establish a new TCP connection and do an SSL handshake with the internal-gateway multiple times per job, which is expensive and slow. We currently have to dedicate a 2-core NGINX sidecar for the batch-driver just to terminate",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12095:399,config,configure,399,https://hail.is,https://github.com/hail-is/hail/pull/12095,2,['config'],['configure']
Modifiability,"This is a name to IP address and port service. GKE exposes pod IPs onto our VDC; network. As such, regular Google Cloud VMs can access pods by IP. GKE cannot; expose our services as IPs on our VDC because the way services load balance; traffic is more complex than DNS can handle. We acknowledge and accept the; limitations of client-side load balancing. In particular, if there are not many; clients and clients re-use address-port-pairs traffic will likely be; unbalanced. This is not a problem for the planned Shuffle service because the; clients are intended to be numerous (consider all the workers in a Query or; Batch pipeline). The big change is that deploy config now has an `addresses` function which will; return a list of address-port pairs. Deploy config also now has `address` which; randomly chooses one of the address-port pairs. I have included a simple test. Please review both code and overall design, considering how it fits in the wider system.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9129:666,config,config,666,https://hail.is,https://github.com/hail-is/hail/pull/9129,2,['config'],['config']
Modifiability,"This is a pod running in default that mounts deploy-config and database-server-config. `mysql` will connect to the database as root. Useful for troubleshooting. I often have it running, but figure it should be official. Doesn't run in test since it doesn't have a database-server-config.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7819:52,config,config,52,https://hail.is,https://github.com/hail-is/hail/pull/7819,3,['config'],['config']
Modifiability,"This is a pretty simple change, though the diff is a little bizarre. I don't want running a ukbb server to be a requirement of running a hail instance. Since the ukbb app is a special case in the way we deploy apps in k8s, we would render the gateway configuration server blocks with the logic:. - For each service, if it's not ukbb, render it the usual way; - Render the ukbb block. This is a very simple change to instead make the logic. - For each service, if it's ukbb render it the ukbb way, else render it the usual way. Together with the separation of the ukbb terraform into its own module in #10842, it should be easier to deploy hail without the ukbb app and simplify the bootstrap process. This is currently running in hail-vdc.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10845:251,config,configuration,251,https://hail.is,https://github.com/hail-is/hail/pull/10845,1,['config'],['configuration']
Modifiability,"This is a prototype for just build 37. My plan is to add other genome builds, expose as variable in HailContext, and add support for reading JSON from a file not in the Java resources in subsequent PRs.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1780:88,variab,variable,88,https://hail.is,https://github.com/hail-is/hail/pull/1780,1,['variab'],['variable']
Modifiability,"This is a rebased update to the closed PR #3715. Updates:. - `locus_table` is now `locus_expr`, an expression on a table or matrix table. This is more flexible, and avoids unnatural requirements on key (rather than order). - uses `global_position` and requires/checks ascending order, rather than reordering within the method. Re-ordering, if non-trivial, would silently invalidate the results with respect to the row-order of the source. This also avoids a potentially unnecessary shuffle, and addresses the issue that contig order may not be alphabetical in the reference. - keeps the size of data collected close to the minimal data necessary (in particular, no collection of contigs). When `coord_expr` is not set, its an array of int. When `coord_expr` is set, its an array of (int, float). A tuple of arrays would be better, but directly collecting two arrays in order would require two actions with the current infrastructure since agg.collect() does not preserve order.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3873:151,flexible,flexible,151,https://hail.is,https://github.com/hail-is/hail/pull/3873,1,['flexible'],['flexible']
Modifiability,"This is a series of small refactorings in AppendOnlyBTree that removes; the folds in code generation, replacing a pattern that I find difficult; to follow with a more imperative CodeBuilder style that is necessary for; future changes to proceed as the folding style does not work well with; functions that need code builders.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9850:26,refactor,refactorings,26,https://hail.is,https://github.com/hail-is/hail/pull/9850,1,['refactor'],['refactorings']
Modifiability,"This is a simple refactor, that moves `Stream[A]` to a top-level class. Some of my wip depends on this, so it will be helpful to get it merged. This should also simplify merging `Stream` with the PType infrastructure, where `Stream` should become a `PCode`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8547:17,refactor,refactor,17,https://hail.is,https://github.com/hail-is/hail/pull/8547,1,['refactor'],['refactor']
Modifiability,"This is a simple refactoring of `lir.Emit` to directly use the core visitor based interface of ASM, rather than the higher level `tree` interface. This should have a small performance benefit, as we aren't building the in-memory tree representation only to immediately walk it with a visitor. But I also find this version of `Emit` slightly cleaner. For reference, you can find the documentation for ASM 5.1 [here](https://javadoc.io/doc/org.ow2.asm/asm/5.1/index.html).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9511:17,refactor,refactoring,17,https://hail.is,https://github.com/hail-is/hail/pull/9511,1,['refactor'],['refactoring']
Modifiability,"This is a simple tidying refactoring to hide the `children` array from consumers of `BaseIR`. My main motivation is to make it easier to explore other ir data structure designs, and to migrate to a new design in the future, e.g. to allow for in-place mutation without requiring large-scale changes to every compiler pass, and to simplify how we encode binding structure.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13214:25,refactor,refactoring,25,https://hail.is,https://github.com/hail-is/hail/pull/13214,1,['refactor'],['refactoring']
Modifiability,"This is a step towards requiring names on all generated objects.; - {Emit}{Class, Method, Function}Builder now takes a type parameter that represents (a supertype) of the class being built: e.g. MethodBuilder[C] is a builder for a method on a class of type C. Note, we can't have a type parameter that represents the actual class type because that doesn't exist yet.; - {Emit}FunctionBuilder all but gone: {Emit}FunctionBuilder is now just a {Emit}MethodBuilder is an apply method. Most functionality moved to {Emit}ClassBuilder.; - Added EmitClassBuilder.; - It is convenient to have e.g. MethodBuilder support the ClassBuilder interface: this is what the Wrapped traits are for: MethodBuilder extends WrappedClassBuilder and ClassBuilder extends WrappedModuleBuilder. So MethodBuilder has the ClassBuilder interface, but is not actually a ClassBuilder. I tried a bunch of variants for the design of this, and while I don't think this is quite perfect, it seems workable.; - EmitMethodBuilder extends WrappedMethodBuilder, etc. Rather than overloading, the two interfaces are distinct: genMethod vs genEmitMethod, etc.; - Pushed ""new vs gen"" into more places e.g. newMethod vs genMethod. newMethod takes a name and creates a method of that name (e.g. apply). genMethod takes a baseName and creates a unique name based on the baseName.; - MethodBuilder newField => genFieldThisRef to distinguish it from ClassBuilder.newField. The former returns a Settable[T] referencing `this.<field>`, the latter just returns a Field.; - All methods supporting code generation for IR take EmitMethodBuilder rather than MethodBuilder (PType routines, aggregators, etc.). Summarizing the new class structure:. ```; class ModuleBuilder; trait WrappedModuleBuilder; def modb: ModuleBuilder; class ClassBuilder[C] extends WrappedModuleBuilder; trait WrappedClassBuilder[C]; def cb: ClassBuilder[C]; class MethodBuilder[C] extends WrappedClassBuilder[C]; trait WrappedMethodBuilder[C]; def mb: MethodBuilder; class Funct",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8335:1260,extend,extends,1260,https://hail.is,https://github.com/hail-is/hail/pull/8335,1,['extend'],['extends']
Modifiability,This is a trivial (non-semantic) refactor.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10802:33,refactor,refactor,33,https://hail.is,https://github.com/hail-is/hail/pull/10802,1,['refactor'],['refactor']
Modifiability,"This is an adaptation of my comment on the TLS PR. I moved the old `tls.md` to `tls-cookbook.md`. Git doesn't realize that. Dania & @catoverdrive, y'all are probably the two folks most likely to benefit from tls.md, so I'd appreciate your comments on the readability of this document.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9196:11,adapt,adaptation,11,https://hail.is,https://github.com/hail-is/hail/pull/9196,1,['adapt'],['adaptation']
Modifiability,"This is an attempt to modularize / refactor our terraform code regarding google service accounts and kubernetes secrets. This doesn't add any new functionality. Currently, our use of terraform is one flat file `main.tf` where we declare every `resource` in GCP that should exist. Examples of such resources are `google_service_account`, `google_service_account_key` and `kubernetes_secret`. For each of the accounts we create for various services, we end up creating these three resources (and sometimes IAM roles) in the same way. To abstract this, we can create a custom `module`, which is just a collection of resources, a set of inputs called `variables`, and a set of outputs. A module can then be ""instantiated"" using a `module` block in `main.tf`, providing it the source path of the module and values for its declared variables. Tested by hand in my own GCP project.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10785:35,refactor,refactor,35,https://hail.is,https://github.com/hail-is/hail/pull/10785,3,"['refactor', 'variab']","['refactor', 'variables']"
Modifiability,This is an enhancement of #7498. We adjust the number of cores in a user's request to make sure they have enough memory based on the memory per core rather than giving them the exact resources they asked for.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7583:11,enhance,enhancement,11,https://hail.is,https://github.com/hail-is/hail/pull/7583,1,['enhance'],['enhancement']
Modifiability,"This is currently just dead code, although it could conceivably be useful in the future; I want to remove this for now as it's pretty simple to add back in at a later date (follows the pattern of Serialize/Deserialize Aggs pretty much exactly) and makes for less code to keep refactoring as we optimize the aggregator stuff.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6813:276,refactor,refactoring,276,https://hail.is,https://github.com/hail-is/hail/pull/6813,1,['refactor'],['refactoring']
Modifiability,"This is mostly straightforward, except in the case of PBinary and PString, where I elected to move static methods to instance methods. This was done because these methods completely depend on the PType, and having them as static methods prevents use of non-canonical versions of these methods (regardless of where they are). This includes functions like allocate, which deal with memory layout, and therefore must be configurable by ptype. Places where these static methods are used often include places where a PString or PBinary are passed around. Will finish this up after I get back most likely, or we can punt on the PStirng/PBinary issue for later (but I think it's worth doing now for the reasons outlined above). Stacked on https://github.com/hail-is/hail/pull/7903; ping @tpoterba",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7904:417,config,configurable,417,https://hail.is,https://github.com/hail-is/hail/pull/7904,1,['config'],['configurable']
Modifiability,This is needed for future genome reference pull requests to be able to access the ordering from the GenomeReference after the variable GR has been substituted for.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2528:126,variab,variable,126,https://hail.is,https://github.com/hail-is/hail/pull/2528,1,['variab'],['variable']
Modifiability,This is one piece of a multi-part saga to use tls for any and all communication between pods. This basically just required adding the `create_certs` step to the ci test `build.yaml` so we can create a ssl config for `hello`.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10192:205,config,config,205,https://hail.is,https://github.com/hail-is/hail/pull/10192,1,['config'],['config']
Modifiability,This is pretty bare bones but I thought this might help a lot with the testing of all your upcoming `hailctl config` changes rather than having to manually test various possible combinations. Run by just invoking pytest: `pytest hail/python/test/hailtop/hailctl/config`,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13389:109,config,config,109,https://hail.is,https://github.com/hail-is/hail/pull/13389,2,['config'],['config']
Modifiability,"This is runIfRequested deployment that simply has hail; and ipython installed. It facilitates developmnent of; services that interact with Hail Query (i.e. the Shuffler). I do this silly thing with a tar file because:; - I do not know the hail version (which is included in the wheel filename), so; - I am unable to copy it out with a variable name, and; - python refuses to install a wheel that does not have the version in the filename. I added `make update-hail-repl` to `hail/Makefile` which updates the hail wheel on the hail-repo without changing the pod or rebuilding the image. If the pod is restarted you lose your version, but the risk is worth the immense benefit of 5s deploys.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8194:335,variab,variable,335,https://hail.is,https://github.com/hail-is/hail/pull/8194,1,['variab'],['variable']
Modifiability,"This is running on hail-vdc/vdc. Summary:; - parameterize project; - gateway option to forward to letsencrypt only for bootstrapping; - service accounts for gateway, letsencrypt; - mysql instance running. I did not make default:default cluster admin, so it should have no special privileges. Changes are not yet being applied automatically.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4725:45,parameteriz,parameterize,45,https://hail.is,https://github.com/hail-is/hail/pull/4725,1,['parameteriz'],['parameterize']
Modifiability,"This is small addition on top of #2665, only review last commit if that has yet to go in. Here's the logic/plan: rows refers to actual rows as in RowMatrix or MatrixTable. nRows refers to the number of rows, as already used in GridPartitioner, RowMatrix, etc. Breeze uses mat.rows for nRows, but we'll still use nRows as variable name of number of rows in Hail's linear algebra. In Python, we'll use num_rows and num_cols.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2698:321,variab,variable,321,https://hail.is,https://github.com/hail-is/hail/pull/2698,1,['variab'],['variable']
Modifiability,This is stacked on https://github.com/hail-is/hail/pull/9842 which rewrites hailctl argument handling. Probably not worth reviewing until that is in.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9913:67,rewrite,rewrites,67,https://hail.is,https://github.com/hail-is/hail/pull/9913,1,['rewrite'],['rewrites']
Modifiability,"This is the common use case for collapsed burden testing, and will eventually be the input to linreg_burden and logreg_burden. The resulting table can by pushed to Python or PySpark for flexible analysis. Unlike in the burden regression methods, this table need not have numeric values, and it doesn't filter out samples with missing phenotype or covariates (since there are none to speak of here).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/1765:186,flexible,flexible,186,https://hail.is,https://github.com/hail-is/hail/pull/1765,1,['flexible'],['flexible']
Modifiability,"This is the current state of the C++ support. If you look at the tests in src/test/is/hail/nativecode/NativeCodeSuite.scala that should give a; quick overview of how it works, viz. 1. Generate C++ source code as a Scala String, then create a NativeModule which handles; the grunt work of getting it compiled, linked, and loaded, and allows you to look up functions; by name, and get a callable Scala object corresponding to the C++ function. 2. The NativeModule also allows the binary of the DLL to be passed around and instantiated; on other cluster nodes (but note that those nodes will need to have the correct versions of; the C++ runtime shared libraries in the right directories to allow symbols in the DLL to be; correctly resolved). This is not tested yet. 3. I have been using llvm-6.0.0 on Mac, and llvm-5.0 on linux. It makes a half-hearted attempt; to use whatever other compiler you have, but that may not work. We probably need to figure; out a standardized and automated way to get the right tools installed in the right place (and; get the right shared libraries on worker nodes). 4. Data which needs to be accessible to both Scala and C++ is held in C++ objects inheriting; from NativeObj, with lifetimes managed by std::shared_ptr, i.e. reference-counted. There's; some dirty under-the-hood plumbing to allow a shared_ptr to be smuggled into a Scala; object derived from NativeBase. These Scala-side object references must be managed; carefully using copyAssign/moveAssign/close in order to maintain the off-heap ref-counts. 5. There are some gnarly differences between Linux and MacOSX in the linker and dynamic; loading. I think I'm converging on the right compile/link options for each, but in getting; Linux to work it's possible that Mac is temporarily broken ... Not really expecting that we'll merge this right away, but I wanted to put it out there to get the; review process started before it grows any bigger.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3461:1179,inherit,inheriting,1179,https://hail.is,https://github.com/hail-is/hail/pull/3461,1,['inherit'],['inheriting']
Modifiability,"This is the final stop for now on our nginx tour. This builds on #10207, which altered `internal.hail.is` use k8s dns instead of router/router-resolver to proxy directly to services, and does so in default now as well. Unlike #10207, however, traffic coming in through `hail.is` is not necessarily authenticated, and we do not expose just any k8s service that happens to exist. Instead, I've altered `letsencrypt/domains.txt` to now be `letsencrypt/subdomains.txt` and templated the gateway config to generate explicit server blocks for each subdomain in `subdomains.txt`. This enforces that you cannot expose a service unless it is also listed in the `letsencrypt` directory (the dev must still remember to regenerate the certs). Now, the process for exposing a service is:; - Add a subdomain to `subdomains.txt`; - Make a k8s Service with the name of the subdomain that points to new app; - Regenerate certs and redeploy gateway. Also added a default server block that returns a 444 (no response) for invalid subdomains. Unfortunately this still presents to the user that the cert is invalid, since *.hail.is is registered in dns (I think?) and browsers will verify certificates before anything else, but users won't be able to click through and land at the website like they could before.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10247:491,config,config,491,https://hail.is,https://github.com/hail-is/hail/pull/10247,1,['config'],['config']
Modifiability,"This is the first step to removing batch workers' reliance on the docker daemon and docker in general, in favor of a lower level of abstraction that gives us finer control over resources on the worker like overlays and network namespaces, allowing us to shortcut and pre-configure some of the overhead that goes into running a job. ## What this does differently; Currently, the high-level process for running a job involves communicating with the docker daemon to:; 1. Pull an image for a job; 2. Start a container from that image; 3. Run the container; 4. Delete the container and its associated resources. We offload some of these responsibilities into the worker code and onto [crun](https://github.com/containers/crun), a lightweight low-level runtime with the same API as `runc`, what docker uses to run containers. Once docker has retrieved an image, if we see that the pulled image has a new digest from one we currently have cached on the worker, we extract the image's filesystem into a directory on the worker's disk. We then:. - use `mount` to create an overlay on top of the image that the container will use as its rootfs; - use `xfs_quota` to limit the container's storage in the overlay; - invoke `crun` to run a container with the overlay as its root filesystem and an appropriate network namespace that we set up at worker-start time. Since we control the overlay, we can set the XFS quota before creating the container. So what was separate calls to docker create/start/run/delete is just a single `crun run`. Fewer steps, less back and forth with a single daemon, and pre-configuring the networks gives some sizable performance gains reliable, as well as reliable and consistent performance. ## What this doesn't solve; - Docker is still running the worker container. I don't see any real challenge to this it's just a matter of translating the docker parameters; - Still using docker to pull images and extract filesystems / environment variables from them. I don't have a substitu",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10376:271,config,configure,271,https://hail.is,https://github.com/hail-is/hail/pull/10376,1,['config'],['configure']
Modifiability,"This is the precursor to a follow-up PR which removes `IntervalTree`. `IntervalTree` was doing two jobs: handling queries against the range bounds of a partitioner, which have (essentially) no overlap, and in these interval join methods, where they may overlap arbitrarily. It ended up being suboptimal for both use cases. This PR rewrites the interval join methods, which should now be faster, and no longer depends on `IntervalTree`. The existing interval join methods only supported distinct joins (`product = false`). The implementation I wrote won't work for the `product = true` case, but I have a plan for that, which will fit into the structure I started here.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4487:331,rewrite,rewrites,331,https://hail.is,https://github.com/hail-is/hail/pull/4487,1,['rewrite'],['rewrites']
Modifiability,This is unused and the same as `INTERNAL_GATEWAY_IP` a few variables down,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12005:59,variab,variables,59,https://hail.is,https://github.com/hail-is/hail/pull/12005,1,['variab'],['variables']
Modifiability,"This is why copying is so slow:. ```; ==> NOTE: You are uploading one or more large file(s), which would run; significantly faster if you enable parallel composite uploads. This; feature can be enabled by editing the; ""parallel_composite_upload_threshold"" value in your .boto; configuration file. However, note that if you do this large files will; be uploaded as `composite objects; <https://cloud.google.com/storage/docs/composite-objects>`_,which; means that any user who downloads such objects will need to have a; compiled crcmod installed (see ""gsutil help crcmod""). This is because; without a compiled crcmod, computing checksums on composite objects is; so slow that gsutil disables downloads of composite objects. / [1/1 files][ 4.1 GiB/ 4.1 GiB] 100% Done 45.8 MiB/s ETA 00:00:00; Operation completed over 1 objects/4.1 GiB.; ```. We can also set this with -o GSUtil:parallel_composite_upload_threshold on the command line. https://cloud.google.com/storage/docs/gsutil/commands/cp. We currently use `-m` which is parallel per-file:. If you have a large number of files to transfer you might want to use the; gsutil -m option, to perform a parallel (multi-threaded/multi-processing); copy:. gsutil -m cp -r dir gs://my-bucket",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7024:277,config,configuration,277,https://hail.is,https://github.com/hail-is/hail/pull/7024,1,['config'],['configuration']
Modifiability,"This issue could have been an RFC, but that felt too heavy. I can move this to a formal RFC if desired, but otherwise feedback and/or questions welcome in the discussion here. # Idea; For any key type, create an encoding to variable-length byte arrays, which preserves the key ordering. That way, algorithms and data structures which use key comparisons can be written monomorphically, with `memcmp` as the only comparison function needed. Idea inspired by [Fast and Memory Efficient Multi-Column Sorts in Apache Arrow Rust](https://arrow.apache.org/blog/2022/11/07/multi-column-sorts-in-arrow-rust-part-2/) blog post. But while they've optimized for vectorized encoding (which we currently can't do), I've preferred simplicity and smaller encodings. # Design; Type encoders can emit three kinds of output to a byte array buffer:; - byte - simply add a byte to the result, first padding an incomplete byte if necessary; - bit - add a bit to the result, possibly leaving an incomplete byte. We must know statically how many bits are used in the byte.; - pad - add `0`s to pad the last incomplete byte. This is safe (prefix-free) because the number of used bits is a (statically known) constant. We use this to ensure the number of used bits is known statically.; 	; Types:; - missingness; - treat as a type constructor `optional<T>`, i.e. base types don't encode missingness. Emits a single bit in the encoding. Can invert this bit to control whether missing values come first or last in the ordering. If missing, nothing is emitted after.; - sort-order; - treat reversing the default ordering as a type constructor `reverse<T>`; - simply inverts the encoding bitwise; - primitive types; - same as in datafusion, encoding has same size as original type; - signed integers - flip the sign bit; - floating point numbers - if sign bit is set, invert all bits, otherwise only flip the sign bit; - arrays; - before each element and after last element, emit continuation bit (0 if no more elements); - pad be",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14396:224,variab,variable-length,224,https://hail.is,https://github.com/hail-is/hail/issues/14396,1,['variab'],['variable-length']
Modifiability,"This larger benchmark shows clearer separation between the old pc-relate approach and the current one. this branch (which include's master's improvements); ```; 2020-01-27 13:16:20,975: INFO: [1/1] Running pc_relate_big...; 2020-01-27 13:18:12,886: INFO: burn in: 111.90s; 2020-01-27 13:19:56,255: INFO: run 1: 103.35s; 2020-01-27 13:21:46,801: INFO: run 2: 110.54s; 2020-01-27 13:23:39,147: INFO: run 3: 112.37s; {""config"": {""cores"": 1, ""version"": ""0.2.31-68d448411ab5"", ""timestamp"": ""2020-01-27 13:23:39.157122"", ""system"": ""darwin""}, ""benchmarks"": [{""name"": ""pc_relate_big"", ""failed"": false, ""timed_out"": false, ""times"": [103.35172498200001, 110.53654034999997, 112.369625832]}]}; ```; before improvements `becbbc6d2` (run against this branch's new benchmark); ```; 2020-01-27 13:25:15,789: INFO: [1/1] Running pc_relate_big...; 2020-01-27 13:27:25,725: INFO: burn in: 129.92s; 2020-01-27 13:29:44,260: INFO: run 1: 138.48s; 2020-01-27 13:31:49,675: INFO: run 2: 125.40s; 2020-01-27 13:33:59,580: INFO: run 3: 129.86s; ```. cc: @tpoterba",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7975:416,config,config,416,https://hail.is,https://github.com/hail-is/hail/pull/7975,1,['config'],['config']
Modifiability,"This leverages open batches to submit all QoB stages as updates to the same batch the Query Driver is running in. Most of this implementation feels uncontroversial, but there is a backwards-incompatible change to the JVMJob that I don't love. I needed to let the Query Driver know which batch it's running in and did so by adding that as another argument to main. I initially wanted this as an environment variable, but considering that these containers are long-lived I wasn't quite sure how to do that.; I didn't stack this on open batches so this won't work until that goes in but the changes are entirely disjoint",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12222:406,variab,variable,406,https://hail.is,https://github.com/hail-is/hail/pull/12222,1,['variab'],['variable']
Modifiability,"This leverages the Indeed LSM tree. It implements this API:; - `start(...)`; - `put(x1, ...)` (keys are extracted from the records themselves); - `get(l, r)` which takes two key records and retrieves the values in `[l, r)`. There's a server (`ShuffleServer.scala`) and a client (`ShuffleClient.scala`). They communicate over TLS-secured TCP/IP sockets on a configurable port. The server has one thread per client socket. The client is currently single-threaded. I had to add a `log4j.properties` because I don't start a HailContext and log4j gets upset when you don't configure it. Files; - `HailLSM.scala` - This wraps the Indeed LSM tree with some shims so that we encoders and decoders use `InputStream` and `OutputStream` instead of these were `Data...` interfaces.; - `HailSSLContext.scala` - This implements creation of an actually secure `SSLContext` from a key store and a trust store. It requires clients to identify themselves with a trusted certificate.; - `ShuffleClient.scala` - Self-explanatory.; - `ShuffleServer.scala` - Three classes: `Handler` corresponds to a client connection. It has its own thread. `Shuffle` owns the `Region` , the LSM tree, and the encoder/decoders. `ShuffleServer` waits for connections and spawns threads. It owns the executor service.; - `ShuffleUtils.scala` - Odds and ends.; - `Wire.scala` - Serializers and deserializers for various things. Includes renames that help me keep everything sensible (e.g. for every X I use, I have ""writeX"" and ""readX"").; - `ShuffleSuite.scala` - One test: write 1,000,000 randomly ordered numbers into the LSM tree and read them all back in order. Takes about 1 minute. Obviously we need to dramatically improve the performance of that (I think this should take not longer than one second).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8361:357,config,configurable,357,https://hail.is,https://github.com/hail-is/hail/pull/8361,2,['config'],"['configurable', 'configure']"
Modifiability,This logic can happen at config time instead of runtime.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11026:25,config,config,25,https://hail.is,https://github.com/hail-is/hail/pull/11026,1,['config'],['config']
Modifiability,This means people who don't use hailctl get these configurations.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7739:50,config,configurations,50,https://hail.is,https://github.com/hail-is/hail/pull/7739,1,['config'],['configurations']
Modifiability,"This mirrors the functionality available on `TypedCodecSpec`. In some cases (the shuffler),; you might be handed a buffer that is already configured, but you still want to create a; decoder whose PType is known to be a subtype of PStruct.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8766:138,config,configured,138,https://hail.is,https://github.com/hail-is/hail/pull/8766,1,['config'],['configured']
Modifiability,"This moves the nginx proxy configuration out of router and into a sidecar in the notebook/workshop pod. This extends TLS termination from router to the notebook pod and consolidates the notebook routing logic. I didn't run a scale test but this doesn't change any functionality, and I tested in dev that I could log in to a workshop, start and open a notebook.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10204:27,config,configuration,27,https://hail.is,https://github.com/hail-is/hail/pull/10204,2,"['config', 'extend']","['configuration', 'extends']"
Modifiability,"This opens the possibility for compiler differences to fail builds for our users. The CI server should simply set CXX and CC to clang and rebuild hail. Moreover, we need to ensure the hail build system passes these variables all the way down to `libsimdpp`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1327:215,variab,variables,215,https://hail.is,https://github.com/hail-is/hail/issues/1327,1,['variab'],['variables']
Modifiability,"This probably needs a little cleanup. What's this for? Well, in another branch I have a bunch of IR rewrite optimizations. Those rewrite rules (1) want to test types (e.g. eliminate a cast of a type to itself), and they (2) also want to create new IRs which therefore need well-formed types. Calculating all the intermediate types explicitly (or calling Infer) everywhere both seem like non-starters. Therefore, I changed the IR nodes to compute their own types. I repurposed Infer, but it is no longer recursive. This meant that In, InAgg and Ref needed to carry their types, becuase, in the old, Infer-based way, they were dependent on the environment to type themselves, but that's no longer possible. I also repurposed Infer as a recursive type checker. This created two subtle problems: (1) the IR code uses rvRowType everywhere in stead of rowType (so it can reuse pointers to the full row) and (2) toIR needs to set the Ref type from the symbol table, but the symbol table strips out all missing bits, so the types on Ref terms disagreed with the actual values flowing around. I resolved this in two ways: (1) va now refers to the full rvRowType in all eval contexts, everywhere. (This is closer to the existing IR behavior.) (2) the symbol table no longer strips missingness, but it is stripped by Ref when the symbol is referenced. Ref also records the unstripped type which is used by toIR. The sooner we can kill AST, the better.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3332:100,rewrite,rewrite,100,https://hail.is,https://github.com/hail-is/hail/pull/3332,2,['rewrite'],['rewrite']
Modifiability,"This proposes a way to test `hailctl dataproc`, starting with `hailctl dataproc start`. 1. Move `subprocess` calls to run gcloud commands and get gcloud configuration to a separate `gcloud` module. This module serves as a convenient place to insert mocks in tests.; 2. Automatically (with pytests's `autouse`) mock calls to the `gcloud` module's methods in tests. This prevents actually running `gcloud` in tests. This also provides a pytest fixture to set the mocked `gcloud` configuration values.; 3. Add some tests for `hailctl dataproc start`. These tests pass arguments to `cli.main` and make assertions about the resulting `gcloud` command(s).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9066:153,config,configuration,153,https://hail.is,https://github.com/hail-is/hail/pull/9066,2,['config'],['configuration']
Modifiability,"This pull request lowers the TableAggregate node. It also reimplements; the AggStateValue and CombOpValue nodes. However, this is not the final design -- I think that there should also; be an InitFromSerializedValue node that is used to prevent us from; initializing twice (and inlining aggs.init in the lowering). feel free to push back on merging this before that refactoring, but it works and I have a preference for making that change in a followup. After that, I'll move on to lowering TableMapRows with scans, as well as designing the pass to lift out nodes as relational lets that we discussed. Woohoo!",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8991:366,refactor,refactoring,366,https://hail.is,https://github.com/hail-is/hail/pull/8991,1,['refactor'],['refactoring']
Modifiability,"This refactors the parser to use `BindingEnv`, which tracks the separate eval, agg, scan, and relational environments. This was motivated by the new randomness work, which needs to be able to rebind row and col references in both eval and agg scopes, which was breaking the parser. I don't like duplicating the (rather complicated) binding behavior of the nodes, but I couldn't find a way to avoid it without a much larger refactoring of the IR. So I tried to make the binding logic in the parser be as direct a copy of what is encoded in `Binds.scala` as possible. For example, relational nodes always pass `env.onlyRelational` to their children, which isn't necessary if we ensure that only relational bindings exist in environments passed to relational nodes, but it matches the logic in `Binds`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12289:5,refactor,refactors,5,https://hail.is,https://github.com/hail-is/hail/pull/12289,2,['refactor'],"['refactoring', 'refactors']"
Modifiability,This removes unused google-specific environment variables from the auth modules.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10899:48,variab,variables,48,https://hail.is,https://github.com/hail-is/hail/pull/10899,1,['variab'],['variables']
Modifiability,"This should be configurable, but that was harder than I expected. This should cut down on the number of class A operations we do a bit. It is quite high right now.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11984:15,config,configurable,15,https://hail.is,https://github.com/hail-is/hail/pull/11984,1,['config'],['configurable']
Modifiability,This should be just a simple refactoring in anticipation of having bunches for job groups as well.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13448:29,refactor,refactoring,29,https://hail.is,https://github.com/hail-is/hail/pull/13448,1,['refactor'],['refactoring']
Modifiability,"This simply adds the wrapping structure + header from app.hail.is. Includes no scss from app.hail.is. That will be the next PR unless you want it here. We should also decide whether we want a home page (the smoothly-rising Hail that Arcturus liked), i.e whether this will be extended with a link to batch, or not (we discussed the option at our last meeting). cc @cseed",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5429:275,extend,extended,275,https://hail.is,https://github.com/hail-is/hail/pull/5429,1,['extend'],['extended']
Modifiability,"This the beginning of some Code infrastructure changes and cleanup. The plan is to clean up the tangle of builder classes. I'm still working on the plan for dependent functions, but the skeleton of the rest looks like:. ```; class ClassBuilder[C]; def newMethod(suffix: String, argsInfo: Array[TypeInfo[_]], returnInfo: TypeInfo[_]): MethodBuilder; def newField[T]: ...; def result(): () => C. class MethodBuilder:; def newLocal[T]: LocalRef[T]; def emit(c: Code): Unit. class FunctionBuilder[C]:; val classBuilder: ClassBuilder[C]; def applyMethod: MethodBuilder; def result(): () => C = classBuilder.result(). class EmitMethodBuilder; val mb: MethodBuilder // contain don't extend; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8179:676,extend,extend,676,https://hail.is,https://github.com/hail-is/hail/pull/8179,1,['extend'],['extend']
Modifiability,"This was an easy one, since we already had `BlockMatrixBroadcast` lowered. All `ValueToBlockMatrix` does is make a tiny 1x1 BlockMatrix that can later be broadcast. I kind of think this is a weird IR design and that we should actually have a `BlockMatrixBroadcast` that takes a value `IR` child instead of a `BlockMatrixIR`, but I'll experiment with that refactoring later. Trying to just get the current thing lowered.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10426:355,refactor,refactoring,355,https://hail.is,https://github.com/hail-is/hail/pull/10426,1,['refactor'],['refactoring']
Modifiability,"This was left over from the old AST parsing stuff and I don't think it's used anymore (except in one test, which I just refactored).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6946:120,refactor,refactored,120,https://hail.is,https://github.com/hail-is/hail/pull/6946,1,['refactor'],['refactored']
Modifiability,This was preventing use of cache when building the notebook leader image. The `$*` variable is for use with [Pattern Rules](https://www.gnu.org/software/make/manual/html_node/Automatic-Variables.html#Automatic-Variables). Still note sure why the build is failing.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5226:83,variab,variable,83,https://hail.is,https://github.com/hail-is/hail/pull/5226,3,"['Variab', 'variab']","['Variables', 'variable']"
Modifiability,"This was the patch I had to apply to fix the 500s that we had yesterday in PR pages. The URI to URL rewrite enforced GCP which caused the 500. I removed the assertion but don't know yet the proper way to link to a **private** blob storage containers so I just return the URI. I looked at the [canonical URL for blob storage containers](https://docs.microsoft.com/en-us/rest/api/storageservices/naming-and-referencing-containers--blobs--and-metadata#resource-uri-syntax) but appears to only work for public containers. When I looked up how to get a URL for private containers, I get a lot of articles on SAS URLs that bake a token into the URL -- not what we want. We really just use this to link to the portal/console, but when I went to the portal the URL contains subscription-specific parameters that we don't have based on just the URI. This was the point where I figured our time was best spent elsewhere… Unless I'm missing something obvious, I can add this to the bottom of the TODO list. I also fixed the deploy_steps environment variable to match what was actually declared in the ci/deployment.yaml",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11121:100,rewrite,rewrite,100,https://hail.is,https://github.com/hail-is/hail/pull/11121,2,"['rewrite', 'variab']","['rewrite', 'variable']"
Modifiability,"This will hopefully make it easier to develop QoB. Now, running `make -C hail install-for-qob NAMESPACE=default` will push a jar and configure hailctl to use that jar. So `make -C hail install-for-qob NAMESPACE=default && ipython` will drop you into an ipython session pointed at production where any hail queries reflects your local code. `make -C hail pytest-qob NAMESPACE=default PYTEST_ARGS='-k test_foo'` runs `test_foo` with any of your current changes. Things to note:; - Variables like `QUERY_STORAGE_URI` are lazy so this should hopefully not break any current usages of the file for non-developers; - You are at no risk of overwriting a release jar unless you specify `UPLOAD_RELEASE_JAR=true` in the make invocation.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12342:133,config,configure,133,https://hail.is,https://github.com/hail-is/hail/pull/12342,2,"['Variab', 'config']","['Variables', 'configure']"
Modifiability,"This works better with my environment and it means that, e.g., Brandon, only needs Java and python set up correctly to run: `git clone ... && cd hail/hail && make pytest`. No environment variables, no packages to install.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6561:187,variab,variables,187,https://hail.is,https://github.com/hail-is/hail/pull/6561,1,['variab'],['variables']
Modifiability,Those env variables most have been copy-pasted from another step because they're neither correct nor necessary. I tried downloading the batch-gsa-key and running `upload-query-jar` with it as the credentials and it succeeded.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11881:10,variab,variables,10,https://hail.is,https://github.com/hail-is/hail/pull/11881,1,['variab'],['variables']
Modifiability,"Three changes:. 1. I noticed the costs were all 0. I think this is due to `cores_mcpu INTO cores_mcpu` scoping issues in the attempt triggers, where the local variable was always zero. At least changing the local variable name immediately fixed the problem. 2. I wrote a test to verify the costs were non-zero and consistent with the reported timing for the succeeding job. It is hard to do on the cost string, so I included msec_mcpu in the batch/job status response to verify it. In trying to verify it, I noticed that timestamps in the attempts table were slightly truncated compared to start/end times in the status (JSON). This lead to rounding errors and slight disagreement. 3. Rather descend into the floating point rabbit hole of madness, I changed times everywhere to be stored as integers in milliseconds (like unix time, since the epoch). In the database, they are not BIGINT. Millisecond resolution seems fine for everything we're building. 4. (Bonus change!) Don't let timing for jobs be negative. This will require another reset.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7628:159,variab,variable,159,https://hail.is,https://github.com/hail-is/hail/pull/7628,2,['variab'],['variable']
Modifiability,"To do this add an intermidiate abstract PartitionWriter,; SimplePartitionWriter, and extend it with TextTablePartitionWriter. SimplePartitionWriter manages the output stream for its subclasses. The; subclasses need to implement consumeElement, and optionally preConsume; and postConsume. TextTablePartitionWriter handles the delimiter delimited writing per; element item and the line delimited writing per element of the stream.; It will also optionally write the header if ExportType.PARALLEL_HEADER_IN_SHARD; has been requested. TextTableFinalizer is the 'MetadataWriter' (name change pending), for; TextTableWriter. That's where the header is written for; PARALLEL_SEPARATE_HEADER and CONCATENATED, and files are merged for; CONCATENATED. There are currently a few idosyncracies that don't replicate bug-for-bug; compatibility with the non-lowered version. 1. We avoid the use of fs.copyMerge, as such, we don't check for the; existence of the _SUCCESS file (even though we create it).; 2. ExportType.PARALLEL_COMPOSABLE is unsupported.; 3. We rely on the temporary file cleaner to clean up the files; created for CONCATENATED export, rather than deleting them; explicitly.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11323:85,extend,extend,85,https://hail.is,https://github.com/hail-is/hail/pull/11323,1,['extend'],['extend']
Modifiability,"To enable easy testing, I also parameterized the methods by the branchingFactor and broke generation of the byte array away from writing the byte array to a file. The key issue is that `k * 1024 % 1024 = 0` for any integer `k`, which we were interpreting as meaning that the last block needed 1024 more elements to be full. There are no errors on write. On read, we try to calculate the number of layers present in the BGEN using `calcDepth` but this fails to correctly guess the layers when the size of the file is not a positive integral power of 1024. The only real changes (the rest are restructuring/whitespace) are using `branchingFactor` in place of `1024` and replacing; ```; - // Pad last layer so last block is 1024 elements (1024*8 bytes); - val paddingRequired = 1024 - (arr.length % 1024); ```; with; ```; + // Pad last layer so last block is branchingFactor elements (branchingFactor*8 bytes); + val danglingElements = (arr.length % branchingFactor); + val paddingRequired =; + if (danglingElements == 0) 0; + else branchingFactor - danglingElements; ```. cc: @jigold one of the PRs you asked me to break out.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/3750:31,parameteriz,parameterized,31,https://hail.is,https://github.com/hail-is/hail/pull/3750,3,"['layers', 'parameteriz']","['layers', 'parameterized']"
Modifiability,To make uber jar: `mvn assembly:single`. `compile` automatically runs `make` for the NativeLib stuff.; `clean` automatically runs `make clean` for NativeLib; Not sure if I needed to incorporate `nativeLibTest` or `nativeLibPrebuilt`. Added two test configurations. One is for all tests and the other is for the set of tests with HAIL_ENABLE_CPP_CODEGEN=1. I double checked the Python tests pass with the uber jar. The test output doesn't have the nice formatting that we have in Gradle. Would be some work with listeners and reporters to do that: http://maven.apache.org/surefire/maven-surefire-plugin/examples/testng.html#. There also isn't the `check` input and some other bells and whistles we have in Gradle. I had to add `com.google.inject:guice` to get rid of some compile warnings with the test-jar. Let me know if there's other things to add/enable or if this is good enough for ci2. We should probably add some CI tests for this in a makefile somewhere.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5906:249,config,configurations,249,https://hail.is,https://github.com/hail-is/hail/pull/5906,2,"['config', 'plugin']","['configurations', 'plugin']"
Modifiability,"To properly implement IR sets, I need to staged UnsafeOrdering's, or, at the very least, I need to be able to call them from `Code`-land. Since objects at IR-compile-time are not available at IR-run-time (without shipping them to the nodes and passing them as arguments, which I'd like to avoid), I must be able to call static methods, or have fully code-ified versions of every UnsafeOrdering used in the IR. Whenever possible, I tried to call static methods. In a few cases, I couldn't figure out how to make that work, so I had to reimplement the operation in `Code`. I also had to introduce `BindingCode[T]` which is a type alias for `(FunctionBuilder, StagedBitSet) => Code[T]`. The function builder is used to allocate new variables and the `StagedBitSet` is used to compactly store boolean values. I am also somewhat confused by the `missingGreatest` parameter which existed on the original `UnsafeOrdering`s (which I refactored while Code-ifying). cc: @cseed, I guess this parameter is only sensible on compound data? It seems like there should be a:. ```; def compare(r1: MemoryBuffer, o1: Long, m1: Boolean, r2: MemoryBuffer, o2: Long, m2: Boolean): Int; ```. which correctly applies the `missingGreatest` parameter.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/2519:729,variab,variables,729,https://hail.is,https://github.com/hail-is/hail/pull/2519,2,"['refactor', 'variab']","['refactored', 'variables']"
Modifiability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: ; https://discuss.hail.is/. Please include the full Hail version and as much detail as possible. -----------------------------------------------------------------------------; First of all, thank you for making such a highly integrated tool. . I learned that this tool could be run in two modes, on Cloud and locally. Well, I happen to have an HPC server that I can work on, so I'd love to use the tool locally. However, many annotation tools require many annotation data that need to be prepared in advance, and no one has seen the exact format of them. Plus, the annotation data sometimes is stored on a google cloud bucket that is requester paid so I don't have a chance to take a peek at them. Therefore, even I try to fill my configuration file, the annotation data needed cannot be prepared unless I have a template of them. . Pls, consider adding a feature like, if we want to run an annotation job locally, let us download package containing all the necessary annotation data in there. So we can set up the configuration file on our own and run the job on a local HPC server. Much appreciated!",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9059:848,config,configuration,848,https://hail.is,https://github.com/hail-is/hail/issues/9059,2,['config'],['configuration']
Modifiability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: ; https://discuss.hail.is/. Please include the full Hail version and as much detail as possible. -----------------------------------------------------------------------------; Versions of software products:. Running on Apache Spark version 2.4.5; SparkUI available at http://vhabosgen72:4040; Welcome to; __ __ <>__; / /_/ /__ __/ /; / __ / _ `/ / /; /_/ /_/\_,_/_/_/ version 0.2.61-3c86d3ba497a; LOGGING: writing to /dacs1/team/vhabhsxum/tasks/ancestryPainting/hail-20210125-1235-0.2.61-3c86d3ba497a.log. I am running the GWAS tutorial hosted at https://hail.is/docs/0.2/tutorials/01-genome-wide-association-study.html#Let's-do-a-GWAS. Everything is OK until the line to do GWAS. The error I have is as follows:. -------------- start of error ------------------; 2021-01-25 12:36:11 Hail: INFO: linear_regression_rows: running on 250 samples for 1 response variable y,; with input variable x, and 1 additional covariate...; ERROR:root:Exception while sending command.; Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1159, in send_command; raise Py4JNetworkError(""Answer from Java side is empty""); py4j.protocol.Py4JNetworkError: Answer from Java side is empty. During handling of the above exception, another exception occurred:. Traceback (most recent call last):; File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 985, in send_command; response = connection.send_command(command); File ""/fnas/tools/anaconda3/envs/R_361/lib/python3.6/site-packages/py4j/java_gateway.py"", line 1164, in send_command; ""Error while receiving"", e, proto.ERROR_ON_RECEIVE); py4j.protocol.Py4JNetworkError: Error while receiving; ERROR:py4j.java_gateway:An error occurred while trying to connect to the Java server (127.0.0.1:44859); Traceback (most recent call last):; File ",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/9939:975,variab,variable,975,https://hail.is,https://github.com/hail-is/hail/issues/9939,2,['variab'],['variable']
Modifiability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version:. devel-406fc7f6af42. ### What you did:. Calling `export_elasticsearch` without a `config` argument works fine.; ```python; hl.export_elasticsearch(table, ""host"", 9200, ""someindex"", ""sometype"", 1000, config=None); ```. However, attempting to pass `config`, for example:; ```python; es_config = {""es.write.operation"": ""index""}; hl.export_elasticsearch(table, ""host"", 9200, ""someindex"", ""sometype"", 1000, config=es_config); ```; causes the following error:. ### What went wrong (all error messages here, including the full java stack trace):. ```; Traceback (most recent call last):; File ""/tmp/0ba8fc2c770d4b2ba96dc23c50fd6eab/load_clinvar_to_es.py"", line 105, in <module>; verbose=True,; File ""/tmp/0ba8fc2c770d4b2ba96dc23c50fd6eab/hail_v02_scripts.zip/hail_v02_scripts/utils/elasticsearch/client.py"", line 234, in export_table_to_elasticsearch; File ""/home/hail/hail.zip/hail/typecheck/check.py"", line 547, in wrapper; File ""/home/hail/hail.zip/hail/methods/impex.py"", line 1885, in export_elasticsearch; File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py"", line 1133, in __call__; File ""/home/hail/hail.zip/hail/utils/java.py"", line 188, in deco; File ""/usr/lib/spark/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py"", line 323, in get_return_value; py4j.protocol.Py4JError: An error occurred while calling z:is.hail.io.ElasticsearchConnector.export. Trace:; py4j.Py4JException: Method export([class is.hail.table.Table, class java.lang.String, class java.lang.Integer, class java.lang.String, class java.lang.String, class java.lang.Integer, class java.util.HashMap, class java.lang.Boolean]) does not exist; 	at py4j.reflection.ReflectionEngine.getMethod(ReflectionEngine.java:318); 	at py4j.reflection.ReflectionEngine.getM",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/4063:335,config,config,335,https://hail.is,https://github.com/hail-is/hail/issues/4063,4,['config'],['config']
Modifiability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version:; 0.2; ### What you did:; Export hail table to elasticsearch; >>> hl.utils.get_movie_lens('data/'); >>> users = hl.read_table('data/users.ht'); >>> hl.export_elasticsearch(users, 'XX.XXX.XXX.XXX', XXXX, 'data', 'variant', 200,config=N; one, verbose=True). ### What went wrong (all error messages here, including the full java stack trace):. Error:; Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""</usr/local/lib/python3.6/site-packages/decorator.py:decorator-gen-1118>"", line 2, in export_elasticsearch; File ""/opt/hail-on-EMR/src/hail/hail/build/distributions/hail-python.zip/hail/typecheck/check.py"", line 561, in wrapper; File ""/opt/hail-on-EMR/src/hail/hail/build/distributions/hail-python.zip/hail/methods/impex.py"", line 2104, in export_elasticsearch; File ""/opt/hail-on-EMR/src/hail/hail/build/distributions/hail-python.zip/hail/table.py"", line 101, in __getattr__; AttributeError: Table instance has no attribute '_jt'",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5583:478,config,config,478,https://hail.is,https://github.com/hail-is/hail/issues/5583,1,['config'],['config']
Modifiability,"To report a bug, fill in the information below. ; For support and feature requests, please use the discussion forum: http://discuss.hail.is/. -------------------------------------------------------------------------------------------. ### Hail version:; 0.2; ### What you did:; users = hl.read_table('data/users.ht'); hl.export_elasticsearch(users, 'XX.XXX.XXX.XXX', 32565, 'users', 'movies', 200,config=None, verbose=True ). ### What went wrong (all error messages here, including the full java stack trace):; Gotten this error even though the elasticsearch IP and port number 32565 is correct. The IP mentioned in the error 192.168.185.157:9200 was not found anywhere in our EMR or elasticsearch cluster. ; >>> hl.export_elasticsearch(users, 'XX.XXX.XXX.XXX', 32565, 'users', 'movies', 200,config=None, verbose=True ); Config Map(es.nodes -> XX.XXX.XXX.XXX, es.port -> 32565, es.batch.size.entries -> 200, es.index.auto.create -> true); [Stage 0:> (0 + 32) / 65]Traceback (most recent call last):; File ""<stdin>"", line 1, in <module>; File ""</usr/local/lib/python3.6/site-packages/decorator.py:decorator-gen-1122>"", line 2, in export_elasticsearch; File ""/opt/hail-on-EMR/src/hail/hail/build/distributions/hail-python.zip/hail/typecheck/check.py"", line 561, in wrapper; File ""/opt/hail-on-EMR/src/hail/hail/build/distributions/hail-python.zip/hail/methods/impex.py"", line 2106, in export_elasticsearch; File ""/usr/lib/spark/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py"", line 1257, in __call__; File ""/opt/hail-on-EMR/src/hail/hail/build/distributions/hail-python.zip/hail/utils/java.py"", line 227, in deco; hail.utils.java.FatalError: EsHadoopNoNodesLeftException: Connection error (check network and/or proxy settings)- all nodes failed; tried [[192.168.185.157:9200, 192.168.81.209:9200]] . Java stack trace:; org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 0.0 failed 4 times, most recent failure: Lost task 1.3 in stage 0.0 (TID 73, ip-172-31-10-234.ap",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5643:397,config,config,397,https://hail.is,https://github.com/hail-is/hail/issues/5643,3,"['Config', 'config']","['Config', 'config']"
Modifiability,"True`.; - `raise_for_status`: this parameter now defaults to `True` and includes the; response body text in the error message. Both; Both parameters may be overridden on a per-request basis. - `httpx.ResponseManager` and `httpx.ClientSession` work together to enable; `retry_transient` and `raise_for_status`. Aiohttp has this unusual structure where; all the request methods are synchronous but they return an object that is both; awaitable and an async context manager. I mirror their structure exactly. The; `httpx.ResponseManager` is both awaitable and an async context manager. Its; `response_coroutine` field is a coroutine that includes the retry and; raise-for-status logic. - The `HailResolver` overrides domain name resolution to first consult the Hail; `address` service. `address` is effectively a domain name server. It watches; kubernetes services and publishes the pod IPs. It supports two name styles:; `service` and `service.namespace`. The former uses the deploy config to; determine in which namespace to find the given service. Currently, the; client-side library only looks up IPs for `shuffler` and `address`. - `BlockingClientSession` and `BlockingContextManager` wrap the; aforementioned `httpx` classes. `BlockingClientResponse` wraps an; `aiohttp.ClientResponse`. ---. Examples of correct usage:. A blocking HTTPS request:. ```python3; with httpx.blocking_client_session() as session:; with session.post(url, json=config, headers=headers) as resp:; assert resp.status == 200; print(resp.text()); ```. An asynchronous HTTPS request to auth:; ```python3; async with httpx.client_session() as session:; async with session.get(; deploy_config.url('auth', '/api/v1alpha/userinfo'),; headers=headers) as resp:; assert resp.status == 200; print(await resp.json()); ```. A blocking HTTPS session with a large default timeout:. ```python3; httpx.blocking_client_session(; headers=service_auth_headers(deploy_config, 'query'),; timeout=aiohttp.ClientTimeout(total=600)); ```. cc: @cat",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9554:2400,config,config,2400,https://hail.is,https://github.com/hail-is/hail/pull/9554,1,['config'],['config']
Modifiability,Trying to build on ubuntu ; Welcome to Ubuntu Xenial Xerus (development branch) (GNU/Linux 4.4.0-16-generic x86_64). This tree builds fine on mac using grade installDist. ; On ubuntu it gives the below failure message. We wondered if it might have something to do with case sensitivity issues in file/path naming (mac maintaining case but being case-insensitive). Let me know if you would like more info. ; :compileJava UP-TO-DATE; :compileScala FAILED. FAILURE: Build failed with an exception.; - What went wrong:; A problem was found with the configuration of task ':compileScala'.; > No value has been specified for property 'zincClasspath'.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/275:545,config,configuration,545,https://hail.is,https://github.com/hail-is/hail/issues/275,1,['config'],['configuration']
Modifiability,"Trying to make it more ergonomic to simply do `python3 -m pytest batch/test/test_batch.py::test_job` (now works without any extra environment variables or configuration). This involved the following changes:; - Deleted of some env vars that are no longer used / can be easily consolidated into existing ones; - Gave defaults to those testing env variables for which there are reasonable defaults. E.g. `DOCKER_ROOT_IMAGE` and `HAIL_GENETICS_HAIL_IMAGE`.; - Pushed other environment variables for which there are not reasonable defaults into the tests that need them. If you run a test that requires `HAIL_CLOUD`, you'll still get an error that that env variable is unset and you should set it. But, if you just want to run a single test that doesn't need `HAIL_CLOUD` it won't get in the way.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12862:142,variab,variables,142,https://hail.is,https://github.com/hail-is/hail/pull/12862,5,"['config', 'variab']","['configuration', 'variable', 'variables']"
Modifiability,Trying to slowly add more reliability to the `hailctl` CLI. This adds some very basic tests for the `hailctl batch billing` subcommand that mocks the `BatchClient` so it's just testing that command line parsing and yaml dumping don't break. Most of the other noise in this PR is a refactor. I moved `hail/python/test/hailtop/hailctl/config/conftest.py` up a level so I could reuse its `CLIRunner` fixture across all `hailctl` test modules. That fixture sets a new config directory per test so if you use it in a test the test won't accidentally use or modify the user's actual hailctl config.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13490:281,refactor,refactor,281,https://hail.is,https://github.com/hail-is/hail/pull/13490,4,"['config', 'refactor']","['config', 'refactor']"
Modifiability,Two things:; - I broke `hailctl batch init` after my changes to auth in the case where you are starting from no config (`~/.config/hail` does not exist); - The service account needs delete permissions on the temp bucket to run `remove_tmpdir` jobs. Cutting a release here so we can use this in today's workshop.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13681:112,config,config,112,https://hail.is,https://github.com/hail-is/hail/pull/13681,2,['config'],['config']
Modifiability,"Unclear what changed. GKE release history doesn't specify when Docker was upgraded to 19.03.1. We think Notebook worked in the past. Anyway, the fix is to never specify ""m"" (lowercase m) as the size modifier for a Kubernetes memory limit. Docker silently drops the ""m"" which means the limit is set to a few thousand bytes (e.g. 3500m becomes 3.5kB). The resulting error message is this:; ```; Failed create pod sandbox: rpc error: code = Unknown desc = failed to start sandbox container for pod ""notebook-worker-9l2wq"": Error response from daemon: OCI runtime create failed: container_linux.go:345: starting container process caused ""process_linux.go:303: getting the final child's pid from pipe caused \""read init-p: connection reset by peer\"""": unknown; ```; Which you can see in `kubectl describe pod`:; ```; Warning FailedCreatePodSandBox 73s (x13 over 85s) kubelet, gke-vdc-non-preemptible-pool-5-80798769-kp8n Failed create pod sandbox: rpc error: code = Unknown desc = failed to start sandbox container for pod ""notebook-worker-9l2wq"": Error response from daemon: OCI runtime create failed: container_linux.go:345: starting container process caused ""process_linux.go:303: getting the final child's pid from pipe caused \""read init-p: connection reset by peer\"""": unknown; Normal SandboxChanged 73s (x12 over 84s) kubelet, gke-vdc-non-preemptible-pool-5-80798769-kp8n Pod sandbox changed, it will be killed and re-created.; ```. We narrowed down to this error by trial and error of removing and adding lines of the YAML file. https://github.com/kubernetes/kubernetes/issues/79950. The fix is to use `Mi` not `m`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8165:411,sandbox,sandbox,411,https://hail.is,https://github.com/hail-is/hail/issues/8165,6,"['Sandbox', 'sandbox']","['SandboxChanged', 'sandbox']"
Modifiability,"Unclear what's wrong, but this k8s container got stuck in container creating. ```; (base) dking@wmb16-359 # k describe pods -n test job-4-7xqf9; Name: job-4-7xqf9; Namespace: test; Node: gke-vdc-non-preemptible-pool-0106a51b-zsmg/10.128.0.5; Start Time: Thu, 17 Jan 2019 16:31:42 -0500; Labels: app=batch-job; hail.is/batch-instance=21706daa42404f5489a53bb5ad22a068; uuid=b4fbcb0d4e2045e8bc4aea6b012ffad6; Annotations: <none>; Status: Pending; IP: ; Containers:; default:; Container ID: ; Image: alpine; Image ID: ; Port: <none>; Host Port: <none>; Command:; sleep; 1; State: Waiting; Reason: ContainerCreating; Ready: False; Restart Count: 0; Environment:; POD_IP: (v1:status.podIP); POD_NAME: job-4-7xqf9 (v1:metadata.name); Mounts:; /var/run/secrets/kubernetes.io/serviceaccount from default-token-85kwr (ro); Conditions:; Type Status; Initialized True ; Ready False ; PodScheduled True ; Volumes:; default-token-85kwr:; Type: Secret (a volume populated by a Secret); SecretName: default-token-85kwr; Optional: false; QoS Class: BestEffort; Node-Selectors: <none>; Tolerations: node.kubernetes.io/not-ready:NoExecute for 300s; node.kubernetes.io/unreachable:NoExecute for 300s; Events:; Type Reason Age From Message; ---- ------ ---- ---- -------; Normal SandboxChanged 11m (x171 over 1h) kubelet, gke-vdc-non-preemptible-pool-0106a51b-zsmg Pod sandbox changed, it will be killed and re-created.; Warning FailedSync 6m kubelet, gke-vdc-non-preemptible-pool-0106a51b-zsmg error determining status: rpc error: code = Unknown desc = Error: No such container: 741291eb67b9026c0fe4ac52d1f5a553ea420f07f5a7d7368c9dba93e707a079; Warning FailedCreatePodSandBox 1m (x203 over 1h) kubelet, gke-vdc-non-preemptible-pool-0106a51b-zsmg Failed create pod sandbox: rpc error: code = Unknown desc = NetworkPlugin kubenet failed to set up pod ""job-4-7xqf9_test"" network: Error adding container to network: failed to allocate for range 0: no IP addresses available in range set: 10.32.3.1-10.32.3.254; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5168:1258,Sandbox,SandboxChanged,1258,https://hail.is,https://github.com/hail-is/hail/issues/5168,3,"['Sandbox', 'sandbox']","['SandboxChanged', 'sandbox']"
Modifiability,Unfortunately this is hard to test in the current setup because the tests never get the root config file (which has no database set).,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7706:93,config,config,93,https://hail.is,https://github.com/hail-is/hail/pull/7706,1,['config'],['config']
Modifiability,"Updated db.py to allow user to specify region as shown below. `db = hl.experimental.DB(region='us')`; `mt = db.annotate_rows_db(mt, 'gnomad_lof_metrics')`. Data will be accessed from the requester pays bucket in the region specified by the user, available regions are `'us'` and `'eu'`. Modified the following to include region parameter:; - `DB` class ; - `Dataset.from_name_and_json()`. Added method `DatasetVersion.insert_region()` to replace `'{region}'` in `DatasetVersion.url` instance variable with the specified region.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9410:492,variab,variable,492,https://hail.is,https://github.com/hail-is/hail/pull/9410,1,['variab'],['variable']
Modifiability,"Updated the datasets/annotation_db.json config file with datasets currently available in bucket at gs://hail-datasets-hail-data, also updated docs to reflect the datasets available via the `load_datasets()` function.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9331:40,config,config,40,https://hail.is,https://github.com/hail-is/hail/pull/9331,1,['config'],['config']
Modifiability,Updates the GCP terraform to catch up with additions made for Azure. Soon the clouds will share the same module for the global-config so this won't be something we need to worry about.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11012:127,config,config,127,https://hail.is,https://github.com/hail-is/hail/pull/11012,1,['config'],['config']
Modifiability,"Updates the requirements on [astroid](https://github.com/PyCQA/astroid) to permit the latest version.; <details>; <summary>Changelog</summary>; <p><em>Sourced from <a href=""https://github.com/PyCQA/astroid/blob/main/ChangeLog"">astroid's changelog</a>.</em></p>; <blockquote>; <h1>What's New in astroid 2.10.0?</h1>; <p>Release date: 2022-02-27</p>; <ul>; <li>; <p>Fixed inference of <code>self</code> in binary operations in which <code>self</code>; is part of a list or tuple.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/4826"">PyCQA/pylint#4826</a></p>; </li>; <li>; <p>Fixed builtin inference on <code>property</code> calls not calling the <code>postinit</code> of the new node, which; resulted in instance arguments missing on these nodes.</p>; </li>; <li>; <p>Fixed a crash on <code>Super.getattr</code> when the attribute was previously uninferable due to a cache; limit size. This limit can be hit when the inheritance pattern of a class (and therefore of the; <code>__init__</code> attribute) is very large.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5679"">PyCQA/pylint#5679</a></p>; </li>; <li>; <p>Inlcude names of keyword-only arguments in <code>astroid.scoped_nodes.Lambda.argnames</code>.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5771"">PyCQA/pylint#5771</a></p>; </li>; <li>; <p>Fixed a crash inferring on a <code>NewType</code> named with an f-string.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/pylint/issues/5770"">PyCQA/pylint#5770</a></p>; </li>; <li>; <p>Add support for <a href=""https://github.com/python-attrs/attrs/releases/tag/21.3.0"">attrs v21.3.0</a> which; added a new <code>attrs</code> module alongside the existing <code>attr</code>.</p>; <p>Closes <a href=""https://github-redirect.dependabot.com/PyCQA/astroid/issues/1330"">#1330</a></p>; </li>; <li>; <p>Use the <code>end_lineno</code> attribute for the <code>NodeNG.tolineno</",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11463:952,inherit,inheritance,952,https://hail.is,https://github.com/hail-is/hail/pull/11463,2,['inherit'],['inheritance']
Modifiability,Use ?= in make variables for spark and scala versions,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9556:15,variab,variables,15,https://hail.is,https://github.com/hail-is/hail/pull/9556,1,['variab'],['variables']
Modifiability,Use configured compute zone as default for hailctl dataproc,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8790:4,config,configured,4,https://hail.is,https://github.com/hail-is/hail/pull/8790,1,['config'],['configured']
Modifiability,"Users who build from source are often confused by the native; library configuration. This adds a target that handles native; library configuration for the user. I also changed the docs to; encourage the use of this target. This means everyone building hail; from source will need to build the C libraries, but I think this; is for the best, since most people building from source need to; correctly handle native libraries anyway. Resolves https://github.com/hail-is/hail/issues/6132",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6134:70,config,configuration,70,https://hail.is,https://github.com/hail-is/hail/pull/6134,2,['config'],['configuration']
Modifiability,"Uses method in line with PStruct, PTuple rewrite to avoid unimplemented def, at the cost of more lines of code.; * lazy in line with PStruct and PTuple fundamentalTypes, and also it doesn't seem right to have more than one fundamental type for a single instance of the class.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7751:41,rewrite,rewrite,41,https://hail.is,https://github.com/hail-is/hail/pull/7751,1,['rewrite'],['rewrite']
Modifiability,"Using `591f7e6`, getting a NullPointer when trying to `explode` and then write to parquet. ```; Caused by: java.lang.NullPointerException; at is.hail.keytable.KeyTable$$anonfun$59.apply(KeyTable.scala:536); at is.hail.keytable.KeyTable$$anonfun$59.apply(KeyTable.scala:534); at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:434); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:440); ```. Example:; ```; from hail import *; hc = HailContext(); output = 'gs://' # set this to some output file; a_anns = [u'va.info.AC', u'va.info.AF', u'va.info.AS_FilterStatus']. def index_into_arrays(a_based_annotations, vep_root=None):; annotations = []; if a_based_annotations:; for ann in a_based_annotations:; annotations.append('%s = %s[va.aIndex - 1]' % (ann, ann)); if vep_root:; sub_fields = ['transcript_consequences', 'intergenic_consequences', 'motif_feature_consequences', 'regulatory_feature_consequences']; annotations.extend(['%s.%s = %s.%s.filter(x => x.allele_num == va.aIndex)' % (vep_root, sub_field, vep_root, sub_field) for sub_field in sub_fields]); return annotations. kt = (hc.read('gs://gnomad-public/release-170228/gnomad.exomes.r2.0.1.sites.autosomes.vds').split_multi(); .annotate_variants_expr('va.info = select(va.info, AC, AF, AS_FilterStatus)'); .annotate_variants_expr(index_into_arrays(a_anns, vep_root='va.vep')); .annotate_variants_expr(['va.filters = va.filters.mkString(""|"")',; 'va.info.AS_FilterStatus = va.info.AS_FilterStatus.mkString(""|"")',; 'va.vep = va.vep.transcript_consequences.map(x => drop(x, domains))']); .variants_keytable()). # kt.flatten().to_dataframe().write.parquet(output) # works; kt.flatten().explode('va.vep').to_dataframe().write.parquet(output) # fails; ```",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1601:942,extend,extend,942,https://hail.is,https://github.com/hail-is/hail/issues/1601,1,['extend'],['extend']
Modifiability,"Using hail 0.2.32, `hailctl dataproc submit` results in the following error:. ```; hailctl dataproc submit hail-test {python file} -- {arguments to script}; Submitting to cluster 'hail-test'...; gcloud command:; gcloud dataproc jobs submit pyspark {python file} \; --cluster=hail-test \; --files= \; --py-files=/var/folders/7y/hvrzyxts3xg74r3m2jbq0kc0zt3g3z/T/pyscripts_srh2ze4a.zip \; --properties= \; -- \; {arguments to script}; ERROR: (gcloud.dataproc.jobs.submit.pyspark) The required property [region] is not currently set.; It can be set on a per-command basis by re-running your command with the [--region] flag. You may set it for your current workspace by running:. $ gcloud config set dataproc/region VALUE. or it can be set temporarily by the environment variable [CLOUDSDK_DATAPROC_REGION]; Traceback (most recent call last):; File ""/Users/aarong/Documents/gtex-wgs/.devenv/bin/hailctl"", line 8, in <module>; sys.exit(main()); File ""/Users/aarong/Documents/gtex-wgs/.devenv/lib/python3.7/site-packages/hailtop/hailctl/__main__.py"", line 94, in main; cli.main(args); File ""/Users/aarong/Documents/gtex-wgs/.devenv/lib/python3.7/site-packages/hailtop/hailctl/dataproc/cli.py"", line 107, in main; jmp[args.module].main(args, pass_through_args); File ""/Users/aarong/Documents/gtex-wgs/.devenv/lib/python3.7/site-packages/hailtop/hailctl/dataproc/submit.py"", line 78, in main; check_call(cmd); File ""/usr/local/Cellar/python/3.7.6_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/subprocess.py"", line 363, in check_call; raise CalledProcessError(retcode, cmd); subprocess.CalledProcessError; ``` . However, adding `--region us-central1` to any location in the argument string to hailctl dataproc submit results in the argument being picked up as an input to the script, not to the underlying gcloud command",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8078:685,config,config,685,https://hail.is,https://github.com/hail-is/hail/issues/8078,2,"['config', 'variab']","['config', 'variable']"
Modifiability,"Using vep99 and Hail 0.2.57 (and 0.2.70) leads to the absence of vep transcript_consequences annotation (mt.vep.transcript_consequences). We verified that if we run vep annotation outside hail the annotation is present while hl.vep gives absent ones with NA in transcript_consequences field. Here I am attaching the vcf file (I changed extension to '.txt' to allow for the file upload) with two variants, where the chr4:113358472 one gives NA in the transcript_consequences field. The gene is in coding region and have many transcripts. Also vep config json is attached (also needed to change extension to '.txt').; [vep99-loftee-grch38-aws.txt](https://github.com/hail-is/hail/files/6733985/vep99-loftee-grch38-aws.txt). [batch109_subset.txt](https://github.com/hail-is/hail/files/6733958/batch109_subset.txt)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/10623:546,config,config,546,https://hail.is,https://github.com/hail-is/hail/issues/10623,1,['config'],['config']
Modifiability,VEP will now automatically look for a config file in environment variable `VEP_CONFIG_URI` if one isn't specified. This environment variable is prepopulated on dataproc clusters started with `hailctl dataproc`,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8929:38,config,config,38,https://hail.is,https://github.com/hail-is/hail/pull/8929,3,"['config', 'variab']","['config', 'variable']"
Modifiability,"Was hitting a very annoying bug because `PCanonicalNDArray` didn't explicitly override the default. Creators of new `PType`s should not have to magically know that this method exists and override it. It should not have a default implementation. . I had to specify that `PCanonicalNDArray` does have pointers, and that `PVoid` and `PPrimitive` don't. I said `false` for `PCanonicalStream` too, but that was less clear. `false` is the value it was inheriting previously, but idk if you can even `deepCopy` a stream. If you can, then maybe it should recur to the `elementType`? You'd know best Patrick.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9242:446,inherit,inheriting,446,https://hail.is,https://github.com/hail-is/hail/pull/9242,1,['inherit'],['inheriting']
Modifiability,"We currently cannot run untrusted code on our cluster and guarantee that malicious code in one pod does not leak into other pods, or affect the entire cluster. This proposal outlines a solution to this problem. *This is a work in progress*. ### TL;DR; Use Kata + CRI-Containerd runtime to sandbox pods, at a low performance cost. [Jessie Frazelle’s Blog: Hard Multi-Tenancy in Kubernetes](https://blog.jessfraz.com/post/hard-multi-tenancy-in-kubernetes/). ### Roadmap; I would like to implement a test cluster that uses this system, and begin migrating our existing workloads to it asap. . *TODO*. ### Rationale; 1. We want resource preemption across users., running multiple user containers on a single cluster.; 2. This means sandboxing at the cluster level is out.; 3. Therefore we must sandbox at the pod (or container) level. Kata + CRI-Containerd chosen for performance and maturity reasons.; CRI-Containerd is much faster than CRI-O, and Kata is much faster than gVisor. Kata is a relatively mature product from Intel. Production users include JD.com. ### User-level access control ; An orthogonal issue that still needs to be addressed. [RBAC Authorization - Kubernetes](https://kubernetes.io/docs/reference/access-authn-authz/rbac/). *TODO*. ### Related: Firecracker; Interesting project, similar to Kata and gVisor in its isolation properties. Doesn’t work with Kubernetes, replicates some Kube functionality.; * [Announcing the Firecracker Open Source Technology: Secure and Fast microVM for Serverless Computing | AWS Open Source Blog](https://aws.amazon.com/blogs/opensource/firecracker-open-source-secure-fast-microvm-serverless/); * Potentially lower runtime cost that Kata; * Written in Rust :). ### Alternatives; [Nabla containers: a new approach to container isolation · Nabla Containers](https://nabla-containers.github.io); * Unclear how good containment is. Worth exploring. ### Performance; [Runtime performance benchmark result. containerd vs CRI-containerd vs CRI-O · GitHub](h",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5111:289,sandbox,sandbox,289,https://hail.is,https://github.com/hail-is/hail/issues/5111,3,['sandbox'],"['sandbox', 'sandboxing']"
Modifiability,We don't make it easy to copy the hail log off the driver when a spark job fails. We should make that as automatic as possible. One way to do this is to add a call to [`hl.copy_log`](https://hail.is/docs/0.2/utils/index.html#hail.utils.copy_log) in the `except` block of `SparkBackend.execute`. We would need to expose some configuration for where to copy logs.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14431:324,config,configuration,324,https://hail.is,https://github.com/hail-is/hail/issues/14431,1,['config'],['configuration']
Modifiability,"We get a lot of spurious Grafana alerts because batch-driver has unclosed `aiohttp.ClientSession` objects. `aiohttp` can [report the creation location](https://github.com/aio-libs/aiohttp/blob/master/aiohttp/client.py#L242-L247), but only when aysncio is in debug mode. I am hesitant to enable debug mode because I suspect it will slow down everything by grabbing stack traces for every coroutine (so that it can report an error later). I adapted the code from the linked asyncio code and tested it as follows:. ```; In [1]: import aiohttp; ...: import traceback; ...: import sys; ...:; ...: oldinit = aiohttp.ClientSession.__init__; ...: def newinit(self, *args, **kwargs):; ...: oldinit(self, *args, **kwargs); ...: self._source_traceback: Optional[; ...: traceback.StackSummary; ...: ] = traceback.extract_stack(sys._getframe(1)); ...: aiohttp.ClientSession.__init__ = newinit. In [2]: aiohttp.ClientSession(); <ipython-input-1-028690903e5f>:7: DeprecationWarning: The object should be created within an async function; oldinit(self, *args, **kwargs); Out[2]: <aiohttp.client.ClientSession at 0x104ab3850>. In [3]: aiohttp.ClientSession(); <ipython-input-1-028690903e5f>:7: DeprecationWarning: The object should be created within an async function; oldinit(self, *args, **kwargs); Out[3]: <aiohttp.client.ClientSession at 0x104dac8b0>. In [4]: aiohttp.ClientSession(); <ipython-input-1-028690903e5f>:7: DeprecationWarning: The object should be created within an async function; oldinit(self, *args, **kwargs); Out[4]: <aiohttp.client.ClientSession at 0x104daeec0>. In [5]:. Do you really want to exit ([y]/n)? y; Unclosed client session; client_session: <aiohttp.client.ClientSession object at 0x104ab3850>; source_traceback: Object created at (most recent call last):; File ""/Users/dking/miniconda3/bin/ipython"", line 8, in <module>; sys.exit(start_ipython()); File ""/Users/dking/miniconda3/lib/python3.10/site-packages/IPython/__init__.py"", line 128, in start_ipython; return launch_new_instance(",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13421:439,adapt,adapted,439,https://hail.is,https://github.com/hail-is/hail/pull/13421,1,['adapt'],['adapted']
Modifiability,"We have chosen to prototype a new hail query compiler and runtime using; the LLVM project's MLIR framework for query compilation infrastructure.; This creates a simple project skeleton that will serve as a jumping off; point for the work. The README should be enough to get it built. There; is an implementation of the opt tool for investigating IRs, and; a completely empty dialect. I chose to rewrite this rather than copy over [hail-is/mlir-hail] as; breaking API changes from LLVM/MLIR 14 to 15 made it very difficult to; update that repo. The difficulties in updating LLVM versions may prove; to be a source of pain going forward, as this will be a pretty deep; dependency of the system. [hail-is/mlir-hail]: https://github.com/hail-is/mlir-hail",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12070:395,rewrite,rewrite,395,https://hail.is,https://github.com/hail-is/hail/pull/12070,1,['rewrite'],['rewrite']
Modifiability,We have configured curl to retry so we should always prefer it to wget. I also; fixed that long-standing mistake I made when I added retry-all-errors before; it was supported in our version of curl.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11649:8,config,configured,8,https://hail.is,https://github.com/hail-is/hail/pull/11649,1,['config'],['configured']
Modifiability,"We need to configure Grafana with an SMTP server so that it can send us alert emails. I'd like to have alerts for things like disks getting dangerously close to filling up, abnormally high latency, etc.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/6697:11,config,configure,11,https://hail.is,https://github.com/hail-is/hail/issues/6697,1,['config'],['configure']
Modifiability,"We need to include the :members: directive in newer Sphinx versions. I also elided; hidden and inherited members for now, though we can add those back if we like.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9402:95,inherit,inherited,95,https://hail.is,https://github.com/hail-is/hail/pull/9402,1,['inherit'],['inherited']
Modifiability,"We should extend filtervariants to take a file consisting of a list of positions (contig, start) or a list of variants (contig, start, ref, alt). In GoT2D, there are related .pos files of positions that pass various filters, and vcftools allows one to subset.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/114:10,extend,extend,10,https://hail.is,https://github.com/hail-is/hail/issues/114,1,['extend'],['extend']
Modifiability,"We should never have been using `await`. (aiomysql should probably not implement `__await__`). `create_pool` returns `aiomysql.utils._PoolContextManager` which inherits from `aiomysql.utils._ContextManager` which implements `__await__`, `__aenter__`, and `__aexit__` thusly:. ```python3; def __await__(self):; return self._coro.__await__(). async def __aenter__(self):; self._obj = await self._coro; return self._obj. async def __aexit__(self, exc_type, exc, tb):; await self._obj.close(); self._obj = None; ```. `__await__` is a footgun! You should never do that! You should close the return value of the coroutine!",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13869:160,inherit,inherits,160,https://hail.is,https://github.com/hail-is/hail/pull/13869,1,['inherit'],['inherits']
Modifiability,"We should use __init__ to initialize variables to avoid duplication. This requires changing the init methods to not do any work and have static methods that do the database calls, construct pods, etc.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5944:37,variab,variables,37,https://hail.is,https://github.com/hail-is/hail/issues/5944,1,['variab'],['variables']
Modifiability,"We've had a number of pip issues recently, particularly incompatibilities with the `six` package. The central issue is that pip will install incompatible package versions with only a warning message. This primarily happens when a set of packages is installed (say in a parent image) and then a new set of packages are installed later. Pip attempts to satisfy all requirements of the packages in an installed set, but it does not consider the versions of packages already installed. In this PR, I pervasively change every use of `pip` to be followed by the use of `pip check`. Pip check errors if there are incompatible package versions installed. Rather than change every place that we use `pip install`, I created an ubuntu image with a script, `hail-pip-install`, and pip configuration which makes it easy to do the right thing. Now, we should always install python packages like this:. ```; hail-pip-install package1 package2 package3; ```. The script will ensure that all packages are compatible with existing packages. Moreover, it will retry downloads five times. I did not make every Dockerfile depend on the new hail-ubuntu-image because they are legacy Dockerfile that I didn't want to edit. These include the benchmark Dockerfile and some notebook workers. PySpark presented a challenge because we did not install it via pip. As a result, packages, such as Hail, which depend on PySpark failed the `pip check`. I modified all uses of PySpark to instead use the standard pip-installed version of PySpark. In particular, take a look at how query and shuffler changed. cc: @Dania-Abuhijleh @catoverdrive",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9593:774,config,configuration,774,https://hail.is,https://github.com/hail-is/hail/pull/9593,1,['config'],['configuration']
Modifiability,"We've had to do a redeploy of our hail batch instance on Azure. This PR resolves/clarifies two issues we encountered. 1) Storage Account Name Uniqueness. Due to Azure's restrictions on storage account naming (mainly that names must be globally unique) the redeploy did not succeed. This is because the resource group name (we chose to reuse hail) is possible under a new subscription, but the generated storage account names were therefore identical to our previous stack. I've added in an argument called `storage_account_suffix` to account for this issue. It can be set to any arbitrary string that complies with Azure's storage account naming scheme in order to avoid naming conflicts in the future. While the option remains to simply choose a novel resource group name this is not enforced by Azure and anyone deploying a stack similarly named to someone else would not know until the `terraform apply` stage that the name would not work. 2) Mysql Flexible Server Zones. The only other issue is that the zone argument for the mysql flexible server is no longer always valid depending on your compute region. We needed to comment it out for a successful deploy in Australia East. The comment that has been added we hope will be helpful for others in future.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13058:952,Flexible,Flexible,952,https://hail.is,https://github.com/hail-is/hail/pull/13058,2,"['Flexible', 'flexible']","['Flexible', 'flexible']"
Modifiability,"What do we want a new Hail user to see / do, and in what order? This is what someone sees when they open the docs:. <img width=""1221"" alt=""Screen Shot 2020-03-02 at 3 10 09 PM"" src=""https://user-images.githubusercontent.com/13773586/75713528-fa74d800-5c97-11ea-9e55-01065f5f8c21.png"">. They get information from two places now. The side bar has some stuff, and this paragraph does as well. The first thing this paragraph recommends is the `Overview`, which is the wrong first step in my opinion, unless we rewrite the overview. The Overview is written in a very ""bottom up"" way, starting with talking about hail types. A geneticist does not want to arrive at `import_vcf`/`variant_qc`/`sample_qc` by first slowly walking through our weird version of lazy typed python. I think putting the tutorials first would be a good first step. Going through all the tutorials in order (even they we really mostly like the first tutorial) is more useful than jumping into hail types. . I also don't like the ordering on the sidebar. ""Installation"" is a fine start, but ""Hail on the Cloud"" is too soon. ""Datasets"" and ""Annotation Database"" are very experimental, those should be towards the very bottom, maybe just above ""Hail for Developers"". ""Cheat Sheets"" should be higher up. ""Cheat Sheets"" should also be advertised somewhere in the tutorials / intro paragraph, as I think getting the matrix table and hail table pictures in front of people is crucial to understanding. Finally, I want to pick a place in the hail new user flow where users find out hail is lazy. I frequently run into users who don't know it works this way, and I want to make that set of people smaller.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/8217:506,rewrite,rewrite,506,https://hail.is,https://github.com/hail-is/hail/issues/8217,1,['rewrite'],['rewrite']
Modifiability,"When Hail is pip-installed, you cannot use it with an already constructed SparkContext, unless said SparkContext's class path includes the hail JAR file. It is somewhat annoying to find the hail JAR location and add that to the class path. The primary reason users want to pass an already constructed SparkContext is to specify some configuration parameters. `hl.init` should take a `conf` as either a `SparkConf` or a `dict`.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7080:333,config,configuration,333,https://hail.is,https://github.com/hail-is/hail/issues/7080,1,['config'],['configuration']
Modifiability,"With EIGENSTRAT's smartpca, you can specify a grouping variable in the indiv file then specify which group to call PCs on using -w flag & project onto the rest. Would be great to have this feature as this will allow projection with 1000G samples, related samples, etc.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/442:55,variab,variable,55,https://hail.is,https://github.com/hail-is/hail/issues/442,1,['variab'],['variable']
Modifiability,"With new aggregators, users could e.g. access Apache Math3 libraries to do arbitrary analyses based on case/control genotype counts.; Furthermore having ability to add new jars to classpath would allow flexible addition of new functions by users.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/359:202,flexible,flexible,202,https://hail.is,https://github.com/hail-is/hail/issues/359,1,['flexible'],['flexible']
Modifiability,"Without this `make test-local` fails because there is no running server. This ensures that `make test-local` first starts a server to test against. Recreated for stacked PRs from #4785. ---. The `until curl ...` nonsense is because the server takes some time to start up, so we poll until we get a successful return value from `curl`. `-f` means return non-zero-exit-code on failure. `-L` means follow redirects (not really necessary here, but I think it's good practice to use `-L`). `BATCH_USE_KUBE_CONFG=1` tells batch to use the latent kubernetes configuration, which means the developer must already have set up `kubectl`. This is a reasonable expectation for a developer of `batch`. The `trap cleanup EXIT` ensures we run cleanup before the shell exits. `trap ""exit 24"" INT TERM` converts interruption (`Ctrl-c`) and termination (`kill -15`) into an `EXIT` signal. We do this to ensure that the exit handler is called once. if we did `trap cleanup EXIT INT TERM` some shells would call `cleanup` twice. Once for the interruption and once for the shell exiting. Inside `cleanup` we `trap """" INT TERM` to make `Ctrl-c` do nothing, because the user COUGH cotton COUGH might smash ctrl-c repeatedly and we might not kill the subprocess before they kills us ;).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4786:551,config,configuration,551,https://hail.is,https://github.com/hail-is/hail/pull/4786,1,['config'],['configuration']
Modifiability,"Without this `make test-local` fails because there is no running server. This ensures that `make test-local` first starts a server to test against. The `until curl ...` nonsense is because the server takes some time to start up, so we poll until we get a successful return value from `curl`. `-f` means return non-zero-exit-code on failure. `-L` means follow redirects (not really necessary here, but I think it's good practice to use `-L`). `BATCH_USE_KUBE_CONFG=1` tells batch to use the latent kubernetes configuration, which means the developer must already have set up `kubectl`. This is a reasonable expectation for a developer of `batch`. The `trap cleanup EXIT` ensures we run cleanup before the shell exits. `trap ""exit 24"" INT TERM` converts interruption (`Ctrl-c`) and termination (`kill -15`) into an `EXIT` signal. We do this to ensure that the exit handler is called once. if we did `trap cleanup EXIT INT TERM` some shells would call `cleanup` twice. Once for the interruption and once for the shell exiting. Inside `cleanup` we `trap """" INT TERM` to make `Ctrl-c` do nothing, because the user COUGH cotton COUGH might smash ctrl-c repeatedly and we might not kill the subprocess before they kills us ;).",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/4785:508,config,configuration,508,https://hail.is,https://github.com/hail-is/hail/pull/4785,1,['config'],['configuration']
Modifiability,"Would it be possible to add an option to annotate with --tab and --pick_allele, as below:; This would be super helpful!. <hail.vep.perl>; <hail.vep.location>; --format vcf; --tab; --pick_allele; --everything; --allele_number; --no_stats; --cache --offline; --dir <hail.vep.cache_dir>; --fasta <hail.vep.cache_dir>/homo_sapiens/81_GRCh37/Homo_sapiens.GRCh37.75.dna.primary_assembly.fa; --minimal; --assembly GRCh37; --plugin LoF,human_ancestor_fa:$<hail.vep.lof.human_ancestor>,filter_position:0.05,min_intron_size:15,conservation_file:<hail.vep.lof.conservation_file>; -o STDOUT",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/489:417,plugin,plugin,417,https://hail.is,https://github.com/hail-is/hail/issues/489,1,['plugin'],['plugin']
Modifiability,"Yet Another Terraform Refactoring PR, this creates two simple modules:; - A gcs_bucket module to remove the redundancy of resources that we have across the batch-logs, query and test bucket; - A ukbb module which sets up the ukbb k8s resources. While this technically would allow us to reuse this, say in azure, it's more an attempt to tease it apart from the google-specific infrastructure so that we wouldn't have to. In short, it would be nice to organize things such that deploying hail with or without the ukbb site is as simple as choosing to include or omit a terraform module.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10842:22,Refactor,Refactoring,22,https://hail.is,https://github.com/hail-is/hail/pull/10842,1,['Refactor'],['Refactoring']
Modifiability,[Config] Appsec sandbox config and files,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14726:1,Config,Config,1,https://hail.is,https://github.com/hail-is/hail/pull/14726,3,"['Config', 'config', 'sandbox']","['Config', 'config', 'sandbox']"
Modifiability,[QOB] Parameterize code cache by backend (don't cache on service),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12618:6,Parameteriz,Parameterize,6,https://hail.is,https://github.com/hail-is/hail/pull/12618,1,['Parameteriz'],['Parameterize']
Modifiability,[RFC] Proposal: Move to sandboxed containers,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/5111:24,sandbox,sandboxed,24,https://hail.is,https://github.com/hail-is/hail/issues/5111,1,['sandbox'],['sandboxed']
Modifiability,"[SIG Node]</li>; <li>Kubelet: add '--logging-format' flag to support structured logging (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/91532"">kubernetes/kubernetes#91532</a>, <a href=""https://github.com/afrouzMashaykhi""><code>@​afrouzMashaykhi</code></a>) [SIG API Machinery, Cluster Lifecycle, Instrumentation and Node]</li>; <li>Kubernetes is now built with golang 1.15.0-rc.1.; <ul>; <li>The deprecated, legacy behavior of treating the CommonName field on X.509 serving certificates as a host name when no Subject Alternative Names are present is now disabled by default. It can be temporarily re-enabled by adding the value x509ignoreCN=0 to the GODEBUG environment variable. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/93264"">kubernetes/kubernetes#93264</a>, <a href=""https://github.com/justaugustus""><code>@​justaugustus</code></a>) [SIG API Machinery, Auth, CLI, Cloud Provider, Cluster Lifecycle, Instrumentation, Network, Node, Release, Scalability, Storage and Testing]</li>; </ul>; </li>; <li>Promote Immutable Secrets/ConfigMaps feature to Beta and enable the feature by default.; This allows to set <code>Immutable</code> field in Secrets or ConfigMap object to mark their contents as immutable. (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/89594"">kubernetes/kubernetes#89594</a>, <a href=""https://github.com/wojtek-t""><code>@​wojtek-t</code></a>) [SIG Apps and Testing]</li>; <li>Remove <code>BindTimeoutSeconds</code> from schedule configuration <code>KubeSchedulerConfiguration</code> (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/91580"">kubernetes/kubernetes#91580</a>, <a href=""https://github.com/cofyc""><code>@​cofyc</code></a>) [SIG Scheduling and Testing]</li>; <li>Remove kubescheduler.config.k8s.io/v1alpha1 (<a href=""https://github-redirect.dependabot.com/kubernetes/kubernetes/pull/89298"">kubernetes/kubernetes#89298</a>, <a href=""https://github.com/gavi",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11462:11158,Config,ConfigMaps,11158,https://hail.is,https://github.com/hail-is/hail/pull/11462,1,['Config'],['ConfigMaps']
Modifiability,"[VCF version 4.5](https://samtools.github.io/hts-specs/VCFv4.5.pdf) contains the changes we developed as part of our work developing the [Scalable Variant Call Representation](https://www.biorxiv.org/content/10.1101/2024.01.09.574205v1). As the developers and drivers of these changes, we should fully support v4.5 via import to VDS and export from VDS. Current checklist. May be extended over time:. - [x] Prefer `LEN` over `END` for reference blocks. (Begins in #14675); - [x] Update the combiner to convert to `LEN` from INFO `END` (Part of #14675).; - [x] Update `to_dense_mt` to use `LEN` (we think it may be more efficient).; - [ ] Add VDS to VCF export. (#14743); - [ ] Add Sparse VCF to VDS import. (#14743); - [x] ~'Official' non-ref genotype `<*>` support?~ (not part of this issue); - [ ] Make sure that we output well formed VCF 4.5, this includes things like VCF 4.4's phased haploid calls (this will also require updates to our parser)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14655:380,extend,extended,380,https://hail.is,https://github.com/hail-is/hail/issues/14655,1,['extend'],['extended']
Modifiability,"[`BlockMatrixIsDistributedMatrix`](https://github.com/hail-is/hail/blob/master/src/main/scala/is/hail/distributedmatrix/BlockMatrixIsDistributedMatrix.scala) implements the [`DistributedMatrix`](https://github.com/hail-is/hail/blob/master/src/main/scala/is/hail/distributedmatrix/DistributedMatrix.scala) API for Spark's `BlockMatrix` type. We should rewrite `BlockMatrix` from scratch to use Breeze matrices because the Spark `DenseMatrix` type doesn't provide a rich interface, in particular there are no exposed mutation primitives. I hope that an implementation on top of Breeze can more efficiently implement `vectorAddToEveryColumn` and `vectorPointwiseMultiplyEveryColumn` and `vectorPointwiseMultiplyEveryRow`. Also, we can move into `is.hail.distributedmatrix` `BetterBlockMatrix` which we, rather illicitly, shove into the apache package during jar creation.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/1979:351,rewrite,rewrite,351,https://hail.is,https://github.com/hail-is/hail/issues/1979,1,['rewrite'],['rewrite']
Modifiability,[aioclient] Refactor BatchBuilder submit for ease of job groups changes,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13448:12,Refactor,Refactor,12,https://hail.is,https://github.com/hail-is/hail/pull/13448,1,['Refactor'],['Refactor']
Modifiability,"[annotationdb] [datasets] specify region in annotation db instance, use reformatted/unified json config file, updated datasets",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9496:97,config,config,97,https://hail.is,https://github.com/hail-is/hail/pull/9496,1,['config'],['config']
Modifiability,[apiserver]: fix variable expansion,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5829:17,variab,variable,17,https://hail.is,https://github.com/hail-is/hail/pull/5829,1,['variab'],['variable']
Modifiability,[auth] Mount the global config in the auth driver pod,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10962:24,config,config,24,https://hail.is,https://github.com/hail-is/hail/pull/10962,1,['config'],['config']
Modifiability,[auth] Remove dead google config variables,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10899:26,config,config,26,https://hail.is,https://github.com/hail-is/hail/pull/10899,2,"['config', 'variab']","['config', 'variables']"
Modifiability,[auth] get GSuite organization from global-config,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9793:43,config,config,43,https://hail.is,https://github.com/hail-is/hail/pull/9793,1,['config'],['config']
Modifiability,[batch2] a config error won't have a timing field,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7542:11,config,config,11,https://hail.is,https://github.com/hail-is/hail/pull/7542,1,['config'],['config']
Modifiability,[batch2] add memory request to docker container config,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7498:48,config,config,48,https://hail.is,https://github.com/hail-is/hail/pull/7498,2,['config'],['config']
Modifiability,[batch2] expose configuration in batch2 driver web UI,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7606:16,config,configuration,16,https://hail.is,https://github.com/hail-is/hail/pull/7606,1,['config'],['configuration']
Modifiability,[batch2] fix status if error occurred when getting the job config,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7522:59,config,config,59,https://hail.is,https://github.com/hail-is/hail/pull/7522,1,['config'],['config']
Modifiability,"[batch2] refactor Batch, Job",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7211:9,refactor,refactor,9,https://hail.is,https://github.com/hail-is/hail/pull/7211,1,['refactor'],['refactor']
Modifiability,[batch] Add batch-config to expose current batch id to user jobs,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12246:18,config,config,18,https://hail.is,https://github.com/hail-is/hail/pull/12246,1,['config'],['config']
Modifiability,[batch] Add configurable spot price percentage increases,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13252:12,config,configurable,12,https://hail.is,https://github.com/hail-is/hail/pull/13252,1,['config'],['configurable']
Modifiability,[batch] Add environment variable for batch id in worker,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12662:24,variab,variable,24,https://hail.is,https://github.com/hail-is/hail/pull/12662,1,['variab'],['variable']
Modifiability,[batch] Add hailctl config batch/backend,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12522:20,config,config,20,https://hail.is,https://github.com/hail-is/hail/pull/12522,1,['config'],['config']
Modifiability,[batch] Add json parsing and severity to GCP Ops Agent config,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14187:55,config,config,55,https://hail.is,https://github.com/hail-is/hail/pull/14187,1,['config'],['config']
Modifiability,[batch] Clean up environment variables for easier local execution of batch tests,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12862:29,variab,variables,29,https://hail.is,https://github.com/hail-is/hail/pull/12862,1,['variab'],['variables']
Modifiability,[batch] Compare and reject stale driver config changes,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11798:40,config,config,40,https://hail.is,https://github.com/hail-is/hail/pull/11798,1,['config'],['config']
Modifiability,[batch] Compute optimal worker type based on cpu / memory configuration,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10097:58,config,configuration,58,https://hail.is,https://github.com/hail-is/hail/pull/10097,1,['config'],['configuration']
Modifiability,[batch] Configurable worker disk type,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9288:8,Config,Configurable,8,https://hail.is,https://github.com/hail-is/hail/pull/9288,1,['Config'],['Configurable']
Modifiability,[batch] Configure XFS quotas without configuration files,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10467:8,Config,Configure,8,https://hail.is,https://github.com/hail-is/hail/pull/10467,2,"['Config', 'config']","['Configure', 'configuration']"
Modifiability,[batch] Delete unused batch user code ssl config,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13068:42,config,config,42,https://hail.is,https://github.com/hail-is/hail/pull/13068,1,['config'],['config']
Modifiability,[batch] Expose region variable to users,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12465:22,variab,variable,22,https://hail.is,https://github.com/hail-is/hail/pull/12465,1,['variab'],['variable']
Modifiability,[batch] Fix autoscaling policy in GCP Terraform config,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12025:48,config,config,48,https://hail.is,https://github.com/hail-is/hail/pull/12025,1,['config'],['config']
Modifiability,[batch] Fix defaulting to config.ini for domain,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11131:26,config,config,26,https://hail.is,https://github.com/hail-is/hail/pull/11131,1,['config'],['config']
Modifiability,[batch] Fix jq wiping deploy config in test,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10850:29,config,config,29,https://hail.is,https://github.com/hail-is/hail/pull/10850,1,['config'],['config']
Modifiability,[batch] Flexible storage configuration,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9598:8,Flexible,Flexible,8,https://hail.is,https://github.com/hail-is/hail/pull/9598,4,"['Flexible', 'config']","['Flexible', 'configuration']"
Modifiability,[batch] Let worker control job deploy-config instead of using k8s secret,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13056:38,config,config,38,https://hail.is,https://github.com/hail-is/hail/pull/13056,1,['config'],['config']
Modifiability,[batch] Make ServiceBackend respect environment variable configuration,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12799:48,variab,variable,48,https://hail.is,https://github.com/hail-is/hail/pull/12799,2,"['config', 'variab']","['configuration', 'variable']"
Modifiability,[batch] Make driver parameters configurable in the UI,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12575:31,config,configurable,31,https://hail.is,https://github.com/hail-is/hail/pull/12575,1,['config'],['configurable']
Modifiability,[batch] Mitigate test failures by extending batch client timeout,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12709:34,extend,extending,34,https://hail.is,https://github.com/hail-is/hail/pull/12709,1,['extend'],['extending']
Modifiability,[batch] Mount external deploy config for public jobs,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10774:30,config,config,30,https://hail.is,https://github.com/hail-is/hail/pull/10774,1,['config'],['config']
Modifiability,[batch] Mount worker deploy config instead of using k8s secret,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13203:28,config,config,28,https://hail.is,https://github.com/hail-is/hail/pull/13203,1,['config'],['config']
Modifiability,[batch] Move config.json into the container bundle,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13438:13,config,config,13,https://hail.is,https://github.com/hail-is/hail/pull/13438,1,['config'],['config']
Modifiability,[batch] Refactor resource billing checks with additional debugging info,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12713:8,Refactor,Refactor,8,https://hail.is,https://github.com/hail-is/hail/pull/12713,1,['Refactor'],['Refactor']
Modifiability,[batch] Refactor scheduler code for multiple instance pools,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9774:8,Refactor,Refactor,8,https://hail.is,https://github.com/hail-is/hail/pull/9774,1,['Refactor'],['Refactor']
Modifiability,[batch] Refactor the driver to be cloud-agnostic,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10860:8,Refactor,Refactor,8,https://hail.is,https://github.com/hail-is/hail/pull/10860,1,['Refactor'],['Refactor']
Modifiability,[batch] Refactor worker Container class into Image and Container,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11396:8,Refactor,Refactor,8,https://hail.is,https://github.com/hail-is/hail/pull/11396,1,['Refactor'],['Refactor']
Modifiability,[batch] Refactor zone quotas code into a zone monitor,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9769:8,Refactor,Refactor,8,https://hail.is,https://github.com/hail-is/hail/pull/9769,1,['Refactor'],['Refactor']
Modifiability,[batch] Remove redundant env variable for internal gateway ip,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12005:29,variab,variable,29,https://hail.is,https://github.com/hail-is/hail/pull/12005,1,['variab'],['variable']
Modifiability,[batch] Specify web server port through env variable,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12613:44,variab,variable,44,https://hail.is,https://github.com/hail-is/hail/pull/12613,1,['variab'],['variable']
Modifiability,[batch] Use weights for cpu and blkio in container config,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8973:51,config,config,51,https://hail.is,https://github.com/hail-is/hail/pull/8973,1,['config'],['config']
Modifiability,[batch] add batch/bucket configuration,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8852:25,config,configuration,25,https://hail.is,https://github.com/hail-is/hail/pull/8852,1,['config'],['configuration']
Modifiability,[batch] adds requester pays config to `hailtop.fs.open`,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13795:28,config,config,28,https://hail.is,https://github.com/hail-is/hail/pull/13795,1,['config'],['config']
Modifiability,[batch] configure logging,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6873:8,config,configure,8,https://hail.is,https://github.com/hail-is/hail/pull/6873,1,['config'],['configure']
Modifiability,[batch] fix HAIL_GENETICS_IMAGES variable,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11117:33,variab,variable,33,https://hail.is,https://github.com/hail-is/hail/pull/11117,1,['variab'],['variable']
Modifiability,[batch] fix deserialize for compound variable names,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5738:37,variab,variable,37,https://hail.is,https://github.com/hail-is/hail/pull/5738,1,['variab'],['variable']
Modifiability,[batch] fix getting status when job config fails,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8760:36,config,config,36,https://hail.is,https://github.com/hail-is/hail/pull/8760,1,['config'],['config']
Modifiability,[batch] fix warning to use forward slash in config,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11116:44,config,config,44,https://hail.is,https://github.com/hail-is/hail/pull/11116,1,['config'],['config']
Modifiability,[batch] make master url configurable,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6805:24,config,configurable,24,https://hail.is,https://github.com/hail-is/hail/pull/6805,1,['config'],['configurable']
Modifiability,[batch] make standing worker configurable in the UI,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9844:29,config,configurable,29,https://hail.is,https://github.com/hail-is/hail/pull/9844,1,['config'],['configurable']
Modifiability,[batch] reads `HAIL_BATCH_REGIONS` environment variable correctly,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13239:47,variab,variable,47,https://hail.is,https://github.com/hail-is/hail/pull/13239,1,['variab'],['variable']
Modifiability,[batch] refactor how jobs are submitted in batches,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6479:8,refactor,refactor,8,https://hail.is,https://github.com/hail-is/hail/pull/6479,1,['refactor'],['refactor']
Modifiability,[batch] refactor job schema to understand different job types,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9857:8,refactor,refactor,8,https://hail.is,https://github.com/hail-is/hail/pull/9857,1,['refactor'],['refactor']
Modifiability,[batch] refactor test_batch.py to use pytest instead of unittest,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9584:8,refactor,refactor,8,https://hail.is,https://github.com/hail-is/hail/pull/9584,1,['refactor'],['refactor']
Modifiability,[batch] remove unused variable in test,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5542:22,variab,variable,22,https://hail.is,https://github.com/hail-is/hail/pull/5542,1,['variab'],['variable']
Modifiability,[batch] rewrite schema validation so that schema description is working validation function,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9861:8,rewrite,rewrite,8,https://hail.is,https://github.com/hail-is/hail/pull/9861,1,['rewrite'],['rewrite']
Modifiability,"[benchmark] Add more configuration, add version info to json output",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6796:21,config,configuration,21,https://hail.is,https://github.com/hail-is/hail/pull/6796,1,['config'],['configuration']
Modifiability,[benchmark] Allow configuration of `BENCHMARK_DOCKER_TAG`,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12846:18,config,configuration,18,https://hail.is,https://github.com/hail-is/hail/pull/12846,1,['config'],['configuration']
Modifiability,[benchmark] Parameterize batch service,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7461:12,Parameteriz,Parameterize,12,https://hail.is,https://github.com/hail-is/hail/pull/7461,1,['Parameteriz'],['Parameterize']
Modifiability,"[benchmark] Parameterize output formats, files, verbosity.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6558:12,Parameteriz,Parameterize,12,https://hail.is,https://github.com/hail-is/hail/pull/6558,1,['Parameteriz'],['Parameterize']
Modifiability,[benchmark] add `visualize` + refactor hail-bench,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12856:30,refactor,refactor,30,https://hail.is,https://github.com/hail-is/hail/pull/12856,1,['refactor'],['refactor']
Modifiability,[benchmark] add debugging / refactor test,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10144:28,refactor,refactor,28,https://hail.is,https://github.com/hail-is/hail/pull/10144,1,['refactor'],['refactor']
Modifiability,"[benchmark] parameterize metric, skip short benchmarks",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7105:12,parameteriz,parameterize,12,https://hail.is,https://github.com/hail-is/hail/pull/7105,1,['parameteriz'],['parameterize']
Modifiability,[benchmark] use HAIL_PYTHON3 variable instead of `python`,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7017:29,variab,variable,29,https://hail.is,https://github.com/hail-is/hail/pull/7017,1,['variab'],['variable']
Modifiability,"[bugfix] rewrite StringLength and StringSlice as IR functions, fix behavior of len(:poop:)",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5619:9,rewrite,rewrite,9,https://hail.is,https://github.com/hail-is/hail/pull/5619,1,['rewrite'],['rewrite']
Modifiability,[build.yaml] standardize on one location for sql-config.cnf,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8416:49,config,config,49,https://hail.is,https://github.com/hail-is/hail/pull/8416,1,['config'],['config']
Modifiability,[build.yaml] steps using database-server-config must depend on its creation,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11441:41,config,config,41,https://hail.is,https://github.com/hail-is/hail/pull/11441,1,['config'],['config']
Modifiability,[build] Check cloud at config time in deploy config step,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11026:23,config,config,23,https://hail.is,https://github.com/hail-is/hail/pull/11026,2,['config'],['config']
Modifiability,[build] rewrite kubectl secret copying to avoid deprecated --export flag,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9561:8,rewrite,rewrite,8,https://hail.is,https://github.com/hail-is/hail/pull/9561,1,['rewrite'],['rewrite']
Modifiability,[build] stop evaluating upload-qob-jar variables on makefile parsing,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12616:39,variab,variables,39,https://hail.is,https://github.com/hail-is/hail/pull/12616,1,['variab'],['variables']
Modifiability,[c++] Pass Hadoop Config to C++ and write NDArray,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5837:18,Config,Config,18,https://hail.is,https://github.com/hail-is/hail/pull/5837,1,['Config'],['Config']
Modifiability,[ci] Add kubernetes server url to global variables,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7459:41,variab,variables,41,https://hail.is,https://github.com/hail-is/hail/pull/7459,1,['variab'],['variables']
Modifiability,[ci] Add tests for generating envoy xds configs,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14524:40,config,configs,40,https://hail.is,https://github.com/hail-is/hail/pull/14524,1,['config'],['configs']
Modifiability,[ci] Alert zulip when deploy config fails to build,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10828:29,config,config,29,https://hail.is,https://github.com/hail-is/hail/pull/10828,1,['config'],['config']
Modifiability,[ci] Catch cloud-incompatible steps at build config time,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11159:45,config,config,45,https://hail.is,https://github.com/hail-is/hail/pull/11159,1,['config'],['config']
Modifiability,[ci] Clean up temporary config for OAuth changes,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13570:24,config,config,24,https://hail.is,https://github.com/hail-is/hail/pull/13570,1,['config'],['config']
Modifiability,[ci] Fix errant line in environment variable spec,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13628:36,variab,variable,36,https://hail.is,https://github.com/hail-is/hail/pull/13628,1,['variab'],['variable']
Modifiability,[ci] Fix global-config creation,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9795:16,config,config,16,https://hail.is,https://github.com/hail-is/hail/pull/9795,1,['config'],['config']
Modifiability,[ci] Make zulip-config optional,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11299:16,config,config,16,https://hail.is,https://github.com/hail-is/hail/pull/11299,1,['config'],['config']
Modifiability,[ci] Mostly pass through global-config in CI instead of constructing from env variables,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10911:32,config,config,32,https://hail.is,https://github.com/hail-is/hail/pull/10911,2,"['config', 'variab']","['config', 'variables']"
Modifiability,[ci] Pretty print create_database.py json config,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9533:42,config,config,42,https://hail.is,https://github.com/hail-is/hail/pull/9533,1,['config'],['config']
Modifiability,[ci] Remove dead code from CI configs,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13967:30,config,configs,30,https://hail.is,https://github.com/hail-is/hail/pull/13967,1,['config'],['configs']
Modifiability,[ci] Remove unnecessary worker-deploy-config secret,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13343:38,config,config,38,https://hail.is,https://github.com/hail-is/hail/pull/13343,1,['config'],['config']
Modifiability,[ci] actually fix nullness in sql config,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8500:34,config,config,34,https://hail.is,https://github.com/hail-is/hail/pull/8500,1,['config'],['config']
Modifiability,[ci] add docker root image and prefix to CI global config,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10340:51,config,config,51,https://hail.is,https://github.com/hail-is/hail/pull/10340,1,['config'],['config']
Modifiability,[ci] change CreateDatabase step to use config file,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7302:39,config,config,39,https://hail.is,https://github.com/hail-is/hail/pull/7302,1,['config'],['config']
Modifiability,"[ci] create global-config in ""default"" namespaces created by CI",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9777:19,config,config,19,https://hail.is,https://github.com/hail-is/hail/pull/9777,1,['config'],['config']
Modifiability,[ci] parameterize CreateDatabase step,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7283:5,parameteriz,parameterize,5,https://hail.is,https://github.com/hail-is/hail/pull/7283,1,['parameteriz'],['parameterize']
Modifiability,[ci] use dev database server config in dev deploy,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7683:29,config,config,29,https://hail.is,https://github.com/hail-is/hail/pull/7683,1,['config'],['config']
Modifiability,[ci] use global config in ci test deployment,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9790:16,config,config,16,https://hail.is,https://github.com/hail-is/hail/pull/9790,1,['config'],['config']
Modifiability,[combiner] use a single variable rather than a map for merge function,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5585:24,variab,variable,24,https://hail.is,https://github.com/hail-is/hail/pull/5585,1,['variab'],['variable']
Modifiability,[compiler] Add `scalafix` and `scalafmt` configs,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14126:41,config,configs,41,https://hail.is,https://github.com/hail-is/hail/pull/14126,1,['config'],['configs']
Modifiability,[compiler] Add rewrite rule for nested CastRename nodes,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10577:15,rewrite,rewrite,15,https://hail.is,https://github.com/hail-is/hail/pull/10577,1,['rewrite'],['rewrite']
Modifiability,"[compiler] BIG PR: refactor type propagation to EmitCodes, remove InferPType",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10477:19,refactor,refactor,19,https://hail.is,https://github.com/hail-is/hail/pull/10477,1,['refactor'],['refactor']
Modifiability,[compiler] Refactor EncodedLiteral / TableLiteral to use multiple byte arrays,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11062:11,Refactor,Refactor,11,https://hail.is,https://github.com/hail-is/hail/pull/11062,1,['Refactor'],['Refactor']
Modifiability,[compiler] Refactor ExecuteContext to live in `is.hail.backend`,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10967:11,Refactor,Refactor,11,https://hail.is,https://github.com/hail-is/hail/pull/10967,1,['Refactor'],['Refactor']
Modifiability,[compiler] Refactor UID knowledge into TableReader subtrait,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12579:11,Refactor,Refactor,11,https://hail.is,https://github.com/hail-is/hail/pull/12579,1,['Refactor'],['Refactor']
Modifiability,[compiler] Refactor compiled functions to take a HailTaskContext inst…,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12597:11,Refactor,Refactor,11,https://hail.is,https://github.com/hail-is/hail/pull/12597,1,['Refactor'],['Refactor']
Modifiability,[compiler] Rewrite StreamTake and StreamDrop to TakeWhile and DropWhile,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10773:11,Rewrite,Rewrite,11,https://hail.is,https://github.com/hail-is/hail/pull/10773,1,['Rewrite'],['Rewrite']
Modifiability,[compiler] Rewrite lowered partition alignment with takeWhile/dropWhile,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10788:11,Rewrite,Rewrite,11,https://hail.is,https://github.com/hail-is/hail/pull/10788,1,['Rewrite'],['Rewrite']
Modifiability,[compiler] extend + fix simplifier for integral types,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12754:11,extend,extend,11,https://hail.is,https://github.com/hail-is/hail/pull/12754,2,['extend'],['extend']
Modifiability,[compiler] refactor BlockMatrix lowering to generate small IR,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12624:11,refactor,refactor,11,https://hail.is,https://github.com/hail-is/hail/pull/12624,1,['refactor'],['refactor']
Modifiability,"[compiler] refactor PType.store, SType.coerceOrCopy to take/return values",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10848:11,refactor,refactor,11,https://hail.is,https://github.com/hail-is/hail/pull/10848,1,['refactor'],['refactor']
Modifiability,[compiler] refactor types in bindings,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14517:11,refactor,refactor,11,https://hail.is,https://github.com/hail-is/hail/pull/14517,1,['refactor'],['refactor']
Modifiability,[compiler] rewrite ExtractIntervalFilters to be more robust,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13355:11,rewrite,rewrite,11,https://hail.is,https://github.com/hail-is/hail/pull/13355,1,['rewrite'],['rewrite']
Modifiability,[compiler] rewrite FreeVariables to not duplicate binding structure,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14451:11,rewrite,rewrite,11,https://hail.is,https://github.com/hail-is/hail/pull/14451,1,['rewrite'],['rewrite']
Modifiability,[config] Add max_polling_delay environment variable for wait ops,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13281:1,config,config,1,https://hail.is,https://github.com/hail-is/hail/pull/13281,2,"['config', 'variab']","['config', 'variable']"
Modifiability,[config] Fixed handling of non-existent domain,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11334:1,config,config,1,https://hail.is,https://github.com/hail-is/hail/pull/11334,1,['config'],['config']
Modifiability,[datasets] Update datasets.py to use checked-in config file,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9411:48,config,config,48,https://hail.is,https://github.com/hail-is/hail/pull/9411,1,['config'],['config']
Modifiability,[deploy-config] add service deploy-config location to defaults,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8580:8,config,config,8,https://hail.is,https://github.com/hail-is/hail/pull/8580,2,['config'],['config']
Modifiability,[deploy_config] Add domain support to hailctl config,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11113:46,config,config,46,https://hail.is,https://github.com/hail-is/hail/pull/11113,1,['config'],['config']
Modifiability,"[dev] Parameterize shadowJar/releaseJar, better names for install targets",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6450:6,Parameteriz,Parameterize,6,https://hail.is,https://github.com/hail-is/hail/pull/6450,1,['Parameteriz'],['Parameterize']
Modifiability,[devdocs] Add dev doc describing gateways configuration,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14488:42,config,configuration,42,https://hail.is,https://github.com/hail-is/hail/pull/14488,1,['config'],['configuration']
Modifiability,[docker] Add config support for docker prefix and root image,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10347:13,config,config,13,https://hail.is,https://github.com/hail-is/hail/pull/10347,1,['config'],['config']
Modifiability,[docker] Reorder hailgenetics hail docker image layers,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12301:48,layers,layers,48,https://hail.is,https://github.com/hail-is/hail/pull/12301,1,['layers'],['layers']
Modifiability,[docker] fix keyfile name in Spark config,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7834:35,config,config,35,https://hail.is,https://github.com/hail-is/hail/pull/7834,1,['config'],['config']
Modifiability,[docs] Add VEP config file locations on Google Storage to docs,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6143:15,config,config,15,https://hail.is,https://github.com/hail-is/hail/pull/6143,1,['config'],['config']
Modifiability,[feature] Extend import_table missing parameter to support multiple v…,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5614:10,Extend,Extend,10,https://hail.is,https://github.com/hail-is/hail/pull/5614,1,['Extend'],['Extend']
Modifiability,[fs] Teach GoogleStorageAsyncFS to use the rewrite API,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14603:43,rewrite,rewrite,43,https://hail.is,https://github.com/hail-is/hail/pull/14603,1,['rewrite'],['rewrite']
Modifiability,[fs] hailtop.fs makes it impossible to explicitly configure the GCS requester pays project in code,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13567:50,config,configure,50,https://hail.is,https://github.com/hail-is/hail/issues/13567,1,['config'],['configure']
Modifiability,[gear] Add GCPConfig that can be deduced from global config at app runtime,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10957:53,config,config,53,https://hail.is,https://github.com/hail-is/hail/pull/10957,1,['config'],['config']
Modifiability,[global] add batch regions to global-config,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9786:37,config,config,37,https://hail.is,https://github.com/hail-is/hail/pull/9786,1,['config'],['config']
Modifiability,[gradle] update shadow plugin,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10263:23,plugin,plugin,23,https://hail.is,https://github.com/hail-is/hail/pull/10263,1,['plugin'],['plugin']
Modifiability,[grafana] Configure datasources in ConfigMap,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10627:10,Config,Configure,10,https://hail.is,https://github.com/hail-is/hail/pull/10627,2,['Config'],"['ConfigMap', 'Configure']"
Modifiability,[hail/ptypes] improve representation type check for ComplexPType inheritors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7746:65,inherit,inheritors,65,https://hail.is,https://github.com/hail-is/hail/issues/7746,1,['inherit'],['inheritors']
Modifiability,"[hail/ptypes] lift rvd.rowPType/bind to variable, to avoid rvd serialization",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8134:40,variab,variable,40,https://hail.is,https://github.com/hail-is/hail/pull/8134,1,['variab'],['variable']
Modifiability,[hail/ptypes] refactor InferPType.getNestedElementPTypesOfSameType to method on ptype,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7921:14,refactor,refactor,14,https://hail.is,https://github.com/hail-is/hail/issues/7921,1,['refactor'],['refactor']
Modifiability,[hail/ptypes] refactor getNestedElementPTypes,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7927:14,refactor,refactor,14,https://hail.is,https://github.com/hail-is/hail/pull/7927,1,['refactor'],['refactor']
Modifiability,[hail/ptypes] refactor pType.isOfType,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7926:14,refactor,refactor,14,https://hail.is,https://github.com/hail-is/hail/issues/7926,1,['refactor'],['refactor']
Modifiability,[hail] (PTypes) Extend function registry to support returned PTypes,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6650:16,Extend,Extend,16,https://hail.is,https://github.com/hail-is/hail/pull/6650,1,['Extend'],['Extend']
Modifiability,"[hail] Extend AggArrayPerElement to support a ""knownLength"" argument.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6125:7,Extend,Extend,7,https://hail.is,https://github.com/hail-is/hail/pull/6125,1,['Extend'],['Extend']
Modifiability,[hail] Extend ExtractIntervalFilters to operate on key structs,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6302:7,Extend,Extend,7,https://hail.is,https://github.com/hail-is/hail/pull/6302,1,['Extend'],['Extend']
Modifiability,[hail] Extend PruneDeadFields to prune tuples,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6699:7,Extend,Extend,7,https://hail.is,https://github.com/hail-is/hail/pull/6699,1,['Extend'],['Extend']
Modifiability,[hail] Extend TableKeyByAndAggregate => TableAggregateByKey rewrite,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7073:7,Extend,Extend,7,https://hail.is,https://github.com/hail-is/hail/pull/7073,2,"['Extend', 'rewrite']","['Extend', 'rewrite']"
Modifiability,[hail] Extend naming functionality on FunctionBuilder,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7053:7,Extend,Extend,7,https://hail.is,https://github.com/hail-is/hail/pull/7053,1,['Extend'],['Extend']
Modifiability,[hail] Fix memory leak in BM and make cache size configurable,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9501:49,config,configurable,49,https://hail.is,https://github.com/hail-is/hail/pull/9501,1,['config'],['configurable']
Modifiability,[hail] Fix simplify rewrite of ArrayLen(TableCollect),MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7539:20,rewrite,rewrite,20,https://hail.is,https://github.com/hail-is/hail/pull/7539,2,['rewrite'],['rewrite']
Modifiability,"[hail] Introduce ptypes to BGEN, refactor pruning logic to be simpler",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6576:33,refactor,refactor,33,https://hail.is,https://github.com/hail-is/hail/pull/6576,2,['refactor'],['refactor']
Modifiability,[hail] Parameterize check on union_rows. Don't check in `split_multi`,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6669:7,Parameteriz,Parameterize,7,https://hail.is,https://github.com/hail-is/hail/pull/6669,1,['Parameteriz'],['Parameterize']
Modifiability,[hail] Refactor ExtractIntervalFilters,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6298:7,Refactor,Refactor,7,https://hail.is,https://github.com/hail-is/hail/pull/6298,1,['Refactor'],['Refactor']
Modifiability,[hail] Refactor LowerTableIR to use new LoweringPipeline infrastructure.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7535:7,Refactor,Refactor,7,https://hail.is,https://github.com/hail-is/hail/pull/7535,1,['Refactor'],['Refactor']
Modifiability,"[hail] Refactor getOrDefineMethod to be on FB, not EFB",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8108:7,Refactor,Refactor,7,https://hail.is,https://github.com/hail-is/hail/pull/8108,1,['Refactor'],['Refactor']
Modifiability,"[hail] Rewrite PType.subsetTo to avoid using `canonical`, which is wrong",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7870:7,Rewrite,Rewrite,7,https://hail.is,https://github.com/hail-is/hail/pull/7870,1,['Rewrite'],['Rewrite']
Modifiability,[hail] Rewrite VCF INFO Parser to not use htsjdk,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5828:7,Rewrite,Rewrite,7,https://hail.is,https://github.com/hail-is/hail/pull/5828,1,['Rewrite'],['Rewrite']
Modifiability,[hail] Rewrite the boundary of encoders and physical types,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6748:7,Rewrite,Rewrite,7,https://hail.is,https://github.com/hail-is/hail/pull/6748,1,['Rewrite'],['Rewrite']
Modifiability,[hail] Unify sql-config secret creation,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9113:17,config,config,17,https://hail.is,https://github.com/hail-is/hail/pull/9113,1,['config'],['config']
Modifiability,[hail] makefiles traditionally have spaces around variable defs,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6294:50,variab,variable,50,https://hail.is,https://github.com/hail-is/hail/pull/6294,1,['variab'],['variable']
Modifiability,"[hail] parameterize the `In` node by ptype, not virtual type.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7451:7,parameteriz,parameterize,7,https://hail.is,https://github.com/hail-is/hail/pull/7451,1,['parameteriz'],['parameterize']
Modifiability,[hail] refactor RPrimitive.typeSupported,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8765:7,refactor,refactor,7,https://hail.is,https://github.com/hail-is/hail/pull/8765,1,['refactor'],['refactor']
Modifiability,[hail] refactor context and broadcast value handling in TableStage,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7898:7,refactor,refactor,7,https://hail.is,https://github.com/hail-is/hail/pull/7898,1,['refactor'],['refactor']
Modifiability,[hail] remove setRegion(region) parameterization,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/7908:32,parameteriz,parameterization,32,https://hail.is,https://github.com/hail-is/hail/issues/7908,1,['parameteriz'],['parameterization']
Modifiability,[hail] rewrite uniroot in python,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7748:7,rewrite,rewrite,7,https://hail.is,https://github.com/hail-is/hail/pull/7748,1,['rewrite'],['rewrite']
Modifiability,[hail][annotationdb] refactor annotation db,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7178:21,refactor,refactor,21,https://hail.is,https://github.com/hail-is/hail/pull/7178,1,['refactor'],['refactor']
Modifiability,[hail][bugfix] Fix TableFilterIntervals/TableMapRows rewrite,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6419:53,rewrite,rewrite,53,https://hail.is,https://github.com/hail-is/hail/pull/6419,1,['rewrite'],['rewrite']
Modifiability,[hailctl config] Add checking to 'batch/bucket' and 'email',MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9115:9,config,config,9,https://hail.is,https://github.com/hail-is/hail/pull/9115,1,['config'],['config']
Modifiability,"[hailctl dataproc] Use an env variable for log dir, set on dataproc",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10574:30,variab,variable,30,https://hail.is,https://github.com/hail-is/hail/pull/10574,1,['variab'],['variable']
Modifiability,[hailctl] Add basic tests for hailctl config,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13389:38,config,config,38,https://hail.is,https://github.com/hail-is/hail/pull/13389,1,['config'],['config']
Modifiability,[hailctl] Add list command to dump parts of user config,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9529:49,config,config,49,https://hail.is,https://github.com/hail-is/hail/pull/9529,1,['config'],['config']
Modifiability,"[hailctl] Autocomplete for hailctl config {get,set,unset}",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13224:35,config,config,35,https://hail.is,https://github.com/hail-is/hail/pull/13224,1,['config'],['config']
Modifiability,[hailctl] Configure Hail/Spark to use proper memory allocations,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11016:10,Config,Configure,10,https://hail.is,https://github.com/hail-is/hail/pull/11016,1,['Config'],['Configure']
Modifiability,[hailctl] Dev config set should only change one property,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14169:14,config,config,14,https://hail.is,https://github.com/hail-is/hail/pull/14169,1,['config'],['config']
Modifiability,[hailctl] Don't parameterize safe_call on python version,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10324:16,parameteriz,parameterize,16,https://hail.is,https://github.com/hail-is/hail/pull/10324,1,['parameteriz'],['parameterize']
Modifiability,[hailctl] Dont copy the user's config file into hailctl batch submit jobs,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13506:31,config,config,31,https://hail.is,https://github.com/hail-is/hail/pull/13506,1,['config'],['config']
Modifiability,[hailctl] Dont show local variables in stacktraces,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13212:26,variab,variables,26,https://hail.is,https://github.com/hail-is/hail/pull/13212,1,['variab'],['variables']
Modifiability,[hailctl] Fix config file name,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9493:14,config,config,14,https://hail.is,https://github.com/hail-is/hail/pull/9493,1,['config'],['config']
Modifiability,[hailctl] Fix environments and configurations so things actually work.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6297:31,config,configurations,31,https://hail.is,https://github.com/hail-is/hail/pull/6297,1,['config'],['configurations']
Modifiability,[hailctl] Move default location for hail config directory,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/7125:41,config,config,41,https://hail.is,https://github.com/hail-is/hail/pull/7125,1,['config'],['config']
Modifiability,[hailctl] include deploy configuration in module,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/6196:25,config,configuration,25,https://hail.is,https://github.com/hail-is/hail/pull/6196,1,['config'],['configuration']
Modifiability,[hailctl] rewrite argument parsing,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9842:10,rewrite,rewrite,10,https://hail.is,https://github.com/hail-is/hail/pull/9842,1,['rewrite'],['rewrite']
Modifiability,[hailctl] support missing domain in deploy config,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11333:43,config,config,43,https://hail.is,https://github.com/hail-is/hail/pull/11333,1,['config'],['config']
Modifiability,[hailctl] use consistent names for variables,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10240:35,variab,variables,35,https://hail.is,https://github.com/hail-is/hail/pull/10240,1,['variab'],['variables']
Modifiability,[hailctl][batch] add hailctl config & make tests work locally,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8559:29,config,config,29,https://hail.is,https://github.com/hail-is/hail/pull/8559,1,['config'],['config']
Modifiability,[hailtop] Add subpath to deploy config,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14056:32,config,config,32,https://hail.is,https://github.com/hail-is/hail/pull/14056,1,['config'],['config']
Modifiability,[hailtop] Fix defaulting to hail.is when the user has no deploy-config,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13585:64,config,config,64,https://hail.is,https://github.com/hail-is/hail/pull/13585,1,['config'],['config']
Modifiability,[hailtop] allow configuration of default HTTP timeout,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14206:16,config,configuration,16,https://hail.is,https://github.com/hail-is/hail/pull/14206,1,['config'],['configuration']
Modifiability,[influxdb] Influxdb Config,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10725:20,Config,Config,20,https://hail.is,https://github.com/hail-is/hail/pull/10725,1,['Config'],['Config']
Modifiability,[infra] Add resource group to azure terraform state remote config,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13125:59,config,config,59,https://hail.is,https://github.com/hail-is/hail/pull/13125,1,['config'],['config']
Modifiability,[infra] Add scripts for azure setup and sql/global configs,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10919:51,config,configs,51,https://hail.is,https://github.com/hail-is/hail/pull/10919,1,['config'],['configs']
Modifiability,[infra] Configure GCP peering routes in tf intsead of manually,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11031:8,Config,Configure,8,https://hail.is,https://github.com/hail-is/hail/pull/11031,1,['Config'],['Configure']
Modifiability,[infra] Move azure from mysql single server to mysql flexible server,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11423:53,flexible,flexible,53,https://hail.is,https://github.com/hail-is/hail/pull/11423,1,['flexible'],['flexible']
Modifiability,[infra] Provide namespace variable to bootstrap uses of make deploy,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12044:26,variab,variable,26,https://hail.is,https://github.com/hail-is/hail/pull/12044,1,['variab'],['variable']
Modifiability,[infra] Remove hard-coded values from config.mk,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11414:38,config,config,38,https://hail.is,https://github.com/hail-is/hail/pull/11414,1,['config'],['config']
Modifiability,[infra] Revert GKE metadata workload identity config,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13208:46,config,config,46,https://hail.is,https://github.com/hail-is/hail/pull/13208,1,['config'],['config']
Modifiability,[infra] Update gcp global-config with cloud field,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11012:26,config,config,26,https://hail.is,https://github.com/hail-is/hail/pull/11012,1,['config'],['config']
Modifiability,[infra] Use https instead of hail-az in service configs,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14290:48,config,configs,48,https://hail.is,https://github.com/hail-is/hail/pull/14290,1,['config'],['configs']
Modifiability,[infra] allow configuration of oauth2 callback list,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11322:14,config,configuration,14,https://hail.is,https://github.com/hail-is/hail/pull/11322,1,['config'],['configuration']
Modifiability,[k8s] Use global config values from k8s secret when possible,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10869:17,config,config,17,https://hail.is,https://github.com/hail-is/hail/pull/10869,1,['config'],['config']
Modifiability,[local] Parameterize heap size of local backend,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13122:8,Parameteriz,Parameterize,8,https://hail.is,https://github.com/hail-is/hail/pull/13122,1,['Parameteriz'],['Parameterize']
Modifiability,[lowering] Rewrite maximal independent set to be its own value IR,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12295:11,Rewrite,Rewrite,11,https://hail.is,https://github.com/hail-is/hail/pull/12295,1,['Rewrite'],['Rewrite']
Modifiability,[lowering] TableStage Refactor / TableParallelize Lowering Improvement,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8627:22,Refactor,Refactor,22,https://hail.is,https://github.com/hail-is/hail/pull/8627,1,['Refactor'],['Refactor']
Modifiability,[make] Make pytest-qob not change the user's hail config,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12368:50,config,config,50,https://hail.is,https://github.com/hail-is/hail/pull/12368,1,['config'],['config']
Modifiability,[many] put shared make config in config.mk file,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9339:23,config,config,23,https://hail.is,https://github.com/hail-is/hail/pull/9339,2,['config'],['config']
Modifiability,[memory] Use GCP project from GCPConfig not env variable,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10961:48,variab,variable,48,https://hail.is,https://github.com/hail-is/hail/pull/10961,1,['variab'],['variable']
Modifiability,[nginx] ensure nginx configs dont overwrite each other in build.yaml,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10181:21,config,configs,21,https://hail.is,https://github.com/hail-is/hail/pull/10181,1,['config'],['configs']
Modifiability,[notebook] cleanup notebook_app too and refactor app config,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9983:40,refactor,refactor,40,https://hail.is,https://github.com/hail-is/hail/pull/9983,2,"['config', 'refactor']","['config', 'refactor']"
Modifiability,[notebook] notebook also need global config now,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12429:37,config,config,37,https://hail.is,https://github.com/hail-is/hail/pull/12429,1,['config'],['config']
Modifiability,[notebook][hailtop][gear] move logging configuration out of gear,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9122:39,config,configuration,39,https://hail.is,https://github.com/hail-is/hail/pull/9122,1,['config'],['configuration']
Modifiability,[pipeline] Refactor backend code,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5962:11,Refactor,Refactor,11,https://hail.is,https://github.com/hail-is/hail/pull/5962,1,['Refactor'],['Refactor']
Modifiability,[qob] Update scala deploy config to use new base_path field,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14195:26,config,config,26,https://hail.is,https://github.com/hail-is/hail/pull/14195,1,['config'],['config']
Modifiability,"[query, wip] Some aggregator refactoring",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14289:29,refactor,refactoring,29,https://hail.is,https://github.com/hail-is/hail/pull/14289,1,['refactor'],['refactoring']
Modifiability,[query/ggplot] Adds configurable legend format to point geom,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12244:20,config,configurable,20,https://hail.is,https://github.com/hail-is/hail/pull/12244,1,['config'],['configurable']
Modifiability,[query/service] streamline & standardize configuration for query,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11745:41,config,configuration,41,https://hail.is,https://github.com/hail-is/hail/pull/11745,1,['config'],['configuration']
Modifiability,[query] Add JAVA_HOME configuration to Makefile,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9221:22,config,configuration,22,https://hail.is,https://github.com/hail-is/hail/pull/9221,1,['config'],['configuration']
Modifiability,[query] Add adaptive branching to LowerDistributedSort,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11811:12,adapt,adaptive,12,https://hail.is,https://github.com/hail-is/hail/pull/11811,1,['adapt'],['adaptive']
Modifiability,[query] Drastically simplify binding-based computation/rewrite code,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9247:55,rewrite,rewrite,55,https://hail.is,https://github.com/hail-is/hail/pull/9247,2,['rewrite'],['rewrite']
Modifiability,[query] Extend BindingEnv to include relational bindings,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9041:8,Extend,Extend,8,https://hail.is,https://github.com/hail-is/hail/pull/9041,1,['Extend'],['Extend']
Modifiability,[query] Extend `func_spec` to support functions with default arguments,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12814:8,Extend,Extend,8,https://hail.is,https://github.com/hail-is/hail/pull/12814,1,['Extend'],['Extend']
Modifiability,[query] Extend `hl.export_vcf` to work on Table,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8914:8,Extend,Extend,8,https://hail.is,https://github.com/hail-is/hail/pull/8914,1,['Extend'],['Extend']
Modifiability,[query] Fix TableAggregateByKey with extended physical key,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8729:37,extend,extended,37,https://hail.is,https://github.com/hail-is/hail/pull/8729,1,['extend'],['extended']
Modifiability,[query] Fix `intervals` option on read with extended key,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8708:44,extend,extended,44,https://hail.is,https://github.com/hail-is/hail/pull/8708,1,['extend'],['extended']
Modifiability,[query] Fix lowering of aggs to preserve free variables in init args,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12092:46,variab,variables,46,https://hail.is,https://github.com/hail-is/hail/pull/12092,1,['variab'],['variables']
Modifiability,[query] Make VEP on Dataproc not require a config,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8929:43,config,config,43,https://hail.is,https://github.com/hail-is/hail/pull/8929,1,['config'],['config']
Modifiability,[query] Parameterize Hail Query Class Loading by ClassLoader,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11212:8,Parameteriz,Parameterize,8,https://hail.is,https://github.com/hail-is/hail/pull/11212,1,['Parameteriz'],['Parameterize']
Modifiability,[query] Refactor LoweringPipeline so that optimization is a pass,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9030:8,Refactor,Refactor,8,https://hail.is,https://github.com/hail-is/hail/pull/9030,1,['Refactor'],['Refactor']
Modifiability,[query] Refactor NDArray constructor interfaces,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9960:8,Refactor,Refactor,8,https://hail.is,https://github.com/hail-is/hail/pull/9960,1,['Refactor'],['Refactor']
Modifiability,[query] Refactor PNDArray.construct to return a PCode,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9719:8,Refactor,Refactor,8,https://hail.is,https://github.com/hail-is/hail/pull/9719,1,['Refactor'],['Refactor']
Modifiability,[query] Refactor PStruct to avoid abstract methods,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8528:8,Refactor,Refactor,8,https://hail.is,https://github.com/hail-is/hail/pull/8528,1,['Refactor'],['Refactor']
Modifiability,[query] Refactor `coerce` functions,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12333:8,Refactor,Refactor,8,https://hail.is,https://github.com/hail-is/hail/pull/12333,1,['Refactor'],['Refactor']
Modifiability,[query] Refactor agg lowering to use new InitFromSerializedState node,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9024:8,Refactor,Refactor,8,https://hail.is,https://github.com/hail-is/hail/pull/9024,1,['Refactor'],['Refactor']
Modifiability,[query] Refactor and fix Backend's persist and unpersist,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12864:8,Refactor,Refactor,8,https://hail.is,https://github.com/hail-is/hail/pull/12864,1,['Refactor'],['Refactor']
Modifiability,[query] Refactor define_function to go through backend.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9287:8,Refactor,Refactor,8,https://hail.is,https://github.com/hail-is/hail/pull/9287,1,['Refactor'],['Refactor']
Modifiability,[query] Refactor function registry to not use overloading,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8570:8,Refactor,Refactor,8,https://hail.is,https://github.com/hail-is/hail/pull/8570,1,['Refactor'],['Refactor']
Modifiability,"[query] Refactor ggplot to use pandas, support alpha on histograms and bar charts",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11317:8,Refactor,Refactor,8,https://hail.is,https://github.com/hail-is/hail/pull/11317,1,['Refactor'],['Refactor']
Modifiability,[query] Refactor incomplete struct ordering to be distinct functionality,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8674:8,Refactor,Refactor,8,https://hail.is,https://github.com/hail-is/hail/pull/8674,1,['Refactor'],['Refactor']
Modifiability,[query] Refactor lowering to expose ExecuteContext,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8614:8,Refactor,Refactor,8,https://hail.is,https://github.com/hail-is/hail/pull/8614,1,['Refactor'],['Refactor']
Modifiability,[query] Refactor registerIEmitCode to use EmitCode instead of thunks,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9977:8,Refactor,Refactor,8,https://hail.is,https://github.com/hail-is/hail/pull/9977,1,['Refactor'],['Refactor']
Modifiability,[query] Refactor stream lengths to use code builders,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10446:8,Refactor,Refactor,8,https://hail.is,https://github.com/hail-is/hail/pull/10446,1,['Refactor'],['Refactor']
Modifiability,"[query] Refactor struct code constructor to take codes, not values",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9951:8,Refactor,Refactor,8,https://hail.is,https://github.com/hail-is/hail/pull/9951,1,['Refactor'],['Refactor']
Modifiability,[query] Refactor vds.sample_qc to use independent aggregators,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14297:8,Refactor,Refactor,8,https://hail.is,https://github.com/hail-is/hail/pull/14297,1,['Refactor'],['Refactor']
Modifiability,[query] Rewrite ExportEntriesByCol to stage locally,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8613:8,Rewrite,Rewrite,8,https://hail.is,https://github.com/hail-is/hail/pull/8613,1,['Rewrite'],['Rewrite']
Modifiability,[query] Rewrite import_table type imputation in Python,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9086:8,Rewrite,Rewrite,8,https://hail.is,https://github.com/hail-is/hail/pull/9086,1,['Rewrite'],['Rewrite']
Modifiability,[query] Rewrite ld prune to use java objects for filtering,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12076:8,Rewrite,Rewrite,8,https://hail.is,https://github.com/hail-is/hail/pull/12076,1,['Rewrite'],['Rewrite']
Modifiability,[query] Some refactoring of TableStage,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8917:13,refactor,refactoring,13,https://hail.is,https://github.com/hail-is/hail/pull/8917,1,['refactor'],['refactoring']
Modifiability,[query] correctly handle variables used in aggregator init ops,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/14305:25,variab,variables,25,https://hail.is,https://github.com/hail-is/hail/issues/14305,1,['variab'],['variables']
Modifiability,[query] do not store function return values in variables,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13777:47,variab,variables,47,https://hail.is,https://github.com/hail-is/hail/pull/13777,1,['variab'],['variables']
Modifiability,[query] more refactoring towards removing SCode,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10797:13,refactor,refactoring,13,https://hail.is,https://github.com/hail-is/hail/pull/10797,1,['refactor'],['refactoring']
Modifiability,[query] parameterize field name of TableGroupWithinPartitions and add parser tests,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8607:8,parameteriz,parameterize,8,https://hail.is,https://github.com/hail-is/hail/pull/8607,1,['parameteriz'],['parameterize']
Modifiability,[query] parameterize test expr,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11934:8,parameteriz,parameterize,8,https://hail.is,https://github.com/hail-is/hail/pull/11934,1,['parameteriz'],['parameterize']
Modifiability,[query] refactor BaseIR so children only exposes iterable interface,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13214:8,refactor,refactor,8,https://hail.is,https://github.com/hail-is/hail/pull/13214,1,['refactor'],['refactor']
Modifiability,[query] refactor Code[_],MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8211:8,refactor,refactor,8,https://hail.is,https://github.com/hail-is/hail/pull/8211,1,['refactor'],['refactor']
Modifiability,[query] refactor MakeRVDSpec to have intermediate with no partFiles,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8924:8,refactor,refactor,8,https://hail.is,https://github.com/hail-is/hail/pull/8924,1,['refactor'],['refactor']
Modifiability,[query] refactor PCNDArray constructors,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10769:8,refactor,refactor,8,https://hail.is,https://github.com/hail-is/hail/pull/10769,1,['refactor'],['refactor']
Modifiability,[query] refactor Stream to top-level class,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8547:8,refactor,refactor,8,https://hail.is,https://github.com/hail-is/hail/pull/8547,1,['refactor'],['refactor']
Modifiability,[query] refactor TableStage.context for ease of use and better scoping,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8658:8,refactor,refactor,8,https://hail.is,https://github.com/hail-is/hail/pull/8658,1,['refactor'],['refactor']
Modifiability,[query] refactor approx_cdf to support manual combining,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13935:8,refactor,refactor,8,https://hail.is,https://github.com/hail-is/hail/pull/13935,1,['refactor'],['refactor']
Modifiability,[query] refactor block matrix persistence to take backend context,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9421:8,refactor,refactor,8,https://hail.is,https://github.com/hail-is/hail/pull/9421,1,['refactor'],['refactor']
Modifiability,[query] refactor math in linear_regression_rows,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11070:8,refactor,refactor,8,https://hail.is,https://github.com/hail-is/hail/pull/11070,1,['refactor'],['refactor']
Modifiability,"[query] refactor pca, add spectral moments estimators",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11045:8,refactor,refactor,8,https://hail.is,https://github.com/hail-is/hail/pull/11045,1,['refactor'],['refactor']
Modifiability,[query] refactor primitive SValue -> Value accessor,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11242:8,refactor,refactor,8,https://hail.is,https://github.com/hail-is/hail/pull/11242,1,['refactor'],['refactor']
Modifiability,[query] refactor stream length tracking,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8519:8,refactor,refactor,8,https://hail.is,https://github.com/hail-is/hail/pull/8519,1,['refactor'],['refactor']
Modifiability,[query] store job configuration in user bucket,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8937:18,config,configuration,18,https://hail.is,https://github.com/hail-is/hail/pull/8937,1,['config'],['configuration']
Modifiability,[query] use parameterization for test_blanczos_flags,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13694:12,parameteriz,parameterization,12,https://hail.is,https://github.com/hail-is/hail/pull/13694,1,['parameteriz'],['parameterization']
Modifiability,[query][aggs][ptypes] refactor extracted agg signatures,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8800:22,refactor,refactor,22,https://hail.is,https://github.com/hail-is/hail/pull/8800,1,['refactor'],['refactor']
Modifiability,[query][qggs] refactor PhysicalAggSig,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8996:14,refactor,refactor,14,https://hail.is,https://github.com/hail-is/hail/pull/8996,1,['refactor'],['refactor']
Modifiability,[query][smm 4] rewrite StreamFold and StreamFold2 to prepare for memory management,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/9177:15,rewrite,rewrite,15,https://hail.is,https://github.com/hail-is/hail/pull/9177,1,['rewrite'],['rewrite']
Modifiability,[release] Fix EV syntax in release job for WHEEL variable,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14436:49,variab,variable,49,https://hail.is,https://github.com/hail-is/hail/pull/14436,1,['variab'],['variable']
Modifiability,"[ruff](https://beta.ruff.rs/docs/) is a *very* fast linter that we can use as a drop-in replacement for flake8 and isort. Fast enough to run in a pre-commit hook. While there are many pylint rules implemented in ruff, it is not at parity with pylint yet. This PR replaces flake8 and isort in favor of ruff but does not remove pylint yet. Nevertheless, from what I have seen so far ruff + mypy does catch a vast swath of everyday errors, and I have found that the 30+ seconds it can take to run pylint on any of our python modules is a deterrent to me linting often and catching lint errors early. So I added Makefile targets such as `check-batch-fast` that run all the linters except for pylint. The `check-batch` rule now does `check-batch-fast` and `pylint-batch`. So linter coverage should have strictly increased in CI, but there is a <5s linting target now available for devs in addition to the >30s it can take to also run pylint. You can also now just run `ruff .` in the root of the repo and it completes for me in 0.293 seconds. For the most part in this PR, I added ruff, with the config enabling flake8 + isort + pylint rules, then disabled rules until there were no errors, save for a few rules that I thought to just fix immediately. These mostly line up with the flake8 rules we had already disabled. I also then added ruff's own ruleset ([RUF](https://beta.ruff.rs/docs/rules/#ruff-specific-rules-ruf)) particularly because I appreciated the `asyncio-dangling-task` and `unused-noqa` rules.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12967:1091,config,config,1091,https://hail.is,https://github.com/hail-is/hail/pull/12967,1,['config'],['config']
Modifiability,[services] Fix domain configuration in dev namespaces,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14164:22,config,configuration,22,https://hail.is,https://github.com/hail-is/hail/pull/14164,1,['config'],['configuration']
Modifiability,[shuffle] Track bytes from initial write; adaptive branching all the …,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/11850:42,adapt,adaptive,42,https://hail.is,https://github.com/hail-is/hail/pull/11850,1,['adapt'],['adaptive']
Modifiability,[shuffler] Refactor/simplify codegen interfaces,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10421:11,Refactor,Refactor,11,https://hail.is,https://github.com/hail-is/hail/pull/10421,1,['Refactor'],['Refactor']
Modifiability,[terraform] Add test bucket to the terraform global config,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10807:52,config,config,52,https://hail.is,https://github.com/hail-is/hail/pull/10807,1,['config'],['config']
Modifiability,[test] FSSuite extends TestNGSuite,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/12243:15,extend,extends,15,https://hail.is,https://github.com/hail-is/hail/pull/12243,1,['extend'],['extends']
Modifiability,[tests] use generated config and real sha for tests,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/5813:22,config,config,22,https://hail.is,https://github.com/hail-is/hail/pull/5813,1,['config'],['config']
Modifiability,[tls] Make ssl configs use a relative path,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10275:15,config,configs,15,https://hail.is,https://github.com/hail-is/hail/pull/10275,1,['config'],['configs']
Modifiability,[tls] make internal cert config optional,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/13187:25,config,config,25,https://hail.is,https://github.com/hail-is/hail/pull/13187,1,['config'],['config']
Modifiability,"[uv](https://github.com/astral-sh/uv) is a new package resolver by the same folks who make `ruff`. It's boasted for being really fast, which honestly it is, but mostly it's appealing to me because they support generating lockfiles for alternative platforms and python versions than the system you run it on, which allows us to delete all this dockerizing `pip-compile` in order to generate lockfiles for linux. It's a really green project, so I'm open to pushback on incorporating it, but it seemed like a worthwhile simplification. I also quite like that it allows for additional strategies in generating lockfiles. By default, it behaves as would be expected, where it locks packages to the highest version within the acceptable bounds. But you can also configure it to generate the *lowest* acceptable pins, so we could actually verify whether the lower bounds that we have in our requirements files are actually acceptable or not.",MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/14503:756,config,configure,756,https://hail.is,https://github.com/hail-is/hail/pull/14503,1,['config'],['configure']
Modifiability,[vcf-combiner] Refactor VCF combiner to support other GVCF schemas.,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/8942:15,Refactor,Refactor,15,https://hail.is,https://github.com/hail-is/hail/pull/8942,1,['Refactor'],['Refactor']
Modifiability,[vds/combiner] ensure variable is defined on all code paths,MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/pull/10934:22,variab,variable,22,https://hail.is,https://github.com/hail-is/hail/pull/10934,1,['variab'],['variable']
Modifiability,_.py'; adding 'hailtop/config/deploy_config.py'; adding 'hailtop/config/user_config.py'; adding 'hailtop/fs/__init__.py'; adding 'hailtop/fs/fs.py'; adding 'hailtop/fs/fs_utils.py'; adding 'hailtop/fs/router_fs.py'; adding 'hailtop/fs/stat_result.py'; adding 'hailtop/hailctl/__init__.py'; adding 'hailtop/hailctl/__main__.py'; adding 'hailtop/hailctl/deploy.yaml'; adding 'hailtop/hailctl/describe.py'; adding 'hailtop/hailctl/auth/__init__.py'; adding 'hailtop/hailctl/auth/cli.py'; adding 'hailtop/hailctl/auth/create_user.py'; adding 'hailtop/hailctl/auth/delete_user.py'; adding 'hailtop/hailctl/auth/login.py'; adding 'hailtop/hailctl/batch/__init__.py'; adding 'hailtop/hailctl/batch/batch_cli_utils.py'; adding 'hailtop/hailctl/batch/cli.py'; adding 'hailtop/hailctl/batch/list_batches.py'; adding 'hailtop/hailctl/batch/submit.py'; adding 'hailtop/hailctl/batch/billing/__init__.py'; adding 'hailtop/hailctl/batch/billing/cli.py'; adding 'hailtop/hailctl/config/__init__.py'; adding 'hailtop/hailctl/config/cli.py'; adding 'hailtop/hailctl/dataproc/__init__.py'; adding 'hailtop/hailctl/dataproc/cli.py'; adding 'hailtop/hailctl/dataproc/cluster_config.py'; adding 'hailtop/hailctl/dataproc/connect.py'; adding 'hailtop/hailctl/dataproc/deploy_metadata.py'; adding 'hailtop/hailctl/dataproc/diagnose.py'; adding 'hailtop/hailctl/dataproc/gcloud.py'; adding 'hailtop/hailctl/dataproc/modify.py'; adding 'hailtop/hailctl/dataproc/start.py'; adding 'hailtop/hailctl/dataproc/submit.py'; adding 'hailtop/hailctl/dataproc/utils.py'; adding 'hailtop/hailctl/dev/__init__.py'; adding 'hailtop/hailctl/dev/ci_client.py'; adding 'hailtop/hailctl/dev/cli.py'; adding 'hailtop/hailctl/dev/config.py'; adding 'hailtop/hailctl/hdinsight/__init__.py'; adding 'hailtop/hailctl/hdinsight/cli.py'; adding 'hailtop/hailctl/hdinsight/start.py'; adding 'hailtop/hailctl/hdinsight/submit.py'; adding 'hailtop/utils/__init__.py'; adding 'hailtop/utils/process.py'; adding 'hailtop/utils/rate_limiter.py'; adding ',MatchSource.ISSUE,hail-is,hail,0.2.133,https://github.com/hail-is/hail/issues/13445:11831,config,config,11831,https://hail.is,https://github.com/hail-is/hail/issues/13445,1,['config'],['config']
